{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef elemDump(self, f, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.xmlElemDump(f, self._o, cur__o)", "response": "Dump an XML node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef formatDump(self, f, format):\n        ret = libxml2mod.xmlDocFormatDump(f, self._o, format)\n        return ret", "response": "Dump an XML document to an open FILE object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getRootElement(self):\n        ret = libxml2mod.xmlDocGetRootElement(self._o)\n        if ret is None:raise treeError('xmlDocGetRootElement() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Get the root element of the document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the internal subset of the document", "response": "def intSubset(self):\n        \"\"\"Get the internal subset of a document \"\"\"\n        ret = libxml2mod.xmlGetIntSubset(self._o)\n        if ret is None:raise treeError('xmlGetIntSubset() failed')\n        __tmp = xmlDtd(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef newDocComment(self, content):\n        ret = libxml2mod.xmlNewDocComment(self._o, content)\n        if ret is None:raise treeError('xmlNewDocComment() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new node containing a comment within a document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef newDocFragment(self):\n        ret = libxml2mod.xmlNewDocFragment(self._o)\n        if ret is None:raise treeError('xmlNewDocFragment() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new Fragment node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef newDocNode(self, ns, name, content):\n        if ns is None: ns__o = None\n        else: ns__o = ns._o\n        ret = libxml2mod.xmlNewDocNode(self._o, ns__o, name, content)\n        if ret is None:raise treeError('xmlNewDocNode() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new node element within a document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newDocProp(self, name, value):\n        ret = libxml2mod.xmlNewDocProp(self._o, name, value)\n        if ret is None:raise treeError('xmlNewDocProp() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp", "response": "Create a new property carried by a document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef newDocTextLen(self, content, len):\n        ret = libxml2mod.xmlNewDocTextLen(self._o, content, len)\n        if ret is None:raise treeError('xmlNewDocTextLen() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new text node with an extra content length\n           parameter. The content is the content of the node. The length of the node is len."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef newDtd(self, name, ExternalID, SystemID):\n        ret = libxml2mod.xmlNewDtd(self._o, name, ExternalID, SystemID)\n        if ret is None:raise treeError('xmlNewDtd() failed')\n        __tmp = xmlDtd(_obj=ret)\n        return __tmp", "response": "Creation of a new DTD for the external subset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef newGlobalNs(self, href, prefix):\n        ret = libxml2mod.xmlNewGlobalNs(self._o, href, prefix)\n        if ret is None:raise treeError('xmlNewGlobalNs() failed')\n        __tmp = xmlNs(_obj=ret)\n        return __tmp", "response": "Creation of a Namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nodeDumpOutput(self, buf, cur, level, format, encoding):\n        if buf is None: buf__o = None\n        else: buf__o = buf._o\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.xmlNodeDumpOutput(buf__o, self._o, cur__o, level, format, encoding)", "response": "Dump an XML node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nodeGetBase(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlNodeGetBase(self._o, cur__o)\n        return ret", "response": "Searches for the BASE URL of the node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild the string representation of the node list", "response": "def nodeListGetRawString(self, list, inLine):\n        \"\"\"Builds the string equivalent to the text contained in the\n          Node list made of TEXTs and ENTITY_REFs, contrary to\n          xmlNodeListGetString() this function doesn't do any\n           character encoding handling. \"\"\"\n        if list is None: list__o = None\n        else: list__o = list._o\n        ret = libxml2mod.xmlNodeListGetRawString(self._o, list__o, inLine)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nodeListGetString(self, list, inLine):\n        if list is None: list__o = None\n        else: list__o = list._o\n        ret = libxml2mod.xmlNodeListGetString(self._o, list__o, inLine)\n        return ret", "response": "Build the string equivalent to the text contained in the the\n           node list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef saveFile(self, filename):\n        ret = libxml2mod.xmlSaveFile(filename, self._o)\n        return ret", "response": "Dump an XML document to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef saveFileEnc(self, filename, encoding):\n        ret = libxml2mod.xmlSaveFileEnc(filename, self._o, encoding)\n        return ret", "response": "Save an XML document to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef saveFileTo(self, buf, encoding):\n        if buf is None: buf__o = None\n        else: buf__o = buf._o\n        ret = libxml2mod.xmlSaveFileTo(buf__o, self._o, encoding)\n        return ret", "response": "Dump an XML document to a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump an XML document to a file.", "response": "def saveFormatFile(self, filename, format):\n        \"\"\"Dump an XML document to a file. Will use compression if\n          compiled in and enabled. If @filename is \"-\" the stdout\n          file is used. If @format is set then the document will be\n          indented on output. Note that @format = 1 provide node\n          indenting only if xmlIndentTreeOutput = 1 or\n           xmlKeepBlanksDefault(0) was called \"\"\"\n        ret = libxml2mod.xmlSaveFormatFile(filename, self._o, format)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef saveFormatFileEnc(self, filename, encoding, format):\n        ret = libxml2mod.xmlSaveFormatFileEnc(filename, self._o, encoding, format)\n        return ret", "response": "Dump an XML document to a file or an URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saveFormatFileTo(self, buf, encoding, format):\n        if buf is None: buf__o = None\n        else: buf__o = buf._o\n        ret = libxml2mod.xmlSaveFormatFileTo(buf__o, self._o, encoding, format)\n        return ret", "response": "Dump an XML document to a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef searchNs(self, node, nameSpace):\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlSearchNs(self._o, node__o, nameSpace)\n        if ret is None:raise treeError('xmlSearchNs() failed')\n        __tmp = xmlNs(_obj=ret)\n        return __tmp", "response": "Search a namespace for a given name space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef searchNsByHref(self, node, href):\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlSearchNsByHref(self._o, node__o, href)\n        if ret is None:raise treeError('xmlSearchNsByHref() failed')\n        __tmp = xmlNs(_obj=ret)\n        return __tmp", "response": "Search a namespace by href."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating all nodes in the list to point to the right document", "response": "def setListDoc(self, list):\n        \"\"\"update all nodes in the list to point to the right document \"\"\"\n        if list is None: list__o = None\n        else: list__o = list._o\n        libxml2mod.xmlSetListDoc(list__o, self._o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setRootElement(self, root):\n        if root is None: root__o = None\n        else: root__o = root._o\n        ret = libxml2mod.xmlDocSetRootElement(self._o, root__o)\n        if ret is None:return None\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Set the root element of the document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all nodes under the tree to point to the right document", "response": "def setTreeDoc(self, tree):\n        \"\"\"update all nodes under the tree to point to the right\n           document \"\"\"\n        if tree is None: tree__o = None\n        else: tree__o = tree._o\n        libxml2mod.xmlSetTreeDoc(tree__o, self._o)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the value string and build the node list associated with it", "response": "def stringGetNodeList(self, value):\n        \"\"\"Parse the value string and build the node list associated.\n           Should produce a flat tree with only TEXTs and ENTITY_REFs. \"\"\"\n        ret = libxml2mod.xmlStringGetNodeList(self._o, value)\n        if ret is None:raise treeError('xmlStringGetNodeList() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stringLenGetNodeList(self, value, len):\n        ret = libxml2mod.xmlStringLenGetNodeList(self._o, value, len)\n        if ret is None:raise treeError('xmlStringLenGetNodeList() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Parse the value string and build the node list associated with it"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches the attribute declaring the given ID", "response": "def ID(self, ID):\n        \"\"\"Search the attribute declaring the given ID \"\"\"\n        ret = libxml2mod.xmlGetID(self._o, ID)\n        if ret is None:raise treeError('xmlGetID() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef isID(self, elem, attr):\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlIsID(self._o, elem__o, attr__o)\n        return ret", "response": "Determine if an element is of type ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isMixedElement(self, name):\n        ret = libxml2mod.xmlIsMixedElement(self._o, name)\n        return ret", "response": "Search in the DtDs whether an element is mixed by its name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isRef(self, elem, attr):\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlIsRef(self._o, elem__o, attr__o)\n        return ret", "response": "Determine if an attribute is of type Ref"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the given attribute from the ID table maintained internally.", "response": "def removeID(self, attr):\n        \"\"\"Remove the given attribute from the ID table maintained\n           internally. \"\"\"\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlRemoveID(self._o, attr__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the given attribute from the Ref table maintained internally.", "response": "def removeRef(self, attr):\n        \"\"\"Remove the given attribute from the Ref table maintained\n           internally. \"\"\"\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlRemoveRef(self._o, attr__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validCtxtNormalizeAttributeValue(self, ctxt, elem, name, value):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidCtxtNormalizeAttributeValue(ctxt__o, self._o, elem__o, name, value)\n        return ret", "response": "This function is called by the XML processor to normalize the value of an attribute value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing the normalization of the attribute values.", "response": "def validNormalizeAttributeValue(self, elem, name, value):\n        \"\"\"Does the validation related extra step of the normalization\n          of attribute values:  If the declared value is not CDATA,\n          then the XML processor must further process the normalized\n          attribute value by discarding any leading and trailing\n          space (#x20) characters, and by replacing sequences of\n           space (#x20) characters by single space (#x20) character. \"\"\"\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidNormalizeAttributeValue(self._o, elem__o, name, value)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the document instance", "response": "def validateDocument(self, ctxt):\n        \"\"\"Try to validate the document instance  basically it does\n          the all the checks described by the XML Rec i.e. validates\n          the internal and external subset (if present) and validate\n           the document tree. \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlValidateDocument(ctxt__o, self._o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validateDocumentFinal(self, ctxt):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlValidateDocumentFinal(ctxt__o, self._o)\n        return ret", "response": "Does the final step for the document validation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validateDtd(self, ctxt, dtd):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if dtd is None: dtd__o = None\n        else: dtd__o = dtd._o\n        ret = libxml2mod.xmlValidateDtd(ctxt__o, self._o, dtd__o)\n        return ret", "response": "Validate the document against the DTD instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validateDtdFinal(self, ctxt):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlValidateDtdFinal(ctxt__o, self._o)\n        return ret", "response": "Does the final validation of the dtds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validateElement(self, ctxt, elem):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidateElement(ctxt__o, self._o, elem__o)\n        return ret", "response": "Validate the subtree under an element"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the given name matches a notation declaration.", "response": "def validateNotationUse(self, ctxt, notationName):\n        \"\"\"Validate that the given name match a notation declaration.\n           - [ VC: Notation Declared ] \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlValidateNotationUse(ctxt__o, self._o, notationName)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validateOneAttribute(self, ctxt, elem, attr, value):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlValidateOneAttribute(ctxt__o, self._o, elem__o, attr__o, value)\n        return ret", "response": "This function checks if a single attribute is valid for the given element and attribute."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validateOneElement(self, ctxt, elem):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidateOneElement(ctxt__o, self._o, elem__o)\n        return ret", "response": "This function checks if a single element and its attributes are present in the XML document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to validate a single namespace declaration for an element basically it does the following checks as described by the XML-1.0 recommendation: - [ VC: Attribute Value Type ] - [ VC: Fixed Attribute Default ] - [ VC: Entity Name ] - [ VC: Name Token ] - [ VC: ID ] - [ VC: IDREF ] - [ VC: Entity Name ] - [ VC: Notation Attributes ] The ID/IDREF uniqueness and matching are done separately", "response": "def validateOneNamespace(self, ctxt, elem, prefix, ns, value):\n        \"\"\"Try to validate a single namespace declaration for an\n          element basically it does the following checks as described\n          by the XML-1.0 recommendation: - [ VC: Attribute Value Type\n          ] - [ VC: Fixed Attribute Default ] - [ VC: Entity Name ] -\n          [ VC: Name Token ] - [ VC: ID ] - [ VC: IDREF ] - [ VC:\n          Entity Name ] - [ VC: Notation Attributes ]  The ID/IDREF\n           uniqueness and matching are done separately \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if ns is None: ns__o = None\n        else: ns__o = ns._o\n        ret = libxml2mod.xmlValidateOneNamespace(ctxt__o, self._o, elem__o, prefix, ns__o, value)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npops the element from the validation stack.", "response": "def validatePopElement(self, ctxt, elem, qname):\n        \"\"\"Pop the element end from the validation stack. \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidatePopElement(ctxt__o, self._o, elem__o, qname)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validatePushElement(self, ctxt, elem, qname):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidatePushElement(ctxt__o, self._o, elem__o, qname)\n        return ret", "response": "Push a new element on the validation stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to validate a the root element basically it does the following check as described by the XML-1.0 recommendation: - [ VC: Root Element Type ] it doesn't try to recurse or apply other check to the element", "response": "def validateRoot(self, ctxt):\n        \"\"\"Try to validate a the root element basically it does the\n          following check as described by the XML-1.0 recommendation:\n          - [ VC: Root Element Type ] it doesn't try to recurse or\n           apply other check to the element \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlValidateRoot(ctxt__o, self._o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xincludeProcessFlags(self, flags):\n        ret = libxml2mod.xmlXIncludeProcessFlags(self._o, flags)\n        return ret", "response": "Implement the XInclude substitution on the XML document"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef NewWalker(self, reader):\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlReaderNewWalker(reader__o, self._o)\n        return ret", "response": "Setup an xmltextReader to parse a preparsed XML document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an xmltextReader for a preparsed document.", "response": "def readerWalker(self):\n        \"\"\"Create an xmltextReader for a preparsed document. \"\"\"\n        ret = libxml2mod.xmlReaderWalker(self._o)\n        if ret is None:raise treeError('xmlReaderWalker() failed')\n        __tmp = xmlTextReader(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an XML Schemas parse context for that document.", "response": "def schemaNewDocParserCtxt(self):\n        \"\"\"Create an XML Schemas parse context for that document. NB.\n           The document may be modified during the parsing process. \"\"\"\n        ret = libxml2mod.xmlSchemaNewDocParserCtxt(self._o)\n        if ret is None:raise parserError('xmlSchemaNewDocParserCtxt() failed')\n        __tmp = SchemaParserCtxt(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schemaValidateDoc(self, ctxt):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlSchemaValidateDoc(ctxt__o, self._o)\n        return ret", "response": "Validate a document tree in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xpathNewContext(self):\n        ret = libxml2mod.xmlXPathNewContext(self._o)\n        if ret is None:raise xpathError('xmlXPathNewContext() failed')\n        __tmp = xpathContext(_obj=ret)\n        return __tmp", "response": "Create a new xmlXPathContext"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xpointerNewContext(self, here, origin):\n        if here is None: here__o = None\n        else: here__o = here._o\n        if origin is None: origin__o = None\n        else: origin__o = origin._o\n        ret = libxml2mod.xmlXPtrNewContext(self._o, here__o, origin__o)\n        if ret is None:raise treeError('xmlXPtrNewContext() failed')\n        __tmp = xpathContext(_obj=ret)\n        return __tmp", "response": "Create a new XPointer context"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the document tree from a parser context.", "response": "def doc(self):\n        \"\"\"Get the document tree from a parser context. \"\"\"\n        ret = libxml2mod.xmlParserGetDoc(self._o)\n        if ret is None:raise parserError('xmlParserGetDoc() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef htmlCtxtReadDoc(self, cur, URL, encoding, options):\n        ret = libxml2mod.htmlCtxtReadDoc(self._o, cur, URL, encoding, options)\n        if ret is None:raise treeError('htmlCtxtReadDoc() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp", "response": "parse an XML in - memory document and build a tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef htmlCtxtReadFd(self, fd, URL, encoding, options):\n        ret = libxml2mod.htmlCtxtReadFd(self._o, fd, URL, encoding, options)\n        if ret is None:raise treeError('htmlCtxtReadFd() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp", "response": "parse an XML from a file descriptor and build a tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses an XML file from the filesystem or network", "response": "def htmlCtxtReadFile(self, filename, encoding, options):\n        \"\"\"parse an XML file from the filesystem or the network. This\n           reuses the existing @ctxt parser context \"\"\"\n        ret = libxml2mod.htmlCtxtReadFile(self._o, filename, encoding, options)\n        if ret is None:raise treeError('htmlCtxtReadFile() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef htmlCtxtUseOptions(self, options):\n        ret = libxml2mod.htmlCtxtUseOptions(self._o, options)\n        return ret", "response": "Applies the options to the parser context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef htmlParseChunk(self, chunk, size, terminate):\n        ret = libxml2mod.htmlParseChunk(self._o, chunk, size, terminate)\n        return ret", "response": "Parse a chunk of HTML"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ctxtReadFile(self, filename, encoding, options):\n        ret = libxml2mod.xmlCtxtReadFile(self._o, filename, encoding, options)\n        if ret is None:raise treeError('xmlCtxtReadFile() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp", "response": "parse an XML file from the filesystem or network"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an XML in - memory document and build a tree.", "response": "def ctxtReadMemory(self, buffer, size, URL, encoding, options):\n        \"\"\"parse an XML in-memory document and build a tree. This\n           reuses the existing @ctxt parser context \"\"\"\n        ret = libxml2mod.xmlCtxtReadMemory(self._o, buffer, size, URL, encoding, options)\n        if ret is None:raise treeError('xmlCtxtReadMemory() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets the push parser context", "response": "def ctxtResetPush(self, chunk, size, filename, encoding):\n        \"\"\"Reset a push parser context \"\"\"\n        ret = libxml2mod.xmlCtxtResetPush(self._o, chunk, size, filename, encoding)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ctxtUseOptions(self, options):\n        ret = libxml2mod.xmlCtxtUseOptions(self._o, options)\n        return ret", "response": "Applies the options to the parser context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseChunk(self, chunk, size, terminate):\n        ret = libxml2mod.xmlParseChunk(self._o, chunk, size, terminate)\n        return ret", "response": "Parse a chunk of memory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setupParserForBuffer(self, buffer, filename):\n        libxml2mod.xmlSetupParserForBuffer(self._o, buffer, filename)", "response": "Setup the parser context to parse a new buffer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decodeEntities(self, len, what, end, end2, end3):\n        ret = libxml2mod.xmlDecodeEntities(self._o, len, what, end, end2, end3)\n        return ret", "response": "This function will always process entities\n          content through xmlStringDecodeEntities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handleEntity(self, entity):\n        if entity is None: entity__o = None\n        else: entity__o = entity._o\n        libxml2mod.xmlHandleEntity(self._o, entity__o)", "response": "Default handling of defined entities"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an entity reference declaration", "response": "def parseEntityRef(self):\n        \"\"\"parse ENTITY references declarations  [68] EntityRef ::=\n          '&' Name ';'  [ WFC: Entity Declared ] In a document\n          without any DTD, a document with only an internal DTD\n          subset which contains no parameter entity references, or a\n          document with \"standalone='yes'\", the Name given in the\n          entity reference must match that in an entity declaration,\n          except that well-formed documents need not declare any of\n          the following entities: amp, lt, gt, apos, quot.  The\n          declaration of a parameter entity must precede any\n          reference to it.  Similarly, the declaration of a general\n          entity must precede any reference to it which appears in a\n          default value in an attribute-list declaration. Note that\n          if entities are declared in the external subset or in\n          external parameter entities, a non-validating processor is\n          not obligated to read and process their declarations; for\n          such documents, the rule that an entity must be declared is\n          a well-formedness constraint only if standalone='yes'.  [\n          WFC: Parsed Entity ] An entity reference must not contain\n           the name of an unparsed entity \"\"\"\n        ret = libxml2mod.xmlParseEntityRef(self._o)\n        if ret is None:raise parserError('xmlParseEntityRef() failed')\n        __tmp = xmlEntity(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseExternalSubset(self, ExternalID, SystemID):\n        libxml2mod.xmlParseExternalSubset(self._o, ExternalID, SystemID)", "response": "parse Markup declarations from an external subset"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a entity string content and process to do the adequate substitutions. [67] Reference ::= EntityRef | CharRef [69] PEReference ::= '%' Name ';'", "response": "def stringDecodeEntities(self, str, what, end, end2, end3):\n        \"\"\"Takes a entity string content and process to do the\n          adequate substitutions.  [67] Reference ::= EntityRef |\n           CharRef  [69] PEReference ::= '%' Name ';' \"\"\"\n        ret = libxml2mod.xmlStringDecodeEntities(self._o, str, what, end, end2, end3)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a entity string content and process to do the adequate substitutions. [67] Reference ::= EntityRef | CharRef [69] PEReference ::= '%' Name ';'", "response": "def stringLenDecodeEntities(self, str, len, what, end, end2, end3):\n        \"\"\"Takes a entity string content and process to do the\n          adequate substitutions.  [67] Reference ::= EntityRef |\n           CharRef  [69] PEReference ::= '%' Name ';' \"\"\"\n        ret = libxml2mod.xmlStringLenDecodeEntities(self._o, str, len, what, end, end2, end3)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping debug information for the attribute", "response": "def debugDumpAttr(self, output, depth):\n        \"\"\"Dumps debug information for the attribute \"\"\"\n        libxml2mod.xmlDebugDumpAttr(output, self._o, depth)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping debug information for the attribute list", "response": "def debugDumpAttrList(self, output, depth):\n        \"\"\"Dumps debug information for the attribute list \"\"\"\n        libxml2mod.xmlDebugDumpAttrList(output, self._o, depth)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes a copy of the attribute.", "response": "def copyProp(self, target):\n        \"\"\"Do a copy of the attribute. \"\"\"\n        if target is None: target__o = None\n        else: target__o = target._o\n        ret = libxml2mod.xmlCopyProp(target__o, self._o)\n        if ret is None:raise treeError('xmlCopyProp() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copyPropList(self, target):\n        if target is None: target__o = None\n        else: target__o = target._o\n        ret = libxml2mod.xmlCopyPropList(target__o, self._o)\n        if ret is None:raise treeError('xmlCopyPropList() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp", "response": "Do a copy of an attribute list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef removeID(self, doc):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlRemoveID(doc__o, self._o)\n        return ret", "response": "Removes the given attribute from the ID table maintained\n           internally."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef removeRef(self, doc):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlRemoveRef(doc__o, self._o)\n        return ret", "response": "Removes the given attribute from the Ref table maintained\n           internally."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an entry in the catalog.", "response": "def add(self, type, orig, replace):\n        \"\"\"Add an entry in the catalog, it may overwrite existing but\n           different entries. \"\"\"\n        ret = libxml2mod.xmlACatalogAdd(self._o, type, orig, replace)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, value):\n        ret = libxml2mod.xmlACatalogRemove(self._o, value)\n        return ret", "response": "Remove an entry from the catalog"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a complete resolution lookup of an External Identifier", "response": "def resolve(self, pubID, sysID):\n        \"\"\"Do a complete resolution lookup of an External Identifier \"\"\"\n        ret = libxml2mod.xmlACatalogResolve(self._o, pubID, sysID)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolvePublic(self, pubID):\n        ret = libxml2mod.xmlACatalogResolvePublic(self._o, pubID)\n        return ret", "response": "Try to lookup the catalog local reference associated to a\n           public ID in that catalog"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to lookup the catalog resource for a system ID", "response": "def resolveSystem(self, sysID):\n        \"\"\"Try to lookup the catalog resource for a system ID \"\"\"\n        ret = libxml2mod.xmlACatalogResolveSystem(self._o, sysID)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a complete resolution lookup of an URI", "response": "def resolveURI(self, URI):\n        \"\"\"Do a complete resolution lookup of an URI \"\"\"\n        ret = libxml2mod.xmlACatalogResolveURI(self._o, URI)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo a copy of the dtd.", "response": "def copyDtd(self):\n        \"\"\"Do a copy of the dtd. \"\"\"\n        ret = libxml2mod.xmlCopyDtd(self._o)\n        if ret is None:raise treeError('xmlCopyDtd() failed')\n        __tmp = xmlDtd(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching the DTD for the description of this attribute on this element.", "response": "def dtdAttrDesc(self, elem, name):\n        \"\"\"Search the DTD for the description of this attribute on\n           this element. \"\"\"\n        ret = libxml2mod.xmlGetDtdAttrDesc(self._o, elem, name)\n        if ret is None:raise treeError('xmlGetDtdAttrDesc() failed')\n        __tmp = xmlAttribute(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dtdElementDesc(self, name):\n        ret = libxml2mod.xmlGetDtdElementDesc(self._o, name)\n        if ret is None:raise treeError('xmlGetDtdElementDesc() failed')\n        __tmp = xmlElement(_obj=ret)\n        return __tmp", "response": "Search the DTD for the description of this element"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches the DTD for the description of this qualified attribute on this element.", "response": "def dtdQAttrDesc(self, elem, name, prefix):\n        \"\"\"Search the DTD for the description of this qualified\n           attribute on this element. \"\"\"\n        ret = libxml2mod.xmlGetDtdQAttrDesc(self._o, elem, name, prefix)\n        if ret is None:raise treeError('xmlGetDtdQAttrDesc() failed')\n        __tmp = xmlAttribute(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dtdQElementDesc(self, name, prefix):\n        ret = libxml2mod.xmlGetDtdQElementDesc(self._o, name, prefix)\n        if ret is None:raise treeError('xmlGetDtdQElementDesc() failed')\n        __tmp = xmlElement(_obj=ret)\n        return __tmp", "response": "Search the DTD for the description of this element"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting handling of defined entities", "response": "def handleEntity(self, ctxt):\n        \"\"\"Default handling of defined entities, when should we define\n          a new input stream ? When do we just handle that as a set\n           of chars ?  OBSOLETE: to be removed at some point. \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        libxml2mod.xmlHandleEntity(ctxt__o, self._o)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy the original error to the new place.", "response": "def copyError(self, to):\n        \"\"\"Save the original error to the new place. \"\"\"\n        if to is None: to__o = None\n        else: to__o = to._o\n        ret = libxml2mod.xmlCopyError(self._o, to__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copyNamespace(self):\n        ret = libxml2mod.xmlCopyNamespace(self._o)\n        if ret is None:raise treeError('xmlCopyNamespace() failed')\n        __tmp = xmlNs(_obj=ret)\n        return __tmp", "response": "Do a copy of the namespace."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copyNamespaceList(self):\n        ret = libxml2mod.xmlCopyNamespaceList(self._o)\n        if ret is None:raise treeError('xmlCopyNamespaceList() failed')\n        __tmp = xmlNs(_obj=ret)\n        return __tmp", "response": "Do a copy of an namespace list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newChild(self, parent, name, content):\n        if parent is None: parent__o = None\n        else: parent__o = parent._o\n        ret = libxml2mod.xmlNewChild(parent__o, self._o, name, content)\n        if ret is None:raise treeError('xmlNewChild() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new child element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef newDocNode(self, doc, name, content):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlNewDocNode(doc__o, self._o, name, content)\n        if ret is None:raise treeError('xmlNewDocNode() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new node element within a document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef newNodeEatName(self, name):\n        ret = libxml2mod.xmlNewNodeEatName(self._o, name)\n        if ret is None:raise treeError('xmlNewNodeEatName() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new node element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new property tagged with a namespace and carried by a node.", "response": "def newNsProp(self, node, name, value):\n        \"\"\"Create a new property tagged with a namespace and carried\n           by a node. \"\"\"\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlNewNsProp(node__o, self._o, name, value)\n        if ret is None:raise treeError('xmlNewNsProp() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef newNsPropEatName(self, node, name, value):\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlNewNsPropEatName(node__o, self._o, name, value)\n        if ret is None:raise treeError('xmlNewNsPropEatName() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp", "response": "Create a new property tagged with a namespace and carried\n           by a node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef newTextChild(self, parent, name, content):\n        if parent is None: parent__o = None\n        else: parent__o = parent._o\n        ret = libxml2mod.xmlNewTextChild(parent__o, self._o, name, content)\n        if ret is None:raise treeError('xmlNewTextChild() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Creation of a new child element with the given name and content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setNs(self, node):\n        if node is None: node__o = None\n        else: node__o = node._o\n        libxml2mod.xmlSetNs(node__o, self._o)", "response": "Associate a namespace to a node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the value of an attribute in the ns structure", "response": "def setNsProp(self, node, name, value):\n        \"\"\"Set (or reset) an attribute carried by a node. The ns\n           structure must be in scope, this is not checked \"\"\"\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlSetNsProp(node__o, self._o, name, value)\n        if ret is None:raise treeError('xmlSetNsProp() failed')\n        __tmp = xmlAttr(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove an attribute from a node", "response": "def unsetNsProp(self, node, name):\n        \"\"\"Remove an attribute carried by a node. \"\"\"\n        if node is None: node__o = None\n        else: node__o = node._o\n        ret = libxml2mod.xmlUnsetNsProp(node__o, self._o, name)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps an HTML document.", "response": "def htmlDocContentDumpFormatOutput(self, cur, encoding, format):\n        \"\"\"Dump an HTML document. \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.htmlDocContentDumpFormatOutput(self._o, cur__o, encoding, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef htmlDocContentDumpOutput(self, cur, encoding):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.htmlDocContentDumpOutput(self._o, cur__o, encoding)", "response": "Dump an HTML document. Formating return / spaces are added."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef htmlNodeDumpFormatOutput(self, doc, cur, encoding, format):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.htmlNodeDumpFormatOutput(self._o, doc__o, cur__o, encoding, format)", "response": "Dump an HTML node recursively"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef htmlNodeDumpOutput(self, doc, cur, encoding):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.htmlNodeDumpOutput(self._o, doc__o, cur__o, encoding)", "response": "Dump an HTML node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nodeDumpOutput(self, doc, cur, level, format, encoding):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        libxml2mod.xmlNodeDumpOutput(self._o, doc__o, cur__o, level, format, encoding)", "response": "Dump an XML node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saveFileTo(self, cur, encoding):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlSaveFileTo(self._o, cur__o, encoding)\n        return ret", "response": "Dump an XML document to an I/O buffer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef saveFormatFileTo(self, cur, encoding, format):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlSaveFormatFileTo(self._o, cur__o, encoding, format)\n        return ret", "response": "Dump an XML document to an I/O buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the content of the array in the output buffer.", "response": "def write(self, len, buf):\n        \"\"\"Write the content of the array in the output I/O buffer\n          This routine handle the I18N transcoding from internal\n          UTF-8 The buffer is lossless, i.e. will store in case of\n           partial or delayed writes. \"\"\"\n        ret = libxml2mod.xmlOutputBufferWrite(self._o, len, buf)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the content of a string in the output buffer.", "response": "def writeString(self, str):\n        \"\"\"Write the content of the string in the output I/O buffer\n          This routine handle the I18N transcoding from internal\n          UTF-8 The buffer is lossless, i.e. will store in case of\n           partial or delayed writes. \"\"\"\n        ret = libxml2mod.xmlOutputBufferWriteString(self._o, str)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngrows up the content of the input buffer", "response": "def grow(self, len):\n        \"\"\"Grow up the content of the input buffer, the old data are\n          preserved This routine handle the I18N transcoding to\n          internal UTF-8 This routine is used when operating the\n          parser in normal (pull) mode  TODO: one should be able to\n          remove one extra copy by copying directly onto in->buffer\n           or in->raw \"\"\"\n        ret = libxml2mod.xmlParserInputBufferGrow(self._o, len)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush the content of the arry in the input buffer", "response": "def push(self, len, buf):\n        \"\"\"Push the content of the arry in the input buffer This\n          routine handle the I18N transcoding to internal UTF-8 This\n          is used when operating the parser in progressive (push)\n           mode. \"\"\"\n        ret = libxml2mod.xmlParserInputBufferPush(self._o, len, buf)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the specified number of bytes from the input buffer", "response": "def read(self, len):\n        \"\"\"Refresh the content of the input buffer, the old data are\n          considered consumed This routine handle the I18N\n           transcoding to internal UTF-8 \"\"\"\n        ret = libxml2mod.xmlParserInputBufferRead(self._o, len)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Setup(self, reader, URL, encoding, options):\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlTextReaderSetup(reader__o, self._o, URL, encoding, options)\n        return ret", "response": "Setup an XML reader with new options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an xmlTextReader structure fed with the input", "response": "def newTextReader(self, URI):\n        \"\"\"Create an xmlTextReader structure fed with @input \"\"\"\n        ret = libxml2mod.xmlNewTextReader(self._o, URI)\n        if ret is None:raise treeError('xmlNewTextReader() failed')\n        __tmp = xmlTextReader(_obj=ret)\n        __tmp.input = self\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the regular expression generates the value", "response": "def regexpExec(self, content):\n        \"\"\"Check if the regular expression generates the value \"\"\"\n        ret = libxml2mod.xmlRegexpExec(self._o, content)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relaxNGParse(self):\n        ret = libxml2mod.xmlRelaxNGParse(self._o)\n        if ret is None:raise parserError('xmlRelaxNGParse() failed')\n        __tmp = relaxNgSchema(_obj=ret)\n        return __tmp", "response": "parse a schema definition resource and build an internal\n           XML Shema struture which can be used to validate instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the flags for the context which is a combination of xmlRelaxNGParserFlag", "response": "def relaxParserSetFlag(self, flags):\n        \"\"\"Semi private function used to pass informations to a parser\n           context which are a combination of xmlRelaxNGParserFlag . \"\"\"\n        ret = libxml2mod.xmlRelaxParserSetFlag(self._o, flags)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relaxNGNewValidCtxt(self):\n        ret = libxml2mod.xmlRelaxNGNewValidCtxt(self._o)\n        if ret is None:raise treeError('xmlRelaxNGNewValidCtxt() failed')\n        __tmp = relaxNgValidCtxt(_obj=ret)\n        __tmp.schema = self\n        return __tmp", "response": "Create an XML RelaxNGs validation context based on the passed schema"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef RelaxNGSetSchema(self, reader):\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlTextReaderRelaxNGSetSchema(reader__o, self._o)\n        return ret", "response": "Validate the document schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relaxNGValidateDoc(self, doc):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlRelaxNGValidateDoc(self._o, doc__o)\n        return ret", "response": "Validate a document tree in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relaxNGValidateFullElement(self, doc, elem):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlRelaxNGValidateFullElement(self._o, doc__o, elem__o)\n        return ret", "response": "Validate a full subtree when\n          xmlRelaxNGValidatePushElement is called"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef relaxNGValidatePopElement(self, doc, elem):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlRelaxNGValidatePopElement(self._o, doc__o, elem__o)\n        return ret", "response": "Pop the element from the RelaxNG validation stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the CData parsed for validation in the current stack", "response": "def relaxNGValidatePushCData(self, data, len):\n        \"\"\"check the CData parsed for validation in the current stack \"\"\"\n        ret = libxml2mod.xmlRelaxNGValidatePushCData(self._o, data, len)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npush a new element on the RelaxNG validation stack.", "response": "def relaxNGValidatePushElement(self, doc, elem):\n        \"\"\"Push a new element start on the RelaxNG validation stack. \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlRelaxNGValidatePushElement(self._o, doc__o, elem__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the RelaxNG schema context for the current document.", "response": "def RelaxNGValidateCtxt(self, reader, options):\n        \"\"\"Use RelaxNG schema context to validate the document as it\n          is processed. Activation is only possible before the first\n          Read(). If @ctxt is None, then RelaxNG schema validation is\n           deactivated. \"\"\"\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlTextReaderRelaxNGValidateCtxt(reader__o, self._o, options)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a schema definition resource and build an internal XML Shema struture which can be used to validate instances.", "response": "def schemaParse(self):\n        \"\"\"parse a schema definition resource and build an internal\n           XML Shema struture which can be used to validate instances. \"\"\"\n        ret = libxml2mod.xmlSchemaParse(self._o)\n        if ret is None:raise parserError('xmlSchemaParse() failed')\n        __tmp = Schema(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SetSchema(self, reader):\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlTextReaderSetSchema(reader__o, self._o)\n        return ret", "response": "Set the XSD Schema of the current document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schemaNewValidCtxt(self):\n        ret = libxml2mod.xmlSchemaNewValidCtxt(self._o)\n        if ret is None:raise treeError('xmlSchemaNewValidCtxt() failed')\n        __tmp = SchemaValidCtxt(_obj=ret)\n        __tmp.schema = self\n        return __tmp", "response": "Create an XML Schemas validation context based on the given schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SchemaValidateCtxt(self, reader, options):\n        if reader is None: reader__o = None\n        else: reader__o = reader._o\n        ret = libxml2mod.xmlTextReaderSchemaValidateCtxt(reader__o, self._o, options)\n        return ret", "response": "Use W3C XSD schema context to validate the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the options to be used during the validation.", "response": "def schemaSetValidOptions(self, options):\n        \"\"\"Sets the options to be used during the validation. \"\"\"\n        ret = libxml2mod.xmlSchemaSetValidOptions(self._o, options)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nallow access to the parser context of the schema validation context", "response": "def schemaValidCtxtGetParserCtxt(self):\n        \"\"\"allow access to the parser context of the schema validation\n           context \"\"\"\n        ret = libxml2mod.xmlSchemaValidCtxtGetParserCtxt(self._o)\n        if ret is None:raise parserError('xmlSchemaValidCtxtGetParserCtxt() failed')\n        __tmp = parserCtxt(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schemaValidateDoc(self, doc):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlSchemaValidateDoc(self._o, doc__o)\n        return ret", "response": "Validate a document tree in memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndoes a schemas validation of the given file.", "response": "def schemaValidateFile(self, filename, options):\n        \"\"\"Do a schemas validation of the given resource, it will use\n           the SAX streamable validation internally. \"\"\"\n        ret = libxml2mod.xmlSchemaValidateFile(self._o, filename, options)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating a branch of a tree starting with the given element.", "response": "def schemaValidateOneElement(self, elem):\n        \"\"\"Validate a branch of a tree, starting with the given @elem. \"\"\"\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlSchemaValidateOneElement(self._o, elem__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CurrentDoc(self):\n        ret = libxml2mod.xmlTextReaderCurrentDoc(self._o)\n        if ret is None:raise treeError('xmlTextReaderCurrentDoc() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp", "response": "This function returns the XML document that is currently being parsed by the reader."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhacks interface allowing to get the xmlNodePtr correponding to the current node being accessed by the xmlTextReader. This is dangerous because the underlying node may be destroyed on the next Reads.", "response": "def CurrentNode(self):\n        \"\"\"Hacking interface allowing to get the xmlNodePtr\n          correponding to the current node being accessed by the\n          xmlTextReader. This is dangerous because the underlying\n           node may be destroyed on the next Reads. \"\"\"\n        ret = libxml2mod.xmlTextReaderCurrentNode(self._o)\n        if ret is None:raise treeError('xmlTextReaderCurrentNode() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Expand(self):\n        ret = libxml2mod.xmlTextReaderExpand(self._o)\n        if ret is None:raise treeError('xmlTextReaderExpand() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Reads the contents of the current node and the full\n          subtree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetAttribute(self, name):\n        ret = libxml2mod.xmlTextReaderGetAttribute(self._o, name)\n        return ret", "response": "Provides the value of the attribute with the specified qualified name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovide the value of the attribute with the specified index relative to the containing element.", "response": "def GetAttributeNo(self, no):\n        \"\"\"Provides the value of the attribute with the specified\n           index relative to the containing element. \"\"\"\n        ret = libxml2mod.xmlTextReaderGetAttributeNo(self._o, no)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetAttributeNs(self, localName, namespaceURI):\n        ret = libxml2mod.xmlTextReaderGetAttributeNs(self._o, localName, namespaceURI)\n        return ret", "response": "Provides the value of the specified attribute in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the parser internal property", "response": "def GetParserProp(self, prop):\n        \"\"\"Read the parser internal property. \"\"\"\n        ret = libxml2mod.xmlTextReaderGetParserProp(self._o, prop)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetRemainder(self):\n        ret = libxml2mod.xmlTextReaderGetRemainder(self._o)\n        if ret is None:raise treeError('xmlTextReaderGetRemainder() failed')\n        __tmp = inputBuffer(_obj=ret)\n        return __tmp", "response": "Method to get the remainder of the buffered XML. This method stops the parser and returns the input stream with what s left in the reader s input buffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef LookupNamespace(self, prefix):\n        ret = libxml2mod.xmlTextReaderLookupNamespace(self._o, prefix)\n        return ret", "response": "Resolves a namespace prefix in the scope of the current\n           element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef MoveToAttribute(self, name):\n        ret = libxml2mod.xmlTextReaderMoveToAttribute(self._o, name)\n        return ret", "response": "Moves the position of the current instance to the attribute with the specified qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef MoveToAttributeNo(self, no):\n        ret = libxml2mod.xmlTextReaderMoveToAttributeNo(self._o, no)\n        return ret", "response": "Moves the position of the current instance to the attribute with the specified index relative to the containing element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MoveToAttributeNs(self, localName, namespaceURI):\n        ret = libxml2mod.xmlTextReaderMoveToAttributeNs(self._o, localName, namespaceURI)\n        return ret", "response": "Moves the position of the current instance to the specified local name and namespace URI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef NewDoc(self, cur, URL, encoding, options):\n        ret = libxml2mod.xmlReaderNewDoc(self._o, cur, URL, encoding, options)\n        return ret", "response": "Setup an xmltextReader to parse an XML in - memory document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef NewFd(self, fd, URL, encoding, options):\n        ret = libxml2mod.xmlReaderNewFd(self._o, fd, URL, encoding, options)\n        return ret", "response": "Setup an xmltextReader to parse an XML from a file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef NewFile(self, filename, encoding, options):\n        ret = libxml2mod.xmlReaderNewFile(self._o, filename, encoding, options)\n        return ret", "response": "parse an XML file from the filesystem or network"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef NewWalker(self, doc):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlReaderNewWalker(self._o, doc__o)\n        return ret", "response": "Setup an xmltextReader to parse a preparsed XML document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef RelaxNGSetSchema(self, schema):\n        if schema is None: schema__o = None\n        else: schema__o = schema._o\n        ret = libxml2mod.xmlTextReaderRelaxNGSetSchema(self._o, schema__o)\n        return ret", "response": "Validate the document using RelaxNG."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef RelaxNGValidate(self, rng):\n        ret = libxml2mod.xmlTextReaderRelaxNGValidate(self._o, rng)\n        return ret", "response": "Validate the document using RelaxNG schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the RelaxNG schema context", "response": "def RelaxNGValidateCtxt(self, ctxt, options):\n        \"\"\"Use RelaxNG schema context to validate the document as it\n          is processed. Activation is only possible before the first\n          Read(). If @ctxt is None, then RelaxNG schema validation is\n           deactivated. \"\"\"\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlTextReaderRelaxNGValidateCtxt(self._o, ctxt__o, options)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SchemaValidate(self, xsd):\n        ret = libxml2mod.xmlTextReaderSchemaValidate(self._o, xsd)\n        return ret", "response": "Validate the XML Schema of the current document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SchemaValidateCtxt(self, ctxt, options):\n        if ctxt is None: ctxt__o = None\n        else: ctxt__o = ctxt._o\n        ret = libxml2mod.xmlTextReaderSchemaValidateCtxt(self._o, ctxt__o, options)\n        return ret", "response": "Validate the XML Schema context"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the parser properties of the current document.", "response": "def SetParserProp(self, prop, value):\n        \"\"\"Change the parser processing behaviour by changing some of\n          its internal properties. Note that some properties can only\n           be changed before any read has been done. \"\"\"\n        ret = libxml2mod.xmlTextReaderSetParserProp(self._o, prop, value)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SetSchema(self, schema):\n        if schema is None: schema__o = None\n        else: schema__o = schema._o\n        ret = libxml2mod.xmlTextReaderSetSchema(self._o, schema__o)\n        return ret", "response": "Set the XSD Schema of the current reader."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an interned string from the reader", "response": "def String(self, str):\n        \"\"\"Get an interned string from the reader, allows for example\n           to speedup string name comparisons \"\"\"\n        ret = libxml2mod.xmlTextReaderConstString(self._o, str)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseURIReference(self, str):\n        ret = libxml2mod.xmlParseURIReference(self._o, str)\n        return ret", "response": "Parse an URI reference string based on RFC 3986 and fills\n          in the appropriate fields of the URI structure"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoes the validation related extra step of the normalization of attribute values: If the declared value is not CDATA, then the XML processor must further process the normalized attribute value by discarding any leading and trailing space (#x20) characters, and by replacing sequences of space (#x20) characters by single space (#x20) character. Also check VC: Standalone Document Declaration in P32, and update ctxt->valid accordingly", "response": "def validCtxtNormalizeAttributeValue(self, doc, elem, name, value):\n        \"\"\"Does the validation related extra step of the normalization\n          of attribute values:  If the declared value is not CDATA,\n          then the XML processor must further process the normalized\n          attribute value by discarding any leading and trailing\n          space (#x20) characters, and by replacing sequences of\n          space (#x20) characters by single space (#x20) character.\n          Also  check VC: Standalone Document Declaration in P32, and\n           update ctxt->valid accordingly \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidCtxtNormalizeAttributeValue(self._o, doc__o, elem__o, name, value)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the document instance", "response": "def validateDocument(self, doc):\n        \"\"\"Try to validate the document instance  basically it does\n          the all the checks described by the XML Rec i.e. validates\n          the internal and external subset (if present) and validate\n           the document tree. \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlValidateDocument(self._o, doc__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes the final step for the document validation", "response": "def validateDocumentFinal(self, doc):\n        \"\"\"Does the final step for the document validation once all\n          the incremental validation steps have been completed\n          basically it does the following checks described by the XML\n          Rec  Check all the IDREF/IDREFS attributes definition for\n           validity \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlValidateDocumentFinal(self._o, doc__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the document against the DTD", "response": "def validateDtd(self, doc, dtd):\n        \"\"\"Try to validate the document against the dtd instance\n          Basically it does check all the definitions in the DtD.\n          Note the the internal subset (if present) is de-coupled\n          (i.e. not used), which could give problems if ID or IDREF\n           is present. \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if dtd is None: dtd__o = None\n        else: dtd__o = dtd._o\n        ret = libxml2mod.xmlValidateDtd(self._o, doc__o, dtd__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo the final validation of the dtds", "response": "def validateDtdFinal(self, doc):\n        \"\"\"Does the final step for the dtds validation once all the\n          subsets have been parsed  basically it does the following\n          checks described by the XML Rec - check that ENTITY and\n          ENTITIES type attributes default or possible values matches\n          one of the defined entities. - check that NOTATION type\n          attributes default or possible values matches one of the\n           defined notations. \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlValidateDtdFinal(self._o, doc__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the subtree under an element", "response": "def validateElement(self, doc, elem):\n        \"\"\"Try to validate the subtree under an element \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidateElement(self._o, doc__o, elem__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validateNotationUse(self, doc, notationName):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlValidateNotationUse(self._o, doc__o, notationName)\n        return ret", "response": "Validate that the given name matches a given notation declaration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validateOneAttribute(self, doc, elem, attr, value):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if attr is None: attr__o = None\n        else: attr__o = attr._o\n        ret = libxml2mod.xmlValidateOneAttribute(self._o, doc__o, elem__o, attr__o, value)\n        return ret", "response": "This function checks if a single attribute is valid for an element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validateOneElement(self, doc, elem):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidateOneElement(self._o, doc__o, elem__o)\n        return ret", "response": "This function checks that a single element and its attributes are present in the XML document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validateOneNamespace(self, doc, elem, prefix, ns, value):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        if ns is None: ns__o = None\n        else: ns__o = ns._o\n        ret = libxml2mod.xmlValidateOneNamespace(self._o, doc__o, elem__o, prefix, ns__o, value)\n        return ret", "response": "Validate a single namespace declaration for an element"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npops the element from the validation stack.", "response": "def validatePopElement(self, doc, elem, qname):\n        \"\"\"Pop the element end from the validation stack. \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidatePopElement(self._o, doc__o, elem__o, qname)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validatePushCData(self, data, len):\n        ret = libxml2mod.xmlValidatePushCData(self._o, data, len)\n        return ret", "response": "check the CData parsed for validation in the current stack"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validatePushElement(self, doc, elem, qname):\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        if elem is None: elem__o = None\n        else: elem__o = elem._o\n        ret = libxml2mod.xmlValidatePushElement(self._o, doc__o, elem__o, qname)\n        return ret", "response": "Push a new element on the validation stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate a root element", "response": "def validateRoot(self, doc):\n        \"\"\"Try to validate a the root element basically it does the\n          following check as described by the XML-1.0 recommendation:\n          - [ VC: Root Element Type ] it doesn't try to recurse or\n           apply other check to the element \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        ret = libxml2mod.xmlValidateRoot(self._o, doc__o)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contextDoc(self):\n        ret = libxml2mod.xmlXPathGetContextDoc(self._o)\n        if ret is None:raise xpathError('xmlXPathGetContextDoc() failed')\n        __tmp = xmlDoc(_obj=ret)\n        return __tmp", "response": "Get the doc from an xpathContext"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contextNode(self):\n        ret = libxml2mod.xmlXPathGetContextNode(self._o)\n        if ret is None:raise xpathError('xmlXPathGetContextNode() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Get the current node from an xpathContext"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the doc of an xpathContext", "response": "def setContextDoc(self, doc):\n        \"\"\"Set the doc of an xpathContext \"\"\"\n        if doc is None: doc__o = None\n        else: doc__o = doc._o\n        libxml2mod.xmlXPathSetContextDoc(self._o, doc__o)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the current node of an xpathContext", "response": "def setContextNode(self, node):\n        \"\"\"Set the current node of an xpathContext \"\"\"\n        if node is None: node__o = None\n        else: node__o = node._o\n        libxml2mod.xmlXPathSetContextNode(self._o, node__o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerXPathFunction(self, name, ns_uri, f):\n        ret = libxml2mod.xmlRegisterXPathFunction(self._o, name, ns_uri, f)\n        return ret", "response": "Register a Python written function to the XPath interpreter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xpathRegisterVariable(self, name, ns_uri, value):\n        ret = libxml2mod.xmlXPathRegisterVariable(self._o, name, ns_uri, value)\n        return ret", "response": "Register a variable with the XPath context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpathContextSetCache(self, active, value, options):\n        ret = libxml2mod.xmlXPathContextSetCache(self._o, active, value, options)\n        return ret", "response": "Sets the object cache on the XPath context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpathEval(self, str):\n        ret = libxml2mod.xmlXPathEval(str, self._o)\n        if ret is None:raise xpathError('xmlXPathEval() failed')\n        return xpathObjectRet(ret)", "response": "Evaluate the XPath Location Path in the given context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the XPath expression in the given context.", "response": "def xpathEvalExpression(self, str):\n        \"\"\"Evaluate the XPath expression in the given context. \"\"\"\n        ret = libxml2mod.xmlXPathEvalExpression(str, self._o)\n        if ret is None:raise xpathError('xmlXPathEvalExpression() failed')\n        return xpathObjectRet(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xpathNewParserContext(self, str):\n        ret = libxml2mod.xmlXPathNewParserContext(str, self._o)\n        if ret is None:raise xpathError('xmlXPathNewParserContext() failed')\n        __tmp = xpathParserContext(_obj=ret)\n        return __tmp", "response": "Create a new xmlXPathParserContext"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch in the namespace declaration array of the given namespace name associated to the given prefix.", "response": "def xpathNsLookup(self, prefix):\n        \"\"\"Search in the namespace declaration array of the context\n           for the given namespace name associated to the given prefix \"\"\"\n        ret = libxml2mod.xmlXPathNsLookup(self._o, prefix)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpathRegisterNs(self, prefix, ns_uri):\n        ret = libxml2mod.xmlXPathRegisterNs(self._o, prefix, ns_uri)\n        return ret", "response": "Register a new namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xpathVariableLookup(self, name):\n        ret = libxml2mod.xmlXPathVariableLookup(self._o, name)\n        if ret is None:raise xpathError('xmlXPathVariableLookup() failed')\n        return xpathObjectRet(ret)", "response": "Search in the Variable array of the context for the given variable value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpathVariableLookupNS(self, name, ns_uri):\n        ret = libxml2mod.xmlXPathVariableLookupNS(self._o, name, ns_uri)\n        if ret is None:raise xpathError('xmlXPathVariableLookupNS() failed')\n        return xpathObjectRet(ret)", "response": "Search in the Variable array of the given namespace URI and name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the XPath Location Path in the given context.", "response": "def xpointerEval(self, str):\n        \"\"\"Evaluate the XPath Location Path in the given context. \"\"\"\n        ret = libxml2mod.xmlXPtrEval(str, self._o)\n        if ret is None:raise treeError('xmlXPtrEval() failed')\n        return xpathObjectRet(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef context(self):\n        ret = libxml2mod.xmlXPathParserGetContext(self._o)\n        if ret is None:raise xpathError('xmlXPathParserGetContext() failed')\n        __tmp = xpathContext(_obj=ret)\n        return __tmp", "response": "Get the xpathContext from an xpathParserContext"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpathCompareValues(self, inf, strict):\n        ret = libxml2mod.xmlXPathCompareValues(self._o, inf, strict)\n        return ret", "response": "Implement the compare operation on XPath objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraversing the document tree for the ancestor direction", "response": "def xpathNextAncestor(self, cur):\n        \"\"\"Traversal function for the \"ancestor\" direction the\n          ancestor axis contains the ancestors of the context node;\n          the ancestors of the context node consist of the parent of\n          context node and the parent's parent and so on; the nodes\n          are ordered in reverse document order; thus the parent is\n          the first node on the axis, and the parent's parent is the\n           second node on the axis \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextAncestor(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextAncestor() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xpathNextAncestorOrSelf(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextAncestorOrSelf(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextAncestorOrSelf() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Traverse the document tree for the ancestor - or - self direction"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the tree for the attribute direction", "response": "def xpathNextAttribute(self, cur):\n        \"\"\"Traversal function for the \"attribute\" direction TODO:\n           support DTD inherited default attributes \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextAttribute(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextAttribute() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xpathNextChild(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextChild(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextChild() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Traversal function for the child direction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntraversing the document tree for the descendant direction", "response": "def xpathNextDescendant(self, cur):\n        \"\"\"Traversal function for the \"descendant\" direction the\n          descendant axis contains the descendants of the context\n          node in document order; a descendant is a child or a child\n           of a child and so on. \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextDescendant(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextDescendant() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xpathNextDescendantOrSelf(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextDescendantOrSelf(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextDescendantOrSelf() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Traverse the document tree for the descendant - or - self axis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntraversing the context node for the following - sibling axis", "response": "def xpathNextFollowingSibling(self, cur):\n        \"\"\"Traversal function for the \"following-sibling\" direction\n          The following-sibling axis contains the following siblings\n           of the context node in document order. \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextFollowingSibling(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextFollowingSibling() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xpathNextNamespace(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextNamespace(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextNamespace() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Traverse the namespace tree of the context node"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntraverses the parent node of the context node", "response": "def xpathNextParent(self, cur):\n        \"\"\"Traversal function for the \"parent\" direction The parent\n          axis contains the parent of the context node, if there is\n           one. \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextParent(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextParent() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the document tree for the preceding - sibling axis", "response": "def xpathNextPrecedingSibling(self, cur):\n        \"\"\"Traversal function for the \"preceding-sibling\" direction\n          The preceding-sibling axis contains the preceding siblings\n          of the context node in reverse document order; the first\n          preceding sibling is first on the axis; the sibling\n           preceding that node is the second on the axis and so on. \"\"\"\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextPrecedingSibling(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextPrecedingSibling() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xpathNextSelf(self, cur):\n        if cur is None: cur__o = None\n        else: cur__o = cur._o\n        ret = libxml2mod.xmlXPathNextSelf(self._o, cur__o)\n        if ret is None:raise xpathError('xmlXPathNextSelf() failed')\n        __tmp = xmlNode(_obj=ret)\n        return __tmp", "response": "Traversal function for the self direction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting an XPath error message.", "response": "def xpatherror(self, file, line, no):\n        \"\"\"Formats an error message. \"\"\"\n        libxml2mod.xmlXPatherror(self._o, file, line, no)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_summary_struct(self):\n\n        model_fields = [\n            ('Number of coefficients', 'num_coefficients'),\n            ('Number of examples', 'num_examples'),\n            ('Number of classes', 'num_classes'),\n            ('Number of feature columns', 'num_features'),\n            ('Number of unpacked features', 'num_unpacked_features')]\n\n        hyperparam_fields = [\n            (\"L1 penalty\", 'l1_penalty'),\n            (\"L2 penalty\", 'l2_penalty')\n        ]\n\n        solver_fields = [\n            (\"Solver\", 'solver'),\n            (\"Solver iterations\", 'training_iterations'),\n            (\"Solver status\", 'training_solver_status'),\n            (\"Training time (sec)\", 'training_time')]\n\n        training_fields = [\n            (\"Log-likelihood\", 'training_loss')]\n\n        coefs = self.coefficients\n        top_coefs, bottom_coefs = _toolkit_get_topk_bottomk(coefs,k=5)\n\n        (coefs_list, titles_list) = _summarize_coefficients(top_coefs, \\\n                                                                    bottom_coefs)\n\n        return ([ model_fields, hyperparam_fields, \\\n                        solver_fields, training_fields ] + coefs_list, \\\n                        [ 'Schema', 'Hyperparameters', \\\n                        'Training Summary', 'Settings' ] + titles_list )", "response": "Returns a structured description of the training data model hyperparameters and training statistics."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a classification for each example in the dataset using the logistic regression model.", "response": "def classify(self, dataset, missing_value_action='auto'):\n        \"\"\"\n        Return a classification, for each example in the ``dataset``, using the\n        trained logistic regression model. The output SFrame contains predictions\n        as both class labels (0 or 1) as well as probabilities that the predicted\n        value is the associated label.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            Dataset of new observations. Must include columns with the same\n            names as the features used for model training, but does not require\n            a target column. Additional columns are ignored.\n\n        missing_value_action : str, optional\n            Action to perform when missing values are encountered. This can be\n            one of:\n\n            - 'auto': Default to 'impute'\n            - 'impute': Proceed with evaluation by filling in the missing\n              values with the mean of the training data. Missing\n              values are also imputed if an entire column of data is\n              missing during evaluation.\n            - 'error': Do not proceed with evaluation and terminate with\n              an error message.\n\n        Returns\n        -------\n        out : SFrame\n            An SFrame with model predictions i.e class labels and probabilities.\n\n        See Also\n        ----------\n        create, evaluate, predict\n\n        Examples\n        ----------\n        >>> data =  turicreate.SFrame('https://static.turi.com/datasets/regression/houses.csv')\n\n        >>> data['is_expensive'] = data['price'] > 30000\n        >>> model = turicreate.logistic_classifier.create(data,\n                                             target='is_expensive',\n                                             features=['bath', 'bedroom', 'size'])\n\n        >>> classes = model.classify(data)\n\n        \"\"\"\n\n        return super(LogisticClassifier, self).classify(dataset,\n                                                        missing_value_action=missing_value_action)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_prefix_and_suffix(specified_name, type, property_set):\n\n    property_set = b2.util.jam_to_value_maybe(property_set)\n\n    suffix = \"\"\n    if type:\n        suffix = b2.build.type.generated_target_suffix(type, property_set)\n\n    # Handle suffixes for which no leading dot is desired.  Those are\n    # specified by enclosing them in <...>.  Needed by python so it\n    # can create \"_d.so\" extensions, for example.\n    if get_grist(suffix):\n        suffix = ungrist(suffix)\n    elif suffix:\n        suffix = \".\" + suffix\n\n    prefix = \"\"\n    if type:\n        prefix = b2.build.type.generated_target_prefix(type, property_set)\n\n    if specified_name.startswith(prefix):\n        prefix = \"\"\n\n    if not prefix:\n        prefix = \"\"\n    if not suffix:\n        suffix = \"\"\n    return prefix + specified_name + suffix", "response": "Appends the suffix appropriate to type / property - set combination\n    to the specified name and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the dependency graph of target and return all targets that are not root.", "response": "def traverse (target, include_roots = False, include_sources = False):\n    \"\"\" Traverses the dependency graph of 'target' and return all targets that will\n        be created before this one is created. If root of some dependency graph is\n        found during traversal, it's either included or not, dependencing of the\n        value of 'include_roots'. In either case, sources of root are not traversed.\n    \"\"\"\n    assert isinstance(target, VirtualTarget)\n    assert isinstance(include_roots, (int, bool))\n    assert isinstance(include_sources, (int, bool))\n    result = []\n\n    if target.action ():\n        action = target.action ()\n\n        # This includes 'target' as well\n        result += action.targets ()\n\n        for t in action.sources ():\n\n            # FIXME:\n            # TODO: see comment in Manager.register_object ()\n            #if not isinstance (t, VirtualTarget):\n            #    t = target.project_.manager_.get_object (t)\n\n            if not t.root ():\n                result += traverse (t, include_roots, include_sources)\n\n            elif include_roots:\n                result.append (t)\n\n    elif include_sources:\n        result.append (target)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake an action instance and creates new instance of it and all produced targets.", "response": "def clone_action (action, new_project, new_action_name, new_properties):\n    \"\"\"Takes an 'action' instances and creates new instance of it\n    and all produced target. The rule-name and properties are set\n    to 'new-rule-name' and 'new-properties', if those are specified.\n    Returns the cloned action.\"\"\"\n    if __debug__:\n        from .targets import ProjectTarget\n        assert isinstance(action, Action)\n        assert isinstance(new_project, ProjectTarget)\n        assert isinstance(new_action_name, basestring)\n        assert isinstance(new_properties, property_set.PropertySet)\n    if not new_action_name:\n        new_action_name = action.action_name()\n\n    if not new_properties:\n        new_properties = action.properties()\n\n    cloned_action = action.__class__(action.manager_, action.sources(), new_action_name,\n                                     new_properties)\n\n    cloned_targets = []\n    for target in action.targets():\n\n        n = target.name()\n        # Don't modify the name of the produced targets. Strip the directory f\n        cloned_target = FileTarget(n, target.type(), new_project,\n                                   cloned_action, exact=True)\n\n        d = target.dependencies()\n        if d:\n            cloned_target.depends(d)\n        cloned_target.root(target.root())\n        cloned_target.creating_subvariant(target.creating_subvariant())\n\n        cloned_targets.append(cloned_target)\n\n    return cloned_action"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a new virtual target. Checks if there s already registered target with the same name type project and subvariant properties and also with the same sources and equal action. Returns the virtual target or None if there s already registered target.", "response": "def register (self, target):\n        \"\"\" Registers a new virtual target. Checks if there's already registered target, with the same\n            name, type, project and subvariant properties, and also with the same sources\n            and equal action. If such target is found it is retured and 'target' is not registered.\n            Otherwise, 'target' is registered and returned.\n        \"\"\"\n        assert isinstance(target, VirtualTarget)\n        if target.path():\n            signature = target.path() + \"-\" + target.name()\n        else:\n            signature = \"-\" + target.name()\n\n        result = None\n        if signature not in self.cache_:\n            self.cache_ [signature] = []\n\n        for t in self.cache_ [signature]:\n            a1 = t.action ()\n            a2 = target.action ()\n\n            # TODO: why are we checking for not result?\n            if not result:\n                if not a1 and not a2:\n                    result = t\n                else:\n                    if a1 and a2 and a1.action_name () == a2.action_name () and a1.sources () == a2.sources ():\n                        ps1 = a1.properties ()\n                        ps2 = a2.properties ()\n                        p1 = ps1.base () + ps1.free () +\\\n                            b2.util.set.difference(ps1.dependency(), ps1.incidental())\n                        p2 = ps2.base () + ps2.free () +\\\n                            b2.util.set.difference(ps2.dependency(), ps2.incidental())\n                        if p1 == p2:\n                            result = t\n\n        if not result:\n            self.cache_ [signature].append (target)\n            result = target\n\n        # TODO: Don't append if we found pre-existing target?\n        self.recent_targets_.append(result)\n        self.all_targets_.append(result)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_file (self, file, file_location, project):\n        if __debug__:\n            from .targets import ProjectTarget\n            assert isinstance(file, basestring)\n            assert isinstance(file_location, basestring)\n            assert isinstance(project, ProjectTarget)\n        # Check if we've created a target corresponding to this file.\n        path = os.path.join(os.getcwd(), file_location, file)\n        path = os.path.normpath(path)\n\n        if path in self.files_:\n            return self.files_ [path]\n\n        file_type = b2.build.type.type (file)\n\n        result = FileTarget (file, file_type, project,\n                             None, file_location)\n        self.files_ [path] = result\n\n        return result", "response": "Creates a virtual target from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_suffix (self, specified_name, file_type, prop_set):\n        assert isinstance(specified_name, basestring)\n        assert isinstance(file_type, basestring)\n        assert isinstance(prop_set, property_set.PropertySet)\n        suffix = b2.build.type.generated_target_suffix (file_type, prop_set)\n\n        if suffix:\n            return specified_name + '.' + suffix\n\n        else:\n            return specified_name", "response": "Adds the suffix appropriate to type or property_set combination\n            to the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef depends (self, d):\n        self.dependencies_ = unique (self.dependencies_ + d).sort ()", "response": "Adds additional instances of VirtualTarget that this\n            one depends on."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef actualize (self, scanner = None):\n        if __debug__:\n            from .scanner import Scanner\n            assert scanner is None or isinstance(scanner, Scanner)\n        actual_name = self.actualize_no_scanner ()\n\n        if self.always_:\n            bjam.call(\"ALWAYS\", actual_name)\n\n        if not scanner:\n            return actual_name\n\n        else:\n            # Add the scanner instance to the grist for name.\n            g = '-'.join ([ungrist(get_grist(actual_name)), str(id(scanner))])\n\n            name = replace_grist (actual_name, '<' + g + '>')\n\n            if name not in self.made_:\n                self.made_ [name] = True\n\n                self.project_.manager ().engine ().add_dependency (name, actual_name)\n\n                self.actualize_location (name)\n\n                self.project_.manager ().scanners ().install (scanner, name, str (self))\n\n            return name", "response": "Generates all the actual targets and sets up build actions for the target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_path (self, path):\n        assert isinstance(path, basestring)\n        self.path_ = os.path.normpath(path)", "response": "Sets the path for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the root flag.", "response": "def root (self, set = None):\n        \"\"\" Sets/gets the 'root' flag. Target is root is it directly correspods to some\n            variant of a main target.\n        \"\"\"\n        assert isinstance(set, (int, bool, type(None)))\n        if set:\n            self.root_ = True\n        return self.root_"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets or sets the subvariant which created this target.", "response": "def creating_subvariant (self, s = None):\n        \"\"\" Gets or sets the subvariant which created this target. Subvariant\n        is set when target is brought into existance, and is never changed\n        after that. In particual, if target is shared by subvariant, only\n        the first is stored.\n        s:  If specified, specified the value to set,\n                which should be instance of 'subvariant' class.\n        \"\"\"\n        assert s is None or isinstance(s, Subvariant)\n        if s and not self.creating_subvariant ():\n            if self.creating_subvariant ():\n                raise BaseException (\"Attempt to change 'dg'\")\n\n            else:\n                self.creating_subvariant_ = s\n\n        return self.creating_subvariant_"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grist (self):\n        # Depending on target, there may be different approaches to generating\n        # unique prefixes. We'll generate prefixes in the form\n        # <one letter approach code> <the actual prefix>\n        path = self.path ()\n\n        if path:\n            # The target will be generated to a known path. Just use the path\n            # for identification, since path is as unique as it can get.\n            return 'p' + path\n\n        else:\n            # File is either source, which will be searched for, or is not a file at\n            # all. Use the location of project for distinguishing.\n            project_location = self.project_.get ('location')\n            path_components = b2.util.path.split(project_location)\n            location_grist = '!'.join (path_components)\n\n            if self.action_:\n                ps = self.action_.properties ()\n                property_grist = ps.as_path ()\n                # 'property_grist' can be empty when 'ps' is an empty\n                # property set.\n                if property_grist:\n                    location_grist = location_grist + '/' + property_grist\n\n            return 'l' + location_grist", "response": "Helper to actual_name above. Compute unique prefix used to distinguish this target from other targets with the same name which create different\n            file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __adjust_name(self, specified_name):\n        assert isinstance(specified_name, basestring)\n        if self.action_:\n            ps = self.action_.properties()\n        else:\n            ps = property_set.empty()\n\n        # FIXME: I'm not sure how this is used, need to check with\n        # Rene to figure out how to implement\n        #~ We add ourselves to the properties so that any tag rule can get\n        #~ more direct information about the target than just that available\n        #~ through the properties. This is useful in implementing\n        #~ name changes based on the sources of the target. For example to\n        #~ make unique names of object files based on the source file.\n        #~ --grafik\n        #ps = property_set.create(ps.raw() + [\"<target>%s\" % \"XXXX\"])\n        #ps = [ property-set.create [ $(ps).raw ] <target>$(__name__) ] ;\n\n        tag = ps.get(\"<tag>\")\n\n        if tag:\n\n            if len(tag) > 1:\n                get_manager().errors()(\n                    \"\"\"<tag>@rulename is present but is not the only <tag> feature\"\"\")\n\n            tag = tag[0]\n            if callable(tag):\n                self.name_ = tag(specified_name, self.type_, ps)\n            else:\n                if not tag[0] == '@':\n                    self.manager_.errors()(\"\"\"The value of the <tag> feature must be '@rule-nane'\"\"\")\n\n                exported_ps = b2.util.value_to_jam(ps, methods=True)\n                self.name_ = b2.util.call_jam_function(\n                    tag[1:], specified_name, self.type_, exported_ps)\n                if self.name_:\n                    self.name_ = self.name_[0]\n\n        # If there's no tag or the tag rule returned nothing.\n        if not tag or not self.name_:\n            self.name_ = add_prefix_and_suffix(specified_name, self.type_, ps)", "response": "Adjusts the name of the object file based on the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path to the target file.", "response": "def path (self):\n        \"\"\" Returns the directory for this target.\n        \"\"\"\n        if not self.path_:\n            if self.action_:\n                p = self.action_.properties ()\n                (target_path, relative_to_build_dir) = p.target_path ()\n\n                if relative_to_build_dir:\n                    # Indicates that the path is relative to\n                    # build dir.\n                    target_path = os.path.join (self.project_.build_dir (), target_path)\n\n                # Store the computed path, so that it's not recomputed\n                # any more\n                self.path_ = target_path\n\n        return os.path.normpath(self.path_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef actualize (self):\n        if self.actualized_:\n            return\n\n        self.actualized_ = True\n\n        ps = self.properties ()\n        properties = self.adjust_properties (ps)\n\n\n        actual_targets = []\n\n        for i in self.targets ():\n            actual_targets.append (i.actualize ())\n\n        self.actualize_sources (self.sources (), properties)\n\n        self.engine_.add_dependency (actual_targets, self.actual_sources_ + self.dependency_only_sources_)\n\n        # FIXME: check the comment below. Was self.action_name_ [1]\n        # Action name can include additional rule arguments, which should not\n        # be passed to 'set-target-variables'.\n        # FIXME: breaking circular dependency\n        import toolset\n        toolset.set_target_variables (self.manager_, self.action_name_, actual_targets, properties)\n\n        engine = self.manager_.engine ()\n\n        # FIXME: this is supposed to help --out-xml option, but we don't\n        # implement that now, and anyway, we should handle it in Python,\n        # not but putting variables on bjam-level targets.\n        bjam.call(\"set-target-variable\", actual_targets, \".action\", repr(self))\n\n        self.manager_.engine ().set_update_action (self.action_name_, actual_targets, self.actual_sources_,\n                                                   properties)\n\n        # Since we set up creating action here, we also set up\n        # action for cleaning up\n        self.manager_.engine ().set_update_action ('common.Clean', 'clean-all',\n                                                   actual_targets)\n\n        return actual_targets", "response": "Generates actual build instructions for this target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate actual jam targets for sources.", "response": "def actualize_sources (self, sources, prop_set):\n        \"\"\" Creates actual jam targets for sources. Initializes two member\n            variables:\n            'self.actual_sources_' -- sources which are passed to updating action\n            'self.dependency_only_sources_' -- sources which are made dependencies, but\n            are not used otherwise.\n\n            New values will be *appended* to the variables. They may be non-empty,\n            if caller wants it.\n        \"\"\"\n        assert is_iterable_typed(sources, VirtualTarget)\n        assert isinstance(prop_set, property_set.PropertySet)\n        dependencies = self.properties_.get ('<dependency>')\n\n        self.dependency_only_sources_ += self.actualize_source_type (dependencies, prop_set)\n        self.actual_sources_ += self.actualize_source_type (sources, prop_set)\n\n        # This is used to help bjam find dependencies in generated headers\n        # in other main targets.\n        # Say:\n        #\n        #   make a.h : ....... ;\n        #   exe hello : hello.cpp : <implicit-dependency>a.h ;\n        #\n        # However, for bjam to find the dependency the generated target must\n        # be actualized (i.e. have the jam target). In the above case,\n        # if we're building just hello (\"bjam hello\"), 'a.h' won't be\n        # actualized unless we do it here.\n        implicit = self.properties_.get(\"<implicit-dependency>\")\n\n        for i in implicit:\n            i.actualize()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_referenced_targets(self, result):\n        if __debug__:\n            from .property import Property\n            assert is_iterable_typed(result, (VirtualTarget, Property))\n        # Find directly referenced targets.\n        deps = self.build_properties().dependency()\n        all_targets = self.sources_ + deps\n\n        # Find other subvariants.\n        r = []\n        for e in all_targets:\n            if not e in result:\n                result.add(e)\n                if isinstance(e, property.Property):\n                    t = e.value\n                else:\n                    t = e\n\n                # FIXME: how can this be?\n                cs = t.creating_subvariant()\n                if cs:\n                    r.append(cs)\n        r = unique(r)\n        for s in r:\n            if s != self:\n                s.all_referenced_targets(result)", "response": "Returns all targets referenced by this subvariant and all of its children."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the implicit include paths to the target_type of the target_type of the feature.", "response": "def implicit_includes (self, feature, target_type):\n        \"\"\" Returns the properties which specify implicit include paths to\n            generated headers. This traverses all targets in this subvariant,\n            and subvariants referred by <implcit-dependecy>properties.\n            For all targets which are of type 'target-type' (or for all targets,\n            if 'target_type' is not specified), the result will contain\n            <$(feature)>path-to-that-target.\n        \"\"\"\n        assert isinstance(feature, basestring)\n        assert isinstance(target_type, basestring)\n        if not target_type:\n            key = feature\n        else:\n            key = feature + \"-\" + target_type\n\n\n        result = self.implicit_includes_cache_.get(key)\n        if not result:\n            target_paths = self.all_target_directories(target_type)\n            target_paths = unique(target_paths)\n            result = [\"<%s>%s\" % (feature, p) for p in target_paths]\n            self.implicit_includes_cache_[key] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare if two nodes are equal.", "response": "def cmp_ast(node1, node2):\n    '''\n    Compare if two nodes are equal.\n    '''\n\n    if type(node1) != type(node2):\n        return False\n\n    if isinstance(node1, (list, tuple)):\n        if len(node1) != len(node2):\n            return False\n\n        for left, right in zip(node1, node2):\n            if not cmp_ast(left, right):\n                return False\n\n    elif isinstance(node1, ast.AST):\n        for field in node1._fields:\n            left = getattr(node1, field, Undedined)\n            right = getattr(node2, field, Undedined)\n\n            if not cmp_ast(left, right):\n                return False\n    else:\n        return node1 == node2\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate additional files for the individual MPL - containers.", "response": "def create_more_container_files(sourceDir, suffix, maxElements, containers, containers2):\n    \"\"\"Creates additional files for the individual MPL-containers.\"\"\"\n\n    # Create files for each MPL-container with 20 to 'maxElements' elements\n    # which will be used during generation.\n    for container in containers:\n        for i in range(20, maxElements, 10):\n            # Create copy of \"template\"-file.\n            newFile = os.path.join( sourceDir, container, container + str(i+10) + suffix )\n            shutil.copyfile( os.path.join( sourceDir, container, container + \"20\" + suffix ), newFile ) \n            # Adjust copy of \"template\"-file accordingly.\n            for line in fileinput.input( newFile, inplace=1, mode=\"rU\" ):\n                line = re.sub(r'20', '%TWENTY%', line.rstrip())\n                line = re.sub(r'11', '%ELEVEN%', line.rstrip())\n                line = re.sub(r'10(?![0-9])', '%TEN%', line.rstrip())\n                line = re.sub(r'%TWENTY%', re.escape(str(i+10)), line.rstrip())\n                line = re.sub(r'%ELEVEN%', re.escape(str(i + 1)), line.rstrip())\n                line = re.sub(r'%TEN%', re.escape(str(i)), line.rstrip())\n                print(line)\n    for container in containers2:\n        for i in range(20, maxElements, 10):\n            # Create copy of \"template\"-file.\n            newFile = os.path.join( sourceDir, container, container + str(i+10) + \"_c\" + suffix )\n            shutil.copyfile( os.path.join( sourceDir, container, container + \"20_c\" + suffix ), newFile ) \n            # Adjust copy of \"template\"-file accordingly.\n            for line in fileinput.input( newFile, inplace=1, mode=\"rU\" ):\n                line = re.sub(r'20', '%TWENTY%', line.rstrip())\n                line = re.sub(r'11', '%ELEVEN%', line.rstrip())\n                line = re.sub(r'10(?![0-9])', '%TEN%', line.rstrip())\n                line = re.sub(r'%TWENTY%', re.escape(str(i+10)), line.rstrip())\n                line = re.sub(r'%ELEVEN%', re.escape(str(i + 1)), line.rstrip())\n                line = re.sub(r'%TEN%', re.escape(str(i)), line.rstrip())\n                print(line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_input_for_numbered_sequences(headerDir, sourceDir, containers, maxElements):\n    # Create additional container-list without \"map\".\n    containersWithoutMap = containers[:]\n    try:\n        containersWithoutMap.remove('map')\n    except ValueError:\n        # We can safely ignore if \"map\" is not contained in 'containers'!\n        pass\n    # Create header/source-files.\n    create_more_container_files(headerDir, \".hpp\", maxElements, containers, containersWithoutMap)\n    create_more_container_files(sourceDir, \".cpp\", maxElements, containers, containersWithoutMap)", "response": "Creates additional source - and header - files for the numbered sequence MPL - containers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adjust_container_limits_for_variadic_sequences(headerDir, containers, maxElements):\n    for container in containers:\n        headerFile = os.path.join( headerDir, \"limits\", container + \".hpp\" )\n        regexMatch   = r'(define\\s+BOOST_MPL_LIMIT_' + container.upper() + r'_SIZE\\s+)[0-9]+'\n        regexReplace = r'\\g<1>' + re.escape( str(maxElements) )\n        for line in fileinput.input( headerFile, inplace=1, mode=\"rU\" ):\n            line = re.sub(regexMatch, regexReplace, line.rstrip())\n            print(line)", "response": "Adjusts the limits of variadic MPL - containers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the ( relative ) path to the Boost source - directory this file is located in ( if any ).", "response": "def current_boost_dir():\n    \"\"\"Returns the (relative) path to the Boost source-directory this file is located in (if any).\"\"\"\n    # Path to directory containing this script.\n    path = os.path.dirname( os.path.realpath(__file__) )\n    # Making sure it is located in \"${boost-dir}/libs/mpl/preprocessed\".\n    for directory in reversed( [\"libs\", \"mpl\", \"preprocessed\"] ):\n        (head, tail) = os.path.split(path)\n        if tail == directory:\n            path = head\n        else:\n            return None\n    return os.path.relpath( path )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_positive_multiple_of_10(string):\n    try:\n        value = int(string)\n    except ValueError:\n        msg = '\"%r\" is not a positive multiple of 10 (greater zero).' % string\n        raise argparse.ArgumentTypeError(msg)\n    if value <= 0 or value % 10 != 0:\n        msg = '\"%r\" is not a positive multiple of 10 (greater zero).' % string\n        raise argparse.ArgumentTypeError(msg)\n    return value", "response": "Converts a string into its encoded positive integer ( greater zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    \n    # Find the current Boost source-directory in which this script is located.\n    sourceDir = current_boost_dir()\n    if sourceDir == None:\n        sourceDir = \"\"\n    \n    # Prepare and run cmdline-parser.\n    cmdlineParser = argparse.ArgumentParser(description=\"A generator-script for pre-processed Boost.MPL headers.\")\n    cmdlineParser.add_argument(\"-v\", \"--verbose\", dest='verbose', action='store_true',\n                               help=\"Be a little bit more verbose.\")\n    cmdlineParser.add_argument(\"-s\", \"--sequence-type\", dest='seqType', choices=['variadic', 'numbered', 'both'],\n                               default='both',\n                               help=\"Only update pre-processed headers for the selected sequence types, \"\n                                    \"either 'numbered' sequences, 'variadic' sequences or 'both' sequence \"\n                                    \"types. (Default=both)\")\n    cmdlineParser.add_argument(\"--no-vector\", dest='want_vector', action='store_false',\n                               help=\"Do not update pre-processed headers for Boost.MPL Vector.\")\n    cmdlineParser.add_argument(\"--no-list\", dest='want_list', action='store_false',\n                               help=\"Do not update pre-processed headers for Boost.MPL List.\")\n    cmdlineParser.add_argument(\"--no-set\", dest='want_set', action='store_false',\n                               help=\"Do not update pre-processed headers for Boost.MPL Set.\")\n    cmdlineParser.add_argument(\"--no-map\", dest='want_map', action='store_false',\n                               help=\"Do not update pre-processed headers for Boost.MPL Map.\")\n    cmdlineParser.add_argument(\"--num-elements\", dest='numElements', metavar=\"<num-elements>\",\n                               type=to_positive_multiple_of_10, default=100,\n                               help=\"The maximal number of elements per container sequence. (Default=100)\")\n    cmdlineParser.add_argument(dest='sourceDir', metavar=\"<source-dir>\", default=current_boost_dir(), nargs='?',\n                               type=to_existing_absolute_path,\n                               help=\"The source-directory of Boost. (Default=\\\"\" + sourceDir + \"\\\")\")\n    args = cmdlineParser.parse_args()\n\n    # Some verbose debug output.\n    if args.verbose:\n        print \"Arguments extracted from command-line:\"\n        print \"  verbose          = \", args.verbose\n        print \"  source directory = \", args.sourceDir\n        print \"  num elements     = \", args.numElements\n        print \"  sequence type    = \", args.seqType\n        print \"  want: vector     = \", args.want_vector\n        print \"  want: list       = \", args.want_list\n        print \"  want: set        = \", args.want_set\n        print \"  want: map        = \", args.want_map\n\n    # Verify that we received any source-directory.\n    if args.sourceDir == None:\n        print \"You should specify a valid path to the Boost source-directory.\"\n        sys.exit(0)\n\n    # The directories for header- and source files of Boost.MPL.\n    # NOTE: Assuming 'args.sourceDir' is the source-directory of the entire boost project.\n    headerDir = os.path.join( args.sourceDir, \"boost\", \"mpl\" )\n    sourceDir = os.path.join( args.sourceDir, \"libs\", \"mpl\", \"preprocessed\" )\n    # Check that the header/source-directories exist.\n    if not os.path.exists( headerDir ) or not os.path.exists( sourceDir ):\n        # Maybe 'args.sourceDir' is not the source-directory of the entire boost project\n        # but instead of the Boost.MPL git-directory, only?\n        headerDir = os.path.join( args.sourceDir, \"include\", \"boost\", \"mpl\" )\n        sourceDir = os.path.join( args.sourceDir, \"preprocessed\" )\n        if not os.path.exists( headerDir ) or not os.path.exists( sourceDir ):\n            cmdlineParser.print_usage()\n            print \"error: Cannot find Boost.MPL header/source files in given Boost source-directory!\"\n            sys.exit(0)\n\n    # Some verbose debug output.\n    if args.verbose:\n        print \"Chosen header-directory: \", headerDir\n        print \"Chosen source-directory: \", sourceDir\n\n    # Create list of containers for which files shall be pre-processed.\n    containers = []\n    if args.want_vector:\n        containers.append('vector')\n    if args.want_list:\n        containers.append('list')\n    if args.want_set:\n        containers.append('set')\n    if args.want_map:\n        containers.append('map')\n    if containers == []:\n        print \"Nothing to do.\"\n        print \"(Why did you prevent generating pre-processed headers for all Boost.MPL container types?)\"\n        sys.exit(0)\n\n    # Possibly fix the header-comments of input-files needed for pre-processing.\n    if args.verbose:\n        print \"Checking if prior to pre-processing some input-files need fixing.\"\n    needFixing = fixmpl.check_input_files(headerDir, sourceDir, containers, args.seqType, args.verbose)\n    if needFixing:\n        if args.verbose:\n            print \"Fixing of some input-files prior to pre-processing is needed.\"\n            print \"Will fix them now!\"\n        fixmpl.fix_input_files(headerDir, sourceDir, containers, args.seqType, args.verbose)\n\n    # Some verbose debug output.\n    if args.verbose:\n        print \"Containers for which to pre-process headers: \", containers\n\n    # Create (additional) input files for generating pre-processed headers of numbered sequence MPL containers.\n    if args.seqType == \"both\" or args.seqType == \"numbered\":\n        create_input_for_numbered_sequences(headerDir, sourceDir, containers, args.numElements)\n    # Modify settings for generating pre-processed headers of variadic sequence MPL containers.\n    if args.seqType == \"both\" or args.seqType == \"variadic\":\n        adjust_container_limits_for_variadic_sequences(headerDir, containers, args.numElements)\n\n    # Generate MPL-preprocessed files.\n    os.chdir( sourceDir )\n    if args.seqType == \"both\" or args.seqType == \"numbered\":\n        if args.want_vector:\n            if args.verbose:\n                print \"Pre-process headers for Boost.MPL numbered vectors.\"\n            os.system( \"python \" + os.path.join( sourceDir, \"preprocess_vector.py\" ) + \" all \" + args.sourceDir )\n        if args.want_list:\n            if args.verbose:\n                print \"Pre-process headers for Boost.MPL numbered lists.\"\n            os.system( \"python \" + os.path.join( sourceDir, \"preprocess_list.py\" ) + \" all \" + args.sourceDir )\n        if args.want_set:\n            if args.verbose:\n                print \"Pre-process headers for Boost.MPL numbered sets.\"\n            os.system( \"python \" + os.path.join( sourceDir, \"preprocess_set.py\" ) + \" all \" + args.sourceDir )\n        if args.want_map:\n            if args.verbose:\n                print \"Pre-process headers for Boost.MPL numbered maps.\"\n            os.system( \"python \" + os.path.join( sourceDir, \"preprocess_map.py\" ) + \" all \" + args.sourceDir )\n    if args.seqType == \"both\" or args.seqType == \"variadic\":\n        if args.verbose:\n            print \"Pre-process headers for Boost.MPL variadic containers.\"\n        os.system( \"python \" + os.path.join( sourceDir, \"preprocess.py\" ) + \" all \" + args.sourceDir )", "response": "The main function of the generator - script."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an inner product layer to the model. Parameters ---------- name: str The name of this layer W: numpy.array or bytes() Weight matrix of shape (output_channels, input_channels) If W is of type bytes(), i.e. quantized, other quantization related arguments must be provided as well (see below). b: numpy.array Bias vector of shape (output_channels, ). input_channels: int Number of input channels. output_channels: int Number of output channels. has_bias: boolean Whether the bias vector of this layer is ignored in the spec. - If True, the bias vector of this layer is not ignored. - If False, the bias vector is ignored. input_name: str The input blob name of this layer. output_name: str The output blob name of this layer. Quantization arguments expected in kwargs, when W is of type bytes(): quantization_type : str When weights are quantized (i.e. W is of type bytes()), this should be either \"linear\" or \"lut\". nbits: int Should be between 1 and 8 (inclusive). Number of bits per weight value. Only applicable when weights are quantized. quant_scale: numpy.array(dtype=numpy.float32) scale vector to be used with linear quantization. Must be of length either 1 or output_channels. quant_bias: numpy.array(dtype=numpy.float32) bias vector to be used with linear quantization. Must be of length either 1 or output_channels. quant_lut: numpy.array(dtype=numpy.float32) the LUT (look up table) to be used with LUT quantization. Must be of length 2^nbits. See Also -------- add_embedding, add_convolution", "response": "def add_inner_product(self, name, W, b, input_channels, output_channels, has_bias,\n                          input_name, output_name, **kwargs):\n        \"\"\"\n        Add an inner product layer to the model.\n\n        Parameters\n        ----------\n        name: str\n            The name of this layer\n        W: numpy.array or bytes()\n            Weight matrix of shape (output_channels, input_channels)\n            If W is of type bytes(), i.e. quantized, other quantization related arguments must be provided as well (see below).\n        b: numpy.array\n            Bias vector of shape (output_channels, ).\n        input_channels: int\n            Number of input channels.\n        output_channels: int\n            Number of output channels.\n        has_bias: boolean\n            Whether the bias vector of this layer is ignored in the spec.\n\n            - If True, the bias vector of this layer is not ignored.\n            - If False, the bias vector is ignored.\n\n        input_name: str\n            The input blob name of this layer.\n        output_name: str\n            The output blob name of this layer.\n\n        Quantization arguments expected in kwargs, when W is of type bytes():\n\n            quantization_type : str\n                When weights are quantized (i.e. W is of type bytes()), this should be either \"linear\" or \"lut\".\n\n            nbits: int\n                Should be between 1 and 8 (inclusive). Number of bits per weight value. Only applicable when\n                weights are quantized.\n\n            quant_scale: numpy.array(dtype=numpy.float32)\n                scale vector to be used with linear quantization. Must be of length either 1 or output_channels.\n\n            quant_bias: numpy.array(dtype=numpy.float32)\n                bias vector to be used with linear quantization. Must be of length either 1 or output_channels.\n\n            quant_lut: numpy.array(dtype=numpy.float32)\n                the LUT (look up table) to be used with LUT quantization. Must be of length 2^nbits.\n\n        See Also\n        --------\n        add_embedding, add_convolution\n        \"\"\"\n\n        spec = self.spec\n        nn_spec = self.nn_spec\n\n        # Add a new layer\n        spec_layer = nn_spec.layers.add()\n        spec_layer.name = name\n        spec_layer.input.append(input_name)\n        spec_layer.output.append(output_name)\n        spec_layer_params = spec_layer.innerProduct\n\n        # Fill in the parameters\n        spec_layer_params.inputChannels = input_channels\n        spec_layer_params.outputChannels = output_channels\n        spec_layer_params.hasBias = has_bias\n\n        weights = spec_layer_params.weights\n\n        if len(kwargs) == 0:\n            weights.floatValue.extend(map(float, W.flatten()))\n        else:\n            _verify_quantization_arguments(weight=W, output_channels=output_channels, **kwargs)\n            _fill_quantized_weights(weights_message=weights, W=W, **kwargs)\n\n        if has_bias:\n            bias = spec_layer_params.bias\n            bias.floatValue.extend(map(float, b.flatten()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_convolution(self, name, kernel_channels, output_channels, height,\n            width, stride_height, stride_width, border_mode, groups, W, b, has_bias,\n            is_deconv = False, output_shape = None,\n            input_name = 'data', output_name = 'out',\n            dilation_factors = [1,1],\n            padding_top = 0, padding_bottom = 0, padding_left = 0, padding_right = 0,\n            same_padding_asymmetry_mode = 'BOTTOM_RIGHT_HEAVY',\n            **kwargs):\n        \"\"\"\n        Add a convolution layer to the network.\n\n        Please see the ConvolutionLayerParams in Core ML neural network\n        protobuf message for more information about input and output blob dimensions.\n\n        Parameters\n        ----------\n        name: str\n            The name of this layer.\n        kernel_channels: int\n            Number of channels for the convolution kernels.\n        output_channels: int\n            Number of filter kernels. This is equal to the number of channels in the output blob.\n        height: int\n            Height of each kernel.\n        width: int\n            Width of each kernel.\n        stride_height: int\n            Stride along the height direction.\n        stride_width: int\n            Stride along the height direction.\n        border_mode: str\n            Option for the padding type and output blob shape. Can be either 'valid' or 'same'.\n            Kindly refer to NeuralNetwork.proto for details.\n        groups: int\n            Number of kernel groups. Input is divided into groups along the channel axis. Each kernel group share the same weights.\n        W: numpy.array or bytes()\n            Weight of the convolution kernels.\n\n            - If is_deconv is False, W should have shape (height, width, kernel_channels, output_channels), where kernel_channel = input_channels / groups\n            - If is_deconv is True, W should have shape (height, width, kernel_channels, output_channels / groups), where kernel_channel = input_channels\n\n            If W is of type bytes(), i.e. quantized, other quantization related arguments must be provided as well (see below).\n\n        b: numpy.array\n            Biases of the convolution kernels. b should have shape (outputChannels, ).\n        has_bias: boolean\n            Whether bias is ignored.\n\n            - If True, bias is not ignored.\n            - If False, bias is ignored.\n\n        is_deconv: boolean\n            Whether the convolution layer is performing a convolution or a transposed convolution (deconvolution).\n\n            - If True, the convolution layer is performing transposed convolution.\n            - If False, the convolution layer is performing regular convolution.\n\n        output_shape: tuple | None\n            Either None or a 2-tuple, specifying the output shape (output_height, output_width). Used only when is_deconv == True.\n            When is_deconv == False, this parameter is ignored.\n            If it is None, the output shape is calculated automatically using the border_mode.\n            Kindly refer to NeuralNetwork.proto for details.\n\n        input_name: str\n            The input blob name of this layer.\n        output_name: str\n            The output blob name of this layer.\n\n        dilation_factors: [int]\n            Dilation factors across height and width directions. Must be a list of two positive integers.\n            Defaults to [1,1]\n\n        padding_top, padding_bottom, padding_left, padding_right: int\n            values of height (top, bottom) and width (left, right) padding to be used if border_more is \"valid\".\n\n        same_padding_asymmetry_mode : str.\n            Type of asymmetric padding to be used when  border_mode is 'same'.\n            Can be either 'BOTTOM_RIGHT_HEAVY' or  'TOP_LEFT_HEAVY'.\n            Kindly refer to NeuralNetwork.proto for details.\n\n\n        Depthwise convolution is a special case of convolution, where we have:\n            kernel_channels = 1 (== input_channels / groups)\n            output_channels = channel_multiplier * input_channels\n            groups = input_channels\n            W : [Kernel_height, Kernel_width, 1, channel_multiplier * input_channels]\n\n\n        Quantization arguments expected in kwargs, when W is of type bytes():\n\n            quantization_type : str\n                When weights are quantized (i.e. W is of type bytes()), this should be either \"linear\" or \"lut\".\n\n            nbits: int\n                Should be between 1 and 8 (inclusive). Number of bits per weight value. Only applicable when\n                weights are quantized.\n\n            quant_scale: numpy.array(dtype=numpy.float32)\n                scale vector to be used with linear quantization. Must be of length either 1 or output_channels.\n\n            quant_bias: numpy.array(dtype=numpy.float32)\n                bias vector to be used with linear quantization. Must be of length either 1 or output_channels.\n\n            quant_lut: numpy.array(dtype=numpy.float32)\n                the LUT (look up table) to be used with LUT quantization. Must be of length 2^nbits.\n\n        See Also\n        --------\n        add_pooling, add_activation, add_batchnorm\n\n        \"\"\"\n        spec = self.spec\n        nn_spec = self.nn_spec\n\n        # Add a new layer\n        spec_layer = nn_spec.layers.add()\n        spec_layer.name = name\n        spec_layer.input.append(input_name)\n        spec_layer.output.append(output_name)\n        spec_layer.convolution.MergeFromString(b'') # hack to set empty message\n\n        # Set the layer params\n        spec_layer_params = spec_layer.convolution\n        spec_layer_params.isDeconvolution = is_deconv\n\n        if is_deconv and output_shape:\n            spec_layer_params.outputShape.append(output_shape[0])\n            spec_layer_params.outputShape.append(output_shape[1])\n\n        spec_layer_params.outputChannels = output_channels\n        spec_layer_params.kernelChannels = kernel_channels\n        spec_layer_params.kernelSize.append(height)\n        spec_layer_params.kernelSize.append(width)\n        spec_layer_params.stride.append(stride_height)\n        spec_layer_params.stride.append(stride_width)\n\n        if border_mode == 'valid':\n            height_border = spec_layer_params.valid.paddingAmounts.borderAmounts.add()\n            height_border.startEdgeSize = padding_top\n            height_border.endEdgeSize = padding_bottom\n            width_border = spec_layer_params.valid.paddingAmounts.borderAmounts.add()\n            width_border.startEdgeSize = padding_left\n            width_border.endEdgeSize = padding_right\n        elif border_mode == 'same':\n            if not (same_padding_asymmetry_mode == 'BOTTOM_RIGHT_HEAVY' or  same_padding_asymmetry_mode == 'TOP_LEFT_HEAVY'):\n                raise ValueError(\"Invalid value %d of same_padding_asymmetry_mode parameter\" % same_padding_asymmetry_mode)\n            spec_layer_params.same.asymmetryMode = _NeuralNetwork_pb2.SamePadding.SamePaddingMode.Value(same_padding_asymmetry_mode)\n        else:\n            raise NotImplementedError(\n                'Border mode %s is not implemented.' % border_mode)\n\n        spec_layer_params.nGroups = groups\n        spec_layer_params.hasBias = has_bias\n\n        if len(kwargs) > 0:\n            _verify_quantization_arguments(weight = W, output_channels=output_channels, **kwargs)\n\n            nbits = kwargs.get('nbits', 8)\n            num_weights = (output_channels * kernel_channels * height * width) / groups\n            if nbits < 8:\n                byte_arr = np.frombuffer(W, dtype=np.uint8)\n                W = unpack_to_bytes(byte_arr, num_weights, nbits)\n            else:\n                W = np.frombuffer(W, dtype=np.uint8)\n\n            if is_deconv:\n                W = np.reshape(W, (height, width, kernel_channels, output_channels / groups))\n            else:\n                W = np.reshape(W, (height, width, kernel_channels, output_channels))\n\n\n        # Weight alignment: MLModel Spec requires following weight arrangement:\n        # is_deconv == False ==> (output_channels, kernel_channels, height, width), where kernel_channel = input_channels / groups\n        # is_deconv == True ==> (kernel_channels, output_channels / groups, height, width), where kernel_channel = input_channels\n        if not is_deconv:\n            Wt = W.transpose((3,2,0,1))\n            Wt = Wt.flatten()\n        else:\n            Wt = W.transpose((2,3,0,1)).flatten()\n\n        # Assign weights\n        weights = spec_layer_params.weights\n        if len(kwargs) == 0: # no quantization\n            weights.floatValue.extend(map(float, Wt.flatten()))\n        else: # there is quantization\n            W_bytes = bytes()\n            if nbits == 8:\n                W_bytes += Wt.flatten().tobytes()\n            else:\n                W_bytes += _convert_array_to_nbit_quantized_bytes(Wt.flatten(), nbits).tobytes()\n            _fill_quantized_weights(weights_message = weights, W = W_bytes, **kwargs)\n\n        # Assign biases\n        if has_bias:\n            bias = spec_layer_params.bias\n            for f in range(output_channels):\n                bias.floatValue.append(float(b[f]))\n\n        # add dilation factors\n        spec_layer_params.dilationFactor.append(dilation_factors[0])\n        spec_layer_params.dilationFactor.append(dilation_factors[1])", "response": "This method adds a convolution layer to the Neural Network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding resize bilinear layer to the model.", "response": "def add_resize_bilinear(self, name, input_name, output_name, target_height=1, target_width=1,\n                            mode='ALIGN_ENDPOINTS_MODE'):\n        \"\"\"\n        Add resize bilinear layer to the model. A layer that resizes the input to a given spatial size using bilinear interpolation.\n\n        Parameters\n        ----------\n        name: str\n            The name of this layer.\n        input_name: str\n            The input blob name of this layer.\n        output_name: str\n            The output blob name of this layer.\n        target_height: int\n            Output height dimension.\n        target_width: int\n            Output width dimension.\n        mode: str\n            Following values are supported: 'STRICT_ALIGN_ENDPOINTS_MODE', 'ALIGN_ENDPOINTS_MODE', 'UPSAMPLE_MODE', 'ROI_ALIGN_MODE'.\n            This parameter determines the sampling grid used for bilinear interpolation. Kindly refer to NeuralNetwork.proto for details.\n\n        See Also\n        --------\n        add_upsample\n        \"\"\"\n        spec = self.spec\n        nn_spec = self.nn_spec\n\n        # Add a new inner-product layer\n        spec_layer = nn_spec.layers.add()\n        spec_layer.name = name\n        spec_layer.input.append(input_name)\n        spec_layer.output.append(output_name)\n        spec_layer_params = spec_layer.resizeBilinear\n        spec_layer_params.targetSize.append(target_height)\n        spec_layer_params.targetSize.append(target_width)\n        if mode == 'ALIGN_ENDPOINTS_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('ALIGN_ENDPOINTS_MODE')\n        elif mode == 'STRICT_ALIGN_ENDPOINTS_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('STRICT_ALIGN_ENDPOINTS_MODE')\n        elif mode == 'UPSAMPLE_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('UPSAMPLE_MODE')\n        elif mode == 'ROI_ALIGN_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('ROI_ALIGN_MODE')\n        else:\n            raise ValueError(\"Unspported resize bilinear mode %s\" % mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd crop resize layer to the model. A layer that extracts cropped spatial patches or RoIs (regions of interest) from the input and resizes them to a pre-specified size using bilinear interpolation. Note that RoI Align layer can be implemented with this layer followed by a pooling layer. Kindly refer to NeuralNetwork.proto for details. Parameters ---------- name: str The name of this layer. input_names: [str] Must be a list of two names: image feature map and crop indices/RoI input. First input corresponds to a blob with shape ``[1, Batch, C, H_in, W_in]``. This represents a batch of input image feature data with C channels. The second input shape must be ``[N, 1, 4, 1, 1]`` or ``[N, 1, 5, 1, 1]``. This represents the bounding box coordinates for N patches/RoIs. N: number of patches/RoIs to be extracted If RoI shape = [N, 1, 4, 1, 1] The channel axis corresponds to the four coordinates specifying the bounding box. All the N RoIs are extracted from all the batches of the input. If RoI shape = [N, 1, 5, 1, 1] The first element of the channel axis specifies the input batch id from which to extract the RoI and must be in the interval ``[0, Batch - 1]``. That is, n-th RoI is extracted from the RoI[n,0,0,0]-th input batch id. The last four elements of the channel axis specify the bounding box coordinates. output_name: str The output blob name of this layer. target_height: int Output height dimension. target_width: int Output width dimension. mode: str Following values are supported: 'STRICT_ALIGN_ENDPOINTS_MODE', 'ALIGN_ENDPOINTS_MODE', 'UPSAMPLE_MODE', 'ROI_ALIGN_MODE'. This parameter determines the sampling grid used for bilinear interpolation. Kindly refer to NeuralNetwork.proto for details. normalized_roi: bool If true the bounding box coordinates must be in the interval [0, 1]. They are scaled by (input_height - 1), (input_width - 1), i.e. based on the input spatial dimensions. If false the bounding box coordinates must be in the interval [0, input_height - 1] and [0, input_width - 1], respectively for height and width dimensions. box_indices_mode: str Following values are supported: 'CORNERS_HEIGHT_FIRST', 'CORNERS_WIDTH_FIRST', 'CENTER_SIZE_HEIGHT_FIRST', 'CENTER_SIZE_WIDTH_FIRST' Representation used to interpret the bounding box coordinates (RoI) input. Kindly refer to NeuralNetwork.proto for details. 'CORNERS_HEIGHT_FIRST': [h_start, w_start, h_end, w_end] 'CORNERS_WIDTH_FIRST': [w_start, h_start, w_end, h_end] 'CENTER_SIZE_HEIGHT_FIRST': [h_center, w_center, box_height, box_width] 'CENTER_SIZE_WIDTH_FIRST': [w_center, h_center, box_width, box_height] spatial_scale: float Additional spatial scale that multiplies the bounding box coordinates. Generally used while implementing the RoI Align layer, which uses unnormalized RoI coordinates along with a spatial scale less than or equal to 1. See Also -------- add_resize_bilinear, add_crop", "response": "def add_crop_resize(self, name, input_names, output_name, target_height=1, target_width=1,\n                            mode='STRICT_ALIGN_ENDPOINTS_MODE',\n                            normalized_roi=False,\n                            box_indices_mode='CORNERS_HEIGHT_FIRST',\n                            spatial_scale=1.0):\n        \"\"\"\n        Add crop resize layer to the model. A layer that extracts cropped spatial patches or RoIs (regions of interest)\n        from the input and resizes them to a pre-specified size using bilinear interpolation.\n        Note that RoI Align layer can be implemented with this layer followed by a pooling layer.\n        Kindly refer to NeuralNetwork.proto for details.\n\n        Parameters\n        ----------\n        name: str\n            The name of this layer.\n        input_names: [str]\n            Must be a list of two names: image feature map and crop indices/RoI input.\n            First input corresponds to a blob with shape ``[1, Batch, C, H_in, W_in]``. This represents a batch of input image feature data with C channels.\n            The second input shape must be ``[N, 1, 4, 1, 1]`` or ``[N, 1, 5, 1, 1]``. This represents the bounding box coordinates for N patches/RoIs.\n            N: number of patches/RoIs to be extracted\n            If RoI shape = [N, 1, 4, 1, 1]\n                    The channel axis corresponds to the four coordinates specifying the bounding box.\n                    All the N RoIs are extracted from all the batches of the input.\n            If RoI shape = [N, 1, 5, 1, 1]\n                    The first element of the channel axis specifies the input batch id from which to extract the RoI and\n\t\t\t\t\tmust be in the interval ``[0, Batch - 1]``. That is, n-th RoI is extracted from the RoI[n,0,0,0]-th input batch id.\n                    The last four elements of the channel axis specify the bounding box coordinates.\n        output_name: str\n            The output blob name of this layer.\n        target_height: int\n            Output height dimension.\n        target_width: int\n            Output width dimension.\n        mode: str\n            Following values are supported: 'STRICT_ALIGN_ENDPOINTS_MODE', 'ALIGN_ENDPOINTS_MODE', 'UPSAMPLE_MODE', 'ROI_ALIGN_MODE'.\n            This parameter determines the sampling grid used for bilinear interpolation. Kindly refer to NeuralNetwork.proto for details.\n        normalized_roi: bool\n            If true the bounding box coordinates must be in the interval [0, 1].\n\t        They are scaled by (input_height - 1), (input_width - 1), i.e. based on the input spatial dimensions.\n\t        If false the bounding box coordinates must be in the interval\n\t        [0, input_height - 1] and [0, input_width - 1], respectively for height and width dimensions.\n\t    box_indices_mode: str\n\t        Following values are supported: 'CORNERS_HEIGHT_FIRST', 'CORNERS_WIDTH_FIRST', 'CENTER_SIZE_HEIGHT_FIRST', 'CENTER_SIZE_WIDTH_FIRST'\n\t        Representation used to interpret the bounding box coordinates (RoI) input. Kindly refer to NeuralNetwork.proto for details.\n\t        'CORNERS_HEIGHT_FIRST': [h_start, w_start, h_end, w_end]\n\t        'CORNERS_WIDTH_FIRST': [w_start, h_start, w_end, h_end]\n\t        'CENTER_SIZE_HEIGHT_FIRST': [h_center, w_center, box_height, box_width]\n            'CENTER_SIZE_WIDTH_FIRST': [w_center, h_center, box_width, box_height]\n        spatial_scale: float\n            Additional spatial scale that multiplies the bounding box coordinates.\n            Generally used while implementing the RoI Align layer,\n            which uses unnormalized RoI coordinates along with a spatial scale less than or equal to 1.\n\n\n        See Also\n        --------\n        add_resize_bilinear, add_crop\n        \"\"\"\n        spec = self.spec\n        nn_spec = self.nn_spec\n\n        # Add a new inner-product layer\n        spec_layer = nn_spec.layers.add()\n        spec_layer.name = name\n        if len(input_names) != 2:\n            raise ValueError(\"crop resize layer must have exactly two inputs\")\n        for input_name in input_names:\n            spec_layer.input.append(input_name)\n        spec_layer.output.append(output_name)\n        spec_layer_params = spec_layer.cropResize\n        spec_layer_params.targetSize.append(target_height)\n        spec_layer_params.targetSize.append(target_width)\n        spec_layer_params.normalizedCoordinates = normalized_roi\n        spec_layer_params.spatialScale = spatial_scale\n        if mode == 'ALIGN_ENDPOINTS_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('ALIGN_ENDPOINTS_MODE')\n        elif mode == 'STRICT_ALIGN_ENDPOINTS_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('STRICT_ALIGN_ENDPOINTS_MODE')\n        elif mode == 'UPSAMPLE_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('UPSAMPLE_MODE')\n        elif mode == 'ROI_ALIGN_MODE':\n            spec_layer_params.mode.samplingMethod = _NeuralNetwork_pb2.SamplingMode.Method.Value('ROI_ALIGN_MODE')\n        else:\n            raise ValueError(\"Unuspported crop resize mode %s\" % mode)\n\n        if box_indices_mode == 'CORNERS_HEIGHT_FIRST':\n            spec_layer_params.boxIndicesMode.boxMode = _NeuralNetwork_pb2.BoxCoordinatesMode.Coordinates.Value('CORNERS_HEIGHT_FIRST')\n        elif box_indices_mode == 'CORNERS_WIDTH_FIRST':\n            spec_layer_params.boxIndicesMode.boxMode = _NeuralNetwork_pb2.BoxCoordinatesMode.Coordinates.Value('CORNERS_WIDTH_FIRST')\n        elif box_indices_mode == 'CENTER_SIZE_HEIGHT_FIRST':\n            spec_layer_params.boxIndicesMode.boxMode = _NeuralNetwork_pb2.BoxCoordinatesMode.Coordinates.Value('CENTER_SIZE_HEIGHT_FIRST')\n        elif box_indices_mode == 'CENTER_SIZE_WIDTH_FIRST':\n            spec_layer_params.boxIndicesMode.boxMode = _NeuralNetwork_pb2.BoxCoordinatesMode.Coordinates.Value('CENTER_SIZE_WIDTH_FIRST')\n        else:\n            raise ValueError(\"Unsupported crop resize box indices mode %s\" % box_indices_mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _toolkit_serialize_summary_struct(model, sections, section_titles):\n    output_dict = dict()\n    output_dict['sections'] = [ [ ( field[0], __extract_model_summary_value(model, field[1]) ) \\\n                                                                            for field in section ]\n                                                                            for section in sections ]\n    output_dict['section_titles'] = section_titles\n    return output_dict", "response": "Serialize model summary into a dict with ordered lists of sections and section titles"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_docstring(format_dict):\n    def add_docstring_context(func):\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.__doc__ = func.__doc__.format(**format_dict)\n        return wrapper\n    return add_docstring_context", "response": "Add a docstring to the module that will format the doc - strings on the fly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_only_column_of_type(sframe, target_type, type_name, col_name):\n    image_column_name = None\n    if type(target_type) != list:\n        target_type = [target_type]\n    for name, ctype in zip(sframe.column_names(), sframe.column_types()):\n        if ctype in target_type:\n            if image_column_name is not None:\n                raise ToolkitError('No \"{col_name}\" column specified and more than one {type_name} column in \"dataset\". Can not infer correct {col_name} column.'.format(col_name=col_name, type_name=type_name))\n            image_column_name = name\n    if image_column_name is None:\n        raise ToolkitError('No %s column in \"dataset\".' % type_name)\n    return image_column_name", "response": "Find the only column in SFrame with a type specified by target_type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the only column in sframe with a type of Image.", "response": "def _find_only_image_column(sframe):\n    \"\"\"\n    Finds the only column in `sframe` with a type of turicreate.Image. \n    If there are zero or more than one image columns, an exception will \n    be raised.\n    \"\"\"\n    from turicreate import Image\n    return _find_only_column_of_type(sframe, target_type=Image,\n                                     type_name='image', col_name='feature')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the only column that can be interpreted as a drawing feature column.", "response": "def _find_only_drawing_column(sframe):\n    \"\"\"\n    Finds the only column that can be interpreted as a drawing feature column.\n    A drawing column can be a stroke-based drawing column (with dtype list)\n    or a bitmap-based drawing column (with dtype turicreate.Image)\n    \n    If there are zero or more than one drawing columns, an exception will be\n    raised.\n    \"\"\"\n    from turicreate import Image\n    bitmap_success, stroke_success = False, False\n    bitmap_error, stroke_error = None, None\n    feature = None\n    try:\n        feature = _find_only_column_of_type(sframe, \n            target_type=Image, type_name='drawing', col_name='feature')\n        bitmap_success = True\n    except ToolkitError as err_from_bitmap_search:\n        bitmap_error = err_from_bitmap_search\n    \n    try:\n        feature = _find_only_column_of_type(sframe, \n            target_type=list, type_name='drawing', col_name='feature')\n        stroke_success = True\n    except ToolkitError as err_from_stroke_search:\n        stroke_error = err_from_stroke_search\n\n    more_than_one_image_columns = (\"more than one\" in str(bitmap_error) \n        if not bitmap_success else False)\n    more_than_one_stroke_columns = (\"more than one\" in str(stroke_error) \n        if not stroke_success else False)\n\n    corrective_action_for_user = (\"\\nThe feature column must contain either \" \n        + \"bitmap-based drawings or stroke-based drawings but not both.\\n\" \n        + \"Bitmap-based drawing input must be a grayscale \"\n        + \"tc.Image of any size.\\n\"\n        + \"Stroke-based drawing input must be in the following format:\\n\"\n        + \"Every drawing must be represented by a list of strokes, where each \"\n        + \"stroke must be a list of points in the order in which they were \"\n        + \"drawn on the canvas. \"\n        + \"Every point must be a dictionary with two keys, 'x' and 'y', and \" \n        + \"their respective values must be numerical, \" \n        + \"i.e. either integer or float.\")\n\n    error_message = (lambda num1, type1, input1, num2, type2, input2:\n            ((\"No 'feature' column specified. Found {num1} column with type \" \n            + \"{type1} (for {input1}-based drawing input) and \" \n            + \"{num2} column with type {type2} (for {input2}-based drawing \" \n            + \"input) in 'input_dataset'. \" \n            + \"Can not infer correct 'feature' column.\").format(\n                num1=num1, input1=input1, type1=type1,\n                num2=num2, input2=input2, type2=type2)\n            )\n        )\n\n    if (bitmap_success ^ stroke_success \n        and not more_than_one_image_columns \n        and not more_than_one_stroke_columns):\n        # success! \n        # found exactly one of bitmap-based drawing column and\n        # stroke-based drawing column, and found none of the other.\n        return feature\n    elif bitmap_success and stroke_success:\n        raise ToolkitError(error_message(\n                \"one\", \"turicreate.Image\", \"bitmap\", \"one\", \"list\", \"stroke\") \n            + corrective_action_for_user)\n    else:\n        if more_than_one_image_columns and more_than_one_stroke_columns:\n            raise ToolkitError(error_message(\n                \"more than one\", \"turicreate.Image\", \"bitmap\", \n                \"more than one\", \"list\", \"stroke\") \n                + corrective_action_for_user)\n        elif more_than_one_image_columns and not more_than_one_stroke_columns:\n            raise ToolkitError(error_message(\n                \"more than one\", \"turicreate.Image\", \"bitmap\", \n                \"no\", \"list\", \"stroke\") \n                + corrective_action_for_user)\n        elif not more_than_one_image_columns and more_than_one_stroke_columns:\n            raise ToolkitError(error_message(\n                \"more than one\", \"list\", \"stroke\",\n                \"no\", \"turicreate.Image\", \"bitmap\")\n                + corrective_action_for_user)\n        else:\n            raise ToolkitError(error_message(\n                \"no\", \"list\", \"stroke\", \n                \"no\", \"turicreate.Image\", \"bitmap\")\n                + corrective_action_for_user)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _SGraphFromJsonTree(json_str):\n    g = json.loads(json_str)\n    vertices = [_Vertex(x['id'],\n                dict([(str(k), v) for k, v in _six.iteritems(x) if k != 'id']))\n                                                      for x in g['vertices']]\n    edges = [_Edge(x['src'], x['dst'],\n             dict([(str(k), v) for k, v in _six.iteritems(x) if k != 'src' and k != 'dst']))\n                                                      for x in g['edges']]\n    sg = _SGraph().add_vertices(vertices)\n    if len(edges) > 0:\n        sg = sg.add_edges(edges)\n    return sg", "response": "Convert the Json Tree to SGraph\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _summarize_coefficients(top_coefs, bottom_coefs):\n\n    def get_row_name(row):\n        if row['index'] is None:\n            return row['name']\n        else:\n            return \"%s[%s]\" % (row['name'], row['index'])\n\n    if len(top_coefs) == 0:\n        top_coefs_list = [('No Positive Coefficients', _precomputed_field('') )]\n    else:\n        top_coefs_list = [ (get_row_name(row),\n                            _precomputed_field(row['value'])) \\\n                            for row in top_coefs ]\n\n    if len(bottom_coefs) == 0:\n        bottom_coefs_list = [('No Negative Coefficients', _precomputed_field(''))]\n    else:\n        bottom_coefs_list = [ (get_row_name(row),\n                            _precomputed_field(row['value'])) \\\n                            for row in bottom_coefs ]\n\n    return ([top_coefs_list, bottom_coefs_list], \\\n                    [ 'Highest Positive Coefficients', 'Lowest Negative Coefficients'] )", "response": "Return a tuple of sections and section titles for top and bottom k coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tuple of the top k values from the positive and negative values in a SArray", "response": "def _toolkit_get_topk_bottomk(values, k=5):\n    \"\"\"\n    Returns a tuple of the top k values from the positive and\n    negative values in a SArray\n\n    Parameters\n    ----------\n    values : SFrame of model coefficients\n\n    k: Maximum number of largest positive and k lowest negative numbers to return\n\n    Returns\n    -------\n    (topk_positive, bottomk_positive) : tuple\n            topk_positive : list\n                floats that represent the top 'k' ( or less ) positive\n                values\n            bottomk_positive : list\n                floats that represent the top 'k' ( or less ) negative\n                values\n    \"\"\"\n\n    top_values = values.topk('value', k=k)\n    top_values = top_values[top_values['value'] > 0]\n\n    bottom_values = values.topk('value', k=k, reverse=True)\n    bottom_values = bottom_values[bottom_values['value'] < 0]\n\n    return (top_values, bottom_values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts a model summary field value from a value.", "response": "def __extract_model_summary_value(model, value):\n    \"\"\"\n    Extract a model summary field value\n    \"\"\"\n    field_value = None\n    if isinstance(value, _precomputed_field):\n        field_value = value.field\n    else:\n        field_value = model._get(value)\n    if isinstance(field_value, float):\n        try:\n            field_value = round(field_value, 4)\n        except:\n            pass\n    return field_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nserialize an SFrame to a list of strings that when printed creates a well - formatted table.", "response": "def _make_repr_table_from_sframe(X):\n    \"\"\"\n    Serializes an SFrame to a list of strings, that, when printed, creates a well-formatted table.\n    \"\"\"\n\n    assert isinstance(X, _SFrame)\n\n    column_names = X.column_names()\n\n    out_data = [ [None]*len(column_names) for i in range(X.num_rows())]\n\n    column_sizes = [len(s) for s in column_names]\n\n    for i, c in enumerate(column_names):\n        for j, e in enumerate(X[c]):\n            out_data[j][i] = str(e)\n            column_sizes[i] = max(column_sizes[i], len(e))\n\n    # now, go through and pad everything.\n    out_data = ([ [cn.ljust(k, ' ') for cn, k in zip(column_names, column_sizes)],\n                  [\"-\"*k for k in column_sizes] ]\n                + [ [e.ljust(k, ' ') for e, k in zip(row, column_sizes)] for row in out_data] )\n\n    return ['  '.join(row) for row in out_data]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _toolkit_repr_print(model, fields, section_titles, width = None):\n\n    assert len(section_titles) == len(fields), \\\n        \"The number of section titles ({0}) \".format(len(section_titles)) +\\\n        \"doesn't match the number of groups of fields, {0}.\".format(len(fields))\n\n    out_fields = [ (\"Class\", model.__class__.__name__), \"\"]\n\n    # Record the max_width so that if width is not provided, we calculate it.\n    max_width = len(\"Class\")\n\n    for index, (section_title, field_list) in enumerate(zip(section_titles, fields)):\n\n        # Add in the section header.\n        out_fields += [section_title, \"-\"*len(section_title)]\n\n        # Add in all the key-value pairs\n        for f in field_list:\n            if isinstance(f, tuple):\n                f = (str(f[0]), f[1])\n                out_fields.append( (f[0], __extract_model_summary_value(model, f[1])) )\n                max_width = max(max_width, len(f[0]))\n            elif isinstance(f, _SFrame):\n                out_fields.append(\"\")\n                out_fields += _make_repr_table_from_sframe(f)\n                out_fields.append(\"\")\n            else:\n                raise TypeError(\"Type of field %s not recognized.\" % str(f))\n\n        # Add in the empty footer.\n        out_fields.append(\"\")\n\n    if width is None:\n        width = max_width\n\n    # Now, go through and format the key_value pairs nicely.\n    def format_key_pair(key, value):\n        if type(key) is list:\n            key = ','.join(str(k) for k in key)\n\n        return key.ljust(width, ' ') + ' : ' + str(value)\n    out_fields = [s if type(s) is str else format_key_pair(*s) for s in out_fields]\n\n    return '\\n'.join(out_fields)", "response": "Display a toolkit repr according to some simple rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _map_unity_proxy_to_object(value):\n    vtype = type(value)\n    if vtype in _proxy_map:\n        return _proxy_map[vtype](value)\n    elif vtype == list:\n        return [_map_unity_proxy_to_object(v) for v in value]\n    elif vtype == dict:\n        return {k:_map_unity_proxy_to_object(v) for k,v in value.items()}\n    else:\n        return value", "response": "Map unity proxy to object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _toolkits_select_columns(dataset, columns):\n    try:\n        return dataset.select_columns(columns)\n    except RuntimeError:\n        missing_features = list(set(columns).difference(set(dataset.column_names())))\n        raise ToolkitError(\"Input data does not contain the following columns: \"  +\n                \"{}\".format(missing_features))", "response": "Same as select columns but redirect runtime error to ToolkitError."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _raise_error_if_column_exists(dataset, column_name = 'dataset',\n                            dataset_variable_name = 'dataset',\n                            column_name_error_message_name = 'column_name'):\n    \"\"\"\n    Check if a column exists in an SFrame with error message.\n    \"\"\"\n    err_msg = 'The SFrame {0} must contain the column {1}.'.format(\n                                                dataset_variable_name,\n                                             column_name_error_message_name)\n    if column_name not in dataset.column_names():\n      raise ToolkitError(str(err_msg))", "response": "Check if a column exists in an SFrame with error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_categorical_option_type(option_name, option_value, possible_values):\n    err_msg = '{0} is not a valid option for {1}. '.format(option_value, option_name)\n    err_msg += ' Expected one of: '.format(possible_values)\n\n    err_msg += ', '.join(map(str, possible_values))\n    if option_value not in possible_values:\n        raise ToolkitError(err_msg)", "response": "Checks whether or not the requested option is one of the allowed values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _raise_error_if_not_sarray(dataset, variable_name=\"SArray\"):\n    err_msg = \"Input %s is not an SArray.\"\n    if not isinstance(dataset, _SArray):\n      raise ToolkitError(err_msg % variable_name)", "response": "Check if the input is an SArray. Provide a proper error\n    message otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the input is an SFrame. Provide a proper error message otherwise.", "response": "def _raise_error_if_not_sframe(dataset, variable_name=\"SFrame\"):\n    \"\"\"\n    Check if the input is an SFrame. Provide a proper error\n    message otherwise.\n    \"\"\"\n    err_msg = \"Input %s is not an SFrame. If it is a Pandas DataFrame,\"\n    err_msg += \" you may use the to_sframe() function to convert it to an SFrame.\"\n\n    if not isinstance(dataset, _SFrame):\n      raise ToolkitError(err_msg % variable_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the input is empty.", "response": "def _raise_error_if_sframe_empty(dataset, variable_name=\"SFrame\"):\n    \"\"\"\n    Check if the input is empty.\n    \"\"\"\n    err_msg = \"Input %s either has no rows or no columns. A non-empty SFrame \"\n    err_msg += \"is required.\"\n\n    if dataset.num_rows() == 0 or dataset.num_columns() == 0:\n        raise ToolkitError(err_msg % variable_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the input is an SFrame and if the metric is not in allowed_metrics raise an error otherwise.", "response": "def _raise_error_evaluation_metric_is_valid(metric, allowed_metrics):\n    \"\"\"\n    Check if the input is an SFrame. Provide a proper error\n    message otherwise.\n    \"\"\"\n\n    err_msg = \"Evaluation metric '%s' not recognized. The supported evaluation\"\n    err_msg += \" metrics are (%s).\"\n\n    if metric not in allowed_metrics:\n      raise ToolkitError(err_msg % (metric,\n                          ', '.join(map(lambda x: \"'%s'\" % x, allowed_metrics))))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if numeric parameter is within given range", "response": "def _numeric_param_check_range(variable_name, variable_value, range_bottom, range_top):\n    \"\"\"\n    Checks if numeric parameter is within given range\n    \"\"\"\n    err_msg = \"%s must be between %i and %i\"\n\n    if variable_value < range_bottom or variable_value > range_top:\n        raise ToolkitError(err_msg % (variable_name, range_bottom, range_top))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_data(dataset, target, features=None, validation_set='auto'):\n\n    _raise_error_if_not_sframe(dataset, \"training dataset\")\n\n    # Determine columns to keep\n    if features is None:\n        features = [feat for feat in dataset.column_names() if feat != target]\n    if not hasattr(features, '__iter__'):\n        raise TypeError(\"Input 'features' must be a list.\")\n    if not all([isinstance(x, str) for x in features]):\n        raise TypeError(\n            \"Invalid feature %s: Feature names must be of type str\" % x)\n\n    # Check validation_set argument\n    if isinstance(validation_set, str):\n        # Only string value allowed is 'auto'\n        if validation_set != 'auto':\n            raise TypeError('Unrecognized value for validation_set.')\n    elif isinstance(validation_set, _SFrame):\n        # Attempt to append the two datasets together to check schema\n        validation_set.head().append(dataset.head())\n\n        # Reduce validation set to requested columns\n        validation_set = _toolkits_select_columns(\n            validation_set, features + [target])\n    elif not validation_set is None:\n        raise TypeError(\"validation_set must be either 'auto', None, or an \"\n                        \"SFrame matching the training data.\")\n\n    # Reduce training set to requested columns\n    dataset = _toolkits_select_columns(dataset, features + [target])\n\n    return dataset, validation_set", "response": "Validate and canonicalize training and validation data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating a row label column.", "response": "def _validate_row_label(dataset, label=None, default_label='__id'):\n    \"\"\"\n    Validate a row label column. If the row label is not specified, a column is\n    created with row numbers, named with the string in the `default_label`\n    parameter.\n\n    Parameters\n    ----------\n    dataset : SFrame\n        Input dataset.\n\n    label : str, optional\n        Name of the column containing row labels.\n\n    default_label : str, optional\n        The default column name if `label` is not specified. A column with row\n        numbers is added to the output SFrame in this case.\n\n    Returns\n    -------\n    dataset : SFrame\n        The input dataset, but with an additional row label column, *if* there\n        was no input label.\n\n    label : str\n        The final label column name.\n    \"\"\"\n    ## If no label is provided, set it to be a default and add a row number to\n    #  dataset. Check that this new name does not conflict with an existing\n    #  name.\n    if not label:\n\n        ## Try a bunch of variations of the default label to find one that's not\n        #  already a column name.\n        label_name_base = default_label\n        label = default_label\n        i = 1\n\n        while label in dataset.column_names():\n            label = label_name_base + '.{}'.format(i)\n            i += 1\n\n        dataset = dataset.add_row_number(column_name=label)\n\n    ## Validate the label name and types.\n    if not isinstance(label, str):\n        raise TypeError(\"The row label column name '{}' must be a string.\".format(label))\n\n    if not label in dataset.column_names():\n        raise ToolkitError(\"Row label column '{}' not found in the dataset.\".format(label))\n\n    if not dataset[label].dtype in (str, int):\n        raise TypeError(\"Row labels must be integers or strings.\")\n\n    ## Return the modified dataset and label\n    return dataset, label"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning Mac version as a tuple of integers. On Macs it returns an empty tuple. On non - Macs it returns an empty tuple.", "response": "def _mac_ver():\n    \"\"\"\n    Returns Mac version as a tuple of integers, making it easy to do proper\n    version comparisons. On non-Macs, it returns an empty tuple.\n    \"\"\"\n    import platform\n    import sys\n    if sys.platform == 'darwin':\n        ver_str = platform.mac_ver()[0]\n        return tuple([int(v) for v in ver_str.split('.')])\n    else:\n        return ()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _print_neural_compute_device(cuda_gpus, use_mps, cuda_mem_req=None, has_mps_impl=True):\n    num_cuda_gpus = len(cuda_gpus)\n    if num_cuda_gpus >= 1:\n        gpu_names = ', '.join(gpu['name'] for gpu in cuda_gpus)\n\n    if use_mps:\n        from ._mps_utils import mps_device_name\n        print('Using GPU to create model ({})'.format(mps_device_name()))\n    elif num_cuda_gpus >= 1:\n        from . import _mxnet_utils\n        plural = 's' if num_cuda_gpus >= 2 else ''\n        print('Using GPU{} to create model ({})'.format(plural, gpu_names))\n        if cuda_mem_req is not None:\n            _mxnet_utils._warn_if_less_than_cuda_free_memory(cuda_mem_req, max_devices=num_cuda_gpus)\n    else:\n        import sys\n        print('Using CPU to create model')\n        if sys.platform == 'darwin' and _mac_ver() < (10, 14) and has_mps_impl:\n            print('NOTE: If available, an AMD GPU can be leveraged on macOS 10.14+ for faster model creation')", "response": "Print a message making it clear to the user what compute resource is used in the neural network training."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a proto class from a MessageFactory by full_name.", "response": "def _GetMessageFromFactory(factory, full_name):\n  \"\"\"Get a proto class from the MessageFactory by name.\n\n  Args:\n    factory: a MessageFactory instance.\n    full_name: str, the fully qualified name of the proto type.\n  Returns:\n    A class, for the type identified by full_name.\n  Raises:\n    KeyError, if the proto is not found in the factory's descriptor pool.\n  \"\"\"\n  proto_descriptor = factory.pool.FindMessageTypeByName(full_name)\n  proto_cls = factory.GetPrototype(proto_descriptor)\n  return proto_cls"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Protobuf class whose fields are basic types.", "response": "def MakeSimpleProtoClass(fields, full_name=None, pool=None):\n  \"\"\"Create a Protobuf class whose fields are basic types.\n\n  Note: this doesn't validate field names!\n\n  Args:\n    fields: dict of {name: field_type} mappings for each field in the proto. If\n        this is an OrderedDict the order will be maintained, otherwise the\n        fields will be sorted by name.\n    full_name: optional str, the fully-qualified name of the proto type.\n    pool: optional DescriptorPool instance.\n  Returns:\n    a class, the new protobuf class with a FileDescriptor.\n  \"\"\"\n  factory = message_factory.MessageFactory(pool=pool)\n\n  if full_name is not None:\n    try:\n      proto_cls = _GetMessageFromFactory(factory, full_name)\n      return proto_cls\n    except KeyError:\n      # The factory's DescriptorPool doesn't know about this class yet.\n      pass\n\n  # Get a list of (name, field_type) tuples from the fields dict. If fields was\n  # an OrderedDict we keep the order, but otherwise we sort the field to ensure\n  # consistent ordering.\n  field_items = fields.items()\n  if not isinstance(fields, OrderedDict):\n    field_items = sorted(field_items)\n\n  # Use a consistent file name that is unlikely to conflict with any imported\n  # proto files.\n  fields_hash = hashlib.sha1()\n  for f_name, f_type in field_items:\n    fields_hash.update(f_name.encode('utf-8'))\n    fields_hash.update(str(f_type).encode('utf-8'))\n  proto_file_name = fields_hash.hexdigest() + '.proto'\n\n  # If the proto is anonymous, use the same hash to name it.\n  if full_name is None:\n    full_name = ('net.proto2.python.public.proto_builder.AnonymousProto_' +\n                 fields_hash.hexdigest())\n    try:\n      proto_cls = _GetMessageFromFactory(factory, full_name)\n      return proto_cls\n    except KeyError:\n      # The factory's DescriptorPool doesn't know about this class yet.\n      pass\n\n  # This is the first time we see this proto: add a new descriptor to the pool.\n  factory.pool.Add(\n      _MakeFileDescriptorProto(proto_file_name, full_name, field_items))\n  return _GetMessageFromFactory(factory, full_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _MakeFileDescriptorProto(proto_file_name, full_name, field_items):\n  package, name = full_name.rsplit('.', 1)\n  file_proto = descriptor_pb2.FileDescriptorProto()\n  file_proto.name = os.path.join(package.replace('.', '/'), proto_file_name)\n  file_proto.package = package\n  desc_proto = file_proto.message_type.add()\n  desc_proto.name = name\n  for f_number, (f_name, f_type) in enumerate(field_items, 1):\n    field_proto = desc_proto.field.add()\n    field_proto.name = f_name\n    field_proto.number = f_number\n    field_proto.label = descriptor_pb2.FieldDescriptorProto.LABEL_OPTIONAL\n    field_proto.type = f_type\n  return file_proto", "response": "Populate FileDescriptorProto for MessageFactory s DescriptorPool."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a decision tree model to protobuf format.", "response": "def convert(model, input_name, output_features):\n    \"\"\"Convert a decision tree model to protobuf format.\n\n    Parameters\n    ----------\n    decision_tree : DecisionTreeClassifier\n        A trained scikit-learn tree model.\n\n    input_name: str\n        Name of the input columns.\n\n    output_name: str\n        Name of the output columns.\n\n    Returns\n    -------\n    model_spec: An object of type Model_pb.\n        Protobuf representation of the model\n    \"\"\"\n    if not(HAS_SKLEARN):\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n\n    _sklearn_util.check_expected_type(model, _tree.DecisionTreeClassifier)\n    _sklearn_util.check_fitted(model, lambda m: hasattr(m, 'tree_') and model.tree_ is not None)\n\n    return _MLModel(convert_tree_ensemble(model, input_name, output_features,\n            mode = 'classifier',\n            class_labels = model.classes_))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_model_metadata(model_class, metadata, version=None):\n    from turicreate import __version__\n    info = {\n        'turicreate_version': __version__,\n        'type': model_class,\n    }\n    if version is not None:\n        info['version'] = str(version)\n    info.update(metadata)\n    return info", "response": "Returns user - defined metadata for a given model class and metadata dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_model_metadata(mlmodel, model_class, metadata, version=None):\n    info = _get_model_metadata(model_class, metadata, version)\n    mlmodel.user_defined_metadata.update(info)", "response": "Sets user - defined metadata for the given model class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ToCamelCase(name):\n  capitalize_next = False\n  result = []\n\n  for c in name:\n    if c == '_':\n      if result:\n        capitalize_next = True\n    elif capitalize_next:\n      result.append(c.upper())\n      capitalize_next = False\n    else:\n      result += c\n\n  # Lower-case the first letter.\n  if result and result[0].isupper():\n    result[0] = result[0].lower()\n  return ''.join(result)", "response": "Converts a name to camel - case and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert name to Json name and returns it.", "response": "def _ToJsonName(name):\n  \"\"\"Converts name to Json name and returns it.\"\"\"\n  capitalize_next = False\n  result = []\n\n  for c in name:\n    if c == '_':\n      capitalize_next = True\n    elif capitalize_next:\n      result.append(c.upper())\n      capitalize_next = False\n    else:\n      result += c\n\n  return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the descriptor s options and options_class_name.", "response": "def _SetOptions(self, options, options_class_name):\n    \"\"\"Sets the descriptor's options\n\n    This function is used in generated proto2 files to update descriptor\n    options. It must not be used outside proto2.\n    \"\"\"\n    self._options = options\n    self._options_class_name = options_class_name\n\n    # Does this descriptor have non-default options?\n    self.has_options = options is not None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the options for the descriptor.", "response": "def GetOptions(self):\n    \"\"\"Retrieves descriptor options.\n\n    This method returns the options set or creates the default options for the\n    descriptor.\n    \"\"\"\n    if self._options:\n      return self._options\n    from google.protobuf import descriptor_pb2\n    try:\n      options_class = getattr(descriptor_pb2, self._options_class_name)\n    except AttributeError:\n      raise RuntimeError('Unknown options class name %s!' %\n                         (self._options_class_name))\n    self._options = options_class()\n    return self._options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying this to the matching proto in descriptor_pb2.", "response": "def CopyToProto(self, proto):\n    \"\"\"Copies this to the matching proto in descriptor_pb2.\n\n    Args:\n      proto: An empty proto instance from descriptor_pb2.\n\n    Raises:\n      Error: If self couldnt be serialized, due to to few constructor arguments.\n    \"\"\"\n    if (self.file is not None and\n        self._serialized_start is not None and\n        self._serialized_end is not None):\n      proto.ParseFromString(self.file.serialized_pb[\n          self._serialized_start:self._serialized_end])\n    else:\n      raise Error('Descriptor does not contain serialization.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the string name of an enum value.", "response": "def EnumValueName(self, enum, value):\n    \"\"\"Returns the string name of an enum value.\n\n    This is just a small helper method to simplify a common operation.\n\n    Args:\n      enum: string name of the Enum.\n      value: int, value of the enum.\n\n    Returns:\n      string name of the enum value.\n\n    Raises:\n      KeyError if either the Enum doesn't exist or the value is not a valid\n        value for the enum.\n    \"\"\"\n    return self.enum_types_by_name[enum].values_by_number[value].name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_reference(target_reference, project):\n    # Separate target name from properties override\n    assert isinstance(target_reference, basestring)\n    assert isinstance(project, ProjectTarget)\n    split = _re_separate_target_from_properties.match (target_reference)\n    if not split:\n        raise BaseException (\"Invalid reference: '%s'\" % target_reference)\n\n    id = split.group (1)\n\n    sproperties = []\n\n    if split.group (3):\n        sproperties = property.create_from_strings(feature.split(split.group(3)))\n        sproperties = feature.expand_composites(sproperties)\n\n    # Find the target\n    target = project.find (id)\n\n    return (target, property_set.create(sproperties))", "response": "Given a target_reference made in context of project returns the AbstractTarget instance that is referred to by the project."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a virtual target given by a target reference.", "response": "def generate_from_reference(target_reference, project, property_set_):\n    \"\"\" Attempts to generate the target given by target reference, which\n    can refer both to a main target or to a file.\n    Returns a list consisting of\n    - usage requirements\n    - generated virtual targets, if any\n    target_reference:  Target reference\n    project:           Project where the reference is made\n    property_set:      Properties of the main target that makes the reference\n    \"\"\"\n    assert isinstance(target_reference, basestring)\n    assert isinstance(project, ProjectTarget)\n    assert isinstance(property_set_, property_set.PropertySet)\n    target, sproperties = resolve_reference(target_reference, project)\n\n    # Take properties which should be propagated and refine them\n    # with source-specific requirements.\n    propagated = property_set_.propagated()\n    rproperties = propagated.refine(sproperties)\n\n    return target.generate(rproperties)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main_target_alternative (self, target):\n        assert isinstance(target, AbstractTarget)\n        target.project ().add_alternative (target)\n        return target", "response": "Registers the specified target as a main target alternative."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of sources to use if main target rule is invoked with sources.", "response": "def main_target_sources (self, sources, main_target_name, no_renaming=0):\n        \"\"\"Return the list of sources to use, if main target rule is invoked\n        with 'sources'. If there are any objects in 'sources', they are treated\n        as main target instances, and the name of such targets are adjusted to\n        be '<name_of_this_target>__<name_of_source_target>'. Such renaming\n        is disabled is non-empty value is passed for 'no-renaming' parameter.\"\"\"\n        assert is_iterable_typed(sources, basestring)\n        assert isinstance(main_target_name, basestring)\n        assert isinstance(no_renaming, (int, bool))\n        result = []\n\n        for t in sources:\n\n            t = b2.util.jam_to_value_maybe(t)\n\n            if isinstance (t, AbstractTarget):\n                name = t.name ()\n\n                if not no_renaming:\n                    name = main_target_name + '__' + name\n                    t.rename (name)\n\n                # Inline targets are not built by default.\n                p = t.project()\n                p.mark_targets_as_explicit([name])\n                result.append(name)\n\n            else:\n                result.append (t)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main_target_requirements(self, specification, project):\n        assert is_iterable_typed(specification, basestring)\n        assert isinstance(project, ProjectTarget)\n        # create a copy since the list is being modified\n        specification = list(specification)\n        specification.extend(toolset.requirements())\n\n        requirements = property_set.refine_from_user_input(\n            project.get(\"requirements\"), specification,\n            project.project_module(), project.get(\"location\"))\n\n        return requirements", "response": "Returns the list of requirements to use when declaring a main target"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main_target_usage_requirements (self, specification, project):\n        assert is_iterable_typed(specification, basestring)\n        assert isinstance(project, ProjectTarget)\n        project_usage_requirements = project.get ('usage-requirements')\n\n        # We don't use 'refine-from-user-input' because I'm not sure if:\n        # - removing of parent's usage requirements makes sense\n        # - refining of usage requirements is not needed, since usage requirements\n        #   are always free.\n        usage_requirements = property_set.create_from_user_input(\n            specification, project.project_module(), project.get(\"location\"))\n\n        return project_usage_requirements.add (usage_requirements)", "response": "Returns the set of usage requirements that are used when declaraing a main target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the default build value to use when declaring a main target", "response": "def main_target_default_build (self, specification, project):\n        \"\"\" Return the default build value to use when declaring a main target,\n            which is obtained by using specified value if not empty and parent's\n            default build attribute otherwise.\n            specification:  Default build explicitly specified for a main target\n            project:        Project where the main target is to be declared\n        \"\"\"\n        assert is_iterable_typed(specification, basestring)\n        assert isinstance(project, ProjectTarget)\n        if specification:\n            return property_set.create_with_validation(specification)\n        else:\n            return project.get ('default-build')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting building the main target.", "response": "def start_building (self, main_target_instance):\n        \"\"\" Helper rules to detect cycles in main target references.\n        \"\"\"\n        assert isinstance(main_target_instance, MainTarget)\n        if id(main_target_instance) in self.targets_being_built_:\n            names = []\n            for t in self.targets_being_built_.values() + [main_target_instance]:\n                names.append (t.full_name())\n\n            get_manager().errors()(\"Recursion in main target references\\n\")\n\n        self.targets_being_built_[id(main_target_instance)] = main_target_instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_typed_target (self, type, project, name, sources, requirements, default_build, usage_requirements):\n        assert isinstance(type, basestring)\n        assert isinstance(project, ProjectTarget)\n        assert is_iterable_typed(sources, basestring)\n        assert is_iterable_typed(requirements, basestring)\n        assert is_iterable_typed(default_build, basestring)\n        return self.main_target_alternative (TypedTarget (name, project, type,\n            self.main_target_sources (sources, name),\n            self.main_target_requirements (requirements, project),\n            self.main_target_default_build (default_build, project),\n            self.main_target_usage_requirements (usage_requirements, project)))", "response": "Creates a TypedTarget with the specified properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates all possible targets contained in this project.", "response": "def generate (self, ps):\n        \"\"\" Generates all possible targets contained in this project.\n        \"\"\"\n        assert isinstance(ps, property_set.PropertySet)\n        self.manager_.targets().log(\n            \"Building project '%s' with '%s'\" % (self.name (), str(ps)))\n        self.manager_.targets().increase_indent ()\n\n        result = GenerateResult ()\n\n        for t in self.targets_to_build ():\n            g = t.generate (ps)\n            result.extend (g)\n\n        self.manager_.targets().decrease_indent ()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef targets_to_build (self):\n        result = []\n\n        if not self.built_main_targets_:\n            self.build_main_targets ()\n\n        # Collect all main targets here, except for \"explicit\" ones.\n        for n, t  in self.main_target_.iteritems ():\n            if not t.name () in self.explicit_targets_:\n                result.append (t)\n\n        # Collect all projects referenced via \"projects-to-build\" attribute.\n        self_location = self.get ('location')\n        for pn in self.get ('projects-to-build'):\n            result.append (self.find(pn + \"/\"))\n\n        return result", "response": "Computes and returns a list of AbstractTarget instances which can be built when this project is built."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mark_targets_as_explicit (self, target_names):\n\n        # Record the name of the target, not instance, since this\n        # rule is called before main target instaces are created.\n        assert is_iterable_typed(target_names, basestring)\n        self.explicit_targets_.update(target_names)", "response": "Add target to the list of targets that should be build only by explicit request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_alternative (self, target_instance):\n        assert isinstance(target_instance, AbstractTarget)\n        if self.built_main_targets_:\n            raise IllegalOperation (\"add-alternative called when main targets are already created for project '%s'\" % self.full_name ())\n\n        self.alternatives_.append (target_instance)", "response": "Add a new target alternative."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_main_target (self, name):\n        assert isinstance(name, basestring)\n        if not self.built_main_targets_:\n            self.build_main_targets()\n\n        return name in self.main_target_", "response": "Tells if a main target with the specified name exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_main_target (self, name):\n        assert isinstance(name, basestring)\n        if not self.built_main_targets_:\n            self.build_main_targets ()\n\n        return self.main_targets_.get (name, None)", "response": "Returns a MainTarget class instance corresponding to the name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds and return the target with the specified id.", "response": "def find_really(self, id):\n        \"\"\" Find and return the target with the specified id, treated\n            relative to self.\n        \"\"\"\n        assert isinstance(id, basestring)\n\n        result = None\n        current_location = self.get ('location')\n\n        __re_split_project_target = re.compile (r'(.*)//(.*)')\n        split = __re_split_project_target.match (id)\n\n        project_part = None\n        target_part = None\n\n        if split:\n            project_part = split.group(1)\n            target_part = split.group(2)\n            if not target_part:\n                get_manager().errors()(\n                    'Project ID, \"{}\", is not a valid target reference. There should '\n                    'be either a target name after the \"//\" or the \"//\" should be removed '\n                    'from the target reference.'\n                    .format(id)\n                )\n\n\n        project_registry = self.project_.manager ().projects ()\n\n        extra_error_message = ''\n        if project_part:\n            # There's explicit project part in id. Looks up the\n            # project and pass the request to it.\n            pm = project_registry.find (project_part, current_location)\n\n            if pm:\n                project_target = project_registry.target (pm)\n                result = project_target.find (target_part, no_error=1)\n\n            else:\n                extra_error_message = \"error: could not find project '$(project_part)'\"\n\n        else:\n            # Interpret target-name as name of main target\n            # Need to do this before checking for file. Consider this:\n            #\n            #  exe test : test.cpp ;\n            #  install s : test : <location>. ;\n            #\n            # After first build we'll have target 'test' in Jamfile and file\n            # 'test' on the disk. We need target to override the file.\n\n            result = None\n            if self.has_main_target(id):\n                result = self.main_target(id)\n\n            if not result:\n                result = FileReference (self.manager_, id, self.project_)\n                if not result.exists ():\n                    # File actually does not exist.\n                    # Reset 'target' so that an error is issued.\n                    result = None\n\n\n            if not result:\n                # Interpret id as project-id\n                project_module = project_registry.find (id, current_location)\n                if project_module:\n                    result = project_registry.target (project_module)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_constant(self, name, value, path=0):\n        assert isinstance(name, basestring)\n        assert is_iterable_typed(value, basestring)\n        assert isinstance(path, int)  # will also match bools\n        if path:\n            l = self.location_\n            if not l:\n                # Project corresponding to config files do not have\n                # 'location' attribute, but do have source location.\n                # It might be more reasonable to make every project have\n                # a location and use some other approach to prevent buildable\n                # targets in config files, but that's for later.\n                l = self.get('source-location')\n\n            value = os.path.join(l, value[0])\n            # Now make the value absolute path. Constants should be in\n            # platform-native form.\n            value = [os.path.normpath(os.path.join(os.getcwd(), value))]\n\n        self.constants_[name] = value\n        bjam.call(\"set-variable\", self.project_module(), name, value)", "response": "Adds a new constant for this project."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_alternative (self, target):\n        assert isinstance(target, BasicTarget)\n        d = target.default_build ()\n\n        if self.alternatives_ and self.default_build_ != d:\n            get_manager().errors()(\"default build must be identical in all alternatives\\n\"\n              \"main target is '%s'\\n\"\n              \"with '%s'\\n\"\n              \"differing from previous default build: '%s'\" % (self.full_name (), d.raw (), self.default_build_.raw ()))\n\n        else:\n            self.default_build_ = d\n\n        self.alternatives_.append (target)", "response": "Add a new alternative for this target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect the alternative for this property set.", "response": "def __select_alternatives (self, property_set_, debug):\n        \"\"\" Returns the best viable alternative for this property_set\n            See the documentation for selection rules.\n            # TODO: shouldn't this be 'alternative' (singular)?\n        \"\"\"\n        # When selecting alternatives we have to consider defaults,\n        # for example:\n        #    lib l : l.cpp : <variant>debug ;\n        #    lib l : l_opt.cpp : <variant>release ;\n        # won't work unless we add default value <variant>debug.\n        assert isinstance(property_set_, property_set.PropertySet)\n        assert isinstance(debug, int)  # also matches bools\n\n        property_set_ = property_set_.add_defaults ()\n\n        # The algorithm: we keep the current best viable alternative.\n        # When we've got new best viable alternative, we compare it\n        # with the current one.\n        best = None\n        best_properties = None\n\n        if len (self.alternatives_) == 0:\n            return None\n\n        if len (self.alternatives_) == 1:\n            return self.alternatives_ [0]\n\n        if debug:\n            print \"Property set for selection:\", property_set_\n\n        for v in self.alternatives_:\n            properties = v.match (property_set_, debug)\n\n            if properties is not None:\n                if not best:\n                    best = v\n                    best_properties = properties\n\n                else:\n                    if b2.util.set.equal (properties, best_properties):\n                        return None\n\n                    elif b2.util.set.contains (properties, best_properties):\n                        # Do nothing, this alternative is worse\n                        pass\n\n                    elif b2.util.set.contains (best_properties, properties):\n                        best = v\n                        best_properties = properties\n\n                    else:\n                        return None\n\n        return best"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate (self, ps):\n        assert isinstance(ps, property_set.PropertySet)\n        self.manager_.targets ().start_building (self)\n\n        # We want composite properties in build request act as if\n        # all the properties it expands too are explicitly specified.\n        ps = ps.expand ()\n\n        all_property_sets = self.apply_default_build (ps)\n\n        result = GenerateResult ()\n\n        for p in all_property_sets:\n            result.extend (self.__generate_really (p))\n\n        self.manager_.targets ().end_building (self)\n\n        return result", "response": "Generate an alternative for this main target by finding all alternatives that satisfy the given properties set and then applying the default build to the alternative."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __generate_really (self, prop_set):\n        assert isinstance(prop_set, property_set.PropertySet)\n        best_alternative = self.__select_alternatives (prop_set, debug=0)\n        self.best_alternative = best_alternative\n\n        if not best_alternative:\n            # FIXME: revive.\n            # self.__select_alternatives(prop_set, debug=1)\n            self.manager_.errors()(\n                \"No best alternative for '%s'.\\n\"\n                  % (self.full_name(),))\n\n        result = best_alternative.generate (prop_set)\n\n        # Now return virtual targets for the only alternative\n        return result", "response": "Generate the main target with the given property set and returns a list of all virtual targets that are available for the given property set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sources (self):\n        if self.source_targets_ == None:\n            self.source_targets_ = []\n            for s in self.sources_:\n                self.source_targets_.append(resolve_reference(s, self.project_)[0])\n\n        return self.source_targets_", "response": "Returns the list of AbstractTargets which are used as sources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving build request and requirements return propertiescommon to dependency build request and target build properties.", "response": "def common_properties (self, build_request, requirements):\n        \"\"\" Given build request and requirements, return properties\n            common to dependency build request and target build\n            properties.\n        \"\"\"\n        # For optimization, we add free unconditional requirements directly,\n        # without using complex algorithsm.\n        # This gives the complex algorithm better chance of caching results.\n        # The exact effect of this \"optimization\" is no longer clear\n        assert isinstance(build_request, property_set.PropertySet)\n        assert isinstance(requirements, property_set.PropertySet)\n        free_unconditional = []\n        other = []\n        for p in requirements.all():\n            if p.feature.free and not p.condition and p.feature.name != 'conditional':\n                free_unconditional.append(p)\n            else:\n                other.append(p)\n        other = property_set.create(other)\n\n        key = (build_request, other)\n        if key not in self.request_cache:\n            self.request_cache[key] = self.__common_properties2 (build_request, other)\n\n        return self.request_cache[key].add_raw(free_unconditional)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match (self, property_set_, debug):\n        # The condition is composed of all base non-conditional properties.\n        # It's not clear if we should expand 'self.requirements_' or not.\n        # For one thing, it would be nice to be able to put\n        #    <toolset>msvc-6.0\n        # in requirements.\n        # On the other hand, if we have <variant>release in condition it\n        # does not make sense to require <optimization>full to be in\n        # build request just to select this variant.\n        assert isinstance(property_set_, property_set.PropertySet)\n        bcondition = self.requirements_.base ()\n        ccondition = self.requirements_.conditional ()\n        condition = b2.util.set.difference (bcondition, ccondition)\n\n        if debug:\n            print \"    next alternative: required properties:\", [str(p) for p in condition]\n\n        if b2.util.set.contains (condition, property_set_.all()):\n\n            if debug:\n                print \"        matched\"\n\n            return condition\n\n        else:\n            return None", "response": "Returns the alternative condition for this alternative if the condition is satisfied by property_set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_dependency_properties(self, properties, ps):\n        assert is_iterable_typed(properties, property.Property)\n        assert isinstance(ps, property_set.PropertySet)\n        result_properties = []\n        usage_requirements = []\n        for p in properties:\n\n            result = generate_from_reference(p.value, self.project_, ps)\n\n            for t in result.targets():\n                result_properties.append(property.Property(p.feature, t))\n\n            usage_requirements += result.usage_requirements().all()\n\n        return (result_properties, usage_requirements)", "response": "Generates dependency properties for a target id\n            or a dependency property set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a new target and returns a GenerateResult object.", "response": "def generate (self, ps):\n        \"\"\" Determines final build properties, generates sources,\n        and calls 'construct'. This method should not be\n        overridden.\n        \"\"\"\n        assert isinstance(ps, property_set.PropertySet)\n        self.manager_.errors().push_user_context(\n            \"Generating target \" + self.full_name(), self.user_context_)\n\n        if self.manager().targets().logging():\n            self.manager().targets().log(\n                \"Building target '%s'\" % self.name_)\n            self.manager().targets().increase_indent ()\n            self.manager().targets().log(\n                \"Build request: '%s'\" % str (ps.raw ()))\n            cf = self.manager().command_line_free_features()\n            self.manager().targets().log(\n                \"Command line free features: '%s'\" % str (cf.raw ()))\n            self.manager().targets().log(\n                \"Target requirements: %s'\" % str (self.requirements().raw ()))\n\n        self.manager().targets().push_target(self)\n\n        if ps not in self.generated_:\n\n            # Apply free features form the command line.  If user\n            # said\n            #   define=FOO\n            # he most likely want this define to be set for all compiles.\n            ps = ps.refine(self.manager().command_line_free_features())\n            rproperties = self.common_properties (ps, self.requirements_)\n\n            self.manager().targets().log(\n                \"Common properties are '%s'\" % str (rproperties))\n\n            if rproperties.get(\"<build>\") != [\"no\"]:\n\n                result = GenerateResult ()\n\n                properties = rproperties.non_dependency ()\n\n                (p, u) = self.generate_dependency_properties (rproperties.dependency (), rproperties)\n                properties += p\n                assert all(isinstance(p, property.Property) for p in properties)\n                usage_requirements = u\n\n                (source_targets, u) = self.generate_dependency_targets (self.sources_, rproperties)\n                usage_requirements += u\n\n                self.manager_.targets().log(\n                    \"Usage requirements for '%s' are '%s'\" % (self.name_, usage_requirements))\n\n                # FIXME:\n\n                rproperties = property_set.create(properties + usage_requirements)\n                usage_requirements = property_set.create (usage_requirements)\n\n                self.manager_.targets().log(\n                    \"Build properties: '%s'\" % str(rproperties))\n\n                source_targets += rproperties.get('<source>')\n\n                # We might get duplicate sources, for example if\n                # we link to two library which have the same <library> in\n                # usage requirements.\n                # Use stable sort, since for some targets the order is\n                # important. E.g. RUN_PY target need python source to come\n                # first.\n                source_targets = unique(source_targets, stable=True)\n\n                # FIXME: figure why this call messes up source_targets in-place\n                result = self.construct (self.name_, source_targets[:], rproperties)\n\n                if result:\n                    assert len(result) == 2\n                    gur = result [0]\n                    result = result [1]\n\n                    if self.always_:\n                        for t in result:\n                            t.always()\n\n                    s = self.create_subvariant (\n                        result,\n                        self.manager().virtual_targets().recent_targets(), ps,\n                        source_targets, rproperties, usage_requirements)\n                    self.manager().virtual_targets().clear_recent_targets()\n\n                    ur = self.compute_usage_requirements (s)\n                    ur = ur.add (gur)\n                    s.set_usage_requirements (ur)\n\n                    self.manager_.targets().log (\n                        \"Usage requirements from '%s' are '%s'\" %\n                        (self.name(), str(rproperties)))\n\n                    self.generated_[ps] = GenerateResult (ur, result)\n                else:\n                    self.generated_[ps] = GenerateResult (property_set.empty(), [])\n            else:\n                # If we just see <build>no, we cannot produce any reasonable\n                # diagnostics. The code that adds this property is expected\n                # to explain why a target is not built, for example using\n                # the configure.log-component-configuration function.\n\n                # If this target fails to build, add <build>no to properties\n                # to cause any parent target to fail to build.  Except that it\n                # - does not work now, since we check for <build>no only in\n                #   common properties, but not in properties that came from\n                #   dependencies\n                # - it's not clear if that's a good idea anyway.  The alias\n                #   target, for example, should not fail to build if a dependency\n                #   fails.\n                self.generated_[ps] = GenerateResult(\n                    property_set.create([\"<build>no\"]), [])\n        else:\n            self.manager().targets().log (\"Already built\")\n\n        self.manager().targets().pop_target()\n        self.manager().targets().decrease_indent()\n\n        return self.generated_[ps]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes and sets appripriate usage requirements for a given virtual target.", "response": "def compute_usage_requirements (self, subvariant):\n        \"\"\" Given the set of generated targets, and refined build\n            properties, determines and sets appripriate usage requirements\n            on those targets.\n        \"\"\"\n        assert isinstance(subvariant, virtual_target.Subvariant)\n        rproperties = subvariant.build_properties ()\n        xusage_requirements =self.evaluate_requirements(\n            self.usage_requirements_, rproperties, \"added\")\n\n        # We generate all dependency properties and add them,\n        # as well as their usage requirements, to result.\n        (r1, r2) = self.generate_dependency_properties(xusage_requirements.dependency (), rproperties)\n        extra = r1 + r2\n\n        result = property_set.create (xusage_requirements.non_dependency () + extra)\n\n        # Propagate usage requirements we've got from sources, except\n        # for the <pch-header> and <pch-file> features.\n        #\n        # That feature specifies which pch file to use, and should apply\n        # only to direct dependents. Consider:\n        #\n        #   pch pch1 : ...\n        #   lib lib1 : ..... pch1 ;\n        #   pch pch2 :\n        #   lib lib2 : pch2 lib1 ;\n        #\n        # Here, lib2 should not get <pch-header> property from pch1.\n        #\n        # Essentially, when those two features are in usage requirements,\n        # they are propagated only to direct dependents. We might need\n        # a more general mechanism, but for now, only those two\n        # features are special.\n        properties = []\n        for p in subvariant.sources_usage_requirements().all():\n            if p.feature.name not in ('pch-header', 'pch-file'):\n                properties.append(p)\n        if 'shared' in rproperties.get('link'):\n            new_properties = []\n            for p in properties:\n                if p.feature.name != 'library':\n                    new_properties.append(p)\n            properties = new_properties\n\n        result = result.add_raw(properties)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new subvariant - dg instance for the given build request and sources and usage requirements.", "response": "def create_subvariant (self, root_targets, all_targets,\n                           build_request, sources,\n                           rproperties, usage_requirements):\n        \"\"\"Creates a new subvariant-dg instances for 'targets'\n         - 'root-targets' the virtual targets will be returned to dependents\n         - 'all-targets' all virtual\n              targets created while building this main target\n         - 'build-request' is property-set instance with\n         requested build properties\"\"\"\n        assert is_iterable_typed(root_targets, virtual_target.VirtualTarget)\n        assert is_iterable_typed(all_targets, virtual_target.VirtualTarget)\n        assert isinstance(build_request, property_set.PropertySet)\n        assert is_iterable_typed(sources, virtual_target.VirtualTarget)\n        assert isinstance(rproperties, property_set.PropertySet)\n        assert isinstance(usage_requirements, property_set.PropertySet)\n\n        for e in root_targets:\n            e.root (True)\n\n        s = Subvariant (self, build_request, sources,\n                        rproperties, usage_requirements, all_targets)\n\n        for v in all_targets:\n            if not v.creating_subvariant():\n                v.creating_subvariant(s)\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef variant (name, parents_or_properties, explicit_properties = []):\n    parents = []\n    if not explicit_properties:\n        explicit_properties = parents_or_properties\n    else:\n        parents = parents_or_properties\n\n    inherited = property_set.empty()\n    if parents:\n\n        # If we allow multiple parents, we'd have to to check for conflicts\n        # between base variants, and there was no demand for so to bother.\n        if len (parents) > 1:\n            raise BaseException (\"Multiple base variants are not yet supported\")\n\n        p = parents[0]\n        # TODO: the check may be stricter\n        if not feature.is_implicit_value (p):\n            raise BaseException (\"Invalid base variant '%s'\" % p)\n\n        inherited = __variant_explicit_properties[p]\n\n    explicit_properties = property_set.create_with_validation(explicit_properties)\n    explicit_properties = inherited.refine(explicit_properties)\n\n    # Record explicitly specified properties for this variant\n    # We do this after inheriting parents' properties, so that\n    # they affect other variants, derived from this one.\n    __variant_explicit_properties[name] = explicit_properties\n\n    feature.extend('variant', [name])\n    feature.compose (\"<variant>\" + name, explicit_properties.all())", "response": "Declares a new variant by name parents_or_properties and explicit_properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_globals ():\n\n    # This feature is used to determine which OS we're on.\n    # In future, this may become <target-os> and <host-os>\n    # TODO: check this. Compatibility with bjam names? Subfeature for version?\n    os = sys.platform\n    feature.feature ('os', [os], ['propagated', 'link-incompatible'])\n\n\n    # The two OS features define a known set of abstract OS names. The host-os is\n    # the OS under which bjam is running. Even though this should really be a fixed\n    # property we need to list all the values to prevent unknown value errors. Both\n    # set the default value to the current OS to account for the default use case of\n    # building on the target OS.\n    feature.feature('host-os', __os_names)\n    feature.set_default('host-os', default_host_os())\n\n    feature.feature('target-os', __os_names, ['propagated', 'link-incompatible'])\n    feature.set_default('target-os', default_host_os())\n\n    feature.feature ('toolset', [], ['implicit', 'propagated' ,'symmetric'])\n\n    feature.feature ('stdlib', ['native'], ['propagated', 'composite'])\n\n    feature.feature ('link', ['shared', 'static'], ['propagated'])\n    feature.feature ('runtime-link', ['shared', 'static'], ['propagated'])\n    feature.feature ('runtime-debugging', ['on', 'off'], ['propagated'])\n\n\n    feature.feature ('optimization',  ['off', 'speed', 'space'], ['propagated'])\n    feature.feature ('profiling', ['off', 'on'], ['propagated'])\n    feature.feature ('inlining', ['off', 'on', 'full'], ['propagated'])\n\n    feature.feature ('threading', ['single', 'multi'], ['propagated'])\n    feature.feature ('rtti', ['on', 'off'], ['propagated'])\n    feature.feature ('exception-handling', ['on', 'off'], ['propagated'])\n\n    # Whether there is support for asynchronous EH (e.g. catching SEGVs).\n    feature.feature ('asynch-exceptions', ['off', 'on'], ['propagated'])\n\n    # Whether all extern \"C\" functions are considered nothrow by default.\n    feature.feature ('extern-c-nothrow', ['off', 'on'], ['propagated'])\n\n    feature.feature ('debug-symbols', ['on', 'off'], ['propagated'])\n    feature.feature ('define', [], ['free'])\n    feature.feature ('undef', [], ['free'])\n    feature.feature ('include', [], ['free', 'path']) #order-sensitive\n    feature.feature ('cflags', [], ['free'])\n    feature.feature ('cxxflags', [], ['free'])\n    feature.feature ('asmflags', [], ['free'])\n    feature.feature ('linkflags', [], ['free'])\n    feature.feature ('archiveflags', [], ['free'])\n    feature.feature ('version', [], ['free'])\n\n    feature.feature ('location-prefix', [], ['free'])\n\n    feature.feature ('action', [], ['free'])\n\n\n    # The following features are incidental, since\n    # in themself they have no effect on build products.\n    # Not making them incidental will result in problems in corner\n    # cases, for example:\n    #\n    #    unit-test a : a.cpp : <use>b ;\n    #    lib b : a.cpp b ;\n    #\n    # Here, if <use> is not incidental, we'll decide we have two\n    # targets for a.obj with different properties, and will complain.\n    #\n    # Note that making feature incidental does not mean it's ignored. It may\n    # be ignored when creating the virtual target, but the rest of build process\n    # will use them.\n    feature.feature ('use', [], ['free', 'dependency', 'incidental'])\n    feature.feature ('dependency', [], ['free', 'dependency', 'incidental'])\n    feature.feature ('implicit-dependency', [], ['free', 'dependency', 'incidental'])\n\n    feature.feature('warnings', [\n        'on',         # Enable default/\"reasonable\" warning level for the tool.\n        'all',        # Enable all possible warnings issued by the tool.\n        'off'],       # Disable all warnings issued by the tool.\n        ['incidental', 'propagated'])\n\n    feature.feature('warnings-as-errors', [\n        'off',        # Do not fail the compilation if there are warnings.\n        'on'],        # Fail the compilation if there are warnings.\n        ['incidental', 'propagated'])\n\n    feature.feature('c++-template-depth',\n        [str(i) for i in range(64,1024+1,64)] +\n        [str(i) for i in range(20,1000+1,10)] +\n        #   Maximum template instantiation depth guaranteed for ANSI/ISO C++\n        # conforming programs.\n        ['17'],\n        ['incidental', 'optional', 'propagated'])\n\n    feature.feature ('source', [], ['free', 'dependency', 'incidental'])\n    feature.feature ('library', [], ['free', 'dependency', 'incidental'])\n    feature.feature ('file', [], ['free', 'dependency', 'incidental'])\n    feature.feature ('find-shared-library', [], ['free']) #order-sensitive ;\n    feature.feature ('find-static-library', [], ['free']) #order-sensitive ;\n    feature.feature ('library-path', [], ['free', 'path']) #order-sensitive ;\n    # Internal feature.\n    feature.feature ('library-file', [], ['free', 'dependency'])\n\n    feature.feature ('name', [], ['free'])\n    feature.feature ('tag', [], ['free'])\n    feature.feature ('search', [], ['free', 'path']) #order-sensitive ;\n    feature.feature ('location', [], ['free', 'path'])\n\n    feature.feature ('dll-path', [], ['free', 'path'])\n    feature.feature ('hardcode-dll-paths', ['true', 'false'], ['incidental'])\n\n\n    # This is internal feature which holds the paths of all dependency\n    # dynamic libraries. On Windows, it's needed so that we can all\n    # those paths to PATH, when running applications.\n    # On Linux, it's needed to add proper -rpath-link command line options.\n    feature.feature ('xdll-path', [], ['free', 'path'])\n\n    #provides means to specify def-file for windows dlls.\n    feature.feature ('def-file', [], ['free', 'dependency'])\n\n    # This feature is used to allow specific generators to run.\n    # For example, QT tools can only be invoked when QT library\n    # is used. In that case, <allow>qt will be in usage requirement\n    # of the library.\n    feature.feature ('allow', [], ['free'])\n\n    # The addressing model to generate code for. Currently a limited set only\n    # specifying the bit size of pointers.\n    feature.feature('address-model', ['16', '32', '64'], ['propagated', 'optional'])\n\n    # Type of CPU architecture to compile for.\n    feature.feature('architecture', [\n        # x86 and x86-64\n        'x86',\n\n        # ia64\n        'ia64',\n\n        # Sparc\n        'sparc',\n\n        # RS/6000 & PowerPC\n        'power',\n\n        # MIPS/SGI\n        'mips1', 'mips2', 'mips3', 'mips4', 'mips32', 'mips32r2', 'mips64',\n\n        # HP/PA-RISC\n        'parisc',\n\n        # Advanced RISC Machines\n        'arm',\n\n        # Combined architectures for platforms/toolsets that support building for\n        # multiple architectures at once. \"combined\" would be the default multi-arch\n        # for the toolset.\n        'combined',\n        'combined-x86-power'],\n\n        ['propagated', 'optional'])\n\n    # The specific instruction set in an architecture to compile.\n    feature.feature('instruction-set', [\n        # x86 and x86-64\n        'native', 'i486', 'i586', 'i686', 'pentium', 'pentium-mmx', 'pentiumpro', 'pentium2', 'pentium3',\n        'pentium3m', 'pentium-m', 'pentium4', 'pentium4m', 'prescott', 'nocona', 'core2', 'corei7', 'corei7-avx', 'core-avx-i',\n        'conroe', 'conroe-xe', 'conroe-l', 'allendale', 'merom', 'merom-xe', 'kentsfield', 'kentsfield-xe', 'penryn', 'wolfdale',\n        'yorksfield', 'nehalem', 'sandy-bridge', 'ivy-bridge', 'haswell', 'k6', 'k6-2', 'k6-3', 'athlon', 'athlon-tbird', 'athlon-4', 'athlon-xp',\n        'athlon-mp', 'k8', 'opteron', 'athlon64', 'athlon-fx', 'k8-sse3', 'opteron-sse3', 'athlon64-sse3', 'amdfam10', 'barcelona',\n        'bdver1', 'bdver2', 'bdver3', 'btver1', 'btver2', 'winchip-c6', 'winchip2', 'c3', 'c3-2', 'atom',\n\n        # ia64\n        'itanium', 'itanium1', 'merced', 'itanium2', 'mckinley',\n\n        # Sparc\n        'v7', 'cypress', 'v8', 'supersparc', 'sparclite', 'hypersparc', 'sparclite86x', 'f930', 'f934',\n        'sparclet', 'tsc701', 'v9', 'ultrasparc', 'ultrasparc3',\n\n        # RS/6000 & PowerPC\n        '401', '403', '405', '405fp', '440', '440fp', '505', '601', '602',\n        '603', '603e', '604', '604e', '620', '630', '740', '7400',\n        '7450', '750', '801', '821', '823', '860', '970', '8540',\n        'power-common', 'ec603e', 'g3', 'g4', 'g5', 'power', 'power2',\n        'power3', 'power4', 'power5', 'powerpc', 'powerpc64', 'rios',\n        'rios1', 'rsc', 'rios2', 'rs64a',\n\n        # MIPS\n        '4kc', '4kp', '5kc', '20kc', 'm4k', 'r2000', 'r3000', 'r3900', 'r4000',\n        'r4100', 'r4300', 'r4400', 'r4600', 'r4650',\n        'r6000', 'r8000', 'rm7000', 'rm9000', 'orion', 'sb1', 'vr4100',\n        'vr4111', 'vr4120', 'vr4130', 'vr4300',\n        'vr5000', 'vr5400', 'vr5500',\n\n        # HP/PA-RISC\n        '700', '7100', '7100lc', '7200', '7300', '8000',\n\n        # Advanced RISC Machines\n        'armv2', 'armv2a', 'armv3', 'armv3m', 'armv4', 'armv4t', 'armv5',\n        'armv5t', 'armv5te', 'armv6', 'armv6j', 'iwmmxt', 'ep9312'],\n\n        ['propagated', 'optional'])\n\n    feature.feature('conditional', [], ['incidental', 'free'])\n\n    # The value of 'no' prevents building of a target.\n    feature.feature('build', ['yes', 'no'], ['optional'])\n\n    # Windows-specific features\n    feature.feature ('user-interface', ['console', 'gui', 'wince', 'native', 'auto'], [])\n    feature.feature ('variant', [], ['implicit', 'composite', 'propagated', 'symmetric'])\n\n\n    variant ('debug', ['<optimization>off', '<debug-symbols>on', '<inlining>off', '<runtime-debugging>on'])\n    variant ('release', ['<optimization>speed', '<debug-symbols>off', '<inlining>full',\n                         '<runtime-debugging>off', '<define>NDEBUG'])\n    variant ('profile', ['release'], ['<profiling>on', '<debug-symbols>on'])", "response": "Registers all features and variants declared by this module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lib(names, sources=[], requirements=[], default_build=[], usage_requirements=[]):\n    assert is_iterable_typed(names, basestring)\n    assert is_iterable_typed(sources, basestring)\n    assert is_iterable_typed(requirements, basestring)\n    assert is_iterable_typed(default_build, basestring)\n    assert is_iterable_typed(usage_requirements, basestring)\n    if len(names) > 1:\n        if any(r.startswith('<name>') for r in requirements):\n            get_manager().errors()(\"When several names are given to the 'lib' rule\\n\" +\n                                   \"it is not allowed to specify the <name> feature.\")\n\n        if sources:\n            get_manager().errors()(\"When several names are given to the 'lib' rule\\n\" +\n                                   \"it is not allowed to specify sources.\")\n\n    project = get_manager().projects().current()\n    result = []\n\n    for name in names:\n        r = requirements[:]\n\n        # Support \" lib a ; \" and \" lib a b c ; \" syntax.\n        if not sources and not any(r.startswith(\"<name>\") for r in requirements) \\\n           and not any(r.startswith(\"<file\") for r in requirements):\n            r.append(\"<name>\" + name)\n\n        result.append(targets.create_typed_metatarget(name, \"LIB\", sources,\n                                                      r,\n                                                      default_build,\n                                                      usage_requirements))\n    return result", "response": "The implementation of the lib rule. Beyond standard syntax that rule allows\n    simplified : lib a b c ;"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjust_properties (self, prop_set):\n        assert isinstance(prop_set, property_set.PropertySet)\n        s = self.targets () [0].creating_subvariant ()\n\n        return prop_set.add_raw (s.implicit_includes ('include', 'H'))", "response": "Adjusts the properties of the property_set to include path for all virtual targets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new unweighted no - item model that makes recommendations using the given observation data.", "response": "def create(observation_data,\n           user_id='user_id', item_id='item_id', target=None,\n           user_data=None, item_data=None,\n           random_seed=0,\n           verbose=True):\n    \"\"\"\n    Create a model that makes recommendations using item popularity. When no\n    target column is provided, the popularity is determined by the number of\n    observations involving each item. When a target is provided, popularity\n    is computed using the item's mean target value. When the target column\n    contains ratings, for example, the model computes the mean rating for\n    each item and uses this to rank items for recommendations.\n\n    Parameters\n    ----------\n    observation_data : SFrame\n        The dataset to use for training the model. It must contain a column of\n        user ids and a column of item ids. Each row represents an observed\n        interaction between the user and the item.  The (user, item) pairs\n        are stored with the model so that they can later be excluded from\n        recommendations if desired. It can optionally contain a target ratings\n        column. All other columns are interpreted by the underlying model as\n        side features for the observations.\n\n        The user id and item id columns must be of type 'int' or 'str'. The\n        target column must be of type 'int' or 'float'.\n\n    user_id : string, optional\n        The name of the column in `observation_data` that corresponds to the\n        user id.\n\n    item_id : string, optional\n        The name of the column in `observation_data` that corresponds to the\n        item id.\n\n    target : string, optional\n        The `observation_data` can optionally contain a column of scores\n        representing ratings given by the users. If present, the name of this\n        column may be specified variables `target`.\n\n    user_data : SFrame, optional\n        Side information for the users.  This SFrame must have a column with\n        the same name as what is specified by the `user_id` input parameter.\n        `user_data` can provide any amount of additional user-specific\n        information.\n\n    item_data : SFrame, optional\n        Side information for the items.  This SFrame must have a column with\n        the same name as what is specified by the `item_id` input parameter.\n        `item_data` can provide any amount of additional item-specific\n        information.\n\n    verbose : bool, optional\n        Enables verbose output.\n\n    Examples\n    --------\n    >>> sf = turicreate.SFrame({'user_id': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\n    ...                       'item_id': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\n    ...                       'rating': [1, 3, 2, 5, 4, 1, 4, 3]})\n    >>> m = turicreate.popularity_recommender.create(sf, target='rating')\n\n    See Also\n    --------\n    PopularityRecommender\n    \"\"\"\n    from turicreate._cython.cy_server import QuietProgress\n\n    opts = {}\n    model_proxy = _turicreate.extensions.popularity()\n    model_proxy.init_options(opts)\n\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    nearest_items = _turicreate.SFrame()\n\n    opts = {'user_id': user_id,\n            'item_id': item_id,\n            'target': target,\n            'random_seed': 1}\n\n    extra_data = {\"nearest_items\" : _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n\n    return PopularityRecommender(model_proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets xgboost type parameters.", "response": "def get_xgb_params(self):\n        \"\"\"Get xgboost type parameters.\"\"\"\n        xgb_params = self.get_params()\n\n        xgb_params['silent'] = 1 if self.silent else 0\n\n        if self.nthread <= 0:\n            xgb_params.pop('nthread', None)\n        return xgb_params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting the gradient boosting model to the set of features and labels.", "response": "def fit(self, X, y, eval_set=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True):\n        # pylint: disable=missing-docstring,invalid-name,attribute-defined-outside-init\n        \"\"\"\n        Fit the gradient boosting model\n\n        Parameters\n        ----------\n        X : array_like\n            Feature matrix\n        y : array_like\n            Labels\n        eval_set : list, optional\n            A list of (X, y) tuple pairs to use as a validation set for\n            early-stopping\n        eval_metric : str, callable, optional\n            If a str, should be a built-in evaluation metric to use. See\n            doc/parameter.md. If callable, a custom evaluation metric. The call\n            signature is func(y_predicted, y_true) where y_true will be a\n            DMatrix object such that you may need to call the get_label\n            method. It must return a str, value pair where the str is a name\n            for the evaluation and value is the value of the evaluation\n            function. This objective is always minimized.\n        early_stopping_rounds : int\n            Activates early stopping. Validation error needs to decrease at\n            least every <early_stopping_rounds> round(s) to continue training.\n            Requires at least one item in evals.  If there's more than one,\n            will use the last. Returns the model from the last iteration\n            (not the best one). If early stopping occurs, the model will\n            have two additional fields: bst.best_score and bst.best_iteration.\n        verbose : bool\n            If `verbose` and an evaluation set is used, writes the evaluation\n            metric measured on the validation set to stderr.\n        \"\"\"\n        trainDmatrix = DMatrix(X, label=y, missing=self.missing)\n\n        evals_result = {}\n        if eval_set is not None:\n            evals = list(DMatrix(x[0], label=x[1]) for x in eval_set)\n            evals = list(zip(evals, [\"validation_{}\".format(i) for i in\n                                     range(len(evals))]))\n        else:\n            evals = ()\n\n        params = self.get_xgb_params()\n\n        feval = eval_metric if callable(eval_metric) else None\n        if eval_metric is not None:\n            if callable(eval_metric):\n                eval_metric = None\n            else:\n                params.update({'eval_metric': eval_metric})\n\n        self._Booster = train(params, trainDmatrix,\n                              self.n_estimators, evals=evals,\n                              early_stopping_rounds=early_stopping_rounds,\n                              evals_result=evals_result, feval=feval,\n                              verbose_eval=verbose)\n\n        if evals_result:\n            for val in evals_result.items():\n                evals_result_key = list(val[1].keys())[0]\n                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\n            self.evals_result_ = evals_result\n\n        if early_stopping_rounds is not None:\n            self.best_score = self._Booster.best_score\n            self.best_iteration = self._Booster.best_iteration\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits gradient boosting classifier to the given data.", "response": "def fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None,\n            early_stopping_rounds=None, verbose=True):\n        # pylint: disable = attribute-defined-outside-init,arguments-differ\n        \"\"\"\n        Fit gradient boosting classifier\n\n        Parameters\n        ----------\n        X : array_like\n            Feature matrix\n        y : array_like\n            Labels\n        sample_weight : array_like\n            Weight for each instance\n        eval_set : list, optional\n            A list of (X, y) pairs to use as a validation set for\n            early-stopping\n        eval_metric : str, callable, optional\n            If a str, should be a built-in evaluation metric to use. See\n            doc/parameter.md. If callable, a custom evaluation metric. The call\n            signature is func(y_predicted, y_true) where y_true will be a\n            DMatrix object such that you may need to call the get_label\n            method. It must return a str, value pair where the str is a name\n            for the evaluation and value is the value of the evaluation\n            function. This objective is always minimized.\n        early_stopping_rounds : int, optional\n            Activates early stopping. Validation error needs to decrease at\n            least every <early_stopping_rounds> round(s) to continue training.\n            Requires at least one item in evals.  If there's more than one,\n            will use the last. Returns the model from the last iteration\n            (not the best one). If early stopping occurs, the model will\n            have two additional fields: bst.best_score and bst.best_iteration.\n        verbose : bool\n            If `verbose` and an evaluation set is used, writes the evaluation\n            metric measured on the validation set to stderr.\n        \"\"\"\n        evals_result = {}\n        self.classes_ = list(np.unique(y))\n        self.n_classes_ = len(self.classes_)\n        if self.n_classes_ > 2:\n            # Switch to using a multiclass objective in the underlying XGB instance\n            self.objective = \"multi:softprob\"\n            xgb_options = self.get_xgb_params()\n            xgb_options['num_class'] = self.n_classes_\n        else:\n            xgb_options = self.get_xgb_params()\n\n        feval = eval_metric if callable(eval_metric) else None\n        if eval_metric is not None:\n            if callable(eval_metric):\n                eval_metric = None\n            else:\n                xgb_options.update({\"eval_metric\": eval_metric})\n\n        if eval_set is not None:\n            # TODO: use sample_weight if given?\n            evals = list(DMatrix(x[0], label=x[1]) for x in eval_set)\n            nevals = len(evals)\n            eval_names = [\"validation_{}\".format(i) for i in range(nevals)]\n            evals = list(zip(evals, eval_names))\n        else:\n            evals = ()\n\n        self._le = LabelEncoder().fit(y)\n        training_labels = self._le.transform(y)\n\n        if sample_weight is not None:\n            train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n                                    missing=self.missing)\n        else:\n            train_dmatrix = DMatrix(X, label=training_labels,\n                                    missing=self.missing)\n\n        self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n                              evals=evals,\n                              early_stopping_rounds=early_stopping_rounds,\n                              evals_result=evals_result, feval=feval,\n                              verbose_eval=verbose)\n\n        if evals_result:\n            for val in evals_result.items():\n                evals_result_key = list(val[1].keys())[0]\n                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\n            self.evals_result_ = evals_result\n\n        if early_stopping_rounds is not None:\n            self.best_score = self._Booster.best_score\n            self.best_iteration = self._Booster.best_iteration\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_grist (features):\n    assert is_iterable_typed(features, basestring) or isinstance(features, basestring)\n    def grist_one (feature):\n        if feature [0] != '<' and feature [len (feature) - 1] != '>':\n            return '<' + feature + '>'\n        else:\n            return feature\n\n    if isinstance (features, str):\n        return grist_one (features)\n    else:\n        return [ grist_one (feature) for feature in features ]", "response": "Transform a string by bracketing it with \"<>\". If already bracketed does nothing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_grist (features, new_grist):\n    assert is_iterable_typed(features, basestring) or isinstance(features, basestring)\n    assert isinstance(new_grist, basestring)\n    # this function is used a lot in the build phase and the original implementation\n    # was extremely slow; thus some of the weird-looking optimizations for this function.\n    single_item = False\n    if isinstance(features, str):\n        features = [features]\n        single_item = True\n\n    result = []\n    for feature in features:\n        # '<feature>value' -> ('<feature', '>', 'value')\n        # 'something' -> ('something', '', '')\n        # '<toolset>msvc/<feature>value' -> ('<toolset', '>', 'msvc/<feature>value')\n        grist, split, value = feature.partition('>')\n        # if a partition didn't occur, then grist is just 'something'\n        # set the value to be the grist\n        if not value and not split:\n            value = grist\n        result.append(new_grist + value)\n\n    if single_item:\n        return result[0]\n    return result", "response": "Replaces the grist of a string by a new one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the value of a property that is the part following the grist.", "response": "def get_value (property):\n    \"\"\" Gets the value of a property, that is, the part following the grist, if any.\n    \"\"\"\n    assert is_iterable_typed(property, basestring) or isinstance(property, basestring)\n    return replace_grist (property, '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the grist of a string.", "response": "def get_grist (value):\n    \"\"\" Returns the grist of a string.\n        If value is a sequence, does it for every value and returns the result as a sequence.\n    \"\"\"\n    assert is_iterable_typed(value, basestring) or isinstance(value, basestring)\n    def get_grist_one (name):\n        split = __re_grist_and_value.match (name)\n        if not split:\n            return ''\n        else:\n            return split.group (1)\n\n    if isinstance (value, str):\n        return get_grist_one (value)\n    else:\n        return [ get_grist_one (v) for v in value ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value without grist. A sequence is returned if value is a string and does it for every value and returns the result as a sequence.", "response": "def ungrist (value):\n    \"\"\" Returns the value without grist.\n        If value is a sequence, does it for every value and returns the result as a sequence.\n    \"\"\"\n    assert is_iterable_typed(value, basestring) or isinstance(value, basestring)\n    def ungrist_one (value):\n        stripped = __re_grist_content.match (value)\n        if not stripped:\n            raise BaseException (\"in ungrist: '%s' is not of the form <.*>\" % value)\n\n        return stripped.group (1)\n\n    if isinstance (value, str):\n        return ungrist_one (value)\n    else:\n        return [ ungrist_one (v) for v in value ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_suffix (name, new_suffix):\n    assert isinstance(name, basestring)\n    assert isinstance(new_suffix, basestring)\n    split = os.path.splitext (name)\n    return split [0] + new_suffix", "response": "Replaces the suffix of name by new_suffix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_action_id (id):\n    assert isinstance(id, basestring)\n    split = id.split ('.', 1)\n    toolset = split [0]\n    name = ''\n    if len (split) > 1:\n        name = split [1]\n    return (toolset, name)", "response": "Splits an id in the toolset and specific rule parts. E. g. c + returns ( gcc compile. c ++"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if running on windows False otherwise.", "response": "def on_windows ():\n    \"\"\" Returns true if running on windows, whether in cygwin or not.\n    \"\"\"\n    if bjam.variable(\"NT\"):\n        return True\n\n    elif bjam.variable(\"UNIX\"):\n\n        uname = bjam.variable(\"JAMUNAME\")\n        if uname and uname[0].startswith(\"CYGWIN\"):\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_dataset(dataset):\n    if not (isinstance(dataset, _SFrame)):\n        raise TypeError(\"Input 'dataset' must be an SFrame.\")\n\n    if dataset.num_rows() == 0 or dataset.num_columns() == 0:\n        raise ValueError(\"Input 'dataset' has no data.\")", "response": "Validate the main Kmeans dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_initial_centers(initial_centers):\n    if not (isinstance(initial_centers, _SFrame)):\n        raise TypeError(\"Input 'initial_centers' must be an SFrame.\")\n\n    if initial_centers.num_rows() == 0 or initial_centers.num_columns() == 0:\n        raise ValueError(\"An 'initial_centers' argument is provided \" +\n                         \"but has no data.\")", "response": "Validate the initial centers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_num_clusters(num_clusters, initial_centers, num_rows):\n\n    ## Basic validation\n    if num_clusters is not None and not isinstance(num_clusters, int):\n        raise _ToolkitError(\"Parameter 'num_clusters' must be an integer.\")\n\n    ## Determine the correct number of clusters.\n    if initial_centers is None:\n        if num_clusters is None:\n            raise ValueError(\"Number of clusters cannot be determined from \" +\n                             \"'num_clusters' or 'initial_centers'. You must \" +\n                             \"specify one of these arguments.\")\n        else:\n            _num_clusters = num_clusters\n\n    else:\n        num_centers = initial_centers.num_rows()\n\n        if num_clusters is None:\n            _num_clusters = num_centers\n        else:\n            if num_clusters != num_centers:\n                raise ValueError(\"The value of 'num_clusters' does not match \" +\n                                 \"the number of provided initial centers. \" +\n                                 \"Please provide only one of these arguments \" +\n                                 \"or ensure the values match.\")\n            else:\n                _num_clusters = num_clusters\n\n    if _num_clusters > num_rows:\n        raise ValueError(\"The desired number of clusters exceeds the number \" +\n                         \"of data points. Please set 'num_clusters' to be \" +\n                         \"smaller than the number of data points.\")\n\n    return _num_clusters", "response": "Validate the number of clusters in a Kmeans site."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_features(features, column_type_map, valid_types, label):\n    if not isinstance(features, list):\n        raise TypeError(\"Input 'features' must be a list, if specified.\")\n\n    if len(features) == 0:\n        raise ValueError(\"If specified, input 'features' must contain \" +\n                         \"at least one column name.\")\n\n    ## Remove duplicates\n    num_original_features = len(features)\n    features = set(features)\n\n    if len(features) < num_original_features:\n        _logging.warning(\"Duplicates have been removed from the list of features\")\n\n    ## Remove the row label\n    if label in features:\n        features.remove(label)\n        _logging.warning(\"The row label has been removed from the list of features.\")\n\n    ## Check the type of each feature against the list of valid types\n    valid_features = []\n\n    for ftr in features:\n        if not isinstance(ftr, str):\n            _logging.warning(\"Feature '{}' excluded. \".format(ftr) +\n                           \"Features must be specified as strings \" +\n                           \"corresponding to column names in the input dataset.\")\n\n        elif ftr not in column_type_map.keys():\n            _logging.warning(\"Feature '{}' excluded because \".format(ftr) +\n                           \"it is not in the input dataset.\")\n\n        elif column_type_map[ftr] not in valid_types:\n            _logging.warning(\"Feature '{}' excluded because of its type. \".format(ftr) +\n                           \"Kmeans features must be int, float, dict, or array.array type.\")\n\n        else:\n            valid_features.append(ftr)\n\n    if len(valid_features) == 0:\n        raise _ToolkitError(\"All specified features have been excluded. \" +\n                            \"Please specify valid features.\")\n\n    return valid_features", "response": "Validate the features in the Kmeans tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(dataset, num_clusters=None, features=None, label=None,\n           initial_centers=None, max_iterations=10, batch_size=None,\n           verbose=True):\n    \"\"\"\n    Create a k-means clustering model. The KmeansModel object contains the\n    computed cluster centers and the cluster assignment for each instance in\n    the input 'dataset'.\n\n    Given a number of clusters, k-means iteratively chooses the best cluster\n    centers and assigns nearby points to the best cluster. If no points change\n    cluster membership between iterations, the algorithm terminates.\n\n    Parameters\n    ----------\n    dataset : SFrame\n        Each row in the SFrame is an observation.\n\n    num_clusters : int\n        Number of clusters. This is the 'k' in k-means.\n\n    features : list[str], optional\n        Names of feature columns to use in computing distances between\n        observations and cluster centers. 'None' (the default) indicates that\n        all columns should be used as features. Columns may be of the following\n        types:\n\n        - *Numeric*: values of numeric type integer or float.\n\n        - *Array*: list of numeric (int or float) values. Each list element\n          is treated as a distinct feature in the model.\n\n        - *Dict*: dictionary of keys mapped to numeric values. Each unique key\n          is treated as a distinct feature in the model.\n\n        Note that columns of type *list* are not supported. Convert them to\n        array columns if all entries in the list are of numeric types.\n\n    label : str, optional\n        Name of the column to use as row labels in the Kmeans output. The\n        values in this column must be integers or strings. If not specified,\n        row numbers are used by default.\n\n    initial_centers : SFrame, optional\n        Initial centers to use when starting the K-means algorithm. If\n        specified, this parameter overrides the *num_clusters* parameter. The\n        'initial_centers' SFrame must contain the same features used in the\n        input 'dataset'.\n\n        If not specified (the default), initial centers are chosen\n        intelligently with the K-means++ algorithm.\n\n    max_iterations : int, optional\n        The maximum number of iterations to run. Prints a warning if the\n        algorithm does not converge after max_iterations iterations. If set to\n        0, the model returns clusters defined by the initial centers and\n        assignments to those centers.\n\n    batch_size : int, optional\n        Number of randomly-chosen data points to use in each iteration. If\n        'None' (the default) or greater than the number of rows in 'dataset',\n        then this parameter is ignored: all rows of `dataset` are used in each\n        iteration and model training terminates once point assignments stop\n        changing or `max_iterations` is reached.\n\n    verbose : bool, optional\n        If True, print model training progress to the screen.\n\n    Returns\n    -------\n    out : KmeansModel\n        A Model object containing a cluster id for each vertex, and the centers\n        of the clusters.\n\n    See Also\n    --------\n    KmeansModel\n\n    Notes\n    -----\n    - Integer features in the 'dataset' or 'initial_centers' inputs are\n      converted internally to float type, and the corresponding features in the\n      output centers are float-typed.\n\n    - It can be important for the K-means model to standardize the features so\n      they have the same scale. This function does *not* standardize\n      automatically.\n\n    References\n    ----------\n    - `Wikipedia - k-means clustering\n      <http://en.wikipedia.org/wiki/K-means_clustering>`_\n\n    - Artuhur, D. and Vassilvitskii, S. (2007) `k-means++: The Advantages of\n      Careful Seeding <http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf>`_. In\n      Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete\n      Algorithms. pp. 1027-1035.\n\n    - Elkan, C. (2003) `Using the triangle inequality to accelerate k-means\n      <http://www.aaai.org/Papers/ICML/2003/ICML03-022.pdf>`_. In Proceedings\n      of the Twentieth International Conference on Machine Learning, Volume 3,\n      pp. 147-153.\n\n    - Sculley, D. (2010) `Web Scale K-Means Clustering\n      <http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf>`_. In\n      Proceedings of the 19th International Conference on World Wide Web. pp.\n      1177-1178\n\n    Examples\n    --------\n    >>> sf = turicreate.SFrame({\n    ...     'x1': [0.6777, -9.391, 7.0385, 2.2657, 7.7864, -10.16, -8.162,\n    ...            8.8817, -9.525, -9.153, 2.0860, 7.6619, 6.5511, 2.7020],\n    ...     'x2': [5.6110, 8.5139, 5.3913, 5.4743, 8.3606, 7.8843, 2.7305,\n    ...            5.1679, 6.7231, 3.7051, 1.7682, 7.4608, 3.1270, 6.5624]})\n    ...\n    >>> model = turicreate.kmeans.create(sf, num_clusters=3)\n    \"\"\"\n    opts = {'model_name': 'kmeans',\n            'max_iterations': max_iterations,\n            }\n\n    ## Validate the input dataset and initial centers.\n    _validate_dataset(dataset)\n\n    if initial_centers is not None:\n        _validate_initial_centers(initial_centers)\n\n    ## Validate and determine the correct number of clusters.\n    opts['num_clusters'] = _validate_num_clusters(num_clusters,\n                                                  initial_centers,\n                                                  dataset.num_rows())\n\n    ## Validate the row label\n    col_type_map = {c: dataset[c].dtype for c in dataset.column_names()}\n\n    if label is not None:\n        _validate_row_label(label, col_type_map)\n\n        if label in ['cluster_id', 'distance']:\n            raise ValueError(\"Row label column name cannot be 'cluster_id' \" +\n                             \"or 'distance'; these are reserved for other \" +\n                             \"columns in the Kmeans model's output.\")\n\n        opts['row_labels'] = dataset[label]\n        opts['row_label_name'] = label\n\n    else:\n        opts['row_labels'] = _tc.SArray.from_sequence(dataset.num_rows())\n        opts['row_label_name'] = 'row_id'\n\n\n    ## Validate the features relative to the input dataset.\n    if features is None:\n        features = dataset.column_names()\n\n    valid_features = _validate_features(features, col_type_map,\n                                        valid_types=[_array, dict, int, float],\n                                        label=label)\n\n    sf_features = dataset.select_columns(valid_features)\n    opts['features'] = sf_features\n\n    ## Validate the features in the initial centers (if provided)\n    if initial_centers is not None:\n        try:\n            initial_centers = initial_centers.select_columns(valid_features)\n        except:\n            raise ValueError(\"Specified features cannot be extracted from \" +\n                             \"the provided initial centers.\")\n\n        if initial_centers.column_types() != sf_features.column_types():\n            raise TypeError(\"Feature types are different in the dataset and \" +\n                            \"initial centers.\")\n\n    else:\n        initial_centers = _tc.SFrame()\n\n    opts['initial_centers'] = initial_centers\n\n    ## Validate the batch size and determine the training method.\n    if batch_size is None:\n        opts['method'] = 'elkan'\n        opts['batch_size'] = dataset.num_rows()\n\n    else:\n        opts['method'] = 'minibatch'\n        opts['batch_size'] = batch_size\n\n    ## Create and return the model\n    with _QuietProgress(verbose):\n        params = _tc.extensions._kmeans.train(opts)\n\n    return KmeansModel(params['model'])", "response": "Creates a K - Means model object for the given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, dataset, output_type='cluster_id', verbose=True):\n\n        ## Validate the input dataset.\n        _tkutl._raise_error_if_not_sframe(dataset, \"dataset\")\n        _tkutl._raise_error_if_sframe_empty(dataset, \"dataset\")\n\n        ## Validate the output type.\n        if not isinstance(output_type, str):\n            raise TypeError(\"The 'output_type' parameter must be a string.\")\n\n        if not output_type in ('cluster_id', 'distance'):\n            raise ValueError(\"The 'output_type' parameter must be either \" +\n                             \"'cluster_label' or 'distance'.\")\n\n        ## Get model features.\n        ref_features = self.features\n        sf_features = _tkutl._toolkits_select_columns(dataset, ref_features)\n\n        ## Compute predictions.\n        opts = {'model': self.__proxy__,\n                'model_name': self.__name__,\n                'dataset': sf_features}\n\n        with _QuietProgress(verbose):\n            result = _tc.extensions._kmeans.predict(opts)\n\n        sf_result = result['predictions']\n\n        if output_type == 'distance':\n            return sf_result['distance']\n        else:\n            return sf_result['cluster_id']", "response": "Predict the cluster label for instances in the new dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the value of a given field from the model.", "response": "def _get(self, field):\n        \"\"\"\n        Return the value of a given field.\n\n        +-----------------------+----------------------------------------------+\n        |      Field            | Description                                  |\n        +=======================+==============================================+\n        | batch_size            | Number of randomly chosen examples to use in |\n        |                       | each training iteration.                     |\n        +-----------------------+----------------------------------------------+\n        | cluster_id            | Cluster assignment for each data point and   |\n        |                       | Euclidean distance to the cluster center     |\n        +-----------------------+----------------------------------------------+\n        | cluster_info          | Cluster centers, sum of squared Euclidean    |\n        |                       | distances from each cluster member to the    |\n        |                       | assigned center, and the number of data      |\n        |                       | points belonging to the cluster              |\n        +-----------------------+----------------------------------------------+\n        | features              | Names of feature columns                     |\n        +-----------------------+----------------------------------------------+\n        | max_iterations        | Maximum number of iterations to perform      |\n        +-----------------------+----------------------------------------------+\n        | method                | Algorithm used to train the model.           |\n        +-----------------------+----------------------------------------------+\n        | num_clusters          | Number of clusters                           |\n        +-----------------------+----------------------------------------------+\n        | num_examples          | Number of examples in the dataset            |\n        +-----------------------+----------------------------------------------+\n        | num_features          | Number of feature columns used               |\n        +-----------------------+----------------------------------------------+\n        | num_unpacked_features | Number of features unpacked from the         |\n        |                       | feature columns                              |\n        +-----------------------+----------------------------------------------+\n        | training_iterations   | Total number of iterations performed         |\n        +-----------------------+----------------------------------------------+\n        | training_time         | Total time taken to cluster the data         |\n        +-----------------------+----------------------------------------------+\n        | unpacked_features     | Names of features unpacked from the          |\n        |                       | feature columns                              |\n        +-----------------------+----------------------------------------------+\n\n        Parameters\n        ----------\n        field : str\n            The name of the field to query.\n\n        Returns\n        -------\n        out\n            Value of the requested field\n        \"\"\"\n        opts = {'model': self.__proxy__,\n                'model_name': self.__name__,\n                'field': field}\n        response = _tc.extensions._kmeans.get_value(opts)\n\n        return response['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_words(text, to_lower=True, delimiters=DEFAULT_DELIMITERS):\n\n    _raise_error_if_not_sarray(text, \"text\")\n\n    ## Compute word counts\n    sf = _turicreate.SFrame({'docs': text})\n    fe = _feature_engineering.WordCounter(features='docs',\n                                                   to_lower=to_lower,\n                                                   delimiters=delimiters,\n                                                   output_column_prefix=None)\n    output_sf = fe.fit_transform(sf)\n\n    return output_sf['docs']", "response": "Count the occurrences of words in the input text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the n - grams in the input text.", "response": "def count_ngrams(text, n=2, method=\"word\", to_lower=True,\n                 delimiters=DEFAULT_DELIMITERS,\n                 ignore_punct=True, ignore_space=True):\n    \"\"\"\n    Return an SArray of ``dict`` type where each element contains the count\n    for each of the n-grams that appear in the corresponding input element.\n    The n-grams can be specified to be either character n-grams or word\n    n-grams.  The input SArray could contain strings, dicts with string keys\n    and numeric values, or lists of strings.\n\n    Parameters\n    ----------\n    Text : SArray[str | dict | list]\n        Input text data. \n\n    n : int, optional\n        The number of words in each n-gram. An ``n`` value of 1 returns word\n        counts.\n\n    method : {'word', 'character'}, optional\n        If \"word\", the function performs a count of word n-grams. If\n        \"character\", does a character n-gram count.\n\n    to_lower : bool, optional\n        If True, all words are converted to lower case before counting.\n\n    delimiters : list[str], None, optional\n        If method is \"word\", input strings are tokenized using `delimiters`\n        characters in this list. Each entry in this list must contain a single\n        character. If set to `None`, then a Penn treebank-style tokenization is\n        used, which contains smart handling of punctuations. If method is\n        \"character,\" this option is ignored.\n\n    ignore_punct : bool, optional\n        If method is \"character\", indicates if *punctuations* between words are\n        counted as part of the n-gram. For instance, with the input SArray\n        element of \"fun.games\", if this parameter is set to False one\n        tri-gram would be 'n.g'. If ``ignore_punct`` is set to True, there\n        would be no such tri-gram (there would still be 'nga'). This\n        parameter has no effect if the method is set to \"word\".\n\n    ignore_space : bool, optional\n        If method is \"character\", indicates if *spaces* between words are\n        counted as part of the n-gram. For instance, with the input SArray\n        element of \"fun games\", if this parameter is set to False one\n        tri-gram would be 'n g'. If ``ignore_space`` is set to True, there\n        would be no such tri-gram (there would still be 'nga'). This\n        parameter has no effect if the method is set to \"word\".\n\n    Returns\n    -------\n    out : SArray[dict]\n      An SArray of dictionary type, where each key is the n-gram string\n      and each value is its count.\n\n    See Also\n    --------\n    count_words, tokenize,\n\n    Notes\n    -----\n    - Ignoring case (with ``to_lower``) involves a full string copy of the\n      SArray data. To increase speed for large documents, set ``to_lower`` to\n      False.\n\n    - Punctuation and spaces are both delimiters by default when counting\n      word n-grams. When counting character n-grams, one may choose to ignore\n      punctuations, spaces, neither, or both.\n\n    References\n    ----------\n    - `N-gram wikipedia article <http://en.wikipedia.org/wiki/N-gram>`_\n    - `Penn treebank tokenization <https://web.archive.org/web/19970614072242/http://www.cis.upenn.edu:80/~treebank/tokenization.html>`_\n\n    Examples\n    --------\n    .. sourcecode:: python\n\n        >>> import turicreate\n\n        # Counting word n-grams:\n        >>> sa = turicreate.SArray(['I like big dogs. I LIKE BIG DOGS.'])\n        >>> turicreate.text_analytics.count_ngrams(sa, 3)\n        dtype: dict\n        Rows: 1\n        [{'big dogs i': 1, 'like big dogs': 2, 'dogs i like': 1, 'i like big': 2}]\n\n        # Counting character n-grams:\n        >>> sa = turicreate.SArray(['Fun. Is. Fun'])\n        >>> turicreate.text_analytics.count_ngrams(sa, 3, \"character\")\n        dtype: dict\n        Rows: 1\n        {'fun': 2, 'nis': 1, 'sfu': 1, 'isf': 1, 'uni': 1}]\n\n        # Run count_ngrams with dictionary input\n        >>> sa = turicreate.SArray([{'alice bob': 1, 'Bob alice': 0.5},\n                                    {'a dog': 0, 'a dog cat': 5}])\n        >>> turicreate.text_analytics.count_ngrams(sa)\n        dtype: dict\n        Rows: 2\n        [{'bob alice': 0.5, 'alice bob': 1}, {'dog cat': 5, 'a dog': 5}]\n\n        # Run count_ngrams with list input\n        >>> sa = turicreate.SArray([['one', 'bar bah'], ['a dog', 'a dog cat']])\n        >>> turicreate.text_analytics.count_ngrams(sa)\n        dtype: dict\n        Rows: 2\n        [{'bar bah': 1}, {'dog cat': 1, 'a dog': 2}]\n    \"\"\"\n\n    _raise_error_if_not_sarray(text, \"text\")\n\n    # Compute ngrams counts\n    sf = _turicreate.SFrame({'docs': text})\n    fe = _feature_engineering.NGramCounter(features='docs',\n                                                    n=n,\n                                                    method=method,\n                                                    to_lower=to_lower,\n                                                    delimiters=delimiters,\n                                                    ignore_punct=ignore_punct,\n                                                    ignore_space=ignore_space,\n                                                    output_column_prefix=None)\n    output_sf = fe.fit_transform(sf)\n\n    return output_sf['docs']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tf_idf(text):\n    _raise_error_if_not_sarray(text, \"text\")\n\n    if len(text) == 0:\n        return _turicreate.SArray()\n\n    dataset = _turicreate.SFrame({'docs': text})\n    scores = _feature_engineering.TFIDF('docs').fit_transform(dataset)\n\n    return scores['docs']", "response": "Compute the TF - IDF scores for each word in each document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove words that occur below a certain number of times in an SArray. This is a common method of cleaning text before it is used, and can increase the quality and explainability of the models learned on the transformed data. RareWordTrimmer can be applied to all the string-, dictionary-, and list-typed columns in an SArray. * **string** : The string is first tokenized. By default, all letters are first converted to lower case, then tokenized by space characters. Each token is taken to be a word, and the words occurring below a threshold number of times across the entire column are removed, then the remaining tokens are concatenated back into a string. * **list** : Each element of the list must be a string, where each element is assumed to be a token. The remaining tokens are then filtered by count occurrences and a threshold value. * **dict** : The method first obtains the list of keys in the dictionary. This list is then processed as a standard list, except the value of each key must be of integer type and is considered to be the count of that key. Parameters ---------- text : SArray[str | dict | list] The input text data. threshold : int, optional The count below which words are removed from the input. stop_words: list[str], optional A manually specified list of stop words, which are removed regardless of count. to_lower : bool, optional Indicates whether to map the input strings to lower case before counting. delimiters: list[string], optional A list of delimiter characters for tokenization. By default, the list is defined to be the list of space characters. The user can define any custom list of single-character delimiters. Alternatively, setting `delimiters=None` will use a Penn treebank type tokenization, which is better at handling punctuations. (See reference below for details.) Returns ------- out : SArray. An SArray with words below a threshold removed. See Also -------- count_ngrams, tf_idf, tokenize, References ---------- - `Penn treebank tokenization <https://web.archive.org/web/19970614072242/http://www.cis.upenn.edu:80/~treebank/tokenization.html>`_ Examples -------- .. sourcecode:: python >>> import turicreate # Create input data >>> sa = turicreate.SArray([\"The quick brown fox jumps in a fox like way.\", \"Word word WORD, word!!!word\"]) # Run drop_words >>> turicreate.text_analytics.drop_words(sa) dtype: str Rows: 2 ['fox fox', 'word word'] # Run drop_words with Penn treebank style tokenization to handle # punctuations >>> turicreate.text_analytics.drop_words(sa, delimiters=None) dtype: str Rows: 2 ['fox fox', 'word word word'] # Run drop_words with dictionary input >>> sa = turicreate.SArray([{'alice bob': 1, 'Bob alice': 2}, {'a dog': 0, 'a dog cat': 5}]) >>> turicreate.text_analytics.drop_words(sa) dtype: dict Rows: 2 [{'bob alice': 2}, {'a dog cat': 5}] # Run drop_words with list input >>> sa = turicreate.SArray([['one', 'bar bah', 'One'], ['a dog', 'a dog cat', 'A DOG']]) >>> turicreate.text_analytics.drop_words(sa) dtype: list Rows: 2 [['one', 'one'], ['a dog', 'a dog']]", "response": "def drop_words(text, threshold=2, to_lower=True, delimiters=DEFAULT_DELIMITERS,\n               stop_words=None):\n    '''\n    Remove words that occur below a certain number of times in an SArray.\n    This is a common method of cleaning text before it is used, and can increase the\n    quality and explainability of the models learned on the transformed data.\n\n    RareWordTrimmer can be applied to all the string-, dictionary-, and list-typed\n    columns in an SArray.\n\n    * **string** : The string is first tokenized. By default, all letters are\n      first converted to lower case, then tokenized by space characters. Each\n      token is taken to be a word, and the words occurring below a threshold\n      number of times across the entire column are removed, then the remaining\n      tokens are concatenated back into a string.\n\n    * **list** : Each element of the list must be a string, where each element\n      is assumed to be a token. The remaining tokens are then filtered\n      by count occurrences and a threshold value.\n\n    * **dict** : The method first obtains the list of keys in the dictionary.\n      This list is then processed as a standard list, except the value of each\n      key must be of integer type and is considered to be the count of that key.\n\n\n    Parameters\n    ----------\n    text : SArray[str | dict | list]\n        The input text data.\n\n    threshold : int, optional\n        The count below which words are removed from the input.\n\n    stop_words: list[str], optional\n        A manually specified list of stop words, which are removed regardless\n        of count.\n\n    to_lower : bool, optional\n        Indicates whether to map the input strings to lower case before counting.\n\n    delimiters: list[string], optional\n        A list of delimiter characters for tokenization. By default, the list\n        is defined to be the list of space characters. The user can define\n        any custom list of single-character delimiters. Alternatively, setting\n        `delimiters=None` will use a Penn treebank type tokenization, which\n        is better at handling punctuations. (See reference below for details.)\n\n    Returns\n    -------\n    out : SArray.\n        An SArray with words below a threshold removed.\n\n    See Also\n    --------\n    count_ngrams, tf_idf, tokenize,\n\n    References\n    ----------\n    - `Penn treebank tokenization <https://web.archive.org/web/19970614072242/http://www.cis.upenn.edu:80/~treebank/tokenization.html>`_\n\n    Examples\n    --------\n    .. sourcecode:: python\n\n        >>> import turicreate\n\n        # Create input data\n        >>> sa = turicreate.SArray([\"The quick brown fox jumps in a fox like way.\",\n                                    \"Word word WORD, word!!!word\"])\n\n        # Run drop_words\n        >>> turicreate.text_analytics.drop_words(sa)\n        dtype: str\n        Rows: 2\n        ['fox fox', 'word word']\n\n        # Run drop_words with Penn treebank style tokenization to handle\n        # punctuations\n        >>> turicreate.text_analytics.drop_words(sa, delimiters=None)\n        dtype: str\n        Rows: 2\n        ['fox fox', 'word word word']\n\n        # Run drop_words with dictionary input\n        >>> sa = turicreate.SArray([{'alice bob': 1, 'Bob alice': 2},\n                                    {'a dog': 0, 'a dog cat': 5}])\n        >>> turicreate.text_analytics.drop_words(sa)\n        dtype: dict\n        Rows: 2\n        [{'bob alice': 2}, {'a dog cat': 5}]\n\n        # Run drop_words with list input\n        >>> sa = turicreate.SArray([['one', 'bar bah', 'One'],\n                                    ['a dog', 'a dog cat', 'A DOG']])\n        >>> turicreate.text_analytics.drop_words(sa)\n        dtype: list\n        Rows: 2\n        [['one', 'one'], ['a dog', 'a dog']]\n    '''\n\n    _raise_error_if_not_sarray(text, \"text\")\n\n    ## Compute word counts\n    sf = _turicreate.SFrame({'docs': text})\n    fe = _feature_engineering.RareWordTrimmer(features='docs',\n                                                 threshold=threshold,\n                                                 to_lower=to_lower,\n                                                 delimiters=delimiters,\n                                                 stopwords=stop_words,\n                                                 output_column_prefix=None)\n    tokens = fe.fit_transform(sf)\n\n    return tokens['docs']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tokenize(text, to_lower=False, delimiters=DEFAULT_DELIMITERS):\n    _raise_error_if_not_sarray(text, \"text\")\n\n    ## Compute word counts\n    sf = _turicreate.SFrame({'docs': text})\n    fe = _feature_engineering.Tokenizer(features='docs',\n                                                 to_lower=to_lower,\n                                                 delimiters=delimiters,\n                                                 output_column_prefix=None)\n    tokens = fe.fit_transform(sf)\n\n    return tokens['docs']", "response": "Tokenize the input SArray of text and return a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the BM25 score for a given query and set of documents.", "response": "def bm25(dataset, query, k1=1.5, b=.75):\n    \"\"\"\n    For a given query and set of documents, compute the BM25 score for each\n    document. If we have a query with words q_1, ..., q_n the BM25 score for\n    a document is:\n\n        .. math:: \\sum_{i=1}^N IDF(q_i)\\\\frac{f(q_i) * (k_1+1)}{f(q_i) + k_1 * (1-b+b*|D|/d_avg))}\n\n    where\n\n    * :math:`\\mbox{IDF}(q_i) = log((N - n(q_i) + .5)/(n(q_i) + .5)`\n    * :math:`f(q_i)` is the number of times q_i occurs in the document\n    * :math:`n(q_i)` is the number of documents containing q_i\n    * :math:`|D|` is the number of words in the document\n    * :math:`d_avg` is the average number of words per document in the corpus\n    * :math:`k_1` and :math:`b` are free parameters.\n\n    Parameters\n    ----------\n    dataset : SArray of type dict, list, or str\n        An SArray where each element either represents a document in:\n\n        * **dict** : a bag-of-words format, where each key is a word and each\n          value is the number of times that word occurs in the document.\n\n        * **list** : The list is converted to bag of words of format, where the\n          keys are the unique elements in the list and the values are the counts\n          of those unique elements. After this step, the behaviour is identical\n          to dict.\n\n        * **string** : Behaves identically to a **dict**, where the dictionary\n          is generated by converting the string into a bag-of-words format.\n          For example, 'I really like really fluffy dogs\" would get converted\n          to {'I' : 1, 'really': 2, 'like': 1, 'fluffy': 1, 'dogs':1}.\n\n    query : A list, set, or SArray of type str\n        A list, set or SArray where each element is a word.\n\n    k1 : float, optional\n        Free parameter which controls the relative importance of term\n        frequencies. Recommended values are [1.2, 2.0].\n\n    b : float, optional\n        Free parameter which controls how much to downweight scores for long\n        documents. Recommended value is 0.75.\n\n    Returns\n    -------\n    out : SFrame\n        An SFrame containing the BM25 score for each document containing one of\n        the query words. The doc_id column is the row number of the document.\n\n    Examples\n    --------\n    .. sourcecode:: python\n\n        >>> import turicreate\n\n        >>> dataset = turicreate.SArray([\n          {'a':5, 'b':7, 'c':10},\n          {'a':3, 'c':1, 'd':2},\n          {'a':10, 'b':3, 'e':5},\n          {'a':1},\n          {'f':5}])\n\n        >>> query = ['a', 'b', 'c']\n        >>> turicreate.text_analytics.bm25(dataset, query)\n\n\n    References\n    ----------\n    .. [BM25] `\"Okapi BM-25\" <http://en.wikipedia.org/wiki/Okapi_BM25>`_\n    \"\"\"\n\n    if type(dataset) != _turicreate.SArray:\n        raise TypeError('bm25 requires an SArray of dict, list, or str type'+\\\n            ', where each dictionary whose keys are words and whose values' + \\\n            ' are word frequency.')\n    sf = _SFrame({'docs' : dataset})\n\n    if type(query) is dict:  # For backwards compatibility\n        query = list(query.keys())\n    if type(query) is _turicreate.SArray:\n        query = list(query)\n    if type(query) is set:\n        query = list(query)\n    if type(query) is not list:\n        raise TypeError('The query must either be an SArray of str type, '+\\\n           ' a list of strings, or a set of strings.')\n\n    # Calculate BM25\n    sf = sf.add_row_number('doc_id')\n    sf = sf.dropna('docs') # Drop missing documents\n    scores = _feature_engineering.BM25('docs',query, k1, b, output_column_name = 'bm25').fit_transform(sf)\n\n    # Find documents with query words\n\n    if scores['docs'].dtype is dict:\n        scores['doc_terms'] = scores['docs'].dict_keys()\n    elif scores['docs'].dtype is list:\n        scores['doc_terms'] = scores['docs'].apply(lambda x: list(set(x)))\n    elif scores['docs'].dtype is str:\n        scores['doc_terms'] = count_words(scores['docs']).dict_keys()\n    else:\n        # This should never occur (handled by BM25)\n        raise TypeError('bm25 requires an SArray of dict, list, or str type')\n    scores['doc_counts'] = scores['doc_terms'].apply(lambda x: len([word for word in query if word in x]))\n    scores = scores[scores['doc_counts'] > 0] # Drop documents without query word\n    scores = scores.select_columns(['doc_id','bm25'])\n\n    return scores"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a file that s in libSVM format.", "response": "def parse_sparse(filename, vocab_filename):\n    \"\"\"\n    Parse a file that's in libSVM format. In libSVM format each line of the text\n    file represents a document in bag of words format:\n\n    num_unique_words_in_doc word_id:count another_id:count\n\n    The word_ids have 0-based indexing, i.e. 0 corresponds to the first\n    word in the vocab filename.\n\n    Parameters\n    ----------\n    filename : str\n        The name of the file to parse.\n\n    vocab_filename : str\n        A list of words that are used for this data set.\n\n    Returns\n    -------\n    out : SArray\n        Each element represents a document in bag-of-words format.\n\n    Examples\n    --------\n    If we have two documents:\n    1. \"It was the best of times, it was the worst of times\"\n    2. \"It was the age of wisdom, it was the age of foolishness\"\n\n    Then the vocabulary file might contain the unique words, with a word\n    on each line, in the following order:\n    it, was, the, best, of, times, worst, age, wisdom, foolishness\n\n    In this case, the file in libSVM format would have two lines:\n    7 0:2 1:2 2:2 3:1 4:2 5:1 6:1\n    7 0:2 1:2 2:2 7:2 8:1 9:1 10:1\n\n    The following command will parse the above two files into an SArray\n    of type dict.\n\n    >>> file = 'https://static.turi.com/datasets/text/ap.dat'\n    >>> vocab = 'https://static.turi.com/datasets/text/ap.vocab.txt'\n    >>> docs = turicreate.text_analytics.parse_sparse(file, vocab)\n    \"\"\"\n    vocab = _turicreate.SFrame.read_csv(vocab_filename, header=None)['X1']\n    vocab = list(vocab)\n\n    docs = _turicreate.SFrame.read_csv(filename, header=None)\n\n    # Remove first word\n    docs = docs['X1'].apply(lambda x: x.split(' ')[1:])\n\n    # Helper function that checks whether we get too large a word id\n    def get_word(word_id):\n        assert int(word_id) < len(vocab), \\\n                \"Text data contains integers that are larger than the \\\n                 size of the provided vocabulary.\"\n        return vocab[word_id]\n\n    def make_dict(pairs):\n        pairs = [z.split(':') for z in pairs]\n        ret = {}\n        for k, v in pairs:\n            ret[get_word(int(k))] = int(v)\n        return ret\n\n    # Split word_id and count and make into a dictionary\n    docs = docs.apply(lambda x: make_dict(x))\n\n    return docs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_docword(filename, vocab_filename):\n    vocab = _turicreate.SFrame.read_csv(vocab_filename, header=None)['X1']\n    vocab = list(vocab)\n\n    sf = _turicreate.SFrame.read_csv(filename, header=False)\n    sf = sf[3:]\n    sf['X2'] = sf['X1'].apply(lambda x: [int(z) for z in x.split(' ')])\n    del sf['X1']\n    sf = sf.unpack('X2', column_name_prefix='', column_types=[int,int,int])\n    docs = sf.unstack(['1', '2'], 'bow').sort('0')['bow']\n    docs = docs.apply(lambda x: {vocab[k-1]:v for (k, v) in six.iteritems(x)})\n\n    return docs", "response": "Parse a file that s in docword format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_split(dataset, prob=.5):\n\n    def grab_values(x, train=True):\n        if train:\n            ix = 0\n        else:\n            ix = 1\n        return dict([(key, value[ix]) for key, value in six.iteritems(x) \\\n                    if value[ix] != 0])\n\n    def word_count_split(n, p):\n        num_in_test = 0\n        for i in range(n):\n            if random.random() < p:\n                num_in_test += 1\n        return [n - num_in_test, num_in_test]\n\n    # Get an SArray where each word has a 2 element list containing\n    # the count that will be for the training set and the count that will\n    # be assigned to the test set.\n    data = dataset.apply(lambda x: dict([(key, word_count_split(int(value), prob)) \\\n                                for key, value in six.iteritems(x)]))\n\n    # Materialize the data set\n    data.__materialize__()\n\n    # Grab respective counts for each data set\n    train = data.apply(lambda x: grab_values(x, train=True))\n    test  = data.apply(lambda x: grab_values(x, train=False))\n\n    return train, test", "response": "Utility for performing a random split for text data that is already in the bag - of - words format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef train(params, dtrain, num_boost_round=10, evals=(), obj=None, feval=None,\n          maximize=False, early_stopping_rounds=None, evals_result=None,\n          verbose_eval=True, learning_rates=None, xgb_model=None):\n    # pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\n    \"\"\"Train a booster with given parameters.\n\n    Parameters\n    ----------\n    params : dict\n        Booster params.\n    dtrain : DMatrix\n        Data to be trained.\n    num_boost_round: int\n        Number of boosting iterations.\n    watchlist (evals): list of pairs (DMatrix, string)\n        List of items to be evaluated during training, this allows user to watch\n        performance on the validation set.\n    obj : function\n        Customized objective function.\n    feval : function\n        Customized evaluation function.\n    maximize : bool\n        Whether to maximize feval.\n    early_stopping_rounds: int\n        Activates early stopping. Validation error needs to decrease at least\n        every <early_stopping_rounds> round(s) to continue training.\n        Requires at least one item in evals.\n        If there's more than one, will use the last.\n        Returns the model from the last iteration (not the best one).\n        If early stopping occurs, the model will have two additional fields:\n        bst.best_score and bst.best_iteration.\n    evals_result: dict\n        This dictionary stores the evaluation results of all the items in watchlist.\n        Example: with a watchlist containing [(dtest,'eval'), (dtrain,'train')] and\n        and a paramater containing ('eval_metric', 'logloss')\n        Returns: {'train': {'logloss': ['0.48253', '0.35953']},\n                  'eval': {'logloss': ['0.480385', '0.357756']}}\n    verbose_eval : bool\n        If `verbose_eval` then the evaluation metric on the validation set, if\n        given, is printed at each boosting stage.\n    learning_rates: list or function\n        Learning rate for each boosting round (yields learning rate decay).\n        - list l: eta = l[boosting round]\n        - function f: eta = f(boosting round, num_boost_round)\n    xgb_model : file name of stored xgb model or 'Booster' instance\n        Xgb model to be loaded before training (allows training continuation).\n\n    Returns\n    -------\n    booster : a trained booster model\n    \"\"\"\n    evals = list(evals)\n    ntrees = 0\n    if xgb_model is not None:\n        if not isinstance(xgb_model, STRING_TYPES):\n            xgb_model = xgb_model.save_raw()\n        bst = Booster(params, [dtrain] + [d[0] for d in evals], model_file=xgb_model)\n        ntrees = len(bst.get_dump())\n    else:\n        bst = Booster(params, [dtrain] + [d[0] for d in evals])\n\n\n    if evals_result is not None:\n        if not isinstance(evals_result, dict):\n            raise TypeError('evals_result has to be a dictionary')\n        else:\n            evals_name = [d[1] for d in evals]\n            evals_result.clear()\n            evals_result.update({key: {} for key in evals_name})\n\n    if not early_stopping_rounds:\n        for i in range(num_boost_round):\n            bst.update(dtrain, i, obj)\n            ntrees += 1\n            if len(evals) != 0:\n                bst_eval_set = bst.eval_set(evals, i, feval)\n                if isinstance(bst_eval_set, STRING_TYPES):\n                    msg = bst_eval_set\n                else:\n                    msg = bst_eval_set.decode()\n\n                if verbose_eval:\n                    sys.stderr.write(msg + '\\n')\n                if evals_result is not None:\n                    res = re.findall(\"([0-9a-zA-Z@]+[-]*):-?([0-9.]+).\", msg)\n                    for key in evals_name:\n                        evals_idx = evals_name.index(key)\n                        res_per_eval = len(res) // len(evals_name)\n                        for r in range(res_per_eval):\n                            res_item = res[(evals_idx*res_per_eval) + r]\n                            res_key = res_item[0]\n                            res_val = res_item[1]\n                            if res_key in evals_result[key]:\n                                evals_result[key][res_key].append(res_val)\n                            else:\n                                evals_result[key][res_key] = [res_val]\n        bst.best_iteration = (ntrees - 1)\n        return bst\n\n    else:\n        # early stopping\n        if len(evals) < 1:\n            raise ValueError('For early stopping you need at least one set in evals.')\n\n        if verbose_eval:\n            sys.stderr.write(\"Will train until {} error hasn't decreased in {} rounds.\\n\".format(\\\n                evals[-1][1], early_stopping_rounds))\n\n        # is params a list of tuples? are we using multiple eval metrics?\n        if isinstance(params, list):\n            if len(params) != len(dict(params).items()):\n                raise ValueError('Check your params.'\\\n                                     'Early stopping works with single eval metric only.')\n            params = dict(params)\n\n        # either minimize loss or maximize AUC/MAP/NDCG\n        maximize_score = False\n        if 'eval_metric' in params:\n            maximize_metrics = ('auc', 'map', 'ndcg')\n            if any(params['eval_metric'].startswith(x) for x in maximize_metrics):\n                maximize_score = True\n        if feval is not None:\n            maximize_score = maximize\n\n        if maximize_score:\n            best_score = 0.0\n        else:\n            best_score = float('inf')\n\n        best_msg = ''\n        best_score_i = ntrees\n\n        if isinstance(learning_rates, list) and len(learning_rates) != num_boost_round:\n            raise ValueError(\"Length of list 'learning_rates' has to equal 'num_boost_round'.\")\n\n        for i in range(num_boost_round):\n            if learning_rates is not None:\n                if isinstance(learning_rates, list):\n                    bst.set_param({'eta': learning_rates[i]})\n                else:\n                    bst.set_param({'eta': learning_rates(i, num_boost_round)})\n            bst.update(dtrain, i, obj)\n            ntrees += 1\n            bst_eval_set = bst.eval_set(evals, i, feval)\n\n            if isinstance(bst_eval_set, STRING_TYPES):\n                msg = bst_eval_set\n            else:\n                msg = bst_eval_set.decode()\n\n            if verbose_eval:\n                sys.stderr.write(msg + '\\n')\n\n            if evals_result is not None:\n                res = re.findall(\"([0-9a-zA-Z@]+[-]*):-?([0-9.]+).\", msg)\n                for key in evals_name:\n                    evals_idx = evals_name.index(key)\n                    res_per_eval = len(res) // len(evals_name)\n                    for r in range(res_per_eval):\n                        res_item = res[(evals_idx*res_per_eval) + r]\n                        res_key = res_item[0]\n                        res_val = res_item[1]\n                        if res_key in evals_result[key]:\n                            evals_result[key][res_key].append(res_val)\n                        else:\n                            evals_result[key][res_key] = [res_val]\n\n            score = float(msg.rsplit(':', 1)[1])\n            if (maximize_score and score > best_score) or \\\n                    (not maximize_score and score < best_score):\n                best_score = score\n                best_score_i = (ntrees - 1)\n                best_msg = msg\n            elif i - best_score_i >= early_stopping_rounds:\n                sys.stderr.write(\"Stopping. Best iteration:\\n{}\\n\\n\".format(best_msg))\n                bst.best_score = best_score\n                bst.best_iteration = best_score_i\n                break\n        bst.best_score = best_score\n        bst.best_iteration = best_score_i\n        return bst", "response": "Train a booster with given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mknfold(dall, nfold, param, seed, evals=(), fpreproc=None):\n    evals = list(evals)\n    np.random.seed(seed)\n    randidx = np.random.permutation(dall.num_row())\n    kstep = len(randidx) / nfold\n    idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n    ret = []\n    for k in range(nfold):\n        dtrain = dall.slice(np.concatenate([idset[i] for i in range(nfold) if k != i]))\n        dtest = dall.slice(idset[k])\n        # run preprocessing on the data set if needed\n        if fpreproc is not None:\n            dtrain, dtest, tparam = fpreproc(dtrain, dtest, param.copy())\n        else:\n            tparam = param\n        plst = list(tparam.items()) + [('eval_metric', itm) for itm in evals]\n        ret.append(CVPack(dtrain, dtest, plst))\n    return ret", "response": "Make an n - fold list of CVPacks from random indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aggcv(rlist, show_stdv=True, show_progress=None, as_pandas=True):\n    # pylint: disable=invalid-name\n    \"\"\"\n    Aggregate cross-validation results.\n    \"\"\"\n    cvmap = {}\n    idx = rlist[0].split()[0]\n    for line in rlist:\n        arr = line.split()\n        assert idx == arr[0]\n        for it in arr[1:]:\n            if not isinstance(it, STRING_TYPES):\n                it = it.decode()\n            k, v = it.split(':')\n            if k not in cvmap:\n                cvmap[k] = []\n            cvmap[k].append(float(v))\n\n    msg = idx\n\n    if show_stdv:\n        fmt = '\\tcv-{0}:{1}+{2}'\n    else:\n        fmt = '\\tcv-{0}:{1}'\n\n    index = []\n    results = []\n    for k, v in sorted(cvmap.items(), key=lambda x: x[0]):\n        v = np.array(v)\n        if not isinstance(msg, STRING_TYPES):\n            msg = msg.decode()\n        mean, std = np.mean(v), np.std(v)\n        msg += fmt.format(k, mean, std)\n\n        index.extend([k + '-mean', k + '-std'])\n        results.extend([mean, std])\n\n\n\n    if as_pandas:\n        try:\n            import pandas as pd\n            results = pd.Series(results, index=index)\n        except ImportError:\n            if show_progress is None:\n                show_progress = True\n    else:\n        # if show_progress is default (None),\n        # result will be np.ndarray as it can't hold column name\n        if show_progress is None:\n            show_progress = True\n\n    if show_progress:\n        sys.stderr.write(msg + '\\n')\n\n    return results", "response": "Aggregate cross - validation results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncross - validation with given paramaters.", "response": "def cv(params, dtrain, num_boost_round=10, nfold=3, metrics=(),\n       obj=None, feval=None, fpreproc=None, as_pandas=True,\n       show_progress=None, show_stdv=True, seed=0):\n    # pylint: disable = invalid-name\n    \"\"\"Cross-validation with given paramaters.\n\n    Parameters\n    ----------\n    params : dict\n        Booster params.\n    dtrain : DMatrix\n        Data to be trained.\n    num_boost_round : int\n        Number of boosting iterations.\n    nfold : int\n        Number of folds in CV.\n    metrics : list of strings\n        Evaluation metrics to be watched in CV.\n    obj : function\n        Custom objective function.\n    feval : function\n        Custom evaluation function.\n    fpreproc : function\n        Preprocessing function that takes (dtrain, dtest, param) and returns\n        transformed versions of those.\n    as_pandas : bool, default True\n        Return pd.DataFrame when pandas is installed.\n        If False or pandas is not installed, return np.ndarray\n    show_progress : bool or None, default None\n        Whether to display the progress. If None, progress will be displayed\n        when np.ndarray is returned.\n    show_stdv : bool, default True\n        Whether to display the standard deviation in progress.\n        Results are not affected, and always contains std.\n    seed : int\n        Seed used to generate the folds (passed to numpy.random.seed).\n\n    Returns\n    -------\n    evaluation history : list(string)\n    \"\"\"\n    results = []\n    cvfolds = mknfold(dtrain, nfold, params, seed, metrics, fpreproc)\n    for i in range(num_boost_round):\n        for fold in cvfolds:\n            fold.update(i, obj)\n        res = aggcv([f.eval(i, feval) for f in cvfolds],\n                    show_stdv=show_stdv, show_progress=show_progress,\n                    as_pandas=as_pandas)\n        results.append(res)\n\n    if as_pandas:\n        try:\n            import pandas as pd\n            results = pd.DataFrame(results)\n        except ImportError:\n            results = np.array(results)\n    else:\n        results = np.array(results)\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(dataset, target, feature=None, model = 'resnet-50',\n    l2_penalty=0.01, \n    l1_penalty=0.0,\n    solver='auto', feature_rescaling=True,\n    convergence_threshold = _DEFAULT_SOLVER_OPTIONS['convergence_threshold'],\n    step_size = _DEFAULT_SOLVER_OPTIONS['step_size'],\n    lbfgs_memory_level = _DEFAULT_SOLVER_OPTIONS['lbfgs_memory_level'],\n    max_iterations = _DEFAULT_SOLVER_OPTIONS['max_iterations'],\n    class_weights = None,\n    validation_set = 'auto',\n    verbose=True,\n    seed=None,\n    batch_size=64):\n\n    \"\"\"\n    Create a :class:`ImageClassifier` model.\n\n    Parameters\n    ----------\n    dataset : SFrame\n        Input data. The column named by the 'feature' parameter will be\n        extracted for modeling.\n\n    target : string, or int\n        Name of the column containing the target variable. The values in this\n        column must be of string or integer type. String target variables are\n        automatically mapped to integers in the order in which they are provided.\n        For example, a target variable with 'cat' and 'dog' as possible\n        values is mapped to 0 and 1 respectively with 0 being the base class\n        and 1 being the reference class. Use `model.classes` to retrieve\n        the order in which the classes are mapped.\n\n    feature : string, optional\n        indicates that the SFrame has only column of Image type and that will\n        Name of the column containing the input images. 'None' (the default)\n        indicates the only image column in `dataset` should be used as the\n        feature.\n        \n    l2_penalty : float, optional\n        Weight on l2 regularization of the model. The larger this weight, the\n        more the model coefficients shrink toward 0. This introduces bias into\n        the model but decreases variance, potentially leading to better\n        predictions. The default value is 0.01; setting this parameter to 0\n        corresponds to unregularized logistic regression. See the ridge\n        regression reference for more detail.\n\n    l1_penalty : float, optional\n        Weight on l1 regularization of the model. Like the l2 penalty, the\n        higher the l1 penalty, the more the estimated coefficients shrink toward\n        0. The l1 penalty, however, completely zeros out sufficiently small\n        coefficients, automatically indicating features that are not useful\n        for the model. The default weight of 0 prevents any features from\n        being discarded. See the LASSO regression reference for more detail.\n\n    solver : string, optional\n        Name of the solver to be used to solve the regression. See the\n        references for more detail on each solver. Available solvers are:\n\n        - *auto (default)*: automatically chooses the best solver for the data\n          and model parameters.\n        - *newton*: Newton-Raphson\n        - *lbfgs*: limited memory BFGS\n        - *fista*: accelerated gradient descent\n\n        For this model, the Newton-Raphson method is equivalent to the\n        iteratively re-weighted least squares algorithm. If the l1_penalty is\n        greater than 0, use the 'fista' solver.\n\n        The model is trained using a carefully engineered collection of methods\n        that are automatically picked based on the input data. The ``newton``\n        method  works best for datasets with plenty of examples and few features\n        (long datasets). Limited memory BFGS (``lbfgs``) is a robust solver for\n        wide datasets (i.e datasets with many coefficients).  ``fista`` is the\n        default solver for l1-regularized linear regression. The solvers are all\n        automatically tuned and the default options should function well. See\n        the solver options guide for setting additional parameters for each of\n        the solvers.\n\n        See the user guide for additional details on how the solver is chosen.\n        (see `here\n        <https://apple.github.io/turicreate/docs/userguide/supervised-learning/linear-regression.html>`_)\n\n    feature_rescaling : boolean, optional\n        Feature rescaling is an important pre-processing step that ensures that\n        all features are on the same scale. An l2-norm rescaling is performed\n        to make sure that all features are of the same norm. Categorical\n        features are also rescaled by rescaling the dummy variables that are\n        used to represent them. The coefficients are returned in original scale\n        of the problem. This process is particularly useful when features\n        vary widely in their ranges.\n\n    convergence_threshold : float, optional\n        Convergence is tested using variation in the training objective. The\n        variation in the training objective is calculated using the difference\n        between the objective values between two steps. Consider reducing this\n        below the default value (0.01) for a more accurately trained model.\n        Beware of overfitting (i.e a model that works well only on the training\n        data) if this parameter is set to a very low value.\n\n    lbfgs_memory_level : float, optional\n        The L-BFGS algorithm keeps track of gradient information from the\n        previous ``lbfgs_memory_level`` iterations. The storage requirement for\n        each of these gradients is the ``num_coefficients`` in the problem.\n        Increasing the ``lbfgs_memory_level ``can help improve the quality of\n        the model trained. Setting this to more than ``max_iterations`` has the\n        same effect as setting it to ``max_iterations``.\n\n    model : string optional\n        Uses a pretrained model to bootstrap an image classifier:\n\n           - \"resnet-50\" : Uses a pretrained resnet model.\n                           Exported Core ML model will be ~90M.\n\n           - \"squeezenet_v1.1\" : Uses a pretrained squeezenet model.\n                                 Exported Core ML model will be ~4.7M.\n\n           - \"VisionFeaturePrint_Scene\": Uses an OS internal feature extractor.\n                                          Only on available on iOS 12.0+,\n                                          macOS 10.14+ and tvOS 12.0+.\n                                          Exported Core ML model will be ~41K.\n\n        Models are downloaded from the internet if not available locally. Once\n        downloaded, the models are cached for future use.\n        \n    step_size : float, optional\n        The starting step size to use for the ``fista`` solver. The default is\n        set to 1.0, this is an aggressive setting. If the first iteration takes\n        a considerable amount of time, reducing this parameter may speed up\n        model training.\n\n    class_weights : {dict, `auto`}, optional\n        Weights the examples in the training data according to the given class\n        weights. If set to `None`, all classes are supposed to have weight one. The\n        `auto` mode set the class weight to be inversely proportional to number of\n        examples in the training data with the given class.\n\n    validation_set : SFrame, optional\n        A dataset for monitoring the model's generalization performance.\n        The format of this SFrame must be the same as the training set.\n        By default this argument is set to 'auto' and a validation set is\n        automatically sampled and used for progress printing. If\n        validation_set is set to None, then no additional metrics\n        are computed. The default value is 'auto'.\n\n    max_iterations : int, optional\n        The maximum number of allowed passes through the data. More passes over\n        the data can result in a more accurately trained model. Consider\n        increasing this (the default value is 10) if the training accuracy is\n        low and the *Grad-Norm* in the display is large.\n\n    verbose : bool, optional\n        If True, prints progress updates and model details.\n\n    seed : int, optional\n        Seed for random number generation. Set this value to ensure that the\n        same model is created every time.\n\n    batch_size : int, optional\n        If you are getting memory errors, try decreasing this value. If you\n        have a powerful computer, increasing this value may improve performance.\n\n    Returns\n    -------\n    out : ImageClassifier\n        A trained :class:`ImageClassifier` model.\n\n    Examples\n    --------\n    .. sourcecode:: python\n\n        >>> model = turicreate.image_classifier.create(data, target='is_expensive')\n\n        # Make predictions (in various forms)\n        >>> predictions = model.predict(data)      # predictions\n        >>> predictions = model.classify(data)     # predictions with confidence\n        >>> predictions = model.predict_topk(data) # Top-5 predictions (multiclass)\n\n        # Evaluate the model with ground truth data\n        >>> results = model.evaluate(data)\n\n    See Also\n    --------\n    ImageClassifier\n    \"\"\"\n    start_time = _time.time()\n\n    # Check model parameter\n    allowed_models = list(_pre_trained_models.MODELS.keys())\n    if _mac_ver() >= (10,14):\n        allowed_models.append('VisionFeaturePrint_Scene')\n\n        # Also, to make sure existing code doesn't break, replace incorrect name\n        # with the correct name version\n        if model == \"VisionFeaturePrint_Screen\":\n            print(\"WARNING: Correct spelling of model name is VisionFeaturePrint_Scene; VisionFeaturePrint_Screen will be removed in subsequent versions.\")\n            model = \"VisionFeaturePrint_Scene\"\n\n    _tkutl._check_categorical_option_type('model', model, allowed_models)\n\n    # Check dataset parameter\n    if len(dataset) == 0:\n        raise _ToolkitError('Unable to train on empty dataset')\n    if (feature is not None) and (feature not in dataset.column_names()):\n        raise _ToolkitError(\"Image feature column '%s' does not exist\" % feature)\n    if target not in dataset.column_names():\n        raise _ToolkitError(\"Target column '%s' does not exist\" % target)\n\n    if(batch_size < 1):\n        raise ValueError(\"'batch_size' must be greater than or equal to 1\")\n\n    if not (isinstance(validation_set, _tc.SFrame) or validation_set == 'auto' or validation_set is None):\n        raise TypeError(\"Unrecognized value for 'validation_set'.\")\n\n    if feature is None:\n        feature = _tkutl._find_only_image_column(dataset)\n\n    feature_extractor = _image_feature_extractor._create_feature_extractor(model)\n\n    # Extract features\n    extracted_features = _tc.SFrame({\n        target: dataset[target],\n        '__image_features__': feature_extractor.extract_features(dataset, feature, verbose=verbose, batch_size=batch_size),\n        })\n    if isinstance(validation_set, _tc.SFrame):\n        extracted_features_validation = _tc.SFrame({\n            target: validation_set[target],\n            '__image_features__': feature_extractor.extract_features(validation_set, feature, verbose=verbose, batch_size=batch_size),\n        })\n    else:\n        extracted_features_validation = validation_set\n\n    # Train a classifier using the extracted features\n    extracted_features[target] = dataset[target]\n    lr_model = _tc.logistic_classifier.create(extracted_features,\n                                              features=['__image_features__'],\n                                              target=target,\n                                              max_iterations=max_iterations,\n                                              validation_set=extracted_features_validation,\n                                              seed=seed,\n                                              verbose=verbose, l2_penalty=l2_penalty, l1_penalty=l1_penalty,\n                                              solver=solver, feature_rescaling=feature_rescaling,\n                                              convergence_threshold=convergence_threshold, \n                                              step_size=step_size,\n                                              lbfgs_memory_level=lbfgs_memory_level,\n                                              class_weights=class_weights)\n    \n\n    # set input image shape\n    if model in _pre_trained_models.MODELS:\n        input_image_shape = _pre_trained_models.MODELS[model].input_image_shape\n    else:    # model == VisionFeaturePrint_Scene\n        input_image_shape = (3, 299, 299)\n\n    # Save the model\n    state = {\n        'classifier': lr_model,\n        'model': model,\n        'max_iterations': max_iterations,\n        'feature_extractor': feature_extractor,\n        'input_image_shape': input_image_shape,\n        'target': target,\n        'feature': feature,\n        'num_features': 1,\n        'num_classes': lr_model.num_classes,\n        'classes': lr_model.classes,\n        'num_examples': lr_model.num_examples,\n        'training_time': _time.time() - start_time,\n        'training_loss': lr_model.training_loss,\n    }\n    return ImageClassifier(state)", "response": "Creates a new image classifier model for the specified dataset and target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the state of the current model as a dictionary.", "response": "def _get_native_state(self):\n        \"\"\"\n        Save the model as a dictionary, which can be loaded with the\n        :py:func:`~turicreate.load_model` method.\n        \"\"\"\n        state = self.__proxy__.get_state()\n        state['classifier'] = state['classifier'].__proxy__\n        del state['feature_extractor']\n        del state['classes']\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a previously saved ImageClassifier instance.", "response": "def _load_version(cls, state, version):\n        \"\"\"\n        A function to load a previously saved ImageClassifier\n        instance.\n        \"\"\"\n        _tkutl._model_version_check(version, cls._PYTHON_IMAGE_CLASSIFIER_VERSION)\n        from turicreate.toolkits.classifier.logistic_classifier import LogisticClassifier\n        state['classifier'] = LogisticClassifier(state['classifier'])\n        state['classes'] = state['classifier'].classes\n\n        # Correct models saved with a previous typo\n        if state['model'] == \"VisionFeaturePrint_Screen\":\n            state['model'] = \"VisionFeaturePrint_Scene\"\n \n        # Load pre-trained model & feature extractor\n        model_name = state['model']\n        if model_name == \"VisionFeaturePrint_Scene\" and _mac_ver() < (10,14):\n            raise ToolkitError(\"Can not load model on this operating system. This model uses VisionFeaturePrint_Scene, \"\n                               \"which is only supported on macOS 10.14 and higher.\")\n        state['feature_extractor'] = _image_feature_extractor._create_feature_extractor(model_name)\n        state['input_image_shape'] = tuple([int(i) for i in state['input_image_shape']])\n        return ImageClassifier(state)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict(self, dataset, output_type='class', batch_size=64):\n        if not isinstance(dataset, (_tc.SFrame, _tc.SArray, _tc.Image)):\n            raise TypeError('dataset must be either an SFrame, SArray or turicreate.Image')\n        if(batch_size < 1):\n            raise ValueError(\"'batch_size' must be greater than or equal to 1\")\n\n        dataset, unpack = self._canonize_input(dataset)\n\n        extracted_features = self._extract_features(dataset, batch_size=batch_size)\n        return unpack(self.classifier.predict(extracted_features, output_type=output_type))", "response": "Predict the logistic model of the specified dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npredicting the top - k class of the dataset using the trained model.", "response": "def predict_topk(self, dataset, output_type=\"probability\", k=3, batch_size=64):\n        \"\"\"\n        Return top-k predictions for the ``dataset``, using the trained model.\n        Predictions are returned as an SFrame with three columns: `id`,\n        `class`, and `probability`, `margin`,  or `rank`, depending on the ``output_type``\n        parameter. Input dataset size must be the same as for training of the model.\n\n        Parameters\n        ----------\n        dataset : SFrame | SArray | turicreate.Image\n            Images to be classified.\n            If dataset is an SFrame, it must include columns with the same\n            names as the features used for model training, but does not require\n            a target column. Additional columns are ignored.\n\n        output_type : {'probability', 'rank', 'margin'}, optional\n            Choose the return type of the prediction:\n\n            - `probability`: Probability associated with each label in the prediction.\n            - `rank`       : Rank associated with each label in the prediction.\n            - `margin`     : Margin associated with each label in the prediction.\n\n        k : int, optional\n            Number of classes to return for each input example.\n\n        Returns\n        -------\n        out : SFrame\n            An SFrame with model predictions.\n\n        See Also\n        --------\n        predict, classify, evaluate\n\n        Examples\n        --------\n        >>> pred = m.predict_topk(validation_data, k=3)\n        >>> pred\n        +----+-------+-------------------+\n        | id | class |   probability     |\n        +----+-------+-------------------+\n        | 0  |   4   |   0.995623886585  |\n        | 0  |   9   |  0.0038311756216  |\n        | 0  |   7   | 0.000301006948575 |\n        | 1  |   1   |   0.928708016872  |\n        | 1  |   3   |  0.0440889261663  |\n        | 1  |   2   |  0.0176190119237  |\n        | 2  |   3   |   0.996967732906  |\n        | 2  |   2   |  0.00151345680933 |\n        | 2  |   7   | 0.000637513934635 |\n        | 3  |   1   |   0.998070061207  |\n        | .. |  ...  |        ...        |\n        +----+-------+-------------------+\n        [35688 rows x 3 columns]\n        \"\"\"\n        if not isinstance(dataset, (_tc.SFrame, _tc.SArray, _tc.Image)):\n            raise TypeError('dataset must be either an SFrame, SArray or turicreate.Image')\n        if(batch_size < 1):\n            raise ValueError(\"'batch_size' must be greater than or equal to 1\")\n\n        dataset, _ = self._canonize_input(dataset)\n\n        extracted_features = self._extract_features(dataset)\n        return self.classifier.predict_topk(extracted_features, output_type = output_type, k = k)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self, dataset, metric='auto', verbose=True, batch_size=64):\n\n        import os, json, math\n\n        if(batch_size < 1):\n            raise ValueError(\"'batch_size' must be greater than or equal to 1\")\n\n        extracted_features = self._extract_features(dataset, verbose=verbose, batch_size=batch_size)\n        extracted_features[self.target] = dataset[self.target]\n        \n        metrics = self.classifier.evaluate(extracted_features, metric=metric, with_predictions=True)\n        predictions = metrics[\"predictions\"][\"probs\"]\n        state = self.__proxy__.get_state()\n        labels = state[\"classes\"]\n\n\n        def entropy(probs):\n            return _reduce(lambda x, y: x + (y*math.log(1/y, 2) if y > 0 else 0) , probs, 0) / math.log(len(probs),2)\n\n        def confidence(probs):\n            return max(probs)\n\n        def relative_confidence(probs):\n            lp = len(probs)\n            return probs[lp-1] - probs[lp-2]\n\n        def get_confusion_matrix(extended_test, labels):\n            #Init a matrix\n            sf_confusion_matrix = {'label':[], 'predicted_label':[], 'prob_default':[]}\n            for target_l in labels:\n                for predicted_l in labels:\n                    sf_confusion_matrix['label'].append(target_l)\n                    sf_confusion_matrix['predicted_label'].append(predicted_l)\n                    sf_confusion_matrix['prob_default'].append(0)\n\n            sf_confusion_matrix = _tc.SFrame(sf_confusion_matrix)\n            sf_confusion_matrix = sf_confusion_matrix.join(extended_test.groupby(['label', 'predicted_label'], {'count' :_tc.aggregate.COUNT}), how='left', on=['label','predicted_label'])\n            sf_confusion_matrix = sf_confusion_matrix.fillna('count', 0)\n\n            label_column = _tc.SFrame({'label': extended_test['label']})\n            predictions = extended_test['probs']\n            for i in range(0, len(labels)):\n                new_test_data = label_column.add_columns([predictions.apply(lambda probs: probs[i]), predictions.apply(lambda probs: labels[i])], ['prob','predicted_label'])\n                if (i==0):\n                    test_longer_form = new_test_data\n                else:\n                    test_longer_form = test_longer_form.append(new_test_data)\n\n            if len(extended_test) is 0:\n                sf_confusion_matrix = sf_confusion_matrix.rename({'prob_default': 'prob', 'label': 'target_label'})\n            else:\n                sf_confusion_matrix = sf_confusion_matrix.join(test_longer_form.groupby(['label', 'predicted_label'], {'prob': _tc.aggregate.SUM('prob')}), how='left', on=['label', 'predicted_label'])\n                sf_confusion_matrix = sf_confusion_matrix.rename({'label': 'target_label'}).fillna('prob', 0)\n            \n            def wo_divide_by_zero(a,b):\n                if b==0:\n                    return None\n                else:\n                    return a*1.0/b\n\n            sf_confusion_matrix['norm_prob'] = sf_confusion_matrix.join(sf_confusion_matrix.groupby('target_label', {'sum_prob': _tc.aggregate.SUM('prob')}),how='left').apply(lambda x: wo_divide_by_zero(x['prob'], x['sum_prob']))\n            return sf_confusion_matrix.fillna('norm_prob', 0)\n\n\n        def hclusterSort(vectors, dist_fn):\n            distances = []\n            vecs = list(vectors)[:]\n            for i in range(0, len(vecs)):\n                for j in range(i+1, len(vecs)):\n                    distances.append({'from': vecs[i], 'to': vecs[j], 'dist': dist_fn(vecs[i], vecs[j])})\n            distances = sorted(distances, key=lambda d: d['dist'])\n            excluding_names = []\n\n            while(len(distances) > 0):\n                min_dist = distances[0]\n\n                new_vec = {'name': str(min_dist['from']['name']) + '|'+ str(min_dist['to']['name']),\n                        'members': min_dist['from'].get('members', [min_dist['from']]) + min_dist['to'].get('members',[min_dist['to']])}\n\n                excluding_names = [min_dist['from']['name'], min_dist['to']['name']]\n\n                vecs = filter(lambda v: v['name'] not in excluding_names, vecs)\n                distances = filter(lambda dist: (dist['from']['name'] not in excluding_names) and (dist['to']['name'] not in excluding_names), distances)\n\n                for v in vecs:\n                    total = 0\n                    for vi in v.get('members', [v]):\n                        for vj in new_vec['members']:\n                            total += dist_fn(vi, vj)\n                    distances.append({'from': v, 'to': new_vec, 'dist': total/len(v.get('members', [v]))/len(new_vec['members'])})\n\n                vecs.append(new_vec)\n                distances = sorted(distances, key=lambda d: d['dist'])\n\n            return vecs\n\n        def l2Dist(v1, v2):\n            dist = 0\n            for i in range(0, len(v1['pos'])):\n                dist +=  math.pow(v1['pos'][i] - v2['pos'][i], 2)\n            return math.pow(dist, 0.5)\n\n    \n\n        evaluation_result = {k: metrics[k] for k in ['accuracy', 'f1_score', 'log_loss', 'precision', 'recall', 'auc']}\n        evaluation_result['num_test_examples'] = len(dataset)\n        for k in ['num_classes', 'num_features', 'input_image_shape', 'num_examples', 'training_loss', 'training_time', 'model', 'max_iterations']:\n            evaluation_result[k] = getattr(self, k)\n        \n        # Extend the given test data\n        extended_test = dataset.add_column(predictions, 'probs')\n        extended_test['label'] = dataset[self.target]\n        extended_test = extended_test.add_columns( [extended_test.apply(lambda d: labels[d['probs'].index(confidence(d['probs']))]),\n            extended_test.apply(lambda d: entropy(d['probs'])),\n            extended_test.apply(lambda d: confidence(d['probs'])),\n            extended_test.apply(lambda d: relative_confidence(d['probs']))],\n            ['predicted_label', 'entropy', 'confidence', 'relative_confidence'])\n        extended_test = extended_test.add_column(extended_test.apply(lambda d: d['label'] == d['predicted_label']), 'correct')\n\n        # Calculate the confusion matrix\n        sf_conf_mat = get_confusion_matrix(extended_test, labels)\n        confidence_threshold = 0.5\n        hesitant_threshold = 0.2\n        evaluation_result['confidence_threshold'] = confidence_threshold\n        evaluation_result['hesitant_threshold'] = hesitant_threshold\n        evaluation_result['confidence_metric_for_threshold'] = 'relative_confidence'\n        sf_hesitant_conf_mat = get_confusion_matrix(extended_test[extended_test[evaluation_result['confidence_metric_for_threshold']] < hesitant_threshold], labels)\n        sf_confidently_wrong_conf_mat = get_confusion_matrix(extended_test[(extended_test[evaluation_result['confidence_metric_for_threshold']] > confidence_threshold) & (extended_test['correct']==True)], labels)\n\n        evaluation_result['conf_mat'] = list(sf_conf_mat)\n        evaluation_result['hesitant_conf_mat'] = list(sf_hesitant_conf_mat)\n        evaluation_result['confidently_wrong_conf_mat'] = list(sf_confidently_wrong_conf_mat)\n\n        \n        # Get sorted labels (sorted by hCluster)\n        vectors = map(lambda l: {'name': l, 'pos':list(sf_conf_mat[sf_conf_mat['target_label']==l].sort('predicted_label')['norm_prob'])},\n                    labels)\n        evaluation_result['sorted_labels'] = hclusterSort(vectors, l2Dist)[0]['name'].split(\"|\")\n\n        # Get recall and precision per label\n        per_l = extended_test.groupby(['label'], {'count': _tc.aggregate.COUNT, 'correct_count': _tc.aggregate.SUM('correct') })\n        per_l['recall'] = per_l.apply(lambda l: l['correct_count']*1.0 / l['count'])\n\n        per_pl = extended_test.groupby(['predicted_label'], {'predicted_count': _tc.aggregate.COUNT, 'correct_count': _tc.aggregate.SUM('correct') })\n        per_pl['precision'] = per_pl.apply(lambda l: l['correct_count']*1.0 / l['predicted_count'])\n        per_pl = per_pl.rename({'predicted_label': 'label'})\n        evaluation_result['label_metrics'] = list(per_l.join(per_pl, on='label', how='outer').select_columns(['label', 'count', 'correct_count', 'predicted_count', 'recall', 'precision']))\n        evaluation_result['labels'] = labels\n        \n        extended_test = extended_test.add_row_number('__idx').rename({'label': 'target_label'})\n        evaluation_result['test_data'] = extended_test\n        evaluation_result['feature'] = self.feature\n\n        return _Evaluation(evaluation_result)", "response": "Evaluate the model by making predictions of target values and comparing them to actual values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting the Core ML model to a file.", "response": "def export_coreml(self, filename):\n        \"\"\"\n        Save the model in Core ML format.\n\n        See Also\n        --------\n        save\n\n        Examples\n        --------\n        >>> model.export_coreml('myModel.mlmodel')\n        \"\"\"\n        import coremltools\n        # First define three internal helper functions\n\n\n        # Internal helper function\n        def _create_vision_feature_print_scene():\n            prob_name = self.target + 'Probability'\n\n            #\n            # Setup the top level (pipeline classifier) spec\n            #\n            top_spec = coremltools.proto.Model_pb2.Model()\n            top_spec.specificationVersion = 3\n\n            desc = top_spec.description\n            desc.output.add().name = prob_name\n            desc.output.add().name = self.target\n\n            desc.predictedFeatureName = self.target\n            desc.predictedProbabilitiesName = prob_name\n\n            input = desc.input.add()\n            input.name = self.feature\n            input.type.imageType.width = 299\n            input.type.imageType.height = 299\n            BGR_VALUE = coremltools.proto.FeatureTypes_pb2.ImageFeatureType.ColorSpace.Value('BGR')\n            input.type.imageType.colorSpace = BGR_VALUE\n\n            #\n            # VisionFeaturePrint extractor\n            #\n            pipelineClassifier = top_spec.pipelineClassifier\n            scene_print = pipelineClassifier.pipeline.models.add()\n            scene_print.specificationVersion = 3\n            scene_print.visionFeaturePrint.scene.version = 1\n\n            input = scene_print.description.input.add()\n            input.name = self.feature\n            input.type.imageType.width = 299\n            input.type.imageType.height = 299\n            input.type.imageType.colorSpace = BGR_VALUE\n\n            output = scene_print.description.output.add()\n            output.name = \"output_name\"\n            DOUBLE_ARRAY_VALUE = coremltools.proto.FeatureTypes_pb2.ArrayFeatureType.ArrayDataType.Value('DOUBLE')\n            output.type.multiArrayType.dataType = DOUBLE_ARRAY_VALUE\n            output.type.multiArrayType.shape.append(2048)\n\n            #\n            # Neural Network Classifier, which is just logistic regression, in order to use GPUs\n            #\n            temp = top_spec.pipelineClassifier.pipeline.models.add()\n            temp.specificationVersion = 3\n\n            # Empty inner product layer\n            nn_spec = temp.neuralNetworkClassifier\n            feature_layer = nn_spec.layers.add()\n            feature_layer.name = \"feature_layer\"\n            feature_layer.input.append(\"output_name\")\n            feature_layer.output.append(\"softmax_input\")\n            fc_layer_params = feature_layer.innerProduct\n            fc_layer_params.inputChannels = 2048\n\n            # Softmax layer\n            softmax = nn_spec.layers.add()\n            softmax.name = \"softmax\"\n            softmax.softmax.MergeFromString(b'')\n            softmax.input.append(\"softmax_input\")\n            softmax.output.append(prob_name)\n\n            input = temp.description.input.add()\n            input.name = \"output_name\"\n            input.type.multiArrayType.dataType = DOUBLE_ARRAY_VALUE\n            input.type.multiArrayType.shape.append(2048)\n\n            # Set outputs\n            desc = temp.description\n            prob_output = desc.output.add()\n            prob_output.name = prob_name\n            label_output = desc.output.add()\n            label_output.name = self.target\n\n            if type(self.classifier.classes[0]) == int:\n                prob_output.type.dictionaryType.int64KeyType.MergeFromString(b'')\n                label_output.type.int64Type.MergeFromString(b'')\n            else:\n                prob_output.type.dictionaryType.stringKeyType.MergeFromString(b'')\n                label_output.type.stringType.MergeFromString(b'')\n\n            temp.description.predictedFeatureName = self.target\n            temp.description.predictedProbabilitiesName = prob_name\n\n            return top_spec\n\n\n        # Internal helper function\n        def _update_last_two_layers(nn_spec):\n            # Replace the softmax layer with new coeffients\n            num_classes = self.num_classes\n            fc_layer = nn_spec.layers[-2]\n            fc_layer_params = fc_layer.innerProduct\n            fc_layer_params.outputChannels = self.classifier.num_classes\n            inputChannels = fc_layer_params.inputChannels\n            fc_layer_params.hasBias = True\n\n            coefs = self.classifier.coefficients\n            weights = fc_layer_params.weights\n            bias = fc_layer_params.bias\n            del weights.floatValue[:]\n            del bias.floatValue[:]\n\n            import numpy as np\n            W = np.array(coefs[coefs['index'] != None]['value'], ndmin = 2).reshape(\n                                          inputChannels, num_classes - 1, order = 'F')\n            b =  coefs[coefs['index'] == None]['value']\n            Wa = np.hstack((np.zeros((inputChannels, 1)), W))\n            weights.floatValue.extend(Wa.flatten(order = 'F'))\n            bias.floatValue.extend([0.0] + list(b))\n\n        # Internal helper function\n        def _set_inputs_outputs_and_metadata(spec, nn_spec):\n            # Replace the classifier with the new classes\n            class_labels = self.classifier.classes\n\n            probOutput = spec.description.output[0]\n            classLabel = spec.description.output[1]\n            probOutput.type.dictionaryType.MergeFromString(b'')\n            if type(class_labels[0]) == int:\n                nn_spec.ClearField('int64ClassLabels')\n                probOutput.type.dictionaryType.int64KeyType.MergeFromString(b'')\n                classLabel.type.int64Type.MergeFromString(b'')\n                del nn_spec.int64ClassLabels.vector[:]\n                for c in class_labels:\n                    nn_spec.int64ClassLabels.vector.append(c)\n            else:\n                nn_spec.ClearField('stringClassLabels')\n                probOutput.type.dictionaryType.stringKeyType.MergeFromString(b'')\n                classLabel.type.stringType.MergeFromString(b'')\n                del nn_spec.stringClassLabels.vector[:]\n                for c in class_labels:\n                    nn_spec.stringClassLabels.vector.append(c)\n\n            prob_name = self.target + 'Probability'\n            label_name = self.target\n            old_output_name = nn_spec.layers[-1].name\n            coremltools.models.utils.rename_feature(spec, 'classLabel', label_name)\n            coremltools.models.utils.rename_feature(spec, old_output_name, prob_name)\n            if nn_spec.layers[-1].name == old_output_name:\n                nn_spec.layers[-1].name = prob_name\n            if nn_spec.labelProbabilityLayerName == old_output_name:\n                nn_spec.labelProbabilityLayerName = prob_name\n            coremltools.models.utils.rename_feature(spec, 'data', self.feature)\n            if len(nn_spec.preprocessing) > 0:\n                nn_spec.preprocessing[0].featureName = self.feature\n\n            mlmodel = coremltools.models.MLModel(spec)\n            model_type = 'image classifier (%s)' % self.model\n            mlmodel.short_description = _coreml_utils._mlmodel_short_description(model_type)\n            mlmodel.input_description[self.feature] = u'Input image'\n            mlmodel.output_description[prob_name] = 'Prediction probabilities'\n            mlmodel.output_description[label_name] = 'Class label of top prediction'\n            _coreml_utils._set_model_metadata(mlmodel, self.__class__.__name__, {\n                'model': self.model,\n                'target': self.target,\n                'features': self.feature,\n                'max_iterations': str(self.max_iterations),\n            }, version=ImageClassifier._PYTHON_IMAGE_CLASSIFIER_VERSION)\n\n            return mlmodel\n\n\n        # main part of the export_coreml function\n        if self.model in _pre_trained_models.MODELS:\n            ptModel = _pre_trained_models.MODELS[self.model]()\n            feature_extractor = _image_feature_extractor.MXFeatureExtractor(ptModel)\n\n            coreml_model = feature_extractor.get_coreml_model()\n            spec = coreml_model.get_spec()\n            nn_spec = spec.neuralNetworkClassifier\n        else:     # model == VisionFeaturePrint_Scene\n            spec = _create_vision_feature_print_scene()\n            nn_spec = spec.pipelineClassifier.pipeline.models[1].neuralNetworkClassifier\n\n        _update_last_two_layers(nn_spec)\n        mlmodel = _set_inputs_outputs_and_metadata(spec, nn_spec)\n        mlmodel.save(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_input_layers(self):\n        self.input_layers = []\n        in_nodes = self.model._inbound_nodes if hasattr(\n                self.model,'_inbound_nodes') else self.model.inbound_nodes\n        if hasattr(self.model, 'input_layers'):\n            input_keras_layers = self.model.input_layers[:]\n            self.input_layers = [None] * len(input_keras_layers)\n            for layer in self.layer_list:\n                keras_layer = self.keras_layer_map[layer]\n                if isinstance(keras_layer, InputLayer):\n                    if keras_layer in input_keras_layers:\n                        idx = input_keras_layers.index(keras_layer)\n                        self.input_layers[idx] = layer\n        elif hasattr(self.model, 'inputs'):\n            for ts in _to_list(self.model.inputs):\n                # search for the InputLayer that matches this ts\n                for l in self.layer_list:\n                    kl = self.keras_layer_map[l]\n                    if isinstance(kl, InputLayer) and kl.input == ts:\n                        self.input_layers.append(l)\n        elif len(in_nodes) <= 1:\n            for ts in _to_list(self.model.input):\n                # search for the InputLayer that matches this ts\n                for l in self.layer_list:\n                    kl = self.keras_layer_map[l]\n                    if isinstance(kl, InputLayer) and kl.input == ts:\n                        self.input_layers.append(l)\n        else:\n            raise ValueError(\"Input values cannot be identified.\")", "response": "This method extracts the ordering of the input layers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the ordering of output layers.", "response": "def make_output_layers(self):\n        \"\"\"\n        Extract the ordering of output layers.\n        \"\"\"\n        self.output_layers = []\n        # import pytest; pytest.set_trace()\n        if hasattr(self.model, 'output_layers'):\n            # find corresponding output layers in CoreML model\n            # assume output layers are not shared\n            # Helper function to recursively extract output layers\n            # even if the model has a layer which is a nested model\n            def extract_output_layers(keras_model):\n                output_layers = []\n                for layer in keras_model.output_layers:\n                    if hasattr(layer,'output_layers'):\n                        output_layers.extend(extract_output_layers(layer))\n                    else:\n                        output_layers.append(layer)\n                return output_layers\n\n            for kl in extract_output_layers(self.model):\n                coreml_layers = self.get_coreml_layers(kl)\n                if len(coreml_layers) > 0:\n                    for cl in coreml_layers:\n                        self.output_layers.append(cl)\n        elif len(self.model.outputs) > 0:\n            for model_output in self.model.outputs:\n                for l in self.layer_list:\n                    k_layer = self.keras_layer_map[l]\n                    in_nodes = k_layer._inbound_nodes if hasattr(k_layer, '_inbound_nodes') else k_layer.inbound_nodes\n                    for idx in range(len(in_nodes)):\n                        out_tensor = k_layer.get_output_at(idx)\n                        if out_tensor == model_output or (out_tensor.name in model_output.name):\n                            self.output_layers.append(l)\n        if len(self.output_layers) == 0:\n            raise ValueError(\"No outputs can be identified\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _remove_layer_and_reconnect(self, layer):\n        successors = self.get_successors(layer)\n        predecessors = self.get_predecessors(layer)\n        # remove layer's edges\n        for succ in successors:\n            self._remove_edge(layer, succ)\n        for pred in predecessors:\n            self._remove_edge(pred, layer)\n\n        # connect predecessors and successors\n        for pred in predecessors:\n            for succ in successors:\n                self._add_edge(pred, succ)\n\n        # remove layer in the data structures\n        self.layer_list.remove(layer)\n        self.keras_layer_map.pop(layer)\n\n        # re-assign input and output layers if layer happens to be an\n        # input / output layer\n        if layer in self.input_layers:\n            idx = self.input_layers.index(layer)\n            self.input_layers.pop(idx)\n            for pred in predecessors:\n                self.input_layers.insert(idx, pred)\n                idx += 1\n        if layer in self.output_layers:\n            idx = self.output_layers.index(layer)\n            self.output_layers.pop(idx)\n            for succ in successors:\n                self.output_layers.insert(idx, succ)\n                idx += 1", "response": "Remove the layer and reconnect each of its predecessor to each of its successor\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef defuse_activation(self):\n        idx, nb_layers = 0, len(self.layer_list)\n        while idx < nb_layers:\n            layer = self.layer_list[idx]\n            k_layer = self.keras_layer_map[layer]\n            if (isinstance(k_layer, _keras.layers.TimeDistributed)):\n                k_layer = k_layer.layer\n            if (isinstance(k_layer, _keras.layers.Conv2D) or\n                isinstance(k_layer, _keras.layers.Conv1D) or\n                isinstance(k_layer, _keras.layers.SeparableConv2D) or\n                isinstance(k_layer, _keras.layers.SeparableConv1D) or\n                isinstance(k_layer, _keras.layers.Dense)):\n\n                func_name = k_layer.activation.func_name if six.PY2 else \\\n                        k_layer.activation.__name__\n\n                if func_name != 'linear':\n                    # Create new layer\n                    new_layer = layer + '__activation__'\n                    new_keras_layer = _keras.layers.core.Activation(func_name)\n                    # insert new layer after it\n                    self._insert_layer_after(idx, new_layer, new_keras_layer)\n                    idx += 1\n                    nb_layers += 1\n            idx += 1", "response": "Defuse the fused activation layers in the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef date_range(cls,start_time,end_time,freq):\n        '''\n        Returns a new SArray that represents a fixed frequency datetime index.\n\n        Parameters\n        ----------\n        start_time : datetime.datetime\n          Left bound for generating dates.\n\n        end_time : datetime.datetime\n          Right bound for generating dates.\n\n        freq : datetime.timedelta\n          Fixed frequency between two consecutive data points.\n\n        Returns\n        -------\n        out : SArray\n\n        Examples\n        --------\n        >>> import datetime as dt\n        >>> start = dt.datetime(2013, 5, 7, 10, 4, 10)\n        >>> end = dt.datetime(2013, 5, 10, 10, 4, 10)\n        >>> sa = tc.SArray.date_range(start,end,dt.timedelta(1))\n        >>> print sa\n        dtype: datetime\n        Rows: 4\n        [datetime.datetime(2013, 5, 7, 10, 4, 10),\n         datetime.datetime(2013, 5, 8, 10, 4, 10),\n         datetime.datetime(2013, 5, 9, 10, 4, 10),\n         datetime.datetime(2013, 5, 10, 10, 4, 10)]\n       '''\n\n        if not isinstance(start_time,datetime.datetime):\n            raise TypeError(\"The ``start_time`` argument must be from type datetime.datetime.\")\n\n        if not isinstance(end_time,datetime.datetime):\n            raise TypeError(\"The ``end_time`` argument must be from type datetime.datetime.\")\n\n        if not isinstance(freq,datetime.timedelta):\n            raise TypeError(\"The ``freq`` argument must be from type datetime.timedelta.\")\n\n        from .. import extensions\n        return extensions.date_range(start_time,end_time,freq.total_seconds())", "response": "Returns a new SArray that represents a fixed frequency datetime index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_const(cls, value, size, dtype=type(None)):\n        assert isinstance(size, (int, long)) and size >= 0, \"size must be a positive int\"\n        if not isinstance(value, (type(None), int, float, str, array.array, list, dict, datetime.datetime)):\n            raise TypeError('Cannot create sarray of value type %s' % str(type(value)))\n        proxy = UnitySArrayProxy()\n        proxy.load_from_const(value, size, dtype)\n        return cls(_proxy=proxy)", "response": "Construct an unity sarray of size with a const value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_sequence(cls, *args):\n        start = None\n        stop = None\n        # fill with args. This checks for from_sequence(100), from_sequence(10,100)\n        if len(args) == 1:\n            stop = args[0]\n        elif len(args) == 2:\n            start = args[0]\n            stop = args[1]\n\n        if stop is None and start is None:\n            raise TypeError(\"from_sequence expects at least 1 argument. got 0\")\n        elif start is None:\n            return _create_sequential_sarray(stop)\n        else:\n            size = stop - start\n            # this matches the behavior of range\n            # i.e. range(100,10) just returns an empty array\n            if (size < 0):\n                size = 0\n            return _create_sequential_sarray(size, start)", "response": "Create an SArray from a sequence of integers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_json(cls, filename):\n        proxy = UnitySArrayProxy()\n        proxy.load_from_json_record_files(_make_internal_url(filename))\n        return cls(_proxy = proxy)", "response": "Read an SArray from a json file or glob of json files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting elements from either istrue or isfalse depending on the value of the condition SArray. Parameters ---------- condition : SArray An SArray of values such that for each value, if non-zero, yields a value from istrue, otherwise from isfalse. istrue : SArray or constant The elements selected if condition is true. If istrue is an SArray, this must be of the same length as condition. isfalse : SArray or constant The elements selected if condition is false. If istrue is an SArray, this must be of the same length as condition. dtype : type The type of result SArray. This is required if both istrue and isfalse are constants of ambiguous types. Examples -------- Returns an SArray with the same values as g with values above 10 clipped to 10 >>> g = SArray([6,7,8,9,10,11,12,13]) >>> SArray.where(g > 10, 10, g) dtype: int Rows: 8 [6, 7, 8, 9, 10, 10, 10, 10] Returns an SArray with the same values as g with values below 10 clipped to 10 >>> SArray.where(g > 10, g, 10) dtype: int Rows: 8 [10, 10, 10, 10, 10, 11, 12, 13] Returns an SArray with the same values of g with all values == 1 replaced by None >>> g = SArray([1,2,3,4,1,2,3,4]) >>> SArray.where(g == 1, None, g) dtype: int Rows: 8 [None, 2, 3, 4, None, 2, 3, 4] Returns an SArray with the same values of g, but with each missing value replaced by its corresponding element in replace_none >>> g = SArray([1,2,None,None]) >>> replace_none = SArray([3,3,2,2]) >>> SArray.where(g != None, g, replace_none) dtype: int Rows: 4 [1, 2, 2, 2]", "response": "def where(cls, condition, istrue, isfalse, dtype=None):\n        \"\"\"\n        Selects elements from either istrue or isfalse depending on the value\n        of the condition SArray.\n\n        Parameters\n        ----------\n        condition : SArray\n        An SArray of values such that for each value, if non-zero, yields a\n        value from istrue, otherwise from isfalse.\n\n        istrue : SArray or constant\n        The elements selected if condition is true. If istrue is an SArray,\n        this must be of the same length as condition.\n\n        isfalse : SArray or constant\n        The elements selected if condition is false. If istrue is an SArray,\n        this must be of the same length as condition.\n\n        dtype : type\n        The type of result SArray. This is required if both istrue and isfalse\n        are constants of ambiguous types.\n\n        Examples\n        --------\n\n        Returns an SArray with the same values as g with values above 10\n        clipped to 10\n\n        >>> g = SArray([6,7,8,9,10,11,12,13])\n        >>> SArray.where(g > 10, 10, g)\n        dtype: int\n        Rows: 8\n        [6, 7, 8, 9, 10, 10, 10, 10]\n\n        Returns an SArray with the same values as g with values below 10\n        clipped to 10\n\n        >>> SArray.where(g > 10, g, 10)\n        dtype: int\n        Rows: 8\n        [10, 10, 10, 10, 10, 11, 12, 13]\n\n        Returns an SArray with the same values of g with all values == 1\n        replaced by None\n\n        >>> g = SArray([1,2,3,4,1,2,3,4])\n        >>> SArray.where(g == 1, None, g)\n        dtype: int\n        Rows: 8\n        [None, 2, 3, 4, None, 2, 3, 4]\n\n        Returns an SArray with the same values of g, but with each missing value\n        replaced by its corresponding element in replace_none\n\n        >>> g = SArray([1,2,None,None])\n        >>> replace_none = SArray([3,3,2,2])\n        >>> SArray.where(g != None, g, replace_none)\n        dtype: int\n        Rows: 4\n        [1, 2, 2, 2]\n        \"\"\"\n        true_is_sarray = isinstance(istrue, SArray)\n        false_is_sarray = isinstance(isfalse, SArray)\n        if not true_is_sarray and false_is_sarray:\n            istrue = cls(_proxy=condition.__proxy__.to_const(istrue, isfalse.dtype))\n        if true_is_sarray and not false_is_sarray:\n            isfalse = cls(_proxy=condition.__proxy__.to_const(isfalse, istrue.dtype))\n        if not true_is_sarray and not false_is_sarray:\n            if dtype is None:\n                if istrue is None:\n                    dtype = type(isfalse)\n                elif isfalse is None:\n                    dtype = type(istrue)\n                elif type(istrue) != type(isfalse):\n                    raise TypeError(\"true and false inputs are of different types\")\n                elif type(istrue) == type(isfalse):\n                    dtype = type(istrue)\n            if dtype is None:\n                raise TypeError(\"Both true and false are None. Resultant type cannot be inferred.\")\n            istrue = cls(_proxy=condition.__proxy__.to_const(istrue, dtype))\n            isfalse = cls(_proxy=condition.__proxy__.to_const(isfalse, dtype))\n        return cls(_proxy=condition.__proxy__.ternary_operator(istrue.__proxy__, isfalse.__proxy__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the current SArray to file.", "response": "def save(self, filename, format=None):\n        \"\"\"\n        Saves the SArray to file.\n\n        The saved SArray will be in a directory named with the `targetfile`\n        parameter.\n\n        Parameters\n        ----------\n        filename : string\n            A local path or a remote URL.  If format is 'text', it will be\n            saved as a text file. If format is 'binary', a directory will be\n            created at the location which will contain the SArray.\n\n        format : {'binary', 'text', 'csv'}, optional\n            Format in which to save the SFrame. Binary saved SArrays can be\n            loaded much faster and without any format conversion losses.\n            'text' and 'csv' are synonymous: Each SArray row will be written\n            as a single line in an output text file. If not\n            given, will try to infer the format from filename given. If file\n            name ends with 'csv', 'txt' or '.csv.gz', then save as 'csv' format,\n            otherwise save as 'binary' format.\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n\n        if format is None:\n            if filename.endswith(('.csv', '.csv.gz', 'txt')):\n                format = 'text'\n            else:\n                format = 'binary'\n        if format == 'binary':\n            with cython_context():\n                self.__proxy__.save(_make_internal_url(filename))\n        elif format == 'text' or format == 'csv':\n            sf = _SFrame({'X1':self})\n            with cython_context():\n                sf.__proxy__.save_as_csv(_make_internal_url(filename), {'header':False})\n        else:\n            raise ValueError(\"Unsupported format: {}\".format(format))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vector_slice(self, start, end=None):\n        if (self.dtype != array.array) and (self.dtype != list):\n            raise RuntimeError(\"Only Vector type can be sliced\")\n        if end is None:\n            end = start + 1\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.vector_slice(start, end))", "response": "This method returns a new SArray containing each individual element sliced between start and end."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount n - grams in the current object.", "response": "def _count_ngrams(self, n=2, method=\"word\", to_lower=True, ignore_space=True):\n        \"\"\"\n        For documentation, see turicreate.text_analytics.count_ngrams().\n\n        ..WARNING:: This function is deprecated, and will be removed in future\n        versions of Turi Create. Please use the `text_analytics.count_words`\n        function instead.\n        \"\"\"\n        if (self.dtype != str):\n            raise TypeError(\"Only SArray of string type is supported for counting n-grams\")\n\n        if (type(n) != int):\n            raise TypeError(\"Input 'n' must be of type int\")\n\n        if (n < 1):\n            raise ValueError(\"Input 'n' must be greater than 0\")\n\n        if (n > 5):\n            warnings.warn(\"It is unusual for n-grams to be of size larger than 5.\")\n\n\n        # construct options, will extend over time\n        options = dict()\n        options[\"to_lower\"] = to_lower == True\n        options[\"ignore_space\"] = ignore_space == True\n\n\n        if method == \"word\":\n            with cython_context():\n                return SArray(_proxy=self.__proxy__.count_ngrams(n, options))\n        elif method == \"character\" :\n            with cython_context():\n                return SArray(_proxy=self.__proxy__.count_character_ngrams(n, options))\n        else:\n            raise ValueError(\"Invalid 'method' input  value. Please input either 'word' or 'character' \")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_trim_by_keys(self, keys, exclude=True):\n        if not _is_non_string_iterable(keys):\n            keys = [keys]\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.dict_trim_by_keys(keys, exclude))", "response": "Returns an SArray of dictionary type by the given keys."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_trim_by_values(self, lower=None, upper=None):\n\n        if not (lower is None or isinstance(lower, numbers.Number)):\n            raise TypeError(\"lower bound has to be a numeric value\")\n\n        if not (upper is None or isinstance(upper, numbers.Number)):\n            raise TypeError(\"upper bound has to be a numeric value\")\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.dict_trim_by_values(lower, upper))", "response": "Returns an SArray of the keys that are in the given range and are in the given range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a boolean SArray by checking the keys of an SArray of dictionaries. An element of the output SArray is True if the corresponding input element s dictionary has any of the given keys.", "response": "def dict_has_any_keys(self, keys):\n        \"\"\"\n        Create a boolean SArray by checking the keys of an SArray of\n        dictionaries. An element of the output SArray is True if the\n        corresponding input element's dictionary has any of the given keys.\n        Fails on SArrays whose data type is not ``dict``.\n\n        Parameters\n        ----------\n        keys : list\n            A list of key values to check each dictionary against.\n\n        Returns\n        -------\n        out : SArray\n            A SArray of int type, where each element indicates whether the\n            input SArray element contains any key in the input list.\n\n        See Also\n        --------\n        dict_has_all_keys\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray([{\"this\":1, \"is\":5, \"dog\":7}, {\"animal\":1},\n                                 {\"this\": 2, \"are\": 1, \"cat\": 5}])\n        >>> sa.dict_has_any_keys([\"is\", \"this\", \"are\"])\n        dtype: int\n        Rows: 3\n        [1, 0, 1]\n        \"\"\"\n        if not _is_non_string_iterable(keys):\n            keys = [keys]\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.dict_has_any_keys(keys))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_has_all_keys(self, keys):\n        if not _is_non_string_iterable(keys):\n            keys = [keys]\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.dict_has_all_keys(keys))", "response": "Create a boolean SArray by checking the keys of an SArray of\n            dictionaries. An element of the output SArray is True if the corresponding input element s dictionary has all of the given keys."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, fn, dtype=None, skip_na=True, seed=None):\n        assert callable(fn), \"Input function must be callable.\"\n\n        dryrun = [fn(i) for i in self.head(100) if i is not None]\n        if dtype is None:\n            dtype = infer_type_of_list(dryrun)\n        if seed is None:\n            seed = abs(hash(\"%0.20f\" % time.time())) % (2 ** 31)\n\n        # log metric\n\n        # First phase test if it is a toolkit function\n        nativefn = None\n        try:\n            from .. import extensions\n            nativefn = extensions._build_native_function_call(fn)\n        except:\n            # failure are fine. we just fall out into the next few phases\n            pass\n\n        if nativefn is not None:\n            # this is a toolkit lambda. We can do something about it\n            nativefn.native_fn_name = nativefn.native_fn_name.encode()\n            with cython_context():\n                return SArray(_proxy=self.__proxy__.transform_native(nativefn, dtype, skip_na, seed))\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.transform(fn, dtype, skip_na, seed))", "response": "Apply a function to each element of the SArray and return the result as a new SArray."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, fn, skip_na=True, seed=None):\n        assert callable(fn), \"Input must be callable\"\n        if seed is None:\n            seed = abs(hash(\"%0.20f\" % time.time())) % (2 ** 31)\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.filter(fn, skip_na, seed))", "response": "Returns a new SArray with elements from this SArray filtered by a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an SArray which contains a subsample of the current SArray.", "response": "def sample(self, fraction, seed=None, exact=False):\n        \"\"\"\n        Create an SArray which contains a subsample of the current SArray.\n\n        Parameters\n        ----------\n        fraction : float\n            Fraction of the rows to fetch. Must be between 0 and 1.\n            if exact is False (default), the number of rows returned is\n            approximately the fraction times the number of rows.\n\n        seed : int, optional\n            The random seed for the random number generator.\n\n        exact: bool, optional\n            Defaults to False. If exact=True, an exact fraction is returned, \n            but at a performance penalty.\n\n        Returns\n        -------\n        out : SArray\n            The new SArray which contains the subsampled rows.\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray(range(10))\n        >>> sa.sample(.3)\n        dtype: int\n        Rows: 3\n        [2, 6, 9]\n        \"\"\"\n        if (fraction > 1 or fraction < 0):\n            raise ValueError('Invalid sampling rate: ' + str(fraction))\n        if (len(self) == 0):\n            return SArray()\n        if seed is None:\n            seed = abs(hash(\"%0.20f\" % time.time())) % (2 ** 31)\n\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.sample(fraction, seed, exact))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash(self, seed=0):\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.hash(seed))", "response": "Returns an integer SArray with a hash of each element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_integers(cls, size, seed=None):\n        if seed is None:\n            seed = abs(hash(\"%0.20f\" % time.time())) % (2 ** 31)\n        return cls.from_sequence(size).hash(seed)", "response": "Returns an SArray with random integers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the index of the minimum numeric value in an array.", "response": "def argmin(self):\n        \"\"\"\n        Get the index of the minimum numeric value in SArray.\n\n        Returns None on an empty SArray. Raises an exception if called on an\n        SArray with non-numeric type.\n\n        Returns\n        -------\n        out : int\n            index of the minimum value of SArray\n\n        See Also\n        --------\n        argmax\n\n        Examples\n        --------\n        >>> turicreate.SArray([14, 62, 83, 72, 77, 96, 5, 25, 69, 66]).argmin()\n\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n\n        if len(self) == 0:\n            return None\n        if not any([isinstance(self[0], i) for i in [int,float,long]]):\n            raise TypeError(\"SArray must be of type 'int', 'long', or 'float'.\")\n\n        sf = _SFrame(self).add_row_number()\n        sf_out = sf.groupby(key_column_names=[],operations={'minimum_x1': _aggregate.ARGMIN('X1','id')})\n        return sf_out['minimum_x1'][0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the mean value of all the values in the input SArray or mean image.", "response": "def mean(self):\n        \"\"\"\n        Mean of all the values in the SArray, or mean image.\n\n        Returns None on an empty SArray. Raises an exception if called on an\n        SArray with non-numeric type or non-Image type.\n\n        Returns\n        -------\n        out : float | turicreate.Image\n            Mean of all values in SArray, or image holding per-pixel mean\n            across the input SArray.\n        \"\"\"\n        with cython_context():\n            if self.dtype == _Image:\n                from  .. import extensions\n                return extensions.generate_mean(self)\n            else:\n                return self.__proxy__.mean()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datetime_to_str(self,format=\"%Y-%m-%dT%H:%M:%S%ZP\"):\n        if(self.dtype != datetime.datetime):\n            raise TypeError(\"datetime_to_str expects SArray of datetime as input SArray\")\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.datetime_to_str(format))", "response": "Convert the current SArray to a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the string representation of the object to datetime.", "response": "def str_to_datetime(self,format=\"%Y-%m-%dT%H:%M:%S%ZP\"):\n        \"\"\"\n        Create a new SArray with all the values cast to datetime. The string format is\n        specified by the 'format' parameter.\n\n        Parameters\n        ----------\n        format : str\n            The string format of the input SArray. Default format is \"%Y-%m-%dT%H:%M:%S%ZP\".\n            If format is \"ISO\", the the format is \"%Y%m%dT%H%M%S%F%q\"\n        Returns\n        -------\n        out : SArray[datetime.datetime]\n            The SArray converted to the type 'datetime'.\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray([\"20-Oct-2011 09:30:10 GMT-05:30\"])\n        >>> sa.str_to_datetime(\"%d-%b-%Y %H:%M:%S %ZP\")\n        dtype: datetime\n        Rows: 1\n        datetime.datetime(2011, 10, 20, 9, 30, 10, tzinfo=GMT(-5.5))\n\n        See Also\n        ----------\n        datetime_to_str\n\n        References\n        ----------\n        [1] boost date time to string conversion guide (http://www.boost.org/doc/libs/1_48_0/doc/html/date_time/date_time_io.html)\n\n        \"\"\"\n        if(self.dtype != str):\n            raise TypeError(\"str_to_datetime expects SArray of str as input SArray\")\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.str_to_datetime(format))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pixel_array_to_image(self, width, height, channels, undefined_on_failure=True, allow_rounding=False):\n        if(self.dtype != array.array):\n            raise TypeError(\"array_to_img expects SArray of arrays as input SArray\")\n\n        num_to_test = 10\n\n        num_test = min(len(self), num_to_test)\n\n        mod_values = [val % 1 for x in range(num_test) for val in self[x]]\n\n        out_of_range_values = [(val > 255 or val < 0) for x in range(num_test) for val in self[x]]\n\n        if sum(mod_values) != 0.0 and not allow_rounding:\n            raise ValueError(\"There are non-integer values in the array data. Images only support integer data values between 0 and 255. To permit rounding, set the 'allow_rounding' parameter to 1.\")\n\n        if sum(out_of_range_values) != 0:\n            raise ValueError(\"There are values outside the range of 0 to 255. Images only support integer data values between 0 and 255.\")\n\n\n        from .. import extensions\n        return extensions.vector_sarray_to_image_sarray(self, width, height, channels, undefined_on_failure)", "response": "Convert an array of pixel values to Image types."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an SArray with all values cast to the given type.", "response": "def astype(self, dtype, undefined_on_failure=False):\n        \"\"\"\n        Create a new SArray with all values cast to the given type. Throws an\n        exception if the types are not castable to the given type.\n\n        Parameters\n        ----------\n        dtype : {int, float, str, list, array.array, dict, datetime.datetime}\n            The type to cast the elements to in SArray\n\n        undefined_on_failure: bool, optional\n            If set to True, runtime cast failures will be emitted as missing\n            values rather than failing.\n\n        Returns\n        -------\n        out : SArray [dtype]\n            The SArray converted to the type ``dtype``.\n\n        Notes\n        -----\n        - The string parsing techniques used to handle conversion to dictionary\n          and list types are quite generic and permit a variety of interesting\n          formats to be interpreted. For instance, a JSON string can usually be\n          interpreted as a list or a dictionary type. See the examples below.\n        - For datetime-to-string  and string-to-datetime conversions,\n          use sa.datetime_to_str() and sa.str_to_datetime() functions.\n        - For array.array to turicreate.Image conversions, use sa.pixel_array_to_image()\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray(['1','2','3','4'])\n        >>> sa.astype(int)\n        dtype: int\n        Rows: 4\n        [1, 2, 3, 4]\n\n        Given an SArray of strings that look like dicts, convert to a dictionary\n        type:\n\n        >>> sa = turicreate.SArray(['{1:2 3:4}', '{a:b c:d}'])\n        >>> sa.astype(dict)\n        dtype: dict\n        Rows: 2\n        [{1: 2, 3: 4}, {'a': 'b', 'c': 'd'}]\n        \"\"\"\n\n        if (dtype == _Image) and (self.dtype == array.array):\n            raise TypeError(\"Cannot cast from image type to array with sarray.astype(). Please use sarray.pixel_array_to_image() instead.\")\n\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.astype(dtype, undefined_on_failure))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new SArray with each value clipped to be within the given lower and upper bounds.", "response": "def clip(self, lower=float('nan'), upper=float('nan')):\n        \"\"\"\n        Create a new SArray with each value clipped to be within the given\n        bounds.\n\n        In this case, \"clipped\" means that values below the lower bound will be\n        set to the lower bound value. Values above the upper bound will be set\n        to the upper bound value. This function can operate on SArrays of\n        numeric type as well as array type, in which case each individual\n        element in each array is clipped. By default ``lower`` and ``upper`` are\n        set to ``float('nan')`` which indicates the respective bound should be\n        ignored. The method fails if invoked on an SArray of non-numeric type.\n\n        Parameters\n        ----------\n        lower : int, optional\n            The lower bound used to clip. Ignored if equal to ``float('nan')``\n            (the default).\n\n        upper : int, optional\n            The upper bound used to clip. Ignored if equal to ``float('nan')``\n            (the default).\n\n        Returns\n        -------\n        out : SArray\n\n        See Also\n        --------\n        clip_lower, clip_upper\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray([1,2,3])\n        >>> sa.clip(2,2)\n        dtype: int\n        Rows: 3\n        [2, 2, 2]\n        \"\"\"\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.clip(lower, upper))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clip_lower(self, threshold):\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.clip(threshold, float('nan')))", "response": "Create a new SArray with all values clipped to the given lower bound."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an SArray that contains the last n elements in the current SArray.", "response": "def tail(self, n=10):\n        \"\"\"\n        Get an SArray that contains the last n elements in the SArray.\n\n        Parameters\n        ----------\n        n : int\n            The number of elements to fetch\n\n        Returns\n        -------\n        out : SArray\n            A new SArray which contains the last n rows of the current SArray.\n        \"\"\"\n        with cython_context():\n            return SArray(_proxy=self.__proxy__.tail(n))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new SArray with all missing values filled in with the given value.", "response": "def fillna(self, value):\n        \"\"\"\n        Create new SArray with all missing values (None or NaN) filled in\n        with the given value.\n\n        The size of the new SArray will be the same as the original SArray. If\n        the given value is not the same type as the values in the SArray,\n        `fillna` will attempt to convert the value to the original SArray's\n        type. If this fails, an error will be raised.\n\n        Parameters\n        ----------\n        value : type convertible to SArray's type\n            The value used to replace all missing values\n\n        Returns\n        -------\n        out : SArray\n            A new SArray with all missing values filled\n        \"\"\"\n\n        with cython_context():\n            return SArray(_proxy = self.__proxy__.fill_missing_values(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an SArray indicating which elements in the current SArray are in the top k order.", "response": "def is_topk(self, topk=10, reverse=False):\n        \"\"\"\n        Create an SArray indicating which elements are in the top k.\n\n        Entries are '1' if the corresponding element in the current SArray is a\n        part of the top k elements, and '0' if that corresponding element is\n        not. Order is descending by default.\n\n        Parameters\n        ----------\n        topk : int\n            The number of elements to determine if 'top'\n\n        reverse : bool\n            If True, return the topk elements in ascending order\n\n        Returns\n        -------\n        out : SArray (of type int)\n\n        Notes\n        -----\n        This is used internally by SFrame's topk function.\n        \"\"\"\n        with cython_context():\n            return SArray(_proxy = self.__proxy__.topk_index(topk, reverse))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summary(self, background=False, sub_sketch_keys=None):\n        from ..data_structures.sketch import Sketch\n        if (self.dtype == _Image):\n            raise TypeError(\"summary() is not supported for arrays of image type\")\n        if (type(background) != bool):\n            raise TypeError(\"'background' parameter has to be a boolean value\")\n        if (sub_sketch_keys is not None):\n            if (self.dtype != dict and self.dtype != array.array):\n                raise TypeError(\"sub_sketch_keys is only supported for SArray of dictionary or array type\")\n            if not _is_non_string_iterable(sub_sketch_keys):\n                sub_sketch_keys = [sub_sketch_keys]\n            value_types = set([type(i) for i in sub_sketch_keys])\n            if (len(value_types) != 1):\n                raise ValueError(\"sub_sketch_keys member values need to have the same type.\")\n            value_type = value_types.pop()\n            if (self.dtype == dict and value_type != str):\n                raise TypeError(\"Only string value(s) can be passed to sub_sketch_keys for SArray of dictionary type. \"+\n                    \"For dictionary types, sketch summary is computed by casting keys to string values.\")\n            if (self.dtype == array.array and value_type != int):\n                raise TypeError(\"Only int value(s) can be passed to sub_sketch_keys for SArray of array type\")\n        else:\n            sub_sketch_keys = list()\n\n        return Sketch(self, background, sub_sketch_keys = sub_sketch_keys)", "response": "Summary statistics for the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value_counts(self):\n        from .sframe import SFrame as _SFrame\n        return _SFrame({'value':self}).groupby('value', {'count':_aggregate.COUNT}).sort('count', ascending=False)", "response": "Return an SFrame containing counts of unique values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends an SArray to the current SArray.", "response": "def append(self, other):\n        \"\"\"\n        Append an SArray to the current SArray. Creates a new SArray with the\n        rows from both SArrays. Both SArrays must be of the same type.\n\n        Parameters\n        ----------\n        other : SArray\n            Another SArray whose rows are appended to current SArray.\n\n        Returns\n        -------\n        out : SArray\n            A new SArray that contains rows from both SArrays, with rows from\n            the ``other`` SArray coming after all rows from the current SArray.\n\n        See Also\n        --------\n        SFrame.append\n\n        Examples\n        --------\n        >>> sa = turicreate.SArray([1, 2, 3])\n        >>> sa2 = turicreate.SArray([4, 5, 6])\n        >>> sa.append(sa2)\n        dtype: int\n        Rows: 6\n        [1, 2, 3, 4, 5, 6]\n        \"\"\"\n        if type(other) is not SArray:\n            raise RuntimeError(\"SArray append can only work with SArray\")\n\n        if self.dtype != other.dtype:\n            raise RuntimeError(\"Data types in both SArrays have to be the same\")\n\n        with cython_context():\n            return SArray(_proxy = self.__proxy__.append(other.__proxy__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new SArray containing all unique values in the current SArray.", "response": "def unique(self):\n        \"\"\"\n        Get all unique values in the current SArray.\n\n        Raises a TypeError if the SArray is of dictionary type. Will not\n        necessarily preserve the order of the given SArray in the new SArray.\n\n\n        Returns\n        -------\n        out : SArray\n            A new SArray that contains the unique values of the current SArray.\n\n        See Also\n        --------\n        SFrame.unique\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n\n        tmp_sf = _SFrame()\n        tmp_sf.add_column(self, 'X1', inplace=True)\n\n        res = tmp_sf.groupby('X1',{})\n\n        return SArray(_proxy=res['X1'].__proxy__)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying the SArray with the specified title xlabel and ylabel.", "response": "def show(self, title=LABEL_DEFAULT, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT):\n        \"\"\"\n        Visualize the SArray.\n\n        Notes\n        -----\n        - The plot will render either inline in a Jupyter Notebook, or in a\n          native GUI window, depending on the value provided in\n          `turicreate.visualization.set_target` (defaults to 'auto').\n\n        Parameters\n        ----------\n        title : str\n            The plot title to show for the resulting visualization.\n            If the title is None, the title will be omitted.\n\n        xlabel : str\n            The X axis label to show for the resulting visualization.\n            If the xlabel is None, the X axis label will be omitted.\n\n        ylabel : str\n            The Y axis label to show for the resulting visualization.\n            If the ylabel is None, the Y axis label will be omitted.\n\n        Returns\n        -------\n        None\n\n        Examples\n        --------\n        Suppose 'sa' is an SArray, we can view it using:\n\n        >>> sa.show()\n\n        To override the default plot title and axis labels:\n\n        >>> sa.show(title=\"My Plot Title\", xlabel=\"My X Axis\", ylabel=\"My Y Axis\")\n        \"\"\"\n\n        returned_plot = self.plot(title, xlabel, ylabel)\n\n        returned_plot.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(self, title=LABEL_DEFAULT, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT):\n\n        if title == \"\":\n            title = \" \"\n        if xlabel == \"\":\n            xlabel = \" \"\n        if ylabel == \"\":\n            ylabel = \" \"\n\n        if title is None:\n            title = \"\" # C++ otherwise gets \"None\" as std::string\n        if xlabel is None:\n            xlabel = \"\"\n        if ylabel is None:\n            ylabel = \"\"\n\n        return Plot(self.__proxy__.plot(title, xlabel, ylabel))", "response": "Create a plot of the SArray."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef item_length(self):\n        if (self.dtype not in [list, dict, array.array]):\n            raise TypeError(\"item_length() is only applicable for SArray of type list, dict and array.\")\n\n\n        with cython_context():\n            return SArray(_proxy = self.__proxy__.item_length())", "response": "Returns the length of each element in the current SArray."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_split(self, fraction, seed=None):\n        from .sframe import SFrame\n        temporary_sf = SFrame()\n        temporary_sf['X1'] = self\n        (train, test) = temporary_sf.random_split(fraction, seed)\n        return (train['X1'], test['X1'])", "response": "Randomly split the rows of an SArray into two SArrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit an SArray of datetime type into multiple columns.", "response": "def split_datetime(self, column_name_prefix = \"X\", limit=None, timezone=False):\n        \"\"\"\n        Splits an SArray of datetime type to multiple columns, return a\n        new SFrame that contains expanded columns. A SArray of datetime will be\n        split by default into an SFrame of 6 columns, one for each\n        year/month/day/hour/minute/second element.\n\n        **Column Naming**\n\n        When splitting a SArray of datetime type, new columns are named:\n        prefix.year, prefix.month, etc. The prefix is set by the parameter\n        \"column_name_prefix\" and defaults to 'X'. If column_name_prefix is\n        None or empty, then no prefix is used.\n\n        **Timezone Column**\n        If timezone parameter is True, then timezone information is represented\n        as one additional column which is a float shows the offset from\n        GMT(0.0) or from UTC.\n\n\n        Parameters\n        ----------\n        column_name_prefix: str, optional\n            If provided, expanded column names would start with the given prefix.\n            Defaults to \"X\".\n\n        limit: list[str], optional\n            Limits the set of datetime elements to expand.\n            Possible values are 'year','month','day','hour','minute','second',\n            'weekday', 'isoweekday', 'tmweekday', and 'us'.\n            If not provided, only ['year','month','day','hour','minute','second']\n            are expanded.\n\n            - 'year': The year number\n            - 'month': A value between 1 and 12 where 1 is January.\n            - 'day': Day of the months. Begins at 1.\n            - 'hour': Hours since midnight.\n            - 'minute': Minutes after the hour.\n            - 'second': Seconds after the minute.\n            - 'us': Microseconds after the second. Between 0 and 999,999.\n            - 'weekday': A value between 0 and 6 where 0 is Monday.\n            - 'isoweekday': A value between 1 and 7 where 1 is Monday.\n            - 'tmweekday': A value between 0 and 7 where 0 is Sunday\n\n        timezone: bool, optional\n            A boolean parameter that determines whether to show timezone column or not.\n            Defaults to False.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains all expanded columns\n\n        Examples\n        --------\n        To expand only day and year elements of a datetime SArray\n\n         >>> sa = SArray(\n            [datetime(2011, 1, 21, 7, 7, 21, tzinfo=GMT(0)),\n             datetime(2010, 2, 5, 7, 8, 21, tzinfo=GMT(4.5)])\n\n         >>> sa.split_datetime(column_name_prefix=None,limit=['day','year'])\n            Columns:\n                day   int\n                year  int\n            Rows: 2\n            Data:\n            +-------+--------+\n            |  day  |  year  |\n            +-------+--------+\n            |   21  |  2011  |\n            |   5   |  2010  |\n            +-------+--------+\n            [2 rows x 2 columns]\n\n\n        To expand only year and timezone elements of a datetime SArray\n        with timezone column represented as a string. Columns are named with prefix:\n        'Y.column_name'.\n\n        >>> sa.split_datetime(column_name_prefix=\"Y\",limit=['year'],timezone=True)\n            Columns:\n                Y.year  int\n                Y.timezone float\n            Rows: 2\n            Data:\n            +----------+---------+\n            |  Y.year  | Y.timezone |\n            +----------+---------+\n            |    2011  |  0.0    |\n            |    2010  |  4.5    |\n            +----------+---------+\n            [2 rows x 2 columns]\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n\n        if self.dtype != datetime.datetime:\n            raise TypeError(\"Only column of datetime type is supported.\")\n\n        if column_name_prefix is None:\n            column_name_prefix = \"\"\n        if six.PY2 and type(column_name_prefix) == unicode:\n            column_name_prefix = column_name_prefix.encode('utf-8')\n        if type(column_name_prefix) != str:\n            raise TypeError(\"'column_name_prefix' must be a string\")\n\n        # convert limit to column_keys\n        if limit is not None:\n            if not _is_non_string_iterable(limit):\n                raise TypeError(\"'limit' must be a list\")\n\n            name_types = set([type(i) for i in limit])\n            if (len(name_types) != 1):\n                raise TypeError(\"'limit' contains values that are different types\")\n\n            if (name_types.pop() != str):\n                raise TypeError(\"'limit' must contain string values.\")\n\n            if len(set(limit)) != len(limit):\n                raise ValueError(\"'limit' contains duplicate values\")\n\n        column_types = []\n\n        if(limit is None):\n            limit = ['year','month','day','hour','minute','second']\n\n        column_types = [int] * len(limit)\n\n        if(timezone == True):\n            limit += ['timezone']\n            column_types += [float]\n\n\n        with cython_context():\n           return _SFrame(_proxy=self.__proxy__.expand(column_name_prefix, limit, column_types))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a wide SArray to one or two tall columns in an SFrame.", "response": "def stack(self, new_column_name=None, drop_na=False, new_column_type=None):\n        \"\"\"\n        Convert a \"wide\" SArray to one or two \"tall\" columns in an SFrame by\n        stacking all values.\n\n        The stack works only for columns of dict, list, or array type.  If the\n        column is dict type, two new columns are created as a result of\n        stacking: one column holds the key and another column holds the value.\n        The rest of the columns are repeated for each key/value pair.\n\n        If the column is array or list type, one new column is created as a\n        result of stacking. With each row holds one element of the array or list\n        value, and the rest columns from the same original row repeated.\n\n        The returned SFrame includes the newly created column(s).\n\n        Parameters\n        --------------\n        new_column_name : str | list of str, optional\n            The new column name(s). If original column is list/array type,\n            new_column_name must a string. If original column is dict type,\n            new_column_name must be a list of two strings. If not given, column\n            names are generated automatically.\n\n        drop_na : boolean, optional\n            If True, missing values and empty list/array/dict are all dropped\n            from the resulting column(s). If False, missing values are\n            maintained in stacked column(s).\n\n        new_column_type : type | list of types, optional\n            The new column types. If original column is a list/array type\n            new_column_type must be a single type, or a list of one type. If\n            original column is of dict type, new_column_type must be a list of\n            two types. If not provided, the types are automatically inferred\n            from the first 100 values of the SFrame.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains the newly stacked column(s).\n\n        Examples\n        ---------\n        Suppose 'sa' is an SArray of dict type:\n\n        >>> sa = turicreate.SArray([{'a':3, 'cat':2},\n        ...                         {'a':1, 'the':2},\n        ...                         {'the':1, 'dog':3},\n        ...                         {}])\n        [{'a': 3, 'cat': 2}, {'a': 1, 'the': 2}, {'the': 1, 'dog': 3}, {}]\n\n        Stack would stack all keys in one column and all values in another\n        column:\n\n        >>> sa.stack(new_column_name=['word', 'count'])\n        +------+-------+\n        | word | count |\n        +------+-------+\n        |  a   |   3   |\n        | cat  |   2   |\n        |  a   |   1   |\n        | the  |   2   |\n        | the  |   1   |\n        | dog  |   3   |\n        | None |  None |\n        +------+-------+\n        [7 rows x 2 columns]\n\n        Observe that since topic 4 had no words, an empty row is inserted.\n        To drop that row, set drop_na=True in the parameters to stack.\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n        return _SFrame({'SArray': self}).stack('SArray',\n                                               new_column_name=new_column_name,\n                                               drop_na=drop_na,\n                                               new_column_type=new_column_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an SArray of list array or dict type to an SFrame with the given column names and types and values.", "response": "def unpack(self, column_name_prefix = \"X\", column_types=None, na_value=None, limit=None):\n        \"\"\"\n        Convert an SArray of list, array, or dict type to an SFrame with\n        multiple columns.\n\n        `unpack` expands an SArray using the values of each list/array/dict as\n        elements in a new SFrame of multiple columns. For example, an SArray of\n        lists each of length 4 will be expanded into an SFrame of 4 columns,\n        one for each list element. An SArray of lists/arrays of varying size\n        will be expand to a number of columns equal to the longest list/array.\n        An SArray of dictionaries will be expanded into as many columns as\n        there are keys.\n\n        When unpacking an SArray of list or array type, new columns are named:\n        `column_name_prefix`.0, `column_name_prefix`.1, etc. If unpacking a\n        column of dict type, unpacked columns are named\n        `column_name_prefix`.key1, `column_name_prefix`.key2, etc.\n\n        When unpacking an SArray of list or dictionary types, missing values in\n        the original element remain as missing values in the resultant columns.\n        If the `na_value` parameter is specified, all values equal to this\n        given value are also replaced with missing values. In an SArray of\n        array.array type, NaN is interpreted as a missing value.\n\n        :py:func:`turicreate.SFrame.pack_columns()` is the reverse effect of unpack\n\n        Parameters\n        ----------\n        column_name_prefix: str, optional\n            If provided, unpacked column names would start with the given prefix.\n\n        column_types: list[type], optional\n            Column types for the unpacked columns. If not provided, column\n            types are automatically inferred from first 100 rows. Defaults to\n            None.\n\n        na_value: optional\n            Convert all values that are equal to `na_value` to\n            missing value if specified.\n\n        limit: list, optional\n            Limits the set of list/array/dict keys to unpack.\n            For list/array SArrays, 'limit' must contain integer indices.\n            For dict SArray, 'limit' must contain dictionary keys.\n\n        Returns\n        -------\n        out : SFrame\n            A new SFrame that contains all unpacked columns\n\n        Examples\n        --------\n        To unpack a dict SArray\n\n        >>> sa = SArray([{ 'word': 'a',     'count': 1},\n        ...              { 'word': 'cat',   'count': 2},\n        ...              { 'word': 'is',    'count': 3},\n        ...              { 'word': 'coming','count': 4}])\n\n        Normal case of unpacking SArray of type dict:\n\n        >>> sa.unpack(column_name_prefix=None)\n        Columns:\n            count   int\n            word    str\n        <BLANKLINE>\n        Rows: 4\n        <BLANKLINE>\n        Data:\n        +-------+--------+\n        | count |  word  |\n        +-------+--------+\n        |   1   |   a    |\n        |   2   |  cat   |\n        |   3   |   is   |\n        |   4   | coming |\n        +-------+--------+\n        [4 rows x 2 columns]\n        <BLANKLINE>\n\n        Unpack only keys with 'word':\n\n        >>> sa.unpack(limit=['word'])\n        Columns:\n            X.word  str\n        <BLANKLINE>\n        Rows: 4\n        <BLANKLINE>\n        Data:\n        +--------+\n        | X.word |\n        +--------+\n        |   a    |\n        |  cat   |\n        |   is   |\n        | coming |\n        +--------+\n        [4 rows x 1 columns]\n        <BLANKLINE>\n\n        >>> sa2 = SArray([\n        ...               [1, 0, 1],\n        ...               [1, 1, 1],\n        ...               [0, 1]])\n\n        Convert all zeros to missing values:\n\n        >>> sa2.unpack(column_types=[int, int, int], na_value=0)\n        Columns:\n            X.0     int\n            X.1     int\n            X.2     int\n        <BLANKLINE>\n        Rows: 3\n        <BLANKLINE>\n        Data:\n        +------+------+------+\n        | X.0  | X.1  | X.2  |\n        +------+------+------+\n        |  1   | None |  1   |\n        |  1   |  1   |  1   |\n        | None |  1   | None |\n        +------+------+------+\n        [3 rows x 3 columns]\n        <BLANKLINE>\n        \"\"\"\n        from .sframe import SFrame as _SFrame\n\n        if self.dtype not in [dict, array.array, list]:\n            raise TypeError(\"Only SArray of dict/list/array type supports unpack\")\n\n        if column_name_prefix is None:\n            column_name_prefix = \"\"\n        if not(isinstance(column_name_prefix, six.string_types)):\n            raise TypeError(\"'column_name_prefix' must be a string\")\n\n        # validate 'limit'\n        if limit is not None:\n            if (not _is_non_string_iterable(limit)):\n                raise TypeError(\"'limit' must be a list\")\n\n            name_types = set([type(i) for i in limit])\n            if (len(name_types) != 1):\n                raise TypeError(\"'limit' contains values that are different types\")\n\n            # limit value should be numeric if unpacking sarray.array value\n            if (self.dtype != dict) and (name_types.pop() != int):\n                raise TypeError(\"'limit' must contain integer values.\")\n\n            if len(set(limit)) != len(limit):\n                raise ValueError(\"'limit' contains duplicate values\")\n\n        if (column_types is not None):\n            if not _is_non_string_iterable(column_types):\n                raise TypeError(\"column_types must be a list\")\n\n            for column_type in column_types:\n                if (column_type not in (int, float, str, list, dict, array.array)):\n                    raise TypeError(\"column_types contains unsupported types. Supported types are ['float', 'int', 'list', 'dict', 'str', 'array.array']\")\n\n            if limit is not None:\n                if len(limit) != len(column_types):\n                    raise ValueError(\"limit and column_types do not have the same length\")\n            elif self.dtype == dict:\n                raise ValueError(\"if 'column_types' is given, 'limit' has to be provided to unpack dict type.\")\n            else:\n                limit = range(len(column_types))\n\n        else:\n            head_rows = self.head(100).dropna()\n            lengths = [len(i) for i in head_rows]\n            if len(lengths) == 0 or max(lengths) == 0:\n                raise RuntimeError(\"Cannot infer number of items from the SArray, SArray may be empty. please explicitly provide column types\")\n\n            # infer column types for dict type at server side, for list and array, infer from client side\n            if self.dtype != dict:\n                length = max(lengths)\n                if limit is None:\n                    limit = range(length)\n                else:\n                    # adjust the length\n                    length = len(limit)\n\n                if self.dtype == array.array:\n                    column_types = [float for i in range(length)]\n                else:\n                    column_types = list()\n                    for i in limit:\n                        t = [(x[i] if ((x is not None) and len(x) > i) else None) for x in head_rows]\n                        column_types.append(infer_type_of_list(t))\n\n\n        with cython_context():\n            if (self.dtype == dict and column_types is None):\n                limit = limit if limit is not None else []\n                return _SFrame(_proxy=self.__proxy__.unpack_dict(column_name_prefix.encode('utf-8'), limit, na_value))\n            else:\n                return _SFrame(_proxy=self.__proxy__.unpack(column_name_prefix.encode('utf-8'), limit, column_types, na_value))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort(self, ascending=True):\n        from .sframe import SFrame as _SFrame\n\n        if self.dtype not in (int, float, str, datetime.datetime):\n            raise TypeError(\"Only sarray with type (int, float, str, datetime.datetime) can be sorted\")\n        sf = _SFrame()\n        sf['a'] = self\n        return sf.sort('a', ascending)['a']", "response": "Sort all values in this SArray."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rolling_sum(self, window_start, window_end, min_observations=None):\n        min_observations = self.__check_min_observations(min_observations)\n        agg_op = None\n        if self.dtype is array.array:\n            agg_op = '__builtin__vector__sum__'\n        else:\n            agg_op = '__builtin__sum__'\n        return SArray(_proxy=self.__proxy__.builtin_rolling_apply(agg_op, window_start, window_end, min_observations))", "response": "Calculates the sum of the different subsets over a given time range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the maximum value of the current value in a rolling window over the current value.", "response": "def rolling_max(self, window_start, window_end, min_observations=None):\n        \"\"\"\n        Calculate a new SArray of the maximum value of different subsets over\n        this SArray.\n\n        The subset that the maximum is calculated over is defined as an\n        inclusive range relative to the position to each value in the SArray,\n        using `window_start` and `window_end`. For a better understanding of\n        this, see the examples below.\n\n        Parameters\n        ----------\n        window_start : int\n            The start of the subset to calculate the maximum relative to the\n            current value.\n\n        window_end : int\n            The end of the subset to calculate the maximum relative to the current\n            value. Must be greater than `window_start`.\n\n        min_observations : int\n            Minimum number of non-missing observations in window required to\n            calculate the maximum (otherwise result is None). None signifies that\n            the entire window must not include a missing value. A negative\n            number throws an error.\n\n        Returns\n        -------\n        out : SArray\n\n        Examples\n        --------\n        >>> import pandas\n        >>> sa = SArray([1,2,3,4,5])\n        >>> series = pandas.Series([1,2,3,4,5])\n\n        A rolling max with a window including the previous 2 entries including\n        the current:\n        >>> sa.rolling_max(-2,0)\n        dtype: int\n        Rows: 5\n        [None, None, 3, 4, 5]\n\n        Pandas equivalent:\n        >>> pandas.rolling_max(series, 3)\n        0   NaN\n        1   NaN\n        2     3\n        3     4\n        4     5\n        dtype: float64\n\n        Same rolling max operation, but 2 minimum observations:\n        >>> sa.rolling_max(-2,0,min_observations=2)\n        dtype: int\n        Rows: 5\n        [None, 2, 3, 4, 5]\n\n        Pandas equivalent:\n        >>> pandas.rolling_max(series, 3, min_periods=2)\n        0    NaN\n        1      2\n        2      3\n        3      4\n        4      5\n        dtype: float64\n\n        A rolling max with a size of 3, centered around the current:\n        >>> sa.rolling_max(-1,1)\n        dtype: int\n        Rows: 5\n        [None, 3, 4, 5, None]\n\n        Pandas equivalent:\n        >>> pandas.rolling_max(series, 3, center=True)\n        0   NaN\n        1     3\n        2     4\n        3     5\n        4   NaN\n        dtype: float64\n\n        A rolling max with a window including the current and the 2 entries\n        following:\n        >>> sa.rolling_max(0,2)\n        dtype: int\n        Rows: 5\n        [3, 4, 5, None, None]\n\n        A rolling max with a window including the previous 2 entries NOT\n        including the current:\n        >>> sa.rolling_max(-2,-1)\n        dtype: int\n        Rows: 5\n        [None, None, 2, 3, 4]\n        \"\"\"\n        min_observations = self.__check_min_observations(min_observations)\n        agg_op = '__builtin__max__'\n        return SArray(_proxy=self.__proxy__.builtin_rolling_apply(agg_op, window_start, window_end, min_observations))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rolling_count(self, window_start, window_end):\n        agg_op = '__builtin__nonnull__count__'\n        return SArray(_proxy=self.__proxy__.builtin_rolling_apply(agg_op, window_start, window_end, 0))", "response": "Count the number of non - NULL values of different subsets over this SArray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the cumulative sum of the elements in the current SArray.", "response": "def cumulative_sum(self):\n        \"\"\"\n        Return the cumulative sum of the elements in the SArray.\n\n        Returns an SArray where each element in the output corresponds to the\n        sum of all the elements preceding and including it. The SArray is\n        expected to be of numeric type (int, float), or a numeric vector type.\n\n        Returns\n        -------\n        out : sarray[int, float, array.array]\n\n        Notes\n        -----\n         - Missing values are ignored while performing the cumulative\n           aggregate operation.\n         - For SArray's of type array.array, all entries are expected to\n           be of the same size.\n\n        Examples\n        --------\n        >>> sa = SArray([1, 2, 3, 4, 5])\n        >>> sa.cumulative_sum()\n        dtype: int\n        rows: 3\n        [1, 3, 6, 10, 15]\n        \"\"\"\n        from .. import extensions\n        agg_op = \"__builtin__cum_sum__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cumulative_mean(self):\n        from .. import extensions\n        agg_op = \"__builtin__cum_avg__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))", "response": "Return the cumulative mean of the elements in the current SArray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the cumulative minimum value of the elements in the current SArray.", "response": "def cumulative_min(self):\n        \"\"\"\n        Return the cumulative minimum value of the elements in the SArray.\n\n        Returns an SArray where each element in the output corresponds to the\n        minimum value of all the elements preceding and including it. The\n        SArray is expected to be of numeric type (int, float).\n\n        Returns\n        -------\n        out : SArray[int, float]\n\n        Notes\n        -----\n         - Missing values are ignored while performing the cumulative\n           aggregate operation.\n\n        Examples\n        --------\n        >>> sa = SArray([1, 2, 3, 4, 0])\n        >>> sa.cumulative_min()\n        dtype: int\n        rows: 3\n        [1, 1, 1, 1, 0]\n        \"\"\"\n        from .. import extensions\n        agg_op = \"__builtin__cum_min__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cumulative_max(self):\n        from .. import extensions\n        agg_op = \"__builtin__cum_max__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))", "response": "Return the cumulative maximum value of the elements in the current SArray."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the cumulative standard deviation of the elements in the current SArray.", "response": "def cumulative_std(self):\n        \"\"\"\n        Return the cumulative standard deviation of the elements in the SArray.\n\n        Returns an SArray where each element in the output corresponds to the\n        standard deviation of all the elements preceding and including it. The\n        SArray is expected to be of numeric type, or a numeric vector type.\n\n        Returns\n        -------\n        out : SArray[int, float]\n\n        Notes\n        -----\n         - Missing values are ignored while performing the cumulative\n           aggregate operation.\n\n        Examples\n        --------\n        >>> sa = SArray([1, 2, 3, 4, 0])\n        >>> sa.cumulative_std()\n        dtype: float\n        rows: 3\n        [0.0, 0.5, 0.816496580927726, 1.118033988749895, 1.4142135623730951]\n        \"\"\"\n        from .. import extensions\n        agg_op = \"__builtin__cum_std__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cumulative_var(self):\n        from .. import extensions\n        agg_op = \"__builtin__cum_var__\"\n        return SArray(_proxy = self.__proxy__.builtin_cumulative_aggregate(agg_op))", "response": "Return the cumulative variance of the elements in the current SArray."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter an SArray by values inside an iterable object.", "response": "def filter_by(self, values, exclude=False):\n        \n        \"\"\"\n        Filter an SArray by values inside an iterable object. The result is an SArray that\n        only includes (or excludes) the values in the given ``values`` :class:`~turicreate.SArray`.\n        If ``values`` is not an SArray, we attempt to convert it to one before filtering.\n        \n        Parameters\n        ----------\n        values : SArray | list | numpy.ndarray | pandas.Series | str\n        The values to use to filter the SArray. The resulting SArray will\n        only include rows that have one of these values in the given\n        column.\n        \n        exclude : bool\n        If True, the result SArray will contain all rows EXCEPT those that\n        have one of the ``values``.\n        \n        Returns\n        -------\n        out : SArray\n        The filtered SArray.\n        \n        Examples\n        --------\n        >>> sa = SArray(['dog', 'cat', 'cow', 'horse'])\n        >>> sa.filter_by(['cat', 'hamster', 'dog', 'fish', 'bird', 'snake'])\n        dtype: str\n        Rows: 2\n        ['dog', 'cat']\n        \n        >>> sa.filter_by(['cat', 'hamster', 'dog', 'fish', 'bird', 'snake'], exclude=True)\n        dtype: str\n        Rows: 2\n        ['horse', 'cow']\n        \"\"\"\n    \n        from .sframe import SFrame as _SFrame\n        \n        column_name = 'sarray'\n        \n        # Convert values to SArray\n        if not isinstance(values, SArray): #type(values) is not SArray:\n            # If we were given a single element, try to put in list and convert\n            # to SArray\n            if not _is_non_string_iterable(values):\n                values = [values]\n            values = SArray(values)\n    \n        # Convert values to SFrame\n        value_sf = _SFrame()\n        value_sf.add_column(values, column_name, inplace=True)\n        given_type = value_sf.column_types()[0] #value column type\n        \n        existing_type = self.dtype\n        sarray_sf = _SFrame()\n        sarray_sf.add_column(self, column_name, inplace=True)\n        \n        if given_type != existing_type:\n            raise TypeError(\"Type of given values does not match type of the SArray\")\n        \n        # Make sure the values list has unique values, or else join will not\n        # filter.\n        value_sf = value_sf.groupby(column_name, {})\n        \n        with cython_context():\n            if exclude:\n                id_name = \"id\"\n                value_sf = value_sf.add_row_number(id_name)\n                tmp = _SFrame(_proxy=sarray_sf.__proxy__.join(value_sf.__proxy__,\n                                                        'left',\n                                                        {column_name:column_name}))\n                ret_sf = tmp[tmp[id_name] == None]\n                return ret_sf[column_name]\n            else:\n                ret_sf = _SFrame(_proxy=sarray_sf.__proxy__.join(value_sf.__proxy__,\n                                                             'inner',\n                                                             {column_name:column_name}))\n                return ret_sf[column_name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the doxygen make command in the designated folder.", "response": "def run_build_lib(folder):\n    \"\"\"Run the doxygen make command in the designated folder.\"\"\"\n    try:\n        retcode = subprocess.call(\"cd %s; make\" % folder, shell=True)\n        retcode = subprocess.call(\"rm -rf _build/html/doxygen\", shell=True)\n        retcode = subprocess.call(\"mkdir _build\", shell=True)\n        retcode = subprocess.call(\"mkdir _build/html\", shell=True)\n        retcode = subprocess.call(\"cp -rf doxygen/html _build/html/doxygen\", shell=True)\n        if retcode < 0:\n            sys.stderr.write(\"build terminated by signal %s\" % (-retcode))\n    except OSError as e:\n        sys.stderr.write(\"build execution failed: %s\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the doxygen make commands if we re on the ReadTheDocs server", "response": "def generate_doxygen_xml(app):\n    \"\"\"Run the doxygen make commands if we're on the ReadTheDocs server\"\"\"\n    read_the_docs_build = os.environ.get('READTHEDOCS', None) == 'True'\n    if read_the_docs_build:\n        run_doxygen('..')\n        sys.stderr.write('Check if shared lib exists\\n')\n        run_build_lib('..')\n    sys.stderr.write('The wrapper path: %s\\n' % str(os.listdir('../wrapper')))\n    rabit._loadlib()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef MessageToJson(message,\n                  including_default_value_fields=False,\n                  preserving_proto_field_name=False):\n  \"\"\"Converts protobuf message to JSON format.\n\n  Args:\n    message: The protocol buffers message instance to serialize.\n    including_default_value_fields: If True, singular primitive fields,\n        repeated fields, and map fields will always be serialized.  If\n        False, only serialize non-empty fields.  Singular message fields\n        and oneof fields are not affected by this option.\n    preserving_proto_field_name: If True, use the original proto field\n        names as defined in the .proto file. If False, convert the field\n        names to lowerCamelCase.\n\n  Returns:\n    A string containing the JSON formatted protocol buffer message.\n  \"\"\"\n  printer = _Printer(including_default_value_fields,\n                     preserving_proto_field_name)\n  return printer.ToJsonString(message)", "response": "Converts a protobuf message to JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a protobuf message to a dictionary.", "response": "def MessageToDict(message,\n                  including_default_value_fields=False,\n                  preserving_proto_field_name=False):\n  \"\"\"Converts protobuf message to a JSON dictionary.\n\n  Args:\n    message: The protocol buffers message instance to serialize.\n    including_default_value_fields: If True, singular primitive fields,\n        repeated fields, and map fields will always be serialized.  If\n        False, only serialize non-empty fields.  Singular message fields\n        and oneof fields are not affected by this option.\n    preserving_proto_field_name: If True, use the original proto field\n        names as defined in the .proto file. If False, convert the field\n        names to lowerCamelCase.\n\n  Returns:\n    A dict representation of the JSON formatted protocol buffer message.\n  \"\"\"\n  printer = _Printer(including_default_value_fields,\n                     preserving_proto_field_name)\n  # pylint: disable=protected-access\n  return printer._MessageToJsonObject(message)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ParseDict(js_dict, message, ignore_unknown_fields=False):\n  parser = _Parser(ignore_unknown_fields)\n  parser.ConvertMessage(js_dict, message)\n  return message", "response": "Parses a JSON dictionary representation into a protocol buffer message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a scalar value to a single scalar field value.", "response": "def _ConvertScalarFieldValue(value, field, require_str=False):\n  \"\"\"Convert a single scalar field value.\n\n  Args:\n    value: A scalar value to convert the scalar field value.\n    field: The descriptor of the field to convert.\n    require_str: If True, the field value must be a str.\n\n  Returns:\n    The converted scalar field value\n\n  Raises:\n    ParseError: In case of convert problems.\n  \"\"\"\n  if field.cpp_type in _INT_TYPES:\n    return _ConvertInteger(value)\n  elif field.cpp_type in _FLOAT_TYPES:\n    return _ConvertFloat(value)\n  elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_BOOL:\n    return _ConvertBool(value, require_str)\n  elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_STRING:\n    if field.type == descriptor.FieldDescriptor.TYPE_BYTES:\n      return base64.b64decode(value)\n    else:\n      # Checking for unpaired surrogates appears to be unreliable,\n      # depending on the specific Python version, so we check manually.\n      if _UNPAIRED_SURROGATE_PATTERN.search(value):\n        raise ParseError('Unpaired surrogate')\n      return value\n  elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_ENUM:\n    # Convert an enum value.\n    enum_value = field.enum_type.values_by_name.get(value, None)\n    if enum_value is None:\n      try:\n        number = int(value)\n        enum_value = field.enum_type.values_by_number.get(number, None)\n      except ValueError:\n        raise ParseError('Invalid enum value {0} for enum type {1}.'.format(\n            value, field.enum_type.full_name))\n      if enum_value is None:\n        raise ParseError('Invalid enum value {0} for enum type {1}.'.format(\n            value, field.enum_type.full_name))\n    return enum_value.number"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ConvertInteger(value):\n  if isinstance(value, float) and not value.is_integer():\n    raise ParseError('Couldn\\'t parse integer: {0}.'.format(value))\n\n  if isinstance(value, six.text_type) and value.find(' ') != -1:\n    raise ParseError('Couldn\\'t parse integer: \"{0}\".'.format(value))\n\n  return int(value)", "response": "Convert an integer.\n\n  Args:\n    value: A scalar value to convert.\n\n  Returns:\n    The integer value.\n\n  Raises:\n    ParseError: If an integer couldn't be consumed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ConvertFloat(value):\n  if value == 'nan':\n    raise ParseError('Couldn\\'t parse float \"nan\", use \"NaN\" instead.')\n  try:\n    # Assume Python compatible syntax.\n    return float(value)\n  except ValueError:\n    # Check alternative spellings.\n    if value == _NEG_INFINITY:\n      return float('-inf')\n    elif value == _INFINITY:\n      return float('inf')\n    elif value == _NAN:\n      return float('nan')\n    else:\n      raise ParseError('Couldn\\'t parse float: {0}.'.format(value))", "response": "Convert a floating point number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ConvertBool(value, require_str):\n  if require_str:\n    if value == 'true':\n      return True\n    elif value == 'false':\n      return False\n    else:\n      raise ParseError('Expected \"true\" or \"false\", not {0}.'.format(value))\n\n  if not isinstance(value, bool):\n    raise ParseError('Expected true or false without quotes.')\n  return value", "response": "Converts a scalar value to a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a Proto3 message to a JSON object according to Proto3 JSON Specification.", "response": "def _MessageToJsonObject(self, message):\n    \"\"\"Converts message to an object according to Proto3 JSON Specification.\"\"\"\n    message_descriptor = message.DESCRIPTOR\n    full_name = message_descriptor.full_name\n    if _IsWrapperMessage(message_descriptor):\n      return self._WrapperMessageToJsonObject(message)\n    if full_name in _WKTJSONMETHODS:\n      return methodcaller(_WKTJSONMETHODS[full_name][0], message)(self)\n    js = {}\n    return self._RegularMessageToJsonObject(message, js)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _RegularMessageToJsonObject(self, message, js):\n    fields = message.ListFields()\n\n    try:\n      for field, value in fields:\n        if self.preserving_proto_field_name:\n          name = field.name\n        else:\n          name = field.json_name\n        if _IsMapEntry(field):\n          # Convert a map field.\n          v_field = field.message_type.fields_by_name['value']\n          js_map = {}\n          for key in value:\n            if isinstance(key, bool):\n              if key:\n                recorded_key = 'true'\n              else:\n                recorded_key = 'false'\n            else:\n              recorded_key = key\n            js_map[recorded_key] = self._FieldToJsonObject(\n                v_field, value[key])\n          js[name] = js_map\n        elif field.label == descriptor.FieldDescriptor.LABEL_REPEATED:\n          # Convert a repeated field.\n          js[name] = [self._FieldToJsonObject(field, k)\n                      for k in value]\n        else:\n          js[name] = self._FieldToJsonObject(field, value)\n\n      # Serialize default value if including_default_value_fields is True.\n      if self.including_default_value_fields:\n        message_descriptor = message.DESCRIPTOR\n        for field in message_descriptor.fields:\n          # Singular message fields and oneof fields will not be affected.\n          if ((field.label != descriptor.FieldDescriptor.LABEL_REPEATED and\n               field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE) or\n              field.containing_oneof):\n            continue\n          if self.preserving_proto_field_name:\n            name = field.name\n          else:\n            name = field.json_name\n          if name in js:\n            # Skip the field which has been serailized already.\n            continue\n          if _IsMapEntry(field):\n            js[name] = {}\n          elif field.label == descriptor.FieldDescriptor.LABEL_REPEATED:\n            js[name] = []\n          else:\n            js[name] = self._FieldToJsonObject(field, field.default_value)\n\n    except ValueError as e:\n      raise SerializeToJsonError(\n          'Failed to serialize {0} field: {1}.'.format(field.name, e))\n\n    return js", "response": "Converts a regular message according to Proto3 JSON Specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a field value according to Proto3 JSON Specification.", "response": "def _FieldToJsonObject(self, field, value):\n    \"\"\"Converts field value according to Proto3 JSON Specification.\"\"\"\n    if field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:\n      return self._MessageToJsonObject(value)\n    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_ENUM:\n      enum_value = field.enum_type.values_by_number.get(value, None)\n      if enum_value is not None:\n        return enum_value.name\n      else:\n        raise SerializeToJsonError('Enum field contains an integer value '\n                                   'which can not mapped to an enum value.')\n    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_STRING:\n      if field.type == descriptor.FieldDescriptor.TYPE_BYTES:\n        # Use base64 Data encoding for bytes\n        return base64.b64encode(value).decode('utf-8')\n      else:\n        return value\n    elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_BOOL:\n      return bool(value)\n    elif field.cpp_type in _INT64_TYPES:\n      return str(value)\n    elif field.cpp_type in _FLOAT_TYPES:\n      if math.isinf(value):\n        if value < 0.0:\n          return _NEG_INFINITY\n        else:\n          return _INFINITY\n      if math.isnan(value):\n        return _NAN\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts Any message according to Proto3 JSON Specification.", "response": "def _AnyMessageToJsonObject(self, message):\n    \"\"\"Converts Any message according to Proto3 JSON Specification.\"\"\"\n    if not message.ListFields():\n      return {}\n    # Must print @type first, use OrderedDict instead of {}\n    js = OrderedDict()\n    type_url = message.type_url\n    js['@type'] = type_url\n    sub_message = _CreateMessageFromTypeUrl(type_url)\n    sub_message.ParseFromString(message.value)\n    message_descriptor = sub_message.DESCRIPTOR\n    full_name = message_descriptor.full_name\n    if _IsWrapperMessage(message_descriptor):\n      js['value'] = self._WrapperMessageToJsonObject(sub_message)\n      return js\n    if full_name in _WKTJSONMETHODS:\n      js['value'] = methodcaller(_WKTJSONMETHODS[full_name][0],\n                                 sub_message)(self)\n      return js\n    return self._RegularMessageToJsonObject(sub_message, js)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts Value message according to Proto3 JSON Specification.", "response": "def _ValueMessageToJsonObject(self, message):\n    \"\"\"Converts Value message according to Proto3 JSON Specification.\"\"\"\n    which = message.WhichOneof('kind')\n    # If the Value message is not set treat as null_value when serialize\n    # to JSON. The parse back result will be different from original message.\n    if which is None or which == 'null_value':\n      return None\n    if which == 'list_value':\n      return self._ListValueMessageToJsonObject(message.list_value)\n    if which == 'struct_value':\n      value = message.struct_value\n    else:\n      value = getattr(message, which)\n    oneof_descriptor = message.DESCRIPTOR.fields_by_name[which]\n    return self._FieldToJsonObject(oneof_descriptor, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _StructMessageToJsonObject(self, message):\n    fields = message.fields\n    ret = {}\n    for key in fields:\n      ret[key] = self._ValueMessageToJsonObject(fields[key])\n    return ret", "response": "Converts a Proto3 Struct message according to Proto3 JSON Specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ConvertMessage(self, value, message):\n    message_descriptor = message.DESCRIPTOR\n    full_name = message_descriptor.full_name\n    if _IsWrapperMessage(message_descriptor):\n      self._ConvertWrapperMessage(value, message)\n    elif full_name in _WKTJSONMETHODS:\n      methodcaller(_WKTJSONMETHODS[full_name][1], value, message)(self)\n    else:\n      self._ConvertFieldValuePair(value, message)", "response": "Converts a JSON object into a message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ConvertFieldValuePair(self, js, message):\n    names = []\n    message_descriptor = message.DESCRIPTOR\n    fields_by_json_name = dict((f.json_name, f)\n                               for f in message_descriptor.fields)\n    for name in js:\n      try:\n        field = fields_by_json_name.get(name, None)\n        if not field:\n          field = message_descriptor.fields_by_name.get(name, None)\n        if not field:\n          if self.ignore_unknown_fields:\n            continue\n          raise ParseError(\n              'Message type \"{0}\" has no field named \"{1}\".'.format(\n                  message_descriptor.full_name, name))\n        if name in names:\n          raise ParseError('Message type \"{0}\" should not have multiple '\n                           '\"{1}\" fields.'.format(\n                               message.DESCRIPTOR.full_name, name))\n        names.append(name)\n        # Check no other oneof field is parsed.\n        if field.containing_oneof is not None:\n          oneof_name = field.containing_oneof.name\n          if oneof_name in names:\n            raise ParseError('Message type \"{0}\" should not have multiple '\n                             '\"{1}\" oneof fields.'.format(\n                                 message.DESCRIPTOR.full_name, oneof_name))\n          names.append(oneof_name)\n\n        value = js[name]\n        if value is None:\n          if (field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE\n              and field.message_type.full_name == 'google.protobuf.Value'):\n            sub_message = getattr(message, field.name)\n            sub_message.null_value = 0\n          else:\n            message.ClearField(field.name)\n          continue\n\n        # Parse field value.\n        if _IsMapEntry(field):\n          message.ClearField(field.name)\n          self._ConvertMapFieldValue(value, message, field)\n        elif field.label == descriptor.FieldDescriptor.LABEL_REPEATED:\n          message.ClearField(field.name)\n          if not isinstance(value, list):\n            raise ParseError('repeated field {0} must be in [] which is '\n                             '{1}.'.format(name, value))\n          if field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:\n            # Repeated message field.\n            for item in value:\n              sub_message = getattr(message, field.name).add()\n              # None is a null_value in Value.\n              if (item is None and\n                  sub_message.DESCRIPTOR.full_name != 'google.protobuf.Value'):\n                raise ParseError('null is not allowed to be used as an element'\n                                 ' in a repeated field.')\n              self.ConvertMessage(item, sub_message)\n          else:\n            # Repeated scalar field.\n            for item in value:\n              if item is None:\n                raise ParseError('null is not allowed to be used as an element'\n                                 ' in a repeated field.')\n              getattr(message, field.name).append(\n                  _ConvertScalarFieldValue(item, field))\n        elif field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:\n          sub_message = getattr(message, field.name)\n          sub_message.SetInParent()\n          self.ConvertMessage(value, sub_message)\n        else:\n          setattr(message, field.name, _ConvertScalarFieldValue(value, field))\n      except ParseError as e:\n        if field and field.containing_oneof is None:\n          raise ParseError('Failed to parse {0} field: {1}'.format(name, e))\n        else:\n          raise ParseError(str(e))\n      except ValueError as e:\n        raise ParseError('Failed to parse {0} field: {1}.'.format(name, e))\n      except TypeError as e:\n        raise ParseError('Failed to parse {0} field: {1}.'.format(name, e))", "response": "Convert field value pairs into a regular protocol message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ConvertAnyMessage(self, value, message):\n    if isinstance(value, dict) and not value:\n      return\n    try:\n      type_url = value['@type']\n    except KeyError:\n      raise ParseError('@type is missing when parsing any message.')\n\n    sub_message = _CreateMessageFromTypeUrl(type_url)\n    message_descriptor = sub_message.DESCRIPTOR\n    full_name = message_descriptor.full_name\n    if _IsWrapperMessage(message_descriptor):\n      self._ConvertWrapperMessage(value['value'], sub_message)\n    elif full_name in _WKTJSONMETHODS:\n      methodcaller(\n          _WKTJSONMETHODS[full_name][1], value['value'], sub_message)(self)\n    else:\n      del value['@type']\n      self._ConvertFieldValuePair(value, sub_message)\n    # Sets Any message\n    message.value = sub_message.SerializeToString()\n    message.type_url = type_url", "response": "Convert a JSON representation into Any message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a JSON representation into Wrapper message.", "response": "def _ConvertWrapperMessage(self, value, message):\n    \"\"\"Convert a JSON representation into Wrapper message.\"\"\"\n    field = message.DESCRIPTOR.fields_by_name['value']\n    setattr(message, 'value', _ConvertScalarFieldValue(value, field))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a JSON object to a protocol message map field value.", "response": "def _ConvertMapFieldValue(self, value, message, field):\n    \"\"\"Convert map field value for a message map field.\n\n    Args:\n      value: A JSON object to convert the map field value.\n      message: A protocol message to record the converted data.\n      field: The descriptor of the map field to be converted.\n\n    Raises:\n      ParseError: In case of convert problems.\n    \"\"\"\n    if not isinstance(value, dict):\n      raise ParseError(\n          'Map field {0} must be in a dict which is {1}.'.format(\n              field.name, value))\n    key_field = field.message_type.fields_by_name['key']\n    value_field = field.message_type.fields_by_name['value']\n    for key in value:\n      key_value = _ConvertScalarFieldValue(key, key_field, True)\n      if value_field.cpp_type == descriptor.FieldDescriptor.CPPTYPE_MESSAGE:\n        self.ConvertMessage(value[key], getattr(\n            message, field.name)[key_value])\n      else:\n        getattr(message, field.name)[key_value] = _ConvertScalarFieldValue(\n            value[key], value_field)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the data in x and y on the X axis and shows the resulting visualization.", "response": "def plot(x, y, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    \"\"\"\n    Plots the data in `x` on the X axis and the data in `y` on the Y axis\n    in a 2d visualization, and shows the resulting visualization.\n    Uses the following heuristic to choose the visualization:\n\n    * If `x` and `y` are both numeric (SArray of int or float), and they contain\n      fewer than or equal to 5,000 values, show a scatter plot.\n    * If `x` and `y` are both numeric (SArray of int or float), and they contain\n      more than 5,000 values, show a heat map.\n    * If `x` is numeric and `y` is an SArray of string, show a box and whisker\n      plot for the distribution of numeric values for each categorical (string)\n      value.\n    * If `x` and `y` are both SArrays of string, show a categorical heat map.\n\n    This show method supports SArrays of dtypes: int, float, str.\n\n    Notes\n    -----\n    - The plot will be returned as a Plot object, which can then be shown,\n      saved, etc. and will display automatically in a Jupyter Notebook.\n\n    Parameters\n    ----------\n    x : SArray\n      The data to plot on the X axis of a 2d visualization.\n    y : SArray\n      The data to plot on the Y axis of a 2d visualization. Must be the same\n      length as `x`.\n    xlabel : str (optional)\n      The text label for the X axis. Defaults to \"X\".\n    ylabel : str (optional)\n      The text label for the Y axis. Defaults to \"Y\".\n    title : str (optional)\n      The title of the plot. Defaults to LABEL_DEFAULT. If the value is\n      LABEL_DEFAULT, the title will be \"<xlabel> vs. <ylabel>\". If the value\n      is None, the title will be omitted. Otherwise, the string passed in as the\n      title will be used as the plot title.\n\n    Examples\n    --------\n    Show a categorical heat map of pets and their feelings.\n\n    >>> x = turicreate.SArray(['dog', 'cat', 'dog', 'dog', 'cat'])\n    >>> y = turicreate.SArray(['happy', 'grumpy', 'grumpy', 'happy', 'grumpy'])\n    >>> turicreate.show(x, y)\n\n\n    Show a scatter plot of the function y = 2x, for x from 0 through 9, labeling\n    the axes and plot title with custom strings.\n\n    >>> x = turicreate.SArray(range(10))\n    >>> y = x * 2\n    >>> turicreate.show(x, y,\n    ...                 xlabel=\"Custom X label\",\n    ...                 ylabel=\"Custom Y label\",\n    ...                 title=\"Custom title\")\n\n    \"\"\"\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot(x, y, xlabel, ylabel, title)\n    return Plot(plt_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show(x, y, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    plot(x, y, xlabel, ylabel, title).show()", "response": "Displays the data in x and y on the X axis and the data in y on the Y axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scatter(x, y, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    if (not isinstance(x, tc.data_structures.sarray.SArray) or \n        not isinstance(y, tc.data_structures.sarray.SArray) or\n        x.dtype not in [int, float] or y.dtype not in [int, float]):\n        raise ValueError(\"turicreate.visualization.scatter supports \" + \n            \"SArrays of dtypes: int, float\")\n    # legit input\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot_scatter(x, y, \n      xlabel, ylabel,title)\n    return Plot(plt_ref)", "response": "Plots the data in x and y on the X axis and returns the resulting Plot object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef categorical_heatmap(x, y, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    if (not isinstance(x, tc.data_structures.sarray.SArray) or \n        not isinstance(y, tc.data_structures.sarray.SArray) or\n        x.dtype != str or y.dtype != str):\n        raise ValueError(\"turicreate.visualization.categorical_heatmap supports \" + \n            \"SArrays of dtype: str\")\n    # legit input\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot_categorical_heatmap(x, y, \n      xlabel, ylabel, title)\n    return Plot(plt_ref)", "response": "Plots the data in x and y on the X axis and returns the resulting plot object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the data in `x` on the X axis and the data in `y` on the Y axis in a 2d box and whiskers plot, and returns the resulting Plot object. The function x as SArray of dtype str and y as SArray of dtype: int, float. Parameters ---------- x : SArray The data to plot on the X axis of the box and whiskers plot. Must be an SArray with dtype string. y : SArray The data to plot on the Y axis of the box and whiskers plot. Must be numeric (int/float) and must be the same length as `x`. xlabel : str (optional) The text label for the X axis. Defaults to \"X\". ylabel : str (optional) The text label for the Y axis. Defaults to \"Y\". title : str (optional) The title of the plot. Defaults to LABEL_DEFAULT. If the value is LABEL_DEFAULT, the title will be \"<xlabel> vs. <ylabel>\". If the value is None, the title will be omitted. Otherwise, the string passed in as the title will be used as the plot title. Returns ------- out : Plot A :class: Plot object that is the box and whiskers plot. Examples -------- Make a box and whiskers plot. >>> bp = turicreate.visualization.box_plot(tc.SArray(['a','b','c','a','a']),tc.SArray([4.0,3.25,2.1,2.0,1.0]))", "response": "def box_plot(x, y, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    \"\"\"\n    Plots the data in `x` on the X axis and the data in `y` on the Y axis\n    in a 2d box and whiskers plot, and returns the resulting Plot object.\n    \n    The function x as SArray of dtype str and y as SArray of dtype: int, float.\n\n    Parameters\n    ----------\n    x : SArray\n      The data to plot on the X axis of the box and whiskers plot. \n      Must be an SArray with dtype string.\n    y : SArray\n      The data to plot on the Y axis of the box and whiskers plot. \n      Must be numeric (int/float) and must be the same length as `x`.\n    xlabel : str (optional)\n      The text label for the X axis. Defaults to \"X\".\n    ylabel : str (optional)\n      The text label for the Y axis. Defaults to \"Y\".\n    title : str (optional)\n      The title of the plot. Defaults to LABEL_DEFAULT. If the value is\n      LABEL_DEFAULT, the title will be \"<xlabel> vs. <ylabel>\". If the value\n      is None, the title will be omitted. Otherwise, the string passed in as the\n      title will be used as the plot title.\n\n    Returns\n    -------\n    out : Plot\n      A :class: Plot object that is the box and whiskers plot.\n\n    Examples\n    --------\n    Make a box and whiskers plot.\n\n    >>> bp = turicreate.visualization.box_plot(tc.SArray(['a','b','c','a','a']),tc.SArray([4.0,3.25,2.1,2.0,1.0]))\n    \"\"\"\n    if (not isinstance(x, tc.data_structures.sarray.SArray) or \n        not isinstance(y, tc.data_structures.sarray.SArray) or\n        x.dtype != str or y.dtype not in [int, float]):\n        raise ValueError(\"turicreate.visualization.box_plot supports \" + \n            \"x as SArray of dtype str and y as SArray of dtype: int, float.\" +\n            \"\\nExample: turicreate.visualization.box_plot(tc.SArray(['a','b','c','a','a']),tc.SArray([4.0,3.25,2.1,2.0,1.0]))\")\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot_boxes_and_whiskers(x, y, \n      xlabel, ylabel, title)\n    return Plot(plt_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef columnwise_summary(sf):\n    if not isinstance(sf, tc.data_structures.sframe.SFrame):\n        raise ValueError(\"turicreate.visualization.columnwise_summary \" + \n            \"supports SFrame\")\n    plt_ref = tc.extensions.plot_columnwise_summary(sf)\n    return Plot(plt_ref)", "response": "Returns a columnwise summary plot of the input SFrame."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef histogram(sa, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    if (not isinstance(sa, tc.data_structures.sarray.SArray) or \n        sa.dtype not in [int, float]):\n        raise ValueError(\"turicreate.visualization.histogram supports \" + \n            \"SArrays of dtypes: int, float\")\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot_histogram(sa, \n      xlabel, ylabel, title)\n    return Plot(plt_ref)", "response": "Plots a histogram of the input SArray and returns the resulting Plot object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef item_frequency(sa, xlabel=LABEL_DEFAULT, ylabel=LABEL_DEFAULT, title=LABEL_DEFAULT):\n    if (not isinstance(sa, tc.data_structures.sarray.SArray) or\n        sa.dtype != str):\n        raise ValueError(\"turicreate.visualization.item_frequency supports \" + \n            \"SArrays of dtype str\")\n    title = _get_title(title)\n    plt_ref = tc.extensions.plot_item_frequency(sa, \n      xlabel, ylabel, title)\n    return Plot(plt_ref)", "response": "Returns the item frequency plot of the input SArray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the input file and returns a list of C code and corresponding header file.", "response": "def Parse(factory, file):\n    \"\"\"\n    Parses the input file and returns C code and corresponding header file.\n    \"\"\"\n\n    entities = []\n\n    while 1:\n        # Just gets the whole struct nicely formatted\n        data = GetNextStruct(file)\n\n        if not data:\n            break\n\n        entities.extend(ProcessStruct(factory, data))\n\n    return entities"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the name inside an enumeration for distinguishing data types.", "response": "def EntryTagName(self, entry):\n        \"\"\"Creates the name inside an enumeration for distinguishing data\n        types.\"\"\"\n        name = \"%s_%s\" % (self._name, entry.Name())\n        return name.upper()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking an array add indentation to each entry and prints it.", "response": "def PrintIndented(self, file, ident, code):\n        \"\"\"Takes an array, add indentation to each entry and prints it.\"\"\"\n        for entry in code:\n            print >>file, '%s%s' % (ident, entry)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the tag definitions for a structure.", "response": "def PrintTags(self, file):\n        \"\"\"Prints the tag definitions for a structure.\"\"\"\n        print >>file, '/* Tag definition for %s */' % self._name\n        print >>file, 'enum %s_ {' % self._name.lower()\n        for entry in self._entries:\n            print >>file, '  %s=%d,' % (self.EntryTagName(entry),\n                                        entry.Tag())\n        print >>file, '  %s_MAX_TAGS' % (self._name.upper())\n        print >>file, '};\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new resultset that is aggregated by the given quantile values.", "response": "def QUANTILE(src_column, *args):\n    \"\"\"\n    Builtin approximate quantile aggregator for groupby.\n    Accepts as an argument, one or more of a list of quantiles to query.\n    For instance:\n\n    To extract the median\n\n    >>> sf.groupby(\"user\",\n    ...   {'rating_quantiles':tc.aggregate.QUANTILE('rating', 0.5)})\n\n    To extract a few quantiles\n\n    >>> sf.groupby(\"user\",\n    ...   {'rating_quantiles':tc.aggregate.QUANTILE('rating', [0.25,0.5,0.75])})\n\n    Or equivalently\n\n    >>> sf.groupby(\"user\",\n    ...     {'rating_quantiles':tc.aggregate.QUANTILE('rating', 0.25,0.5,0.75)})\n\n    The returned quantiles are guaranteed to have 0.5% accuracy. That is to say,\n    if the requested quantile is 0.50, the resultant quantile value may be\n    between 0.495 and 0.505 of the true quantile.\n    \"\"\"\n    if len(args) == 1:\n        quantiles = args[0]\n    else:\n        quantiles = list(args)\n\n    if not _is_non_string_iterable(quantiles):\n        quantiles = [quantiles]\n    query = \",\".join([str(i) for i in quantiles])\n    return (\"__builtin__quantile__[\" + query + \"]\", [src_column])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(graph, kmin=0, kmax=10, verbose=True):\n    from turicreate._cython.cy_server import QuietProgress\n\n    if not isinstance(graph, _SGraph):\n        raise TypeError('graph input must be a SGraph object.')\n\n    opts = {'graph': graph.__proxy__, 'kmin': kmin, 'kmax': kmax}\n\n    with QuietProgress(verbose):\n        params = _tc.extensions._toolkits.graph.kcore.create(opts)\n\n    return KcoreModel(params['model'])", "response": "Compute the K - Core decomposition of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raise_error_unsupported_categorical_option(option_name, option_value, layer_type, layer_name):\n    raise RuntimeError(\"Unsupported option %s=%s in layer %s(%s)\" % (option_name, option_value,\n        layer_type, layer_name))", "response": "Raise an error if an option is not supported in a categorical layer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_or_validate_classifier_output_features(\n        output_features, class_labels, supports_class_scores = True):\n\n    \"\"\"\n    Given a list of class labels and a list of output_features, validate the\n    list and return a valid version of output_features with all the correct\n    data type information included.\n    \"\"\"\n\n    def raise_error(msg):\n\n        raise ValueError(\"Classifier error: %s\" % msg)\n\n    class_labels = list(class_labels)\n\n    # First, we need to determine the type of the classes.\n    _int_types = _integer_types + (bool, _np.bool_, _np.int32, _np.int64)\n\n    if all(isinstance(cl, _int_types) for cl in class_labels):\n        output_class_type = datatypes.Int64()\n\n    elif all(isinstance(cl, _string_types) for cl in class_labels):\n        output_class_type = datatypes.String()\n\n    else:\n        raise ValueError('Class labels must be all of type int or all of type string.')\n\n    if output_features is None:\n\n        out = [(\"classLabel\", output_class_type)]\n\n        if supports_class_scores:\n            out += [(\"classProbability\", datatypes.Dictionary(output_class_type))]\n\n    elif isinstance(output_features, _string_types):\n\n        out = [(output_features, output_class_type)]\n\n        if supports_class_scores:\n            out += [(\"classProbability\", datatypes.Dictionary(output_class_type))]\n\n    elif (isinstance(output_features, (list, tuple))\n            and all(isinstance(fn, _string_types) for fn in output_features)\n            and len(output_features) == 2):\n\n        if supports_class_scores:\n            out = [(output_features[0], output_class_type),\n                   (output_features[1], datatypes.Dictionary(output_class_type))]\n        else:\n            raise ValueError(\"Classifier model (as trained) does not support output scores for classes.\")\n\n    elif is_valid_feature_list(output_features):\n\n        output_features = [(k, datatypes._normalize_datatype(dt)) for k, dt in output_features]\n\n        if len(output_features) == 1 or not supports_class_scores:\n            if not output_features[0][1] == output_class_type:\n                raise ValueError(\"Type of output class feature does not match type of class labels.\")\n\n        else:\n            # Make sure the first two output features specified give the output\n            # class field and the output class scores dictionary field\n            if (isinstance(output_features[0][1], datatypes.Dictionary)\n                    and isinstance(output_features[1][1], output_class_type)):\n\n                output_features[0], output_features[1] = output_features[1], output_features[0]\n\n            if not isinstance(output_features[1][1], datatypes.Dictionary):\n                raise_error(\"Output features class scores should be dictionary type.\")\n\n            if output_features[1][1].key_type != output_class_type:\n                raise_error(\"Class scores dictionary key type does not match type of class labels.\")\n\n            if output_features[0][1] != output_class_type:\n                raise_error(\"Specified type of output class does not match type of class labels.\")\n\n        # NOTE: We are intentionally allowing the case where additional fields are allowed\n        # beyond the original two features.\n\n        out = output_features\n\n    else:\n        raise_error(\"Form of output features not recognized\")\n\n    return out", "response": "Given a list of output features and a list of class labels and a list of output_features validate the list and return a valid version of output_features with all the correct data type information included."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nputting features into a standard form from a number of different possible forms. The standard form is a list of 2-tuples of (name, datatype) pairs. The name is a string and the datatype is an object as defined in the _datatype module. The possible input forms are as follows: * A list of strings. in this case, the overall dimension is assumed to be the length of the list. If neighboring names are identical, they are assumed to be an input array of that length. For example: [\"a\", \"b\", \"c\"] resolves to [(\"a\", Double), (\"b\", Double), (\"c\", Double)]. And: [\"a\", \"a\", \"b\"] resolves to [(\"a\", Array(2)), (\"b\", Double)]. * A dictionary of keys to indices or ranges of feature indices. In this case, it's presented as a mapping from keys to indices or ranges of contiguous indices. For example, {\"a\" : 0, \"b\" : [2,3], \"c\" : 1} Resolves to [(\"a\", Double), (\"c\", Double), (\"b\", Array(2))]. Note that the ordering is determined by the indices. * A single string. In this case, the input is assumed to be a single array, with the number of dimensions set using num_dimensions. Notes: If the features variable is in the standard form, it is simply checked and returned. If num_dimensions is given, it is used to check against the existing features, or fill in missing information in the case when features is a single string.", "response": "def process_or_validate_features(features, num_dimensions = None, feature_type_map = {}):\n    \"\"\"\n    Puts features into a standard form from a number of different possible forms.\n\n    The standard form is a list of 2-tuples of (name, datatype) pairs.  The name\n    is a string and the datatype is an object as defined in the _datatype module.\n\n    The possible input forms are as follows:\n\n    *   A list of strings. in this case, the overall dimension is assumed to be\n        the length of the list.  If neighboring names are identical, they are\n        assumed to be an input array of that length.  For example:\n\n           [\"a\", \"b\", \"c\"]\n\n        resolves to\n\n            [(\"a\", Double), (\"b\", Double), (\"c\", Double)].\n\n        And:\n\n            [\"a\", \"a\", \"b\"]\n\n        resolves to\n\n            [(\"a\", Array(2)), (\"b\", Double)].\n\n    *   A dictionary of keys to indices or ranges of feature indices.\n\n        In this case, it's presented as a mapping from keys to indices or\n        ranges of contiguous indices.  For example,\n\n            {\"a\" : 0, \"b\" : [2,3], \"c\" : 1}\n\n        Resolves to\n\n            [(\"a\", Double), (\"c\", Double), (\"b\", Array(2))].\n\n        Note that the ordering is determined by the indices.\n\n    *   A single string.  In this case, the input is assumed to be a single array,\n        with the number of dimensions set using num_dimensions.\n\n\n    Notes:\n\n    If the features variable is in the standard form, it is simply checked and\n    returned.\n\n    If num_dimensions is given, it is used to check against the existing features,\n    or fill in missing information in the case when features is a single string.\n    \"\"\"\n\n    original_features = copy(features)\n\n    if num_dimensions is not None and not isinstance(num_dimensions, _integer_types):\n        raise TypeError(\"num_dimensions must be None, an integer or a long, not '%s'\"\n                % str(type(num_dimensions)))\n\n\n    def raise_type_error(additional_msg):\n        raise TypeError(\"Error processing feature list: %s\\nfeatures = %s\"\n                % (additional_msg, str(original_features)))\n\n    if type(features) is dict and is_valid_feature_list(features.items()):\n        features = features.items()\n\n    # First, see if the features are already in the correct form.  If they are,\n    # then we\n    if is_valid_feature_list(features):\n        if num_dimensions is not None:\n            try:\n                feature_dims = dimension_of_array_features(features)\n            except ValueError:\n                feature_dims = None\n\n            if feature_dims is not None and feature_dims != num_dimensions:\n                raise_type_error(\"Dimension mismatch.\")\n\n        # We may need to translate some parts of this back to the actual\n        # datatype class -- e.g. translate str to datatypes.String().\n        return [(k, datatypes._normalize_datatype(dt)) for k, dt in features]\n\n    if isinstance(features, _string_types):\n        if num_dimensions is None:\n            raise_type_error(\"If a single feature name is given, then \"\n                             \"num_dimensions must be provided.\")\n        features = {features : range(num_dimensions)}\n\n    if isinstance(features, (list, tuple, _np.ndarray)):\n        # Change this into a dictionary\n\n        mapping = defaultdict(lambda: [])\n\n        for i, k in enumerate(features):\n            if not isinstance(k, _string_types):\n                raise_type_error(\"List of feature names must be list of strings.\")\n\n        if num_dimensions is not None and len(features) != num_dimensions:\n            raise_type_error((\"List of feature names has wrong length; \"\n                    \"%d required, %d provided.\")\n                        % (num_dimensions, len(features)))\n\n        for i, k in enumerate(features):\n            mapping[k].append(i)\n\n        # Replace the features\n        features = mapping\n\n    if not isinstance(features, dict):\n        raise_type_error(\"features must be either a list of feature names \"\n                \"or a dictionary of feature names to ranges.\")\n\n    # We'll be invasive here so make a copy.\n    features = copy(features)\n\n    for k, v in list(features.items()):\n\n        if not isinstance(k, str):\n            raise_type_error(\"Feature names must be strings.\")\n\n        def test_index(val):\n            error = False\n            try:\n                if val != int(val):\n                    error = True\n            except:\n                error = True\n\n            if error:\n                raise_type_error(\"Specified indices for feature %s must be integers.\" % k)\n\n            if val < 0 or (num_dimensions is not None and val >= num_dimensions):\n                raise_type_error(\"Index in feature %s out of range.\" % k)\n\n        iterable_types = [tuple, list, set]\n        if _PY3:\n            iterable_types.append(range)\n        else:\n            iterable_types.append(xrange)\n        if isinstance(v, tuple(iterable_types)):\n            for idx in v:\n                test_index(idx)\n\n            # Replace and update\n            features[k] = v = list(sorted(v))\n\n        elif isinstance(v, (int, long)):\n            test_index(v)\n            features[k] = v = [v]\n        else:\n            raise_type_error((\"Value type for feature %s not recognized; \"\n                    \"values must be either integers, lists or range objects.\") % k)\n\n        # check to make sure things are contiguous\n        if v != list(range(v[0], v[-1] + 1)):\n            raise_type_error(\"Index list for feature %s must consist of \"\n            \"a contiguous range of indices.\" % k)\n\n        if len(set(v)) != len(v):\n            raise_type_error(\"Index list for feature %s contains duplicates.\" % k)\n\n    # Now, set num dimensions from the list if it's actually None\n    if num_dimensions is None:\n        from itertools import chain\n        num_dimensions = 1 + max(chain(*[il for k, il in features.items()]))\n\n    if (set().union(*features.values()) != set(range(num_dimensions))\n        or sum(len(v) for v in features.values()) != num_dimensions):\n\n        raise_type_error(\"Supplied indices must cover entire range of 0, ..., num_dimensions-1.\")\n\n\n    # Define the output feature types\n    output_features = [None]*len(features)\n\n    # Finally, go through and map all these things out as types.\n    # Sort by first value of the index range.\n    for i, (k, v) in enumerate(sorted(features.items(), key = lambda t: t[1][0])):\n        if k in feature_type_map:\n            output_features[i] = (k, feature_type_map[k])\n\n        elif len(v) == 1:\n            output_features[i] = (k, datatypes.Double())\n        else:\n            output_features[i] = (k, datatypes.Array(len(v)))\n\n    return output_features"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming python - side bootstrapping of Boost. Build and Python.", "response": "def bootstrap(root_path):\n    \"\"\"Performs python-side bootstrapping of Boost.Build/Python.\n\n    This function arranges for 'b2.whatever' package names to work, while also\n    allowing to put python files alongside corresponding jam modules.\n    \"\"\"\n\n    m = imp.new_module(\"b2\")\n    # Note that:\n    # 1. If __path__ is not list of strings, nothing will work\n    # 2. root_path is already list of strings.\n    m.__path__ = root_path\n    sys.modules[\"b2\"] = m\n\n    import b2.build_system\n    return b2.build_system.main()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_history(self, num=10, segment=0):\n        if num < 0:\n            num = 0\n        if segment < 0:\n            raise TypeError(\"segment must be >= 0\")\n        return self._builder.read_history(num, segment)", "response": "Outputs the last num elements that were appended either by append or append_multiple."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new tree of rules that can be set on targets under certain conditions.", "response": "def flags(rule_or_module, variable_name, condition, values = []):\n    \"\"\" Specifies the flags (variables) that must be set on targets under certain\n        conditions, described by arguments.\n        rule_or_module:   If contains dot, should be a rule name.\n                          The flags will be applied when that rule is\n                          used to set up build actions.\n\n                          If does not contain dot, should be a module name.\n                          The flags will be applied for all rules in that\n                          module.\n                          If module for rule is different from the calling\n                          module, an error is issued.\n\n         variable_name:   Variable that should be set on target\n\n         condition        A condition when this flag should be applied.\n                          Should be set of property sets. If one of\n                          those property sets is contained in build\n                          properties, the flag will be used.\n                          Implied values are not allowed:\n                          \"<toolset>gcc\" should be used, not just\n                          \"gcc\". Subfeatures, like in \"<toolset>gcc-3.2\"\n                          are allowed. If left empty, the flag will\n                          always used.\n\n                          Propery sets may use value-less properties\n                          ('<a>'  vs. '<a>value') to match absent\n                          properties. This allows to separately match\n\n                             <architecture>/<address-model>64\n                             <architecture>ia64/<address-model>\n\n                          Where both features are optional. Without this\n                          syntax we'd be forced to define \"default\" value.\n\n         values:          The value to add to variable. If <feature>\n                          is specified, then the value of 'feature'\n                          will be added.\n    \"\"\"\n    assert isinstance(rule_or_module, basestring)\n    assert isinstance(variable_name, basestring)\n    assert is_iterable_typed(condition, basestring)\n    assert is_iterable(values) and all(isinstance(v, (basestring, type(None))) for v in values)\n    caller = bjam.caller()\n    if not '.' in rule_or_module and caller and caller[:-1].startswith(\"Jamfile\"):\n        # Unqualified rule name, used inside Jamfile. Most likely used with\n        # 'make' or 'notfile' rules. This prevents setting flags on the entire\n        # Jamfile module (this will be considered as rule), but who cares?\n        # Probably, 'flags' rule should be split into 'flags' and\n        # 'flags-on-module'.\n        rule_or_module = qualify_jam_action(rule_or_module, caller)\n    else:\n        # FIXME: revive checking that we don't set flags for a different\n        # module unintentionally\n        pass\n\n    if condition and not replace_grist (condition, ''):\n        # We have condition in the form '<feature>', that is, without\n        # value. That's a previous syntax:\n        #\n        #   flags gcc.link RPATH <dll-path> ;\n        # for compatibility, convert it to\n        #   flags gcc.link RPATH : <dll-path> ;\n        values = [ condition ]\n        condition = None\n\n    if condition:\n        transformed = []\n        for c in condition:\n            # FIXME: 'split' might be a too raw tool here.\n            pl = [property.create_from_string(s,False,True) for s in c.split('/')]\n            pl = feature.expand_subfeatures(pl);\n            transformed.append(property_set.create(pl))\n        condition = transformed\n\n        property.validate_property_sets(condition)\n\n    __add_flag (rule_or_module, variable_name, condition, values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the first element of property - sets which is a subset of the given property - set. Returns an empty list if no such element exists.", "response": "def find_satisfied_condition(conditions, ps):\n    \"\"\"Returns the first element of 'property-sets' which is a subset of\n    'properties', or an empty list if no such element exists.\"\"\"\n    assert is_iterable_typed(conditions, property_set.PropertySet)\n    assert isinstance(ps, property_set.PropertySet)\n\n    for condition in conditions:\n\n        found_all = True\n        for i in condition.all():\n\n            if i.value:\n                found = i.value in ps.get(i.feature)\n            else:\n                # Handle value-less properties like '<architecture>' (compare with\n                # '<architecture>x86').\n                # If $(i) is a value-less property it should match default\n                # value of an optional property. See the first line in the\n                # example below:\n                #\n                #  property set     properties     result\n                # <a> <b>foo      <b>foo           match\n                # <a> <b>foo      <a>foo <b>foo    no match\n                # <a>foo <b>foo   <b>foo           no match\n                # <a>foo <b>foo   <a>foo <b>foo    match\n                found = not ps.get(i.feature)\n\n            found_all = found_all and found\n\n        if found_all:\n            return condition\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inherit_flags(toolset, base, prohibited_properties = []):\n    assert isinstance(toolset, basestring)\n    assert isinstance(base, basestring)\n    assert is_iterable_typed(prohibited_properties, basestring)\n    for f in __module_flags.get(base, []):\n\n        if not f.condition or b2.util.set.difference(f.condition, prohibited_properties):\n            match = __re_first_group.match(f.rule)\n            rule_ = None\n            if match:\n                rule_ = match.group(1)\n\n            new_rule_or_module = ''\n\n            if rule_:\n                new_rule_or_module = toolset + '.' + rule_\n            else:\n                new_rule_or_module = toolset\n\n            __add_flag (new_rule_or_module, f.variable_name, f.condition, f.values)", "response": "Bring all flag definitions from the base toolset into the toolset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a rule name and a property set returns a list of tuples of tuples of rule_name and value names and values which must be set on targets for that rule or module.", "response": "def __set_target_variables_aux (manager, rule_or_module, ps):\n    \"\"\" Given a rule name and a property set, returns a list of tuples of\n        variables names and values, which must be set on targets for that\n        rule/properties combination.\n    \"\"\"\n    assert isinstance(rule_or_module, basestring)\n    assert isinstance(ps, property_set.PropertySet)\n    result = []\n\n    for f in __flags.get(rule_or_module, []):\n\n        if not f.condition or find_satisfied_condition (f.condition, ps):\n            processed = []\n            for v in f.values:\n                # The value might be <feature-name> so needs special\n                # treatment.\n                processed += __handle_flag_value (manager, v, ps)\n\n            for r in processed:\n                result.append ((f.variable_name, r))\n\n    # strip away last dot separated part and recurse.\n    next = __re_split_last_segment.match(rule_or_module)\n\n    if next:\n        result.extend(__set_target_variables_aux(\n            manager, next.group(1), ps))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new flag setting with the specified values.", "response": "def __add_flag (rule_or_module, variable_name, condition, values):\n    \"\"\" Adds a new flag setting with the specified values.\n        Does no checking.\n    \"\"\"\n    assert isinstance(rule_or_module, basestring)\n    assert isinstance(variable_name, basestring)\n    assert is_iterable_typed(condition, property_set.PropertySet)\n    assert is_iterable(values) and all(\n        isinstance(v, (basestring, type(None))) for v in values)\n    f = Flag(variable_name, values, condition, rule_or_module)\n\n    # Grab the name of the module\n    m = __re_first_segment.match (rule_or_module)\n    assert m\n    module = m.group(1)\n\n    __module_flags.setdefault(module, []).append(f)\n    __flags.setdefault(rule_or_module, []).append(f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a Logistic Regression model to the protobuf spec.", "response": "def convert(model, feature_names, target):\n    \"\"\"Convert a Logistic Regression model to the protobuf spec.\n    Parameters\n    ----------\n    model: LogisticRegression\n        A trained LogisticRegression model.\n\n    feature_names: [str], optional (default=None)\n        Name of the input columns.\n\n    target: str, optional (default=None)\n        Name of the output column.\n\n    Returns\n    -------\n    model_spec: An object of type Model_pb.\n        Protobuf representation of the model\n    \"\"\"\n    if not(_HAS_SKLEARN):\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n\n    _sklearn_util.check_expected_type(model, LogisticRegression)\n    _sklearn_util.check_fitted(model, lambda m: hasattr(m, 'coef_'))\n\n    return _MLModel(_convert(model, feature_names, target))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the root of the given path.", "response": "def root (path, root):\n    \"\"\" If 'path' is relative, it is rooted at 'root'. Otherwise, it's unchanged.\n    \"\"\"\n    if os.path.isabs (path):\n        return path\n    else:\n        return os.path.join (root, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the string of the reverse of the given path.", "response": "def reverse(path):\n    \"\"\"Returns path2 such that `os.path.join(path, path2) == '.'`.\n    `path` may not contain '..' or be rooted.\n\n    Args:\n        path (str): the path to reverse\n\n    Returns:\n        the string of the reversed path\n\n    Example:\n\n        >>> p1 = 'path/to/somewhere'\n        >>> p2 = reverse('path/to/somewhere')\n        >>> p2\n        '../../..'\n        >>> os.path.normpath(os.path.join(p1, p2))\n        '.'\n    \"\"\"\n    if is_rooted(path) or '..' in path:\n        from b2.manager import get_manager\n        get_manager().errors()(\n            'reverse(path): path is either rooted or contains \"..\" in the path')\n    if path == '.':\n        return path\n    path = os.path.normpath(path)\n    # os.sep.join() is being used over os.path.join() due\n    # to an extra '..' that is created by os.path.join()\n    return os.sep.join('..' for t in path.split(os.sep))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef glob (dirs, patterns):\n#   {\n#       local result ;\n#       if $(patterns:D)\n#       {\n#           # When a pattern has a directory element, we first glob for\n#           # directory, and then glob for file name is the found directories.\n#           for local p in $(patterns)\n#           {\n#               # First glob for directory part.\n#               local globbed-dirs = [ glob $(dirs) : $(p:D) ] ;\n#               result += [ glob $(globbed-dirs) : $(p:D=\"\") ] ;\n#           }\n#       }\n#       else\n#       {\n#           # When a pattern has not directory, we glob directly.\n#           # Take care of special \"..\" value. The \"GLOB\" rule simply ignores\n#           # the \"..\" element (and \".\") element in directory listings. This is\n#           # needed so that\n#           #\n#           #    [ glob libs/*/Jamfile ]\n#           #\n#           # don't return\n#           #\n#           #    libs/../Jamfile (which is the same as ./Jamfile)\n#           #\n#           # On the other hand, when \"..\" is explicitly present in the pattern\n#           # we need to return it.\n#           #\n#           for local dir in $(dirs)\n#           {\n#               for local p in $(patterns)\n#               {\n#                   if $(p) != \"..\"\n#                   {\n#                       result += [ sequence.transform make\n#                           : [ GLOB [ native $(dir) ] : $(p) ] ] ;\n#                   }\n#                   else\n#                   {\n#                       result += [ path.join $(dir) .. ] ;\n#                   }\n#               }\n#           }\n#       }\n#       return $(result) ;\n#   }\n#\n\n# TODO: (PF) I replaced the code above by this. I think it should work but needs to be tested.\n    result = []\n    dirs = to_seq (dirs)\n    patterns = to_seq (patterns)\n\n    splitdirs = []\n    for dir in dirs:\n        splitdirs += dir.split (os.pathsep)\n\n    for dir in splitdirs:\n        for pattern in patterns:\n            p = os.path.join (dir, pattern)\n            import glob\n            result.extend (glob.glob (p))\n    return result", "response": "Globs the given directories and patterns."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef glob(dirs, patterns, exclude_patterns=None):\n\n    assert(isinstance(patterns, list))\n    assert(isinstance(dirs, list))\n\n    if not exclude_patterns:\n        exclude_patterns = []\n    else:\n       assert(isinstance(exclude_patterns, list))\n\n    real_patterns = [os.path.join(d, p) for p in patterns for d in dirs]\n    real_exclude_patterns = [os.path.join(d, p) for p in exclude_patterns\n                             for d in dirs]\n\n    inc = [os.path.normpath(name) for p in real_patterns\n           for name in builtin_glob(p)]\n    exc = [os.path.normpath(name) for p in real_exclude_patterns\n           for name in builtin_glob(p)]\n    return [x for x in inc if x not in exc]", "response": "Returns the list of files matching the given pattern in the specified directories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef glob_in_parents(dir, patterns, upper_limit=None):\n\n    assert(isinstance(dir, str))\n    assert(isinstance(patterns, list))\n\n    result = []\n\n    absolute_dir = os.path.join(os.getcwd(), dir)\n    absolute_dir = os.path.normpath(absolute_dir)\n    while absolute_dir:\n        new_dir = os.path.split(absolute_dir)[0]\n        if new_dir == absolute_dir:\n            break\n        result = glob([new_dir], patterns)\n        if result:\n            break\n        absolute_dir = new_dir\n\n    return result", "response": "Recursive version of GLOB which globs all parent directories of dir until the first match is found. Returns an empty list if no match is found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _run_toolkit_function(fnname, arguments, args, kwargs):\n    # scan for all the arguments in args\n    num_args_got = len(args) + len(kwargs)\n    num_args_required = len(arguments)\n    if num_args_got != num_args_required:\n        raise TypeError(\"Expecting \" + str(num_args_required) + \" arguments, got \" + str(num_args_got))\n\n    ## fill the dict first with the regular args\n    argument_dict = {}\n    for i in range(len(args)):\n        argument_dict[arguments[i]] = args[i]\n\n    # now fill with the kwargs.\n    for k in kwargs.keys():\n        if k in argument_dict:\n            raise TypeError(\"Got multiple values for keyword argument '\" + k + \"'\")\n        argument_dict[k] = kwargs[k]\n\n    # unwrap it\n    with cython_context():\n        ret = _get_unity().run_toolkit(fnname, argument_dict)\n    # handle errors\n    if not ret[0]:\n        if len(ret[1]) > 0:\n            raise _ToolkitError(ret[1])\n        else:\n            raise _ToolkitError(\"Toolkit failed with unknown error\")\n\n    ret = _wrap_function_return(ret[2])\n    if type(ret) is dict and 'return_value' in ret:\n        return ret['return_value']\n    else:\n        return ret", "response": "Dispatches arguments to a toolkit function and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _class_instance_from_name(class_name, *arg, **kwarg):\n    # we first look in tc.extensions for the class name\n    module_path = class_name.split('.')\n    import_path = module_path[0:-1]\n    module = __import__('.'.join(import_path), fromlist=[module_path[-1]])\n    class_ = getattr(module, module_path[-1])\n    instance = class_(*arg, **kwarg)\n    return instance", "response": "This function returns the class instance from the given class name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_class_instance(class_name, _proxy):\n    try:\n        return _class_instance_from_name('turicreate.extensions.' + class_name, _proxy=_proxy)\n    except:\n        pass\n    return _class_instance_from_name(class_name, _proxy=_proxy)", "response": "Create a class instance from a class name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _publish():\n\n    import copy\n    \"\"\"\n    Publishes all functions and classes registered in unity_server.\n    The functions and classes will appear in the module turicreate.extensions\n    \"\"\"\n    unity = _get_unity()\n    fnlist = unity.list_toolkit_functions()\n    # Loop through all the functions and inject it into\n    # turicreate.extensions.[blah]\n    # Note that [blah] may be somemodule.somefunction\n    # and so the injection has to be\n    # turicreate.extensions.somemodule.somefunction\n    for fn in fnlist:\n        props = unity.describe_toolkit_function(fn)\n        # quit if there is nothing we can process\n        if 'arguments' not in props:\n            continue\n        arguments = props['arguments']\n\n        newfunc = _make_injected_function(fn, arguments)\n\n        newfunc.__doc__ = \"Name: \" + fn + \"\\nParameters: \" + str(arguments) + \"\\n\"\n        if 'documentation' in props:\n            newfunc.__doc__ += props['documentation'] + \"\\n\"\n\n        newfunc.__dict__['__glmeta__'] = {'extension_name':fn}\n        modpath = fn.split('.')\n        # walk the module tree\n        mod = _thismodule\n        for path in modpath[:-1]:\n            try:\n                getattr(mod, path)\n            except:\n                _setattr_wrapper(mod, path, _types.ModuleType(name=path))\n            mod = getattr(mod, path)\n        _setattr_wrapper(mod, modpath[-1], newfunc)\n\n    # Repeat for classes\n    tkclasslist = unity.list_toolkit_classes()\n    for tkclass in tkclasslist:\n        m = unity.describe_toolkit_class(tkclass)\n        # of v2 type\n        if not ('functions' in m and 'get_properties' in m and 'set_properties' in m and 'uid' in m):\n            continue\n\n        # create a new class\n        if _version_info.major == 3:\n            new_class = _ToolkitClass.__dict__.copy()\n            del new_class['__dict__']\n            del new_class['__weakref__']\n        else:\n            new_class = copy.deepcopy(_ToolkitClass.__dict__)\n\n        new_class['__init__'] = _types.FunctionType(new_class['__init__'].__code__,\n                                                    new_class['__init__'].__globals__,\n                                                    name='__init__',\n                                                    argdefs=(),\n                                                    closure=())\n\n        # rewrite the init method to add the toolkit class name so it will\n        # default construct correctly\n        new_class['__init__'].tkclass_name = tkclass\n\n        newclass = _class_type(tkclass, (), new_class)\n        setattr(newclass, '__glmeta__', {'extension_name':tkclass})\n        class_uid_to_class[m['uid']] = newclass\n        modpath = tkclass.split('.')\n        # walk the module tree\n        mod = _thismodule\n        for path in modpath[:-1]:\n            try:\n                getattr(mod, path)\n            except:\n                _setattr_wrapper(mod, path, _types.ModuleType(name=path))\n            mod = getattr(mod, path)\n        _setattr_wrapper(mod, modpath[-1], newclass)", "response": "Publishes all functions and classes registered in unity_server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ext_import(soname, module_subpath=\"\"):\n    unity = _get_unity()\n    import os\n    if os.path.exists(soname):\n        soname = os.path.abspath(soname)\n    else:\n        soname = _make_internal_url(soname)\n    ret = unity.load_toolkit(soname, module_subpath)\n    if len(ret) > 0:\n        raise RuntimeError(ret)\n    _publish()\n    # push the functions into the corresponding module namespace\n    return unity.list_toolkit_functions_in_dynamic_module(soname) + unity.list_toolkit_classes_in_dynamic_module(soname)", "response": "This function loads a turicreate extension module from a shared library into the turicreate. extensions namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_argument_list_from_toolkit_function_name(fn):\n    unity = _get_unity()\n    fnprops = unity.describe_toolkit_function(fn)\n    argnames = fnprops['arguments']\n    return argnames", "response": "Given a toolkit function name return the argument list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _descend_namespace(caller_globals, name):\n    names =  name.split('.')\n    cur = caller_globals\n    for i in names:\n        if type(cur) is dict:\n            cur = cur[i]\n        else:\n            cur = getattr(cur, i)\n    return cur", "response": "Given a globals dictionary and a name of the form a. b. c. d return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_native_function_call(fn):\n    # See if fn is the native function itself\n    native_function_name = _get_toolkit_function_name_from_function(fn)\n    if native_function_name != \"\":\n        # yup!\n        # generate an \"identity\" argument list\n        argnames = _get_argument_list_from_toolkit_function_name(native_function_name)\n        arglist = [[0, i] for i in range(len(argnames))]\n        return _Closure(native_function_name, arglist)\n\n    # ok. its not a native function\n    from .util.lambda_closure_capture import translate\n    from .util.lambda_closure_capture import Parameter\n\n    # Lets see if it is a simple lambda\n    capture = translate(fn)\n    # ok. build up the closure arguments\n    # Try to pick up the lambda\n    function = _descend_namespace(capture.caller_globals, capture.closure_fn_name)\n    native_function_name = _get_toolkit_function_name_from_function(function)\n    if native_function_name == \"\":\n        raise RuntimeError(\"Lambda does not contain a native function\")\n\n    argnames = _get_argument_list_from_toolkit_function_name(native_function_name)\n\n    # ok. build up the argument list. this is mildly annoying due to the mix of\n    # positional and named arguments\n    # make an argument list with a placeholder for everything first\n    arglist = [[-1, i] for i in argnames]\n    # loop through the positional arguments\n    for i in range(len(capture.positional_args)):\n        arg = capture.positional_args[i]\n        if type(arg) is Parameter:\n            # This is a lambda argument\n            # arg.name is the actual string of the argument\n            # here we need the index\n            arglist[i] = [0, capture.input_arg_names.index(arg.name)]\n        else:\n            # this is a captured value\n            arglist[i] = [1, arg]\n\n    # now. the named arguments are somewhat annoying\n    for i in capture.named_args:\n        arg = capture.named_args[i]\n        if type(arg) is Parameter:\n            # This is a lambda argument\n            # arg.name is the actual string of the argument\n            # here we need the index\n            arglist[argnames.index(i)] = [0, capture.input_arg_names.index(arg.name)]\n        else:\n            # this is a captured value\n            arglist[argnames.index(i)] = [1, arg]\n\n    # done. Make sure all arguments are filled\n    for i in arglist:\n        if i[0] == -1:\n            raise RuntimeError(\"Incomplete function specification\")\n\n    # attempt to recursively break down any other functions\n    import inspect\n    for i in range(len(arglist)):\n        if arglist[i][0] == 1 and  inspect.isfunction(arglist[i][1]):\n            try:\n                arglist[i][1] = _build_native_function_call(arglist[i][1])\n            except:\n                pass\n    return _Closure(native_function_name, arglist)", "response": "Builds a native function call based on the provided function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_module(self, fullname, submodule_path=None):\n        # first see if we have this particular so has been loaded by\n        # turicreate's extension library before\n        ret = self.try_find_module(fullname, submodule_path)\n        if ret is not None:\n            return ret\n        # nope. has not been loaded before\n        # lets try to find a \".so\" or a \".dylib\" if any of the python\n        # locations\n        import sys\n        import os\n        # This drops the last \".\" So if I am importing aaa.bbb.xxx\n        # module_subpath is aaa.bbb\n        module_subpath = \".\".join(fullname.split('.')[:-1])\n        for path in sys.path:\n            # joins the path to aaa/bbb/xxx\n            pathname = os.path.join(path, os.sep.join(fullname.split('.')))\n            # try to laod the \".so\" extension\n            try:\n                if os.path.exists(pathname + '.so'):\n                    ext_import(pathname + '.so', module_subpath)\n                    break\n            except:\n                pass\n\n            # try to laod the \".dylib\" extension\n            try:\n                if os.path.exists(pathname + '.dylib'):\n                    ext_import(pathname + '.dylib', module_subpath)\n                    break\n            except:\n                pass\n        ret = self.try_find_module(fullname, submodule_path)\n        if ret is not None:\n            return ret", "response": "Try to find a module in sys. path that refers to a specific module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    source_lines = (line.rstrip() for line in sys.stdin)\n    console = InteractiveInterpreter()\n    console.runsource('import turicreate')\n    source = ''\n    try:\n        while True:\n            source = source_lines.next()\n            more = console.runsource(source)\n            while more:\n                next_line = source_lines.next()\n                print '...', next_line\n                source += '\\n' + next_line\n                more = console.runsource(source)\n    except StopIteration:\n        if more:\n            print '... '\n            more = console.runsource(source + '\\n')", "response": "Print lines of input along with output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a type checker for a message field of the specified types.", "response": "def GetTypeChecker(field):\n  \"\"\"Returns a type checker for a message field of the specified types.\n\n  Args:\n    field: FieldDescriptor object for this field.\n\n  Returns:\n    An instance of TypeChecker which can be used to verify the types\n    of values assigned to a field of the specified type.\n  \"\"\"\n  if (field.cpp_type == _FieldDescriptor.CPPTYPE_STRING and\n      field.type == _FieldDescriptor.TYPE_STRING):\n    return UnicodeValueChecker()\n  if field.cpp_type == _FieldDescriptor.CPPTYPE_ENUM:\n    if SupportsOpenEnums(field):\n      # When open enums are supported, any int32 can be assigned.\n      return _VALUE_CHECKERS[_FieldDescriptor.CPPTYPE_INT32]\n    else:\n      return EnumValueChecker(field.enum_type)\n  return _VALUE_CHECKERS[field.cpp_type]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntype check the provided value and return it.", "response": "def CheckValue(self, proposed_value):\n    \"\"\"Type check the provided value and return it.\n\n    The returned value might have been normalized to another type.\n    \"\"\"\n    if not isinstance(proposed_value, self._acceptable_types):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), self._acceptable_types))\n      raise TypeError(message)\n    return proposed_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef python_source(ast, file=sys.stdout):\n    '''\n    Generate executable python source code from an ast node.\n      \n    :param ast: ast node\n    :param file: file to write output to.\n    '''\n    gen = SourceGen()\n    gen.visit(ast)\n    gen.dump(file)", "response": "Generate executable python source code from an ast node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nescape a byte string for use in an ascii protocol buffer.", "response": "def CEscape(text, as_utf8):\n  \"\"\"Escape a bytes string for use in an ascii protocol buffer.\n\n  text.encode('string_escape') does not seem to satisfy our needs as it\n  encodes unprintable characters using two-digit hex escapes whereas our\n  C++ unescaping function allows hex escapes to be any length.  So,\n  \"\\0011\".encode('string_escape') ends up being \"\\\\x011\", which will be\n  decoded in C++ as a single-character string with char code 0x11.\n\n  Args:\n    text: A byte string to be escaped\n    as_utf8: Specifies if result should be returned in UTF-8 encoding\n  Returns:\n    Escaped string\n  \"\"\"\n  # PY3 hack: make Ord work for str and bytes:\n  # //platforms/networking/data uses unicode here, hence basestring.\n  Ord = ord if isinstance(text, six.string_types) else lambda x: x\n  if as_utf8:\n    return ''.join(_cescape_utf8_to_str[Ord(c)] for c in text)\n  return ''.join(_cescape_byte_to_str[Ord(c)] for c in text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CUnescape(text):\n\n  def ReplaceHex(m):\n    # Only replace the match if the number of leading back slashes is odd. i.e.\n    # the slash itself is not escaped.\n    if len(m.group(1)) & 1:\n      return m.group(1) + 'x0' + m.group(2)\n    return m.group(0)\n\n  # This is required because the 'string_escape' encoding doesn't\n  # allow single-digit hex escapes (like '\\xf').\n  result = _CUNESCAPE_HEX.sub(ReplaceHex, text)\n\n  if str is bytes:  # PY2\n    return result.decode('string_escape')\n  result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)\n  return (result.encode('ascii')  # Make it bytes to allow decode.\n          .decode('unicode_escape')\n          # Make it bytes again to return the proper type.\n          .encode('raw_unicode_escape'))", "response": "Unescape a text string with C - style escape sequences to UTF - 8 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset ():\n    global __prefixes_suffixes, __suffixes_to_types, __types, __rule_names_to_types, __target_suffixes_cache\n\n    __register_features ()\n\n    # Stores suffixes for generated targets.\n    __prefixes_suffixes = [property.PropertyMap(), property.PropertyMap()]\n\n    # Maps suffixes to types\n    __suffixes_to_types = {}\n\n    # A map with all the registered types, indexed by the type name\n    # Each entry is a dictionary with following values:\n    # 'base': the name of base type or None if type has no base\n    # 'derived': a list of names of type which derive from this one\n    # 'scanner': the scanner class registered for this type, if any\n    __types = {}\n\n    # Caches suffixes for targets with certain properties.\n    __target_suffixes_cache = {}", "response": "Reset the module state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register (type, suffixes = [], base_type = None):\n    # Type names cannot contain hyphens, because when used as\n    # feature-values they will be interpreted as composite features\n    # which need to be decomposed.\n    if __re_hyphen.search (type):\n        raise BaseException ('type name \"%s\" contains a hyphen' % type)\n\n    # it's possible for a type to be registered with a\n    # base type that hasn't been registered yet. in the\n    # check for base_type below and the following calls to setdefault()\n    # the key `type` will be added to __types. When the base type\n    # actually gets registered, it would fail after the simple check\n    # of \"type in __types\"; thus the check for \"'base' in __types[type]\"\n    if type in __types and 'base' in __types[type]:\n        raise BaseException ('Type \"%s\" is already registered.' % type)\n\n    entry = __types.setdefault(type, {})\n    entry['base'] = base_type\n    entry.setdefault('derived', [])\n    entry.setdefault('scanner', None)\n\n    if base_type:\n        __types.setdefault(base_type, {}).setdefault('derived', []).append(type)\n\n    if len (suffixes) > 0:\n        # Generated targets of 'type' will use the first of 'suffixes'\n        # (this may be overriden)\n        set_generated_target_suffix (type, [], suffixes [0])\n\n        # Specify mapping from suffixes to type\n        register_suffixes (suffixes, type)\n\n    feature.extend('target-type', [type])\n    feature.extend('main-target-type', [type])\n    feature.extend('base-target-type', [type])\n\n    if base_type:\n        feature.compose ('<target-type>' + type, [replace_grist (base_type, '<base-target-type>')])\n        feature.compose ('<base-target-type>' + type, ['<base-target-type>' + base_type])\n\n    import b2.build.generators as generators\n    # Adding a new derived type affects generator selection so we need to\n    # make the generator selection module update any of its cached\n    # information related to a new derived type being defined.\n    generators.update_cached_information_with_a_new_type(type)\n\n    # FIXME: resolving recursive dependency.\n    from b2.manager import get_manager\n    get_manager().projects().project_rules().add_rule_for_type(type)", "response": "Registers a target type with the base - type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the given suffixes with the given type.", "response": "def register_suffixes (suffixes, type):\n    \"\"\" Specifies that targets with suffix from 'suffixes' have the type 'type'.\n        If a different type is already specified for any of syffixes, issues an error.\n    \"\"\"\n    assert is_iterable_typed(suffixes, basestring)\n    assert isinstance(type, basestring)\n    for s in suffixes:\n        if s in __suffixes_to_types:\n            old_type = __suffixes_to_types [s]\n            if old_type != type:\n                raise BaseException ('Attempting to specify type for suffix \"%s\"\\nOld type: \"%s\", New type \"%s\"' % (s, old_type, type))\n        else:\n            __suffixes_to_types [s] = type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a scanner class that will be used for this type.", "response": "def set_scanner (type, scanner):\n    \"\"\" Sets a scanner class that will be used for this 'type'.\n    \"\"\"\n    if __debug__:\n        from .scanner import Scanner\n        assert isinstance(type, basestring)\n        assert issubclass(scanner, Scanner)\n    validate (type)\n    __types [type]['scanner'] = scanner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a scanner instance appropriate to type and property_set.", "response": "def get_scanner (type, prop_set):\n    \"\"\" Returns a scanner instance appropriate to 'type' and 'property_set'.\n    \"\"\"\n    if __debug__:\n        from .property_set import PropertySet\n        assert isinstance(type, basestring)\n        assert isinstance(prop_set, PropertySet)\n    if registered (type):\n        scanner_type = __types [type]['scanner']\n        if scanner_type:\n            return scanner.get (scanner_type, prop_set.raw ())\n            pass\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_bases (type):\n    assert isinstance(type, basestring)\n    result = []\n    while type:\n        result.append (type)\n        type = __types [type]['base']\n\n    return result", "response": "Returns all of the bases of a given type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_derived (type):\n    assert isinstance(type, basestring)\n    result = [type]\n    for d in __types [type]['derived']:\n        result.extend (all_derived (d))\n\n    return result", "response": "Returns all classes that derive from type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true if type is base and base is direct or indirect base.", "response": "def is_derived (type, base):\n    \"\"\" Returns true if 'type' is 'base' or has 'base' as its direct or indirect base.\n    \"\"\"\n    assert isinstance(type, basestring)\n    assert isinstance(base, basestring)\n    # TODO: this isn't very efficient, especially for bases close to type\n    if base in all_bases (type):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if type is a subtype of base.", "response": "def is_subtype (type, base):\n    \"\"\" Same as is_derived. Should be removed.\n    \"\"\"\n    assert isinstance(type, basestring)\n    assert isinstance(base, basestring)\n    # TODO: remove this method\n    return is_derived (type, base)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_generated_target_suffix (type, properties, suffix):\n    assert isinstance(type, basestring)\n    assert is_iterable_typed(properties, basestring)\n    assert isinstance(suffix, basestring)\n    set_generated_target_ps(1, type, properties, suffix)", "response": "Sets a target suffix that should be used when generating a new target\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the suffix previously registered for this type and properties combination.", "response": "def change_generated_target_suffix (type, properties, suffix):\n    \"\"\" Change the suffix previously registered for this type/properties\n        combination. If suffix is not yet specified, sets it.\n    \"\"\"\n    assert isinstance(type, basestring)\n    assert is_iterable_typed(properties, basestring)\n    assert isinstance(suffix, basestring)\n    change_generated_target_ps(1, type, properties, suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generated_target_ps(is_suffix, type, prop_set):\n    if __debug__:\n        from .property_set import PropertySet\n        assert isinstance(is_suffix, (int, bool))\n        assert isinstance(type, basestring)\n        assert isinstance(prop_set, PropertySet)\n    key = (is_suffix, type, prop_set)\n    v = __target_suffixes_cache.get(key, None)\n\n    if not v:\n        v = generated_target_ps_real(is_suffix, type, prop_set.raw())\n        __target_suffixes_cache [key] = v\n\n    return v", "response": "Returns the suffix that should be used when generating target of type with the specified properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef type(filename):\n    assert isinstance(filename, basestring)\n    while 1:\n        filename, suffix = os.path.splitext (filename)\n        if not suffix: return None\n        suffix = suffix[1:]\n\n        if suffix in __suffixes_to_types:\n            return __suffixes_to_types[suffix]", "response": "Returns the file type given it s name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters the given type on the specified OSes or on remaining OSes if os is not specified.", "response": "def register_type (type, suffixes, base_type = None, os = []):\n    \"\"\" Register the given type on the specified OSes, or on remaining OSes\n        if os is not specified.  This rule is injected into each of the type\n        modules for the sake of convenience.\n    \"\"\"\n    assert isinstance(type, basestring)\n    assert is_iterable_typed(suffixes, basestring)\n    assert isinstance(base_type, basestring) or base_type is None\n    assert is_iterable_typed(os, basestring)\n    if registered (type):\n        return\n\n    if not os or os_name () in os:\n        register (type, suffixes, base_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_row(self, **kwargs):\n        '''\n        keys of kwargs must be the names passed to __init__(...) as `column_names`\n        '''\n        meta_string = '|'\n        for key in self.column_names:\n            float_specifier = ''\n            if isinstance(kwargs[key], float):\n                float_specifier = '.3f'\n            meta_string += \" {%s:<{width}%s}|\" % (key, float_specifier)\n        kwargs['width'] = self.column_width - 1\n\n        print(meta_string.format(**kwargs))\n        print(self.hr)", "response": "Prints a row of data in the format that is used by the table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_features(features, exclude):\n\n    # Check types\n    _raise_error_if_not_of_type(features, [NoneType, str, list], 'features')\n    _raise_error_if_not_of_type(exclude, [NoneType, str, list], 'exclude')\n\n    # Make a copy of the parameters.\n    _features = _copy.copy(features)\n    _exclude = _copy.copy(exclude)\n\n    # Check of both are None or empty.\n    if _features and _exclude:\n        raise ValueError(\"The parameters 'features' and 'exclude' cannot both be set.\"\n                \" Please set one or the other.\")\n    if _features == [] and not _exclude:\n        raise ValueError(\"Features cannot be an empty list.\")\n\n\n    # Allow a single list\n    _features = [_features] if type(_features) == str else _features\n    _exclude = [_exclude] if type(_exclude) == str else _exclude\n\n    # Type check each feature/exclude\n    if _features:\n        for f in _features:\n            _raise_error_if_not_of_type(f, str, \"Feature names\")\n    if _exclude:\n        for e in _exclude:\n            _raise_error_if_not_of_type(e, str, \"Excluded feature names\")\n\n    if _exclude is not None and _features is not None:\n        feature_set = set(_features)\n        for col_name in _exclude:\n            if col_name in feature_set:\n                raise ValueError(\"'%s' appears in both features and excluded_features.\" % col_name)\n\n    return _features, _exclude", "response": "Returns a new node that contains the specified features and exclude."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_elementwise_name_from_keras_layer(keras_layer):\n    mode = keras_layer.mode\n    if mode == 'sum':\n        return 'ADD'\n    elif mode == 'mul':\n        return 'MULTIPLY'\n    elif mode == 'concat':\n        if len(keras_layer.input_shape[0]) == 3 and (keras_layer.concat_axis == 1 or keras_layer.concat_axis == -2):\n            return 'SEQUENCE_CONCAT'\n        elif len(keras_layer.input_shape[0]) == 4 and (keras_layer.concat_axis == 3 or keras_layer.concat_axis == -1):\n            return 'CONCAT'\n        elif len(keras_layer.input_shape[0]) == 2 and (keras_layer.concat_axis == 1 or keras_layer.concat_axis == -1):\n            return 'CONCAT'\n        else:\n            option = \"input_shape = %s concat_axis = %s\" % (str(keras_layer.input_shape[0]), str(keras_layer.concat_axis))\n            _utils.raise_error_unsupported_option(option, mode, keras_layer.name)\n    elif mode == 'cos':\n        if len(keras_layer.input_shape[0]) == 2:\n            return 'COS'\n        else:\n            option = \"input_shape = %s\" % (str(keras_layer.input_shape[0]))\n            _utils.raise_error_unsupported_option(option, mode, keras_layer.name)\n    elif mode == 'dot':\n        if len(keras_layer.input_shape[0]) == 2:\n            return 'DOT'\n        else:\n            option = \"input_shape = %s\" % (str(keras_layer.input_shape[0]))\n            _utils.raise_error_unsupported_option(option, mode, keras_layer.name)\n    elif mode == 'max':\n        return 'MAX'\n    elif mode == 'ave':\n        return 'AVE'\n    else:\n        _utils.raise_error_unsupported_categorical_option('mode', mode, 'Merge',\n                keras_layer.name)", "response": "Get the elementwise name from the keras layer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _same_elements_per_channel(x):\n    eps = 1e-5\n    dims = x.shape\n    for c in range(dims[-1]):\n        xc = x[:,:,c].flatten()\n        if not np.all(np.absolute(xc - xc[0]) < eps):\n            return False\n    return True", "response": "Test if a 3D matrix x has the same element in each channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a dense layer from keras to coreml.", "response": "def convert_dense(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert a dense layer from keras to coreml.\n\n    Parameters\n    keras_layer: layer\n    ----------\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    has_bias = keras_layer.bias\n    # Get the weights from keras\n    W = keras_layer.get_weights ()[0].T\n    Wb = keras_layer.get_weights ()[1].T if has_bias else None\n\n    builder.add_inner_product(name = layer,\n            W = W,\n            b = Wb,\n            input_channels = keras_layer.input_dim,\n            output_channels = keras_layer.output_dim,\n            has_bias = has_bias,\n            input_name = input_name,\n            output_name = output_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_activation(builder, layer, input_names, output_names, keras_layer):\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n    non_linearity = _get_activation_name_from_keras_layer(keras_layer)\n\n    # Add a non-linearity layer\n    if non_linearity == 'SOFTMAX':\n        builder.add_softmax(name = layer, input_name = input_name,\n                output_name = output_name)\n        return\n\n    params = None\n    if non_linearity == 'LEAKYRELU':\n        params = [keras_layer.alpha]\n\n    elif non_linearity == 'PRELU':\n        # In Keras 1.2  PReLU layer's weights are stored as a\n        # backend tensor, not a numpy array as it claims in documentation.\n        shared_axes = list(keras_layer.shared_axes)\n        if not (shared_axes == [1,2,3] or shared_axes == [1,2]):\n            _utils.raise_error_unsupported_scenario(\"Shared axis not being [1,2,3] or [1,2]\", 'parametric_relu', layer)\n        params = keras.backend.eval(keras_layer.weights[0])\n    elif non_linearity == 'ELU':\n        params = keras_layer.alpha\n\n    elif non_linearity == 'PARAMETRICSOFTPLUS':\n        # In Keras 1.2  Parametric Softplus layer's weights are stored as a\n        # backend tensor, not a numpy array as it claims in documentation.\n        alphas = keras.backend.eval(keras_layer.weights[0])\n        betas = keras.backend.eval(keras_layer.weights[1])\n\n        if len(alphas.shape) == 3:  # (H,W,C)\n            if not (_same_elements_per_channel(alphas) and _same_elements_per_channel(betas)):\n                _utils.raise_error_unsupported_scenario(\"Different parameter values\", 'parametric_softplus', layer)\n            alphas = alphas[0,0,:]\n            betas = betas[0,0,:]\n        params = [alphas, betas]\n\n    elif non_linearity == 'THRESHOLDEDRELU':\n        params = keras_layer.theta\n    else:\n        pass # do nothing to parameters\n    builder.add_activation(name = layer,\n            non_linearity = non_linearity,\n            input_name = input_name, output_name = output_name,\n            params = params)", "response": "Convert an activation layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a padding layer from keras to coreml.", "response": "def convert_padding(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert padding layer from keras to coreml.\n    Keras only supports zero padding at this time.\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    if isinstance(keras_layer, keras.layers.convolutional.ZeroPadding1D):\n        left, right = keras_layer.padding\n        top, bottom = (0, 0)\n    else: # 2D\n        top, left = keras_layer.padding\n        bottom, right = keras_layer.padding\n\n    # Now add the layer\n    builder.add_padding(name = layer,\n        left = left, right=right, top=top, bottom=bottom, value = 0,\n        input_name = input_name, output_name=output_name\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a cropping layer from keras to coreml.", "response": "def convert_cropping(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert padding layer from keras to coreml.\n    Keras only supports zero padding at this time.\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    if isinstance(keras_layer, keras.layers.convolutional.Cropping1D):\n        left, right = keras_layer.cropping\n        top, bottom = (0, 0)\n    else: # 2D\n        left, right = keras_layer.cropping[0]\n        top, bottom = keras_layer.cropping[1]\n\n    # Now add the layer\n    builder.add_crop(name = layer,\n        left = left, right=right, top=top, bottom=bottom, offset = [0,0],\n        input_names = [input_name], output_name=output_name\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting upsample layer from keras to coreml.", "response": "def convert_upsample(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert convolution layer from keras to coreml.\n\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    if isinstance(keras_layer, keras.layers.convolutional.UpSampling1D):\n        fh, fw = 1, keras_layer.length\n    else: # 2D\n        fh, fw = keras_layer.size\n\n    builder.add_upsample(name = layer,\n             scaling_factor_h = fh,\n             scaling_factor_w = fw,\n             input_name = input_name,\n             output_name = output_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_convolution(builder, layer, input_names, output_names, keras_layer):\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    has_bias = keras_layer.bias\n    is_deconv = isinstance(keras_layer, keras.layers.convolutional.Deconvolution2D)\n\n    # Get the weights from keras.\n    # Keras stores convolution weights as list of numpy arrays\n    weightList = keras_layer.get_weights()\n    output_shape = list(filter(None, keras_layer.output_shape))[:-1]\n\n    # Parameter\n    height, width, channels, n_filters = weightList[0].shape\n    stride_height, stride_width = keras_layer.subsample\n\n    # Weights and bias terms\n    W = weightList[0]\n    b = weightList[1] if has_bias else None\n\n    # dilation factors\n    dilation_factors = [1,1]\n    if isinstance(keras_layer, keras.layers.convolutional.AtrousConvolution2D):\n        dilation_factors = list(keras_layer.atrous_rate)\n\n    builder.add_convolution(name = layer,\n             kernel_channels = channels,\n             output_channels = n_filters,\n             height = height,\n             width = width,\n             stride_height = stride_height,\n             stride_width = stride_width,\n             border_mode = keras_layer.border_mode,\n             groups = 1,\n             W = W,\n             b = b,\n             has_bias = has_bias,\n             is_deconv = is_deconv,\n             output_shape = output_shape,\n             input_name = input_name,\n             output_name = output_name,\n             dilation_factors = dilation_factors)", "response": "Convert a convolution layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a convolution layer from keras to coreml.", "response": "def convert_convolution1d(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert convolution layer from keras to coreml.\n\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    has_bias = keras_layer.bias\n\n    # Get the weights from keras.\n    # Keras stores convolution weights as list of numpy arrays\n    weightList = keras_layer.get_weights()\n    output_shape = list(filter(None, keras_layer.output_shape))[:-1]\n\n    # Parameter\n    # weightList[0].shape = [kernel_length, input_length(time_step), input_dim, num_kernels]\n    filter_length, input_length, input_dim, n_filters = weightList[0].shape\n    stride_width = keras_layer.subsample[0]\n\n    # Weights and bias terms\n    W = weightList[0]\n    b = weightList[1] if has_bias else None\n\n    dilation_factors = [1,1]\n    if isinstance(keras_layer, keras.layers.convolutional.AtrousConvolution1D):\n        dilation_factors[-1] = keras_layer.atrous_rate\n\n    builder.add_convolution(name = layer,\n             kernel_channels = input_dim,\n             output_channels = n_filters,\n             height = 1,\n             width = filter_length,\n             stride_height = 1,\n             stride_width = stride_width,\n             border_mode = keras_layer.border_mode,\n             groups = 1,\n             W = W,\n             b = b,\n             has_bias = has_bias,\n             is_deconv = False,\n             output_shape = output_shape,\n             input_name = input_name,\n             output_name = output_name,\n             dilation_factors = dilation_factors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert an LSTM layer from keras to coreml.", "response": "def convert_lstm(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert an LSTM layer from keras to coreml.\n\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n\n    hidden_size = keras_layer.output_dim\n    input_size = keras_layer.input_shape[-1]\n    if keras_layer.consume_less not in ['cpu', 'gpu']:\n        raise ValueError('Cannot convert Keras layer with consume_less = %s' % keras_layer.consume_less)\n\n    output_all = keras_layer.return_sequences\n    reverse_input = keras_layer.go_backwards\n\n    # Keras: I C F O; W_x, W_h, b\n    # CoreML: I F O G; W_h and W_x are separated\n    W_h, W_x, b = ([], [], [])\n    if keras_layer.consume_less == 'cpu':\n        W_h.append(keras_layer.get_weights()[1].T)\n        W_h.append(keras_layer.get_weights()[7].T)\n        W_h.append(keras_layer.get_weights()[10].T)\n        W_h.append(keras_layer.get_weights()[4].T)\n\n        W_x.append(keras_layer.get_weights()[0].T)\n        W_x.append(keras_layer.get_weights()[6].T)\n        W_x.append(keras_layer.get_weights()[9].T)\n        W_x.append(keras_layer.get_weights()[3].T)\n\n        b.append(keras_layer.get_weights()[2])\n        b.append(keras_layer.get_weights()[8])\n        b.append(keras_layer.get_weights()[11])\n        b.append(keras_layer.get_weights()[5])\n    else:\n        keras_W_h = keras_layer.get_weights()[1].T\n        W_h.append(keras_W_h[0 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[1 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[3 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[2 * hidden_size:][:hidden_size])\n\n        keras_W_x = keras_layer.get_weights()[0].T\n        W_x.append(keras_W_x[0 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[1 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[3 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[2 * hidden_size:][:hidden_size])\n\n        keras_b = keras_layer.get_weights()[2]\n        b.append(keras_b[0 * hidden_size:][:hidden_size])\n        b.append(keras_b[1 * hidden_size:][:hidden_size])\n        b.append(keras_b[3 * hidden_size:][:hidden_size])\n        b.append(keras_b[2 * hidden_size:][:hidden_size])\n\n    # Set activation type\n    inner_activation_str = _get_recurrent_activation_name_from_keras(keras_layer.inner_activation)\n    activation_str = _get_recurrent_activation_name_from_keras(keras_layer.activation)\n\n    # Add to the network\n    builder.add_unilstm(\n        name = layer,\n        W_h = W_h, W_x = W_x, b = b,\n        hidden_size = hidden_size,\n        input_size = input_size,\n        input_names = input_names,\n        output_names = output_names,\n        inner_activation = inner_activation_str,\n        cell_state_update_activation = activation_str,\n        output_activation = activation_str,\n        output_all = output_all,\n        reverse_input = reverse_input)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a SimpleRNN layer from keras to coreml.", "response": "def convert_simple_rnn(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert an SimpleRNN layer from keras to coreml.\n\n    Parameters\n    ----------\n    keras_layer: layer\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    # Get input and output names\n    hidden_size = keras_layer.output_dim\n    input_size = keras_layer.input_shape[-1]\n\n    output_all = keras_layer.return_sequences\n    reverse_input = keras_layer.go_backwards\n\n    if keras_layer.consume_less not in ['cpu', 'gpu']:\n        raise ValueError('Cannot convert Keras layer with consume_less = %s' % keras_layer.consume_less)\n\n    W_h = np.zeros((hidden_size, hidden_size))\n    W_x = np.zeros((hidden_size, input_size))\n    b = np.zeros((hidden_size,))\n\n    if keras_layer.consume_less == 'cpu':\n        W_h = keras_layer.get_weights()[1].T\n        W_x = keras_layer.get_weights()[0].T\n        b = keras_layer.get_weights()[2]\n    else:\n        W_h = keras_layer.get_weights()[1].T\n        W_x = keras_layer.get_weights()[0].T\n        b = keras_layer.get_weights()[2]\n\n    # Set actication type\n    activation_str = _get_recurrent_activation_name_from_keras(keras_layer.activation)\n\n    # Add to the network\n    builder.add_simple_rnn(\n        name = layer,\n        W_h = W_h, W_x = W_x, b = b,\n        hidden_size = hidden_size,\n        input_size = input_size,\n        activation = activation_str,\n        input_names = input_names,\n        output_names = output_names,\n        output_all=output_all,\n        reverse_input=reverse_input)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_gru(builder, layer, input_names, output_names, keras_layer):\n\n    hidden_size = keras_layer.output_dim\n    input_size = keras_layer.input_shape[-1]\n\n    output_all = keras_layer.return_sequences\n    reverse_input = keras_layer.go_backwards\n\n    if keras_layer.consume_less not in ['cpu', 'gpu']:\n        raise ValueError('Cannot convert Keras layer with consume_less = %s' % keras_layer.consume_less)\n\n    # Keras: Z R O\n    # CoreML: Z R O\n    W_h, W_x, b = ([], [], [])\n    if keras_layer.consume_less == 'cpu':\n        W_x.append(keras_layer.get_weights()[0].T)\n        W_x.append(keras_layer.get_weights()[3].T)\n        W_x.append(keras_layer.get_weights()[6].T)\n\n        W_h.append(keras_layer.get_weights()[1].T)\n        W_h.append(keras_layer.get_weights()[4].T)\n        W_h.append(keras_layer.get_weights()[7].T)\n\n        b.append(keras_layer.get_weights()[2])\n        b.append(keras_layer.get_weights()[5])\n        b.append(keras_layer.get_weights()[8])\n    else:\n        print('consume less not implemented')\n\n    # Set actication type\n    inner_activation_str = _get_recurrent_activation_name_from_keras(keras_layer.inner_activation)\n    activation_str = _get_recurrent_activation_name_from_keras(keras_layer.activation)\n\n    # Add to the network\n    builder.add_gru(\n       name = layer,\n       W_h = W_h, W_x = W_x, b = b,\n       input_size = input_size,\n       hidden_size = hidden_size,\n       input_names = input_names,\n       output_names = output_names,\n       activation = activation_str,\n       inner_activation = inner_activation_str,\n       output_all=output_all,\n       reverse_input = reverse_input)", "response": "Convert a GRU layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_bidirectional(builder, layer, input_names, output_names, keras_layer):\n\n    input_size = keras_layer.input_shape[-1]\n\n    lstm_layer = keras_layer.forward_layer\n    if (type(lstm_layer) != keras.layers.recurrent.LSTM):\n        raise TypeError('Bidirectional layers only supported with LSTM')\n\n    if lstm_layer.go_backwards:\n        raise TypeError(' \\'go_backwards\\' mode not supported with Bidirectional layers')\n\n    output_all = keras_layer.return_sequences\n\n    hidden_size = lstm_layer.output_dim\n    #output_size = lstm_layer.output_dim * 2\n\n    if lstm_layer.consume_less not in ['cpu', 'gpu']:\n        raise ValueError('Cannot convert Keras layer with consume_less = %s' % keras_layer.consume_less)\n\n    # Keras: I C F O; W_x, W_h, b\n    # CoreML: I F O G; W_h and W_x are separated\n\n    # Keras has all forward weights, followed by backward in the same order\n    W_h, W_x, b = ([], [], [])\n    if lstm_layer.consume_less == 'cpu':\n        W_h.append(keras_layer.get_weights()[1].T)\n        W_h.append(keras_layer.get_weights()[7].T)\n        W_h.append(keras_layer.get_weights()[10].T)\n        W_h.append(keras_layer.get_weights()[4].T)\n\n        W_x.append(keras_layer.get_weights()[0].T)\n        W_x.append(keras_layer.get_weights()[6].T)\n        W_x.append(keras_layer.get_weights()[9].T)\n        W_x.append(keras_layer.get_weights()[3].T)\n\n        b.append(keras_layer.get_weights()[2])\n        b.append(keras_layer.get_weights()[8])\n        b.append(keras_layer.get_weights()[11])\n        b.append(keras_layer.get_weights()[5])\n    else:\n        keras_W_h = keras_layer.get_weights()[1].T\n        W_h.append(keras_W_h[0 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[1 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[3 * hidden_size:][:hidden_size])\n        W_h.append(keras_W_h[2 * hidden_size:][:hidden_size])\n\n        keras_W_x = keras_layer.get_weights()[0].T\n        W_x.append(keras_W_x[0 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[1 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[3 * hidden_size:][:hidden_size])\n        W_x.append(keras_W_x[2 * hidden_size:][:hidden_size])\n\n        keras_b = keras_layer.get_weights()[2]\n        b.append(keras_b[0 * hidden_size:][:hidden_size])\n        b.append(keras_b[1 * hidden_size:][:hidden_size])\n        b.append(keras_b[3 * hidden_size:][:hidden_size])\n        b.append(keras_b[2 * hidden_size:][:hidden_size])\n\n    W_h_back, W_x_back, b_back = ([],[],[])\n    if keras_layer.backward_layer.consume_less == 'cpu':\n        back_weights = keras_layer.backward_layer.get_weights()\n        W_h_back.append(back_weights[1].T)\n        W_h_back.append(back_weights[7].T)\n        W_h_back.append(back_weights[10].T)\n        W_h_back.append(back_weights[4].T)\n\n        W_x_back.append(back_weights[0].T)\n        W_x_back.append(back_weights[6].T)\n        W_x_back.append(back_weights[9].T)\n        W_x_back.append(back_weights[3].T)\n\n        b_back.append(back_weights[2])\n        b_back.append(back_weights[8])\n        b_back.append(back_weights[11])\n        b_back.append(back_weights[5])\n    else:\n        keras_W_h = keras_layer.backward_layer.get_weights()[1].T\n        W_h_back.append(keras_W_h[0 * hidden_size:][:hidden_size])\n        W_h_back.append(keras_W_h[1 * hidden_size:][:hidden_size])\n        W_h_back.append(keras_W_h[3 * hidden_size:][:hidden_size])\n        W_h_back.append(keras_W_h[2 * hidden_size:][:hidden_size])\n\n        keras_W_x = keras_layer.backward_layer.get_weights()[0].T\n        W_x_back.append(keras_W_x[0 * hidden_size:][:hidden_size])\n        W_x_back.append(keras_W_x[1 * hidden_size:][:hidden_size])\n        W_x_back.append(keras_W_x[3 * hidden_size:][:hidden_size])\n        W_x_back.append(keras_W_x[2 * hidden_size:][:hidden_size])\n\n        keras_b = keras_layer.backward_layer.get_weights()[2]\n        b_back.append(keras_b[0 * hidden_size:][:hidden_size])\n        b_back.append(keras_b[1 * hidden_size:][:hidden_size])\n        b_back.append(keras_b[3 * hidden_size:][:hidden_size])\n        b_back.append(keras_b[2 * hidden_size:][:hidden_size])\n\n    # Set activation type\n    inner_activation_str = _get_recurrent_activation_name_from_keras(lstm_layer.inner_activation)\n    activation_str = _get_recurrent_activation_name_from_keras(lstm_layer.activation)\n\n\n    # Add to the network\n    builder.add_bidirlstm(\n        name = layer,\n        W_h = W_h, W_x = W_x, b = b,\n        W_h_back = W_h_back, W_x_back = W_x_back, b_back = b_back,\n        hidden_size=hidden_size,\n        input_size=input_size,\n        input_names=input_names,\n        output_names=output_names,\n        inner_activation = inner_activation_str,\n        cell_state_update_activation = activation_str,\n        output_activation = activation_str,\n        output_all = output_all)", "response": "Convert a bidirectional layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_batchnorm(builder, layer, input_names, output_names, keras_layer):\n\n    # Get input and output names\n    input_name, output_name = (input_names[0], output_names[0])\n\n    # Currently CoreML supports only per-channel batch-norm\n    if keras_layer.mode != 0:\n        raise NotImplementedError(\n            'Currently supports only per-feature normalization')\n\n    axis = keras_layer.axis\n    nb_channels = keras_layer.input_shape[axis]\n\n\n    # Set parameters\n    # Parameter arrangement in Keras: gamma, beta, mean, variance\n    gamma = keras_layer.get_weights()[0]\n    beta = keras_layer.get_weights()[1]\n    mean = keras_layer.get_weights()[2]\n    std = keras_layer.get_weights()[3]\n    # compute adjusted parameters\n    variance = std * std\n    f = 1.0 / np.sqrt(std + keras_layer.epsilon)\n    gamma1 = gamma*f\n    beta1 = beta - gamma*mean*f\n    mean[:] = 0.0 #mean\n    variance[:] = 1.0 - .00001 #stddev\n\n    builder.add_batchnorm(\n        name = layer,\n        channels = nb_channels,\n        gamma = gamma1,\n        beta = beta1,\n        mean = mean,\n        variance = variance,\n        input_name = input_name,\n        output_name = output_name)", "response": "Convert a batchnorm layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a keras flatten layer from keras to coreml.", "response": "def convert_flatten(builder, layer, input_names, output_names, keras_layer):\n    \"\"\"Convert a flatten layer from keras to coreml.\n\n    Parameters\n    keras_layer: layer\n    ----------\n        A keras layer object.\n\n    builder: NeuralNetworkBuilder\n        A neural network builder object.\n    \"\"\"\n    input_name, output_name = (input_names[0], output_names[0])\n\n    # blob_order == 0 if the input blob needs not be rearranged\n    # blob_order == 1 if the input blob needs to be rearranged\n    blob_order = 0\n\n    # using keras_layer.input.shape have a \"?\" (Dimension[None] at the front),\n    # making a 3D tensor with unknown batch size 4D\n    if len(keras_layer.input.shape) == 4:\n        blob_order = 1\n\n    builder.add_flatten(name=layer, mode=blob_order, input_name=input_name, output_name=output_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_softmax(builder, layer, input_names, output_names, keras_layer):\n    input_name, output_name = (input_names[0], output_names[0])\n\n    builder.add_softmax(name = layer, input_name = input_name,\n            output_name = output_name)", "response": "Convert a keras softmax layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_permute(builder, layer, input_names, output_names, keras_layer):\n    input_name, output_name = (input_names[0], output_names[0])\n\n    keras_dims = keras_layer.dims\n    # Keras permute layer index begins at 1\n    if len(keras_dims) == 3:\n        # Keras input tensor interpret as (H,W,C)\n        x = list(np.array(keras_dims))\n        i1, i2, i3 = x.index(1), x.index(2), x.index(3)\n        x[i1], x[i2], x[i3] = 2, 3, 1\n        # add a sequence axis\n        x = [0] + x\n        dim = tuple(x)\n    elif len(keras_dims) == 4:\n        # Here we use Keras converter as a place holder for inserting\n        # permutations - the values here are not valid Keras dim parameters\n        # but parameters we need to use to convert to CoreML model\n        dim = keras_dims\n    else:\n        raise NotImplementedError('Supports only 3d permutation.')\n\n    builder.add_permute(name = layer, dim=dim, input_name = input_name,\n            output_name = output_name)", "response": "Convert a softmax layer from keras to coreml."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncustomize submit script, that submit nslave jobs, each must contain args as parameter note this can be a lambda function containing additional parameters in input Parameters nslave number of slave process to start up args arguments to launch each job this usually includes the parameters of master_uri and parameters passed into submit", "response": "def sge_submit(nslave, worker_args, worker_envs):\n    \"\"\"\n      customized submit script, that submit nslave jobs, each must contain args as parameter\n      note this can be a lambda function containing additional parameters in input\n      Parameters\n         nslave number of slave process to start up\n         args arguments to launch each job\n              this usually includes the parameters of master_uri and parameters passed into submit\n    \"\"\"\n    env_arg = ','.join(['%s=\\\"%s\\\"' % (k, str(v)) for k, v in worker_envs.items()])\n    cmd = 'qsub -cwd -t 1-%d -S /bin/bash' % nslave\n    if args.queue != 'default':\n        cmd += '-q %s' % args.queue\n    cmd += ' -N %s ' % args.jobname\n    cmd += ' -e %s -o %s' % (args.logdir, args.logdir)\n    cmd += ' -pe orte %d' % (args.vcores)\n    cmd += ' -v %s,PATH=${PATH}:.' % env_arg\n    cmd += ' %s %s' % (runscript, ' '.join(args.command + worker_args))\n    print cmd\n    subprocess.check_call(cmd, shell = True)\n    print 'Waiting for the jobs to get up...'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump an AST into a string.", "response": "def dump_ast(ast, indent=' ', newline='\\n'):\n    '''\n    \n    Returns a string representing the ast.\n    \n    :param ast: the ast to print.\n    :param indent: how far to indent a newline.\n    :param newline: The newline character.\n    \n    '''\n    \n    visitor = ASTPrinter(indent=indent, level=0, newline=newline)\n    visitor.visit(ast)\n    return visitor.dumps()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a ctypes pointer array to a numpy array.", "response": "def ctypes2numpy(cptr, length, dtype):\n    \"\"\"Convert a ctypes pointer array to a numpy array.\n    \"\"\"\n    if not isinstance(cptr, ctypes.POINTER(ctypes.c_float)):\n        raise RuntimeError('expected float pointer')\n    res = np.zeros(length, dtype=dtype)\n    if not ctypes.memmove(res.ctypes.data, cptr, length * res.strides[0]):\n        raise RuntimeError('memmove failed')\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract internal data from pandas. DataFrame.", "response": "def _maybe_from_pandas(data, feature_names, feature_types):\n    \"\"\" Extract internal data from pd.DataFrame \"\"\"\n    try:\n        import pandas as pd\n    except ImportError:\n        return data, feature_names, feature_types\n\n    if not isinstance(data, pd.DataFrame):\n        return data, feature_names, feature_types\n\n    dtypes = data.dtypes\n    if not all(dtype.name in ('int64', 'float64', 'bool') for dtype in dtypes):\n        raise ValueError('DataFrame.dtypes must be int, float or bool')\n\n    if feature_names is None:\n        feature_names = data.columns.format()\n    if feature_types is None:\n        mapper = {'int64': 'int', 'float64': 'q', 'bool': 'i'}\n        feature_types = [mapper[dtype.name] for dtype in dtypes]\n    data = data.values.astype('float')\n    return data, feature_names, feature_types"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize data from a CSR matrix.", "response": "def _init_from_csr(self, csr):\n        \"\"\"\n        Initialize data from a CSR matrix.\n        \"\"\"\n        if len(csr.indices) != len(csr.data):\n            raise ValueError('length mismatch: {} vs {}'.format(len(csr.indices), len(csr.data)))\n        self.handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromCSR(c_array(ctypes.c_ulong, csr.indptr),\n                                                c_array(ctypes.c_uint, csr.indices),\n                                                c_array(ctypes.c_float, csr.data),\n                                                len(csr.indptr), len(csr.data),\n                                                ctypes.byref(self.handle)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_from_csc(self, csc):\n        if len(csc.indices) != len(csc.data):\n            raise ValueError('length mismatch: {} vs {}'.format(len(csc.indices), len(csc.data)))\n        self.handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromCSC(c_array(ctypes.c_ulong, csc.indptr),\n                                                c_array(ctypes.c_uint, csc.indices),\n                                                c_array(ctypes.c_float, csc.data),\n                                                len(csc.indptr), len(csc.data),\n                                                ctypes.byref(self.handle)))", "response": "Initialize data from a CSC matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes data from a 2 - D numpy matrix.", "response": "def _init_from_npy2d(self, mat, missing):\n        \"\"\"\n        Initialize data from a 2-D numpy matrix.\n        \"\"\"\n        if len(mat.shape) != 2:\n            raise ValueError('Input numpy.ndarray must be 2 dimensional')\n        data = np.array(mat.reshape(mat.size), dtype=np.float32)\n        self.handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixCreateFromMat(data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),\n                                                mat.shape[0], mat.shape[1],\n                                                ctypes.c_float(missing),\n                                                ctypes.byref(self.handle)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_float_info(self, field):\n        length = ctypes.c_ulong()\n        ret = ctypes.POINTER(ctypes.c_float)()\n        _check_call(_LIB.XGDMatrixGetFloatInfo(self.handle,\n                                               c_str(field),\n                                               ctypes.byref(length),\n                                               ctypes.byref(ret)))\n        return ctypes2numpy(ret, length.value, np.float32)", "response": "Get the float property from the DMatrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget unsigned integer property from the DMatrix.", "response": "def get_uint_info(self, field):\n        \"\"\"Get unsigned integer property from the DMatrix.\n\n        Parameters\n        ----------\n        field: str\n            The field name of the information\n\n        Returns\n        -------\n        info : array\n            a numpy array of float information of the data\n        \"\"\"\n        length = ctypes.c_ulong()\n        ret = ctypes.POINTER(ctypes.c_uint)()\n        _check_call(_LIB.XGDMatrixGetUIntInfo(self.handle,\n                                              c_str(field),\n                                              ctypes.byref(length),\n                                              ctypes.byref(ret)))\n        return ctypes2numpy(ret, length.value, np.uint32)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the float type property into the DMatrix.", "response": "def set_float_info(self, field, data):\n        \"\"\"Set float type property into the DMatrix.\n\n        Parameters\n        ----------\n        field: str\n            The field name of the information\n\n        data: numpy array\n            The array ofdata to be set\n        \"\"\"\n        _check_call(_LIB.XGDMatrixSetFloatInfo(self.handle,\n                                               c_str(field),\n                                               c_array(ctypes.c_float, data),\n                                               len(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the uint type property into the DMatrix.", "response": "def set_uint_info(self, field, data):\n        \"\"\"Set uint type property into the DMatrix.\n\n        Parameters\n        ----------\n        field: str\n            The field name of the information\n\n        data: numpy array\n            The array ofdata to be set\n        \"\"\"\n        _check_call(_LIB.XGDMatrixSetUIntInfo(self.handle,\n                                              c_str(field),\n                                              c_array(ctypes.c_uint, data),\n                                              len(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_binary(self, fname, silent=True):\n        _check_call(_LIB.XGDMatrixSaveBinary(self.handle,\n                                             c_str(fname),\n                                             int(silent)))", "response": "Save DMatrix to an XGBoost buffer file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the number of rows in the DMatrix.", "response": "def num_row(self):\n        \"\"\"Get the number of rows in the DMatrix.\n\n        Returns\n        -------\n        number of rows : int\n        \"\"\"\n        ret = ctypes.c_ulong()\n        _check_call(_LIB.XGDMatrixNumRow(self.handle,\n                                         ctypes.byref(ret)))\n        return ret.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef num_col(self):\n        ret = ctypes.c_uint()\n        _check_call(_LIB.XGDMatrixNumCol(self.handle,\n                                         ctypes.byref(ret)))\n        return ret.value", "response": "Get the number of columns in the DMatrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nslices the DMatrix and return a new DMatrix that only contains rindex.", "response": "def slice(self, rindex):\n        \"\"\"Slice the DMatrix and return a new DMatrix that only contains `rindex`.\n\n        Parameters\n        ----------\n        rindex : list\n            List of indices to be selected.\n\n        Returns\n        -------\n        res : DMatrix\n            A new DMatrix containing only selected indices.\n        \"\"\"\n        res = DMatrix(None, feature_names=self.feature_names)\n        res.handle = ctypes.c_void_p()\n        _check_call(_LIB.XGDMatrixSliceDMatrix(self.handle,\n                                               c_array(ctypes.c_int, rindex),\n                                               len(rindex),\n                                               ctypes.byref(res.handle)))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef feature_names(self, feature_names):\n        if not feature_names is None:\n            # validate feature name\n            if not isinstance(feature_names, list):\n                feature_names = list(feature_names)\n            if len(feature_names) != len(set(feature_names)):\n                raise ValueError('feature_names must be unique')\n            if len(feature_names) != self.num_col():\n                msg = 'feature_names must have the same length as data'\n                raise ValueError(msg)\n            # prohibit to use symbols may affect to parse. e.g. ``[]=.``\n            if not all(isinstance(f, STRING_TYPES) and f.isalnum()\n                       for f in feature_names):\n                raise ValueError('all feature_names must be alphanumerics')\n        else:\n            # reset feature_types also\n            self.feature_types = None\n        self._feature_names = feature_names", "response": "Set the feature names for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feature_types(self, feature_types):\n        if not feature_types is None:\n\n            if self.feature_names is None:\n                msg = 'Unable to set feature types before setting names'\n                raise ValueError(msg)\n\n            if isinstance(feature_types, STRING_TYPES):\n                # single string will be applied to all columns\n                feature_types = [feature_types] * self.num_col()\n\n            if not isinstance(feature_types, list):\n                feature_types = list(feature_types)\n            if len(feature_types) != self.num_col():\n                msg = 'feature_types must have the same length as data'\n                raise ValueError(msg)\n            # prohibit to use symbols may affect to parse. e.g. ``[]=.``\n\n            valid = ('q', 'i', 'int', 'float')\n            if not all(isinstance(f, STRING_TYPES) and f in valid\n                       for f in feature_types):\n                raise ValueError('all feature_names must be {i, q, int, float}')\n        self._feature_types = feature_types", "response": "Set the feature types of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, dtrain, iteration, fobj=None):\n        if not isinstance(dtrain, DMatrix):\n            raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))\n        self._validate_features(dtrain)\n\n        if fobj is None:\n            _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, iteration, dtrain.handle))\n        else:\n            pred = self.predict(dtrain)\n            grad, hess = fobj(pred, dtrain)\n            self.boost(dtrain, grad, hess)", "response": "Update for one iteration with objective function calculated internally."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nboosting the booster for one iteration with customized gradient statistics.", "response": "def boost(self, dtrain, grad, hess):\n        \"\"\"\n        Boost the booster for one iteration, with customized gradient statistics.\n\n        Parameters\n        ----------\n        dtrain : DMatrix\n            The training DMatrix.\n        grad : list\n            The first order of gradient.\n        hess : list\n            The second order of gradient.\n        \"\"\"\n        if len(grad) != len(hess):\n            raise ValueError('grad / hess length mismatch: {} / {}'.format(len(grad), len(hess)))\n        if not isinstance(dtrain, DMatrix):\n            raise TypeError('invalid training matrix: {}'.format(type(dtrain).__name__))\n        self._validate_features(dtrain)\n\n        _check_call(_LIB.XGBoosterBoostOneIter(self.handle, dtrain.handle,\n                                               c_array(ctypes.c_float, grad),\n                                               c_array(ctypes.c_float, hess),\n                                               len(grad)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate a set of items in a single iteration.", "response": "def eval_set(self, evals, iteration=0, feval=None):\n        # pylint: disable=invalid-name\n        \"\"\"Evaluate  a set of data.\n\n        Parameters\n        ----------\n        evals : list of tuples (DMatrix, string)\n            List of items to be evaluated.\n        iteration : int\n            Current iteration.\n        feval : function\n            Custom evaluation function.\n\n        Returns\n        -------\n        result: str\n            Evaluation result string.\n        \"\"\"\n        if feval is None:\n            for d in evals:\n                if not isinstance(d[0], DMatrix):\n                    raise TypeError('expected DMatrix, got {}'.format(type(d[0]).__name__))\n                if not isinstance(d[1], STRING_TYPES):\n                    raise TypeError('expected string, got {}'.format(type(d[1]).__name__))\n                self._validate_features(d[0])\n\n            dmats = c_array(ctypes.c_void_p, [d[0].handle for d in evals])\n            evnames = c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])\n            msg = ctypes.c_char_p()\n            _check_call(_LIB.XGBoosterEvalOneIter(self.handle, iteration,\n                                                  dmats, evnames, len(evals),\n                                                  ctypes.byref(msg)))\n            return msg.value\n        else:\n            res = '[%d]' % iteration\n            for dmat, evname in evals:\n                name, val = feval(self.predict(dmat), dmat)\n                res += '\\t%s-%s:%f' % (evname, name, val)\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts with data. NOTE: This function is not thread safe. For each booster object, predict can only be called from one thread. If you want to run prediction using multiple thread, call bst.copy() to make copies of model object and then call predict Parameters ---------- data : DMatrix The dmatrix storing the input. output_margin : bool Whether to output the raw untransformed margin value. ntree_limit : int Limit number of trees in the prediction; defaults to 0 (use all trees). pred_leaf : bool When this option is on, the output will be a matrix of (nsample, ntrees) with each record indicating the predicted leaf index of each sample in each tree. Note that the leaf index of a tree is unique per tree, so you may find leaf 1 in both tree 1 and tree 0. Returns ------- prediction : numpy array", "response": "def predict(self, data, output_margin=False, ntree_limit=0, pred_leaf=False):\n        \"\"\"\n        Predict with data.\n\n        NOTE: This function is not thread safe.\n              For each booster object, predict can only be called from one thread.\n              If you want to run prediction using multiple thread, call bst.copy() to make copies\n              of model object and then call predict\n\n        Parameters\n        ----------\n        data : DMatrix\n            The dmatrix storing the input.\n\n        output_margin : bool\n            Whether to output the raw untransformed margin value.\n\n        ntree_limit : int\n            Limit number of trees in the prediction; defaults to 0 (use all trees).\n\n        pred_leaf : bool\n            When this option is on, the output will be a matrix of (nsample, ntrees)\n            with each record indicating the predicted leaf index of each sample in each tree.\n            Note that the leaf index of a tree is unique per tree, so you may find leaf 1\n            in both tree 1 and tree 0.\n\n        Returns\n        -------\n        prediction : numpy array\n        \"\"\"\n        option_mask = 0x00\n        if output_margin:\n            option_mask |= 0x01\n        if pred_leaf:\n            option_mask |= 0x02\n\n        self._validate_features(data)\n\n        length = ctypes.c_ulong()\n        preds = ctypes.POINTER(ctypes.c_float)()\n        _check_call(_LIB.XGBoosterPredict(self.handle, data.handle,\n                                          option_mask, ntree_limit,\n                                          ctypes.byref(length),\n                                          ctypes.byref(preds)))\n        preds = ctypes2numpy(preds, length.value, np.float32)\n        if pred_leaf:\n            preds = preds.astype(np.int32)\n        nrow = data.num_row()\n        if preds.size != nrow and preds.size % nrow == 0:\n            preds = preds.reshape(nrow, preds.size / nrow)\n        return preds"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_raw(self):\n        length = ctypes.c_ulong()\n        cptr = ctypes.POINTER(ctypes.c_char)()\n        _check_call(_LIB.XGBoosterGetModelRaw(self.handle,\n                                              ctypes.byref(length),\n                                              ctypes.byref(cptr)))\n        return ctypes2buffer(cptr, length.value)", "response": "Save the model to a in memory buffer represetation\n        Returns ------- a in memory buffer represetation\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the model from a file.", "response": "def load_model(self, fname):\n        \"\"\"\n        Load the model from a file.\n\n        Parameters\n        ----------\n        fname : string or a memory buffer\n            Input file name or memory buffer(see also save_raw)\n        \"\"\"\n        if isinstance(fname, STRING_TYPES):  # assume file name\n            if os.path.exists(fname):\n                _LIB.XGBoosterLoadModel(self.handle, c_str(fname))\n            else:\n                raise ValueError(\"No such file: {0}\".format(fname))\n        else:\n            buf = fname\n            length = ctypes.c_ulong(len(buf))\n            ptr = (ctypes.c_char * len(buf)).from_buffer(buf)\n            _check_call(_LIB.XGBoosterLoadModelFromBuffer(self.handle, ptr, length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_model(self, fout, fmap='', with_stats=False):\n        if isinstance(fout, STRING_TYPES):\n            fout = open(fout, 'w')\n            need_close = True\n        else:\n            need_close = False\n        ret = self.get_dump(fmap, with_stats)\n        for i in range(len(ret)):\n            fout.write('booster[{}]:\\n'.format(i))\n            fout.write(ret[i])\n        if need_close:\n            fout.close()", "response": "Dump the model into a text file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the dump of the model as a list of strings.", "response": "def get_dump(self, fmap='', with_stats=False):\n        \"\"\"\n        Returns the dump the model as a list of strings.\n        \"\"\"\n\n        length = ctypes.c_ulong()\n        sarr = ctypes.POINTER(ctypes.c_char_p)()\n        if self.feature_names is not None and fmap == '':\n            flen = int(len(self.feature_names))\n\n            fname = from_pystr_to_cstr(self.feature_names)\n\n            if self.feature_types is None:\n                # use quantitative as default\n                # {'q': quantitative, 'i': indicator}\n                ftype = from_pystr_to_cstr(['q'] * flen)\n            else:\n                ftype = from_pystr_to_cstr(self.feature_types)\n            _check_call(_LIB.XGBoosterDumpModelWithFeatures(self.handle,\n                                                            flen,\n                                                            fname,\n                                                            ftype,\n                                                            int(with_stats),\n                                                            ctypes.byref(length),\n                                                            ctypes.byref(sarr)))\n        else:\n            if fmap != '' and not os.path.exists(fmap):\n                raise ValueError(\"No such file: {0}\".format(fmap))\n            _check_call(_LIB.XGBoosterDumpModel(self.handle,\n                                                c_str(fmap),\n                                                int(with_stats),\n                                                ctypes.byref(length),\n                                                ctypes.byref(sarr)))\n        res = from_cstr_to_pystr(sarr, length)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fscore(self, fmap=''):\n        trees = self.get_dump(fmap)\n        fmap = {}\n        for tree in trees:\n            for line in tree.split('\\n'):\n                arr = line.split('[')\n                if len(arr) == 1:\n                    continue\n                fid = arr[1].split(']')[0]\n                fid = fid.split('<')[0]\n                if fid not in fmap:\n                    fmap[fid] = 1\n                else:\n                    fmap[fid] += 1\n        return fmap", "response": "Get feature importance of each feature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate Booster and data s feature_names are identical.", "response": "def _validate_features(self, data):\n        \"\"\"\n        Validate Booster and data's feature_names are identical.\n        Set feature_names and feature_types from DMatrix\n        \"\"\"\n        if self.feature_names is None:\n            self.feature_names = data.feature_names\n            self.feature_types = data.feature_types\n        else:\n            # Booster can't accept data with different feature names\n            if self.feature_names != data.feature_names:\n                msg = 'feature_names mismatch: {0} {1}'\n                raise ValueError(msg.format(self.feature_names,\n                                            data.feature_names))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef disassembler(co, lasti= -1):\n\n    code = co.co_code\n    labels = dis.findlabels(code)\n    linestarts = dict(dis.findlinestarts(co))\n    i = 0\n    extended_arg = 0\n    lineno = 0\n    free = None\n    for i, op, oparg in _walk_ops(co):\n        if i in linestarts:\n            lineno = linestarts[i]\n        instr = Instruction(i=i, op=op, lineno=lineno)\n        instr.linestart = i in linestarts\n\n        if i == lasti:\n            instr.lasti = True\n        else:\n            instr.lasti = False\n\n        if i in labels:\n            instr.label = True\n        else:\n            instr.label = False\n\n        instr.oparg = oparg\n        extended_arg = 0\n        if op == dis.EXTENDED_ARG:\n            extended_arg = oparg * 65536\n        instr.extended_arg = extended_arg\n        if op >= dis.HAVE_ARGUMENT:\n            if op in dis.hasconst:\n                instr.arg = co.co_consts[oparg]\n            elif op in dis.hasname:\n                instr.arg = co.co_names[oparg]\n            elif op in dis.hasjrel:\n                instr.arg = i + oparg\n            elif op in dis.haslocal:\n                instr.arg = co.co_varnames[oparg]\n            elif op in dis.hascompare:\n                instr.arg = dis.cmp_op[oparg]\n            elif op in dis.hasfree:\n                if free is None:\n                    free = co.co_cellvars + co.co_freevars\n                instr.arg = free[oparg]\n\n        yield instr", "response": "Disassemble a code object. \n yields a generator of Instructions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform (list, pattern, indices = [1]):\n    result = []\n\n    for e in list:\n        m = re.match (pattern, e)\n\n        if m:\n            for i in indices:\n                result.append (m.group (i))\n\n    return result", "response": "Matches all elements of list agains the pattern and returns a list of the elements indicated by indices of\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing occurrences of a match string in a given string and returns the new string.", "response": "def replace(s, pattern, replacement):\n    \"\"\"Replaces occurrences of a match string in a given\n    string and returns the new string. The match string\n    can be a regex expression.\n\n    Args:\n        s (str):           the string to modify\n        pattern (str):     the search expression\n        replacement (str): the string to replace each match with\n    \"\"\"\n    # the replacement string may contain invalid backreferences (like \\1 or \\g)\n    # which will cause python's regex to blow up. Since this should emulate\n    # the jam version exactly and the jam version didn't support\n    # backreferences, this version shouldn't either. re.sub\n    # allows replacement to be a callable; this is being used\n    # to simply return the replacement string and avoid the hassle\n    # of worrying about backreferences within the string.\n    def _replacement(matchobj):\n        return replacement\n    return re.sub(pattern, _replacement, s)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_list(items, match, replacement):\n    return [replace(item, match, replacement) for item in items]", "response": "Replaces occurrences of a match string in a given list of strings and returns\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a topic model from the given data set. A topic model assumes each document is a mixture of a set of topics, where for each topic some words are more likely than others. One statistical approach to do this is called a \"topic model\". This method learns a topic model for the given document collection. Parameters ---------- dataset : SArray of type dict or SFrame with a single column of type dict A bag of words representation of a document corpus. Each element is a dictionary representing a single document, where the keys are words and the values are the number of times that word occurs in that document. num_topics : int, optional The number of topics to learn. initial_topics : SFrame, optional An SFrame with a column of unique words representing the vocabulary and a column of dense vectors representing probability of that word given each topic. When provided, these values are used to initialize the algorithm. alpha : float, optional Hyperparameter that controls the diversity of topics in a document. Smaller values encourage fewer topics per document. Provided value must be positive. Default value is 50/num_topics. beta : float, optional Hyperparameter that controls the diversity of words in a topic. Smaller values encourage fewer words per topic. Provided value must be positive. num_iterations : int, optional The number of iterations to perform. num_burnin : int, optional The number of iterations to perform when inferring the topics for documents at prediction time. verbose : bool, optional When True, print most probable words for each topic while printing progress. print_interval : int, optional The number of iterations to wait between progress reports. associations : SFrame, optional An SFrame with two columns named \"word\" and \"topic\" containing words and the topic id that the word should be associated with. These words are not considered during learning. validation_set : SArray of type dict or SFrame with a single column A bag of words representation of a document corpus, similar to the format required for `dataset`. This will be used to monitor model performance during training. Each document in the provided validation set is randomly split: the first portion is used estimate which topic each document belongs to, and the second portion is used to estimate the model's performance at predicting the unseen words in the test data. method : {'cgs', 'alias'}, optional The algorithm used for learning the model. - *cgs:* Collapsed Gibbs sampling - *alias:* AliasLDA method. Returns ------- out : TopicModel A fitted topic model. This can be used with :py:func:`~TopicModel.get_topics()` and :py:func:`~TopicModel.predict()`. While fitting is in progress, several metrics are shown, including: +------------------+---------------------------------------------------+ | Field | Description | +==================+===================================================+ | Elapsed Time | The number of elapsed seconds. | +------------------+---------------------------------------------------+ | Tokens/second | The number of unique words processed per second | +------------------+---------------------------------------------------+ | Est. Perplexity | An estimate of the model's ability to model the | | | training data. See the documentation on evaluate. | +------------------+---------------------------------------------------+ See Also -------- TopicModel, TopicModel.get_topics, TopicModel.predict, turicreate.SArray.dict_trim_by_keys, TopicModel.evaluate References ---------- - `Wikipedia - Latent Dirichlet allocation <http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>`_ - Alias method: Li, A. et al. (2014) `Reducing the Sampling Complexity of Topic Models. <http://www.sravi.org/pubs/fastlda-kdd2014.pdf>`_. KDD 2014. Examples -------- The following example includes an SArray of documents, where each element represents a document in \"bag of words\" representation -- a dictionary with word keys and whose values are the number of times that word occurred in the document: >>> docs = turicreate.SArray('https://static.turi.com/datasets/nytimes') Once in this form, it is straightforward to learn a topic model. >>> m = turicreate.topic_model.create(docs) It is also easy to create a new topic model from an old one -- whether it was created using Turi Create or another package. >>> m2 = turicreate.topic_model.create(docs, initial_topics=m['topics']) To manually fix several words to always be assigned to a topic, use the `associations` argument. The following will ensure that topic 0 has the most probability for each of the provided words: >>> from turicreate import SFrame >>> associations = SFrame({'word':['hurricane', 'wind', 'storm'], 'topic': [0, 0, 0]}) >>> m = turicreate.topic_model.create(docs, associations=associations) More advanced usage allows you to control aspects of the model and the learning method. >>> import turicreate as tc >>> m = tc.topic_model.create(docs, num_topics=20, # number of topics num_iterations=10, # algorithm parameters alpha=.01, beta=.1) # hyperparameters To evaluate the model's ability to generalize, we can create a train/test split where a portion of the words in each document are held out from training. >>> train, test = tc.text_analytics.random_split(.8) >>> m = tc.topic_model.create(train) >>> results = m.evaluate(test) >>> print results['perplexity']", "response": "def create(dataset,\n           num_topics=10,\n           initial_topics=None,\n           alpha=None,\n           beta=.1,\n           num_iterations=10,\n           num_burnin=5,\n           associations=None,\n           verbose=False,\n           print_interval=10,\n           validation_set=None,\n           method='auto'):\n    \"\"\"\n    Create a topic model from the given data set. A topic model assumes each\n    document is a mixture of a set of topics, where for each topic some words\n    are more likely than others. One statistical approach to do this is called a\n    \"topic model\". This method learns a topic model for the given document\n    collection.\n\n    Parameters\n    ----------\n    dataset : SArray of type dict or SFrame with a single column of type dict\n        A bag of words representation of a document corpus.\n        Each element is a dictionary representing a single document, where\n        the keys are words and the values are the number of times that word\n        occurs in that document.\n\n    num_topics : int, optional\n        The number of topics to learn.\n\n    initial_topics : SFrame, optional\n        An SFrame with a column of unique words representing the vocabulary\n        and a column of dense vectors representing\n        probability of that word given each topic. When provided,\n        these values are used to initialize the algorithm.\n\n    alpha : float, optional\n        Hyperparameter that controls the diversity of topics in a document.\n        Smaller values encourage fewer topics per document.\n        Provided value must be positive. Default value is 50/num_topics.\n\n    beta : float, optional\n        Hyperparameter that controls the diversity of words in a topic.\n        Smaller values encourage fewer words per topic. Provided value\n        must be positive.\n\n    num_iterations : int, optional\n        The number of iterations to perform.\n\n    num_burnin : int, optional\n        The number of iterations to perform when inferring the topics for\n        documents at prediction time.\n\n    verbose : bool, optional\n        When True, print most probable words for each topic while printing\n        progress.\n\n    print_interval : int, optional\n        The number of iterations to wait between progress reports.\n\n    associations : SFrame, optional\n        An SFrame with two columns named \"word\" and \"topic\" containing words\n        and the topic id that the word should be associated with. These words\n        are not considered during learning.\n\n    validation_set : SArray of type dict or SFrame with a single column\n        A bag of words representation of a document corpus, similar to the\n        format required for `dataset`. This will be used to monitor model\n        performance during training. Each document in the provided validation\n        set is randomly split: the first portion is used estimate which topic\n        each document belongs to, and the second portion is used to estimate\n        the model's performance at predicting the unseen words in the test data.\n\n    method : {'cgs', 'alias'}, optional\n        The algorithm used for learning the model.\n\n        - *cgs:* Collapsed Gibbs sampling\n        - *alias:* AliasLDA method.\n\n    Returns\n    -------\n    out : TopicModel\n        A fitted topic model. This can be used with\n        :py:func:`~TopicModel.get_topics()` and\n        :py:func:`~TopicModel.predict()`. While fitting is in progress, several\n        metrics are shown, including:\n\n        +------------------+---------------------------------------------------+\n        |      Field       | Description                                       |\n        +==================+===================================================+\n        | Elapsed Time     | The number of elapsed seconds.                    |\n        +------------------+---------------------------------------------------+\n        | Tokens/second    | The number of unique words processed per second   |\n        +------------------+---------------------------------------------------+\n        | Est. Perplexity  | An estimate of the model's ability to model the   |\n        |                  | training data. See the documentation on evaluate. |\n        +------------------+---------------------------------------------------+\n\n    See Also\n    --------\n    TopicModel, TopicModel.get_topics, TopicModel.predict,\n    turicreate.SArray.dict_trim_by_keys, TopicModel.evaluate\n\n    References\n    ----------\n    - `Wikipedia - Latent Dirichlet allocation\n      <http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>`_\n\n    - Alias method: Li, A. et al. (2014) `Reducing the Sampling Complexity of\n      Topic Models. <http://www.sravi.org/pubs/fastlda-kdd2014.pdf>`_.\n      KDD 2014.\n\n    Examples\n    --------\n    The following example includes an SArray of documents, where\n    each element represents a document in \"bag of words\" representation\n    -- a dictionary with word keys and whose values are the number of times\n    that word occurred in the document:\n\n    >>> docs = turicreate.SArray('https://static.turi.com/datasets/nytimes')\n\n    Once in this form, it is straightforward to learn a topic model.\n\n    >>> m = turicreate.topic_model.create(docs)\n\n    It is also easy to create a new topic model from an old one  -- whether\n    it was created using Turi Create or another package.\n\n    >>> m2 = turicreate.topic_model.create(docs, initial_topics=m['topics'])\n\n    To manually fix several words to always be assigned to a topic, use\n    the `associations` argument. The following will ensure that topic 0\n    has the most probability for each of the provided words:\n\n    >>> from turicreate import SFrame\n    >>> associations = SFrame({'word':['hurricane', 'wind', 'storm'],\n                               'topic': [0, 0, 0]})\n    >>> m = turicreate.topic_model.create(docs,\n                                        associations=associations)\n\n    More advanced usage allows you  to control aspects of the model and the\n    learning method.\n\n    >>> import turicreate as tc\n    >>> m = tc.topic_model.create(docs,\n                                  num_topics=20,       # number of topics\n                                  num_iterations=10,   # algorithm parameters\n                                  alpha=.01, beta=.1)  # hyperparameters\n\n    To evaluate the model's ability to generalize, we can create a train/test\n    split where a portion of the words in each document are held out from\n    training.\n\n    >>> train, test = tc.text_analytics.random_split(.8)\n    >>> m = tc.topic_model.create(train)\n    >>> results = m.evaluate(test)\n    >>> print results['perplexity']\n\n    \"\"\"\n    dataset = _check_input(dataset)\n\n    _check_categorical_option_type(\"method\", method, ['auto', 'cgs', 'alias'])\n    if method == 'cgs' or method == 'auto':\n        model_name = 'cgs_topic_model'\n    else:\n        model_name = 'alias_topic_model'\n\n    # If associations are provided, check they are in the proper format\n    if associations is None:\n        associations = _turicreate.SFrame({'word': [], 'topic': []})\n    if isinstance(associations, _turicreate.SFrame) and \\\n       associations.num_rows() > 0:\n        assert set(associations.column_names()) == set(['word', 'topic']), \\\n            \"Provided associations must be an SFrame containing a word column\\\n             and a topic column.\"\n        assert associations['word'].dtype == str, \\\n            \"Words must be strings.\"\n        assert associations['topic'].dtype == int, \\\n            \"Topic ids must be of int type.\"\n    if alpha is None:\n        alpha = float(50) / num_topics\n\n    if validation_set is not None:\n        _check_input(validation_set)  # Must be a single column\n        if isinstance(validation_set, _turicreate.SFrame):\n            column_name = validation_set.column_names()[0]\n            validation_set = validation_set[column_name]\n        (validation_train, validation_test) = _random_split(validation_set)\n    else:\n        validation_train = _SArray()\n        validation_test = _SArray()\n\n    opts = {'model_name': model_name,\n            'data': dataset,\n            'num_topics': num_topics,\n            'num_iterations': num_iterations,\n            'print_interval': print_interval,\n            'alpha': alpha,\n            'beta': beta,\n            'num_burnin': num_burnin,\n            'associations': associations}\n\n    # Initialize the model with basic parameters\n    response = _turicreate.extensions._text.topicmodel_init(opts)\n    m = TopicModel(response['model'])\n\n    # If initial_topics provided, load it into the model\n    if isinstance(initial_topics, _turicreate.SFrame):\n        assert set(['vocabulary', 'topic_probabilities']) ==              \\\n               set(initial_topics.column_names()),                        \\\n            \"The provided initial_topics does not have the proper format, \\\n             e.g. wrong column names.\"\n        observed_topics = initial_topics['topic_probabilities'].apply(lambda x: len(x))\n        assert all(observed_topics == num_topics),                        \\\n            \"Provided num_topics value does not match the number of provided initial_topics.\"\n\n        # Rough estimate of total number of words\n        weight = len(dataset) * 1000\n\n        opts = {'model': m.__proxy__,\n                'topics': initial_topics['topic_probabilities'],\n                'vocabulary': initial_topics['vocabulary'],\n                'weight': weight}\n        response = _turicreate.extensions._text.topicmodel_set_topics(opts)\n        m = TopicModel(response['model'])\n\n    # Train the model on the given data set and retrieve predictions\n    opts = {'model': m.__proxy__,\n            'data': dataset,\n            'verbose': verbose,\n            'validation_train': validation_train,\n            'validation_test': validation_test}\n\n    response = _turicreate.extensions._text.topicmodel_train(opts)\n    m = TopicModel(response['model'])\n\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the perplexity of a set of test documents given a set of predicted topics and a set of vocabulary.", "response": "def perplexity(test_data, predictions, topics, vocabulary):\n    \"\"\"\n    Compute the perplexity of a set of test documents given a set\n    of predicted topics.\n\n    Let theta be the matrix of document-topic probabilities, where\n    theta_ik = p(topic k | document i). Let Phi be the matrix of term-topic\n    probabilities, where phi_jk = p(word j | topic k).\n\n    Then for each word in each document, we compute for a given word w\n    and document d\n\n    .. math::\n        p(word | \\theta[doc_id,:], \\phi[word_id,:]) =\n       \\sum_k \\theta[doc_id, k] * \\phi[word_id, k]\n\n    We compute loglikelihood to be:\n\n    .. math::\n        l(D) = \\sum_{i \\in D} \\sum_{j in D_i} count_{i,j} * log Pr(word_{i,j} | \\theta, \\phi)\n\n    and perplexity to be\n\n    .. math::\n        \\exp \\{ - l(D) / \\sum_i \\sum_j count_{i,j} \\}\n\n    Parameters\n    ----------\n    test_data : SArray of type dict or SFrame with a single column of type dict\n        Documents in bag-of-words format.\n\n    predictions : SArray\n        An SArray of vector type, where each vector contains estimates of the\n        probability that this document belongs to each of the topics.\n        This must have the same size as test_data; otherwise an exception\n        occurs. This can be the output of\n        :py:func:`~turicreate.topic_model.TopicModel.predict`, for example.\n\n    topics : SFrame\n        An SFrame containing two columns: 'vocabulary' and 'topic_probabilities'.\n        The value returned by m['topics'] is a valid input for this argument,\n        where m is a trained :py:class:`~turicreate.topic_model.TopicModel`.\n\n    vocabulary : SArray\n        An SArray of words to use. All words in test_data that are not in this\n        vocabulary will be ignored.\n\n    Notes\n    -----\n    For more details, see equations 13-16 of [PattersonTeh2013].\n\n\n    References\n    ----------\n    .. [PERP] `Wikipedia - perplexity <http://en.wikipedia.org/wiki/Perplexity>`_\n\n    .. [PattersonTeh2013] Patterson, Teh. `\"Stochastic Gradient Riemannian\n       Langevin Dynamics on the Probability Simplex\"\n       <http://www.stats.ox.ac.uk/~teh/research/compstats/PatTeh2013a.pdf>`_\n       NIPS, 2013.\n\n    Examples\n    --------\n    >>> from turicreate import topic_model\n    >>> train_data, test_data = turicreate.text_analytics.random_split(docs)\n    >>> m = topic_model.create(train_data)\n    >>> pred = m.predict(train_data)\n    >>> topics = m['topics']\n    >>> p = topic_model.perplexity(test_data, pred,\n                                   topics['topic_probabilities'],\n                                   topics['vocabulary'])\n    >>> p\n    1720.7  # lower values are better\n    \"\"\"\n    test_data = _check_input(test_data)\n    assert isinstance(predictions, _SArray), \\\n        \"Predictions must be an SArray of vector type.\"\n    assert predictions.dtype == _array.array, \\\n        \"Predictions must be probabilities. Try using m.predict() with \" + \\\n        \"output_type='probability'.\"\n\n    opts = {'test_data': test_data,\n            'predictions': predictions,\n            'topics': topics,\n            'vocabulary': vocabulary}\n    response = _turicreate.extensions._text.topicmodel_get_perplexity(opts)\n    return response['perplexity']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a structured description of the model including the schema training data training statistics and model hyperparameters.", "response": "def _get_summary_struct(self):\n        \"\"\"\n        Returns a structured description of the model, including (where relevant)\n        the schema of the training data, description of the training data,\n        training statistics, and model hyperparameters.\n\n        Returns\n        -------\n        sections : list (of list of tuples)\n            A list of summary sections.\n              Each section is a list.\n                Each item in a section list is a tuple of the form:\n                  ('<label>','<field>')\n        section_titles: list\n            A list of section titles.\n              The order matches that of the 'sections' object.\n        \"\"\"\n        section_titles=['Schema','Settings']\n\n        vocab_length = len(self.vocabulary)\n        verbose = self.verbose == 1\n\n        sections=[\n                    [\n                        ('Vocabulary Size',_precomputed_field(vocab_length))\n                    ],\n                    [\n                        ('Number of Topics', 'num_topics'),\n                        ('alpha','alpha'),\n                        ('beta','beta'),\n                        ('Iterations', 'num_iterations'),\n                        ('Training time', 'training_time'),\n                        ('Verbose', _precomputed_field(verbose))\n                    ]\n                ]\n        return (sections, section_titles)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value of a given field.", "response": "def _get(self, field):\n        \"\"\"\n        Return the value of a given field. The list of all queryable fields is\n        detailed below, and can be obtained with the\n        :py:func:`~TopicModel._list_fields` method.\n\n        +-----------------------+----------------------------------------------+\n        |      Field            | Description                                  |\n        +=======================+==============================================+\n        | topics                | An SFrame containing a column with the unique|\n        |                       | words observed during training, and a column |\n        |                       | of arrays containing the probability values  |\n        |                       | for each word given each of the topics.      |\n        +-----------------------+----------------------------------------------+\n        | vocabulary            | An SArray containing the words used. This is |\n        |                       | same as the vocabulary column in the topics  |\n        |                       | field above.                                 |\n        +-----------------------+----------------------------------------------+\n\n        Parameters\n        ----------\n        field : string\n            Name of the field to be retrieved.\n\n        Returns\n        -------\n        out\n            Value of the requested field.\n        \"\"\"\n\n        opts = {'model': self.__proxy__, 'field': field}\n        response = _turicreate.extensions._text.topicmodel_get_value(opts)\n        return response['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of statistics collected during creation of the current object.", "response": "def _training_stats(self):\n        \"\"\"\n        Return a dictionary of statistics collected during creation of the\n        model. These statistics are also available with the ``get`` method and\n        are described in more detail in that method's documentation.\n\n        Returns\n        -------\n        out : dict\n            Dictionary of statistics compiled during creation of the\n            TopicModel.\n\n        See Also\n        --------\n        summary\n\n        Examples\n        --------\n        >>> docs = turicreate.SArray('https://static.turi.com/datasets/nips-text')\n        >>> m = turicreate.topic_model.create(docs)\n        >>> m._training_stats()\n        {'training_iterations': 20,\n         'training_time': 20.5034}\n        \"\"\"\n\n        fields = self._list_fields()\n        stat_fields = ['training_time',\n                       'training_iterations']\n        if 'validation_perplexity' in fields:\n            stat_fields.append('validation_perplexity')\n\n        ret = {k : self._get(k) for k in stat_fields}\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_topics(self, topic_ids=None, num_words=5, cdf_cutoff=1.0,\n                   output_type='topic_probabilities'):\n\n        \"\"\"\n        Get the words associated with a given topic. The score column is the\n        probability of choosing that word given that you have chosen a\n        particular topic.\n\n        Parameters\n        ----------\n        topic_ids : list of int, optional\n            The topics to retrieve words. Topic ids are zero-based.\n            Throws an error if greater than or equal to m['num_topics'], or\n            if the requested topic name is not present.\n\n        num_words : int, optional\n            The number of words to show.\n\n        cdf_cutoff : float, optional\n            Allows one to only show the most probable words whose cumulative\n            probability is below this cutoff. For example if there exist\n            three words where\n\n            .. math::\n               p(word_1 | topic_k) = .1\n\n               p(word_2 | topic_k) = .2\n\n               p(word_3 | topic_k) = .05\n\n            then setting :math:`cdf_{cutoff}=.3` would return only\n            :math:`word_1` and :math:`word_2` since\n            :math:`p(word_1 | topic_k) + p(word_2 | topic_k) <= cdf_{cutoff}`\n\n        output_type : {'topic_probabilities' | 'topic_words'}, optional\n            Determine the type of desired output. See below.\n\n        Returns\n        -------\n        out : SFrame\n            If output_type is 'topic_probabilities', then the returned value is\n            an SFrame with a column of words ranked by a column of scores for\n            each topic. Otherwise, the returned value is a SArray where\n            each element is a list of the most probable words for each topic.\n\n        Examples\n        --------\n        Get the highest ranked words for all topics.\n\n        >>> docs = turicreate.SArray('https://static.turi.com/datasets/nips-text')\n        >>> m = turicreate.topic_model.create(docs,\n                                            num_iterations=50)\n        >>> m.get_topics()\n        +-------+----------+-----------------+\n        | topic |   word   |      score      |\n        +-------+----------+-----------------+\n        |   0   |   cell   |  0.028974400831 |\n        |   0   |  input   | 0.0259470208503 |\n        |   0   |  image   | 0.0215721599763 |\n        |   0   |  visual  | 0.0173635081992 |\n        |   0   |  object  | 0.0172447874156 |\n        |   1   | function | 0.0482834508265 |\n        |   1   |  input   | 0.0456270024091 |\n        |   1   |  point   | 0.0302662839454 |\n        |   1   |  result  | 0.0239474934631 |\n        |   1   | problem  | 0.0231750116011 |\n        |  ...  |   ...    |       ...       |\n        +-------+----------+-----------------+\n\n        Get the highest ranked words for topics 0 and 1 and show 15 words per\n        topic.\n\n        >>> m.get_topics([0, 1], num_words=15)\n        +-------+----------+------------------+\n        | topic |   word   |      score       |\n        +-------+----------+------------------+\n        |   0   |   cell   |  0.028974400831  |\n        |   0   |  input   | 0.0259470208503  |\n        |   0   |  image   | 0.0215721599763  |\n        |   0   |  visual  | 0.0173635081992  |\n        |   0   |  object  | 0.0172447874156  |\n        |   0   | response | 0.0139740298286  |\n        |   0   |  layer   | 0.0122585145062  |\n        |   0   | features | 0.0115343177265  |\n        |   0   | feature  | 0.0103530459301  |\n        |   0   | spatial  | 0.00823387994361 |\n        |  ...  |   ...    |       ...        |\n        +-------+----------+------------------+\n\n        If one wants to instead just get the top words per topic, one may\n        change the format of the output as follows.\n\n        >>> topics = m.get_topics(output_type='topic_words')\n        dtype: list\n        Rows: 10\n        [['cell', 'image', 'input', 'object', 'visual'],\n         ['algorithm', 'data', 'learning', 'method', 'set'],\n         ['function', 'input', 'point', 'problem', 'result'],\n         ['model', 'output', 'pattern', 'set', 'unit'],\n         ['action', 'learning', 'net', 'problem', 'system'],\n         ['error', 'function', 'network', 'parameter', 'weight'],\n         ['information', 'level', 'neural', 'threshold', 'weight'],\n         ['control', 'field', 'model', 'network', 'neuron'],\n         ['hidden', 'layer', 'system', 'training', 'vector'],\n         ['component', 'distribution', 'local', 'model', 'optimal']]\n        \"\"\"\n        _check_categorical_option_type('output_type', output_type,\n            ['topic_probabilities', 'topic_words'])\n\n        if topic_ids is None:\n            topic_ids = list(range(self._get('num_topics')))\n\n        assert isinstance(topic_ids, list), \\\n            \"The provided topic_ids is not a list.\"\n\n        if any([type(x) == str for x in topic_ids]):\n            raise ValueError(\"Only integer topic_ids can be used at this point in time.\")\n        if not all([x >= 0 and x < self.num_topics for x in topic_ids]):\n            raise ValueError(\"Topic id values must be non-negative and less than the \" + \\\n                \"number of topics used to fit the model.\")\n\n        opts = {'model': self.__proxy__,\n                'topic_ids': topic_ids,\n                'num_words': num_words,\n                'cdf_cutoff': cdf_cutoff}\n        response = _turicreate.extensions._text.topicmodel_get_topic(opts)\n        ret = response['top_words']\n\n        def sort_wordlist_by_prob(z):\n            words = sorted(z.items(), key=_operator.itemgetter(1), reverse=True)\n            return [word for (word, prob) in words]\n\n        if output_type != 'topic_probabilities':\n            ret = ret.groupby('topic',\n                    {'word': _turicreate.aggregate.CONCAT('word', 'score')})\n            words = ret.sort('topic')['word'].apply(sort_wordlist_by_prob)\n            ret = _SFrame({'words': words})\n\n        return ret", "response": "This method returns the most probable words associated with a given topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing the model to predict topics for each unique word w in a set of documents.", "response": "def predict(self, dataset, output_type='assignment', num_burnin=None):\n        \"\"\"\n        Use the model to predict topics for each document. The provided\n        `dataset` should be an SArray object where each element is a dict\n        representing a single document in bag-of-words format, where keys\n        are words and values are their corresponding counts. If `dataset` is\n        an SFrame, then it must contain a single column of dict type.\n\n        The current implementation will make inferences about each document\n        given its estimates of the topics learned when creating the model.\n        This is done via Gibbs sampling.\n\n        Parameters\n        ----------\n        dataset : SArray, SFrame of type dict\n            A set of documents to use for making predictions.\n\n        output_type : str, optional\n            The type of output desired. This can either be\n\n            - assignment: the returned values are integers in [0, num_topics)\n            - probability: each returned prediction is a vector with length\n              num_topics, where element k represents the probability that\n              document belongs to topic k.\n\n        num_burnin : int, optional\n            The number of iterations of Gibbs sampling to perform when\n            inferring the topics for documents at prediction time.\n            If provided this will override the burnin value set during\n            training.\n\n        Returns\n        -------\n        out : SArray\n\n        See Also\n        --------\n        evaluate\n\n        Examples\n        --------\n        Make predictions about which topic each document belongs to.\n\n        >>> docs = turicreate.SArray('https://static.turi.com/datasets/nips-text')\n        >>> m = turicreate.topic_model.create(docs)\n        >>> pred = m.predict(docs)\n\n        If one is interested in the probability of each topic\n\n        >>> pred = m.predict(docs, output_type='probability')\n\n        Notes\n        -----\n        For each unique word w in a document d, we sample an assignment to\n        topic k with probability proportional to\n\n        .. math::\n            p(z_{dw} = k) \\propto (n_{d,k} + \\\\alpha) * \\Phi_{w,k}\n\n        where\n\n        - :math:`W` is the size of the vocabulary,\n        - :math:`n_{d,k}` is the number of other times we have assigned a word in\n          document to d to topic :math:`k`,\n        - :math:`\\Phi_{w,k}` is the probability under the model of choosing word\n          :math:`w` given the word is of topic :math:`k`. This is the matrix\n          returned by calling `m['topics']`.\n\n        This represents a collapsed Gibbs sampler for the document assignments\n        while we keep the topics learned during training fixed.\n        This process is done in parallel across all documents, five times per\n        document.\n\n        \"\"\"\n        dataset = _check_input(dataset)\n\n        if num_burnin is None:\n            num_burnin = self.num_burnin\n\n        opts = {'model': self.__proxy__,\n                'data': dataset,\n                'num_burnin': num_burnin}\n        response = _turicreate.extensions._text.topicmodel_predict(opts)\n        preds = response['predictions']\n\n        # Get most likely topic if probabilities are not requested\n        if output_type not in ['probability', 'probabilities', 'prob']:\n            # equivalent to numpy.argmax(x)\n            preds = preds.apply(lambda x: max(_izip(x, _xrange(len(x))))[1])\n\n        return preds"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the topic model on the given data sets.", "response": "def evaluate(self, train_data, test_data=None, metric='perplexity'):\n        \"\"\"\n        Estimate the model's ability to predict new data. Imagine you have a\n        corpus of books. One common approach to evaluating topic models is to\n        train on the first half of all of the books and see how well the model\n        predicts the second half of each book.\n\n        This method returns a metric called perplexity, which  is related to the\n        likelihood of observing these words under the given model. See\n        :py:func:`~turicreate.topic_model.perplexity` for more details.\n\n        The provided `train_data` and `test_data` must have the same length,\n        i.e., both data sets must have the same number of documents; the model\n        will use train_data to estimate which topic the document belongs to, and\n        this is used to estimate the model's performance at predicting the\n        unseen words in the test data.\n\n        See :py:func:`~turicreate.topic_model.TopicModel.predict` for details\n        on how these predictions are made, and see\n        :py:func:`~turicreate.text_analytics.random_split` for a helper function\n        that can be used for making train/test splits.\n\n        Parameters\n        ----------\n        train_data : SArray or SFrame\n            A set of documents to predict topics for.\n\n        test_data : SArray or SFrame, optional\n            A set of documents to evaluate performance on.\n            By default this will set to be the same as train_data.\n\n        metric : str\n            The chosen metric to use for evaluating the topic model.\n            Currently only 'perplexity' is supported.\n\n        Returns\n        -------\n        out : dict\n            The set of estimated evaluation metrics.\n\n        See Also\n        --------\n        predict, turicreate.toolkits.text_analytics.random_split\n\n        Examples\n        --------\n        >>> docs = turicreate.SArray('https://static.turi.com/datasets/nips-text')\n        >>> train_data, test_data = turicreate.text_analytics.random_split(docs)\n        >>> m = turicreate.topic_model.create(train_data)\n        >>> m.evaluate(train_data, test_data)\n        {'perplexity': 2467.530370396021}\n\n        \"\"\"\n        train_data = _check_input(train_data)\n\n        if test_data is None:\n            test_data = train_data\n        else:\n            test_data = _check_input(test_data)\n\n        predictions = self.predict(train_data, output_type='probability')\n        topics = self.topics\n\n        ret = {}\n        ret['perplexity'] = perplexity(test_data,\n                                       predictions,\n                                       topics['topic_probabilities'],\n                                       topics['vocabulary'])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts from corner bounding box to center and shape", "response": "def bbox_to_ybox(bbox):\n    \"\"\"Convert from corner bounding box to center/shape\"\"\"\n    return [\n            (bbox[1] + bbox[3]) / 2,\n            (bbox[0] + bbox[2]) / 2,\n            (bbox[3] - bbox[1]),\n            (bbox[2] - bbox[0]),\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nraising a ToolkitError if the input dataset is not a drawing classifier.", "response": "def _raise_error_if_not_drawing_classifier_input_sframe(\n    dataset, feature, target):\n    \"\"\"\n    Performs some sanity checks on the SFrame provided as input to \n    `turicreate.drawing_classifier.create` and raises a ToolkitError\n    if something in the dataset is missing or wrong.\n    \"\"\"\n    from turicreate.toolkits._internal_utils import _raise_error_if_not_sframe\n    _raise_error_if_not_sframe(dataset)\n    if feature not in dataset.column_names():\n        raise _ToolkitError(\"Feature column '%s' does not exist\" % feature)\n    if target not in dataset.column_names():\n        raise _ToolkitError(\"Target column '%s' does not exist\" % target)\n    if (dataset[feature].dtype != _tc.Image and dataset[feature].dtype != list):\n        raise _ToolkitError(\"Feature column must contain images\" \n            + \" or stroke-based drawings encoded as lists of strokes\" \n            + \" where each stroke is a list of points and\" \n            + \" each point is stored as a dictionary\")\n    if dataset[target].dtype != int and dataset[target].dtype != str:\n        raise _ToolkitError(\"Target column contains \" + str(dataset[target].dtype)\n            + \" but it must contain strings or integers to represent\" \n            + \" labels for drawings.\")\n    if len(dataset) == 0:\n        raise _ToolkitError(\"Input Dataset is empty!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new training set with the given dataset and target variable.", "response": "def create(input_dataset, target, feature=None, validation_set='auto',\n            warm_start='auto', batch_size=256, \n            max_iterations=100, verbose=True):\n    \"\"\"\n    Create a :class:`DrawingClassifier` model.\n\n    Parameters\n    ----------\n    dataset : SFrame\n        Input data. The columns named by the ``feature`` and ``target``\n        parameters will be extracted for training the drawing classifier.\n\n    target : string\n        Name of the column containing the target variable. The values in this\n        column must be of string or integer type.\n\n    feature : string optional\n        Name of the column containing the input drawings. 'None' (the default)\n        indicates the column in `dataset` named \"drawing\" should be used as the\n        feature.\n        The feature column can contain both bitmap-based drawings as well as\n        stroke-based drawings. Bitmap-based drawing input can be a grayscale\n        tc.Image of any size.\n        Stroke-based drawing input must be in the following format:\n        Every drawing must be represented by a list of strokes, where each\n        stroke must be a list of points in the order in which they were drawn\n        on the canvas.\n        Each point must be a dictionary with two keys, \"x\" and \"y\", and their\n        respective values must be numerical, i.e. either integer or float.\n\n    validation_set : SFrame optional\n        A dataset for monitoring the model's generalization performance.\n        The format of this SFrame must be the same as the training set.\n        By default this argument is set to 'auto' and a validation set is\n        automatically sampled and used for progress printing. If\n        validation_set is set to None, then no additional metrics\n        are computed. The default value is 'auto'.\n\n    warm_start : string optional\n        A string to denote which pretrained model to use. Set to \"auto\"\n        by default which uses a model trained on 245 of the 345 classes in the\n        Quick, Draw! dataset. To disable warm start, pass in None to this \n        argument. Here is a list of all the pretrained models that\n        can be passed in as this argument:\n        \"auto\": Uses quickdraw_245_v0\n        \"quickdraw_245_v0\": Uses a model trained on 245 of the 345 classes in the\n                         Quick, Draw! dataset.\n        None: No Warm Start\n\n    batch_size: int optional\n        The number of drawings per training step. If not set, a default\n        value of 256 will be used. If you are getting memory errors,\n        try decreasing this value. If you have a powerful computer, increasing\n        this value may improve performance.\n\n    max_iterations : int optional\n        The maximum number of allowed passes through the data. More passes over\n        the data can result in a more accurately trained model. \n\n    verbose : bool optional\n        If True, print progress updates and model details.\n\n    Returns\n    -------\n    out : DrawingClassifier\n        A trained :class:`DrawingClassifier` model.\n\n    See Also\n    --------\n    DrawingClassifier\n\n    Examples\n    --------\n    .. sourcecode:: python\n\n        # Train a drawing classifier model\n        >>> model = turicreate.drawing_classifier.create(data)\n\n        # Make predictions on the training set and as column to the SFrame\n        >>> data['predictions'] = model.predict(data)\n\n    \"\"\"\n    \n    import mxnet as _mx\n    from mxnet import autograd as _autograd\n    from ._model_architecture import Model as _Model\n    from ._sframe_loader import SFrameClassifierIter as _SFrameClassifierIter\n    from .._mxnet import _mxnet_utils\n    \n    start_time = _time.time()\n    accepted_values_for_warm_start = [\"auto\", \"quickdraw_245_v0\", None]\n\n    # @TODO: Should be able to automatically choose number of iterations\n    # based on data size: Tracked in Github Issue #1576\n\n    # automatically infer feature column\n    if feature is None:\n        feature = _tkutl._find_only_drawing_column(input_dataset)\n\n    _raise_error_if_not_drawing_classifier_input_sframe(\n        input_dataset, feature, target)\n\n    if batch_size is not None and not isinstance(batch_size, int):\n        raise TypeError(\"'batch_size' must be an integer >= 1\")\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"'batch_size' must be >= 1\")\n    if max_iterations is not None and not isinstance(max_iterations, int):\n        raise TypeError(\"'max_iterations' must be an integer >= 1\")\n    if max_iterations is not None and max_iterations < 1:\n        raise ValueError(\"'max_iterations' must be >= 1\")\n\n    is_stroke_input = (input_dataset[feature].dtype != _tc.Image)\n    dataset = _extensions._drawing_classifier_prepare_data(\n        input_dataset, feature) if is_stroke_input else input_dataset\n\n    iteration = 0\n\n    classes = dataset[target].unique()\n    classes = sorted(classes)\n    class_to_index = {name: index for index, name in enumerate(classes)}\n\n    validation_set_corrective_string = (\"'validation_set' parameter must be \"\n        + \"an SFrame, or None, or must be set to 'auto' for the toolkit to \" \n        + \"automatically create a validation set.\")\n    if isinstance(validation_set, _tc.SFrame):\n        _raise_error_if_not_drawing_classifier_input_sframe(\n            validation_set, feature, target)\n        is_validation_stroke_input = (validation_set[feature].dtype != _tc.Image)\n        validation_dataset = _extensions._drawing_classifier_prepare_data(\n            validation_set, feature) if is_validation_stroke_input else validation_set\n    elif isinstance(validation_set, str):\n        if validation_set == 'auto':\n            if dataset.num_rows() >= 100:\n                if verbose:\n                    print ( \"PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\\n\"\n                            \"          You can set ``validation_set=None`` to disable validation tracking.\\n\")\n                dataset, validation_dataset = dataset.random_split(TRAIN_VALIDATION_SPLIT, exact=True)\n            else:\n                validation_set = None\n                validation_dataset = _tc.SFrame()\n        else:\n            raise _ToolkitError(\"Unrecognized value for 'validation_set'. \"\n                + validation_set_corrective_string)\n    elif validation_set is None:\n        validation_dataset = _tc.SFrame()\n    else:\n        raise TypeError(\"Unrecognized type for 'validation_set'.\"\n            + validation_set_corrective_string)\n\n    train_loader = _SFrameClassifierIter(dataset, batch_size,\n                 feature_column=feature,\n                 target_column=target,\n                 class_to_index=class_to_index,\n                 load_labels=True,\n                 shuffle=True,\n                 iterations=max_iterations)\n    train_loader_to_compute_accuracy = _SFrameClassifierIter(dataset, batch_size,\n                 feature_column=feature,\n                 target_column=target,\n                 class_to_index=class_to_index,\n                 load_labels=True,\n                 shuffle=True,\n                 iterations=1)\n    validation_loader = _SFrameClassifierIter(validation_dataset, batch_size,\n                 feature_column=feature,\n                 target_column=target,\n                 class_to_index=class_to_index,\n                 load_labels=True,\n                 shuffle=True,\n                 iterations=1)\n    if verbose and iteration == 0:\n        column_names = ['iteration', 'train_loss', 'train_accuracy', 'time']\n        column_titles = ['Iteration', 'Training Loss', 'Training Accuracy', 'Elapsed Time (seconds)']\n        if validation_set is not None:\n            column_names.insert(3, 'validation_accuracy')\n            column_titles.insert(3, 'Validation Accuracy')\n        table_printer = _tc.util._ProgressTablePrinter(\n            column_names, column_titles)\n\n    ctx = _mxnet_utils.get_mxnet_context(max_devices=batch_size)\n    model = _Model(num_classes = len(classes), prefix=\"drawing_\")\n    model_params = model.collect_params()\n    model_params.initialize(_mx.init.Xavier(), ctx=ctx)\n\n    if warm_start is not None:\n        if type(warm_start) is not str:\n            raise TypeError(\"'warm_start' must be a string or None. \" \n                + \"'warm_start' can take in the following values: \" \n                + str(accepted_values_for_warm_start))\n        if warm_start not in accepted_values_for_warm_start:\n            raise _ToolkitError(\"Unrecognized value for 'warm_start': \" \n                + warm_start + \". 'warm_start' can take in the following \" \n                + \"values: \" + str(accepted_values_for_warm_start))\n        pretrained_model = _pre_trained_models.DrawingClassifierPreTrainedModel(\n            warm_start)\n        pretrained_model_params_path = pretrained_model.get_model_path()\n        model.load_params(pretrained_model_params_path, \n            ctx=ctx, \n            allow_missing=True)\n    softmax_cross_entropy = _mx.gluon.loss.SoftmaxCrossEntropyLoss()\n    model.hybridize()\n    trainer = _mx.gluon.Trainer(model.collect_params(), 'adam')\n\n    train_accuracy = _mx.metric.Accuracy()\n    validation_accuracy = _mx.metric.Accuracy()\n\n    def get_data_and_label_from_batch(batch):\n        if batch.pad is not None:\n            size = batch_size - batch.pad\n            sliced_data  = _mx.nd.slice_axis(batch.data[0], axis=0, begin=0, end=size)\n            sliced_label = _mx.nd.slice_axis(batch.label[0], axis=0, begin=0, end=size)\n            num_devices = min(sliced_data.shape[0], len(ctx))\n            batch_data = _mx.gluon.utils.split_and_load(sliced_data, ctx_list=ctx[:num_devices], even_split=False)\n            batch_label = _mx.gluon.utils.split_and_load(sliced_label, ctx_list=ctx[:num_devices], even_split=False)\n        else:\n            batch_data = _mx.gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n            batch_label = _mx.gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n        return batch_data, batch_label\n\n    def compute_accuracy(accuracy_metric, batch_loader):\n        batch_loader.reset()\n        accuracy_metric.reset()\n        for batch in batch_loader:\n            batch_data, batch_label = get_data_and_label_from_batch(batch)\n            outputs = []\n            for x, y in zip(batch_data, batch_label):\n                if x is None or y is None: continue\n                z = model(x)\n                outputs.append(z)\n            accuracy_metric.update(batch_label, outputs)\n\n    for train_batch in train_loader:\n        train_batch_data, train_batch_label = get_data_and_label_from_batch(train_batch)\n        with _autograd.record():\n            # Inside training scope\n            for x, y in zip(train_batch_data, train_batch_label):\n                z = model(x)\n                # Computes softmax cross entropy loss.\n                loss = softmax_cross_entropy(z, y)\n                # Backpropagate the error for one iteration.\n                loss.backward()\n\n        # Make one step of parameter update. Trainer needs to know the\n        # batch size of data to normalize the gradient by 1/batch_size.\n        trainer.step(train_batch.data[0].shape[0])\n        # calculate training metrics\n        train_loss = loss.mean().asscalar()\n        train_time = _time.time() - start_time\n\n        if train_batch.iteration > iteration:\n            # Compute training accuracy\n            compute_accuracy(train_accuracy, train_loader_to_compute_accuracy)\n            # Compute validation accuracy\n            if validation_set is not None:\n                compute_accuracy(validation_accuracy, validation_loader)\n            iteration = train_batch.iteration\n            if verbose:\n                kwargs = {  \"iteration\": iteration,\n                            \"train_loss\": float(train_loss),\n                            \"train_accuracy\": train_accuracy.get()[1],\n                            \"time\": train_time}\n                if validation_set is not None:\n                    kwargs[\"validation_accuracy\"] = validation_accuracy.get()[1]\n                table_printer.print_row(**kwargs)\n\n    state = {\n        '_model': model,\n        '_class_to_index': class_to_index,\n        'num_classes': len(classes),\n        'classes': classes,\n        'input_image_shape': (1, BITMAP_WIDTH, BITMAP_HEIGHT),\n        'batch_size': batch_size,\n        'training_loss': train_loss,\n        'training_accuracy': train_accuracy.get()[1],\n        'training_time': train_time,\n        'validation_accuracy': validation_accuracy.get()[1], \n        # nan if validation_set=None\n        'max_iterations': max_iterations,\n        'target': target,\n        'feature': feature,\n        'num_examples': len(input_dataset)\n    }\n    return DrawingClassifier(state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export_coreml(self, filename, verbose=False):\n        import mxnet as _mx\n        from .._mxnet._mxnet_to_coreml import _mxnet_converter\n        import coremltools as _coremltools\n\n        batch_size = 1\n        image_shape = (batch_size,) + (1, BITMAP_WIDTH, BITMAP_HEIGHT)\n        s_image = _mx.sym.Variable(self.feature,\n            shape=image_shape, dtype=_np.float32)\n\n        from copy import copy as _copy\n        net = _copy(self._model)\n        s_ymap = net(s_image)\n        \n        mod = _mx.mod.Module(symbol=s_ymap, label_names=None, data_names=[self.feature])\n        mod.bind(for_training=False, data_shapes=[(self.feature, image_shape)])\n        mod.init_params()\n        \n        arg_params, aux_params = mod.get_params()\n        net_params = net.collect_params()\n\n        new_arg_params = {}\n        for k, param in arg_params.items():\n            new_arg_params[k] = net_params[k].data(net_params[k].list_ctx()[0])\n        new_aux_params = {}\n        for k, param in aux_params.items():\n            new_aux_params[k] = net_params[k].data(net_params[k].list_ctx()[0])\n        mod.set_params(new_arg_params, new_aux_params)\n\n        coreml_model = _mxnet_converter.convert(mod, mode='classifier',\n                                class_labels=self.classes,\n                                input_shape=[(self.feature, image_shape)],\n                                builder=None, verbose=verbose,\n                                preprocessor_args={\n                                    'image_input_names': [self.feature],\n                                    'image_scale': 1.0/255\n                                })\n\n        DESIRED_OUTPUT_NAME = self.target + \"Probabilities\"\n        spec = coreml_model._spec\n        class_label_output_index = 0 if spec.description.output[0].name == \"classLabel\" else 1\n        probabilities_output_index = 1-class_label_output_index\n        spec.neuralNetworkClassifier.labelProbabilityLayerName = DESIRED_OUTPUT_NAME\n        spec.neuralNetworkClassifier.layers[-1].name = DESIRED_OUTPUT_NAME\n        spec.neuralNetworkClassifier.layers[-1].output[0] = DESIRED_OUTPUT_NAME\n        spec.description.predictedProbabilitiesName = DESIRED_OUTPUT_NAME\n        spec.description.output[probabilities_output_index].name = DESIRED_OUTPUT_NAME\n        from turicreate.toolkits import _coreml_utils\n        model_type = \"drawing classifier\"\n        spec.description.metadata.shortDescription = _coreml_utils._mlmodel_short_description(model_type)\n        spec.description.input[0].shortDescription = self.feature\n        spec.description.output[probabilities_output_index].shortDescription = 'Prediction probabilities'\n        spec.description.output[class_label_output_index].shortDescription = 'Class Label of Top Prediction'\n        from coremltools.models.utils import save_spec as _save_spec\n        _save_spec(spec, filename)", "response": "Exports the Core ML model of the classifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting the class of each class in the input dataset with probabilities.", "response": "def _predict_with_probabilities(self, input_dataset, batch_size=None, \n        verbose=True):\n        \"\"\"\n        Predict with probabilities. The core prediction part that both \n        `evaluate` and `predict` share.\n\n        Returns an SFrame with two columns, self.target, and \"probabilities\".\n\n        The column with column name, self.target, contains the predictions made\n        by the model for the provided dataset.\n\n        The \"probabilities\" column contains the probabilities for each class \n        that the model predicted for the data provided to the function.\n        \"\"\"\n\n        from .._mxnet import _mxnet_utils\n        import mxnet as _mx\n        from ._sframe_loader import SFrameClassifierIter as _SFrameClassifierIter\n\n        is_stroke_input = (input_dataset[self.feature].dtype != _tc.Image)\n        dataset = _extensions._drawing_classifier_prepare_data(\n                input_dataset, self.feature) if is_stroke_input else input_dataset\n    \n        batch_size = self.batch_size if batch_size is None else batch_size\n        loader = _SFrameClassifierIter(dataset, batch_size,\n                    class_to_index=self._class_to_index,\n                    feature_column=self.feature,\n                    target_column=self.target,\n                    load_labels=False,\n                    shuffle=False,\n                    iterations=1)\n\n        dataset_size = len(dataset)\n        ctx = _mxnet_utils.get_mxnet_context()\n\n        index = 0\n        last_time = 0\n        done = False\n\n        from turicreate import SArrayBuilder\n        from array import array\n\n        classes = self.classes\n        all_predicted_builder = SArrayBuilder(dtype=type(classes[0]))\n        all_probabilities_builder = SArrayBuilder(dtype=array)\n\n        for batch in loader:\n            if batch.pad is not None:\n                size = batch_size - batch.pad\n                batch_data = _mx.nd.slice_axis(batch.data[0], \n                    axis=0, begin=0, end=size)\n            else:\n                batch_data = batch.data[0]\n                size = batch_size\n\n            num_devices = min(batch_data.shape[0], len(ctx))\n            split_data = _mx.gluon.utils.split_and_load(batch_data, ctx_list=ctx[:num_devices], even_split=False)\n\n            for data in split_data:\n                z = self._model(data).asnumpy()\n                predicted = list(map(lambda x: classes[x], z.argmax(axis=1)))\n                split_length = z.shape[0]\n                all_predicted_builder.append_multiple(predicted)\n                all_probabilities_builder.append_multiple(z.tolist())\n                index += split_length\n                if index == dataset_size - 1:\n                    done = True\n\n                cur_time = _time.time()\n                # Do not print progress if only a few samples are predicted\n                if verbose and (dataset_size >= 5\n                    and cur_time > last_time + 10 or done):\n                    print('Predicting {cur_n:{width}d}/{max_n:{width}d}'.format(\n                        cur_n = index + 1,\n                        max_n = dataset_size,\n                        width = len(str(dataset_size))))\n                    last_time = cur_time\n\n        return (_tc.SFrame({self.target: all_predicted_builder.close(),\n                            'probability': all_probabilities_builder.close()}))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self, dataset, metric='auto', batch_size=None, verbose=True):\n\n        if self.target not in dataset.column_names():\n            raise _ToolkitError(\"Must provide ground truth column, '\" \n                + self.target + \"' in the evaluation dataset.\")\n\n        predicted = self._predict_with_probabilities(dataset, batch_size, verbose)\n\n        avail_metrics = ['accuracy', 'auc', 'precision', 'recall',\n                         'f1_score', 'confusion_matrix', 'roc_curve']\n\n        _tkutl._check_categorical_option_type(\n                        'metric', metric, avail_metrics + ['auto'])\n\n        metrics = avail_metrics if metric == 'auto' else [metric]\n        \n        ret = {}\n        if 'accuracy' in metrics:\n            ret['accuracy'] = _evaluation.accuracy(\n                dataset[self.target], predicted[self.target])\n        if 'auc' in metrics:\n            ret['auc'] = _evaluation.auc(\n                dataset[self.target], predicted['probability'], \n                index_map=self._class_to_index)\n        if 'precision' in metrics:\n            ret['precision'] = _evaluation.precision(\n                dataset[self.target], predicted[self.target])\n        if 'recall' in metrics:\n            ret['recall'] = _evaluation.recall(\n                dataset[self.target], predicted[self.target])\n        if 'f1_score' in metrics:\n            ret['f1_score'] = _evaluation.f1_score(\n                dataset[self.target], predicted[self.target])\n        if 'confusion_matrix' in metrics:\n            ret['confusion_matrix'] = _evaluation.confusion_matrix(\n                dataset[self.target], predicted[self.target])\n        if 'roc_curve' in metrics:\n            ret['roc_curve'] = _evaluation.roc_curve(\n                dataset[self.target], predicted['probability'], \n                index_map=self._class_to_index)\n        \n        return ret", "response": "Evaluate the model by making predictions of target values and comparing them to actual values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict_topk(self, dataset, output_type=\"probability\", k=3,\n        batch_size=None):\n        \"\"\"\n        Return top-k predictions for the ``dataset``, using the trained model.\n        Predictions are returned as an SFrame with three columns: `id`,\n        `class`, and `probability` or `rank`, depending on the ``output_type``\n        parameter.\n\n        Parameters\n        ----------\n        dataset : SFrame | SArray | turicreate.Image | list\n            Drawings to be classified.\n            If dataset is an SFrame, it must include columns with the same\n            names as the features used for model training, but does not require\n            a target column. Additional columns are ignored.\n\n        output_type : {'probability', 'rank'}, optional\n            Choose the return type of the prediction:\n\n            - `probability`: Probability associated with each label in the \n                             prediction.\n            - `rank`       : Rank associated with each label in the prediction.\n            \n        k : int, optional\n            Number of classes to return for each input example.\n\n        batch_size : int, optional\n            If you are getting memory errors, try decreasing this value. If you\n            have a powerful computer, increasing this value may improve\n            performance.\n\n        Returns\n        -------\n        out : SFrame\n            An SFrame with model predictions.\n\n        See Also\n        --------\n        predict, evaluate\n\n        Examples\n        --------\n        >>> pred = m.predict_topk(validation_data, k=3)\n        >>> pred\n        +----+-------+-------------------+\n        | id | class |   probability     |\n        +----+-------+-------------------+\n        | 0  |   4   |   0.995623886585  |\n        | 0  |   9   |  0.0038311756216  |\n        | 0  |   7   | 0.000301006948575 |\n        | 1  |   1   |   0.928708016872  |\n        | 1  |   3   |  0.0440889261663  |\n        | 1  |   2   |  0.0176190119237  |\n        | 2  |   3   |   0.996967732906  |\n        | 2  |   2   |  0.00151345680933 |\n        | 2  |   7   | 0.000637513934635 |\n        | 3  |   1   |   0.998070061207  |\n        | .. |  ...  |        ...        |\n        +----+-------+-------------------+\n        [35688 rows x 3 columns]\n        \"\"\"\n        _tkutl._check_categorical_option_type(\"output_type\", output_type, \n            [\"probability\", \"rank\"])\n        \n        if not isinstance(k, int): \n            raise TypeError(\"'k' must be an integer >= 1\")\n        if k <= 0: \n            raise ValueError(\"'k' must be >= 1\")\n        if batch_size is not None and not isinstance(batch_size, int):\n            raise TypeError(\"'batch_size' must be an integer >= 1\")\n        if batch_size is not None and batch_size < 1:\n            raise ValueError(\"'batch_size' must be >= 1\")\n\n        prob_vector = self.predict(\n            dataset, output_type='probability_vector', batch_size=batch_size)\n\n        classes = self.classes\n        if output_type == 'probability':\n            results = prob_vector.apply(lambda p: [\n                        {'class': classes[i], 'probability': p[i]}\n                        for i in reversed(_np.argsort(p)[-k:])]\n                      )\n        else:\n            assert(output_type == 'rank')\n            results = prob_vector.apply(lambda p: [\n                        {'class': classes[index], 'rank': rank}\n                        for rank, index in enumerate(reversed(_np.argsort(p)[-k:]))]\n                      )\n\n        results = _tc.SFrame({'X': results})\n        results = results.add_row_number()\n        results = results.stack('X', new_column_name='X')\n        results = results.unpack('X', column_name_prefix='')\n        return results", "response": "Predicts the top - k predictions for the dataset using the trained model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the class of the specified set of classes.", "response": "def predict(self, data, output_type='class', batch_size=None, verbose=True):\n        \"\"\"\n        Predict on an SFrame or SArray of drawings, or on a single drawing.\n\n        Parameters\n        ----------\n        data : SFrame | SArray | tc.Image | list\n            The drawing(s) on which to perform drawing classification.\n            If dataset is an SFrame, it must have a column with the same name\n            as the feature column during training. Additional columns are\n            ignored.\n            If the data is a single drawing, it can be either of type tc.Image,\n            in which case it is a bitmap-based drawing input,\n            or of type list, in which case it is a stroke-based drawing input.\n\n        output_type : {'probability', 'class', 'probability_vector'}, optional\n            Form of the predictions which are one of:\n            \n            - 'class': Class prediction. For multi-class classification, this\n              returns the class with maximum probability.\n            - 'probability': Prediction probability associated with the True\n              class (not applicable for multi-class classification)\n            - 'probability_vector': Prediction probability associated with each\n              class as a vector. Label ordering is dictated by the ``classes``\n              member variable.\n\n        batch_size : int, optional\n            If you are getting memory errors, try decreasing this value. If you\n            have a powerful computer, increasing this value may improve\n            performance.\n\n        verbose : bool, optional\n            If True, prints prediction progress.\n\n        Returns\n        -------\n        out : SArray\n            An SArray with model predictions. Each element corresponds to\n            a drawing and contains a single value corresponding to the\n            predicted label. Each prediction will have type integer or string\n            depending on the type of the classes the model was trained on.\n            If `data` is a single drawing, the return value will be a single\n            prediction.\n\n        See Also\n        --------\n        evaluate\n\n        Examples\n        --------\n        .. sourcecode:: python\n\n            # Make predictions\n            >>> pred = model.predict(data)\n\n            # Print predictions, for a better overview\n            >>> print(pred)\n            dtype: int\n            Rows: 10\n            [3, 4, 3, 3, 4, 5, 8, 8, 8, 4]\n        \"\"\"\n        _tkutl._check_categorical_option_type(\"output_type\", output_type, \n            [\"probability\", \"class\", \"probability_vector\"])\n        if isinstance(data, _tc.SArray):\n            predicted = self._predict_with_probabilities(\n                _tc.SFrame({\n                    self.feature: data\n                }),\n                batch_size,\n                verbose\n            )\n        elif isinstance(data, _tc.SFrame):\n            predicted = self._predict_with_probabilities(data, batch_size, verbose)\n        else:\n            # single input\n            predicted = self._predict_with_probabilities(\n                _tc.SFrame({\n                    self.feature: [data]\n                }),\n                batch_size,\n                verbose\n            )\n        if output_type == \"class\":\n            return predicted[self.target]\n        elif output_type == \"probability\":\n            _class_to_index = self._class_to_index\n            target = self.target\n            return predicted.apply(\n                lambda row: row[\"probability\"][_class_to_index[row[target]]])\n        else:\n            assert (output_type == \"probability_vector\")\n            return predicted[\"probability\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts features from an SFrame of images.", "response": "def extract_features(self, dataset, feature, batch_size=64, verbose=False):\n        \"\"\"\n        Parameters\n        ----------\n        dataset: SFrame\n            SFrame of images\n        \"\"\"\n        from ._mxnet._mx_sframe_iter import SFrameImageIter as _SFrameImageIter\n        from six.moves.queue import Queue as _Queue\n        from threading import Thread as _Thread\n        import turicreate as _tc\n        import array\n\n        if len(dataset) == 0:\n            return _tc.SArray([], array.array)\n\n        batch_size = min(len(dataset), batch_size)\n        # Make a data iterator\n        dataIter = _SFrameImageIter(sframe=dataset, data_field=[feature], batch_size=batch_size, image_shape=self.image_shape)\n\n        # Setup the MXNet model\n        model = MXFeatureExtractor._get_mx_module(self.ptModel.mxmodel,\n                self.data_layer, self.feature_layer, self.context, self.image_shape, batch_size)\n\n        out = _tc.SArrayBuilder(dtype = array.array)\n        progress = { 'num_processed' : 0, 'total' : len(dataset) }\n        if verbose:\n            print(\"Performing feature extraction on resized images...\")\n\n        # Encapsulates the work done by the MXNet model for a single batch\n        def handle_request(batch):\n            model.forward(batch)\n            mx_out = [array.array('d',m) for m in model.get_outputs()[0].asnumpy()]\n            if batch.pad != 0:\n                # If batch size is not evenly divisible by the length, it will loop back around.\n                # We don't want that.\n                mx_out = mx_out[:-batch.pad]\n            return mx_out\n\n        # Copies the output from MXNet into the SArrayBuilder and emits progress\n        def consume_response(mx_out):\n            out.append_multiple(mx_out)\n\n            progress['num_processed'] += len(mx_out)\n            if verbose:\n                print('Completed {num_processed:{width}d}/{total:{width}d}'.format(\n                    width = len(str(progress['total'])), **progress))\n\n        # Create a dedicated thread for performing MXNet work, using two FIFO\n        # queues for communication back and forth with this thread, with the\n        # goal of keeping MXNet busy throughout.\n        request_queue = _Queue()\n        response_queue = _Queue()\n        def mx_worker():\n            while True:\n                batch = request_queue.get()  # Consume request\n                if batch is None:\n                    # No more work remains. Allow the thread to finish.\n                    return\n                response_queue.put(handle_request(batch))  # Produce response\n        mx_worker_thread = _Thread(target=mx_worker)\n        mx_worker_thread.start()\n\n        try:\n            # Attempt to have two requests in progress at any one time (double\n            # buffering), so that the iterator is creating one batch while MXNet\n            # performs inference on the other.\n            if dataIter.has_next:\n                request_queue.put(next(dataIter))  # Produce request\n                while dataIter.has_next:\n                    request_queue.put(next(dataIter))  # Produce request\n                    consume_response(response_queue.get())\n                consume_response(response_queue.get())\n        finally:\n            # Tell the worker thread to shut down.\n            request_queue.put(None)\n\n        return out.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the coreml model for the current state of the coreml model.", "response": "def get_coreml_model(self, mode = 'classifier'):\n        \"\"\"\n        Parameters\n        ----------\n        mode: str ('classifier', 'regressor' or None)\n            Mode of the converted coreml model.\n            When mode = 'classifier', a NeuralNetworkClassifier spec will be constructed.\n            When mode = 'regressor', a NeuralNetworkRegressor spec will be constructed.\n\n        Returns\n        -------\n        model: MLModel\n            Return the underlying model.\n        \"\"\"\n        import mxnet as _mx\n        from ._mxnet import _mxnet_utils\n        from ._mxnet._mxnet_to_coreml import _mxnet_converter\n\n        (sym, arg_params, aux_params) = self.ptModel.mxmodel\n        fe_mxmodel = self.ptModel.mxmodel\n\n        if self.ptModel.is_feature_layer_final:\n            feature_layer_size = self.ptModel.feature_layer_size\n            num_dummy_classes = 10\n            feature_layer_sym = sym.get_children()[0]\n            fc_symbol = _mx.symbol.FullyConnected(feature_layer_sym, num_hidden=num_dummy_classes)\n            prob = _mx.symbol.SoftmaxOutput(fc_symbol, name = sym.name, attr=sym.attr_dict()[sym.name])\n            arg_params['%s_weight' % fc_symbol.name] = _mx.ndarray.zeros((num_dummy_classes, feature_layer_size))\n            arg_params['%s_bias' % fc_symbol.name] = _mx.ndarray.zeros((num_dummy_classes))\n            fe_mxmodel = (prob, arg_params, aux_params)\n\n        model = MXFeatureExtractor._get_mx_module(fe_mxmodel,\n                self.data_layer, self.ptModel.output_layer, _mxnet_utils.get_mxnet_context(max_devices=1),\n                self.image_shape, label_layer = self.ptModel.label_layer)\n\n        preprocessor_args = {'image_input_names': [self.data_layer]}\n        return _mxnet_converter.convert(model, mode = 'classifier',\n                input_shape=[(self.data_layer, (1, ) + self.image_shape)],\n                class_labels = list(map(str, range(self.ptModel.num_classes))),\n                preprocessor_args = preprocessor_args, verbose = False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef available_parameters_subset(self, mx_params):\n        from copy import copy\n        from collections import OrderedDict\n        subset_params = copy(mx_params)\n        subset_params._params = OrderedDict([\n            (k, v) for k, v in mx_params.items() if k in self.weight_names\n        ])\n        return subset_params", "response": "Takes an OrderedDict of mxnet parameter collect and subsets it with the available parameters in this base network."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _BOW_FEATURE_EXTRACTOR(sf, target=None):\n    if isinstance(sf, dict):\n        out = _tc.SArray([sf]).unpack('')\n    elif isinstance(sf, _tc.SFrame):\n        out = sf.__copy__()\n    else:\n        raise ValueError(\"Unrecognized input to feature extractor.\")\n    for f in _get_str_columns(out):\n        if target != f:\n            out[f] = _tc.text_analytics.count_words(out[f])\n    return out", "response": "Returns an SFrame containing a bag of words representation of each column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new classifier model that trains text from a dataset.", "response": "def create(dataset, target, features = None, drop_stop_words = True,\n           word_count_threshold = 2, method = 'auto', validation_set = 'auto',\n           max_iterations = 10):\n    \"\"\"\n    Create a model that trains a classifier to classify text from a\n    collection of documents. The model is a\n    :class:`~turicreate.logistic_classifier.LogisticClassifier` model trained\n    using a bag-of-words representation of the text dataset.\n\n    Parameters\n    ----------\n    dataset : SFrame\n      Contains one or more columns of text data. This can be unstructured text\n      dataset, such as that appearing in forums, user-generated reviews, etc.\n\n    target : str\n      The column name containing class labels for each document.\n\n    features : list[str], optional\n      The column names of interest containing text dataset. Each provided column\n      must be str type. Defaults to using all columns of type str.\n\n    drop_stop_words : bool, optional\n        Ignore very common words, eg: \"the\", \"a\", \"is\".\n        For the complete list of stop words, see: `text_classifier.drop_words()`.\n\n    word_count_threshold : int, optional\n        Words which occur less than this often, in the entire dataset, will be\n        ignored.\n\n    method: str, optional\n      Method to use for feature engineering and modeling. Currently only\n      bag-of-words and logistic classifier ('bow-logistic') is available.\n\n    validation_set : SFrame, optional\n      A dataset for monitoring the model's generalization performance.\n      For each row of the progress table, the chosen metrics are computed\n      for both the provided training dataset and the validation_set. The\n      format of this SFrame must be the same as the training set.\n      By default this argument is set to 'auto' and a validation set is\n      automatically sampled and used for progress printing. If\n      validation_set is set to None, then no additional metrics\n      are computed. The default value is 'auto'.\n\n    max_iterations : int, optional\n      The maximum number of allowed passes through the data. More passes over\n      the data can result in a more accurately trained model. Consider\n      increasing this (the default value is 10) if the training accuracy is\n      low and the *Grad-Norm* in the display is large.\n\n    Returns\n    -------\n    out : :class:`~TextClassifier`\n\n    Examples\n    --------\n    >>> import turicreate as tc\n    >>> dataset = tc.SFrame({'rating': [1, 5], 'text': ['hate it', 'love it']})\n\n    >>> m = tc.text_classifier.create(dataset, 'rating', features=['text'])\n    >>> m.predict(dataset)\n\n    You may also evaluate predictions against known text scores.\n\n    >>> metrics = m.evaluate(dataset)\n\n    See Also\n    --------\n    text_classifier.stop_words, text_classifier.drop_words\n\n\n    \"\"\"\n    _raise_error_if_not_sframe(dataset, \"dataset\")\n\n    # Validate method.\n    if method == 'auto':\n        method = 'bow-logistic'\n    if method not in ['bow-logistic']:\n        raise ValueError(\"Unsupported method provided.\")\n\n    # Validate dataset\n    if features is None:\n        features = dataset.column_names()\n\n    # Remove target column from list of feature columns.\n    features = [f for f in features if f != target]\n\n    # Process training set using the default feature extractor.\n    feature_extractor = _BOW_FEATURE_EXTRACTOR\n    train = feature_extractor(dataset, target)\n\n    stop_words = None\n    if drop_stop_words:\n        stop_words = _text_analytics.stop_words()\n    for cur_feature in features:\n        train[cur_feature] = _text_analytics.drop_words(train[cur_feature],\n                                                        threshold = word_count_threshold,\n                                                        stop_words = stop_words)\n\n    # Check for a validation set.\n    if isinstance(validation_set, _tc.SFrame):\n        validation_set = feature_extractor(validation_set, target)\n\n    m = _tc.logistic_classifier.create(train,\n                                       target=target,\n                                       features=features,\n                                       l2_penalty=.2,\n                                       max_iterations=max_iterations,\n                                       validation_set=validation_set)\n    num_examples = len(dataset)\n    model = TextClassifier()\n    model.__proxy__.update(\n        {'target':   target,\n         'features': features,\n         'method':   method,\n         'num_examples': num_examples,\n         'num_features': len(features),\n         'classifier': m})\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of names of columns that are string type.", "response": "def _get_str_columns(sf):\n    \"\"\"\n    Returns a list of names of columns that are string type.\n    \"\"\"\n    return [name for name in sf.column_names() if sf[name].dtype == str]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts the new observations for the given dataset using the trained model.", "response": "def predict(self, dataset, output_type='class'):\n        \"\"\"\n        Return predictions for ``dataset``, using the trained model.\n\n        Parameters\n        ----------\n        dataset : SFrame\n            dataset of new observations. Must include columns with the same\n            names as the features used for model training, but does not require\n            a target column. Additional columns are ignored.\n\n        output_type : {'class', 'probability_vector'}, optional\n            Form of the predictions which are one of:\n\n            - 'probability_vector': Prediction probability associated with each\n              class as a vector. The probability of the first class (sorted\n              alphanumerically by name of the class in the training set) is in\n              position 0 of the vector, the second in position 1 and so on.\n            - 'class': Class prediction. For multi-class classification, this\n              returns the class with maximum probability.\n\n        Returns\n        -------\n        out : SArray\n            An SArray with model predictions.\n\n        See Also\n        ----------\n        create, evaluate, classify\n\n\n        Examples\n        --------\n        >>> import turicreate as tc\n        >>> dataset = tc.SFrame({'rating': [1, 5], 'text': ['hate it', 'love it']})\n        >>> m = tc.text_classifier.create(dataset, 'rating', features=['text'])\n        >>> m.predict(dataset)\n\n        \"\"\"\n        m = self.__proxy__['classifier']\n        target = self.__proxy__['target']\n        f = _BOW_FEATURE_EXTRACTOR\n        return m.predict(f(dataset, target), output_type=output_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef classify(self, dataset):\n        m = self.__proxy__['classifier']\n        target = self.__proxy__['target']\n        f = _BOW_FEATURE_EXTRACTOR\n        return m.classify(f(dataset, target))", "response": "Return a classification for each example in the dataset using the APK s trained model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evaluate(self, dataset, metric='auto', **kwargs):\n        m = self.__proxy__['classifier']\n        target = self.__proxy__['target']\n        f = _BOW_FEATURE_EXTRACTOR\n        test = f(dataset, target)\n        return m.evaluate(test, metric, **kwargs)", "response": "Evaluate the model by making predictions of target values and comparing them to actual values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_base_svm_regression_spec(model):\n    if not(_HAS_SKLEARN):\n        raise RuntimeError('scikit-learn not found. scikit-learn conversion API is disabled.')\n\n    spec = _Model_pb2.Model()\n    spec.specificationVersion = SPECIFICATION_VERSION\n    svm = spec.supportVectorRegressor\n\n    _set_kernel(model, svm)\n\n    svm.rho = -model.intercept_[0]\n    for i in range(len(model._dual_coef_)):\n        for cur_alpha in model._dual_coef_[i]:\n            svm.coefficients.alpha.append(cur_alpha)\n\n    for cur_src_vector in model.support_vectors_:\n        cur_dest_vector = svm.denseSupportVectors.vectors.add()\n        for i in cur_src_vector:\n            cur_dest_vector.values.append(i)\n    return spec", "response": "Generates a base SVM regression spec using the parts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a Support Vector Regressor model to the protobuf spec.", "response": "def convert(model, features, target):\n    \"\"\"Convert a Support Vector Regressor (SVR) model to the protobuf spec.\n    Parameters\n    ----------\n    model: SVR\n        A trained SVR encoder model.\n\n    feature_names: [str]\n        Name of the input columns.\n\n    target: str\n        Name of the output column.\n\n    Returns\n    -------\n    model_spec: An object of type Model_pb.\n        Protobuf representation of the model\n    \"\"\"\n    spec = _generate_base_svm_regression_spec(model)\n    spec = set_regressor_interface_params(spec, features, target)\n    return _MLModel(spec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _VerifyExtensionHandle(message, extension_handle):\n\n  if not isinstance(extension_handle, _FieldDescriptor):\n    raise KeyError('HasExtension() expects an extension handle, got: %s' %\n                   extension_handle)\n\n  if not extension_handle.is_extension:\n    raise KeyError('\"%s\" is not an extension.' % extension_handle.full_name)\n\n  if not extension_handle.containing_type:\n    raise KeyError('\"%s\" is missing a containing_type.'\n                   % extension_handle.full_name)\n\n  if extension_handle.containing_type is not message.DESCRIPTOR:\n    raise KeyError('Extension \"%s\" extends message type \"%s\", but this '\n                   'message is of type \"%s\".' %\n                   (extension_handle.full_name,\n                    extension_handle.containing_type.full_name,\n                    message.DESCRIPTOR.full_name))", "response": "Verify that the given extension handle is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds all enum values to the class.", "response": "def _AddEnumValues(descriptor, cls):\n  \"\"\"Sets class-level attributes for all enum fields defined in this message.\n\n  Also exporting a class-level object that can name enum values.\n\n  Args:\n    descriptor: Descriptor object for this message type.\n    cls: Class we're constructing for this message type.\n  \"\"\"\n  for enum_type in descriptor.enum_types:\n    setattr(cls, enum_type.name, enum_type_wrapper.EnumTypeWrapper(enum_type))\n    for enum_value in enum_type.values:\n      setattr(cls, enum_value.name, enum_value.number)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a function which returns a default value for a given field.", "response": "def _DefaultValueConstructorForField(field):\n  \"\"\"Returns a function which returns a default value for a field.\n\n  Args:\n    field: FieldDescriptor object for this field.\n\n  The returned function has one argument:\n    message: Message instance containing this field, or a weakref proxy\n      of same.\n\n  That function in turn returns a default value for this field.  The default\n    value may refer back to |message| via a weak reference.\n  \"\"\"\n\n  if _IsMapField(field):\n    return _GetInitializeDefaultForMap(field)\n\n  if field.label == _FieldDescriptor.LABEL_REPEATED:\n    if field.has_default_value and field.default_value != []:\n      raise ValueError('Repeated field default value not empty list: %s' % (\n          field.default_value))\n    if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n      # We can't look at _concrete_class yet since it might not have\n      # been set.  (Depends on order in which we initialize the classes).\n      message_type = field.message_type\n      def MakeRepeatedMessageDefault(message):\n        return containers.RepeatedCompositeFieldContainer(\n            message._listener_for_children, field.message_type)\n      return MakeRepeatedMessageDefault\n    else:\n      type_checker = type_checkers.GetTypeChecker(field)\n      def MakeRepeatedScalarDefault(message):\n        return containers.RepeatedScalarFieldContainer(\n            message._listener_for_children, type_checker)\n      return MakeRepeatedScalarDefault\n\n  if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n    # _concrete_class may not yet be initialized.\n    message_type = field.message_type\n    def MakeSubMessageDefault(message):\n      result = message_type._concrete_class()\n      result._SetListener(\n          _OneofListener(message, field)\n          if field.containing_oneof is not None\n          else message._listener_for_children)\n      return result\n    return MakeSubMessageDefault\n\n  def MakeScalarDefault(message):\n    # TODO(protobuf-team): This may be broken since there may not be\n    # default_value.  Combine with has_default_value somehow.\n    return field.default_value\n  return MakeScalarDefault"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _AddInitMethod(message_descriptor, cls):\n\n  def _GetIntegerEnumValue(enum_type, value):\n    \"\"\"Convert a string or integer enum value to an integer.\n\n    If the value is a string, it is converted to the enum value in\n    enum_type with the same name.  If the value is not a string, it's\n    returned as-is.  (No conversion or bounds-checking is done.)\n    \"\"\"\n    if isinstance(value, six.string_types):\n      try:\n        return enum_type.values_by_name[value].number\n      except KeyError:\n        raise ValueError('Enum type %s: unknown label \"%s\"' % (\n            enum_type.full_name, value))\n    return value\n\n  def init(self, **kwargs):\n    self._cached_byte_size = 0\n    self._cached_byte_size_dirty = len(kwargs) > 0\n    self._fields = {}\n    # Contains a mapping from oneof field descriptors to the descriptor\n    # of the currently set field in that oneof field.\n    self._oneofs = {}\n\n    # _unknown_fields is () when empty for efficiency, and will be turned into\n    # a list if fields are added.\n    self._unknown_fields = ()\n    self._is_present_in_parent = False\n    self._listener = message_listener_mod.NullMessageListener()\n    self._listener_for_children = _Listener(self)\n    for field_name, field_value in kwargs.items():\n      field = _GetFieldByName(message_descriptor, field_name)\n      if field is None:\n        raise TypeError(\"%s() got an unexpected keyword argument '%s'\" %\n                        (message_descriptor.name, field_name))\n      if field_value is None:\n        # field=None is the same as no field at all.\n        continue\n      if field.label == _FieldDescriptor.LABEL_REPEATED:\n        copy = field._default_constructor(self)\n        if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:  # Composite\n          if _IsMapField(field):\n            if _IsMessageMapField(field):\n              for key in field_value:\n                copy[key].MergeFrom(field_value[key])\n            else:\n              copy.update(field_value)\n          else:\n            for val in field_value:\n              if isinstance(val, dict):\n                copy.add(**val)\n              else:\n                copy.add().MergeFrom(val)\n        else:  # Scalar\n          if field.cpp_type == _FieldDescriptor.CPPTYPE_ENUM:\n            field_value = [_GetIntegerEnumValue(field.enum_type, val)\n                           for val in field_value]\n          copy.extend(field_value)\n        self._fields[field] = copy\n      elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n        copy = field._default_constructor(self)\n        new_val = field_value\n        if isinstance(field_value, dict):\n          new_val = field.message_type._concrete_class(**field_value)\n        try:\n          copy.MergeFrom(new_val)\n        except TypeError:\n          _ReraiseTypeErrorWithFieldName(message_descriptor.name, field_name)\n        self._fields[field] = copy\n      else:\n        if field.cpp_type == _FieldDescriptor.CPPTYPE_ENUM:\n          field_value = _GetIntegerEnumValue(field.enum_type, field_value)\n        try:\n          setattr(self, field_name, field_value)\n        except TypeError:\n          _ReraiseTypeErrorWithFieldName(message_descriptor.name, field_name)\n\n  init.__module__ = None\n  init.__doc__ = None\n  cls.__init__ = init", "response": "Adds an __init__ method to cls."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a field descriptor by field name.", "response": "def _GetFieldByName(message_descriptor, field_name):\n  \"\"\"Returns a field descriptor by field name.\n\n  Args:\n    message_descriptor: A Descriptor describing all fields in message.\n    field_name: The name of the field to retrieve.\n  Returns:\n    The field descriptor associated with the field name.\n  \"\"\"\n  try:\n    return message_descriptor.fields_by_name[field_name]\n  except KeyError:\n    raise ValueError('Protocol message %s has no \"%s\" field.' %\n                     (message_descriptor.name, field_name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _AddPropertiesForFields(descriptor, cls):\n  for field in descriptor.fields:\n    _AddPropertiesForField(field, cls)\n\n  if descriptor.is_extendable:\n    # _ExtensionDict is just an adaptor with no state so we allocate a new one\n    # every time it is accessed.\n    cls.Extensions = property(lambda self: _ExtensionDict(self))", "response": "Adds properties for all fields in this protocol message type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _AddPropertiesForField(field, cls):\n  # Catch it if we add other types that we should\n  # handle specially here.\n  assert _FieldDescriptor.MAX_CPPTYPE == 10\n\n  constant_name = field.name.upper() + \"_FIELD_NUMBER\"\n  setattr(cls, constant_name, field.number)\n\n  if field.label == _FieldDescriptor.LABEL_REPEATED:\n    _AddPropertiesForRepeatedField(field, cls)\n  elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n    _AddPropertiesForNonRepeatedCompositeField(field, cls)\n  else:\n    _AddPropertiesForNonRepeatedScalarField(field, cls)", "response": "Adds a public property for a protocol message field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a public property for a repeated protocol message field.", "response": "def _AddPropertiesForRepeatedField(field, cls):\n  \"\"\"Adds a public property for a \"repeated\" protocol message field.  Clients\n  can use this property to get the value of the field, which will be either a\n  _RepeatedScalarFieldContainer or _RepeatedCompositeFieldContainer (see\n  below).\n\n  Note that when clients add values to these containers, we perform\n  type-checking in the case of repeated scalar fields, and we also set any\n  necessary \"has\" bits as a side-effect.\n\n  Args:\n    field: A FieldDescriptor for this field.\n    cls: The class we're constructing.\n  \"\"\"\n  proto_field_name = field.name\n  property_name = _PropertyName(proto_field_name)\n\n  def getter(self):\n    field_value = self._fields.get(field)\n    if field_value is None:\n      # Construct a new object to represent this field.\n      field_value = field._default_constructor(self)\n\n      # Atomically check if another thread has preempted us and, if not, swap\n      # in the new object we just created.  If someone has preempted us, we\n      # take that object and discard ours.\n      # WARNING:  We are relying on setdefault() being atomic.  This is true\n      #   in CPython but we haven't investigated others.  This warning appears\n      #   in several other locations in this file.\n      field_value = self._fields.setdefault(field, field_value)\n    return field_value\n  getter.__module__ = None\n  getter.__doc__ = 'Getter for %s.' % proto_field_name\n\n  # We define a setter just so we can throw an exception with a more\n  # helpful error message.\n  def setter(self, new_value):\n    raise AttributeError('Assignment not allowed to repeated field '\n                         '\"%s\" in protocol message object.' % proto_field_name)\n\n  doc = 'Magic attribute generated for \"%s\" proto field.' % proto_field_name\n  setattr(cls, property_name, property(getter, setter, doc=doc))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _AddPropertiesForNonRepeatedScalarField(field, cls):\n  proto_field_name = field.name\n  property_name = _PropertyName(proto_field_name)\n  type_checker = type_checkers.GetTypeChecker(field)\n  default_value = field.default_value\n  valid_values = set()\n  is_proto3 = field.containing_type.syntax == \"proto3\"\n\n  def getter(self):\n    # TODO(protobuf-team): This may be broken since there may not be\n    # default_value.  Combine with has_default_value somehow.\n    return self._fields.get(field, default_value)\n  getter.__module__ = None\n  getter.__doc__ = 'Getter for %s.' % proto_field_name\n\n  clear_when_set_to_default = is_proto3 and not field.containing_oneof\n\n  def field_setter(self, new_value):\n    # pylint: disable=protected-access\n    # Testing the value for truthiness captures all of the proto3 defaults\n    # (0, 0.0, enum 0, and False).\n    new_value = type_checker.CheckValue(new_value)\n    if clear_when_set_to_default and not new_value:\n      self._fields.pop(field, None)\n    else:\n      self._fields[field] = new_value\n    # Check _cached_byte_size_dirty inline to improve performance, since scalar\n    # setters are called frequently.\n    if not self._cached_byte_size_dirty:\n      self._Modified()\n\n  if field.containing_oneof:\n    def setter(self, new_value):\n      field_setter(self, new_value)\n      self._UpdateOneofState(field)\n  else:\n    setter = field_setter\n\n  setter.__module__ = None\n  setter.__doc__ = 'Setter for %s.' % proto_field_name\n\n  # Add a property to encapsulate the getter/setter.\n  doc = 'Magic attribute generated for \"%s\" proto field.' % proto_field_name\n  setattr(cls, property_name, property(getter, setter, doc=doc))", "response": "Adds a public property for a nonrepeated scalar protocol message field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding properties for all fields in this protocol message type.", "response": "def _AddPropertiesForExtensions(descriptor, cls):\n  \"\"\"Adds properties for all fields in this protocol message type.\"\"\"\n  extension_dict = descriptor.extensions_by_name\n  for extension_name, extension_field in extension_dict.items():\n    constant_name = extension_name.upper() + \"_FIELD_NUMBER\"\n    setattr(cls, constant_name, extension_field.number)\n\n  # TODO(amauryfa): Migrate all users of these attributes to functions like\n  #   pool.FindExtensionByNumber(descriptor).\n  if descriptor.file is not None:\n    # TODO(amauryfa): Use cls.MESSAGE_FACTORY.pool when available.\n    pool = descriptor.file.pool\n    cls._extensions_by_number = pool._extensions_by_number[descriptor]\n    cls._extensions_by_name = pool._extensions_by_name[descriptor]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true if the item is present in the list.", "response": "def _IsPresent(item):\n  \"\"\"Given a (FieldDescriptor, value) tuple from _fields, return true if the\n  value should be included in the list returned by ListFields().\"\"\"\n\n  if item[0].label == _FieldDescriptor.LABEL_REPEATED:\n    return bool(item[1])\n  elif item[0].cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n    return item[1]._is_present_in_parent\n  else:\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _AddListFieldsMethod(message_descriptor, cls):\n\n  def ListFields(self):\n    all_fields = [item for item in self._fields.items() if _IsPresent(item)]\n    all_fields.sort(key = lambda item: item[0].number)\n    return all_fields\n\n  cls.ListFields = ListFields", "response": "Add a ListFields method to the class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _AddHasFieldMethod(message_descriptor, cls):\n\n  is_proto3 = (message_descriptor.syntax == \"proto3\")\n  error_msg = _Proto3HasError if is_proto3 else _Proto2HasError\n\n  hassable_fields = {}\n  for field in message_descriptor.fields:\n    if field.label == _FieldDescriptor.LABEL_REPEATED:\n      continue\n    # For proto3, only submessages and fields inside a oneof have presence.\n    if (is_proto3 and field.cpp_type != _FieldDescriptor.CPPTYPE_MESSAGE and\n        not field.containing_oneof):\n      continue\n    hassable_fields[field.name] = field\n\n  if not is_proto3:\n    # Fields inside oneofs are never repeated (enforced by the compiler).\n    for oneof in message_descriptor.oneofs:\n      hassable_fields[oneof.name] = oneof\n\n  def HasField(self, field_name):\n    try:\n      field = hassable_fields[field_name]\n    except KeyError:\n      raise ValueError(error_msg % field_name)\n\n    if isinstance(field, descriptor_mod.OneofDescriptor):\n      try:\n        return HasField(self, self._oneofs[field].name)\n      except KeyError:\n        return False\n    else:\n      if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n        value = self._fields.get(field)\n        return value is not None and value._is_present_in_parent\n      else:\n        return field in self._fields\n\n  cls.HasField = HasField", "response": "Adds HasField method to cls."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _AddClearFieldMethod(message_descriptor, cls):\n  def ClearField(self, field_name):\n    try:\n      field = message_descriptor.fields_by_name[field_name]\n    except KeyError:\n      try:\n        field = message_descriptor.oneofs_by_name[field_name]\n        if field in self._oneofs:\n          field = self._oneofs[field]\n        else:\n          return\n      except KeyError:\n        raise ValueError('Protocol message %s() has no \"%s\" field.' %\n                         (message_descriptor.name, field_name))\n\n    if field in self._fields:\n      # To match the C++ implementation, we need to invalidate iterators\n      # for map fields when ClearField() happens.\n      if hasattr(self._fields[field], 'InvalidateIterators'):\n        self._fields[field].InvalidateIterators()\n\n      # Note:  If the field is a sub-message, its listener will still point\n      #   at us.  That's fine, because the worst than can happen is that it\n      #   will call _Modified() and invalidate our byte size.  Big deal.\n      del self._fields[field]\n\n      if self._oneofs.get(field.containing_oneof, None) is field:\n        del self._oneofs[field.containing_oneof]\n\n    # Always call _Modified() -- even if nothing was changed, this is\n    # a mutating method, and thus calling it should cause the field to become\n    # present in the parent message.\n    self._Modified()\n\n  cls.ClearField = ClearField", "response": "Add ClearField method to cls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd HasExtension method to the class.", "response": "def _AddHasExtensionMethod(cls):\n  \"\"\"Helper for _AddMessageMethods().\"\"\"\n  def HasExtension(self, extension_handle):\n    _VerifyExtensionHandle(self, extension_handle)\n    if extension_handle.label == _FieldDescriptor.LABEL_REPEATED:\n      raise KeyError('\"%s\" is repeated.' % extension_handle.full_name)\n\n    if extension_handle.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n      value = self._fields.get(extension_handle)\n      return value is not None and value._is_present_in_parent\n    else:\n      return extension_handle in self._fields\n  cls.HasExtension = HasExtension"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunpack Any message and returns the unpacked message.", "response": "def _InternalUnpackAny(msg):\n  \"\"\"Unpacks Any message and returns the unpacked message.\n\n  This internal method is different from public Any Unpack method which takes\n  the target message as argument. _InternalUnpackAny method does not have\n  target message type and need to find the message type in descriptor pool.\n\n  Args:\n    msg: An Any message to be unpacked.\n\n  Returns:\n    The unpacked message.\n  \"\"\"\n  # TODO(amauryfa): Don't use the factory of generated messages.\n  # To make Any work with custom factories, use the message factory of the\n  # parent message.\n  # pylint: disable=g-import-not-at-top\n  from google.protobuf import symbol_database\n  factory = symbol_database.Default()\n\n  type_url = msg.type_url\n\n  if not type_url:\n    return None\n\n  # TODO(haberman): For now we just strip the hostname.  Better logic will be\n  # required.\n  type_name = type_url.split('/')[-1]\n  descriptor = factory.pool.FindMessageTypeByName(type_name)\n\n  if descriptor is None:\n    return None\n\n  message_class = factory.GetPrototype(descriptor)\n  message = message_class()\n\n  message.ParseFromString(msg.value)\n  return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _BytesForNonRepeatedElement(value, field_number, field_type):\n  try:\n    fn = type_checkers.TYPE_TO_BYTE_SIZE_FN[field_type]\n    return fn(field_number, value)\n  except KeyError:\n    raise message_mod.EncodeError('Unrecognized field type: %d' % field_type)", "response": "Returns the number of bytes needed to serialize a non - repeated element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the ByteSize method to the class.", "response": "def _AddByteSizeMethod(message_descriptor, cls):\n  \"\"\"Helper for _AddMessageMethods().\"\"\"\n\n  def ByteSize(self):\n    if not self._cached_byte_size_dirty:\n      return self._cached_byte_size\n\n    size = 0\n    for field_descriptor, field_value in self.ListFields():\n      size += field_descriptor._sizer(field_value)\n\n    for tag_bytes, value_bytes in self._unknown_fields:\n      size += len(tag_bytes) + len(value_bytes)\n\n    self._cached_byte_size = size\n    self._cached_byte_size_dirty = False\n    self._listener_for_children.dirty = False\n    return size\n\n  cls.ByteSize = ByteSize"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _AddSerializeToStringMethod(message_descriptor, cls):\n\n  def SerializeToString(self):\n    # Check if the message has all of its required fields set.\n    errors = []\n    if not self.IsInitialized():\n      raise message_mod.EncodeError(\n          'Message %s is missing required fields: %s' % (\n          self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n    return self.SerializePartialToString()\n  cls.SerializeToString = SerializeToString", "response": "Adds SerializeToString method to the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _AddSerializePartialToStringMethod(message_descriptor, cls):\n\n  def SerializePartialToString(self):\n    out = BytesIO()\n    self._InternalSerialize(out.write)\n    return out.getvalue()\n  cls.SerializePartialToString = SerializePartialToString\n\n  def InternalSerialize(self, write_bytes):\n    for field_descriptor, field_value in self.ListFields():\n      field_descriptor._encoder(write_bytes, field_value)\n    for tag_bytes, value_bytes in self._unknown_fields:\n      write_bytes(tag_bytes)\n      write_bytes(value_bytes)\n  cls._InternalSerialize = InternalSerialize", "response": "Adds the SerializePartialToString method to the class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the IsInitialized and FindInitializationError methods to the protocol message class.", "response": "def _AddIsInitializedMethod(message_descriptor, cls):\n  \"\"\"Adds the IsInitialized and FindInitializationError methods to the\n  protocol message class.\"\"\"\n\n  required_fields = [field for field in message_descriptor.fields\n                           if field.label == _FieldDescriptor.LABEL_REQUIRED]\n\n  def IsInitialized(self, errors=None):\n    \"\"\"Checks if all required fields of a message are set.\n\n    Args:\n      errors:  A list which, if provided, will be populated with the field\n               paths of all missing required fields.\n\n    Returns:\n      True iff the specified message has all required fields set.\n    \"\"\"\n\n    # Performance is critical so we avoid HasField() and ListFields().\n\n    for field in required_fields:\n      if (field not in self._fields or\n          (field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE and\n           not self._fields[field]._is_present_in_parent)):\n        if errors is not None:\n          errors.extend(self.FindInitializationErrors())\n        return False\n\n    for field, value in list(self._fields.items()):  # dict can change size!\n      if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n        if field.label == _FieldDescriptor.LABEL_REPEATED:\n          if (field.message_type.has_options and\n              field.message_type.GetOptions().map_entry):\n            continue\n          for element in value:\n            if not element.IsInitialized():\n              if errors is not None:\n                errors.extend(self.FindInitializationErrors())\n              return False\n        elif value._is_present_in_parent and not value.IsInitialized():\n          if errors is not None:\n            errors.extend(self.FindInitializationErrors())\n          return False\n\n    return True\n\n  cls.IsInitialized = IsInitialized\n\n  def FindInitializationErrors(self):\n    \"\"\"Finds required fields which are not initialized.\n\n    Returns:\n      A list of strings.  Each string is a path to an uninitialized field from\n      the top-level message, e.g. \"foo.bar[5].baz\".\n    \"\"\"\n\n    errors = []  # simplify things\n\n    for field in required_fields:\n      if not self.HasField(field.name):\n        errors.append(field.name)\n\n    for field, value in self.ListFields():\n      if field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n        if field.is_extension:\n          name = \"(%s)\" % field.full_name\n        else:\n          name = field.name\n\n        if _IsMapField(field):\n          if _IsMessageMapField(field):\n            for key in value:\n              element = value[key]\n              prefix = \"%s[%s].\" % (name, key)\n              sub_errors = element.FindInitializationErrors()\n              errors += [prefix + error for error in sub_errors]\n          else:\n            # ScalarMaps can't have any initialization errors.\n            pass\n        elif field.label == _FieldDescriptor.LABEL_REPEATED:\n          for i in range(len(value)):\n            element = value[i]\n            prefix = \"%s[%d].\" % (name, i)\n            sub_errors = element.FindInitializationErrors()\n            errors += [prefix + error for error in sub_errors]\n        else:\n          prefix = name + \".\"\n          sub_errors = value.FindInitializationErrors()\n          errors += [prefix + error for error in sub_errors]\n\n    return errors\n\n  cls.FindInitializationErrors = FindInitializationErrors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _AddMessageMethods(message_descriptor, cls):\n  _AddListFieldsMethod(message_descriptor, cls)\n  _AddHasFieldMethod(message_descriptor, cls)\n  _AddClearFieldMethod(message_descriptor, cls)\n  if message_descriptor.is_extendable:\n    _AddClearExtensionMethod(cls)\n    _AddHasExtensionMethod(cls)\n  _AddEqualsMethod(message_descriptor, cls)\n  _AddStrMethod(message_descriptor, cls)\n  _AddReprMethod(message_descriptor, cls)\n  _AddUnicodeMethod(message_descriptor, cls)\n  _AddByteSizeMethod(message_descriptor, cls)\n  _AddSerializeToStringMethod(message_descriptor, cls)\n  _AddSerializePartialToStringMethod(message_descriptor, cls)\n  _AddMergeFromStringMethod(message_descriptor, cls)\n  _AddIsInitializedMethod(message_descriptor, cls)\n  _AddMergeFromMethod(cls)\n  _AddWhichOneofMethod(message_descriptor, cls)\n  _AddReduceMethod(cls)\n  # Adds methods which do not depend on cls.\n  cls.Clear = _Clear\n  cls.DiscardUnknownFields = _DiscardUnknownFields\n  cls._SetListener = _SetListener", "response": "Adds implementations of all Message methods to cls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding implementation of private helper methods to cls.", "response": "def _AddPrivateHelperMethods(message_descriptor, cls):\n  \"\"\"Adds implementation of private helper methods to cls.\"\"\"\n\n  def Modified(self):\n    \"\"\"Sets the _cached_byte_size_dirty bit to true,\n    and propagates this to our listener iff this was a state change.\n    \"\"\"\n\n    # Note:  Some callers check _cached_byte_size_dirty before calling\n    #   _Modified() as an extra optimization.  So, if this method is ever\n    #   changed such that it does stuff even when _cached_byte_size_dirty is\n    #   already true, the callers need to be updated.\n    if not self._cached_byte_size_dirty:\n      self._cached_byte_size_dirty = True\n      self._listener_for_children.dirty = True\n      self._is_present_in_parent = True\n      self._listener.Modified()\n\n  def _UpdateOneofState(self, field):\n    \"\"\"Sets field as the active field in its containing oneof.\n\n    Will also delete currently active field in the oneof, if it is different\n    from the argument. Does not mark the message as modified.\n    \"\"\"\n    other_field = self._oneofs.setdefault(field.containing_oneof, field)\n    if other_field is not field:\n      del self._fields[other_field]\n      self._oneofs[field.containing_oneof] = field\n\n  cls._Modified = Modified\n  cls.SetInParent = Modified\n  cls._UpdateOneofState = _UpdateOneofState"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Name(self, number):\n    if number in self._enum_type.values_by_number:\n      return self._enum_type.values_by_number[number].name\n    raise ValueError('Enum %s has no name defined for value %d' % (\n        self._enum_type.name, number))", "response": "Returns a string containing the name of an enum value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Value(self, name):\n    if name in self._enum_type.values_by_name:\n      return self._enum_type.values_by_name[name].number\n    raise ValueError('Enum %s has no value defined for name %s' % (\n        self._enum_type.name, name))", "response": "Returns the value coresponding to the given enum name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of the name value pairs of the enum.", "response": "def items(self):\n    \"\"\"Return a list of the (name, value) pairs of the enum.\n\n    These are returned in the order they were defined in the .proto file.\n    \"\"\"\n    return [(value_descriptor.name, value_descriptor.number)\n            for value_descriptor in self._enum_type.values]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading global singleton of tcmps lib handler.", "response": "def _load_tcmps_lib():\n    \"\"\"\n    Load global singleton of tcmps lib handler.\n\n    This function is used not used at the top level, so\n    that the shared library is loaded lazily only when needed.\n    \"\"\"\n    global _g_TCMPS_LIB\n    if _g_TCMPS_LIB is None:\n        # This library requires macOS 10.14 or above\n        if _mac_ver() < (10, 14):\n            return None\n\n        # The symbols defined in libtcmps are now exposed directly by\n        # libunity_shared. Eventually the object_detector and\n        # activity_classifier toolkits will use the same Python/C++ bridge as\n        # the other toolkits, and this usage of ctypes will go away.\n        file_dir = _os.path.dirname(__file__)\n        lib_path = _os.path.abspath(_os.path.join(file_dir, _os.pardir, 'libunity_shared.dylib'))\n        try:\n            _g_TCMPS_LIB = _ctypes.CDLL(lib_path, _ctypes.RTLD_LOCAL)\n        except OSError:\n            pass\n    return _g_TCMPS_LIB"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the environment has MPS backend support and a high - power metatermodel device is available.", "response": "def has_fast_mps_support():\n    \"\"\"\n    Returns True if the environment has MPS backend support\n    and a high-power (fast) device is available.\n    \"\"\"\n    lib = _load_tcmps_lib()\n    if lib is None:\n        return False\n\n    c_bool = _ctypes.c_bool()\n    ret = lib.TCMPSHasHighPowerMetalDevice(_ctypes.byref(c_bool))\n    return ret == 0 and c_bool.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mps_device_name():\n    lib = _load_tcmps_lib()\n    if lib is None:\n        return None\n\n    n = 256\n    c_name = (_ctypes.c_char * n)()\n    ret = lib.TCMPSMetalDeviceName(_ctypes.byref(c_name), _ctypes.c_int32(n))\n    if ret == 0:\n        return _decode_bytes_to_native_string(c_name.value)\n    else:\n        return None", "response": "Returns name of MPS device that will be used in the MPS virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mps_device_memory_limit():\n    lib = _load_tcmps_lib()\n    if lib is None:\n        return None\n\n    c_size = _ctypes.c_uint64()\n    ret = lib.TCMPSMetalDeviceMemoryLimit(_ctypes.byref(c_size))\n    return c_size.value if ret == 0 else None", "response": "Returns the memory size in bytes that can be effectively allocated on the MPS device that will be used."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies the shape from TCMPS as a new numpy ndarray.", "response": "def shape(self):\n        \"\"\"Copy the shape from TCMPS as a new numpy ndarray.\"\"\"\n\n        # Create C variables that will serve as out parameters for TCMPS.\n        shape_ptr = _ctypes.POINTER(_ctypes.c_size_t)()  # size_t* shape_ptr\n        dim = _ctypes.c_size_t()                         # size_t dim\n\n        # Obtain pointer into memory owned by the C++ object self.handle.\n        status_code = self._LIB.TCMPSGetFloatArrayShape(\n            self.handle, _ctypes.byref(shape_ptr), _ctypes.byref(dim))\n        assert status_code == 0, \"Error calling TCMPSGetFloatArrayShape\"\n\n        return _shape_tuple_from_ctypes(shape_ptr, dim)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asnumpy(self):\n\n        # Create C variables that will serve as out parameters for TCMPS.\n        data_ptr = _ctypes.POINTER(_ctypes.c_float)()    # float* data_ptr\n        shape_ptr = _ctypes.POINTER(_ctypes.c_size_t)()  # size_t* shape_ptr\n        dim = _ctypes.c_size_t()                         # size_t dim\n\n        # Obtain pointers into memory owned by the C++ object self.handle.\n        # Note that this may trigger synchronization with another thread\n        # producing the data.\n        status_code = self._LIB.TCMPSReadFloatArray(\n            self.handle, _ctypes.byref(data_ptr), _ctypes.byref(shape_ptr),\n            _ctypes.byref(dim))\n        assert status_code == 0, \"Error calling TCMPSReadFloatArray\"\n\n        return _numpy_array_from_ctypes(data_ptr, shape_ptr, dim)", "response": "Copy the data from TCMPS into a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the TCMPSTrainGraph on the specified input and label.", "response": "def train(self, input, label):\n        \"\"\"\n        Submits an input batch to the model. Returns a MpsFloatArray\n        representing the batch loss. Calling asnumpy() on this value will wait\n        for the batch to finish and yield the loss as a numpy array.\n        \"\"\"\n\n        assert self._mode == MpsGraphMode.Train\n        assert input.shape == self._ishape\n        assert label.shape == self._oshape\n\n        input_array = MpsFloatArray(input)\n        label_array = MpsFloatArray(label)\n        result_handle = _ctypes.c_void_p()\n        status_code = self._LIB.TCMPSTrainGraph(\n            self.handle, input_array.handle, label_array.handle,\n            _ctypes.byref(result_handle))\n\n        assert status_code == 0, \"Error calling TCMPSTrainGraph\"\n        assert result_handle, \"TCMPSTrainGraph unexpectedly returned NULL pointer\"\n\n        result = MpsFloatArray(result_handle)\n\n        # Output from training should be a one-dimensional array of loss values,\n        # one per example in the batch.\n        assert result.shape() == (self._oshape[0],)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, input):\n\n        assert self._mode == MpsGraphMode.Inference\n        assert input.shape == self._ishape\n\n        input_array = MpsFloatArray(input)\n        result_handle = _ctypes.c_void_p()\n        status_code = self._LIB.TCMPSPredictGraph(\n            self.handle, input_array.handle, _ctypes.byref(result_handle))\n\n        assert status_code == 0, \"Error calling TCMPSPredictGraph\"\n        assert result_handle, \"TCMPSPredictGraph unexpectedly returned NULL pointer\"\n\n        result = MpsFloatArray(result_handle)\n        assert result.shape() == self._oshape\n\n        return result", "response": "Predicts the model on the input batch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a train return gradient graph on the input batch followed by a backward pass. Returns a numpy array representing the output of the forward pass followed by a backward pass.", "response": "def train_return_grad(self, input, grad):\n        \"\"\"\n        Performs a forward pass from the input batch, followed by a backward\n        pass using the provided gradient (in place of a loss function). Returns\n        a MpsFloatArray representing the output (final gradient) of the backward\n        pass. Calling asnumpy() on this value will wait for the batch to finish\n        and yield the output as a numpy array.\n        \"\"\"\n\n        assert self._mode == MpsGraphMode.TrainReturnGrad\n        assert input.shape == self._ishape\n        assert grad.shape == self._oshape\n\n        input_array = MpsFloatArray(input)\n        grad_array = MpsFloatArray(grad)\n        result_handle = _ctypes.c_void_p()\n        status_code = self._LIB.TCMPSTrainGraph(\n            self.handle, input_array.handle, grad_array.handle,\n                _ctypes.byref(result_handle))\n\n        assert status_code == 0, \"Error calling TCMPSTrainReturnGradGraph\"\n        assert result_handle, \"TCMPSTrainReturnGradGraph unexpectedly returned NULL pointer\"\n\n        result = MpsFloatArray(result_handle)\n        assert result.shape() == self._ishape\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an SNS Message deserialises the message and runs the function with the args", "response": "def route_sns_task(event, context):\n    \"\"\"\n    Gets SNS Message, deserialises the message,\n    imports the function, calls the function with args\n    \"\"\"\n    record = event['Records'][0]\n    message = json.loads(\n            record['Sns']['Message']\n        )\n    return run_message(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a function defined by a message object with keys task_path args and kwargs used by lambda routing and returns the response.", "response": "def run_message(message):\n    \"\"\"\n    Runs a function defined by a message object with keys:\n    'task_path', 'args', and 'kwargs' used by lambda routing\n    and a 'command' in handler.py\n    \"\"\"\n    if message.get('capture_response', False):\n        DYNAMODB_CLIENT.put_item(\n            TableName=ASYNC_RESPONSE_TABLE,\n            Item={\n                'id': {'S': str(message['response_id'])},\n                'ttl': {'N': str(int(time.time()+600))},\n                'async_status': {'S': 'in progress'},\n                'async_response': {'S': str(json.dumps('N/A'))},\n            }\n        )\n\n    func = import_and_get_task(message['task_path'])\n    if hasattr(func, 'sync'):\n        response = func.sync(\n            *message['args'],\n            **message['kwargs']\n        )\n    else:\n        response = func(\n            *message['args'],\n            **message['kwargs']\n        )\n\n    if message.get('capture_response', False):\n        DYNAMODB_CLIENT.update_item(\n            TableName=ASYNC_RESPONSE_TABLE,\n            Key={'id': {'S': str(message['response_id'])}},\n            UpdateExpression=\"SET async_response = :r, async_status = :s\",\n            ExpressionAttributeValues={\n                ':r': {'S': str(json.dumps(response))},\n                ':s': {'S': 'complete'},\n            },\n        )\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(func, args=[], kwargs={}, service='lambda', capture_response=False,\n        remote_aws_lambda_function_name=None, remote_aws_region=None, **task_kwargs):\n    \"\"\"\n    Instead of decorating a function with @task, you can just run it directly.\n    If you were going to do func(*args, **kwargs), then you will call this:\n\n    import zappa.asynchronous.run\n    zappa.asynchronous.run(func, args, kwargs)\n\n    If you want to use SNS, then do:\n\n    zappa.asynchronous.run(func, args, kwargs, service='sns')\n\n    and other arguments are similar to @task\n    \"\"\"\n    lambda_function_name = remote_aws_lambda_function_name or os.environ.get('AWS_LAMBDA_FUNCTION_NAME')\n    aws_region = remote_aws_region or os.environ.get('AWS_REGION')\n\n    task_path = get_func_task_path(func)\n    return ASYNC_CLASSES[service](lambda_function_name=lambda_function_name,\n                                  aws_region=aws_region,\n                                  capture_response=capture_response,\n                                  **task_kwargs).send(task_path, args, kwargs)", "response": "A function that runs a function in a synchronous manner."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a modular path to a function import that module and return that function.", "response": "def import_and_get_task(task_path):\n    \"\"\"\n    Given a modular path to a function, import that module\n    and return the function.\n    \"\"\"\n    module, function = task_path.rsplit('.', 1)\n    app_module = importlib.import_module(module)\n    app_function = getattr(app_module, function)\n    return app_function"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the modular task path for a function.", "response": "def get_func_task_path(func):\n    \"\"\"\n    Format the modular task path for a function via inspection.\n    \"\"\"\n    module_path = inspect.getmodule(func).__name__\n    task_path = '{module_path}.{func_name}'.format(\n                                        module_path=module_path,\n                                        func_name=func.__name__\n                                    )\n    return task_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the response from the async table", "response": "def get_async_response(response_id):\n    \"\"\"\n    Get the response from the async table\n    \"\"\"\n    response = DYNAMODB_CLIENT.get_item(\n        TableName=ASYNC_RESPONSE_TABLE,\n        Key={'id': {'S': str(response_id)}}\n    )\n    if 'Item' not in response:\n        return None\n\n    return {\n        'status': response['Item']['async_status']['S'],\n        'response': json.loads(response['Item']['async_response']['S']),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a message to the master.", "response": "def send(self, task_path, args, kwargs):\n        \"\"\"\n        Create the message object and pass it to the actual sender.\n        \"\"\"\n        message = {\n                'task_path': task_path,\n                'capture_response': self.capture_response,\n                'response_id': self.response_id,\n                'args': args,\n                'kwargs': kwargs\n            }\n        self._send(message)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send(self, message):\n        message['command'] = 'zappa.asynchronous.route_lambda_task'\n        payload = json.dumps(message).encode('utf-8')\n        if len(payload) > LAMBDA_ASYNC_PAYLOAD_LIMIT: # pragma: no cover\n            raise AsyncException(\"Payload too large for async Lambda call\")\n        self.response = self.client.invoke(\n                                    FunctionName=self.lambda_function_name,\n                                    InvocationType='Event', #makes the call async\n                                    Payload=payload\n                                )\n        self.sent = (self.response.get('StatusCode', 0) == 202)", "response": "Send a message to the Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a message to this topic.", "response": "def _send(self, message):\n        \"\"\"\n        Given a message, publish to this topic.\n        \"\"\"\n        message['command'] = 'zappa.asynchronous.route_sns_task'\n        payload = json.dumps(message).encode('utf-8')\n        if len(payload) > LAMBDA_ASYNC_PAYLOAD_LIMIT: # pragma: no cover\n            raise AsyncException(\"Payload too large for SNS\")\n        self.response = self.client.publish(\n                                TargetArn=self.arn,\n                                Message=payload\n                            )\n        self.sent = self.response.get('MessageId')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse an S3 URL and returns bucket and file.", "response": "def parse_s3_url(url):\n    \"\"\"\n    Parses S3 URL.\n\n    Returns bucket (domain) and file (full path).\n    \"\"\"\n    bucket = ''\n    path = ''\n    if url:\n        result = urlparse(url)\n        bucket = result.netloc\n        path = result.path.strip('/')\n    return bucket, path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a str returns an int timestamp.", "response": "def string_to_timestamp(timestring):\n    \"\"\"\n    Accepts a str, returns an int timestamp.\n    \"\"\"\n\n    ts = None\n\n    # Uses an extended version of Go's duration string.\n    try:\n        delta = durationpy.from_str(timestring);\n        past = datetime.datetime.utcnow() - delta\n        ts = calendar.timegm(past.timetuple())\n        return ts\n    except Exception as e:\n        pass\n\n    if ts:\n        return ts\n    # else:\n    #     print(\"Unable to parse timestring.\")\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an event_source dictionary create the object and add the event source.", "response": "def add_event_source(event_source, lambda_arn, target_function, boto_session, dry=False):\n    \"\"\"\n    Given an event_source dictionary, create the object and add the event source.\n    \"\"\"\n\n    event_source_obj, ctx, funk = get_event_source(event_source, lambda_arn, target_function, boto_session, dry=False)\n    # TODO: Detect changes in config and refine exists algorithm\n    if not dry:\n        if not event_source_obj.status(funk):\n            event_source_obj.add(funk)\n            return 'successful' if event_source_obj.status(funk) else 'failed'\n        else:\n            return 'exists'\n\n    return 'dryrun'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_event_source(event_source, lambda_arn, target_function, boto_session, dry=False):\n\n    event_source_obj, ctx, funk = get_event_source(event_source, lambda_arn, target_function, boto_session, dry=False)\n\n    # This is slightly dirty, but necessary for using Kappa this way.\n    funk.arn = lambda_arn\n    if not dry:\n        rule_response = event_source_obj.remove(funk)\n        return rule_response\n    else:\n        return event_source_obj", "response": "Given an event_source dictionary create the object and remove the event source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an event source dictionary create the object and get the event source status.", "response": "def get_event_source_status(event_source, lambda_arn, target_function, boto_session, dry=False):\n    \"\"\"\n    Given an event_source dictionary, create the object and get the event source status.\n    \"\"\"\n\n    event_source_obj, ctx, funk = get_event_source(event_source, lambda_arn, target_function, boto_session, dry=False)\n    return event_source_obj.status(funk)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a newer version of Zappa is available.", "response": "def check_new_version_available(this_version):\n    \"\"\"\n    Checks if a newer version of Zappa is available.\n\n    Returns True is updateable, else False.\n\n    \"\"\"\n    import requests\n\n    pypi_url = 'https://pypi.python.org/pypi/Zappa/json'\n    resp = requests.get(pypi_url, timeout=1.5)\n    top_version = resp.json()['info']['version']\n\n    return this_version != top_version"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_name(name, maxlen=80):\n    if not isinstance(name, basestring):\n        msg = \"Name must be of type string\"\n        raise InvalidAwsLambdaName(msg)\n    if len(name) > maxlen:\n        msg = \"Name is longer than {maxlen} characters.\"\n        raise InvalidAwsLambdaName(msg.format(maxlen=maxlen))\n    if len(name) == 0:\n        msg = \"Name must not be empty string.\"\n        raise InvalidAwsLambdaName(msg)\n    if not re.match(\"^[a-zA-Z0-9-_]+$\", name):\n        msg = \"Name can only contain characters from a-z, A-Z, 0-9, _ and -\"\n        raise InvalidAwsLambdaName(msg)\n    return name", "response": "Validate the name for AWS Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the folder contains. py or. pyc files and returns True if it contains. py or. pyc files.", "response": "def contains_python_files_or_subdirs(folder):\n    \"\"\"\n    Checks (recursively) if the directory contains .py or .pyc files\n    \"\"\"\n    for root, dirs, files in os.walk(folder):\n        if [filename for filename in files if filename.endswith('.py') or filename.endswith('.pyc')]:\n            return True\n\n        for d in dirs:\n            for _, subdirs, subfiles in os.walk(d):\n                if [filename for filename in subfiles if filename.endswith('.py') or filename.endswith('.pyc')]:\n                    return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conflicts_with_a_neighbouring_module(directory_path):\n    parent_dir_path, current_dir_name = os.path.split(os.path.normpath(directory_path))\n    neighbours = os.listdir(parent_dir_path)\n    conflicting_neighbour_filename = current_dir_name+'.py'\n    return conflicting_neighbour_filename in neighbours", "response": "Checks if a directory lies in the same directory as a. py file with the same name as a. py file with the same name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid_bucket_name(name):\n    # Bucket names must be at least 3 and no more than 63 characters long.\n    if (len(name) < 3 or len(name) > 63):\n        return False\n    # Bucket names must not contain uppercase characters or underscores.\n    if (any(x.isupper() for x in name)):\n        return False\n    if \"_\" in name:\n        return False\n    # Bucket names must start with a lowercase letter or number.\n    if not (name[0].islower() or name[0].isdigit()):\n        return False\n    # Bucket names must be a series of one or more labels. Adjacent labels are separated by a single period (.).\n    for label in name.split(\".\"):\n        # Each label must start and end with a lowercase letter or a number.\n        if len(label) < 1:\n            return False\n        if not (label[0].islower() or label[0].isdigit()):\n            return False\n        if not (label[-1].islower() or label[-1].isdigit()):\n            return False\n    # Bucket names must not be formatted as an IP address (for example, 192.168.5.4).\n    looks_like_IP = True\n    for label in name.split(\".\"):\n        if not label.isdigit():\n            looks_like_IP = False\n            break\n    if looks_like_IP:\n        return False\n\n    return True", "response": "Checks if an S3 bucket name is valid according to the S3 bucket naming rules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging the values of headers and multiValueHeaders into a single dict.", "response": "def merge_headers(event):\n    \"\"\"\n    Merge the values of headers and multiValueHeaders into a single dict.\n    Opens up support for multivalue headers via API Gateway and ALB.\n    See: https://github.com/Miserlou/Zappa/pull/1756\n    \"\"\"\n    headers = event.get('headers') or {}\n    multi_headers = (event.get('multiValueHeaders') or {}).copy()\n    for h in set(headers.keys()):\n        if h not in multi_headers:\n            multi_headers[h] = [headers[h]]\n    for h in multi_headers.keys():\n        multi_headers[h] = ', '.join(multi_headers[h])\n    return multi_headers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_wsgi_request(event_info,\n                        server_name='zappa',\n                        script_name=None,\n                        trailing_slash=True,\n                        binary_support=False,\n                        base_path=None,\n                        context_header_mappings={},\n                        ):\n        \"\"\"\n        Given some event_info via API Gateway,\n        create and return a valid WSGI request environ.\n        \"\"\"\n        method = event_info['httpMethod']\n        headers = merge_headers(event_info) or {} # Allow for the AGW console 'Test' button to work (Pull #735)\n\n        \"\"\"\n        API Gateway and ALB both started allowing for multi-value querystring\n        params in Nov. 2018. If there aren't multi-value params present, then\n        it acts identically to 'queryStringParameters', so we can use it as a\n        drop-in replacement.\n\n        The one caveat here is that ALB will only include _one_ of\n        queryStringParameters _or_ multiValueQueryStringParameters, which means\n        we have to check for the existence of one and then fall back to the\n        other.\n        \"\"\"\n        if 'multiValueQueryStringParameters' in event_info:\n            query = event_info['multiValueQueryStringParameters']\n            query_string = urlencode(query, doseq=True) if query else ''\n        else:\n            query = event_info.get('queryStringParameters', {})\n            query_string = urlencode(query) if query else ''\n\n        if context_header_mappings:\n            for key, value in context_header_mappings.items():\n                parts = value.split('.')\n                header_val = event_info['requestContext']\n                for part in parts:\n                    if part not in header_val:\n                        header_val = None\n                        break\n                    else:\n                        header_val = header_val[part]\n                if header_val is not None:\n                    headers[key] = header_val\n\n        # Extract remote user from context if Authorizer is enabled\n        remote_user = None\n        if event_info['requestContext'].get('authorizer'):\n            remote_user = event_info['requestContext']['authorizer'].get('principalId')\n        elif event_info['requestContext'].get('identity'):\n            remote_user = event_info['requestContext']['identity'].get('userArn')\n\n        # Related:  https://github.com/Miserlou/Zappa/issues/677\n        #           https://github.com/Miserlou/Zappa/issues/683\n        #           https://github.com/Miserlou/Zappa/issues/696\n        #           https://github.com/Miserlou/Zappa/issues/836\n        #           https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Summary_table\n        if binary_support and (method in BINARY_METHODS):\n            if event_info.get('isBase64Encoded', False):\n                encoded_body = event_info['body']\n                body = base64.b64decode(encoded_body)\n            else:\n                body = event_info['body']\n                if isinstance(body, six.string_types):\n                    body = body.encode(\"utf-8\")\n\n        else:\n            body = event_info['body']\n            if isinstance(body, six.string_types):\n                body = body.encode(\"utf-8\")\n\n        # Make header names canonical, e.g. content-type => Content-Type\n        # https://github.com/Miserlou/Zappa/issues/1188\n        headers = titlecase_keys(headers)\n\n        path = urls.url_unquote(event_info['path'])\n        if base_path:\n            script_name = '/' + base_path\n\n            if path.startswith(script_name):\n                path = path[len(script_name):]\n\n        x_forwarded_for = headers.get('X-Forwarded-For', '')\n        if ',' in x_forwarded_for:\n            # The last one is the cloudfront proxy ip. The second to last is the real client ip.\n            # Everything else is user supplied and untrustworthy.\n            remote_addr = x_forwarded_for.split(', ')[-2]\n        else:\n            remote_addr = '127.0.0.1'\n\n        environ = {\n            'PATH_INFO': get_wsgi_string(path),\n            'QUERY_STRING': get_wsgi_string(query_string),\n            'REMOTE_ADDR': remote_addr,\n            'REQUEST_METHOD': method,\n            'SCRIPT_NAME': get_wsgi_string(str(script_name)) if script_name else '',\n            'SERVER_NAME': str(server_name),\n            'SERVER_PORT': headers.get('X-Forwarded-Port', '80'),\n            'SERVER_PROTOCOL': str('HTTP/1.1'),\n            'wsgi.version': (1, 0),\n            'wsgi.url_scheme': headers.get('X-Forwarded-Proto', 'http'),\n            'wsgi.input': body,\n            'wsgi.errors': stderr,\n            'wsgi.multiprocess': False,\n            'wsgi.multithread': False,\n            'wsgi.run_once': False,\n        }\n\n        # Input processing\n        if method in [\"POST\", \"PUT\", \"PATCH\", \"DELETE\"]:\n            if 'Content-Type' in headers:\n                environ['CONTENT_TYPE'] = headers['Content-Type']\n\n            # This must be Bytes or None\n            environ['wsgi.input'] = six.BytesIO(body)\n            if body:\n                environ['CONTENT_LENGTH'] = str(len(body))\n            else:\n                environ['CONTENT_LENGTH'] = '0'\n\n        for header in headers:\n            wsgi_name = \"HTTP_\" + header.upper().replace('-', '_')\n            environ[wsgi_name] = str(headers[header])\n\n        if script_name:\n            environ['SCRIPT_NAME'] = script_name\n            path_info = environ['PATH_INFO']\n\n            if script_name in path_info:\n                environ['PATH_INFO'].replace(script_name, '')\n\n        if remote_user:\n            environ['REMOTE_USER'] = remote_user\n\n        if event_info['requestContext'].get('authorizer'):\n            environ['API_GATEWAY_AUTHORIZER'] = event_info['requestContext']['authorizer']\n\n        return environ", "response": "Given some event_info create and return a WSGI request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog this event in Common Log Format.", "response": "def common_log(environ, response, response_time=None):\n    \"\"\"\n    Given the WSGI environ and the response,\n    log this event in Common Log Format.\n\n    \"\"\"\n\n    logger = logging.getLogger()\n\n    if response_time:\n        formatter = ApacheFormatter(with_response_time=True)\n        try:\n            log_entry = formatter(response.status_code, environ,\n                                  len(response.content), rt_us=response_time)\n        except TypeError:\n            # Upstream introduced a very annoying breaking change on the rt_ms/rt_us kwarg.\n            log_entry = formatter(response.status_code, environ,\n                                  len(response.content), rt_ms=response_time)\n    else:\n        formatter = ApacheFormatter(with_response_time=False)\n        log_entry = formatter(response.status_code, environ,\n                              len(response.content))\n\n    logger.info(log_entry)\n\n    return log_entry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the remote project archive from S3 and adds it to path", "response": "def load_remote_project_archive(self, project_zip_path):\n        \"\"\"\n        Puts the project files from S3 in /tmp and adds to path\n        \"\"\"\n        project_folder = '/tmp/{0!s}'.format(self.settings.PROJECT_NAME)\n        if not os.path.isdir(project_folder):\n            # The project folder doesn't exist in this cold lambda, get it from S3\n            if not self.session:\n                boto_session = boto3.Session()\n            else:\n                boto_session = self.session\n\n            # Download zip file from S3\n            remote_bucket, remote_file = parse_s3_url(project_zip_path)\n            s3 = boto_session.resource('s3')\n            archive_on_s3 = s3.Object(remote_bucket, remote_file).get()\n\n            with tarfile.open(fileobj=archive_on_s3['Body'], mode=\"r|gz\") as t:\n                t.extractall(project_folder)\n\n        # Add to project path\n        sys.path.insert(0, project_folder)\n\n        # Change working directory to project folder\n        # Related: https://github.com/Miserlou/Zappa/issues/702\n        os.chdir(project_folder)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_remote_settings(self, remote_bucket, remote_file):\n        if not self.session:\n            boto_session = boto3.Session()\n        else:\n            boto_session = self.session\n\n        s3 = boto_session.resource('s3')\n        try:\n            remote_env_object = s3.Object(remote_bucket, remote_file).get()\n        except Exception as e:  # pragma: no cover\n            # catch everything aws might decide to raise\n            print('Could not load remote settings file.', e)\n            return\n\n        try:\n            content = remote_env_object['Body'].read()\n        except Exception as e:  # pragma: no cover\n            # catch everything aws might decide to raise\n            print('Exception while reading remote settings file.', e)\n            return\n\n        try:\n            settings_dict = json.loads(content)\n        except (ValueError, TypeError):  # pragma: no cover\n            print('Failed to parse remote settings!')\n            return\n\n        # add each key-value to environment - overwrites existing keys!\n        for key, value in settings_dict.items():\n            if self.settings.LOG_LEVEL == \"DEBUG\":\n                print('Adding {} -> {} to environment'.format(\n                    key,\n                    value\n                ))\n            # Environment variable keys can't be Unicode\n            # https://github.com/Miserlou/Zappa/issues/604\n            try:\n                os.environ[str(key)] = value\n            except Exception:\n                if self.settings.LOG_LEVEL == \"DEBUG\":\n                    print(\"Environment variable keys must be non-unicode!\")", "response": "Attempts to read a file from s3 containing a flat json object and adds each key - value pair as environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a modular path to a function import that module and return the function.", "response": "def import_module_and_get_function(whole_function):\n        \"\"\"\n        Given a modular path to a function, import that module\n        and return the function.\n        \"\"\"\n        module, function = whole_function.rsplit('.', 1)\n        app_module = importlib.import_module(module)\n        app_function = getattr(app_module, function)\n        return app_function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a function and event context detect signature and execute return any result.", "response": "def run_function(app_function, event, context):\n        \"\"\"\n        Given a function and event context,\n        detect signature and execute, returning any result.\n        \"\"\"\n        # getargspec does not support python 3 method with type hints\n        # Related issue: https://github.com/Miserlou/Zappa/issues/1452\n        if hasattr(inspect, \"getfullargspec\"):  # Python 3\n            args, varargs, keywords, defaults, _, _, _ = inspect.getfullargspec(app_function)\n        else:  # Python 2\n            args, varargs, keywords, defaults = inspect.getargspec(app_function)\n        num_args = len(args)\n        if num_args == 0:\n            result = app_function(event, context) if varargs else app_function()\n        elif num_args == 1:\n            result = app_function(event, context) if varargs else app_function(event)\n        elif num_args == 2:\n            result = app_function(event, context)\n        else:\n            raise RuntimeError(\"Function signature is invalid. Expected a function that accepts at most \"\n                               \"2 arguments or varargs.\")\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_function_for_aws_event(self, record):\n        if 's3' in record:\n            if ':' in record['s3']['configurationId']:\n                return record['s3']['configurationId'].split(':')[-1]\n\n        arn = None\n        if 'Sns' in record:\n            try:\n                message = json.loads(record['Sns']['Message'])\n                if message.get('command'):\n                    return message['command']\n            except ValueError:\n                pass\n            arn = record['Sns'].get('TopicArn')\n        elif 'dynamodb' in record or 'kinesis' in record:\n            arn = record.get('eventSourceARN')\n        elif 'eventSource' in record and record.get('eventSource') == 'aws:sqs':\n            arn = record.get('eventSourceARN')\n        elif 's3' in record:\n            arn = record['s3']['bucket']['arn']\n\n        if arn:\n            return self.settings.AWS_EVENT_MAPPING.get(arn)\n\n        return None", "response": "Get the associated function to execute for a triggered AWS event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_function_from_bot_intent_trigger(self, event):\n        intent = event.get('currentIntent')\n        if intent:\n            intent = intent.get('name')\n            if intent:\n                return self.settings.AWS_BOT_EVENT_MAPPING.get(\n                    \"{}:{}\".format(intent, event.get('invocationSource'))\n                )", "response": "Returns the function that is configured for the given event build ARN and the configured function that is configured for the given bot intent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the associated function to execute for a cognito trigger", "response": "def get_function_for_cognito_trigger(self, trigger):\n        \"\"\"\n        Get the associated function to execute for a cognito trigger\n        \"\"\"\n        print(\"get_function_for_cognito_trigger\", self.settings.COGNITO_TRIGGER_MAPPING, trigger, self.settings.COGNITO_TRIGGER_MAPPING.get(trigger))\n        return self.settings.COGNITO_TRIGGER_MAPPING.get(trigger)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the incoming token", "response": "def lambda_handler(event, context):\n    print(\"Client token: \" + event['authorizationToken'])\n    print(\"Method ARN: \" + event['methodArn'])\n    \"\"\"validate the incoming token\"\"\"\n    \"\"\"and produce the principal user identifier associated with the token\"\"\"\n\n    \"\"\"this could be accomplished in a number of ways:\"\"\"\n    \"\"\"1. Call out to OAuth provider\"\"\"\n    \"\"\"2. Decode a JWT token inline\"\"\"\n    \"\"\"3. Lookup in a self-managed DB\"\"\"\n    principalId = \"user|a1b2c3d4\"\n\n    \"\"\"you can send a 401 Unauthorized response to the client by failing like so:\"\"\"\n    \"\"\"raise Exception('Unauthorized')\"\"\"\n\n    \"\"\"if the token is valid, a policy must be generated which will allow or deny access to the client\"\"\"\n\n    \"\"\"if access is denied, the client will receive a 403 Access Denied response\"\"\"\n    \"\"\"if access is allowed, API Gateway will proceed with the backend integration configured on the method that was called\"\"\"\n\n    \"\"\"this function must generate a policy that is associated with the recognized principal user identifier.\"\"\"\n    \"\"\"depending on your use case, you might store policies in a DB, or generate them on the fly\"\"\"\n\n    \"\"\"keep in mind, the policy is cached for 5 minutes by default (TTL is configurable in the authorizer)\"\"\"\n    \"\"\"and will apply to subsequent calls to any method/resource in the RestApi\"\"\"\n    \"\"\"made with the same token\"\"\"\n\n    \"\"\"the example policy below denies access to all resources in the RestApi\"\"\"\n    tmp = event['methodArn'].split(':')\n    apiGatewayArnTmp = tmp[5].split('/')\n    awsAccountId = tmp[4]\n\n    policy = AuthPolicy(principalId, awsAccountId)\n    policy.restApiId = apiGatewayArnTmp[0]\n    policy.region = tmp[3]\n    policy.stage = apiGatewayArnTmp[1]\n\n    # Blueprint denies all methods by default\n    # policy.denyAllMethods()\n\n    # Example allows all methods\n    policy.allowAllMethods()\n\n    \"\"\"policy.allowMethod(HttpVerb.GET, \"/pets/*\")\"\"\"\n\n    \"\"\"finally, build the policy and exit the function using return\"\"\"\n    return policy.build()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _addMethod(self, effect, verb, resource, conditions):\n        if verb != \"*\" and not hasattr(HttpVerb, verb):\n            raise NameError(\"Invalid HTTP verb \" + verb + \". Allowed verbs in HttpVerb class\")\n        resourcePattern = re.compile(self.pathRegex)\n        if not resourcePattern.match(resource):\n            raise NameError(\"Invalid resource path: \" + resource + \". Path should match \" + self.pathRegex)\n\n        if resource[:1] == \"/\":\n            resource = resource[1:]\n\n        resourceArn = (\"arn:aws:execute-api:\" +\n            self.region + \":\" +\n            self.awsAccountId + \":\" +\n            self.restApiId + \"/\" +\n            self.stage + \"/\" +\n            verb + \"/\" +\n            resource)\n\n        if effect.lower() == \"allow\":\n            self.allowMethods.append({\n                'resourceArn' : resourceArn,\n                'conditions' : conditions\n            })\n        elif effect.lower() == \"deny\":\n            self.denyMethods.append({\n                'resourceArn' : resourceArn,\n                'conditions' : conditions\n            })", "response": "Adds a method to the internal list of allowed or denied methods. Each object in\n        is added to the internal list of allowed or denied methods. Each object in\n        is added to the internal list of allowed or denied methods. The condition statement can be null."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an API Gateway method with the given verb + resource path and add a condition for the policy statement.", "response": "def allowMethodWithConditions(self, verb, resource, conditions):\n        \"\"\"Adds an API Gateway method (Http verb + Resource path) to the list of allowed\n        methods and includes a condition for the policy statement. More on AWS policy\n        conditions here: http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements.html#Condition\"\"\"\n        self._addMethod(\"Allow\", verb, resource, conditions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an API Gateway method to the list of denied methods and includes a condition for the policy statement.", "response": "def denyMethodWithConditions(self, verb, resource, conditions):\n        \"\"\"Adds an API Gateway method (Http verb + Resource path) to the list of denied\n        methods and includes a condition for the policy statement. More on AWS policy\n        conditions here: http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements.html#Condition\"\"\"\n        self._addMethod(\"Deny\", verb, resource, conditions)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build(self):\n        if ((self.allowMethods is None or len(self.allowMethods) == 0) and\n            (self.denyMethods is None or len(self.denyMethods) == 0)):\n            raise NameError(\"No statements defined for the policy\")\n\n        policy = {\n            'principalId' : self.principalId,\n            'policyDocument' : {\n                'Version' : self.version,\n                'Statement' : []\n            }\n        }\n\n        policy['policyDocument']['Statement'].extend(self._getStatementForEffect(\"Allow\", self.allowMethods))\n        policy['policyDocument']['Statement'].extend(self._getStatementForEffect(\"Deny\", self.denyMethods))\n\n        return policy", "response": "Builds the policy document based on the internal lists of allowed and denied conditions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nallow for custom endpoint urls for non - AWS deployments", "response": "def configure_boto_session_method_kwargs(self, service, kw):\n        \"\"\"Allow for custom endpoint urls for non-AWS (testing and bootleg cloud) deployments\"\"\"\n        if service in self.endpoint_urls and not 'endpoint_url' in kw:\n            kw['endpoint_url'] = self.endpoint_urls[service]\n        return kw"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef boto_client(self, service, *args, **kwargs):\n        return self.boto_session.client(service, *args, **self.configure_boto_session_method_kwargs(service, kwargs))", "response": "A wrapper to apply configuration options to boto clients"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef boto_resource(self, service, *args, **kwargs):\n        return self.boto_session.resource(service, *args, **self.configure_boto_session_method_kwargs(service, kwargs))", "response": "A wrapper to apply configuration options to boto resources"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cache_param(self, value):\n        '''Returns a troposphere Ref to a value cached as a parameter.'''\n\n        if value not in self.cf_parameters:\n            keyname = chr(ord('A') + len(self.cf_parameters))\n            param = self.cf_template.add_parameter(troposphere.Parameter(\n                keyname, Type=\"String\", Default=value, tags=self.tags\n            ))\n\n            self.cf_parameters[value] = param\n\n        return troposphere.Ref(self.cf_parameters[value])", "response": "Returns a troposphere Ref to a value cached as a parameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of required packages. Recursive.", "response": "def get_deps_list(self, pkg_name, installed_distros=None):\n        \"\"\"\n        For a given package, returns a list of required packages. Recursive.\n        \"\"\"\n        # https://github.com/Miserlou/Zappa/issues/1478.  Using `pkg_resources`\n        # instead of `pip` is the recommended approach.  The usage is nearly\n        # identical.\n        import pkg_resources\n        deps = []\n        if not installed_distros:\n            installed_distros = pkg_resources.WorkingSet()\n        for package in installed_distros:\n            if package.project_name.lower() == pkg_name.lower():\n                deps = [(package.project_name, package.version)]\n                for req in package.requires():\n                    deps += self.get_deps_list(pkg_name=req.project_name, installed_distros=installed_distros)\n        return list(set(deps))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_handler_venv(self):\n        import subprocess\n\n        # We will need the currenv venv to pull Zappa from\n        current_venv = self.get_current_venv()\n\n        # Make a new folder for the handler packages\n        ve_path = os.path.join(os.getcwd(), 'handler_venv')\n\n        if os.sys.platform == 'win32':\n            current_site_packages_dir = os.path.join(current_venv, 'Lib', 'site-packages')\n            venv_site_packages_dir = os.path.join(ve_path, 'Lib', 'site-packages')\n        else:\n            current_site_packages_dir = os.path.join(current_venv, 'lib', get_venv_from_python_version(), 'site-packages')\n            venv_site_packages_dir = os.path.join(ve_path, 'lib', get_venv_from_python_version(), 'site-packages')\n\n        if not os.path.isdir(venv_site_packages_dir):\n            os.makedirs(venv_site_packages_dir)\n\n        # Copy zappa* to the new virtualenv\n        zappa_things = [z for z in os.listdir(current_site_packages_dir) if z.lower()[:5] == 'zappa']\n        for z in zappa_things:\n            copytree(os.path.join(current_site_packages_dir, z), os.path.join(venv_site_packages_dir, z))\n\n        # Use pip to download zappa's dependencies. Copying from current venv causes issues with things like PyYAML that installs as yaml\n        zappa_deps = self.get_deps_list('zappa')\n        pkg_list = ['{0!s}=={1!s}'.format(dep, version) for dep, version in zappa_deps]\n\n        # Need to manually add setuptools\n        pkg_list.append('setuptools')\n        command = [\"pip\", \"install\", \"--quiet\", \"--target\", venv_site_packages_dir] + pkg_list\n\n        # This is the recommended method for installing packages if you don't\n        # to depend on `setuptools`\n        # https://github.com/pypa/pip/issues/5240#issuecomment-381662679\n        pip_process = subprocess.Popen(command, stdout=subprocess.PIPE)\n        # Using communicate() to avoid deadlocks\n        pip_process.communicate()\n        pip_return_code = pip_process.returncode\n\n        if pip_return_code:\n          raise EnvironmentError(\"Pypi lookup failed\")\n\n        return ve_path", "response": "Takes the installed zappa and brings it into a fresh virtualenv - like folder. All dependencies are downloaded."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_venv():\n        if 'VIRTUAL_ENV' in os.environ:\n            venv = os.environ['VIRTUAL_ENV']\n        elif os.path.exists('.python-version'):  # pragma: no cover\n            try:\n                subprocess.check_output(['pyenv', 'help'], stderr=subprocess.STDOUT)\n            except OSError:\n                print(\"This directory seems to have pyenv's local venv, \"\n                      \"but pyenv executable was not found.\")\n            with open('.python-version', 'r') as f:\n                # minor fix in how .python-version is read\n                # Related: https://github.com/Miserlou/Zappa/issues/921\n                env_name = f.readline().strip()\n            bin_path = subprocess.check_output(['pyenv', 'which', 'python']).decode('utf-8')\n            venv = bin_path[:bin_path.rfind(env_name)] + env_name\n        else:  # pragma: no cover\n            return None\n        return venv", "response": "Returns the path to the current virtualenv"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Lambda - ready zip file of the current virtual environment and working directory.", "response": "def create_lambda_zip(  self,\n                            prefix='lambda_package',\n                            handler_file=None,\n                            slim_handler=False,\n                            minify=True,\n                            exclude=None,\n                            use_precompiled_packages=True,\n                            include=None,\n                            venv=None,\n                            output=None,\n                            disable_progress=False,\n                            archive_format='zip'\n                        ):\n        \"\"\"\n        Create a Lambda-ready zip file of the current virtualenvironment and working directory.\n\n        Returns path to that file.\n\n        \"\"\"\n        # Validate archive_format\n        if archive_format not in ['zip', 'tarball']:\n            raise KeyError(\"The archive format to create a lambda package must be zip or tarball\")\n\n        # Pip is a weird package.\n        # Calling this function in some environments without this can cause.. funkiness.\n        import pip\n\n        if not venv:\n            venv = self.get_current_venv()\n\n        build_time = str(int(time.time()))\n        cwd = os.getcwd()\n        if not output:\n            if archive_format == 'zip':\n                archive_fname = prefix + '-' + build_time + '.zip'\n            elif archive_format == 'tarball':\n                archive_fname = prefix + '-' + build_time + '.tar.gz'\n        else:\n            archive_fname = output\n        archive_path = os.path.join(cwd, archive_fname)\n\n        # Files that should be excluded from the zip\n        if exclude is None:\n            exclude = list()\n\n        # Exclude the zip itself\n        exclude.append(archive_path)\n\n        # Make sure that 'concurrent' is always forbidden.\n        # https://github.com/Miserlou/Zappa/issues/827\n        if not 'concurrent' in exclude:\n            exclude.append('concurrent')\n\n        def splitpath(path):\n            parts = []\n            (path, tail) = os.path.split(path)\n            while path and tail:\n                parts.append(tail)\n                (path, tail) = os.path.split(path)\n            parts.append(os.path.join(path, tail))\n            return list(map(os.path.normpath, parts))[::-1]\n        split_venv = splitpath(venv)\n        split_cwd = splitpath(cwd)\n\n        # Ideally this should be avoided automatically,\n        # but this serves as an okay stop-gap measure.\n        if split_venv[-1] == split_cwd[-1]:  # pragma: no cover\n            print(\n                \"Warning! Your project and virtualenv have the same name! You may want \"\n                \"to re-create your venv with a new name, or explicitly define a \"\n                \"'project_name', as this may cause errors.\"\n            )\n\n        # First, do the project..\n        temp_project_path = tempfile.mkdtemp(prefix='zappa-project')\n\n        if not slim_handler:\n            # Slim handler does not take the project files.\n            if minify:\n                # Related: https://github.com/Miserlou/Zappa/issues/744\n                excludes = ZIP_EXCLUDES + exclude + [split_venv[-1]]\n                copytree(cwd, temp_project_path, metadata=False, symlinks=False, ignore=shutil.ignore_patterns(*excludes))\n            else:\n                copytree(cwd, temp_project_path, metadata=False, symlinks=False)\n\n        # If a handler_file is supplied, copy that to the root of the package,\n        # because that's where AWS Lambda looks for it. It can't be inside a package.\n        if handler_file:\n            filename = handler_file.split(os.sep)[-1]\n            shutil.copy(handler_file, os.path.join(temp_project_path, filename))\n\n        # Create and populate package ID file and write to temp project path\n        package_info = {}\n        package_info['uuid'] = str(uuid.uuid4())\n        package_info['build_time'] = build_time\n        package_info['build_platform'] = os.sys.platform\n        package_info['build_user'] = getpass.getuser()\n        # TODO: Add git head and info?\n\n        # Ex, from @scoates:\n        # def _get_git_branch():\n        #     chdir(DIR)\n        #     out = check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).strip()\n        #     lambci_branch = environ.get('LAMBCI_BRANCH', None)\n        #     if out == \"HEAD\" and lambci_branch:\n        #         out += \" lambci:{}\".format(lambci_branch)\n        #     return out\n\n        # def _get_git_hash():\n        #     chdir(DIR)\n        #     return check_output(['git', 'rev-parse', 'HEAD']).strip()\n\n        # def _get_uname():\n        #     return check_output(['uname', '-a']).strip()\n\n        # def _get_user():\n        #     return check_output(['whoami']).strip()\n\n        # def set_id_info(zappa_cli):\n        #     build_info = {\n        #         'branch': _get_git_branch(),\n        #         'hash': _get_git_hash(),\n        #         'build_uname': _get_uname(),\n        #         'build_user': _get_user(),\n        #         'build_time': datetime.datetime.utcnow().isoformat(),\n        #     }\n        #     with open(path.join(DIR, 'id_info.json'), 'w') as f:\n        #         json.dump(build_info, f)\n        #     return True\n\n        package_id_file = open(os.path.join(temp_project_path, 'package_info.json'), 'w')\n        dumped = json.dumps(package_info, indent=4)\n        try:\n            package_id_file.write(dumped)\n        except TypeError: # This is a Python 2/3 issue. TODO: Make pretty!\n            package_id_file.write(unicode(dumped))\n        package_id_file.close()\n\n        # Then, do site site-packages..\n        egg_links = []\n        temp_package_path = tempfile.mkdtemp(prefix='zappa-packages')\n        if os.sys.platform == 'win32':\n            site_packages = os.path.join(venv, 'Lib', 'site-packages')\n        else:\n            site_packages = os.path.join(venv, 'lib', get_venv_from_python_version(), 'site-packages')\n        egg_links.extend(glob.glob(os.path.join(site_packages, '*.egg-link')))\n\n        if minify:\n            excludes = ZIP_EXCLUDES + exclude\n            copytree(site_packages, temp_package_path, metadata=False, symlinks=False, ignore=shutil.ignore_patterns(*excludes))\n        else:\n            copytree(site_packages, temp_package_path, metadata=False, symlinks=False)\n\n        # We may have 64-bin specific packages too.\n        site_packages_64 = os.path.join(venv, 'lib64', get_venv_from_python_version(), 'site-packages')\n        if os.path.exists(site_packages_64):\n            egg_links.extend(glob.glob(os.path.join(site_packages_64, '*.egg-link')))\n            if minify:\n                excludes = ZIP_EXCLUDES + exclude\n                copytree(site_packages_64, temp_package_path, metadata = False, symlinks=False, ignore=shutil.ignore_patterns(*excludes))\n            else:\n                copytree(site_packages_64, temp_package_path, metadata = False, symlinks=False)\n\n        if egg_links:\n            self.copy_editable_packages(egg_links, temp_package_path)\n\n        copy_tree(temp_package_path, temp_project_path, update=True)\n\n        # Then the pre-compiled packages..\n        if use_precompiled_packages:\n            print(\"Downloading and installing dependencies..\")\n            installed_packages = self.get_installed_packages(site_packages, site_packages_64)\n\n            try:\n                for installed_package_name, installed_package_version in installed_packages.items():\n                    if self.have_correct_lambda_package_version(installed_package_name, installed_package_version):\n                        print(\" - %s==%s: Using precompiled lambda package \" % (installed_package_name, installed_package_version,))\n                        self.extract_lambda_package(installed_package_name, temp_project_path)\n                    else:\n                        cached_wheel_path = self.get_cached_manylinux_wheel(installed_package_name, installed_package_version, disable_progress)\n                        if cached_wheel_path:\n                            # Otherwise try to use manylinux packages from PyPi..\n                            # Related: https://github.com/Miserlou/Zappa/issues/398\n                            shutil.rmtree(os.path.join(temp_project_path, installed_package_name), ignore_errors=True)\n                            with zipfile.ZipFile(cached_wheel_path) as zfile:\n                                zfile.extractall(temp_project_path)\n\n                        elif self.have_any_lambda_package_version(installed_package_name):\n                            # Finally see if we may have at least one version of the package in lambda packages\n                            # Related: https://github.com/Miserlou/Zappa/issues/855\n                            lambda_version = lambda_packages[installed_package_name][self.runtime]['version']\n                            print(\" - %s==%s: Warning! Using precompiled lambda package version %s instead!\" % (installed_package_name, installed_package_version, lambda_version, ))\n                            self.extract_lambda_package(installed_package_name, temp_project_path)\n\n                # This is a special case!\n                # SQLite3 is part of the _system_ Python, not a package. Still, it lives in `lambda-packages`.\n                # Everybody on Python3 gets it!\n                if self.runtime in (\"python3.6\", \"python3.7\"):\n                    print(\" - sqlite==python3: Using precompiled lambda package\")\n                    self.extract_lambda_package('sqlite3', temp_project_path)\n\n            except Exception as e:\n                print(e)\n                # XXX - What should we do here?\n\n        # Then archive it all up..\n        if archive_format == 'zip':\n            print(\"Packaging project as zip.\")\n\n            try:\n                compression_method = zipfile.ZIP_DEFLATED\n            except ImportError:  # pragma: no cover\n                compression_method = zipfile.ZIP_STORED\n            archivef = zipfile.ZipFile(archive_path, 'w', compression_method)\n\n        elif archive_format == 'tarball':\n            print(\"Packaging project as gzipped tarball.\")\n            archivef = tarfile.open(archive_path, 'w|gz')\n\n        for root, dirs, files in os.walk(temp_project_path):\n\n            for filename in files:\n\n                # Skip .pyc files for Django migrations\n                # https://github.com/Miserlou/Zappa/issues/436\n                # https://github.com/Miserlou/Zappa/issues/464\n                if filename[-4:] == '.pyc' and root[-10:] == 'migrations':\n                    continue\n\n                # If there is a .pyc file in this package,\n                # we can skip the python source code as we'll just\n                # use the compiled bytecode anyway..\n                if filename[-3:] == '.py' and root[-10:] != 'migrations':\n                    abs_filname = os.path.join(root, filename)\n                    abs_pyc_filename = abs_filname + 'c'\n                    if os.path.isfile(abs_pyc_filename):\n\n                        # but only if the pyc is older than the py,\n                        # otherwise we'll deploy outdated code!\n                        py_time = os.stat(abs_filname).st_mtime\n                        pyc_time = os.stat(abs_pyc_filename).st_mtime\n\n                        if pyc_time > py_time:\n                            continue\n\n                # Make sure that the files are all correctly chmodded\n                # Related: https://github.com/Miserlou/Zappa/issues/484\n                # Related: https://github.com/Miserlou/Zappa/issues/682\n                os.chmod(os.path.join(root, filename),  0o755)\n\n                if archive_format == 'zip':\n                    # Actually put the file into the proper place in the zip\n                    # Related: https://github.com/Miserlou/Zappa/pull/716\n                    zipi = zipfile.ZipInfo(os.path.join(root.replace(temp_project_path, '').lstrip(os.sep), filename))\n                    zipi.create_system = 3\n                    zipi.external_attr = 0o755 << int(16) # Is this P2/P3 functional?\n                    with open(os.path.join(root, filename), 'rb') as f:\n                        archivef.writestr(zipi, f.read(), compression_method)\n                elif archive_format == 'tarball':\n                    tarinfo = tarfile.TarInfo(os.path.join(root.replace(temp_project_path, '').lstrip(os.sep), filename))\n                    tarinfo.mode = 0o755\n\n                    stat = os.stat(os.path.join(root, filename))\n                    tarinfo.mtime = stat.st_mtime\n                    tarinfo.size = stat.st_size\n                    with open(os.path.join(root, filename), 'rb') as f:\n                        archivef.addfile(tarinfo, f)\n\n            # Create python init file if it does not exist\n            # Only do that if there are sub folders or python files and does not conflict with a neighbouring module\n            # Related: https://github.com/Miserlou/Zappa/issues/766\n            if not contains_python_files_or_subdirs(root):\n                # if the directory does not contain any .py file at any level, we can skip the rest\n                dirs[:] = [d for d in dirs if d != root]\n            else:\n                if '__init__.py' not in files and not conflicts_with_a_neighbouring_module(root):\n                    tmp_init = os.path.join(temp_project_path, '__init__.py')\n                    open(tmp_init, 'a').close()\n                    os.chmod(tmp_init,  0o755)\n\n                    arcname = os.path.join(root.replace(temp_project_path, ''),\n                                           os.path.join(root.replace(temp_project_path, ''), '__init__.py'))\n                    if archive_format == 'zip':\n                        archivef.write(tmp_init, arcname)\n                    elif archive_format == 'tarball':\n                        archivef.add(tmp_init, arcname)\n\n        # And, we're done!\n        archivef.close()\n\n        # Trash the temp directory\n        shutil.rmtree(temp_project_path)\n        shutil.rmtree(temp_package_path)\n        if os.path.isdir(venv) and slim_handler:\n            # Remove the temporary handler venv folder\n            shutil.rmtree(venv)\n\n        return archive_fname"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_lambda_package(self, package_name, path):\n        lambda_package = lambda_packages[package_name][self.runtime]\n\n        # Trash the local version to help with package space saving\n        shutil.rmtree(os.path.join(path, package_name), ignore_errors=True)\n\n        tar = tarfile.open(lambda_package['path'], mode=\"r:gz\")\n        for member in tar.getmembers():\n            tar.extract(member, path)", "response": "Extracts the lambda package into a given path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of installed packages that Zappa cares about.", "response": "def get_installed_packages(site_packages, site_packages_64):\n        \"\"\"\n        Returns a dict of installed packages that Zappa cares about.\n        \"\"\"\n        import pkg_resources\n\n        package_to_keep = []\n        if os.path.isdir(site_packages):\n            package_to_keep += os.listdir(site_packages)\n        if os.path.isdir(site_packages_64):\n            package_to_keep += os.listdir(site_packages_64)\n\n        package_to_keep = [x.lower() for x in package_to_keep]\n\n        installed_packages = {package.project_name.lower(): package.version for package in\n                              pkg_resources.WorkingSet()\n                              if package.project_name.lower() in package_to_keep\n                              or package.location.lower() in [site_packages.lower(), site_packages_64.lower()]}\n\n        return installed_packages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a given package version binary should be copied over from lambda packages.", "response": "def have_correct_lambda_package_version(self, package_name, package_version):\n        \"\"\"\n        Checks if a given package version binary should be copied over from lambda packages.\n        package_name should be lower-cased version of package name.\n        \"\"\"\n        lambda_package_details = lambda_packages.get(package_name, {}).get(self.runtime)\n\n        if lambda_package_details is None:\n            return False\n\n        # Binaries can be compiled for different package versions\n        # Related: https://github.com/Miserlou/Zappa/issues/800\n        if package_version != lambda_package_details['version']:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a given url in chunks and writes it to the provided stream.", "response": "def download_url_with_progress(url, stream, disable_progress):\n        \"\"\"\n        Downloads a given url in chunks and writes to the provided stream (can be any io stream).\n        Displays the progress bar for the download.\n        \"\"\"\n        resp = requests.get(url, timeout=float(os.environ.get('PIP_TIMEOUT', 2)), stream=True)\n        resp.raw.decode_content = True\n\n        progress = tqdm(unit=\"B\", unit_scale=True, total=int(resp.headers.get('Content-Length', 0)), disable=disable_progress)\n        for chunk in resp.iter_content(chunk_size=1024):\n            if chunk:\n                progress.update(len(chunk))\n                stream.write(chunk)\n\n        progress.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cached_manylinux_wheel(self, package_name, package_version, disable_progress=False):\n        cached_wheels_dir = os.path.join(tempfile.gettempdir(), 'cached_wheels')\n        if not os.path.isdir(cached_wheels_dir):\n            os.makedirs(cached_wheels_dir)\n\n        wheel_file = '{0!s}-{1!s}-{2!s}'.format(package_name, package_version, self.manylinux_wheel_file_suffix)\n        wheel_path = os.path.join(cached_wheels_dir, wheel_file)\n\n        if not os.path.exists(wheel_path) or not zipfile.is_zipfile(wheel_path):\n            # The file is not cached, download it.\n            wheel_url = self.get_manylinux_wheel_url(package_name, package_version)\n            if not wheel_url:\n                return None\n\n            print(\" - {}=={}: Downloading\".format(package_name, package_version))\n            with open(wheel_path, 'wb') as f:\n                self.download_url_with_progress(wheel_url, f, disable_progress)\n\n            if not zipfile.is_zipfile(wheel_path):\n                return None\n        else:\n            print(\" - {}=={}: Using locally cached manylinux wheel\".format(package_name, package_version))\n\n        return wheel_path", "response": "Gets the locally stored version of a manylinux wheel. If one does not exist the function downloads it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_manylinux_wheel_url(self, package_name, package_version):\n        cached_pypi_info_dir = os.path.join(tempfile.gettempdir(), 'cached_pypi_info')\n        if not os.path.isdir(cached_pypi_info_dir):\n            os.makedirs(cached_pypi_info_dir)\n        # Even though the metadata is for the package, we save it in a\n        # filename that includes the package's version. This helps in\n        # invalidating the cached file if the user moves to a different\n        # version of the package.\n        # Related: https://github.com/Miserlou/Zappa/issues/899\n        json_file = '{0!s}-{1!s}.json'.format(package_name, package_version)\n        json_file_path = os.path.join(cached_pypi_info_dir, json_file)\n        if os.path.exists(json_file_path):\n            with open(json_file_path, 'rb') as metafile:\n                data = json.load(metafile)\n        else:\n            url = 'https://pypi.python.org/pypi/{}/json'.format(package_name)\n            try:\n                res = requests.get(url, timeout=float(os.environ.get('PIP_TIMEOUT', 1.5)))\n                data = res.json()\n            except Exception as e: # pragma: no cover\n                return None\n            with open(json_file_path, 'wb') as metafile:\n                jsondata = json.dumps(data)\n                metafile.write(bytes(jsondata, \"utf-8\"))\n\n        if package_version not in data['releases']:\n            return None\n\n        for f in data['releases'][package_version]:\n            if f['filename'].endswith(self.manylinux_wheel_file_suffix):\n                return f['url']\n        return None", "response": "Get a link to the download URL of a manylinux wheel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_to_s3(self, source_path, bucket_name, disable_progress=False):\n        try:\n            self.s3_client.head_bucket(Bucket=bucket_name)\n        except botocore.exceptions.ClientError:\n            # This is really stupid S3 quirk. Technically, us-east-1 one has no S3,\n            # it's actually \"US Standard\", or something.\n            # More here: https://github.com/boto/boto3/issues/125\n            if self.aws_region == 'us-east-1':\n                self.s3_client.create_bucket(\n                    Bucket=bucket_name,\n                )\n            else:\n                self.s3_client.create_bucket(\n                    Bucket=bucket_name,\n                    CreateBucketConfiguration={'LocationConstraint': self.aws_region},\n                )\n\n            if self.tags:\n                tags = {\n                    'TagSet': [{'Key': key, 'Value': self.tags[key]} for key in self.tags.keys()]\n                }\n                self.s3_client.put_bucket_tagging(Bucket=bucket_name, Tagging=tags)\n\n        if not os.path.isfile(source_path) or os.stat(source_path).st_size == 0:\n            print(\"Problem with source file {}\".format(source_path))\n            return False\n\n        dest_path = os.path.split(source_path)[1]\n        try:\n            source_size = os.stat(source_path).st_size\n            print(\"Uploading {0} ({1})..\".format(dest_path, human_size(source_size)))\n            progress = tqdm(total=float(os.path.getsize(source_path)), unit_scale=True, unit='B', disable=disable_progress)\n\n            # Attempt to upload to S3 using the S3 meta client with the progress bar.\n            # If we're unable to do that, try one more time using a session client,\n            # which cannot use the progress bar.\n            # Related: https://github.com/boto/boto3/issues/611\n            try:\n                self.s3_client.upload_file(\n                    source_path, bucket_name, dest_path,\n                    Callback=progress.update\n                )\n            except Exception as e:  # pragma: no cover\n                self.s3_client.upload_file(source_path, bucket_name, dest_path)\n\n            progress.close()\n        except (KeyboardInterrupt, SystemExit):  # pragma: no cover\n            raise\n        except Exception as e:  # pragma: no cover\n            print(e)\n            return False\n        return True", "response": "r Uploads a file to S3."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying a file from src_file_name to dst_file_name within a bucket.", "response": "def copy_on_s3(self, src_file_name, dst_file_name, bucket_name):\n        \"\"\"\n        Copies src file to destination within a bucket.\n        \"\"\"\n        try:\n            self.s3_client.head_bucket(Bucket=bucket_name)\n        except botocore.exceptions.ClientError as e:  # pragma: no cover\n            # If a client error is thrown, then check that it was a 404 error.\n            # If it was a 404 error, then the bucket does not exist.\n            error_code = int(e.response['Error']['Code'])\n            if error_code == 404:\n                return False\n\n        copy_src = {\n            \"Bucket\": bucket_name,\n            \"Key\": src_file_name\n        }\n        try:\n            self.s3_client.copy(\n                CopySource=copy_src,\n                Bucket=bucket_name,\n                Key=dst_file_name\n            )\n            return True\n        except botocore.exceptions.ClientError:  # pragma: no cover\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a file from S3.", "response": "def remove_from_s3(self, file_name, bucket_name):\n        \"\"\"\n        Given a file name and a bucket, remove it from S3.\n\n        There's no reason to keep the file hosted on S3 once its been made into a Lambda function, so we can delete it from S3.\n\n        Returns True on success, False on failure.\n\n        \"\"\"\n        try:\n            self.s3_client.head_bucket(Bucket=bucket_name)\n        except botocore.exceptions.ClientError as e:  # pragma: no cover\n            # If a client error is thrown, then check that it was a 404 error.\n            # If it was a 404 error, then the bucket does not exist.\n            error_code = int(e.response['Error']['Code'])\n            if error_code == 404:\n                return False\n\n        try:\n            self.s3_client.delete_object(Bucket=bucket_name, Key=file_name)\n            return True\n        except (botocore.exceptions.ParamValidationError, botocore.exceptions.ClientError):  # pragma: no cover\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_lambda_function( self,\n                                bucket=None,\n                                function_name=None,\n                                handler=None,\n                                s3_key=None,\n                                description='Zappa Deployment',\n                                timeout=30,\n                                memory_size=512,\n                                publish=True,\n                                vpc_config=None,\n                                dead_letter_config=None,\n                                runtime='python2.7',\n                                aws_environment_variables=None,\n                                aws_kms_key_arn=None,\n                                xray_tracing=False,\n                                local_zip=None,\n                                use_alb=False,\n                            ):\n        \"\"\"\n        Given a bucket and key (or a local path) of a valid Lambda-zip, a function name and a handler, register that Lambda function.\n        \"\"\"\n        if not vpc_config:\n            vpc_config = {}\n        if not dead_letter_config:\n            dead_letter_config = {}\n        if not self.credentials_arn:\n            self.get_credentials_arn()\n        if not aws_environment_variables:\n            aws_environment_variables = {}\n        if not aws_kms_key_arn:\n            aws_kms_key_arn = ''\n\n        kwargs = dict(\n            FunctionName=function_name,\n            Runtime=runtime,\n            Role=self.credentials_arn,\n            Handler=handler,\n            Description=description,\n            Timeout=timeout,\n            MemorySize=memory_size,\n            Publish=publish,\n            VpcConfig=vpc_config,\n            DeadLetterConfig=dead_letter_config,\n            Environment={'Variables': aws_environment_variables},\n            KMSKeyArn=aws_kms_key_arn,\n            TracingConfig={\n                'Mode': 'Active' if self.xray_tracing else 'PassThrough'\n            }\n        )\n        if local_zip:\n            kwargs['Code'] = {\n                'ZipFile': local_zip\n            }\n        else:\n            kwargs['Code'] = {\n                'S3Bucket': bucket,\n                'S3Key': s3_key\n            }\n\n        response = self.lambda_client.create_function(**kwargs)\n\n        resource_arn = response['FunctionArn']\n        version = response['Version']\n\n        # If we're using an ALB, let's create an alias mapped to the newly\n        # created function. This allows clean, no downtime association when\n        # using application load balancers as an event source.\n        # See: https://github.com/Miserlou/Zappa/pull/1730\n        #      https://github.com/Miserlou/Zappa/issues/1823\n        if use_alb:\n            self.lambda_client.create_alias(\n                FunctionName=resource_arn,\n                FunctionVersion=version,\n                Name=ALB_LAMBDA_ALIAS,\n            )\n\n        if self.tags:\n            self.lambda_client.tag_resource(Resource=resource_arn, Tags=self.tags)\n\n        return resource_arn", "response": "Creates a Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the Lambda function s code.", "response": "def update_lambda_function(self, bucket, function_name, s3_key=None, publish=True, local_zip=None, num_revisions=None):\n        \"\"\"\n        Given a bucket and key (or a local path) of a valid Lambda-zip, a function name and a handler, update that Lambda function's code.\n        Optionally, delete previous versions if they exceed the optional limit.\n        \"\"\"\n        print(\"Updating Lambda function code..\")\n\n        kwargs = dict(\n            FunctionName=function_name,\n            Publish=publish\n        )\n        if local_zip:\n            kwargs['ZipFile'] = local_zip\n        else:\n            kwargs['S3Bucket'] = bucket\n            kwargs['S3Key'] = s3_key\n\n        response = self.lambda_client.update_function_code(**kwargs)\n        resource_arn = response['FunctionArn']\n        version = response['Version']\n\n        # If the lambda has an ALB alias, let's update the alias\n        # to point to the newest version of the function. We have to use a GET\n        # here, as there's no HEAD-esque call to retrieve metadata about a\n        # function alias.\n        # Related: https://github.com/Miserlou/Zappa/pull/1730\n        #          https://github.com/Miserlou/Zappa/issues/1823\n        try:\n            response = self.lambda_client.get_alias(\n                FunctionName=function_name,\n                Name=ALB_LAMBDA_ALIAS,\n            )\n            alias_exists = True\n        except botocore.exceptions.ClientError as e:  # pragma: no cover\n            if \"ResourceNotFoundException\" not in e.response[\"Error\"][\"Code\"]:\n                raise e\n            alias_exists = False\n\n        if alias_exists:\n            self.lambda_client.update_alias(\n                FunctionName=function_name,\n                FunctionVersion=version,\n                Name=ALB_LAMBDA_ALIAS,\n            )\n\n        if num_revisions:\n            # Find the existing revision IDs for the given function\n            # Related: https://github.com/Miserlou/Zappa/issues/1402\n            versions_in_lambda = []\n            versions = self.lambda_client.list_versions_by_function(FunctionName=function_name)\n            for version in versions['Versions']:\n                versions_in_lambda.append(version['Version'])\n            while 'NextMarker' in versions:\n                versions = self.lambda_client.list_versions_by_function(FunctionName=function_name,Marker=versions['NextMarker'])\n                for version in versions['Versions']:\n                    versions_in_lambda.append(version['Version'])\n            versions_in_lambda.remove('$LATEST')\n            # Delete older revisions if their number exceeds the specified limit\n            for version in versions_in_lambda[::-1][num_revisions:]:\n                self.lambda_client.delete_function(FunctionName=function_name,Qualifier=version)\n\n        return resource_arn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_lambda_configuration(    self,\n                                        lambda_arn,\n                                        function_name,\n                                        handler,\n                                        description='Zappa Deployment',\n                                        timeout=30,\n                                        memory_size=512,\n                                        publish=True,\n                                        vpc_config=None,\n                                        runtime='python2.7',\n                                        aws_environment_variables=None,\n                                        aws_kms_key_arn=None\n                                    ):\n        \"\"\"\n        Given an existing function ARN, update the configuration variables.\n        \"\"\"\n        print(\"Updating Lambda function configuration..\")\n\n        if not vpc_config:\n            vpc_config = {}\n        if not self.credentials_arn:\n            self.get_credentials_arn()\n        if not aws_kms_key_arn:\n            aws_kms_key_arn = ''\n        if not aws_environment_variables:\n            aws_environment_variables = {}\n\n        # Check if there are any remote aws lambda env vars so they don't get trashed.\n        # https://github.com/Miserlou/Zappa/issues/987,  Related: https://github.com/Miserlou/Zappa/issues/765\n        lambda_aws_config = self.lambda_client.get_function_configuration(FunctionName=function_name)\n        if \"Environment\" in lambda_aws_config:\n            lambda_aws_environment_variables = lambda_aws_config[\"Environment\"].get(\"Variables\", {})\n            # Append keys that are remote but not in settings file\n            for key, value in lambda_aws_environment_variables.items():\n                if key not in aws_environment_variables:\n                    aws_environment_variables[key] = value\n\n        response = self.lambda_client.update_function_configuration(\n            FunctionName=function_name,\n            Runtime=runtime,\n            Role=self.credentials_arn,\n            Handler=handler,\n            Description=description,\n            Timeout=timeout,\n            MemorySize=memory_size,\n            VpcConfig=vpc_config,\n            Environment={'Variables': aws_environment_variables},\n            KMSKeyArn=aws_kms_key_arn,\n            TracingConfig={\n                'Mode': 'Active' if self.xray_tracing else 'PassThrough'\n            }\n        )\n\n        resource_arn = response['FunctionArn']\n\n        if self.tags:\n            self.lambda_client.tag_resource(Resource=resource_arn, Tags=self.tags)\n\n        return resource_arn", "response": "Update the Lambda function configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invoke_lambda_function( self,\n                                function_name,\n                                payload,\n                                invocation_type='Event',\n                                log_type='Tail',\n                                client_context=None,\n                                qualifier=None\n                            ):\n        \"\"\"\n        Directly invoke a named Lambda function with a payload.\n        Returns the response.\n        \"\"\"\n        return self.lambda_client.invoke(\n            FunctionName=function_name,\n            InvocationType=invocation_type,\n            LogType=log_type,\n            Payload=payload\n        )", "response": "Directly invoke a named Lambda function with a payload."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_lambda_function(self, function_name):\n        response = self.lambda_client.get_function(\n                FunctionName=function_name)\n        return response['Configuration']['FunctionArn']", "response": "Returns the lambda function ARN given a name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the versions available for a Lambda function given a function name.", "response": "def get_lambda_function_versions(self, function_name):\n        \"\"\"\n        Simply returns the versions available for a Lambda function, given a function name.\n\n        \"\"\"\n        try:\n            response = self.lambda_client.list_versions_by_function(\n                FunctionName=function_name\n            )\n            return response.get('Versions', [])\n        except Exception:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy_lambda_alb(  self,\n                            lambda_arn,\n                            lambda_name,\n                            alb_vpc_config,\n                            timeout\n                         ):\n        \"\"\"\n        The `zappa deploy` functionality for ALB infrastructure.\n        \"\"\"\n        if not alb_vpc_config:\n            raise EnvironmentError('When creating an ALB, alb_vpc_config must be filled out in zappa_settings.')\n        if 'SubnetIds' not in alb_vpc_config:\n            raise EnvironmentError('When creating an ALB, you must supply two subnets in different availability zones.')\n        if 'SecurityGroupIds' not in alb_vpc_config:\n            alb_vpc_config[\"SecurityGroupIds\"] = []\n        if not alb_vpc_config.get('CertificateArn'):\n            raise EnvironmentError('When creating an ALB, you must supply a CertificateArn for the HTTPS listener.')\n        print(\"Deploying ALB infrastructure...\")\n\n        # Create load balancer\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.create_load_balancer\n        kwargs = dict(\n            Name=lambda_name,\n            Subnets=alb_vpc_config[\"SubnetIds\"],\n            SecurityGroups=alb_vpc_config[\"SecurityGroupIds\"],\n            # TODO: Scheme can also be \"internal\" we need to add a new option for this.\n            Scheme=\"internet-facing\",\n            # TODO: Tags might be a useful means of stock-keeping zappa-generated assets.\n            #Tags=[],\n            Type=\"application\",\n            # TODO: can be ipv4 or dualstack (for ipv4 and ipv6) ipv4 is required for internal Scheme.\n            IpAddressType=\"ipv4\"\n        )\n        response = self.elbv2_client.create_load_balancer(**kwargs)\n        if not(response[\"LoadBalancers\"]) or len(response[\"LoadBalancers\"]) != 1:\n            raise EnvironmentError(\"Failure to create application load balancer. Response was in unexpected format. Response was: {}\".format(repr(response)))\n        if response[\"LoadBalancers\"][0]['State']['Code'] == 'failed':\n            raise EnvironmentError(\"Failure to create application load balancer. Response reported a failed state: {}\".format(response[\"LoadBalancers\"][0]['State']['Reason']))\n        load_balancer_arn = response[\"LoadBalancers\"][0][\"LoadBalancerArn\"]\n        load_balancer_dns = response[\"LoadBalancers\"][0][\"DNSName\"]\n        load_balancer_vpc = response[\"LoadBalancers\"][0][\"VpcId\"]\n        waiter = self.elbv2_client.get_waiter('load_balancer_available')\n\n        # Match the lambda timeout on the load balancer.\n        self.elbv2_client.modify_load_balancer_attributes(\n            LoadBalancerArn=load_balancer_arn,\n            Attributes=[{\n                'Key': 'idle_timeout.timeout_seconds',\n                'Value': str(timeout)\n            }]\n        )\n\n        # Create/associate target group.\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.create_target_group\n        kwargs = dict(\n            Name=lambda_name,\n            TargetType=\"lambda\",\n            # TODO: Add options for health checks\n        )\n\n        response = self.elbv2_client.create_target_group(**kwargs)\n        if not(response[\"TargetGroups\"]) or len(response[\"TargetGroups\"]) != 1:\n            raise EnvironmentError(\"Failure to create application load balancer target group. Response was in unexpected format. Response was: {}\".format(repr(response)))\n        target_group_arn = response[\"TargetGroups\"][0][\"TargetGroupArn\"]\n\n        # Enable multi-value headers by default.\n        response = self.elbv2_client.modify_target_group_attributes(\n            TargetGroupArn=target_group_arn,\n            Attributes=[\n                {\n                    'Key': 'lambda.multi_value_headers.enabled',\n                    'Value': 'true'\n                },\n            ]\n        )\n\n        # Allow execute permissions from target group to lambda.\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/lambda.html#Lambda.Client.add_permission\n        kwargs = dict(\n            Action=\"lambda:InvokeFunction\",\n            FunctionName=\"{}:{}\".format(lambda_arn, ALB_LAMBDA_ALIAS),\n            Principal=\"elasticloadbalancing.amazonaws.com\",\n            SourceArn=target_group_arn,\n            StatementId=lambda_name\n        )\n        response = self.lambda_client.add_permission(**kwargs)\n\n        # Register target group to lambda association.\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.register_targets\n        kwargs = dict(\n            TargetGroupArn=target_group_arn,\n            Targets=[{\"Id\": \"{}:{}\".format(lambda_arn, ALB_LAMBDA_ALIAS)}]\n        )\n        response = self.elbv2_client.register_targets(**kwargs)\n\n        # Bind listener to load balancer with default rule to target group.\n        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.create_listener\n        kwargs = dict(\n            # TODO: Listeners support custom ssl certificates (Certificates). For now we leave this default.\n            Certificates=[{\"CertificateArn\": alb_vpc_config['CertificateArn']}],\n            DefaultActions=[{\n                \"Type\": \"forward\",\n                \"TargetGroupArn\": target_group_arn,\n            }],\n            LoadBalancerArn=load_balancer_arn,\n            Protocol=\"HTTPS\",\n            # TODO: Add option for custom ports\n            Port=443,\n            # TODO: Listeners support custom ssl security policy (SslPolicy). For now we leave this default.\n        )\n        response = self.elbv2_client.create_listener(**kwargs)\n        print(\"ALB created with DNS: {}\".format(load_balancer_dns))\n        print(\"Note it may take several minutes for load balancer to become available.\")", "response": "Deploy an ALB infrastructure to the AWS Lambda."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef undeploy_lambda_alb(self, lambda_name):\n        print(\"Undeploying ALB infrastructure...\")\n\n        # Locate and delete alb/lambda permissions\n        try:\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/lambda.html#Lambda.Client.remove_permission\n            self.lambda_client.remove_permission(\n                FunctionName=lambda_name,\n                StatementId=lambda_name\n            )\n        except botocore.exceptions.ClientError as e: # pragma: no cover\n            if \"ResourceNotFoundException\" in e.response[\"Error\"][\"Code\"]:\n                pass\n            else:\n                raise e\n\n        # Locate and delete load balancer\n        try:\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.describe_load_balancers\n            response = self.elbv2_client.describe_load_balancers(\n                Names=[lambda_name]\n            )\n            if not(response[\"LoadBalancers\"]) or len(response[\"LoadBalancers\"]) > 1:\n                raise EnvironmentError(\"Failure to locate/delete ALB named [{}]. Response was: {}\".format(lambda_name, repr(response)))\n            load_balancer_arn = response[\"LoadBalancers\"][0][\"LoadBalancerArn\"]\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.describe_listeners\n            response = self.elbv2_client.describe_listeners(LoadBalancerArn=load_balancer_arn)\n            if not(response[\"Listeners\"]):\n                print('No listeners found.')\n            elif len(response[\"Listeners\"]) > 1:\n                raise EnvironmentError(\"Failure to locate/delete listener for ALB named [{}]. Response was: {}\".format(lambda_name, repr(response)))\n            else:\n                listener_arn = response[\"Listeners\"][0][\"ListenerArn\"]\n                # Remove the listener. This explicit deletion of the listener seems necessary to avoid ResourceInUseExceptions when deleting target groups.\n                # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.delete_listener\n                response = self.elbv2_client.delete_listener(ListenerArn=listener_arn)\n            # Remove the load balancer and wait for completion\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.delete_load_balancer\n            response = self.elbv2_client.delete_load_balancer(LoadBalancerArn=load_balancer_arn)\n            waiter = self.elbv2_client.get_waiter('load_balancers_deleted')\n            print('Waiting for load balancer [{}] to be deleted..'.format(lambda_name))\n            waiter.wait(LoadBalancerArns=[load_balancer_arn], WaiterConfig={\"Delay\": 3})\n        except botocore.exceptions.ClientError as e: # pragma: no cover\n            print(e.response[\"Error\"][\"Code\"])\n            if \"LoadBalancerNotFound\" in e.response[\"Error\"][\"Code\"]:\n                pass\n            else:\n                raise e\n\n        # Locate and delete target group\n        try:\n            # Locate the lambda ARN\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/lambda.html#Lambda.Client.get_function\n            response = self.lambda_client.get_function(FunctionName=lambda_name)\n            lambda_arn = response[\"Configuration\"][\"FunctionArn\"]\n            # Locate the target group ARN\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.describe_target_groups\n            response = self.elbv2_client.describe_target_groups(Names=[lambda_name])\n            if not(response[\"TargetGroups\"]) or len(response[\"TargetGroups\"]) > 1:\n                raise EnvironmentError(\"Failure to locate/delete ALB target group named [{}]. Response was: {}\".format(lambda_name, repr(response)))\n            target_group_arn = response[\"TargetGroups\"][0][\"TargetGroupArn\"]\n            # Deregister targets and wait for completion\n            self.elbv2_client.deregister_targets(\n                TargetGroupArn=target_group_arn,\n                Targets=[{\"Id\": lambda_arn}]\n            )\n            waiter = self.elbv2_client.get_waiter('target_deregistered')\n            print('Waiting for target [{}] to be deregistered...'.format(lambda_name))\n            waiter.wait(\n                TargetGroupArn=target_group_arn,\n                Targets=[{\"Id\": lambda_arn}],\n                WaiterConfig={\"Delay\": 3}\n            )\n            # Remove the target group\n            # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/elbv2.html#ElasticLoadBalancingv2.Client.delete_target_group\n            self.elbv2_client.delete_target_group(TargetGroupArn=target_group_arn)\n        except botocore.exceptions.ClientError as e: # pragma: no cover\n            print(e.response[\"Error\"][\"Code\"])\n            if \"TargetGroupNotFound\" in e.response[\"Error\"][\"Code\"]:\n                pass\n            else:\n                raise e", "response": "Undeploy an ALB infrastructure."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_api_gateway_routes(  self,\n                                    lambda_arn,\n                                    api_name=None,\n                                    api_key_required=False,\n                                    authorization_type='NONE',\n                                    authorizer=None,\n                                    cors_options=None,\n                                    description=None,\n                                    endpoint_configuration=None\n                                ):\n        \"\"\"\n        Create the API Gateway for this Zappa deployment.\n\n        Returns the new RestAPI CF resource.\n        \"\"\"\n\n        restapi = troposphere.apigateway.RestApi('Api')\n        restapi.Name = api_name or lambda_arn.split(':')[-1]\n        if not description:\n            description = 'Created automatically by Zappa.'\n        restapi.Description = description\n        endpoint_configuration = [] if endpoint_configuration is None else endpoint_configuration\n        if self.boto_session.region_name == \"us-gov-west-1\":\n            endpoint_configuration.append(\"REGIONAL\")\n        if endpoint_configuration:\n            endpoint = troposphere.apigateway.EndpointConfiguration()\n            endpoint.Types = list(set(endpoint_configuration))\n            restapi.EndpointConfiguration = endpoint\n        if self.apigateway_policy:\n            restapi.Policy = json.loads(self.apigateway_policy)\n        self.cf_template.add_resource(restapi)\n\n        root_id = troposphere.GetAtt(restapi, 'RootResourceId')\n        invocation_prefix = \"aws\" if self.boto_session.region_name != \"us-gov-west-1\" else \"aws-us-gov\"\n        invocations_uri = 'arn:' + invocation_prefix + ':apigateway:' + self.boto_session.region_name + ':lambda:path/2015-03-31/functions/' + lambda_arn + '/invocations'\n\n        ##\n        # The Resources\n        ##\n        authorizer_resource = None\n        if authorizer:\n            authorizer_lambda_arn = authorizer.get('arn', lambda_arn)\n            lambda_uri = 'arn:{invocation_prefix}:apigateway:{region_name}:lambda:path/2015-03-31/functions/{lambda_arn}/invocations'.format(\n                invocation_prefix=invocation_prefix,\n                region_name=self.boto_session.region_name,\n                lambda_arn=authorizer_lambda_arn\n            )\n            authorizer_resource = self.create_authorizer(\n                restapi, lambda_uri, authorizer\n            )\n\n        self.create_and_setup_methods(  restapi,\n                                        root_id,\n                                        api_key_required,\n                                        invocations_uri,\n                                        authorization_type,\n                                        authorizer_resource,\n                                        0\n                                        )\n\n        if cors_options:\n            self.create_and_setup_cors( restapi,\n                                        root_id,\n                                        invocations_uri,\n                                        0,\n                                        cors_options\n                                    )\n\n        resource = troposphere.apigateway.Resource('ResourceAnyPathSlashed')\n        self.cf_api_resources.append(resource.title)\n        resource.RestApiId = troposphere.Ref(restapi)\n        resource.ParentId = root_id\n        resource.PathPart = \"{proxy+}\"\n        self.cf_template.add_resource(resource)\n\n        self.create_and_setup_methods(  restapi,\n                                        resource,\n                                        api_key_required,\n                                        invocations_uri,\n                                        authorization_type,\n                                        authorizer_resource,\n                                        1\n                                    )  # pragma: no cover\n\n        if cors_options:\n            self.create_and_setup_cors( restapi,\n                                        resource,\n                                        invocations_uri,\n                                        1,\n                                        cors_options\n                                    )  # pragma: no cover\n        return restapi", "response": "Create the API Gateway for this deployment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates Authorizer for API Gateway", "response": "def create_authorizer(self, restapi, uri, authorizer):\n        \"\"\"\n        Create Authorizer for API gateway\n        \"\"\"\n        authorizer_type = authorizer.get(\"type\", \"TOKEN\").upper()\n        identity_validation_expression = authorizer.get('validation_expression', None)\n\n        authorizer_resource = troposphere.apigateway.Authorizer(\"Authorizer\")\n        authorizer_resource.RestApiId = troposphere.Ref(restapi)\n        authorizer_resource.Name = authorizer.get(\"name\", \"ZappaAuthorizer\")\n        authorizer_resource.Type = authorizer_type\n        authorizer_resource.AuthorizerUri = uri\n        authorizer_resource.IdentitySource = \"method.request.header.%s\" % authorizer.get('token_header', 'Authorization')\n        if identity_validation_expression:\n            authorizer_resource.IdentityValidationExpression = identity_validation_expression\n\n        if authorizer_type == 'TOKEN':\n            if not self.credentials_arn:\n                self.get_credentials_arn()\n            authorizer_resource.AuthorizerResultTtlInSeconds = authorizer.get('result_ttl', 300)\n            authorizer_resource.AuthorizerCredentials = self.credentials_arn\n        if authorizer_type == 'COGNITO_USER_POOLS':\n            authorizer_resource.ProviderARNs = authorizer.get('provider_arns')\n\n        self.cf_api_resources.append(authorizer_resource.title)\n        self.cf_template.add_resource(authorizer_resource)\n\n        return authorizer_resource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the methods and integration responses for a given resource.", "response": "def create_and_setup_methods(\n                                    self,\n                                    restapi,\n                                    resource,\n                                    api_key_required,\n                                    uri,\n                                    authorization_type,\n                                    authorizer_resource,\n                                    depth\n                                ):\n        \"\"\"\n        Set up the methods, integration responses and method responses for a given API Gateway resource.\n        \"\"\"\n        for method_name in self.http_methods:\n            method = troposphere.apigateway.Method(method_name + str(depth))\n            method.RestApiId = troposphere.Ref(restapi)\n            if type(resource) is troposphere.apigateway.Resource:\n                method.ResourceId = troposphere.Ref(resource)\n            else:\n                method.ResourceId = resource\n            method.HttpMethod = method_name.upper()\n            method.AuthorizationType = authorization_type\n            if authorizer_resource:\n                method.AuthorizerId = troposphere.Ref(authorizer_resource)\n            method.ApiKeyRequired = api_key_required\n            method.MethodResponses = []\n            self.cf_template.add_resource(method)\n            self.cf_api_resources.append(method.title)\n\n            if not self.credentials_arn:\n                self.get_credentials_arn()\n            credentials = self.credentials_arn  # This must be a Role ARN\n\n            integration = troposphere.apigateway.Integration()\n            integration.CacheKeyParameters = []\n            integration.CacheNamespace = 'none'\n            integration.Credentials = credentials\n            integration.IntegrationHttpMethod = 'POST'\n            integration.IntegrationResponses = []\n            integration.PassthroughBehavior = 'NEVER'\n            integration.Type = 'AWS_PROXY'\n            integration.Uri = uri\n            method.Integration = integration"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the methods integration responses and method responses for a given API Gateway resource.", "response": "def create_and_setup_cors(self, restapi, resource, uri, depth, config):\n        \"\"\"\n        Set up the methods, integration responses and method responses for a given API Gateway resource.\n        \"\"\"\n        if config is True:\n            config = {}\n        method_name = \"OPTIONS\"\n        method = troposphere.apigateway.Method(method_name + str(depth))\n        method.RestApiId = troposphere.Ref(restapi)\n        if type(resource) is troposphere.apigateway.Resource:\n            method.ResourceId = troposphere.Ref(resource)\n        else:\n            method.ResourceId = resource\n        method.HttpMethod = method_name.upper()\n        method.AuthorizationType = \"NONE\"\n        method_response = troposphere.apigateway.MethodResponse()\n        method_response.ResponseModels = {\n            \"application/json\": \"Empty\"\n        }\n        response_headers = {\n            \"Access-Control-Allow-Headers\": \"'%s'\" % \",\".join(config.get(\n                \"allowed_headers\", [\"Content-Type\", \"X-Amz-Date\",\n                                    \"Authorization\", \"X-Api-Key\",\n                                    \"X-Amz-Security-Token\"])),\n            \"Access-Control-Allow-Methods\": \"'%s'\" % \",\".join(config.get(\n                \"allowed_methods\", [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"])),\n            \"Access-Control-Allow-Origin\": \"'%s'\" % config.get(\n                \"allowed_origin\", \"*\")\n        }\n        method_response.ResponseParameters = {\n            \"method.response.header.%s\" % key: True for key in response_headers\n        }\n        method_response.StatusCode = \"200\"\n        method.MethodResponses = [\n            method_response\n        ]\n        self.cf_template.add_resource(method)\n        self.cf_api_resources.append(method.title)\n\n        integration = troposphere.apigateway.Integration()\n        integration.Type = 'MOCK'\n        integration.PassthroughBehavior = 'NEVER'\n        integration.RequestTemplates = {\n            \"application/json\": \"{\\\"statusCode\\\": 200}\"\n        }\n        integration_response = troposphere.apigateway.IntegrationResponse()\n        integration_response.ResponseParameters = {\n            \"method.response.header.%s\" % key: value for key, value in response_headers.items()\n        }\n        integration_response.ResponseTemplates = {\n            \"application/json\": \"\"\n        }\n        integration_response.StatusCode = \"200\"\n        integration.IntegrationResponses = [\n            integration_response\n        ]\n\n        integration.Uri = uri\n        method.Integration = integration"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeploys the API Gateway to Amazon.", "response": "def deploy_api_gateway( self,\n                            api_id,\n                            stage_name,\n                            stage_description=\"\",\n                            description=\"\",\n                            cache_cluster_enabled=False,\n                            cache_cluster_size='0.5',\n                            variables=None,\n                            cloudwatch_log_level='OFF',\n                            cloudwatch_data_trace=False,\n                            cloudwatch_metrics_enabled=False,\n                            cache_cluster_ttl=300,\n                            cache_cluster_encrypted=False\n                        ):\n        \"\"\"\n        Deploy the API Gateway!\n\n        Return the deployed API URL.\n        \"\"\"\n        print(\"Deploying API Gateway..\")\n\n        self.apigateway_client.create_deployment(\n            restApiId=api_id,\n            stageName=stage_name,\n            stageDescription=stage_description,\n            description=description,\n            cacheClusterEnabled=cache_cluster_enabled,\n            cacheClusterSize=cache_cluster_size,\n            variables=variables or {}\n        )\n\n        if cloudwatch_log_level not in self.cloudwatch_log_levels:\n            cloudwatch_log_level = 'OFF'\n\n        self.apigateway_client.update_stage(\n            restApiId=api_id,\n            stageName=stage_name,\n            patchOperations=[\n                self.get_patch_op('logging/loglevel', cloudwatch_log_level),\n                self.get_patch_op('logging/dataTrace', cloudwatch_data_trace),\n                self.get_patch_op('metrics/enabled', cloudwatch_metrics_enabled),\n                self.get_patch_op('caching/ttlInSeconds', str(cache_cluster_ttl)),\n                self.get_patch_op('caching/dataEncrypted', cache_cluster_encrypted)\n            ]\n        )\n\n        return \"https://{}.execute-api.{}.amazonaws.com/{}\".format(api_id, self.boto_session.region_name, stage_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_binary_support(self, api_id, cors=False):\n        response = self.apigateway_client.get_rest_api(\n            restApiId=api_id\n        )\n        if \"binaryMediaTypes\" in response and \"*/*\" in response[\"binaryMediaTypes\"]:\n            self.apigateway_client.update_rest_api(\n                restApiId=api_id,\n                patchOperations=[\n                    {\n                        'op': 'remove',\n                        'path': '/binaryMediaTypes/*~1*'\n                    }\n                ]\n            )\n        if cors:\n            # go through each resource and change the contentHandling type\n            response = self.apigateway_client.get_resources(restApiId=api_id)\n            resource_ids = [\n                item['id'] for item in response['items']\n                if 'OPTIONS' in item.get('resourceMethods', {})\n            ]\n\n            for resource_id in resource_ids:\n                self.apigateway_client.update_integration(\n                    restApiId=api_id,\n                    resourceId=resource_id,\n                    httpMethod='OPTIONS',\n                    patchOperations=[\n                        {\n                            \"op\": \"replace\",\n                            \"path\": \"/contentHandling\",\n                            \"value\": \"\"\n                        }\n                    ]\n                )", "response": "Remove binary support from API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds Rest API compression", "response": "def add_api_compression(self, api_id, min_compression_size):\n        \"\"\"\n        Add Rest API compression\n        \"\"\"\n        self.apigateway_client.update_rest_api(\n            restApiId=api_id,\n            patchOperations=[\n                {\n                    'op': 'replace',\n                    'path': '/minimumCompressionSize',\n                    'value': str(min_compression_size)\n                }\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_api_keys(self, api_id, stage_name):\n        response = self.apigateway_client.get_api_keys(limit=500)\n        stage_key = '{}/{}'.format(api_id, stage_name)\n        for api_key in response.get('items'):\n            if stage_key in api_key.get('stageKeys'):\n                yield api_key.get('id')", "response": "Generator that yields per API key associated to an API ID and stage name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_api_key(self, api_id, stage_name):\n        response = self.apigateway_client.create_api_key(\n            name='{}_{}'.format(stage_name, api_id),\n            description='Api Key for {}'.format(api_id),\n            enabled=True,\n            stageKeys=[\n                {\n                    'restApiId': '{}'.format(api_id),\n                    'stageName': '{}'.format(stage_name)\n                },\n            ]\n        )\n        print('Created a new x-api-key: {}'.format(response['id']))", "response": "Create new API key and link it with an api_id and a stage_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a generated API key for api_id and stage_name.", "response": "def remove_api_key(self, api_id, stage_name):\n        \"\"\"\n        Remove a generated API key for api_id and stage_name\n        \"\"\"\n        response = self.apigateway_client.get_api_keys(\n            limit=1,\n            nameQuery='{}_{}'.format(stage_name, api_id)\n        )\n        for api_key in response.get('items'):\n            self.apigateway_client.delete_api_key(\n                apiKey=\"{}\".format(api_key['id'])\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds api stage to Api key", "response": "def add_api_stage_to_api_key(self, api_key, api_id, stage_name):\n        \"\"\"\n        Add api stage to Api key\n        \"\"\"\n        self.apigateway_client.update_api_key(\n            apiKey=api_key,\n            patchOperations=[\n                {\n                    'op': 'add',\n                    'path': '/stages',\n                    'value': '{}/{}'.format(api_id, stage_name)\n                }\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_patch_op(self, keypath, value, op='replace'):\n        if isinstance(value, bool):\n            value = str(value).lower()\n        return {'op': op, 'path': '/*/*/{}'.format(keypath), 'value': value}", "response": "Get a patch operation that will be applied on all available HTTP methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a deployed REST API Gateway.", "response": "def undeploy_api_gateway(self, lambda_name, domain_name=None, base_path=None):\n        \"\"\"\n        Delete a deployed REST API Gateway.\n        \"\"\"\n        print(\"Deleting API Gateway..\")\n\n        api_id = self.get_api_id(lambda_name)\n\n        if domain_name:\n\n            # XXX - Remove Route53 smartly here?\n            # XXX - This doesn't raise, but doesn't work either.\n\n            try:\n                self.apigateway_client.delete_base_path_mapping(\n                    domainName=domain_name,\n                    basePath='(none)' if base_path is None else base_path\n                )\n            except Exception as e:\n                # We may not have actually set up the domain.\n                pass\n\n        was_deleted = self.delete_stack(lambda_name, wait=True)\n\n        if not was_deleted:\n            # try erasing it with the older method\n            for api in self.get_rest_apis(lambda_name):\n                self.apigateway_client.delete_rest_api(\n                    restApiId=api['id']\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate CloudWatch metrics configuration for a given stage.", "response": "def update_stage_config(    self,\n                                project_name,\n                                stage_name,\n                                cloudwatch_log_level,\n                                cloudwatch_data_trace,\n                                cloudwatch_metrics_enabled\n                            ):\n        \"\"\"\n        Update CloudWatch metrics configuration.\n        \"\"\"\n        if cloudwatch_log_level not in self.cloudwatch_log_levels:\n            cloudwatch_log_level = 'OFF'\n\n        for api in self.get_rest_apis(project_name):\n            self.apigateway_client.update_stage(\n                restApiId=api['id'],\n                stageName=stage_name,\n                patchOperations=[\n                    self.get_patch_op('logging/loglevel', cloudwatch_log_level),\n                    self.get_patch_op('logging/dataTrace', cloudwatch_data_trace),\n                    self.get_patch_op('metrics/enabled', cloudwatch_metrics_enabled),\n                ]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the CF stack managed by Zappa.", "response": "def delete_stack(self, name, wait=False):\n        \"\"\"\n        Delete the CF stack managed by Zappa.\n        \"\"\"\n        try:\n            stack = self.cf_client.describe_stacks(StackName=name)['Stacks'][0]\n        except: # pragma: no cover\n            print('No Zappa stack named {0}'.format(name))\n            return False\n\n        tags = {x['Key']:x['Value'] for x in stack['Tags']}\n        if tags.get('ZappaProject') == name:\n            self.cf_client.delete_stack(StackName=name)\n            if wait:\n                waiter = self.cf_client.get_waiter('stack_delete_complete')\n                print('Waiting for stack {0} to be deleted..'.format(name))\n                waiter.wait(StackName=name)\n            return True\n        else:\n            print('ZappaProject tag not found on {0}, doing nothing'.format(name))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new CF stack template.", "response": "def create_stack_template(  self,\n                                lambda_arn,\n                                lambda_name,\n                                api_key_required,\n                                iam_authorization,\n                                authorizer,\n                                cors_options=None,\n                                description=None,\n                                endpoint_configuration=None\n                            ):\n        \"\"\"\n        Build the entire CF stack.\n        Just used for the API Gateway, but could be expanded in the future.\n        \"\"\"\n\n        auth_type = \"NONE\"\n        if iam_authorization and authorizer:\n            logger.warn(\"Both IAM Authorization and Authorizer are specified, this is not possible. \"\n                        \"Setting Auth method to IAM Authorization\")\n            authorizer = None\n            auth_type = \"AWS_IAM\"\n        elif iam_authorization:\n            auth_type = \"AWS_IAM\"\n        elif authorizer:\n            auth_type = authorizer.get(\"type\", \"CUSTOM\")\n\n        # build a fresh template\n        self.cf_template = troposphere.Template()\n        self.cf_template.add_description('Automatically generated with Zappa')\n        self.cf_api_resources = []\n        self.cf_parameters = {}\n\n        restapi = self.create_api_gateway_routes(\n                                            lambda_arn,\n                                            api_name=lambda_name,\n                                            api_key_required=api_key_required,\n                                            authorization_type=auth_type,\n                                            authorizer=authorizer,\n                                            cors_options=cors_options,\n                                            description=description,\n                                            endpoint_configuration=endpoint_configuration\n                                        )\n        return self.cf_template"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_stack(self, name, working_bucket, wait=False, update_only=False, disable_progress=False):\n        capabilities = []\n\n        template = name + '-template-' + str(int(time.time())) + '.json'\n        with open(template, 'wb') as out:\n            out.write(bytes(self.cf_template.to_json(indent=None, separators=(',',':')), \"utf-8\"))\n\n        self.upload_to_s3(template, working_bucket, disable_progress=disable_progress)\n        if self.boto_session.region_name == \"us-gov-west-1\":\n            url = 'https://s3-us-gov-west-1.amazonaws.com/{0}/{1}'.format(working_bucket, template)\n        else:\n            url = 'https://s3.amazonaws.com/{0}/{1}'.format(working_bucket, template)\n\n        tags = [{'Key': key, 'Value': self.tags[key]}\n                for key in self.tags.keys()\n                if key != 'ZappaProject']\n        tags.append({'Key':'ZappaProject','Value':name})\n        update = True\n\n        try:\n            self.cf_client.describe_stacks(StackName=name)\n        except botocore.client.ClientError:\n            update = False\n\n        if update_only and not update:\n            print('CloudFormation stack missing, re-deploy to enable updates')\n            return\n\n        if not update:\n            self.cf_client.create_stack(StackName=name,\n                                        Capabilities=capabilities,\n                                        TemplateURL=url,\n                                        Tags=tags)\n            print('Waiting for stack {0} to create (this can take a bit)..'.format(name))\n        else:\n            try:\n                self.cf_client.update_stack(StackName=name,\n                                            Capabilities=capabilities,\n                                            TemplateURL=url,\n                                            Tags=tags)\n                print('Waiting for stack {0} to update..'.format(name))\n            except botocore.client.ClientError as e:\n                if e.response['Error']['Message'] == 'No updates are to be performed.':\n                    wait = False\n                else:\n                    raise\n\n        if wait:\n            total_resources = len(self.cf_template.resources)\n            current_resources = 0\n            sr = self.cf_client.get_paginator('list_stack_resources')\n            progress = tqdm(total=total_resources, unit='res', disable=disable_progress)\n            while True:\n                time.sleep(3)\n                result = self.cf_client.describe_stacks(StackName=name)\n                if not result['Stacks']:\n                    continue  # might need to wait a bit\n\n                if result['Stacks'][0]['StackStatus'] in ['CREATE_COMPLETE', 'UPDATE_COMPLETE']:\n                    break\n\n                # Something has gone wrong.\n                # Is raising enough? Should we also remove the Lambda function?\n                if result['Stacks'][0]['StackStatus'] in [\n                                                            'DELETE_COMPLETE',\n                                                            'DELETE_IN_PROGRESS',\n                                                            'ROLLBACK_IN_PROGRESS',\n                                                            'UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS',\n                                                            'UPDATE_ROLLBACK_COMPLETE'\n                                                        ]:\n                    raise EnvironmentError(\"Stack creation failed. \"\n                                           \"Please check your CloudFormation console. \"\n                                           \"You may also need to `undeploy`.\")\n\n                count = 0\n                for result in sr.paginate(StackName=name):\n                    done = (1 for x in result['StackResourceSummaries']\n                            if 'COMPLETE' in x['ResourceStatus'])\n                    count += sum(done)\n                if count:\n                    # We can end up in a situation where we have more resources being created\n                    # than anticipated.\n                    if (count - current_resources) > 0:\n                        progress.update(count - current_resources)\n                current_resources = count\n            progress.close()\n\n        try:\n            os.remove(template)\n        except OSError:\n            pass\n\n        self.remove_from_s3(template, working_bucket)", "response": "Update or create the CF stack managed by Zappa."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a name describes CloudFront stacks and returns dict of the stack Outputs", "response": "def stack_outputs(self, name):\n        \"\"\"\n        Given a name, describes CloudFront stacks and returns dict of the stack Outputs\n        , else returns an empty dict.\n        \"\"\"\n        try:\n            stack = self.cf_client.describe_stacks(StackName=name)['Stacks'][0]\n            return {x['OutputKey']: x['OutputValue'] for x in stack['Outputs']}\n        except botocore.client.ClientError:\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a lambda_name and stage_name return a valid API URL.", "response": "def get_api_url(self, lambda_name, stage_name):\n        \"\"\"\n        Given a lambda_name and stage_name, return a valid API URL.\n        \"\"\"\n        api_id = self.get_api_id(lambda_name)\n        if api_id:\n            return \"https://{}.execute-api.{}.amazonaws.com/{}\".format(api_id, self.boto_session.region_name, stage_name)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the API ID for a given lambda name.", "response": "def get_api_id(self, lambda_name):\n        \"\"\"\n        Given a lambda_name, return the API id.\n        \"\"\"\n        try:\n            response = self.cf_client.describe_stack_resource(StackName=lambda_name,\n                                                              LogicalResourceId='Api')\n            return response['StackResourceDetail'].get('PhysicalResourceId', None)\n        except: # pragma: no cover\n            try:\n                # Try the old method (project was probably made on an older, non CF version)\n                response = self.apigateway_client.get_rest_apis(limit=500)\n\n                for item in response['items']:\n                    if item['name'] == lambda_name:\n                        return item['id']\n\n                logger.exception('Could not get API ID.')\n                return None\n            except: # pragma: no cover\n                # We don't even have an API deployed. That's okay!\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the API GW domain and returns the resulting DNS name.", "response": "def create_domain_name(self,\n                           domain_name,\n                           certificate_name,\n                           certificate_body=None,\n                           certificate_private_key=None,\n                           certificate_chain=None,\n                           certificate_arn=None,\n                           lambda_name=None,\n                           stage=None,\n                           base_path=None):\n        \"\"\"\n        Creates the API GW domain and returns the resulting DNS name.\n        \"\"\"\n\n        # This is a Let's Encrypt or custom certificate\n        if not certificate_arn:\n            agw_response = self.apigateway_client.create_domain_name(\n                domainName=domain_name,\n                certificateName=certificate_name,\n                certificateBody=certificate_body,\n                certificatePrivateKey=certificate_private_key,\n                certificateChain=certificate_chain\n            )\n        # This is an AWS ACM-hosted Certificate\n        else:\n            agw_response = self.apigateway_client.create_domain_name(\n                domainName=domain_name,\n                certificateName=certificate_name,\n                certificateArn=certificate_arn\n            )\n\n        api_id = self.get_api_id(lambda_name)\n        if not api_id:\n            raise LookupError(\"No API URL to certify found - did you deploy?\")\n\n        self.apigateway_client.create_base_path_mapping(\n            domainName=domain_name,\n            basePath='' if base_path is None else base_path,\n            restApiId=api_id,\n            stage=stage\n        )\n\n        return agw_response['distributionDomainName']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates Route53 Records following GW domain creation.", "response": "def update_route53_records(self, domain_name, dns_name):\n        \"\"\"\n        Updates Route53 Records following GW domain creation\n        \"\"\"\n        zone_id = self.get_hosted_zone_id_for_domain(domain_name)\n\n        is_apex = self.route53.get_hosted_zone(Id=zone_id)['HostedZone']['Name'][:-1] == domain_name\n        if is_apex:\n            record_set = {\n                'Name': domain_name,\n                'Type': 'A',\n                'AliasTarget': {\n                    'HostedZoneId': 'Z2FDTNDATAQYW2', # This is a magic value that means \"CloudFront\"\n                    'DNSName': dns_name,\n                    'EvaluateTargetHealth': False\n                }\n            }\n        else:\n            record_set = {\n                'Name': domain_name,\n                'Type': 'CNAME',\n                'ResourceRecords': [\n                    {\n                        'Value': dns_name\n                    }\n                ],\n                'TTL': 60\n            }\n\n        # Related: https://github.com/boto/boto3/issues/157\n        # and: http://docs.aws.amazon.com/Route53/latest/APIReference/CreateAliasRRSAPI.html\n        # and policy: https://spin.atomicobject.com/2016/04/28/route-53-hosted-zone-managment/\n        # pure_zone_id = zone_id.split('/hostedzone/')[1]\n\n        # XXX: ClientError: An error occurred (InvalidChangeBatch) when calling the ChangeResourceRecordSets operation:\n        # Tried to create an alias that targets d1awfeji80d0k2.cloudfront.net., type A in zone Z1XWOQP59BYF6Z,\n        # but the alias target name does not lie within the target zone\n        response = self.route53.change_resource_record_sets(\n            HostedZoneId=zone_id,\n            ChangeBatch={\n                'Changes': [\n                    {\n                        'Action': 'UPSERT',\n                        'ResourceRecordSet': record_set\n                    }\n                ]\n            }\n        )\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_domain_name(self,\n                           domain_name,\n                           certificate_name=None,\n                           certificate_body=None,\n                           certificate_private_key=None,\n                           certificate_chain=None,\n                           certificate_arn=None,\n                           lambda_name=None,\n                           stage=None,\n                           route53=True,\n                           base_path=None):\n        \"\"\"\n        This updates your certificate information for an existing domain,\n        with similar arguments to boto's update_domain_name API Gateway api.\n\n        It returns the resulting new domain information including the new certificate's ARN\n        if created during this process.\n\n        Previously, this method involved downtime that could take up to 40 minutes\n        because the API Gateway api only allowed this by deleting, and then creating it.\n\n        Related issues:     https://github.com/Miserlou/Zappa/issues/590\n                            https://github.com/Miserlou/Zappa/issues/588\n                            https://github.com/Miserlou/Zappa/pull/458\n                            https://github.com/Miserlou/Zappa/issues/882\n                            https://github.com/Miserlou/Zappa/pull/883\n        \"\"\"\n\n        print(\"Updating domain name!\")\n\n        certificate_name = certificate_name + str(time.time())\n\n        api_gateway_domain = self.apigateway_client.get_domain_name(domainName=domain_name)\n        if not certificate_arn\\\n           and certificate_body and certificate_private_key and certificate_chain:\n            acm_certificate = self.acm_client.import_certificate(Certificate=certificate_body,\n                                                                 PrivateKey=certificate_private_key,\n                                                                 CertificateChain=certificate_chain)\n            certificate_arn = acm_certificate['CertificateArn']\n\n        self.update_domain_base_path_mapping(domain_name, lambda_name, stage, base_path)\n\n        return self.apigateway_client.update_domain_name(domainName=domain_name,\n                                                         patchOperations=[\n                                                             {\"op\" : \"replace\",\n                                                              \"path\" : \"/certificateName\",\n                                                              \"value\" : certificate_name},\n                                                             {\"op\" : \"replace\",\n                                                              \"path\" : \"/certificateArn\",\n                                                              \"value\" : certificate_arn}\n                                                         ])", "response": "This method updates the certificate name and base path mapping for an existing domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate base path mapping on API Gateway if it was changed", "response": "def update_domain_base_path_mapping(self, domain_name, lambda_name, stage, base_path):\n        \"\"\"\n        Update domain base path mapping on API Gateway if it was changed\n        \"\"\"\n        api_id = self.get_api_id(lambda_name)\n        if not api_id:\n            print(\"Warning! Can't update base path mapping!\")\n            return\n        base_path_mappings = self.apigateway_client.get_base_path_mappings(domainName=domain_name)\n        found = False\n        for base_path_mapping in base_path_mappings.get('items', []):\n            if base_path_mapping['restApiId'] == api_id and base_path_mapping['stage'] == stage:\n                found = True\n                if base_path_mapping['basePath'] != base_path:\n                    self.apigateway_client.update_base_path_mapping(domainName=domain_name,\n                                                                    basePath=base_path_mapping['basePath'],\n                                                                    patchOperations=[\n                                                                        {\"op\" : \"replace\",\n                                                                         \"path\" : \"/basePath\",\n                                                                         \"value\" : '' if base_path is None else base_path}\n                                                                    ])\n        if not found:\n            self.apigateway_client.create_base_path_mapping(\n                domainName=domain_name,\n                basePath='' if base_path is None else base_path,\n                restApiId=api_id,\n                stage=stage\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_zones(self):\n        zones = {'HostedZones': []}\n\n        new_zones = self.route53.list_hosted_zones(MaxItems='100')\n        while new_zones['IsTruncated']:\n            zones['HostedZones'] += new_zones['HostedZones']\n            new_zones = self.route53.list_hosted_zones(Marker=new_zones['NextMarker'], MaxItems='100')\n\n        zones['HostedZones'] += new_zones['HostedZones']\n        return zones", "response": "Same behaviour of list_host_zones but transparently handling pagination."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the domain name from the API Gateway.", "response": "def get_domain_name(self, domain_name, route53=True):\n        \"\"\"\n        Scan our hosted zones for the record of a given name.\n\n        Returns the record entry, else None.\n\n        \"\"\"\n        # Make sure api gateway domain is present\n        try:\n            self.apigateway_client.get_domain_name(domainName=domain_name)\n        except Exception:\n            return None\n\n        if not route53:\n            return True\n\n        try:\n            zones = self.get_all_zones()\n            for zone in zones['HostedZones']:\n                records = self.route53.list_resource_record_sets(HostedZoneId=zone['Id'])\n                for record in records['ResourceRecordSets']:\n                    if record['Type'] in ('CNAME', 'A') and record['Name'][:-1] == domain_name:\n                        return record\n\n        except Exception as e:\n            return None\n\n        ##\n        # Old, automatic logic.\n        # If re-introduced, should be moved to a new function.\n        # Related ticket: https://github.com/Miserlou/Zappa/pull/458\n        ##\n\n        # We may be in a position where Route53 doesn't have a domain, but the API Gateway does.\n        # We need to delete this before we can create the new Route53.\n        # try:\n        #     api_gateway_domain = self.apigateway_client.get_domain_name(domainName=domain_name)\n        #     self.apigateway_client.delete_domain_name(domainName=domain_name)\n        # except Exception:\n        #     pass\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_credentials_arn(self):\n        role = self.iam.Role(self.role_name)\n        self.credentials_arn = role.arn\n        return role, self.credentials_arn", "response": "Get and set the credentials_arn."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_iam_roles(self):\n        attach_policy_obj = json.loads(self.attach_policy)\n        assume_policy_obj = json.loads(self.assume_policy)\n\n        if self.extra_permissions:\n            for permission in self.extra_permissions:\n                attach_policy_obj['Statement'].append(dict(permission))\n            self.attach_policy = json.dumps(attach_policy_obj)\n\n        updated = False\n\n        # Create the role if needed\n        try:\n            role, credentials_arn = self.get_credentials_arn()\n\n        except botocore.client.ClientError:\n            print(\"Creating \" + self.role_name + \" IAM Role..\")\n\n            role = self.iam.create_role(\n                RoleName=self.role_name,\n                AssumeRolePolicyDocument=self.assume_policy\n            )\n            self.credentials_arn = role.arn\n            updated = True\n\n        # create or update the role's policies if needed\n        policy = self.iam.RolePolicy(self.role_name, 'zappa-permissions')\n        try:\n            if policy.policy_document != attach_policy_obj:\n                print(\"Updating zappa-permissions policy on \" + self.role_name + \" IAM Role.\")\n\n                policy.put(PolicyDocument=self.attach_policy)\n                updated = True\n\n        except botocore.client.ClientError:\n            print(\"Creating zappa-permissions policy on \" + self.role_name + \" IAM Role.\")\n            policy.put(PolicyDocument=self.attach_policy)\n            updated = True\n\n        if role.assume_role_policy_document != assume_policy_obj and \\\n                set(role.assume_role_policy_document['Statement'][0]['Principal']['Service']) != set(assume_policy_obj['Statement'][0]['Principal']['Service']):\n            print(\"Updating assume role policy on \" + self.role_name + \" IAM Role.\")\n            self.iam_client.update_assume_role_policy(\n                RoleName=self.role_name,\n                PolicyDocument=self.assume_policy\n            )\n            updated = True\n\n        return self.credentials_arn, updated", "response": "Create and defines the IAM roles and policies necessary for Zappa."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _clear_policy(self, lambda_name):\n        try:\n            policy_response = self.lambda_client.get_policy(\n                FunctionName=lambda_name\n            )\n            if policy_response['ResponseMetadata']['HTTPStatusCode'] == 200:\n                statement = json.loads(policy_response['Policy'])['Statement']\n                for s in statement:\n                    delete_response = self.lambda_client.remove_permission(\n                        FunctionName=lambda_name,\n                        StatementId=s['Sid']\n                    )\n                    if delete_response['ResponseMetadata']['HTTPStatusCode'] != 204:\n                        logger.error('Failed to delete an obsolete policy statement: {}'.format(policy_response))\n            else:\n                logger.debug('Failed to load Lambda function policy: {}'.format(policy_response))\n        except ClientError as e:\n            if e.args[0].find('ResourceNotFoundException') > -1:\n                logger.debug('No policy found, must be first run.')\n            else:\n                logger.error('Unexpected client error {}'.format(e.args[0]))", "response": "Remove obsolete policy statements to prevent policy from bloating over the limit after repeated updates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_event_permission(self, lambda_name, principal, source_arn):\n        logger.debug('Adding new permission to invoke Lambda function: {}'.format(lambda_name))\n        permission_response = self.lambda_client.add_permission(\n            FunctionName=lambda_name,\n            StatementId=''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)),\n            Action='lambda:InvokeFunction',\n            Principal=principal,\n            SourceArn=source_arn,\n        )\n\n        if permission_response['ResponseMetadata']['HTTPStatusCode'] != 201:\n            print('Problem creating permission to invoke Lambda function')\n            return None  # XXX: Raise?\n\n        return permission_response", "response": "Create permission to link to an event."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a Lambda ARN name and a list of events schedule this as CloudWatch Events.", "response": "def schedule_events(self, lambda_arn, lambda_name, events, default=True):\n        \"\"\"\n        Given a Lambda ARN, name and a list of events, schedule this as CloudWatch Events.\n\n        'events' is a list of dictionaries, where the dict must contains the string\n        of a 'function' and the string of the event 'expression', and an optional 'name' and 'description'.\n\n        Expressions can be in rate or cron format:\n            http://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html\n        \"\"\"\n\n        # The stream sources - DynamoDB, Kinesis and SQS - are working differently than the other services (pull vs push)\n        # and do not require event permissions. They do require additional permissions on the Lambda roles though.\n        # http://docs.aws.amazon.com/lambda/latest/dg/lambda-api-permissions-ref.html\n        pull_services = ['dynamodb', 'kinesis', 'sqs']\n\n        # XXX: Not available in Lambda yet.\n        # We probably want to execute the latest code.\n        # if default:\n        #     lambda_arn = lambda_arn + \":$LATEST\"\n\n        self.unschedule_events(lambda_name=lambda_name, lambda_arn=lambda_arn, events=events,\n                               excluded_source_services=pull_services)\n        for event in events:\n            function = event['function']\n            expression = event.get('expression', None) # single expression\n            expressions = event.get('expressions', None) # multiple expression\n            kwargs = event.get('kwargs', {}) # optional dict of keyword arguments for the event\n            event_source = event.get('event_source', None)\n            description = event.get('description', function)\n\n            #   - If 'cron' or 'rate' in expression, use ScheduleExpression\n            #   - Else, use EventPattern\n            #       - ex https://github.com/awslabs/aws-lambda-ddns-function\n\n            if not self.credentials_arn:\n                self.get_credentials_arn()\n\n            if expression:\n                expressions = [expression] # same code for single and multiple expression\n\n            if expressions:\n                for index, expression in enumerate(expressions):\n                    name = self.get_scheduled_event_name(event, function, lambda_name, index)\n                    # if it's possible that we truncated name, generate a unique, shortened name\n                    # https://github.com/Miserlou/Zappa/issues/970\n                    if len(name) >= 64:\n                        rule_name = self.get_hashed_rule_name(event, function, lambda_name)\n                    else:\n                        rule_name = name\n\n                    rule_response = self.events_client.put_rule(\n                        Name=rule_name,\n                        ScheduleExpression=expression,\n                        State='ENABLED',\n                        Description=description,\n                        RoleArn=self.credentials_arn\n                    )\n\n                    if 'RuleArn' in rule_response:\n                        logger.debug('Rule created. ARN {}'.format(rule_response['RuleArn']))\n\n                    # Specific permissions are necessary for any trigger to work.\n                    self.create_event_permission(lambda_name, 'events.amazonaws.com', rule_response['RuleArn'])\n\n                    # Overwriting the input, supply the original values and add kwargs\n                    input_template = '{\"time\": <time>, ' \\\n                                     '\"detail-type\": <detail-type>, ' \\\n                                     '\"source\": <source>,' \\\n                                     '\"account\": <account>, ' \\\n                                     '\"region\": <region>,' \\\n                                     '\"detail\": <detail>, ' \\\n                                     '\"version\": <version>,' \\\n                                     '\"resources\": <resources>,' \\\n                                     '\"id\": <id>,' \\\n                                     '\"kwargs\": %s' \\\n                                     '}' % json.dumps(kwargs)\n\n                    # Create the CloudWatch event ARN for this function.\n                    # https://github.com/Miserlou/Zappa/issues/359\n                    target_response = self.events_client.put_targets(\n                        Rule=rule_name,\n                        Targets=[\n                            {\n                                'Id': 'Id' + ''.join(random.choice(string.digits) for _ in range(12)),\n                                'Arn': lambda_arn,\n                                'InputTransformer': {\n                                    'InputPathsMap': {\n                                        'time': '$.time',\n                                        'detail-type': '$.detail-type',\n                                        'source': '$.source',\n                                        'account': '$.account',\n                                        'region': '$.region',\n                                        'detail': '$.detail',\n                                        'version': '$.version',\n                                        'resources': '$.resources',\n                                        'id': '$.id'\n                                    },\n                                    'InputTemplate': input_template\n                                }\n                            }\n                        ]\n                    )\n\n                    if target_response['ResponseMetadata']['HTTPStatusCode'] == 200:\n                        print(\"Scheduled {} with expression {}!\".format(rule_name, expression))\n                    else:\n                        print(\"Problem scheduling {} with expression {}.\".format(rule_name, expression))\n\n            elif event_source:\n                service = self.service_from_arn(event_source['arn'])\n\n                if service not in pull_services:\n                    svc = ','.join(event['event_source']['events'])\n                    self.create_event_permission(\n                        lambda_name,\n                        service + '.amazonaws.com',\n                        event['event_source']['arn']\n                    )\n                else:\n                    svc = service\n\n                rule_response = add_event_source(\n                    event_source,\n                    lambda_arn,\n                    function,\n                    self.boto_session\n                )\n\n                if rule_response == 'successful':\n                    print(\"Created {} event schedule for {}!\".format(svc, function))\n                elif rule_response == 'failed':\n                    print(\"Problem creating {} event schedule for {}!\".format(svc, function))\n                elif rule_response == 'exists':\n                    print(\"{} event schedule for {} already exists - Nothing to do here.\".format(svc, function))\n                elif rule_response == 'dryrun':\n                    print(\"Dryrun for creating {} event schedule for {}!!\".format(svc, function))\n            else:\n                print(\"Could not create event {} - Please define either an expression or an event source\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_event_name(lambda_name, name):\n        return '{prefix:.{width}}-{postfix}'.format(prefix=lambda_name, width=max(0, 63 - len(name)), postfix=name)[:64]", "response": "Returns an AWS - valid Lambda event name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_hashed_rule_name(event, function, lambda_name):\n        event_name = event.get('name', function)\n        name_hash = hashlib.sha1('{}-{}'.format(lambda_name, event_name).encode('UTF-8')).hexdigest()\n        return Zappa.get_event_name(name_hash, function)", "response": "Returns an AWS - valid CloudWatch rule name using a hash of the event name lambda name and function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a CWE rule.", "response": "def delete_rule(self, rule_name):\n        \"\"\"\n        Delete a CWE rule.\n\n        This  deletes them, but they will still show up in the AWS console.\n        Annoying.\n\n        \"\"\"\n        logger.debug('Deleting existing rule {}'.format(rule_name))\n\n        # All targets must be removed before\n        # we can actually delete the rule.\n        try:\n            targets = self.events_client.list_targets_by_rule(Rule=rule_name)\n        except botocore.exceptions.ClientError as e:\n            # This avoids misbehavior if low permissions, related: https://github.com/Miserlou/Zappa/issues/286\n            error_code = e.response['Error']['Code']\n            if error_code == 'AccessDeniedException':\n                raise\n            else:\n                logger.debug('No target found for this rule: {} {}'.format(rule_name, e.args[0]))\n                return\n\n        if 'Targets' in targets and targets['Targets']:\n            self.events_client.remove_targets(Rule=rule_name, Ids=[x['Id'] for x in targets['Targets']])\n        else:  # pragma: no cover\n            logger.debug('No target to delete')\n\n        # Delete our rule.\n        self.events_client.delete_rule(Name=rule_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all of the rule names associated with a lambda function.", "response": "def get_event_rule_names_for_lambda(self, lambda_arn):\n        \"\"\"\n        Get all of the rule names associated with a lambda function.\n        \"\"\"\n        response = self.events_client.list_rule_names_by_target(TargetArn=lambda_arn)\n        rule_names = response['RuleNames']\n        # Iterate when the results are paginated\n        while 'NextToken' in response:\n            response = self.events_client.list_rule_names_by_target(TargetArn=lambda_arn,\n                                                                    NextToken=response['NextToken'])\n            rule_names.extend(response['RuleNames'])\n        return rule_names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_event_rules_for_lambda(self, lambda_arn):\n        rule_names = self.get_event_rule_names_for_lambda(lambda_arn=lambda_arn)\n        return [self.events_client.describe_rule(Name=r) for r in rule_names]", "response": "Get all of the event rules associated with this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unschedule_events(self, events, lambda_arn=None, lambda_name=None, excluded_source_services=None):\n        excluded_source_services = excluded_source_services or []\n        \"\"\"\n        Given a list of events, unschedule these CloudWatch Events.\n\n        'events' is a list of dictionaries, where the dict must contains the string\n        of a 'function' and the string of the event 'expression', and an optional 'name' and 'description'.\n        \"\"\"\n        self._clear_policy(lambda_name)\n\n        rule_names = self.get_event_rule_names_for_lambda(lambda_arn=lambda_arn)\n        for rule_name in rule_names:\n            self.delete_rule(rule_name)\n            print('Unscheduled ' + rule_name + '.')\n\n        non_cwe = [e for e in events if 'event_source' in e]\n        for event in non_cwe:\n            # TODO: This WILL miss non CW events that have been deployed but changed names. Figure out a way to remove\n            # them no matter what.\n            # These are non CWE event sources.\n            function = event['function']\n            name = event.get('name', function)\n            event_source = event.get('event_source', function)\n            service = self.service_from_arn(event_source['arn'])\n            # DynamoDB and Kinesis streams take quite a while to setup after they are created and do not need to be\n            # re-scheduled when a new Lambda function is deployed. Therefore, they should not be removed during zappa\n            # update or zappa schedule.\n            if service not in excluded_source_services:\n                remove_event_source(\n                    event_source,\n                    lambda_arn,\n                    function,\n                    self.boto_session\n                )\n                print(\"Removed event {}{}.\".format(\n                        name,\n                        \" ({})\".format(str(event_source['events'])) if 'events' in event_source else '')\n                )", "response": "Given a list of events, unschedule these CloudWatch Events.\n\n        'events' is a list of dictionaries, where the dict must contains the string\n        of a 'function' and the string of the event 'expression', and an optional 'name' and 'description'."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the SNS - based async topic.", "response": "def create_async_sns_topic(self, lambda_name, lambda_arn):\n        \"\"\"\n        Create the SNS-based async topic.\n        \"\"\"\n        topic_name = get_topic_name(lambda_name)\n        # Create SNS topic\n        topic_arn = self.sns_client.create_topic(\n            Name=topic_name)['TopicArn']\n        # Create subscription\n        self.sns_client.subscribe(\n            TopicArn=topic_arn,\n            Protocol='lambda',\n            Endpoint=lambda_arn\n        )\n        # Add Lambda permission for SNS to invoke function\n        self.create_event_permission(\n            lambda_name=lambda_name,\n            principal='sns.amazonaws.com',\n            source_arn=topic_arn\n        )\n        # Add rule for SNS topic as a event source\n        add_event_source(\n            event_source={\n                \"arn\": topic_arn,\n                \"events\": [\"sns:Publish\"]\n            },\n            lambda_arn=lambda_arn,\n            target_function=\"zappa.asynchronous.route_task\",\n            boto_session=self.boto_session\n        )\n        return topic_arn"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the async SNS topic.", "response": "def remove_async_sns_topic(self, lambda_name):\n        \"\"\"\n        Remove the async SNS topic.\n        \"\"\"\n        topic_name = get_topic_name(lambda_name)\n        removed_arns = []\n        for sub in self.sns_client.list_subscriptions()['Subscriptions']:\n            if topic_name in sub['TopicArn']:\n                self.sns_client.delete_topic(TopicArn=sub['TopicArn'])\n                removed_arns.append(sub['TopicArn'])\n        return removed_arns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_async_dynamodb_table(self, table_name, read_capacity, write_capacity):\n        try:\n            dynamodb_table = self.dynamodb_client.describe_table(TableName=table_name)\n            return False, dynamodb_table\n\n        # catch this exception (triggered if the table doesn't exist)\n        except botocore.exceptions.ClientError:\n            dynamodb_table = self.dynamodb_client.create_table(\n                AttributeDefinitions=[\n                    {\n                        'AttributeName': 'id',\n                        'AttributeType': 'S'\n                    }\n                ],\n                TableName=table_name,\n                KeySchema=[\n                    {\n                        'AttributeName': 'id',\n                        'KeyType': 'HASH'\n                    },\n                ],\n                ProvisionedThroughput = {\n                    'ReadCapacityUnits': read_capacity,\n                    'WriteCapacityUnits': write_capacity\n                }\n            )\n            if dynamodb_table:\n                try:\n                    self._set_async_dynamodb_table_ttl(table_name)\n                except botocore.exceptions.ClientError:\n                    # this fails because the operation is async, so retry\n                    time.sleep(10)\n                    self._set_async_dynamodb_table_ttl(table_name)\n\n        return True, dynamodb_table", "response": "Create the DynamoDB table for async task return values"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches CloudWatch logs for a given Lambda name.", "response": "def fetch_logs(self, lambda_name, filter_pattern='', limit=10000, start_time=0):\n        \"\"\"\n        Fetch the CloudWatch logs for a given Lambda name.\n        \"\"\"\n        log_name = '/aws/lambda/' + lambda_name\n        streams = self.logs_client.describe_log_streams(\n            logGroupName=log_name,\n            descending=True,\n            orderBy='LastEventTime'\n        )\n\n        all_streams = streams['logStreams']\n        all_names = [stream['logStreamName'] for stream in all_streams]\n\n        events = []\n        response = {}\n        while not response or 'nextToken' in response:\n            extra_args = {}\n            if 'nextToken' in response:\n                extra_args['nextToken'] = response['nextToken']\n\n            # Amazon uses millisecond epoch for some reason.\n            # Thanks, Jeff.\n            start_time = start_time * 1000\n            end_time = int(time.time()) * 1000\n\n            response = self.logs_client.filter_log_events(\n                logGroupName=log_name,\n                logStreamNames=all_names,\n                startTime=start_time,\n                endTime=end_time,\n                filterPattern=filter_pattern,\n                limit=limit,\n                interleaved=True, # Does this actually improve performance?\n                **extra_args\n            )\n            if response and 'events' in response:\n                events += response['events']\n\n        return sorted(events, key=lambda k: k['timestamp'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the log group with the given name.", "response": "def remove_log_group(self, group_name):\n        \"\"\"\n        Filter all log groups that match the name given in log_filter.\n        \"\"\"\n        print(\"Removing log group: {}\".format(group_name))\n        try:\n            self.logs_client.delete_log_group(logGroupName=group_name)\n        except botocore.exceptions.ClientError as e:\n            print(\"Couldn't remove '{}' because of: {}\".format(group_name, e))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all logs that are assigned to a given rest api id.", "response": "def remove_api_gateway_logs(self, project_name):\n        \"\"\"\n        Removed all logs that are assigned to a given rest api id.\n        \"\"\"\n        for rest_api in self.get_rest_apis(project_name):\n            for stage in self.apigateway_client.get_stages(restApiId=rest_api['id'])['item']:\n                self.remove_log_group('API-Gateway-Execution-Logs_{}/{}'.format(rest_api['id'], stage['stageName']))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the Hosted Zone ID for a given domain.", "response": "def get_hosted_zone_id_for_domain(self, domain):\n        \"\"\"\n        Get the Hosted Zone ID for a given domain.\n\n        \"\"\"\n        all_zones = self.get_all_zones()\n        return self.get_best_match_zone(all_zones, domain)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_best_match_zone(all_zones, domain):\n\n        # Related: https://github.com/Miserlou/Zappa/issues/459\n        public_zones = [zone for zone in all_zones['HostedZones'] if not zone['Config']['PrivateZone']]\n\n        zones = {zone['Name'][:-1]: zone['Id'] for zone in public_zones if zone['Name'][:-1] in domain}\n        if zones:\n            keys = max(zones.keys(), key=lambda a: len(a))  # get longest key -- best match.\n            return zones[keys]\n        else:\n            return None", "response": "Return zone id which name is closer matched with domain name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_dns_challenge_txt(self, zone_id, domain, txt_challenge):\n        print(\"Deleting DNS challenge..\")\n        resp = self.route53.change_resource_record_sets(\n            HostedZoneId=zone_id,\n            ChangeBatch=self.get_dns_challenge_change_batch('DELETE', domain, txt_challenge)\n        )\n\n        return resp", "response": "Remove DNS challenge TXT."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading AWS credentials from config file or environment.", "response": "def load_credentials(self, boto_session=None, profile_name=None):\n        \"\"\"\n        Load AWS credentials.\n\n        An optional boto_session can be provided, but that's usually for testing.\n\n        An optional profile_name can be provided for config files that have multiple sets\n        of credentials.\n        \"\"\"\n        # Automatically load credentials from config or environment\n        if not boto_session:\n\n            # If provided, use the supplied profile name.\n            if profile_name:\n                self.boto_session = boto3.Session(profile_name=profile_name, region_name=self.aws_region)\n            elif os.environ.get('AWS_ACCESS_KEY_ID') and os.environ.get('AWS_SECRET_ACCESS_KEY'):\n                region_name = os.environ.get('AWS_DEFAULT_REGION') or self.aws_region\n                session_kw = {\n                    \"aws_access_key_id\": os.environ.get('AWS_ACCESS_KEY_ID'),\n                    \"aws_secret_access_key\": os.environ.get('AWS_SECRET_ACCESS_KEY'),\n                    \"region_name\": region_name,\n                }\n\n                # If we're executing in a role, AWS_SESSION_TOKEN will be present, too.\n                if os.environ.get(\"AWS_SESSION_TOKEN\"):\n                    session_kw[\"aws_session_token\"] = os.environ.get(\"AWS_SESSION_TOKEN\")\n\n                self.boto_session = boto3.Session(**session_kw)\n            else:\n                self.boto_session = boto3.Session(region_name=self.aws_region)\n\n            logger.debug(\"Loaded boto session from config: %s\", boto_session)\n        else:\n            logger.debug(\"Using provided boto session: %s\", boto_session)\n            self.boto_session = boto_session\n\n        # use provided session's region in case it differs\n        self.aws_region = self.boto_session.region_name\n\n        if self.boto_session.region_name not in LAMBDA_REGIONS:\n            print(\"Warning! AWS Lambda may not be available in this AWS Region!\")\n\n        if self.boto_session.region_name not in API_GATEWAY_REGIONS:\n            print(\"Warning! AWS API Gateway may not be available in this AWS Region!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cert_and_update_domain(\n                                zappa_instance,\n                                lambda_name,\n                                api_stage,\n                                domain=None,\n                                manual=False,\n                            ):\n    \"\"\"\n    Main cert installer path.\n    \"\"\"\n\n    try:\n        create_domain_key()\n        create_domain_csr(domain)\n        get_cert(zappa_instance)\n        create_chained_certificate()\n\n        with open('{}/signed.crt'.format(gettempdir())) as f:\n            certificate_body = f.read()\n\n        with open('{}/domain.key'.format(gettempdir())) as f:\n            certificate_private_key = f.read()\n\n        with open('{}/intermediate.pem'.format(gettempdir())) as f:\n            certificate_chain = f.read()\n\n        if not manual:\n            if domain:\n                if not zappa_instance.get_domain_name(domain):\n                    zappa_instance.create_domain_name(\n                        domain_name=domain,\n                        certificate_name=domain + \"-Zappa-LE-Cert\",\n                        certificate_body=certificate_body,\n                        certificate_private_key=certificate_private_key,\n                        certificate_chain=certificate_chain,\n                        certificate_arn=None,\n                        lambda_name=lambda_name,\n                        stage=api_stage\n                    )\n                    print(\"Created a new domain name. Please note that it can take up to 40 minutes for this domain to be created and propagated through AWS, but it requires no further work on your part.\")\n                else:\n                    zappa_instance.update_domain_name(\n                        domain_name=domain,\n                        certificate_name=domain + \"-Zappa-LE-Cert\",\n                        certificate_body=certificate_body,\n                        certificate_private_key=certificate_private_key,\n                        certificate_chain=certificate_chain,\n                        certificate_arn=None,\n                        lambda_name=lambda_name,\n                        stage=api_stage\n                    )\n        else:\n            print(\"Cerificate body:\\n\")\n            print(certificate_body)\n\n            print(\"\\nCerificate private key:\\n\")\n            print(certificate_private_key)\n\n            print(\"\\nCerificate chain:\\n\")\n            print(certificate_chain)\n\n    except Exception as e:\n        print(e)\n        return False\n\n    return True", "response": "Get the certificate and update the domain name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_account_key():\n    LOGGER.info(\"Parsing account key...\")\n    cmd = [\n        'openssl', 'rsa',\n        '-in', os.path.join(gettempdir(), 'account.key'),\n        '-noout',\n        '-text'\n    ]\n    devnull = open(os.devnull, 'wb')\n    return subprocess.check_output(cmd, stderr=devnull)", "response": "Parse the account key to get public key"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses certificate signing request for domains", "response": "def parse_csr():\n    \"\"\"\n    Parse certificate signing request for domains\n    \"\"\"\n    LOGGER.info(\"Parsing CSR...\")\n    cmd = [\n        'openssl', 'req',\n        '-in', os.path.join(gettempdir(), 'domain.csr'),\n        '-noout',\n        '-text'\n    ]\n    devnull = open(os.devnull, 'wb')\n    out = subprocess.check_output(cmd, stderr=devnull)\n    domains = set([])\n    common_name = re.search(r\"Subject:.*? CN\\s?=\\s?([^\\s,;/]+)\", out.decode('utf8'))\n    if common_name is not None:\n        domains.add(common_name.group(1))\n    subject_alt_names = re.search(r\"X509v3 Subject Alternative Name: \\n +([^\\n]+)\\n\", out.decode('utf8'), re.MULTILINE | re.DOTALL)\n    if subject_alt_names is not None:\n        for san in subject_alt_names.group(1).split(\", \"):\n            if san.startswith(\"DNS:\"):\n                domains.add(san[4:])\n\n    return domains"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dict that can be used to send to Boulder", "response": "def get_boulder_header(key_bytes):\n    \"\"\"\n    Use regular expressions to find crypto values from parsed account key,\n    and return a header we can send to our Boulder instance.\n    \"\"\"\n    pub_hex, pub_exp = re.search(\n        r\"modulus:\\n\\s+00:([a-f0-9\\:\\s]+?)\\npublicExponent: ([0-9]+)\",\n        key_bytes.decode('utf8'), re.MULTILINE | re.DOTALL).groups()\n    pub_exp = \"{0:x}\".format(int(pub_exp))\n    pub_exp = \"0{0}\".format(pub_exp) if len(pub_exp) % 2 else pub_exp\n    header = {\n        \"alg\": \"RS256\",\n        \"jwk\": {\n            \"e\": _b64(binascii.unhexlify(pub_exp.encode(\"utf-8\"))),\n            \"kty\": \"RSA\",\n            \"n\": _b64(binascii.unhexlify(re.sub(r\"(\\s|:)\", \"\", pub_hex).encode(\"utf-8\"))),\n        },\n    }\n\n    return header"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_account():\n    LOGGER.info(\"Registering account...\")\n    code, result = _send_signed_request(DEFAULT_CA + \"/acme/new-reg\", {\n        \"resource\": \"new-reg\",\n        \"agreement\": \"https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf\",\n    })\n    if code == 201:  # pragma: no cover\n        LOGGER.info(\"Registered!\")\n    elif code == 409:  # pragma: no cover\n        LOGGER.info(\"Already registered!\")\n    else:  # pragma: no cover\n        raise ValueError(\"Error registering: {0} {1}\".format(code, result))", "response": "Register a new LE TOS\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a new certificate for the account key.", "response": "def get_cert(zappa_instance, log=LOGGER, CA=DEFAULT_CA):\n    \"\"\"\n    Call LE to get a new signed CA.\n    \"\"\"\n    out = parse_account_key()\n    header = get_boulder_header(out)\n    accountkey_json = json.dumps(header['jwk'], sort_keys=True, separators=(',', ':'))\n    thumbprint = _b64(hashlib.sha256(accountkey_json.encode('utf8')).digest())\n\n    # find domains\n    domains = parse_csr()\n\n    # get the certificate domains and expiration\n    register_account()\n\n    # verify each domain\n    for domain in domains:\n        log.info(\"Verifying {0}...\".format(domain))\n\n        # get new challenge\n        code, result = _send_signed_request(CA + \"/acme/new-authz\", {\n            \"resource\": \"new-authz\",\n            \"identifier\": {\"type\": \"dns\", \"value\": domain},\n        })\n        if code != 201:\n            raise ValueError(\"Error requesting challenges: {0} {1}\".format(code, result))\n\n        challenge = [ch for ch in json.loads(result.decode('utf8'))['challenges'] if ch['type'] == \"dns-01\"][0]\n        token = re.sub(r\"[^A-Za-z0-9_\\-]\", \"_\", challenge['token'])\n        keyauthorization = \"{0}.{1}\".format(token, thumbprint).encode('utf-8')\n\n        # sha256_b64\n        digest = _b64(hashlib.sha256(keyauthorization).digest())\n\n        zone_id = zappa_instance.get_hosted_zone_id_for_domain(domain)\n        if not zone_id:\n            raise ValueError(\"Could not find Zone ID for: \" + domain)\n        zappa_instance.set_dns_challenge_txt(zone_id, domain, digest)  # resp is unused\n\n        print(\"Waiting for DNS to propagate..\")\n\n        # What's optimal here?\n        # import time  # double import; import in loop; shadowed import\n        time.sleep(45)\n\n        # notify challenge are met\n        code, result = _send_signed_request(challenge['uri'], {\n            \"resource\": \"challenge\",\n            \"keyAuthorization\": keyauthorization.decode('utf-8'),\n        })\n        if code != 202:\n            raise ValueError(\"Error triggering challenge: {0} {1}\".format(code, result))\n\n        # wait for challenge to be verified\n        verify_challenge(challenge['uri'])\n\n        # Challenge verified, clean up R53\n        zappa_instance.remove_dns_challenge_txt(zone_id, domain, digest)\n\n    # Sign\n    result = sign_certificate()\n    # Encode to PEM format\n    encode_certificate(result)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if our challenge is valid.", "response": "def verify_challenge(uri):\n    \"\"\"\n    Loop until our challenge is verified, else fail.\n    \"\"\"\n    while True:\n        try:\n            resp = urlopen(uri)\n            challenge_status = json.loads(resp.read().decode('utf8'))\n        except IOError as e:\n            raise ValueError(\"Error checking challenge: {0} {1}\".format(\n                e.code, json.loads(e.read().decode('utf8'))))\n        if challenge_status['status'] == \"pending\":\n            time.sleep(2)\n        elif challenge_status['status'] == \"valid\":\n            LOGGER.info(\"Domain verified!\")\n            break\n        else:\n            raise ValueError(\"Domain challenge did not pass: {0}\".format(\n                challenge_status))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sign_certificate():\n    LOGGER.info(\"Signing certificate...\")\n    cmd = [\n        'openssl', 'req',\n        '-in', os.path.join(gettempdir(), 'domain.csr'),\n        '-outform', 'DER'\n    ]\n    devnull = open(os.devnull, 'wb')\n    csr_der = subprocess.check_output(cmd, stderr=devnull)\n    code, result = _send_signed_request(DEFAULT_CA + \"/acme/new-cert\", {\n        \"resource\": \"new-cert\",\n        \"csr\": _b64(csr_der),\n    })\n    if code != 201:\n        raise ValueError(\"Error signing certificate: {0} {1}\".format(code, result))\n    LOGGER.info(\"Certificate signed!\")\n\n    return result", "response": "Get the new certificate.\n    Returns the signed bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes certificate bytes to PEM encoded cert file.", "response": "def encode_certificate(result):\n    \"\"\"\n    Encode cert bytes to PEM encoded cert file.\n    \"\"\"\n    cert_body = \"\"\"-----BEGIN CERTIFICATE-----\\n{0}\\n-----END CERTIFICATE-----\\n\"\"\".format(\n        \"\\n\".join(textwrap.wrap(base64.b64encode(result).decode('utf8'), 64)))\n    signed_crt = open(\"{}/signed.crt\".format(gettempdir()), \"w\")\n    signed_crt.write(cert_body)\n    signed_crt.close()\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npromoting our little community.", "response": "def shamelessly_promote():\n    \"\"\"\n    Shamelessly promote our little community.\n    \"\"\"\n\n    click.echo(\"Need \" + click.style(\"help\", fg='green', bold=True) +\n               \"? Found a \" + click.style(\"bug\", fg='green', bold=True) +\n               \"? Let us \" + click.style(\"know\", fg='green', bold=True) + \"! :D\")\n    click.echo(\"File bug reports on \" + click.style(\"GitHub\", bold=True) + \" here: \"\n               + click.style(\"https://github.com/Miserlou/Zappa\", fg='cyan', bold=True))\n    click.echo(\"And join our \" + click.style(\"Slack\", bold=True) + \" channel here: \"\n               + click.style(\"https://slack.zappa.io\", fg='cyan', bold=True))\n    click.echo(\"Love!,\")\n    click.echo(\" ~ Team \" + click.style(\"Zappa\", bold=True) + \"!\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of all the settings for a stage.", "response": "def stage_config(self):\n        \"\"\"\n        A shortcut property for settings of a stage.\n        \"\"\"\n\n        def get_stage_setting(stage, extended_stages=None):\n            if extended_stages is None:\n                extended_stages = []\n\n            if stage in extended_stages:\n                raise RuntimeError(stage + \" has already been extended to these settings. \"\n                                           \"There is a circular extends within the settings file.\")\n            extended_stages.append(stage)\n\n            try:\n                stage_settings = dict(self.zappa_settings[stage].copy())\n            except KeyError:\n                raise ClickException(\"Cannot extend settings for undefined stage '\" + stage + \"'.\")\n\n            extends_stage = self.zappa_settings[stage].get('extends', None)\n            if not extends_stage:\n                return stage_settings\n            extended_settings = get_stage_setting(stage=extends_stage, extended_stages=extended_stages)\n            extended_settings.update(stage_settings)\n            return extended_settings\n\n        settings = get_stage_setting(stage=self.api_stage)\n\n        # Backwards compatible for delete_zip setting that was more explicitly named delete_local_zip\n        if u'delete_zip' in settings:\n            settings[u'delete_local_zip'] = settings.get(u'delete_zip')\n\n        settings.update(self.stage_config_overrides)\n\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef override_stage_config_setting(self, key, val):\n        self._stage_config_overrides = getattr(self, '_stage_config_overrides', {})\n        self._stage_config_overrides.setdefault(self.api_stage, {})[key] = val", "response": "Forcefully override a setting set by zappa_settings for the current stage only"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch_command(self, command, stage):\n\n        self.api_stage = stage\n\n        if command not in ['status', 'manage']:\n            if not self.vargs.get('json', None):\n                click.echo(\"Calling \" + click.style(command, fg=\"green\", bold=True) + \" for stage \" +\n                           click.style(self.api_stage, bold=True) + \"..\" )\n\n        # Explicitly define the app function.\n        # Related: https://github.com/Miserlou/Zappa/issues/832\n        if self.vargs.get('app_function', None):\n            self.app_function = self.vargs['app_function']\n\n        # Load our settings, based on api_stage.\n        try:\n            self.load_settings(self.vargs.get('settings_file'))\n        except ValueError as e:\n            if hasattr(e, 'message'):\n                print(\"Error: {}\".format(e.message))\n            else:\n                print(str(e))\n            sys.exit(-1)\n        self.callback('settings')\n\n        # Hand it off\n        if command == 'deploy': # pragma: no cover\n            self.deploy(self.vargs['zip'])\n        if command == 'package': # pragma: no cover\n            self.package(self.vargs['output'])\n        if command == 'template': # pragma: no cover\n            self.template(      self.vargs['lambda_arn'],\n                                self.vargs['role_arn'],\n                                output=self.vargs['output'],\n                                json=self.vargs['json']\n                            )\n        elif command == 'update': # pragma: no cover\n            self.update(self.vargs['zip'], self.vargs['no_upload'])\n        elif command == 'rollback': # pragma: no cover\n            self.rollback(self.vargs['num_rollback'])\n        elif command == 'invoke': # pragma: no cover\n\n            if not self.vargs.get('command_rest'):\n                print(\"Please enter the function to invoke.\")\n                return\n\n            self.invoke(\n                self.vargs['command_rest'],\n                raw_python=self.vargs['raw'],\n                no_color=self.vargs['no_color'],\n            )\n        elif command == 'manage': # pragma: no cover\n\n            if not self.vargs.get('command_rest'):\n                print(\"Please enter the management command to invoke.\")\n                return\n\n            if not self.django_settings:\n                print(\"This command is for Django projects only!\")\n                print(\"If this is a Django project, please define django_settings in your zappa_settings.\")\n                return\n\n            command_tail = self.vargs.get('command_rest')\n            if len(command_tail) > 1:\n                command = \" \".join(command_tail) # ex: zappa manage dev \"shell --version\"\n            else:\n                command = command_tail[0] # ex: zappa manage dev showmigrations admin\n\n            self.invoke(\n                command,\n                command=\"manage\",\n                no_color=self.vargs['no_color'],\n            )\n\n        elif command == 'tail': # pragma: no cover\n            self.tail(\n                colorize=(not self.vargs['no_color']),\n                http=self.vargs['http'],\n                non_http=self.vargs['non_http'],\n                since=self.vargs['since'],\n                filter_pattern=self.vargs['filter'],\n                force_colorize=self.vargs['force_color'] or None,\n                keep_open=not self.vargs['disable_keep_open']\n            )\n        elif command == 'undeploy': # pragma: no cover\n            self.undeploy(\n                no_confirm=self.vargs['yes'],\n                remove_logs=self.vargs['remove_logs']\n            )\n        elif command == 'schedule': # pragma: no cover\n            self.schedule()\n        elif command == 'unschedule': # pragma: no cover\n            self.unschedule()\n        elif command == 'status': # pragma: no cover\n            self.status(return_json=self.vargs['json'])\n        elif command == 'certify': # pragma: no cover\n            self.certify(\n                no_confirm=self.vargs['yes'],\n                manual=self.vargs['manual']\n            )\n        elif command == 'shell': # pragma: no cover\n            self.shell()", "response": "Dispatches a command to the appropriate handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the Lambda package.", "response": "def package(self, output=None):\n        \"\"\"\n        Only build the package\n        \"\"\"\n        # Make sure we're in a venv.\n        self.check_venv()\n\n        # force not to delete the local zip\n        self.override_stage_config_setting('delete_local_zip', False)\n        # Execute the prebuild script\n        if self.prebuild_script:\n            self.execute_prebuild_script()\n        # Create the Lambda Zip\n        self.create_package(output)\n        self.callback('zip')\n        size = human_size(os.path.getsize(self.zip_path))\n        click.echo(click.style(\"Package created\", fg=\"green\", bold=True) + \": \" + click.style(self.zip_path, bold=True) + \" (\" + size + \")\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the template file for the given Lambda and Role.", "response": "def template(self, lambda_arn, role_arn, output=None, json=False):\n        \"\"\"\n        Only build the template file.\n        \"\"\"\n\n        if not lambda_arn:\n            raise ClickException(\"Lambda ARN is required to template.\")\n\n        if not role_arn:\n            raise ClickException(\"Role ARN is required to template.\")\n\n        self.zappa.credentials_arn = role_arn\n\n        # Create the template!\n        template = self.zappa.create_stack_template(\n                                            lambda_arn=lambda_arn,\n                                            lambda_name=self.lambda_name,\n                                            api_key_required=self.api_key_required,\n                                            iam_authorization=self.iam_authorization,\n                                            authorizer=self.authorizer,\n                                            cors_options=self.cors,\n                                            description=self.apigateway_description,\n                                            policy=self.apigateway_policy,\n                                            endpoint_configuration=self.endpoint_configuration\n                                        )\n\n        if not output:\n            template_file = self.lambda_name + '-template-' + str(int(time.time())) + '.json'\n        else:\n            template_file = output\n        with open(template_file, 'wb') as out:\n            out.write(bytes(template.to_json(indent=None, separators=(',',':')), \"utf-8\"))\n\n        if not json:\n            click.echo(click.style(\"Template created\", fg=\"green\", bold=True) + \": \" + click.style(template_file, bold=True))\n        else:\n            with open(template_file, 'r') as out:\n                print(out.read())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy(self, source_zip=None):\n\n        if not source_zip:\n            # Make sure we're in a venv.\n            self.check_venv()\n\n            # Execute the prebuild script\n            if self.prebuild_script:\n                self.execute_prebuild_script()\n\n            # Make sure this isn't already deployed.\n            deployed_versions = self.zappa.get_lambda_function_versions(self.lambda_name)\n            if len(deployed_versions) > 0:\n                raise ClickException(\"This application is \" + click.style(\"already deployed\", fg=\"red\") +\n                                     \" - did you mean to call \" + click.style(\"update\", bold=True) + \"?\")\n\n            # Make sure the necessary IAM execution roles are available\n            if self.manage_roles:\n                try:\n                    self.zappa.create_iam_roles()\n                except botocore.client.ClientError:\n                    raise ClickException(\n                        click.style(\"Failed\", fg=\"red\") + \" to \" + click.style(\"manage IAM roles\", bold=True) + \"!\\n\" +\n                        \"You may \" + click.style(\"lack the necessary AWS permissions\", bold=True) +\n                        \" to automatically manage a Zappa execution role.\\n\" +\n                        \"To fix this, see here: \" +\n                        click.style(\"https://github.com/Miserlou/Zappa#custom-aws-iam-roles-and-policies-for-deployment\", bold=True)\n                        + '\\n')\n\n            # Create the Lambda Zip\n            self.create_package()\n            self.callback('zip')\n\n            # Upload it to S3\n            success = self.zappa.upload_to_s3(\n                    self.zip_path, self.s3_bucket_name, disable_progress=self.disable_progress)\n            if not success: # pragma: no cover\n                raise ClickException(\"Unable to upload to S3. Quitting.\")\n\n            # If using a slim handler, upload it to S3 and tell lambda to use this slim handler zip\n            if self.stage_config.get('slim_handler', False):\n                # https://github.com/Miserlou/Zappa/issues/510\n                success = self.zappa.upload_to_s3(self.handler_path, self.s3_bucket_name, disable_progress=self.disable_progress)\n                if not success:  # pragma: no cover\n                    raise ClickException(\"Unable to upload handler to S3. Quitting.\")\n\n                # Copy the project zip to the current project zip\n                current_project_name = '{0!s}_{1!s}_current_project.tar.gz'.format(self.api_stage, self.project_name)\n                success = self.zappa.copy_on_s3(src_file_name=self.zip_path, dst_file_name=current_project_name,\n                                                bucket_name=self.s3_bucket_name)\n                if not success:  # pragma: no cover\n                    raise ClickException(\"Unable to copy the zip to be the current project. Quitting.\")\n\n                handler_file = self.handler_path\n            else:\n                handler_file = self.zip_path\n\n        # Fixes https://github.com/Miserlou/Zappa/issues/613\n        try:\n            self.lambda_arn = self.zappa.get_lambda_function(\n                function_name=self.lambda_name)\n        except botocore.client.ClientError:\n            # Register the Lambda function with that zip as the source\n            # You'll also need to define the path to your lambda_handler code.\n            kwargs = dict(\n                handler=self.lambda_handler,\n                description=self.lambda_description,\n                vpc_config=self.vpc_config,\n                dead_letter_config=self.dead_letter_config,\n                timeout=self.timeout_seconds,\n                memory_size=self.memory_size,\n                runtime=self.runtime,\n                aws_environment_variables=self.aws_environment_variables,\n                aws_kms_key_arn=self.aws_kms_key_arn,\n                use_alb=self.use_alb\n            )\n            if source_zip and source_zip.startswith('s3://'):\n                bucket, key_name = parse_s3_url(source_zip)\n                kwargs['function_name'] = self.lambda_name\n                kwargs['bucket'] = bucket\n                kwargs['s3_key'] = key_name\n            elif source_zip and not source_zip.startswith('s3://'):\n                with open(source_zip, mode='rb') as fh:\n                    byte_stream = fh.read()\n                kwargs['function_name'] = self.lambda_name\n                kwargs['local_zip'] = byte_stream\n            else:\n                kwargs['function_name'] = self.lambda_name\n                kwargs['bucket'] = self.s3_bucket_name\n                kwargs['s3_key'] = handler_file\n\n            self.lambda_arn = self.zappa.create_lambda_function(**kwargs)\n\n        # Schedule events for this deployment\n        self.schedule()\n\n        endpoint_url = ''\n        deployment_string = click.style(\"Deployment complete\", fg=\"green\", bold=True) + \"!\"\n\n        if self.use_alb:\n            kwargs = dict(\n                lambda_arn=self.lambda_arn,\n                lambda_name=self.lambda_name,\n                alb_vpc_config=self.alb_vpc_config,\n                timeout=self.timeout_seconds\n            )\n            self.zappa.deploy_lambda_alb(**kwargs)\n\n        if self.use_apigateway:\n\n            # Create and configure the API Gateway\n            template = self.zappa.create_stack_template(\n                                                        lambda_arn=self.lambda_arn,\n                                                        lambda_name=self.lambda_name,\n                                                        api_key_required=self.api_key_required,\n                                                        iam_authorization=self.iam_authorization,\n                                                        authorizer=self.authorizer,\n                                                        cors_options=self.cors,\n                                                        description=self.apigateway_description,\n                                                        endpoint_configuration=self.endpoint_configuration\n                                                    )\n\n            self.zappa.update_stack(\n                                    self.lambda_name,\n                                    self.s3_bucket_name,\n                                    wait=True,\n                                    disable_progress=self.disable_progress\n                                )\n\n            api_id = self.zappa.get_api_id(self.lambda_name)\n\n            # Add binary support\n            if self.binary_support:\n                self.zappa.add_binary_support(api_id=api_id, cors=self.cors)\n\n            # Add payload compression\n            if self.stage_config.get('payload_compression', True):\n                self.zappa.add_api_compression(\n                    api_id=api_id,\n                    min_compression_size=self.stage_config.get('payload_minimum_compression_size', 0))\n\n            # Deploy the API!\n            endpoint_url = self.deploy_api_gateway(api_id)\n            deployment_string = deployment_string + \": {}\".format(endpoint_url)\n\n            # Create/link API key\n            if self.api_key_required:\n                if self.api_key is None:\n                    self.zappa.create_api_key(api_id=api_id, stage_name=self.api_stage)\n                else:\n                    self.zappa.add_api_stage_to_api_key(api_key=self.api_key, api_id=api_id, stage_name=self.api_stage)\n\n            if self.stage_config.get('touch', True):\n                self.touch_endpoint(endpoint_url)\n\n        # Finally, delete the local copy our zip package\n        if not source_zip:\n            if self.stage_config.get('delete_local_zip', True):\n                self.remove_local_zip()\n\n        # Remove the project zip from S3.\n        if not source_zip:\n            self.remove_uploaded_zip()\n\n        self.callback('post')\n\n        click.echo(deployment_string)", "response": "Deploy the application to the Zappa."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the function code and the code.", "response": "def update(self, source_zip=None, no_upload=False):\n        \"\"\"\n        Repackage and update the function code.\n        \"\"\"\n\n        if not source_zip:\n            # Make sure we're in a venv.\n            self.check_venv()\n\n            # Execute the prebuild script\n            if self.prebuild_script:\n                self.execute_prebuild_script()\n\n            # Temporary version check\n            try:\n                updated_time = 1472581018\n                function_response = self.zappa.lambda_client.get_function(FunctionName=self.lambda_name)\n                conf = function_response['Configuration']\n                last_updated = parser.parse(conf['LastModified'])\n                last_updated_unix = time.mktime(last_updated.timetuple())\n            except botocore.exceptions.BotoCoreError as e:\n                click.echo(click.style(type(e).__name__, fg=\"red\") + \": \" + e.args[0])\n                sys.exit(-1)\n            except Exception as e:\n                click.echo(click.style(\"Warning!\", fg=\"red\") + \" Couldn't get function \" + self.lambda_name +\n                           \" in \" + self.zappa.aws_region + \" - have you deployed yet?\")\n                sys.exit(-1)\n\n            if last_updated_unix <= updated_time:\n                click.echo(click.style(\"Warning!\", fg=\"red\") +\n                           \" You may have upgraded Zappa since deploying this application. You will need to \" +\n                           click.style(\"redeploy\", bold=True) + \" for this deployment to work properly!\")\n\n            # Make sure the necessary IAM execution roles are available\n            if self.manage_roles:\n                try:\n                    self.zappa.create_iam_roles()\n                except botocore.client.ClientError:\n                    click.echo(click.style(\"Failed\", fg=\"red\") + \" to \" + click.style(\"manage IAM roles\", bold=True) + \"!\")\n                    click.echo(\"You may \" + click.style(\"lack the necessary AWS permissions\", bold=True) +\n                               \" to automatically manage a Zappa execution role.\")\n                    click.echo(\"To fix this, see here: \" +\n                               click.style(\"https://github.com/Miserlou/Zappa#custom-aws-iam-roles-and-policies-for-deployment\",\n                                           bold=True))\n                    sys.exit(-1)\n\n            # Create the Lambda Zip,\n            if not no_upload:\n                self.create_package()\n                self.callback('zip')\n\n            # Upload it to S3\n            if not no_upload:\n                success = self.zappa.upload_to_s3(self.zip_path, self.s3_bucket_name, disable_progress=self.disable_progress)\n                if not success:  # pragma: no cover\n                    raise ClickException(\"Unable to upload project to S3. Quitting.\")\n\n                # If using a slim handler, upload it to S3 and tell lambda to use this slim handler zip\n                if self.stage_config.get('slim_handler', False):\n                    # https://github.com/Miserlou/Zappa/issues/510\n                    success = self.zappa.upload_to_s3(self.handler_path, self.s3_bucket_name, disable_progress=self.disable_progress)\n                    if not success:  # pragma: no cover\n                        raise ClickException(\"Unable to upload handler to S3. Quitting.\")\n\n                    # Copy the project zip to the current project zip\n                    current_project_name = '{0!s}_{1!s}_current_project.tar.gz'.format(self.api_stage, self.project_name)\n                    success = self.zappa.copy_on_s3(src_file_name=self.zip_path, dst_file_name=current_project_name,\n                                                    bucket_name=self.s3_bucket_name)\n                    if not success:  # pragma: no cover\n                        raise ClickException(\"Unable to copy the zip to be the current project. Quitting.\")\n\n                    handler_file = self.handler_path\n                else:\n                    handler_file = self.zip_path\n\n        # Register the Lambda function with that zip as the source\n        # You'll also need to define the path to your lambda_handler code.\n        kwargs = dict(\n            bucket=self.s3_bucket_name,\n            function_name=self.lambda_name,\n            num_revisions=self.num_retained_versions\n        )\n        if source_zip and source_zip.startswith('s3://'):\n            bucket, key_name = parse_s3_url(source_zip)\n            kwargs.update(dict(\n                bucket=bucket,\n                s3_key=key_name\n            ))\n            self.lambda_arn = self.zappa.update_lambda_function(**kwargs)\n        elif source_zip and not source_zip.startswith('s3://'):\n            with open(source_zip, mode='rb') as fh:\n                byte_stream = fh.read()\n            kwargs['local_zip'] = byte_stream\n            self.lambda_arn = self.zappa.update_lambda_function(**kwargs)\n        else:\n            if not no_upload:\n                kwargs['s3_key'] = handler_file\n                self.lambda_arn = self.zappa.update_lambda_function(**kwargs)\n\n        # Remove the uploaded zip from S3, because it is now registered..\n        if not source_zip and not no_upload:\n            self.remove_uploaded_zip()\n\n        # Update the configuration, in case there are changes.\n        self.lambda_arn = self.zappa.update_lambda_configuration(\n                                                        lambda_arn=self.lambda_arn,\n                                                        function_name=self.lambda_name,\n                                                        handler=self.lambda_handler,\n                                                        description=self.lambda_description,\n                                                        vpc_config=self.vpc_config,\n                                                        timeout=self.timeout_seconds,\n                                                        memory_size=self.memory_size,\n                                                        runtime=self.runtime,\n                                                        aws_environment_variables=self.aws_environment_variables,\n                                                        aws_kms_key_arn=self.aws_kms_key_arn\n                                                    )\n\n        # Finally, delete the local copy our zip package\n        if not source_zip and not no_upload:\n            if self.stage_config.get('delete_local_zip', True):\n                self.remove_local_zip()\n\n        if self.use_apigateway:\n\n            self.zappa.create_stack_template(\n                                            lambda_arn=self.lambda_arn,\n                                            lambda_name=self.lambda_name,\n                                            api_key_required=self.api_key_required,\n                                            iam_authorization=self.iam_authorization,\n                                            authorizer=self.authorizer,\n                                            cors_options=self.cors,\n                                            description=self.apigateway_description,\n                                            endpoint_configuration=self.endpoint_configuration\n                                        )\n            self.zappa.update_stack(\n                                    self.lambda_name,\n                                    self.s3_bucket_name,\n                                    wait=True,\n                                    update_only=True,\n                                    disable_progress=self.disable_progress)\n\n            api_id = self.zappa.get_api_id(self.lambda_name)\n\n            # Update binary support\n            if self.binary_support:\n                self.zappa.add_binary_support(api_id=api_id, cors=self.cors)\n            else:\n                self.zappa.remove_binary_support(api_id=api_id, cors=self.cors)\n\n            if self.stage_config.get('payload_compression', True):\n                self.zappa.add_api_compression(\n                    api_id=api_id,\n                    min_compression_size=self.stage_config.get('payload_minimum_compression_size', 0))\n            else:\n                self.zappa.remove_api_compression(api_id=api_id)\n\n            # It looks a bit like we might actually be using this just to get the URL,\n            # but we're also updating a few of the APIGW settings.\n            endpoint_url = self.deploy_api_gateway(api_id)\n\n            if self.stage_config.get('domain', None):\n                endpoint_url = self.stage_config.get('domain')\n\n        else:\n            endpoint_url = None\n\n        self.schedule()\n\n        # Update any cognito pool with the lambda arn\n        # do this after schedule as schedule clears the lambda policy and we need to add one\n        self.update_cognito_triggers()\n\n        self.callback('post')\n\n        if endpoint_url and 'https://' not in endpoint_url:\n            endpoint_url = 'https://' + endpoint_url\n\n        if self.base_path:\n            endpoint_url += '/' + self.base_path\n\n        deployed_string = \"Your updated Zappa deployment is \" + click.style(\"live\", fg='green', bold=True) + \"!\"\n        if self.use_apigateway:\n            deployed_string = deployed_string + \": \" + click.style(\"{}\".format(endpoint_url), bold=True)\n\n            api_url = None\n            if endpoint_url and 'amazonaws.com' not in endpoint_url:\n                api_url = self.zappa.get_api_url(\n                    self.lambda_name,\n                    self.api_stage)\n\n                if endpoint_url != api_url:\n                    deployed_string = deployed_string + \" (\" + api_url + \")\"\n\n            if self.stage_config.get('touch', True):\n                if api_url:\n                    self.touch_endpoint(api_url)\n                elif endpoint_url:\n                    self.touch_endpoint(endpoint_url)\n\n        click.echo(deployed_string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntailing the logs of this function.", "response": "def tail(self, since, filter_pattern, limit=10000, keep_open=True, colorize=True, http=False, non_http=False, force_colorize=False):\n        \"\"\"\n        Tail this function's logs.\n\n        if keep_open, do so repeatedly, printing any new logs\n        \"\"\"\n\n        try:\n            since_stamp = string_to_timestamp(since)\n\n            last_since = since_stamp\n            while True:\n                new_logs = self.zappa.fetch_logs(\n                    self.lambda_name,\n                    start_time=since_stamp,\n                    limit=limit,\n                    filter_pattern=filter_pattern,\n                    )\n\n                new_logs = [ e for e in new_logs if e['timestamp'] > last_since ]\n                self.print_logs(new_logs, colorize, http, non_http, force_colorize)\n\n                if not keep_open:\n                    break\n                if new_logs:\n                    last_since = new_logs[-1]['timestamp']\n                time.sleep(1)\n        except KeyboardInterrupt: # pragma: no cover\n            # Die gracefully\n            try:\n                sys.exit(0)\n            except SystemExit:\n                os._exit(130)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntears down an existing deployment.", "response": "def undeploy(self, no_confirm=False, remove_logs=False):\n        \"\"\"\n        Tear down an existing deployment.\n        \"\"\"\n\n        if not no_confirm: # pragma: no cover\n            confirm = input(\"Are you sure you want to undeploy? [y/n] \")\n            if confirm != 'y':\n                return\n\n        if self.use_alb:\n            self.zappa.undeploy_lambda_alb(self.lambda_name)\n\n        if self.use_apigateway:\n            if remove_logs:\n                self.zappa.remove_api_gateway_logs(self.lambda_name)\n\n            domain_name = self.stage_config.get('domain', None)\n            base_path = self.stage_config.get('base_path', None)\n\n            # Only remove the api key when not specified\n            if self.api_key_required and self.api_key is None:\n                api_id = self.zappa.get_api_id(self.lambda_name)\n                self.zappa.remove_api_key(api_id, self.api_stage)\n\n            gateway_id = self.zappa.undeploy_api_gateway(\n                self.lambda_name,\n                domain_name=domain_name,\n                base_path=base_path\n            )\n\n        self.unschedule()  # removes event triggers, including warm up event.\n\n        self.zappa.delete_lambda_function(self.lambda_name)\n        if remove_logs:\n            self.zappa.remove_lambda_function_logs(self.lambda_name)\n\n        click.echo(click.style(\"Done\", fg=\"green\", bold=True) + \"!\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_cognito_triggers(self):\n        if self.cognito:\n            user_pool = self.cognito.get('user_pool')\n            triggers = self.cognito.get('triggers', [])\n            lambda_configs = set()\n            for trigger in triggers:\n                lambda_configs.add(trigger['source'].split('_')[0])\n            self.zappa.update_cognito(self.lambda_name, user_pool, lambda_configs, self.lambda_arn)", "response": "Update any cognito triggers that are present in the user pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schedule(self):\n        events = self.stage_config.get('events', [])\n\n        if events:\n            if not isinstance(events, list): # pragma: no cover\n                print(\"Events must be supplied as a list.\")\n                return\n\n        for event in events:\n            self.collision_warning(event.get('function'))\n\n        if self.stage_config.get('keep_warm', True):\n            if not events:\n                events = []\n\n            keep_warm_rate = self.stage_config.get('keep_warm_expression', \"rate(4 minutes)\")\n            events.append({'name': 'zappa-keep-warm',\n                           'function': 'handler.keep_warm_callback',\n                           'expression': keep_warm_rate,\n                           'description': 'Zappa Keep Warm - {}'.format(self.lambda_name)})\n\n        if events:\n            try:\n                function_response = self.zappa.lambda_client.get_function(FunctionName=self.lambda_name)\n            except botocore.exceptions.ClientError as e: # pragma: no cover\n                click.echo(click.style(\"Function does not exist\", fg=\"yellow\") + \", please \" +\n                           click.style(\"deploy\", bold=True) + \"first. Ex:\" +\n                           click.style(\"zappa deploy {}.\".format(self.api_stage), bold=True))\n                sys.exit(-1)\n\n            print(\"Scheduling..\")\n            self.zappa.schedule_events(\n                lambda_arn=function_response['Configuration']['FunctionArn'],\n                lambda_name=self.lambda_name,\n                events=events\n            )\n\n        # Add async tasks SNS\n        if self.stage_config.get('async_source', None) == 'sns' \\\n           and self.stage_config.get('async_resources', True):\n            self.lambda_arn = self.zappa.get_lambda_function(\n                function_name=self.lambda_name)\n            topic_arn = self.zappa.create_async_sns_topic(\n                lambda_name=self.lambda_name,\n                lambda_arn=self.lambda_arn\n            )\n            click.echo('SNS Topic created: %s' % topic_arn)\n\n        # Add async tasks DynamoDB\n        table_name = self.stage_config.get('async_response_table', False)\n        read_capacity = self.stage_config.get('async_response_table_read_capacity', 1)\n        write_capacity = self.stage_config.get('async_response_table_write_capacity', 1)\n        if table_name and self.stage_config.get('async_resources', True):\n            created, response_table = self.zappa.create_async_dynamodb_table(\n                table_name, read_capacity, write_capacity)\n            if created:\n                click.echo('DynamoDB table created: %s' % table_name)\n            else:\n                click.echo('DynamoDB table exists: %s' % table_name)\n                provisioned_throughput = response_table['Table']['ProvisionedThroughput']\n                if provisioned_throughput['ReadCapacityUnits'] != read_capacity or \\\n                    provisioned_throughput['WriteCapacityUnits'] != write_capacity:\n                        click.echo(click.style(\n                            \"\\nWarning! Existing DynamoDB table ({}) does not match configured capacity.\\n\".format(table_name),\n                            fg='red'\n                        ))", "response": "Schedules the function to execute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unschedule(self):\n\n        # Run even if events are not defined to remove previously existing ones (thus default to []).\n        events = self.stage_config.get('events', [])\n\n        if not isinstance(events, list): # pragma: no cover\n            print(\"Events must be supplied as a list.\")\n            return\n\n        function_arn = None\n        try:\n            function_response = self.zappa.lambda_client.get_function(FunctionName=self.lambda_name)\n            function_arn = function_response['Configuration']['FunctionArn']\n        except botocore.exceptions.ClientError as e: # pragma: no cover\n            raise ClickException(\"Function does not exist, you should deploy first. Ex: zappa deploy {}. \"\n                  \"Proceeding to unschedule CloudWatch based events.\".format(self.api_stage))\n\n        print(\"Unscheduling..\")\n        self.zappa.unschedule_events(\n            lambda_name=self.lambda_name,\n            lambda_arn=function_arn,\n            events=events,\n            )\n\n        # Remove async task SNS\n        if self.stage_config.get('async_source', None) == 'sns' \\\n           and self.stage_config.get('async_resources', True):\n            removed_arns = self.zappa.remove_async_sns_topic(self.lambda_name)\n            click.echo('SNS Topic removed: %s' % ', '.join(removed_arns))", "response": "Unschedule CloudWatch based events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invoke(self, function_name, raw_python=False, command=None, no_color=False):\n\n        # There are three likely scenarios for 'command' here:\n        #   command, which is a modular function path\n        #   raw_command, which is a string of python to execute directly\n        #   manage, which is a Django-specific management command invocation\n        key = command if command is not None else 'command'\n        if raw_python:\n            command = {'raw_command': function_name}\n        else:\n            command = {key: function_name}\n\n        # Can't use hjson\n        import json as json\n\n        response = self.zappa.invoke_lambda_function(\n            self.lambda_name,\n            json.dumps(command),\n            invocation_type='RequestResponse',\n        )\n\n        if 'LogResult' in response:\n            if no_color:\n                print(base64.b64decode(response['LogResult']))\n            else:\n                decoded = base64.b64decode(response['LogResult']).decode()\n                formatted = self.format_invoke_command(decoded)\n                colorized = self.colorize_invoke_command(formatted)\n                print(colorized)\n        else:\n            print(response)\n\n        # For a successful request FunctionError is not in response.\n        # https://github.com/Miserlou/Zappa/pull/1254/\n        if 'FunctionError' in response:\n            raise ClickException(\n                \"{} error occurred while invoking command.\".format(response['FunctionError'])\n)", "response": "Invoke a remote function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_invoke_command(self, string):\n\n        string = string.replace('\\\\n', '\\n')\n\n        formated_response = ''\n        for line in string.splitlines():\n            if line.startswith('REPORT'):\n                line = line.replace('\\t', '\\n')\n            if line.startswith('[DEBUG]'):\n                line = line.replace('\\t', ' ')\n            formated_response += line + '\\n'\n        formated_response = formated_response.replace('\\n\\n', '\\n')\n\n        return formated_response", "response": "Formats correctly the string output from the invoke method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef colorize_invoke_command(self, string):\n\n        final_string = string\n\n        try:\n\n            # Line headers\n            try:\n                for token in ['START', 'END', 'REPORT', '[DEBUG]']:\n                    if token in final_string:\n                        format_string = '[{}]'\n                        # match whole words only\n                        pattern = r'\\b{}\\b'\n                        if token == '[DEBUG]':\n                            format_string = '{}'\n                            pattern = re.escape(token)\n                        repl = click.style(\n                            format_string.format(token),\n                            bold=True,\n                            fg='cyan'\n                        )\n                        final_string = re.sub(\n                            pattern.format(token), repl, final_string\n                        )\n            except Exception: # pragma: no cover\n                pass\n\n            # Green bold Tokens\n            try:\n                for token in [\n                    'Zappa Event:',\n                    'RequestId:',\n                    'Version:',\n                    'Duration:',\n                    'Billed',\n                    'Memory Size:',\n                    'Max Memory Used:'\n                ]:\n                    if token in final_string:\n                        final_string = final_string.replace(token, click.style(\n                            token,\n                            bold=True,\n                            fg='green'\n                        ))\n            except Exception: # pragma: no cover\n                pass\n\n            # UUIDs\n            for token in final_string.replace('\\t', ' ').split(' '):\n                try:\n                    if token.count('-') is 4 and token.replace('-', '').isalnum():\n                        final_string = final_string.replace(\n                            token,\n                            click.style(token, fg='magenta')\n                        )\n                except Exception: # pragma: no cover\n                    pass\n\n            return final_string\n        except Exception:\n            return string", "response": "Return a colorized version of the invoke command string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef status(self, return_json=False):\n\n        def tabular_print(title, value):\n            \"\"\"\n            Convenience function for priting formatted table items.\n            \"\"\"\n            click.echo('%-*s%s' % (32, click.style(\"\\t\" + title, fg='green') + ':', str(value)))\n            return\n\n        # Lambda Env Details\n        lambda_versions = self.zappa.get_lambda_function_versions(self.lambda_name)\n\n        if not lambda_versions:\n            raise ClickException(click.style(\"No Lambda %s detected in %s - have you deployed yet?\" %\n                                             (self.lambda_name, self.zappa.aws_region), fg='red'))\n\n        status_dict = collections.OrderedDict()\n        status_dict[\"Lambda Versions\"] = len(lambda_versions)\n        function_response = self.zappa.lambda_client.get_function(FunctionName=self.lambda_name)\n        conf = function_response['Configuration']\n        self.lambda_arn = conf['FunctionArn']\n        status_dict[\"Lambda Name\"] = self.lambda_name\n        status_dict[\"Lambda ARN\"] = self.lambda_arn\n        status_dict[\"Lambda Role ARN\"] = conf['Role']\n        status_dict[\"Lambda Handler\"] = conf['Handler']\n        status_dict[\"Lambda Code Size\"] = conf['CodeSize']\n        status_dict[\"Lambda Version\"] = conf['Version']\n        status_dict[\"Lambda Last Modified\"] = conf['LastModified']\n        status_dict[\"Lambda Memory Size\"] = conf['MemorySize']\n        status_dict[\"Lambda Timeout\"] = conf['Timeout']\n        status_dict[\"Lambda Runtime\"] = conf['Runtime']\n        if 'VpcConfig' in conf.keys():\n            status_dict[\"Lambda VPC ID\"] = conf.get('VpcConfig', {}).get('VpcId', 'Not assigned')\n        else:\n            status_dict[\"Lambda VPC ID\"] = None\n\n        # Calculated statistics\n        try:\n            function_invocations = self.zappa.cloudwatch.get_metric_statistics(\n                                       Namespace='AWS/Lambda',\n                                       MetricName='Invocations',\n                                       StartTime=datetime.utcnow()-timedelta(days=1),\n                                       EndTime=datetime.utcnow(),\n                                       Period=1440,\n                                       Statistics=['Sum'],\n                                       Dimensions=[{'Name': 'FunctionName',\n                                                    'Value': '{}'.format(self.lambda_name)}]\n                                       )['Datapoints'][0]['Sum']\n        except Exception as e:\n            function_invocations = 0\n        try:\n            function_errors = self.zappa.cloudwatch.get_metric_statistics(\n                                       Namespace='AWS/Lambda',\n                                       MetricName='Errors',\n                                       StartTime=datetime.utcnow()-timedelta(days=1),\n                                       EndTime=datetime.utcnow(),\n                                       Period=1440,\n                                       Statistics=['Sum'],\n                                       Dimensions=[{'Name': 'FunctionName',\n                                                    'Value': '{}'.format(self.lambda_name)}]\n                                       )['Datapoints'][0]['Sum']\n        except Exception as e:\n            function_errors = 0\n\n        try:\n            error_rate = \"{0:.2f}%\".format(function_errors / function_invocations * 100)\n        except:\n            error_rate = \"Error calculating\"\n        status_dict[\"Invocations (24h)\"] = int(function_invocations)\n        status_dict[\"Errors (24h)\"] = int(function_errors)\n        status_dict[\"Error Rate (24h)\"] = error_rate\n\n        # URLs\n        if self.use_apigateway:\n            api_url = self.zappa.get_api_url(\n                self.lambda_name,\n                self.api_stage)\n\n            status_dict[\"API Gateway URL\"] = api_url\n\n            # Api Keys\n            api_id = self.zappa.get_api_id(self.lambda_name)\n            for api_key in self.zappa.get_api_keys(api_id, self.api_stage):\n                status_dict[\"API Gateway x-api-key\"] = api_key\n\n            # There literally isn't a better way to do this.\n            # AWS provides no way to tie a APIGW domain name to its Lambda function.\n            domain_url = self.stage_config.get('domain', None)\n            base_path = self.stage_config.get('base_path', None)\n            if domain_url:\n                status_dict[\"Domain URL\"] = 'https://' + domain_url\n                if base_path:\n                    status_dict[\"Domain URL\"] += '/' + base_path\n            else:\n                status_dict[\"Domain URL\"] = \"None Supplied\"\n\n        # Scheduled Events\n        event_rules = self.zappa.get_event_rules_for_lambda(lambda_arn=self.lambda_arn)\n        status_dict[\"Num. Event Rules\"] = len(event_rules)\n        if len(event_rules) > 0:\n            status_dict['Events'] = []\n        for rule in event_rules:\n            event_dict = {}\n            rule_name = rule['Name']\n            event_dict[\"Event Rule Name\"] = rule_name\n            event_dict[\"Event Rule Schedule\"] = rule.get(u'ScheduleExpression', None)\n            event_dict[\"Event Rule State\"] = rule.get(u'State', None).title()\n            event_dict[\"Event Rule ARN\"] = rule.get(u'Arn', None)\n            status_dict['Events'].append(event_dict)\n\n        if return_json:\n            # Putting the status in machine readable format\n            # https://github.com/Miserlou/Zappa/issues/407\n            print(json.dumpsJSON(status_dict))\n        else:\n            click.echo(\"Status for \" + click.style(self.lambda_name, bold=True) + \": \")\n            for k, v in status_dict.items():\n                if k == 'Events':\n                    # Events are a list of dicts\n                    for event in v:\n                        for item_k, item_v in event.items():\n                            tabular_print(item_k, item_v)\n                else:\n                    tabular_print(k, v)\n\n        # TODO: S3/SQS/etc. type events?\n\n        return True", "response": "Get the status of the current deployment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the environment contains only strings", "response": "def check_environment(self, environment):\n        \"\"\"\n        Make sure the environment contains only strings\n\n        (since putenv needs a string)\n        \"\"\"\n\n        non_strings = []\n        for (k,v) in environment.items():\n            if not isinstance(v, basestring):\n                non_strings.append(k)\n        if non_strings:\n            raise ValueError(\"The following environment variables are not strings: {}\".format(\", \".join(non_strings)))\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize a new Zappa project by creating a new Zappa_settings. json in a guided process.", "response": "def init(self, settings_file=\"zappa_settings.json\"):\n        \"\"\"\n        Initialize a new Zappa project by creating a new zappa_settings.json in a guided process.\n\n        This should probably be broken up into few separate componants once it's stable.\n        Testing these inputs requires monkeypatching with mock, which isn't pretty.\n\n        \"\"\"\n\n        # Make sure we're in a venv.\n        self.check_venv()\n\n        # Ensure that we don't already have a zappa_settings file.\n        if os.path.isfile(settings_file):\n            raise ClickException(\"This project already has a \" + click.style(\"{0!s} file\".format(settings_file), fg=\"red\", bold=True) + \"!\")\n\n        # Explain system.\n        click.echo(click.style(u\"\"\"\\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2557\n\u255a\u2550\u2550\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\n  \u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\n \u2588\u2588\u2588\u2554\u255d  \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551     \u2588\u2588\u2551     \u2588\u2588\u2551  \u2588\u2588\u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d     \u255a\u2550\u255d     \u255a\u2550\u255d  \u255a\u2550\u255d\\n\"\"\", fg='green', bold=True))\n\n        click.echo(click.style(\"Welcome to \", bold=True) + click.style(\"Zappa\", fg='green', bold=True) + click.style(\"!\\n\", bold=True))\n        click.echo(click.style(\"Zappa\", bold=True) + \" is a system for running server-less Python web applications\"\n                                                     \" on AWS Lambda and AWS API Gateway.\")\n        click.echo(\"This `init` command will help you create and configure your new Zappa deployment.\")\n        click.echo(\"Let's get started!\\n\")\n\n        # Create Env\n        while True:\n            click.echo(\"Your Zappa configuration can support multiple production stages, like '\" +\n                       click.style(\"dev\", bold=True)  + \"', '\" + click.style(\"staging\", bold=True)  + \"', and '\" +\n                       click.style(\"production\", bold=True)  + \"'.\")\n            env = input(\"What do you want to call this environment (default 'dev'): \") or \"dev\"\n            try:\n                self.check_stage_name(env)\n                break\n            except ValueError:\n                click.echo(click.style(\"Stage names must match a-zA-Z0-9_\", fg=\"red\"))\n\n        # Detect AWS profiles and regions\n        # If anyone knows a more straightforward way to easily detect and parse AWS profiles I'm happy to change this, feels like a hack\n        session = botocore.session.Session()\n        config  = session.full_config\n        profiles = config.get(\"profiles\", {})\n        profile_names = list(profiles.keys())\n\n        click.echo(\"\\nAWS Lambda and API Gateway are only available in certain regions. \"\\\n                   \"Let's check to make sure you have a profile set up in one that will work.\")\n\n        if not profile_names:\n            profile_name, profile = None, None\n            click.echo(\"We couldn't find an AWS profile to use. Before using Zappa, you'll need to set one up. See here for more info: {}\"\n                       .format(click.style(BOTO3_CONFIG_DOCS_URL, fg=\"blue\", underline=True)))\n        elif len(profile_names) == 1:\n            profile_name = profile_names[0]\n            profile = profiles[profile_name]\n            click.echo(\"Okay, using profile {}!\".format(click.style(profile_name, bold=True)))\n        else:\n            if \"default\" in profile_names:\n                default_profile = [p for p in profile_names if p == \"default\"][0]\n            else:\n                default_profile = profile_names[0]\n\n            while True:\n                profile_name = input(\"We found the following profiles: {}, and {}. \"\\\n                                         \"Which would you like us to use? (default '{}'): \"\n                                         .format(\n                                             ', '.join(profile_names[:-1]),\n                                             profile_names[-1],\n                                             default_profile\n                                         )) or default_profile\n                if profile_name in profiles:\n                    profile = profiles[profile_name]\n                    break\n                else:\n                    click.echo(\"Please enter a valid name for your AWS profile.\")\n\n        profile_region = profile.get(\"region\") if profile else None\n\n        # Create Bucket\n        click.echo(\"\\nYour Zappa deployments will need to be uploaded to a \" + click.style(\"private S3 bucket\", bold=True)  + \".\")\n        click.echo(\"If you don't have a bucket yet, we'll create one for you too.\")\n        default_bucket = \"zappa-\" + ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(9))\n        while True:\n            bucket = input(\"What do you want to call your bucket? (default '%s'): \" % default_bucket) or default_bucket\n\n            if is_valid_bucket_name(bucket):\n                break\n\n            click.echo(click.style(\"Invalid bucket name!\", bold=True))\n            click.echo(\"S3 buckets must be named according to the following rules:\")\n            click.echo(\"\"\"* Bucket names must be unique across all existing bucket names in Amazon S3.\n* Bucket names must comply with DNS naming conventions.\n* Bucket names must be at least 3 and no more than 63 characters long.\n* Bucket names must not contain uppercase characters or underscores.\n* Bucket names must start with a lowercase letter or number.\n* Bucket names must be a series of one or more labels. Adjacent labels are separated\n  by a single period (.). Bucket names can contain lowercase letters, numbers, and\n  hyphens. Each label must start and end with a lowercase letter or a number.\n* Bucket names must not be formatted as an IP address (for example, 192.168.5.4).\n* When you use virtual hosted\u2013style buckets with Secure Sockets Layer (SSL), the SSL\n  wildcard certificate only matches buckets that don't contain periods. To work around\n  this, use HTTP or write your own certificate verification logic. We recommend that\n  you do not use periods (\".\") in bucket names when using virtual hosted\u2013style buckets.\n\"\"\")\n\n\n        # Detect Django/Flask\n        try: # pragma: no cover\n            import django\n            has_django = True\n        except ImportError as e:\n            has_django = False\n\n        try: # pragma: no cover\n            import flask\n            has_flask = True\n        except ImportError as e:\n            has_flask = False\n\n        print('')\n        # App-specific\n        if has_django: # pragma: no cover\n            click.echo(\"It looks like this is a \" + click.style(\"Django\", bold=True)  + \" application!\")\n            click.echo(\"What is the \" + click.style(\"module path\", bold=True)  + \" to your projects's Django settings?\")\n            django_settings = None\n\n            matches = detect_django_settings()\n            while django_settings in [None, '']:\n                if matches:\n                    click.echo(\"We discovered: \" + click.style(', '.join('{}'.format(i) for v, i in enumerate(matches)), bold=True))\n                    django_settings = input(\"Where are your project's settings? (default '%s'): \" % matches[0]) or matches[0]\n                else:\n                    click.echo(\"(This will likely be something like 'your_project.settings')\")\n                    django_settings = input(\"Where are your project's settings?: \")\n            django_settings = django_settings.replace(\"'\", \"\")\n            django_settings = django_settings.replace('\"', \"\")\n        else:\n            matches = None\n            if has_flask:\n                click.echo(\"It looks like this is a \" + click.style(\"Flask\", bold=True)  + \" application.\")\n                matches = detect_flask_apps()\n            click.echo(\"What's the \" + click.style(\"modular path\", bold=True)  + \" to your app's function?\")\n            click.echo(\"This will likely be something like 'your_module.app'.\")\n            app_function = None\n            while app_function in [None, '']:\n                if matches:\n                    click.echo(\"We discovered: \" + click.style(', '.join('{}'.format(i) for v, i in enumerate(matches)), bold=True))\n                    app_function = input(\"Where is your app's function? (default '%s'): \" % matches[0]) or matches[0]\n                else:\n                    app_function = input(\"Where is your app's function?: \")\n            app_function = app_function.replace(\"'\", \"\")\n            app_function = app_function.replace('\"', \"\")\n\n        # TODO: Create VPC?\n        # Memory size? Time limit?\n        # Domain? LE keys? Region?\n        # 'Advanced Settings' mode?\n\n        # Globalize\n        click.echo(\"\\nYou can optionally deploy to \" + click.style(\"all available regions\", bold=True)  + \" in order to provide fast global service.\")\n        click.echo(\"If you are using Zappa for the first time, you probably don't want to do this!\")\n        global_deployment = False\n        while True:\n            global_type = input(\"Would you like to deploy this application \" + click.style(\"globally\", bold=True)  + \"? (default 'n') [y/n/(p)rimary]: \")\n            if not global_type:\n                break\n            if global_type.lower() in [\"y\", \"yes\", \"p\", \"primary\"]:\n                global_deployment = True\n                break\n            if global_type.lower() in [\"n\", \"no\"]:\n                global_deployment = False\n                break\n\n        # The given environment name\n        zappa_settings = {\n            env: {\n                'profile_name': profile_name,\n                's3_bucket': bucket,\n                'runtime': get_venv_from_python_version(),\n                'project_name': self.get_project_name()\n            }\n        }\n\n        if profile_region:\n            zappa_settings[env]['aws_region'] = profile_region\n\n        if has_django:\n            zappa_settings[env]['django_settings'] = django_settings\n        else:\n            zappa_settings[env]['app_function'] = app_function\n\n        # Global Region Deployment\n        if global_deployment:\n            additional_regions = [r for r in API_GATEWAY_REGIONS if r != profile_region]\n            # Create additional stages\n            if global_type.lower() in [\"p\", \"primary\"]:\n                additional_regions = [r for r in additional_regions if '-1' in r]\n\n            for region in additional_regions:\n                env_name = env + '_' + region.replace('-', '_')\n                g_env = {\n                    env_name: {\n                        'extends': env,\n                        'aws_region': region\n                    }\n                }\n                zappa_settings.update(g_env)\n\n        import json as json # hjson is fine for loading, not fine for writing.\n        zappa_settings_json = json.dumps(zappa_settings, sort_keys=True, indent=4)\n\n        click.echo(\"\\nOkay, here's your \" + click.style(\"zappa_settings.json\", bold=True) + \":\\n\")\n        click.echo(click.style(zappa_settings_json, fg=\"yellow\", bold=False))\n\n        confirm = input(\"\\nDoes this look \" + click.style(\"okay\", bold=True, fg=\"green\")  + \"? (default 'y') [y/n]: \") or 'yes'\n        if confirm[0] not in ['y', 'Y', 'yes', 'YES']:\n            click.echo(\"\" + click.style(\"Sorry\", bold=True, fg='red') + \" to hear that! Please init again.\")\n            return\n\n        # Write\n        with open(\"zappa_settings.json\", \"w\") as zappa_settings_file:\n            zappa_settings_file.write(zappa_settings_json)\n\n        if global_deployment:\n            click.echo(\"\\n\" + click.style(\"Done\", bold=True) + \"! You can also \" + click.style(\"deploy all\", bold=True)  + \" by executing:\\n\")\n            click.echo(click.style(\"\\t$ zappa deploy --all\", bold=True))\n\n            click.echo(\"\\nAfter that, you can \" + click.style(\"update\", bold=True) + \" your application code with:\\n\")\n            click.echo(click.style(\"\\t$ zappa update --all\", bold=True))\n        else:\n            click.echo(\"\\n\" + click.style(\"Done\", bold=True) + \"! Now you can \" + click.style(\"deploy\", bold=True)  + \" your Zappa application by executing:\\n\")\n            click.echo(click.style(\"\\t$ zappa deploy %s\" % env, bold=True))\n\n            click.echo(\"\\nAfter that, you can \" + click.style(\"update\", bold=True) + \" your application code with:\\n\")\n            click.echo(click.style(\"\\t$ zappa update %s\" % env, bold=True))\n\n        click.echo(\"\\nTo learn more, check out our project page on \" + click.style(\"GitHub\", bold=True) +\n                   \" here: \" + click.style(\"https://github.com/Miserlou/Zappa\", fg=\"cyan\", bold=True))\n        click.echo(\"and stop by our \" + click.style(\"Slack\", bold=True) + \" channel here: \" +\n                   click.style(\"https://slack.zappa.io\", fg=\"cyan\", bold=True))\n        click.echo(\"\\nEnjoy!,\")\n        click.echo(\" ~ Team \" + click.style(\"Zappa\", bold=True) + \"!\")\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncertifying a domain certificate for this application.", "response": "def certify(self, no_confirm=True, manual=False):\n        \"\"\"\n        Register or update a domain certificate for this env.\n        \"\"\"\n\n        if not self.domain:\n            raise ClickException(\"Can't certify a domain without \" + click.style(\"domain\", fg=\"red\", bold=True) + \" configured!\")\n\n        if not no_confirm: # pragma: no cover\n            confirm = input(\"Are you sure you want to certify? [y/n] \")\n            if confirm != 'y':\n                return\n\n        # Make sure this isn't already deployed.\n        deployed_versions = self.zappa.get_lambda_function_versions(self.lambda_name)\n        if len(deployed_versions) == 0:\n            raise ClickException(\"This application \" + click.style(\"isn't deployed yet\", fg=\"red\") +\n                                 \" - did you mean to call \" + click.style(\"deploy\", bold=True) + \"?\")\n\n\n        account_key_location = self.stage_config.get('lets_encrypt_key', None)\n        cert_location = self.stage_config.get('certificate', None)\n        cert_key_location = self.stage_config.get('certificate_key', None)\n        cert_chain_location = self.stage_config.get('certificate_chain', None)\n        cert_arn = self.stage_config.get('certificate_arn', None)\n        base_path = self.stage_config.get('base_path', None)\n\n        # These are sensitive\n        certificate_body = None\n        certificate_private_key = None\n        certificate_chain = None\n\n        # Prepare for custom Let's Encrypt\n        if not cert_location and not cert_arn:\n            if not account_key_location:\n                raise ClickException(\"Can't certify a domain without \" + click.style(\"lets_encrypt_key\", fg=\"red\", bold=True) +\n                                     \" or \" + click.style(\"certificate\", fg=\"red\", bold=True)+\n                                     \" or \" + click.style(\"certificate_arn\", fg=\"red\", bold=True) + \" configured!\")\n\n            # Get install account_key to /tmp/account_key.pem\n            from .letsencrypt import gettempdir\n            if account_key_location.startswith('s3://'):\n                bucket, key_name = parse_s3_url(account_key_location)\n                self.zappa.s3_client.download_file(bucket, key_name, os.path.join(gettempdir(), 'account.key'))\n            else:\n                from shutil import copyfile\n                copyfile(account_key_location, os.path.join(gettempdir(), 'account.key'))\n\n        # Prepare for Custom SSL\n        elif not account_key_location and not cert_arn:\n            if not cert_location or not cert_key_location or not cert_chain_location:\n                raise ClickException(\"Can't certify a domain without \" +\n                                     click.style(\"certificate, certificate_key and certificate_chain\", fg=\"red\", bold=True) + \" configured!\")\n\n            # Read the supplied certificates.\n            with open(cert_location) as f:\n                certificate_body = f.read()\n\n            with open(cert_key_location) as f:\n                certificate_private_key = f.read()\n\n            with open(cert_chain_location) as f:\n                certificate_chain = f.read()\n\n\n        click.echo(\"Certifying domain \" + click.style(self.domain, fg=\"green\", bold=True) + \"..\")\n\n        # Get cert and update domain.\n\n        # Let's Encrypt\n        if not cert_location and not cert_arn:\n            from .letsencrypt import get_cert_and_update_domain\n            cert_success = get_cert_and_update_domain(\n                    self.zappa,\n                    self.lambda_name,\n                    self.api_stage,\n                    self.domain,\n                    manual\n                )\n\n        # Custom SSL / ACM\n        else:\n            route53 = self.stage_config.get('route53_enabled', True)\n            if not self.zappa.get_domain_name(self.domain, route53=route53):\n                dns_name = self.zappa.create_domain_name(\n                    domain_name=self.domain,\n                    certificate_name=self.domain + \"-Zappa-Cert\",\n                    certificate_body=certificate_body,\n                    certificate_private_key=certificate_private_key,\n                    certificate_chain=certificate_chain,\n                    certificate_arn=cert_arn,\n                    lambda_name=self.lambda_name,\n                    stage=self.api_stage,\n                    base_path=base_path\n                )\n                if route53:\n                    self.zappa.update_route53_records(self.domain, dns_name)\n                print(\"Created a new domain name with supplied certificate. Please note that it can take up to 40 minutes for this domain to be \"\n                      \"created and propagated through AWS, but it requires no further work on your part.\")\n            else:\n                self.zappa.update_domain_name(\n                    domain_name=self.domain,\n                    certificate_name=self.domain + \"-Zappa-Cert\",\n                    certificate_body=certificate_body,\n                    certificate_private_key=certificate_private_key,\n                    certificate_chain=certificate_chain,\n                    certificate_arn=cert_arn,\n                    lambda_name=self.lambda_name,\n                    stage=self.api_stage,\n                    route53=route53,\n                    base_path=base_path\n                )\n\n            cert_success = True\n\n        if cert_success:\n            click.echo(\"Certificate \" + click.style(\"updated\", fg=\"green\", bold=True) + \"!\")\n        else:\n            click.echo(click.style(\"Failed\", fg=\"red\", bold=True) + \" to generate or install certificate! :(\")\n            click.echo(\"\\n==============\\n\")\n            shamelessly_promote()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nspawns a debug shell.", "response": "def shell(self):\n        \"\"\"\n        Spawn a debug shell.\n        \"\"\"\n        click.echo(click.style(\"NOTICE!\", fg=\"yellow\", bold=True) + \" This is a \" + click.style(\"local\", fg=\"green\", bold=True) + \" shell, inside a \" + click.style(\"Zappa\", bold=True) + \" object!\")\n        self.zappa.shell()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nallows the execution of custom code between creation of the zip file and deployment to AWS.", "response": "def callback(self, position):\n        \"\"\"\n        Allows the execution of custom code between creation of the zip file and deployment to AWS.\n\n        :return: None\n        \"\"\"\n\n        callbacks = self.stage_config.get('callbacks', {})\n        callback = callbacks.get(position)\n\n        if callback:\n            (mod_path, cb_func_name) = callback.rsplit('.', 1)\n\n            try:  # Prefer callback in working directory\n                if mod_path.count('.') >= 1:  # Callback function is nested in a folder\n                    (mod_folder_path, mod_name) = mod_path.rsplit('.', 1)\n                    mod_folder_path_fragments = mod_folder_path.split('.')\n                    working_dir = os.path.join(os.getcwd(), *mod_folder_path_fragments)\n                else:\n                    mod_name = mod_path\n                    working_dir = os.getcwd()\n\n                working_dir_importer = pkgutil.get_importer(working_dir)\n                module_ = working_dir_importer.find_module(mod_name).load_module(mod_name)\n\n            except (ImportError, AttributeError):\n\n                try: # Callback func might be in virtualenv\n                    module_ = importlib.import_module(mod_path)\n                except ImportError: # pragma: no cover\n                    raise ClickException(click.style(\"Failed \", fg=\"red\") + 'to ' + click.style(\n                        \"import {position} callback \".format(position=position),\n                        bold=True) + 'module: \"{mod_path}\"'.format(mod_path=click.style(mod_path, bold=True)))\n\n            if not hasattr(module_, cb_func_name): # pragma: no cover\n                raise ClickException(click.style(\"Failed \", fg=\"red\") + 'to ' + click.style(\n                    \"find {position} callback \".format(position=position), bold=True) + 'function: \"{cb_func_name}\" '.format(\n                    cb_func_name=click.style(cb_func_name, bold=True)) + 'in module \"{mod_path}\"'.format(mod_path=mod_path))\n\n\n            cb_func = getattr(module_, cb_func_name)\n            cb_func(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if there s a new Zappa version available.", "response": "def check_for_update(self):\n        \"\"\"\n        Print a warning if there's a new Zappa version available.\n        \"\"\"\n        try:\n            version = pkg_resources.require(\"zappa\")[0].version\n            updateable = check_new_version_available(version)\n            if updateable:\n                click.echo(click.style(\"Important!\", fg=\"yellow\", bold=True) +\n                           \" A new version of \" + click.style(\"Zappa\", bold=True) + \" is available!\")\n                click.echo(\"Upgrade with: \" + click.style(\"pip install zappa --upgrade\", bold=True))\n                click.echo(\"Visit the project page on GitHub to see the latest changes: \" +\n                           click.style(\"https://github.com/Miserlou/Zappa\", bold=True))\n        except Exception as e: # pragma: no cover\n            print(e)\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_settings(self, settings_file=None, session=None):\n\n        # Ensure we're passed a valid settings file.\n        if not settings_file:\n            settings_file = self.get_json_or_yaml_settings()\n        if not os.path.isfile(settings_file):\n            raise ClickException(\"Please configure your zappa_settings file.\")\n\n        # Load up file\n        self.load_settings_file(settings_file)\n\n        # Make sure that the stages are valid names:\n        for stage_name in self.zappa_settings.keys():\n            try:\n                self.check_stage_name(stage_name)\n            except ValueError:\n                raise ValueError(\"API stage names must match a-zA-Z0-9_ ; '{0!s}' does not.\".format(stage_name))\n\n        # Make sure that this stage is our settings\n        if self.api_stage not in self.zappa_settings.keys():\n            raise ClickException(\"Please define stage '{0!s}' in your Zappa settings.\".format(self.api_stage))\n\n        # We need a working title for this project. Use one if supplied, else cwd dirname.\n        if 'project_name' in self.stage_config: # pragma: no cover\n            # If the name is invalid, this will throw an exception with message up stack\n            self.project_name = validate_name(self.stage_config['project_name'])\n        else:\n            self.project_name = self.get_project_name()\n\n        # The name of the actual AWS Lambda function, ex, 'helloworld-dev'\n        # Assume that we already have have validated the name beforehand.\n        # Related:  https://github.com/Miserlou/Zappa/pull/664\n        #           https://github.com/Miserlou/Zappa/issues/678\n        #           And various others from Slack.\n        self.lambda_name = slugify.slugify(self.project_name + '-' + self.api_stage)\n\n        # Load stage-specific settings\n        self.s3_bucket_name = self.stage_config.get('s3_bucket', \"zappa-\" + ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(9)))\n        self.vpc_config = self.stage_config.get('vpc_config', {})\n        self.memory_size = self.stage_config.get('memory_size', 512)\n        self.app_function = self.stage_config.get('app_function', None)\n        self.exception_handler = self.stage_config.get('exception_handler', None)\n        self.aws_region = self.stage_config.get('aws_region', None)\n        self.debug = self.stage_config.get('debug', True)\n        self.prebuild_script = self.stage_config.get('prebuild_script', None)\n        self.profile_name = self.stage_config.get('profile_name', None)\n        self.log_level = self.stage_config.get('log_level', \"DEBUG\")\n        self.domain = self.stage_config.get('domain', None)\n        self.base_path = self.stage_config.get('base_path', None)\n        self.timeout_seconds = self.stage_config.get('timeout_seconds', 30)\n        dead_letter_arn = self.stage_config.get('dead_letter_arn', '')\n        self.dead_letter_config = {'TargetArn': dead_letter_arn} if dead_letter_arn else {}\n        self.cognito = self.stage_config.get('cognito', None)\n        self.num_retained_versions = self.stage_config.get('num_retained_versions',None)\n\n        # Check for valid values of num_retained_versions\n        if self.num_retained_versions is not None and type(self.num_retained_versions) is not int:\n            raise ClickException(\"Please supply either an integer or null for num_retained_versions in the zappa_settings.json. Found %s\" % type(self.num_retained_versions))\n        elif type(self.num_retained_versions) is int and self.num_retained_versions<1:\n            raise ClickException(\"The value for num_retained_versions in the zappa_settings.json should be greater than 0.\")\n\n        # Provide legacy support for `use_apigateway`, now `apigateway_enabled`.\n        # https://github.com/Miserlou/Zappa/issues/490\n        # https://github.com/Miserlou/Zappa/issues/493\n        self.use_apigateway = self.stage_config.get('use_apigateway', True)\n        if self.use_apigateway:\n            self.use_apigateway = self.stage_config.get('apigateway_enabled', True)\n        self.apigateway_description = self.stage_config.get('apigateway_description', None)\n\n        self.lambda_handler = self.stage_config.get('lambda_handler', 'handler.lambda_handler')\n        # DEPRECATED. https://github.com/Miserlou/Zappa/issues/456\n        self.remote_env_bucket = self.stage_config.get('remote_env_bucket', None)\n        self.remote_env_file = self.stage_config.get('remote_env_file', None)\n        self.remote_env = self.stage_config.get('remote_env', None)\n        self.settings_file = self.stage_config.get('settings_file', None)\n        self.django_settings = self.stage_config.get('django_settings', None)\n        self.manage_roles = self.stage_config.get('manage_roles', True)\n        self.binary_support = self.stage_config.get('binary_support', True)\n        self.api_key_required = self.stage_config.get('api_key_required', False)\n        self.api_key = self.stage_config.get('api_key')\n        self.endpoint_configuration = self.stage_config.get('endpoint_configuration', None)\n        self.iam_authorization = self.stage_config.get('iam_authorization', False)\n        self.cors = self.stage_config.get(\"cors\", False)\n        self.lambda_description = self.stage_config.get('lambda_description', \"Zappa Deployment\")\n        self.environment_variables = self.stage_config.get('environment_variables', {})\n        self.aws_environment_variables = self.stage_config.get('aws_environment_variables', {})\n        self.check_environment(self.environment_variables)\n        self.authorizer = self.stage_config.get('authorizer', {})\n        self.runtime = self.stage_config.get('runtime', get_runtime_from_python_version())\n        self.aws_kms_key_arn = self.stage_config.get('aws_kms_key_arn', '')\n        self.context_header_mappings = self.stage_config.get('context_header_mappings', {})\n        self.xray_tracing = self.stage_config.get('xray_tracing', False)\n        self.desired_role_arn = self.stage_config.get('role_arn')\n\n        # Load ALB-related settings\n        self.use_alb = self.stage_config.get('alb_enabled', False)\n        self.alb_vpc_config = self.stage_config.get('alb_vpc_config', {})\n\n        # Additional tags\n        self.tags = self.stage_config.get('tags', {})\n\n        desired_role_name = self.lambda_name + \"-ZappaLambdaExecutionRole\"\n        self.zappa = Zappa( boto_session=session,\n                            profile_name=self.profile_name,\n                            aws_region=self.aws_region,\n                            load_credentials=self.load_credentials,\n                            desired_role_name=desired_role_name,\n                            desired_role_arn=self.desired_role_arn,\n                            runtime=self.runtime,\n                            tags=self.tags,\n                            endpoint_urls=self.stage_config.get('aws_endpoint_urls',{}),\n                            xray_tracing=self.xray_tracing\n                        )\n\n        for setting in CUSTOM_SETTINGS:\n            if setting in self.stage_config:\n                setting_val = self.stage_config[setting]\n                # Read the policy file contents.\n                if setting.endswith('policy'):\n                    with open(setting_val, 'r') as f:\n                        setting_val = f.read()\n                setattr(self.zappa, setting, setting_val)\n\n        if self.app_function:\n            self.collision_warning(self.app_function)\n            if self.app_function[-3:] == '.py':\n                click.echo(click.style(\"Warning!\", fg=\"red\", bold=True) +\n                           \" Your app_function is pointing to a \" + click.style(\"file and not a function\", bold=True) +\n                           \"! It should probably be something like 'my_file.app', not 'my_file.py'!\")\n\n        return self.zappa", "response": "Load the local Zappa settings file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_json_or_yaml_settings(self, settings_name=\"zappa_settings\"):\n        zs_json = settings_name + \".json\"\n        zs_yml = settings_name + \".yml\"\n        zs_yaml = settings_name + \".yaml\"\n        zs_toml = settings_name + \".toml\"\n\n        # Must have at least one\n        if not os.path.isfile(zs_json) \\\n            and not os.path.isfile(zs_yml) \\\n            and not os.path.isfile(zs_yaml) \\\n            and not os.path.isfile(zs_toml):\n            raise ClickException(\"Please configure a zappa_settings file or call `zappa init`.\")\n\n        # Prefer JSON\n        if os.path.isfile(zs_json):\n            settings_file = zs_json\n        elif os.path.isfile(zs_toml):\n            settings_file = zs_toml\n        elif os.path.isfile(zs_yml):\n            settings_file = zs_yml\n        else:\n            settings_file = zs_yaml\n\n        return settings_file", "response": "Return the path to the zappa_settings file as JSON or YAML as appropriate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading our settings file.", "response": "def load_settings_file(self, settings_file=None):\n        \"\"\"\n        Load our settings file.\n        \"\"\"\n\n        if not settings_file:\n            settings_file = self.get_json_or_yaml_settings()\n        if not os.path.isfile(settings_file):\n            raise ClickException(\"Please configure your zappa_settings file or call `zappa init`.\")\n\n        path, ext = os.path.splitext(settings_file)\n        if ext == '.yml' or ext == '.yaml':\n            with open(settings_file) as yaml_file:\n                try:\n                    self.zappa_settings = yaml.load(yaml_file)\n                except ValueError: # pragma: no cover\n                    raise ValueError(\"Unable to load the Zappa settings YAML. It may be malformed.\")\n        elif ext == '.toml':\n            with open(settings_file) as toml_file:\n                try:\n                    self.zappa_settings = toml.load(toml_file)\n                except ValueError: # pragma: no cover\n                    raise ValueError(\"Unable to load the Zappa settings TOML. It may be malformed.\")\n        else:\n            with open(settings_file) as json_file:\n                try:\n                    self.zappa_settings = json.load(json_file)\n                except ValueError: # pragma: no cover\n                    raise ValueError(\"Unable to load the Zappa settings JSON. It may be malformed.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the Lambda package and the handler file.", "response": "def create_package(self, output=None):\n        \"\"\"\n        Ensure that the package can be properly configured,\n        and then create it.\n\n        \"\"\"\n\n        # Create the Lambda zip package (includes project and virtualenvironment)\n        # Also define the path the handler file so it can be copied to the zip\n        # root for Lambda.\n        current_file = os.path.dirname(os.path.abspath(\n            inspect.getfile(inspect.currentframe())))\n        handler_file = os.sep.join(current_file.split(os.sep)[0:]) + os.sep + 'handler.py'\n\n        # Create the zip file(s)\n        if self.stage_config.get('slim_handler', False):\n            # Create two zips. One with the application and the other with just the handler.\n            # https://github.com/Miserlou/Zappa/issues/510\n            self.zip_path = self.zappa.create_lambda_zip(\n                prefix=self.lambda_name,\n                use_precompiled_packages=self.stage_config.get('use_precompiled_packages', True),\n                exclude=self.stage_config.get('exclude', []),\n                disable_progress=self.disable_progress,\n                archive_format='tarball'\n            )\n\n            # Make sure the normal venv is not included in the handler's zip\n            exclude = self.stage_config.get('exclude', [])\n            cur_venv = self.zappa.get_current_venv()\n            exclude.append(cur_venv.split('/')[-1])\n            self.handler_path = self.zappa.create_lambda_zip(\n                prefix='handler_{0!s}'.format(self.lambda_name),\n                venv=self.zappa.create_handler_venv(),\n                handler_file=handler_file,\n                slim_handler=True,\n                exclude=exclude,\n                output=output,\n                disable_progress=self.disable_progress\n            )\n        else:\n\n            # Custom excludes for different versions.\n            # Related: https://github.com/kennethreitz/requests/issues/3985\n            if sys.version_info[0] < 3:\n                # Exclude packages already builtin to the python lambda environment\n                # Related: https://github.com/Miserlou/Zappa/issues/556\n                exclude = self.stage_config.get(\n                        'exclude', [\n                                        \"boto3\",\n                                        \"dateutil\",\n                                        \"botocore\",\n                                        \"s3transfer\",\n                                        \"six.py\",\n                                        \"jmespath\",\n                                        \"concurrent\"\n                                    ])\n            else:\n                # This could be python3.6 optimized.\n                exclude = self.stage_config.get(\n                        'exclude', [\n                                        \"boto3\",\n                                        \"dateutil\",\n                                        \"botocore\",\n                                        \"s3transfer\",\n                                        \"concurrent\"\n                                    ])\n\n            # Create a single zip that has the handler and application\n            self.zip_path = self.zappa.create_lambda_zip(\n                prefix=self.lambda_name,\n                handler_file=handler_file,\n                use_precompiled_packages=self.stage_config.get('use_precompiled_packages', True),\n                exclude=exclude,\n                output=output,\n                disable_progress=self.disable_progress\n            )\n\n            # Warn if this is too large for Lambda.\n            file_stats = os.stat(self.zip_path)\n            if file_stats.st_size > 52428800:  # pragma: no cover\n                print('\\n\\nWarning: Application zip package is likely to be too large for AWS Lambda. '\n                      'Try setting \"slim_handler\" to true in your Zappa settings file.\\n\\n')\n\n        # Throw custom settings into the zip that handles requests\n        if self.stage_config.get('slim_handler', False):\n            handler_zip = self.handler_path\n        else:\n            handler_zip = self.zip_path\n\n        with zipfile.ZipFile(handler_zip, 'a') as lambda_zip:\n\n            settings_s = \"# Generated by Zappa\\n\"\n\n            if self.app_function:\n                if '.' not in self.app_function: # pragma: no cover\n                    raise ClickException(\"Your \" + click.style(\"app_function\", fg='red', bold=True) + \" value is not a modular path.\" +\n                        \" It needs to be in the format `\" + click.style(\"your_module.your_app_object\", bold=True) + \"`.\")\n                app_module, app_function = self.app_function.rsplit('.', 1)\n                settings_s = settings_s + \"APP_MODULE='{0!s}'\\nAPP_FUNCTION='{1!s}'\\n\".format(app_module, app_function)\n\n            if self.exception_handler:\n                settings_s += \"EXCEPTION_HANDLER='{0!s}'\\n\".format(self.exception_handler)\n            else:\n                settings_s += \"EXCEPTION_HANDLER=None\\n\"\n\n            if self.debug:\n                settings_s = settings_s + \"DEBUG=True\\n\"\n            else:\n                settings_s = settings_s + \"DEBUG=False\\n\"\n\n            settings_s = settings_s + \"LOG_LEVEL='{0!s}'\\n\".format((self.log_level))\n\n            if self.binary_support:\n                settings_s = settings_s + \"BINARY_SUPPORT=True\\n\"\n            else:\n                settings_s = settings_s + \"BINARY_SUPPORT=False\\n\"\n\n            head_map_dict = {}\n            head_map_dict.update(dict(self.context_header_mappings))\n            settings_s = settings_s + \"CONTEXT_HEADER_MAPPINGS={0}\\n\".format(\n                head_map_dict\n            )\n\n            # If we're on a domain, we don't need to define the /<<env>> in\n            # the WSGI PATH\n            if self.domain:\n                settings_s = settings_s + \"DOMAIN='{0!s}'\\n\".format((self.domain))\n            else:\n                settings_s = settings_s + \"DOMAIN=None\\n\"\n\n            if self.base_path:\n                settings_s = settings_s + \"BASE_PATH='{0!s}'\\n\".format((self.base_path))\n            else:\n                settings_s = settings_s + \"BASE_PATH=None\\n\"\n\n            # Pass through remote config bucket and path\n            if self.remote_env:\n                settings_s = settings_s + \"REMOTE_ENV='{0!s}'\\n\".format(\n                    self.remote_env\n                )\n            # DEPRECATED. use remove_env instead\n            elif self.remote_env_bucket and self.remote_env_file:\n                settings_s = settings_s + \"REMOTE_ENV='s3://{0!s}/{1!s}'\\n\".format(\n                    self.remote_env_bucket, self.remote_env_file\n                )\n\n            # Local envs\n            env_dict = {}\n            if self.aws_region:\n                env_dict['AWS_REGION'] = self.aws_region\n            env_dict.update(dict(self.environment_variables))\n\n            # Environment variable keys must be ascii\n            # https://github.com/Miserlou/Zappa/issues/604\n            # https://github.com/Miserlou/Zappa/issues/998\n            try:\n                env_dict = dict((k.encode('ascii').decode('ascii'), v) for (k, v) in env_dict.items())\n            except Exception:\n                raise ValueError(\"Environment variable keys must be ascii.\")\n\n            settings_s = settings_s + \"ENVIRONMENT_VARIABLES={0}\\n\".format(\n                    env_dict\n                )\n\n            # We can be environment-aware\n            settings_s = settings_s + \"API_STAGE='{0!s}'\\n\".format((self.api_stage))\n            settings_s = settings_s + \"PROJECT_NAME='{0!s}'\\n\".format((self.project_name))\n\n            if self.settings_file:\n                settings_s = settings_s + \"SETTINGS_FILE='{0!s}'\\n\".format((self.settings_file))\n            else:\n                settings_s = settings_s + \"SETTINGS_FILE=None\\n\"\n\n            if self.django_settings:\n                settings_s = settings_s + \"DJANGO_SETTINGS='{0!s}'\\n\".format((self.django_settings))\n            else:\n                settings_s = settings_s + \"DJANGO_SETTINGS=None\\n\"\n\n            # If slim handler, path to project zip\n            if self.stage_config.get('slim_handler', False):\n                settings_s += \"ARCHIVE_PATH='s3://{0!s}/{1!s}_{2!s}_current_project.tar.gz'\\n\".format(\n                    self.s3_bucket_name, self.api_stage, self.project_name)\n\n                # since includes are for slim handler add the setting here by joining arbitrary list from zappa_settings file\n                # and tell the handler we are the slim_handler\n                # https://github.com/Miserlou/Zappa/issues/776\n                settings_s += \"SLIM_HANDLER=True\\n\"\n\n                include = self.stage_config.get('include', [])\n                if len(include) >= 1:\n                    settings_s += \"INCLUDE=\" + str(include) + '\\n'\n\n            # AWS Events function mapping\n            event_mapping = {}\n            events = self.stage_config.get('events', [])\n            for event in events:\n                arn = event.get('event_source', {}).get('arn')\n                function = event.get('function')\n                if arn and function:\n                    event_mapping[arn] = function\n            settings_s = settings_s + \"AWS_EVENT_MAPPING={0!s}\\n\".format(event_mapping)\n\n            # Map Lext bot events\n            bot_events = self.stage_config.get('bot_events', [])\n            bot_events_mapping = {}\n            for bot_event in bot_events:\n                event_source = bot_event.get('event_source', {})\n                intent = event_source.get('intent')\n                invocation_source = event_source.get('invocation_source')\n                function = bot_event.get('function')\n                if intent and invocation_source and function:\n                    bot_events_mapping[str(intent) + ':' + str(invocation_source)] = function\n\n            settings_s = settings_s + \"AWS_BOT_EVENT_MAPPING={0!s}\\n\".format(bot_events_mapping)\n\n            # Map cognito triggers\n            cognito_trigger_mapping = {}\n            cognito_config = self.stage_config.get('cognito', {})\n            triggers = cognito_config.get('triggers', [])\n            for trigger in triggers:\n                source = trigger.get('source')\n                function = trigger.get('function')\n                if source and function:\n                    cognito_trigger_mapping[source] = function\n            settings_s = settings_s + \"COGNITO_TRIGGER_MAPPING={0!s}\\n\".format(cognito_trigger_mapping)\n\n            # Authorizer config\n            authorizer_function = self.authorizer.get('function', None)\n            if authorizer_function:\n                settings_s += \"AUTHORIZER_FUNCTION='{0!s}'\\n\".format(authorizer_function)\n\n            # Copy our Django app into root of our package.\n            # It doesn't work otherwise.\n            if self.django_settings:\n                base = __file__.rsplit(os.sep, 1)[0]\n                django_py = ''.join(os.path.join(base, 'ext', 'django_zappa.py'))\n                lambda_zip.write(django_py, 'django_zappa_app.py')\n\n            # async response\n            async_response_table = self.stage_config.get('async_response_table', '')\n            settings_s += \"ASYNC_RESPONSE_TABLE='{0!s}'\\n\".format(async_response_table)\n\n            # Lambda requires a specific chmod\n            temp_settings = tempfile.NamedTemporaryFile(delete=False)\n            os.chmod(temp_settings.name, 0o644)\n            temp_settings.write(bytes(settings_s, \"utf-8\"))\n            temp_settings.close()\n            lambda_zip.write(temp_settings.name, 'zappa_settings.py')\n            os.unlink(temp_settings.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_local_zip(self):\n\n        if self.stage_config.get('delete_local_zip', True):\n            try:\n                if os.path.isfile(self.zip_path):\n                    os.remove(self.zip_path)\n                if self.handler_path and os.path.isfile(self.handler_path):\n                    os.remove(self.handler_path)\n            except Exception as e: # pragma: no cover\n                sys.exit(-1)", "response": "Remove our local zip file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_uploaded_zip(self):\n\n        # Remove the uploaded zip from S3, because it is now registered..\n        if self.stage_config.get('delete_s3_zip', True):\n            self.zappa.remove_from_s3(self.zip_path, self.s3_bucket_name)\n            if self.stage_config.get('slim_handler', False):\n                # Need to keep the project zip as the slim handler uses it.\n                self.zappa.remove_from_s3(self.handler_path, self.s3_bucket_name)", "response": "Remove the uploaded zip file from S3 if it is already registered."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_exit(self):\n        if self.zip_path:\n            # Only try to remove uploaded zip if we're running a command that has loaded credentials\n            if self.load_credentials:\n                self.remove_uploaded_zip()\n\n            self.remove_local_zip()", "response": "Cleanup after the command finishes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the logs to the console.", "response": "def print_logs(self, logs, colorize=True, http=False, non_http=False, force_colorize=None):\n        \"\"\"\n        Parse, filter and print logs to the console.\n\n        \"\"\"\n\n        for log in logs:\n            timestamp = log['timestamp']\n            message = log['message']\n            if \"START RequestId\" in message:\n                continue\n            if \"REPORT RequestId\" in message:\n                continue\n            if \"END RequestId\" in message:\n                continue\n\n            if not colorize and not force_colorize:\n                if http:\n                    if self.is_http_log_entry(message.strip()):\n                        print(\"[\" + str(timestamp) + \"] \" + message.strip())\n                elif non_http:\n                    if not self.is_http_log_entry(message.strip()):\n                        print(\"[\" + str(timestamp) + \"] \" + message.strip())\n                else:\n                    print(\"[\" + str(timestamp) + \"] \" + message.strip())\n            else:\n                if http:\n                    if self.is_http_log_entry(message.strip()):\n                        click.echo(click.style(\"[\", fg='cyan') + click.style(str(timestamp), bold=True) + click.style(\"]\", fg='cyan') + self.colorize_log_entry(message.strip()), color=force_colorize)\n                elif non_http:\n                    if not self.is_http_log_entry(message.strip()):\n                        click.echo(click.style(\"[\", fg='cyan') + click.style(str(timestamp), bold=True) + click.style(\"]\", fg='cyan') + self.colorize_log_entry(message.strip()), color=force_colorize)\n                else:\n                    click.echo(click.style(\"[\", fg='cyan') + click.style(str(timestamp), bold=True) + click.style(\"]\", fg='cyan') + self.colorize_log_entry(message.strip()), color=force_colorize)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_http_log_entry(self, string):\n        # Debug event filter\n        if 'Zappa Event' in string:\n            return False\n\n        # IP address filter\n        for token in string.replace('\\t', ' ').split(' '):\n            try:\n                if (token.count('.') is 3 and token.replace('.', '').isnumeric()):\n                    return True\n            except Exception: # pragma: no cover\n                pass\n\n        return False", "response": "Determines if a log entry is an HTTP - formatted log string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef colorize_log_entry(self, string):\n\n        final_string = string\n        try:\n\n            # First, do stuff in square brackets\n            inside_squares = re.findall(r'\\[([^]]*)\\]', string)\n            for token in inside_squares:\n                if token in ['CRITICAL', 'ERROR', 'WARNING', 'DEBUG', 'INFO', 'NOTSET']:\n                    final_string = final_string.replace('[' + token + ']', click.style(\"[\", fg='cyan') + click.style(token, fg='cyan', bold=True) + click.style(\"]\", fg='cyan'))\n                else:\n                    final_string = final_string.replace('[' + token + ']', click.style(\"[\", fg='cyan') + click.style(token, bold=True) + click.style(\"]\", fg='cyan'))\n\n            # Then do quoted strings\n            quotes = re.findall(r'\"[^\"]*\"', string)\n            for token in quotes:\n                final_string = final_string.replace(token, click.style(token, fg=\"yellow\"))\n\n            # And UUIDs\n            for token in final_string.replace('\\t', ' ').split(' '):\n                try:\n                    if token.count('-') is 4 and token.replace('-', '').isalnum():\n                        final_string = final_string.replace(token, click.style(token, fg=\"magenta\"))\n                except Exception: # pragma: no cover\n                    pass\n\n                # And IP addresses\n                try:\n                    if token.count('.') is 3 and token.replace('.', '').isnumeric():\n                        final_string = final_string.replace(token, click.style(token, fg=\"red\"))\n                except Exception: # pragma: no cover\n                    pass\n\n                # And status codes\n                try:\n                    if token in ['200']:\n                        final_string = final_string.replace(token, click.style(token, fg=\"green\"))\n                    if token in ['400', '401', '403', '404', '405', '500']:\n                        final_string = final_string.replace(token, click.style(token, fg=\"red\"))\n                except Exception: # pragma: no cover\n                    pass\n\n            # And Zappa Events\n            try:\n                if \"Zappa Event:\" in final_string:\n                    final_string = final_string.replace(\"Zappa Event:\", click.style(\"Zappa Event:\", bold=True, fg=\"green\"))\n            except Exception: # pragma: no cover\n                pass\n\n            # And dates\n            for token in final_string.split('\\t'):\n                try:\n                    is_date = parser.parse(token)\n                    final_string = final_string.replace(token, click.style(token, fg=\"green\"))\n                except Exception: # pragma: no cover\n                    pass\n\n            final_string = final_string.replace('\\t', ' ').replace('   ', ' ')\n            if final_string[0] != ' ':\n                final_string = ' ' + final_string\n            return final_string\n        except Exception as e: # pragma: no cover\n            return string", "response": "Return a colorized version of a log entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_prebuild_script(self):\n\n        (pb_mod_path, pb_func) = self.prebuild_script.rsplit('.', 1)\n\n        try:  # Prefer prebuild script in working directory\n            if pb_mod_path.count('.') >= 1:  # Prebuild script func is nested in a folder\n                (mod_folder_path, mod_name) = pb_mod_path.rsplit('.', 1)\n                mod_folder_path_fragments = mod_folder_path.split('.')\n                working_dir = os.path.join(os.getcwd(), *mod_folder_path_fragments)\n            else:\n                mod_name = pb_mod_path\n                working_dir = os.getcwd()\n\n            working_dir_importer = pkgutil.get_importer(working_dir)\n            module_ = working_dir_importer.find_module(mod_name).load_module(mod_name)\n\n        except (ImportError, AttributeError):\n\n            try:  # Prebuild func might be in virtualenv\n                module_ = importlib.import_module(pb_mod_path)\n            except ImportError:  # pragma: no cover\n                raise ClickException(click.style(\"Failed \", fg=\"red\") + 'to ' + click.style(\n                    \"import prebuild script \", bold=True) + 'module: \"{pb_mod_path}\"'.format(\n                    pb_mod_path=click.style(pb_mod_path, bold=True)))\n\n        if not hasattr(module_, pb_func):  # pragma: no cover\n            raise ClickException(click.style(\"Failed \", fg=\"red\") + 'to ' + click.style(\n                \"find prebuild script \", bold=True) + 'function: \"{pb_func}\" '.format(\n                pb_func=click.style(pb_func, bold=True)) + 'in module \"{pb_mod_path}\"'.format(\n                pb_mod_path=pb_mod_path))\n\n        prebuild_function = getattr(module_, pb_func)\n        prebuild_function()", "response": "Parse and execute the prebuild script from the zappa_settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a warning if this could collide with a Zappa core package module.", "response": "def collision_warning(self, item):\n        \"\"\"\n        Given a string, print a warning if this could\n        collide with a Zappa core package module.\n\n        Use for app functions and events.\n        \"\"\"\n\n        namespace_collisions = [\n            \"zappa.\", \"wsgi.\", \"middleware.\", \"handler.\", \"util.\", \"letsencrypt.\", \"cli.\"\n        ]\n        for namespace_collision in namespace_collisions:\n            if item.startswith(namespace_collision):\n                click.echo(click.style(\"Warning!\", fg=\"red\", bold=True) +\n                           \" You may have a namespace collision between \" +\n                           click.style(item, bold=True) +\n                           \" and \" +\n                           click.style(namespace_collision, bold=True) +\n                           \"! You may want to rename that file.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure we re inside a virtualenv.", "response": "def check_venv(self):\n        \"\"\" Ensure we're inside a virtualenv. \"\"\"\n        if self.zappa:\n            venv = self.zappa.get_current_venv()\n        else:\n            # Just for `init`, when we don't have settings yet.\n            venv = Zappa.get_current_venv()\n        if not venv:\n            raise ClickException(\n                click.style(\"Zappa\", bold=True) + \" requires an \" + click.style(\"active virtual environment\", bold=True, fg=\"red\") + \"!\\n\" +\n                \"Learn more about virtual environments here: \" + click.style(\"http://docs.python-guide.org/en/latest/dev/virtualenvs/\", bold=False, fg=\"cyan\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef silence(self):\n\n        sys.stdout = open(os.devnull, 'w')\n        sys.stderr = open(os.devnull, 'w')", "response": "Route all stdout to null."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting the deployed endpoint with a GET request.", "response": "def touch_endpoint(self, endpoint_url):\n        \"\"\"\n        Test the deployed endpoint with a GET request.\n        \"\"\"\n\n        # Private APIGW endpoints most likely can't be reached by a deployer\n        # unless they're connected to the VPC by VPN. Instead of trying\n        # connect to the service, print a warning and let the user know\n        # to check it manually.\n        # See: https://github.com/Miserlou/Zappa/pull/1719#issuecomment-471341565\n        if 'PRIVATE' in self.stage_config.get('endpoint_configuration', []):\n            print(\n                click.style(\"Warning!\", fg=\"yellow\", bold=True) +\n                \" Since you're deploying a private API Gateway endpoint,\"\n                \" Zappa cannot determine if your function is returning \"\n                \" a correct status code. You should check your API's response\"\n                \" manually before considering this deployment complete.\"\n            )\n            return\n\n        touch_path = self.stage_config.get('touch_path', '/')\n        req = requests.get(endpoint_url + touch_path)\n\n        # Sometimes on really large packages, it can take 60-90 secs to be\n        # ready and requests will return 504 status_code until ready.\n        # So, if we get a 504 status code, rerun the request up to 4 times or\n        # until we don't get a 504 error\n        if req.status_code == 504:\n            i = 0\n            status_code = 504\n            while status_code == 504 and i <= 4:\n                req = requests.get(endpoint_url + touch_path)\n                status_code = req.status_code\n                i += 1\n\n        if req.status_code >= 500:\n            raise ClickException(click.style(\"Warning!\", fg=\"red\", bold=True) +\n                \" Status check on the deployed lambda failed.\" +\n                \" A GET request to '\" + touch_path + \"' yielded a \" +\n                click.style(str(req.status_code), fg=\"red\", bold=True) + \" response code.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npermutes all casings of a given string.", "response": "def all_casings(input_string):\n    \"\"\"\n    Permute all casings of a given string.\n\n    A pretty algorithm, via @Amber\n    http://stackoverflow.com/questions/6792803/finding-all-possible-case-permutations-in-python\n    \"\"\"\n    if not input_string:\n        yield \"\"\n    else:\n        first = input_string[:1]\n        if first.lower() == first.upper():\n            for sub_casing in all_casings(input_string[1:]):\n                yield first + sub_casing\n        else:\n            for sub_casing in all_casings(input_string[1:]):\n                yield first.lower() + sub_casing\n                yield first.upper() + sub_casing"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status_count(self, project):\n        '''\n        return a dict\n        '''\n        result = dict()\n        if project not in self.projects:\n            self._list_project()\n        if project not in self.projects:\n            return result\n        tablename = self._tablename(project)\n        for status, count in self._execute(\"SELECT `status`, count(1) FROM %s GROUP BY `status`\" %\n                                           self.escape(tablename)):\n            result[status] = count\n        return result", "response": "get the number of times a specific project has been created"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting encoding from request headers or page head.", "response": "def get_encoding(headers, content):\n    \"\"\"Get encoding from request headers or page head.\"\"\"\n    encoding = None\n\n    content_type = headers.get('content-type')\n    if content_type:\n        _, params = cgi.parse_header(content_type)\n        if 'charset' in params:\n            encoding = params['charset'].strip(\"'\\\"\")\n\n    if not encoding:\n        content = utils.pretty_unicode(content[:1000]) if six.PY3 else content\n\n        charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]',\n                                flags=re.I)\n        pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]',\n                               flags=re.I)\n        xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n        encoding = (charset_re.findall(content) +\n                    pragma_re.findall(content) +\n                    xml_re.findall(content))\n        encoding = encoding and encoding[0] or None\n\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the encoding of the response.", "response": "def encoding(self):\n        \"\"\"\n        encoding of Response.content.\n\n        if Response.encoding is None, encoding will be guessed\n        by header or content or chardet if available.\n        \"\"\"\n        if hasattr(self, '_encoding'):\n            return self._encoding\n\n        # content is unicode\n        if isinstance(self.content, six.text_type):\n            return 'unicode'\n\n        # Try charset from content-type or content\n        encoding = get_encoding(self.headers, self.content)\n\n        # Fallback to auto-detected encoding.\n        if not encoding and chardet is not None:\n            encoding = chardet.detect(self.content[:600])['encoding']\n\n        if encoding and encoding.lower() == 'gb2312':\n            encoding = 'gb18030'\n\n        self._encoding = encoding or 'utf-8'\n        return self._encoding"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef text(self):\n        if hasattr(self, '_text') and self._text:\n            return self._text\n        if not self.content:\n            return u''\n        if isinstance(self.content, six.text_type):\n            return self.content\n\n        content = None\n        encoding = self.encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = self.content.decode(encoding, 'replace')\n        except LookupError:\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # So we try blindly encoding.\n            content = self.content.decode('utf-8', 'replace')\n\n        self._text = content\n        return content", "response": "Return the content of the response in unicode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json(self):\n        if hasattr(self, '_json'):\n            return self._json\n        try:\n            self._json = json.loads(self.text or self.content)\n        except ValueError:\n            self._json = None\n        return self._json", "response": "Returns the json - encoded content of the response if any."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doc(self):\n        if hasattr(self, '_doc'):\n            return self._doc\n        elements = self.etree\n        doc = self._doc = PyQuery(elements)\n        doc.make_links_absolute(utils.text(self.url))\n        return doc", "response": "Returns a PyQuery object of the response s content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef etree(self):\n        if not hasattr(self, '_elements'):\n            try:\n                parser = lxml.html.HTMLParser(encoding=self.encoding)\n                self._elements = lxml.html.fromstring(self.content, parser=parser)\n            except LookupError:\n                # lxml would raise LookupError when encoding not supported\n                # try fromstring without encoding instead.\n                # on windows, unicode is not availabe as encoding for lxml\n                self._elements = lxml.html.fromstring(self.content)\n        if isinstance(self._elements, lxml.etree._ElementTree):\n            self._elements = self._elements.getroot()\n        return self._elements", "response": "Returns a lxml. etree. _ElementTree object of the response s content that can be selected by xpath"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raise_for_status(self, allow_redirects=True):\n\n        if self.status_code == 304:\n            return\n        elif self.error:\n            if self.traceback:\n                six.reraise(Exception, Exception(self.error), Traceback.from_string(self.traceback).as_traceback())\n            http_error = HTTPError(self.error)\n        elif (self.status_code >= 300) and (self.status_code < 400) and not allow_redirects:\n            http_error = HTTPError('%s Redirection' % (self.status_code))\n        elif (self.status_code >= 400) and (self.status_code < 500):\n            http_error = HTTPError('%s Client Error' % (self.status_code))\n        elif (self.status_code >= 500) and (self.status_code < 600):\n            http_error = HTTPError('%s Server Error' % (self.status_code))\n        else:\n            return\n\n        http_error.response = self\n        raise http_error", "response": "Raises HTTPError or URLError if one occurred."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef not_send_status(func):\n    @functools.wraps(func)\n    def wrapper(self, response, task):\n        self._extinfo['not_send_status'] = True\n        function = func.__get__(self, self.__class__)\n        return self._run_func(function, response, task)\n    return wrapper", "response": "Decorator to mark a task as not sending status to scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef every(minutes=NOTSET, seconds=NOTSET):\n    def wrapper(func):\n        # mark the function with variable 'is_cronjob=True', the function would be\n        # collected into the list Handler._cron_jobs by meta class\n        func.is_cronjob = True\n\n        # collect interval and unify to seconds, it's used in meta class. See the\n        # comments in meta class.\n        func.tick = minutes * 60 + seconds\n        return func\n\n    if inspect.isfunction(minutes):\n        func = minutes\n        minutes = 1\n        seconds = 0\n        return wrapper(func)\n\n    if minutes is NOTSET:\n        if seconds is NOTSET:\n            minutes = 1\n            seconds = 0\n        else:\n            minutes = 0\n    if seconds is NOTSET:\n        seconds = 0\n\n    return wrapper", "response": "Decorator for cronjob functions"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncatches errors of rabbitmq then reconnect", "response": "def catch_error(func):\n    \"\"\"Catch errors of rabbitmq then reconnect\"\"\"\n    import amqp\n    try:\n        import pika.exceptions\n        connect_exceptions = (\n            pika.exceptions.ConnectionClosed,\n            pika.exceptions.AMQPConnectionError,\n        )\n    except ImportError:\n        connect_exceptions = ()\n\n    connect_exceptions += (\n        select.error,\n        socket.error,\n        amqp.ConnectionError\n    )\n\n    def wrap(self, *args, **kwargs):\n        try:\n            return func(self, *args, **kwargs)\n        except connect_exceptions as e:\n            logging.error('RabbitMQ error: %r, reconnect.', e)\n            self.reconnect()\n            return func(self, *args, **kwargs)\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconnect(self):\n        import pika\n        import pika.exceptions\n\n        self.connection = pika.BlockingConnection(pika.URLParameters(self.amqp_url))\n        self.channel = self.connection.channel()\n        try:\n            self.channel.queue_declare(self.name)\n        except pika.exceptions.ChannelClosed:\n            self.connection = pika.BlockingConnection(pika.URLParameters(self.amqp_url))\n            self.channel = self.connection.channel()", "response": "Reconnect to rabbitmq server"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reconnect(self):\n        parsed = urlparse.urlparse(self.amqp_url)\n        port = parsed.port or 5672\n        self.connection = amqp.Connection(host=\"%s:%s\" % (parsed.hostname, port),\n                                          userid=parsed.username or 'guest',\n                                          password=parsed.password or 'guest',\n                                          virtual_host=unquote(\n                                              parsed.path.lstrip('/') or '%2F'))\n        self.channel = self.connection.channel()\n        try:\n            self.channel.queue_declare(self.name)\n        except amqp.exceptions.PreconditionFailed:\n            pass", "response": "Reconnect to rabbitmq server"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put(self, taskid, priority=0, exetime=0):\n        now = time.time()\n\n        task = InQueueTask(taskid, priority, exetime)\n\n        self.mutex.acquire()\n        if taskid in self.priority_queue:\n            self.priority_queue.put(task)\n        elif taskid in self.time_queue:\n            self.time_queue.put(task)\n        elif taskid in self.processing and self.processing[taskid].taskid:\n            # force update a processing task is not allowed as there are so many\n            # problems may happen\n            pass\n        else:\n            if exetime and exetime > now:\n                self.time_queue.put(task)\n            else:\n                task.exetime = 0\n                self.priority_queue.put(task)\n\n        self.mutex.release()", "response": "Put a task into the priority queue and time queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a task from queue when bucket available", "response": "def get(self):\n        '''Get a task from queue when bucket available'''\n        if self.bucket.get() < 1:\n            return None\n        now = time.time()\n        self.mutex.acquire()\n        try:\n            task = self.priority_queue.get_nowait()\n            self.bucket.desc()\n        except Queue.Empty:\n            self.mutex.release()\n            return None\n        task.exetime = now + self.processing_timeout\n        self.processing.put(task)\n        self.mutex.release()\n        return task.taskid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_processing(self, taskid):\n        '''\n        return True if taskid is in processing\n        '''\n        return taskid in self.processing and self.processing[taskid].taskid", "response": "Returns True if taskid is in processing or False if taskid is not in processing\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logstr(self):\n\n        result = []\n        formater = LogFormatter(color=False)\n        for record in self.logs:\n            if isinstance(record, six.string_types):\n                result.append(pretty_unicode(record))\n            else:\n                if record.exc_info:\n                    a, b, tb = record.exc_info\n                    tb = hide_me(tb, globals())\n                    record.exc_info = a, b, tb\n                result.append(pretty_unicode(formater.format(record)))\n                result.append(u'\\n')\n        return u''.join(result)", "response": "handler the log records to formatted string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the loop of the processor.", "response": "def run(self):\n        '''Run loop'''\n        logger.info(\"processor starting...\")\n\n        while not self._quit:\n            try:\n                task, response = self.inqueue.get(timeout=1)\n                self.on_task(task, response)\n                self._exceptions = 0\n            except Queue.Empty as e:\n                continue\n            except KeyboardInterrupt:\n                break\n            except Exception as e:\n                logger.exception(e)\n                self._exceptions += 1\n                if self._exceptions > self.EXCEPTION_LIMIT:\n                    break\n                continue\n\n        logger.info(\"processor exiting...\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect_message_queue(name, url=None, maxsize=0, lazy_limit=True):\n\n    if not url:\n        from pyspider.libs.multiprocessing_queue import Queue\n        return Queue(maxsize=maxsize)\n\n    parsed = urlparse.urlparse(url)\n    if parsed.scheme == 'amqp':\n        from .rabbitmq import Queue\n        return Queue(name, url, maxsize=maxsize, lazy_limit=lazy_limit)\n    elif parsed.scheme == 'beanstalk':\n        from .beanstalk import Queue\n        return Queue(name, host=parsed.netloc, maxsize=maxsize)\n    elif parsed.scheme == 'redis':\n        from .redis_queue import Queue\n        if ',' in parsed.netloc:\n            \"\"\"\n            redis in cluster mode (there is no concept of 'db' in cluster mode)\n            ex. redis://host1:port1,host2:port2,...,hostn:portn\n            \"\"\"\n            cluster_nodes = []\n            for netloc in parsed.netloc.split(','):\n                cluster_nodes.append({'host': netloc.split(':')[0], 'port': int(netloc.split(':')[1])})\n\n            return Queue(name=name, maxsize=maxsize, lazy_limit=lazy_limit, cluster_nodes=cluster_nodes)\n\n        else:\n            db = parsed.path.lstrip('/').split('/')\n            try:\n                db = int(db[0])\n            except:\n                logging.warning('redis DB must zero-based numeric index, using 0 instead')\n                db = 0\n\n            password = parsed.password or None\n\n            return Queue(name=name, host=parsed.hostname, port=parsed.port, db=db, maxsize=maxsize, password=password, lazy_limit=lazy_limit)\n    elif url.startswith('kombu+'):\n        url = url[len('kombu+'):]\n        from .kombu_queue import Queue\n        return Queue(name, url, maxsize=maxsize, lazy_limit=lazy_limit)\n    else:\n        raise Exception('unknown connection url: %s', url)", "response": "create a connection to a message queue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hide_me(tb, g=globals()):\n    base_tb = tb\n    try:\n        while tb and tb.tb_frame.f_globals is not g:\n            tb = tb.tb_next\n        while tb and tb.tb_frame.f_globals is g:\n            tb = tb.tb_next\n    except Exception as e:\n        logging.exception(e)\n        tb = base_tb\n    if not tb:\n        tb = base_tb\n    return tb", "response": "Hide stack traceback of given stack"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun function in subprocess return a Process object", "response": "def run_in_subprocess(func, *args, **kwargs):\n    \"\"\"Run function in subprocess, return a Process object\"\"\"\n    from multiprocessing import Process\n    thread = Process(target=func, args=args, kwargs=kwargs)\n    thread.daemon = True\n    thread.start()\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_date(date, gmt_offset=0, relative=True, shorter=False, full_format=False):\n\n    if not date:\n        return '-'\n    if isinstance(date, float) or isinstance(date, int):\n        date = datetime.datetime.utcfromtimestamp(date)\n    now = datetime.datetime.utcnow()\n    if date > now:\n        if relative and (date - now).seconds < 60:\n            # Due to click skew, things are some things slightly\n            # in the future. Round timestamps in the immediate\n            # future down to now in relative mode.\n            date = now\n        else:\n            # Otherwise, future dates always use the full format.\n            full_format = True\n    local_date = date - datetime.timedelta(minutes=gmt_offset)\n    local_now = now - datetime.timedelta(minutes=gmt_offset)\n    local_yesterday = local_now - datetime.timedelta(hours=24)\n    difference = now - date\n    seconds = difference.seconds\n    days = difference.days\n\n    format = None\n    if not full_format:\n        ret_, fff_format = fix_full_format(days, seconds, relative, shorter, local_date, local_yesterday)\n        format = fff_format\n        if ret_:\n            return format\n        else:\n            format = format\n\n    if format is None:\n        format = \"%(month_name)s %(day)s, %(year)s\" if shorter else \\\n            \"%(month_name)s %(day)s, %(year)s at %(time)s\"\n\n    str_time = \"%d:%02d\" % (local_date.hour, local_date.minute)\n\n    return format % {\n        \"month_name\": local_date.strftime('%b'),\n        \"weekday\": local_date.strftime('%A'),\n        \"day\": str(local_date.day),\n        \"year\": str(local_date.year),\n        \"month\": local_date.month,\n        \"time\": str_time\n    }", "response": "Formats the given date in a tornado - internal format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes sure string is utf8 encoded bytes.", "response": "def utf8(string):\n    \"\"\"\n    Make sure string is utf8 encoded bytes.\n\n    If parameter is a object, object.__str__ will been called before encode as bytes\n    \"\"\"\n    if isinstance(string, six.text_type):\n        return string.encode('utf8')\n    elif isinstance(string, six.binary_type):\n        return string\n    else:\n        return six.text_type(string).encode('utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef text(string, encoding='utf8'):\n    if isinstance(string, six.text_type):\n        return string\n    elif isinstance(string, six.binary_type):\n        return string.decode(encoding)\n    else:\n        return six.text_type(string)", "response": "Make sure string is unicode type decode with given encoding if it s not."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_unicode(string):\n    if isinstance(string, six.text_type):\n        return string\n    try:\n        return string.decode(\"utf8\")\n    except UnicodeDecodeError:\n        return string.decode('Latin-1').encode('unicode_escape').decode(\"utf8\")", "response": "Make sure string is unicode try to decode with utf8 escaped string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unicode_string(string):\n    if isinstance(string, six.text_type):\n        return string\n    try:\n        return string.decode(\"utf8\")\n    except UnicodeDecodeError:\n        return '[BASE64-DATA]' + base64.b64encode(string) + '[/BASE64-DATA]'", "response": "Make sure string is unicode try to default with base64"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking sure keys and values of dict are unicode.", "response": "def unicode_dict(_dict):\n    \"\"\"\n    Make sure keys and values of dict is unicode.\n    \"\"\"\n    r = {}\n    for k, v in iteritems(_dict):\n        r[unicode_obj(k)] = unicode_obj(v)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unicode_obj(obj):\n    if isinstance(obj, dict):\n        return unicode_dict(obj)\n    elif isinstance(obj, (list, tuple)):\n        return unicode_list(obj)\n    elif isinstance(obj, six.string_types):\n        return unicode_string(obj)\n    elif isinstance(obj, (int, float)):\n        return obj\n    elif obj is None:\n        return obj\n    else:\n        try:\n            return text(obj)\n        except:\n            return text(repr(obj))", "response": "Convert obj into unicode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding string encoded by unicode_string", "response": "def decode_unicode_string(string):\n    \"\"\"\n    Decode string encoded by `unicode_string`\n    \"\"\"\n    if string.startswith('[BASE64-DATA]') and string.endswith('[/BASE64-DATA]'):\n        return base64.b64decode(string[len('[BASE64-DATA]'):-len('[/BASE64-DATA]')])\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode_unicode_obj(obj):\n    if isinstance(obj, dict):\n        r = {}\n        for k, v in iteritems(obj):\n            r[decode_unicode_string(k)] = decode_unicode_obj(v)\n        return r\n    elif isinstance(obj, six.string_types):\n        return decode_unicode_string(obj)\n    elif isinstance(obj, (list, tuple)):\n        return [decode_unicode_obj(x) for x in obj]\n    else:\n        return obj", "response": "Decode unicoded dict list tuple encoded by unicode_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_object(name):\n\n    if \".\" not in name:\n        raise Exception('load object need module.object')\n\n    module_name, object_name = name.rsplit('.', 1)\n    if six.PY2:\n        module = __import__(module_name, globals(), locals(), [utf8(object_name)], -1)\n    else:\n        module = __import__(module_name, globals(), locals(), [object_name])\n    return getattr(module, object_name)", "response": "Load object from module"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an interactive python console instance with caller s stack AttributeNames.", "response": "def get_python_console(namespace=None):\n    \"\"\"\n    Return a interactive python console instance with caller's stack\n    \"\"\"\n\n    if namespace is None:\n        import inspect\n        frame = inspect.currentframe()\n        caller = frame.f_back\n        if not caller:\n            logging.error(\"can't find caller who start this console.\")\n            caller = frame\n        namespace = dict(caller.f_globals)\n        namespace.update(caller.f_locals)\n\n    try:\n        from IPython.terminal.interactiveshell import TerminalInteractiveShell\n        shell = TerminalInteractiveShell(user_ns=namespace)\n    except ImportError:\n        try:\n            import readline\n            import rlcompleter\n            readline.set_completer(rlcompleter.Completer(namespace).complete)\n            readline.parse_and_bind(\"tab: complete\")\n        except ImportError:\n            pass\n        import code\n        shell = code.InteractiveConsole(namespace)\n        shell._quit = False\n\n        def exit():\n            shell._quit = True\n\n        def readfunc(prompt=\"\"):\n            if shell._quit:\n                raise EOFError\n            return six.moves.input(prompt)\n\n        # inject exit method\n        shell.ask_exit = exit\n        shell.raw_input = readfunc\n\n    return shell"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a interactive python console with caller s stack", "response": "def python_console(namespace=None):\n    \"\"\"Start a interactive python console with caller's stack\"\"\"\n\n    if namespace is None:\n        import inspect\n        frame = inspect.currentframe()\n        caller = frame.f_back\n        if not caller:\n            logging.error(\"can't find caller who start this console.\")\n            caller = frame\n        namespace = dict(caller.f_globals)\n        namespace.update(caller.f_locals)\n\n    return get_python_console(namespace=namespace).interact()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the HTTP POST request.", "response": "def handle_POST(self, environ, start_response):\n        \"\"\"Handles the HTTP POST request.\n\n        Attempts to interpret all HTTP POST requests as XML-RPC calls,\n        which are forwarded to the server's _dispatch method for handling.\n\n        Most code taken from SimpleXMLRPCServer with modifications for wsgi and my custom dispatcher.\n        \"\"\"\n\n        try:\n            # Get arguments by reading body of request.\n            # We read this in chunks to avoid straining\n            # socket.read(); around the 10 or 15Mb mark, some platforms\n            # begin to have problems (bug #792570).\n\n            length = int(environ['CONTENT_LENGTH'])\n            data = environ['wsgi.input'].read(length)\n\n            # In previous versions of SimpleXMLRPCServer, _dispatch\n            # could be overridden in this class, instead of in\n            # SimpleXMLRPCDispatcher. To maintain backwards compatibility,\n            # check to see if a subclass implements _dispatch and\n            # using that method if present.\n            response = self.dispatcher._marshaled_dispatch(\n                data, getattr(self.dispatcher, '_dispatch', None)\n            )\n            response += b'\\n'\n        except Exception as e:  # This should only happen if the module is buggy\n            # internal error, report as HTTP server error\n            logger.exception(e)\n            start_response(\"500 Server error\", [('Content-Type', 'text/plain')])\n            return []\n        else:\n            # got a valid XML RPC response\n            start_response(\"200 OK\", [('Content-Type', 'text/xml'), ('Content-Length', str(len(response)),)])\n            return [response]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_database(url):\n    db = _connect_database(url)\n    db.copy = lambda: _connect_database(url)\n    return db", "response": "create database object by url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate one project by creating or updating it with the project information", "response": "def _update_project(self, project):\n        '''update one project'''\n        if project['name'] not in self.projects:\n            self.projects[project['name']] = Project(self, project)\n        else:\n            self.projects[project['name']].update(project)\n\n        project = self.projects[project['name']]\n\n        if project._send_on_get_info:\n            # update project runtime info from processor by sending a _on_get_info\n            # request, result is in status_page.track.save\n            project._send_on_get_info = False\n            self.on_select_task({\n                'taskid': '_on_get_info',\n                'project': project.name,\n                'url': 'data:,_on_get_info',\n                'status': self.taskdb.SUCCESS,\n                'fetch': {\n                    'save': self.get_info_attributes,\n                },\n                'process': {\n                    'callback': '_on_get_info',\n                },\n            })\n\n        # load task queue when project is running and delete task_queue when project is stoped\n        if project.active:\n            if not project.task_loaded:\n                self._load_tasks(project)\n                project.task_loaded = True\n        else:\n            if project.task_loaded:\n                project.task_queue = TaskQueue()\n                project.task_loaded = False\n\n            if project not in self._cnt['all']:\n                self._update_project_cnt(project.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads tasks from database", "response": "def _load_tasks(self, project):\n        '''load tasks from database'''\n        task_queue = project.task_queue\n\n        for task in self.taskdb.load_tasks(\n                self.taskdb.ACTIVE, project.name, self.scheduler_task_fields\n        ):\n            taskid = task['taskid']\n            _schedule = task.get('schedule', self.default_schedule)\n            priority = _schedule.get('priority', self.default_schedule['priority'])\n            exetime = _schedule.get('exetime', self.default_schedule['exetime'])\n            task_queue.put(taskid, priority, exetime)\n        project.task_loaded = True\n        logger.debug('project: %s loaded %d tasks.', project.name, len(task_queue))\n\n        if project not in self._cnt['all']:\n            self._update_project_cnt(project.name)\n        self._cnt['all'].value((project.name, 'pending'), len(project.task_queue))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies that a task is valid.", "response": "def task_verify(self, task):\n        '''\n        return False if any of 'taskid', 'project', 'url' is not in task dict\n                        or project in not in task_queue\n        '''\n        for each in ('taskid', 'project', 'url', ):\n            if each not in task or not task[each]:\n                logger.error('%s not in task: %.200r', each, task)\n                return False\n        if task['project'] not in self.projects:\n            logger.error('unknown project: %s', task['project'])\n            return False\n\n        project = self.projects[task['project']]\n        if not project.active:\n            logger.error('project %s not started, please set status to RUNNING or DEBUG',\n                         task['project'])\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put_task(self, task):\n        '''put task to task queue'''\n        _schedule = task.get('schedule', self.default_schedule)\n        self.projects[task['project']].task_queue.put(\n            task['taskid'],\n            priority=_schedule.get('priority', self.default_schedule['priority']),\n            exetime=_schedule.get('exetime', self.default_schedule['exetime'])\n        )", "response": "put task to task queue"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_task(self, task, force=True):\n        '''\n        dispatch task to fetcher\n\n        out queue may have size limit to prevent block, a send_buffer is used\n        '''\n        try:\n            self.out_queue.put_nowait(task)\n        except Queue.Full:\n            if force:\n                self._send_buffer.appendleft(task)\n            else:\n                raise", "response": "dispatch task to fetcher\n\n        out queue and append it to the send_buffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks status queue for tasks that are done and check if they are still valid.", "response": "def _check_task_done(self):\n        '''Check status queue'''\n        cnt = 0\n        try:\n            while True:\n                task = self.status_queue.get_nowait()\n                # check _on_get_info result here\n                if task.get('taskid') == '_on_get_info' and 'project' in task and 'track' in task:\n                    if task['project'] not in self.projects:\n                        continue\n                    project = self.projects[task['project']]\n                    project.on_get_info(task['track'].get('save') or {})\n                    logger.info(\n                        '%s on_get_info %r', task['project'], task['track'].get('save', {})\n                    )\n                    continue\n                elif not self.task_verify(task):\n                    continue\n                self.on_task_status(task)\n                cnt += 1\n        except Queue.Empty:\n            pass\n        return cnt"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks new task queue and check if new task is valid.", "response": "def _check_request(self):\n        '''Check new task queue'''\n        # check _postpone_request first\n        todo = []\n        for task in self._postpone_request:\n            if task['project'] not in self.projects:\n                continue\n            if self.projects[task['project']].task_queue.is_processing(task['taskid']):\n                todo.append(task)\n            else:\n                self.on_request(task)\n        self._postpone_request = todo\n\n        tasks = {}\n        while len(tasks) < self.LOOP_LIMIT:\n            try:\n                task = self.newtask_queue.get_nowait()\n            except Queue.Empty:\n                break\n\n            if isinstance(task, list):\n                _tasks = task\n            else:\n                _tasks = (task, )\n\n            for task in _tasks:\n                if not self.task_verify(task):\n                    continue\n\n                if task['taskid'] in self.projects[task['project']].task_queue:\n                    if not task.get('schedule', {}).get('force_update', False):\n                        logger.debug('ignore newtask %(project)s:%(taskid)s %(url)s', task)\n                        continue\n\n                if task['taskid'] in tasks:\n                    if not task.get('schedule', {}).get('force_update', False):\n                        continue\n\n                tasks[task['taskid']] = task\n\n        for task in itervalues(tasks):\n            self.on_request(task)\n\n        return len(tasks)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck projects cronjob tick return True when a new tick is sended", "response": "def _check_cronjob(self):\n        \"\"\"Check projects cronjob tick, return True when a new tick is sended\"\"\"\n        now = time.time()\n        self._last_tick = int(self._last_tick)\n        if now - self._last_tick < 1:\n            return False\n        self._last_tick += 1\n        for project in itervalues(self.projects):\n            if not project.active:\n                continue\n            if project.waiting_get_info:\n                continue\n            if int(project.min_tick) == 0:\n                continue\n            if self._last_tick % int(project.min_tick) != 0:\n                continue\n            self.on_select_task({\n                'taskid': '_on_cronjob',\n                'project': project.name,\n                'url': 'data:,_on_cronjob',\n                'status': self.taskdb.SUCCESS,\n                'fetch': {\n                    'save': {\n                        'tick': self._last_tick,\n                    },\n                },\n                'process': {\n                    'callback': '_on_cronjob',\n                },\n            })\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects task to fetch & process", "response": "def _check_select(self):\n        '''Select task to fetch & process'''\n        while self._send_buffer:\n            _task = self._send_buffer.pop()\n            try:\n                # use force=False here to prevent automatic send_buffer append and get exception\n                self.send_task(_task, False)\n            except Queue.Full:\n                self._send_buffer.append(_task)\n                break\n\n        if self.out_queue.full():\n            return {}\n\n        taskids = []\n        cnt = 0\n        cnt_dict = dict()\n        limit = self.LOOP_LIMIT\n\n        # dynamic assign select limit for each project, use qsize as weight\n        project_weights, total_weight = dict(), 0\n        for project in itervalues(self.projects):  # type:Project\n            if not project.active:\n                continue\n            # only check project pause when select new tasks, cronjob and new request still working\n            if project.paused:\n                continue\n            if project.waiting_get_info:\n                continue\n\n            # task queue\n            task_queue = project.task_queue  # type:TaskQueue\n            pro_weight = task_queue.size()\n            total_weight += pro_weight\n            project_weights[project.name] = pro_weight\n            pass\n\n        min_project_limit = int(limit / 10.)  # ensure minimum select limit for each project\n        max_project_limit = int(limit / 3.0)  # ensure maximum select limit for each project\n\n        for pro_name, pro_weight in iteritems(project_weights):\n            if cnt >= limit:\n                break\n\n            project = self.projects[pro_name]  # type:Project\n\n            # task queue\n            task_queue = project.task_queue\n            task_queue.check_update()\n            project_cnt = 0\n\n            # calculate select limit for project\n            if total_weight < 1 or pro_weight < 1:\n                project_limit = min_project_limit\n            else:\n                project_limit = int((1.0 * pro_weight / total_weight) * limit)\n                if project_limit < min_project_limit:\n                    project_limit = min_project_limit\n                elif project_limit > max_project_limit:\n                    project_limit = max_project_limit\n\n            # check send_buffer here. when not empty, out_queue may blocked. Not sending tasks\n            while cnt < limit and project_cnt < project_limit:\n                taskid = task_queue.get()\n                if not taskid:\n                    break\n\n                taskids.append((project.name, taskid))\n                if taskid != 'on_finished':\n                    project_cnt += 1\n                cnt += 1\n\n            cnt_dict[project.name] = project_cnt\n            if project_cnt:\n                project._selected_tasks = True\n                project._send_finished_event_wait = 0\n\n            # check and send finished event to project\n            if not project_cnt and len(task_queue) == 0 and project._selected_tasks:\n                # wait for self.FAIL_PAUSE_NUM steps to make sure all tasks in queue have been processed\n                if project._send_finished_event_wait < self.FAIL_PAUSE_NUM:\n                    project._send_finished_event_wait += 1\n                else:\n                    project._selected_tasks = False\n                    project._send_finished_event_wait = 0\n\n                    self._postpone_request.append({\n                        'project': project.name,\n                        'taskid': 'on_finished',\n                        'url': 'data:,on_finished',\n                        'process': {\n                            'callback': 'on_finished',\n                        },\n                        \"schedule\": {\n                            \"age\": 0,\n                            \"priority\": 9,\n                            \"force_update\": True,\n                        },\n                    })\n\n        for project, taskid in taskids:\n            self._load_put_task(project, taskid)\n\n        return cnt_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dump_cnt(self):\n        '''Dump counters to file'''\n        self._cnt['1h'].dump(os.path.join(self.data_path, 'scheduler.1h'))\n        self._cnt['1d'].dump(os.path.join(self.data_path, 'scheduler.1d'))\n        self._cnt['all'].dump(os.path.join(self.data_path, 'scheduler.all'))", "response": "Dump counters to file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping counters every 60 seconds", "response": "def _try_dump_cnt(self):\n        '''Dump counters every 60 seconds'''\n        now = time.time()\n        if now - self._last_dump_cnt > 60:\n            self._last_dump_cnt = now\n            self._dump_cnt()\n            self._print_counter_log()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if project delete is still in progress.", "response": "def _check_delete(self):\n        '''Check project delete'''\n        now = time.time()\n        for project in list(itervalues(self.projects)):\n            if project.db_status != 'STOP':\n                continue\n            if now - project.updatetime < self.DELETE_TIME:\n                continue\n            if 'delete' not in self.projectdb.split_group(project.group):\n                continue\n\n            logger.warning(\"deleting project: %s!\", project.name)\n            del self.projects[project.name]\n            self.taskdb.drop(project.name)\n            self.projectdb.drop(project.name)\n            if self.resultdb:\n                self.resultdb.drop(project.name)\n            for each in self._cnt.values():\n                del each[project.name]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping xmlrpc server and xmlrpc ioloop", "response": "def quit(self):\n        '''Set quit signal'''\n        self._quit = True\n        # stop xmlrpc server\n        if hasattr(self, 'xmlrpc_server'):\n            self.xmlrpc_ioloop.add_callback(self.xmlrpc_server.stop)\n            self.xmlrpc_ioloop.add_callback(self.xmlrpc_ioloop.stop)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun tasks to fetcher once", "response": "def run_once(self):\n        '''comsume queues and feed tasks to fetcher, once'''\n\n        self._update_projects()\n        self._check_task_done()\n        self._check_request()\n        while self._check_cronjob():\n            pass\n        self._check_select()\n        self._check_delete()\n        self._try_dump_cnt()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when a new request arrived", "response": "def on_new_request(self, task):\n        '''Called when a new request is arrived'''\n        task['status'] = self.taskdb.ACTIVE\n        self.insert_task(task)\n        self.put_task(task)\n\n        project = task['project']\n        self._cnt['5m'].event((project, 'pending'), +1)\n        self._cnt['1h'].event((project, 'pending'), +1)\n        self._cnt['1d'].event((project, 'pending'), +1)\n        self._cnt['all'].event((project, 'pending'), +1)\n        logger.info('new task %(project)s:%(taskid)s %(url)s', task)\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_old_request(self, task, old_task):\n        '''Called when a crawled task is arrived'''\n        now = time.time()\n\n        _schedule = task.get('schedule', self.default_schedule)\n        old_schedule = old_task.get('schedule', {})\n\n        if _schedule.get('force_update') and self.projects[task['project']].task_queue.is_processing(task['taskid']):\n            # when a task is in processing, the modify may conflict with the running task.\n            # postpone the modify after task finished.\n            logger.info('postpone modify task %(project)s:%(taskid)s %(url)s', task)\n            self._postpone_request.append(task)\n            return\n\n        restart = False\n        schedule_age = _schedule.get('age', self.default_schedule['age'])\n        if _schedule.get('itag') and _schedule['itag'] != old_schedule.get('itag'):\n            restart = True\n        elif schedule_age >= 0 and schedule_age + (old_task.get('lastcrawltime', 0) or 0) < now:\n            restart = True\n        elif _schedule.get('force_update'):\n            restart = True\n\n        if not restart:\n            logger.debug('ignore newtask %(project)s:%(taskid)s %(url)s', task)\n            return\n\n        if _schedule.get('cancel'):\n            logger.info('cancel task %(project)s:%(taskid)s %(url)s', task)\n            task['status'] = self.taskdb.BAD\n            self.update_task(task)\n            self.projects[task['project']].task_queue.delete(task['taskid'])\n            return task\n\n        task['status'] = self.taskdb.ACTIVE\n        self.update_task(task)\n        self.put_task(task)\n\n        project = task['project']\n        if old_task['status'] != self.taskdb.ACTIVE:\n            self._cnt['5m'].event((project, 'pending'), +1)\n            self._cnt['1h'].event((project, 'pending'), +1)\n            self._cnt['1d'].event((project, 'pending'), +1)\n        if old_task['status'] == self.taskdb.SUCCESS:\n            self._cnt['all'].event((project, 'success'), -1).event((project, 'pending'), +1)\n        elif old_task['status'] == self.taskdb.FAILED:\n            self._cnt['all'].event((project, 'failed'), -1).event((project, 'pending'), +1)\n        logger.info('restart task %(project)s:%(taskid)s %(url)s', task)\n        return task", "response": "Called when a task is arrived"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_task_status(self, task):\n        '''Called when a status pack is arrived'''\n        try:\n            procesok = task['track']['process']['ok']\n            if not self.projects[task['project']].task_queue.done(task['taskid']):\n                logging.error('not processing pack: %(project)s:%(taskid)s %(url)s', task)\n                return None\n        except KeyError as e:\n            logger.error(\"Bad status pack: %s\", e)\n            return None\n\n        if procesok:\n            ret = self.on_task_done(task)\n        else:\n            ret = self.on_task_failed(task)\n\n        if task['track']['fetch'].get('time'):\n            self._cnt['5m_time'].event((task['project'], 'fetch_time'),\n                                       task['track']['fetch']['time'])\n        if task['track']['process'].get('time'):\n            self._cnt['5m_time'].event((task['project'], 'process_time'),\n                                       task['track']['process'].get('time'))\n        self.projects[task['project']].active_tasks.appendleft((time.time(), task))\n        return ret", "response": "Called when a status pack is arrived"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when a task is done and success", "response": "def on_task_done(self, task):\n        '''Called when a task is done and success, called by `on_task_status`'''\n        task['status'] = self.taskdb.SUCCESS\n        task['lastcrawltime'] = time.time()\n\n        if 'schedule' in task:\n            if task['schedule'].get('auto_recrawl') and 'age' in task['schedule']:\n                task['status'] = self.taskdb.ACTIVE\n                next_exetime = task['schedule'].get('age')\n                task['schedule']['exetime'] = time.time() + next_exetime\n                self.put_task(task)\n            else:\n                del task['schedule']\n        self.update_task(task)\n\n        project = task['project']\n        self._cnt['5m'].event((project, 'success'), +1)\n        self._cnt['1h'].event((project, 'success'), +1)\n        self._cnt['1d'].event((project, 'success'), +1)\n        self._cnt['all'].event((project, 'success'), +1).event((project, 'pending'), -1)\n        logger.info('task done %(project)s:%(taskid)s %(url)s', task)\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_task_failed(self, task):\n        '''Called when a task is failed, called by `on_task_status`'''\n\n        if 'schedule' not in task:\n            old_task = self.taskdb.get_task(task['project'], task['taskid'], fields=['schedule'])\n            if old_task is None:\n                logging.error('unknown status pack: %s' % task)\n                return\n            task['schedule'] = old_task.get('schedule', {})\n\n        retries = task['schedule'].get('retries', self.default_schedule['retries'])\n        retried = task['schedule'].get('retried', 0)\n\n        project_info = self.projects[task['project']]\n        retry_delay = project_info.retry_delay or self.DEFAULT_RETRY_DELAY\n        next_exetime = retry_delay.get(retried, retry_delay.get('', self.DEFAULT_RETRY_DELAY['']))\n\n        if task['schedule'].get('auto_recrawl') and 'age' in task['schedule']:\n            next_exetime = min(next_exetime, task['schedule'].get('age'))\n        else:\n            if retried >= retries:\n                next_exetime = -1\n            elif 'age' in task['schedule'] and next_exetime > task['schedule'].get('age'):\n                next_exetime = task['schedule'].get('age')\n\n        if next_exetime < 0:\n            task['status'] = self.taskdb.FAILED\n            task['lastcrawltime'] = time.time()\n            self.update_task(task)\n\n            project = task['project']\n            self._cnt['5m'].event((project, 'failed'), +1)\n            self._cnt['1h'].event((project, 'failed'), +1)\n            self._cnt['1d'].event((project, 'failed'), +1)\n            self._cnt['all'].event((project, 'failed'), +1).event((project, 'pending'), -1)\n            logger.info('task failed %(project)s:%(taskid)s %(url)s' % task)\n            return task\n        else:\n            task['schedule']['retried'] = retried + 1\n            task['schedule']['exetime'] = time.time() + next_exetime\n            task['lastcrawltime'] = time.time()\n            self.update_task(task)\n            self.put_task(task)\n\n            project = task['project']\n            self._cnt['5m'].event((project, 'retry'), +1)\n            self._cnt['1h'].event((project, 'retry'), +1)\n            self._cnt['1d'].event((project, 'retry'), +1)\n            # self._cnt['all'].event((project, 'retry'), +1)\n            logger.info('task retry %d/%d %%(project)s:%%(taskid)s %%(url)s' % (\n                retried, retries), task)\n            return task", "response": "Called when a task is failed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when a task is selected to fetch & process", "response": "def on_select_task(self, task):\n        '''Called when a task is selected to fetch & process'''\n        # inject informations about project\n        logger.info('select %(project)s:%(taskid)s %(url)s', task)\n\n        project_info = self.projects.get(task['project'])\n        assert project_info, 'no such project'\n        task['type'] = self.TASK_PACK\n        task['group'] = project_info.group\n        task['project_md5sum'] = project_info.md5sum\n        task['project_updatetime'] = project_info.updatetime\n\n        # lazy join project.crawl_config\n        if getattr(project_info, 'crawl_config', None):\n            task = BaseHandler.task_join_crawl_config(task, project_info.crawl_config)\n\n        project_info.active_tasks.appendleft((time.time(), task))\n        self.send_task(task)\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if select tasks are in interactive mode", "response": "def _check_select(self):\n        \"\"\"\n        interactive mode of select tasks\n        \"\"\"\n        if not self.interactive:\n            return super(OneScheduler, self)._check_select()\n\n        # waiting for running tasks\n        if self.running_task > 0:\n            return\n\n        is_crawled = []\n\n        def run(project=None):\n            return crawl('on_start', project=project)\n\n        def crawl(url, project=None, **kwargs):\n            \"\"\"\n            Crawl given url, same parameters as BaseHandler.crawl\n\n            url - url or taskid, parameters will be used if in taskdb\n            project - can be ignored if only one project exists.\n            \"\"\"\n\n            # looking up the project instance\n            if project is None:\n                if len(self.projects) == 1:\n                    project = list(self.projects.keys())[0]\n                else:\n                    raise LookupError('You need specify the project: %r'\n                                      % list(self.projects.keys()))\n            project_data = self.processor.project_manager.get(project)\n            if not project_data:\n                raise LookupError('no such project: %s' % project)\n\n            # get task package\n            instance = project_data['instance']\n            instance._reset()\n            task = instance.crawl(url, **kwargs)\n            if isinstance(task, list):\n                raise Exception('url list is not allowed in interactive mode')\n\n            # check task in taskdb\n            if not kwargs:\n                dbtask = self.taskdb.get_task(task['project'], task['taskid'],\n                                              fields=self.request_task_fields)\n                if not dbtask:\n                    dbtask = self.taskdb.get_task(task['project'], task['url'],\n                                                  fields=self.request_task_fields)\n                if dbtask:\n                    task = dbtask\n\n            # select the task\n            self.on_select_task(task)\n            is_crawled.append(True)\n\n            shell.ask_exit()\n\n        def quit_interactive():\n            '''Quit interactive mode'''\n            is_crawled.append(True)\n            self.interactive = False\n            shell.ask_exit()\n\n        def quit_pyspider():\n            '''Close pyspider'''\n            is_crawled[:] = []\n            shell.ask_exit()\n\n        shell = utils.get_python_console()\n        banner = (\n            'pyspider shell - Select task\\n'\n            'crawl(url, project=None, **kwargs) - same parameters as BaseHandler.crawl\\n'\n            'quit_interactive() - Quit interactive mode\\n'\n            'quit_pyspider() - Close pyspider'\n        )\n        if hasattr(shell, 'show_banner'):\n            shell.show_banner(banner)\n            shell.interact()\n        else:\n            shell.interact(banner)\n        if not is_crawled:\n            self.ioloop.add_callback(self.ioloop.stop)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when a task is completed or failed.", "response": "def on_task_status(self, task):\n        \"\"\"Ignore not processing error in interactive mode\"\"\"\n        if not self.interactive:\n            super(OneScheduler, self).on_task_status(task)\n\n        try:\n            procesok = task['track']['process']['ok']\n        except KeyError as e:\n            logger.error(\"Bad status pack: %s\", e)\n            return None\n\n        if procesok:\n            ret = self.on_task_done(task)\n        else:\n            ret = self.on_task_failed(task)\n        if task['track']['fetch'].get('time'):\n            self._cnt['5m_time'].event((task['project'], 'fetch_time'),\n                                       task['track']['fetch']['time'])\n        if task['track']['process'].get('time'):\n            self._cnt['5m_time'].event((task['project'], 'process_time'),\n                                       task['track']['process'].get('time'))\n        self.projects[task['project']].active_tasks.appendleft((time.time(), task))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds project script as module", "response": "def build_module(project, env=None):\n        '''Build project script as module'''\n        from pyspider.libs import base_handler\n        assert 'name' in project, 'need name of project'\n        assert 'script' in project, 'need script of project'\n\n        if env is None:\n            env = {}\n        # fix for old non-package version scripts\n        pyspider_path = os.path.join(os.path.dirname(__file__), \"..\")\n        if pyspider_path not in sys.path:\n            sys.path.insert(1, pyspider_path)\n\n        env = dict(env)\n        env.update({\n            'debug': project.get('status', 'DEBUG') == 'DEBUG',\n        })\n\n        loader = ProjectLoader(project)\n        module = loader.load_module(project['name'])\n\n        # logger inject\n        module.log_buffer = []\n        module.logging = module.logger = logging.Logger(project['name'])\n        if env.get('enable_stdout_capture', True):\n            handler = SaveLogHandler(module.log_buffer)\n            handler.setFormatter(LogFormatter(color=False))\n        else:\n            handler = logging.StreamHandler()\n            handler.setFormatter(LogFormatter(color=True))\n        module.logger.addHandler(handler)\n\n        if '__handler_cls__' not in module.__dict__:\n            BaseHandler = module.__dict__.get('BaseHandler', base_handler.BaseHandler)\n            for each in list(six.itervalues(module.__dict__)):\n                if inspect.isclass(each) and each is not BaseHandler \\\n                        and issubclass(each, BaseHandler):\n                    module.__dict__['__handler_cls__'] = each\n        _class = module.__dict__.get('__handler_cls__')\n        assert _class is not None, \"need BaseHandler in project module\"\n\n        instance = _class()\n        instance.__env__ = env\n        instance.project_name = project['name']\n        instance.project = project\n\n        return {\n            'loader': loader,\n            'module': module,\n            'class': _class,\n            'instance': instance,\n            'exception': None,\n            'exception_log': '',\n            'info': project,\n            'load_time': time.time(),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if project_name need update", "response": "def _need_update(self, project_name, updatetime=None, md5sum=None):\n        '''Check if project_name need update'''\n        if project_name not in self.projects:\n            return True\n        elif md5sum and md5sum != self.projects[project_name]['info'].get('md5sum'):\n            return True\n        elif updatetime and updatetime > self.projects[project_name]['info'].get('updatetime', 0):\n            return True\n        elif time.time() - self.projects[project_name]['load_time'] > self.RELOAD_PROJECT_INTERVAL:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking projects by last update time", "response": "def _check_projects(self):\n        '''Check projects by last update time'''\n        for project in self.projectdb.check_update(self.last_check_projects,\n                                                   ['name', 'updatetime']):\n            if project['name'] not in self.projects:\n                continue\n            if project['updatetime'] > self.projects[project['name']]['info'].get('updatetime', 0):\n                self._update_project(project['name'])\n        self.last_check_projects = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates one project from database", "response": "def _update_project(self, project_name):\n        '''Update one project from database'''\n        project = self.projectdb.get(project_name)\n        if not project:\n            return None\n        return self._load_project(project)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_project(self, project):\n        '''Load project into self.projects from project info dict'''\n        try:\n            project['md5sum'] = utils.md5string(project['script'])\n            ret = self.build_module(project, self.env)\n            self.projects[project['name']] = ret\n        except Exception as e:\n            logger.exception(\"load project %s error\", project.get('name', None))\n            ret = {\n                'loader': None,\n                'module': None,\n                'class': None,\n                'instance': None,\n                'exception': e,\n                'exception_log': traceback.format_exc(),\n                'info': project,\n                'load_time': time.time(),\n            }\n            self.projects[project['name']] = ret\n            return False\n        logger.debug('project: %s updated.', project.get('name', None))\n        return True", "response": "Load project into self. projects from project info dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget project data object return None if not exists", "response": "def get(self, project_name, updatetime=None, md5sum=None):\n        '''get project data object, return None if not exists'''\n        if time.time() - self.last_check_projects > self.CHECK_PROJECTS_INTERVAL:\n            self._check_projects()\n        if self._need_update(project_name, updatetime, md5sum):\n            self._update_project(project_name)\n        return self.projects.get(project_name, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all cookies with the given name", "response": "def get_all(self, name, default=None):\n        \"\"\"make cookie python 3 version use this instead of getheaders\"\"\"\n        if default is None:\n            default = []\n        return self._headers.get_list(name) or default"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status_count(self, project):\n        '''\n        return a dict\n        '''\n        pipe = self.redis.pipeline(transaction=False)\n        for status in range(1, 5):\n            pipe.scard(self._gen_status_key(project, status))\n        ret = pipe.execute()\n\n        result = {}\n        for status, count in enumerate(ret):\n            if count > 0:\n                result[status + 1] = count\n        return result", "response": "return a dict with the number of active items in the given project"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef increment(self, n=1):\n        with self.count.get_lock():\n            self.count.value += n", "response": "Increment the counter by n."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh(self):\n        self._changed = False\n        self.es.indices.refresh(index=self.index)", "response": "Explicitly refresh one or more index, making all operations\n        performed since the last refresh available for search."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_result(self, type, task, result):\n        '''Send fetch result to processor'''\n        if self.outqueue:\n            try:\n                self.outqueue.put((task, result))\n            except Exception as e:\n                logger.exception(e)", "response": "Send fetch result to processor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_fetch(self, url, task):\n        '''A fake fetcher for dataurl'''\n        self.on_fetch('data', task)\n        result = {}\n        result['orig_url'] = url\n        result['content'] = dataurl.decode(url)\n        result['headers'] = {}\n        result['status_code'] = 200\n        result['url'] = url\n        result['cookies'] = {}\n        result['time'] = 0\n        result['save'] = task.get('fetch', {}).get('save')\n        if len(result['content']) < 70:\n            logger.info(\"[200] %s:%s %s 0s\", task.get('project'), task.get('taskid'), url)\n        else:\n            logger.info(\n                \"[200] %s:%s data:,%s...[content:%d] 0s\",\n                task.get('project'), task.get('taskid'),\n                result['content'][:70],\n                len(result['content'])\n            )\n\n        return result", "response": "A fake fetcher for dataurl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef phantomjs_fetch(self, url, task):\n        '''Fetch with phantomjs proxy'''\n        start_time = time.time()\n        self.on_fetch('phantomjs', task)\n        handle_error = lambda x: self.handle_error('phantomjs', url, task, start_time, x)\n\n        # check phantomjs proxy is enabled\n        if not self.phantomjs_proxy:\n            result = {\n                \"orig_url\": url,\n                \"content\": \"phantomjs is not enabled.\",\n                \"headers\": {},\n                \"status_code\": 501,\n                \"url\": url,\n                \"time\": time.time() - start_time,\n                \"cookies\": {},\n                \"save\": task.get('fetch', {}).get('save')\n            }\n            logger.warning(\"[501] %s:%s %s 0s\", task.get('project'), task.get('taskid'), url)\n            raise gen.Return(result)\n\n        # setup request parameters\n        fetch = self.pack_tornado_request_parameters(url, task)\n        task_fetch = task.get('fetch', {})\n        for each in task_fetch:\n            if each not in fetch:\n                fetch[each] = task_fetch[each]\n\n        # robots.txt\n        if task_fetch.get('robots_txt', False):\n            user_agent = fetch['headers']['User-Agent']\n            can_fetch = yield self.can_fetch(user_agent, url)\n            if not can_fetch:\n                error = tornado.httpclient.HTTPError(403, 'Disallowed by robots.txt')\n                raise gen.Return(handle_error(error))\n\n        request_conf = {\n            'follow_redirects': False\n        }\n        request_conf['connect_timeout'] = fetch.get('connect_timeout', 20)\n        request_conf['request_timeout'] = fetch.get('request_timeout', 120) + 1\n\n        session = cookies.RequestsCookieJar()\n        if 'Cookie' in fetch['headers']:\n            c = http_cookies.SimpleCookie()\n            try:\n                c.load(fetch['headers']['Cookie'])\n            except AttributeError:\n                c.load(utils.utf8(fetch['headers']['Cookie']))\n            for key in c:\n                session.set(key, c[key])\n            del fetch['headers']['Cookie']\n        if 'cookies' in fetch:\n            session.update(fetch['cookies'])\n            del fetch['cookies']\n\n        request = tornado.httpclient.HTTPRequest(url=fetch['url'])\n        cookie_header = cookies.get_cookie_header(session, request)\n        if cookie_header:\n            fetch['headers']['Cookie'] = cookie_header\n\n        # making requests\n        fetch['headers'] = dict(fetch['headers'])\n        try:\n            request = tornado.httpclient.HTTPRequest(\n                url=self.phantomjs_proxy, method=\"POST\",\n                body=json.dumps(fetch), **request_conf)\n        except Exception as e:\n            raise gen.Return(handle_error(e))\n\n        try:\n            response = yield gen.maybe_future(self.http_client.fetch(request))\n        except tornado.httpclient.HTTPError as e:\n            if e.response:\n                response = e.response\n            else:\n                raise gen.Return(handle_error(e))\n\n        if not response.body:\n            raise gen.Return(handle_error(Exception('no response from phantomjs: %r' % response)))\n\n        result = {}\n        try:\n            result = json.loads(utils.text(response.body))\n            assert 'status_code' in result, result\n        except Exception as e:\n            if response.error:\n                result['error'] = utils.text(response.error)\n            raise gen.Return(handle_error(e))\n\n        if result.get('status_code', 200):\n            logger.info(\"[%d] %s:%s %s %.2fs\", result['status_code'],\n                        task.get('project'), task.get('taskid'), url, result['time'])\n        else:\n            logger.error(\"[%d] %s:%s %s, %r %.2fs\", result['status_code'],\n                         task.get('project'), task.get('taskid'),\n                         url, result['content'], result['time'])\n\n        raise gen.Return(result)", "response": "Fetch with phantomjs proxy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        '''Run loop'''\n        logger.info(\"fetcher starting...\")\n\n        def queue_loop():\n            if not self.outqueue or not self.inqueue:\n                return\n            while not self._quit:\n                try:\n                    if self.outqueue.full():\n                        break\n                    if self.http_client.free_size() <= 0:\n                        break\n                    task = self.inqueue.get_nowait()\n                    # FIXME: decode unicode_obj should used after data selete from\n                    # database, it's used here for performance\n                    task = utils.decode_unicode_obj(task)\n                    self.fetch(task)\n                except queue.Empty:\n                    break\n                except KeyboardInterrupt:\n                    break\n                except Exception as e:\n                    logger.exception(e)\n                    break\n\n        tornado.ioloop.PeriodicCallback(queue_loop, 100, io_loop=self.ioloop).start()\n        tornado.ioloop.PeriodicCallback(self.clear_robot_txt_cache, 10000, io_loop=self.ioloop).start()\n        self._running = True\n\n        try:\n            self.ioloop.start()\n        except KeyboardInterrupt:\n            pass\n\n        logger.info(\"fetcher exiting...\")", "response": "Run the fetch loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_result(self, type, task, result):\n        '''Called after task fetched'''\n        status_code = result.get('status_code', 599)\n        if status_code != 599:\n            status_code = (int(status_code) / 100 * 100)\n        self._cnt['5m'].event((task.get('project'), status_code), +1)\n        self._cnt['1h'].event((task.get('project'), status_code), +1)\n\n        if type in ('http', 'phantomjs') and result.get('time'):\n            content_len = len(result.get('content', ''))\n            self._cnt['5m'].event((task.get('project'), 'speed'),\n                                  float(content_len) / result.get('time'))\n            self._cnt['1h'].event((task.get('project'), 'speed'),\n                                  float(content_len) / result.get('time'))\n            self._cnt['5m'].event((task.get('project'), 'time'), result.get('time'))\n            self._cnt['1h'].event((task.get('project'), 'time'), result.get('time'))", "response": "Called after task fetched"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump counters as a dict", "response": "def to_dict(self, get_value=None):\n        \"\"\"Dump counters as a dict\"\"\"\n        result = {}\n        for key, value in iteritems(self):\n            if isinstance(value, BaseCounter):\n                if get_value is not None:\n                    value = getattr(value, get_value)\n                result[key] = value\n            else:\n                result[key] = value.to_dict(get_value)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a counter by counter key", "response": "def value(self, key, value=1):\n        \"\"\"Set value of a counter by counter key\"\"\"\n        if isinstance(key, six.string_types):\n            key = (key, )\n        # assert all(isinstance(k, six.string_types) for k in key)\n        assert isinstance(key, tuple), \"event key type error\"\n        if key not in self.counters:\n            self.counters[key] = self.cls()\n        self.counters[key].value(value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear not used counters", "response": "def trim(self):\n        \"\"\"Clear not used counters\"\"\"\n        for key, value in list(iteritems(self.counters)):\n            if value.empty():\n                del self.counters[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps counters as a dict", "response": "def to_dict(self, get_value=None):\n        \"\"\"Dump counters as a dict\"\"\"\n        self.trim()\n        result = {}\n        for key, value in iteritems(self.counters):\n            if get_value is not None:\n                value = getattr(value, get_value)\n            r = result\n            for _key in key[:-1]:\n                r = r.setdefault(_key, {})\n            r[key[-1]] = value\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(self, filename):\n        try:\n            with open(filename, 'wb') as fp:\n                cPickle.dump(self.counters, fp)\n        except Exception as e:\n            logging.warning(\"can't dump counter to file %s: %s\", filename, e)\n            return False\n        return True", "response": "Dump counters to file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, filename):\n        try:\n            with open(filename, 'rb') as fp:\n                self.counters = cPickle.load(fp)\n        except:\n            logging.debug(\"can't load counter from file: %s\", filename)\n            return False\n        return True", "response": "Load counters from file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx, **kwargs):\n    if kwargs['add_sys_path']:\n        sys.path.append(os.getcwd())\n\n    logging.config.fileConfig(kwargs['logging_config'])\n\n    # get db from env\n    for db in ('taskdb', 'projectdb', 'resultdb'):\n        if kwargs[db] is not None:\n            continue\n        if os.environ.get('MYSQL_NAME'):\n            kwargs[db] = utils.Get(lambda db=db: connect_database(\n                'sqlalchemy+mysql+%s://%s:%s/%s' % (\n                    db, os.environ['MYSQL_PORT_3306_TCP_ADDR'],\n                    os.environ['MYSQL_PORT_3306_TCP_PORT'], db)))\n        elif os.environ.get('MONGODB_NAME'):\n            kwargs[db] = utils.Get(lambda db=db: connect_database(\n                'mongodb+%s://%s:%s/%s' % (\n                    db, os.environ['MONGODB_PORT_27017_TCP_ADDR'],\n                    os.environ['MONGODB_PORT_27017_TCP_PORT'], db)))\n        elif ctx.invoked_subcommand == 'bench':\n            if kwargs['data_path'] == './data':\n                kwargs['data_path'] += '/bench'\n                shutil.rmtree(kwargs['data_path'], ignore_errors=True)\n                os.mkdir(kwargs['data_path'])\n            if db in ('taskdb', 'resultdb'):\n                kwargs[db] = utils.Get(lambda db=db: connect_database('sqlite+%s://' % (db)))\n            elif db in ('projectdb', ):\n                kwargs[db] = utils.Get(lambda db=db: connect_database('local+%s://%s' % (\n                    db, os.path.join(os.path.dirname(__file__), 'libs/bench.py'))))\n        else:\n            if not os.path.exists(kwargs['data_path']):\n                os.mkdir(kwargs['data_path'])\n            kwargs[db] = utils.Get(lambda db=db: connect_database('sqlite+%s:///%s/%s.db' % (\n                db, kwargs['data_path'], db[:-2])))\n            kwargs['is_%s_default' % db] = True\n\n    # create folder for counter.dump\n    if not os.path.exists(kwargs['data_path']):\n        os.mkdir(kwargs['data_path'])\n\n    # message queue, compatible with old version\n    if kwargs.get('message_queue'):\n        pass\n    elif kwargs.get('amqp_url'):\n        kwargs['message_queue'] = kwargs['amqp_url']\n    elif os.environ.get('RABBITMQ_NAME'):\n        kwargs['message_queue'] = (\"amqp://guest:guest@%(RABBITMQ_PORT_5672_TCP_ADDR)s\"\n                                   \":%(RABBITMQ_PORT_5672_TCP_PORT)s/%%2F\" % os.environ)\n    elif kwargs.get('beanstalk'):\n        kwargs['message_queue'] = \"beanstalk://%s/\" % kwargs['beanstalk']\n\n    for name in ('newtask_queue', 'status_queue', 'scheduler2fetcher',\n                 'fetcher2processor', 'processor2result'):\n        if kwargs.get('message_queue'):\n            kwargs[name] = utils.Get(lambda name=name: connect_message_queue(\n                name, kwargs.get('message_queue'), kwargs['queue_maxsize']))\n        else:\n            kwargs[name] = connect_message_queue(name, kwargs.get('message_queue'),\n                                                 kwargs['queue_maxsize'])\n\n    # phantomjs-proxy\n    if kwargs.get('phantomjs_proxy'):\n        pass\n    elif os.environ.get('PHANTOMJS_NAME'):\n        kwargs['phantomjs_proxy'] = os.environ['PHANTOMJS_PORT_25555_TCP'][len('tcp://'):]\n\n    # puppeteer-proxy\n    if kwargs.get('puppeteer_proxy'):\n        pass\n    elif os.environ.get('PUPPETEER_NAME'):\n        kwargs['puppeteer_proxy'] = os.environ['PUPPETEER_PORT_22222_TCP'][len('tcp://'):]\n\n    ctx.obj = utils.ObjectDict(ctx.obj or {})\n    ctx.obj['instances'] = []\n    ctx.obj.update(kwargs)\n\n    if ctx.invoked_subcommand is None and not ctx.obj.get('testing_mode'):\n        ctx.invoke(all)\n    return ctx", "response": "A powerful spider system in python."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns Scheduler, only one scheduler is allowed.", "response": "def scheduler(ctx, xmlrpc, xmlrpc_host, xmlrpc_port,\n              inqueue_limit, delete_time, active_tasks, loop_limit, fail_pause_num,\n              scheduler_cls, threads, get_object=False):\n    \"\"\"\n    Run Scheduler, only one scheduler is allowed.\n    \"\"\"\n    g = ctx.obj\n    Scheduler = load_cls(None, None, scheduler_cls)\n\n    kwargs = dict(taskdb=g.taskdb, projectdb=g.projectdb, resultdb=g.resultdb,\n                  newtask_queue=g.newtask_queue, status_queue=g.status_queue,\n                  out_queue=g.scheduler2fetcher, data_path=g.get('data_path', 'data'))\n    if threads:\n        kwargs['threads'] = int(threads)\n\n    scheduler = Scheduler(**kwargs)\n    scheduler.INQUEUE_LIMIT = inqueue_limit\n    scheduler.DELETE_TIME = delete_time\n    scheduler.ACTIVE_TASKS = active_tasks\n    scheduler.LOOP_LIMIT = loop_limit\n    scheduler.FAIL_PAUSE_NUM = fail_pause_num\n\n    g.instances.append(scheduler)\n    if g.get('testing_mode') or get_object:\n        return scheduler\n\n    if xmlrpc:\n        utils.run_in_thread(scheduler.xmlrpc_run, port=xmlrpc_port, bind=xmlrpc_host)\n    scheduler.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef processor(ctx, processor_cls, process_time_limit, enable_stdout_capture=True, get_object=False):\n    g = ctx.obj\n    Processor = load_cls(None, None, processor_cls)\n\n    processor = Processor(projectdb=g.projectdb,\n                          inqueue=g.fetcher2processor, status_queue=g.status_queue,\n                          newtask_queue=g.newtask_queue, result_queue=g.processor2result,\n                          enable_stdout_capture=enable_stdout_capture,\n                          process_time_limit=process_time_limit)\n\n    g.instances.append(processor)\n    if g.get('testing_mode') or get_object:\n        return processor\n\n    processor.run()", "response": "Run a single Processor instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns phantomjs fetcher if phantomjs is installed.", "response": "def phantomjs(ctx, phantomjs_path, port, auto_restart, args):\n    \"\"\"\n    Run phantomjs fetcher if phantomjs is installed.\n    \"\"\"\n    args = args or ctx.default_map and ctx.default_map.get('args', [])\n\n    import subprocess\n    g = ctx.obj\n    _quit = []\n    phantomjs_fetcher = os.path.join(\n        os.path.dirname(pyspider.__file__), 'fetcher/phantomjs_fetcher.js')\n    cmd = [phantomjs_path,\n           # this may cause memory leak: https://github.com/ariya/phantomjs/issues/12903\n           #'--load-images=false',\n           '--ssl-protocol=any',\n           '--disk-cache=true'] + list(args or []) + [phantomjs_fetcher, str(port)]\n\n    try:\n        _phantomjs = subprocess.Popen(cmd)\n    except OSError:\n        logging.warning('phantomjs not found, continue running without it.')\n        return None\n\n    def quit(*args, **kwargs):\n        _quit.append(1)\n        _phantomjs.kill()\n        _phantomjs.wait()\n        logging.info('phantomjs exited.')\n\n    if not g.get('phantomjs_proxy'):\n        g['phantomjs_proxy'] = '127.0.0.1:%s' % port\n\n    phantomjs = utils.ObjectDict(port=port, quit=quit)\n    g.instances.append(phantomjs)\n    if g.get('testing_mode'):\n        return phantomjs\n\n    while True:\n        _phantomjs.wait()\n        if _quit or not auto_restart:\n            break\n        _phantomjs = subprocess.Popen(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun puppeteer fetcher if puppeteer is installed.", "response": "def puppeteer(ctx, port, auto_restart, args):\n    \"\"\"\n    Run puppeteer fetcher if puppeteer is installed.\n    \"\"\"\n\n    import subprocess\n    g = ctx.obj\n    _quit = []\n    puppeteer_fetcher = os.path.join(\n        os.path.dirname(pyspider.__file__), 'fetcher/puppeteer_fetcher.js')\n    cmd = ['node', puppeteer_fetcher, str(port)]\n\n    try:\n        _puppeteer = subprocess.Popen(cmd)\n    except OSError:\n        logging.warning('puppeteer not found, continue running without it.')\n        return None\n\n    def quit(*args, **kwargs):\n        _quit.append(1)\n        _puppeteer.kill()\n        _puppeteer.wait()\n        logging.info('puppeteer exited.')\n\n    if not g.get('puppeteer_proxy'):\n        g['puppeteer_proxy'] = '127.0.0.1:%s' % port\n\n    puppeteer = utils.ObjectDict(port=port, quit=quit)\n    g.instances.append(puppeteer)\n    if g.get('testing_mode'):\n        return puppeteer\n\n    while True:\n        _puppeteer.wait()\n        if _quit or not auto_restart:\n            break\n        _puppeteer = subprocess.Popen(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all(ctx, fetcher_num, processor_num, result_worker_num, run_in):\n\n    ctx.obj['debug'] = False\n    g = ctx.obj\n\n    # FIXME: py34 cannot run components with threads\n    if run_in == 'subprocess' and os.name != 'nt':\n        run_in = utils.run_in_subprocess\n    else:\n        run_in = utils.run_in_thread\n\n    threads = []\n\n    try:\n        # phantomjs\n        if not g.get('phantomjs_proxy'):\n            phantomjs_config = g.config.get('phantomjs', {})\n            phantomjs_config.setdefault('auto_restart', True)\n            threads.append(run_in(ctx.invoke, phantomjs, **phantomjs_config))\n            time.sleep(2)\n            if threads[-1].is_alive() and not g.get('phantomjs_proxy'):\n                g['phantomjs_proxy'] = '127.0.0.1:%s' % phantomjs_config.get('port', 25555)\n\n        # puppeteer\n        if not g.get('puppeteer_proxy'):\n            puppeteer_config = g.config.get('puppeteer', {})\n            puppeteer_config.setdefault('auto_restart', True)\n            threads.append(run_in(ctx.invoke, puppeteer, **puppeteer_config))\n            time.sleep(2)\n            if threads[-1].is_alive() and not g.get('puppeteer_proxy'):\n                g['puppeteer_proxy'] = '127.0.0.1:%s' % puppeteer_config.get('port', 22222)\n\n        # result worker\n        result_worker_config = g.config.get('result_worker', {})\n        for i in range(result_worker_num):\n            threads.append(run_in(ctx.invoke, result_worker, **result_worker_config))\n\n        # processor\n        processor_config = g.config.get('processor', {})\n        for i in range(processor_num):\n            threads.append(run_in(ctx.invoke, processor, **processor_config))\n\n        # fetcher\n        fetcher_config = g.config.get('fetcher', {})\n        fetcher_config.setdefault('xmlrpc_host', '127.0.0.1')\n        for i in range(fetcher_num):\n            threads.append(run_in(ctx.invoke, fetcher, **fetcher_config))\n\n        # scheduler\n        scheduler_config = g.config.get('scheduler', {})\n        scheduler_config.setdefault('xmlrpc_host', '127.0.0.1')\n        threads.append(run_in(ctx.invoke, scheduler, **scheduler_config))\n\n        # running webui in main thread to make it exitable\n        webui_config = g.config.get('webui', {})\n        webui_config.setdefault('scheduler_rpc', 'http://127.0.0.1:%s/'\n                                % g.config.get('scheduler', {}).get('xmlrpc_port', 23333))\n        ctx.invoke(webui, **webui_config)\n    finally:\n        # exit components run in threading\n        for each in g.instances:\n            each.quit()\n\n        # exit components run in subprocess\n        for each in threads:\n            if not each.is_alive():\n                continue\n            if hasattr(each, 'terminate'):\n                each.terminate()\n            each.join()", "response": "Run all the components in subprocess or thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bench(ctx, fetcher_num, processor_num, result_worker_num, run_in, total, show,\n          taskdb_bench, message_queue_bench, all_bench):\n    \"\"\"\n    Run Benchmark test.\n    In bench mode, in-memory sqlite database is used instead of on-disk sqlite database.\n    \"\"\"\n    from pyspider.libs import bench\n    from pyspider.webui import bench_test  # flake8: noqa\n\n    ctx.obj['debug'] = False\n    g = ctx.obj\n    if result_worker_num == 0:\n        g['processor2result'] = None\n\n    if run_in == 'subprocess' and os.name != 'nt':\n        run_in = utils.run_in_subprocess\n    else:\n        run_in = utils.run_in_thread\n\n    all_test = not taskdb_bench and not message_queue_bench and not all_bench\n\n    # test taskdb\n    if all_test or taskdb_bench:\n        bench.bench_test_taskdb(g.taskdb)\n    # test message queue\n    if all_test or message_queue_bench:\n        bench.bench_test_message_queue(g.scheduler2fetcher)\n    # test all\n    if not all_test and not all_bench:\n        return\n\n    project_name = 'bench'\n\n    def clear_project():\n        g.taskdb.drop(project_name)\n        g.resultdb.drop(project_name)\n\n    clear_project()\n\n    # disable log\n    logging.getLogger().setLevel(logging.ERROR)\n    logging.getLogger('scheduler').setLevel(logging.ERROR)\n    logging.getLogger('fetcher').setLevel(logging.ERROR)\n    logging.getLogger('processor').setLevel(logging.ERROR)\n    logging.getLogger('result').setLevel(logging.ERROR)\n    logging.getLogger('webui').setLevel(logging.ERROR)\n    logging.getLogger('werkzeug').setLevel(logging.ERROR)\n\n    try:\n        threads = []\n\n        # result worker\n        result_worker_config = g.config.get('result_worker', {})\n        for i in range(result_worker_num):\n            threads.append(run_in(ctx.invoke, result_worker,\n                                  result_cls='pyspider.libs.bench.BenchResultWorker',\n                                  **result_worker_config))\n\n        # processor\n        processor_config = g.config.get('processor', {})\n        for i in range(processor_num):\n            threads.append(run_in(ctx.invoke, processor,\n                                  processor_cls='pyspider.libs.bench.BenchProcessor',\n                                  **processor_config))\n\n        # fetcher\n        fetcher_config = g.config.get('fetcher', {})\n        fetcher_config.setdefault('xmlrpc_host', '127.0.0.1')\n        for i in range(fetcher_num):\n            threads.append(run_in(ctx.invoke, fetcher,\n                                  fetcher_cls='pyspider.libs.bench.BenchFetcher',\n                                  **fetcher_config))\n\n        # webui\n        webui_config = g.config.get('webui', {})\n        webui_config.setdefault('scheduler_rpc', 'http://127.0.0.1:%s/'\n                                % g.config.get('scheduler', {}).get('xmlrpc_port', 23333))\n        threads.append(run_in(ctx.invoke, webui, **webui_config))\n\n        # scheduler\n        scheduler_config = g.config.get('scheduler', {})\n        scheduler_config.setdefault('xmlrpc_host', '127.0.0.1')\n        scheduler_config.setdefault('xmlrpc_port', 23333)\n        threads.append(run_in(ctx.invoke, scheduler,\n                              scheduler_cls='pyspider.libs.bench.BenchScheduler',\n                              **scheduler_config))\n        scheduler_rpc = connect_rpc(ctx, None,\n                                    'http://%(xmlrpc_host)s:%(xmlrpc_port)s/' % scheduler_config)\n\n        for _ in range(20):\n            if utils.check_port_open(23333):\n                break\n            time.sleep(1)\n\n        scheduler_rpc.newtask({\n            \"project\": project_name,\n            \"taskid\": \"on_start\",\n            \"url\": \"data:,on_start\",\n            \"fetch\": {\n                \"save\": {\"total\": total, \"show\": show}\n            },\n            \"process\": {\n                \"callback\": \"on_start\",\n            },\n        })\n\n        # wait bench test finished\n        while True:\n            time.sleep(1)\n            if scheduler_rpc.size() == 0:\n                break\n    finally:\n        # exit components run in threading\n        for each in g.instances:\n            each.quit()\n\n        # exit components run in subprocess\n        for each in threads:\n            if hasattr(each, 'terminate'):\n                each.terminate()\n            each.join(1)\n\n        clear_project()", "response": "Run Benchmark test.\n    In bench mode, in-memory sqlite database is used instead of on-disk sqlite database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef one(ctx, interactive, enable_phantomjs, enable_puppeteer, scripts):\n\n    ctx.obj['debug'] = False\n    g = ctx.obj\n    g['testing_mode'] = True\n\n    if scripts:\n        from pyspider.database.local.projectdb import ProjectDB\n        g['projectdb'] = ProjectDB(scripts)\n        if g.get('is_taskdb_default'):\n            g['taskdb'] = connect_database('sqlite+taskdb://')\n        if g.get('is_resultdb_default'):\n            g['resultdb'] = None\n\n    if enable_phantomjs:\n        phantomjs_config = g.config.get('phantomjs', {})\n        phantomjs_obj = ctx.invoke(phantomjs, **phantomjs_config)\n        if phantomjs_obj:\n            g.setdefault('phantomjs_proxy', '127.0.0.1:%s' % phantomjs_obj.port)\n    else:\n        phantomjs_obj = None\n\n    if enable_puppeteer:\n        puppeteer_config = g.config.get('puppeteer', {})\n        puppeteer_obj = ctx.invoke(puppeteer, **puppeteer_config)\n        if puppeteer_obj:\n            g.setdefault('puppeteer_proxy', '127.0.0.1:%s' % puppeteer.port)\n    else:\n        puppeteer_obj = None\n\n    result_worker_config = g.config.get('result_worker', {})\n    if g.resultdb is None:\n        result_worker_config.setdefault('result_cls',\n                                        'pyspider.result.OneResultWorker')\n    result_worker_obj = ctx.invoke(result_worker, **result_worker_config)\n\n    processor_config = g.config.get('processor', {})\n    processor_config.setdefault('enable_stdout_capture', False)\n    processor_obj = ctx.invoke(processor, **processor_config)\n\n    fetcher_config = g.config.get('fetcher', {})\n    fetcher_config.setdefault('xmlrpc', False)\n    fetcher_obj = ctx.invoke(fetcher, **fetcher_config)\n\n    scheduler_config = g.config.get('scheduler', {})\n    scheduler_config.setdefault('xmlrpc', False)\n    scheduler_config.setdefault('scheduler_cls',\n                                'pyspider.scheduler.OneScheduler')\n    scheduler_obj = ctx.invoke(scheduler, **scheduler_config)\n\n    scheduler_obj.init_one(ioloop=fetcher_obj.ioloop,\n                           fetcher=fetcher_obj,\n                           processor=processor_obj,\n                           result_worker=result_worker_obj,\n                           interactive=interactive)\n    if scripts:\n        for project in g.projectdb.projects:\n            scheduler_obj.trigger_on_start(project)\n\n    try:\n        scheduler_obj.run()\n    finally:\n        scheduler_obj.quit()\n        if phantomjs_obj:\n            phantomjs_obj.quit()\n        if puppeteer_obj:\n            puppeteer_obj.quit()", "response": "One mode only means all - in - one it runs every thing in one process over tornado. ioloop for debug purpose"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(ctx, scheduler_rpc, project, message):\n    if isinstance(scheduler_rpc, six.string_types):\n        scheduler_rpc = connect_rpc(ctx, None, scheduler_rpc)\n    if scheduler_rpc is None and os.environ.get('SCHEDULER_NAME'):\n        scheduler_rpc = connect_rpc(ctx, None, 'http://%s/' % (\n            os.environ['SCHEDULER_PORT_23333_TCP'][len('tcp://'):]))\n    if scheduler_rpc is None:\n        scheduler_rpc = connect_rpc(ctx, None, 'http://127.0.0.1:23333/')\n\n    return scheduler_rpc.send_task({\n        'taskid': utils.md5string('data:,on_message'),\n        'project': project,\n        'url': 'data:,on_message',\n        'fetch': {\n            'save': ('__command__', message),\n        },\n        'process': {\n            'callback': '_on_message',\n        }\n    })", "response": "Send a message to a project from command line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pprint(object, stream=None, indent=1, width=80, depth=None):\n    printer = PrettyPrinter(\n        stream=stream, indent=indent, width=width, depth=depth)\n    printer.pprint(object)", "response": "Pretty - print a Python object to a stream [ default is sys. stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pformat(object, indent=1, width=80, depth=None):\n    return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(object)", "response": "Format a Python object into a pretty - printed representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format(self, object, context, maxlevels, level):\n        return _safe_repr(object, context, maxlevels, level)", "response": "Format object for a specific context returning a string containing the representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the loop in order to get the result from the inqueue and call the on_result method.", "response": "def run(self):\n        '''Run loop'''\n        logger.info(\"result_worker starting...\")\n\n        while not self._quit:\n            try:\n                task, result = self.inqueue.get(timeout=1)\n                self.on_result(task, result)\n            except Queue.Empty as e:\n                continue\n            except KeyboardInterrupt:\n                break\n            except AssertionError as e:\n                logger.error(e)\n                continue\n            except Exception as e:\n                logger.exception(e)\n                continue\n\n        logger.info(\"result_worker exiting...\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self):\n        '''Get the number of tokens in bucket'''\n        now = time.time()\n        if self.bucket >= self.burst:\n            self.last_update = now\n            return self.bucket\n        bucket = self.rate * (now - self.last_update)\n        self.mutex.acquire()\n        if bucket > 1:\n            self.bucket += bucket\n            if self.bucket > self.burst:\n                self.bucket = self.burst\n            self.last_update = now\n        self.mutex.release()\n        return self.bucket", "response": "Get the number of tokens in bucket"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmigrate the database from one database to another.", "response": "def migrate(pool, from_connection, to_connection):\n    \"\"\"\n    Migrate tool for pyspider\n    \"\"\"\n    f = connect_database(from_connection)\n    t = connect_database(to_connection)\n\n    if isinstance(f, ProjectDB):\n        for each in f.get_all():\n            each = unicode_obj(each)\n            logging.info(\"projectdb: %s\", each['name'])\n            t.drop(each['name'])\n            t.insert(each['name'], each)\n    elif isinstance(f, TaskDB):\n        pool = Pool(pool)\n        pool.map(\n            lambda x, f=from_connection, t=to_connection: taskdb_migrating(x, f, t),\n            f.projects)\n    elif isinstance(f, ResultDB):\n        pool = Pool(pool)\n        pool.map(\n            lambda x, f=from_connection, t=to_connection: resultdb_migrating(x, f, t),\n            f.projects)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode(data, mime_type='', charset='utf-8', base64=True):\n    if isinstance(data, six.text_type):\n        data = data.encode(charset)\n    else:\n        charset = None\n    if base64:\n        data = utils.text(b64encode(data))\n    else:\n        data = utils.text(quote(data))\n\n    result = ['data:', ]\n    if mime_type:\n        result.append(mime_type)\n    if charset:\n        result.append(';charset=')\n        result.append(charset)\n    if base64:\n        result.append(';base64')\n    result.append(',')\n    result.append(data)\n\n    return ''.join(result)", "response": "Encode data to DataURL"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode(data_url):\n    metadata, data = data_url.rsplit(',', 1)\n    _, metadata = metadata.split('data:', 1)\n    parts = metadata.split(';')\n    if parts[-1] == 'base64':\n        data = b64decode(data)\n    else:\n        data = unquote(data)\n\n    for part in parts:\n        if part.startswith(\"charset=\"):\n            data = data.decode(part[8:])\n    return data", "response": "Decode data_url into a list of base64 encoded strings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the actual URL to use.", "response": "def _build_url(url, _params):\n    \"\"\"Build the actual URL to use.\"\"\"\n\n    # Support for unicode domain names and paths.\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n    netloc = netloc.encode('idna').decode('utf-8')\n    if not path:\n        path = '/'\n\n    if six.PY2:\n        if isinstance(scheme, six.text_type):\n            scheme = scheme.encode('utf-8')\n        if isinstance(netloc, six.text_type):\n            netloc = netloc.encode('utf-8')\n        if isinstance(path, six.text_type):\n            path = path.encode('utf-8')\n        if isinstance(params, six.text_type):\n            params = params.encode('utf-8')\n        if isinstance(query, six.text_type):\n            query = query.encode('utf-8')\n        if isinstance(fragment, six.text_type):\n            fragment = fragment.encode('utf-8')\n\n    enc_params = _encode_params(_params)\n    if enc_params:\n        if query:\n            query = '%s&%s' % (query, enc_params)\n        else:\n            query = enc_params\n    url = (urlunparse([scheme, netloc, path, params, query, fragment]))\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquoting non - ascii characters in a Chinese URL.", "response": "def quote_chinese(url, encodeing=\"utf-8\"):\n    \"\"\"Quote non-ascii characters\"\"\"\n    if isinstance(url, six.text_type):\n        return quote_chinese(url.encode(encodeing))\n    if six.PY3:\n        res = [six.int2byte(b).decode('latin-1') if b < 128 else '%%%02X' % b for b in url]\n    else:\n        res = [b if ord(b) < 128 else '%%%02X' % ord(b) for b in url]\n    return \"\".join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DownloadResource(url, path):\n    '''Downloads resources from s3 by url and unzips them to the provided path'''\n    import requests\n    from six import BytesIO\n    import zipfile\n    print(\"Downloading... {} to {}\".format(url, path))\n    r = requests.get(url, stream=True)\n    z = zipfile.ZipFile(BytesIO(r.content))\n    z.extractall(path)\n    print(\"Completed download and extraction.\")", "response": "Downloads resources from s3 by url and unzips them to the provided path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddLeNetModel(model, data):\n    '''\n    This part is the standard LeNet model: from data to the softmax prediction.\n\n    For each convolutional layer we specify dim_in - number of input channels\n    and dim_out - number or output channels. Also each Conv and MaxPool layer changes the\n    image size. For example, kernel of size 5 reduces each side of an image by 4.\n\n    While when we have kernel and stride sizes equal 2 in a MaxPool layer, it divides\n    each side in half.\n    '''\n    # Image size: 28 x 28 -> 24 x 24\n    conv1 = brew.conv(model, data, 'conv1', dim_in=1, dim_out=20, kernel=5)\n    # Image size: 24 x 24 -> 12 x 12\n    pool1 = brew.max_pool(model, conv1, 'pool1', kernel=2, stride=2)\n    # Image size: 12 x 12 -> 8 x 8\n    conv2 = brew.conv(model, pool1, 'conv2', dim_in=20, dim_out=100, kernel=5)\n    # Image size: 8 x 8 -> 4 x 4\n    pool2 = brew.max_pool(model, conv2, 'pool2', kernel=2, stride=2)\n    # 50 * 4 * 4 stands for dim_out from previous layer multiplied by the\n    # image size\n    fc3 = brew.fc(model, pool2, 'fc3', dim_in=100 * 4 * 4, dim_out=500)\n    relu = brew.relu(model, fc3, fc3)\n    pred = brew.fc(model, relu, 'pred', 500, 10)\n    softmax = brew.softmax(model, pred, 'softmax')\n    return softmax", "response": "This part is the standard LeNet model that uses the data to predict the image size of the image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an accuracy op to the model", "response": "def AddAccuracy(model, softmax, label):\n    \"\"\"Adds an accuracy op to the model\"\"\"\n    accuracy = brew.accuracy(model, [softmax, label], \"accuracy\")\n    return accuracy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd training operators to the model.", "response": "def AddTrainingOperators(model, softmax, label):\n    \"\"\"Adds training operators to the model.\"\"\"\n    xent = model.LabelCrossEntropy([softmax, label], 'xent')\n    # compute the expected loss\n    loss = model.AveragedLoss(xent, \"loss\")\n    # track the accuracy of the model\n    AddAccuracy(model, softmax, label)\n    # use the average loss we just computed to add gradient operators to the\n    # model\n    model.AddGradientOperators([loss])\n    # do a simple stochastic gradient descent\n    ITER = brew.iter(model, \"iter\")\n    # set the learning rate schedule\n    LR = model.LearningRate(\n        ITER, \"LR\", base_lr=-0.1, policy=\"step\", stepsize=1, gamma=0.999)\n    # ONE is a constant value that is used in the gradient update. We only need\n    # to create it once, so it is explicitly placed in param_init_net.\n    ONE = model.param_init_net.ConstantFill([], \"ONE\", shape=[1], value=1.0)\n    # Now, for each parameter, we do the gradient updates.\n    for param in model.params:\n        # Note how we get the gradient of each parameter - ModelHelper keeps\n        # track of that.\n        param_grad = model.param_to_grad[param]\n        # The update is a simple weighted sum: param = param + param_grad * LR\n        model.WeightedSum([param, ONE, param_grad, LR], param)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddBookkeepingOperators(model):\n    # Print basically prints out the content of the blob. to_file=1 routes the\n    # printed output to a file. The file is going to be stored under\n    #     root_folder/[blob name]\n    model.Print('accuracy', [], to_file=1)\n    model.Print('loss', [], to_file=1)\n    # Summarizes the parameters. Different from Print, Summarize gives some\n    # statistics of the parameter, such as mean, std, min and max.\n    for param in model.params:\n        model.Summarize(param, [], to_file=1)\n        model.Summarize(model.param_to_grad[param], [], to_file=1)", "response": "Adds a few bookkeeping operators that we can inspect later."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_loss_func(self, C=1.0, k=1):\n        def lf(x):\n            mu, ln_var = self.encode(x)\n            batchsize = len(mu.data)\n            # reconstruction loss\n            rec_loss = 0\n            for l in six.moves.range(k):\n                z = F.gaussian(mu, ln_var)\n                rec_loss += F.bernoulli_nll(x, self.decode(z, sigmoid=False)) \\\n                    / (k * batchsize)\n            self.rec_loss = rec_loss\n            self.loss = self.rec_loss + \\\n                C * gaussian_kl_divergence(mu, ln_var) / batchsize\n            return self.loss\n        return lf", "response": "Returns loss function of VAE."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntrains the agent on the given environment.", "response": "def fit(self, env, nb_steps, action_repetition=1, callbacks=None, verbose=1,\n            visualize=False, nb_max_start_steps=0, start_step_policy=None, log_interval=10000,\n            nb_max_episode_steps=None):\n        \"\"\"Trains the agent on the given environment.\n\n        # Arguments\n            env: (`Env` instance): Environment that the agent interacts with. See [Env](#env) for details.\n            nb_steps (integer): Number of training steps to be performed.\n            action_repetition (integer): Number of times the agent repeats the same action without\n                observing the environment again. Setting this to a value > 1 can be useful\n                if a single action only has a very small effect on the environment.\n            callbacks (list of `keras.callbacks.Callback` or `rl.callbacks.Callback` instances):\n                List of callbacks to apply during training. See [callbacks](/callbacks) for details.\n            verbose (integer): 0 for no logging, 1 for interval logging (compare `log_interval`), 2 for episode logging\n            visualize (boolean): If `True`, the environment is visualized during training. However,\n                this is likely going to slow down training significantly and is thus intended to be\n                a debugging instrument.\n            nb_max_start_steps (integer): Number of maximum steps that the agent performs at the beginning\n                of each episode using `start_step_policy`. Notice that this is an upper limit since\n                the exact number of steps to be performed is sampled uniformly from [0, max_start_steps]\n                at the beginning of each episode.\n            start_step_policy (`lambda observation: action`): The policy\n                to follow if `nb_max_start_steps` > 0. If set to `None`, a random action is performed.\n            log_interval (integer): If `verbose` = 1, the number of steps that are considered to be an interval.\n            nb_max_episode_steps (integer): Number of steps per episode that the agent performs before\n                automatically resetting the environment. Set to `None` if each episode should run\n                (potentially indefinitely) until the environment signals a terminal state.\n\n        # Returns\n            A `keras.callbacks.History` instance that recorded the entire training process.\n        \"\"\"\n        if not self.compiled:\n            raise RuntimeError('Your tried to fit your agent but it hasn\\'t been compiled yet. Please call `compile()` before `fit()`.')\n        if action_repetition < 1:\n            raise ValueError('action_repetition must be >= 1, is {}'.format(action_repetition))\n\n        self.training = True\n\n        callbacks = [] if not callbacks else callbacks[:]\n\n        if verbose == 1:\n            callbacks += [TrainIntervalLogger(interval=log_interval)]\n        elif verbose > 1:\n            callbacks += [TrainEpisodeLogger()]\n        if visualize:\n            callbacks += [Visualizer()]\n        history = History()\n        callbacks += [history]\n        callbacks = CallbackList(callbacks)\n        if hasattr(callbacks, 'set_model'):\n            callbacks.set_model(self)\n        else:\n            callbacks._set_model(self)\n        callbacks._set_env(env)\n        params = {\n            'nb_steps': nb_steps,\n        }\n        if hasattr(callbacks, 'set_params'):\n            callbacks.set_params(params)\n        else:\n            callbacks._set_params(params)\n        self._on_train_begin()\n        callbacks.on_train_begin()\n\n        episode = np.int16(0)\n        self.step = np.int16(0)\n        observation = None\n        episode_reward = None\n        episode_step = None\n        did_abort = False\n        try:\n            while self.step < nb_steps:\n                if observation is None:  # start of a new episode\n                    callbacks.on_episode_begin(episode)\n                    episode_step = np.int16(0)\n                    episode_reward = np.float32(0)\n\n                    # Obtain the initial observation by resetting the environment.\n                    self.reset_states()\n                    observation = deepcopy(env.reset())\n                    if self.processor is not None:\n                        observation = self.processor.process_observation(observation)\n                    assert observation is not None\n\n                    # Perform random starts at beginning of episode and do not record them into the experience.\n                    # This slightly changes the start position between games.\n                    nb_random_start_steps = 0 if nb_max_start_steps == 0 else np.random.randint(nb_max_start_steps)\n                    for _ in range(nb_random_start_steps):\n                        if start_step_policy is None:\n                            action = env.action_space.sample()\n                        else:\n                            action = start_step_policy(observation)\n                        if self.processor is not None:\n                            action = self.processor.process_action(action)\n                        callbacks.on_action_begin(action)\n                        observation, reward, done, info = env.step(action)\n                        observation = deepcopy(observation)\n                        if self.processor is not None:\n                            observation, reward, done, info = self.processor.process_step(observation, reward, done, info)\n                        callbacks.on_action_end(action)\n                        if done:\n                            warnings.warn('Env ended before {} random steps could be performed at the start. You should probably lower the `nb_max_start_steps` parameter.'.format(nb_random_start_steps))\n                            observation = deepcopy(env.reset())\n                            if self.processor is not None:\n                                observation = self.processor.process_observation(observation)\n                            break\n\n                # At this point, we expect to be fully initialized.\n                assert episode_reward is not None\n                assert episode_step is not None\n                assert observation is not None\n\n                # Run a single step.\n                callbacks.on_step_begin(episode_step)\n                # This is were all of the work happens. We first perceive and compute the action\n                # (forward step) and then use the reward to improve (backward step).\n                action = self.forward(observation)\n                if self.processor is not None:\n                    action = self.processor.process_action(action)\n                reward = np.float32(0)\n                accumulated_info = {}\n                done = False\n                for _ in range(action_repetition):\n                    callbacks.on_action_begin(action)\n                    observation, r, done, info = env.step(action)\n                    observation = deepcopy(observation)\n                    if self.processor is not None:\n                        observation, r, done, info = self.processor.process_step(observation, r, done, info)\n                    for key, value in info.items():\n                        if not np.isreal(value):\n                            continue\n                        if key not in accumulated_info:\n                            accumulated_info[key] = np.zeros_like(value)\n                        accumulated_info[key] += value\n                    callbacks.on_action_end(action)\n                    reward += r\n                    if done:\n                        break\n                if nb_max_episode_steps and episode_step >= nb_max_episode_steps - 1:\n                    # Force a terminal state.\n                    done = True\n                metrics = self.backward(reward, terminal=done)\n                episode_reward += reward\n\n                step_logs = {\n                    'action': action,\n                    'observation': observation,\n                    'reward': reward,\n                    'metrics': metrics,\n                    'episode': episode,\n                    'info': accumulated_info,\n                }\n                callbacks.on_step_end(episode_step, step_logs)\n                episode_step += 1\n                self.step += 1\n\n                if done:\n                    # We are in a terminal state but the agent hasn't yet seen it. We therefore\n                    # perform one more forward-backward call and simply ignore the action before\n                    # resetting the environment. We need to pass in `terminal=False` here since\n                    # the *next* state, that is the state of the newly reset environment, is\n                    # always non-terminal by convention.\n                    self.forward(observation)\n                    self.backward(0., terminal=False)\n\n                    # This episode is finished, report and reset.\n                    episode_logs = {\n                        'episode_reward': episode_reward,\n                        'nb_episode_steps': episode_step,\n                        'nb_steps': self.step,\n                    }\n                    callbacks.on_episode_end(episode, episode_logs)\n\n                    episode += 1\n                    observation = None\n                    episode_step = None\n                    episode_reward = None\n        except KeyboardInterrupt:\n            # We catch keyboard interrupts here so that training can be be safely aborted.\n            # This is so common that we've built this right into this function, which ensures that\n            # the `on_train_end` method is properly called.\n            did_abort = True\n        callbacks.on_train_end(logs={'did_abort': did_abort})\n        self._on_train_end()\n\n        return history"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_step(self, observation, reward, done, info):\n        observation = self.process_observation(observation)\n        reward = self.process_reward(reward)\n        info = self.process_info(info)\n        return observation, reward, done, info", "response": "Processes a single step by applying the processor to the observation reward and info arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns current annealing value", "response": "def get_current_value(self):\n        \"\"\"Return current annealing value\n\n        # Returns\n            Value to use in annealing\n        \"\"\"\n        if self.agent.training:\n            # Linear annealed: f(x) = ax + b.\n            a = -float(self.value_max - self.value_min) / float(self.nb_steps)\n            b = float(self.value_max)\n            value = max(self.value_min, a * float(self.agent.step) + b)\n        else:\n            value = self.value_test\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchooses an action to perform", "response": "def select_action(self, **kwargs):\n        \"\"\"Choose an action to perform\n\n        # Returns\n            Action to take (int)\n        \"\"\"\n        setattr(self.inner_policy, self.attr, self.get_current_value())\n        return self.inner_policy.select_action(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self):\n        config = super(LinearAnnealedPolicy, self).get_config()\n        config['attr'] = self.attr\n        config['value_max'] = self.value_max\n        config['value_min'] = self.value_min\n        config['value_test'] = self.value_test\n        config['nb_steps'] = self.nb_steps\n        config['inner_policy'] = get_object_config(self.inner_policy)\n        return config", "response": "Returns configurations of LinearAnnealedPolicy\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_action(self, nb_actions, probs):\n        action = np.random.choice(range(nb_actions), p=probs)\n        return action", "response": "Select a random action from the set of actions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_action(self, q_values):\n        assert q_values.ndim == 1\n        nb_actions = q_values.shape[0]\n\n        if np.random.uniform() < self.eps:\n            action = np.random.randint(0, nb_actions)\n        else:\n            action = np.argmax(q_values)\n        return action", "response": "Returns the selected action from the estimations of Q for each action in the list q_values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning configurations of EpsGreedyQPolicy", "response": "def get_config(self):\n        \"\"\"Return configurations of EpsGreedyQPolicy\n\n        # Returns\n            Dict of config\n        \"\"\"\n        config = super(EpsGreedyQPolicy, self).get_config()\n        config['eps'] = self.eps\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the selected action from the estimations of Q for each action in the list q_values", "response": "def select_action(self, q_values):\n        \"\"\"Return the selected action\n\n        # Arguments\n            q_values (np.ndarray): List of the estimations of Q for each action\n\n        # Returns\n            Selection action\n        \"\"\"\n        assert q_values.ndim == 1\n        action = np.argmax(q_values)\n        return action"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn configurations of BoltzmannQPolicy", "response": "def get_config(self):\n        \"\"\"Return configurations of BoltzmannQPolicy\n\n        # Returns\n            Dict of config\n        \"\"\"\n        config = super(BoltzmannQPolicy, self).get_config()\n        config['tau'] = self.tau\n        config['clip'] = self.clip\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_action(self, q_values):\n        assert q_values.ndim == 1\n        q_values = q_values.astype('float64')\n        nb_actions = q_values.shape[0]\n\n        if np.random.uniform() < self.eps:\n            exp_values = np.exp(np.clip(q_values / self.tau, self.clip[0], self.clip[1]))\n            probs = exp_values / np.sum(exp_values)\n            action = np.random.choice(range(nb_actions), p=probs)\n        else:\n            action = np.argmax(q_values)\n        return action", "response": "Select the action from the set of estimations of Q for each action in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns configurations of MaxBoltzmannQPolicy", "response": "def get_config(self):\n        \"\"\"Return configurations of MaxBoltzmannQPolicy\n\n        # Returns\n            Dict of config\n        \"\"\"\n        config = super(MaxBoltzmannQPolicy, self).get_config()\n        config['eps'] = self.eps\n        config['tau'] = self.tau\n        config['clip'] = self.clip\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_action(self, q_values):\n        # We can't use BGE during testing, since we don't have access to the\n        # action_counts at the end of training.\n        assert self.agent.training, \"BoltzmannGumbelQPolicy should only be used for training, not testing\"\n\n        assert q_values.ndim == 1, q_values.ndim\n        q_values = q_values.astype('float64')\n\n        # If we are starting training, we should reset the action_counts.\n        # Otherwise, action_counts should already be initialized, since we\n        # always do so when we begin training.\n        if self.agent.step == 0:\n            self.action_counts = np.ones(q_values.shape)\n        assert self.action_counts is not None, self.agent.step\n        assert self.action_counts.shape == q_values.shape, (self.action_counts.shape, q_values.shape)\n\n        beta = self.C/np.sqrt(self.action_counts)\n        Z = np.random.gumbel(size=q_values.shape)\n\n        perturbation = beta * Z\n        perturbed_q_values = q_values + perturbation\n        action = np.argmax(perturbed_q_values)\n\n        self.action_counts[action] += 1\n        return action", "response": "Select the next action from the set of estimations of Q for each action in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning configurations of BoltzmannGumbelQPolicy", "response": "def get_config(self):\n        \"\"\"Return configurations of BoltzmannGumbelQPolicy\n\n        # Returns\n            Dict of config\n        \"\"\"\n        config = super(BoltzmannGumbelQPolicy, self).get_config()\n        config['C'] = self.C\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_env(self, env):\n        for callback in self.callbacks:\n            if callable(getattr(callback, '_set_env', None)):\n                callback._set_env(env)", "response": "Set the environment for all the callbacks in callbackList."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls at beginning of each episode for each callback in callbackList", "response": "def on_episode_begin(self, episode, logs={}):\n        \"\"\" Called at beginning of each episode for each callback in callbackList\"\"\"\n        for callback in self.callbacks:\n            # Check if callback supports the more appropriate `on_episode_begin` callback.\n            # If not, fall back to `on_epoch_begin` to be compatible with built-in Keras callbacks.\n            if callable(getattr(callback, 'on_episode_begin', None)):\n                callback.on_episode_begin(episode, logs=logs)\n            else:\n                callback.on_epoch_begin(episode, logs=logs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_episode_end(self, episode, logs={}):\n        for callback in self.callbacks:\n            # Check if callback supports the more appropriate `on_episode_end` callback.\n            # If not, fall back to `on_epoch_end` to be compatible with built-in Keras callbacks.\n            if callable(getattr(callback, 'on_episode_end', None)):\n                callback.on_episode_end(episode, logs=logs)\n            else:\n                callback.on_epoch_end(episode, logs=logs)", "response": "Called at end of each episode for each callback in callbackList"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_step_begin(self, step, logs={}):\n        for callback in self.callbacks:\n            # Check if callback supports the more appropriate `on_step_begin` callback.\n            # If not, fall back to `on_batch_begin` to be compatible with built-in Keras callbacks.\n            if callable(getattr(callback, 'on_step_begin', None)):\n                callback.on_step_begin(step, logs=logs)\n            else:\n                callback.on_batch_begin(step, logs=logs)", "response": "Called at beginning of each step for each callback in callbackList"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls at end of each step for each callback in callbackList", "response": "def on_step_end(self, step, logs={}):\n        \"\"\" Called at end of each step for each callback in callbackList\"\"\"\n        for callback in self.callbacks:\n            # Check if callback supports the more appropriate `on_step_end` callback.\n            # If not, fall back to `on_batch_end` to be compatible with built-in Keras callbacks.\n            if callable(getattr(callback, 'on_step_end', None)):\n                callback.on_step_end(step, logs=logs)\n            else:\n                callback.on_batch_end(step, logs=logs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_action_begin(self, action, logs={}):\n        for callback in self.callbacks:\n            if callable(getattr(callback, 'on_action_begin', None)):\n                callback.on_action_begin(action, logs=logs)", "response": "Called at beginning of each action for each callback in callbackList"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_action_end(self, action, logs={}):\n        for callback in self.callbacks:\n            if callable(getattr(callback, 'on_action_end', None)):\n                callback.on_action_end(action, logs=logs)", "response": "Called at end of each action for each callback in callbackList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_train_begin(self, logs):\n        self.train_start = timeit.default_timer()\n        self.metrics_names = self.model.metrics_names\n        print('Training for {} steps ...'.format(self.params['nb_steps']))", "response": "Print training values at beginning of training"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_train_end(self, logs):\n        duration = timeit.default_timer() - self.train_start\n        print('done, took {:.3f} seconds'.format(duration))", "response": "Print training time at end of training"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset environment variables at beginning of each episode", "response": "def on_episode_begin(self, episode, logs):\n        \"\"\" Reset environment variables at beginning of each episode \"\"\"\n        self.episode_start[episode] = timeit.default_timer()\n        self.observations[episode] = []\n        self.rewards[episode] = []\n        self.actions[episode] = []\n        self.metrics[episode] = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_episode_end(self, episode, logs):\n        duration = timeit.default_timer() - self.episode_start[episode]\n        episode_steps = len(self.observations[episode])\n\n        # Format all metrics.\n        metrics = np.array(self.metrics[episode])\n        metrics_template = ''\n        metrics_variables = []\n        with warnings.catch_warnings():\n            warnings.filterwarnings('error')\n            for idx, name in enumerate(self.metrics_names):\n                if idx > 0:\n                    metrics_template += ', '\n                try:\n                    value = np.nanmean(metrics[:, idx])\n                    metrics_template += '{}: {:f}'\n                except Warning:\n                    value = '--'\n                    metrics_template += '{}: {}'\n                metrics_variables += [name, value]          \n        metrics_text = metrics_template.format(*metrics_variables)\n\n        nb_step_digits = str(int(np.ceil(np.log10(self.params['nb_steps']))) + 1)\n        template = '{step: ' + nb_step_digits + 'd}/{nb_steps}: episode: {episode}, duration: {duration:.3f}s, episode steps: {episode_steps}, steps per second: {sps:.0f}, episode reward: {episode_reward:.3f}, mean reward: {reward_mean:.3f} [{reward_min:.3f}, {reward_max:.3f}], mean action: {action_mean:.3f} [{action_min:.3f}, {action_max:.3f}], mean observation: {obs_mean:.3f} [{obs_min:.3f}, {obs_max:.3f}], {metrics}'\n        variables = {\n            'step': self.step,\n            'nb_steps': self.params['nb_steps'],\n            'episode': episode + 1,\n            'duration': duration,\n            'episode_steps': episode_steps,\n            'sps': float(episode_steps) / duration,\n            'episode_reward': np.sum(self.rewards[episode]),\n            'reward_mean': np.mean(self.rewards[episode]),\n            'reward_min': np.min(self.rewards[episode]),\n            'reward_max': np.max(self.rewards[episode]),\n            'action_mean': np.mean(self.actions[episode]),\n            'action_min': np.min(self.actions[episode]),\n            'action_max': np.max(self.actions[episode]),\n            'obs_mean': np.mean(self.observations[episode]),\n            'obs_min': np.min(self.observations[episode]),\n            'obs_max': np.max(self.observations[episode]),\n            'metrics': metrics_text,\n        }\n        print(template.format(**variables))\n\n        # Free up resources.\n        del self.episode_start[episode]\n        del self.observations[episode]\n        del self.rewards[episode]\n        del self.actions[episode]\n        del self.metrics[episode]", "response": "Compute and print training statistics of the episode when done"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_step_end(self, step, logs):\n        episode = logs['episode']\n        self.observations[episode].append(logs['observation'])\n        self.rewards[episode].append(logs['reward'])\n        self.actions[episode].append(logs['action'])\n        self.metrics[episode].append(logs['metrics'])\n        self.step += 1", "response": "Update statistics of episode after each step"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset(self):\n        self.interval_start = timeit.default_timer()\n        self.progbar = Progbar(target=self.interval)\n        self.metrics = []\n        self.infos = []\n        self.info_names = None\n        self.episode_rewards = []", "response": "Reset statistics to empty"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints metrics if interval is over", "response": "def on_step_begin(self, step, logs):\n        \"\"\" Print metrics if interval is over \"\"\"\n        if self.step % self.interval == 0:\n            if len(self.episode_rewards) > 0:\n                metrics = np.array(self.metrics)\n                assert metrics.shape == (self.interval, len(self.metrics_names))\n                formatted_metrics = ''\n                if not np.isnan(metrics).all():  # not all values are means\n                    means = np.nanmean(self.metrics, axis=0)\n                    assert means.shape == (len(self.metrics_names),)\n                    for name, mean in zip(self.metrics_names, means):\n                        formatted_metrics += ' - {}: {:.3f}'.format(name, mean)\n                \n                formatted_infos = ''\n                if len(self.infos) > 0:\n                    infos = np.array(self.infos)\n                    if not np.isnan(infos).all():  # not all values are means\n                        means = np.nanmean(self.infos, axis=0)\n                        assert means.shape == (len(self.info_names),)\n                        for name, mean in zip(self.info_names, means):\n                            formatted_infos += ' - {}: {:.3f}'.format(name, mean)\n                print('{} episodes - episode_reward: {:.3f} [{:.3f}, {:.3f}]{}{}'.format(len(self.episode_rewards), np.mean(self.episode_rewards), np.min(self.episode_rewards), np.max(self.episode_rewards), formatted_metrics, formatted_infos))\n                print('')\n            self.reset()\n            print('Interval {} ({} steps performed)'.format(self.step // self.interval + 1, self.step))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_step_end(self, step, logs):\n        if self.info_names is None:\n            self.info_names = logs['info'].keys()\n        values = [('reward', logs['reward'])]\n        if KERAS_VERSION > '2.1.3':\n            self.progbar.update((self.step % self.interval) + 1, values=values)\n        else:\n            self.progbar.update((self.step % self.interval) + 1, values=values, force=True)\n        self.step += 1\n        self.metrics.append(logs['metrics'])\n        if len(self.info_names) > 0:\n            self.infos.append([logs['info'][k] for k in self.info_names])", "response": "Update progression bar at the end of each step"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_episode_begin(self, episode, logs):\n        assert episode not in self.metrics\n        assert episode not in self.starts\n        self.metrics[episode] = []\n        self.starts[episode] = timeit.default_timer()", "response": "Initialize metrics at the beginning of each episode"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes and print metrics at the end of each episode", "response": "def on_episode_end(self, episode, logs):\n        \"\"\" Compute and print metrics at the end of each episode \"\"\" \n        duration = timeit.default_timer() - self.starts[episode]\n\n        metrics = self.metrics[episode]\n        if np.isnan(metrics).all():\n            mean_metrics = np.array([np.nan for _ in self.metrics_names])\n        else:\n            mean_metrics = np.nanmean(metrics, axis=0)\n        assert len(mean_metrics) == len(self.metrics_names)\n\n        data = list(zip(self.metrics_names, mean_metrics))\n        data += list(logs.items())\n        data += [('episode', episode), ('duration', duration)]\n        for key, value in data:\n            if key not in self.data:\n                self.data[key] = []\n            self.data[key].append(value)\n\n        if self.interval is not None and episode % self.interval == 0:\n            self.save_data()\n\n        # Clean up.\n        del self.metrics[episode]\n        del self.starts[episode]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_data(self):\n        if len(self.data.keys()) == 0:\n            return\n\n        # Sort everything by episode.\n        assert 'episode' in self.data\n        sorted_indexes = np.argsort(self.data['episode'])\n        sorted_data = {}\n        for key, values in self.data.items():\n            assert len(self.data[key]) == len(sorted_indexes)\n            # We convert to np.array() and then to list to convert from np datatypes to native datatypes.\n            # This is necessary because json.dump cannot handle np.float32, for example.\n            sorted_data[key] = np.array([self.data[key][idx] for idx in sorted_indexes]).tolist()\n\n        # Overwrite already open file. We can simply seek to the beginning since the file will\n        # grow strictly monotonously.\n        with open(self.filepath, 'w') as f:\n            json.dump(sorted_data, f)", "response": "Save metrics in a json file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving weights at interval steps during training", "response": "def on_step_end(self, step, logs={}):\n        \"\"\" Save weights at interval steps during training \"\"\"\n        self.total_steps += 1\n        if self.total_steps % self.interval != 0:\n            # Nothing to do.\n            return\n\n        filepath = self.filepath.format(step=self.total_steps, **logs)\n        if self.verbose > 0:\n            print('Step {}: saving model to {}'.format(self.total_steps, filepath))\n        self.model.save_weights(filepath, overwrite=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sample_batch_indexes(low, high, size):\n    if high - low >= size:\n        # We have enough data. Draw without replacement, that is each index is unique in the\n        # batch. We cannot use `np.random.choice` here because it is horribly inefficient as\n        # the memory grows. See https://github.com/numpy/numpy/issues/2764 for a discussion.\n        # `random.sample` does the same thing (drawing without replacement) and is way faster.\n        try:\n            r = xrange(low, high)\n        except NameError:\n            r = range(low, high)\n        batch_idxs = random.sample(r, size)\n    else:\n        # Not enough data. Help ourselves with sampling from the range, but the same index\n        # can occur multiple times. This is not good and should be avoided by picking a\n        # large enough warm-up phase.\n        warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n        batch_idxs = np.random.random_integers(low, high - 1, size=size)\n    assert len(batch_idxs) == size\n    return batch_idxs", "response": "Return a random batch of size unique elements between low and high."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array of zeros with same shape as given observation", "response": "def zeroed_observation(observation):\n    \"\"\"Return an array of zeros with same shape as given observation\n\n    # Argument\n        observation (list): List of observation\n    \n    # Return\n        A np.ndarray of zeros with observation.shape\n    \"\"\"\n    if hasattr(observation, 'shape'):\n        return np.zeros(observation.shape)\n    elif hasattr(observation, '__iter__'):\n        out = []\n        for x in observation:\n            out.append(zeroed_observation(x))\n        return out\n    else:\n        return 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_recent_state(self, current_observation):\n        # This code is slightly complicated by the fact that subsequent observations might be\n        # from different episodes. We ensure that an experience never spans multiple episodes.\n        # This is probably not that important in practice but it seems cleaner.\n        state = [current_observation]\n        idx = len(self.recent_observations) - 1\n        for offset in range(0, self.window_length - 1):\n            current_idx = idx - offset\n            current_terminal = self.recent_terminals[current_idx - 1] if current_idx - 1 >= 0 else False\n            if current_idx < 0 or (not self.ignore_episode_boundaries and current_terminal):\n                # The previously handled observation was terminal, don't add the current one.\n                # Otherwise we would leak into a different episode.\n                break\n            state.insert(0, self.recent_observations[current_idx])\n        while len(state) < self.window_length:\n            state.insert(0, zeroed_observation(state[0]))\n        return state", "response": "Return the state of the recent episode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample(self, batch_size, batch_idxs=None):\n        # It is not possible to tell whether the first state in the memory is terminal, because it\n        # would require access to the \"terminal\" flag associated to the previous state. As a result\n        # we will never return this first state (only using `self.terminals[0]` to know whether the\n        # second state is terminal).\n        # In addition we need enough entries to fill the desired window length.\n        assert self.nb_entries >= self.window_length + 2, 'not enough entries in the memory'\n\n        if batch_idxs is None:\n            # Draw random indexes such that we have enough entries before each index to fill the\n            # desired window length.\n            batch_idxs = sample_batch_indexes(\n                self.window_length, self.nb_entries - 1, size=batch_size)\n        batch_idxs = np.array(batch_idxs) + 1\n        assert np.min(batch_idxs) >= self.window_length + 1\n        assert np.max(batch_idxs) < self.nb_entries\n        assert len(batch_idxs) == batch_size\n\n        # Create experiences\n        experiences = []\n        for idx in batch_idxs:\n            terminal0 = self.terminals[idx - 2]\n            while terminal0:\n                # Skip this transition because the environment was reset here. Select a new, random\n                # transition and use this instead. This may cause the batch to contain the same\n                # transition twice.\n                idx = sample_batch_indexes(self.window_length + 1, self.nb_entries, size=1)[0]\n                terminal0 = self.terminals[idx - 2]\n            assert self.window_length + 1 <= idx < self.nb_entries\n\n            # This code is slightly complicated by the fact that subsequent observations might be\n            # from different episodes. We ensure that an experience never spans multiple episodes.\n            # This is probably not that important in practice but it seems cleaner.\n            state0 = [self.observations[idx - 1]]\n            for offset in range(0, self.window_length - 1):\n                current_idx = idx - 2 - offset\n                assert current_idx >= 1\n                current_terminal = self.terminals[current_idx - 1]\n                if current_terminal and not self.ignore_episode_boundaries:\n                    # The previously handled observation was terminal, don't add the current one.\n                    # Otherwise we would leak into a different episode.\n                    break\n                state0.insert(0, self.observations[current_idx])\n            while len(state0) < self.window_length:\n                state0.insert(0, zeroed_observation(state0[0]))\n            action = self.actions[idx - 1]\n            reward = self.rewards[idx - 1]\n            terminal1 = self.terminals[idx - 1]\n\n            # Okay, now we need to create the follow-up state. This is state0 shifted on timestep\n            # to the right. Again, we need to be careful to not include an observation from the next\n            # episode if the last state is terminal.\n            state1 = [np.copy(x) for x in state0[1:]]\n            state1.append(self.observations[idx])\n\n            assert len(state0) == self.window_length\n            assert len(state1) == len(state0)\n            experiences.append(Experience(state0=state0, action=action, reward=reward,\n                                          state1=state1, terminal1=terminal1))\n        assert len(experiences) == batch_size\n        return experiences", "response": "Return a randomized batch of experiences from the memory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append(self, observation, action, reward, terminal, training=True):\n        super(SequentialMemory, self).append(observation, action, reward, terminal, training=training)\n        \n        # This needs to be understood as follows: in `observation`, take `action`, obtain `reward`\n        # and weather the next state is `terminal` or not.\n        if training:\n            self.observations.append(observation)\n            self.actions.append(action)\n            self.rewards.append(reward)\n            self.terminals.append(terminal)", "response": "Append an observation to the memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn configurations of SequentialMemory Dict", "response": "def get_config(self):\n        \"\"\"Return configurations of SequentialMemory\n\n        # Returns\n            Dict of config\n        \"\"\"\n        config = super(SequentialMemory, self).get_config()\n        config['limit'] = self.limit\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a randomized batch of params and rewards from the current state of the cluster.", "response": "def sample(self, batch_size, batch_idxs=None):\n        \"\"\"Return a randomized batch of params and rewards\n\n        # Argument\n            batch_size (int): Size of the all batch\n            batch_idxs (int): Indexes to extract\n        # Returns\n            A list of params randomly selected and a list of associated rewards\n        \"\"\"\n        if batch_idxs is None:\n            batch_idxs = sample_batch_indexes(0, self.nb_entries, size=batch_size)\n        assert len(batch_idxs) == batch_size\n\n        batch_params = []\n        batch_total_rewards = []\n        for idx in batch_idxs:\n            batch_params.append(self.params[idx])\n            batch_total_rewards.append(self.total_rewards[idx])\n        return batch_params, batch_total_rewards"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend a reward to the memory", "response": "def append(self, observation, action, reward, terminal, training=True):\n        \"\"\"Append a reward to the memory\n\n        # Argument\n            observation (dict): Observation returned by environment\n            action (int): Action taken to obtain this observation\n            reward (float): Reward obtained by taking this action\n            terminal (boolean): Is the state terminal\n        \"\"\"\n        super(EpisodeParameterMemory, self).append(observation, action, reward, terminal, training=training)\n        if training:\n            self.intermediate_rewards.append(reward)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the current episode sums up rewards and stores the parameters", "response": "def finalize_episode(self, params):\n        \"\"\"Closes the current episode, sums up rewards and stores the parameters\n\n        # Argument\n            params (object): Parameters associated with the episode to be stored and then retrieved back in sample()\n        \"\"\"\n        total_reward = sum(self.intermediate_rewards)\n        self.total_rewards.append(total_reward)\n        self.params.append(params)\n        self.intermediate_rewards = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_gym_env(env_id, num_env=2, seed=123, wrapper_kwargs=None, start_index=0):\n    if wrapper_kwargs is None:\n        wrapper_kwargs = {}\n\n    def make_env(rank): # pylint: disable=C0111\n        def _thunk():\n            env = gym.make(env_id)\n            env.seed(seed + rank)\n            return env\n        return _thunk\n\n    set_global_seeds(seed)\n    return SubprocVecEnv([make_env(i + start_index) for i in range(num_env)])", "response": "Create a wrapped Gym Environments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_or_default_template_file_name(ctx, param, provided_value, include_build):\n\n    search_paths = [\n        \"template.yaml\",\n        \"template.yml\",\n    ]\n\n    if include_build:\n        search_paths.insert(0, os.path.join(\".aws-sam\", \"build\", \"template.yaml\"))\n\n    if provided_value == _TEMPLATE_OPTION_DEFAULT_VALUE:\n        # Default value was used. Value can either be template.yaml or template.yml. Decide based on which file exists\n        # .yml is the default, even if it does not exist.\n        provided_value = \"template.yml\"\n\n        for option in search_paths:\n            if os.path.exists(option):\n                provided_value = option\n                break\n\n    result = os.path.abspath(provided_value)\n    LOG.debug(\"Using SAM Template at %s\", result)\n    return result", "response": "This method returns the user provided file name or default value for the SAM Template file name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef template_click_option(include_build=True):\n    return click.option('--template', '-t',\n                        default=_TEMPLATE_OPTION_DEFAULT_VALUE,\n                        type=click.Path(),\n                        envvar=\"SAM_TEMPLATE_FILE\",\n                        callback=partial(get_or_default_template_file_name, include_build=include_build),\n                        show_default=True,\n                        help=\"AWS SAM template file\")", "response": "Click Option for template option"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n\n        # We care about passing only stderr to the Service and not stdout because stdout from Docker container\n        # contains the response to the API which is sent out as HTTP response. Only stderr needs to be printed\n        # to the console or a log file. stderr from Docker container contains runtime logs and output of print\n        # statements from the Lambda function\n        service = LocalLambdaInvokeService(lambda_runner=self.lambda_runner,\n                                           port=self.port,\n                                           host=self.host,\n                                           stderr=self.stderr_stream)\n\n        service.create()\n\n        LOG.info(\"Starting the Local Lambda Service. You can now invoke your Lambda Functions defined in your template\"\n                 \" through the endpoint.\")\n\n        service.run()", "response": "Starts the Local Lambda Invoke service."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting and returns function information from the given dictionary of SAM and CloudFormation resources. This method supports functions defined with AWS Serverless and AWS Lambda functions.", "response": "def _extract_functions(resources):\n        \"\"\"\n        Extracts and returns function information from the given dictionary of SAM/CloudFormation resources. This\n        method supports functions defined with AWS::Serverless::Function and AWS::Lambda::Function\n\n        :param dict resources: Dictionary of SAM/CloudFormation resources\n        :return dict(string : samcli.commands.local.lib.provider.Function): Dictionary of function LogicalId to the\n            Function configuration object\n        \"\"\"\n\n        result = {}\n\n        for name, resource in resources.items():\n\n            resource_type = resource.get(\"Type\")\n            resource_properties = resource.get(\"Properties\", {})\n\n            if resource_type == SamFunctionProvider._SERVERLESS_FUNCTION:\n                layers = SamFunctionProvider._parse_layer_info(resource_properties.get(\"Layers\", []), resources)\n                result[name] = SamFunctionProvider._convert_sam_function_resource(name, resource_properties, layers)\n\n            elif resource_type == SamFunctionProvider._LAMBDA_FUNCTION:\n                layers = SamFunctionProvider._parse_layer_info(resource_properties.get(\"Layers\", []), resources)\n                result[name] = SamFunctionProvider._convert_lambda_function_resource(name, resource_properties, layers)\n\n            # We don't care about other resource types. Just ignore them\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_sam_function_resource(name, resource_properties, layers):\n\n        codeuri = SamFunctionProvider._extract_sam_function_codeuri(name, resource_properties, \"CodeUri\")\n\n        LOG.debug(\"Found Serverless function with name='%s' and CodeUri='%s'\", name, codeuri)\n\n        return Function(\n            name=name,\n            runtime=resource_properties.get(\"Runtime\"),\n            memory=resource_properties.get(\"MemorySize\"),\n            timeout=resource_properties.get(\"Timeout\"),\n            handler=resource_properties.get(\"Handler\"),\n            codeuri=codeuri,\n            environment=resource_properties.get(\"Environment\"),\n            rolearn=resource_properties.get(\"Role\"),\n            layers=layers\n        )", "response": "Converts a AWS Serverless function resource to a Function configuration usable by the provider."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the SAM Function CodeUri from the Resource Properties and returns it", "response": "def _extract_sam_function_codeuri(name, resource_properties, code_property_key):\n        \"\"\"\n        Extracts the SAM Function CodeUri from the Resource Properties\n\n        Parameters\n        ----------\n        name str\n            LogicalId of the resource\n        resource_properties dict\n            Dictionary representing the Properties of the Resource\n        code_property_key str\n            Property Key of the code on the Resource\n\n        Returns\n        -------\n        str\n            Representing the local code path\n        \"\"\"\n        codeuri = resource_properties.get(code_property_key, SamFunctionProvider._DEFAULT_CODEURI)\n        # CodeUri can be a dictionary of S3 Bucket/Key or a S3 URI, neither of which are supported\n        if isinstance(codeuri, dict) or \\\n                (isinstance(codeuri, six.string_types) and codeuri.startswith(\"s3://\")):\n            codeuri = SamFunctionProvider._DEFAULT_CODEURI\n            LOG.warning(\"Lambda function '%s' has specified S3 location for CodeUri which is unsupported. \"\n                        \"Using default value of '%s' instead\", name, codeuri)\n        return codeuri"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_lambda_function_resource(name, resource_properties, layers):  # pylint: disable=invalid-name\n\n        # CodeUri is set to \".\" in order to get code locally from current directory. AWS::Lambda::Function's ``Code``\n        # property does not support specifying a local path\n        codeuri = SamFunctionProvider._extract_lambda_function_code(resource_properties, \"Code\")\n\n        LOG.debug(\"Found Lambda function with name='%s' and CodeUri='%s'\", name, codeuri)\n\n        return Function(\n            name=name,\n            runtime=resource_properties.get(\"Runtime\"),\n            memory=resource_properties.get(\"MemorySize\"),\n            timeout=resource_properties.get(\"Timeout\"),\n            handler=resource_properties.get(\"Handler\"),\n            codeuri=codeuri,\n            environment=resource_properties.get(\"Environment\"),\n            rolearn=resource_properties.get(\"Role\"),\n            layers=layers\n        )", "response": "Converts a AWS Lambda function resource to a Function configuration usable by the provider."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the Lambda Function Code from the Resource Properties and returns the codeuri", "response": "def _extract_lambda_function_code(resource_properties, code_property_key):\n        \"\"\"\n        Extracts the Lambda Function Code from the Resource Properties\n\n        Parameters\n        ----------\n        resource_properties dict\n            Dictionary representing the Properties of the Resource\n        code_property_key str\n            Property Key of the code on the Resource\n\n        Returns\n        -------\n        str\n            Representing the local code path\n        \"\"\"\n\n        codeuri = resource_properties.get(code_property_key, SamFunctionProvider._DEFAULT_CODEURI)\n\n        if isinstance(codeuri, dict):\n            codeuri = SamFunctionProvider._DEFAULT_CODEURI\n\n        return codeuri"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the list of layers and resources from a template and returns a list of Layer objects that are represented by the resources and the list of layers that are defined within the template and the list of layers that are defined within the template.", "response": "def _parse_layer_info(list_of_layers, resources):\n        \"\"\"\n        Creates a list of Layer objects that are represented by the resources and the list of layers\n\n        Parameters\n        ----------\n        list_of_layers List(str)\n            List of layers that are defined within the Layers Property on a function\n        resources dict\n            The Resources dictionary defined in a template\n\n        Returns\n        -------\n        List(samcli.commands.local.lib.provider.Layer)\n            List of the Layer objects created from the template and layer list defined on the function. The order\n            of the layers does not change.\n\n            I.E: list_of_layers = [\"layer1\", \"layer2\"] the return would be [Layer(\"layer1\"), Layer(\"layer2\")]\n        \"\"\"\n        layers = []\n        for layer in list_of_layers:\n            # If the layer is a string, assume it is the arn\n            if isinstance(layer, six.string_types):\n                layers.append(LayerVersion(layer, None))\n                continue\n\n            # In the list of layers that is defined within a template, you can reference a LayerVersion resource.\n            # When running locally, we need to follow that Ref so we can extract the local path to the layer code.\n            if isinstance(layer, dict) and layer.get(\"Ref\"):\n                layer_logical_id = layer.get(\"Ref\")\n                layer_resource = resources.get(layer_logical_id)\n                if not layer_resource or \\\n                        layer_resource.get(\"Type\", \"\") not in (SamFunctionProvider._SERVERLESS_LAYER,\n                                                               SamFunctionProvider._LAMBDA_LAYER):\n                    raise InvalidLayerReference()\n\n                layer_properties = layer_resource.get(\"Properties\", {})\n                resource_type = layer_resource.get(\"Type\")\n                codeuri = None\n\n                if resource_type == SamFunctionProvider._LAMBDA_LAYER:\n                    codeuri = SamFunctionProvider._extract_lambda_function_code(layer_properties, \"Content\")\n\n                if resource_type == SamFunctionProvider._SERVERLESS_LAYER:\n                    codeuri = SamFunctionProvider._extract_sam_function_codeuri(layer_logical_id,\n                                                                                layer_properties,\n                                                                                \"ContentUri\")\n\n                layers.append(LayerVersion(layer_logical_id, codeuri))\n\n        return layers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve(self):\n\n        # AWS_* variables must always be passed to the function, but user has the choice to override them\n        result = self._get_aws_variables()\n\n        # Default value for the variable gets lowest priority\n        for name, value in self.variables.items():\n\n            # Shell environment values, second priority\n            if name in self.shell_env_values:\n                value = self.shell_env_values[name]\n\n            # Overridden values, highest priority\n            if name in self.override_values:\n                value = self.override_values[name]\n\n            # Any value must be a string when passed to Lambda runtime.\n            # Runtime expects a Map<String, String> for environment variables\n            result[name] = self._stringify_value(value)\n\n        return result", "response": "Resolves the values from different sources and returns a dict of environment variables to use when running the function locally."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the AWS specific environment variables that should be available in Lambda runtime.", "response": "def _get_aws_variables(self):\n        \"\"\"\n        Returns the AWS specific environment variables that should be available in the Lambda runtime.\n        They are prefixed it \"AWS_*\".\n\n        :return dict: Name and value of AWS environment variable\n        \"\"\"\n\n        result = {\n            # Variable that says this function is running in Local Lambda\n            \"AWS_SAM_LOCAL\": \"true\",\n\n            # Function configuration\n            \"AWS_LAMBDA_FUNCTION_MEMORY_SIZE\": str(self.memory),\n            \"AWS_LAMBDA_FUNCTION_TIMEOUT\": str(self.timeout),\n            \"AWS_LAMBDA_FUNCTION_HANDLER\": str(self._function[\"handler\"]),\n\n            # AWS Credentials - Use the input credentials or use the defaults\n            \"AWS_REGION\": self.aws_creds.get(\"region\", self._DEFAULT_AWS_CREDS[\"region\"]),\n\n            \"AWS_DEFAULT_REGION\": self.aws_creds.get(\"region\", self._DEFAULT_AWS_CREDS[\"region\"]),\n\n            \"AWS_ACCESS_KEY_ID\": self.aws_creds.get(\"key\", self._DEFAULT_AWS_CREDS[\"key\"]),\n\n            \"AWS_SECRET_ACCESS_KEY\": self.aws_creds.get(\"secret\", self._DEFAULT_AWS_CREDS[\"secret\"])\n\n            # Additional variables we don't fill in\n            # \"AWS_ACCOUNT_ID=\"\n            # \"AWS_LAMBDA_EVENT_BODY=\",\n            # \"AWS_LAMBDA_FUNCTION_NAME=\",\n            # \"AWS_LAMBDA_FUNCTION_VERSION=\",\n        }\n\n        # Session Token should be added **only** if the input creds have a token and the value is not empty.\n        if self.aws_creds.get(\"sessiontoken\"):\n            result[\"AWS_SESSION_TOKEN\"] = self.aws_creds.get(\"sessiontoken\")\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self):\n\n        if self.is_created():\n            raise RuntimeError(\"This container already exists. Cannot create again.\")\n\n        LOG.info(\"Mounting %s as %s:ro,delegated inside runtime container\", self._host_dir, self._working_dir)\n\n        kwargs = {\n            \"command\": self._cmd,\n            \"working_dir\": self._working_dir,\n            \"volumes\": {\n                self._host_dir: {\n                    # Mount the host directory as \"read only\" directory inside container at working_dir\n                    # https://docs.docker.com/storage/bind-mounts\n                    # Mount the host directory as \"read only\" inside container\n                    \"bind\": self._working_dir,\n                    \"mode\": \"ro,delegated\"\n                }\n            },\n            # We are not running an interactive shell here.\n            \"tty\": False\n        }\n\n        if self._container_opts:\n            kwargs.update(self._container_opts)\n\n        if self._additional_volumes:\n            kwargs[\"volumes\"].update(self._additional_volumes)\n\n        # Make sure all mounts are of posix path style.\n        kwargs[\"volumes\"] = {to_posix_path(host_dir): mount for host_dir, mount in kwargs[\"volumes\"].items()}\n\n        if self._env_vars:\n            kwargs[\"environment\"] = self._env_vars\n\n        if self._exposed_ports:\n            kwargs[\"ports\"] = self._exposed_ports\n\n        if self._entrypoint:\n            kwargs[\"entrypoint\"] = self._entrypoint\n\n        if self._memory_limit_mb:\n            # Ex: 128m => 128MB\n            kwargs[\"mem_limit\"] = \"{}m\".format(self._memory_limit_mb)\n\n        if self.network_id == 'host':\n            kwargs[\"network_mode\"] = self.network_id\n\n        real_container = self.docker_client.containers.create(self._image, **kwargs)\n        self.id = real_container.id\n\n        if self.network_id and self.network_id != 'host':\n            network = self.docker_client.networks.get(self.network_id)\n            network.connect(self.id)\n\n        return self.id", "response": "Creates a new container instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a container from the cluster.", "response": "def delete(self):\n        \"\"\"\n        Removes a container that was created earlier.\n        \"\"\"\n        if not self.is_created():\n            LOG.debug(\"Container was not created. Skipping deletion\")\n            return\n\n        try:\n            self.docker_client.containers\\\n                .get(self.id)\\\n                .remove(force=True)  # Remove a container, even if it is running\n        except docker.errors.NotFound:\n            # Container is already not there\n            LOG.debug(\"Container with ID %s does not exist. Skipping deletion\", self.id)\n        except docker.errors.APIError as ex:\n            msg = str(ex)\n            removal_in_progress = (\"removal of container\" in msg) and (\"is already in progress\" in msg)\n\n            # When removal is already started, Docker API will throw an exception\n            # Skip such exceptions.\n            if not removal_in_progress:\n                raise ex\n\n        self.id = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, input_data=None):\n\n        if input_data:\n            raise ValueError(\"Passing input through container's stdin is not supported\")\n\n        if not self.is_created():\n            raise RuntimeError(\"Container does not exist. Cannot start this container\")\n\n        # Get the underlying container instance from Docker API\n        real_container = self.docker_client.containers.get(self.id)\n\n        # Start the container\n        real_container.start()", "response": "Calls Docker API to start the container. The container must be created at the first place to run.\n        It waits for the container to complete, fetches both stdout and stderr logs and returns through the\n        given streams.\n\n        Parameters\n        ----------\n        input_data\n            Optional. Input data sent to the container through container's stdin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the contents of the output_itr to the appropriate streams for the current container.", "response": "def _write_container_output(output_itr, stdout=None, stderr=None):\n        \"\"\"\n        Based on the data returned from the Container output, via the iterator, write it to the appropriate streams\n\n        Parameters\n        ----------\n        output_itr: Iterator\n            Iterator returned by the Docker Attach command\n        stdout: samcli.lib.utils.stream_writer.StreamWriter, optional\n            Stream writer to write stdout data from Container into\n        stderr: samcli.lib.utils.stream_writer.StreamWriter, optional\n            Stream writer to write stderr data from the Container into\n        \"\"\"\n\n        # Iterator returns a tuple of (frame_type, data) where the frame type determines which stream we write output\n        # to\n        for frame_type, data in output_itr:\n\n            if frame_type == Container._STDOUT_FRAME_TYPE and stdout:\n                # Frame type 1 is stdout data.\n                stdout.write(data)\n\n            elif frame_type == Container._STDERR_FRAME_TYPE and stderr:\n                # Frame type 2 is stderr data.\n                stderr.write(data)\n\n            else:\n                # Either an unsupported frame type or stream for this frame type is not configured\n                LOG.debug(\"Dropping Docker container output because of unconfigured frame type. \"\n                          \"Frame Type: %s. Data: %s\", frame_type, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli(ctx, location, runtime, dependency_manager, output_dir, name, no_input):\n    # All logic must be implemented in the `do_cli` method. This helps ease unit tests\n    do_cli(ctx, location, runtime, dependency_manager, output_dir,\n           name, no_input)", "response": "This command is used to initialize a serverless application with a custom template and a custom dependency manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Swagger document and returns a list of Api objects.", "response": "def get_apis(self):\n        \"\"\"\n        Parses a swagger document and returns a list of APIs configured in the document.\n\n        Swagger documents have the following structure\n        {\n            \"/path1\": {    # path\n                \"get\": {   # method\n                    \"x-amazon-apigateway-integration\": {   # integration\n                        \"type\": \"aws_proxy\",\n\n                        # URI contains the Lambda function ARN that needs to be parsed to get Function Name\n                        \"uri\": {\n                            \"Fn::Sub\":\n                                \"arn:aws:apigateway:aws:lambda:path/2015-03-31/functions/${LambdaFunction.Arn}/...\"\n                        }\n                    }\n                },\n                \"post\": {\n                },\n            },\n            \"/path2\": {\n                ...\n            }\n        }\n\n        Returns\n        -------\n        list of samcli.commands.local.lib.provider.Api\n            List of APIs that are configured in the Swagger document\n        \"\"\"\n\n        result = []\n        paths_dict = self.swagger.get(\"paths\", {})\n\n        binary_media_types = self.get_binary_media_types()\n\n        for full_path, path_config in paths_dict.items():\n            for method, method_config in path_config.items():\n\n                function_name = self._get_integration_function_name(method_config)\n                if not function_name:\n                    LOG.debug(\"Lambda function integration not found in Swagger document at path='%s' method='%s'\",\n                              full_path, method)\n                    continue\n\n                if method.lower() == self._ANY_METHOD_EXTENSION_KEY:\n                    # Convert to a more commonly used method notation\n                    method = self._ANY_METHOD\n\n                api = Api(path=full_path, method=method, function_name=function_name, cors=None,\n                          binary_media_types=binary_media_types)\n                result.append(api)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_integration_function_name(self, method_config):\n        if not isinstance(method_config, dict) or self._INTEGRATION_KEY not in method_config:\n            return None\n\n        integration = method_config[self._INTEGRATION_KEY]\n\n        if integration \\\n                and isinstance(integration, dict) \\\n                and integration.get(\"type\") == IntegrationType.aws_proxy.value:\n            # Integration must be \"aws_proxy\" otherwise we don't care about it\n            return LambdaUri.get_function_name(integration.get(\"uri\"))", "response": "Tries to parse the Lambda Function name from the Integration defined in the method configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_cli(ctx, host, port, template, env_vars, debug_port, debug_args,  # pylint: disable=R0914\n           debugger_path, docker_volume_basedir, docker_network, log_file, layer_cache_basedir, skip_pull_image,\n           force_image_build, parameter_overrides):\n    \"\"\"\n    Implementation of the ``cli`` method, just separated out for unit testing purposes\n    \"\"\"\n\n    LOG.debug(\"local start_lambda command is called\")\n\n    # Pass all inputs to setup necessary context to invoke function locally.\n    # Handler exception raised by the processor for invalid args and print errors\n\n    try:\n        with InvokeContext(template_file=template,\n                           function_identifier=None,  # Don't scope to one particular function\n                           env_vars_file=env_vars,\n                           docker_volume_basedir=docker_volume_basedir,\n                           docker_network=docker_network,\n                           log_file=log_file,\n                           skip_pull_image=skip_pull_image,\n                           debug_port=debug_port,\n                           debug_args=debug_args,\n                           debugger_path=debugger_path,\n                           parameter_overrides=parameter_overrides,\n                           layer_cache_basedir=layer_cache_basedir,\n                           force_image_build=force_image_build,\n                           aws_region=ctx.region) as invoke_context:\n\n            service = LocalLambdaService(lambda_invoke_context=invoke_context,\n                                         port=port,\n                                         host=host)\n            service.start()\n\n    except (InvalidSamDocumentException,\n            OverridesNotWellDefinedError,\n            InvalidLayerReference,\n            DebuggingNotSupported) as ex:\n        raise UserException(str(ex))", "response": "This function is used to start a local lambda service."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the given CloudWatch Logs Event dictionary as necessary and returns an iterable that will be formatted as a string.", "response": "def do_format(self, event_iterable):\n        \"\"\"\n        Formats the given CloudWatch Logs Event dictionary as necessary and returns an iterable that will\n        return the formatted string. This can be used to parse and format the events based on context\n        ie. In Lambda Function logs, a formatter may wish to color the \"ERROR\" keywords red,\n        or highlight a filter keyword separately etc.\n\n        This method takes an iterable as input and returns an iterable. It does not immediately format the event.\n        Instead, it sets up the formatter chain appropriately and returns the iterable. Actual formatting happens\n        only when the iterable is used by the caller.\n\n        Parameters\n        ----------\n        event_iterable : iterable of samcli.lib.logs.event.LogEvent\n            Iterable that returns an object containing information about each log event.\n\n        Returns\n        -------\n        iterable of string\n            Iterable that returns a formatted event as a string.\n        \"\"\"\n\n        for operation in self.formatter_chain:\n\n            # Make sure the operation has access to certain basic objects like colored\n            partial_op = functools.partial(operation, colored=self.colored)\n            event_iterable = imap(partial_op, event_iterable)\n\n        return event_iterable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pretty_print_event(event, colored):\n        event.timestamp = colored.yellow(event.timestamp)\n        event.log_stream_name = colored.cyan(event.log_stream_name)\n\n        return ' '.join([event.log_stream_name, event.timestamp, event.message])", "response": "Pretty print an event object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhighlight commonly known Lambda error cases in red", "response": "def colorize_errors(event, colored):\n        \"\"\"\n        Highlights some commonly known Lambda error cases in red:\n            - Nodejs process crashes\n            - Lambda function timeouts\n        \"\"\"\n\n        nodejs_crash_msg = \"Process exited before completing request\"\n        timeout_msg = \"Task timed out\"\n\n        if nodejs_crash_msg in event.message \\\n                or timeout_msg in event.message:\n            event.message = colored.red(event.message)\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhighlighting the keywords in the log statement by drawing an underline", "response": "def highlight_keywords(self, event, colored):\n        \"\"\"\n        Highlight the keyword in the log statement by drawing an underline\n        \"\"\"\n        if self.keyword:\n            highlight = colored.underline(self.keyword)\n            event.message = event.message.replace(self.keyword, highlight)\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat the event message in JSON format.", "response": "def format_json(event, colored):\n        \"\"\"\n        If the event message is a JSON string, then pretty print the JSON with 2 indents and sort the keys. This makes\n        it very easy to visually parse and search JSON data\n        \"\"\"\n\n        try:\n            if event.message.startswith(\"{\"):\n                msg_dict = json.loads(event.message)\n                event.message = json.dumps(msg_dict, indent=2)\n        except Exception:\n            # Skip if the event message was not JSON\n            pass\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the template file parse it as JSON and return the template as a dictionary.", "response": "def get_template_data(template_file):\n    \"\"\"\n    Read the template file, parse it as JSON/YAML and return the template as a dictionary.\n\n    Parameters\n    ----------\n    template_file : string\n        Path to the template to read\n\n    Returns\n    -------\n    Template data as a dictionary\n    \"\"\"\n\n    if not pathlib.Path(template_file).exists():\n        raise ValueError(\"Template file not found at {}\".format(template_file))\n\n    with open(template_file, 'r') as fp:\n        try:\n            return yaml_parse(fp.read())\n        except (ValueError, yaml.YAMLError) as ex:\n            raise ValueError(\"Failed to parse template: {}\".format(str(ex)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_template(src_template_path,\n                  dest_template_path,\n                  template_dict):\n    \"\"\"\n    Move the SAM/CloudFormation template from ``src_template_path`` to ``dest_template_path``. For convenience, this\n    method accepts a dictionary of template data ``template_dict`` that will be written to the destination instead of\n    reading from the source file.\n\n    SAM/CloudFormation template can contain certain properties whose value is a relative path to a local file/folder.\n    This path is always relative to the template's location. Before writing the template to ``dest_template_path`,\n    we will update these paths to be relative to the new location.\n\n    This methods updates resource properties supported by ``aws cloudformation package`` command:\n    https://docs.aws.amazon.com/cli/latest/reference/cloudformation/package.html\n\n    You must use this method if you are reading a template from one location, modifying it, and writing it back to a\n    different location.\n\n    Parameters\n    ----------\n    src_template_path : str\n        Path to the original location of the template\n\n    dest_template_path : str\n        Path to the destination location where updated template should be written to\n\n    template_dict : dict\n        Dictionary containing template contents. This dictionary will be updated & written to ``dest`` location.\n    \"\"\"\n\n    original_root = os.path.dirname(src_template_path)\n    new_root = os.path.dirname(dest_template_path)\n\n    # Next up, we will be writing the template to a different location. Before doing so, we should\n    # update any relative paths in the template to be relative to the new location.\n    modified_template = _update_relative_paths(template_dict,\n                                               original_root,\n                                               new_root)\n\n    with open(dest_template_path, \"w\") as fp:\n        fp.write(yaml_dump(modified_template))", "response": "Move the SAM template from one location to another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate relative paths in AWS include directive.", "response": "def _update_aws_include_relative_path(template_dict, original_root, new_root):\n    \"\"\"\n    Update relative paths in \"AWS::Include\" directive. This directive can be present at any part of the template,\n    and not just within resources.\n    \"\"\"\n\n    for key, val in template_dict.items():\n        if key == \"Fn::Transform\":\n            if isinstance(val, dict) and val.get(\"Name\") == \"AWS::Include\":\n                path = val.get(\"Parameters\", {}).get(\"Location\", {})\n                updated_path = _resolve_relative_to(path, original_root, new_root)\n                if not updated_path:\n                    # This path does not need to get updated\n                    continue\n\n                val[\"Parameters\"][\"Location\"] = updated_path\n\n        # Recurse through all dictionary values\n        elif isinstance(val, dict):\n            _update_aws_include_relative_path(val, original_root, new_root)\n        elif isinstance(val, list):\n            for item in val:\n                if isinstance(item, dict):\n                    _update_aws_include_relative_path(item, original_root, new_root)\n\n    return template_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _resolve_relative_to(path, original_root, new_root):\n\n    if not isinstance(path, six.string_types) \\\n            or path.startswith(\"s3://\") \\\n            or os.path.isabs(path):\n        # Value is definitely NOT a relative path. It is either a S3 URi or Absolute path or not a string at all\n        return None\n\n    # Value is definitely a relative path. Change it relative to the destination directory\n    return os.path.relpath(\n        os.path.normpath(os.path.join(original_root, path)),  # Absolute original path w.r.t ``original_root``\n        new_root)", "response": "Resolves the given path relative to the given original_root and new_root."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse AWS :: Include transform data and return the location of the included file.", "response": "def parse_aws_include_transform(data):\n    \"\"\"\n    If the input data is an AWS::Include data, then parse and return the location of the included file.\n\n    AWS::Include transform data usually has the following format:\n    {\n        \"Fn::Transform\": {\n            \"Name\": \"AWS::Include\",\n            \"Parameters\": {\n                \"Location\": \"s3://MyAmazonS3BucketName/swagger.yaml\"\n            }\n        }\n    }\n\n    Parameters\n    ----------\n    data : dict\n        Dictionary data to parse\n\n    Returns\n    -------\n    str\n        Location of the included file, if available. None, otherwise\n    \"\"\"\n\n    if not data:\n        return\n\n    if _FN_TRANSFORM not in data:\n        return\n\n    transform_data = data[_FN_TRANSFORM]\n\n    name = transform_data.get(\"Name\")\n    location = transform_data.get(\"Parameters\", {}).get(\"Location\")\n    if name == \"AWS::Include\":\n        LOG.debug(\"Successfully parsed location from AWS::Include transform: %s\", location)\n        return location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the Swagger document from either the given locations or downloads it from the given URI.", "response": "def read(self):\n        \"\"\"\n        Gets the Swagger document from either of the given locations. If we fail to retrieve or parse the Swagger\n        file, this method will return None.\n\n        Returns\n        -------\n        dict:\n            Swagger document. None, if we cannot retrieve the document\n        \"\"\"\n\n        swagger = None\n\n        # First check if there is inline swagger\n        if self.definition_body:\n            swagger = self._read_from_definition_body()\n\n        if not swagger and self.definition_uri:\n            # If not, then try to download it from the given URI\n            swagger = self._download_swagger(self.definition_uri)\n\n        return swagger"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_from_definition_body(self):\n\n        # Let's try to parse it as AWS::Include Transform first. If not, then fall back to assuming the Swagger document\n        # was inclined directly into the body\n        location = parse_aws_include_transform(self.definition_body)\n        if location:\n            LOG.debug(\"Trying to download Swagger from %s\", location)\n            return self._download_swagger(location)\n\n        # Inline Swagger, just return the contents which should already be a dictionary\n        LOG.debug(\"Detected Inline Swagger definition\")\n        return self.definition_body", "response": "Read the Swagger document from the DefinitionBody."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads the file from given location and return it as a dict.", "response": "def _download_swagger(self, location):\n        \"\"\"\n        Download the file from given local or remote location and return it\n\n        Parameters\n        ----------\n        location : str or dict\n            Local path or S3 path to Swagger file to download. Consult the ``__init__.py`` documentation for specifics\n            on structure of this property.\n\n        Returns\n        -------\n        dict or None\n            Downloaded and parsed Swagger document. None, if unable to download\n        \"\"\"\n\n        if not location:\n            return\n\n        bucket, key, version = self._parse_s3_location(location)\n        if bucket and key:\n            LOG.debug(\"Downloading Swagger document from Bucket=%s, Key=%s, Version=%s\", bucket, key, version)\n            swagger_str = self._download_from_s3(bucket, key, version)\n            return yaml_parse(swagger_str)\n\n        if not isinstance(location, string_types):\n            # This is not a string and not a S3 Location dictionary. Probably something invalid\n            LOG.debug(\"Unable to download Swagger file. Invalid location: %s\", location)\n            return\n\n        # ``location`` is a string and not a S3 path. It is probably a local path. Let's resolve relative path if any\n        filepath = location\n        if self.working_dir:\n            # Resolve relative paths, if any, with respect to working directory\n            filepath = os.path.join(self.working_dir, location)\n\n        if not os.path.exists(filepath):\n            LOG.debug(\"Unable to download Swagger file. File not found at location %s\", filepath)\n            return\n\n        LOG.debug(\"Reading Swagger document from local file at %s\", filepath)\n        with open(filepath, \"r\") as fp:\n            return yaml_parse(fp.read())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _download_from_s3(bucket, key, version=None):\n\n        s3 = boto3.client('s3')\n\n        extra_args = {}\n        if version:\n            extra_args[\"VersionId\"] = version\n\n        with tempfile.TemporaryFile() as fp:\n            try:\n                s3.download_fileobj(\n                    bucket, key, fp,\n                    ExtraArgs=extra_args)\n\n                # go to start of file\n                fp.seek(0)\n\n                # Read and return all the contents\n                return fp.read()\n\n            except botocore.exceptions.ClientError:\n                LOG.error(\"Unable to download Swagger document from S3 Bucket=%s Key=%s Version=%s\",\n                          bucket, key, version)\n                raise", "response": "Download a file from S3 location if available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the given location and returns the bucket key and version as separate values.", "response": "def _parse_s3_location(location):\n        \"\"\"\n        Parses the given location input as a S3 Location and returns the file's bucket, key and version as separate\n        values. Input can be in two different formats:\n\n        1. Dictionary with ``Bucket``, ``Key``, ``Version`` keys\n        2. String of S3 URI in format ``s3://<bucket>/<key>?versionId=<version>``\n\n        If the input is not in either of the above formats, this method will return (None, None, None) tuple for all\n        the values.\n\n        Parameters\n        ----------\n        location : str or dict\n            Location of the S3 file\n\n        Returns\n        -------\n        str\n            Name of the S3 Bucket. None, if bucket value was not found\n        str\n            Key of the file from S3. None, if key was not provided\n        str\n            Optional Version ID of the file. None, if version ID is not provided\n        \"\"\"\n\n        bucket, key, version = None, None, None\n        if isinstance(location, dict):\n            # This is a S3 Location dictionary. Just grab the fields. It is very well possible that\n            # this dictionary has none of the fields we expect. Return None if the fields don't exist.\n            bucket, key, version = (\n                location.get(\"Bucket\"),\n                location.get(\"Key\"),\n                location.get(\"Version\")\n            )\n\n        elif isinstance(location, string_types) and location.startswith(\"s3://\"):\n            # This is a S3 URI. Parse it using a standard URI parser to extract the components\n\n            parsed = urlparse(location)\n            query = parse_qs(parsed.query)\n\n            bucket = parsed.netloc\n            key = parsed.path.lstrip('/')  # Leading '/' messes with S3 APIs. Remove it.\n\n            # If there is a query string that has a single versionId field,\n            # set the object version and return\n            if query and 'versionId' in query and len(query['versionId']) == 1:\n                version = query['versionId'][0]\n\n        return bucket, key, version"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef debug(self, value):\n        self._debug = value\n\n        if self._debug:\n            # Turn on debug logging\n            logging.getLogger().setLevel(logging.DEBUG)", "response": "Turn on debug logging if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the default session based on the current context.", "response": "def _refresh_session(self):\n        \"\"\"\n        Update boto3's default session by creating a new session based on values set in the context. Some properties of\n        the Boto3's session object are read-only. Therefore when Click parses new AWS session related properties (like\n        region & profile), it will call this method to create a new session with latest values for these properties.\n        \"\"\"\n        boto3.setup_default_session(region_name=self._aws_region,\n                                    profile_name=self._aws_profile)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_project(\n        location=None, runtime=\"nodejs\", dependency_manager=None,\n        output_dir=\".\", name='sam-sample-app', no_input=False):\n    \"\"\"Generates project using cookiecutter and options given\n\n    Generate project scaffolds a project using default templates if user\n    doesn't provide one via location parameter. Default templates are\n    automatically chosen depending on runtime given by the user.\n\n    Parameters\n    ----------\n    location: Path, optional\n        Git, HTTP, Local path or Zip containing cookiecutter template\n        (the default is None, which means no custom template)\n    runtime: str, optional\n        Lambda Runtime (the default is \"nodejs\", which creates a nodejs project)\n    dependency_manager: str, optional\n        Dependency Manager for the Lambda Runtime Project(the default is \"npm\" for a \"nodejs\" Lambda runtime)\n    output_dir: str, optional\n        Output directory where project should be generated\n        (the default is \".\", which implies current folder)\n    name: str, optional\n        Name of the project\n        (the default is \"sam-sample-app\", which implies a project named sam-sample-app will be created)\n    no_input : bool, optional\n        Whether to prompt for input or to accept default values\n        (the default is False, which prompts the user for values it doesn't know for baking)\n\n    Raises\n    ------\n    GenerateProjectFailedError\n        If the process of baking a project fails\n    \"\"\"\n\n    template = None\n\n    for mapping in list(itertools.chain(*(RUNTIME_DEP_TEMPLATE_MAPPING.values()))):\n        if runtime in mapping['runtimes'] or any([r.startswith(runtime) for r in mapping['runtimes']]):\n            if not dependency_manager:\n                template = mapping['init_location']\n                break\n            elif dependency_manager == mapping['dependency_manager']:\n                template = mapping['init_location']\n\n    if not template:\n        msg = \"Lambda Runtime {} does not support dependency manager: {}\".format(runtime, dependency_manager)\n        raise GenerateProjectFailedError(project=name, provider_error=msg)\n\n    params = {\n        \"template\": location if location else template,\n        \"output_dir\": output_dir,\n        \"no_input\": no_input\n    }\n\n    LOG.debug(\"Parameters dict created with input given\")\n    LOG.debug(\"%s\", params)\n\n    if not location and name is not None:\n        params['extra_context'] = {'project_name': name, 'runtime': runtime}\n        params['no_input'] = True\n        LOG.debug(\"Parameters dict updated with project name as extra_context\")\n        LOG.debug(\"%s\", params)\n\n    try:\n        LOG.debug(\"Baking a new template with cookiecutter with all parameters\")\n        cookiecutter(**params)\n    except CookiecutterException as e:\n        raise GenerateProjectFailedError(project=name, provider_error=e)", "response": "Generates a project from a cookiecutter template and optional options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_utc(some_time):\n\n    # Convert timezone aware objects to UTC\n    if some_time.tzinfo and some_time.utcoffset():\n        some_time = some_time.astimezone(tzutc())\n\n    # Now that time is UTC, simply remove the timezone component.\n    return some_time.replace(tzinfo=None)", "response": "Convert the given date to UTC"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a date string into a datetime object.", "response": "def parse_date(date_string):\n    \"\"\"\n    Parse the given string as datetime object. This parser supports in almost any string formats.\n\n    For relative times, like `10min ago`, this parser computes the actual time relative to current UTC time. This\n    allows time to always be in UTC if an explicit time zone is not provided.\n\n    Parameters\n    ----------\n    date_string : str\n        String representing the date\n\n    Returns\n    -------\n    datetime.datetime\n        Parsed datetime object. None, if the string cannot be parsed.\n    \"\"\"\n\n    parser_settings = {\n        # Relative times like '10m ago' must subtract from the current UTC time. Without this setting, dateparser\n        # will use current local time as the base for subtraction, but falsely assume it is a UTC time. Therefore\n        # the time that dateparser returns will be a `datetime` object that did not have any timezone information.\n        # So be explicit to set the time to UTC.\n        \"RELATIVE_BASE\": datetime.datetime.utcnow()\n    }\n\n    return dateparser.parse(date_string, settings=parser_settings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef function_name(self):\n        if self._function_identifier:\n            return self._function_identifier\n\n        # Function Identifier is *not* provided. If there is only one function in the template,\n        # default to it.\n\n        all_functions = [f for f in self._function_provider.get_all()]\n        if len(all_functions) == 1:\n            return all_functions[0].name\n\n        # Get all the available function names to print helpful exception message\n        all_function_names = [f.name for f in all_functions]\n\n        # There are more functions in the template, and function identifier is not provided, hence raise.\n        raise InvokeContextException(\"You must provide a function identifier (function's Logical ID in the template). \"\n                                     \"Possible options in your template: {}\".format(all_function_names))", "response": "Returns the name of the function in the template."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an instance of the local Lambda runner capable of running Lambda functions locally", "response": "def local_lambda_runner(self):\n        \"\"\"\n        Returns an instance of the runner capable of running Lambda functions locally\n\n        :return samcli.commands.local.lib.local_lambda.LocalLambdaRunner: Runner configured to run Lambda functions\n            locally\n        \"\"\"\n\n        layer_downloader = LayerDownloader(self._layer_cache_basedir, self.get_cwd())\n        image_builder = LambdaImage(layer_downloader,\n                                    self._skip_pull_image,\n                                    self._force_image_build)\n\n        lambda_runtime = LambdaRuntime(self._container_manager, image_builder)\n        return LocalLambdaRunner(local_runtime=lambda_runtime,\n                                 function_provider=self._function_provider,\n                                 cwd=self.get_cwd(),\n                                 env_vars_values=self._env_vars_value,\n                                 debug_context=self._debug_context)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stdout(self):\n        stream = self._log_file_handle if self._log_file_handle else osutils.stdout()\n        return StreamWriter(stream, self._is_debugging)", "response": "Returns a stream writer for stdout to output Lambda function logs toUniversalLog"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stderr(self):\n        stream = self._log_file_handle if self._log_file_handle else osutils.stderr()\n        return StreamWriter(stream, self._is_debugging)", "response": "Returns a stream writer for stderr to output Lambda function errors to the Lambda function errors to the Lambda function errors to"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the working directory for the Docker image.", "response": "def get_cwd(self):\n        \"\"\"\n        Get the working directory. This is usually relative to the directory that contains the template. If a Docker\n        volume location is specified, it takes preference\n\n        All Lambda function code paths are resolved relative to this working directory\n\n        :return string: Working directory\n        \"\"\"\n\n        cwd = os.path.dirname(os.path.abspath(self._template_file))\n        if self._docker_volume_basedir:\n            cwd = self._docker_volume_basedir\n\n        return cwd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the file containing values of environment variables and returns the value of that environment variable.", "response": "def _get_env_vars_value(filename):\n        \"\"\"\n        If the user provided a file containing values of environment variables, this method will read the file and\n        return its value\n\n        :param string filename: Path to file containing environment variable values\n        :return dict: Value of environment variables, if provided. None otherwise\n        :raises InvokeContextException: If the file was not found or not a valid JSON\n        \"\"\"\n        if not filename:\n            return None\n\n        # Try to read the file and parse it as JSON\n        try:\n\n            with open(filename, 'r') as fp:\n                return json.load(fp)\n\n        except Exception as ex:\n            raise InvokeContextException(\"Could not read environment variables overrides from file {}: {}\".format(\n                                         filename,\n                                         str(ex)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a DebugContext object if the InvokeContext is in debugging mode.", "response": "def _get_debug_context(debug_port, debug_args, debugger_path):\n        \"\"\"\n        Creates a DebugContext if the InvokeContext is in a debugging mode\n\n        Parameters\n        ----------\n        debug_port int\n             Port to bind the debugger to\n        debug_args str\n            Additional arguments passed to the debugger\n        debugger_path str\n            Path to the directory of the debugger to mount on Docker\n\n        Returns\n        -------\n        samcli.commands.local.lib.debug_context.DebugContext\n            Object representing the DebugContext\n\n        Raises\n        ------\n        samcli.commands.local.cli_common.user_exceptions.DebugContext\n            When the debugger_path is not valid\n        \"\"\"\n        if debug_port and debugger_path:\n            try:\n                debugger = Path(debugger_path).resolve(strict=True)\n            except OSError as error:\n                if error.errno == errno.ENOENT:\n                    raise DebugContextException(\"'{}' could not be found.\".format(debugger_path))\n                else:\n                    raise error\n\n            # We turn off pylint here due to https://github.com/PyCQA/pylint/issues/1660\n            if not debugger.is_dir():  # pylint: disable=no-member\n                raise DebugContextException(\"'{}' should be a directory with the debugger in it.\".format(debugger_path))\n            debugger_path = str(debugger)\n\n        return DebugContext(debug_port=debug_port, debug_args=debug_args, debugger_path=debugger_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a socket and yields the appropriate types and data.", "response": "def _read_socket(socket):\n    \"\"\"\n    The stdout and stderr data from the container multiplexed into one stream of response from the Docker API.\n    It follows the protocol described here https://docs.docker.com/engine/api/v1.30/#operation/ContainerAttach.\n    The stream starts with a 8 byte header that contains the frame type and also payload size. Follwing that is the\n    actual payload of given size. Once you read off this payload, we are ready to read the next header.\n\n    This method will follow this protocol to read payload from the stream and return an iterator that returns\n    a tuple containing the frame type and frame data. Callers can handle the data appropriately based on the frame\n    type.\n\n        Stdout => Frame Type = 1\n        Stderr => Frame Type = 2\n\n\n    Parameters\n    ----------\n    socket\n        Socket to read responses from\n\n    Yields\n    -------\n    int\n        Type of the stream (1 => stdout, 2 => stderr)\n    str\n        Data in the stream\n    \"\"\"\n\n    # Keep reading the stream until the stream terminates\n    while True:\n\n        try:\n\n            payload_type, payload_size = _read_header(socket)\n            if payload_size < 0:\n                # Something is wrong with the data stream. Payload size can't be less than zero\n                break\n\n            for data in _read_payload(socket, payload_size):\n                yield payload_type, data\n\n        except timeout:\n            # Timeouts are normal during debug sessions and long running tasks\n            LOG.debug(\"Ignoring docker socket timeout\")\n\n        except SocketError:\n            # There isn't enough data in the stream. Probably the socket terminated\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_payload(socket, payload_size):\n\n    remaining = payload_size\n    while remaining > 0:\n\n        # Try and read as much as possible\n        data = read(socket, remaining)\n        if data is None:\n            # ``read`` will terminate with an empty string. This is just a transient state where we didn't get any data\n            continue\n\n        if len(data) == 0:  # pylint: disable=C1801\n            # Empty string. Socket does not have any more data. We are done here even if we haven't read full payload\n            break\n\n        remaining -= len(data)\n        yield data", "response": "Reads and yields the given size from the given socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef debug_option(f):\n    def callback(ctx, param, value):\n        state = ctx.ensure_object(Context)\n        state.debug = value\n        return value\n\n    return click.option('--debug',\n                        expose_value=False,\n                        is_flag=True,\n                        envvar=\"SAM_DEBUG\",\n                        help='Turn on debug logging to print debug message generated by SAM CLI.',\n                        callback=callback)(f)", "response": "Configures the debug option for CLI\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef region_option(f):\n    def callback(ctx, param, value):\n        state = ctx.ensure_object(Context)\n        state.region = value\n        return value\n\n    return click.option('--region',\n                        expose_value=False,\n                        help='Set the AWS Region of the service (e.g. us-east-1).',\n                        callback=callback)(f)", "response": "Configures the -- region option for CLI\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef profile_option(f):\n    def callback(ctx, param, value):\n        state = ctx.ensure_object(Context)\n        state.profile = value\n        return value\n\n    return click.option('--profile',\n                        expose_value=False,\n                        help='Select a specific profile from your credential file to get AWS credentials.',\n                        callback=callback)(f)", "response": "Configures the -- profile option for CLI\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Lambda Service ResourceNotFound Response object representing the Lambda Service ResourceNotFound exception", "response": "def resource_not_found(function_name):\n        \"\"\"\n        Creates a Lambda Service ResourceNotFound Response\n\n        Parameters\n        ----------\n        function_name str\n            Name of the function that was requested to invoke\n\n        Returns\n        -------\n        Flask.Response\n            A response object representing the ResourceNotFound Error\n        \"\"\"\n        exception_tuple = LambdaErrorResponses.ResourceNotFoundException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(\n                LambdaErrorResponses.USER_ERROR,\n                \"Function not found: arn:aws:lambda:us-west-2:012345678901:function:{}\".format(function_name)\n            ),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Lambda Service InvalidRequestContent Response object representing the InvalidRequestContent exception.", "response": "def invalid_request_content(message):\n        \"\"\"\n        Creates a Lambda Service InvalidRequestContent Response\n\n        Parameters\n        ----------\n        message str\n            Message to be added to the body of the response\n\n        Returns\n        -------\n        Flask.Response\n            A response object representing the InvalidRequestContent Error\n        \"\"\"\n        exception_tuple = LambdaErrorResponses.InvalidRequestContentException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(LambdaErrorResponses.USER_ERROR, message),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unsupported_media_type(content_type):\n        exception_tuple = LambdaErrorResponses.UnsupportedMediaTypeException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(LambdaErrorResponses.USER_ERROR,\n                                                                \"Unsupported content type: {}\".format(content_type)),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )", "response": "Creates a Lambda Service UnsupportedMediaType Response object representing the UnsupportedMediaType exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Lambda Service Generic ServiceException Response containing the exception message and a set of attributes that are not set.", "response": "def generic_service_exception(*args):\n        \"\"\"\n        Creates a Lambda Service Generic ServiceException Response\n\n        Parameters\n        ----------\n        args list\n            List of arguments Flask passes to the method\n\n        Returns\n        -------\n        Flask.Response\n            A response object representing the GenericServiceException Error\n        \"\"\"\n        exception_tuple = LambdaErrorResponses.ServiceException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(LambdaErrorResponses.SERVICE_ERROR, \"ServiceException\"),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generic_path_not_found(*args):\n        exception_tuple = LambdaErrorResponses.PathNotFoundException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(\n                LambdaErrorResponses.LOCAL_SERVICE_ERROR, \"PathNotFoundException\"),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )", "response": "Creates a Lambda Service Generic PathNotFound Response object representing the PathNotFound exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a Lambda Service Generic MethodNotAllowed Response", "response": "def generic_method_not_allowed(*args):\n        \"\"\"\n        Creates a Lambda Service Generic MethodNotAllowed Response\n\n        Parameters\n        ----------\n        args list\n            List of arguments Flask passes to the method\n\n        Returns\n        -------\n        Flask.Response\n            A response object representing the GenericMethodNotAllowed Error\n        \"\"\"\n        exception_tuple = LambdaErrorResponses.MethodNotAllowedException\n\n        return BaseLocalService.service_response(\n            LambdaErrorResponses._construct_error_response_body(LambdaErrorResponses.LOCAL_SERVICE_ERROR,\n                                                                \"MethodNotAllowedException\"),\n            LambdaErrorResponses._construct_headers(exception_tuple[0]),\n            exception_tuple[1]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the SAM template file provided and returns the dictionary representation of the file.", "response": "def _read_sam_file(template):\n    \"\"\"\n    Reads the file (json and yaml supported) provided and returns the dictionary representation of the file.\n\n    :param str template: Path to the template file\n    :return dict: Dictionary representing the SAM Template\n    :raises: SamTemplateNotFoundException when the template file does not exist\n    \"\"\"\n    if not os.path.exists(template):\n        click.secho(\"SAM Template Not Found\", bg='red')\n        raise SamTemplateNotFoundException(\"Template at {} is not found\".format(template))\n\n    with click.open_file(template, 'r') as sam_template:\n        sam_template = yaml_parse(sam_template.read())\n\n    return sam_template"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_code_path(cwd, codeuri):\n    LOG.debug(\"Resolving code path. Cwd=%s, CodeUri=%s\", cwd, codeuri)\n\n    # First, let us figure out the current working directory.\n    # If current working directory is not provided, then default to the directory where the CLI is running from\n    if not cwd or cwd == PRESENT_DIR:\n        cwd = os.getcwd()\n\n    # Make sure cwd is an absolute path\n    cwd = os.path.abspath(cwd)\n\n    # Next, let us get absolute path of function code.\n    # Codepath is always relative to current working directory\n    # If the path is relative, then construct the absolute version\n    if not os.path.isabs(codeuri):\n        codeuri = os.path.normpath(os.path.join(cwd, codeuri))\n\n    return codeuri", "response": "Resolves the path to the function code based on the current working directory and codeuri."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_path_to_flask(path):\n        proxy_sub_path = APIGW_TO_FLASK_REGEX.sub(FLASK_CAPTURE_ALL_PATH, path)\n\n        # Replace the '{' and '}' with '<' and '>' respectively\n        return proxy_sub_path.replace(LEFT_BRACKET, LEFT_ANGLE_BRACKET).replace(RIGHT_BRACKET, RIGHT_ANGLE_BRACKET)", "response": "Converts a Path from an Api Gateway defined path to a Flask defined path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_path_to_api_gateway(path):\n        proxy_sub_path = FLASK_TO_APIGW_REGEX.sub(PROXY_PATH_PARAMS, path)\n\n        # Replace the '<' and '>' with '{' and '}' respectively\n        return proxy_sub_path.replace(LEFT_ANGLE_BRACKET, LEFT_BRACKET).replace(RIGHT_ANGLE_BRACKET, RIGHT_BRACKET)", "response": "Converts a Path from a Flask defined path to an Api Gateway defined path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_function_name(integration_uri):\n\n        arn = LambdaUri._get_function_arn(integration_uri)\n\n        LOG.debug(\"Extracted Function ARN: %s\", arn)\n\n        return LambdaUri._get_function_name_from_arn(arn)", "response": "Gets the name of the function from the Integration URI ARN."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_function_name_from_arn(function_arn):\n\n        if not function_arn:\n            return None\n\n        matches = re.match(LambdaUri._REGEX_GET_FUNCTION_NAME, function_arn)\n        if not matches or not matches.groups():\n            LOG.debug(\"No Lambda function ARN defined for integration containing ARN %s\", function_arn)\n            return None\n\n        groups = matches.groups()\n        maybe_function_name = groups[0]  # This regex has only one group match\n\n        # Function name could be a real name or a stage variable or some unknown format\n        if re.match(LambdaUri._REGEX_STAGE_VARIABLE, maybe_function_name):\n            # yes, this is a stage variable\n            LOG.debug(\"Stage variables are not supported. Ignoring integration with function ARN %s\", function_arn)\n            return None\n\n        elif re.match(LambdaUri._REGEX_VALID_FUNCTION_NAME, maybe_function_name):\n            # Yes, this is a real function name\n            return maybe_function_name\n\n        # Some unknown format\n        LOG.debug(\"Ignoring integration ARN. Unable to parse Function Name from function arn %s\",\n                  function_arn)", "response": "Given an integration ARN extract the Lambda function name from the ARN."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _resolve_fn_sub(uri_data):\n\n        # Try the short form of Fn::Sub syntax where the value is the ARN\n        arn = uri_data[LambdaUri._FN_SUB]\n\n        if isinstance(arn, list):\n            # This is the long form of Fn::Sub syntax\n            #\n            # {\n            #   \"Fn::Sub\":[ \"arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${MyARn}/invocations\",\n            #               {\"MyARn\": {\"Ref\": MyFunction\"}\n            #             ]\n            # }\n            #\n            # Get the ARN out of the list\n            arn = arn[0]\n\n        if not isinstance(arn, string_types):\n            # Even after all the processing, ARN is still not a string. Probably customer provided wrong syntax\n            # for Fn::Sub. Let's skip this altogether\n            LOG.debug(\"Unable to resolve Fn::Sub value for integration URI: %s\", uri_data)\n            return uri_data\n\n        # Now finally we got the ARN string. Let us try to resolve it.\n        # We only support value of type ${XXX.Arn} or ${YYY.Alias}. The `.Alias` syntax is a SAM specific intrinsic\n        # to get ARN of Lambda Alias when using DeploymentPreference\n        lambda_function_arn_template = r'arn:aws:lambda:${AWS::Region}:123456789012:function:\\1'\n\n        return re.sub(LambdaUri._REGEX_SUB_FUNCTION_ARN,  # Find all ${blah} patterns\n                      # Replace with Lambda Function ARN, where function name is from pattern\n                      lambda_function_arn_template,\n                      arn)", "response": "Resolves a Fn :: Sub intrinsic function to a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_sub_intrinsic(data):\n        return isinstance(data, dict) and len(data) == 1 and LambdaUri._FN_SUB in data", "response": "Checks if the input data is a Fn :: Sub intrinsic function\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the event from the given file.", "response": "def _get_event(event_file_name):\n    \"\"\"\n    Read the event JSON data from the given file. If no file is provided, read the event from stdin.\n\n    :param string event_file_name: Path to event file, or '-' for stdin\n    :return string: Contents of the event file or stdin\n    \"\"\"\n\n    if event_file_name == STDIN_FILE_NAME:\n        # If event is empty, listen to stdin for event data until EOF\n        LOG.info(\"Reading invoke payload from stdin (you can also pass it from file with --event)\")\n\n    # click.open_file knows to open stdin when filename is '-'. This is safer than manually opening streams, and\n    # accidentally closing a standard stream\n    with click.open_file(event_file_name, 'r') as fp:\n        return fp.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize(template_dict):\n        resources = template_dict.get(RESOURCES_KEY, {})\n\n        for logical_id, resource in resources.items():\n            resource_metadata = resource.get(METADATA_KEY, {})\n            asset_path = resource_metadata.get(ASSET_PATH_METADATA_KEY)\n            asset_property = resource_metadata.get(ASSET_PROPERTY_METADATA_KEY)\n\n            ResourceMetadataNormalizer._replace_property(asset_property, asset_path, resource, logical_id)", "response": "This method will normalize all Resources in the template with the Metadata Key on the resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing a property with an asset on a given resource", "response": "def _replace_property(property_key, property_value, resource, logical_id):\n        \"\"\"\n        Replace a property with an asset on a given resource\n\n        This method will mutate the template\n\n        Parameters\n        ----------\n        property str\n            The property to replace on the resource\n        property_value str\n            The new value of the property\n        resource dict\n            Dictionary representing the Resource to change\n        logical_id str\n            LogicalId of the Resource\n\n        \"\"\"\n        if property_key and property_value:\n            resource.get(PROPERTIES_KEY, {})[property_key] = property_value\n        elif property_key or property_value:\n            LOG.info(\"WARNING: Ignoring Metadata for Resource %s. Metadata contains only aws:asset:path or \"\n                     \"aws:assert:property but not both\", logical_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_commands(package_names):\n\n        commands = {}\n\n        for pkg_name in package_names:\n            cmd_name = pkg_name.split('.')[-1]\n            commands[cmd_name] = pkg_name\n\n        return commands", "response": "Extracts the command name from the package name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns Click CLI object for given command name.", "response": "def get_command(self, ctx, cmd_name):\n        \"\"\"\n        Overrides method from ``click.MultiCommand`` that returns Click CLI object for given command name, if found.\n\n        :param ctx: Click context\n        :param cmd_name: Top-level command name\n        :return: Click object representing the command\n        \"\"\"\n        if cmd_name not in self._commands:\n            logger.error(\"Command %s not available\", cmd_name)\n            return\n\n        pkg_name = self._commands[cmd_name]\n\n        try:\n            mod = importlib.import_module(pkg_name)\n        except ImportError:\n            logger.exception(\"Command '%s' is not configured correctly. Unable to import '%s'\", cmd_name, pkg_name)\n            return\n\n        if not hasattr(mod, \"cli\"):\n            logger.error(\"Command %s is not configured correctly. It must expose an function called 'cli'\", cmd_name)\n            return\n\n        return mod.cli"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, output):\n        self._stream.write(output)\n\n        if self._auto_flush:\n            self._stream.flush()", "response": "Writes specified text to the underlying stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_workflow_config(runtime, code_dir, project_dir):\n\n    selectors_by_runtime = {\n        \"python2.7\": BasicWorkflowSelector(PYTHON_PIP_CONFIG),\n        \"python3.6\": BasicWorkflowSelector(PYTHON_PIP_CONFIG),\n        \"python3.7\": BasicWorkflowSelector(PYTHON_PIP_CONFIG),\n        \"nodejs4.3\": BasicWorkflowSelector(NODEJS_NPM_CONFIG),\n        \"nodejs6.10\": BasicWorkflowSelector(NODEJS_NPM_CONFIG),\n        \"nodejs8.10\": BasicWorkflowSelector(NODEJS_NPM_CONFIG),\n        \"ruby2.5\": BasicWorkflowSelector(RUBY_BUNDLER_CONFIG),\n        \"dotnetcore2.0\": BasicWorkflowSelector(DOTNET_CLIPACKAGE_CONFIG),\n        \"dotnetcore2.1\": BasicWorkflowSelector(DOTNET_CLIPACKAGE_CONFIG),\n\n        # When Maven builder exists, add to this list so we can automatically choose a builder based on the supported\n        # manifest\n        \"java8\": ManifestWorkflowSelector([\n            # Gradle builder needs custom executable paths to find `gradlew` binary\n            JAVA_GRADLE_CONFIG._replace(executable_search_paths=[code_dir, project_dir]),\n            JAVA_KOTLIN_GRADLE_CONFIG._replace(executable_search_paths=[code_dir, project_dir]),\n            JAVA_MAVEN_CONFIG\n        ]),\n    }\n\n    if runtime not in selectors_by_runtime:\n        raise UnsupportedRuntimeException(\"'{}' runtime is not supported\".format(runtime))\n\n    selector = selectors_by_runtime[runtime]\n\n    try:\n        config = selector.get_config(code_dir, project_dir)\n        return config\n    except ValueError as ex:\n        raise UnsupportedRuntimeException(\"Unable to find a supported build workflow for runtime '{}'. Reason: {}\"\n                                          .format(runtime, str(ex)))", "response": "Returns a namedtuple that represents the most appropriate workflow for the given runtime."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a workflow config this method provides a boolean on whether the workflow can be built within a container or not.", "response": "def supports_build_in_container(config):\n    \"\"\"\n    Given a workflow config, this method provides a boolean on whether the workflow can run within a container or not.\n\n    Parameters\n    ----------\n    config namedtuple(Capability)\n        Config specifying the particular build workflow\n\n    Returns\n    -------\n    tuple(bool, str)\n        True, if this workflow can be built inside a container. False, along with a reason message if it cannot be.\n    \"\"\"\n\n    def _key(c):\n        return str(c.language) + str(c.dependency_manager) + str(c.application_framework)\n\n    # This information could have beeen bundled inside the Workflow Config object. But we this way because\n    # ultimately the workflow's implementation dictates whether it can run within a container or not.\n    # A \"workflow config\" is like a primary key to identify the workflow. So we use the config as a key in the\n    # map to identify which workflows can support building within a container.\n\n    unsupported = {\n        _key(DOTNET_CLIPACKAGE_CONFIG): \"We do not support building .NET Core Lambda functions within a container. \"\n                                        \"Try building without the container. Most .NET Core functions will build \"\n                                        \"successfully.\",\n    }\n\n    thiskey = _key(config)\n    if thiskey in unsupported:\n        return False, unsupported[thiskey]\n\n    return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config(self, code_dir, project_dir):\n\n        # Search for manifest first in code directory and then in the project directory.\n        # Search order is important here because we want to prefer the manifest present within the code directory over\n        # a manifest present in project directory.\n        search_dirs = [code_dir, project_dir]\n        LOG.debug(\"Looking for a supported build workflow in following directories: %s\", search_dirs)\n\n        for config in self.configs:\n\n            if any([self._has_manifest(config, directory) for directory in search_dirs]):\n                return config\n\n        raise ValueError(\"None of the supported manifests '{}' were found in the following paths '{}'\".format(\n                         [config.manifest_name for config in self.configs],\n                         search_dirs))", "response": "Find a configuration by looking for a manifest in the given directories."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef intrinsics_multi_constructor(loader, tag_prefix, node):\n\n    # Get the actual tag name excluding the first exclamation\n    tag = node.tag[1:]\n\n    # Some intrinsic functions doesn't support prefix \"Fn::\"\n    prefix = \"Fn::\"\n    if tag in [\"Ref\", \"Condition\"]:\n        prefix = \"\"\n\n    cfntag = prefix + tag\n\n    if tag == \"GetAtt\" and isinstance(node.value, six.string_types):\n        # ShortHand notation for !GetAtt accepts Resource.Attribute format\n        # while the standard notation is to use an array\n        # [Resource, Attribute]. Convert shorthand to standard format\n        value = node.value.split(\".\", 1)\n\n    elif isinstance(node, ScalarNode):\n        # Value of this node is scalar\n        value = loader.construct_scalar(node)\n\n    elif isinstance(node, SequenceNode):\n        # Value of this node is an array (Ex: [1,2])\n        value = loader.construct_sequence(node)\n\n    else:\n        # Value of this node is an mapping (ex: {foo: bar})\n        value = loader.construct_mapping(node)\n\n    return {cfntag: value}", "response": "This is a YAML constructor that parses CloudFormation intrinsics. It will parse CloudFormation intrinsics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef yaml_parse(yamlstr):\n    try:\n        # PyYAML doesn't support json as well as it should, so if the input\n        # is actually just json it is better to parse it with the standard\n        # json parser.\n        return json.loads(yamlstr)\n    except ValueError:\n        yaml.SafeLoader.add_multi_constructor(\"!\", intrinsics_multi_constructor)\n        return yaml.safe_load(yamlstr)", "response": "Parse a yaml string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode(self, tags, encoding, values_to_sub):\n\n        for tag in tags:\n            if tags[tag].get(encoding) != \"None\":\n                if tags[tag].get(encoding) == \"url\":\n                    values_to_sub[tag] = self.url_encode(values_to_sub[tag])\n                if tags[tag].get(encoding) == \"base64\":\n                    values_to_sub[tag] = self.base64_utf_encode(values_to_sub[tag])\n        return values_to_sub", "response": "Encodes the json - related key - value pairs of a particular event - mapping."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the event json, substitutes the values in, and returns the customized event json Parameters ---------- service_name: string name of the top level service (S3, apigateway, etc) event_type: string name of the event underneath the service values_to_sub: dict key/value pairs to substitute into the json Returns ------- renderer.render(): string string version of the custom event json", "response": "def generate_event(self, service_name, event_type, values_to_sub):\n        \"\"\"\n        opens the event json, substitutes the values in, and\n        returns the customized event json\n\n        Parameters\n        ----------\n        service_name: string\n            name of the top level service (S3, apigateway, etc)\n        event_type: string\n            name of the event underneath the service\n        values_to_sub: dict\n            key/value pairs to substitute into the json\n        Returns\n        -------\n        renderer.render(): string\n            string version of the custom event json\n        \"\"\"\n\n        # set variables for easy calling\n        tags = self.event_mapping[service_name][event_type]['tags']\n        values_to_sub = self.encode(tags, 'encoding', values_to_sub)\n\n        # construct the path to the Events json file\n        this_folder = os.path.dirname(os.path.abspath(__file__))\n        file_name = self.event_mapping[service_name][event_type]['filename'] + \".json\"\n        file_path = os.path.join(this_folder, \"events\", service_name, file_name)\n\n        # open the file\n        with open(file_path) as f:\n            data = json.load(f)\n\n        data = json.dumps(data, indent=2)\n\n        # return the substituted file\n        return renderer.render(data, values_to_sub)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _color(self, msg, color):\n        kwargs = {'fg': color}\n        return click.style(msg, **kwargs) if self.colorize else msg", "response": "Internal helper method to add colors to input"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch logs from all streams under the given CloudWatch Log Group and yields in the output.", "response": "def fetch(self, log_group_name, start=None, end=None, filter_pattern=None):\n        \"\"\"\n        Fetch logs from all streams under the given CloudWatch Log Group and yields in the output. Optionally, caller\n        can filter the logs using a pattern or a start/end time.\n\n        Parameters\n        ----------\n        log_group_name : string\n            Name of CloudWatch Logs Group to query.\n\n        start : datetime.datetime\n            Optional start time for logs.\n\n        end : datetime.datetime\n            Optional end time for logs.\n\n        filter_pattern : str\n            Expression to filter the logs by. This is passed directly to CloudWatch, so any expression supported by\n            CloudWatch Logs API is supported here.\n\n        Yields\n        ------\n\n        samcli.lib.logs.event.LogEvent\n            Object containing the information from each log event returned by CloudWatch Logs\n        \"\"\"\n\n        kwargs = {\n            \"logGroupName\": log_group_name,\n            \"interleaved\": True\n        }\n\n        if start:\n            kwargs[\"startTime\"] = to_timestamp(start)\n\n        if end:\n            kwargs[\"endTime\"] = to_timestamp(end)\n\n        if filter_pattern:\n            kwargs[\"filterPattern\"] = filter_pattern\n\n        while True:\n            LOG.debug(\"Fetching logs from CloudWatch with parameters %s\", kwargs)\n            result = self.cw_client.filter_log_events(**kwargs)\n\n            # Several events will be returned. Yield one at a time\n            for event in result.get('events', []):\n                yield LogEvent(log_group_name, event)\n\n            # Keep iterating until there are no more logs left to query.\n            next_token = result.get(\"nextToken\", None)\n            kwargs[\"nextToken\"] = next_token\n            if not next_token:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tail(self, log_group_name, start=None, filter_pattern=None, max_retries=1000, poll_interval=0.3):\n\n        # On every poll, startTime of the API call is the timestamp of last record observed\n        latest_event_time = 0  # Start of epoch\n        if start:\n            latest_event_time = to_timestamp(start)\n\n        counter = max_retries\n        while counter > 0:\n\n            LOG.debug(\"Tailing logs from %s starting at %s\", log_group_name, str(latest_event_time))\n\n            has_data = False\n            counter -= 1\n            events_itr = self.fetch(log_group_name,\n                                    start=to_datetime(latest_event_time),\n                                    filter_pattern=filter_pattern)\n\n            # Find the timestamp of the most recent log event.\n            for event in events_itr:\n                has_data = True\n\n                if event.timestamp_millis > latest_event_time:\n                    latest_event_time = event.timestamp_millis\n\n                # Yield the event back so it behaves similar to ``fetch``\n                yield event\n\n            # This poll fetched logs. Reset the retry counter and set the timestamp for next poll\n            if has_data:\n                counter = max_retries\n                latest_event_time += 1  # one extra millisecond to fetch next log event\n\n            # We already fetched logs once. Sleep for some time before querying again.\n            # This also helps us scoot under the TPS limit for CloudWatch API call.\n            time.sleep(poll_interval)", "response": "This method returns a list of CloudWatch Logs for the specified log group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compute_layer_version(is_defined_within_template, arn):\n\n        if is_defined_within_template:\n            return None\n\n        try:\n            _, layer_version = arn.rsplit(':', 1)\n            layer_version = int(layer_version)\n        except ValueError:\n            raise InvalidLayerVersionArn(arn + \" is an Invalid Layer Arn.\")\n\n        return layer_version", "response": "Computes the Layer Version from the Layer Version ARN."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing a unique name based on the LayerVersion and the LayerVersion ARN.", "response": "def _compute_layer_name(is_defined_within_template, arn):\n        \"\"\"\n        Computes a unique name based on the LayerVersion Arn\n\n        Format:\n        <Name of the LayerVersion>-<Version of the LayerVersion>-<sha256 of the arn>\n\n        Parameters\n        ----------\n        is_defined_within_template bool\n            True if the resource is a Ref to a resource otherwise False\n        arn str\n            ARN of the Resource\n\n        Returns\n        -------\n        str\n            A unique name that represents the LayerVersion\n        \"\"\"\n\n        # If the Layer is defined in the template, the arn will represent the LogicalId of the LayerVersion Resource,\n        # which does not require creating a name based on the arn.\n        if is_defined_within_template:\n            return arn\n\n        try:\n            _, layer_name, layer_version = arn.rsplit(':', 2)\n        except ValueError:\n            raise InvalidLayerVersionArn(arn + \" is an Invalid Layer Arn.\")\n\n        return LayerVersion.LAYER_NAME_DELIMETER.join([layer_name,\n                                                       layer_version,\n                                                       hashlib.sha256(arn.encode('utf-8')).hexdigest()[0:10]])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the stdout as a byte stream in a Py2 or Py3 compatible manner", "response": "def stdout():\n    \"\"\"\n    Returns the stdout as a byte stream in a Py2/PY3 compatible manner\n\n    Returns\n    -------\n    io.BytesIO\n        Byte stream of Stdout\n    \"\"\"\n\n    # We write all of the data to stdout with bytes, typically io.BytesIO. stdout in Python2\n    # accepts bytes but Python3 does not. This is due to a type change on the attribute. To keep\n    # this consistent, we leave Python2 the same and get the .buffer attribute on stdout in Python3\n    byte_stdout = sys.stdout\n\n    if sys.version_info.major > 2:\n        byte_stdout = sys.stdout.buffer  # pylint: disable=no-member\n\n    return byte_stdout"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the stderr as a byte stream in a Py2 or Py3 compatible manner", "response": "def stderr():\n    \"\"\"\n    Returns the stderr as a byte stream in a Py2/PY3 compatible manner\n\n    Returns\n    -------\n    io.BytesIO\n        Byte stream of stderr\n    \"\"\"\n\n    # We write all of the data to stderr with bytes, typically io.BytesIO. stderr in Python2\n    # accepts bytes but Python3 does not. This is due to a type change on the attribute. To keep\n    # this consistent, we leave Python2 the same and get the .buffer attribute on stderr in Python3\n    byte_stderr = sys.stderr\n\n    if sys.version_info.major > 2:\n        byte_stderr = sys.stderr.buffer  # pylint: disable=no-member\n\n    return byte_stderr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a list of layers to the cache", "response": "def download_all(self, layers, force=False):\n        \"\"\"\n        Download a list of layers to the cache\n\n        Parameters\n        ----------\n        layers list(samcli.commands.local.lib.provider.Layer)\n            List of Layers representing the layer to be downloaded\n        force bool\n            True to download the layer even if it exists already on the system\n\n        Returns\n        -------\n        List(Path)\n            List of Paths to where the layer was cached\n        \"\"\"\n        layer_dirs = []\n        for layer in layers:\n            layer_dirs.append(self.download(layer, force))\n\n        return layer_dirs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download(self, layer, force=False):\n        if layer.is_defined_within_template:\n            LOG.info(\"%s is a local Layer in the template\", layer.name)\n            layer.codeuri = resolve_code_path(self.cwd, layer.codeuri)\n            return layer\n\n        # disabling no-member due to https://github.com/PyCQA/pylint/issues/1660\n        layer_path = Path(self.layer_cache).joinpath(layer.name).resolve()  # pylint: disable=no-member\n        is_layer_downloaded = self._is_layer_cached(layer_path)\n        layer.codeuri = str(layer_path)\n\n        if is_layer_downloaded and not force:\n            LOG.info(\"%s is already cached. Skipping download\", layer.arn)\n            return layer\n\n        layer_zip_path = layer.codeuri + '.zip'\n        layer_zip_uri = self._fetch_layer_uri(layer)\n        unzip_from_uri(layer_zip_uri,\n                       layer_zip_path,\n                       unzip_output_dir=layer.codeuri,\n                       progressbar_label='Downloading {}'.format(layer.layer_arn))\n\n        return layer", "response": "Download a given layer to the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fetch_layer_uri(self, layer):\n        try:\n            layer_version_response = self.lambda_client.get_layer_version(LayerName=layer.layer_arn,\n                                                                          VersionNumber=layer.version)\n        except NoCredentialsError:\n            raise CredentialsRequired(\"Layers require credentials to download the layers locally.\")\n        except ClientError as e:\n            error_code = e.response.get('Error').get('Code')\n            error_exc = {\n                'AccessDeniedException': CredentialsRequired(\n                    \"Credentials provided are missing lambda:Getlayerversion policy that is needed to download the \"\n                    \"layer or you do not have permission to download the layer\"),\n                'ResourceNotFoundException': ResourceNotFound(\"{} was not found.\".format(layer.arn))\n            }\n\n            if error_code in error_exc:\n                raise error_exc[error_code]\n\n            # If it was not 'AccessDeniedException' or 'ResourceNotFoundException' re-raise\n            raise e\n\n        return layer_version_response.get(\"Content\").get(\"Location\")", "response": "Fetch the Layer Uri based on the LayerVersion Arn and the LayerVersion Version Number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the Cache directory if it does not exist.", "response": "def _create_cache(layer_cache):\n        \"\"\"\n        Create the Cache directory if it does not exist.\n\n        Parameters\n        ----------\n        layer_cache\n            Directory to where the layers should be cached\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        Path(layer_cache).mkdir(mode=0o700, parents=True, exist_ok=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid(self):\n        managed_policy_map = self.managed_policy_loader.load()\n\n        sam_translator = Translator(managed_policy_map=managed_policy_map,\n                                    sam_parser=self.sam_parser,\n                                    plugins=[])\n\n        self._replace_local_codeuri()\n\n        try:\n            template = sam_translator.translate(sam_template=self.sam_template,\n                                                parameter_values={})\n            LOG.debug(\"Translated template is:\\n%s\", yaml_dump(template))\n        except InvalidDocumentException as e:\n            raise InvalidSamDocumentException(\n                functools.reduce(lambda message, error: message + ' ' + str(error), e.causes, str(e)))", "response": "Checks if the SAM template provided is valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace the CodeUri in AWS Serverless Function and DefinitionUri in AWS Serverless API with a fake S3 Uri.", "response": "def _replace_local_codeuri(self):\n        \"\"\"\n        Replaces the CodeUri in AWS::Serverless::Function and DefinitionUri in AWS::Serverless::Api to a fake\n        S3 Uri. This is to support running the SAM Translator with valid values for these fields. If this in not done,\n        the template is invalid in the eyes of SAM Translator (the translator does not support local paths)\n        \"\"\"\n\n        all_resources = self.sam_template.get(\"Resources\", {})\n\n        for _, resource in all_resources.items():\n\n            resource_type = resource.get(\"Type\")\n            resource_dict = resource.get(\"Properties\")\n\n            if resource_type == \"AWS::Serverless::Function\":\n\n                SamTemplateValidator._update_to_s3_uri(\"CodeUri\", resource_dict)\n\n            if resource_type == \"AWS::Serverless::LayerVersion\":\n\n                SamTemplateValidator._update_to_s3_uri(\"ContentUri\", resource_dict)\n\n            if resource_type == \"AWS::Serverless::Api\":\n                if \"DefinitionBody\" not in resource_dict:\n                    SamTemplateValidator._update_to_s3_uri(\"DefinitionUri\", resource_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the property_key in the resource_property_dict to the value of s3_uri_value", "response": "def _update_to_s3_uri(property_key, resource_property_dict, s3_uri_value=\"s3://bucket/value\"):\n        \"\"\"\n        Updates the 'property_key' in the 'resource_property_dict' to the value of 's3_uri_value'\n\n        Note: The function will mutate the resource_property_dict that is pass in\n\n        Parameters\n        ----------\n        property_key str, required\n            Key in the resource_property_dict\n        resource_property_dict dict, required\n            Property dictionary of a Resource in the template to replace\n        s3_uri_value str, optional\n            Value to update the value of the property_key to\n        \"\"\"\n        uri_property = resource_property_dict.get(property_key, \".\")\n\n        # ignore if dict or already an S3 Uri\n        if isinstance(uri_property, dict) or SamTemplateValidator.is_s3_uri(uri_property):\n            return\n\n        resource_property_dict[property_key] = s3_uri_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef formatter(self):\n        formatter_chain = [\n            LambdaLogMsgFormatters.colorize_errors,\n\n            # Format JSON \"before\" highlighting the keywords. Otherwise, JSON will be invalid from all the\n            # ANSI color codes and fail to pretty print\n            JSONMsgFormatter.format_json,\n\n            KeywordHighlighter(self._filter_pattern).highlight_keywords,\n        ]\n\n        return LogsFormatter(self.colored, formatter_chain)", "response": "Creates and returns a LogsFormatter capable of nicely formatting Lambda function logs\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the CloudWatch Log Group that we will be querying.", "response": "def log_group_name(self):\n        \"\"\"\n        Name of the AWS CloudWatch Log Group that we will be querying. It generates the name based on the\n        Lambda Function name and stack name provided.\n\n        Returns\n        -------\n        str\n            Name of the CloudWatch Log Group\n        \"\"\"\n\n        function_id = self._function_name\n        if self._stack_name:\n            function_id = self._get_resource_id_from_stack(self._cfn_client, self._stack_name, self._function_name)\n            LOG.debug(\"Function with LogicalId '%s' in stack '%s' resolves to actual physical ID '%s'\",\n                      self._function_name, self._stack_name, function_id)\n\n        return LogGroupProvider.for_lambda_function(function_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the time from the given string convert to UTC and return the datetime object.", "response": "def _parse_time(time_str, property_name):\n        \"\"\"\n        Parse the time from the given string, convert to UTC, and return the datetime object\n\n        Parameters\n        ----------\n        time_str : str\n            The time to parse\n\n        property_name : str\n            Name of the property where this time came from. Used in the exception raised if time is not parseable\n\n        Returns\n        -------\n        datetime.datetime\n            Parsed datetime object\n\n        Raises\n        ------\n        samcli.commands.exceptions.UserException\n            If the string cannot be parsed as a timestamp\n        \"\"\"\n        if not time_str:\n            return\n\n        parsed = parse_date(time_str)\n        if not parsed:\n            raise UserException(\"Unable to parse the time provided by '{}'\".format(property_name))\n\n        return to_utc(parsed)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_resource_id_from_stack(cfn_client, stack_name, logical_id):\n\n        LOG.debug(\"Getting resource's PhysicalId from AWS CloudFormation stack. StackName=%s, LogicalId=%s\",\n                  stack_name, logical_id)\n\n        try:\n            response = cfn_client.describe_stack_resource(StackName=stack_name, LogicalResourceId=logical_id)\n\n            LOG.debug(\"Response from AWS CloudFormation %s\", response)\n            return response[\"StackResourceDetail\"][\"PhysicalResourceId\"]\n\n        except botocore.exceptions.ClientError as ex:\n            LOG.debug(\"Unable to fetch resource name from CloudFormation Stack: \"\n                      \"StackName=%s, ResourceLogicalId=%s, Response=%s\", stack_name, logical_id, ex.response)\n\n            # The exception message already has a well formatted error message that we can surface to user\n            raise UserException(str(ex))", "response": "Get the PhysicalId of a resource within a specified stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a SAM template dictionary return a cleaned copy of the template where the SAM plugins have been run and the parameter values have been substituted.", "response": "def get_template(template_dict, parameter_overrides=None):\n        \"\"\"\n        Given a SAM template dictionary, return a cleaned copy of the template where SAM plugins have been run\n        and parameter values have been substituted.\n\n        Parameters\n        ----------\n        template_dict : dict\n            unprocessed SAM template dictionary\n\n        parameter_overrides: dict\n            Optional dictionary of values for template parameters\n\n        Returns\n        -------\n        dict\n            Processed SAM template\n        \"\"\"\n\n        template_dict = template_dict or {}\n        if template_dict:\n            template_dict = SamTranslatorWrapper(template_dict).run_plugins()\n\n        template_dict = SamBaseProvider._resolve_parameters(template_dict, parameter_overrides)\n        ResourceMetadataNormalizer.normalize(template_dict)\n        return template_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the parameters of the user defined template with their respective values.", "response": "def _resolve_parameters(template_dict, parameter_overrides):\n        \"\"\"\n        In the given template, apply parameter values to resolve intrinsic functions\n\n        Parameters\n        ----------\n        template_dict : dict\n            SAM Template\n\n        parameter_overrides : dict\n            Values for template parameters provided by user\n\n        Returns\n        -------\n        dict\n            Resolved SAM template\n        \"\"\"\n\n        parameter_values = SamBaseProvider._get_parameter_values(template_dict, parameter_overrides)\n\n        supported_intrinsics = {action.intrinsic_name: action() for action in SamBaseProvider._SUPPORTED_INTRINSICS}\n\n        # Intrinsics resolver will mutate the original template\n        return IntrinsicsResolver(parameters=parameter_values, supported_intrinsics=supported_intrinsics)\\\n            .resolve_parameter_refs(template_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_parameter_values(template_dict, parameter_overrides):\n\n        default_values = SamBaseProvider._get_default_parameter_values(template_dict)\n\n        # NOTE: Ordering of following statements is important. It makes sure that any user-supplied values\n        # override the defaults\n        parameter_values = {}\n        parameter_values.update(SamBaseProvider._DEFAULT_PSEUDO_PARAM_VALUES)\n        parameter_values.update(default_values)\n        parameter_values.update(parameter_overrides or {})\n\n        return parameter_values", "response": "Constructs a list of values for CloudFormation template parameters based on user - supplied values and sane defaults for pseudo - parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a Windows path to a POSIX - style path.", "response": "def to_posix_path(code_path):\n    \"\"\"\n    Change the code_path to be of unix-style if running on windows when supplied with an absolute windows path.\n\n    Parameters\n    ----------\n    code_path : str\n        Directory in the host operating system that should be mounted within the container.\n    Returns\n    -------\n    str\n        Posix equivalent of absolute windows style path.\n    Examples\n    --------\n    >>> to_posix_path('/Users/UserName/sam-app')\n    /Users/UserName/sam-app\n    >>> to_posix_path('C:\\\\\\\\Users\\\\\\\\UserName\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\mydir')\n    /c/Users/UserName/AppData/Local/Temp/mydir\n    \"\"\"\n\n    return re.sub(\"^([A-Za-z])+:\",\n                  lambda match: posixpath.sep + match.group().replace(\":\", \"\").lower(),\n                  pathlib.PureWindowsPath(code_path).as_posix()) if os.name == \"nt\" else code_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn additional Docker container options. Used by container debug mode to enable certain container specific options.", "response": "def _get_additional_options(runtime, debug_options):\n        \"\"\"\n        Return additional Docker container options. Used by container debug mode to enable certain container\n        security options.\n        :param DebugContext debug_options: DebugContext for the runtime of the container.\n        :return dict: Dictionary containing additional arguments to be passed to container creation.\n        \"\"\"\n        if not debug_options:\n            return None\n\n        opts = {}\n\n        if runtime == Runtime.go1x.value:\n            # These options are required for delve to function properly inside a docker container on docker < 1.12\n            # See https://github.com/moby/moby/issues/21051\n            opts[\"security_opt\"] = [\"seccomp:unconfined\"]\n            opts[\"cap_add\"] = [\"SYS_PTRACE\"]\n\n        return opts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_entry_point(runtime, debug_options=None):  # pylint: disable=too-many-branches\n\n        if not debug_options:\n            return None\n\n        if runtime not in LambdaContainer._supported_runtimes():\n            raise DebuggingNotSupported(\n                \"Debugging is not currently supported for {}\".format(runtime))\n\n        debug_port = debug_options.debug_port\n        debug_args_list = []\n\n        if debug_options.debug_args:\n            debug_args_list = debug_options.debug_args.split(\" \")\n\n        # configs from: https://github.com/lambci/docker-lambda\n        # to which we add the extra debug mode options\n        entrypoint = None\n        if runtime == Runtime.java8.value:\n\n            entrypoint = [\"/usr/bin/java\"] \\\n                   + debug_args_list \\\n                   + [\n                        \"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,quiet=y,address=\" + str(debug_port),\n                        \"-XX:MaxHeapSize=2834432k\",\n                        \"-XX:MaxMetaspaceSize=163840k\",\n                        \"-XX:ReservedCodeCacheSize=81920k\",\n                        \"-XX:+UseSerialGC\",\n                        # \"-Xshare:on\", doesn't work in conjunction with the debug options\n                        \"-XX:-TieredCompilation\",\n                        \"-Djava.net.preferIPv4Stack=true\",\n                        \"-jar\",\n                        \"/var/runtime/lib/LambdaJavaRTEntry-1.0.jar\",\n                   ]\n\n        elif runtime in (Runtime.dotnetcore20.value, Runtime.dotnetcore21.value):\n            entrypoint = [\"/var/lang/bin/dotnet\"] \\\n                + debug_args_list \\\n                + [\n                    \"/var/runtime/MockBootstraps.dll\",\n                    \"--debugger-spin-wait\"\n                  ]\n\n        elif runtime == Runtime.go1x.value:\n            entrypoint = [\"/var/runtime/aws-lambda-go\"] \\\n                + debug_args_list \\\n                + [\n                    \"-debug=true\",\n                    \"-delvePort=\" + str(debug_port),\n                    \"-delvePath=\" + LambdaContainer._DEFAULT_CONTAINER_DBG_GO_PATH,\n                  ]\n\n        elif runtime == Runtime.nodejs.value:\n\n            entrypoint = [\"/usr/bin/node\"] \\\n                   + debug_args_list \\\n                   + [\n                       \"--debug-brk=\" + str(debug_port),\n                       \"--nolazy\",\n                       \"--max-old-space-size=1229\",\n                       \"--max-new-space-size=153\",\n                       \"--max-executable-size=153\",\n                       \"--expose-gc\",\n                       \"/var/runtime/node_modules/awslambda/bin/awslambda\",\n                   ]\n\n        elif runtime == Runtime.nodejs43.value:\n\n            entrypoint = [\"/usr/local/lib64/node-v4.3.x/bin/node\"] \\\n                   + debug_args_list \\\n                   + [\n                       \"--debug-brk=\" + str(debug_port),\n                       \"--nolazy\",\n                       \"--max-old-space-size=2547\",\n                       \"--max-semi-space-size=150\",\n                       \"--max-executable-size=160\",\n                       \"--expose-gc\",\n                       \"/var/runtime/node_modules/awslambda/index.js\",\n                   ]\n\n        elif runtime == Runtime.nodejs610.value:\n\n            entrypoint = [\"/var/lang/bin/node\"] \\\n                   + debug_args_list \\\n                   + [\n                       \"--debug-brk=\" + str(debug_port),\n                       \"--nolazy\",\n                       \"--max-old-space-size=2547\",\n                       \"--max-semi-space-size=150\",\n                       \"--max-executable-size=160\",\n                       \"--expose-gc\",\n                       \"/var/runtime/node_modules/awslambda/index.js\",\n                   ]\n\n        elif runtime == Runtime.nodejs810.value:\n\n            entrypoint = [\"/var/lang/bin/node\"] \\\n                    + debug_args_list \\\n                    + [\n                        # Node8 requires the host to be explicitly set in order to bind to localhost\n                        # instead of 127.0.0.1. https://github.com/nodejs/node/issues/11591#issuecomment-283110138\n                        \"--inspect-brk=0.0.0.0:\" + str(debug_port),\n                        \"--nolazy\",\n                        \"--expose-gc\",\n                        \"--max-semi-space-size=150\",\n                        \"--max-old-space-size=2707\",\n                        \"/var/runtime/node_modules/awslambda/index.js\",\n                    ]\n\n        elif runtime == Runtime.python27.value:\n\n            entrypoint = [\"/usr/bin/python2.7\"] \\\n                   + debug_args_list \\\n                   + [\n                       \"/var/runtime/awslambda/bootstrap.py\"\n                   ]\n\n        elif runtime == Runtime.python36.value:\n\n            entrypoint = [\"/var/lang/bin/python3.6\"] \\\n                   + debug_args_list \\\n                   + [\n                       \"/var/runtime/awslambda/bootstrap.py\"\n                   ]\n\n        elif runtime == Runtime.python37.value:\n            entrypoint = [\"/var/rapid/init\",\n                          \"--bootstrap\",\n                          \"/var/lang/bin/python3.7\",\n                          \"--bootstrap-args\",\n                          json.dumps(debug_args_list + [\"/var/runtime/bootstrap\"])\n                          ]\n\n        return entrypoint", "response": "Returns the entry point for the Lambda container."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts all Implicit Apis from Serverless Function with an Api Event", "response": "def _extract_apis(self, resources):\n        \"\"\"\n        Extract all Implicit Apis (Apis defined through Serverless Function with an Api Event\n\n        :param dict resources: Dictionary of SAM/CloudFormation resources\n        :return: List of nametuple Api\n        \"\"\"\n\n        # Some properties like BinaryMediaTypes, Cors are set once on the resource but need to be applied to each API.\n        # For Implicit APIs, which are defined on the Function resource, these properties\n        # are defined on a AWS::Serverless::Api resource with logical ID \"ServerlessRestApi\". Therefore, no matter\n        # if it is an implicit API or an explicit API, there is a corresponding resource of type AWS::Serverless::Api\n        # that contains these additional configurations.\n        #\n        # We use this assumption in the following loop to collect information from resources of type\n        # AWS::Serverless::Api. We also extract API from Serverless::Function resource and add them to the\n        # corresponding Serverless::Api resource. This is all done using the ``collector``.\n\n        collector = ApiCollector()\n\n        for logical_id, resource in resources.items():\n\n            resource_type = resource.get(SamApiProvider._TYPE)\n\n            if resource_type == SamApiProvider._SERVERLESS_FUNCTION:\n                self._extract_apis_from_function(logical_id, resource, collector)\n\n            if resource_type == SamApiProvider._SERVERLESS_API:\n                self._extract_from_serverless_api(logical_id, resource, collector)\n\n        apis = SamApiProvider._merge_apis(collector)\n        return self._normalize_apis(apis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_from_serverless_api(self, logical_id, api_resource, collector):\n\n        properties = api_resource.get(\"Properties\", {})\n        body = properties.get(\"DefinitionBody\")\n        uri = properties.get(\"DefinitionUri\")\n        binary_media = properties.get(\"BinaryMediaTypes\", [])\n\n        if not body and not uri:\n            # Swagger is not found anywhere.\n            LOG.debug(\"Skipping resource '%s'. Swagger document not found in DefinitionBody and DefinitionUri\",\n                      logical_id)\n            return\n\n        reader = SamSwaggerReader(definition_body=body,\n                                  definition_uri=uri,\n                                  working_dir=self.cwd)\n        swagger = reader.read()\n        parser = SwaggerParser(swagger)\n        apis = parser.get_apis()\n        LOG.debug(\"Found '%s' APIs in resource '%s'\", len(apis), logical_id)\n\n        collector.add_apis(logical_id, apis)\n        collector.add_binary_media_types(logical_id, parser.get_binary_media_types())  # Binary media from swagger\n        collector.add_binary_media_types(logical_id, binary_media)", "response": "Extract APIs from AWS Serverless API resource by reading and parsing Swagger documents and adding them to the collector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _merge_apis(collector):\n\n        implicit_apis = []\n        explicit_apis = []\n\n        # Store implicit and explicit APIs separately in order to merge them later in the correct order\n        # Implicit APIs are defined on a resource with logicalID ServerlessRestApi\n        for logical_id, apis in collector:\n            if logical_id == SamApiProvider._IMPLICIT_API_RESOURCE_ID:\n                implicit_apis.extend(apis)\n            else:\n                explicit_apis.extend(apis)\n\n        # We will use \"path+method\" combination as key to this dictionary and store the Api config for this combination.\n        # If an path+method combo already exists, then overwrite it if and only if this is an implicit API\n        all_apis = {}\n\n        # By adding implicit APIs to the end of the list, they will be iterated last. If a configuration was already\n        # written by explicit API, it will be overriden by implicit API, just by virtue of order of iteration.\n        all_configs = explicit_apis + implicit_apis\n\n        for config in all_configs:\n            # Normalize the methods before de-duping to allow an ANY method in implicit API to override a regular HTTP\n            # method on explicit API.\n            for normalized_method in SamApiProvider._normalize_http_methods(config.method):\n                key = config.path + normalized_method\n                all_apis[key] = config\n\n        result = set(all_apis.values())  # Assign to a set() to de-dupe\n        LOG.debug(\"Removed duplicates from '%d' Explicit APIs and '%d' Implicit APIs to produce '%d' APIs\",\n                  len(explicit_apis), len(implicit_apis), len(result))\n\n        return list(result)", "response": "This method merges implicit and explicit APIs into a single API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _normalize_apis(apis):\n\n        result = list()\n        for api in apis:\n            for normalized_method in SamApiProvider._normalize_http_methods(api.method):\n                # _replace returns a copy of the namedtuple. This is the official way of creating copies of namedtuple\n                result.append(api._replace(method=normalized_method))\n\n        return result", "response": "Normalizes the APIs to use standard method name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the APIs configured for this SAM Function resource from the serverless function events.", "response": "def _extract_apis_from_function(logical_id, function_resource, collector):\n        \"\"\"\n        Fetches a list of APIs configured for this SAM Function resource.\n\n        Parameters\n        ----------\n        logical_id : str\n            Logical ID of the resource\n\n        function_resource : dict\n            Contents of the function resource including its properties\n\n        collector : ApiCollector\n            Instance of the API collector that where we will save the API information\n        \"\"\"\n\n        resource_properties = function_resource.get(\"Properties\", {})\n        serverless_function_events = resource_properties.get(SamApiProvider._FUNCTION_EVENT, {})\n        SamApiProvider._extract_apis_from_events(logical_id, serverless_function_events, collector)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an AWS Serverless function logical ID and an Api collector and an ApiCollector object this function extracts all API events from the serverless function event dictionary and stores them into the ApiCollector instance.", "response": "def _extract_apis_from_events(function_logical_id, serverless_function_events, collector):\n        \"\"\"\n        Given an AWS::Serverless::Function Event Dictionary, extract out all 'Api' events and store  within the\n        collector\n\n        Parameters\n        ----------\n        function_logical_id : str\n            LogicalId of the AWS::Serverless::Function\n\n        serverless_function_events : dict\n            Event Dictionary of a AWS::Serverless::Function\n\n        collector : ApiCollector\n            Instance of the API collector that where we will save the API information\n        \"\"\"\n        count = 0\n        for _, event in serverless_function_events.items():\n\n            if SamApiProvider._FUNCTION_EVENT_TYPE_API == event.get(SamApiProvider._TYPE):\n                api_resource_id, api = SamApiProvider._convert_event_api(function_logical_id, event.get(\"Properties\"))\n                collector.add_apis(api_resource_id, [api])\n                count += 1\n\n        LOG.debug(\"Found '%d' API Events in Serverless function with name '%s'\", count, function_logical_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_event_api(lambda_logical_id, event_properties):\n        path = event_properties.get(SamApiProvider._EVENT_PATH)\n        method = event_properties.get(SamApiProvider._EVENT_METHOD)\n\n        # An API Event, can have RestApiId property which designates the resource that owns this API. If omitted,\n        # the API is owned by Implicit API resource. This could either be a direct resource logical ID or a\n        # \"Ref\" of the logicalID\n        api_resource_id = event_properties.get(\"RestApiId\", SamApiProvider._IMPLICIT_API_RESOURCE_ID)\n        if isinstance(api_resource_id, dict) and \"Ref\" in api_resource_id:\n            api_resource_id = api_resource_id[\"Ref\"]\n\n        # This is still a dictionary. Something wrong with the template\n        if isinstance(api_resource_id, dict):\n            LOG.debug(\"Invalid RestApiId property of event %s\", event_properties)\n            raise InvalidSamDocumentException(\"RestApiId property of resource with logicalId '{}' is invalid. \"\n                                              \"It should either be a LogicalId string or a Ref of a Logical Id string\"\n                                              .format(lambda_logical_id))\n\n        return api_resource_id, Api(path=path, method=method, function_name=lambda_logical_id)", "response": "Converts a AWS Serverless Lambda event property to an Api configuration usable by the provider."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalize_http_methods(http_method):\n\n        if http_method.upper() == 'ANY':\n            for method in SamApiProvider._ANY_HTTP_METHODS:\n                yield method.upper()\n        else:\n            yield http_method.upper()", "response": "Normalizes the HTTP Methods of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_apis(self, logical_id, apis):\n        properties = self._get_properties(logical_id)\n        properties.apis.extend(apis)", "response": "Adds the given APIs to the set of APIs tagged under the given logicalId."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_binary_media_types(self, logical_id, binary_media_types):\n        properties = self._get_properties(logical_id)\n\n        binary_media_types = binary_media_types or []\n        for value in binary_media_types:\n            normalized_value = self._normalize_binary_media_type(value)\n\n            # If the value is not supported, then just skip it.\n            if normalized_value:\n                properties.binary_media_types.add(normalized_value)\n            else:\n                LOG.debug(\"Unsupported data type of binary media type value of resource '%s'\", logical_id)", "response": "Adds the given list of binary media types supported by this resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of APIs in this resource along with additional configuration such as binary media types cors etc.", "response": "def _get_apis_with_config(self, logical_id):\n        \"\"\"\n        Returns the list of APIs in this resource along with other extra configuration such as binary media types,\n        cors etc. Additional configuration is merged directly into the API data because these properties, although\n        defined globally, actually apply to each API.\n\n        Parameters\n        ----------\n        logical_id : str\n            Logical ID of the resource to fetch data for\n\n        Returns\n        -------\n        list of samcli.commands.local.lib.provider.Api\n            List of APIs with additional configurations for the resource with given logicalId. If there are no APIs,\n            then it returns an empty list\n        \"\"\"\n\n        properties = self._get_properties(logical_id)\n\n        # These configs need to be applied to each API\n        binary_media = sorted(list(properties.binary_media_types))  # Also sort the list to keep the ordering stable\n        cors = properties.cors\n\n        result = []\n        for api in properties.apis:\n            # Create a copy of the API with updated configuration\n            updated_api = api._replace(binary_media_types=binary_media,\n                                       cors=cors)\n            result.append(updated_api)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the properties of the resource with given logical ID.", "response": "def _get_properties(self, logical_id):\n        \"\"\"\n        Returns the properties of resource with given logical ID. If a resource is not found, then it returns an\n        empty data.\n\n        Parameters\n        ----------\n        logical_id : str\n            Logical ID of the resource\n\n        Returns\n        -------\n        samcli.commands.local.lib.sam_api_provider.ApiCollector.Properties\n            Properties object for this resource.\n        \"\"\"\n\n        if logical_id not in self.by_resource:\n            self.by_resource[logical_id] = self.Properties(apis=[],\n                                                           # Use a set() to be able to easily de-dupe\n                                                           binary_media_types=set(),\n                                                           cors=None)\n\n        return self.by_resource[logical_id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nunzips a file to a temporary directory and returns the real path to the file.", "response": "def _unzip_file(filepath):\n    \"\"\"\n    Helper method to unzip a file to a temporary directory\n\n    :param string filepath: Absolute path to this file\n    :return string: Path to the temporary directory where it was unzipped\n    \"\"\"\n\n    temp_dir = tempfile.mkdtemp()\n\n    if os.name == 'posix':\n        os.chmod(temp_dir, 0o755)\n\n    LOG.info(\"Decompressing %s\", filepath)\n\n    unzip(filepath, temp_dir)\n\n    # The directory that Python returns might have symlinks. The Docker File sharing settings will not resolve\n    # symlinks. Hence get the real path before passing to Docker.\n    # Especially useful in Mac OSX which returns /var/folders which is a symlink to /private/var/folders that is a\n    # part of Docker's Shared Files directories\n    return os.path.realpath(temp_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef invoke(self,\n               function_config,\n               event,\n               debug_context=None,\n               stdout=None,\n               stderr=None):\n        \"\"\"\n        Invoke the given Lambda function locally.\n\n        ##### NOTE: THIS IS A LONG BLOCKING CALL #####\n        This method will block until either the Lambda function completes or timed out, which could be seconds.\n        A blocking call will block the thread preventing any other operations from happening. If you are using this\n        method in a web-server or in contexts where your application needs to be responsive when function is running,\n        take care to invoke the function in a separate thread. Co-Routines or micro-threads might not perform well\n        because the underlying implementation essentially blocks on a socket, which is synchronous.\n\n        :param FunctionConfig function_config: Configuration of the function to invoke\n        :param event: String input event passed to Lambda function\n        :param DebugContext debug_context: Debugging context for the function (includes port, args, and path)\n        :param io.IOBase stdout: Optional. IO Stream to that receives stdout text from container.\n        :param io.IOBase stderr: Optional. IO Stream that receives stderr text from container\n        :raises Keyboard\n        \"\"\"\n        timer = None\n\n        # Update with event input\n        environ = function_config.env_vars\n        environ.add_lambda_event_body(event)\n        # Generate a dictionary of environment variable key:values\n        env_vars = environ.resolve()\n\n        with self._get_code_dir(function_config.code_abs_path) as code_dir:\n            container = LambdaContainer(function_config.runtime,\n                                        function_config.handler,\n                                        code_dir,\n                                        function_config.layers,\n                                        self._image_builder,\n                                        memory_mb=function_config.memory,\n                                        env_vars=env_vars,\n                                        debug_options=debug_context)\n\n            try:\n\n                # Start the container. This call returns immediately after the container starts\n                self._container_manager.run(container)\n\n                # Setup appropriate interrupt - timeout or Ctrl+C - before function starts executing.\n                #\n                # Start the timer **after** container starts. Container startup takes several seconds, only after which,\n                # our Lambda function code will run. Starting the timer is a reasonable approximation that function has\n                # started running.\n                timer = self._configure_interrupt(function_config.name,\n                                                  function_config.timeout,\n                                                  container,\n                                                  bool(debug_context))\n\n                # NOTE: BLOCKING METHOD\n                # Block the thread waiting to fetch logs from the container. This method will return after container\n                # terminates, either successfully or killed by one of the interrupt handlers above.\n                container.wait_for_logs(stdout=stdout, stderr=stderr)\n\n            except KeyboardInterrupt:\n                # When user presses Ctrl+C, we receive a Keyboard Interrupt. This is especially very common when\n                # container is in debugging mode. We have special handling of Ctrl+C. So handle KeyboardInterrupt\n                # and swallow the exception. The ``finally`` block will also take care of cleaning it up.\n                LOG.debug(\"Ctrl+C was pressed. Aborting Lambda execution\")\n\n            finally:\n                # We will be done with execution, if either the execution completed or an interrupt was fired\n                # Any case, cleanup the timer and container.\n                #\n                # If we are in debugging mode, timer would not be created. So skip cleanup of the timer\n                if timer:\n                    timer.cancel()\n                self._container_manager.stop(container)", "response": "Invoke the given Lambda function locally."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure interrupt handlers for the Lambda function.", "response": "def _configure_interrupt(self, function_name, timeout, container, is_debugging):\n        \"\"\"\n        When a Lambda function is executing, we setup certain interrupt handlers to stop the execution.\n        Usually, we setup a function timeout interrupt to kill the container after timeout expires. If debugging though,\n        we don't enforce a timeout. But we setup a SIGINT interrupt to catch Ctrl+C and terminate the container.\n\n        :param string function_name: Name of the function we are running\n        :param integer timeout: Timeout in seconds\n        :param samcli.local.docker.container.Container container: Instance of a container to terminate\n        :param bool is_debugging: Are we debugging?\n        :return threading.Timer: Timer object, if we setup a timer. None otherwise\n        \"\"\"\n\n        def timer_handler():\n            # NOTE: This handler runs in a separate thread. So don't try to mutate any non-thread-safe data structures\n            LOG.info(\"Function '%s' timed out after %d seconds\", function_name, timeout)\n            self._container_manager.stop(container)\n\n        def signal_handler(sig, frame):\n            # NOTE: This handler runs in a separate thread. So don't try to mutate any non-thread-safe data structures\n            LOG.info(\"Execution of function %s was interrupted\", function_name)\n            self._container_manager.stop(container)\n\n        if is_debugging:\n            LOG.debug(\"Setting up SIGTERM interrupt handler\")\n            signal.signal(signal.SIGTERM, signal_handler)\n        else:\n            # Start a timer, we'll use this to abort the function if it runs beyond the specified timeout\n            LOG.debug(\"Starting a timer for %s seconds for function '%s'\", timeout, function_name)\n            timer = threading.Timer(timeout, timer_handler, ())\n            timer.start()\n            return timer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the image if one is not already on the system that matches the runtime and layers.", "response": "def build(self, runtime, layers):\n        \"\"\"\n        Build the image if one is not already on the system that matches the runtime and layers\n\n        Parameters\n        ----------\n        runtime str\n            Name of the Lambda runtime\n        layers list(samcli.commands.local.lib.provider.Layer)\n            List of layers\n\n        Returns\n        -------\n        str\n            The image to be used (REPOSITORY:TAG)\n        \"\"\"\n        base_image = \"{}:{}\".format(self._DOCKER_LAMBDA_REPO_NAME, runtime)\n\n        # Don't build the image if there are no layers.\n        if not layers:\n            LOG.debug(\"Skipping building an image since no layers were defined\")\n            return base_image\n\n        downloaded_layers = self.layer_downloader.download_all(layers, self.force_image_build)\n\n        docker_image_version = self._generate_docker_image_version(downloaded_layers, runtime)\n        image_tag = \"{}:{}\".format(self._SAM_CLI_REPO_NAME, docker_image_version)\n\n        image_not_found = False\n\n        try:\n            self.docker_client.images.get(image_tag)\n        except docker.errors.ImageNotFound:\n            LOG.info(\"Image was not found.\")\n            image_not_found = True\n\n        if self.force_image_build or \\\n                image_not_found or \\\n                any(layer.is_defined_within_template for layer in downloaded_layers):\n            LOG.info(\"Building image...\")\n            self._build_image(base_image, image_tag, downloaded_layers)\n\n        return image_tag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the Docker TAG that will be used to create the image", "response": "def _generate_docker_image_version(layers, runtime):\n        \"\"\"\n        Generate the Docker TAG that will be used to create the image\n\n        Parameters\n        ----------\n        layers list(samcli.commands.local.lib.provider.Layer)\n            List of the layers\n\n        runtime str\n            Runtime of the image to create\n\n        Returns\n        -------\n        str\n            String representing the TAG to be attached to the image\n        \"\"\"\n\n        # Docker has a concept of a TAG on an image. This is plus the REPOSITORY is a way to determine\n        # a version of the image. We will produced a TAG for a combination of the runtime with the layers\n        # specified in the template. This will allow reuse of the runtime and layers across different\n        # functions that are defined. If two functions use the same runtime with the same layers (in the\n        # same order), SAM CLI will only produce one image and use this image across both functions for invoke.\n        return runtime + '-' + hashlib.sha256(\n            \"-\".join([layer.name for layer in layers]).encode('utf-8')).hexdigest()[0:25]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the image and stores it in the layer cache", "response": "def _build_image(self, base_image, docker_tag, layers):\n        \"\"\"\n        Builds the image\n\n        Parameters\n        ----------\n        base_image str\n            Base Image to use for the new image\n        docker_tag\n            Docker tag (REPOSITORY:TAG) to use when building the image\n        layers list(samcli.commands.local.lib.provider.Layer)\n            List of Layers to be use to mount in the image\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        samcli.commands.local.cli_common.user_exceptions.ImageBuildException\n            When docker fails to build the image\n        \"\"\"\n        dockerfile_content = self._generate_dockerfile(base_image, layers)\n\n        # Create dockerfile in the same directory of the layer cache\n        dockerfile_name = \"dockerfile_\" + str(uuid.uuid4())\n        full_dockerfile_path = Path(self.layer_downloader.layer_cache, dockerfile_name)\n\n        try:\n            with open(str(full_dockerfile_path), \"w\") as dockerfile:\n                dockerfile.write(dockerfile_content)\n\n            tar_paths = {str(full_dockerfile_path): \"Dockerfile\"}\n            for layer in layers:\n                tar_paths[layer.codeuri] = '/' + layer.name\n\n            with create_tarball(tar_paths) as tarballfile:\n                try:\n                    self.docker_client.images.build(fileobj=tarballfile,\n                                                    custom_context=True,\n                                                    rm=True,\n                                                    tag=docker_tag,\n                                                    pull=not self.skip_pull_image)\n                except (docker.errors.BuildError, docker.errors.APIError):\n                    LOG.exception(\"Failed to build Docker Image\")\n                    raise ImageBuildException(\"Building Image failed.\")\n        finally:\n            if full_dockerfile_path.exists():\n                full_dockerfile_path.unlink()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the Dockerfile contents for the new image and list of layers", "response": "def _generate_dockerfile(base_image, layers):\n        \"\"\"\n        Generate the Dockerfile contents\n\n        A generated Dockerfile will look like the following:\n        ```\n        FROM lambci/lambda:python3.6\n\n        ADD --chown=sbx_user1051:495 layer1 /opt\n        ADD --chown=sbx_user1051:495 layer2 /opt\n        ```\n\n        Parameters\n        ----------\n        base_image str\n            Base Image to use for the new image\n        layers list(samcli.commands.local.lib.provider.Layer)\n            List of Layers to be use to mount in the image\n\n        Returns\n        -------\n        str\n            String representing the Dockerfile contents for the image\n\n        \"\"\"\n        dockerfile_content = \"FROM {}\\n\".format(base_image)\n\n        for layer in layers:\n            dockerfile_content = dockerfile_content + \\\n                                 \"ADD --chown=sbx_user1051:495 {} {}\\n\".format(layer.name, LambdaImage._LAYERS_DIR)\n        return dockerfile_content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n\n        routing_list = self._make_routing_list(self.api_provider)\n\n        if not routing_list:\n            raise NoApisDefined(\"No APIs available in SAM template\")\n\n        static_dir_path = self._make_static_dir_path(self.cwd, self.static_dir)\n\n        # We care about passing only stderr to the Service and not stdout because stdout from Docker container\n        # contains the response to the API which is sent out as HTTP response. Only stderr needs to be printed\n        # to the console or a log file. stderr from Docker container contains runtime logs and output of print\n        # statements from the Lambda function\n        service = LocalApigwService(routing_list=routing_list,\n                                    lambda_runner=self.lambda_runner,\n                                    static_dir=static_dir_path,\n                                    port=self.port,\n                                    host=self.host,\n                                    stderr=self.stderr_stream)\n\n        service.create()\n\n        # Print out the list of routes that will be mounted\n        self._print_routes(self.api_provider, self.host, self.port)\n        LOG.info(\"You can now browse to the above endpoints to invoke your functions. \"\n                 \"You do not need to restart/reload SAM CLI while working on your functions, \"\n                 \"changes will be reflected instantly/automatically. You only need to restart \"\n                 \"SAM CLI if you update your AWS SAM template\")\n\n        service.run()", "response": "Creates and starts the local API Gateway service."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of routes to configure the Local API Service based on the APIs configured in the template.", "response": "def _make_routing_list(api_provider):\n        \"\"\"\n        Returns a list of routes to configure the Local API Service based on the APIs configured in the template.\n\n        Parameters\n        ----------\n        api_provider : samcli.commands.local.lib.sam_api_provider.SamApiProvider\n\n        Returns\n        -------\n        list(samcli.local.apigw.service.Route)\n            List of Routes to pass to the service\n        \"\"\"\n\n        routes = []\n        for api in api_provider.get_all():\n            route = Route(methods=[api.method], function_name=api.function_name, path=api.path,\n                          binary_types=api.binary_media_types)\n            routes.append(route)\n\n        return routes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Flask Application that can be started.", "response": "def create(self):\n        \"\"\"\n        Creates a Flask Application that can be started.\n        \"\"\"\n        self._app = Flask(__name__)\n\n        path = '/2015-03-31/functions/<function_name>/invocations'\n        self._app.add_url_rule(path,\n                               endpoint=path,\n                               view_func=self._invoke_request_handler,\n                               methods=['POST'],\n                               provide_automatic_options=False)\n\n        # setup request validation before Flask calls the view_func\n        self._app.before_request(LocalLambdaInvokeService.validate_request)\n\n        self._construct_error_handling()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the incoming request and returns a flask. Response object with the result of the validation.", "response": "def validate_request():\n        \"\"\"\n        Validates the incoming request\n\n        The following are invalid\n            1. The Request data is not json serializable\n            2. Query Parameters are sent to the endpoint\n            3. The Request Content-Type is not application/json\n            4. 'X-Amz-Log-Type' header is not 'None'\n            5. 'X-Amz-Invocation-Type' header is not 'RequestResponse'\n\n        Returns\n        -------\n        flask.Response\n            If the request is not valid a flask Response is returned\n\n        None:\n            If the request passes all validation\n        \"\"\"\n        flask_request = request\n        request_data = flask_request.get_data()\n\n        if not request_data:\n            request_data = b'{}'\n\n        request_data = request_data.decode('utf-8')\n\n        try:\n            json.loads(request_data)\n        except ValueError as json_error:\n            LOG.debug(\"Request body was not json. Exception: %s\", str(json_error))\n            return LambdaErrorResponses.invalid_request_content(\n                \"Could not parse request body into json: No JSON object could be decoded\")\n\n        if flask_request.args:\n            LOG.debug(\"Query parameters are in the request but not supported\")\n            return LambdaErrorResponses.invalid_request_content(\"Query Parameters are not supported\")\n\n        request_headers = CaseInsensitiveDict(flask_request.headers)\n\n        log_type = request_headers.get('X-Amz-Log-Type', 'None')\n        if log_type != 'None':\n            LOG.debug(\"log-type: %s is not supported. None is only supported.\", log_type)\n            return LambdaErrorResponses.not_implemented_locally(\n                \"log-type: {} is not supported. None is only supported.\".format(log_type))\n\n        invocation_type = request_headers.get('X-Amz-Invocation-Type', 'RequestResponse')\n        if invocation_type != 'RequestResponse':\n            LOG.warning(\"invocation-type: %s is not supported. RequestResponse is only supported.\", invocation_type)\n            return LambdaErrorResponses.not_implemented_locally(\n                \"invocation-type: {} is not supported. RequestResponse is only supported.\".format(invocation_type))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing the error handling handlers for different error codes", "response": "def _construct_error_handling(self):\n        \"\"\"\n        Updates the Flask app with Error Handlers for different Error Codes\n\n        \"\"\"\n        self._app.register_error_handler(500, LambdaErrorResponses.generic_service_exception)\n        self._app.register_error_handler(404, LambdaErrorResponses.generic_path_not_found)\n        self._app.register_error_handler(405, LambdaErrorResponses.generic_method_not_allowed)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _invoke_request_handler(self, function_name):\n        flask_request = request\n\n        request_data = flask_request.get_data()\n\n        if not request_data:\n            request_data = b'{}'\n\n        request_data = request_data.decode('utf-8')\n\n        stdout_stream = io.BytesIO()\n        stdout_stream_writer = StreamWriter(stdout_stream, self.is_debugging)\n\n        try:\n            self.lambda_runner.invoke(function_name, request_data, stdout=stdout_stream_writer, stderr=self.stderr)\n        except FunctionNotFound:\n            LOG.debug('%s was not found to invoke.', function_name)\n            return LambdaErrorResponses.resource_not_found(function_name)\n\n        lambda_response, lambda_logs, is_lambda_user_error_response = \\\n            LambdaOutputParser.get_lambda_output(stdout_stream)\n\n        if self.stderr and lambda_logs:\n            # Write the logs to stderr if available.\n            self.stderr.write(lambda_logs)\n\n        if is_lambda_user_error_response:\n            return self.service_response(lambda_response,\n                                         {'Content-Type': 'application/json', 'x-amz-function-error': 'Unhandled'},\n                                         200)\n\n        return self.service_response(lambda_response, {'Content-Type': 'application/json'}, 200)", "response": "This method is responsible for understanding the incoming lambda request and invoking the Local Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunzips the given file into the given directory.", "response": "def unzip(zip_file_path, output_dir, permission=None):\n    \"\"\"\n    Unzip the given file into the given directory while preserving file permissions in the process.\n\n    Parameters\n    ----------\n    zip_file_path : str\n        Path to the zip file\n\n    output_dir : str\n        Path to the directory where the it should be unzipped to\n\n    permission : octal int\n        Permission to set\n    \"\"\"\n\n    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n\n        # For each item in the zip file, extract the file and set permissions if available\n        for file_info in zip_ref.infolist():\n            name = file_info.filename\n            extracted_path = os.path.join(output_dir, name)\n\n            zip_ref.extract(name, output_dir)\n            _set_permissions(file_info, extracted_path)\n\n            _override_permissions(extracted_path, permission)\n\n    _override_permissions(output_dir, permission)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets permissions on the extracted file by reading the external_attr property of the zip file info.", "response": "def _set_permissions(zip_file_info, extracted_path):\n    \"\"\"\n    Sets permissions on the extracted file by reading the ``external_attr`` property of given file info.\n\n    Parameters\n    ----------\n    zip_file_info : zipfile.ZipInfo\n        Object containing information about a file within a zip archive\n\n    extracted_path : str\n        Path where the file has been extracted to\n    \"\"\"\n\n    # Permission information is stored in first two bytes.\n    permission = zip_file_info.external_attr >> 16\n    if not permission:\n        # Zips created on certain Windows machines, however, might not have any permission information on them.\n        # Skip setting a permission on these files.\n        LOG.debug(\"File %s in zipfile does not have permission information\", zip_file_info.filename)\n        return\n\n    os.chmod(extracted_path, permission)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unzip_from_uri(uri, layer_zip_path, unzip_output_dir, progressbar_label):\n    try:\n        get_request = requests.get(uri, stream=True, verify=os.environ.get('AWS_CA_BUNDLE', True))\n\n        with open(layer_zip_path, 'wb') as local_layer_file:\n            file_length = int(get_request.headers['Content-length'])\n\n            with progressbar(file_length, progressbar_label) as p_bar:\n                # Set the chunk size to None. Since we are streaming the request, None will allow the data to be\n                # read as it arrives in whatever size the chunks are received.\n                for data in get_request.iter_content(chunk_size=None):\n                    local_layer_file.write(data)\n                    p_bar.update(len(data))\n\n        # Forcefully set the permissions to 700 on files and directories. This is to ensure the owner\n        # of the files is the only one that can read, write, or execute the files.\n        unzip(layer_zip_path, unzip_output_dir, permission=0o700)\n\n    finally:\n        # Remove the downloaded zip file\n        path_to_layer = Path(layer_zip_path)\n        if path_to_layer.exists():\n            path_to_layer.unlink()", "response": "Download the LayerVersion Zip from the LayerVersion Zip to the Layer Pkg Cache\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self):\n\n        self._app = Flask(__name__,\n                          static_url_path=\"\",  # Mount static files at root '/'\n                          static_folder=self.static_dir  # Serve static files from this directory\n                          )\n\n        for api_gateway_route in self.routing_list:\n            path = PathConverter.convert_path_to_flask(api_gateway_route.path)\n            for route_key in self._generate_route_keys(api_gateway_route.methods,\n                                                       path):\n                self._dict_of_routes[route_key] = api_gateway_route\n\n            self._app.add_url_rule(path,\n                                   endpoint=path,\n                                   view_func=self._request_handler,\n                                   methods=api_gateway_route.methods,\n                                   provide_automatic_options=False)\n\n        self._construct_error_handling()", "response": "Creates a Flask application that can be started."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the key to the _dict_of_routes based on the list of HTTP Methods and path", "response": "def _generate_route_keys(self, methods, path):\n        \"\"\"\n        Generates the key to the _dict_of_routes based on the list of methods\n        and path supplied\n\n        :param list(str) methods: List of HTTP Methods\n        :param str path: Path off the base url\n        :return: str of Path:Method\n        \"\"\"\n        for method in methods:\n            yield self._route_key(method, path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing the error handling handlers for different Error Codes", "response": "def _construct_error_handling(self):\n        \"\"\"\n        Updates the Flask app with Error Handlers for different Error Codes\n        \"\"\"\n        # Both path and method not present\n        self._app.register_error_handler(404, ServiceErrorResponses.route_not_found)\n        # Path is present, but method not allowed\n        self._app.register_error_handler(405, ServiceErrorResponses.route_not_found)\n        # Something went wrong\n        self._app.register_error_handler(500, ServiceErrorResponses.lambda_failure_response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _request_handler(self, **kwargs):\n        route = self._get_current_route(request)\n\n        try:\n            event = self._construct_event(request, self.port, route.binary_types)\n        except UnicodeDecodeError:\n            return ServiceErrorResponses.lambda_failure_response()\n\n        stdout_stream = io.BytesIO()\n        stdout_stream_writer = StreamWriter(stdout_stream, self.is_debugging)\n\n        try:\n            self.lambda_runner.invoke(route.function_name, event, stdout=stdout_stream_writer, stderr=self.stderr)\n        except FunctionNotFound:\n            return ServiceErrorResponses.lambda_not_found_response()\n\n        lambda_response, lambda_logs, _ = LambdaOutputParser.get_lambda_output(stdout_stream)\n\n        if self.stderr and lambda_logs:\n            # Write the logs to stderr if available.\n            self.stderr.write(lambda_logs)\n\n        try:\n            (status_code, headers, body) = self._parse_lambda_output(lambda_response,\n                                                                     route.binary_types,\n                                                                     request)\n        except (KeyError, TypeError, ValueError):\n            LOG.error(\"Function returned an invalid response (must include one of: body, headers or \"\n                      \"statusCode in the response object). Response received: %s\", lambda_response)\n            return ServiceErrorResponses.lambda_failure_response()\n\n        return self.service_response(body, headers, status_code)", "response": "This function is called by the request handler method. It handles all requests and returns a dict containing the service - level attributes that are passed to the handler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_current_route(self, flask_request):\n        endpoint = flask_request.endpoint\n        method = flask_request.method\n\n        route_key = self._route_key(method, endpoint)\n        route = self._dict_of_routes.get(route_key, None)\n\n        if not route:\n            LOG.debug(\"Lambda function for the route not found. This should not happen because Flask is \"\n                      \"already configured to serve all path/methods given to the service. \"\n                      \"Path=%s Method=%s RouteKey=%s\", endpoint, method, route_key)\n            raise KeyError(\"Lambda function for the route not found\")\n\n        return route", "response": "Get the route based on the current request and the current route key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the output from the Lambda Invoke API call and returns the status code headers and body.", "response": "def _parse_lambda_output(lambda_output, binary_types, flask_request):\n        \"\"\"\n        Parses the output from the Lambda Container\n\n        :param str lambda_output: Output from Lambda Invoke\n        :return: Tuple(int, dict, str, bool)\n        \"\"\"\n        json_output = json.loads(lambda_output)\n\n        if not isinstance(json_output, dict):\n            raise TypeError(\"Lambda returned %{s} instead of dict\", type(json_output))\n\n        status_code = json_output.get(\"statusCode\") or 200\n        headers = CaseInsensitiveDict(json_output.get(\"headers\") or {})\n        body = json_output.get(\"body\") or \"no data\"\n        is_base_64_encoded = json_output.get(\"isBase64Encoded\") or False\n\n        try:\n            status_code = int(status_code)\n            if status_code <= 0:\n                raise ValueError\n        except ValueError:\n            message = \"statusCode must be a positive int\"\n            LOG.error(message)\n            raise TypeError(message)\n\n        # If the customer doesn't define Content-Type default to application/json\n        if \"Content-Type\" not in headers:\n            LOG.info(\"No Content-Type given. Defaulting to 'application/json'.\")\n            headers[\"Content-Type\"] = \"application/json\"\n\n        if LocalApigwService._should_base64_decode_body(binary_types, flask_request, headers, is_base_64_encoded):\n            body = base64.b64decode(body)\n\n        return status_code, headers, body"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _should_base64_decode_body(binary_types, flask_request, lamba_response_headers, is_base_64_encoded):\n        best_match_mimetype = flask_request.accept_mimetypes.best_match([lamba_response_headers[\"Content-Type\"]])\n        is_best_match_in_binary_types = best_match_mimetype in binary_types or '*/*' in binary_types\n\n        return best_match_mimetype and is_best_match_in_binary_types and is_base_64_encoded", "response": "Returns True if the body should be decoded from Base64 to Binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct_event(flask_request, port, binary_types):\n\n        identity = ContextIdentity(source_ip=flask_request.remote_addr)\n\n        endpoint = PathConverter.convert_path_to_api_gateway(flask_request.endpoint)\n        method = flask_request.method\n\n        request_data = flask_request.get_data()\n\n        request_mimetype = flask_request.mimetype\n\n        is_base_64 = LocalApigwService._should_base64_encode(binary_types, request_mimetype)\n\n        if is_base_64:\n            LOG.debug(\"Incoming Request seems to be binary. Base64 encoding the request data before sending to Lambda.\")\n            request_data = base64.b64encode(request_data)\n\n        if request_data:\n            # Flask does not parse/decode the request data. We should do it ourselves\n            request_data = request_data.decode('utf-8')\n\n        context = RequestContext(resource_path=endpoint,\n                                 http_method=method,\n                                 stage=\"prod\",\n                                 identity=identity,\n                                 path=endpoint)\n\n        event_headers = dict(flask_request.headers)\n        event_headers[\"X-Forwarded-Proto\"] = flask_request.scheme\n        event_headers[\"X-Forwarded-Port\"] = str(port)\n\n        # APIGW does not support duplicate query parameters. Flask gives query params as a list so\n        # we need to convert only grab the first item unless many were given, were we grab the last to be consistent\n        # with APIGW\n        query_string_dict = LocalApigwService._query_string_params(flask_request)\n\n        event = ApiGatewayLambdaEvent(http_method=method,\n                                      body=request_data,\n                                      resource=endpoint,\n                                      request_context=context,\n                                      query_string_params=query_string_dict,\n                                      headers=event_headers,\n                                      path_parameters=flask_request.view_args,\n                                      path=flask_request.path,\n                                      is_base_64_encoded=is_base_64)\n\n        event_str = json.dumps(event.to_dict())\n        LOG.debug(\"Constructed String representation of Event to invoke Lambda. Event: %s\", event_str)\n        return event_str", "response": "Helper method that constructs the Event to be passed to Lambda."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _query_string_params(flask_request):\n        query_string_dict = {}\n\n        # Flask returns an ImmutableMultiDict so convert to a dictionary that becomes\n        # a dict(str: list) then iterate over\n        for query_string_key, query_string_list in flask_request.args.lists():\n            query_string_value_length = len(query_string_list)\n\n            # if the list is empty, default to empty string\n            if not query_string_value_length:\n                query_string_dict[query_string_key] = \"\"\n            else:\n                # APIGW doesn't handle duplicate query string keys, picking the last one in the list\n                query_string_dict[query_string_key] = query_string_list[-1]\n\n        return query_string_dict", "response": "Constructs an APIGW equivalent query string dictionary from flask_request. args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invoke(self, function_name, event, stdout=None, stderr=None):\n\n        # Generate the correct configuration based on given inputs\n        function = self.provider.get(function_name)\n\n        if not function:\n            all_functions = [f.name for f in self.provider.get_all()]\n            available_function_message = \"{} not found. Possible options in your template: {}\"\\\n                .format(function_name, all_functions)\n            LOG.info(available_function_message)\n            raise FunctionNotFound(\"Unable to find a Function with name '%s'\", function_name)\n\n        LOG.debug(\"Found one Lambda function with name '%s'\", function_name)\n\n        LOG.info(\"Invoking %s (%s)\", function.handler, function.runtime)\n        config = self._get_invoke_config(function)\n\n        # Invoke the function\n        self.local_runtime.invoke(config, event, debug_context=self.debug_context, stdout=stdout, stderr=stderr)", "response": "Invoke the Lambda function with given name and return the result of the Lambda function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_invoke_config(self, function):\n\n        env_vars = self._make_env_vars(function)\n        code_abs_path = resolve_code_path(self.cwd, function.codeuri)\n\n        LOG.debug(\"Resolved absolute path to code is %s\", code_abs_path)\n\n        function_timeout = function.timeout\n\n        # The Runtime container handles timeout inside the container. When debugging with short timeouts, this can\n        # cause the container execution to stop. When in debug mode, we set the timeout in the container to a max 10\n        # hours. This will ensure the container doesn't unexpectedly stop while debugging function code\n        if self.is_debugging():\n            function_timeout = self.MAX_DEBUG_TIMEOUT\n\n        return FunctionConfig(name=function.name,\n                              runtime=function.runtime,\n                              handler=function.handler,\n                              code_abs_path=code_abs_path,\n                              layers=function.layers,\n                              memory=function.memory,\n                              timeout=function_timeout,\n                              env_vars=env_vars)", "response": "Returns the invoke configuration for the given Lambda function"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_env_vars(self, function):\n\n        name = function.name\n\n        variables = None\n        if function.environment and isinstance(function.environment, dict) and \"Variables\" in function.environment:\n            variables = function.environment[\"Variables\"]\n        else:\n            LOG.debug(\"No environment variables found for function '%s'\", name)\n\n        # This could either be in standard format, or a CloudFormation parameter file format.\n        #\n        # Standard format is {FunctionName: {key:value}, FunctionName: {key:value}}\n        # CloudFormation parameter file is {\"Parameters\": {key:value}}\n\n        for env_var_value in self.env_vars_values.values():\n            if not isinstance(env_var_value, dict):\n                reason = \"\"\"\n                            Environment variables must be in either CloudFormation parameter file\n                            format or in {FunctionName: {key:value}} JSON pairs\n                            \"\"\"\n                LOG.debug(reason)\n                raise OverridesNotWellDefinedError(reason)\n\n        if \"Parameters\" in self.env_vars_values:\n            LOG.debug(\"Environment variables overrides data is in CloudFormation parameter file format\")\n            # CloudFormation parameter file format\n            overrides = self.env_vars_values[\"Parameters\"]\n        else:\n            # Standard format\n            LOG.debug(\"Environment variables overrides data is standard format\")\n            overrides = self.env_vars_values.get(name, None)\n\n        shell_env = os.environ\n        aws_creds = self.get_aws_creds()\n\n        return EnvironmentVariables(function.memory,\n                                    function.timeout,\n                                    function.handler,\n                                    variables=variables,\n                                    shell_env_values=shell_env,\n                                    override_values=overrides,\n                                    aws_creds=aws_creds)", "response": "Returns the environment variables configuration for this Lambda function"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the AWS credentials obtained from the shell environment or given profile", "response": "def get_aws_creds(self):\n        \"\"\"\n        Returns AWS credentials obtained from the shell environment or given profile\n\n        :return dict: A dictionary containing credentials. This dict has the structure\n             {\"region\": \"\", \"key\": \"\", \"secret\": \"\", \"sessiontoken\": \"\"}. If credentials could not be resolved,\n             this returns None\n        \"\"\"\n        result = {}\n\n        # to pass command line arguments for region & profile to setup boto3 default session\n        if boto3.DEFAULT_SESSION:\n            session = boto3.DEFAULT_SESSION\n        else:\n            session = boto3.session.Session()\n\n        profile_name = session.profile_name if session else None\n        LOG.debug(\"Loading AWS credentials from session with profile '%s'\", profile_name)\n\n        if not session:\n            return result\n\n        # Load the credentials from profile/environment\n        creds = session.get_credentials()\n\n        if not creds:\n            # If we were unable to load credentials, then just return empty. We will use the default\n            return result\n\n        # After loading credentials, region name might be available here.\n        if hasattr(session, 'region_name') and session.region_name:\n            result[\"region\"] = session.region_name\n\n        # Only add the key, if its value is present\n        if hasattr(creds, 'access_key') and creds.access_key:\n            result[\"key\"] = creds.access_key\n\n        if hasattr(creds, 'secret_key') and creds.secret_key:\n            result[\"secret\"] = creds.secret_key\n\n        if hasattr(creds, 'token') and creds.token:\n            result[\"sessiontoken\"] = creds.token\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a dictionary representation of the Identity Object to be used in serializing to JSON", "response": "def to_dict(self):\n        \"\"\"\n        Constructs an dictionary representation of the Identity Object to be used in serializing to JSON\n\n        :return: dict representing the object\n        \"\"\"\n        json_dict = {\"apiKey\": self.api_key,\n                     \"userArn\": self.user_arn,\n                     \"cognitoAuthenticationType\": self.cognito_authentication_type,\n                     \"caller\": self.caller,\n                     \"userAgent\": self.user_agent,\n                     \"user\": self.user,\n                     \"cognitoIdentityPoolId\": self.cognito_identity_pool_id,\n                     \"cognitoAuthenticationProvider\": self.cognito_authentication_provider,\n                     \"sourceIp\": self.source_ip,\n                     \"accountId\": self.account_id\n                     }\n\n        return json_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a dictionary representation of the RequestContext Object to be used in serializing to JSON", "response": "def to_dict(self):\n        \"\"\"\n        Constructs an dictionary representation of the RequestContext Object to be used in serializing to JSON\n\n        :return: dict representing the object\n        \"\"\"\n        identity_dict = {}\n        if self.identity:\n            identity_dict = self.identity.to_dict()\n\n        json_dict = {\"resourceId\": self.resource_id,\n                     \"apiId\": self.api_id,\n                     \"resourcePath\": self.resource_path,\n                     \"httpMethod\": self.http_method,\n                     \"requestId\": self.request_id,\n                     \"accountId\": self.account_id,\n                     \"stage\": self.stage,\n                     \"identity\": identity_dict,\n                     \"extendedRequestId\": self.extended_request_id,\n                     \"path\": self.path\n                     }\n\n        return json_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        request_context_dict = {}\n        if self.request_context:\n            request_context_dict = self.request_context.to_dict()\n\n        json_dict = {\"httpMethod\": self.http_method,\n                     \"body\": self.body if self.body else None,\n                     \"resource\": self.resource,\n                     \"requestContext\": request_context_dict,\n                     \"queryStringParameters\": dict(self.query_string_params) if self.query_string_params else None,\n                     \"headers\": dict(self.headers) if self.headers else None,\n                     \"pathParameters\": dict(self.path_parameters) if self.path_parameters else None,\n                     \"stageVariables\": dict(self.stage_variables) if self.stage_variables else None,\n                     \"path\": self.path,\n                     \"isBase64Encoded\": self.is_base_64_encoded\n                     }\n\n        return json_dict", "response": "Constructs a dictionary representation of the ApiGatewayLambdaEvent Object to be used in serializing to JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if Docker daemon is available and if it is available.", "response": "def is_docker_reachable(self):\n        \"\"\"\n        Checks if Docker daemon is running. This is required for us to invoke the function locally\n\n        Returns\n        -------\n        bool\n            True, if Docker is available, False otherwise\n        \"\"\"\n        try:\n            self.docker_client.ping()\n\n            return True\n\n        # When Docker is not installed, a request.exceptions.ConnectionError is thrown.\n        except (docker.errors.APIError, requests.exceptions.ConnectionError):\n            LOG.debug(\"Docker is not reachable\", exc_info=True)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and run a Docker container based on the given configuration.", "response": "def run(self, container, input_data=None, warm=False):\n        \"\"\"\n        Create and run a Docker container based on the given configuration.\n\n        :param samcli.local.docker.container.Container container: Container to create and run\n        :param input_data: Optional. Input data sent to the container through container's stdin.\n        :param bool warm: Indicates if an existing container can be reused. Defaults False ie. a new container will\n            be created for every request.\n        :raises DockerImagePullFailedException: If the Docker image was not available in the server\n        \"\"\"\n\n        if warm:\n            raise ValueError(\"The facility to invoke warm container does not exist\")\n\n        image_name = container.image\n\n        is_image_local = self.has_image(image_name)\n\n        # Skip Pulling a new image if: a) Image name is samcli/lambda OR b) Image is available AND\n        # c) We are asked to skip pulling the image\n        if (is_image_local and self.skip_pull_image) or image_name.startswith('samcli/lambda'):\n            LOG.info(\"Requested to skip pulling images ...\\n\")\n        else:\n            try:\n                self.pull_image(image_name)\n            except DockerImagePullFailedException:\n                if not is_image_local:\n                    raise DockerImagePullFailedException(\n                        \"Could not find {} image locally and failed to pull it from docker.\".format(image_name))\n\n                LOG.info(\n                    \"Failed to download a new %s image. Invoking with the already downloaded image.\", image_name)\n\n        if not container.is_created():\n            # Create the container first before running.\n            # Create the container in appropriate Docker network\n            container.network_id = self.docker_network_id\n            container.create()\n\n        container.start(input_data=input_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pull_image(self, image_name, stream=None):\n        stream_writer = stream or StreamWriter(sys.stderr)\n\n        try:\n            result_itr = self.docker_client.api.pull(image_name, stream=True, decode=True)\n        except docker.errors.APIError as ex:\n            LOG.debug(\"Failed to download image with name %s\", image_name)\n            raise DockerImagePullFailedException(str(ex))\n\n        # io streams, especially StringIO, work only with unicode strings\n        stream_writer.write(u\"\\nFetching {} Docker container image...\".format(image_name))\n\n        # Each line contains information on progress of the pull. Each line is a JSON string\n        for _ in result_itr:\n            # For every line, print a dot to show progress\n            stream_writer.write(u'.')\n            stream_writer.flush()\n\n        # We are done. Go to the next line\n        stream_writer.write(u\"\\n\")", "response": "Ask Docker to pull the container image with given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_image(self, image_name):\n\n        try:\n            self.docker_client.images.get(image_name)\n            return True\n        except docker.errors.ImageNotFound:\n            return False", "response": "Check if the image with given name exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish the application based on command line inputs.", "response": "def do_cli(ctx, template, semantic_version):\n    \"\"\"Publish the application based on command line inputs.\"\"\"\n    try:\n        template_data = get_template_data(template)\n    except ValueError as ex:\n        click.secho(\"Publish Failed\", fg='red')\n        raise UserException(str(ex))\n\n    # Override SemanticVersion in template metadata when provided in command input\n    if semantic_version and SERVERLESS_REPO_APPLICATION in template_data.get(METADATA, {}):\n        template_data.get(METADATA).get(SERVERLESS_REPO_APPLICATION)[SEMANTIC_VERSION] = semantic_version\n\n    try:\n        publish_output = publish_application(template_data)\n        click.secho(\"Publish Succeeded\", fg=\"green\")\n        click.secho(_gen_success_message(publish_output))\n    except InvalidS3UriError:\n        click.secho(\"Publish Failed\", fg='red')\n        raise UserException(\n            \"Your SAM template contains invalid S3 URIs. Please make sure that you have uploaded application \"\n            \"artifacts to S3 by packaging the template. See more details in {}\".format(SAM_PACKAGE_DOC))\n    except ServerlessRepoError as ex:\n        click.secho(\"Publish Failed\", fg='red')\n        LOG.debug(\"Failed to publish application to serverlessrepo\", exc_info=True)\n        error_msg = '{}\\nPlease follow the instructions in {}'.format(str(ex), SAM_PUBLISH_DOC)\n        raise UserException(error_msg)\n\n    application_id = publish_output.get('application_id')\n    _print_console_link(ctx.region, application_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate detailed success message for published applications.", "response": "def _gen_success_message(publish_output):\n    \"\"\"\n    Generate detailed success message for published applications.\n\n    Parameters\n    ----------\n    publish_output : dict\n        Output from serverlessrepo publish_application\n\n    Returns\n    -------\n    str\n        Detailed success message\n    \"\"\"\n    application_id = publish_output.get('application_id')\n    details = json.dumps(publish_output.get('details'), indent=2)\n\n    if CREATE_APPLICATION in publish_output.get('actions'):\n        return \"Created new application with the following metadata:\\n{}\".format(details)\n\n    return 'The following metadata of application \"{}\" has been updated:\\n{}'.format(application_id, details)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting link for the application in AWS Serverless Application Repository console.", "response": "def _print_console_link(region, application_id):\n    \"\"\"\n    Print link for the application in AWS Serverless Application Repository console.\n\n    Parameters\n    ----------\n    region : str\n        AWS region name\n    application_id : str\n        The Amazon Resource Name (ARN) of the application\n\n    \"\"\"\n    if not region:\n        region = boto3.Session().region_name\n\n    console_link = SERVERLESSREPO_CONSOLE_URL.format(region, application_id.replace('/', '~'))\n    msg = \"Click the link below to view your application in AWS console:\\n{}\".format(console_link)\n    click.secho(msg, fg=\"yellow\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a Flask Response for when a Lambda function is not found for an endpoint.", "response": "def lambda_not_found_response(*args):\n        \"\"\"\n        Constructs a Flask Response for when a Lambda function is not found for an endpoint\n\n        :return: a Flask Response\n        \"\"\"\n        response_data = jsonify(ServiceErrorResponses._NO_LAMBDA_INTEGRATION)\n        return make_response(response_data, ServiceErrorResponses.HTTP_STATUS_CODE_502)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a Flask Response for when a API Route is not found.", "response": "def route_not_found(*args):\n        \"\"\"\n        Constructs a Flask Response for when a API Route (path+method) is not found. This is usually\n        HTTP 404 but with API Gateway this is a HTTP 403 (https://forums.aws.amazon.com/thread.jspa?threadID=2166840)\n\n        :return: a Flask Response\n        \"\"\"\n        response_data = jsonify(ServiceErrorResponses._MISSING_AUTHENTICATION)\n        return make_response(response_data, ServiceErrorResponses.HTTP_STATUS_CODE_403)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef progressbar(length, label):\n    return click.progressbar(length=length, label=label, show_pos=True)", "response": "Returns a progressbar that shows the length and label of the base tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _unquote(value):\n        if value and (value[0] == value[-1] == '\"'):\n            # Remove quotes only if the string is wrapped in quotes\n            value = value.strip('\"')\n\n        return value.replace(\"\\\\ \", \" \").replace('\\\\\"', '\"')", "response": "r Unquotes double quotes and any \\ spaces characters in the input string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        if not self._app:\n            raise RuntimeError(\"The application must be created before running\")\n\n        # Flask can operate as a single threaded server (which is default) and a multi-threaded server which is\n        # more for development. When the Lambda container is going to be debugged, then it does not make sense\n        # to turn on multi-threading because customers can realistically attach only one container at a time to\n        # the debugger. Keeping this single threaded also enables the Lambda Runner to handle Ctrl+C in order to\n        # kill the container gracefully (Ctrl+C can be handled only by the main thread)\n        multi_threaded = not self.is_debugging\n\n        LOG.debug(\"Localhost server is starting up. Multi-threading = %s\", multi_threaded)\n\n        # This environ signifies we are running a main function for Flask. This is true, since we are using it within\n        # our cli and not on a production server.\n        os.environ['WERKZEUG_RUN_MAIN'] = 'true'\n\n        self._app.run(threaded=multi_threaded, host=self.host, port=self.port)", "response": "This starts up the local server and runs the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef service_response(body, headers, status_code):\n        response = Response(body)\n        response.headers = headers\n        response.status_code = status_code\n        return response", "response": "Constructs a Flask Response from the body headers and status_code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_lambda_output(stdout_stream):\n        # We only want the last line of stdout, because it's possible that\n        # the function may have written directly to stdout using\n        # System.out.println or similar, before docker-lambda output the result\n        stdout_data = stdout_stream.getvalue().rstrip(b'\\n')\n\n        # Usually the output is just one line and contains response as JSON string, but if the Lambda function\n        # wrote anything directly to stdout, there will be additional lines. So just extract the last line as\n        # response and everything else as log output.\n        lambda_response = stdout_data\n        lambda_logs = None\n\n        last_line_position = stdout_data.rfind(b'\\n')\n        if last_line_position >= 0:\n            # So there are multiple lines. Separate them out.\n            # Everything but the last line are logs\n            lambda_logs = stdout_data[:last_line_position]\n            # Last line is Lambda response. Make sure to strip() so we get rid of extra whitespaces & newlines around\n            lambda_response = stdout_data[last_line_position:].strip()\n\n        lambda_response = lambda_response.decode('utf-8')\n\n        # When the Lambda Function returns an Error/Exception, the output is added to the stdout of the container. From\n        # our perspective, the container returned some value, which is not always true. Since the output is the only\n        # information we have, we need to inspect this to understand if the container returned a some data or raised an\n        # error\n        is_lambda_user_error_response = LambdaOutputParser.is_lambda_error_response(lambda_response)\n\n        return lambda_response, lambda_logs, is_lambda_user_error_response", "response": "This method will extract the output from the Lambda function and return the response as JSON string and the error and exception from the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks to see if the response from the Lambda is in the form of an Error or Exception.", "response": "def is_lambda_error_response(lambda_response):\n        \"\"\"\n        Check to see if the output from the container is in the form of an Error/Exception from the Lambda invoke\n\n        Parameters\n        ----------\n        lambda_response str\n            The response the container returned\n\n        Returns\n        -------\n        bool\n            True if the output matches the Error/Exception Dictionary otherwise False\n        \"\"\"\n        is_lambda_user_error_response = False\n        try:\n            lambda_response_dict = json.loads(lambda_response)\n\n            # This is a best effort attempt to determine if the output (lambda_response) from the container was an\n            # Error/Exception that was raised/returned/thrown from the container. To ensure minimal false positives in\n            # this checking, we check for all three keys that can occur in Lambda raised/thrown/returned an\n            # Error/Exception. This still risks false positives when the data returned matches exactly a dictionary with\n            # the keys 'errorMessage', 'errorType' and 'stackTrace'.\n            if isinstance(lambda_response_dict, dict) and \\\n                    len(lambda_response_dict) == 3 and \\\n                    'errorMessage' in lambda_response_dict and \\\n                    'errorType' in lambda_response_dict and \\\n                    'stackTrace' in lambda_response_dict:\n                is_lambda_user_error_response = True\n        except ValueError:\n            # If you can't serialize the output into a dict, then do nothing\n            pass\n        return is_lambda_user_error_response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(self):\n\n        result = {}\n\n        for lambda_function in self._functions_to_build:\n\n            LOG.info(\"Building resource '%s'\", lambda_function.name)\n            result[lambda_function.name] = self._build_function(lambda_function.name,\n                                                                lambda_function.codeuri,\n                                                                lambda_function.runtime)\n\n        return result", "response": "Builds the entire application and returns a dictionary of resource names to their logical IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the template with the codeUris and artifacts that are needed for the template file.", "response": "def update_template(self, template_dict, original_template_path, built_artifacts):\n        \"\"\"\n        Given the path to built artifacts, update the template to point appropriate resource CodeUris to the artifacts\n        folder\n\n        Parameters\n        ----------\n        template_dict\n        original_template_path : str\n            Path where the template file will be written to\n\n        built_artifacts : dict\n            Map of LogicalId of a resource to the path where the the built artifacts for this resource lives\n\n        Returns\n        -------\n        dict\n            Updated template\n        \"\"\"\n\n        original_dir = os.path.dirname(original_template_path)\n\n        for logical_id, resource in template_dict.get(\"Resources\", {}).items():\n\n            if logical_id not in built_artifacts:\n                # this resource was not built. So skip it\n                continue\n\n            # Artifacts are written relative to the template because it makes the template portable\n            #   Ex: A CI/CD pipeline build stage could zip the output folder and pass to a\n            #   package stage running on a different machine\n            artifact_relative_path = os.path.relpath(built_artifacts[logical_id], original_dir)\n\n            resource_type = resource.get(\"Type\")\n            properties = resource.setdefault(\"Properties\", {})\n            if resource_type == \"AWS::Serverless::Function\":\n                properties[\"CodeUri\"] = artifact_relative_path\n\n            if resource_type == \"AWS::Lambda::Function\":\n                properties[\"Code\"] = artifact_relative_path\n\n        return template_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_function(self, function_name, codeuri, runtime):\n\n        # Create the arguments to pass to the builder\n        # Code is always relative to the given base directory.\n        code_dir = str(pathlib.Path(self._base_dir, codeuri).resolve())\n\n        config = get_workflow_config(runtime, code_dir, self._base_dir)\n\n        # artifacts directory will be created by the builder\n        artifacts_dir = str(pathlib.Path(self._build_dir, function_name))\n\n        with osutils.mkdir_temp() as scratch_dir:\n            manifest_path = self._manifest_path_override or os.path.join(code_dir, config.manifest_name)\n\n            # By default prefer to build in-process for speed\n            build_method = self._build_function_in_process\n            if self._container_manager:\n                build_method = self._build_function_on_container\n\n            return build_method(config,\n                                code_dir,\n                                artifacts_dir,\n                                scratch_dir,\n                                manifest_path,\n                                runtime)", "response": "Build the Lambda function given the function information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_container_dirs(source_dir, manifest_dir):\n        base = \"/tmp/samcli\"\n        result = {\n            \"source_dir\": \"{}/source\".format(base),\n            \"artifacts_dir\": \"{}/artifacts\".format(base),\n            \"scratch_dir\": \"{}/scratch\".format(base),\n            \"manifest_dir\": \"{}/manifest\".format(base)\n        }\n\n        if pathlib.PurePath(source_dir) == pathlib.PurePath(manifest_dir):\n            # It is possible that the manifest resides within the source. In that case, we won't mount the manifest\n            # directory separately.\n            result[\"manifest_dir\"] = result[\"source_dir\"]\n\n        return result", "response": "Returns a dictionary containing the paths to directories that are required by the builder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convert_to_container_dirs(host_paths_to_convert, host_to_container_path_mapping):\n\n        if not host_paths_to_convert:\n            # Nothing to do\n            return host_paths_to_convert\n\n        # Make sure the key is absolute host path. Relative paths are tricky to work with because two different\n        # relative paths can point to the same directory (\"../foo\", \"../../foo\")\n        mapping = {str(pathlib.Path(p).resolve()): v for p, v in host_to_container_path_mapping.items()}\n\n        result = []\n        for original_path in host_paths_to_convert:\n            abspath = str(pathlib.Path(original_path).resolve())\n\n            if abspath in mapping:\n                result.append(mapping[abspath])\n            else:\n                result.append(original_path)\n                LOG.debug(\"Cannot convert host path '%s' to its equivalent path within the container. \"\n                          \"Host path is not mounted within the container\", abspath)\n\n        return result", "response": "Convert a list of host paths to a list of equivalent paths within the container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __translate(self, parameter_values):\n\n        template_copy = self.template\n\n        sam_parser = Parser()\n        sam_translator = Translator(managed_policy_map=self.__managed_policy_map(),\n                                    sam_parser=sam_parser,\n                                    # Default plugins are already initialized within the Translator\n                                    plugins=self.extra_plugins)\n\n        return sam_translator.translate(sam_template=template_copy,\n                                        parameter_values=parameter_values)", "response": "This method is used to translate the SAM template into a new SAM template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict of managed policies and their local names.", "response": "def __managed_policy_map(self):\n        \"\"\"\n        This method is unused and a Work In Progress\n        \"\"\"\n        try:\n            iam_client = boto3.client('iam')\n            return ManagedPolicyLoader(iam_client).load()\n        except Exception as ex:\n\n            if self._offline_fallback:\n                # If offline flag is set, then fall back to the list of default managed policies\n                # This should be sufficient for most cases\n                with open(self._DEFAULT_MANAGED_POLICIES_FILE, 'r') as fp:\n                    return json.load(fp)\n\n            # Offline is not enabled. So just raise the exception\n            raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate(self, sam_template):\n\n        if \"Resources\" not in sam_template or not isinstance(sam_template[\"Resources\"], dict) \\\n                or not sam_template[\"Resources\"]:\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\"'Resources' section is required\")])\n\n        SamTemplateValidator.validate(sam_template)", "response": "Validates the SAM template and parameter values and raises exceptions if there s an issue"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_command(self, ctx, cmd_name):\n\n        if cmd_name not in self.all_cmds:\n            return None\n        return EventTypeSubCommand(self.events_lib, cmd_name, self.all_cmds[cmd_name])", "response": "Returns the command object for the given command name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_command(self, ctx, cmd_name):\n\n        \"\"\"\n        gets the Click Commands underneath a service name\n\n        Parameters\n        ----------\n        ctx: Context\n            context object passed in\n        cmd_name: string\n            the service name\n        Returns\n        -------\n        cmd: Click.Command\n            the Click Commands that can be called from the CLI\n        \"\"\"\n\n        if cmd_name not in self.subcmd_definition:\n            return None\n        parameters = []\n        for param_name in self.subcmd_definition[cmd_name][self.TAGS].keys():\n            default = self.subcmd_definition[cmd_name][self.TAGS][param_name][\"default\"]\n            parameters.append(click.Option(\n                [\"--{}\".format(param_name)],\n                default=default,\n                help=\"Specify the {} name you'd like, otherwise the default = {}\".format(param_name, default)\n            ))\n\n        command_callback = functools.partial(self.cmd_implementation,\n                                             self.events_lib,\n                                             self.top_level_cmd_name,\n                                             cmd_name)\n        cmd = click.Command(name=cmd_name,\n                            short_help=self.subcmd_definition[cmd_name][\"help\"],\n                            params=parameters,\n                            callback=command_callback)\n\n        cmd = debug_option(cmd)\n        return cmd", "response": "Gets the Click. Command object that can be called from the CLI."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling for value substitution in the event json and returns the customized json as a string Parameters ---------- events_lib top_level_cmd_name: string the name of the service subcmd_name: string the name of the event under the service args: tuple any arguments passed in before kwargs kwargs: dict the keys and values for substitution in the json Returns ------- event: string returns the customized event json as a string", "response": "def cmd_implementation(self, events_lib, top_level_cmd_name, subcmd_name, *args, **kwargs):\n        \"\"\"\n        calls for value substitution in the event json and returns the\n        customized json as a string\n\n        Parameters\n        ----------\n        events_lib\n        top_level_cmd_name: string\n            the name of the service\n        subcmd_name: string\n            the name of the event under the service\n        args: tuple\n            any arguments passed in before kwargs\n        kwargs: dict\n            the keys and values for substitution in the json\n        Returns\n        -------\n        event: string\n            returns the customized event json as a string\n        \"\"\"\n        event = events_lib.generate_event(top_level_cmd_name, subcmd_name, kwargs)\n        click.echo(event)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_lars_path(weighted_data, weighted_labels):\n        x_vector = weighted_data\n        alphas, _, coefs = lars_path(x_vector,\n                                     weighted_labels,\n                                     method='lasso',\n                                     verbose=False)\n        return alphas, coefs", "response": "Generates the lars path for weighted data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef forward_selection(self, data, labels, weights, num_features):\n        clf = Ridge(alpha=0, fit_intercept=True, random_state=self.random_state)\n        used_features = []\n        for _ in range(min(num_features, data.shape[1])):\n            max_ = -100000000\n            best = 0\n            for feature in range(data.shape[1]):\n                if feature in used_features:\n                    continue\n                clf.fit(data[:, used_features + [feature]], labels,\n                        sample_weight=weights)\n                score = clf.score(data[:, used_features + [feature]],\n                                  labels,\n                                  sample_weight=weights)\n                if score > max_:\n                    best = feature\n                    max_ = score\n            used_features.append(best)\n        return np.array(used_features)", "response": "Iteratively adds features to the model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feature_selection(self, data, labels, weights, num_features, method):\n        if method == 'none':\n            return np.array(range(data.shape[1]))\n        elif method == 'forward_selection':\n            return self.forward_selection(data, labels, weights, num_features)\n        elif method == 'highest_weights':\n            clf = Ridge(alpha=0, fit_intercept=True,\n                        random_state=self.random_state)\n            clf.fit(data, labels, sample_weight=weights)\n            feature_weights = sorted(zip(range(data.shape[0]),\n                                         clf.coef_ * data[0]),\n                                     key=lambda x: np.abs(x[1]),\n                                     reverse=True)\n            return np.array([x[0] for x in feature_weights[:num_features]])\n        elif method == 'lasso_path':\n            weighted_data = ((data - np.average(data, axis=0, weights=weights))\n                             * np.sqrt(weights[:, np.newaxis]))\n            weighted_labels = ((labels - np.average(labels, weights=weights))\n                               * np.sqrt(weights))\n            nonzero = range(weighted_data.shape[1])\n            _, coefs = self.generate_lars_path(weighted_data,\n                                               weighted_labels)\n            for i in range(len(coefs.T) - 1, 0, -1):\n                nonzero = coefs.T[i].nonzero()[0]\n                if len(nonzero) <= num_features:\n                    break\n            used_features = nonzero\n            return used_features\n        elif method == 'auto':\n            if num_features <= 6:\n                n_method = 'forward_selection'\n            else:\n                n_method = 'highest_weights'\n            return self.feature_selection(data, labels, weights,\n                                          num_features, n_method)", "response": "Selects features for the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef explain_instance_with_data(self,\n                                   neighborhood_data,\n                                   neighborhood_labels,\n                                   distances,\n                                   label,\n                                   num_features,\n                                   feature_selection='auto',\n                                   model_regressor=None):\n        \"\"\"Takes perturbed data, labels and distances, returns explanation.\n\n        Args:\n            neighborhood_data: perturbed data, 2d array. first element is\n                               assumed to be the original data point.\n            neighborhood_labels: corresponding perturbed labels. should have as\n                                 many columns as the number of possible labels.\n            distances: distances to original data point.\n            label: label for which we want an explanation\n            num_features: maximum number of features in explanation\n            feature_selection: how to select num_features. options are:\n                'forward_selection': iteratively add features to the model.\n                    This is costly when num_features is high\n                'highest_weights': selects the features that have the highest\n                    product of absolute weight * original data point when\n                    learning with all the features\n                'lasso_path': chooses features based on the lasso\n                    regularization path\n                'none': uses all features, ignores num_features\n                'auto': uses forward_selection if num_features <= 6, and\n                    'highest_weights' otherwise.\n            model_regressor: sklearn regressor to use in explanation.\n                Defaults to Ridge regression if None. Must have\n                model_regressor.coef_ and 'sample_weight' as a parameter\n                to model_regressor.fit()\n\n        Returns:\n            (intercept, exp, score, local_pred):\n            intercept is a float.\n            exp is a sorted list of tuples, where each tuple (x,y) corresponds\n            to the feature id (x) and the local weight (y). The list is sorted\n            by decreasing absolute value of y.\n            score is the R^2 value of the returned explanation\n            local_pred is the prediction of the explanation model on the original instance\n        \"\"\"\n\n        weights = self.kernel_fn(distances)\n        labels_column = neighborhood_labels[:, label]\n        used_features = self.feature_selection(neighborhood_data,\n                                               labels_column,\n                                               weights,\n                                               num_features,\n                                               feature_selection)\n\n        if model_regressor is None:\n            model_regressor = Ridge(alpha=1, fit_intercept=True,\n                                    random_state=self.random_state)\n        easy_model = model_regressor\n        easy_model.fit(neighborhood_data[:, used_features],\n                       labels_column, sample_weight=weights)\n        prediction_score = easy_model.score(\n            neighborhood_data[:, used_features],\n            labels_column, sample_weight=weights)\n\n        local_pred = easy_model.predict(neighborhood_data[0, used_features].reshape(1, -1))\n\n        if self.verbose:\n            print('Intercept', easy_model.intercept_)\n            print('Prediction_local', local_pred,)\n            print('Right:', neighborhood_labels[0, label])\n        return (easy_model.intercept_,\n                sorted(zip(used_features, easy_model.coef_),\n                       key=lambda x: np.abs(x[1]), reverse=True),\n                prediction_score, local_pred)", "response": "This function returns an explanation of an instance with the original data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef id_generator(size=15, random_state=None):\n    chars = list(string.ascii_uppercase + string.digits)\n    return ''.join(random_state.choice(chars, size, replace=True))", "response": "Helper function to generate random div ids. This is useful for embedding\n    HTML into ipython notebooks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef available_labels(self):\n        try:\n            assert self.mode == \"classification\"\n        except AssertionError:\n            raise NotImplementedError('Not supported for regression explanations.')\n        else:\n            ans = self.top_labels if self.top_labels else self.local_exp.keys()\n            return list(ans)", "response": "Returns the list of labels that are available for classification explanations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the explanation as a list.", "response": "def as_list(self, label=1, **kwargs):\n        \"\"\"Returns the explanation as a list.\n\n        Args:\n            label: desired label. If you ask for a label for which an\n                explanation wasn't computed, will throw an exception.\n                Will be ignored for regression explanations.\n            kwargs: keyword arguments, passed to domain_mapper\n\n        Returns:\n            list of tuples (representation, weight), where representation is\n            given by domain_mapper. Weight is a float.\n        \"\"\"\n        label_to_use = label if self.mode == \"classification\" else self.dummy_label\n        ans = self.domain_mapper.map_exp_ids(self.local_exp[label_to_use], **kwargs)\n        ans = [(x[0], float(x[1])) for x in ans]\n        return ans"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the explanation as a pyplot figure.", "response": "def as_pyplot_figure(self, label=1, **kwargs):\n        \"\"\"Returns the explanation as a pyplot figure.\n\n        Will throw an error if you don't have matplotlib installed\n        Args:\n            label: desired label. If you ask for a label for which an\n                   explanation wasn't computed, will throw an exception.\n                   Will be ignored for regression explanations.\n            kwargs: keyword arguments, passed to domain_mapper\n\n        Returns:\n            pyplot figure (barchart).\n        \"\"\"\n        import matplotlib.pyplot as plt\n        exp = self.as_list(label=label, **kwargs)\n        fig = plt.figure()\n        vals = [x[1] for x in exp]\n        names = [x[0] for x in exp]\n        vals.reverse()\n        names.reverse()\n        colors = ['green' if x > 0 else 'red' for x in vals]\n        pos = np.arange(len(exp)) + .5\n        plt.barh(pos, vals, align='center', color=colors)\n        plt.yticks(pos, names)\n        if self.mode == \"classification\":\n            title = 'Local explanation for class %s' % self.class_names[label]\n        else:\n            title = 'Local explanation'\n        plt.title(title)\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows html explanation in ipython notebook.", "response": "def show_in_notebook(self,\n                         labels=None,\n                         predict_proba=True,\n                         show_predicted_value=True,\n                         **kwargs):\n        \"\"\"Shows html explanation in ipython notebook.\n\n        See as_html() for parameters.\n        This will throw an error if you don't have IPython installed\"\"\"\n\n        from IPython.core.display import display, HTML\n        display(HTML(self.as_html(labels=labels,\n                                  predict_proba=predict_proba,\n                                  show_predicted_value=show_predicted_value,\n                                  **kwargs)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current state of the entry to a file.", "response": "def save_to_file(self,\n                     file_path,\n                     labels=None,\n                     predict_proba=True,\n                     show_predicted_value=True,\n                     **kwargs):\n        \"\"\"Saves html explanation to file. .\n\n        Params:\n            file_path: file to save explanations to\n\n        See as_html() for additional parameters.\n\n        \"\"\"\n        file_ = open(file_path, 'w', encoding='utf8')\n        file_.write(self.as_html(labels=labels,\n                                 predict_proba=predict_proba,\n                                 show_predicted_value=show_predicted_value,\n                                 **kwargs))\n        file_.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_html(self,\n                labels=None,\n                predict_proba=True,\n                show_predicted_value=True,\n                **kwargs):\n        \"\"\"Returns the explanation as an html page.\n\n        Args:\n            labels: desired labels to show explanations for (as barcharts).\n                If you ask for a label for which an explanation wasn't\n                computed, will throw an exception. If None, will show\n                explanations for all available labels. (only used for classification)\n            predict_proba: if true, add  barchart with prediction probabilities\n                for the top classes. (only used for classification)\n            show_predicted_value: if true, add  barchart with expected value\n                (only used for regression)\n            kwargs: keyword arguments, passed to domain_mapper\n\n        Returns:\n            code for an html page, including javascript includes.\n        \"\"\"\n\n        def jsonize(x):\n            return json.dumps(x, ensure_ascii=False)\n\n        if labels is None and self.mode == \"classification\":\n            labels = self.available_labels()\n\n        this_dir, _ = os.path.split(__file__)\n        bundle = open(os.path.join(this_dir, 'bundle.js'),\n                      encoding=\"utf8\").read()\n\n        out = u'''<html>\n        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF8\">\n        <head><script>%s </script></head><body>''' % bundle\n        random_id = id_generator(size=15, random_state=check_random_state(self.random_state))\n        out += u'''\n        <div class=\"lime top_div\" id=\"top_div%s\"></div>\n        ''' % random_id\n\n        predict_proba_js = ''\n        if self.mode == \"classification\" and predict_proba:\n            predict_proba_js = u'''\n            var pp_div = top_div.append('div')\n                                .classed('lime predict_proba', true);\n            var pp_svg = pp_div.append('svg').style('width', '100%%');\n            var pp = new lime.PredictProba(pp_svg, %s, %s);\n            ''' % (jsonize([str(x) for x in self.class_names]),\n                   jsonize(list(self.predict_proba.astype(float))))\n\n        predict_value_js = ''\n        if self.mode == \"regression\" and show_predicted_value:\n            # reference self.predicted_value\n            # (svg, predicted_value, min_value, max_value)\n            predict_value_js = u'''\n                    var pp_div = top_div.append('div')\n                                        .classed('lime predicted_value', true);\n                    var pp_svg = pp_div.append('svg').style('width', '100%%');\n                    var pp = new lime.PredictedValue(pp_svg, %s, %s, %s);\n                    ''' % (jsonize(float(self.predicted_value)),\n                           jsonize(float(self.min_value)),\n                           jsonize(float(self.max_value)))\n\n        exp_js = '''var exp_div;\n            var exp = new lime.Explanation(%s);\n        ''' % (jsonize([str(x) for x in self.class_names]))\n\n        if self.mode == \"classification\":\n            for label in labels:\n                exp = jsonize(self.as_list(label))\n                exp_js += u'''\n                exp_div = top_div.append('div').classed('lime explanation', true);\n                exp.show(%s, %d, exp_div);\n                ''' % (exp, label)\n        else:\n            exp = jsonize(self.as_list())\n            exp_js += u'''\n            exp_div = top_div.append('div').classed('lime explanation', true);\n            exp.show(%s, %s, exp_div);\n            ''' % (exp, self.dummy_label)\n\n        raw_js = '''var raw_div = top_div.append('div');'''\n\n        if self.mode == \"classification\":\n            html_data = self.local_exp[labels[0]]\n        else:\n            html_data = self.local_exp[self.dummy_label]\n\n        raw_js += self.domain_mapper.visualize_instance_html(\n                html_data,\n                labels[0] if self.mode == \"classification\" else self.dummy_label,\n                'raw_div',\n                'exp',\n                **kwargs)\n        out += u'''\n        <script>\n        var top_div = d3.select('#top_div%s').classed('lime top_div', true);\n        %s\n        %s\n        %s\n        %s\n        </script>\n        ''' % (random_id, predict_proba_js, predict_value_js, exp_js, raw_js)\n        out += u'</body></html>'\n\n        return out", "response": "Returns the explanation as an html page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_params(self, parameters):\n        a_valid_fn = []\n        if self.target_fn is None:\n            if callable(self):\n                a_valid_fn.append(self.__call__)\n            else:\n                raise TypeError('invalid argument: tested object is not callable,\\\n                 please provide a valid target_fn')\n        elif isinstance(self.target_fn, types.FunctionType) \\\n                or isinstance(self.target_fn, types.MethodType):\n            a_valid_fn.append(self.target_fn)\n        else:\n            a_valid_fn.append(self.target_fn.__call__)\n\n        if not isinstance(parameters, str):\n            for p in parameters:\n                for fn in a_valid_fn:\n                    if has_arg(fn, p):\n                        pass\n                    else:\n                        raise ValueError('{} is not a valid parameter'.format(p))\n        else:\n            raise TypeError('invalid argument: list or dictionnary expected')", "response": "Checks for mistakes in parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_params(self, fn, override=None):\n        override = override or {}\n        result = {}\n        for name, value in self.target_params.items():\n            if has_arg(fn, name):\n                result.update({name: value})\n        result.update(override)\n        return result", "response": "Filters target_params and returns those in fn s arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_exp_ids(self, exp, positions=False):\n        if positions:\n            exp = [('%s_%s' % (\n                self.indexed_string.word(x[0]),\n                '-'.join(\n                    map(str,\n                        self.indexed_string.string_position(x[0])))), x[1])\n                   for x in exp]\n        else:\n            exp = [(self.indexed_string.word(x[0]), x[1]) for x in exp]\n        return exp", "response": "Maps ids to words or word - position strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visualize_instance_html(self, exp, label, div_name, exp_object_name,\n                                text=True, opacity=True):\n        \"\"\"Adds text with highlighted words to visualization.\n\n        Args:\n             exp: list of tuples [(id, weight), (id,weight)]\n             label: label id (integer)\n             div_name: name of div object to be used for rendering(in js)\n             exp_object_name: name of js explanation object\n             text: if False, return empty\n             opacity: if True, fade colors according to weight\n        \"\"\"\n        if not text:\n            return u''\n        text = (self.indexed_string.raw_string()\n                .encode('utf-8', 'xmlcharrefreplace').decode('utf-8'))\n        text = re.sub(r'[<>&]', '|', text)\n        exp = [(self.indexed_string.word(x[0]),\n                self.indexed_string.string_position(x[0]),\n                x[1]) for x in exp]\n        all_occurrences = list(itertools.chain.from_iterable(\n            [itertools.product([x[0]], x[1], [x[2]]) for x in exp]))\n        all_occurrences = [(x[0], int(x[1]), x[2]) for x in all_occurrences]\n        ret = '''\n            %s.show_raw_text(%s, %d, %s, %s, %s);\n            ''' % (exp_object_name, json.dumps(all_occurrences), label,\n                   json.dumps(text), div_name, json.dumps(opacity))\n        return ret", "response": "Adds text with highlighted words to visualize the instance of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef string_position(self, id_):\n        if self.bow:\n            return self.string_start[self.positions[id_]]\n        else:\n            return self.string_start[[self.positions[id_]]]", "response": "Returns a np array with indices to id_ ( int ) occurrences"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string after removing the appropriate words.", "response": "def inverse_removing(self, words_to_remove):\n        \"\"\"Returns a string after removing the appropriate words.\n\n        If self.bow is false, replaces word with UNKWORDZ instead of removing\n        it.\n\n        Args:\n            words_to_remove: list of ids (ints) to remove\n\n        Returns:\n            original raw string with appropriate words removed.\n        \"\"\"\n        mask = np.ones(self.as_np.shape[0], dtype='bool')\n        mask[self.__get_idxs(words_to_remove)] = False\n        if not self.bow:\n            return ''.join([self.as_list[i] if mask[i]\n                            else 'UNKWORDZ' for i in range(mask.shape[0])])\n        return ''.join([self.as_list[v] for v in mask.nonzero()[0]])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _segment_with_tokens(text, tokens):\n        list_form = []\n        text_ptr = 0\n        for token in tokens:\n            inter_token_string = []\n            while not text[text_ptr:].startswith(token):\n                inter_token_string.append(text[text_ptr])\n                text_ptr += 1\n                if text_ptr >= len(text):\n                    raise ValueError(\"Tokenization produced tokens that do not belong in string!\")\n            text_ptr += len(token)\n            if inter_token_string:\n                list_form.append(''.join(inter_token_string))\n            list_form.append(token)\n        if text_ptr < len(text):\n            list_form.append(text[text_ptr:])\n        return list_form", "response": "Segment a string around the tokens created by a passed - in tokenizer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_idxs(self, words):\n        if self.bow:\n            return list(itertools.chain.from_iterable(\n                [self.positions[z] for z in words]))\n        else:\n            return self.positions[words]", "response": "Returns indexes to appropriate words."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef explain_instance(self,\n                         text_instance,\n                         classifier_fn,\n                         labels=(1,),\n                         top_labels=None,\n                         num_features=10,\n                         num_samples=5000,\n                         distance_metric='cosine',\n                         model_regressor=None):\n        \"\"\"Generates explanations for a prediction.\n\n        First, we generate neighborhood data by randomly hiding features from\n        the instance (see __data_labels_distance_mapping). We then learn\n        locally weighted linear models on this neighborhood data to explain\n        each of the classes in an interpretable way (see lime_base.py).\n\n        Args:\n            text_instance: raw text string to be explained.\n            classifier_fn: classifier prediction probability function, which\n                takes a list of d strings and outputs a (d, k) numpy array with\n                prediction probabilities, where k is the number of classes.\n                For ScikitClassifiers , this is classifier.predict_proba.\n            labels: iterable with labels to be explained.\n            top_labels: if not None, ignore labels and produce explanations for\n                the K labels with highest prediction probabilities, where K is\n                this parameter.\n            num_features: maximum number of features present in explanation\n            num_samples: size of the neighborhood to learn the linear model\n            distance_metric: the distance metric to use for sample weighting,\n                defaults to cosine similarity\n            model_regressor: sklearn regressor to use in explanation. Defaults\n            to Ridge regression in LimeBase. Must have model_regressor.coef_\n            and 'sample_weight' as a parameter to model_regressor.fit()\n        Returns:\n            An Explanation object (see explanation.py) with the corresponding\n            explanations.\n        \"\"\"\n\n        indexed_string = IndexedCharacters(\n            text_instance, bow=self.bow) if self.char_level else IndexedString(\n            text_instance, bow=self.bow, split_expression=self.split_expression)\n        domain_mapper = TextDomainMapper(indexed_string)\n        data, yss, distances = self.__data_labels_distances(\n            indexed_string, classifier_fn, num_samples,\n            distance_metric=distance_metric)\n        if self.class_names is None:\n            self.class_names = [str(x) for x in range(yss[0].shape[0])]\n        ret_exp = explanation.Explanation(domain_mapper=domain_mapper,\n                                          class_names=self.class_names,\n                                          random_state=self.random_state)\n        ret_exp.predict_proba = yss[0]\n        if top_labels:\n            labels = np.argsort(yss[0])[-top_labels:]\n            ret_exp.top_labels = list(labels)\n            ret_exp.top_labels.reverse()\n        for label in labels:\n            (ret_exp.intercept[label],\n             ret_exp.local_exp[label],\n             ret_exp.score, ret_exp.local_pred) = self.base.explain_instance_with_data(\n                data, yss, distances, label, num_features,\n                model_regressor=model_regressor,\n                feature_selection=self.feature_selection)\n        return ret_exp", "response": "Generates explanations for a prediction of a single instance of a class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __data_labels_distances(self,\n                                indexed_string,\n                                classifier_fn,\n                                num_samples,\n                                distance_metric='cosine'):\n        \"\"\"Generates a neighborhood around a prediction.\n\n        Generates neighborhood data by randomly removing words from\n        the instance, and predicting with the classifier. Uses cosine distance\n        to compute distances between original and perturbed instances.\n        Args:\n            indexed_string: document (IndexedString) to be explained,\n            classifier_fn: classifier prediction probability function, which\n                takes a string and outputs prediction probabilities. For\n                ScikitClassifier, this is classifier.predict_proba.\n            num_samples: size of the neighborhood to learn the linear model\n            distance_metric: the distance metric to use for sample weighting,\n                defaults to cosine similarity.\n\n\n        Returns:\n            A tuple (data, labels, distances), where:\n                data: dense num_samples * K binary matrix, where K is the\n                    number of tokens in indexed_string. The first row is the\n                    original instance, and thus a row of ones.\n                labels: num_samples * L matrix, where L is the number of target\n                    labels\n                distances: cosine distance between the original instance and\n                    each perturbed instance (computed in the binary 'data'\n                    matrix), times 100.\n        \"\"\"\n\n        def distance_fn(x):\n            return sklearn.metrics.pairwise.pairwise_distances(\n                x, x[0], metric=distance_metric).ravel() * 100\n\n        doc_size = indexed_string.num_words()\n        sample = self.random_state.randint(1, doc_size + 1, num_samples - 1)\n        data = np.ones((num_samples, doc_size))\n        data[0] = np.ones(doc_size)\n        features_range = range(doc_size)\n        inverse_data = [indexed_string.raw_string()]\n        for i, size in enumerate(sample, start=1):\n            inactive = self.random_state.choice(features_range, size,\n                                                replace=False)\n            data[i, inactive] = 0\n            inverse_data.append(indexed_string.inverse_removing(inactive))\n        labels = classifier_fn(inverse_data)\n        distances = distance_fn(sp.sparse.csr_matrix(data))\n        return data, labels, distances", "response": "Generates a neighborhood around a prediction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmapping ids to feature names.", "response": "def map_exp_ids(self, exp):\n        \"\"\"Maps ids to feature names.\n\n        Args:\n            exp: list of tuples [(id, weight), (id,weight)]\n\n        Returns:\n            list of tuples (feature_name, weight)\n        \"\"\"\n        names = self.exp_feature_names\n        if self.discretized_feature_names is not None:\n            names = self.discretized_feature_names\n        return [(names[x[0]], x[1]) for x in exp]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visualize_instance_html(self,\n                                exp,\n                                label,\n                                div_name,\n                                exp_object_name,\n                                show_table=True,\n                                show_all=False):\n        \"\"\"Shows the current example in a table format.\n\n        Args:\n             exp: list of tuples [(id, weight), (id,weight)]\n             label: label id (integer)\n             div_name: name of div object to be used for rendering(in js)\n             exp_object_name: name of js explanation object\n             show_table: if False, don't show table visualization.\n             show_all: if True, show zero-weighted features in the table.\n        \"\"\"\n        if not show_table:\n            return ''\n        weights = [0] * len(self.feature_names)\n        for x in exp:\n            weights[x[0]] = x[1]\n        out_list = list(zip(self.exp_feature_names,\n                            self.feature_values,\n                            weights))\n        if not show_all:\n            out_list = [out_list[x[0]] for x in exp]\n        ret = u'''\n            %s.show_raw_tabular(%s, %d, %s);\n        ''' % (exp_object_name, json.dumps(out_list, ensure_ascii=False), label, div_name)\n        return ret", "response": "Shows the current example in a table format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef explain_instance(self,\n                         data_row,\n                         predict_fn,\n                         labels=(1,),\n                         top_labels=None,\n                         num_features=10,\n                         num_samples=5000,\n                         distance_metric='euclidean',\n                         model_regressor=None):\n        \"\"\"Generates explanations for a prediction.\n\n        First, we generate neighborhood data by randomly perturbing features\n        from the instance (see __data_inverse). We then learn locally weighted\n        linear models on this neighborhood data to explain each of the classes\n        in an interpretable way (see lime_base.py).\n\n        Args:\n            data_row: 1d numpy array, corresponding to a row\n            predict_fn: prediction function. For classifiers, this should be a\n                function that takes a numpy array and outputs prediction\n                probabilities. For regressors, this takes a numpy array and\n                returns the predictions. For ScikitClassifiers, this is\n                `classifier.predict_proba()`. For ScikitRegressors, this\n                is `regressor.predict()`. The prediction function needs to work\n                on multiple feature vectors (the vectors randomly perturbed\n                from the data_row).\n            labels: iterable with labels to be explained.\n            top_labels: if not None, ignore labels and produce explanations for\n                the K labels with highest prediction probabilities, where K is\n                this parameter.\n            num_features: maximum number of features present in explanation\n            num_samples: size of the neighborhood to learn the linear model\n            distance_metric: the distance metric to use for weights.\n            model_regressor: sklearn regressor to use in explanation. Defaults\n                to Ridge regression in LimeBase. Must have model_regressor.coef_\n                and 'sample_weight' as a parameter to model_regressor.fit()\n\n        Returns:\n            An Explanation object (see explanation.py) with the corresponding\n            explanations.\n        \"\"\"\n        data, inverse = self.__data_inverse(data_row, num_samples)\n        scaled_data = (data - self.scaler.mean_) / self.scaler.scale_\n\n        distances = sklearn.metrics.pairwise_distances(\n                scaled_data,\n                scaled_data[0].reshape(1, -1),\n                metric=distance_metric\n        ).ravel()\n\n        yss = predict_fn(inverse)\n\n        # for classification, the model needs to provide a list of tuples - classes\n        # along with prediction probabilities\n        if self.mode == \"classification\":\n            if len(yss.shape) == 1:\n                raise NotImplementedError(\"LIME does not currently support \"\n                                          \"classifier models without probability \"\n                                          \"scores. If this conflicts with your \"\n                                          \"use case, please let us know: \"\n                                          \"https://github.com/datascienceinc/lime/issues/16\")\n            elif len(yss.shape) == 2:\n                if self.class_names is None:\n                    self.class_names = [str(x) for x in range(yss[0].shape[0])]\n                else:\n                    self.class_names = list(self.class_names)\n                if not np.allclose(yss.sum(axis=1), 1.0):\n                    warnings.warn(\"\"\"\n                    Prediction probabilties do not sum to 1, and\n                    thus does not constitute a probability space.\n                    Check that you classifier outputs probabilities\n                    (Not log probabilities, or actual class predictions).\n                    \"\"\")\n            else:\n                raise ValueError(\"Your model outputs \"\n                                 \"arrays with {} dimensions\".format(len(yss.shape)))\n\n        # for regression, the output should be a one-dimensional array of predictions\n        else:\n            try:\n                assert isinstance(yss, np.ndarray) and len(yss.shape) == 1\n            except AssertionError:\n                raise ValueError(\"Your model needs to output single-dimensional \\\n                    numpyarrays, not arrays of {} dimensions\".format(yss.shape))\n\n            predicted_value = yss[0]\n            min_y = min(yss)\n            max_y = max(yss)\n\n            # add a dimension to be compatible with downstream machinery\n            yss = yss[:, np.newaxis]\n\n        feature_names = copy.deepcopy(self.feature_names)\n        if feature_names is None:\n            feature_names = [str(x) for x in range(data_row.shape[0])]\n\n        values = self.convert_and_round(data_row)\n\n        for i in self.categorical_features:\n            if self.discretizer is not None and i in self.discretizer.lambdas:\n                continue\n            name = int(data_row[i])\n            if i in self.categorical_names:\n                name = self.categorical_names[i][name]\n            feature_names[i] = '%s=%s' % (feature_names[i], name)\n            values[i] = 'True'\n        categorical_features = self.categorical_features\n\n        discretized_feature_names = None\n        if self.discretizer is not None:\n            categorical_features = range(data.shape[1])\n            discretized_instance = self.discretizer.discretize(data_row)\n            discretized_feature_names = copy.deepcopy(feature_names)\n            for f in self.discretizer.names:\n                discretized_feature_names[f] = self.discretizer.names[f][int(\n                        discretized_instance[f])]\n\n        domain_mapper = TableDomainMapper(feature_names,\n                                          values,\n                                          scaled_data[0],\n                                          categorical_features=categorical_features,\n                                          discretized_feature_names=discretized_feature_names)\n        ret_exp = explanation.Explanation(domain_mapper,\n                                          mode=self.mode,\n                                          class_names=self.class_names)\n        ret_exp.scaled_data = scaled_data\n        if self.mode == \"classification\":\n            ret_exp.predict_proba = yss[0]\n            if top_labels:\n                labels = np.argsort(yss[0])[-top_labels:]\n                ret_exp.top_labels = list(labels)\n                ret_exp.top_labels.reverse()\n        else:\n            ret_exp.predicted_value = predicted_value\n            ret_exp.min_value = min_y\n            ret_exp.max_value = max_y\n            labels = [0]\n\n        for label in labels:\n            (ret_exp.intercept[label],\n             ret_exp.local_exp[label],\n             ret_exp.score, ret_exp.local_pred) = self.base.explain_instance_with_data(\n                    scaled_data,\n                    yss,\n                    distances,\n                    label,\n                    num_features,\n                    model_regressor=model_regressor,\n                    feature_selection=self.feature_selection)\n\n        if self.mode == \"regression\":\n            ret_exp.intercept[1] = ret_exp.intercept[0]\n            ret_exp.local_exp[1] = [x for x in ret_exp.local_exp[0]]\n            ret_exp.local_exp[0] = [(i, -1 * j) for i, j in ret_exp.local_exp[1]]\n\n        return ret_exp", "response": "Generates explanations for a prediction of a classifier or regressor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a neighborhood around a prediction.", "response": "def __data_inverse(self,\n                       data_row,\n                       num_samples):\n        \"\"\"Generates a neighborhood around a prediction.\n\n        For numerical features, perturb them by sampling from a Normal(0,1) and\n        doing the inverse operation of mean-centering and scaling, according to\n        the means and stds in the training data. For categorical features,\n        perturb by sampling according to the training distribution, and making\n        a binary feature that is 1 when the value is the same as the instance\n        being explained.\n\n        Args:\n            data_row: 1d numpy array, corresponding to a row\n            num_samples: size of the neighborhood to learn the linear model\n\n        Returns:\n            A tuple (data, inverse), where:\n                data: dense num_samples * K matrix, where categorical features\n                are encoded with either 0 (not equal to the corresponding value\n                in data_row) or 1. The first row is the original instance.\n                inverse: same as data, except the categorical features are not\n                binary, but categorical (as the original data)\n        \"\"\"\n        data = np.zeros((num_samples, data_row.shape[0]))\n        categorical_features = range(data_row.shape[0])\n        if self.discretizer is None:\n            data = self.random_state.normal(\n                0, 1, num_samples * data_row.shape[0]).reshape(\n                num_samples, data_row.shape[0])\n            if self.sample_around_instance:\n                data = data * self.scaler.scale_ + data_row\n            else:\n                data = data * self.scaler.scale_ + self.scaler.mean_\n            categorical_features = self.categorical_features\n            first_row = data_row\n        else:\n            first_row = self.discretizer.discretize(data_row)\n        data[0] = data_row.copy()\n        inverse = data.copy()\n        for column in categorical_features:\n            values = self.feature_values[column]\n            freqs = self.feature_frequencies[column]\n            inverse_column = self.random_state.choice(values, size=num_samples,\n                                                      replace=True, p=freqs)\n            binary_column = np.array([1 if x == first_row[column]\n                                      else 0 for x in inverse_column])\n            binary_column[0] = 1\n            inverse_column[0] = data[0, column]\n            data[:, column] = binary_column\n            inverse[:, column] = inverse_column\n        if self.discretizer is not None:\n            inverse[1:] = self.discretizer.undiscretize(inverse[1:])\n        inverse[0] = data_row\n        return data, inverse"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_predict_proba(self, func):\n\n        def predict_proba(X):\n            n_samples = X.shape[0]\n            new_shape = (n_samples, self.n_features, self.n_timesteps)\n            X = np.transpose(X.reshape(new_shape), axes=(0, 2, 1))\n            return func(X)\n\n        return predict_proba", "response": "A function that returns predict_proba for a keras - style cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating explanations for a prediction of a class in a recurrent tabular experiment.", "response": "def explain_instance(self, data_row, classifier_fn, labels=(1,),\n                         top_labels=None, num_features=10, num_samples=5000,\n                         distance_metric='euclidean', model_regressor=None):\n        \"\"\"Generates explanations for a prediction.\n\n        First, we generate neighborhood data by randomly perturbing features\n        from the instance (see __data_inverse). We then learn locally weighted\n        linear models on this neighborhood data to explain each of the classes\n        in an interpretable way (see lime_base.py).\n\n        Args:\n            data_row: 2d numpy array, corresponding to a row\n            classifier_fn: classifier prediction probability function, which\n                takes a numpy array and outputs prediction probabilities. For\n                ScikitClassifiers , this is classifier.predict_proba.\n            labels: iterable with labels to be explained.\n            top_labels: if not None, ignore labels and produce explanations for\n                the K labels with highest prediction probabilities, where K is\n                this parameter.\n            num_features: maximum number of features present in explanation\n            num_samples: size of the neighborhood to learn the linear model\n            distance_metric: the distance metric to use for weights.\n            model_regressor: sklearn regressor to use in explanation. Defaults\n                to Ridge regression in LimeBase. Must have\n                model_regressor.coef_ and 'sample_weight' as a parameter\n                to model_regressor.fit()\n\n        Returns:\n            An Explanation object (see explanation.py) with the corresponding\n            explanations.\n        \"\"\"\n\n        # Flatten input so that the normal explainer can handle it\n        data_row = data_row.T.reshape(self.n_timesteps * self.n_features)\n\n        # Wrap the classifier to reshape input\n        classifier_fn = self._make_predict_proba(classifier_fn)\n        return super(RecurrentTabularExplainer, self).explain_instance(\n            data_row, classifier_fn,\n            labels=labels,\n            top_labels=top_labels,\n            num_features=num_features,\n            num_samples=num_samples,\n            distance_metric=distance_metric,\n            model_regressor=model_regressor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_image_and_mask(self, label, positive_only=True, hide_rest=False,\n                           num_features=5, min_weight=0.):\n        \"\"\"Init function.\n\n        Args:\n            label: label to explain\n            positive_only: if True, only take superpixels that contribute to\n                the prediction of the label. Otherwise, use the top\n                num_features superpixels, which can be positive or negative\n                towards the label\n            hide_rest: if True, make the non-explanation part of the return\n                image gray\n            num_features: number of superpixels to include in explanation\n            min_weight: TODO\n\n        Returns:\n            (image, mask), where image is a 3d numpy array and mask is a 2d\n            numpy array that can be used with\n            skimage.segmentation.mark_boundaries\n        \"\"\"\n        if label not in self.local_exp:\n            raise KeyError('Label not in explanation')\n        segments = self.segments\n        image = self.image\n        exp = self.local_exp[label]\n        mask = np.zeros(segments.shape, segments.dtype)\n        if hide_rest:\n            temp = np.zeros(self.image.shape)\n        else:\n            temp = self.image.copy()\n        if positive_only:\n            fs = [x[0] for x in exp\n                  if x[1] > 0 and x[1] > min_weight][:num_features]\n            for f in fs:\n                temp[segments == f] = image[segments == f].copy()\n                mask[segments == f] = 1\n            return temp, mask\n        else:\n            for f, w in exp[:num_features]:\n                if np.abs(w) < min_weight:\n                    continue\n                c = 0 if w < 0 else 1\n                mask[segments == f] = 1 if w < 0 else 2\n                temp[segments == f] = image[segments == f].copy()\n                temp[segments == f, c] = np.max(image)\n                for cp in [0, 1, 2]:\n                    if c == cp:\n                        continue\n                    # temp[segments == f, cp] *= 0.5\n            return temp, mask", "response": "This function returns the image and mask for the given label."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef explain_instance(self, image, classifier_fn, labels=(1,),\n                         hide_color=None,\n                         top_labels=5, num_features=100000, num_samples=1000,\n                         batch_size=10,\n                         segmentation_fn=None,\n                         distance_metric='cosine',\n                         model_regressor=None,\n                         random_seed=None):\n        \"\"\"Generates explanations for a prediction.\n\n        First, we generate neighborhood data by randomly perturbing features\n        from the instance (see __data_inverse). We then learn locally weighted\n        linear models on this neighborhood data to explain each of the classes\n        in an interpretable way (see lime_base.py).\n\n        Args:\n            image: 3 dimension RGB image. If this is only two dimensional,\n                we will assume it's a grayscale image and call gray2rgb.\n            classifier_fn: classifier prediction probability function, which\n                takes a numpy array and outputs prediction probabilities.  For\n                ScikitClassifiers , this is classifier.predict_proba.\n            labels: iterable with labels to be explained.\n            hide_color: TODO\n            top_labels: if not None, ignore labels and produce explanations for\n                the K labels with highest prediction probabilities, where K is\n                this parameter.\n            num_features: maximum number of features present in explanation\n            num_samples: size of the neighborhood to learn the linear model\n            batch_size: TODO\n            distance_metric: the distance metric to use for weights.\n            model_regressor: sklearn regressor to use in explanation. Defaults\n            to Ridge regression in LimeBase. Must have model_regressor.coef_\n            and 'sample_weight' as a parameter to model_regressor.fit()\n            segmentation_fn: SegmentationAlgorithm, wrapped skimage\n            segmentation function\n            random_seed: integer used as random seed for the segmentation\n                algorithm. If None, a random integer, between 0 and 1000,\n                will be generated using the internal random number generator.\n\n        Returns:\n            An Explanation object (see explanation.py) with the corresponding\n            explanations.\n        \"\"\"\n        if len(image.shape) == 2:\n            image = gray2rgb(image)\n        if random_seed is None:\n            random_seed = self.random_state.randint(0, high=1000)\n\n        if segmentation_fn is None:\n            segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=4,\n                                                    max_dist=200, ratio=0.2,\n                                                    random_seed=random_seed)\n        try:\n            segments = segmentation_fn(image)\n        except ValueError as e:\n            raise e\n\n        fudged_image = image.copy()\n        if hide_color is None:\n            for x in np.unique(segments):\n                fudged_image[segments == x] = (\n                    np.mean(image[segments == x][:, 0]),\n                    np.mean(image[segments == x][:, 1]),\n                    np.mean(image[segments == x][:, 2]))\n        else:\n            fudged_image[:] = hide_color\n\n        top = labels\n\n        data, labels = self.data_labels(image, fudged_image, segments,\n                                        classifier_fn, num_samples,\n                                        batch_size=batch_size)\n\n        distances = sklearn.metrics.pairwise_distances(\n            data,\n            data[0].reshape(1, -1),\n            metric=distance_metric\n        ).ravel()\n\n        ret_exp = ImageExplanation(image, segments)\n        if top_labels:\n            top = np.argsort(labels[0])[-top_labels:]\n            ret_exp.top_labels = list(top)\n            ret_exp.top_labels.reverse()\n        for label in top:\n            (ret_exp.intercept[label],\n             ret_exp.local_exp[label],\n             ret_exp.score, ret_exp.local_pred) = self.base.explain_instance_with_data(\n                data, labels, distances, label, num_features,\n                model_regressor=model_regressor,\n                feature_selection=self.feature_selection)\n        return ret_exp", "response": "Generates explanations for a prediction of a class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate images and predictions in the neighborhood of this image.", "response": "def data_labels(self,\n                    image,\n                    fudged_image,\n                    segments,\n                    classifier_fn,\n                    num_samples,\n                    batch_size=10):\n        \"\"\"Generates images and predictions in the neighborhood of this image.\n\n        Args:\n            image: 3d numpy array, the image\n            fudged_image: 3d numpy array, image to replace original image when\n                superpixel is turned off\n            segments: segmentation of the image\n            classifier_fn: function that takes a list of images and returns a\n                matrix of prediction probabilities\n            num_samples: size of the neighborhood to learn the linear model\n            batch_size: classifier_fn will be called on batches of this size.\n\n        Returns:\n            A tuple (data, labels), where:\n                data: dense num_samples * num_superpixels\n                labels: prediction probabilities matrix\n        \"\"\"\n        n_features = np.unique(segments).shape[0]\n        data = self.random_state.randint(0, 2, num_samples * n_features)\\\n            .reshape((num_samples, n_features))\n        labels = []\n        data[0, :] = 1\n        imgs = []\n        for row in data:\n            temp = copy.deepcopy(image)\n            zeros = np.where(row == 0)[0]\n            mask = np.zeros(segments.shape).astype(bool)\n            for z in zeros:\n                mask[segments == z] = True\n            temp[mask] = fudged_image[mask]\n            imgs.append(temp)\n            if len(imgs) == batch_size:\n                preds = classifier_fn(np.array(imgs))\n                labels.extend(preds)\n                imgs = []\n        if len(imgs) > 0:\n            preds = classifier_fn(np.array(imgs))\n            labels.extend(preds)\n        return data, np.array(labels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a callable accepts a given keyword argument.", "response": "def has_arg(fn, arg_name):\n    \"\"\"Checks if a callable accepts a given keyword argument.\n\n    Args:\n        fn: callable to inspect\n        arg_name: string, keyword argument name to check\n\n    Returns:\n        bool, whether `fn` accepts a `arg_name` keyword argument.\n    \"\"\"\n    if sys.version_info < (3,):\n        if isinstance(fn, types.FunctionType) or isinstance(fn, types.MethodType):\n            arg_spec = inspect.getargspec(fn)\n        else:\n            try:\n                arg_spec = inspect.getargspec(fn.__call__)\n            except AttributeError:\n                return False\n        return (arg_name in arg_spec.args)\n    elif sys.version_info < (3, 6):\n        arg_spec = inspect.getfullargspec(fn)\n        return (arg_name in arg_spec.args or\n                arg_name in arg_spec.kwonlyargs)\n    else:\n        try:\n            signature = inspect.signature(fn)\n        except ValueError:\n            # handling Cython\n            signature = inspect.signature(fn.__call__)\n        parameter = signature.parameters.get(arg_name)\n        if parameter is None:\n            return False\n        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n                                   inspect.Parameter.KEYWORD_ONLY))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discretize(self, data):\n        ret = data.copy()\n        for feature in self.lambdas:\n            if len(data.shape) == 1:\n                ret[feature] = int(self.lambdas[feature](ret[feature]))\n            else:\n                ret[:, feature] = self.lambdas[feature](\n                    ret[:, feature]).astype(int)\n        return ret", "response": "Discretizes the data.\n        Args:\n            data: numpy 2d or 1d array\n        Returns:\n            numpy array of same dimension, discretized."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_remote(self, config, name):\n        from dvc.remote import Remote\n\n        remote = config.get(name)\n\n        if not remote:\n            return None\n\n        settings = self.repo.config.get_remote_settings(remote)\n        return Remote(self.repo, settings)", "response": "Returns a Remote instance for the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw(vertexes, edges):\n    # pylint: disable=too-many-locals\n    # NOTE: coordinates might me negative, so we need to shift\n    # everything to the positive plane before we actually draw it.\n    Xs = []  # pylint: disable=invalid-name\n    Ys = []  # pylint: disable=invalid-name\n\n    sug = _build_sugiyama_layout(vertexes, edges)\n\n    for vertex in sug.g.sV:\n        # NOTE: moving boxes w/2 to the left\n        Xs.append(vertex.view.xy[0] - vertex.view.w / 2.0)\n        Xs.append(vertex.view.xy[0] + vertex.view.w / 2.0)\n        Ys.append(vertex.view.xy[1])\n        Ys.append(vertex.view.xy[1] + vertex.view.h)\n\n    for edge in sug.g.sE:\n        for x, y in edge.view._pts:  # pylint: disable=protected-access\n            Xs.append(x)\n            Ys.append(y)\n\n    minx = min(Xs)\n    miny = min(Ys)\n    maxx = max(Xs)\n    maxy = max(Ys)\n\n    canvas_cols = int(math.ceil(math.ceil(maxx) - math.floor(minx))) + 1\n    canvas_lines = int(round(maxy - miny))\n\n    canvas = AsciiCanvas(canvas_cols, canvas_lines)\n\n    # NOTE: first draw edges so that node boxes could overwrite them\n    for edge in sug.g.sE:\n        # pylint: disable=protected-access\n        assert len(edge.view._pts) > 1\n        for index in range(1, len(edge.view._pts)):\n            start = edge.view._pts[index - 1]\n            end = edge.view._pts[index]\n\n            start_x = int(round(start[0] - minx))\n            start_y = int(round(start[1] - miny))\n            end_x = int(round(end[0] - minx))\n            end_y = int(round(end[1] - miny))\n\n            assert start_x >= 0\n            assert start_y >= 0\n            assert end_x >= 0\n            assert end_y >= 0\n\n            canvas.line(start_x, start_y, end_x, end_y, \"*\")\n\n    for vertex in sug.g.sV:\n        # NOTE: moving boxes w/2 to the left\n        x = vertex.view.xy[0] - vertex.view.w / 2.0\n        y = vertex.view.xy[1]\n\n        canvas.box(\n            int(round(x - minx)),\n            int(round(y - miny)),\n            vertex.view.w,\n            vertex.view.h,\n        )\n\n        canvas.text(\n            int(round(x - minx)) + 1, int(round(y - miny)) + 1, vertex.data\n        )\n\n    canvas.draw()", "response": "Builds a DAG and draw it in ASCII."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws ASCII canvas on the screen.", "response": "def draw(self):\n        \"\"\"Draws ASCII canvas on the screen.\"\"\"\n        if sys.stdout.isatty():  # pragma: no cover\n            from asciimatics.screen import Screen\n\n            Screen.wrapper(self._do_draw)\n        else:\n            for line in self.canvas:\n                print(\"\".join(line))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef point(self, x, y, char):\n        assert len(char) == 1\n        assert x >= 0\n        assert x < self.cols\n        assert y >= 0\n        assert y < self.lines\n\n        self.canvas[y][x] = char", "response": "Create a point on ASCII canvas."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a line on ASCII canvas.", "response": "def line(self, x0, y0, x1, y1, char):\n        \"\"\"Create a line on ASCII canvas.\n\n        Args:\n            x0 (int): x coordinate where the line should start.\n            y0 (int): y coordinate where the line should start.\n            x1 (int): x coordinate where the line should end.\n            y1 (int): y coordinate where the line should end.\n            char (str): character to draw the line with.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-branches\n        if x0 > x1:\n            x1, x0 = x0, x1\n            y1, y0 = y0, y1\n\n        dx = x1 - x0\n        dy = y1 - y0\n\n        if dx == 0 and dy == 0:\n            self.point(x0, y0, char)\n        elif abs(dx) >= abs(dy):\n            for x in range(x0, x1 + 1):\n                if dx == 0:\n                    y = y0\n                else:\n                    y = y0 + int(round((x - x0) * dy / float((dx))))\n                self.point(x, y, char)\n        elif y0 < y1:\n            for y in range(y0, y1 + 1):\n                if dy == 0:\n                    x = x0\n                else:\n                    x = x0 + int(round((y - y0) * dx / float((dy))))\n                self.point(x, y, char)\n        else:\n            for y in range(y1, y0 + 1):\n                if dy == 0:\n                    x = x0\n                else:\n                    x = x1 + int(round((y - y1) * dx / float((dy))))\n                self.point(x, y, char)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef text(self, x, y, text):\n        for i, char in enumerate(text):\n            self.point(x + i, y, char)", "response": "Print a text on ASCII canvas."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef box(self, x0, y0, width, height):\n        assert width > 1\n        assert height > 1\n\n        width -= 1\n        height -= 1\n\n        for x in range(x0, x0 + width):\n            self.point(x, y0, \"-\")\n            self.point(x, y0 + height, \"-\")\n\n        for y in range(y0, y0 + height):\n            self.point(x0, y, \"|\")\n            self.point(x0 + width, y, \"|\")\n\n        self.point(x0, y0, \"+\")\n        self.point(x0 + width, y0, \"+\")\n        self.point(x0, y0 + height, \"+\")\n        self.point(x0 + width, y0 + height, \"+\")", "response": "Create a box on ASCII canvas."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the progress bar.", "response": "def refresh(self, line=None):\n        \"\"\"Refreshes progress bar.\"\"\"\n        # Just go away if it is locked. Will update next time\n        if not self._lock.acquire(False):\n            return\n\n        if line is None:\n            line = self._line\n\n        if sys.stdout.isatty() and line is not None:\n            self._writeln(line)\n            self._line = line\n\n        self._lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the progress bar for a specified target.", "response": "def update_target(self, name, current, total):\n        \"\"\"Updates progress bar for a specified target.\"\"\"\n        self.refresh(self._bar(name, current, total))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinishes the progress bar for a specified target.", "response": "def finish_target(self, name):\n        \"\"\"Finishes progress bar for a specified target.\"\"\"\n        # We have to write a msg about finished target\n        with self._lock:\n            pbar = self._bar(name, 100, 100)\n\n            if sys.stdout.isatty():\n                self.clearln()\n\n            self._print(pbar)\n\n            self._n_finished += 1\n            self._line = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _bar(self, target_name, current, total):\n        bar_len = 30\n\n        if total is None:\n            state = 0\n            percent = \"?% \"\n        else:\n            total = int(total)\n            state = int((100 * current) / total) if current < total else 100\n            percent = str(state) + \"% \"\n\n        if self._n_total > 1:\n            num = \"({}/{}): \".format(self._n_finished + 1, self._n_total)\n        else:\n            num = \"\"\n\n        n_sh = int((state * bar_len) / 100)\n        n_sp = bar_len - n_sh\n        pbar = \"[\" + \"#\" * n_sh + \" \" * n_sp + \"] \"\n\n        return num + pbar + percent + target_name", "response": "Make a progress bar out of info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_dir(self, dir_not_exists, output):\n    if not dir_not_exists:\n        lst = output.dir_cache\n        return {i[\"relpath\"]: i[\"md5\"] for i in lst}\n    return {}", "response": "Extract the content of the dvc tree file from the output directory"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef diff(self, a_ref, target=None, b_ref=None):\n    result = {}\n    diff_dct = self.scm.get_diff_trees(a_ref, b_ref=b_ref)\n    result[DIFF_A_REF] = diff_dct[DIFF_A_REF]\n    result[DIFF_B_REF] = diff_dct[DIFF_B_REF]\n    if diff_dct[DIFF_EQUAL]:\n        result[DIFF_EQUAL] = True\n        return result\n    result[DIFF_LIST] = []\n    diff_outs = _get_diff_outs(self, diff_dct)\n    if target is None:\n        result[DIFF_LIST] = [\n            _diff_royal(self, path, diff_outs[path]) for path in diff_outs\n        ]\n    elif target in diff_outs:\n        result[DIFF_LIST] = [_diff_royal(self, target, diff_outs[target])]\n    else:\n        msg = \"Have not found file/directory '{}' in the commits\"\n        raise FileNotInCommitError(msg.format(target))\n    return result", "response": "Gerenates diff message string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reproduce_stages(\n    G,\n    stages,\n    node,\n    force,\n    dry,\n    interactive,\n    ignore_build_cache,\n    no_commit,\n    downstream,\n):\n    r\"\"\"Derive the evaluation of the given node for the given graph.\n\n    When you _reproduce a stage_, you want to _evaluate the descendants_\n    to know if it make sense to _recompute_ it. A post-ordered search\n    will give us an order list of the nodes we want.\n\n    For example, let's say that we have the following pipeline:\n\n                               E\n                              / \\\n                             D   F\n                            / \\   \\\n                           B   C   G\n                            \\ /\n                             A\n\n    The derived evaluation of D would be: [A, B, C, D]\n\n    In case that `downstream` option is specifed, the desired effect\n    is to derive the evaluation starting from the given stage up to the\n    ancestors. However, the `networkx.ancestors` returns a set, without\n    any guarantee of any order, so we are going to reverse the graph and\n    use a pre-ordered search using the given stage as a starting point.\n\n                   E                                   A\n                  / \\                                 / \\\n                 D   F                               B   C   G\n                / \\   \\        --- reverse -->        \\ /   /\n               B   C   G                               D   F\n                \\ /                                     \\ /\n                 A                                       E\n\n    The derived evaluation of _downstream_ B would be: [B, D, E]\n    \"\"\"\n\n    import networkx as nx\n\n    if downstream:\n        # NOTE (py3 only):\n        # Python's `deepcopy` defaults to pickle/unpickle the object.\n        # Stages are complex objects (with references to `repo`, `outs`,\n        # and `deps`) that cause struggles when you try to serialize them.\n        # We need to create a copy of the graph itself, and then reverse it,\n        # instead of using graph.reverse() directly because it calls\n        # `deepcopy` underneath -- unless copy=False is specified.\n        pipeline = nx.dfs_preorder_nodes(G.copy().reverse(copy=False), node)\n    else:\n        pipeline = nx.dfs_postorder_nodes(G, node)\n\n    result = []\n    for n in pipeline:\n        try:\n            ret = _reproduce_stage(\n                stages, n, force, dry, interactive, no_commit\n            )\n\n            if len(ret) != 0 and ignore_build_cache:\n                # NOTE: we are walking our pipeline from the top to the\n                # bottom. If one stage is changed, it will be reproduced,\n                # which tells us that we should force reproducing all of\n                # the other stages down below, even if their direct\n                # dependencies didn't change.\n                force = True\n\n            result += ret\n        except Exception as ex:\n            raise ReproductionError(stages[n].relpath, ex)\n    return result", "response": "r Reproduces the stage objects for a given node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef istextfile(fname, blocksize=512):\n    with open(fname, \"rb\") as fobj:\n        block = fobj.read(blocksize)\n\n    if not block:\n        # An empty file is considered a valid text file\n        return True\n\n    if b\"\\x00\" in block:\n        # Files with null bytes are binary\n        return False\n\n    # Use translate's 'deletechars' argument to efficiently remove all\n    # occurrences of TEXT_CHARS from the block\n    nontext = block.translate(None, TEXT_CHARS)\n    return float(len(nontext)) / len(block) <= 0.30", "response": "Returns True if the given file is a text file or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef csv_reader(unicode_csv_data, dialect=None, **kwargs):\n    import csv\n\n    dialect = dialect or csv.excel\n\n    if is_py3:\n        # Python3 supports encoding by default, so just return the object\n        for row in csv.reader(unicode_csv_data, dialect=dialect, **kwargs):\n            yield [cell for cell in row]\n\n    else:\n        # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n        reader = csv.reader(\n            utf_8_encoder(unicode_csv_data), dialect=dialect, **kwargs\n        )\n        for row in reader:\n            # decode UTF-8 back to Unicode, cell by cell:\n            yield [unicode(cell, \"utf-8\") for cell in row]", "response": "CSV reader that supports Unicode input."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncast a string to bytes.", "response": "def cast_bytes(s, encoding=None):\n    \"\"\"Source: https://github.com/ipython/ipython_genutils\"\"\"\n    if not isinstance(s, bytes):\n        return encode(s, encoding)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _makedirs(name, mode=0o777, exist_ok=False):\n    head, tail = os.path.split(name)\n    if not tail:\n        head, tail = os.path.split(head)\n    if head and tail and not os.path.exists(head):\n        try:\n            _makedirs(head, exist_ok=exist_ok)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        cdir = os.curdir\n        if isinstance(tail, bytes):\n            cdir = bytes(os.curdir, \"ASCII\")\n        if tail == cdir:\n            return\n    try:\n        os.mkdir(name, mode)\n    except OSError:\n        if not exist_ok or not os.path.isdir(name):\n            raise", "response": "Create a new directory if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install(self, address, target_dir, select=[], fname=None):\n\n    if not os.path.isdir(target_dir):\n        raise DvcException(\n            \"target directory '{}' does not exist\".format(target_dir)\n        )\n\n    curr_dir = os.path.realpath(os.curdir)\n    if not os.path.realpath(target_dir).startswith(curr_dir):\n        raise DvcException(\n            \"the current directory should be a subdirectory of the target \"\n            \"dir '{}'\".format(target_dir)\n        )\n\n    addresses = [address] if address else PackageManager.read_packages()\n    for addr in addresses:\n        mgr = PackageManager.get_package(addr)\n        mgr.install_or_update(self, address, target_dir, select, fname)", "response": "Installs the DVC package in the DVC project root."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_import(self):\n        return not self.cmd and len(self.deps) == 1 and len(self.outs) == 1", "response": "Whether the stage file was created with dvc import."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing mainly for dvc remove -- outs and Stage. produce.", "response": "def remove_outs(self, ignore_remove=False, force=False):\n        \"\"\"Used mainly for `dvc remove --outs` and :func:`Stage.reproduce`.\"\"\"\n        for out in self.outs:\n            if out.persist and not force:\n                out.unprotect()\n            else:\n                logger.debug(\n                    \"Removing output '{out}' of '{stage}'.\".format(\n                        out=out, stage=self.relpath\n                    )\n                )\n                out.remove(ignore_remove=ignore_remove)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if this stage has been already ran and stored", "response": "def is_cached(self):\n        \"\"\"\n        Checks if this stage has been already ran and stored\n        \"\"\"\n        from dvc.remote.local import RemoteLOCAL\n        from dvc.remote.s3 import RemoteS3\n\n        old = Stage.load(self.repo, self.path)\n        if old._changed_outs():\n            return False\n\n        # NOTE: need to save checksums for deps in order to compare them\n        # with what is written in the old stage.\n        for dep in self.deps:\n            dep.save()\n\n        old_d = old.dumpd()\n        new_d = self.dumpd()\n\n        # NOTE: need to remove checksums from old dict in order to compare\n        # it to the new one, since the new one doesn't have checksums yet.\n        old_d.pop(self.PARAM_MD5, None)\n        new_d.pop(self.PARAM_MD5, None)\n        outs = old_d.get(self.PARAM_OUTS, [])\n        for out in outs:\n            out.pop(RemoteLOCAL.PARAM_CHECKSUM, None)\n            out.pop(RemoteS3.PARAM_CHECKSUM, None)\n\n        if old_d != new_d:\n            return False\n\n        # NOTE: committing to prevent potential data duplication. For example\n        #\n        #    $ dvc config cache.type hardlink\n        #    $ echo foo > foo\n        #    $ dvc add foo\n        #    $ rm -f foo\n        #    $ echo foo > foo\n        #    $ dvc add foo # should replace foo with a link to cache\n        #\n        old.commit()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlaunching a dvc daemon command in a detached process.", "response": "def daemon(args):\n    \"\"\"Launch a `dvc daemon` command in a detached process.\n\n    Args:\n        args (list): list of arguments to append to `dvc daemon` command.\n    \"\"\"\n    if os.environ.get(DVC_DAEMON):\n        logger.debug(\"skipping launching a new daemon.\")\n        return\n\n    cmd = [sys.executable]\n    if not is_binary():\n        cmd += [\"-m\", \"dvc\"]\n    cmd += [\"daemon\", \"-q\"] + args\n\n    env = fix_env()\n    file_path = os.path.abspath(inspect.stack()[0][1])\n    env[cast_bytes_py2(\"PYTHONPATH\")] = cast_bytes_py2(\n        os.path.dirname(os.path.dirname(file_path))\n    )\n    env[cast_bytes_py2(DVC_DAEMON)] = cast_bytes_py2(\"1\")\n\n    _spawn(cmd, env)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parsed_cmd(self):\n        if len(self.args.command) < 2:\n            return \" \".join(self.args.command)\n\n        return \" \".join(self._quote_argument(arg) for arg in self.args.command)", "response": "Parse the command line and return the result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_parser(subparsers, parent_parser):\n    INIT_HELP = \"Initialize DVC in the current directory.\"\n    INIT_DESCRIPTION = (\n        \"Initialize DVC in the current directory. Expects directory\\n\"\n        \"to be a Git repository unless --no-scm option is specified.\"\n    )\n\n    init_parser = subparsers.add_parser(\n        \"init\",\n        parents=[parent_parser],\n        description=append_doc_link(INIT_DESCRIPTION, \"init\"),\n        help=INIT_HELP,\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    init_parser.add_argument(\n        \"--no-scm\",\n        action=\"store_true\",\n        default=False,\n        help=\"Initiate dvc in directory that is \"\n        \"not tracked by any scm tool (e.g. git).\",\n    )\n    init_parser.add_argument(\n        \"-f\",\n        \"--force\",\n        action=\"store_true\",\n        default=False,\n        help=(\n            \"Overwrite existing '.dvc' directory. \"\n            \"This operation removes local cache.\"\n        ),\n    )\n    init_parser.set_defaults(func=CmdInit)", "response": "Setup parser for dvc init."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _format_csv(content, delimiter):\n    reader = csv_reader(StringIO(content), delimiter=builtin_str(delimiter))\n    rows = [row for row in reader]\n    max_widths = [max(map(len, column)) for column in zip(*rows)]\n\n    lines = [\n        \" \".join(\n            \"{entry:{width}}\".format(entry=entry, width=width + 2)\n            for entry, width in zip(row, max_widths)\n        )\n        for row in rows\n    ]\n\n    return \"\\n\".join(lines)", "response": "Format delimited text to have same column width."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _format_output(content, typ):\n\n    if \"csv\" in str(typ):\n        return _format_csv(content, delimiter=\",\")\n\n    if \"tsv\" in str(typ):\n        return _format_csv(content, delimiter=\"\\t\")\n\n    return content", "response": "Tabularize the content according to its type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngathers all the metrics from the given path.", "response": "def _collect_metrics(repo, path, recursive, typ, xpath, branch):\n    \"\"\"Gather all the metric outputs.\n\n    Args:\n        path (str): Path to a metric file or a directory.\n        recursive (bool): If path is a directory, do a recursive search for\n            metrics on the given path.\n        typ (str): The type of metric to search for, could be one of the\n            following (raw|json|tsv|htsv|csv|hcsv).\n        xpath (str): Path to search for.\n        branch (str): Branch to look up for metrics.\n\n    Returns:\n        list(tuple): (output, typ, xpath)\n            - output:\n            - typ:\n            - xpath:\n    \"\"\"\n    outs = [out for stage in repo.stages() for out in stage.outs]\n\n    if path:\n        try:\n            outs = repo.find_outs_by_path(path, outs=outs, recursive=recursive)\n        except OutputNotFoundError:\n            logger.debug(\n                \"stage file not for found for '{}' in branch '{}'\".format(\n                    path, branch\n                )\n            )\n            return []\n\n    res = []\n    for o in outs:\n        if not o.metric:\n            continue\n\n        if not typ and isinstance(o.metric, dict):\n            t = o.metric.get(o.PARAM_METRIC_TYPE, typ)\n            x = o.metric.get(o.PARAM_METRIC_XPATH, xpath)\n        else:\n            t = typ\n            x = xpath\n\n        res.append((o, t, x))\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_metrics(repo, metrics, branch):\n    res = {}\n    for out, typ, xpath in metrics:\n        assert out.scheme == \"local\"\n        if not typ:\n            typ = os.path.splitext(out.path.lower())[1].replace(\".\", \"\")\n        if out.use_cache:\n            open_fun = open\n            path = repo.cache.local.get(out.checksum)\n        else:\n            open_fun = repo.tree.open\n            path = out.path\n        try:\n\n            with open_fun(path) as fd:\n                metric = _read_metric(\n                    fd,\n                    typ=typ,\n                    xpath=xpath,\n                    rel_path=out.rel_path,\n                    branch=branch,\n                )\n        except IOError as e:\n            if e.errno == errno.ENOENT:\n                logger.warning(\n                    NO_METRICS_FILE_AT_REFERENCE_WARNING.format(\n                        out.rel_path, branch\n                    )\n                )\n                metric = None\n            else:\n                raise\n\n        if not metric:\n            continue\n\n        res[out.rel_path] = metric\n\n    return res", "response": "Read the content of each metric file and format it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef graph(self, stages=None, from_directory=None):\n        import networkx as nx\n        from dvc.exceptions import (\n            OutputDuplicationError,\n            StagePathAsOutputError,\n            OverlappingOutputPathsError,\n        )\n\n        G = nx.DiGraph()\n        G_active = nx.DiGraph()\n        stages = stages or self.stages(from_directory, check_dag=False)\n        stages = [stage for stage in stages if stage]\n        outs = []\n\n        for stage in stages:\n            for out in stage.outs:\n                existing = []\n                for o in outs:\n                    if o.path == out.path:\n                        existing.append(o.stage)\n\n                    in_o_dir = out.path.startswith(o.path + o.sep)\n                    in_out_dir = o.path.startswith(out.path + out.sep)\n                    if in_o_dir or in_out_dir:\n                        raise OverlappingOutputPathsError(o, out)\n\n                if existing:\n                    stages = [stage.relpath, existing[0].relpath]\n                    raise OutputDuplicationError(out.path, stages)\n\n                outs.append(out)\n\n        for stage in stages:\n            path_dir = os.path.dirname(stage.path) + os.sep\n            for out in outs:\n                if path_dir.startswith(out.path + os.sep):\n                    raise StagePathAsOutputError(stage.wdir, stage.relpath)\n\n        for stage in stages:\n            node = os.path.relpath(stage.path, self.root_dir)\n\n            G.add_node(node, stage=stage)\n            G_active.add_node(node, stage=stage)\n\n            for dep in stage.deps:\n                for out in outs:\n                    if (\n                        out.path != dep.path\n                        and not dep.path.startswith(out.path + out.sep)\n                        and not out.path.startswith(dep.path + dep.sep)\n                    ):\n                        continue\n\n                    dep_stage = out.stage\n                    dep_node = os.path.relpath(dep_stage.path, self.root_dir)\n                    G.add_node(dep_node, stage=dep_stage)\n                    G.add_edge(node, dep_node)\n                    if not stage.locked:\n                        G_active.add_node(dep_node, stage=dep_stage)\n                        G_active.add_edge(node, dep_node)\n\n        self._check_cyclic_graph(G)\n\n        return G, G_active", "response": "Generate a graph of the nodes of the current stage and the edges of the other stages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of Stage objects that are added to the DVC.", "response": "def stages(self, from_directory=None, check_dag=True):\n        \"\"\"\n        Walks down the root directory looking for Dvcfiles,\n        skipping the directories that are related with\n        any SCM (e.g. `.git`), DVC itself (`.dvc`), or directories\n        tracked by DVC (e.g. `dvc add data` would skip `data/`)\n\n        NOTE: For large repos, this could be an expensive\n              operation. Consider using some memoization.\n        \"\"\"\n        from dvc.stage import Stage\n\n        if not from_directory:\n            from_directory = self.root_dir\n        elif not os.path.isdir(from_directory):\n            raise TargetNotDirectoryError(from_directory)\n\n        stages = []\n        outs = []\n\n        ignore_file_handler = DvcIgnoreFileHandler(self.tree)\n        for root, dirs, files in self.tree.walk(\n            from_directory, ignore_file_handler=ignore_file_handler\n        ):\n            for fname in files:\n                path = os.path.join(root, fname)\n                if not Stage.is_valid_filename(path):\n                    continue\n                stage = Stage.load(self, path)\n                for out in stage.outs:\n                    outs.append(out.path + out.sep)\n                stages.append(stage)\n\n            def filter_dirs(dname, root=root):\n                path = os.path.join(root, dname)\n                if path in (self.dvc_dir, self.scm.dir):\n                    return False\n                for out in outs:\n                    if path == os.path.normpath(out) or path.startswith(out):\n                        return False\n                return True\n\n            dirs[:] = list(filter(filter_dirs, dirs))\n\n        if check_dag:\n            self.check_dag(stages)\n\n        return stages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new line if progress bar hasn t finished", "response": "def _progress_aware(self):\n        \"\"\"Add a new line if progress bar hasn't finished\"\"\"\n        from dvc.progress import progress\n\n        if not progress.is_finished:\n            progress._print()\n        progress.clearln()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self, path, binary=False):\n        if binary:\n            return open(path, \"rb\")\n        return open(path, encoding=\"utf-8\")", "response": "Open file and return a stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading config for list object api paginate through list objects.", "response": "def _list_paths(self, bucket, prefix):\n        \"\"\" Read config for list object api, paginate through list objects.\"\"\"\n        s3 = self.s3\n        kwargs = {\"Bucket\": bucket, \"Prefix\": prefix}\n        if self.list_objects:\n            list_objects_api = \"list_objects\"\n        else:\n            list_objects_api = \"list_objects_v2\"\n        paginator = s3.get_paginator(list_objects_api)\n        for page in paginator.paginate(**kwargs):\n            contents = page.get(\"Contents\", None)\n            if not contents:\n                continue\n            for item in contents:\n                yield item[\"Key\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_path(path, config_file):\n        if os.path.isabs(path):\n            return path\n        return os.path.relpath(path, os.path.dirname(config_file))", "response": "Resolve path relative to config file location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_diff_trees(self, a_ref, b_ref=None):\n        diff_dct = {DIFF_EQUAL: False}\n        trees, commit_refs = self._get_diff_trees(a_ref, b_ref)\n        diff_dct[DIFF_A_REF] = commit_refs[0]\n        diff_dct[DIFF_B_REF] = commit_refs[1]\n        if commit_refs[0] == commit_refs[1]:\n            diff_dct[DIFF_EQUAL] = True\n            return diff_dct\n        diff_dct[DIFF_A_TREE] = trees[DIFF_A_TREE]\n        diff_dct[DIFF_B_TREE] = trees[DIFF_B_TREE]\n        return diff_dct", "response": "Method for getting two repo trees between two git tag commits\n            returns the dvc hash names of changed file and directory tree that are not in the same git tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the data has changed.", "response": "def changed(self, path_info, checksum_info):\n        \"\"\"Checks if data has changed.\n\n        A file is considered changed if:\n            - It doesn't exist on the working directory (was unlinked)\n            - Checksum is not computed (saving a new file)\n            - The checkusm stored in the State is different from the given one\n            - There's no file in the cache\n\n        Args:\n            path_info: dict with path information.\n            checksum: expected checksum for this data.\n\n        Returns:\n            bool: True if data has changed, False otherwise.\n        \"\"\"\n\n        logger.debug(\n            \"checking if '{}'('{}') has changed.\".format(\n                path_info, checksum_info\n            )\n        )\n\n        if not self.exists(path_info):\n            logger.debug(\"'{}' doesn't exist.\".format(path_info))\n            return True\n\n        checksum = checksum_info.get(self.PARAM_CHECKSUM)\n        if checksum is None:\n            logger.debug(\"checksum for '{}' is missing.\".format(path_info))\n            return True\n\n        if self.changed_cache(checksum):\n            logger.debug(\n                \"cache for '{}'('{}') has changed.\".format(path_info, checksum)\n            )\n            return True\n\n        actual = self.save_info(path_info)[self.PARAM_CHECKSUM]\n        if checksum != actual:\n            logger.debug(\n                \"checksum '{}'(actual '{}') for '{}' has changed.\".format(\n                    checksum, actual, path_info\n                )\n            )\n            return True\n\n        logger.debug(\"'{}' hasn't changed.\".format(path_info))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef confirm(statement):\n    prompt = \"{statement} [y/n]\".format(statement=statement)\n    answer = _ask(prompt, limited_to=[\"yes\", \"no\", \"y\", \"n\"])\n    return answer and answer.startswith(\"y\")", "response": "Ask the user for confirmation about the specified statement."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(argv=None):\n    args = None\n    cmd = None\n\n    try:\n        args = parse_args(argv)\n\n        if args.quiet:\n            logger.setLevel(logging.CRITICAL)\n\n        elif args.verbose:\n            logger.setLevel(logging.DEBUG)\n\n        cmd = args.func(args)\n        ret = cmd.run_cmd()\n    except KeyboardInterrupt:\n        logger.exception(\"interrupted by the user\")\n        ret = 252\n    except NotDvcRepoError:\n        logger.exception(\"\")\n        ret = 253\n    except DvcParserError:\n        ret = 254\n    except Exception:  # pylint: disable=broad-except\n        logger.exception(\"unexpected error\")\n        ret = 255\n\n    Analytics().send_cmd(cmd, args, ret)\n\n    return ret", "response": "Run dvc CLI command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef supported_cache_type(types):\n    if isinstance(types, str):\n        types = [typ.strip() for typ in types.split(\",\")]\n    for typ in types:\n        if typ not in [\"reflink\", \"hardlink\", \"symlink\", \"copy\"]:\n            return False\n    return True", "response": "Checks if link type config option has a valid value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the global config location. E. g. ~. config", "response": "def get_global_config_dir():\n        \"\"\"Returns global config location. E.g. ~/.config/dvc/config.\n\n        Returns:\n            str: path to the global config directory.\n        \"\"\"\n        from appdirs import user_config_dir\n\n        return user_config_dir(\n            appname=Config.APPNAME, appauthor=Config.APPAUTHOR\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_system_config_dir():\n        from appdirs import site_config_dir\n\n        return site_config_dir(\n            appname=Config.APPNAME, appauthor=Config.APPAUTHOR\n        )", "response": "Returns the system config location. E. g. / etc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(dvc_dir):\n        config_file = os.path.join(dvc_dir, Config.CONFIG)\n        open(config_file, \"w+\").close()\n        return Config(dvc_dir)", "response": "Initializes dvc config.\n\n        Args:\n            dvc_dir (str): path to .dvc directory.\n\n        Returns:\n            dvc.config.Config: config object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload config from all the config files.", "response": "def load(self, validate=True):\n        \"\"\"Loads config from all the config files.\n\n        Args:\n            validate (bool): optional flag to tell dvc if it should validate\n                the config or just load it as is. 'True' by default.\n\n\n        Raises:\n            dvc.config.ConfigError: thrown if config has invalid format.\n        \"\"\"\n        self._load()\n        try:\n            self.config = self._load_config(self.system_config_file)\n            user = self._load_config(self.global_config_file)\n            config = self._load_config(self.config_file)\n            local = self._load_config(self.config_local_file)\n\n            # NOTE: schema doesn't support ConfigObj.Section validation, so we\n            # need to convert our config to dict before passing it to\n            for conf in [user, config, local]:\n                self.config = self._merge(self.config, conf)\n\n            if validate:\n                self.config = Schema(self.SCHEMA).validate(self.config)\n\n            # NOTE: now converting back to ConfigObj\n            self.config = configobj.ConfigObj(\n                self.config, write_empty_values=True\n            )\n            self.config.filename = self.config_file\n            self._resolve_paths(self.config, self.config_file)\n        except Exception as ex:\n            raise ConfigError(ex)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave config to config files.", "response": "def save(self, config=None):\n        \"\"\"Saves config to config files.\n\n        Args:\n            config (configobj.ConfigObj): optional config object to save.\n\n        Raises:\n            dvc.config.ConfigError: thrown if failed to write config file.\n        \"\"\"\n        if config is not None:\n            clist = [config]\n        else:\n            clist = [\n                self._system_config,\n                self._global_config,\n                self._repo_config,\n                self._local_config,\n            ]\n\n        for conf in clist:\n            if conf.filename is None:\n                continue\n\n            try:\n                logger.debug(\"Writing '{}'.\".format(conf.filename))\n                dname = os.path.dirname(os.path.abspath(conf.filename))\n                try:\n                    os.makedirs(dname)\n                except OSError as exc:\n                    if exc.errno != errno.EEXIST:\n                        raise\n                conf.write()\n            except Exception as exc:\n                msg = \"failed to write config '{}'\".format(conf.filename)\n                raise ConfigError(msg, exc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the remote settings for a given remote name.", "response": "def get_remote_settings(self, name):\n        import posixpath\n\n        \"\"\"\n        Args:\n            name (str): The name of the remote that we want to retrieve\n\n        Returns:\n            dict: The content beneath the given remote name.\n\n        Example:\n            >>> config = {'remote \"server\"': {'url': 'ssh://localhost/'}}\n            >>> get_remote_settings(\"server\")\n            {'url': 'ssh://localhost/'}\n        \"\"\"\n        settings = self.config[self.SECTION_REMOTE_FMT.format(name)]\n        parsed = urlparse(settings[\"url\"])\n\n        # Support for cross referenced remotes.\n        # This will merge the settings, giving priority to the outer reference.\n        # For example, having:\n        #\n        #       dvc remote add server ssh://localhost\n        #       dvc remote modify server user root\n        #       dvc remote modify server ask_password true\n        #\n        #       dvc remote add images remote://server/tmp/pictures\n        #       dvc remote modify images user alice\n        #       dvc remote modify images ask_password false\n        #       dvc remote modify images password asdf1234\n        #\n        # Results on a config dictionary like:\n        #\n        #       {\n        #           \"url\": \"ssh://localhost/tmp/pictures\",\n        #           \"user\": \"alice\",\n        #           \"password\": \"asdf1234\",\n        #           \"ask_password\": False,\n        #       }\n        #\n        if parsed.scheme == \"remote\":\n            reference = self.get_remote_settings(parsed.netloc)\n            url = posixpath.join(reference[\"url\"], parsed.path.lstrip(\"/\"))\n            merged = reference.copy()\n            merged.update(settings)\n            merged[\"url\"] = url\n            return merged\n\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unset(config, section, opt=None):\n        if section not in config.keys():\n            raise ConfigError(\"section '{}' doesn't exist\".format(section))\n\n        if opt is None:\n            del config[section]\n            return\n\n        if opt not in config[section].keys():\n            raise ConfigError(\n                \"option '{}.{}' doesn't exist\".format(section, opt)\n            )\n        del config[section][opt]\n\n        if not config[section]:\n            del config[section]", "response": "Unsets specified option and section in the config."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set(config, section, opt, value):\n        if section not in config.keys():\n            config[section] = {}\n\n        config[section][opt] = value", "response": "Sets specified option in the config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint option value from the config.", "response": "def show(config, section, opt):\n        \"\"\"Prints option value from the config.\n\n        Args:\n            config (configobj.ConfigObj): config to work on.\n            section (str): section name.\n            opt (str): option name.\n        \"\"\"\n        if section not in config.keys():\n            raise ConfigError(\"section '{}' doesn't exist\".format(section))\n\n        if opt not in config[section].keys():\n            raise ConfigError(\n                \"option '{}.{}' doesn't exist\".format(section, opt)\n            )\n\n        logger.info(config[section][opt])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move(self, from_path, to_path):\n    import dvc.output as Output\n    from dvc.stage import Stage\n\n    from_out = Output.loads_from(Stage(self), [from_path])[0]\n\n    to_path = _expand_target_path(from_path, to_path)\n\n    outs = self.find_outs_by_path(from_out.path)\n    assert len(outs) == 1\n    out = outs[0]\n    stage = out.stage\n\n    if not stage.is_data_source:\n        raise MoveNotDataSourceError(stage.relpath)\n\n    stage_name = os.path.splitext(os.path.basename(stage.path))[0]\n    from_name = os.path.basename(from_out.path)\n    if stage_name == from_name:\n        os.unlink(stage.path)\n\n        stage.path = os.path.join(\n            os.path.dirname(to_path),\n            os.path.basename(to_path) + Stage.STAGE_FILE_SUFFIX,\n        )\n\n        stage.wdir = os.path.abspath(\n            os.path.join(os.curdir, os.path.dirname(to_path))\n        )\n\n    to_out = Output.loads_from(\n        stage, [os.path.basename(to_path)], out.use_cache, out.metric\n    )[0]\n\n    with self.state:\n        out.move(to_out)\n\n    stage.dump()", "response": "Moves an output file and modifies the stage associated\n    to reflect the change on the pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(root_dir=os.curdir, no_scm=False, force=False):\n    root_dir = os.path.abspath(root_dir)\n    dvc_dir = os.path.join(root_dir, Repo.DVC_DIR)\n    scm = SCM(root_dir)\n    if isinstance(scm, NoSCM) and not no_scm:\n        raise InitError(\n            \"{repo} is not tracked by any supported scm tool (e.g. git). \"\n            \"Use '--no-scm' if you don't want to use any scm.\".format(\n                repo=root_dir\n            )\n        )\n\n    if os.path.isdir(dvc_dir):\n        if not force:\n            raise InitError(\n                \"'{repo}' exists. Use '-f' to force.\".format(\n                    repo=os.path.relpath(dvc_dir)\n                )\n            )\n\n        shutil.rmtree(dvc_dir)\n\n    os.mkdir(dvc_dir)\n\n    config = Config.init(dvc_dir)\n    proj = Repo(root_dir)\n\n    scm.add([config.config_file])\n\n    if scm.ignore_file:\n        scm.add([os.path.join(dvc_dir, scm.ignore_file)])\n        logger.info(\"\\nYou can now commit the changes to git.\\n\")\n\n    _welcome_message()\n\n    return proj", "response": "Creates an empty repo on the given directory and creates a new DVC directory with the configuration and cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a version with information about the git repository", "response": "def _generate_version(base_version):\n    \"\"\"Generate a version with information about the git repository\"\"\"\n    pkg_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n\n    if not _is_git_repo(pkg_dir) or not _have_git():\n        return base_version\n\n    if _is_release(pkg_dir, base_version) and not _is_dirty(pkg_dir):\n        return base_version\n\n    return \"{base_version}+{short_sha}{dirty}\".format(\n        base_version=base_version,\n        short_sha=_git_revision(pkg_dir).decode(\"utf-8\")[0:6],\n        dirty=\".mod\" if _is_dirty(pkg_dir) else \"\",\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether a git repository has uncommitted changes.", "response": "def _is_dirty(dir_path):\n    \"\"\"Check whether a git repository has uncommitted changes.\"\"\"\n    try:\n        subprocess.check_call([\"git\", \"diff\", \"--quiet\"], cwd=dir_path)\n        return False\n    except subprocess.CalledProcessError:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file_md5(fname):\n    from dvc.progress import progress\n    from dvc.istextfile import istextfile\n\n    if os.path.exists(fname):\n        hash_md5 = hashlib.md5()\n        binary = not istextfile(fname)\n        size = os.path.getsize(fname)\n        bar = False\n        if size >= LARGE_FILE_SIZE:\n            bar = True\n            msg = \"Computing md5 for a large file {}. This is only done once.\"\n            logger.info(msg.format(os.path.relpath(fname)))\n            name = os.path.relpath(fname)\n            total = 0\n\n        with open(fname, \"rb\") as fobj:\n            while True:\n                data = fobj.read(LOCAL_CHUNK_SIZE)\n                if not data:\n                    break\n\n                if bar:\n                    total += len(data)\n                    progress.update_target(name, total, size)\n\n                if binary:\n                    chunk = data\n                else:\n                    chunk = dos2unix(data)\n\n                hash_md5.update(chunk)\n\n        if bar:\n            progress.finish_target(name)\n\n        return (hash_md5.hexdigest(), hash_md5.digest())\n    else:\n        return (None, None)", "response": "get the md5 hexdigest and md5 digest of a file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a nested dict with the keys in exclude", "response": "def dict_filter(d, exclude=[]):\n    \"\"\"\n    Exclude specified keys from a nested dict\n    \"\"\"\n\n    if isinstance(d, list):\n        ret = []\n        for e in d:\n            ret.append(dict_filter(e, exclude))\n        return ret\n    elif isinstance(d, dict):\n        ret = {}\n        for k, v in d.items():\n            if isinstance(k, builtin_str):\n                k = str(k)\n\n            assert isinstance(k, str)\n            if k in exclude:\n                continue\n            ret[k] = dict_filter(v, exclude)\n        return ret\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copyfile(src, dest, no_progress_bar=False, name=None):\n    from dvc.progress import progress\n\n    copied = 0\n    name = name if name else os.path.basename(dest)\n    total = os.stat(src).st_size\n\n    if os.path.isdir(dest):\n        dest = os.path.join(dest, os.path.basename(src))\n\n    with open(src, \"rb\") as fsrc, open(dest, \"wb+\") as fdest:\n        while True:\n            buf = fsrc.read(LOCAL_CHUNK_SIZE)\n            if not buf:\n                break\n            fdest.write(buf)\n            copied += len(buf)\n            if not no_progress_bar:\n                progress.update_target(name, copied, total)\n\n    if not no_progress_bar:\n        progress.finish_target(name)", "response": "Copy file with progress bar"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a message in a specified color.", "response": "def colorize(message, color=None):\n    \"\"\"Returns a message in a specified color.\"\"\"\n    if not color:\n        return message\n\n    colors = {\n        \"green\": colorama.Fore.GREEN,\n        \"yellow\": colorama.Fore.YELLOW,\n        \"blue\": colorama.Fore.BLUE,\n        \"red\": colorama.Fore.RED,\n    }\n\n    return \"{color}{message}{nc}\".format(\n        color=colors.get(color, \"\"), message=message, nc=colorama.Fore.RESET\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef boxify(message, border_color=None):\n    lines = message.split(\"\\n\")\n    max_width = max(_visual_width(line) for line in lines)\n\n    padding_horizontal = 5\n    padding_vertical = 1\n\n    box_size_horizontal = max_width + (padding_horizontal * 2)\n\n    chars = {\"corner\": \"+\", \"horizontal\": \"-\", \"vertical\": \"|\", \"empty\": \" \"}\n\n    margin = \"{corner}{line}{corner}\\n\".format(\n        corner=chars[\"corner\"], line=chars[\"horizontal\"] * box_size_horizontal\n    )\n\n    padding_lines = [\n        \"{border}{space}{border}\\n\".format(\n            border=colorize(chars[\"vertical\"], color=border_color),\n            space=chars[\"empty\"] * box_size_horizontal,\n        )\n        * padding_vertical\n    ]\n\n    content_lines = [\n        \"{border}{space}{content}{space}{border}\\n\".format(\n            border=colorize(chars[\"vertical\"], color=border_color),\n            space=chars[\"empty\"] * padding_horizontal,\n            content=_visual_center(line, max_width),\n        )\n        for line in lines\n    ]\n\n    box_str = \"{margin}{padding}{content}{padding}{margin}\".format(\n        margin=colorize(margin, color=border_color),\n        padding=\"\".join(padding_lines),\n        content=\"\".join(content_lines),\n    )\n\n    return box_str", "response": "Put a message inside a box."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _visual_width(line):\n\n    return len(re.sub(colorama.ansitowin32.AnsiToWin32.ANSI_CSI_RE, \"\", line))", "response": "Get the number of columns required to display a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncenters align string according to it s visual width", "response": "def _visual_center(line, width):\n    \"\"\"Center align string according to it's visual width\"\"\"\n\n    spaces = max(width - _visual_width(line), 0)\n    left_padding = int(spaces / 2)\n    right_padding = spaces - left_padding\n\n    return (left_padding * \" \") + line + (right_padding * \" \")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfixes subparsers to fix bug in Python 3.", "response": "def fix_subparsers(subparsers):\n    \"\"\"Workaround for bug in Python 3. See more info at:\n        https://bugs.python.org/issue16308\n        https://github.com/iterative/dvc/issues/769\n\n        Args:\n            subparsers: subparsers to fix.\n    \"\"\"\n    from dvc.utils.compat import is_py3\n\n    if is_py3:  # pragma: no cover\n        subparsers.required = True\n        subparsers.dest = \"cmd\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_targets(self):\n        from dvc.stage import Stage\n\n        msg = \"assuming default target '{}'.\".format(Stage.STAGE_FILE)\n        logger.warning(msg)\n        return [Stage.STAGE_FILE]", "response": "Default targets for dvc repro and dvc pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SCM(root_dir, repo=None):  # pylint: disable=invalid-name\n    if Git.is_repo(root_dir) or Git.is_submodule(root_dir):\n        return Git(root_dir, repo=repo)\n\n    return NoSCM(root_dir, repo=repo)", "response": "Returns a SCM instance that corresponds to a repo at the specified root_dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an argument parser containing common arguments shared among all the commands.", "response": "def get_parent_parser():\n    \"\"\"Create instances of a parser containing common arguments shared among\n    all the commands.\n\n    When overwritting `-q` or `-v`, you need to instantiate a new object\n    in order to prevent some weird behavior.\n    \"\"\"\n    parent_parser = argparse.ArgumentParser(add_help=False)\n\n    log_level_group = parent_parser.add_mutually_exclusive_group()\n    log_level_group.add_argument(\n        \"-q\", \"--quiet\", action=\"store_true\", default=False, help=\"Be quiet.\"\n    )\n    log_level_group.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        default=False,\n        help=\"Be verbose.\",\n    )\n\n    return parent_parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing CLI arguments. Args: argv: optional list of arguments to parse. sys.argv is used by default. Raises: dvc.exceptions.DvcParserError: raised for argument parsing errors.", "response": "def parse_args(argv=None):\n    \"\"\"Parses CLI arguments.\n\n    Args:\n        argv: optional list of arguments to parse. sys.argv is used by default.\n\n    Raises:\n        dvc.exceptions.DvcParserError: raised for argument parsing errors.\n    \"\"\"\n    parent_parser = get_parent_parser()\n\n    # Main parser\n    desc = \"Data Version Control\"\n    parser = DvcParser(\n        prog=\"dvc\",\n        description=desc,\n        parents=[parent_parser],\n        formatter_class=argparse.RawTextHelpFormatter,\n    )\n\n    # NOTE: On some python versions action='version' prints to stderr\n    # instead of stdout https://bugs.python.org/issue18920\n    parser.add_argument(\n        \"-V\",\n        \"--version\",\n        action=VersionAction,\n        nargs=0,\n        help=\"Show program's version.\",\n    )\n\n    # Sub commands\n    subparsers = parser.add_subparsers(\n        title=\"Available Commands\",\n        metavar=\"COMMAND\",\n        dest=\"cmd\",\n        help=\"Use dvc COMMAND --help for command-specific help.\",\n    )\n\n    fix_subparsers(subparsers)\n\n    for cmd in COMMANDS:\n        cmd.add_parser(subparsers, parent_parser)\n\n    args = parser.parse_args(argv)\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_diff(src, dest):\n    Seq = (list, tuple)\n    Container = (Mapping, list, tuple)\n\n    def is_same_type(a, b):\n        return any(\n            isinstance(a, t) and isinstance(b, t)\n            for t in [str, Mapping, Seq, bool]\n        )\n\n    if isinstance(src, Mapping) and isinstance(dest, Mapping):\n        for key, value in src.items():\n            if isinstance(value, Container) and is_same_type(\n                value, dest.get(key)\n            ):\n                apply_diff(value, dest[key])\n            elif key not in dest or value != dest[key]:\n                dest[key] = value\n        for key in set(dest) - set(src):\n            del dest[key]\n    elif isinstance(src, Seq) and isinstance(dest, Seq):\n        if len(src) != len(dest):\n            dest[:] = src\n        else:\n            for i, value in enumerate(src):\n                if isinstance(value, Container) and is_same_type(\n                    value, dest[i]\n                ):\n                    apply_diff(value, dest[i])\n                elif value != dest[i]:\n                    dest[i] = value\n    else:\n        raise AssertionError(\n            \"Can't apply diff from {} to {}\".format(\n                src.__class__.__name__, dest.__class__.__name__\n            )\n        )", "response": "Recursively apply changes from src to dest."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef percent_cb(name, complete, total):\n    logger.debug(\n        \"{}: {} transferred out of {}\".format(\n            name, sizeof_fmt(complete), sizeof_fmt(total)\n        )\n    )\n    progress.update_target(name, complete, total)", "response": "Callback for updating target progress"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the MD5 of the file at the specified path.", "response": "def md5(self, path):\n        \"\"\"\n        Use different md5 commands depending on the OS:\n\n         - Darwin's `md5` returns BSD-style checksums by default\n         - Linux's `md5sum` needs the `--tag` flag for a similar output\n\n         Example:\n              MD5 (foo.txt) = f3d220a856b52aabbf294351e8a24300\n        \"\"\"\n        uname = self.execute(\"uname\").strip()\n\n        command = {\n            \"Darwin\": \"md5 {}\".format(path),\n            \"Linux\": \"md5sum --tag {}\".format(path),\n        }.get(uname)\n\n        if not command:\n            raise DvcException(\n                \"'{uname}' is not supported as a remote\".format(uname=uname)\n            )\n\n        md5 = self.execute(command).split()[-1]\n        assert len(md5) == 32\n        return md5"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload analytics report from json file specified by path.", "response": "def load(path):\n        \"\"\"Loads analytics report from json file specified by path.\n\n        Args:\n            path (str): path to json file with analytics report.\n        \"\"\"\n        with open(path, \"r\") as fobj:\n            analytics = Analytics(info=json.load(fobj))\n        os.unlink(path)\n        return analytics"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect_cmd(self, args, ret):\n        from dvc.command.daemon import CmdDaemonAnalytics\n\n        assert isinstance(ret, int) or ret is None\n\n        if ret is not None:\n            self.info[self.PARAM_CMD_RETURN_CODE] = ret\n\n        if args is not None and hasattr(args, \"func\"):\n            assert args.func != CmdDaemonAnalytics\n            self.info[self.PARAM_CMD_CLASS] = args.func.__name__", "response": "Collect analytics info from a CLI command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving analytics report to a temporary file.", "response": "def dump(self):\n        \"\"\"Save analytics report to a temporary file.\n\n        Returns:\n            str: path to the temporary file that contains the analytics report.\n        \"\"\"\n        import tempfile\n\n        with tempfile.NamedTemporaryFile(delete=False, mode=\"w\") as fobj:\n            json.dump(self.info, fobj)\n            return fobj.name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollects and send analytics for the given CLI command.", "response": "def send_cmd(cmd, args, ret):\n        \"\"\"Collect and send analytics for CLI command.\n\n        Args:\n            args (list): parsed args for the CLI command.\n            ret (int): return value of the CLI command.\n        \"\"\"\n        from dvc.daemon import daemon\n\n        if not Analytics._is_enabled(cmd):\n            return\n\n        analytics = Analytics()\n        analytics.collect_cmd(args, ret)\n        daemon([\"analytics\", analytics.dump()])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects and send analytics.", "response": "def send(self):\n        \"\"\"Collect and send analytics.\"\"\"\n        import requests\n\n        if not self._is_enabled():\n            return\n\n        self.collect()\n\n        logger.debug(\"Sending analytics: {}\".format(self.info))\n\n        try:\n            requests.post(self.URL, json=self.info, timeout=self.TIMEOUT_POST)\n        except requests.exceptions.RequestException as exc:\n            logger.debug(\"Failed to send analytics: {}\".format(str(exc)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push(self, targets, jobs=None, remote=None, show_checksums=False):\n        return self.repo.cache.local.push(\n            targets,\n            jobs=jobs,\n            remote=self._get_cloud(remote, \"push\"),\n            show_checksums=show_checksums,\n        )", "response": "Push data items to the cloud."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(self, targets, jobs=None, remote=None, show_checksums=False):\n        cloud = self._get_cloud(remote, \"status\")\n        return self.repo.cache.local.status(\n            targets, jobs=jobs, remote=cloud, show_checksums=show_checksums\n        )", "response": "Check status of data items in a cloud - agnostic way."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the file or directory has the expected md5.", "response": "def changed(self, path, md5):\n        \"\"\"Check if file/directory has the expected md5.\n\n        Args:\n            path (str): path to the file/directory to check.\n            md5 (str): expected md5.\n\n        Returns:\n            bool: True if path has the expected md5, False otherwise.\n        \"\"\"\n        actual = self.update(path)\n\n        msg = \"File '{}', md5 '{}', actual '{}'\"\n        logger.debug(msg.format(path, md5, actual))\n\n        if not md5 or not actual:\n            return True\n\n        return actual.split(\".\")[0] != md5.split(\".\")[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the state database.", "response": "def load(self):\n        \"\"\"Loads state database.\"\"\"\n        retries = 1\n        while True:\n            assert self.database is None\n            assert self.cursor is None\n            assert self.inserts == 0\n            empty = not os.path.exists(self.state_file)\n            self.database = sqlite3.connect(self.state_file)\n            self.cursor = self.database.cursor()\n\n            # Try loading once to check that the file is indeed a database\n            # and reformat it if it is not.\n            try:\n                self._prepare_db(empty=empty)\n                return\n            except sqlite3.DatabaseError:\n                self.cursor.close()\n                self.database.close()\n                self.database = None\n                self.cursor = None\n                self.inserts = 0\n                if retries > 0:\n                    os.unlink(self.state_file)\n                    retries -= 1\n                else:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, path_info, checksum):\n        assert path_info[\"scheme\"] == \"local\"\n        assert checksum is not None\n\n        path = path_info[\"path\"]\n        assert os.path.exists(path)\n\n        actual_mtime, actual_size = get_mtime_and_size(path)\n        actual_inode = get_inode(path)\n\n        existing_record = self.get_state_record_for_inode(actual_inode)\n        if not existing_record:\n            self._insert_new_state_record(\n                path, actual_inode, actual_mtime, actual_size, checksum\n            )\n            return\n\n        self._update_state_for_path_changed(\n            path, actual_inode, actual_mtime, actual_size, checksum\n        )", "response": "Save checksum for the specified path info."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the checksum for the specified path info.", "response": "def get(self, path_info):\n        \"\"\"Gets the checksum for the specified path info. Checksum will be\n        retrieved from the state database if available.\n\n        Args:\n            path_info (dict): path info to get the checksum for.\n\n        Returns:\n            str or None: checksum for the specified path info or None if it\n            doesn't exist in the state database.\n        \"\"\"\n        assert path_info[\"scheme\"] == \"local\"\n        path = path_info[\"path\"]\n\n        if not os.path.exists(path):\n            return None\n\n        actual_mtime, actual_size = get_mtime_and_size(path)\n        actual_inode = get_inode(path)\n\n        existing_record = self.get_state_record_for_inode(actual_inode)\n        if not existing_record:\n            return None\n\n        mtime, size, checksum, _ = existing_record\n        if self._file_metadata_changed(actual_mtime, mtime, actual_size, size):\n            return None\n\n        self._update_state_record_timestamp_for_inode(actual_inode)\n        return checksum"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_link(self, path_info):\n        assert path_info[\"scheme\"] == \"local\"\n        path = path_info[\"path\"]\n\n        if not os.path.exists(path):\n            return\n\n        mtime, _ = get_mtime_and_size(path)\n        inode = get_inode(path)\n        relpath = os.path.relpath(path, self.root_dir)\n\n        cmd = (\n            \"REPLACE INTO {}(path, inode, mtime) \"\n            'VALUES (\"{}\", {}, \"{}\")'.format(\n                self.LINK_STATE_TABLE, relpath, self._to_sqlite(inode), mtime\n            )\n        )\n        self._execute(cmd)", "response": "Save the specified path to the list of links created by dvc checkout."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_unused_links(self, used):\n        unused = []\n\n        self._execute(\"SELECT * FROM {}\".format(self.LINK_STATE_TABLE))\n        for row in self.cursor:\n            relpath, inode, mtime = row\n            inode = self._from_sqlite(inode)\n            path = os.path.join(self.root_dir, relpath)\n\n            if path in used:\n                continue\n\n            if not os.path.exists(path):\n                continue\n\n            actual_inode = get_inode(path)\n            actual_mtime, _ = get_mtime_and_size(path)\n\n            if inode == actual_inode and mtime == actual_mtime:\n                logger.debug(\"Removing '{}' as unused link.\".format(path))\n                remove(path)\n                unused.append(relpath)\n\n        for relpath in unused:\n            cmd = 'DELETE FROM {} WHERE path = \"{}\"'\n            self._execute(cmd.format(self.LINK_STATE_TABLE, relpath))", "response": "Removes all saved links except the ones that are used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_metrics(metrics, all_branches=False, all_tags=False):\n    for branch, val in metrics.items():\n        if all_branches or all_tags:\n            logger.info(\"{branch}:\".format(branch=branch))\n\n        for fname, metric in val.items():\n            lines = metric if type(metric) is list else metric.splitlines()\n\n            if len(lines) > 1:\n                logger.info(\"\\t{fname}:\".format(fname=fname))\n\n                for line in lines:\n                    logger.info(\"\\t\\t{content}\".format(content=line))\n\n            else:\n                logger.info(\"\\t{}: {}\".format(fname, metric))", "response": "Prints out the metrics in a log file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nacquire lock for dvc repo.", "response": "def lock(self):\n        \"\"\"Acquire lock for dvc repo.\"\"\"\n        try:\n            self._do_lock()\n            return\n        except LockError:\n            time.sleep(self.TIMEOUT)\n\n        self._do_lock()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_mail(window):\n    mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n\n    (retcode, capabilities) = mail.login(LOGIN_EMAIL, LOGIN_PASSWORD)\n    mail.list()\n    typ, data = mail.select('Inbox')\n    n = 0\n    now = datetime.now()\n    # get messages from today\n    search_string = '(SENTON {}-{}-{})'.format(now.day, calendar.month_abbr[now.month], now.year)\n    (retcode, messages) = mail.search(None, search_string)\n    if retcode == 'OK':\n        msg_list = messages[0].split()  # message numbers are separated by spaces, turn into list\n        msg_list.sort(reverse=True)  # sort messages descending\n        for n, message in enumerate(msg_list):\n            if n >= MAX_EMAILS:\n                break\n            from_elem = window.FindElement('{}from'.format(n))\n            date_elem = window.FindElement('{}date'.format(n))\n            from_elem.Update('')  # erase them so you know they're changing\n            date_elem.Update('')\n            window.Refresh()\n            typ, data = mail.fetch(message, '(RFC822)')\n            for response_part in data:\n                if isinstance(response_part, tuple):\n                    original = email.message_from_bytes(response_part[1])\n                    date_str = original['Date'][:22]\n                    from_elem.Update(original['From'])\n                    date_elem.Update(date_str)\n                    window.Refresh()", "response": "Reads late emails from IMAP server and displays them in the Window\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef runCommand(cmd, timeout=None):\n    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = ''\n\n    out, err = p.communicate()\n    p.wait(timeout)\n\n    return (out, err)", "response": "run shell command\n\n\t@param cmd: command to execute\n\t@param timeout: timeout for command execution\n\n\t@return: (return code from command, command output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nkilling a process tree with signal signal.", "response": "def kill_proc_tree(pid, sig=signal.SIGTERM, include_parent=True,\n                   timeout=None, on_terminate=None):\n    \"\"\"Kill a process tree (including grandchildren) with signal\n    \"sig\" and return a (gone, still_alive) tuple.\n    \"on_terminate\", if specified, is a callabck function which is\n    called as soon as a child terminates.\n    \"\"\"\n    if pid == os.getpid():\n        raise RuntimeError(\"I refuse to kill myself\")\n    parent = psutil.Process(pid)\n    children = parent.children(recursive=True)\n    if include_parent:\n        children.append(parent)\n    for p in children:\n        p.send_signal(sig)\n    gone, alive = psutil.wait_procs(children, timeout=timeout,\n                                    callback=on_terminate)\n    return (gone, alive)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Popup object from the given arguments.", "response": "def Popup(*args, **_3to2kwargs):\n    if 'location' in _3to2kwargs: location = _3to2kwargs['location']; del _3to2kwargs['location']\n    else: location = (None, None)\n    if 'keep_on_top' in _3to2kwargs: keep_on_top = _3to2kwargs['keep_on_top']; del _3to2kwargs['keep_on_top']\n    else: keep_on_top = False\n    if 'grab_anywhere' in _3to2kwargs: grab_anywhere = _3to2kwargs['grab_anywhere']; del _3to2kwargs['grab_anywhere']\n    else: grab_anywhere = False\n    if 'no_titlebar' in _3to2kwargs: no_titlebar = _3to2kwargs['no_titlebar']; del _3to2kwargs['no_titlebar']\n    else: no_titlebar = False\n    if 'font' in _3to2kwargs: font = _3to2kwargs['font']; del _3to2kwargs['font']\n    else: font = None\n    if 'line_width' in _3to2kwargs: line_width = _3to2kwargs['line_width']; del _3to2kwargs['line_width']\n    else: line_width = None\n    if 'icon' in _3to2kwargs: icon = _3to2kwargs['icon']; del _3to2kwargs['icon']\n    else: icon = DEFAULT_WINDOW_ICON\n    if 'non_blocking' in _3to2kwargs: non_blocking = _3to2kwargs['non_blocking']; del _3to2kwargs['non_blocking']\n    else: non_blocking = False\n    if 'custom_text' in _3to2kwargs: custom_text = _3to2kwargs['custom_text']; del _3to2kwargs['custom_text']\n    else: custom_text = (None, None)\n    if 'auto_close_duration' in _3to2kwargs: auto_close_duration = _3to2kwargs['auto_close_duration']; del _3to2kwargs['auto_close_duration']\n    else: auto_close_duration = None\n    if 'auto_close' in _3to2kwargs: auto_close = _3to2kwargs['auto_close']; del _3to2kwargs['auto_close']\n    else: auto_close = False\n    if 'button_type' in _3to2kwargs: button_type = _3to2kwargs['button_type']; del _3to2kwargs['button_type']\n    else: button_type = POPUP_BUTTONS_OK\n    if 'text_color' in _3to2kwargs: text_color = _3to2kwargs['text_color']; del _3to2kwargs['text_color']\n    else: text_color = None\n    if 'background_color' in _3to2kwargs: background_color = _3to2kwargs['background_color']; del _3to2kwargs['background_color']\n    else: background_color = None\n    if 'button_color' in _3to2kwargs: button_color = _3to2kwargs['button_color']; del _3to2kwargs['button_color']\n    else: button_color = None\n    if 'title' in _3to2kwargs: title = _3to2kwargs['title']; del _3to2kwargs['title']\n    else: title = None\n    \"\"\"\n    Popup - Display a popup box with as many parms as you wish to include\n    :param args:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param button_type:\n    :param auto_close:\n    :param auto_close_duration:\n    :param non_blocking:\n    :param icon:\n    :param line_width:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:\n    \"\"\"\n    if not args:\n        args_to_print = ['']\n    else:\n        args_to_print = args\n    if line_width != None:\n        local_line_width = line_width\n    else:\n        local_line_width = MESSAGE_BOX_LINE_WIDTH\n    _title =  title if title is not None else args_to_print[0]\n    window = Window(_title, auto_size_text=True, background_color=background_color, button_color=button_color,\n                    auto_close=auto_close, auto_close_duration=auto_close_duration, icon=icon, font=font,\n                    no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)\n    max_line_total, total_lines = 0, 0\n    for message in args_to_print:\n        # fancy code to check if string and convert if not is not need. Just always convert to string :-)\n        # if not isinstance(message, str): message = str(message)\n        message = str(message)\n        if message.count('\\n'):\n            message_wrapped = message\n        else:\n            message_wrapped = textwrap.fill(message, local_line_width)\n        message_wrapped_lines = message_wrapped.count('\\n') + 1\n        longest_line_len = max([len(l) for l in message.split('\\n')])\n        width_used = min(longest_line_len, local_line_width)\n        max_line_total = max(max_line_total, width_used)\n        # height = _GetNumLinesNeeded(message, width_used)\n        height = message_wrapped_lines\n        window.AddRow(\n            Text(message_wrapped, auto_size_text=True, text_color=text_color, background_color=background_color))\n        total_lines += height\n\n    if non_blocking:\n        PopupButton = DummyButton  # important to use or else button will close other windows too!\n    else:\n        PopupButton = CloseButton\n    # show either an OK or Yes/No depending on paramater\n    if custom_text != (None, None):\n        if type(custom_text) is not tuple:\n            window.AddRow(PopupButton(custom_text,size=(len(custom_text),1), button_color=button_color, focus=True, bind_return_key=True))\n        elif custom_text[1] is None:\n            window.AddRow(PopupButton(custom_text[0],size=(len(custom_text[0]),1), button_color=button_color, focus=True, bind_return_key=True))\n        else:\n            window.AddRow(PopupButton(custom_text[0], button_color=button_color, focus=True, bind_return_key=True, size=(len(custom_text[0]), 1)),\n                          PopupButton(custom_text[1], button_color=button_color, size=(len(custom_text[0]), 1)))\n    elif button_type is POPUP_BUTTONS_YES_NO:\n        window.AddRow(PopupButton('Yes', button_color=button_color, focus=True, bind_return_key=True, pad=((20, 5), 3),\n                                  size=(5, 1)), PopupButton('No', button_color=button_color, size=(5, 1)))\n    elif button_type is POPUP_BUTTONS_CANCELLED:\n        window.AddRow(\n            PopupButton('Cancelled', button_color=button_color, focus=True, bind_return_key=True, pad=((20, 0), 3)))\n    elif button_type is POPUP_BUTTONS_ERROR:\n        window.AddRow(PopupButton('Error', size=(6, 1), button_color=button_color, focus=True, bind_return_key=True,\n                                  pad=((20, 0), 3)))\n    elif button_type is POPUP_BUTTONS_OK_CANCEL:\n        window.AddRow(PopupButton('OK', size=(6, 1), button_color=button_color, focus=True, bind_return_key=True),\n                      PopupButton('Cancel', size=(6, 1), button_color=button_color))\n    elif button_type is POPUP_BUTTONS_NO_BUTTONS:\n        pass\n    else:\n        window.AddRow(PopupButton('OK', size=(5, 1), button_color=button_color, focus=True, bind_return_key=True,\n                                  pad=((20, 0), 3)))\n\n    if non_blocking:\n        button, values = window.Read(timeout=0)\n    else:\n        button, values = window.Read()\n\n    return button"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef PopupNoButtons(*args, **_3to2kwargs):\n    if 'location' in _3to2kwargs: location = _3to2kwargs['location']; del _3to2kwargs['location']\n    else: location = (None, None)\n    if 'keep_on_top' in _3to2kwargs: keep_on_top = _3to2kwargs['keep_on_top']; del _3to2kwargs['keep_on_top']\n    else: keep_on_top = False\n    if 'grab_anywhere' in _3to2kwargs: grab_anywhere = _3to2kwargs['grab_anywhere']; del _3to2kwargs['grab_anywhere']\n    else: grab_anywhere = False\n    if 'no_titlebar' in _3to2kwargs: no_titlebar = _3to2kwargs['no_titlebar']; del _3to2kwargs['no_titlebar']\n    else: no_titlebar = False\n    if 'font' in _3to2kwargs: font = _3to2kwargs['font']; del _3to2kwargs['font']\n    else: font = None\n    if 'line_width' in _3to2kwargs: line_width = _3to2kwargs['line_width']; del _3to2kwargs['line_width']\n    else: line_width = None\n    if 'icon' in _3to2kwargs: icon = _3to2kwargs['icon']; del _3to2kwargs['icon']\n    else: icon = DEFAULT_WINDOW_ICON\n    if 'non_blocking' in _3to2kwargs: non_blocking = _3to2kwargs['non_blocking']; del _3to2kwargs['non_blocking']\n    else: non_blocking = False\n    if 'auto_close_duration' in _3to2kwargs: auto_close_duration = _3to2kwargs['auto_close_duration']; del _3to2kwargs['auto_close_duration']\n    else: auto_close_duration = None\n    if 'auto_close' in _3to2kwargs: auto_close = _3to2kwargs['auto_close']; del _3to2kwargs['auto_close']\n    else: auto_close = False\n    if 'text_color' in _3to2kwargs: text_color = _3to2kwargs['text_color']; del _3to2kwargs['text_color']\n    else: text_color = None\n    if 'background_color' in _3to2kwargs: background_color = _3to2kwargs['background_color']; del _3to2kwargs['background_color']\n    else: background_color = None\n    if 'button_color' in _3to2kwargs: button_color = _3to2kwargs['button_color']; del _3to2kwargs['button_color']\n    else: button_color = None\n    if 'title' in _3to2kwargs: title = _3to2kwargs['title']; del _3to2kwargs['title']\n    else: title = None\n    \"\"\"\n    Show a Popup but without any buttons\n    :param args:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param auto_close:\n    :param auto_close_duration:\n    :param non_blocking:\n    :param icon:\n    :param line_width:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:\n    \"\"\"\n    Popup(*args, title=title, button_color=button_color, background_color=background_color, text_color=text_color,\n          button_type=POPUP_BUTTONS_NO_BUTTONS,\n          auto_close=auto_close, auto_close_duration=auto_close_duration, non_blocking=non_blocking, icon=icon,\n          line_width=line_width,\n          font=font, no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)", "response": "Popups a new window with no buttons."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the scroll region on the canvas", "response": "def set_scrollregion(self, event=None):\n        \"\"\" Set the scroll region on the canvas\"\"\"\n        self.canvas.configure(scrollregion=self.canvas.bbox('all'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures canvas for a new selection.", "response": "def _show_selection(self, text, bbox):\n        \"\"\"Configure canvas for a new selection.\"\"\"\n        x, y, width, height = bbox\n\n        textw = self._font.measure(text)\n\n        canvas = self._canvas\n        canvas.configure(width=width, height=height)\n        canvas.coords(canvas.text, width - textw, height / 2 - 1)\n        canvas.itemconfigure(canvas.text, text=text)\n        canvas.place(in_=self._calendar, x=x, y=y)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pressed(self, evt):\n        x, y, widget = evt.x, evt.y, evt.widget\n        item = widget.identify_row(y)\n        column = widget.identify_column(x)\n\n        if not column or not item in self._items:\n            # clicked in the weekdays row or just outside the columns\n            return\n\n        item_values = widget.item(item)['values']\n        if not len(item_values):  # row is empty for this month\n            return\n\n        text = item_values[int(column[1]) - 1]\n        if not text:  # date is empty\n            return\n\n        bbox = widget.bbox(item, column)\n        if not bbox:  # calendar not visible yet\n            return\n\n        # update and then show selection\n        text = '%02d' % text\n        self._selection = (text, item, column)\n        self._show_selection(text, bbox)\n        year, month = self._date.year, self._date.month\n        try:\n            self._TargetElement.Update(self.datetime(year, month, int(self._selection[0])))\n            if self._TargetElement.ChangeSubmits:\n                self._TargetElement.ParentForm.LastButtonClicked = self._TargetElement.Key\n                self._TargetElement.ParentForm.FormRemainedOpen = True\n                self._TargetElement.ParentForm.TKroot.quit()  # kick the users out of the mainloop\n        except:\n            pass\n        if self.close_when_chosen:\n            self._master.destroy()", "response": "Called when the user clicks the keypad in the calendar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prev_month(self):\n        self._canvas.place_forget()\n\n        self._date = self._date - self.timedelta(days=1)\n        self._date = self.datetime(self._date.year, self._date.month, 1)\n        self._build_calendar()", "response": "Update calendar to show the previous month."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates calendar to show the next month.", "response": "def _next_month(self):\n        \"\"\"Update calendar to show the next month.\"\"\"\n        self._canvas.place_forget()\n\n        year, month = self._date.year, self._date.month\n        self._date = self._date + self.timedelta(\n            days=calendar.monthrange(year, month)[1] + 1)\n        self._date = self.datetime(self._date.year, self._date.month, 1)\n        self._build_calendar()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a datetime representing the current selected date.", "response": "def selection(self):\n        \"\"\"Return a datetime representing the current selected date.\"\"\"\n        if not self._selection:\n            return None\n\n        year, month = self._date.year, self._date.month\n        return self.datetime(year, month, int(self._selection[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddRow(self, *args):\n        ''' Parms are a variable number of Elements '''\n        NumRows = len(self.Rows)  # number of existing rows is our row number\n        CurrentRowNumber = NumRows  # this row's number\n        CurrentRow = []  # start with a blank row and build up\n        # -------------------------  Add the elements to a row  ------------------------- #\n        for i, element in enumerate(args):  # Loop through list of elements and add them to the row\n            element.Position = (CurrentRowNumber, i)\n            element.ParentContainer = self\n            CurrentRow.append(element)\n        # -------------------------  Append the row to list of Rows  ------------------------- #\n        self.Rows.append(CurrentRow)", "response": "Adds a row to the list of rows."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the window s transparency .", "response": "def SetAlpha(self, alpha):\n        '''\n        Change the window's transparency\n        :param alpha: From 0 to 1 with 0 being completely transparent\n        :return:\n        '''\n        self._AlphaChannel = alpha\n        self.TKroot.attributes('-alpha', alpha)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset Card s color and escape code.", "response": "def setColor(self, color):\n        '''Sets Card's color and escape code.'''\n        if color == 'blue':\n            self.color = 'blue'\n            self.colorCode = self.colors['blue']\n            self.colorCodeDark = self.colors['dblue']\n        elif color == 'red':\n            self.color = 'red'\n            self.colorCode = self.colors['red']\n            self.colorCodeDark = self.colors['dred']\n        elif color == 'yellow':\n            self.color = 'yellow'\n            self.colorCode = self.colors['yellow']\n            self.colorCodeDark = self.colors['dyellow']\n        elif color == 'green':\n            self.color = 'green'\n            self.colorCode = self.colors['green']\n            self.colorCodeDark = self.colors['dgreen']\n        elif color == 'wild':  # No color modification\n            self.wild = True\n            self.color = 'wild'\n            self.colorCodeDark = self.colors['dwild']\n            self.colorCode = self.colors['wild']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_img_data(f, maxsize = (1200, 850), first = False):\n    img = Image.open(f)\n    img.thumbnail(maxsize)\n    if first:                     # tkinter is inactive the first time\n        bio = io.BytesIO()\n        img.save(bio, format = \"PNG\")\n        del img\n        return bio.getvalue()\n    return ImageTk.PhotoImage(img)", "response": "Generate image data using PIL PIL\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_one(myStats, destIP, hostname, timeout, mySeqNumber, packet_size, quiet=False):\n    delay = None\n\n    try:  # One could use UDP here, but it's obscure\n        mySocket = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.getprotobyname(\"icmp\"))\n    except socket.error as e:\n        print(\"failed. (socket error: '%s')\" % e.args[1])\n        raise  # raise the original error\n\n    my_ID = os.getpid() & 0xFFFF\n\n    sentTime = send_one_ping(mySocket, destIP, my_ID, mySeqNumber, packet_size)\n    if sentTime == None:\n        mySocket.close()\n        return delay\n\n    myStats.pktsSent += 1\n\n    recvTime, dataSize, iphSrcIP, icmpSeqNumber, iphTTL = receive_one_ping(mySocket, my_ID, timeout)\n\n    mySocket.close()\n\n    if recvTime:\n        delay = (recvTime - sentTime) * 1000\n        if not quiet:\n            print(\"%d bytes from %s: icmp_seq=%d ttl=%d time=%d ms\" % (\n                dataSize, socket.inet_ntoa(struct.pack(\"!I\", iphSrcIP)), icmpSeqNumber, iphTTL, delay)\n                  )\n        myStats.pktsRcvd += 1\n        myStats.totTime += delay\n        if myStats.minTime > delay:\n            myStats.minTime = delay\n        if myStats.maxTime < delay:\n            myStats.maxTime = delay\n    else:\n        delay = None\n        print(\"Request timed out.\")\n\n    return delay", "response": "Send one ping to the specified destination IP and return the delay on success."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quiet_ping(hostname, timeout=WAIT_TIMEOUT, count=NUM_PACKETS,\n               packet_size=PACKET_SIZE, path_finder=False):\n    \"\"\"\n    Same as verbose_ping, but the results are returned as tuple\n    \"\"\"\n    myStats = MyStats() # Reset the stats\n    mySeqNumber = 0 # Starting value\n\n    try:\n        destIP = socket.gethostbyname(hostname)\n    except socket.gaierror as e:\n        return 0,0,0,0\n\n    myStats.thisIP = destIP\n\n    # This will send packet that we dont care about 0.5 seconds before it starts\n    # acrutally pinging. This is needed in big MAN/LAN networks where you sometimes\n    # loose the first packet. (while the switches find the way... :/ )\n    if path_finder:\n        fakeStats = MyStats()\n        do_one(fakeStats, destIP, hostname, timeout,\n                        mySeqNumber, packet_size, quiet=True)\n        time.sleep(0.5)\n\n    for i in range(count):\n        delay = do_one(myStats, destIP, hostname, timeout,\n                        mySeqNumber, packet_size, quiet=True)\n\n        if delay == None:\n            delay = 0\n\n        mySeqNumber += 1\n\n        # Pause for the remainder of the MAX_SLEEP period (if applicable)\n        if (MAX_SLEEP > delay):\n            time.sleep((MAX_SLEEP - delay)/1000)\n\n    if myStats.pktsSent > 0:\n        myStats.fracLoss = (myStats.pktsSent - myStats.pktsRcvd)/myStats.pktsSent\n    if myStats.pktsRcvd > 0:\n        myStats.avrgTime = myStats.totTime / myStats.pktsRcvd\n\n    # return tuple(max_rtt, min_rtt, avrg_rtt, percent_lost)\n    return myStats.maxTime, myStats.minTime, myStats.avrgTime, myStats.fracLoss", "response": "This function is used to send a ping to the specified hostname and return the results as tuple\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_page(pno, zoom = False, max_size = None, first = False):\n    dlist = dlist_tab[pno]   # get display list of page number\n    if not dlist:            # create if not yet there\n        dlist_tab[pno] = doc[pno].getDisplayList()\n        dlist = dlist_tab[pno]\n    r = dlist.rect           # the page rectangle\n    clip = r\n    # ensure image fits screen:\n    # exploit, but do not exceed width or height\n    zoom_0 = 1\n    if max_size:\n        zoom_0 = min(1, max_size[0] / r.width, max_size[1] / r.height)\n        if zoom_0 == 1:\n            zoom_0 = min(max_size[0] / r.width, max_size[1] / r.height)\n    mat_0 = fitz.Matrix(zoom_0, zoom_0)\n\n    if not zoom:             # show total page\n        pix = dlist.getPixmap(matrix = mat_0, alpha=False)\n    else:\n        mp = r.tl + (r.br - r.tl) * 0.5     # page rect center\n        w2 = r.width / 2\n        h2 = r.height / 2\n        clip = r * 0.5\n        tl = zoom[0]          # old top-left\n        tl.x += zoom[1] * (w2 / 2)\n        tl.x = max(0, tl.x)\n        tl.x = min(w2, tl.x)\n        tl.y += zoom[2] * (h2 / 2)\n        tl.y = max(0, tl.y)\n        tl.y = min(h2, tl.y)\n        clip = fitz.Rect(tl, tl.x + w2, tl.y + h2)\n\n        mat = mat_0 * fitz.Matrix(2, 2)      # zoom matrix\n        pix = dlist.getPixmap(alpha=False, matrix=mat, clip=clip)\n\n    if first:                     # first call: tkinter still inactive\n        img = pix.getPNGData()    # so use fitz png output\n    else:                         # else take tk photo image\n        pilimg = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n        img = ImageTk.PhotoImage(pilimg)\n\n    return img, clip.tl", "response": "Return a PNG image for a document page number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncount the number of live neighbours around point i and j.", "response": "def live_neighbours(self, i, j):\n        \"\"\" Count the number of live neighbours around point (i, j). \"\"\"\n        s = 0  # The total number of live neighbours.\n        # Loop over all the neighbours.\n        for x in [i - 1, i, i + 1]:\n            for y in [j - 1, j, j + 1]:\n                if (x == i and y == j):\n                    continue  # Skip the current point itself - we only want to count the neighbours!\n                if (x != self.N and y != self.N):\n                    s += self.old_grid[x][y]\n                # The remaining branches handle the case where the neighbour is off the end of the grid.\n                # In this case, we loop back round such that the grid becomes a \"toroidal array\".\n                elif (x == self.N and y != self.N):\n                    s += self.old_grid[0][y]\n                elif (x != self.N and y == self.N):\n                    s += self.old_grid[x][0]\n                else:\n                    s += self.old_grid[0][0]\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play(self):\n\n        # Write the initial configuration to file.\n\n        self.t = 1  # Current time level\n        while self.t <= self.T:  # Evolve!\n            # print( \"At time level %d\" % t)\n\n            # Loop over each cell of the grid and apply Conway's rules.\n            for i in range(self.N):\n                for j in range(self.N):\n                    live = self.live_neighbours(i, j)\n                    if (self.old_grid[i][j] == 1 and live < 2):\n                        self.new_grid[i][j] = 0  # Dead from starvation.\n                    elif (self.old_grid[i][j] == 1 and (live == 2 or live == 3)):\n                        self.new_grid[i][j] = 1  # Continue living.\n                    elif (self.old_grid[i][j] == 1 and live > 3):\n                        self.new_grid[i][j] = 0  # Dead from overcrowding.\n                    elif (self.old_grid[i][j] == 0 and live == 3):\n                        self.new_grid[i][j] = 1  # Alive from reproduction.\n\n            # Output the new configuration.\n\n            # The new configuration becomes the old configuration for the next generation.\n            self.old_grid = self.new_grid.copy()\n            self.draw_board()\n            # Move on to the next time level\n            self.t += 1", "response": "Play Conway s Game of Life."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a human readable string reprentation of bytes", "response": "def human_size(bytes, units=[' bytes','KB','MB','GB','TB', 'PB', 'EB']):\n    \"\"\" Returns a human readable string reprentation of bytes\"\"\"\n    return str(bytes) + units[0] if bytes < 1024 else human_size(bytes>>10, units[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking and show a window (PySimpleGUI form) that takes user input and sends to the HowDoI web oracle Excellent example of 2 GUI concepts 1. Output Element that will show text in a scrolled window 2. Non-Window-Closing Buttons - These buttons will cause the form to return with the form's values, but doesn't close the form :return: never returns", "response": "def HowDoI():\n    '''\n    Make and show a window (PySimpleGUI form) that takes user input and sends to the HowDoI web oracle\n    Excellent example of 2 GUI concepts\n        1. Output Element that will show text in a scrolled window\n        2. Non-Window-Closing Buttons - These buttons will cause the form to return with the form's values, but doesn't close the form\n    :return: never returns\n    '''\n    # -------  Make a new Window  ------- #\n    sg.ChangeLookAndFeel('GreenTan')            # give our form a spiffy set of colors\n\n    layout =  [\n                [sg.Text('Ask and your answer will appear here....', size=(40, 1))],\n                [sg.MultilineOutput(size_px=(980, 400),key='_OUTPUT_' )],\n                # [ sg.Spin(values=(1, 2, 3, 4), initial_value=1, size=(2, 1), key='Num Answers', font='Helvetica 15'),\n                [ sg.Checkbox('Display Full Text', key='full text', font='Helvetica 15'),\n                sg.T('Command History', font='Helvetica 15'), sg.T('', size=(40,3), text_color=sg.BLUES[0], key='history')],\n                [sg.Multiline(size=(85, 5), enter_submits=True, key='query', do_not_clear=False),\n                sg.ReadButton('SEND', button_color=(sg.YELLOWS[0], sg.BLUES[0]), bind_return_key=True),\n                sg.Button('EXIT', button_color=(sg.YELLOWS[0], sg.GREENS[0]))]\n              ]\n\n    window = sg.Window('How Do I ??', default_element_size=(30,1), icon=DEFAULT_ICON, font=('Helvetica',' 17'), default_button_element_size=(8,2), return_keyboard_events=False, )\n    window.Layout(layout)\n    # ---===--- Loop taking in user input and using it to query HowDoI --- #\n    command_history = []\n    history_offset = 0\n    while True:\n        event, values = window.Read()\n        # print(event, values)\n        if type(event) is int:\n            event = str(event)\n        if event == 'SEND':\n            query = values['query'].rstrip()\n            window.Element('_OUTPUT_').Update(query, append=True)\n            print(query)\n            QueryHowDoI(query, 1, values['full text'], window)  # send the string to HowDoI\n            command_history.append(query)\n            history_offset = len(command_history)-1\n            window.FindElement('query').Update('')                       # manually clear input because keyboard events blocks clear\n            window.FindElement('history').Update('\\n'.join(command_history[-3:]))\n        elif event == None or event == 'EXIT':            # if exit button or closed using X\n            break\n        elif 'Up' in event and len(command_history):                                # scroll back in history\n            command = command_history[history_offset]\n            history_offset -= 1 * (history_offset > 0)      # decrement is not zero\n            window.FindElement('query').Update(command)\n        elif 'Down' in event and len(command_history):                              # scroll forward in history\n            history_offset += 1 * (history_offset < len(command_history)-1) # increment up to end of list\n            command = command_history[history_offset]\n            window.FindElement('query').Update(command)\n        elif 'Escape' in event:                            # clear currently line\n            window.FindElement('query').Update('')\n\n    window.Close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the HowDoI web engine and returns the result.", "response": "def QueryHowDoI(Query, num_answers, full_text, window:sg.Window):\n    '''\n    Kicks off a subprocess to send the 'Query' to HowDoI\n    Prints the result, which in this program will route to a gooeyGUI window\n    :param Query: text english question to ask the HowDoI web engine\n    :return: nothing\n    '''\n    howdoi_command = HOW_DO_I_COMMAND\n    full_text_option = ' -a' if full_text else ''\n    t = subprocess.Popen(howdoi_command + ' \\\"'+ Query + '\\\" -n ' + str(num_answers)+full_text_option, stdout=subprocess.PIPE)\n    (output, err) = t.communicate()\n    window.Element('_OUTPUT_').Update('{:^88}'.format(Query.rstrip()), append=True)\n    window.Element('_OUTPUT_').Update('_'*60, append=True)\n    window.Element('_OUTPUT_').Update(output.decode(\"utf-8\"), append=True)\n    exit_code = t.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_view_on_selected(self, widget, selected_item_key):\n        self.lbl.set_text('List selection: ' + self.listView.children[selected_item_key].get_text())", "response": "The selection event of the listView returns a key of the clicked event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PyplotArtistBoxPlots():\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # fake data\n    np.random.seed(937)\n    data = np.random.lognormal(size=(37, 4), mean=1.5, sigma=1.75)\n    labels = list('ABCD')\n    fs = 10  # fontsize\n\n    # demonstrate how to toggle the display of different elements:\n    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6, 6), sharey=True)\n    axes[0, 0].boxplot(data, labels=labels)\n    axes[0, 0].set_title('Default', fontsize=fs)\n\n    axes[0, 1].boxplot(data, labels=labels, showmeans=True)\n    axes[0, 1].set_title('showmeans=True', fontsize=fs)\n\n    axes[0, 2].boxplot(data, labels=labels, showmeans=True, meanline=True)\n    axes[0, 2].set_title('showmeans=True,\\nmeanline=True', fontsize=fs)\n\n    axes[1, 0].boxplot(data, labels=labels, showbox=False, showcaps=False)\n    tufte_title = 'Tufte Style \\n(showbox=False,\\nshowcaps=False)'\n    axes[1, 0].set_title(tufte_title, fontsize=fs)\n\n    axes[1, 1].boxplot(data, labels=labels, notch=True, bootstrap=10000)\n    axes[1, 1].set_title('notch=True,\\nbootstrap=10000', fontsize=fs)\n\n    axes[1, 2].boxplot(data, labels=labels, showfliers=False)\n    axes[1, 2].set_title('showfliers=False', fontsize=fs)\n\n    for ax in axes.flatten():\n        ax.set_yscale('log')\n        ax.set_yticklabels([])\n\n    fig.subplots_adjust(hspace=0.4)\n    return fig", "response": "This function is a simple example of how to use the basic and standardized box plots for the given base - artist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef PyplotLineStyles():\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from collections import OrderedDict\n    from matplotlib.transforms import blended_transform_factory\n\n    linestyles = OrderedDict(\n        [('solid', (0, ())),\n         ('loosely dotted', (0, (1, 10))),\n         ('dotted', (0, (1, 5))),\n         ('densely dotted', (0, (1, 1))),\n\n         ('loosely dashed', (0, (5, 10))),\n         ('dashed', (0, (5, 5))),\n         ('densely dashed', (0, (5, 1))),\n\n         ('loosely dashdotted', (0, (3, 10, 1, 10))),\n         ('dashdotted', (0, (3, 5, 1, 5))),\n         ('densely dashdotted', (0, (3, 1, 1, 1))),\n\n         ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n         ('dashdotdotted', (0, (3, 5, 1, 5, 1, 5))),\n         ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))])\n\n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot(1, 1, 1)\n\n    X, Y = np.linspace(0, 100, 10), np.zeros(10)\n    for i, (name, linestyle) in enumerate(linestyles.items()):\n        ax.plot(X, Y + i, linestyle=linestyle, linewidth=1.5, color='black')\n\n    ax.set_ylim(-0.5, len(linestyles) - 0.5)\n    plt.yticks(np.arange(len(linestyles)), linestyles.keys())\n    plt.xticks([])\n\n    # For each line style, add a text annotation with a small offset from\n    # the reference point (0 in Axes coords, y tick value in Data coords).\n    reference_transform = blended_transform_factory(ax.transAxes, ax.transData)\n    for i, (name, linestyle) in enumerate(linestyles.items()):\n        ax.annotate(str(linestyle), xy=(0.0, i), xycoords=reference_transform,\n                    xytext=(-6, -12), textcoords='offset points', color=\"blue\",\n                    fontsize=8, ha=\"right\", family=\"monospace\")\n\n    plt.tight_layout()\n    return plt.gcf()", "response": "Plots the line styles of the Tikz - PGF."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts size in characters to size in pixels", "response": "def convert_tkinter_size_to_Qt(size):\n    \"\"\"\n    Converts size in characters to size in pixels\n    :param size:  size in characters, rows\n    :return: size in pixels, pixels\n    \"\"\"\n    qtsize = size\n    if size[1] is not None and size[1] < DEFAULT_PIXEL_TO_CHARS_CUTOFF:        # change from character based size to pixels (roughly)\n        qtsize = size[0]*DEFAULT_PIXELS_TO_CHARS_SCALING[0], size[1]*DEFAULT_PIXELS_TO_CHARS_SCALING[1]\n    return qtsize"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert from font string to Qt style sheet string", "response": "def create_style_from_font(font):\n    \"\"\"\n    Convert from font string/tyuple into a Qt style sheet string\n    :param font: \"Arial 10 Bold\" or ('Arial', 10, 'Bold)\n    :return: style string that can be combined with other style strings\n    \"\"\"\n\n    if font is None:\n        return ''\n\n    if type(font) is str:\n        _font = font.split(' ')\n    else:\n        _font = font\n\n    style = ''\n    style += 'font-family: %s;\\n' % _font[0]\n    style += 'font-size: %spt;\\n' % _font[1]\n    font_items = ''\n    for item in _font[2:]:\n        if item == 'underline':\n            style += 'text-decoration: underline;\\n'\n        else:\n            font_items += item + ' '\n    if font_items != '':\n        style += 'font: %s;\\n' % (font_items)\n    return style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PopupGetFolder(message, title=None, default_path='', no_window=False, size=(None, None), button_color=None,\n                   background_color=None, text_color=None, icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False,\n                   grab_anywhere=False, keep_on_top=False, location=(None, None), initial_folder=None):\n    \"\"\"\n    Display popup with text entry field and browse button. Browse for folder\n    :param message:\n    :param default_path:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return: Contents of text field. None if closed using X or cancelled\n    \"\"\"\n\n\n    if no_window:\n        if Window.QTApplication is None:\n            Window.QTApplication = QApplication(sys.argv)\n\n        folder_name = QFileDialog.getExistingDirectory(dir=initial_folder)\n        return folder_name\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=size), FolderBrowse(initial_folder=initial_folder)],\n              [CloseButton('Ok', size=(60, 20), bind_return_key=True), CloseButton('Cancel', size=(60, 20))]]\n\n    _title = title if title is not None else message\n    window = Window(title=_title, icon=icon, auto_size_text=True, button_color=button_color,\n                    background_color=background_color,\n                    font=font, no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top,\n                    location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path", "response": "Displays a popup with text entry field and browse button."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a popup with text entry field and browse button.", "response": "def PopupGetFile(message, title=None, default_path='', default_extension='', save_as=False, file_types=((\"ALL Files\", \"*\"),),\n                 no_window=False, size=(None, None), button_color=None, background_color=None, text_color=None,\n                 icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False, grab_anywhere=False, keep_on_top=False,\n                 location=(None, None), initial_folder=None):\n    \"\"\"\n        Display popup with text entry field and browse button. Browse for file\n    :param message:\n    :param default_path:\n    :param default_extension:\n    :param save_as:\n    :param file_types:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:  string representing the path chosen, None if cancelled or window closed with X\n    \"\"\"\n\n    if no_window:\n        if Window.QTApplication is None:\n            Window.QTApplication = QApplication(sys.argv)\n\n        if save_as:\n            qt_types = convert_tkinter_filetypes_to_qt(file_types)\n            filename = QFileDialog.getSaveFileName(dir=initial_folder, filter=qt_types)\n        else:\n            qt_types = convert_tkinter_filetypes_to_qt(file_types)\n            filename = QFileDialog.getOpenFileName(dir=initial_folder, filter=qt_types)\n        return filename[0]\n\n\n    browse_button = SaveAs(file_types=file_types, initial_folder=initial_folder) if save_as else FileBrowse(\n        file_types=file_types, initial_folder=initial_folder)\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=(30,1)), browse_button],\n              [CButton('Ok', size=(60, 20), bind_return_key=True), CButton('Cancel', size=(60, 20))]]\n\n    _title = title if title is not None else message\n\n    window = Window(title=_title, icon=icon, auto_size_text=True, button_color=button_color, font=font,\n                    background_color=background_color,\n                    no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n    # window.Close()\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay Popup with text entry field.", "response": "def PopupGetText(message, title=None, default_text='', password_char='', size=(None, None), button_color=None,\n                 background_color=None, text_color=None, icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False,\n                 grab_anywhere=False, keep_on_top=False, location=(None, None)):\n    \"\"\"\n    Display Popup with text entry field\n    :param message:\n    :param default_text:\n    :param password_char:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return: Text entered or None if window was closed\n    \"\"\"\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color, font=font)],\n              [InputText(default_text=default_text, size=size, password_char=password_char)],\n              [CloseButton('Ok', size=(60, 20), bind_return_key=True), CloseButton('Cancel', size=(60, 20))]]\n\n    _title = title if title is not None else message\n\n    window = Window(title=_title, icon=icon, auto_size_text=True, button_color=button_color, no_titlebar=no_titlebar,\n                    background_color=background_color, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top,\n                    location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n\n    if button != 'Ok':\n        return None\n    else:\n        return input_values[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the context menu and returns the item.", "response": "def Read(self, timeout=None):\n        '''\n        Reads the context menu\n        :param timeout: Optional.  Any value other than None indicates a non-blocking read\n        :return:\n        '''\n        if not self.Shown:\n            self.Shown = True\n            self.TrayIcon.show()\n        if timeout is None:\n            self.App.exec_()\n        elif timeout == 0:\n            self.App.processEvents()\n        else:\n            self.timer = start_systray_read_timer(self, timeout)\n            self.App.exec_()\n\n            if self.timer:\n                stop_timer(self.timer)\n\n        item = self.MenuItemChosen\n        self.MenuItemChosen = TIMEOUT_KEY\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ShowMessage(self, title, message, filename=None, data=None, data_base64=None, messageicon=None, time=10000):\n        '''\n        Shows a balloon above icon in system tray\n        :param title:  Title shown in balloon\n        :param message: Message to be displayed\n        :param filename: Optional icon filename\n        :param data: Optional in-ram icon\n        :param data_base64: Optional base64 icon\n        :param time: How long to display message in milliseconds\n        :return:\n        '''\n        qicon = None\n        if filename is not None:\n            qicon = QIcon(filename)\n        elif data is not None:\n            ba = QtCore.QByteArray.fromRawData(data)\n            pixmap = QtGui.QPixmap()\n            pixmap.loadFromData(ba)\n            qicon = QIcon(pixmap)\n        elif data_base64 is not None:\n            ba = QtCore.QByteArray.fromBase64(data_base64)\n            pixmap = QtGui.QPixmap()\n            pixmap.loadFromData(ba)\n            qicon = QIcon(pixmap)\n\n        if qicon is not None:\n            self.TrayIcon.showMessage(title, message, qicon, time)\n        elif messageicon is not None:\n            self.TrayIcon.showMessage(title, message, messageicon, time)\n        else:\n            self.TrayIcon.showMessage(title, message, QIcon(), time)\n\n        self.LastMessage = message\n        self.LastTitle = title\n        return self", "response": "Show a message in system tray."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the menu tooltip or icon with the given data.", "response": "def Update(self, menu=None, tooltip=None,filename=None, data=None, data_base64=None,):\n        '''\n        Updates the menu, tooltip or icon\n        :param menu: menu defintion\n        :param tooltip: string representing tooltip\n        :param filename:  icon filename\n        :param data:  icon raw image\n        :param data_base64: icon base 64 image\n        :return:\n        '''\n        # Menu\n        if menu is not None:\n            self.Menu = menu\n            qmenu = QMenu()\n            qmenu.setTitle(self.Menu[0])\n            AddTrayMenuItem(qmenu, self.Menu[1], self)\n            self.TrayIcon.setContextMenu(qmenu)\n        # Tooltip\n        if tooltip is not None:\n            self.TrayIcon.setToolTip(str(tooltip))\n        # Icon\n        qicon = None\n        if filename is not None:\n            qicon = QIcon(filename)\n        elif data is not None:\n            ba = QtCore.QByteArray.fromRawData(data)\n            pixmap = QtGui.QPixmap()\n            pixmap.loadFromData(ba)\n            qicon = QIcon(pixmap)\n        elif data_base64 is not None:\n            ba = QtCore.QByteArray.fromBase64(data_base64)\n            pixmap = QtGui.QPixmap()\n            pixmap.loadFromData(ba)\n            qicon = QIcon(pixmap)\n        if qicon is not None:\n            self.TrayIcon.setIcon(qicon)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the window s transparency.", "response": "def SetAlpha(self, alpha):\n        '''\n        Change the window's transparency\n        :param alpha: From 0 to 1 with 0 being completely transparent\n        :return:\n        '''\n        self._AlphaChannel = alpha\n        if self._AlphaChannel is not None:\n            self.QT_QMainWindow.setWindowOpacity(self._AlphaChannel)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert size in characters to size in pixels", "response": "def convert_tkinter_size_to_Wx(size):\n    \"\"\"\n    Converts size in characters to size in pixels\n    :param size:  size in characters, rows\n    :return: size in pixels, pixels\n    \"\"\"\n    qtsize = size\n    if size[1] is not None and size[1] < DEFAULT_PIXEL_TO_CHARS_CUTOFF:        # change from character based size to pixels (roughly)\n        qtsize = size[0]*DEFAULT_PIXELS_TO_CHARS_SCALING[0], size[1]*DEFAULT_PIXELS_TO_CHARS_SCALING[1]\n    return qtsize"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef font_to_wx_font(font):\n\n    if font is None:\n        return ''\n\n    if type(font) is str:\n        _font = font.split(' ')\n    else:\n        _font = font\n    name = _font[0]\n    family = _font[0]\n    point_size = int(_font[1])\n\n    # style = _font[2]\n\n    underline =  'underline' in _font[2:]\n    bold =  'bold' in _font\n\n    wxfont = wx.Font(point_size,\n                     wx.FONTFAMILY_DEFAULT,\n                     wx.FONTSTYLE_NORMAL,\n                     wx.FONTWEIGHT_BOLD if bold else wx.FONTWEIGHT_NORMAL,\n                     underline,\n                     faceName=family)\n\n    return wxfont", "response": "Convert a font string into a Qt style sheet string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a popup with text entry field and browse button.", "response": "def PopupGetFolder(message, title=None, default_path='', no_window=False, size=(None, None), button_color=None,\n                   background_color=None, text_color=None, icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False,\n                   grab_anywhere=False, keep_on_top=False, location=(None, None), initial_folder=None):\n    \"\"\"\n    Display popup with text entry field and browse button. Browse for folder\n    :param message:\n    :param default_path:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return: Contents of text field. None if closed using X or cancelled\n    \"\"\"\n\n\n    if no_window:\n        app = wx.App(False)\n        frame = wx.Frame()\n\n        if initial_folder:\n            dialog = wx.DirDialog(frame, style=wx.FD_OPEN)\n        else:\n            dialog = wx.DirDialog(frame)\n        folder_name = ''\n        if dialog.ShowModal() == wx.ID_OK:\n            folder_name = dialog.GetPath()\n        return folder_name\n\n\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=size), FolderBrowse(initial_folder=initial_folder)],\n              [Button('Ok', size=(60, 20), bind_return_key=True), Button('Cancel', size=(60, 20))]]\n\n    _title = title if title is not None else message\n    window = Window(title=_title, icon=icon, auto_size_text=True, button_color=button_color,\n                    background_color=background_color,\n                    font=font, no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top,\n                    location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n    window.Close()\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying a popup with text entry field and browse button.", "response": "def PopupGetFile(message, title=None, default_path='', default_extension='', save_as=False, file_types=((\"ALL Files\", \"*\"),),\n                 no_window=False, size=(None, None), button_color=None, background_color=None, text_color=None,\n                 icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False, grab_anywhere=False, keep_on_top=False,\n                 location=(None, None), initial_folder=None):\n    \"\"\"\n        Display popup with text entry field and browse button. Browse for file\n    :param message:\n    :param default_path:\n    :param default_extension:\n    :param save_as:\n    :param file_types:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:  string representing the path chosen, None if cancelled or window closed with X\n    \"\"\"\n\n    if no_window:\n        app = wx.App(False)\n        frame = wx.Frame()\n\n        qt_types = convert_tkinter_filetypes_to_wx(file_types)\n        style = wx.FD_SAVE if save_as else wx.FD_OPEN\n        if initial_folder:\n            dialog = wx.FileDialog(frame, defaultDir=initial_folder, wildcard=qt_types,\n                                   style=style)\n        else:\n            dialog = wx.FileDialog(frame, wildcard=qt_types, style=style)\n        if dialog.ShowModal() == wx.ID_OK:\n            file_name = dialog.GetPath()\n        else:\n            file_name = ''\n        return file_name\n\n    browse_button = SaveAs(file_types=file_types, initial_folder=initial_folder) if save_as else FileBrowse(\n        file_types=file_types, initial_folder=initial_folder)\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=(30,1)), browse_button],\n              [Button('Ok', size=(60, 20), bind_return_key=True), Button('Cancel', size=(60, 20))]]\n\n    _title = title if title is not None else message\n\n    window = Window(title=_title, icon=icon, auto_size_text=True, button_color=button_color, font=font,\n                    background_color=background_color,\n                    no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n    window.Close()\n    # window.Close()\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Read(self, timeout=None):\n        '''\n        Reads the context menu\n        :param timeout: Optional.  Any value other than None indicates a non-blocking read\n        :return:\n        '''\n        # if not self.Shown:\n        #     self.Shown = True\n        #     self.TrayIcon.show()\n        timeout1 = timeout\n        # if timeout1 == 0:\n        #     timeout1 = 1\n            # if wx.GetApp():\n            #     wx.GetApp().ProcessPendingEvents()\n            # self.App.ProcessPendingEvents()\n            # self.App.ProcessIdle()\n            # return self.MenuItemChosen\n        if timeout1 is not None:\n            try:\n                self.timer = wx.Timer(self.TaskBarIcon)\n                self.TaskBarIcon.Bind(wx.EVT_TIMER, self.timer_timeout)\n                self.timer.Start(milliseconds=timeout1, oneShot=wx.TIMER_ONE_SHOT)\n            except:\n                print('*** Got error in Read ***')\n        self.RunningMainLoop = True\n        self.App.MainLoop()\n        self.RunningMainLoop = False\n        if self.timer:\n            self.timer.Stop()\n        self.MenuItemChosen = self.TaskBarIcon.menu_item_chosen\n        return self.MenuItemChosen", "response": "Reads the context menu and returns the menu item that was chosen."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ShowMessage(self, title, message, filename=None, data=None, data_base64=None, messageicon=None, time=10000):\n        '''\n        Shows a balloon above icon in system tray\n        :param title:  Title shown in balloon\n        :param message: Message to be displayed\n        :param filename: Optional icon filename\n        :param data: Optional in-ram icon\n        :param data_base64: Optional base64 icon\n        :param time: How long to display message in milliseconds\n        :return:\n        '''\n        if messageicon is None:\n            self.TaskBarIcon.ShowBalloon(title, message, msec=time)\n        else:\n            self.TaskBarIcon.ShowBalloon(title, message, msec=time, flags=messageicon)\n\n        return self", "response": "Shows a balloon above icon in system tray."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the menu tooltip or icon", "response": "def Update(self, menu=None, tooltip=None,filename=None, data=None, data_base64=None,):\n        '''\n        Updates the menu, tooltip or icon\n        :param menu: menu defintion\n        :param tooltip: string representing tooltip\n        :param filename:  icon filename\n        :param data:  icon raw image\n        :param data_base64: icon base 64 image\n        :return:\n        '''\n        # Menu\n        if menu is not None:\n            self.TaskBarIcon.menu = menu\n        if filename:\n            self.icon = wx.Icon(filename, wx.BITMAP_TYPE_ANY)\n        elif data_base64:\n            self.icon = PyEmbeddedImage(data_base64).GetIcon()\n        elif not self.icon:\n            self.icon = PyEmbeddedImage(DEFAULT_BASE64_ICON).GetIcon()\n        if self.icon:\n            self.Tooltip = tooltip or self.Tooltip\n            self.TaskBarIcon.SetIcon(self.icon, tooltip=self.Tooltip)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_mouse(self, event):\n        '''\n        implement dragging\n        '''\n        # print('on_mouse')\n        if not event.Dragging():\n            self._dragPos = None\n            return\n        # self.CaptureMouse()\n        if not self._dragPos:\n            self._dragPos = event.GetPosition()\n        else:\n            pos = event.GetPosition()\n            displacement = self._dragPos - pos\n            self.SetPosition( self.GetPosition() - displacement )", "response": "implement dragging\n            implement dragging\n            implement dragging\n        implement dragging\n            implement dragging\n            implement dragging\n            implement dragging\n            implement dragging\n            implement dragging\n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the window s transparency by a factor of 255.", "response": "def SetAlpha(self, alpha):\n        '''\n        Change the window's transparency\n        :param alpha: From 0 to 1 with 0 being completely transparent\n        :return:\n        '''\n        self._AlphaChannel = alpha * 255\n        if self._AlphaChannel is not None:\n            self.MasterFrame.SetTransparent(self._AlphaChannel)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef worker_thread(thread_name, run_freq,  gui_queue):\n    print('Starting thread - {} that runds every {} ms'.format(thread_name, run_freq))\n    for i in itertools.count():                             # loop forever, keeping count in i as it loops\n        time.sleep(run_freq/1000)                           # sleep for a while\n        gui_queue.put('{} - {}'.format(thread_name, i))     # put a message into queue for GUI\n        print('..')", "response": "A worker thread that communicates with the GUI"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_one_ping(mySocket, destIP, myID, mySeqNumber, packet_size):\n    #destIP  =  socket.gethostbyname(destIP)\n\n    # Header is type (8), code (8), checksum (16), id (16), sequence (16)\n    # (packet_size - 8) - Remove header size from packet size\n    myChecksum = 0\n\n    # Make a dummy heder with a 0 checksum.\n    header = struct.pack(\n        \"!BBHHH\", ICMP_ECHO, 0, myChecksum, myID, mySeqNumber\n    )\n\n    padBytes = []\n    startVal = 0x42\n    # 'cose of the string/byte changes in python 2/3 we have\n    # to build the data differnely for different version\n    # or it will make packets with unexpected size.\n    if sys.version[:1] == '2':\n        bytes = struct.calcsize(\"d\")\n        data = ((packet_size - 8) - bytes) * \"Q\"\n        data = struct.pack(\"d\", default_timer()) + data\n    else:\n        for i in range(startVal, startVal + (packet_size-8)):\n            padBytes += [(i & 0xff)]  # Keep chars in the 0-255 range\n        #data = bytes(padBytes)\n        data = bytearray(padBytes)\n\n\n    # Calculate the checksum on the data and the dummy header.\n    myChecksum = checksum(header + data) # Checksum is in network order\n\n    # Now that we have the right checksum, we put that in. It's just easier\n    # to make up a new header than to stuff it into the dummy.\n    header = struct.pack(\n        \"!BBHHH\", ICMP_ECHO, 0, myChecksum, myID, mySeqNumber\n    )\n\n    packet = header + data\n\n    sendTime = default_timer()\n\n    try:\n        mySocket.sendto(packet, (destIP, 1)) # Port number is irrelevant for ICMP\n    except socket.error as e:\n        print(\"General failure (%s)\" % (e.args[1]))\n        return\n\n    return sendTime", "response": "Send one ping to the given destination IP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef receive_one_ping(mySocket, myID, timeout):\n    timeLeft = timeout/1000\n\n    while True: # Loop while waiting for packet or timeout\n        startedSelect = default_timer()\n        whatReady = select.select([mySocket], [], [], timeLeft)\n        howLongInSelect = (default_timer() - startedSelect)\n        if whatReady[0] == []: # Timeout\n            return None, 0, 0, 0, 0\n\n        timeReceived = default_timer()\n\n        recPacket, addr = mySocket.recvfrom(ICMP_MAX_RECV)\n\n        ipHeader = recPacket[:20]\n        iphVersion, iphTypeOfSvc, iphLength, \\\n        iphID, iphFlags, iphTTL, iphProtocol, \\\n        iphChecksum, iphSrcIP, iphDestIP = struct.unpack(\n            \"!BBHHHBBHII\", ipHeader\n        )\n\n        icmpHeader = recPacket[20:28]\n        icmpType, icmpCode, icmpChecksum, \\\n        icmpPacketID, icmpSeqNumber = struct.unpack(\n            \"!BBHHH\", icmpHeader\n        )\n\n        if icmpPacketID == myID: # Our packet\n            dataSize = len(recPacket) - 28\n            #print (len(recPacket.encode()))\n            return timeReceived, (dataSize+8), iphSrcIP, icmpSeqNumber, iphTTL\n\n        timeLeft = timeLeft - howLongInSelect\n        if timeLeft <= 0:\n            return None, 0, 0, 0, 0", "response": "Receive one ping from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns shell command @param cmd: command to execute @param timeout: timeout for command execution @param window: the PySimpleGUI window that the output is going to (needed to do refresh on) @return: (return code from command, command output)", "response": "def runCommand(cmd, timeout=None, window=None):\n    \"\"\" run shell command\n\t@param cmd: command to execute\n\t@param timeout: timeout for command execution\n\t@param window: the PySimpleGUI window that the output is going to (needed to do refresh on)\n\t@return: (return code from command, command output)\n\t\"\"\"\n    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    output = ''\n    for line in p.stdout:\n        line = line.decode(errors='replace' if (sys.version_info) < (3, 5) else 'backslashreplace').rstrip()\n        output += line\n        print(line)\n        window.Refresh() if window else None        # yes, a 1-line if, so shoot me\n\n    retval = p.wait(timeout)\n    return (retval, output)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert from font string to Qt style sheet string", "response": "def font_parse_string(font):\n    \"\"\"\n    Convert from font string/tyuple into a Qt style sheet string\n    :param font: \"Arial 10 Bold\" or ('Arial', 10, 'Bold)\n    :return: style string that can be combined with other style strings\n    \"\"\"\n\n    if font is None:\n        return ''\n\n    if type(font) is str:\n        _font = font.split(' ')\n    else:\n        _font = font\n    family = _font[0]\n    point_size = int(_font[1])\n\n    style = _font[2:] if len(_font) > 1 else None\n\n    # underline =  'underline' in _font[2:]\n    # bold =  'bold' in _font\n\n    return family, point_size, style"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and show a progress meter on the tbe caller s behalf.", "response": "def _ProgressMeter(title, max_value, *args, orientation=None, bar_color=(None, None), button_color=None,\n                   size=DEFAULT_PROGRESS_BAR_SIZE, border_width=None, grab_anywhere=False):\n    '''\n    Create and show a form on tbe caller's behalf.\n    :param title:\n    :param max_value:\n    :param args: ANY number of arguments the caller wants to display\n    :param orientation:\n    :param bar_color:\n    :param size:\n    :param Style:\n    :param StyleOffset:\n    :return: ProgressBar object that is in the form\n    '''\n    local_orientation = DEFAULT_METER_ORIENTATION if orientation is None else orientation\n    local_border_width = DEFAULT_PROGRESS_BAR_BORDER_WIDTH if border_width is None else border_width\n    bar2 = ProgressBar(max_value, orientation=local_orientation, size=size, bar_color=bar_color,\n                       border_width=local_border_width, relief=DEFAULT_PROGRESS_BAR_RELIEF)\n    form = Window(title, auto_size_text=True, grab_anywhere=grab_anywhere)\n\n    # Form using a horizontal bar\n    if local_orientation[0].lower() == 'h':\n        single_line_message, width, height = ConvertArgsToSingleString(*args)\n        bar2.TextToDisplay = single_line_message\n        bar2.TextToDisplay = single_line_message\n        bar2.MaxValue = max_value\n        bar2.CurrentValue = 0\n        bar_text = Text(single_line_message, size=(width, height + 3), auto_size_text=True)\n        form.AddRow(bar_text)\n        form.AddRow((bar2))\n        form.AddRow((CloseButton('Cancel', button_color=button_color)))\n    else:\n        single_line_message, width, height = ConvertArgsToSingleString(*args)\n        bar2.TextToDisplay = single_line_message\n        bar2.MaxValue = max_value\n        bar2.CurrentValue = 0\n        bar_text = Text(single_line_message, size=(width, height + 3), auto_size_text=True)\n        form.AddRow(bar2, bar_text)\n        form.AddRow((CloseButton('Cancel', button_color=button_color)))\n\n    form.NonBlocking = True\n    form.Show(non_blocking=True)\n    return bar2, bar_text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ProgressMeterUpdate(bar, value, text_elem, *args):\n    '''\n    Update the progress meter for a form\n    :param form: class ProgressBar\n    :param value: int\n    :return: True if not cancelled, OK....False if Error\n    '''\n    global _my_windows\n    if bar == None: return False\n    if bar.BarExpired: return False\n    message, w, h = ConvertArgsToSingleString(*args)\n    text_elem.Update(message)\n    # bar.TextToDisplay = message\n    bar.CurrentValue = value\n    rc = bar.UpdateBar(value)\n    if value >= bar.MaxValue or not rc:\n        bar.BarExpired = True\n        bar.ParentForm._Close()\n        if rc:  # if update was OK but bar expired, decrement num windows\n            _my_windows.Decrement()\n    if bar.ParentForm.RootNeedsDestroying:\n        try:\n            bar.ParentForm.TKroot.destroy()\n            # there is a bug with progress meters not decrementing the number of windows\n            # correctly when the X is used to close the window\n            # uncommenting this line fixes that problem, but causes a double-decrement when\n            # the cancel button is used... damned if you do, damned if you don't, so I'm choosing\n            # don't, as in don't decrement too many times. It's OK now to have a mismatch in\n            # number of windows because of the \"hidden\" master window. This ensures all windows\n            # will be toplevel.  Sorry about the bug, but the user never sees any problems as a result\n            # _my_windows.Decrement()\n        except:\n            pass\n        bar.ParentForm.RootNeedsDestroying = False\n        bar.ParentForm.__del__()\n        return False\n\n    return rc", "response": "Update the progress meter for a form\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef PopupNonBlocking(*args, button_type=POPUP_BUTTONS_OK, button_color=None, background_color=None, text_color=None,\n                     auto_close=False, auto_close_duration=None, non_blocking=True, icon=DEFAULT_WINDOW_ICON,\n                     line_width=None, font=None, no_titlebar=False, grab_anywhere=False, keep_on_top=False,\n                     location=(None, None)):\n    \"\"\"\n    Show Popup box and immediately return (does not block)\n    :param args:\n    :param button_type:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param auto_close:\n    :param auto_close_duration:\n    :param non_blocking:\n    :param icon:\n    :param line_width:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:\n    \"\"\"\n    Popup(*args, button_color=button_color, background_color=background_color, text_color=text_color,\n          button_type=button_type,\n          auto_close=auto_close, auto_close_duration=auto_close_duration, non_blocking=non_blocking, icon=icon,\n          line_width=line_width,\n          font=font, no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)", "response": "Show Popup box and immediately return."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PopupGetFolder(message, default_path='', no_window=False, size=(None, None), button_color=None,\n                   background_color=None, text_color=None, icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False,\n                   grab_anywhere=False, keep_on_top=False, location=(None, None), initial_folder=None):\n    \"\"\"\n    Display popup with text entry field and browse button. Browse for folder\n    :param message:\n    :param default_path:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return: Contents of text field. None if closed using X or cancelled\n    \"\"\"\n\n    global _my_windows\n\n    if no_window:\n        if _my_windows.NumOpenWindows:\n            root = tk.Toplevel()\n        else:\n            root = tk.Tk()\n        try:\n            root.attributes('-alpha', 0)  # hide window while building it. makes for smoother 'paint'\n        except:\n            pass\n        folder_name = tk.filedialog.askdirectory()  # show the 'get folder' dialog box\n        root.destroy()\n        return folder_name\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=size), FolderBrowse(initial_folder=initial_folder)],\n              [Button('Ok', size=(5, 1), bind_return_key=True), Button('Cancel', size=(5, 1))]]\n\n    window = Window(title=message, icon=icon, auto_size_text=True, button_color=button_color,\n                    background_color=background_color,\n                    font=font, no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top,\n                    location=location)\n\n    (button, input_values) = window.LayoutAndRead(layout)\n    window.Close()\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path", "response": "Displays a popup with text entry field and browse button."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a popup with text entry field and browse button.", "response": "def PopupGetFile(message, default_path='', default_extension='', save_as=False, file_types=((\"ALL Files\", \"*.*\"),),\n                 no_window=False, size=(None, None), button_color=None, background_color=None, text_color=None,\n                 icon=DEFAULT_WINDOW_ICON, font=None, no_titlebar=False, grab_anywhere=False, keep_on_top=False,\n                 location=(None, None), initial_folder=None):\n    \"\"\"\n        Display popup with text entry field and browse button. Browse for file\n    :param message:\n    :param default_path:\n    :param default_extension:\n    :param save_as:\n    :param file_types:\n    :param no_window:\n    :param size:\n    :param button_color:\n    :param background_color:\n    :param text_color:\n    :param icon:\n    :param font:\n    :param no_titlebar:\n    :param grab_anywhere:\n    :param keep_on_top:\n    :param location:\n    :return:  string representing the path chosen, None if cancelled or window closed with X\n    \"\"\"\n\n    global _my_windows\n\n    if no_window:\n        if _my_windows.NumOpenWindows:\n            root = tk.Toplevel()\n        else:\n            root = tk.Tk()\n        try:\n            root.attributes('-alpha', 0)  # hide window while building it. makes for smoother 'paint'\n        except:\n            pass\n        if save_as:\n            filename = tk.filedialog.asksaveasfilename(filetypes=file_types,\n                                                       defaultextension=default_extension)  # show the 'get file' dialog box\n        else:\n            filename = tk.filedialog.askopenfilename(filetypes=file_types,\n                                                     defaultextension=default_extension)  # show the 'get file' dialog box\n        root.destroy()\n        return filename\n\n    browse_button = SaveAs(file_types=file_types, initial_folder=initial_folder) if save_as else FileBrowse(\n        file_types=file_types, initial_folder=initial_folder)\n\n    layout = [[Text(message, auto_size_text=True, text_color=text_color, background_color=background_color)],\n              [InputText(default_text=default_path, size=size), browse_button],\n              [Button('Ok', size=(6, 1), bind_return_key=True), Button('Cancel', size=(6, 1))]]\n\n    window = Window(title=message, icon=icon, auto_size_text=True, button_color=button_color, font=font,\n                    background_color=background_color,\n                    no_titlebar=no_titlebar, grab_anywhere=grab_anywhere, keep_on_top=keep_on_top, location=location)\n\n    (button, input_values) = window.Layout(layout).Read()\n    window.Close()\n    if button != 'Ok':\n        return None\n    else:\n        path = input_values[0]\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay data in a table format", "response": "def TableSimulation():\n    \"\"\"\n    Display data in a table format\n    \"\"\"\n    sg.SetOptions(element_padding=(0,0))\n\n    menu_def = [['File', ['Open', 'Save', 'Exit']],\n                ['Edit', ['Paste', ['Special', 'Normal',], 'Undo'],],\n                ['Help', 'About...'],]\n\n    columm_layout = [[]]\n\n    MAX_ROWS = 20\n    MAX_COL = 10\n    for i in range(MAX_ROWS):\n        inputs = [sg.T('{}'.format(i), size=(4,1), justification='right')] + [sg.In(size=(10, 1), pad=(1, 1), justification='right', key=(i,j), do_not_clear=True) for j in range(MAX_COL)]\n        columm_layout.append(inputs)\n\n    layout = [ [sg.Menu(menu_def)],\n               [sg.T('Table Using Combos and Input Elements', font='Any 18')],\n               [sg.T('Type in a row, column and value. The form will update the values in realtime as you type'),\n               sg.In(key='inputrow', justification='right', size=(8,1), pad=(1,1), do_not_clear=True),\n               sg.In(key='inputcol', size=(8,1), pad=(1,1), justification='right', do_not_clear=True),\n               sg.In(key='value', size=(8,1), pad=(1,1), justification='right', do_not_clear=True)],\n               [sg.Column(columm_layout, size=(800,600), scrollable=True)] ]\n\n    window = sg.Window('Table', return_keyboard_events=True).Layout(layout)\n\n    while True:\n        event, values = window.Read()\n        # --- Process buttons --- #\n        if event is None or event == 'Exit':\n            break\n        elif event == 'About...':\n            sg.Popup('Demo of table capabilities')\n        elif event == 'Open':\n            filename = sg.PopupGetFile('filename to open', no_window=True, file_types=((\"CSV Files\",\"*.csv\"),))\n            # --- populate table with file contents --- #\n            if filename is not None:\n                with open(filename, \"r\") as infile:\n                    reader = csv.reader(infile)\n                    try:\n                        data = list(reader)  # read everything else into a list of rows\n                    except:\n                        sg.PopupError('Error reading file')\n                        continue\n                # clear the table\n                [window.FindElement((i,j)).Update('') for j in range(MAX_COL) for i in range(MAX_ROWS)]\n\n                for i, row in enumerate(data):\n                    for j, item in enumerate(row):\n                        location = (i,j)\n                        try:            # try the best we can at reading and filling the table\n                            target_element = window.FindElement(location)\n                            new_value = item\n                            if target_element is not None and new_value != '':\n                                target_element.Update(new_value)\n                        except:\n                            pass\n\n        # if a valid table location entered, change that location's value\n        try:\n            location = (int(values['inputrow']), int(values['inputcol']))\n            target_element = window.FindElement(location)\n            new_value = values['value']\n            if target_element is not None and new_value != '':\n                target_element.Update(new_value)\n        except:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef HowDoI():\n    '''\n    Make and show a window (PySimpleGUI form) that takes user input and sends to the HowDoI web oracle\n    Excellent example of 2 GUI concepts\n        1. Output Element that will show text in a scrolled window\n        2. Non-Window-Closing Buttons - These buttons will cause the form to return with the form's values, but doesn't close the form\n    :return: never returns\n    '''\n    # -------  Make a new Window  ------- #\n    sg.ChangeLookAndFeel('GreenTan')            # give our form a spiffy set of colors\n\n    layout =  [\n                [sg.Text('Ask and your answer will appear here....', size=(40, 1))],\n                [sg.Output(size=(127, 30), font=('Helvetica 10'))],\n                [ sg.Spin(values=(1, 2, 3, 4), initial_value=1, size=(2, 1), key='Num Answers', font='Helvetica 15'),\n                  sg.Text('Num Answers',font='Helvetica 15'), sg.Checkbox('Display Full Text', key='full text', font='Helvetica 15'),\n                sg.T('Command History', font='Helvetica 15'), sg.T('', size=(40,3), text_color=sg.BLUES[0], key='history')],\n                [sg.Multiline(size=(85, 5), enter_submits=True, key='query', do_not_clear=False),\n                sg.ReadButton('SEND', button_color=(sg.YELLOWS[0], sg.BLUES[0]), bind_return_key=True),\n                sg.Button('EXIT', button_color=(sg.YELLOWS[0], sg.GREENS[0]))]\n              ]\n\n    window = sg.Window('How Do I ??',\n                       default_element_size=(30, 2),\n                       font=('Helvetica',' 13'),\n                       default_button_element_size=(8,2),\n                       icon=DEFAULT_ICON,\n                       return_keyboard_events=True).Layout(layout)\n\n    # ---===--- Loop taking in user input and using it to query HowDoI --- #\n    command_history = []\n    history_offset = 0\n    while True:\n        (button, value) = window.Read()\n        if button is 'SEND':\n            query = value['query'].rstrip()\n            print(query)\n            QueryHowDoI(query, value['Num Answers'], value['full text'])  # send the string to HowDoI\n            command_history.append(query)\n            history_offset = len(command_history)-1\n            window.FindElement('query').Update('')                       # manually clear input because keyboard events blocks clear\n            window.FindElement('history').Update('\\n'.join(command_history[-3:]))\n        elif button is None or button is 'EXIT':            # if exit button or closed using X\n            break\n        elif 'Up' in button and len(command_history):                                # scroll back in history\n            command = command_history[history_offset]\n            history_offset -= 1 * (history_offset > 0)      # decrement is not zero\n            window.FindElement('query').Update(command)\n        elif 'Down' in button and len(command_history):                              # scroll forward in history\n            history_offset += 1 * (history_offset < len(command_history)-1) # increment up to end of list\n            command = command_history[history_offset]\n            window.FindElement('query').Update(command)\n        elif 'Escape' in button:                            # clear currently line\n            window.FindElement('query').Update('')", "response": "A function that returns a window that takes user input and sends to the HowDoI web oracle\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the HowDoI web engine and returns the result", "response": "def QueryHowDoI(Query, num_answers, full_text):\n    '''\n    Kicks off a subprocess to send the 'Query' to HowDoI\n    Prints the result, which in this program will route to a gooeyGUI window\n    :param Query: text english question to ask the HowDoI web engine\n    :return: nothing\n    '''\n    howdoi_command = HOW_DO_I_COMMAND\n    full_text_option = ' -a' if full_text else ''\n    t = subprocess.Popen(howdoi_command + ' \\\"'+ Query + '\\\" -n ' + str(num_answers)+full_text_option, stdout=subprocess.PIPE)\n    (output, err) = t.communicate()\n    print('{:^88}'.format(Query.rstrip()))\n    print('_'*60)\n    print(output.decode(\"utf-8\") )\n    exit_code = t.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting a module spec with weights taken from a checkpoint.", "response": "def export(self, path, _sentinel=None,  # pylint: disable=invalid-name\n             checkpoint_path=None, name_transform_fn=None):\n    \"\"\"Exports a ModuleSpec with weights taken from a checkpoint.\n\n    This is an helper to export modules directly from a ModuleSpec\n    without having to create a session and set the variables to the\n    intended values.\n\n    Example usage:\n\n    ```python\n    spec = hub.create_module_spec(module_fn)\n    spec.export(\"/path/to/export_module\",\n                checkpoint_path=\"/path/to/training_model\")\n    ```\n\n    In some cases, the variable name in the checkpoint does not match\n    the variable name in the module. It is possible to work around that\n    by providing a checkpoint_map_fn that performs the variable mapping.\n    For example with: `name_transform_fn = lambda x: \"extra_scope/\" + x`.\n\n    Args:\n      path: path where to export the module to.\n      _sentinel: used to prevent positional arguments besides `path`.\n      checkpoint_path: path where to load the weights for the module.\n        Mandatory parameter and must be passed by name.\n      name_transform_fn: optional function to provide mapping between\n        variable name in the module and the variable name in the checkpoint.\n\n    Raises:\n      ValueError: if missing mandatory `checkpoint_path` parameter.\n    \"\"\"\n    from tensorflow_hub.module import export_module_spec  # pylint: disable=g-import-not-at-top\n    if not checkpoint_path:\n      raise ValueError(\"Missing mandatory `checkpoint_path` parameter\")\n    name_transform_fn = name_transform_fn or (lambda x: x)\n    export_module_spec(self, path, checkpoint_path, name_transform_fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_attached_message(self, key, message_type, tags=None, required=False):\n    attached_bytes = self._get_attached_bytes(key, tags)\n    if attached_bytes is None:\n      if required:\n        raise KeyError(\"No attached message for key '%s' in graph version %s \"\n                       \"of Hub Module\" % (key, sorted(tags or [])))\n      else:\n        return None\n    message = message_type()\n    message.ParseFromString(attached_bytes)\n    return message", "response": "Returns the message contents attached to the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_image_lists(image_dir, testing_percentage, validation_percentage):\n  if not tf.gfile.Exists(image_dir):\n    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n    return None\n  result = collections.OrderedDict()\n  sub_dirs = sorted(x[0] for x in tf.gfile.Walk(image_dir))\n  # The root directory comes first, so skip it.\n  is_root_dir = True\n  for sub_dir in sub_dirs:\n    if is_root_dir:\n      is_root_dir = False\n      continue\n    extensions = sorted(set(os.path.normcase(ext)  # Smash case on Windows.\n                            for ext in ['JPEG', 'JPG', 'jpeg', 'jpg', 'png']))\n    file_list = []\n    dir_name = os.path.basename(\n        # tf.gfile.Walk() returns sub-directory with trailing '/' when it is in\n        # Google Cloud Storage, which confuses os.path.basename().\n        sub_dir[:-1] if sub_dir.endswith('/') else sub_dir)\n\n    if dir_name == image_dir:\n      continue\n    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n    for extension in extensions:\n      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n      file_list.extend(tf.gfile.Glob(file_glob))\n    if not file_list:\n      tf.logging.warning('No files found')\n      continue\n    if len(file_list) < 20:\n      tf.logging.warning(\n          'WARNING: Folder has less than 20 images, which may cause issues.')\n    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n      tf.logging.warning(\n          'WARNING: Folder {} has more than {} images. Some images will '\n          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n    training_images = []\n    testing_images = []\n    validation_images = []\n    for file_name in file_list:\n      base_name = os.path.basename(file_name)\n      # We want to ignore anything after '_nohash_' in the file name when\n      # deciding which set to put an image in, the data set creator has a way of\n      # grouping photos that are close variations of each other. For example\n      # this is used in the plant disease data set to group multiple pictures of\n      # the same leaf.\n      hash_name = re.sub(r'_nohash_.*$', '', file_name)\n      # This looks a bit magical, but we need to decide whether this file should\n      # go into the training, testing, or validation sets, and we want to keep\n      # existing files in the same set even if more files are subsequently\n      # added.\n      # To do that, we need a stable way of deciding based on just the file name\n      # itself, so we do a hash of that and then use that to generate a\n      # probability value that we use to assign it.\n      hash_name_hashed = hashlib.sha1(tf.compat.as_bytes(hash_name)).hexdigest()\n      percentage_hash = ((int(hash_name_hashed, 16) %\n                          (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n                         (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n      if percentage_hash < validation_percentage:\n        validation_images.append(base_name)\n      elif percentage_hash < (testing_percentage + validation_percentage):\n        testing_images.append(base_name)\n      else:\n        training_images.append(base_name)\n    result[label_name] = {\n        'dir': dir_name,\n        'training': training_images,\n        'testing': testing_images,\n        'validation': validation_images,\n    }\n  return result", "response": "Builds a list of training images from the file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_image_path(image_lists, label_name, index, image_dir, category):\n  if label_name not in image_lists:\n    tf.logging.fatal('Label does not exist %s.', label_name)\n  label_lists = image_lists[label_name]\n  if category not in label_lists:\n    tf.logging.fatal('Category does not exist %s.', category)\n  category_list = label_lists[category]\n  if not category_list:\n    tf.logging.fatal('Label %s has no images in the category %s.',\n                     label_name, category)\n  mod_index = index % len(category_list)\n  base_name = category_list[mod_index]\n  sub_dir = label_lists['dir']\n  full_path = os.path.join(image_dir, sub_dir, base_name)\n  return full_path", "response": "Returns a path to an image for a given label at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,\n                        category, module_name):\n  \"\"\"Returns a path to a bottleneck file for a label at the given index.\n\n  Args:\n    image_lists: OrderedDict of training images for each label.\n    label_name: Label string we want to get an image for.\n    index: Integer offset of the image we want. This will be moduloed by the\n    available number of images for the label, so it can be arbitrarily large.\n    bottleneck_dir: Folder string holding cached files of bottleneck values.\n    category: Name string of set to pull images from - training, testing, or\n    validation.\n    module_name: The name of the image module being used.\n\n  Returns:\n    File system path string to an image that meets the requested parameters.\n  \"\"\"\n  module_name = (module_name.replace('://', '~')  # URL scheme.\n                 .replace('/', '~')  # URL and Unix paths.\n                 .replace(':', '~').replace('\\\\', '~'))  # Windows paths.\n  return get_image_path(image_lists, label_name, index, bottleneck_dir,\n                        category) + '_' + module_name + '.txt'", "response": "Returns a path to a bottleneck file for a given label."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_module_graph(module_spec):\n  height, width = hub.get_expected_image_size(module_spec)\n  with tf.Graph().as_default() as graph:\n    resized_input_tensor = tf.placeholder(tf.float32, [None, height, width, 3])\n    m = hub.Module(module_spec)\n    bottleneck_tensor = m(resized_input_tensor)\n    wants_quantization = any(node.op in FAKE_QUANT_OPS\n                             for node in graph.as_graph_def().node)\n  return graph, bottleneck_tensor, resized_input_tensor, wants_quantization", "response": "Creates a graph and loads Hub Module into it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun inference on an image to extract the bottleneck summary layer.", "response": "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n                            decoded_image_tensor, resized_input_tensor,\n                            bottleneck_tensor):\n  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n\n  Args:\n    sess: Current active TensorFlow Session.\n    image_data: String of raw JPEG data.\n    image_data_tensor: Input data layer in the graph.\n    decoded_image_tensor: Output of initial image resizing and preprocessing.\n    resized_input_tensor: The input node of the recognition graph.\n    bottleneck_tensor: Layer before the final softmax.\n\n  Returns:\n    Numpy array of bottleneck values.\n  \"\"\"\n  # First decode the JPEG image, resize it, and rescale the pixel values.\n  resized_input_values = sess.run(decoded_image_tensor,\n                                  {image_data_tensor: image_data})\n  # Then run it through the recognition network.\n  bottleneck_values = sess.run(bottleneck_tensor,\n                               {resized_input_tensor: resized_input_values})\n  bottleneck_values = np.squeeze(bottleneck_values)\n  return bottleneck_values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n                           image_dir, category, sess, jpeg_data_tensor,\n                           decoded_image_tensor, resized_input_tensor,\n                           bottleneck_tensor):\n  \"\"\"Create a single bottleneck file.\"\"\"\n  tf.logging.debug('Creating bottleneck at ' + bottleneck_path)\n  image_path = get_image_path(image_lists, label_name, index,\n                              image_dir, category)\n  if not tf.gfile.Exists(image_path):\n    tf.logging.fatal('File does not exist %s', image_path)\n  image_data = tf.gfile.GFile(image_path, 'rb').read()\n  try:\n    bottleneck_values = run_bottleneck_on_image(\n        sess, image_data, jpeg_data_tensor, decoded_image_tensor,\n        resized_input_tensor, bottleneck_tensor)\n  except Exception as e:\n    raise RuntimeError('Error during processing file %s (%s)' % (image_path,\n                                                                 str(e)))\n  bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n  with open(bottleneck_path, 'w') as bottleneck_file:\n    bottleneck_file.write(bottleneck_string)", "response": "Create a single bottleneck file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve or creates a bottleneck file for an image.", "response": "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n                             category, bottleneck_dir, jpeg_data_tensor,\n                             decoded_image_tensor, resized_input_tensor,\n                             bottleneck_tensor, module_name):\n  \"\"\"Retrieves or calculates bottleneck values for an image.\n\n  If a cached version of the bottleneck data exists on-disk, return that,\n  otherwise calculate the data and save it to disk for future use.\n\n  Args:\n    sess: The current active TensorFlow Session.\n    image_lists: OrderedDict of training images for each label.\n    label_name: Label string we want to get an image for.\n    index: Integer offset of the image we want. This will be modulo-ed by the\n    available number of images for the label, so it can be arbitrarily large.\n    image_dir: Root folder string of the subfolders containing the training\n    images.\n    category: Name string of which set to pull images from - training, testing,\n    or validation.\n    bottleneck_dir: Folder string holding cached files of bottleneck values.\n    jpeg_data_tensor: The tensor to feed loaded jpeg data into.\n    decoded_image_tensor: The output of decoding and resizing the image.\n    resized_input_tensor: The input node of the recognition graph.\n    bottleneck_tensor: The output tensor for the bottleneck values.\n    module_name: The name of the image module being used.\n\n  Returns:\n    Numpy array of values produced by the bottleneck layer for the image.\n  \"\"\"\n  label_lists = image_lists[label_name]\n  sub_dir = label_lists['dir']\n  sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n  ensure_dir_exists(sub_dir_path)\n  bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n                                        bottleneck_dir, category, module_name)\n  if not os.path.exists(bottleneck_path):\n    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n                           image_dir, category, sess, jpeg_data_tensor,\n                           decoded_image_tensor, resized_input_tensor,\n                           bottleneck_tensor)\n  with open(bottleneck_path, 'r') as bottleneck_file:\n    bottleneck_string = bottleneck_file.read()\n  did_hit_error = False\n  try:\n    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n  except ValueError:\n    tf.logging.warning('Invalid float found, recreating bottleneck')\n    did_hit_error = True\n  if did_hit_error:\n    create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n                           image_dir, category, sess, jpeg_data_tensor,\n                           decoded_image_tensor, resized_input_tensor,\n                           bottleneck_tensor)\n    with open(bottleneck_path, 'r') as bottleneck_file:\n      bottleneck_string = bottleneck_file.read()\n    # Allow exceptions to propagate here, since they shouldn't happen after a\n    # fresh creation\n    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n  return bottleneck_values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring all the training, testing, and validation bottlenecks are cached. Because we're likely to read the same image multiple times (if there are no distortions applied during training) it can speed things up a lot if we calculate the bottleneck layer values once for each image during preprocessing, and then just read those cached values repeatedly during training. Here we go through all the images we've found, calculate those values, and save them off. Args: sess: The current active TensorFlow Session. image_lists: OrderedDict of training images for each label. image_dir: Root folder string of the subfolders containing the training images. bottleneck_dir: Folder string holding cached files of bottleneck values. jpeg_data_tensor: Input tensor for jpeg data from file. decoded_image_tensor: The output of decoding and resizing the image. resized_input_tensor: The input node of the recognition graph. bottleneck_tensor: The penultimate output layer of the graph. module_name: The name of the image module being used. Returns: Nothing.", "response": "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n                      jpeg_data_tensor, decoded_image_tensor,\n                      resized_input_tensor, bottleneck_tensor, module_name):\n  \"\"\"Ensures all the training, testing, and validation bottlenecks are cached.\n\n  Because we're likely to read the same image multiple times (if there are no\n  distortions applied during training) it can speed things up a lot if we\n  calculate the bottleneck layer values once for each image during\n  preprocessing, and then just read those cached values repeatedly during\n  training. Here we go through all the images we've found, calculate those\n  values, and save them off.\n\n  Args:\n    sess: The current active TensorFlow Session.\n    image_lists: OrderedDict of training images for each label.\n    image_dir: Root folder string of the subfolders containing the training\n    images.\n    bottleneck_dir: Folder string holding cached files of bottleneck values.\n    jpeg_data_tensor: Input tensor for jpeg data from file.\n    decoded_image_tensor: The output of decoding and resizing the image.\n    resized_input_tensor: The input node of the recognition graph.\n    bottleneck_tensor: The penultimate output layer of the graph.\n    module_name: The name of the image module being used.\n\n  Returns:\n    Nothing.\n  \"\"\"\n  how_many_bottlenecks = 0\n  ensure_dir_exists(bottleneck_dir)\n  for label_name, label_lists in image_lists.items():\n    for category in ['training', 'testing', 'validation']:\n      category_list = label_lists[category]\n      for index, unused_base_name in enumerate(category_list):\n        get_or_create_bottleneck(\n            sess, image_lists, label_name, index, image_dir, category,\n            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n            resized_input_tensor, bottleneck_tensor, module_name)\n\n        how_many_bottlenecks += 1\n        if how_many_bottlenecks % 100 == 0:\n          tf.logging.info(\n              str(how_many_bottlenecks) + ' bottleneck files created.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves bottleneck values for cached images. If no distortions are being applied, this function can retrieve the cached bottleneck values directly from disk for images. It picks a random set of images from the specified category. Args: sess: Current TensorFlow Session. image_lists: OrderedDict of training images for each label. how_many: If positive, a random sample of this size will be chosen. If negative, all bottlenecks will be retrieved. category: Name string of which set to pull from - training, testing, or validation. bottleneck_dir: Folder string holding cached files of bottleneck values. image_dir: Root folder string of the subfolders containing the training images. jpeg_data_tensor: The layer to feed jpeg image data into. decoded_image_tensor: The output of decoding and resizing the image. resized_input_tensor: The input node of the recognition graph. bottleneck_tensor: The bottleneck output layer of the CNN graph. module_name: The name of the image module being used. Returns: List of bottleneck arrays, their corresponding ground truths, and the relevant filenames.", "response": "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n                                  decoded_image_tensor, resized_input_tensor,\n                                  bottleneck_tensor, module_name):\n  \"\"\"Retrieves bottleneck values for cached images.\n\n  If no distortions are being applied, this function can retrieve the cached\n  bottleneck values directly from disk for images. It picks a random set of\n  images from the specified category.\n\n  Args:\n    sess: Current TensorFlow Session.\n    image_lists: OrderedDict of training images for each label.\n    how_many: If positive, a random sample of this size will be chosen.\n    If negative, all bottlenecks will be retrieved.\n    category: Name string of which set to pull from - training, testing, or\n    validation.\n    bottleneck_dir: Folder string holding cached files of bottleneck values.\n    image_dir: Root folder string of the subfolders containing the training\n    images.\n    jpeg_data_tensor: The layer to feed jpeg image data into.\n    decoded_image_tensor: The output of decoding and resizing the image.\n    resized_input_tensor: The input node of the recognition graph.\n    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n    module_name: The name of the image module being used.\n\n  Returns:\n    List of bottleneck arrays, their corresponding ground truths, and the\n    relevant filenames.\n  \"\"\"\n  class_count = len(image_lists.keys())\n  bottlenecks = []\n  ground_truths = []\n  filenames = []\n  if how_many >= 0:\n    # Retrieve a random sample of bottlenecks.\n    for unused_i in range(how_many):\n      label_index = random.randrange(class_count)\n      label_name = list(image_lists.keys())[label_index]\n      image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n      image_name = get_image_path(image_lists, label_name, image_index,\n                                  image_dir, category)\n      bottleneck = get_or_create_bottleneck(\n          sess, image_lists, label_name, image_index, image_dir, category,\n          bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n          resized_input_tensor, bottleneck_tensor, module_name)\n      bottlenecks.append(bottleneck)\n      ground_truths.append(label_index)\n      filenames.append(image_name)\n  else:\n    # Retrieve all bottlenecks.\n    for label_index, label_name in enumerate(image_lists.keys()):\n      for image_index, image_name in enumerate(\n          image_lists[label_name][category]):\n        image_name = get_image_path(image_lists, label_name, image_index,\n                                    image_dir, category)\n        bottleneck = get_or_create_bottleneck(\n            sess, image_lists, label_name, image_index, image_dir, category,\n            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n            resized_input_tensor, bottleneck_tensor, module_name)\n        bottlenecks.append(bottleneck)\n        ground_truths.append(label_index)\n        filenames.append(image_name)\n  return bottlenecks, ground_truths, filenames"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_random_distorted_bottlenecks(\n    sess, image_lists, how_many, category, image_dir, input_jpeg_tensor,\n    distorted_image, resized_input_tensor, bottleneck_tensor):\n  \"\"\"Retrieves bottleneck values for training images, after distortions.\n\n  If we're training with distortions like crops, scales, or flips, we have to\n  recalculate the full model for every image, and so we can't use cached\n  bottleneck values. Instead we find random images for the requested category,\n  run them through the distortion graph, and then the full graph to get the\n  bottleneck results for each.\n\n  Args:\n    sess: Current TensorFlow Session.\n    image_lists: OrderedDict of training images for each label.\n    how_many: The integer number of bottleneck values to return.\n    category: Name string of which set of images to fetch - training, testing,\n    or validation.\n    image_dir: Root folder string of the subfolders containing the training\n    images.\n    input_jpeg_tensor: The input layer we feed the image data to.\n    distorted_image: The output node of the distortion graph.\n    resized_input_tensor: The input node of the recognition graph.\n    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n\n  Returns:\n    List of bottleneck arrays and their corresponding ground truths.\n  \"\"\"\n  class_count = len(image_lists.keys())\n  bottlenecks = []\n  ground_truths = []\n  for unused_i in range(how_many):\n    label_index = random.randrange(class_count)\n    label_name = list(image_lists.keys())[label_index]\n    image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n    image_path = get_image_path(image_lists, label_name, image_index, image_dir,\n                                category)\n    if not tf.gfile.Exists(image_path):\n      tf.logging.fatal('File does not exist %s', image_path)\n    jpeg_data = tf.gfile.GFile(image_path, 'rb').read()\n    # Note that we materialize the distorted_image_data as a numpy array before\n    # sending running inference on the image. This involves 2 memory copies and\n    # might be optimized in other implementations.\n    distorted_image_data = sess.run(distorted_image,\n                                    {input_jpeg_tensor: jpeg_data})\n    bottleneck_values = sess.run(bottleneck_tensor,\n                                 {resized_input_tensor: distorted_image_data})\n    bottleneck_values = np.squeeze(bottleneck_values)\n    bottlenecks.append(bottleneck_values)\n    ground_truths.append(label_index)\n  return bottlenecks, ground_truths", "response": "This function returns bottleneck values for training images after distortions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the operations to apply the specified distortions. During training it can help to improve the results if we run the images through simple distortions like crops, scales, and flips. These reflect the kind of variations we expect in the real world, and so can help train the model to cope with natural data more effectively. Here we take the supplied parameters and construct a network of operations to apply them to an image. Cropping ~~~~~~~~ Cropping is done by placing a bounding box at a random position in the full image. The cropping parameter controls the size of that box relative to the input image. If it's zero, then the box is the same size as the input and no cropping is performed. If the value is 50%, then the crop box will be half the width and height of the input. In a diagram it looks like this: < width > +---------------------+ | | | width - crop% | | < > | | +------+ | | | | | | | | | | | | | | +------+ | | | | | +---------------------+ Scaling ~~~~~~~ Scaling is a lot like cropping, except that the bounding box is always centered and its size varies randomly within the given range. For example if the scale percentage is zero, then the bounding box is the same size as the input and no scaling is applied. If it's 50%, then the bounding box will be in a random range between half the width and height and full size. Args: flip_left_right: Boolean whether to randomly mirror images horizontally. random_crop: Integer percentage setting the total margin used around the crop box. random_scale: Integer percentage of how much to vary the scale by. random_brightness: Integer range to randomly multiply the pixel values by. graph. module_spec: The hub.ModuleSpec for the image module being used. Returns: The jpeg input layer and the distorted result tensor.", "response": "def add_input_distortions(flip_left_right, random_crop, random_scale,\n                          random_brightness, module_spec):\n  \"\"\"Creates the operations to apply the specified distortions.\n\n  During training it can help to improve the results if we run the images\n  through simple distortions like crops, scales, and flips. These reflect the\n  kind of variations we expect in the real world, and so can help train the\n  model to cope with natural data more effectively. Here we take the supplied\n  parameters and construct a network of operations to apply them to an image.\n\n  Cropping\n  ~~~~~~~~\n\n  Cropping is done by placing a bounding box at a random position in the full\n  image. The cropping parameter controls the size of that box relative to the\n  input image. If it's zero, then the box is the same size as the input and no\n  cropping is performed. If the value is 50%, then the crop box will be half the\n  width and height of the input. In a diagram it looks like this:\n\n  <       width         >\n  +---------------------+\n  |                     |\n  |   width - crop%     |\n  |    <      >         |\n  |    +------+         |\n  |    |      |         |\n  |    |      |         |\n  |    |      |         |\n  |    +------+         |\n  |                     |\n  |                     |\n  +---------------------+\n\n  Scaling\n  ~~~~~~~\n\n  Scaling is a lot like cropping, except that the bounding box is always\n  centered and its size varies randomly within the given range. For example if\n  the scale percentage is zero, then the bounding box is the same size as the\n  input and no scaling is applied. If it's 50%, then the bounding box will be in\n  a random range between half the width and height and full size.\n\n  Args:\n    flip_left_right: Boolean whether to randomly mirror images horizontally.\n    random_crop: Integer percentage setting the total margin used around the\n    crop box.\n    random_scale: Integer percentage of how much to vary the scale by.\n    random_brightness: Integer range to randomly multiply the pixel values by.\n    graph.\n    module_spec: The hub.ModuleSpec for the image module being used.\n\n  Returns:\n    The jpeg input layer and the distorted result tensor.\n  \"\"\"\n  input_height, input_width = hub.get_expected_image_size(module_spec)\n  input_depth = hub.get_num_image_channels(module_spec)\n  jpeg_data = tf.placeholder(tf.string, name='DistortJPGInput')\n  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n  # Convert from full range of uint8 to range [0,1] of float32.\n  decoded_image_as_float = tf.image.convert_image_dtype(decoded_image,\n                                                        tf.float32)\n  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n  margin_scale = 1.0 + (random_crop / 100.0)\n  resize_scale = 1.0 + (random_scale / 100.0)\n  margin_scale_value = tf.constant(margin_scale)\n  resize_scale_value = tf.random_uniform(shape=[],\n                                         minval=1.0,\n                                         maxval=resize_scale)\n  scale_value = tf.multiply(margin_scale_value, resize_scale_value)\n  precrop_width = tf.multiply(scale_value, input_width)\n  precrop_height = tf.multiply(scale_value, input_height)\n  precrop_shape = tf.stack([precrop_height, precrop_width])\n  precrop_shape_as_int = tf.cast(precrop_shape, dtype=tf.int32)\n  precropped_image = tf.image.resize_bilinear(decoded_image_4d,\n                                              precrop_shape_as_int)\n  precropped_image_3d = tf.squeeze(precropped_image, axis=[0])\n  cropped_image = tf.random_crop(precropped_image_3d,\n                                 [input_height, input_width, input_depth])\n  if flip_left_right:\n    flipped_image = tf.image.random_flip_left_right(cropped_image)\n  else:\n    flipped_image = cropped_image\n  brightness_min = 1.0 - (random_brightness / 100.0)\n  brightness_max = 1.0 + (random_brightness / 100.0)\n  brightness_value = tf.random_uniform(shape=[],\n                                       minval=brightness_min,\n                                       maxval=brightness_max)\n  brightened_image = tf.multiply(flipped_image, brightness_value)\n  distort_result = tf.expand_dims(brightened_image, 0, name='DistortResult')\n  return jpeg_data, distort_result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattaching a lot of summaries to a TensorBoard visualization.", "response": "def variable_summaries(var):\n  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n  with tf.name_scope('summaries'):\n    mean = tf.reduce_mean(var)\n    tf.summary.scalar('mean', mean)\n    with tf.name_scope('stddev'):\n      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n    tf.summary.scalar('stddev', stddev)\n    tf.summary.scalar('max', tf.reduce_max(var))\n    tf.summary.scalar('min', tf.reduce_min(var))\n    tf.summary.histogram('histogram', var)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_final_retrain_ops(class_count, final_tensor_name, bottleneck_tensor,\n                          quantize_layer, is_training):\n  \"\"\"Adds a new softmax and fully-connected layer for training and eval.\n\n  We need to retrain the top layer to identify our new classes, so this function\n  adds the right operations to the graph, along with some variables to hold the\n  weights, and then sets up all the gradients for the backward pass.\n\n  The set up for the softmax and fully-connected layers is based on:\n  https://www.tensorflow.org/tutorials/mnist/beginners/index.html\n\n  Args:\n    class_count: Integer of how many categories of things we're trying to\n        recognize.\n    final_tensor_name: Name string for the new final node that produces results.\n    bottleneck_tensor: The output of the main CNN graph.\n    quantize_layer: Boolean, specifying whether the newly added layer should be\n        instrumented for quantization with TF-Lite.\n    is_training: Boolean, specifying whether the newly add layer is for training\n        or eval.\n\n  Returns:\n    The tensors for the training and cross entropy results, and tensors for the\n    bottleneck input and ground truth input.\n  \"\"\"\n  batch_size, bottleneck_tensor_size = bottleneck_tensor.get_shape().as_list()\n  assert batch_size is None, 'We want to work with arbitrary batch size.'\n  with tf.name_scope('input'):\n    bottleneck_input = tf.placeholder_with_default(\n        bottleneck_tensor,\n        shape=[batch_size, bottleneck_tensor_size],\n        name='BottleneckInputPlaceholder')\n\n    ground_truth_input = tf.placeholder(\n        tf.int64, [batch_size], name='GroundTruthInput')\n\n  # Organizing the following ops so they are easier to see in TensorBoard.\n  layer_name = 'final_retrain_ops'\n  with tf.name_scope(layer_name):\n    with tf.name_scope('weights'):\n      initial_value = tf.truncated_normal(\n          [bottleneck_tensor_size, class_count], stddev=0.001)\n      layer_weights = tf.Variable(initial_value, name='final_weights')\n      variable_summaries(layer_weights)\n\n    with tf.name_scope('biases'):\n      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n      variable_summaries(layer_biases)\n\n    with tf.name_scope('Wx_plus_b'):\n      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n      tf.summary.histogram('pre_activations', logits)\n\n  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n\n  # The tf.contrib.quantize functions rewrite the graph in place for\n  # quantization. The imported model graph has already been rewritten, so upon\n  # calling these rewrites, only the newly added final layer will be\n  # transformed.\n  if quantize_layer:\n    if is_training:\n      tf.contrib.quantize.create_training_graph()\n    else:\n      tf.contrib.quantize.create_eval_graph()\n\n  tf.summary.histogram('activations', final_tensor)\n\n  # If this is an eval graph, we don't need to add loss ops or an optimizer.\n  if not is_training:\n    return None, None, bottleneck_input, ground_truth_input, final_tensor\n\n  with tf.name_scope('cross_entropy'):\n    cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(\n        labels=ground_truth_input, logits=logits)\n\n  tf.summary.scalar('cross_entropy', cross_entropy_mean)\n\n  with tf.name_scope('train'):\n    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n    train_step = optimizer.minimize(cross_entropy_mean)\n\n  return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n          final_tensor)", "response": "Adds a new softmax and fully - connected layer for training and eval."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the operations needed to evaluate the accuracy of our results.", "response": "def add_evaluation_step(result_tensor, ground_truth_tensor):\n  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n\n  Args:\n    result_tensor: The new final node that produces results.\n    ground_truth_tensor: The node we feed ground truth data\n    into.\n\n  Returns:\n    Tuple of (evaluation step, prediction).\n  \"\"\"\n  with tf.name_scope('accuracy'):\n    with tf.name_scope('correct_prediction'):\n      prediction = tf.argmax(result_tensor, 1)\n      correct_prediction = tf.equal(prediction, ground_truth_tensor)\n    with tf.name_scope('accuracy'):\n      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n  tf.summary.scalar('accuracy', evaluation_step)\n  return evaluation_step, prediction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a final evaluation on an eval graph using the test data set.", "response": "def run_final_eval(train_session, module_spec, class_count, image_lists,\n                   jpeg_data_tensor, decoded_image_tensor,\n                   resized_image_tensor, bottleneck_tensor):\n  \"\"\"Runs a final evaluation on an eval graph using the test data set.\n\n  Args:\n    train_session: Session for the train graph with the tensors below.\n    module_spec: The hub.ModuleSpec for the image module being used.\n    class_count: Number of classes\n    image_lists: OrderedDict of training images for each label.\n    jpeg_data_tensor: The layer to feed jpeg image data into.\n    decoded_image_tensor: The output of decoding and resizing the image.\n    resized_image_tensor: The input node of the recognition graph.\n    bottleneck_tensor: The bottleneck output layer of the CNN graph.\n  \"\"\"\n  test_bottlenecks, test_ground_truth, test_filenames = (\n      get_random_cached_bottlenecks(train_session, image_lists,\n                                    FLAGS.test_batch_size,\n                                    'testing', FLAGS.bottleneck_dir,\n                                    FLAGS.image_dir, jpeg_data_tensor,\n                                    decoded_image_tensor, resized_image_tensor,\n                                    bottleneck_tensor, FLAGS.tfhub_module))\n\n  (eval_session, _, bottleneck_input, ground_truth_input, evaluation_step,\n   prediction) = build_eval_session(module_spec, class_count)\n  test_accuracy, predictions = eval_session.run(\n      [evaluation_step, prediction],\n      feed_dict={\n          bottleneck_input: test_bottlenecks,\n          ground_truth_input: test_ground_truth\n      })\n  tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n                  (test_accuracy * 100, len(test_bottlenecks)))\n\n  if FLAGS.print_misclassified_test_images:\n    tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n    for i, test_filename in enumerate(test_filenames):\n      if predictions[i] != test_ground_truth[i]:\n        tf.logging.info('%70s  %s' % (test_filename,\n                                      list(image_lists.keys())[predictions[i]]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_eval_session(module_spec, class_count):\n  # If quantized, we need to create the correct eval graph for exporting.\n  eval_graph, bottleneck_tensor, resized_input_tensor, wants_quantization = (\n      create_module_graph(module_spec))\n\n  eval_sess = tf.Session(graph=eval_graph)\n  with eval_graph.as_default():\n    # Add the new layer for exporting.\n    (_, _, bottleneck_input,\n     ground_truth_input, final_tensor) = add_final_retrain_ops(\n         class_count, FLAGS.final_tensor_name, bottleneck_tensor,\n         wants_quantization, is_training=False)\n\n    # Now we need to restore the values from the training graph to the eval\n    # graph.\n    tf.train.Saver().restore(eval_sess, CHECKPOINT_NAME)\n\n    evaluation_step, prediction = add_evaluation_step(final_tensor,\n                                                      ground_truth_input)\n\n  return (eval_sess, resized_input_tensor, bottleneck_input, ground_truth_input,\n          evaluation_step, prediction)", "response": "Builds an eval session with the given module_spec and class_count."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_graph_to_file(graph_file_name, module_spec, class_count):\n  sess, _, _, _, _, _ = build_eval_session(module_spec, class_count)\n  graph = sess.graph\n\n  output_graph_def = tf.graph_util.convert_variables_to_constants(\n      sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n\n  with tf.gfile.GFile(graph_file_name, 'wb') as f:\n    f.write(output_graph_def.SerializeToString())", "response": "Saves an graph to file creating a valid quantized one if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd operations that perform JPEG decoding and resizing to the graph.", "response": "def add_jpeg_decoding(module_spec):\n  \"\"\"Adds operations that perform JPEG decoding and resizing to the graph..\n\n  Args:\n    module_spec: The hub.ModuleSpec for the image module being used.\n\n  Returns:\n    Tensors for the node to feed JPEG data into, and the output of the\n      preprocessing steps.\n  \"\"\"\n  input_height, input_width = hub.get_expected_image_size(module_spec)\n  input_depth = hub.get_num_image_channels(module_spec)\n  jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\n  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n  # Convert from full range of uint8 to range [0,1] of float32.\n  decoded_image_as_float = tf.image.convert_image_dtype(decoded_image,\n                                                        tf.float32)\n  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n  resize_shape = tf.stack([input_height, input_width])\n  resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n  resized_image = tf.image.resize_bilinear(decoded_image_4d,\n                                           resize_shape_as_int)\n  return jpeg_data, resized_image"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting the model for serving.", "response": "def export_model(module_spec, class_count, saved_model_dir):\n  \"\"\"Exports model for serving.\n\n  Args:\n    module_spec: The hub.ModuleSpec for the image module being used.\n    class_count: The number of classes.\n    saved_model_dir: Directory in which to save exported model and variables.\n  \"\"\"\n  # The SavedModel should hold the eval graph.\n  sess, in_image, _, _, _, _ = build_eval_session(module_spec, class_count)\n  with sess.graph.as_default() as graph:\n    tf.saved_model.simple_save(\n        sess,\n        saved_model_dir,\n        inputs={'image': in_image},\n        outputs={'prediction': graph.get_tensor_by_name('final_result:0')},\n        legacy_init_op=tf.group(tf.tables_initializer(), name='legacy_init_op')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logging_level_verbosity(logging_verbosity):\n  name_to_level = {\n    'FATAL': tf.logging.FATAL,\n    'ERROR': tf.logging.ERROR,\n    'WARN': tf.logging.WARN,\n    'INFO': tf.logging.INFO,\n    'DEBUG': tf.logging.DEBUG\n  }\n\n  try:\n    return name_to_level[logging_verbosity]\n  except Exception as e:\n    raise RuntimeError('Not supported logs verbosity (%s). Use one of %s.' %\n                       (str(e), list(name_to_level)))", "response": "Converts logging_level into TensorFlow logging verbosity value\n\n Arguments"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_image_module_info(module_or_spec, required=False):\n  return module_or_spec.get_attached_message(\n      IMAGE_MODULE_INFO_KEY, ImageModuleInfo, required=required)", "response": "Returns the attached ImageModuleInfo message or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_expected_image_size(module_or_spec, signature=None, input_name=None):\n  # First see if an attached ImageModuleInfo provides this information.\n  image_module_info = get_image_module_info(module_or_spec)\n  if image_module_info:\n    size = image_module_info.default_image_size\n    if size.height and size.width:\n      return [size.height, size.width]\n\n  # Else inspect the input shape in the module signature.\n  if input_name is None:\n    input_name = \"images\"\n  input_info_dict = module_or_spec.get_input_info_dict(signature)\n  try:\n    shape = input_info_dict[input_name].get_shape()\n  except KeyError:\n    raise ValueError(\"Module is missing input '%s' in signature '%s'.\" %\n                     (input_name, signature or \"default\"))\n  try:\n    _, height, width, _ = shape.as_list()\n    if not height or not width:\n      raise ValueError\n  except ValueError:\n    raise ValueError(\n        \"Shape of module input is %s, \"\n        \"expected [batch_size, height, width, num_channels] \"\n        \"with known height and width.\" % shape)\n  return [height, width]", "response": "Returns the expected height and width dimensions of an image input."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns expected num_channels dimensions of an image input.", "response": "def get_num_image_channels(module_or_spec, signature=None, input_name=None):\n  \"\"\"Returns expected num_channels dimensions of an image input.\n\n  This is for advanced users only who expect to handle modules with\n  image inputs that might not have the 3 usual RGB channels.\n\n  Args:\n    module_or_spec: a Module or ModuleSpec that accepts image inputs.\n    signature: a string with the key of the signature in question.\n      If None, the default signature is used.\n    input_name: a string with the input name for images. If None, the\n      conventional input name `images` for the default signature is used.\n\n  Returns:\n    An integer with the number of input channels to the module.\n\n  Raises:\n    ValueError: If the channel information is missing or malformed.\n  \"\"\"\n  if input_name is None:\n    input_name = \"images\"\n  input_info_dict = module_or_spec.get_input_info_dict(signature)\n  try:\n    shape = input_info_dict[input_name].get_shape()\n  except KeyError:\n    raise ValueError(\"Module is missing input '%s' in signature '%s'.\" %\n                     (input_name, signature or \"default\"))\n  try:\n    _, _, _, num_channels = shape.as_list()\n    if num_channels is None:\n      raise ValueError\n  except ValueError:\n    raise ValueError(\n        \"Shape of module input is %s, \"\n        \"expected [batch_size, height, width, num_channels] \"\n        \"with known num_channels\" % shape)\n  return num_channels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a ParsedTensorInfo instance from a TensorInfo proto.", "response": "def _parse_tensor_info_proto(tensor_info):\n  \"\"\"Returns a ParsedTensorInfo instance from a TensorInfo proto.\"\"\"\n  encoding = tensor_info.WhichOneof(\"encoding\")\n  dtype = tf.DType(tensor_info.dtype)\n  shape = tf.TensorShape(tensor_info.tensor_shape)\n  if encoding == \"name\":\n    return ParsedTensorInfo(dtype=dtype, shape=shape, is_sparse=False)\n  elif encoding == \"coo_sparse\":\n    return ParsedTensorInfo(dtype=dtype, shape=shape, is_sparse=True)\n  else:\n    raise ValueError(\"Unsupported TensorInfo encoding %r\" % encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_sparse(x):\n  return (\n      isinstance(x, (tf.SparseTensor, tf_v1.SparseTensorValue)) or\n      (hasattr(x, \"is_sparse\") and x.is_sparse))", "response": "Returns whether x is a SparseTensor or a parsed sparse tensor info."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_to_compatible_tensor(value, target, error_prefix):\n  try:\n    tensor = tf_v1.convert_to_tensor_or_indexed_slices(value, target.dtype)\n  except TypeError as e:\n    raise TypeError(\"%s: %s\" % (error_prefix, e))\n  if _is_sparse(tensor) != _is_sparse(target):\n    if _is_sparse(tensor):\n      raise TypeError(\"%s: Is sparse. Expected dense.\" % error_prefix)\n    else:\n      raise TypeError(\"%s: Is dense. Expected sparse.\" % error_prefix)\n  if not tensor.get_shape().is_compatible_with(target.get_shape()):\n    raise TypeError(\"%s: Shape %r is incompatible with %r\" %\n                    (error_prefix, tensor.get_shape(), target.get_shape()))\n  return tensor", "response": "Converts value into a tensor that can be feed into tensor_info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_dict_to_compatible_tensor(values, targets):\n  result = {}\n  for key, value in sorted(values.items()):\n    result[key] = _convert_to_compatible_tensor(\n        value, targets[key], error_prefix=\"Can't convert %r\" % key)\n  return result", "response": "Converts dict values in tensors that are compatible with targets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_input_map(protomap, inputs):\n  if set(protomap.keys()) != set(inputs.keys()):\n    raise ValueError(\"build_input_map: keys do not match.\")\n  input_map = {}\n  for key, tensor_info in protomap.items():\n    arg = inputs[key]\n    encoding = tensor_info.WhichOneof(\"encoding\")\n    if encoding == \"name\":\n      input_map[tensor_info.name] = arg\n    elif encoding == \"coo_sparse\":\n      coo_sparse = tensor_info.coo_sparse\n      input_map[coo_sparse.values_tensor_name] = arg.values\n      input_map[coo_sparse.indices_tensor_name] = arg.indices\n      input_map[coo_sparse.dense_shape_tensor_name] = arg.dense_shape\n    else:\n      raise ValueError(\"Invalid TensorInfo.encoding: %s\" % encoding)\n  return input_map", "response": "Builds a map to feed tensors in protomap using inputs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_output_map(protomap, get_tensor_by_name):\n\n  def get_output_from_tensor_info(tensor_info):\n    encoding = tensor_info.WhichOneof(\"encoding\")\n    if encoding == \"name\":\n      return get_tensor_by_name(tensor_info.name)\n    elif encoding == \"coo_sparse\":\n      return tf.SparseTensor(\n          get_tensor_by_name(tensor_info.coo_sparse.indices_tensor_name),\n          get_tensor_by_name(tensor_info.coo_sparse.values_tensor_name),\n          get_tensor_by_name(tensor_info.coo_sparse.dense_shape_tensor_name))\n    else:\n      raise ValueError(\"Invalid TensorInfo.encoding: %s\" % encoding)\n\n  return {\n      key: get_output_from_tensor_info(tensor_info)\n      for key, tensor_info in protomap.items()\n  }", "response": "Builds a map from a proto map<string TensorInfo > protomap using get_tensor_by_name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tensor_info_proto_maps_match(map_a, map_b):\n  iter_a = sorted(parse_tensor_info_map(map_a).items())\n  iter_b = sorted(parse_tensor_info_map(map_b).items())\n  if len(iter_a) != len(iter_b):\n    return False  # Mismatch count.\n  for info_a, info_b in zip(iter_a, iter_b):\n    if info_a[0] != info_b[0]:\n      return False  # Mismatch keys.\n    if _is_sparse(info_a[1]) != _is_sparse(info_b[1]):\n      return False\n    if info_a[1].dtype != info_b[1].dtype:\n      return False\n    if not _shape_match(info_a[1].get_shape(), info_b[1].get_shape()):\n      return False\n  return True", "response": "Returns True if two signature inputs and outputs match in dtype shape and sparsity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_line(line):\n  columns = line.split()\n  token = columns.pop(0)\n  values = [float(column) for column in columns]\n  return token, values", "response": "Parses a line of a text embedding file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(file_path, parse_line_fn):\n  vocabulary = []\n  embeddings = []\n  embeddings_dim = None\n  for line in tf.gfile.GFile(file_path):\n    token, embedding = parse_line_fn(line)\n    if not embeddings_dim:\n      embeddings_dim = len(embedding)\n    elif embeddings_dim != len(embedding):\n      raise ValueError(\n          \"Inconsistent embedding dimension detected, %d != %d for token %s\",\n          embeddings_dim, len(embedding), token)\n\n    vocabulary.append(token)\n    embeddings.append(embedding)\n\n  return vocabulary, np.array(embeddings)", "response": "Loads a text embedding into memory as a numpy matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_module_spec(vocabulary_file, vocab_size, embeddings_dim,\n                     num_oov_buckets, preprocess_text):\n  \"\"\"Makes a module spec to simply perform token to embedding lookups.\n\n  Input of this module is a 1-D list of string tokens. For T tokens input and\n  an M dimensional embedding table, the lookup result is a [T, M] shaped Tensor.\n\n  Args:\n    vocabulary_file: Text file where each line is a key in the vocabulary.\n    vocab_size: The number of tokens contained in the vocabulary.\n    embeddings_dim: The embedding dimension.\n    num_oov_buckets: The number of out-of-vocabulary buckets.\n    preprocess_text: Whether to preprocess the input tensor by removing\n      punctuation and splitting on spaces.\n\n  Returns:\n    A module spec object used for constructing a TF-Hub module.\n  \"\"\"\n\n  def module_fn():\n    \"\"\"Spec function for a token embedding module.\"\"\"\n    tokens = tf.placeholder(shape=[None], dtype=tf.string, name=\"tokens\")\n\n    embeddings_var = tf.get_variable(\n        initializer=tf.zeros([vocab_size + num_oov_buckets, embeddings_dim]),\n        name=EMBEDDINGS_VAR_NAME,\n        dtype=tf.float32)\n\n    lookup_table = tf.contrib.lookup.index_table_from_file(\n        vocabulary_file=vocabulary_file,\n        num_oov_buckets=num_oov_buckets,\n    )\n    ids = lookup_table.lookup(tokens)\n    combined_embedding = tf.nn.embedding_lookup(params=embeddings_var, ids=ids)\n    hub.add_signature(\"default\", {\"tokens\": tokens},\n                      {\"default\": combined_embedding})\n\n  def module_fn_with_preprocessing():\n    \"\"\"Spec function for a full-text embedding module with preprocessing.\"\"\"\n    sentences = tf.placeholder(shape=[None], dtype=tf.string, name=\"sentences\")\n    # Perform a minimalistic text preprocessing by removing punctuation and\n    # splitting on spaces.\n    normalized_sentences = tf.regex_replace(\n        input=sentences, pattern=r\"\\pP\", rewrite=\"\")\n    tokens = tf.string_split(normalized_sentences, \" \")\n\n    embeddings_var = tf.get_variable(\n        initializer=tf.zeros([vocab_size + num_oov_buckets, embeddings_dim]),\n        name=EMBEDDINGS_VAR_NAME,\n        dtype=tf.float32)\n    lookup_table = tf.contrib.lookup.index_table_from_file(\n        vocabulary_file=vocabulary_file,\n        num_oov_buckets=num_oov_buckets,\n    )\n    sparse_ids = tf.SparseTensor(\n        indices=tokens.indices,\n        values=lookup_table.lookup(tokens.values),\n        dense_shape=tokens.dense_shape)\n\n    # In case some of the input sentences are empty before or after\n    # normalization, we will end up with empty rows. We do however want to\n    # return embedding for every row, so we have to fill in the empty rows with\n    # a default.\n    sparse_ids, _ = tf.sparse_fill_empty_rows(\n        sparse_ids, lookup_table.lookup(tf.constant(\"\")))\n    # In case all of the input sentences are empty before or after\n    # normalization, we will end up with a SparseTensor with shape [?, 0]. After\n    # filling in the empty rows we must ensure the shape is set properly to\n    # [?, 1]. At this point, there are no empty rows, so the new shape will be\n    # [sparse_ids.dense_shape[0], max(1, sparse_ids.dense_shape[1])].\n    sparse_ids = tf.sparse_reset_shape(sparse_ids)\n\n    combined_embedding = tf.nn.embedding_lookup_sparse(\n        params=embeddings_var,\n        sp_ids=sparse_ids,\n        sp_weights=None,\n        combiner=\"sqrtn\")\n\n    hub.add_signature(\"default\", {\"sentences\": sentences},\n                      {\"default\": combined_embedding})\n\n  if preprocess_text:\n    return hub.create_module_spec(module_fn_with_preprocessing)\n  else:\n    return hub.create_module_spec(module_fn)", "response": "Makes a module spec to simply perform token to embedding lookups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export(export_path, vocabulary, embeddings, num_oov_buckets,\n           preprocess_text):\n  \"\"\"Exports a TF-Hub module that performs embedding lookups.\n\n  Args:\n    export_path: Location to export the module.\n    vocabulary: List of the N tokens in the vocabulary.\n    embeddings: Numpy array of shape [N+K,M] the first N rows are the\n      M dimensional embeddings for the respective tokens and the next K\n      rows are for the K out-of-vocabulary buckets.\n    num_oov_buckets: How many out-of-vocabulary buckets to add.\n    preprocess_text: Whether to preprocess the input tensor by removing\n      punctuation and splitting on spaces.\n  \"\"\"\n  # Write temporary vocab file for module construction.\n  tmpdir = tempfile.mkdtemp()\n  vocabulary_file = os.path.join(tmpdir, \"tokens.txt\")\n  with tf.gfile.GFile(vocabulary_file, \"w\") as f:\n    f.write(\"\\n\".join(vocabulary))\n  vocab_size = len(vocabulary)\n  embeddings_dim = embeddings.shape[1]\n  spec = make_module_spec(vocabulary_file, vocab_size, embeddings_dim,\n                          num_oov_buckets, preprocess_text)\n\n  try:\n    with tf.Graph().as_default():\n      m = hub.Module(spec)\n      # The embeddings may be very large (e.g., larger than the 2GB serialized\n      # Tensor limit).  To avoid having them frozen as constant Tensors in the\n      # graph we instead assign them through the placeholders and feed_dict\n      # mechanism.\n      p_embeddings = tf.placeholder(tf.float32)\n      load_embeddings = tf.assign(m.variable_map[EMBEDDINGS_VAR_NAME],\n                                  p_embeddings)\n\n      with tf.Session() as sess:\n        sess.run([load_embeddings], feed_dict={p_embeddings: embeddings})\n        m.export(export_path, sess)\n  finally:\n    shutil.rmtree(tmpdir)", "response": "Exports a TF - Hub module that performs embedding lookups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding zero vectors for OOV buckets if num_oov_buckets > 0.", "response": "def maybe_append_oov_vectors(embeddings, num_oov_buckets):\n  \"\"\"Adds zero vectors for oov buckets if num_oov_buckets > 0.\n\n  Since we are assigning zero vectors, adding more that one oov bucket is only\n  meaningful if we perform fine-tuning.\n\n  Args:\n    embeddings: Embeddings to extend.\n    num_oov_buckets: Number of OOV buckets in the extended embedding.\n  \"\"\"\n  num_embeddings = np.shape(embeddings)[0]\n  embedding_dim = np.shape(embeddings)[1]\n  embeddings.resize(\n      [num_embeddings + num_oov_buckets, embedding_dim], refcheck=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ModuleSpec from a SavedModel.", "response": "def create_module_spec_from_saved_model(saved_model_path,\n                                        drop_collections=None):\n  \"\"\"Experimental: Create a ModuleSpec out of a SavedModel.\n\n  Define a ModuleSpec from a SavedModel. Note that this is not guaranteed to\n  work in all cases and it assumes the SavedModel has followed some conventions:\n\n  - The serialized SaverDef can be ignored and instead can be reconstructed.\n  - The init op and main op can be ignored and instead the module can be\n    initialized by using the conventions followed by\n    `tf.train.MonitoredSession`.\n\n  Note that the set of features supported can increase over time and have side\n  effects that were not previously visible. The pattern followed to avoid\n  surprises is forcing users to declare which features to ignore (even\n  if they are not supported).\n\n  Note that this function creates a ModuleSpec that when exported exports a\n  Module (based on a modified copy of the original SavedModel) and not a\n  SavedModel.\n\n  Args:\n    saved_model_path: Directory with the SavedModel to use.\n    drop_collections: Additionally list of collection to drop.\n\n  Returns:\n    A ModuleSpec.\n  \"\"\"\n  saved_model_handler = saved_model_lib.load(saved_model_path)\n  checkpoint_filename = saved_model_lib.get_variables_path(saved_model_path)\n\n  drop_collections = (set(_ALWAYS_DROPPED_COLLECTIONS) |\n                      (set(drop_collections) if drop_collections else set()))\n  _drop_collections(saved_model_handler, drop_collections)\n\n  return native_module._ModuleSpec(saved_model_handler, checkpoint_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a Module instance to be exported byLatestModuleExporter.", "response": "def register_module_for_export(module, export_name):\n  \"\"\"Register a Module to be exported under `export_name`.\n\n\n  This function registers `module` to be exported by `LatestModuleExporter`\n  under a subdirectory named `export_name`.\n\n  Note that `export_name` must be unique for each module exported from the\n  current graph. It only controls the export subdirectory name and it has\n  no scope effects such as the `name` parameter during Module instantiation.\n\n  Args:\n    module: Module instance to be exported.\n    export_name: subdirectory name to use when performing the export.\n\n  Raises:\n    ValueError: if `export_name` is already taken in the current graph.\n  \"\"\"\n  for used_name, _ in tf_v1.get_collection(_EXPORT_MODULES_COLLECTION):\n    if used_name == export_name:\n      raise ValueError(\n          \"There is already a module registered to be exported as %r\"\n          % export_name)\n  tf_v1.add_to_collection(_EXPORT_MODULES_COLLECTION, (export_name, module))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a session for serving the given estimator and serving_input_fn.", "response": "def _make_estimator_serving_session(estimator, serving_input_fn,\n                                    checkpoint_path):\n  \"\"\"Returns a session constructed using `estimator` and `serving_input_fn`.\n\n  The Estimator API does not provide an API to construct a graph and session,\n  making it necessary for this function to replicate how an estimator builds\n  a graph.\n\n  This code is based on `Estimator.export_savedmodel` (another function that\n  has to replicate how an estimator builds a graph).\n\n  Args:\n    estimator: tf.Estimator to use when constructing the session.\n    serving_input_fn: A function that takes no arguments and returns a\n      `ServingInputReceiver`. It is used to construct the session.\n    checkpoint_path: The checkpoint path to restore in the session. Must not\n      be None.\n  \"\"\"\n  with tf.Graph().as_default() as g:\n    mode = tf_v1.estimator.ModeKeys.PREDICT\n    tf_v1.train.create_global_step(g)\n    tf_v1.set_random_seed(estimator.config.tf_random_seed)\n    serving_input_receiver = serving_input_fn()\n\n    estimator_spec = estimator.model_fn(\n        features=serving_input_receiver.features,\n        labels=None,\n        mode=mode,\n        config=estimator.config)\n\n    # pylint: disable=protected-access\n    # Note that MonitoredSession(), despite the name is not a Session, and\n    # can't be used to export Modules as one can't use them with Savers.\n    # As so this must use a raw tf.Session().\n    session = tf_v1.Session(config=estimator._session_config)\n    # pylint: enable=protected-access\n\n    with session.as_default():\n      # TODO(b/71839662): Consider if this needs to support TPUEstimatorSpec\n      # which does not have a scaffold member.\n      saver_for_restore = estimator_spec.scaffold.saver or tf_v1.train.Saver(\n          sharded=True)\n      saver_for_restore.restore(session, checkpoint_path)\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a ModuleSpec from a function that builds the graph of the current module.", "response": "def create_module_spec(module_fn, tags_and_args=None, drop_collections=None):\n  \"\"\"Creates a ModuleSpec from a function that builds the module's graph.\n\n  The `module_fn` is called on a new graph (not the current one) to build the\n  graph of the module and define its signatures via `hub.add_signature()`.\n  Example:\n\n  ```python\n  # Define a text embedding module.\n  def my_text_module_fn():\n    text_input = tf.placeholder(dtype=tf.string, shape=[None])\n    embeddings = compute_embedding(text_input)\n    hub.add_signature(inputs=text_input, outputs=embeddings)\n  ```\n\n  See `add_signature()` for documentation on adding multiple input/output\n  signatures.\n\n  NOTE: In anticipation of future TF-versions, `module_fn` is called on a graph\n  that uses resource variables by default. If you want old-style variables then\n  you can use `with tf.variable_scope(\"\", use_resource=False)` in `module_fn`.\n\n  Multiple graph variants can be defined by using the `tags_and_args` argument.\n  For example, the code:\n\n  ```python\n  hub.create_module_spec(\n      module_fn,\n      tags_and_args=[({\"train\"}, {\"is_training\":True}),\n                     (set(), {\"is_training\":False})])\n  ```\n\n  calls `module_fn` twice, once as `module_fn(is_training=True)` and once as\n  `module_fn(is_training=False)` to define the respective graph variants:\n  for training with tags {\"train\"} and for inference with the empty set of tags.\n  Using the empty set aligns the inference case with the default in\n  Module.__init__().\n\n  Args:\n    module_fn: a function to build a graph for the Module.\n    tags_and_args: Optional list of tuples (tags, kwargs) of tags and keyword\n      args used to define graph variants. If omitted, it is interpreted as\n      [(set(), {})], meaning `module_fn` is called once with no args.\n    drop_collections: list of collection to drop.\n\n  Returns:\n    A ModuleSpec.\n\n  Raises:\n    ValueError: if it fails to construct the ModuleSpec due to bad or\n      unsupported values in the arguments or in the graphs constructed by\n      `module_fn`.\n  \"\"\"\n  if not drop_collections:\n    drop_collections = []\n\n  report_tags = True\n  if not tags_and_args:\n    tags_and_args = [(set(), {})]\n    report_tags = False\n\n  saved_model_handler = saved_model_lib.SavedModelHandler()\n  for tags, args in tags_and_args:\n    with tf.Graph().as_default() as graph:\n      with tf_v1.variable_scope(\"\", use_resource=True):\n        module_fn(**args)\n\n      for collection_key in drop_collections:\n        del tf_v1.get_collection_ref(collection_key)[:]\n\n    err = find_state_op_colocation_error(graph, tags if report_tags else None)\n    if err: raise ValueError(err)\n    saved_model_handler.add_graph_copy(graph, tags=tags)\n\n  return _ModuleSpec(saved_model_handler, checkpoint_variables_path=None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_signature(name=None, inputs=None, outputs=None):\n  if not name:\n    name = \"default\"\n  if inputs is None:\n    inputs = {}\n  if outputs is None:\n    outputs = {}\n  if not isinstance(inputs, dict):\n    inputs = {\"default\": inputs}\n  if not isinstance(outputs, dict):\n    outputs = {\"default\": outputs}\n  message = find_signature_inputs_from_multivalued_ops(inputs)\n  if message: logging.error(message)\n  message = find_signature_input_colocation_error(name, inputs)\n  if message: raise ValueError(message)\n  saved_model_lib.add_signature(name, inputs, outputs)", "response": "Adds a signature to the module definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attach_message(key, message):\n  if not re.match(r\"[a-zA-Z][a-zA-Z0-9_]*$\", key):\n    raise ValueError(\n        \"hub.attach_message() called with malformed key '%s'\" % key)\n  saved_model_lib.attach_bytes(key, message.SerializeToString())", "response": "Adds an attached message to the module definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_registered_stateful_ops_without_inputs():\n  return set([\n      name\n      for name, op in op_def_registry.get_registered_ops().items()\n      if op.is_stateful and not op.input_arg\n  ])", "response": "Returns a list of registered stateful ops that do not expect inputs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_state_map(meta_graph, state_ops, unsupported_state_ops,\n                  get_tensor_by_name):\n  \"\"\"Returns a map from tensor names to tensors that hold the state.\"\"\"\n  state_map = {}\n  for node in meta_graph.graph_def.node:\n    if node.op in state_ops:\n      tensor_name = node.name + \":0\"\n      tensor = get_tensor_by_name(tensor_name)\n      num_outputs = len(tensor.op.outputs)\n      if num_outputs != 1:\n        raise ValueError(\"Stateful op %s has %d outputs, expected 1\" %\n                         (node.op, num_outputs))\n      state_map[tensor_name] = tensor\n    if node.op in unsupported_state_ops:\n      raise ValueError(\"Unsupported stateful op: %s\" % node.op)\n  return state_map", "response": "Returns a map from tensor names to tensors that hold the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces state ops with non state Placeholder ops for the apply graph.", "response": "def replace_apply_state(meta_graph, state_ops, feed_map):\n  \"\"\"Replaces state ops with non state Placeholder ops for the apply graph.\"\"\"\n  for node in meta_graph.graph_def.node:\n    keys_to_purge = []\n    tensor_name = node.name + \":0\"\n    # Verify that the node is a state op and that its due to be rewired\n    # in the feedmap.\n    if node.op in state_ops and tensor_name in feed_map:\n      node.op = \"Placeholder\"\n      for key in node.attr:\n        # Only shape and dtype are required for Placeholder. Remove other\n        # attributes.\n        if key != \"shape\":\n          keys_to_purge.append(key)\n      for key in keys_to_purge:\n        del node.attr[key]\n      node.attr[\"dtype\"].type = types_pb2.DT_RESOURCE"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _split_tensor_name(tensor_name):\n  result = re.match(r\"(.*):(\\d+)$\", tensor_name)\n  if not result:\n    raise ValueError(\n        \"Unexpected format for tensor name. Expected node_name:output_number. \"\n        \"Got %r\" % tensor_name)\n  return result.group(1), int(result.group(2))", "response": "Given a tensor name as node_name : output_number returns both parts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_variable_parts(variable_key, variable):\n  name, offset, partitioned = None, None, False\n  # pylint: disable=protected-access\n  if variable._save_slice_info:\n    name = variable_key[:variable_key.rfind(\"/\")]\n    if not variable._save_slice_info.full_name.endswith(name):\n      raise RuntimeError(\"Unexpected handling of partitioned variable.\")\n    offset = variable._save_slice_info.var_offset[0]\n    partitioned = True\n  # pylint: enable=protected-access\n  return partitioned, name, offset", "response": "Matches a variable to individual parts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recover_partitioned_variable_map(var_node_map):\n  offset_variables_map = {}\n  for var_key, var_tensor in var_node_map.items():\n    match, var_name, offset = _extract_variable_parts(var_key, var_tensor)\n\n    if not match:\n      # This is a standard variable, so we can safely add it to the output.\n      if var_key in offset_variables_map:\n        raise RuntimeError(\n            \"Variable %s exists both as a single and partitioned variable.\")\n      offset_variables_map[var_key] = var_tensor\n      continue\n\n    if var_name not in offset_variables_map:\n      offset_variables_map[var_name] = {}\n    elif not isinstance(offset_variables_map[var_name], dict):\n      raise RuntimeError(\n          \"Variable %s exists both as a single and partitioned variable.\")\n\n    # Duplicated variable offsets should not exist.\n    if offset in offset_variables_map[var_name]:\n      raise RuntimeError(\n          \"Variable map contains duplicate offset %d for variable [%s]\" %\n          (offset, var_name))\n    offset_variables_map[var_name][offset] = var_tensor\n\n  variables_map = {}\n  # Use offsets for sorting, then strip them from the dictionary and keep only\n  # a list of variables per each variable name.\n  for var_name, var_value in offset_variables_map.items():\n    if not isinstance(var_value, dict):\n      variables_map[var_name] = var_value\n      continue\n    shapes = [var_tensor.shape[1:] for var_tensor in var_value.values()]\n    if not all(shape == shapes[0] for shape in shapes):\n      raise RuntimeError(\"Shapes not compatible: %s\" % (shapes))\n    for _, tensor in sorted(var_value.items()):\n      variables_map[var_name] = [\n          tensor for _, tensor in sorted(var_value.items())\n      ]\n\n  return variables_map", "response": "Re - creates a proper variable map if it contains PartitionedVariables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the tag list contains each set of tags only once.", "response": "def check_unique_tags(tag_list):\n  \"\"\"Checks that tag list contains each set of tags only once.\"\"\"\n  frozen_tags_seen = set()\n  for tags in tag_list:\n    frozen_tags = frozenset(tags)\n    if frozen_tags in frozen_tags_seen:\n      raise ValueError(\"Tags %r used repeatedly\" % tags)\n    frozen_tags_seen.add(frozen_tags)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_collections_are_supported(saved_model_handler, supported):\n  for meta_graph in saved_model_handler.meta_graphs:\n    used_collection_keys = set(meta_graph.collection_def.keys())\n    unsupported = used_collection_keys - supported\n    if unsupported:\n      raise ValueError(\"Unsupported collections in graph: %s\\n\"\n                       \"Use hub.create_module_spec(..., drop_collections=[...])\"\n                       \" as appropriate.\" % list(unsupported))", "response": "Checks that SavedModelHandler only uses supported collections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister graph ops that are not present in op_def_registry.", "response": "def register_ops_if_needed(graph_ops):\n  \"\"\"Register graph ops absent in op_def_registry, if present in c++ registry.\n\n  Args:\n    graph_ops: set with graph op names to register.\n\n  Raises:\n    RuntimeError: if `graph_ops` contains ops that are not in either python or\n      c++ registry.\n  \"\"\"\n  missing_ops = graph_ops - set(op_def_registry.get_registered_ops().keys())\n\n  if not missing_ops:\n    return\n\n  p_buffer = c_api.TF_GetAllOpList()\n  cpp_op_list = op_def_pb2.OpList()\n  cpp_op_list.ParseFromString(c_api.TF_GetBuffer(p_buffer))\n  cpp_registry_ops = {op.name: op for op in cpp_op_list.op}\n\n  missing_op_list = op_def_pb2.OpList()\n  for missing_op in missing_ops:\n    if missing_op not in cpp_registry_ops:\n      logging.info(\n          \"Op %s is missing from both the python and C++ registry.\",\n          missing_op)\n    else:\n      missing_op_list.op.extend([cpp_registry_ops[missing_op]])\n      logging.info(\n          \"Adding op %s from c++ registry to python registry.\",\n          missing_op)\n\n  op_def_registry.register_op_list(missing_op_list)\n\n  # Note: Only raise missing op ValueError after trying to load ops.\n  # This allows the test to exercise all the calls into TensorFlow\n  # without having to write a C + python test.\n  if not missing_ops <= set(cpp_registry_ops.keys()):\n    raise RuntimeError(\n        \"Graph ops missing from the python registry (%s) are also absent from \"\n        \"the c++ registry.\"\n        % missing_ops.difference(set(cpp_registry_ops.keys())))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfixes colocation attributes after import according to input_map. This function is meant to be called after importing a GraphDef, in order to rewrite colocate_with constrains analogous to how inputs to ops are rewritten by input_map during import. It also updates devices accordingly. The nodes in the given import scope of the current default graph have their colocation attributes (that is, the \"loc:@...\" values in the \"_class\" attr) rewritten as follows: If, before the call, op x has attribute loc:@y, and `input_map` replaces an output of y with an output of z, then loc:@y gets replaced by the colocation attributes of z (that is, loc:@z, if no other constraints are in play). This style of rewriting imposes the following requirements: * If an output of node y is an input tensor in a signature of the module, y must not have any colocation attributes on it, such that colocations with y are expressed by loc:@y and can be adjusted with a rewriting rule for it. Function `find_signature_input_colocation_error()` checks this during module creation. * If y1 is a state node, its colocation constraints must only reference other state nodes, say, y2. Since all outputs of state nodes are mapped the same way, all their rewriting rules together will do the same thing. Function `find_state_op_colocation_error()` checks this during module creation. * Other nodes may have arbitrary colocation attributes. Mapping of inputs works with tensors, while colocation constraints work with ops. Issues may arise when mapping tensors from ops with multiple outputs. If the outputs of y are replaced by outputs of distinct ops z1, z2, ..., rewriting of loc:@y becomes ambiguous unless z1, z2, ... have equal colocation_groups) If some but not all outputs of y are replaced, it becomes ambiguous whether to rewrite loc:@y at all. For now, this is handled conservatively by raising an error (instead of rewriting to the union of all applicable constraints). This should be very rare: all state ops so far have single outputs (and even if not, the rewriting would be consistent); input ops usually are placeholders, which have single outputs. Args: input_map: a dict mapping from tensor names in the imported graph to existing Tensors, typically the same as passed to tf.import_graph_def(). absolute_import_scope: a string with the full name of the import scope, comprising the current scope when import_graph_def() as called plus the import_scope passed to it. Raises: ValueError: if one imported op has its multiple outputs and they are remapped in a way that causes conflicting colocation rewrites.", "response": "def fix_colocation_after_import(input_map, absolute_import_scope):\n  \"\"\"Fixes colocation attributes after import according to input_map.\n\n  This function is meant to be called after importing a GraphDef, in order\n  to rewrite colocate_with constrains analogous to how inputs to ops\n  are rewritten by input_map during import. It also updates devices accordingly.\n\n  The nodes in the given import scope of the current default graph have their\n  colocation attributes (that is, the \"loc:@...\" values in the \"_class\" attr)\n  rewritten as follows: If, before the call, op x has attribute loc:@y, and\n  `input_map` replaces an output of y with an output of z, then loc:@y gets\n  replaced by the colocation attributes of z (that is, loc:@z, if no other\n  constraints are in play).\n\n  This style of rewriting imposes the following requirements:\n\n    * If an output of node y is an input tensor in a signature of the module,\n      y must not have any colocation attributes on it, such that colocations\n      with y are expressed by loc:@y and can be adjusted with a rewriting rule\n      for it. Function `find_signature_input_colocation_error()` checks this\n      during module creation.\n\n    * If y1 is a state node, its colocation constraints must only reference\n      other state nodes, say, y2. Since all outputs of state nodes are mapped\n      the same way, all their rewriting rules together will do the same thing.\n      Function `find_state_op_colocation_error()` checks this during module\n      creation.\n\n    * Other nodes may have arbitrary colocation attributes.\n\n  Mapping of inputs works with tensors, while colocation constraints work with\n  ops. Issues may arise when mapping tensors from ops with multiple outputs.\n  If the outputs of y are replaced by outputs of distinct ops z1, z2, ...,\n  rewriting of loc:@y becomes ambiguous unless z1, z2, ... have equal\n  colocation_groups) If some but not all outputs of y are replaced, it\n  becomes ambiguous whether to rewrite loc:@y at all. For now, this is\n  handled conservatively by raising an error (instead of rewriting to the\n  union of all applicable constraints). This should be very rare: all state\n  ops so far have single outputs (and even if not, the rewriting would be\n  consistent); input ops usually are placeholders, which have single outputs.\n\n  Args:\n    input_map: a dict mapping from tensor names in the imported graph to\n      existing Tensors, typically the same as passed to tf.import_graph_def().\n    absolute_import_scope: a string with the full name of the import scope,\n      comprising the current scope when import_graph_def() as called plus\n      the import_scope passed to it.\n\n  Raises:\n    ValueError: if one imported op has its multiple outputs and they are\n      remapped in a way that causes conflicting colocation rewrites.\n  \"\"\"\n  attr_map = _build_colocation_attr_map(input_map, absolute_import_scope)\n  _apply_colocation_attr_map(attr_map, absolute_import_scope)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_colocation_attr_map(input_map, absolute_import_scope):\n  colocation_attr_map = collections.defaultdict(_ConsistentValue)\n  used_outputs_of_imported_ops = collections.defaultdict(set)\n  # Collect mappings from the input_map.\n  for imported_tensor_name, mapped_tensor in input_map.items():\n    imported_tensor_name = absolute_import_scope + \"/\" + imported_tensor_name\n    imported_op_name, imported_index = _split_tensor_name(imported_tensor_name)\n    key = tf.compat.as_bytes(\"loc:@\" + imported_op_name)\n    colocation_attr_map[key].Set(\n        mapped_tensor.op.colocation_groups(),\n        {\"reason\": \"input '%s' is substituted by '%s'\" % (\n            imported_tensor_name, mapped_tensor.name)})\n    used_outputs_of_imported_ops[imported_op_name].add(imported_index)\n  # Add unchanged mappings for additional, non-remapped outputs of ops touched\n  # by the input_map. For now, these just signal inconsistency when used.\n  for imported_op_name, used_outputs in used_outputs_of_imported_ops.items():\n    imported_op = tf_v1.get_default_graph().get_operation_by_name(\n        imported_op_name)\n    unused_outputs = set(range(len(imported_op.outputs))) - used_outputs\n    if not unused_outputs: continue\n    key = tf.compat.as_bytes(\"loc:@\" + imported_op_name)\n    if imported_op.colocation_groups() != [key]:\n      # This should never happen: state nodes are remapped fully, input nodes\n      # are prevented from having colocation attributes.\n      raise ValueError(\n          \"Internal error: tensors from op '%s' are partially remapped in \"\n          \"import but op.colocation_groups=%s cannot be captured in a \"\n          \"simple rewrite rule.\" %\n          (imported_op_name, imported_op.colocation_groups()))\n    colocation_attr_map[key].Set(\n        [key],\n        {\"reason\": \"tensor '%s:%s' is not substituted by inputs\" % (\n            imported_op_name,\n            \",\".join(str(i) for i in sorted(unused_outputs)))})\n\n  return colocation_attr_map", "response": "Builds a colocation attr map from pre - import to post - import colocation attrs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _apply_colocation_attr_map(colocation_attr_map, absolute_import_scope):\n  graph = tf_v1.get_default_graph()\n  for op in graph.get_operations():\n    # Rewrite the values of the \"_class\" attr that store colocation constraints.\n    # NOTE: The colocation_group loc:@X of a node with itself is not stored\n    # explicitly as an attr, so rewrite errors for loc:@X are not triggered\n    # by the mere existence of X.\n    if not op.name.startswith(absolute_import_scope + \"/\"): continue\n    try:\n      class_values = op.get_attr(\"_class\")\n    except ValueError:\n      continue  # No _class attr found; nothing to do.\n    new_attr_value = tf_v1.AttrValue()\n    new_coloc_groups = []\n    for class_value in class_values:\n      if class_value.startswith(tf.compat.as_bytes(\"loc:@\")):\n        if class_value not in colocation_attr_map:\n          rewritten_class_value = [class_value]\n        else:\n          rewritten_class_value = (colocation_attr_map[\n              class_value].GetConsistentValueOrRaise(\n                  \"Failed to rewrite colocation constraints while applying \"\n                  \"hub.Module:\\n\"\n                  \"The module graph contains a node {op!r} \"\n                  \"that has a colocation constraint {class_value!r} \"\n                  \"with ambiguous rewriting {old_value!r} vs {new_value!r} \"\n                  \"because {old_reason} and {new_reason}, respectively.\\n\"\n                  \"To fix, avoid publishing a module with inputs comprising \"\n                  \"multiple outputs of one op that is referenced in \"\n                  \"tf.colocate_with(...) constraints on other ops.\",\n                  {\"op\": op.name, \"class_value\": class_value}))\n        new_coloc_groups.extend(rewritten_class_value)\n      else:\n        new_attr_value.list.s.append(class_value)\n    new_coloc_groups = sorted(set(new_coloc_groups))\n    new_attr_value.list.s.extend(new_coloc_groups)\n    op._set_attr(\"_class\", new_attr_value)  # pylint: disable=protected-access\n\n    # Mimic the code of tf.import_graph_def(): If there are colocation\n    # constraints, use any of them to set the device (overriding what the\n    # device function stack would do), without attempting to merge or check for\n    # equality. If they were inconsistent, TensorFlow's C++ runtime would fail\n    # anyways due to conflicting colocation constraints.\n    # Note that Hub imports GraphDefs with devices cleared, so this code deals\n    # with the result of import_graph_def, not a setting saved in the module.\n    if new_coloc_groups:\n      new_coloc_device = \"\"\n      for new_coloc_group in new_coloc_groups:\n        assert new_coloc_group.startswith(tf.compat.as_bytes(\"loc:@\"))\n        new_coloc_target_op = graph.get_operation_by_name(\n            tf.compat.as_str_any(new_coloc_group[5:]))\n        new_coloc_device = new_coloc_target_op.device\n        if new_coloc_device: break\n      # Set this, even if empty, to avoid retaining an outdated value.\n      op._set_device(new_coloc_device)", "response": "Rewrites colocation constraints in the current default graph according to colocation_attr_map."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_state_op_colocation_error(graph, reported_tags=None):\n  state_op_types = list_registered_stateful_ops_without_inputs()\n  state_op_map = {op.name: op for op in graph.get_operations()\n                  if op.type in state_op_types}\n  for op in state_op_map.values():\n    for colocation_group in op.colocation_groups():\n      if not (colocation_group.startswith(tf.compat.as_bytes(\"loc:@\")) and\n              tf.compat.as_str_any(colocation_group[5:]) in state_op_map):\n        tags_prefix = (\"\" if reported_tags is None else\n                       \"in the graph for tags %s, \" % reported_tags)\n        return (\n            \"A state-holding node x of a module's graph (e.g., a Variable op) \"\n            \"must not be subject to a tf.colocate_with(y) constraint \"\n            \"unless y is also a state-holding node.\\n\"\n            \"Details: %snode '%s' has op '%s', which counts as state-holding, \"\n            \"but Operation.colocation_groups() == %s. \" %\n            (tags_prefix, op.name, op.type, op.colocation_groups()))\n  return None", "response": "Returns error message for colocation of state ops."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning error message for colocation of signature inputs.", "response": "def find_signature_input_colocation_error(signature_name, inputs):\n  \"\"\"Returns error message for colocation of signature inputs, or None if ok.\"\"\"\n  for input_name, tensor in inputs.items():\n    expected_colocation_groups = [tf.compat.as_bytes(\"loc:@\" + tensor.op.name)]\n    if tensor.op.colocation_groups() != expected_colocation_groups:\n      return (\n          \"A tensor x used as input in a signature must not be subject to a \"\n          \"tf.colocate_with(y) constraint. (The reverse would be allowed.)\\n\"\n          \"Details: tensor '%s' appears as input '%s' of signature '%s' \"\n          \"but has Tensor.op.colocation_groups() == %s\" %\n          (tensor, input_name, signature_name, tensor.op.colocation_groups()))\n  return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_signature_inputs_from_multivalued_ops(inputs):\n  dense_inputs = []  # List of (str, Tensor), with SparseTensors decomposed.\n  for name, tensor in sorted(inputs.items()):\n    if isinstance(tensor, tf.SparseTensor):\n      dense_inputs.extend((\"%s.%s\" % (name, attr), getattr(tensor, attr))\n                          for attr in (\"indices\", \"values\", \"dense_shape\"))\n    else:\n      dense_inputs.append((name, tensor))\n  warnings = [(name, tensor.name) for name, tensor in dense_inputs\n              if len(tensor.op.outputs) != 1]\n  if warnings:\n    return (\n        \"WARNING: The inputs declared in hub.add_signature() should be tensors \"\n        \"from ops with a single output, or else uses of tf.colocate_with() on \"\n        \"that op can trigger fatal errors when the module is applied and \"\n        \"colocation constraints have to be rewritten.\\nAffected inputs: %s\" %\n        \", \".join(\"%s='%s'\" % pair for pair in warnings))\n  return None", "response": "Returns error message for module inputs from ops with multiple outputs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _export(self, path, variables_saver):\n    self._saved_model_handler.export(path, variables_saver=variables_saver)\n\n    module_def_proto = module_def_pb2.ModuleDef()\n    module_def_proto.format = module_def_pb2.ModuleDef.FORMAT_V3\n    module_def_filename = get_module_proto_path(path)\n    tf_utils.atomic_write_string_to_file(\n        module_def_filename,\n        module_def_proto.SerializeToString(),\n        overwrite=False)\n    logging.info(\"Exported TF-Hub module to: %s\", path)", "response": "Exports the current state of the current module to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the state graph for the given name scope.", "response": "def _create_state_graph(self, name):\n    \"\"\"Creates the graph nodes that hold the state of the Module.\n\n    Args:\n      name: name scope to create the state graph in.\n\n    Returns:\n      A tuple consisting of:\n        variables_tensor_map: a map from tensor names in the original graph def\n          to the created Variables objects.\n        state_map: a map from tensors names in the original graph def to the\n          instantiated tensors to be used as a state_map.\n    \"\"\"\n    import_collections = [\n        tf_v1.GraphKeys.GLOBAL_VARIABLES,\n        tf_v1.GraphKeys.MODEL_VARIABLES,\n        tf_v1.GraphKeys.TABLE_INITIALIZERS,\n        tf_v1.GraphKeys.ASSET_FILEPATHS,  # Typically used to initialize tables.\n        tf_v1.GraphKeys.COND_CONTEXT,\n        tf_v1.GraphKeys.WHILE_CONTEXT,\n    ]\n    if self._trainable:\n      # TODO(b/64049014): Import UPDATE_OPS which do not depend on inputs.\n      import_collections.extend([tf_v1.GraphKeys.TRAINABLE_VARIABLES,\n                                 tf_v1.GraphKeys.REGULARIZATION_LOSSES])\n\n    absolute_scope_name = tf_v1.get_default_graph().unique_name(\n        name, mark_as_used=False)\n    relative_scope_name = absolute_scope_name.split(\"/\")[-1]\n    assert relative_scope_name == name  # verify name scope was indeed unused.\n\n    meta_graph = meta_graph_pb2.MetaGraphDef()\n    meta_graph.CopyFrom(self._meta_graph)\n\n    meta_graph_lib.filter_collections(meta_graph, import_collections)\n    meta_graph_lib.prefix_shared_name_attributes(meta_graph,\n                                                 absolute_scope_name)\n\n    tf_v1.train.import_meta_graph(\n        meta_graph,\n        input_map={},\n        import_scope=relative_scope_name)\n\n    # Build a list from the variable name in the module definition to the actual\n    # instantiated variables.\n    variables_tensor_map = {}\n    for var in tf_v1.global_variables():\n      if var.op.name.startswith(absolute_scope_name + \"/\"):\n        variables_tensor_map[var.name[len(absolute_scope_name)+1:]] = var\n\n    # Build a map of tensors to feed from the state-graph into subsequent\n    # apply-graphs.\n    def _get_tensor(tensor_name):\n      return tf_v1.get_default_graph().get_tensor_by_name(\n          meta_graph_lib.prepend_name_scope(\n              tensor_name, import_scope=absolute_scope_name))\n\n    state_op_names = list_registered_stateful_ops_without_inputs()\n    state_map = get_state_map(meta_graph, state_op_names, set(), _get_tensor)\n\n    return variables_tensor_map, state_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_apply_graph(self, signature, input_tensors, name):\n    signature_def = self._meta_graph.signature_def.get(signature)\n    meta_graph = meta_graph_pb2.MetaGraphDef()\n    meta_graph.CopyFrom(self._meta_graph)\n    apply_graph = tf_v1.get_default_graph()\n    infeed_map = tensor_info.build_input_map(signature_def.inputs,\n                                             input_tensors)\n\n    # Build a input map to feed when importing the apply-graph by augmenting the\n    # state_map with the input args. This allows an input to override a tensor\n    # from the state-graph.\n    feed_map = dict(self._state_map)\n    # If we are applying the module in a function with a TPUReplicateContext, we\n    # must capture the state tensors in generating our feedmap and prune out\n    # assign ops. Function graph semantics are different in that all ops are\n    # executed regardless of dependency.\n    # TODO(b/112575006): The following adds functionality of function call\n    # within a TPU context. Work to generalize this for all function calls is\n    # ongoing.\n    if self._is_tpu_graph_function():\n      for k, v in self._state_map.items():\n        feed_map[k] = apply_graph.capture(v)\n      meta_graph_lib.prune_unused_nodes(meta_graph, signature_def)\n      # After we prune the metagraph def, we might need to prune away\n      # infeeds which no longer exist.\n      meta_graph_lib.prune_feed_map(meta_graph, infeed_map)\n    elif apply_graph.building_function:\n      raise NotImplementedError(\n          \"Using TF-Hub module within a TensorFlow defined function \"\n          \"is currently not supported.\")\n\n    # As state ops in the apply graph are unused, replace them with Placeholders\n    # so that in a heirarchical instantiation, apply_graph state ops are\n    # ignored.\n    replace_apply_state(meta_graph,\n                        list_registered_stateful_ops_without_inputs(), feed_map)\n    feed_map.update(infeed_map)\n\n    # Make state tensors enter the current context. This way the Module can be\n    # applied inside a control flow structure such as a while_loop.\n    control_flow = apply_graph._get_control_flow_context()  # pylint: disable=protected-access\n    if control_flow:\n      for key, value in sorted(feed_map.items()):\n        feed_map[key] = control_flow.AddValue(value)\n\n    # Don't mark the name as used at this point - import_scoped_meta_graph will\n    # start using it.\n    absolute_scope_name = apply_graph.unique_name(name, mark_as_used=False)\n    relative_scope_name = absolute_scope_name.split(\"/\")[-1]\n\n    import_collections = [\n        # In most cases ASSET_FILEPATHS are only used for the TABLE_INITIALIZERS\n        # ops, however one could create a graph that uses an asset at any other\n        # time. As so everytime we bring the tensor with that has the asset\n        # filename we must annotate it as so, so later re-exports have that\n        # semantic information and can handle it.\n        tf_v1.GraphKeys.ASSET_FILEPATHS,\n        tf_v1.GraphKeys.COND_CONTEXT,\n        tf_v1.GraphKeys.WHILE_CONTEXT,\n    ]\n    if self._trainable:\n      import_collections.extend([tf_v1.GraphKeys.UPDATE_OPS])\n\n    meta_graph_lib.filter_collections(meta_graph, import_collections)\n    meta_graph_lib.prefix_shared_name_attributes(meta_graph,\n                                                 absolute_scope_name)\n    if len(meta_graph.collection_def) and self._is_tpu_graph_function():\n      raise NotImplementedError(\n          \"Applying modules with collections inside TPU functions is not \"\n          \"supported.\")\n\n    tf_v1.train.import_meta_graph(\n        meta_graph,\n        input_map=feed_map,\n        import_scope=relative_scope_name)\n    fix_colocation_after_import(input_map=feed_map,\n                                absolute_import_scope=absolute_scope_name)\n\n    def get_tensor(name):\n      # When trying to output an input tensor there are no nodes created within\n      # the apply scope. So one must look into the input map.\n      try:\n        return feed_map[name]\n      except KeyError:\n        return apply_graph.get_tensor_by_name(\n            meta_graph_lib.prepend_name_scope(\n                name, import_scope=absolute_scope_name))\n\n    return tensor_info.build_output_map(signature_def.outputs, get_tensor)", "response": "Creates the apply - graph for the given signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(self, path, session):\n    def variables_saver(variables_path):\n      if self._saver:\n        self._saver.save(\n            session, variables_path,\n            write_meta_graph=False,\n            write_state=False)\n\n    self._spec._export(path, variables_saver)", "response": "Exports the current state of the object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreceive a value for the object and some context on its source.", "response": "def Set(self, value, context=None):\n    \"\"\"Receives a value for the object and some context on its source.\"\"\"\n    if self.has_error: return\n    if self.value is None:\n      self.value = value\n      self._context[\"old_value\"] = value\n      self._context.update({\"old_\" + k: v for k, v in context.items()})\n    elif self.value != value:\n      self.has_error = True\n      self._context[\"new_value\"] = value\n      self._context.update({\"new_\" + k: v for k, v in context.items()})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetConsistentValueOrRaise(self, error_format, context=None):\n    if self.has_error:\n      full_context = dict(self._context)\n      if context: full_context.update(context)\n      raise ValueError(error_format.format(**full_context))\n    return self.value", "response": "Gets consistent value or raises ValueError with formatted contexts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _module_dir(handle):\n  cache_dir = resolver.tfhub_cache_dir(use_temp=True)\n  return resolver.create_local_module_dir(\n      cache_dir,\n      hashlib.sha1(handle.encode(\"utf8\")).hexdigest())", "response": "Returns the directory where to cache the module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_variables_path(export_dir):\n  return os.path.join(\n      tf.compat.as_bytes(export_dir),\n      tf.compat.as_bytes(tf_v1.saved_model.constants.VARIABLES_DIRECTORY),\n      tf.compat.as_bytes(tf_v1.saved_model.constants.VARIABLES_FILENAME))", "response": "Returns the path for storing variables checkpoints."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_node_name_from_tensor(tensor_name):\n  result = re.match(r\"([^:]*):\\d+$\", tensor_name)\n  if not result:\n    raise ValueError(\n        \"Unexpected format for tensor name. Expected node_name:output_number. \"\n        \"Got %r\" % tensor_name)\n  return result.group(1)", "response": "Returns node_name from tensor name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_signature(key, inputs, outputs):\n  _check_dict_maps_to_tensors_or_sparse_tensors(inputs)\n  _check_dict_maps_to_tensors_or_sparse_tensors(outputs)\n  input_info = {\n      input_name: tf_v1.saved_model.utils.build_tensor_info(tensor)\n      for input_name, tensor in inputs.items()\n  }\n  output_info = {\n      output_name: tf_v1.saved_model.utils.build_tensor_info(tensor)\n      for output_name, tensor in outputs.items()\n  }\n  signature = tf_v1.saved_model.signature_def_utils.build_signature_def(\n      input_info, output_info)\n  tf_v1.add_to_collection(_SIGNATURE_COLLECTION, (key, signature))", "response": "Adds a signature to current graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _export_signatures(meta_graph):\n  named_signatures = tf_v1.get_collection(_SIGNATURE_COLLECTION)\n  if not named_signatures:\n    raise ValueError(\"No signatures present. Please call hub.add_signature(...)\"\n                     \"at least once in the module_fn.\")\n  for key, signature in named_signatures:\n    meta_graph.signature_def[key].CopyFrom(signature)", "response": "Exports signatures from current graph into a MetaGraphDef."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attach_bytes(key, the_bytes):\n  tf_v1.add_to_collection(\n      _ATTACHMENT_COLLECTION_INTERNAL,\n      module_attachment_pb2.ModuleAttachment(key=key, value=the_bytes))", "response": "Adds a ModuleAttachment to the current graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport ModuleAttachments from the current tf. Graph into meta_graph.", "response": "def _export_module_attachments(meta_graph):\n  \"\"\"Exports ModuleAttachments from the current tf.Graph into `meta_graph`.\"\"\"\n  added_attachments = tf_v1.get_collection(_ATTACHMENT_COLLECTION_INTERNAL)\n  if not added_attachments: return  # Don't touch `meta_graph`.\n  unique_attachments = collections.OrderedDict(  # Avoid indeterminism.\n      (attachment.key, attachment)\n      for attachment in added_attachments)\n  meta_graph.collection_def[ATTACHMENT_COLLECTION_SAVED].bytes_list.value[:] = [\n      attachment.SerializeToString()\n      for attachment in unique_attachments.values()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_attached_bytes_map(meta_graph):\n  result = {}\n  if ATTACHMENT_COLLECTION_SAVED not in meta_graph.collection_def:\n    return result\n  collection_def = meta_graph.collection_def[ATTACHMENT_COLLECTION_SAVED]\n  if collection_def.WhichOneof(\"kind\") != \"bytes_list\":\n    raise ValueError(\n        \"Internal CollectionDef for attached messages has kind %s, \"\n        \"expected bytes_list\" % collection_def.WhichOneof(\"kind\"))\n  attachment = module_attachment_pb2.ModuleAttachment()\n  for value in collection_def.bytes_list.value:\n    attachment.ParseFromString(value)\n    result[attachment.key] = attachment.value  # Immutable; needs no copy.\n  return result", "response": "Returns the dict of ModuleAttachments stored in meta_graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise TypeError if node_def does not match the expectations.", "response": "def _check_asset_node_def(node_def):\n  \"\"\"Raises TypeError if `node_def` does not match the expectations.\"\"\"\n  if node_def.op != \"Const\":\n    raise TypeError(\"Asset node must be of type constant.\")\n  if tf.as_dtype(node_def.attr[\"dtype\"].type) != tf.string:\n    raise TypeError(\"Asset node must be of dtype string.\")\n  if len(node_def.attr[\"value\"].tensor.string_val) != 1:\n    raise TypeError(\"Asset node must be a scalar.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _merge_assets_key_collection(saved_model_proto, path):\n  for meta_graph in saved_model_proto.meta_graphs:\n    node_asset_map = {}\n    if tf_v1.saved_model.constants.ASSETS_KEY in meta_graph.collection_def:\n      assets_any_proto = meta_graph.collection_def[\n          tf_v1.saved_model.constants.ASSETS_KEY].any_list.value\n      for asset_any_proto in assets_any_proto:\n        asset_proto = meta_graph_pb2.AssetFileDef()\n        asset_any_proto.Unpack(asset_proto)\n        asset_filename = _get_asset_filename(path, asset_proto.filename)\n        node_asset_map[_get_node_name_from_tensor(\n            asset_proto.tensor_info.name)] = asset_filename\n      del meta_graph.collection_def[tf_v1.saved_model.constants.ASSETS_KEY]\n\n    for node in meta_graph.graph_def.node:\n      asset_filepath = node_asset_map.get(node.name)\n      if asset_filepath:\n        _check_asset_node_def(node)\n        node.attr[\"value\"].tensor.string_val[0] = asset_filepath", "response": "Merges the ASSETS_KEY collection into the SavedModel proto."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an ASSETS_KEY collection in the GraphDefs in the SavedModel and returns a list of ASSETS_KEY values.", "response": "def _make_assets_key_collection(saved_model_proto, export_path):\n  \"\"\"Creates an ASSETS_KEY collection in the GraphDefs in saved_model_proto.\n\n  Adds an ASSETS_KEY collection to the GraphDefs in the SavedModel and returns\n  a map from original asset filename to filename when exporting the SavedModel\n  to `export_path`.\n\n  This is roughly the inverse operation of `_merge_assets_key_collection`.\n\n  Args:\n    saved_model_proto: SavedModel proto to be modified.\n    export_path: string with path where the saved_model_proto will be exported.\n\n  Returns:\n    A map from original asset filename to asset filename when exporting the\n    SavedModel to path.\n\n  Raises:\n    ValueError: on unsuported/unexpected SavedModel.\n  \"\"\"\n  asset_filenames = {}\n  used_asset_filenames = set()\n\n  def _make_asset_filename(original_filename):\n    \"\"\"Returns the asset filename to use for the file.\"\"\"\n    if original_filename in asset_filenames:\n      return asset_filenames[original_filename]\n\n    basename = os.path.basename(original_filename)\n    suggestion = basename\n    index = 0\n    while suggestion in used_asset_filenames:\n      suggestion = \"%s%d\" % (basename, index)\n      index += 1\n    asset_filenames[original_filename] = suggestion\n    used_asset_filenames.add(suggestion)\n    return suggestion\n\n  for meta_graph in saved_model_proto.meta_graphs:\n    collection_def = meta_graph.collection_def.get(\n        tf_v1.GraphKeys.ASSET_FILEPATHS)\n\n    if collection_def is None:\n      continue\n    if collection_def.WhichOneof(\"kind\") != \"node_list\":\n      raise ValueError(\n          \"MetaGraph collection ASSET_FILEPATHS is not a list of tensors.\")\n\n    for tensor in collection_def.node_list.value:\n      if not tensor.endswith(\":0\"):\n        raise ValueError(\"Unexpected tensor in ASSET_FILEPATHS collection.\")\n\n    asset_nodes = set([\n        _get_node_name_from_tensor(tensor)\n        for tensor in collection_def.node_list.value\n    ])\n\n    tensor_filename_map = {}\n    for node in meta_graph.graph_def.node:\n      if node.name in asset_nodes:\n        _check_asset_node_def(node)\n        filename = node.attr[\"value\"].tensor.string_val[0]\n        tensor_filename_map[node.name + \":0\"] = filename\n        # Clear value to avoid leaking the original path.\n        node.attr[\"value\"].tensor.string_val[0] = (\n            tf.compat.as_bytes(\"SAVEDMODEL-ASSET\"))\n\n    if tensor_filename_map:\n      assets_key_collection = meta_graph.collection_def[\n          tf_v1.saved_model.constants.ASSETS_KEY]\n\n      for tensor, filename in sorted(tensor_filename_map.items()):\n        asset_proto = meta_graph_pb2.AssetFileDef()\n        asset_proto.filename = _make_asset_filename(filename)\n        asset_proto.tensor_info.name = tensor\n        assets_key_collection.any_list.value.add().Pack(asset_proto)\n\n  return {\n      original_filename: _get_asset_filename(export_path, asset_filename)\n      for original_filename, asset_filename in asset_filenames.items()\n  }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_saved_model(path):\n  # Based on tensorflow/python/saved_model/loader.py implementation.\n  path_to_pb = _get_saved_model_proto_path(path)\n  file_content = tf_v1.gfile.Open(path_to_pb, \"rb\").read()\n  saved_model = saved_model_pb2.SavedModel()\n  try:\n    saved_model.ParseFromString(file_content)\n  except message.DecodeError as e:\n    raise IOError(\"Cannot parse file %s: %s.\" % (path_to_pb, str(e)))\n  return saved_model", "response": "Reads the savedmodel. pb file containing SavedModel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a SavedModelHandler from a SavedModel in path.", "response": "def load(path):\n  \"\"\"Creates a SavedModelHandler from a SavedModel in `path`.\"\"\"\n  proto = _parse_saved_model(path)\n  _merge_assets_key_collection(proto, path)\n  handler = SavedModelHandler()\n  handler._proto = proto  # pylint: disable=protected-access\n  return handler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a copy of Graph with the specified set of tags.", "response": "def add_graph_copy(self, graph, tags=None):\n    \"\"\"Adds a copy of Graph with the specified set of tags.\"\"\"\n    with graph.as_default():\n      # Remove default attrs so that Modules created by a tensorflow version\n      # with ops that have new attrs that are left to their default values can\n      # still be loaded by older versions unware of those attributes.\n      meta_graph = tf_v1.train.export_meta_graph(strip_default_attrs=True)\n      _export_tags(meta_graph, tags)\n      _export_signatures(meta_graph)\n      _export_module_attachments(meta_graph)\n    self._proto.meta_graphs.extend([meta_graph])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_meta_graph_copy(self, tags=None):\n    meta_graph = self.get_meta_graph(tags)\n    copy = tf_v1.MetaGraphDef()\n    copy.CopyFrom(meta_graph)\n    return copy", "response": "Returns a copy of a MetaGraph with the identical set of tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of set of tags.", "response": "def get_tags(self):\n    \"\"\"Returns a list of set of tags.\"\"\"\n    return sorted([frozenset(meta_graph.meta_info_def.tags)\n                   for meta_graph in self.meta_graphs])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting the current SavedModel to a directory.", "response": "def export(self, path, variables_saver=None):\n    \"\"\"Exports to SavedModel directory.\n\n    Args:\n      path: path where to export the SavedModel to.\n      variables_saver: lambda that receives a directory path where to\n        export checkpoints of variables.\n    \"\"\"\n    # Operate on a copy of self._proto since it needs to be modified.\n    proto = saved_model_pb2.SavedModel()\n    proto.CopyFrom(self._proto)\n    assets_map = _make_assets_key_collection(proto, path)\n\n    self._save_all_assets(path, assets_map)\n    self._save_variables(path, variables_saver)\n    self._save_proto(path, proto)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the matching MetaGraphDef or raises KeyError.", "response": "def get_meta_graph(self, tags=None):\n    \"\"\"Returns the matching MetaGraphDef or raises KeyError.\"\"\"\n    matches = [meta_graph\n               for meta_graph in self.meta_graphs\n               if set(meta_graph.meta_info_def.tags) == set(tags or [])]\n    if not matches:\n      raise KeyError(\"SavedModelHandler has no graph with tags: %r\" % tags)\n    if len(matches) != 1:\n      raise KeyError(\n          \"SavedModelHandler has multiple graphs with tags %r\" % tags)\n    return matches[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_existing_weight(self, weight, trainable=None):\n    if trainable is None: trainable = weight.trainable\n    self.add_weight(name=weight.name, shape=weight.shape, dtype=weight.dtype,\n                    trainable=trainable, getter=lambda *_, **__: weight)", "response": "Calls add_weight() to register but not create an existing weight."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to find a fresh variable scope for a given module s state.", "response": "def _try_get_state_scope(name, mark_name_scope_used=True):\n  \"\"\"Returns a fresh variable/name scope for a module's state.\n\n  In order to import a module into a given scope without major complications\n  we require the scope to be empty. This function deals with deciding an unused\n  scope where to define the module state. This is non trivial in cases where\n  name_scope and variable_scopes are out of sync, e.g. tpus or re-entering\n  scopes.\n\n  Args:\n    name: A string with the name of the module as supplied by the client.\n    mark_name_scope_used: a boolean, indicating whether to mark the name\n        scope of the returned value as used.\n\n  Raises:\n    RuntimeError: if the name scope of the freshly created variable scope is\n        already used.\n  \"\"\"\n  tmp_scope_name = tf_v1.get_variable_scope().name\n  if tmp_scope_name:\n    tmp_scope_name += \"/\"\n  with tf.name_scope(tmp_scope_name):\n    # Pick an unused variable scope.\n    with tf_v1.variable_scope(\n        None, default_name=name, auxiliary_name_scope=False) as vs:\n      abs_state_scope = vs.name + \"/\"\n    # Verify that the name scope is available and mark it used if requested.\n    graph = tf_v1.get_default_graph()\n    unique_name_scope = graph.unique_name(name, mark_name_scope_used) + \"/\"\n    if unique_name_scope != abs_state_scope:\n      raise RuntimeError(\n          \"variable_scope %s was unused but the corresponding \"\n          \"name_scope was already taken.\" % abs_state_scope)\n  return abs_state_scope"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert inputs to a dict of inputs and checks extra args.", "response": "def _prepare_dict_inputs(inputs, tensor_info_map):\n  \"\"\"Converts inputs to a dict of inputs and checks extra/missing args.\n\n  Args:\n    inputs: inputs fed to Module.__call__().\n    tensor_info_map: A map from string to `tensor_info.ParsedTensorInfo`\n      describing the signature inputs.\n\n  Returns:\n    A dict of values with the same keys as tensor_info_map.\n\n  Raises:\n    TypeError: If it fails to convert the input values into a dict of tensors\n      to feed to the signature instantiation.\n  \"\"\"\n  if inputs is None:\n    dict_inputs = {}\n  elif isinstance(inputs, dict):\n    dict_inputs = inputs\n  elif len(tensor_info_map) == 1:\n    dict_inputs = {list(tensor_info_map.keys())[0]: inputs}\n  elif not tensor_info_map:\n    raise TypeError(\"Signature expects no inputs.\")\n  else:\n    raise TypeError(\"Signature expects multiple inputs. Use a dict.\")\n\n  dict_inputs_keys = set(dict_inputs.keys())\n  tensor_info_map_keys = set(tensor_info_map.keys())\n  if dict_inputs_keys != tensor_info_map_keys:\n    raise TypeError(\"Cannot convert dict_inputs: missing %r, extra given %r\" %\n                    (sorted(list(tensor_info_map_keys - dict_inputs_keys)),\n                     sorted(list(dict_inputs_keys - tensor_info_map_keys))))\n\n  return dict_inputs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_dict_inputs(inputs, tensor_info_map):\n  dict_inputs = _prepare_dict_inputs(inputs, tensor_info_map)\n  return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n                                                       tensor_info_map)", "response": "Converts from inputs into dict of input tensors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_function_for_module(spec, tags=None):\n  # We create a separate graph and add all the signatures of the module to it.\n  original_graph = tf_v1.get_default_graph()\n  with tf.Graph().as_default():\n    module = Module(spec, tags=tags)\n    input_tensors_per_signature = {}\n    output_tensors_per_signature = {}\n    for signature in module.get_signature_names():\n      # We scope with the signature name as different signatures will likely\n      # contain tensors with the same name (e.g. the input and output tensors).\n      with tf_v1.variable_scope(signature):\n        input_tensors = {}\n        for name, tensorinfo in module.get_input_info_dict(signature).items():\n          # We need to be care with the shape as it may be fully-known,\n          # partially-known or even unknown.\n          shape = tensorinfo.get_shape()\n          effective_shape = None if shape.dims is None else shape.as_list()\n          if tensorinfo.is_sparse:\n            input_tensors[name] = tf_v1.sparse_placeholder(\n                tensorinfo.dtype, shape=effective_shape, name=name)\n          else:\n            input_tensors[name] = tf_v1.placeholder(\n                tensorinfo.dtype, shape=effective_shape, name=name)\n        input_tensors_per_signature[signature] = input_tensors\n        output_tensors_per_signature[signature] = module(\n            input_tensors_per_signature[signature],\n            signature=signature,\n            as_dict=True)\n\n  # Evaluating the tfhub module requires an active tensorflow session.\n    with tf_v1.train.SingularMonitoredSession() as sess:\n\n      def func(\n          inputs=None,\n          _sentinel=None,  # pylint: disable=invalid-name\n          signature=None,\n          as_dict=None):\n        \"\"\"Function that directly evaluates a signature in the module.\"\"\"\n        signature = signature or \"default\"\n        input_tensors = input_tensors_per_signature[signature]\n\n        dict_inputs = _prepare_dict_inputs(inputs, input_tensors)\n\n        # The input arguments are directly fed into the session.\n        feed_dict = {\n            input_tensors[key]: value for key, value in dict_inputs.items()\n        }\n        output = output_tensors_per_signature[signature]\n        output = _prepare_outputs(output, as_dict)\n        return sess.run(output, feed_dict=feed_dict)\n\n      with original_graph.as_default():\n        # Yield the function since that will keep the session alive until the\n        # user exits the context.\n        yield func", "response": "A context manager that yields a function to directly evaluate a module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(handle):\n  if hasattr(tf_v1.saved_model, \"load_v2\"):\n    module_handle = resolve(handle)\n    return tf_v1.saved_model.load_v2(module_handle)\n  else:\n    raise NotImplementedError(\"hub.load() is not implemented for TF < 1.14.x, \"\n                              \"Current version: %s\", tf.__version__)", "response": "Loads a module from a handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndescribes the inputs required by a signature.", "response": "def get_input_info_dict(self, signature=None):\n    \"\"\"Describes the inputs required by a signature.\n\n    Args:\n      signature: A string with the signature to get inputs information for.\n        If None, the default signature is used if defined.\n\n    Returns:\n      The result of ModuleSpec.get_input_info_dict() for the given signature,\n      and the graph variant selected by `tags` when this Module was initialized.\n\n    Raises:\n      KeyError: if there is no such signature.\n    \"\"\"\n    return self._spec.get_input_info_dict(signature=signature, tags=self._tags)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndescribe the outputs provided by a signature.", "response": "def get_output_info_dict(self, signature=None):\n    \"\"\"Describes the outputs provided by a signature.\n\n    Args:\n      signature: A string with the signature to get ouputs information for.\n        If None, the default signature is used if defined.\n\n    Returns:\n      The result of ModuleSpec.get_output_info_dict() for the given signature,\n      and the graph variant selected by `tags` when this Module was initialized.\n\n    Raises:\n      KeyError: if there is no such signature.\n    \"\"\"\n    return self._spec.get_output_info_dict(signature=signature, tags=self._tags)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall ModuleSpec. get_attached_message ; see there for more.", "response": "def get_attached_message(self, key, message_type, required=False):\n    \"\"\"Calls ModuleSpec.get_attached_message(); see there for more.\"\"\"\n    return self._spec.get_attached_message(key, message_type,\n                                           tags=self._tags, required=required)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(self, path, session):\n    if self._graph is not tf_v1.get_default_graph():\n      raise RuntimeError(\"default graph differs from the graph where the \"\n                         \"module was instantiated.\")\n    if self._graph is not session.graph:\n      raise RuntimeError(\"session graph differs from the graph where the \"\n                         \"module was instantiated.\")\n    self._impl.export(path, session)", "response": "Exports the module with the variables from the session in path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of all tf. Variables created by module instantiation.", "response": "def variables(self):\n    \"\"\"Returns the list of all tf.Variables created by module instantiation.\"\"\"\n    result = []\n    for _, value in sorted(self.variable_map.items()):\n      if isinstance(value, list):\n        result.extend(value)\n      else:\n        result.append(value)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing a Module to construct a dense representation of a text feature.", "response": "def text_embedding_column(key, module_spec, trainable=False):\n  \"\"\"Uses a Module to construct a dense representation from a text feature.\n\n  This feature column can be used on an input feature whose values are strings\n  of arbitrary size.\n\n  The result of this feature column is the result of passing its `input`\n  through the module `m` instantiated from `module_spec`, as per\n  `result = m(input)`. The `result` must have dtype float32 and shape\n  `[batch_size, num_features]` with a known value of num_features.\n\n  Example:\n\n  ```python\n    comment = text_embedding_column(\"comment\", \"/tmp/text-module\")\n    feature_columns = [comment, ...]\n    ...\n    features = {\n      \"comment\": np.array([\"wow, much amazing\", \"so easy\", ...]),\n      ...\n    }\n    labels = np.array([[1], [0], ...])\n    # If running TF 2.x, use `tf.compat.v1.estimator.inputs.numpy_input_fn`\n    input_fn = tf.estimator.inputs.numpy_input_fn(features, labels,\n                                                  shuffle=True)\n    estimator = tf.estimator.DNNClassifier(hidden_units, feature_columns)\n    estimator.train(input_fn, max_steps=100)\n  ```\n\n  Args:\n    key: A string or `_FeatureColumn` identifying the text feature.\n    module_spec: A ModuleSpec defining the Module to instantiate or a path where\n      to load a ModuleSpec via `load_module_spec`\n    trainable: Whether or not the Module is trainable. False by default,\n      meaning the pre-trained weights are frozen. This is different from the\n      ordinary tf.feature_column.embedding_column(), but that one is intended\n      for training from scratch.\n\n  Returns:\n    `_DenseColumn` that converts from text input.\n\n  Raises:\n     ValueError: if module_spec is not suitable for use in this feature column.\n  \"\"\"\n  module_spec = module.as_module_spec(module_spec)\n  _check_module_is_text_embedding(module_spec)\n  return _TextEmbeddingColumn(key=key, module_spec=module_spec,\n                              trainable=trainable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the module_spec is a text - embedding module.", "response": "def _check_module_is_text_embedding(module_spec):\n  \"\"\"Raises ValueError if `module_spec` is not a text-embedding module.\n\n  Args:\n    module_spec: A `ModuleSpec` to test.\n\n  Raises:\n    ValueError: if `module_spec` default signature is not compatible with\n    Tensor(string, shape=(?,)) -> Tensor(float32, shape=(?,K)).\n  \"\"\"\n  issues = []\n\n  # Find issues with signature inputs.\n  input_info_dict = module_spec.get_input_info_dict()\n  if len(input_info_dict) != 1:\n    issues.append(\"Module default signature must require only one input\")\n  else:\n    input_info, = input_info_dict.values()\n    input_shape = input_info.get_shape()\n    if not (input_info.dtype == tf.string and input_shape.ndims == 1 and\n            input_shape.as_list() == [None]):\n      issues.append(\n          \"Module default signature must have only one input \"\n          \"tf.Tensor(shape=(?,), dtype=string)\"\n      )\n\n  # Find issues with signature outputs.\n  output_info_dict = module_spec.get_output_info_dict()\n  if \"default\" not in output_info_dict:\n    issues.append(\"Module default signature must have a 'default' output.\")\n  else:\n    output_info = output_info_dict[\"default\"]\n    output_shape = output_info.get_shape()\n    if not (output_info.dtype == tf.float32 and output_shape.ndims == 2 and\n            not output_shape.as_list()[0] and output_shape.as_list()[1]):\n      issues.append(\n          \"Module default signature must have a 'default' output of \"\n          \"tf.Tensor(shape=(?,K), dtype=float32).\"\n      )\n\n  if issues:\n    raise ValueError(\"Module is not a text-embedding: %r\" % issues)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse a Module to get a dense 1 - D representation of images.", "response": "def image_embedding_column(key, module_spec):\n  \"\"\"Uses a Module to get a dense 1-D representation from the pixels of images.\n\n  This feature column can be used on images, represented as float32 tensors of\n  RGB pixel data in the range [0,1]. This can be read from a numeric_column()\n  if the tf.Example input data happens to have decoded images, all with the\n  same shape [height, width, 3]. More commonly, the input_fn will have code to\n  explicitly decode images, resize them (possibly after performing data\n  augmentation such as random crops etc.), and provide a batch of shape\n  [batch_size, height, width, 3].\n\n  The result of this feature column is the result of passing its `input`\n  through the module `m` instantiated from `module_spec`, as per\n  `result = m({\"images\": input})`. The `result` must have dtype float32 and\n  shape `[batch_size, num_features]` with a known value of num_features.\n\n  Example:\n\n  ```python\n    image_column = hub.image_embedding_column(\"embeddings\", \"/tmp/image-module\")\n    feature_columns = [image_column, ...]\n    estimator = tf.estimator.LinearClassifier(feature_columns, ...)\n    height, width = hub.get_expected_image_size(image_column.module_spec)\n    input_fn = ...  # Provides \"embeddings\" with shape [None, height, width, 3].\n    estimator.train(input_fn, ...)\n  ```\n\n  Args:\n    key: A string or `_FeatureColumn` identifying the input image data.\n    module_spec: A string handle or a `ModuleSpec` identifying the module.\n\n  Returns:\n    `_DenseColumn` that converts from pixel data.\n\n  Raises:\n     ValueError: if module_spec is not suitable for use in this feature column.\n  \"\"\"\n  module_spec = module.as_module_spec(module_spec)\n  _check_module_is_image_embedding(module_spec)\n  return _ImageEmbeddingColumn(key=key, module_spec=module_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_module_is_image_embedding(module_spec):\n  issues = []\n\n  # Find issues with \"default\" signature inputs. The common signatures for\n  # image models prescribe a specific name; we trust it if we find it\n  # and if we can do the necessary inference of input shapes from it.\n  input_info_dict = module_spec.get_input_info_dict()\n  if (list(input_info_dict.keys()) != [\"images\"] or\n      input_info_dict[\"images\"].dtype != tf.float32):\n    issues.append(\"Module 'default' signature must require a single input, \"\n                  \"which must have type float32 and name 'images'.\")\n  else:\n    try:\n      image_util.get_expected_image_size(module_spec)\n    except ValueError as e:\n      issues.append(\"Module does not support hub.get_expected_image_size(); \"\n                    \"original error was:\\n\" + str(e))  # Raised again below.\n\n  # Find issues with \"default\" signature outputs. We test that the dtype and\n  # shape is appropriate for use in input_layer().\n  output_info_dict = module_spec.get_output_info_dict()\n  if \"default\" not in output_info_dict:\n    issues.append(\"Module 'default' signature must have a 'default' output.\")\n  else:\n    output_type = output_info_dict[\"default\"].dtype\n    output_shape = output_info_dict[\"default\"].get_shape()\n    if not (output_type == tf.float32 and output_shape.ndims == 2 and\n            output_shape.dims[1].value):\n      issues.append(\"Module 'default' signature must have a 'default' output \"\n                    \"of tf.Tensor(shape=(_,K), dtype=float32).\")\n\n  if issues:\n    raise ValueError(\"Module is not usable as image embedding: %r\" % issues)", "response": "Checks if the module_spec is usable as image embedding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn string. Used for variable scope and naming.", "response": "def name(self):\n    \"\"\"Returns string. Used for variable_scope and naming.\"\"\"\n    if not hasattr(self, \"_name\"):\n      self._name = \"{}_hub_module_embedding\".format(self.key)\n    return self._name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_example_spec(self):\n    height, width = image_util.get_expected_image_size(self.module_spec)\n    input_shape = [height, width, 3]\n    return {self.key: tf_v1.FixedLenFeature(input_shape, tf.float32)}", "response": "Returns a tf. Example parsing spec as dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_dense_tensor(self, inputs, weight_collections=None, trainable=None):\n    del weight_collections, trainable  # Unused.\n    m = module.Module(self.module_spec, trainable=False)\n    images = inputs.get(self)\n    return m({\"images\": images})", "response": "Returns a Tensor to represent this feature in the input_layer ("}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a module from a handle.", "response": "def load(handle):\n  \"\"\"Loads a module from a handle.\n\n  Currently this method only works with Tensorflow 2.x and can only load modules\n  created by calling tensorflow.saved_model.save(). The method works in both\n  eager and graph modes.\n\n  Depending on the type of handle used, the call may involve downloading a\n  Tensorflow Hub module to a local cache location specified by the\n  TFHUB_CACHE_DIR environment variable. If a copy of the module is already\n  present in the TFHUB_CACHE_DIR, the download step is skipped.\n\n  Currently, three types of module handles are supported:\n    1) Smart URL resolvers such as tfhub.dev, e.g.:\n       https://tfhub.dev/google/nnlm-en-dim128/1.\n    2) A directory on a file system supported by Tensorflow containing module\n       files. This may include a local directory (e.g. /usr/local/mymodule) or a\n       Google Cloud Storage bucket (gs://mymodule).\n    3) A URL pointing to a TGZ archive of a module, e.g.\n       https://example.com/mymodule.tar.gz.\n\n  Args:\n    handle: (string) the Module handle to resolve.\n\n  Returns:\n    A trackable object (see tf.saved_model.load() documentation for details).\n\n  Raises:\n    NotImplementedError: If the code is running against incompatible (1.x)\n                         version of TF.\n  \"\"\"\n  if hasattr(tf_v1.saved_model, \"load_v2\"):\n    module_handle = resolve(handle)\n    if tf_v1.gfile.Exists(native_module.get_module_proto_path(module_handle)):\n      raise NotImplementedError(\"TF Hub module '%s' is stored using TF 1.x \"\n                                \"format. Loading of the module using \"\n                                \"hub.load() is not supported.\" % handle)\n    return tf_v1.saved_model.load_v2(module_handle)\n  else:\n    raise NotImplementedError(\"hub.load() is not implemented for TF < 1.14.x, \"\n                              \"Current version: %s\", tf.__version__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn cache directory from either TFHUB_CACHE_DIR or default if set.", "response": "def tfhub_cache_dir(default_cache_dir=None, use_temp=False):\n  \"\"\"Returns cache directory.\n\n  Returns cache directory from either TFHUB_CACHE_DIR environment variable\n  or --tfhub_cache_dir or default, if set.\n\n  Args:\n    default_cache_dir: Default cache location to use if neither TFHUB_CACHE_DIR\n                       environment variable nor --tfhub_cache_dir are\n                       not specified.\n    use_temp: bool, Optional to enable using system's temp directory as a\n              module cache directory if neither default_cache_dir nor\n              --tfhub_cache_dir nor TFHUB_CACHE_DIR environment variable are\n              specified .\n  \"\"\"\n\n  # Note: We are using FLAGS[\"tfhub_cache_dir\"] (and not FLAGS.tfhub_cache_dir)\n  # to access the flag value in order to avoid parsing argv list. The flags\n  # should have been parsed by now in main() by tf.app.run(). If that was not\n  # the case (say in Colab env) we skip flag parsing because argv may contain\n  # unknown flags.\n  cache_dir = (\n      os.getenv(_TFHUB_CACHE_DIR, \"\") or FLAGS[\"tfhub_cache_dir\"].value or\n      default_cache_dir)\n  if not cache_dir and use_temp:\n    # Place all TF-Hub modules under <system's temp>/tfhub_modules.\n    cache_dir = os.path.join(tempfile.gettempdir(), \"tfhub_modules\")\n  if cache_dir:\n    logging.log_first_n(logging.INFO, \"Using %s to cache modules.\", 1,\n                        cache_dir)\n  return cache_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_local_module_dir(cache_dir, module_name):\n  tf_v1.gfile.MakeDirs(cache_dir)\n  return os.path.join(cache_dir, module_name)", "response": "Creates and returns the name of the directory where to cache a module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging a relative tar file to a destination.", "response": "def _merge_relative_path(dst_path, rel_path):\n  \"\"\"Merge a relative tar file to a destination (which can be \"gs://...\").\"\"\"\n  # Convert rel_path to be relative and normalize it to remove \".\", \"..\", \"//\",\n  # which are valid directories in fileystems like \"gs://\".\n  norm_rel_path = os.path.normpath(rel_path.lstrip(\"/\"))\n\n  if norm_rel_path == \".\":\n    return dst_path\n\n  # Check that the norm rel path does not starts with \"..\".\n  if norm_rel_path.startswith(\"..\"):\n    raise ValueError(\"Relative path %r is invalid.\" % rel_path)\n\n  merged = os.path.join(dst_path, norm_rel_path)\n\n  # After merging verify that the merged path keeps the original dst_path.\n  if not merged.startswith(dst_path):\n    raise ValueError(\"Relative path %r is invalid. Failed to merge with %r.\" % (\n        rel_path, dst_path))\n  return merged"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a descriptor file about the directory containing a module.", "response": "def _write_module_descriptor_file(handle, module_dir):\n  \"\"\"Writes a descriptor file about the directory containing a module.\n\n  Args:\n    handle: Module name/handle.\n    module_dir: Directory where a module was downloaded.\n  \"\"\"\n  readme = _module_descriptor_file(module_dir)\n  readme_content = (\n      \"Module: %s\\nDownload Time: %s\\nDownloader Hostname: %s (PID:%d)\" %\n      (handle, str(datetime.datetime.today()), socket.gethostname(),\n       os.getpid()))\n  # The descriptor file has no semantic meaning so we allow 'overwrite' since\n  # there is a chance that another process might have written the file (and\n  # crashed), we just overwrite it.\n  tf_utils.atomic_write_string_to_file(readme, readme_content, overwrite=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn total size in bytes of the given directory.", "response": "def _dir_size(directory):\n  \"\"\"Returns total size (in bytes) of the given 'directory'.\"\"\"\n  size = 0\n  for elem in tf_v1.gfile.ListDirectory(directory):\n    elem_full_path = os.path.join(directory, elem)\n    stat = tf_v1.gfile.Stat(elem_full_path)\n    size += _dir_size(elem_full_path) if stat.is_directory else stat.length\n  return size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the size of the temp dir pointed to by the given lock file.", "response": "def _locked_tmp_dir_size(lock_filename):\n  \"\"\"Returns the size of the temp dir pointed to by the given lock file.\"\"\"\n  task_uid = _task_uid_from_lock_file(lock_filename)\n  try:\n    return _dir_size(\n        _temp_download_dir(_module_dir(lock_filename), task_uid))\n  except tf.errors.NotFoundError:\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait for the lock file to disappear.", "response": "def _wait_for_lock_to_disappear(handle, lock_file, lock_file_timeout_sec):\n  \"\"\"Waits for the lock file to disappear.\n\n  The lock file was created by another process that is performing a download\n  into its own temporary directory. The name of this temp directory is\n  sha1(<module>).<uuid>.tmp where <uuid> comes from the lock file.\n\n  Args:\n    handle: The location from where a module is being download.\n    lock_file: Lock file created by another process downloading this module.\n    lock_file_timeout_sec: The amount of time to wait (in seconds) before we\n                           can declare that the other downloaded has been\n                           abandoned. The download is declared abandoned if\n                           there is no file size change in the temporary\n                           directory within the last 'lock_file_timeout_sec'.\n  \"\"\"\n  locked_tmp_dir_size = 0\n  locked_tmp_dir_size_check_time = time.time()\n  lock_file_content = None\n  while tf_v1.gfile.Exists(lock_file):\n    try:\n      logging.log_every_n(\n          logging.INFO,\n          \"Module '%s' already being downloaded by '%s'. Waiting.\", 10,\n          handle, tf_utils.read_file_to_string(lock_file))\n      if (time.time() - locked_tmp_dir_size_check_time >\n          lock_file_timeout_sec):\n        # Check whether the holder of the current lock downloaded anything\n        # in its temporary directory in the last 'lock_file_timeout_sec'.\n        cur_locked_tmp_dir_size = _locked_tmp_dir_size(lock_file)\n        cur_lock_file_content = tf_utils.read_file_to_string(lock_file)\n        if (cur_locked_tmp_dir_size == locked_tmp_dir_size and\n            cur_lock_file_content == lock_file_content):\n          # There is was no data downloaded in the past\n          # 'lock_file_timeout_sec'. Steal the lock and proceed with the\n          # local download.\n          logging.warning(\"Deleting lock file %s due to inactivity.\",\n                          lock_file)\n          tf_v1.gfile.Remove(lock_file)\n          break\n        locked_tmp_dir_size = cur_locked_tmp_dir_size\n        locked_tmp_dir_size_check_time = time.time()\n        lock_file_content = cur_lock_file_content\n    except tf.errors.NotFoundError:\n      # Lock file or temp directory were deleted during check. Continue\n      # to check whether download succeeded or we need to start our own\n      # download.\n      pass\n    finally:\n      time.sleep(5)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload the content of a module into a temporary directory.", "response": "def atomic_download(handle,\n                    download_fn,\n                    module_dir,\n                    lock_file_timeout_sec=10 * 60):\n  \"\"\"Returns the path to a Module directory for a given TF-Hub Module handle.\n\n  Args:\n    handle: (string) Location of a TF-Hub Module.\n    download_fn: Callback function that actually performs download. The callback\n                 receives two arguments, handle and the location of a temporary\n                 directory to download the content into.\n    module_dir: Directory where to download the module files to.\n    lock_file_timeout_sec: The amount of time we give the current holder of\n                           the lock to make progress in downloading a module.\n                           If no progress is made, the lock is revoked.\n\n  Returns:\n    A string containing the path to a TF-Hub Module directory.\n\n  Raises:\n    ValueError: if the Module is not found.\n  \"\"\"\n  lock_file = _lock_filename(module_dir)\n  task_uid = uuid.uuid4().hex\n  lock_contents = _lock_file_contents(task_uid)\n  tmp_dir = _temp_download_dir(module_dir, task_uid)\n\n  # Attempt to protect against cases of processes being cancelled with\n  # KeyboardInterrupt by using a try/finally clause to remove the lock\n  # and tmp_dir.\n  try:\n    while True:\n      try:\n        tf_utils.atomic_write_string_to_file(lock_file, lock_contents,\n                                             overwrite=False)\n        # Must test condition again, since another process could have created\n        # the module and deleted the old lock file since last test.\n        if tf_v1.gfile.Exists(module_dir):\n          # Lock file will be deleted in the finally-clause.\n          return module_dir\n        break  # Proceed to downloading the module.\n      except tf.errors.OpError:\n        pass\n\n      # Wait for lock file to disappear.\n      _wait_for_lock_to_disappear(handle, lock_file, lock_file_timeout_sec)\n      # At this point we either deleted a lock or a lock got removed by the\n      # owner or another process. Perform one more iteration of the while-loop,\n      # we would either terminate due tf_v1.gfile.Exists(module_dir) or because\n      # we would obtain a lock ourselves, or wait again for the lock to\n      # disappear.\n\n    # Lock file acquired.\n    logging.info(\"Downloading TF-Hub Module '%s'.\", handle)\n    tf_v1.gfile.MakeDirs(tmp_dir)\n    download_fn(handle, tmp_dir)\n    # Write module descriptor to capture information about which module was\n    # downloaded by whom and when. The file stored at the same level as a\n    # directory in order to keep the content of the 'model_dir' exactly as it\n    # was define by the module publisher.\n    #\n    # Note: The descriptor is written purely to help the end-user to identify\n    # which directory belongs to which module. The descriptor is not part of the\n    # module caching protocol and no code in the TF-Hub library reads its\n    # content.\n    _write_module_descriptor_file(handle, module_dir)\n    try:\n      tf_v1.gfile.Rename(tmp_dir, module_dir)\n      logging.info(\"Downloaded TF-Hub Module '%s'.\", handle)\n    except tf.errors.AlreadyExistsError:\n      logging.warning(\"Module already exists in %s\", module_dir)\n\n  finally:\n    try:\n      # Temp directory is owned by the current process, remove it.\n      tf_v1.gfile.DeleteRecursively(tmp_dir)\n    except tf.errors.NotFoundError:\n      pass\n    try:\n      contents = tf_utils.read_file_to_string(lock_file)\n    except tf.errors.NotFoundError:\n      contents = \"\"\n    if contents == lock_contents:\n      # Lock file exists and is owned by this process.\n      try:\n        tf_v1.gfile.Remove(lock_file)\n      except tf.errors.NotFoundError:\n        pass\n\n  return module_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _print_download_progress_msg(self, msg, flush=False):\n    if self._interactive_mode():\n      # Print progress message to console overwriting previous progress\n      # message.\n      self._max_prog_str = max(self._max_prog_str, len(msg))\n      sys.stdout.write(\"\\r%-{}s\".format(self._max_prog_str) % msg)\n      sys.stdout.flush()\n      if flush:\n        print(\"\\n\")\n    else:\n      # Interactive progress tracking is disabled. Print progress to the\n      # standard TF log.\n      logging.info(msg)", "response": "Prints a message about download progress to the console or TF log."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_progress(self, bytes_downloaded):\n    self._total_bytes_downloaded += bytes_downloaded\n    now = time.time()\n    if (self._interactive_mode() or\n        now - self._last_progress_msg_print_time > 15):\n      # Print progress message every 15 secs or if interactive progress\n      # tracking is enabled.\n      self._print_download_progress_msg(\n          \"Downloading %s: %s\" % (self._url,\n                                  tf_utils.bytes_to_readable_str(\n                                      self._total_bytes_downloaded, True)))\n      self._last_progress_msg_print_time = now", "response": "Logs progress information about ongoing module download."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract tarinfo from tgz and writes to dst_path.", "response": "def _extract_file(self, tgz, tarinfo, dst_path, buffer_size=10<<20):\n    \"\"\"Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'.\"\"\"\n    src = tgz.extractfile(tarinfo)\n    dst = tf_v1.gfile.GFile(dst_path, \"wb\")\n    while 1:\n      buf = src.read(buffer_size)\n      if not buf:\n        break\n      dst.write(buf)\n      self._log_progress(len(buf))\n    dst.close()\n    src.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_and_uncompress(self, fileobj, dst_path):\n    try:\n      with tarfile.open(mode=\"r|*\", fileobj=fileobj) as tgz:\n        for tarinfo in tgz:\n          abs_target_path = _merge_relative_path(dst_path, tarinfo.name)\n\n          if tarinfo.isfile():\n            self._extract_file(tgz, tarinfo, abs_target_path)\n          elif tarinfo.isdir():\n            tf_v1.gfile.MakeDirs(abs_target_path)\n          else:\n            # We do not support symlinks and other uncommon objects.\n            raise ValueError(\n                \"Unexpected object type in tar archive: %s\" % tarinfo.type)\n\n        total_size_str = tf_utils.bytes_to_readable_str(\n            self._total_bytes_downloaded, True)\n        self._print_download_progress_msg(\n            \"Downloaded %s, Total size: %s\" % (self._url, total_size_str),\n            flush=True)\n    except tarfile.ReadError:\n      raise IOError(\"%s does not appear to be a valid module.\" % self._url)", "response": "Downloads the content for the fileobj and stores the result in dst_path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prefix_shared_name_attributes(meta_graph, absolute_import_scope):\n  shared_name_attr = \"shared_name\"\n  for node in meta_graph.graph_def.node:\n    shared_name_value = node.attr.get(shared_name_attr, None)\n    if shared_name_value and shared_name_value.HasField(\"s\"):\n      if shared_name_value.s:\n        node.attr[shared_name_attr].s = tf.compat.as_bytes(\n            prepend_name_scope(\n                shared_name_value.s, import_scope=absolute_import_scope))", "response": "In - place prefixes shared_name attributes of nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to propagate backwards in the graph and mark nodes as used.", "response": "def mark_backward(output_tensor, used_node_names):\n  \"\"\"Function to propagate backwards in the graph and mark nodes as used.\n\n  Traverses recursively through the graph from the end tensor, through the op\n  that generates the tensor, and then to the input tensors that feed the op.\n  Nodes encountered are stored in used_node_names.\n\n  Args:\n    output_tensor: A Tensor which we start the propagation.\n    used_node_names: A list of strings, stores the name of nodes we've marked as\n      visited.\n  \"\"\"\n  op = output_tensor.op\n  if op.name in used_node_names:\n    return\n  used_node_names.add(op.name)\n  for input_tensor in op.inputs:\n    mark_backward(input_tensor, used_node_names)\n  for control_input_op in op.control_inputs:\n    used_node_names.add(control_input_op.name)\n    for input_tensor in control_input_op.inputs:\n      mark_backward(input_tensor, used_node_names)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prune_unused_nodes(meta_graph, signature_def):\n  # Instantiate a temporary empty graph so that we have access to Graph API\n  # and import the meta_graph.\n  graph = tf_v1.Graph()\n  with graph.as_default():\n    tf_v1.train.import_meta_graph(meta_graph, input_map={}, import_scope=\"\")\n    # Traverse from all outputs and mark all nodes.\n    used_node_names = set()\n    for _, tensor_def in signature_def.outputs.items():\n      output_tensor = graph.get_tensor_by_name(tensor_def.name)\n      mark_backward(output_tensor, used_node_names)\n    # Filter out all nodes in the meta_graph that are not used.\n    node_filter_in_list = []\n    for node in meta_graph.graph_def.node:\n      # Make a special exception for VarHandleOp. Removing VarhandleOps\n      # will make the graph not importable as they often leave nodes hanging.\n      # These will be disconnected through the feedmap when importing the\n      # metagraph.\n      if node.name in used_node_names or node.op == \"VarHandleOp\":\n        node_filter_in_list.append(node)\n    del meta_graph.graph_def.node[:]\n    meta_graph.graph_def.node.extend(node_filter_in_list)\n  del graph", "response": "Function to prune unused ops given a signature def."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prune_feed_map(meta_graph, feed_map):\n  node_names = [x.name + \":0\" for x in meta_graph.graph_def.node]\n  keys_to_delete = []\n  for k, _ in feed_map.items():\n    if k not in node_names:\n      keys_to_delete.append(k)\n  for k in keys_to_delete:\n    del feed_map[k]", "response": "Function to prune the feedmap of nodes which no longer exist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting to filename atomically.", "response": "def atomic_write_string_to_file(filename, contents, overwrite):\n  \"\"\"Writes to `filename` atomically.\n\n  This means that when `filename` appears in the filesystem, it will contain\n  all of `contents`. With write_string_to_file, it is possible for the file\n  to appear in the filesystem with `contents` only partially written.\n\n  Accomplished by writing to a temp file and then renaming it.\n\n  Args:\n    filename: string, pathname for a file\n    contents: string, contents that need to be written to the file\n    overwrite: boolean, if false it's an error for `filename` to be occupied by\n      an existing file.\n  \"\"\"\n  temp_pathname = (tf.compat.as_bytes(filename) +\n                   tf.compat.as_bytes(\".tmp\") +\n                   tf.compat.as_bytes(uuid.uuid4().hex))\n  with tf_v1.gfile.GFile(temp_pathname, mode=\"w\") as f:\n    f.write(contents)\n  try:\n    tf_v1.gfile.Rename(temp_pathname, filename, overwrite)\n  except tf.errors.OpError:\n    tf_v1.gfile.Remove(temp_pathname)\n    raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_timestamped_export_dir(export_dir_base):\n  attempts = 0\n  while attempts < MAX_DIRECTORY_CREATION_ATTEMPTS:\n    export_timestamp = int(time.time())\n\n    export_dir = os.path.join(\n        tf.compat.as_bytes(export_dir_base),\n        tf.compat.as_bytes(str(export_timestamp)))\n    if not tf_v1.gfile.Exists(export_dir):\n      # Collisions are still possible (though extremely unlikely): this\n      # directory is not actually created yet, but it will be almost\n      # instantly on return from this function.\n      return export_dir\n    time.sleep(1)\n    attempts += 1\n    logging.warn(\n        \"Export directory %s already exists; retrying (attempt %d/%d)\",\n        export_dir, attempts, MAX_DIRECTORY_CREATION_ATTEMPTS)\n  raise RuntimeError(\"Failed to obtain a unique export directory name after \"\n                     \"%d attempts.\".MAX_DIRECTORY_CREATION_ATTEMPTS)", "response": "Builds a path to a new subdirectory within the base directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_temp_export_dir(timestamped_export_dir):\n  (dirname, basename) = os.path.split(timestamped_export_dir)\n  temp_export_dir = os.path.join(\n      tf.compat.as_bytes(dirname),\n      tf.compat.as_bytes(\"temp-{}\".format(basename)))\n  return temp_export_dir", "response": "Builds a directory name based on the argument but starting with temp -."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef garbage_collect_exports(export_dir_base, exports_to_keep):\n  if exports_to_keep is None:\n    return\n  version_paths = []  # List of tuples (version, path)\n  for filename in tf_v1.gfile.ListDirectory(export_dir_base):\n    path = os.path.join(\n        tf.compat.as_bytes(export_dir_base),\n        tf.compat.as_bytes(filename))\n    if len(filename) == 10 and filename.isdigit():\n      version_paths.append((int(filename), path))\n\n  oldest_version_path = sorted(version_paths)[:-exports_to_keep]\n  for _, path in oldest_version_path:\n    try:\n      tf_v1.gfile.DeleteRecursively(path)\n    except tf.errors.NotFoundError as e:\n      logging.warn(\"Can not delete %s recursively: %s\", path, e)", "response": "Deletes older exports and retaining only a given number of the most recent."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a human - readable string representing the number of bytes.", "response": "def bytes_to_readable_str(num_bytes, include_b=False):\n  \"\"\"Generate a human-readable string representing number of bytes.\n\n  The units B, kB, MB and GB are used.\n\n  Args:\n    num_bytes: (`int` or None) Number of bytes.\n    include_b: (`bool`) Include the letter B at the end of the unit.\n\n  Returns:\n    (`str`) A string representing the number of bytes in a human-readable way,\n      including a unit at the end.\n  \"\"\"\n\n  if num_bytes is None:\n    return str(num_bytes)\n  if num_bytes < 1024:\n    result = \"%d\" % num_bytes\n  elif num_bytes < 1048576:\n    result = \"%.2fk\" % (num_bytes / float(1 << 10))\n  elif num_bytes < 1073741824:\n    result = \"%.2fM\" % (num_bytes / float(1 << 20))\n  else:\n    result = \"%.2fG\" % (num_bytes / float(1 << 30))\n\n  if include_b:\n    result += \"B\"\n  return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a new release announcement entry in the docs.", "response": "def announce(version):\n    \"\"\"Generates a new release announcement entry in the docs.\"\"\"\n    # Get our list of authors\n    stdout = check_output([\"git\", \"describe\", \"--abbrev=0\", \"--tags\"])\n    stdout = stdout.decode(\"utf-8\")\n    last_version = stdout.strip()\n\n    stdout = check_output(\n        [\"git\", \"log\", \"{}..HEAD\".format(last_version), \"--format=%aN\"]\n    )\n    stdout = stdout.decode(\"utf-8\")\n\n    contributors = set(stdout.splitlines())\n\n    template_name = (\n        \"release.minor.rst\" if version.endswith(\".0\") else \"release.patch.rst\"\n    )\n    template_text = (\n        Path(__file__).parent.joinpath(template_name).read_text(encoding=\"UTF-8\")\n    )\n\n    contributors_text = (\n        \"\\n\".join(\"* {}\".format(name) for name in sorted(contributors)) + \"\\n\"\n    )\n    text = template_text.format(version=version, contributors=contributors_text)\n\n    target = Path(__file__).parent.joinpath(\n        \"../doc/en/announce/release-{}.rst\".format(version)\n    )\n    target.write_text(text, encoding=\"UTF-8\")\n    print(f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Generated {target.name}\")\n\n    # Update index with the new release entry\n    index_path = Path(__file__).parent.joinpath(\"../doc/en/announce/index.rst\")\n    lines = index_path.read_text(encoding=\"UTF-8\").splitlines()\n    indent = \"   \"\n    for index, line in enumerate(lines):\n        if line.startswith(\"{}release-\".format(indent)):\n            new_line = indent + target.stem\n            if line != new_line:\n                lines.insert(index, new_line)\n                index_path.write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"UTF-8\")\n                print(\n                    f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Updated {index_path.name}\"\n                )\n            else:\n                print(\n                    f\"{Fore.CYAN}[generate.announce] {Fore.RESET}Skip {index_path.name} (already contains release)\"\n                )\n            break\n\n    check_call([\"git\", \"add\", str(target)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pre_release(version):\n    announce(version)\n    regen()\n    changelog(version, write_out=True)\n    fix_formatting()\n\n    msg = \"Preparing release version {}\".format(version)\n    check_call([\"git\", \"commit\", \"-a\", \"-m\", msg])\n\n    print()\n    print(f\"{Fore.CYAN}[generate.pre_release] {Fore.GREEN}All done!\")\n    print()\n    print(f\"Please push your branch and open a PR.\")", "response": "Generates new docs release announcements and creates a local tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_namespaced_horizontal_pod_autoscaler(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, **kwargs)\n            return data", "response": "This method deletes a HorizontalPodAutoscaler with the specified name and namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_api_resources(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.get_api_resources_with_http_info(**kwargs)\n        else:\n            (data) = self.get_api_resources_with_http_info(**kwargs)\n            return data", "response": "Get available resources from API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch_namespaced_horizontal_pod_autoscaler(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Patch the object with the given name namespace with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npatches the status of a HorizontalPodAutoscaler with the given body.", "response": "def patch_namespaced_horizontal_pod_autoscaler_status(self, name, namespace, body, **kwargs):\n        \"\"\"\n        partially update status of the specified HorizontalPodAutoscaler\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_namespaced_horizontal_pod_autoscaler_status(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the HorizontalPodAutoscaler (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V2beta1HorizontalPodAutoscaler\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_horizontal_pod_autoscaler_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_horizontal_pod_autoscaler_status_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_namespaced_horizontal_pod_autoscaler(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_horizontal_pod_autoscaler_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified HorizontalPodAutoscaler with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces the status of the specified HorizontalPodAutoscaler with the specified body.", "response": "def replace_namespaced_horizontal_pod_autoscaler_status(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace status of the specified HorizontalPodAutoscaler\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_horizontal_pod_autoscaler_status(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the HorizontalPodAutoscaler (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V2beta1HorizontalPodAutoscaler body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V2beta1HorizontalPodAutoscaler\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_horizontal_pod_autoscaler_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_horizontal_pod_autoscaler_status_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the ca_bundle of this V1alpha1WebhookClientConfig.", "response": "def ca_bundle(self, ca_bundle):\n        \"\"\"\n        Sets the ca_bundle of this V1alpha1WebhookClientConfig.\n        `caBundle` is a PEM encoded CA bundle which will be used to validate the webhook's server certificate. If unspecified, system trust roots on the apiserver are used.\n\n        :param ca_bundle: The ca_bundle of this V1alpha1WebhookClientConfig.\n        :type: str\n        \"\"\"\n        if ca_bundle is not None and not re.search('^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$', ca_bundle):\n            raise ValueError(\"Invalid value for `ca_bundle`, must be a follow pattern or equal to `/^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$/`\")\n\n        self._ca_bundle = ca_bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a PodPreset with the given namespace and body.", "response": "def create_namespaced_pod_preset(self, namespace, body, **kwargs):\n        \"\"\"\n        create a PodPreset\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_pod_preset(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1alpha1PodPreset body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1alpha1PodPreset\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_pod_preset_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_pod_preset_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_collection_namespaced_pod_preset(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_pod_preset_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_pod_preset_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes a collection of PodPresets from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists or watch objects of kind PodPreset This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_pod_preset_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1alpha1PodPresetList If the method is called asynchronously, returns the request thread.", "response": "def list_pod_preset_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind PodPreset\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_pod_preset_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1alpha1PodPresetList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_pod_preset_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_pod_preset_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_namespaced_cron_job(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_cron_job_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_cron_job_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a new CronJob with the given namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting collection of CronJob This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_namespaced_cron_job(namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_namespaced_cron_job(self, namespace, **kwargs):\n        \"\"\"\n        delete collection of CronJob\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_namespaced_cron_job(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_cron_job_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_cron_job_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_cron_job_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_cron_job_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_cron_job_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of cron jobs for all namespaces"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_namespaced_cron_job(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_cron_job_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_cron_job_with_http_info(namespace, **kwargs)\n            return data", "response": "List the cron jobs in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a single CronJob with the specified namespace.", "response": "def read_namespaced_cron_job(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified CronJob\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_cron_job(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CronJob (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V2alpha1CronJob\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_cron_job_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_cron_job_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the status of a specific CronJob in a namespace.", "response": "def read_namespaced_cron_job_status(self, name, namespace, **kwargs):\n        \"\"\"\n        read status of the specified CronJob\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_cron_job_status(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CronJob (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V2alpha1CronJob\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_cron_job_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_cron_job_status_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a CustomResourceDefinition This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.create_custom_resource_definition(body, async_req=True) >>> result = thread.get() :param async_req bool :param V1beta1CustomResourceDefinition body: (required) :param str pretty: If 'true', then the output is pretty printed. :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. :return: V1beta1CustomResourceDefinition If the method is called asynchronously, returns the request thread.", "response": "def create_custom_resource_definition(self, body, **kwargs):\n        \"\"\"\n        create a CustomResourceDefinition\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_custom_resource_definition(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1CustomResourceDefinition body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1CustomResourceDefinition\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_custom_resource_definition_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_custom_resource_definition_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_custom_resource_definition(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_custom_resource_definition_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_custom_resource_definition_with_http_info(name, **kwargs)\n            return data", "response": "Delete a CustomResourceDefinition by name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_custom_resource_definition(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_custom_resource_definition_with_http_info(**kwargs)\n        else:\n            (data) = self.list_custom_resource_definition_with_http_info(**kwargs)\n            return data", "response": "List custom resource definitions of kind CustomResourceDefinition"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_custom_resource_definition(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_custom_resource_definition_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_custom_resource_definition_with_http_info(name, **kwargs)\n            return data", "response": "Read a specific custom resource definition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the status of a specific CustomResourceDefinition", "response": "def read_custom_resource_definition_status(self, name, **kwargs):\n        \"\"\"\n        read status of the specified CustomResourceDefinition\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_custom_resource_definition_status(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CustomResourceDefinition (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1beta1CustomResourceDefinition\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_custom_resource_definition_status_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_custom_resource_definition_status_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_namespaced_ingress(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_ingress_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_ingress_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Delete an ingress with the specified name and namespace."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_namespaced_ingress(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_ingress_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_ingress_with_http_info(namespace, **kwargs)\n            return data", "response": "List the objects in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npatching the status of a NetworkingV1beta1 Ingress with the given body.", "response": "def patch_namespaced_ingress_status(self, name, namespace, body, **kwargs):\n        \"\"\"\n        partially update status of the specified Ingress\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_namespaced_ingress_status(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Ingress (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: NetworkingV1beta1Ingress\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_ingress_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_ingress_status_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the specified Ingress in a namespace", "response": "def read_namespaced_ingress(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified Ingress\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_ingress(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Ingress (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: NetworkingV1beta1Ingress\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_ingress_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_ingress_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace the specified Ingress with the specified body.", "response": "def replace_namespaced_ingress(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace the specified Ingress\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_ingress(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Ingress (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param NetworkingV1beta1Ingress body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: NetworkingV1beta1Ingress\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_ingress_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_ingress_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_namespaced_ingress_status(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_ingress_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_ingress_status_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the status of the specified Ingress with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect_delete_namespaced_service_proxy_with_path(self, name, namespace, path, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_delete_namespaced_service_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n        else:\n            (data) = self.connect_delete_namespaced_service_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n            return data", "response": "This method connects DELETE requests to proxy of ServiceProxyOptions and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect_get_namespaced_pod_exec(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_get_namespaced_pod_exec_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_get_namespaced_pod_exec_with_http_info(name, namespace, **kwargs)\n            return data", "response": "This method connects GET requests to exec of a pod with the given name and namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects GET requests to proxy of Service This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.connect_get_namespaced_service_proxy(name, namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the ServiceProxyOptions (required) :param str namespace: object name and auth scope, such as for teams and projects (required) :param str path: Path is the part of URLs that include service endpoints, suffixes, and parameters to use for the current proxy request to service. For example, the whole request URL is http://localhost/api/v1/namespaces/kube-system/services/elasticsearch-logging/_search?q=user:kimchy. Path is _search?q=user:kimchy. :return: str If the method is called asynchronously, returns the request thread.", "response": "def connect_get_namespaced_service_proxy(self, name, namespace, **kwargs):\n        \"\"\"\n        connect GET requests to proxy of Service\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_get_namespaced_service_proxy(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ServiceProxyOptions (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str path: Path is the part of URLs that include service endpoints, suffixes, and parameters to use for the current proxy request to service. For example, the whole request URL is http://localhost/api/v1/namespaces/kube-system/services/elasticsearch-logging/_search?q=user:kimchy. Path is _search?q=user:kimchy.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_get_namespaced_service_proxy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_get_namespaced_service_proxy_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect the given pod to the proxy of the specified namespace.", "response": "def connect_head_namespaced_pod_proxy(self, name, namespace, **kwargs):\n        \"\"\"\n        connect HEAD requests to proxy of Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_head_namespaced_pod_proxy(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PodProxyOptions (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str path: Path is the URL path to use for the current proxy request to pod.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_head_namespaced_pod_proxy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_head_namespaced_pod_proxy_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting HEAD requests to proxy of NodeProxyOptions", "response": "def connect_head_node_proxy(self, name, **kwargs):\n        \"\"\"\n        connect HEAD requests to proxy of Node\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_head_node_proxy(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NodeProxyOptions (required)\n        :param str path: Path is the URL path to use for the current proxy request to node.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_head_node_proxy_with_http_info(name, **kwargs)\n        else:\n            (data) = self.connect_head_node_proxy_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_options_namespaced_service_proxy(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_options_namespaced_service_proxy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_options_namespaced_service_proxy_with_http_info(name, namespace, **kwargs)\n            return data", "response": "This method connects OPTIONS requests to proxy of ServiceProxyOptions objects with the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting PATCH requests to proxy of PodProxyOptions", "response": "def connect_patch_namespaced_pod_proxy(self, name, namespace, **kwargs):\n        \"\"\"\n        connect PATCH requests to proxy of Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_patch_namespaced_pod_proxy(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PodProxyOptions (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str path: Path is the URL path to use for the current proxy request to pod.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_patch_namespaced_pod_proxy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_patch_namespaced_pod_proxy_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting the HTTP request to the node proxy", "response": "def connect_patch_node_proxy(self, name, **kwargs):\n        \"\"\"\n        connect PATCH requests to proxy of Node\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_patch_node_proxy(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NodeProxyOptions (required)\n        :param str path: Path is the URL path to use for the current proxy request to node.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_patch_node_proxy_with_http_info(name, **kwargs)\n        else:\n            (data) = self.connect_patch_node_proxy_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_post_namespaced_pod_portforward(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_post_namespaced_pod_portforward_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.connect_post_namespaced_pod_portforward_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Connects to a pod with portforward"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_post_namespaced_service_proxy_with_path(self, name, namespace, path, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_post_namespaced_service_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n        else:\n            (data) = self.connect_post_namespaced_service_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n            return data", "response": "This method connects POST requests to the service proxy of a specific namespace with the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect PUT requests to proxy of Pod This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.connect_put_namespaced_pod_proxy_with_path(name, namespace, path, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the PodProxyOptions (required) :param str namespace: object name and auth scope, such as for teams and projects (required) :param str path: path to the resource (required) :param str path2: Path is the URL path to use for the current proxy request to pod. :return: str If the method is called asynchronously, returns the request thread.", "response": "def connect_put_namespaced_pod_proxy_with_path(self, name, namespace, path, **kwargs):\n        \"\"\"\n        connect PUT requests to proxy of Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_put_namespaced_pod_proxy_with_path(name, namespace, path, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PodProxyOptions (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str path: path to the resource (required)\n        :param str path2: Path is the URL path to use for the current proxy request to pod.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_put_namespaced_pod_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n        else:\n            (data) = self.connect_put_namespaced_pod_proxy_with_path_with_http_info(name, namespace, path, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect PUT requests to proxy of Node This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.connect_put_node_proxy_with_path(name, path, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the NodeProxyOptions (required) :param str path: path to the resource (required) :param str path2: Path is the URL path to use for the current proxy request to node. :return: str If the method is called asynchronously, returns the request thread.", "response": "def connect_put_node_proxy_with_path(self, name, path, **kwargs):\n        \"\"\"\n        connect PUT requests to proxy of Node\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.connect_put_node_proxy_with_path(name, path, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NodeProxyOptions (required)\n        :param str path: path to the resource (required)\n        :param str path2: Path is the URL path to use for the current proxy request to node.\n        :return: str\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.connect_put_node_proxy_with_path_with_http_info(name, path, **kwargs)\n        else:\n            (data) = self.connect_put_node_proxy_with_path_with_http_info(name, path, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_namespaced_endpoints(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_endpoints_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_endpoints_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create the V1 Endpoints in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_namespaced_event(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_event_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_event_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create an event in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a V1Pod with the specified namespace and body.", "response": "def create_namespaced_pod(self, namespace, body, **kwargs):\n        \"\"\"\n        create a Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_pod(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1Pod body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Pod\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_pod_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_pod_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_namespaced_replication_controller(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_replication_controller_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_replication_controller_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a ReplicationController with the specified namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_namespaced_service_account(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_service_account_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_service_account_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a new ServiceAccount with the specified namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_collection_namespaced_endpoints(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_endpoints_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_endpoints_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes all the endpoints in the specified namespace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete collection of Event This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_namespaced_event(namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_namespaced_event(self, namespace, **kwargs):\n        \"\"\"\n        delete collection of Event\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_namespaced_event(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_event_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_event_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_collection_namespaced_pod(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_pod_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_pod_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes all items in the specified namespace from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes collection of PodTemplate This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_namespaced_pod_template(namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_namespaced_pod_template(self, namespace, **kwargs):\n        \"\"\"\n        delete collection of PodTemplate\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_namespaced_pod_template(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_pod_template_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_pod_template_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_collection_namespaced_secret(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_secret_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_secret_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes a collection of secrets in a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete collection of ServiceAccount This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_namespaced_service_account(namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_namespaced_service_account(self, namespace, **kwargs):\n        \"\"\"\n        delete collection of ServiceAccount\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_namespaced_service_account(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_service_account_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_service_account_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a Namespace This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_namespace(name, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the Namespace (required) :param str pretty: If 'true', then the output is pretty printed. :param V1DeleteOptions body: :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately. :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both. :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_namespace(self, name, **kwargs):\n        \"\"\"\n        delete a Namespace\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespace(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Namespace (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespace_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_namespace_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_namespaced_config_map(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_config_map_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_config_map_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Delete a ConfigMap with the specified name and namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a namespace - level LimitRange object", "response": "def delete_namespaced_limit_range(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a LimitRange\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_limit_range(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the LimitRange (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_limit_range_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_limit_range_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a namespaced persistent volume claim.", "response": "def delete_namespaced_persistent_volume_claim(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a PersistentVolumeClaim\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_persistent_volume_claim(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PersistentVolumeClaim (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_persistent_volume_claim_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_persistent_volume_claim_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a ReplicationController with the specified name and namespace.", "response": "def delete_namespaced_replication_controller(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a ReplicationController\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_replication_controller(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ReplicationController (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_replication_controller_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_replication_controller_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_namespaced_resource_quota(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_resource_quota_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_resource_quota_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Delete a resource quota for a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a namespaced ServiceAccount", "response": "def delete_namespaced_service_account(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a ServiceAccount\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_service_account(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ServiceAccount (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_service_account_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_service_account_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_node(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_node_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_node_with_http_info(name, **kwargs)\n            return data", "response": "Delete a node from the store"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the status of the specified component.", "response": "def list_component_status(self, **kwargs):\n        \"\"\"\n        list objects of kind ComponentStatus\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_component_status(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ComponentStatusList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_component_status_with_http_info(**kwargs)\n        else:\n            (data) = self.list_component_status_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_config_map_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_config_map_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_config_map_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "List all namespaces of ConfigMap objects"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_endpoints_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_endpoints_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_endpoints_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of endpoints of kind Endpoints that are all namespaces of the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist or watch objects of kind LimitRange This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_limit_range_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1LimitRangeList If the method is called asynchronously, returns the request thread.", "response": "def list_limit_range_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind LimitRange\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_limit_range_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1LimitRangeList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_limit_range_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_limit_range_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all the namespaces in the current namespace.", "response": "def list_namespace(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind Namespace\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespace(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1NamespaceList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespace_with_http_info(**kwargs)\n        else:\n            (data) = self.list_namespace_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_namespaced_config_map(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_config_map_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_config_map_with_http_info(namespace, **kwargs)\n            return data", "response": "List all the config objects in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_namespaced_event(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_event_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_event_with_http_info(namespace, **kwargs)\n            return data", "response": "List all events in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all the objects in the specified namespace that are in the specified limit range.", "response": "def list_namespaced_limit_range(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind LimitRange\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_limit_range(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1LimitRangeList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_limit_range_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_limit_range_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_namespaced_persistent_volume_claim(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_persistent_volume_claim_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_persistent_volume_claim_with_http_info(namespace, **kwargs)\n            return data", "response": "List persistent volume claim objects of kind PersistentVolumeClaim"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the objects in the specified namespace.", "response": "def list_namespaced_pod(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_pod(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1PodList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_pod_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_pod_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_namespaced_pod_template(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_pod_template_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_pod_template_with_http_info(namespace, **kwargs)\n            return data", "response": "List all pods in a namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist replication controllers with the specified namespace.", "response": "def list_namespaced_replication_controller(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind ReplicationController\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_replication_controller(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ReplicationControllerList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_replication_controller_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_replication_controller_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_namespaced_resource_quota(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_resource_quota_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_resource_quota_with_http_info(namespace, **kwargs)\n            return data", "response": "List all the resource versions of a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all secrets in the specified namespace.", "response": "def list_namespaced_secret(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind Secret\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_secret(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1SecretList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_secret_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_secret_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_namespaced_service(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_service_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_service_with_http_info(namespace, **kwargs)\n            return data", "response": "List the objects in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all the objects in the specified namespace.", "response": "def list_namespaced_service_account(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind ServiceAccount\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_service_account(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ServiceAccountList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_service_account_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_service_account_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_node(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_node_with_http_info(**kwargs)\n        else:\n            (data) = self.list_node_with_http_info(**kwargs)\n            return data", "response": "List nodes of kind NodeTTS"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_persistent_volume(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_persistent_volume_with_http_info(**kwargs)\n        else:\n            (data) = self.list_persistent_volume_with_http_info(**kwargs)\n            return data", "response": "List persistent volumes of kind PersistentVolume"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_persistent_volume_claim_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_persistent_volume_claim_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_persistent_volume_claim_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of persistent volume claim objects of kind PersistentVolumeClaim by all namespaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist all namespaces of a pod.", "response": "def list_pod_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind Pod\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_pod_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1PodList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_pod_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_pod_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_pod_template_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_pod_template_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_pod_template_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "List all namespaces of a pod template"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_replication_controller_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_replication_controller_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_replication_controller_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of replication controllers for all namespaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_resource_quota_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_resource_quota_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_resource_quota_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of all namespaces in the current namespace."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_secret_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_secret_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_secret_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of secrets for all namespaces in the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists or watch objects of kind ServiceAccount This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_service_account_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1ServiceAccountList If the method is called asynchronously, returns the request thread.", "response": "def list_service_account_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind ServiceAccount\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_service_account_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ServiceAccountList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_service_account_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_service_account_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all namespaces of a service.", "response": "def list_service_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind Service\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_service_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ServiceList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_service_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_service_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch_namespace(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespace_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_namespace_with_http_info(name, body, **kwargs)\n            return data", "response": "Partially update the specified Namespace"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef patch_namespace_status(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespace_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_namespace_status_with_http_info(name, body, **kwargs)\n            return data", "response": "Partially update the status of a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_namespaced_config_map(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_config_map_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_config_map_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Patch the specified ConfigMap with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_namespaced_endpoints(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_endpoints_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_endpoints_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Partially update the specified Endpoints with the given body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the status of the specified PersistentVolumeClaim with optional filtering.", "response": "def read_namespaced_persistent_volume_claim_status(self, name, namespace, **kwargs):\n        \"\"\"\n        read status of the specified PersistentVolumeClaim\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_persistent_volume_claim_status(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PersistentVolumeClaim (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1PersistentVolumeClaim\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_persistent_volume_claim_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_persistent_volume_claim_status_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_namespaced_pod_template(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_pod_template_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_pod_template_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Read a pod template with the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the specified ResourceQuota from the specified namespace.", "response": "def read_namespaced_resource_quota(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified ResourceQuota\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_resource_quota(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ResourceQuota (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1ResourceQuota\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_resource_quota_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_resource_quota_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_namespaced_service_account(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_service_account_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_service_account_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Read the specified ServiceAccount in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_persistent_volume(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_persistent_volume_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_persistent_volume_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified persistent volume."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace status of the specified Namespace This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.replace_namespace_status(name, body, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the Namespace (required) :param V1Namespace body: (required) :param str pretty: If 'true', then the output is pretty printed. :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. :return: V1Namespace If the method is called asynchronously, returns the request thread.", "response": "def replace_namespace_status(self, name, body, **kwargs):\n        \"\"\"\n        replace status of the specified Namespace\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespace_status(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Namespace (required)\n        :param V1Namespace body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Namespace\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespace_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_namespace_status_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_namespaced_limit_range(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_limit_range_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_limit_range_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified LimitRange with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_namespaced_pod_status(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_pod_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_pod_status_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the status of a pod with a new status."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace the status of the specified ReplicationController with the specified body.", "response": "def replace_namespaced_replication_controller_status(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace status of the specified ReplicationController\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_replication_controller_status(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ReplicationController (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1ReplicationController body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1ReplicationController\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_replication_controller_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_replication_controller_status_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing the specified Service with the specified body.", "response": "def replace_namespaced_service(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace the specified Service\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_service(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Service (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1Service body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Service\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_service_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_service_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the status of a node in the specified NodeVersion.", "response": "def replace_node_status(self, name, body, **kwargs):\n        \"\"\"\n        replace status of the specified Node\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_node_status(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Node (required)\n        :param V1Node body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Node\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_node_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_node_status_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the raw of this RuntimeRawExtension.", "response": "def raw(self, raw):\n        \"\"\"\n        Sets the raw of this RuntimeRawExtension.\n        Raw is the underlying serialization of this object.\n\n        :param raw: The raw of this RuntimeRawExtension.\n        :type: str\n        \"\"\"\n        if raw is None:\n            raise ValueError(\"Invalid value for `raw`, must not be `None`\")\n        if raw is not None and not re.search('^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$', raw):\n            raise ValueError(\"Invalid value for `raw`, must be a follow pattern or equal to `/^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$/`\")\n\n        self._raw = raw"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating thread pool on first request avoids instantiating unused threadpool for blocking clients.", "response": "def pool(self):\n        \"\"\"Create thread pool on first request\n         avoids instantiating unused threadpool for blocking clients.\n        \"\"\"\n        if self._pool is None:\n            self._pool = ThreadPool(self.pool_threads)\n        return self._pool"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sanitize_for_serialization(self, obj):\n        if obj is None:\n            return None\n        elif isinstance(obj, self.PRIMITIVE_TYPES):\n            return obj\n        elif isinstance(obj, list):\n            return [self.sanitize_for_serialization(sub_obj)\n                    for sub_obj in obj]\n        elif isinstance(obj, tuple):\n            return tuple(self.sanitize_for_serialization(sub_obj)\n                         for sub_obj in obj)\n        elif isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n\n        if isinstance(obj, dict):\n            obj_dict = obj\n        else:\n            # Convert model obj to dict except\n            # attributes `swagger_types`, `attribute_map`\n            # and attributes which value is not None.\n            # Convert attribute name to json key in\n            # model definition for request.\n            obj_dict = {obj.attribute_map[attr]: getattr(obj, attr)\n                        for attr, _ in iteritems(obj.swagger_types)\n                        if getattr(obj, attr) is not None}\n\n        return {key: self.sanitize_for_serialization(val)\n                for key, val in iteritems(obj_dict)}", "response": "Sanitize the data in the object for serialization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_header_accept(self, accepts):\n        if not accepts:\n            return\n\n        accepts = [x.lower() for x in accepts]\n\n        if 'application/json' in accepts:\n            return 'application/json'\n        else:\n            return ', '.join(accepts)", "response": "Select the Accept header based on an array of accepts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect the content - type based on an array of content - types provided.", "response": "def select_header_content_type(self, content_types):\n        \"\"\"\n        Returns `Content-Type` based on an array of content_types provided.\n\n        :param content_types: List of content-types.\n        :return: Content-Type (e.g. application/json).\n        \"\"\"\n        if not content_types:\n            return 'application/json'\n\n        content_types = [x.lower() for x in content_types]\n\n        if 'application/json' in content_types or '*/*' in content_types:\n            return 'application/json'\n        else:\n            return content_types[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_params_for_auth(self, headers, querys, auth_settings):\n        if not auth_settings:\n            return\n\n        for auth in auth_settings:\n            auth_setting = self.configuration.auth_settings().get(auth)\n            if auth_setting:\n                if not auth_setting['value']:\n                    continue\n                elif auth_setting['in'] == 'header':\n                    headers[auth_setting['key']] = auth_setting['value']\n                elif auth_setting['in'] == 'query':\n                    querys.append((auth_setting['key'], auth_setting['value']))\n                else:\n                    raise ValueError(\n                        'Authentication token must be in `query` or `header`'\n                    )", "response": "Updates header and query params based on authentication settings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef debug(self, value):\n        self.__debug = value\n        if self.__debug:\n            # if debug status is True, turn on debug logging\n            for _, logger in iteritems(self.logger):\n                logger.setLevel(logging.DEBUG)\n            # turn on httplib debug\n            httplib.HTTPConnection.debuglevel = 1\n        else:\n            # if debug status is False, turn off debug logging,\n            # setting log level to default `logging.WARNING`\n            for _, logger in iteritems(self.logger):\n                logger.setLevel(logging.WARNING)\n            # turn off httplib debug\n            httplib.HTTPConnection.debuglevel = 0", "response": "Sets the debug status of the HTTP connection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logger_format(self, value):\n        self.__logger_format = value\n        self.logger_formatter = logging.Formatter(self.__logger_format)", "response": "Sets the logger_format.\n\n        The logger_formatter will be updated when sets logger_format.\n\n        :param value: The format string.\n        :type: str"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets API key with prefix if set.", "response": "def get_api_key_with_prefix(self, identifier):\n        \"\"\"\n        Gets API key (with prefix if set).\n\n        :param identifier: The identifier of apiKey.\n        :return: The token for api key authentication.\n        \"\"\"\n        if self.api_key.get(identifier) and self.api_key_prefix.get(identifier):\n            return self.api_key_prefix[identifier] + ' ' + self.api_key[identifier]\n        elif self.api_key.get(identifier):\n            return self.api_key[identifier]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the HTTP basic authentication header.", "response": "def get_basic_auth_token(self):\n        \"\"\"\n        Gets HTTP basic authentication header (string).\n\n        :return: The token for basic HTTP authentication.\n        \"\"\"\n        return urllib3.util.make_headers(basic_auth=self.username + ':' + self.password)\\\n                           .get('authorization')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a Lease in the specified namespace.", "response": "def create_namespaced_lease(self, namespace, body, **kwargs):\n        \"\"\"\n        create a Lease\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_lease(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1Lease body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Lease\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_lease_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_lease_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes collection of Lease This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_namespaced_lease(namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_namespaced_lease(self, namespace, **kwargs):\n        \"\"\"\n        delete collection of Lease\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_namespaced_lease(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_lease_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_lease_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_namespaced_lease(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_lease_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_lease_with_http_info(namespace, **kwargs)\n            return data", "response": "List all lease objects in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_namespaced_lease(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_lease_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_lease_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Partially updates the specified Lease with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_audit_sink(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_audit_sink_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_audit_sink_with_http_info(body, **kwargs)\n            return data", "response": "create an AuditSink\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_audit_sink(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1alpha1AuditSink body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1alpha1AuditSink\n                 If the method is called asynchronously,\n                 returns the request thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_audit_sink(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_audit_sink_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_audit_sink_with_http_info(name, **kwargs)\n            return data", "response": "Delete an AuditSink by name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting or watch objects of kind AuditSink This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_audit_sink(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1alpha1AuditSinkList If the method is called asynchronously, returns the request thread.", "response": "def list_audit_sink(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind AuditSink\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_audit_sink(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1alpha1AuditSinkList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_audit_sink_with_http_info(**kwargs)\n        else:\n            (data) = self.list_audit_sink_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patch_audit_sink(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_audit_sink_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_audit_sink_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the audit sink with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_audit_sink(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_audit_sink_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_audit_sink_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified AuditSink. This method is idempotent and will return the response thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_audit_sink(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_audit_sink_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_audit_sink_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified AuditSink with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information of a group by its unique identifier.", "response": "def get_api_group(self, **kwargs):\n        \"\"\"\n        get information of a group\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.get_api_group(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :return: V1APIGroup\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.get_api_group_with_http_info(**kwargs)\n        else:\n            (data) = self.get_api_group_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the certificate of this V1beta1CertificateSigningRequestStatus.", "response": "def certificate(self, certificate):\n        \"\"\"\n        Sets the certificate of this V1beta1CertificateSigningRequestStatus.\n        If request was approved, the controller will place the issued certificate here.\n\n        :param certificate: The certificate of this V1beta1CertificateSigningRequestStatus.\n        :type: str\n        \"\"\"\n        if certificate is not None and not re.search('^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$', certificate):\n            raise ValueError(\"Invalid value for `certificate`, must be a follow pattern or equal to `/^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$/`\")\n\n        self._certificate = certificate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a ClusterRole This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.create_cluster_role(body, async_req=True) >>> result = thread.get() :param async_req bool :param V1ClusterRole body: (required) :param str pretty: If 'true', then the output is pretty printed. :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. :return: V1ClusterRole If the method is called asynchronously, returns the request thread.", "response": "def create_cluster_role(self, body, **kwargs):\n        \"\"\"\n        create a ClusterRole\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_cluster_role(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1ClusterRole body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1ClusterRole\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_cluster_role_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_cluster_role_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new role in the specified namespace.", "response": "def create_namespaced_role(self, namespace, body, **kwargs):\n        \"\"\"\n        create a Role\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_role(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1Role body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1Role\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_role_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_role_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new role binding with the specified namespace and body.", "response": "def create_namespaced_role_binding(self, namespace, body, **kwargs):\n        \"\"\"\n        create a RoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_role_binding(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1RoleBinding body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1RoleBinding\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_role_binding_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_role_binding_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_cluster_role(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_cluster_role_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_cluster_role_with_http_info(name, **kwargs)\n            return data", "response": "Delete a ClusterRole by name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting collection of ClusterRole This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_cluster_role(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_cluster_role(self, **kwargs):\n        \"\"\"\n        delete collection of ClusterRole\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_cluster_role(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_cluster_role_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_cluster_role_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_collection_cluster_role_binding(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_cluster_role_binding_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_cluster_role_binding_with_http_info(**kwargs)\n            return data", "response": "This method deletes a cluster role binding from the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_collection_namespaced_role(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_role_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_role_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes a collection of roles from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_namespaced_role(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_role_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_role_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Delete a namespaced role in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a RoleBinding This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_namespaced_role_binding(name, namespace, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the RoleBinding (required) :param str namespace: object name and auth scope, such as for teams and projects (required) :param str pretty: If 'true', then the output is pretty printed. :param V1DeleteOptions body: :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately. :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both. :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_namespaced_role_binding(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a RoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_role_binding(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the RoleBinding (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_role_binding_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_role_binding_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist cluster role objects", "response": "def list_cluster_role(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind ClusterRole\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_cluster_role(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ClusterRoleList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_cluster_role_with_http_info(**kwargs)\n        else:\n            (data) = self.list_cluster_role_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting the objects in the specified namespace.", "response": "def list_namespaced_role(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind Role\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_role(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1RoleList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_role_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_role_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all objects of kind RoleBinding in the specified namespace.", "response": "def list_namespaced_role_binding(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind RoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_role_binding(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1RoleBindingList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_role_binding_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_role_binding_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists or watch objects of kind RoleBinding This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_role_binding_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1RoleBindingList If the method is called asynchronously, returns the request thread.", "response": "def list_role_binding_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind RoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_role_binding_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1RoleBindingList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_role_binding_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_role_binding_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch a cluster role.", "response": "def patch_cluster_role(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified ClusterRole\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_cluster_role(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ClusterRole (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1ClusterRole\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_cluster_role_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_cluster_role_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npatching a ClusterRoleBinding with the given body.", "response": "def patch_cluster_role_binding(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified ClusterRoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_cluster_role_binding(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ClusterRoleBinding (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1ClusterRoleBinding\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_cluster_role_binding_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_cluster_role_binding_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_cluster_role(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_cluster_role_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_cluster_role_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified ClusterRole"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_cluster_role_binding(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_cluster_role_binding_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_cluster_role_binding_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified ClusterRoleBinding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the specified Role from the specified namespace", "response": "def read_namespaced_role(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified Role\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_role(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Role (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1Role\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_role_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_role_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_cluster_role(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_cluster_role_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_cluster_role_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified ClusterRole with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces the specified ClusterRoleBinding with the specified body.", "response": "def replace_cluster_role_binding(self, name, body, **kwargs):\n        \"\"\"\n        replace the specified ClusterRoleBinding\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_cluster_role_binding(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ClusterRoleBinding (required)\n        :param V1ClusterRoleBinding body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1ClusterRoleBinding\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_cluster_role_binding_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_cluster_role_binding_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_namespaced_role(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_role_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_role_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified Role with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange labels of the minikube node", "response": "def main():\n    \"\"\"\n    Change labels of the \"minikube\" node:\n     - Add label \"foo\" with value \"bar\". This will overwrite the \"foo\" label\n       if it already exists.\n     - Remove the label \"baz\" from the node.\n    \"\"\"\n\n    config.load_kube_config()\n\n    api_instance = client.CoreV1Api()\n\n    body = {\n        \"metadata\": {\n            \"labels\": {\n                \"foo\": \"bar\",\n                \"baz\": None}\n        }\n    }\n\n    api_response = api_instance.patch_node(\"minikube\", body)\n\n    pprint(api_response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_namespaced_daemon_set(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_daemon_set_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_daemon_set_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a daemon set with the specified namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_collection_namespaced_controller_revision(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_controller_revision_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_controller_revision_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes the specified controller revision from the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_collection_namespaced_daemon_set(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_daemon_set_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_daemon_set_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes the set of daemon sets with the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_collection_namespaced_deployment(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_deployment_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_deployment_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes all objects in the specified namespace from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_namespaced_stateful_set(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_stateful_set_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_stateful_set_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Delete a namespace named with optional namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists or watch objects of kind DaemonSet This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_daemon_set_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1DaemonSetList If the method is called asynchronously, returns the request thread.", "response": "def list_daemon_set_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind DaemonSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_daemon_set_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1DaemonSetList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_daemon_set_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_daemon_set_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all deployment entries for all namespaces", "response": "def list_deployment_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind Deployment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_deployment_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1DeploymentList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_deployment_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_deployment_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all the objects in the specified namespace that are in the given namespace.", "response": "def list_namespaced_controller_revision(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind ControllerRevision\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_controller_revision(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ControllerRevisionList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_controller_revision_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_controller_revision_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_namespaced_deployment(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_deployment_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_deployment_with_http_info(namespace, **kwargs)\n            return data", "response": "List all deployments in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist replica sets of kind ReplicaSet", "response": "def list_namespaced_replica_set(self, namespace, **kwargs):\n        \"\"\"\n        list or watch objects of kind ReplicaSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_replica_set(namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1ReplicaSetList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_replica_set_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.list_namespaced_replica_set_with_http_info(namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_stateful_set_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_stateful_set_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_stateful_set_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of StatefulSet objects that are all namespaces of the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_namespaced_deployment(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_deployment_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_deployment_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Partially updates the specified Deployment with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npatch the properties of a ReplicaSet with the given body.", "response": "def patch_namespaced_replica_set_scale(self, name, namespace, body, **kwargs):\n        \"\"\"\n        partially update scale of the specified ReplicaSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_namespaced_replica_set_scale(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Scale (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1Scale\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_replica_set_scale_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_replica_set_scale_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef patch_namespaced_stateful_set_status(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_stateful_set_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_stateful_set_status_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Patch the status of a stateful set with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the specified DaemonSet with the specified namespace.", "response": "def read_namespaced_daemon_set(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified DaemonSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_daemon_set(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the DaemonSet (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1DaemonSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_daemon_set_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_daemon_set_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_namespaced_daemon_set_status(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_daemon_set_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_daemon_set_status_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Read the status of the specified DaemonSet with optional HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the specified Deployment with the specified namespace", "response": "def read_namespaced_deployment(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified Deployment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_deployment(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Deployment (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1Deployment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_deployment_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_deployment_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_namespaced_deployment_scale(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_deployment_scale_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_deployment_scale_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Read the named Deployment\n clf and return it as V1Scale\n                "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the status of the specified Deployment with the specified namespace.", "response": "def read_namespaced_deployment_status(self, name, namespace, **kwargs):\n        \"\"\"\n        read status of the specified Deployment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_deployment_status(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Deployment (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1Deployment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_deployment_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_deployment_status_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the named ReplicaSet with the specified namespace.", "response": "def read_namespaced_replica_set_scale(self, name, namespace, **kwargs):\n        \"\"\"\n        read scale of the specified ReplicaSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_replica_set_scale(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the Scale (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1Scale\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_replica_set_scale_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_replica_set_scale_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the status of the specified StatefulSet and namespace.", "response": "def read_namespaced_stateful_set_status(self, name, namespace, **kwargs):\n        \"\"\"\n        read status of the specified StatefulSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_stateful_set_status(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the StatefulSet (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1StatefulSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_stateful_set_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_stateful_set_status_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_namespaced_daemon_set(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_daemon_set_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_daemon_set_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified DaemonSet with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_namespaced_deployment(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_deployment_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_deployment_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified Deployment with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_namespaced_deployment_scale(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_deployment_scale_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_deployment_scale_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the named Deployment with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_namespaced_deployment_status(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_deployment_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_deployment_status_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the status of the specified Deployment with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace the specified ReplicaSet with the specified body.", "response": "def replace_namespaced_replica_set(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace the specified ReplicaSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_replica_set(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ReplicaSet (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1ReplicaSet body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1ReplicaSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_replica_set_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_replica_set_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_namespaced_replica_set_scale(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_replica_set_scale_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_replica_set_scale_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the named ReplicaSet with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_namespaced_replica_set_status(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_replica_set_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_replica_set_status_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the status of the specified ReplicaSet with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace the status of a stateful set with a new status.", "response": "def replace_namespaced_stateful_set_status(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace status of the specified StatefulSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_stateful_set_status(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the StatefulSet (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1StatefulSet body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1StatefulSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_stateful_set_status_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_stateful_set_status_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a NetworkPolicy with the specified namespace and body.", "response": "def create_namespaced_network_policy(self, namespace, body, **kwargs):\n        \"\"\"\n        create a NetworkPolicy\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_namespaced_network_policy(namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1beta1NetworkPolicy body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1NetworkPolicy\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_network_policy_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_network_policy_with_http_info(namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a PodSecurityPolicy with the given body.", "response": "def create_pod_security_policy(self, body, **kwargs):\n        \"\"\"\n        create a PodSecurityPolicy\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_pod_security_policy(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param ExtensionsV1beta1PodSecurityPolicy body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: ExtensionsV1beta1PodSecurityPolicy\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_pod_security_policy_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_pod_security_policy_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_collection_pod_security_policy(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_pod_security_policy_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_pod_security_policy_with_http_info(**kwargs)\n            return data", "response": "This method deletes a set of PodSecurityPolicy items from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a NetworkPolicy with the specified name and namespace.", "response": "def delete_namespaced_network_policy(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a NetworkPolicy\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_network_policy(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NetworkPolicy (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_network_policy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_network_policy_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_pod_security_policy(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_pod_security_policy_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_pod_security_policy_with_http_info(name, **kwargs)\n            return data", "response": "Delete a PodSecurityPolicy by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_network_policy_for_all_namespaces(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_network_policy_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_network_policy_for_all_namespaces_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of NetworkPolicy objects that are all namespaces of the specified network namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_pod_security_policy(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_pod_security_policy_with_http_info(**kwargs)\n        else:\n            (data) = self.list_pod_security_policy_with_http_info(**kwargs)\n            return data", "response": "List PodSecurityPolicy objects of kind PodSecurityPolicy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_namespaced_network_policy(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_network_policy_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_network_policy_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Patch the specified NetworkPolicy with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the specified NetworkPolicy with the specified namespace.", "response": "def read_namespaced_network_policy(self, name, namespace, **kwargs):\n        \"\"\"\n        read the specified NetworkPolicy\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_network_policy(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NetworkPolicy (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1beta1NetworkPolicy\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_network_policy_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_network_policy_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces the specified NetworkPolicy with the specified body.", "response": "def replace_namespaced_network_policy(self, name, namespace, body, **kwargs):\n        \"\"\"\n        replace the specified NetworkPolicy\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_namespaced_network_policy(name, namespace, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the NetworkPolicy (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param V1beta1NetworkPolicy body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1NetworkPolicy\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_network_policy_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_network_policy_with_http_info(name, namespace, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_namespaced_replication_controller_dummy_scale(self, name, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_replication_controller_dummy_scale_with_http_info(name, namespace, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_replication_controller_dummy_scale_with_http_info(name, namespace, body, **kwargs)\n            return data", "response": "Replace the specified ReplicationControllerDummy with a new one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a TokenReview This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.create_token_review(body, async_req=True) >>> result = thread.get() :param async_req bool :param V1beta1TokenReview body: (required) :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. :param str pretty: If 'true', then the output is pretty printed. :return: V1beta1TokenReview If the method is called asynchronously, returns the request thread.", "response": "def create_token_review(self, body, **kwargs):\n        \"\"\"\n        create a TokenReview\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_token_review(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1TokenReview body: (required)\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1beta1TokenReview\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_token_review_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_token_review_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting collection of VolumeAttachment This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_volume_attachment(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_volume_attachment(self, **kwargs):\n        \"\"\"\n        delete collection of VolumeAttachment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_volume_attachment(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_volume_attachment_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_volume_attachment_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_storage_class(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_storage_class_with_http_info(**kwargs)\n        else:\n            (data) = self.list_storage_class_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of objects of kind StorageClass by kind."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist volume attachments of kind VolumeAttachment", "response": "def list_volume_attachment(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind VolumeAttachment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_volume_attachment(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1VolumeAttachmentList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_volume_attachment_with_http_info(**kwargs)\n        else:\n            (data) = self.list_volume_attachment_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch_volume_attachment_status(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_volume_attachment_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_volume_attachment_status_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the status of a specific volume attachment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the specified StorageClass from the specified Cluster.", "response": "def read_storage_class(self, name, **kwargs):\n        \"\"\"\n        read the specified StorageClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_storage_class(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the StorageClass (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1StorageClass\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_storage_class_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_storage_class_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_storage_class(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_storage_class_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_storage_class_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified StorageClass with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_volume_attachment(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_volume_attachment_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_volume_attachment_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified VolumeAttachment with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_runtime_class(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_runtime_class_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_runtime_class_with_http_info(body, **kwargs)\n            return data", "response": "Create a RuntimeClassV1beta1 object. This method is used to create a RuntimeClassV1beta1 object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_collection_runtime_class(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_runtime_class_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_runtime_class_with_http_info(**kwargs)\n            return data", "response": "This method deletes the specified runtime class from the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_runtime_class(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_runtime_class_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_runtime_class_with_http_info(name, **kwargs)\n            return data", "response": "Delete a RuntimeClass by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_runtime_class(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_runtime_class_with_http_info(**kwargs)\n        else:\n            (data) = self.list_runtime_class_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of objects of kind RuntimeClass\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef patch_runtime_class(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_runtime_class_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_runtime_class_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the RuntimeClass with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_runtime_class(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_runtime_class_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_runtime_class_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified RuntimeClass from the specified Cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_runtime_class(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_runtime_class_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_runtime_class_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified RuntimeClass with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_csi_driver(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_csi_driver_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_csi_driver_with_http_info(body, **kwargs)\n            return data", "response": "Create a CSIDriver with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a CSINode with the given body.", "response": "def create_csi_node(self, body, **kwargs):\n        \"\"\"\n        create a CSINode\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_csi_node(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1CSINode body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1CSINode\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_csi_node_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_csi_node_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete collection of CSIDriver This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_csi_driver(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_csi_driver(self, **kwargs):\n        \"\"\"\n        delete collection of CSIDriver\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_csi_driver(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_csi_driver_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_csi_driver_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes collection of CSINode This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_csi_node(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_csi_node(self, **kwargs):\n        \"\"\"\n        delete collection of CSINode\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_csi_node(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_csi_node_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_csi_node_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a CSIDriver by name.", "response": "def delete_csi_driver(self, name, **kwargs):\n        \"\"\"\n        delete a CSIDriver\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_csi_driver(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CSIDriver (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_csi_driver_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_csi_driver_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a CSINode by name", "response": "def delete_csi_node(self, name, **kwargs):\n        \"\"\"\n        delete a CSINode\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_csi_node(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CSINode (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_csi_node_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_csi_node_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_csi_driver(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_csi_driver_with_http_info(**kwargs)\n        else:\n            (data) = self.list_csi_driver_with_http_info(**kwargs)\n            return data", "response": "List all CSIDriver objects of kind CSIDriverONE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_csi_node(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_csi_node_with_http_info(**kwargs)\n        else:\n            (data) = self.list_csi_node_with_http_info(**kwargs)\n            return data", "response": "List CSNodes of kind CSINode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npatching the specified CSIDriver with the given body.", "response": "def patch_csi_driver(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified CSIDriver\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_csi_driver(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CSIDriver (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1beta1CSIDriver\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_csi_driver_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_csi_driver_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npatches a CSINode with the given body.", "response": "def patch_csi_node(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified CSINode\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_csi_node(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CSINode (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1beta1CSINode\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_csi_node_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_csi_node_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_csi_driver(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_csi_driver_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_csi_driver_with_http_info(name, **kwargs)\n            return data", "response": "Read the specified CSIDriver and return the corresponding V1beta1CSIDriver object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_csi_node(self, name, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_csi_node_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_csi_node_with_http_info(name, **kwargs)\n            return data", "response": "Read a CSINode with the specified name and return the corresponding CSINode object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_csi_driver(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_csi_driver_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_csi_driver_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified CSIDriver with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_csi_node(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_csi_node_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_csi_node_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified CSINode with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_yaml(\n        k8s_client,\n        yaml_file,\n        verbose=False,\n        **kwargs):\n    \"\"\"\n    Perform an action from a yaml file. Pass True for verbose to\n    print confirmation information.\n    Input:\n    yaml_file: string. Contains the path to yaml file.\n    k8s_client: an ApiClient object, initialized with the client args.\n    verbose: If True, print confirmation from the create action.\n        Default is False.\n\n    Returns:\n    An k8s api object or list of apis objects created from YAML.\n    When a single object is generated, return type is dependent\n    on output_list.\n\n    Throws a FailToCreateError exception if creation of any object\n    fails with helpful messages from the server.\n\n    Available parameters for creating <kind>:\n    :param async_req bool\n    :param bool include_uninitialized: If true, partially initialized\n        resources are included in the response.\n    :param str pretty: If 'true', then the output is pretty printed.\n    :param str dry_run: When present, indicates that modifications\n        should not be persisted. An invalid or unrecognized dryRun\n        directive will result in an error response and no further\n        processing of the request.\n        Valid values are: - All: all dry run stages will be processed\n    \"\"\"\n\n    with open(path.abspath(yaml_file)) as f:\n        yml_document_all = yaml.safe_load_all(f)\n        api_exceptions = []\n        # Load all documents from a single YAML file\n        for yml_document in yml_document_all:\n            # If it is a list type, will need to iterate its items\n            if \"List\" in yml_document[\"kind\"]:\n                # Could be \"List\" or \"Pod/Service/...List\"\n                # This is a list type. iterate within its items\n                kind = yml_document[\"kind\"].replace(\"List\", \"\")\n                for yml_object in yml_document[\"items\"]:\n                    # Mitigate cases when server returns a xxxList object\n                    # See kubernetes-client/python#586\n                    if kind is not \"\":\n                        yml_object[\"apiVersion\"] = yml_document[\"apiVersion\"]\n                        yml_object[\"kind\"] = kind\n                    try:\n                        create_from_yaml_single_item(\n                            k8s_client, yml_object, verbose, **kwargs)\n                    except client.rest.ApiException as api_exception:\n                        api_exceptions.append(api_exception)\n            else:\n                # This is a single object. Call the single item method\n                try:\n                    create_from_yaml_single_item(\n                        k8s_client, yml_document, verbose, **kwargs)\n                except client.rest.ApiException as api_exception:\n                    api_exceptions.append(api_exception)\n    # In case we have exceptions waiting for us, raise them\n    if api_exceptions:\n        raise FailToCreateError(api_exceptions)", "response": "Create a k8s api object from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_namespaced_local_subject_access_review(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_local_subject_access_review_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_local_subject_access_review_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a LocalSubjectAccessReview with the given namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a SelfSubjectRulesReview of a specific resource.", "response": "def create_self_subject_rules_review(self, body, **kwargs):\n        \"\"\"\n        create a SelfSubjectRulesReview\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_self_subject_rules_review(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1SelfSubjectRulesReview body: (required)\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1SelfSubjectRulesReview\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_self_subject_rules_review_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_self_subject_rules_review_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_subject_access_review(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_subject_access_review_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_subject_access_review_with_http_info(body, **kwargs)\n            return data", "response": "Create a SubjectAccessReview using the provided body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_priority_class(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_priority_class_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_priority_class_with_http_info(body, **kwargs)\n            return data", "response": "create a PriorityClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_priority_class(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1PriorityClass body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1PriorityClass\n                 If the method is called asynchronously,\n                 returns the request thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_collection_priority_class(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_priority_class_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_priority_class_with_http_info(**kwargs)\n            return data", "response": "This method deletes a priority class from the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a priority class.", "response": "def delete_priority_class(self, name, **kwargs):\n        \"\"\"\n        delete a PriorityClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_priority_class(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PriorityClass (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_priority_class_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_priority_class_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_priority_class(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_priority_class_with_http_info(**kwargs)\n        else:\n            (data) = self.list_priority_class_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of priority class objects of kind PriorityClass."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch a priority class.", "response": "def patch_priority_class(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified PriorityClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_priority_class(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PriorityClass (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1PriorityClass\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_priority_class_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_priority_class_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a specific PriorityClass from the specified Cluster.", "response": "def read_priority_class(self, name, **kwargs):\n        \"\"\"\n        read the specified PriorityClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_priority_class(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PriorityClass (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1PriorityClass\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_priority_class_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_priority_class_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an API Service by name", "response": "def delete_api_service(self, name, **kwargs):\n        \"\"\"\n        delete an APIService\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_api_service(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the APIService (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_api_service_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_api_service_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_collection_api_service(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_api_service_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_api_service_with_http_info(**kwargs)\n            return data", "response": "This method deletes the specified APIService from the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_api_service_status(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_api_service_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_api_service_status_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace status of the specified APIService with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the request of this V1beta1CertificateSigningRequestSpec.", "response": "def request(self, request):\n        \"\"\"\n        Sets the request of this V1beta1CertificateSigningRequestSpec.\n        Base64-encoded PKCS#10 CSR data\n\n        :param request: The request of this V1beta1CertificateSigningRequestSpec.\n        :type: str\n        \"\"\"\n        if request is None:\n            raise ValueError(\"Invalid value for `request`, must not be `None`\")\n        if request is not None and not re.search('^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$', request):\n            raise ValueError(\"Invalid value for `request`, must be a follow pattern or equal to `/^(?:[A-Za-z0-9+\\/]{4})*(?:[A-Za-z0-9+\\/]{2}==|[A-Za-z0-9+\\/]{3}=)?$/`\")\n\n        self._request = request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, method, url, query_params=None, headers=None,\n                body=None, post_params=None, _preload_content=True, _request_timeout=None):\n        \"\"\"\n        :param method: http request method\n        :param url: http request url\n        :param query_params: query parameters in the url\n        :param headers: http request headers\n        :param body: request json body, for `application/json`\n        :param post_params: request post parameters,\n                            `application/x-www-form-urlencoded`\n                            and `multipart/form-data`\n        :param _preload_content: if False, the urllib3.HTTPResponse object will be returned without\n                                 reading/decoding response data. Default is True.\n        :param _request_timeout: timeout setting for this request. If one number provided, it will be total request\n                                 timeout. It can also be a pair (tuple) of (connection, read) timeouts.\n        \"\"\"\n        method = method.upper()\n        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS']\n\n        if post_params and body:\n            raise ValueError(\n                \"body parameter cannot be used with post_params parameter.\"\n            )\n\n        post_params = post_params or {}\n        headers = headers or {}\n\n        timeout = None\n        if _request_timeout:\n            if isinstance(_request_timeout, (int, ) if PY3 else (int, long)):\n                timeout = urllib3.Timeout(total=_request_timeout)\n            elif isinstance(_request_timeout, tuple) and len(_request_timeout) == 2:\n                timeout = urllib3.Timeout(connect=_request_timeout[0], read=_request_timeout[1])\n\n        if 'Content-Type' not in headers:\n            headers['Content-Type'] = 'application/json'\n\n        try:\n            # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`\n            if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:\n                if query_params:\n                    url += '?' + urlencode(query_params)\n                if re.search('json', headers['Content-Type'], re.IGNORECASE):\n                    if headers['Content-Type'] == 'application/json-patch+json':\n                        if not isinstance(body, list):\n                            headers['Content-Type'] = \\\n                                'application/strategic-merge-patch+json'\n                    request_body = None\n                    if body is not None:\n                        request_body = json.dumps(body)\n                    r = self.pool_manager.request(method, url,\n                                                  body=request_body,\n                                                  preload_content=_preload_content,\n                                                  timeout=timeout,\n                                                  headers=headers)\n                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':\n                    r = self.pool_manager.request(method, url,\n                                                  fields=post_params,\n                                                  encode_multipart=False,\n                                                  preload_content=_preload_content,\n                                                  timeout=timeout,\n                                                  headers=headers)\n                elif headers['Content-Type'] == 'multipart/form-data':\n                    # must del headers['Content-Type'], or the correct Content-Type\n                    # which generated by urllib3 will be overwritten.\n                    del headers['Content-Type']\n                    r = self.pool_manager.request(method, url,\n                                                  fields=post_params,\n                                                  encode_multipart=True,\n                                                  preload_content=_preload_content,\n                                                  timeout=timeout,\n                                                  headers=headers)\n                # Pass a `string` parameter directly in the body to support\n                # other content types than Json when `body` argument is provided\n                # in serialized form\n                elif isinstance(body, str):\n                    request_body = body\n                    r = self.pool_manager.request(method, url,\n                                                  body=request_body,\n                                                  preload_content=_preload_content,\n                                                  timeout=timeout,\n                                                  headers=headers)\n                else:\n                    # Cannot generate the request from given parameters\n                    msg = \"\"\"Cannot prepare a request message for provided arguments.\n                             Please check that your arguments match declared content type.\"\"\"\n                    raise ApiException(status=0, reason=msg)\n            # For `GET`, `HEAD`\n            else:\n                r = self.pool_manager.request(method, url,\n                                              fields=query_params,\n                                              preload_content=_preload_content,\n                                              timeout=timeout,\n                                              headers=headers)\n        except urllib3.exceptions.SSLError as e:\n            msg = \"{0}\\n{1}\".format(type(e).__name__, str(e))\n            raise ApiException(status=0, reason=msg)\n\n        if _preload_content:\n            r = RESTResponse(r)\n\n            # In the python 3, the response.data is bytes.\n            # we need to decode it to string.\n            if PY3:\n                r.data = r.data.decode('utf8')\n\n            # log response body\n            logger.debug(\"response body: %s\", r.data)\n\n        if not 200 <= r.status <= 299:\n            raise ApiException(http_resp=r)\n\n        return r", "response": "This method is used to make a request to the specified url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_mutating_webhook_configuration(self, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_mutating_webhook_configuration_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_mutating_webhook_configuration_with_http_info(body, **kwargs)\n            return data", "response": "create a MutatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_mutating_webhook_configuration(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1MutatingWebhookConfiguration body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1MutatingWebhookConfiguration\n                 If the method is called asynchronously,\n                 returns the request thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ValidatingWebhookConfiguration This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.create_validating_webhook_configuration(body, async_req=True) >>> result = thread.get() :param async_req bool :param V1beta1ValidatingWebhookConfiguration body: (required) :param str pretty: If 'true', then the output is pretty printed. :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. :return: V1beta1ValidatingWebhookConfiguration If the method is called asynchronously, returns the request thread.", "response": "def create_validating_webhook_configuration(self, body, **kwargs):\n        \"\"\"\n        create a ValidatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_validating_webhook_configuration(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1ValidatingWebhookConfiguration body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1ValidatingWebhookConfiguration\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_validating_webhook_configuration_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_validating_webhook_configuration_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete collection of ValidatingWebhookConfiguration This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_collection_validating_webhook_configuration(async_req=True) >>> result = thread.get() :param async_req bool :param str pretty: If 'true', then the output is pretty printed. :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_collection_validating_webhook_configuration(self, **kwargs):\n        \"\"\"\n        delete collection of ValidatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_collection_validating_webhook_configuration(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_validating_webhook_configuration_with_http_info(**kwargs)\n        else:\n            (data) = self.delete_collection_validating_webhook_configuration_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a MutatingWebhookConfiguration by name", "response": "def delete_mutating_webhook_configuration(self, name, **kwargs):\n        \"\"\"\n        delete a MutatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_mutating_webhook_configuration(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the MutatingWebhookConfiguration (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_mutating_webhook_configuration_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_mutating_webhook_configuration_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a ValidatingWebhookConfiguration by name.", "response": "def delete_validating_webhook_configuration(self, name, **kwargs):\n        \"\"\"\n        delete a ValidatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_validating_webhook_configuration(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ValidatingWebhookConfiguration (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_validating_webhook_configuration_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_validating_webhook_configuration_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_validating_webhook_configuration(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_validating_webhook_configuration_with_http_info(**kwargs)\n        else:\n            (data) = self.list_validating_webhook_configuration_with_http_info(**kwargs)\n            return data", "response": "This method returns a list of ValidatingWebhookConfiguration objects"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_mutating_webhook_configuration(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_mutating_webhook_configuration_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_mutating_webhook_configuration_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the MutatingWebhookConfiguration with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch_validating_webhook_configuration(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_validating_webhook_configuration_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_validating_webhook_configuration_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the ValidatingWebhookConfiguration with the given body."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the specified ValidatingWebhookConfiguration", "response": "def read_validating_webhook_configuration(self, name, **kwargs):\n        \"\"\"\n        read the specified ValidatingWebhookConfiguration\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_validating_webhook_configuration(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the ValidatingWebhookConfiguration (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param bool exact: Should the export be exact.  Exact export maintains cluster-specific fields like 'Namespace'. Deprecated. Planned for removal in 1.18.\n        :param bool export: Should this value be exported.  Export strips fields that a user can not specify. Deprecated. Planned for removal in 1.18.\n        :return: V1beta1ValidatingWebhookConfiguration\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_validating_webhook_configuration_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_validating_webhook_configuration_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_mutating_webhook_configuration(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_mutating_webhook_configuration_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_mutating_webhook_configuration_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified MutatingWebhookConfiguration with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_validating_webhook_configuration(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_validating_webhook_configuration_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_validating_webhook_configuration_with_http_info(name, body, **kwargs)\n            return data", "response": "Replace the specified ValidatingWebhookConfiguration with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_namespaced_custom_object(self, group, version, namespace, plural, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n        else:\n            (data) = self.delete_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n            return data", "response": "Delete a custom object in a namespace scoped manner."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a namespace scoped custom object", "response": "def get_namespaced_custom_object(self, group, version, namespace, plural, name, **kwargs):\n        \"\"\"\n        Returns a namespace scoped custom object\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.get_namespaced_custom_object(group, version, namespace, plural, name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str group: the custom resource's group (required)\n        :param str version: the custom resource's version (required)\n        :param str namespace: The custom resource's namespace (required)\n        :param str plural: the custom resource's plural name. For TPRs this would be lowercase plural kind. (required)\n        :param str name: the custom object's name (required)\n        :return: object\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.get_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, **kwargs)\n        else:\n            (data) = self.get_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists the custom objects in a namespace scoped manner.", "response": "def list_namespaced_custom_object(self, group, version, namespace, plural, **kwargs):\n        \"\"\"\n        list or watch namespace scoped custom objects\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_namespaced_custom_object(group, version, namespace, plural, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str group: The custom resource's group name (required)\n        :param str version: The custom resource's version (required)\n        :param str namespace: The custom resource's namespace (required)\n        :param str plural: The custom resource's plural name. For TPRs this would be lowercase plural kind. (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications.\n        :return: object\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_namespaced_custom_object_with_http_info(group, version, namespace, plural, **kwargs)\n        else:\n            (data) = self.list_namespaced_custom_object_with_http_info(group, version, namespace, plural, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npatching the specified namespace scoped custom object", "response": "def patch_namespaced_custom_object(self, group, version, namespace, plural, name, body, **kwargs):\n        \"\"\"\n        patch the specified namespace scoped custom object\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_namespaced_custom_object(group, version, namespace, plural, name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str group: the custom resource's group (required)\n        :param str version: the custom resource's version (required)\n        :param str namespace: The custom resource's namespace (required)\n        :param str plural: the custom resource's plural name. For TPRs this would be lowercase plural kind. (required)\n        :param str name: the custom object's name (required)\n        :param object body: The JSON schema of the Resource to patch. (required)\n        :return: object\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n        else:\n            (data) = self.patch_namespaced_custom_object_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_cluster_custom_object_scale(self, group, version, plural, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_cluster_custom_object_scale_with_http_info(group, version, plural, name, body, **kwargs)\n        else:\n            (data) = self.replace_cluster_custom_object_scale_with_http_info(group, version, plural, name, body, **kwargs)\n            return data", "response": "Replace cluster scoped custom object scale"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_namespaced_custom_object_status(self, group, version, namespace, plural, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_namespaced_custom_object_status_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n        else:\n            (data) = self.replace_namespaced_custom_object_status_with_http_info(group, version, namespace, plural, name, body, **kwargs)\n            return data", "response": "Replace the status of the specified namespace scoped custom object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_namespaced_job(self, namespace, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_namespaced_job_with_http_info(namespace, body, **kwargs)\n        else:\n            (data) = self.create_namespaced_job_with_http_info(namespace, body, **kwargs)\n            return data", "response": "Create a new Job with the given namespace and body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_collection_namespaced_job(self, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_collection_namespaced_job_with_http_info(namespace, **kwargs)\n        else:\n            (data) = self.delete_collection_namespaced_job_with_http_info(namespace, **kwargs)\n            return data", "response": "This method deletes a collection of Job objects from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a PodDisruptionBudget object in the specified namespace.", "response": "def delete_namespaced_pod_disruption_budget(self, name, namespace, **kwargs):\n        \"\"\"\n        delete a PodDisruptionBudget\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_namespaced_pod_disruption_budget(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PodDisruptionBudget (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_namespaced_pod_disruption_budget_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.delete_namespaced_pod_disruption_budget_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting or watch objects of kind PodDisruptionBudget This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.list_pod_disruption_budget_for_all_namespaces(async_req=True) >>> result = thread.get() :param async_req bool :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\". This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications. :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything. :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything. :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true. The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned. :param str pretty: If 'true', then the output is pretty printed. :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv. :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity. :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion. :return: V1beta1PodDisruptionBudgetList If the method is called asynchronously, returns the request thread.", "response": "def list_pod_disruption_budget_for_all_namespaces(self, **kwargs):\n        \"\"\"\n        list or watch objects of kind PodDisruptionBudget\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.list_pod_disruption_budget_for_all_namespaces(async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \\\"next key\\\".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.\n        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.\n        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.\n        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str resource_version: When specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. When specified for list: - if unset, then the result is returned from remote storage based on quorum-read flag; - if it's 0, then we simply return what we currently have in cache, no guarantee; - if set to non zero, then the result is at least as fresh as given rv.\n        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.\n        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.\n        :return: V1beta1PodDisruptionBudgetList\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_pod_disruption_budget_for_all_namespaces_with_http_info(**kwargs)\n        else:\n            (data) = self.list_pod_disruption_budget_for_all_namespaces_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_namespaced_pod_disruption_budget(self, name, namespace, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_pod_disruption_budget_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_pod_disruption_budget_with_http_info(name, namespace, **kwargs)\n            return data", "response": "Read the PodDisruptionBudget for a given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the status of the specified PodDisruptionBudget object.", "response": "def read_namespaced_pod_disruption_budget_status(self, name, namespace, **kwargs):\n        \"\"\"\n        read status of the specified PodDisruptionBudget\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_namespaced_pod_disruption_budget_status(name, namespace, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the PodDisruptionBudget (required)\n        :param str namespace: object name and auth scope, such as for teams and projects (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1beta1PodDisruptionBudget\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_namespaced_pod_disruption_budget_status_with_http_info(name, namespace, **kwargs)\n        else:\n            (data) = self.read_namespaced_pod_disruption_budget_status_with_http_info(name, namespace, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a CertificateSigningRequest by default. This method makes a synchronous HTTP request by default.", "response": "def create_certificate_signing_request(self, body, **kwargs):\n        \"\"\"\n        create a CertificateSigningRequest\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.create_certificate_signing_request(body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param V1beta1CertificateSigningRequest body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1CertificateSigningRequest\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.create_certificate_signing_request_with_http_info(body, **kwargs)\n        else:\n            (data) = self.create_certificate_signing_request_with_http_info(body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a CertificateSigningRequest This method makes a synchronous HTTP request by default. To make an asynchronous HTTP request, please pass async_req=True >>> thread = api.delete_certificate_signing_request(name, async_req=True) >>> result = thread.get() :param async_req bool :param str name: name of the CertificateSigningRequest (required) :param str pretty: If 'true', then the output is pretty printed. :param V1DeleteOptions body: :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately. :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both. :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground. :return: V1Status If the method is called asynchronously, returns the request thread.", "response": "def delete_certificate_signing_request(self, name, **kwargs):\n        \"\"\"\n        delete a CertificateSigningRequest\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.delete_certificate_signing_request(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CertificateSigningRequest (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param V1DeleteOptions body:\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param int grace_period_seconds: The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.\n        :param bool orphan_dependents: Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the \\\"orphan\\\" finalizer will be added to/removed from the object's finalizers list. Either this field or PropagationPolicy may be set, but not both.\n        :param str propagation_policy: Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: 'Orphan' - orphan the dependents; 'Background' - allow the garbage collector to delete the dependents in the background; 'Foreground' - a cascading policy that deletes all dependents in the foreground.\n        :return: V1Status\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.delete_certificate_signing_request_with_http_info(name, **kwargs)\n        else:\n            (data) = self.delete_certificate_signing_request_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_certificate_signing_request(self, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.list_certificate_signing_request_with_http_info(**kwargs)\n        else:\n            (data) = self.list_certificate_signing_request_with_http_info(**kwargs)\n            return data", "response": "This method is used to make a list of certificate signing requests for a particular resource version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npatch the certificate signing request with the given body.", "response": "def patch_certificate_signing_request(self, name, body, **kwargs):\n        \"\"\"\n        partially update the specified CertificateSigningRequest\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.patch_certificate_signing_request(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CertificateSigningRequest (required)\n        :param object body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).\n        :param bool force: Force is going to \\\"force\\\" Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.\n        :return: V1beta1CertificateSigningRequest\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_certificate_signing_request_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_certificate_signing_request_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch_certificate_signing_request_status(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.patch_certificate_signing_request_status_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.patch_certificate_signing_request_status_with_http_info(name, body, **kwargs)\n            return data", "response": "Patch the status of a certificate signing request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the status of the specified CertificateSigningRequest.", "response": "def read_certificate_signing_request_status(self, name, **kwargs):\n        \"\"\"\n        read status of the specified CertificateSigningRequest\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.read_certificate_signing_request_status(name, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CertificateSigningRequest (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :return: V1beta1CertificateSigningRequest\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.read_certificate_signing_request_status_with_http_info(name, **kwargs)\n        else:\n            (data) = self.read_certificate_signing_request_status_with_http_info(name, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces the specified CertificateSigningRequest with the specified body.", "response": "def replace_certificate_signing_request(self, name, body, **kwargs):\n        \"\"\"\n        replace the specified CertificateSigningRequest\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async_req=True\n        >>> thread = api.replace_certificate_signing_request(name, body, async_req=True)\n        >>> result = thread.get()\n\n        :param async_req bool\n        :param str name: name of the CertificateSigningRequest (required)\n        :param V1beta1CertificateSigningRequest body: (required)\n        :param str pretty: If 'true', then the output is pretty printed.\n        :param str dry_run: When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed\n        :param str field_manager: fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.\n        :return: V1beta1CertificateSigningRequest\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_certificate_signing_request_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_certificate_signing_request_with_http_info(name, body, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_certificate_signing_request_approval(self, name, body, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async_req'):\n            return self.replace_certificate_signing_request_approval_with_http_info(name, body, **kwargs)\n        else:\n            (data) = self.replace_certificate_signing_request_approval_with_http_info(name, body, **kwargs)\n            return data", "response": "This method replaces approval of the specified CertificateSigningRequest with the specified body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef notify_owner(func):\n    ''' A decorator for mutating methods of property container classes\n    that notifies owners of the property container about mutating changes.\n\n    Args:\n        func (callable) : the container method to wrap in a notification\n\n    Returns:\n        wrapped method\n\n    Examples:\n\n        A ``__setitem__`` could be wrapped like this:\n\n        .. code-block:: python\n\n            # x[i] = y\n            @notify_owner\n            def __setitem__(self, i, y):\n                return super(PropertyValueDict, self).__setitem__(i, y)\n\n    The returned wrapped method will have a docstring indicating what\n    original method it is wrapping.\n\n    '''\n    def wrapper(self, *args, **kwargs):\n        old = self._saved_copy()\n        result = func(self, *args, **kwargs)\n        self._notify_owners(old)\n        return result\n    wrapper.__doc__ = \"Container method ``%s`` instrumented to notify property owners\" % func.__name__\n    return wrapper", "response": "A decorator for mutating methods of property container classes that notifies owners of the property container about mutating changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _stream(self, doc, source, new_data, rollover=None, setter=None):\n        ''' Internal implementation to handle special-casing stream events\n        on ``ColumnDataSource`` columns.\n\n        Normally any changes to the ``.data`` dict attribute on a\n        ``ColumnDataSource`` triggers a notification, causing all of the data\n        to be synchronized between server and clients.\n\n        The ``.stream`` method on column data sources exists to provide a\n        more efficient way to perform streaming (i.e. append-only) updates\n        to a data source, without having to perform a full synchronization,\n        which would needlessly re-send all the data.\n\n        To accomplish this, this function bypasses the wrapped methods on\n        ``PropertyValueDict`` and uses the unwrapped versions on the dict\n        superclass directly. It then explicitly makes a notification, adding\n        a special ``ColumnsStreamedEvent`` hint to the message containing\n        only the small streamed data that BokehJS needs in order to\n        efficiently synchronize.\n\n        .. warning::\n            This function assumes the integrity of ``new_data`` has already\n            been verified.\n\n        '''\n        old = self._saved_copy()\n\n        # TODO (bev) Currently this reports old differently for array vs list\n        # For arrays is reports the actual old value. For lists, the old value\n        # is actually the already updated value. This is because the method\n        # self._saved_copy() makes a shallow copy.\n        for k, v in  new_data.items():\n            if isinstance(self[k], np.ndarray) or isinstance(new_data[k], np.ndarray):\n                data = np.append(self[k], new_data[k])\n                if rollover and len(data) > rollover:\n                    data = data[-rollover:]\n                super(PropertyValueDict, self).__setitem__(k, data)\n            else:\n                L = self[k]\n                L.extend(new_data[k])\n                if rollover is not None:\n                    del L[:-rollover]\n\n        from ...document.events import ColumnsStreamedEvent\n\n        self._notify_owners(old,\n                            hint=ColumnsStreamedEvent(doc, source, new_data, rollover, setter))", "response": "Internal method to handle special - casing stream events on column data sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _patch(self, doc, source, patches, setter=None):\n        ''' Internal implementation to handle special-casing patch events\n        on ``ColumnDataSource`` columns.\n\n        Normally any changes to the ``.data`` dict attribute on a\n        ``ColumnDataSource`` triggers a notification, causing all of the data\n        to be synchronized between server and clients.\n\n        The ``.patch`` method on column data sources exists to provide a\n        more efficient way to perform patching (i.e. random access) updates\n        to a data source, without having to perform a full synchronization,\n        which would needlessly re-send all the data.\n\n        To accomplish this, this function bypasses the wrapped methods on\n        ``PropertyValueDict`` and uses the unwrapped versions on the dict\n        superclass directly. It then explicitly makes a notification, adding\n        a special ``ColumnsPatchedEvent`` hint to the message containing\n        only the small patched data that BokehJS needs in order to efficiently\n        synchronize.\n\n        .. warning::\n            This function assumes the integrity of ``patches`` has already\n            been verified.\n\n        '''\n        old = self._saved_copy()\n\n        for name, patch in patches.items():\n            for ind, value in patch:\n                if isinstance(ind, (int, slice)):\n                    self[name][ind] = value\n                else:\n                    shape = self[name][ind[0]][tuple(ind[1:])].shape\n                    self[name][ind[0]][tuple(ind[1:])] = np.array(value, copy=False).reshape(shape)\n\n        from ...document.events import ColumnsPatchedEvent\n\n        self._notify_owners(old,\n                            hint=ColumnsPatchedEvent(doc, source, patches, setter))", "response": "Internal method to handle special - casing patches on column data sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef license():\n    ''' Print the Bokeh license to the console.\n\n    Returns:\n        None\n\n    '''\n    from os.path import join\n    with open(join(__path__[0], 'LICENSE.txt')) as lic:\n        print(lic.read())", "response": "Print the Bokeh license to the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _copy_default(cls, default):\n        ''' Return a copy of the default, or a new value if the default\n        is specified by a function.\n\n        '''\n        if not isinstance(default, types.FunctionType):\n            return copy(default)\n        else:\n            return default()", "response": "Return a copy of the default or a new value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef matches(self, new, old):\n        ''' Whether two parameters match values.\n\n        If either ``new`` or ``old`` is a NumPy array or Pandas Series or Index,\n        then the result of ``np.array_equal`` will determine if the values match.\n\n        Otherwise, the result of standard Python equality will be returned.\n\n        Returns:\n            True, if new and old match, False otherwise\n\n        '''\n        if isinstance(new, np.ndarray) or isinstance(old, np.ndarray):\n            return np.array_equal(new, old)\n\n        if pd:\n            if isinstance(new, pd.Series) or isinstance(old, pd.Series):\n                return np.array_equal(new, old)\n\n            if isinstance(new, pd.Index) or isinstance(old, pd.Index):\n                return np.array_equal(new, old)\n\n        try:\n\n            # this handles the special but common case where there is a dict with array\n            # or series as values (e.g. the .data property of a ColumnDataSource)\n            if isinstance(new, dict) and isinstance(old, dict):\n                if set(new.keys()) != set(old.keys()):\n                    return False\n                return all(self.matches(new[k], old[k]) for k in new)\n\n            return new == old\n\n        # if the comparison fails for some reason, just punt and return no-match\n        except ValueError:\n            return False", "response": "Returns True if two parameters match values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid(self, value):\n        ''' Whether the value passes validation\n\n        Args:\n            value (obj) : the value to validate against this property type\n\n        Returns:\n            True if valid, False otherwise\n\n        '''\n        try:\n            if validation_on():\n                self.validate(value, False)\n        except ValueError:\n            return False\n        else:\n            return True", "response": "Whether the value passes validation\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accepts(self, tp, converter):\n        ''' Declare that other types may be converted to this property type.\n\n        Args:\n            tp (Property) :\n                A type that may be converted automatically to this property\n                type.\n\n            converter (callable) :\n                A function accepting ``value`` to perform conversion of the\n                value to this property type.\n\n        Returns:\n            self\n\n        '''\n\n        tp = ParameterizedProperty._validate_type_param(tp)\n        self.alternatives.append((tp, converter))\n        return self", "response": "Declare that other types may be converted automatically to this property type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a function to be called when the value of a column in a table is verified.", "response": "def asserts(self, fn, msg_or_fn):\n        ''' Assert that prepared values satisfy given conditions.\n\n        Assertions are intended in enforce conditions beyond simple value\n        type validation. For instance, this method can be use to assert that\n        the columns of a ``ColumnDataSource`` all collectively have the same\n        length at all times.\n\n        Args:\n            fn (callable) :\n                A function accepting ``(obj, value)`` that returns True if the value\n                passes the assertion, or False otherwise.\n\n            msg_or_fn (str or callable) :\n                A message to print in case the assertion fails, or a function\n                accepting ``(obj, name, value)`` to call in in case the assertion\n                fails.\n\n        Returns:\n            self\n\n        '''\n        self.assertions.append((fn, msg_or_fn))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure the default output state to generate output saved to a file when show is called.", "response": "def output_file(filename, title=\"Bokeh Plot\", mode=\"cdn\", root_dir=None):\n    '''Configure the default output state to generate output saved\n    to a file when :func:`show` is called.\n\n    Does not change the current ``Document`` from ``curdoc()``. File and notebook\n    output may be active at the same time, so e.g., this does not clear the\n    effects of ``output_notebook()``.\n\n    Args:\n        filename (str) : a filename for saving the HTML document\n\n        title (str, optional) : a title for the HTML document (default: \"Bokeh Plot\")\n\n        mode (str, optional) : how to include BokehJS (default: ``'cdn'``)\n            One of: ``'inline'``, ``'cdn'``, ``'relative(-dev)'`` or\n            ``'absolute(-dev)'``. See :class:`bokeh.resources.Resources` for more details.\n\n        root_dir (str, optional) : root directory to use for 'absolute' resources. (default: None)\n            This value is ignored for other resource types, e.g. ``INLINE`` or\n            ``CDN``.\n\n    Returns:\n        None\n\n    .. note::\n        Generally, this should be called at the beginning of an interactive\n        session or the top of a script.\n\n    .. warning::\n        This output file will be overwritten on every save, e.g., each time\n        show() or save() is invoked.\n\n    '''\n    curstate().output_file(\n        filename,\n        title=title,\n        mode=mode,\n        root_dir=root_dir\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the default output state to generate output in notebook cells", "response": "def output_notebook(resources=None, verbose=False, hide_banner=False, load_timeout=5000, notebook_type='jupyter'):\n    ''' Configure the default output state to generate output in notebook cells\n    when :func:`show` is called. Note that, :func:`show` may be called multiple\n    times in a single cell to display multiple objects in the output cell. The\n    objects will be displayed in order.\n\n    Args:\n        resources (Resource, optional) :\n            How and where to load BokehJS from (default: CDN)\n\n        verbose (bool, optional) :\n            whether to display detailed BokehJS banner (default: False)\n\n        hide_banner (bool, optional):\n            whether to hide the Bokeh banner (default: False)\n\n        load_timeout (int, optional) :\n            Timeout in milliseconds when plots assume load timed out (default: 5000)\n\n        notebook_type (string, optional):\n            Notebook type (default: jupyter)\n\n    Returns:\n        None\n\n    .. note::\n        Generally, this should be called at the beginning of an interactive\n        session or the top of a script.\n\n    '''\n    # verify notebook_type first in curstate().output_notebook\n    curstate().output_notebook(notebook_type)\n    run_notebook_hook(notebook_type, 'load', resources, verbose, hide_banner, load_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_path(self):\n        ''' The last path component for the basename of the configured filename.\n\n        '''\n        if self.failed:\n            return None\n        else:\n            # TODO should fix invalid URL characters\n            return '/' + os.path.splitext(os.path.basename(self._runner.path))[0]", "response": "The last path component for the basename of the configured filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expr(expression, transform=None):\n    ''' Convenience function to explicitly return an \"expr\" specification for\n    a Bokeh :class:`~bokeh.core.properties.DataSpec` property.\n\n    Args:\n        expression (Expression) : a computed expression for a\n            ``DataSpec`` property.\n\n        transform (Transform, optional) : a transform to apply (default: None)\n\n    Returns:\n        dict : ``{ \"expr\": expression }``\n\n    .. note::\n        This function is included for completeness. String values for\n        property specifications are by default interpreted as field names.\n\n    '''\n    if transform:\n        return dict(expr=expression, transform=transform)\n    return dict(expr=expression)", "response": "A convenience function to explicitly return an expr specification for a Bokeh DataSpec property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict that represents a field for a data source.", "response": "def field(name, transform=None):\n    ''' Convenience function to explicitly return a \"field\" specification for\n    a Bokeh :class:`~bokeh.core.properties.DataSpec` property.\n\n    Args:\n        name (str) : name of a data source field to reference for a\n            ``DataSpec`` property.\n\n        transform (Transform, optional) : a transform to apply (default: None)\n\n    Returns:\n        dict : ``{ \"field\": name }``\n\n    .. note::\n        This function is included for completeness. String values for\n        property specifications are by default interpreted as field names.\n\n    '''\n    if transform:\n        return dict(field=name, transform=transform)\n    return dict(field=name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value(val, transform=None):\n    ''' Convenience function to explicitly return a \"value\" specification for\n    a Bokeh :class:`~bokeh.core.properties.DataSpec` property.\n\n    Args:\n        val (any) : a fixed value to specify for a ``DataSpec`` property.\n\n        transform (Transform, optional) : a transform to apply (default: None)\n\n    Returns:\n        dict : ``{ \"value\": name }``\n\n    .. note::\n        String values for property specifications are by default interpreted\n        as field names. This function is especially useful when you want to\n        specify a fixed value with text properties.\n\n    Example:\n\n        .. code-block:: python\n\n            # The following will take text values to render from a data source\n            # column \"text_column\", but use a fixed value \"12pt\" for font size\n            p.text(\"x\", \"y\", text=\"text_column\",\n                   text_font_size=value(\"12pt\"), source=source)\n\n    '''\n    if transform:\n        return dict(value=val, transform=transform)\n    return dict(value=val)", "response": "Convenience function to explicitly return a value specification for a Bokeh DataSpec property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_descriptors(self, base_name):\n        ''' Return a list of ``PropertyDescriptor`` instances to install on a\n        class, in order to delegate attribute access to this property.\n\n        Unlike simpler property types, ``UnitsSpec`` returns multiple\n        descriptors to install. In particular, descriptors for the base\n        property as well as the associated units property are returned.\n\n        Args:\n            name (str) : the name of the property these descriptors are for\n\n        Returns:\n            list[PropertyDescriptor]\n\n        The descriptors returned are collected by the ``MetaHasProps``\n        metaclass and added to ``HasProps`` subclasses during class creation.\n        '''\n        units_name = base_name + \"_units\"\n        units_props = self._units_type.make_descriptors(units_name)\n        return units_props + [ UnitsSpecPropertyDescriptor(base_name, self, units_props[0]) ]", "response": "Returns a list of PropertyDescriptor instances to install on the base_name property."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef isconst(cls, val):\n        ''' Whether the value is a string color literal.\n\n        Checks for a well-formed hexadecimal color value or a named color.\n\n        Args:\n            val (str) : the value to check\n\n        Returns:\n            True, if the value is a string color literal\n\n        '''\n        return isinstance(val, string_types) and \\\n               ((len(val) == 7 and val[0] == \"#\") or val in enums.NamedColor)", "response": "Whether the value is a string color literal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompress and pickles given object to the given filename.", "response": "def save_object(filename, obj):\n    \"\"\"Compresses and pickles given object to the given filename.\"\"\"\n    logging.info('saving {}...'.format(filename))\n    try:\n        with gzip.GzipFile(filename, 'wb') as f:\n            f.write(pickle.dumps(obj, 1))\n    except Exception as e:\n        logging.error('save failure: {}'.format(e))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the section heading for the issue or None if this issue should be ignored.", "response": "def issue_section(issue):\n    \"\"\"Returns the section heading for the issue, or None if this issue should be ignored.\"\"\"\n    labels = issue.get('labels', [])\n    for label in labels:\n        if not label['name'].startswith('type: '):\n            continue\n\n        if label['name'] in LOG_SECTION:\n            return LOG_SECTION[label['name']]\n        elif label['name'] in IGNORE_ISSUE_TYPE:\n            return None\n        else:\n            logging.warning('unknown issue type: \"{}\" for: {}'.format(label['name'], issue_line(issue)))\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of tags for this issue.", "response": "def issue_tags(issue):\n    \"\"\"Returns list of tags for this issue.\"\"\"\n    labels = issue.get('labels', [])\n    return [label['name'].replace('tag: ', '') for label in labels if label['name'].startswith('tag: ')]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef closed_issue(issue, after=None):\n    if issue['state'] == 'closed':\n        if after is None or parse_timestamp(issue['closed_at']) > after:\n            return True\n    return False", "response": "Returns True iff this issue was closed after given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef relevent_issue(issue, after):\n    return (closed_issue(issue, after) and\n            issue_completed(issue) and\n            issue_section(issue))", "response": "Returns True iff this issue is something we should show in the changelog."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relevant_issues(issues, after):\n    logging.info('finding relevant issues after {}...'.format(after))\n    seen = set()\n    for issue in issues:\n        if relevent_issue(issue, after) and issue['title'] not in seen:\n            seen.add(issue['title'])\n            yield issue", "response": "Yields relevant closed issues given a list of issues."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef closed_issues(issues, after):\n    logging.info('finding closed issues after {}...'.format(after))\n    seen = set()\n    for issue in issues:\n        if closed_issue(issue, after) and issue['title'] not in seen:\n            seen.add(issue['title'])\n            yield issue", "response": "Yields closed issues given a list of issues."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_issues(issues):\n    logging.info('finding issues...')\n    seen = set()\n    for issue in issues:\n        if issue['title'] not in seen:\n            seen.add(issue['title'])\n            yield issue", "response": "Yields unique set of issues given a list of issues."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_issues_url(page, after):\n    template = '{base_url}/{owner}/{repo}/issues?state=closed&per_page=100&page={page}&since={after}'\n    return template.format(page=page, after=after.isoformat(), **API_PARAMS)", "response": "Returns github API URL for querying tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse ISO8601 timestamps given by github API.", "response": "def parse_timestamp(timestamp):\n    \"\"\"Parse ISO8601 timestamps given by github API.\"\"\"\n    dt = dateutil.parser.parse(timestamp)\n    return dt.astimezone(dateutil.tz.tzutc())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_url(url):\n    logging.debug('reading {url} ...'.format(url=url))\n    token = os.environ.get(\"BOKEH_GITHUB_API_TOKEN\")\n    headers = {}\n    if token:\n        headers['Authorization'] = 'token %s' % token\n    request = Request(url, headers=headers)\n    response = urlopen(request).read()\n    return json.loads(response.decode(\"UTF-8\"))", "response": "Reads given URL as JSON and returns data as loaded python object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhitting the github API for all closed issues after the given date returns the data.", "response": "def query_all_issues(after):\n    \"\"\"Hits the github API for all closed issues after the given date, returns the data.\"\"\"\n    page = count(1)\n    data = []\n    while True:\n        page_data = query_issues(next(page), after)\n        if not page_data:\n            break\n        data.extend(page_data)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of tags returns the datetime of the tag with the given name ; Otherwise None.", "response": "def dateof(tag_name, tags):\n    \"\"\"Given a list of tags, returns the datetime of the tag with the given name; Otherwise None.\"\"\"\n    for tag in tags:\n        if tag['name'] == tag_name:\n            commit = read_url(tag['commit']['url'])\n            return parse_timestamp(commit['commit']['committer']['date'])\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_data(query_func, load_data=False, save_data=False):\n    if hasattr(query_func, '__name__'):\n        func_name = query_func.__name__\n    elif hasattr(query_func, 'func'):\n        func_name = query_func.func.__name__\n\n    pickle_file = '{}.pickle'.format(func_name)\n\n    if load_data:\n        data = load_object(pickle_file)\n    else:\n        data = query_func()\n        if save_data:\n            save_object(pickle_file, data)\n    return data", "response": "Gets data from query_func optionally saving that data to a file ; or loads data from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking issues for BEP 1 compliance.", "response": "def check_issues(issues, after=None):\n    \"\"\"Checks issues for BEP 1 compliance.\"\"\"\n    issues = closed_issues(issues, after) if after else all_issues(issues)\n    issues = sorted(issues, key=ISSUES_SORT_KEY)\n\n    have_warnings = False\n\n    for section, issue_group in groupby(issues, key=ISSUES_BY_SECTION):\n        for issue in issue_group:\n            have_warnings |= check_issue(issue, after)\n\n    return have_warnings"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning log line for given issue.", "response": "def issue_line(issue):\n    \"\"\"Returns log line for given issue.\"\"\"\n    template = '#{number} {tags}{title}'\n    tags = issue_tags(issue)\n    params = {\n        'title': issue['title'].capitalize().rstrip('.'),\n        'number': issue['number'],\n        'tags': ' '.join('[{}]'.format(tag) for tag in tags) + (' ' if tags else '')\n    }\n    return template.format(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of this color value.", "response": "def copy(self):\n        ''' Return a copy of this color value.\n\n        Returns:\n            :class:`~bokeh.colors.rgb.RGB`\n\n        '''\n        return RGB(self.r, self.g, self.b, self.a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the CSS representation of this RGB color.", "response": "def to_css(self):\n        ''' Generate the CSS representation of this RGB color.\n\n        Returns:\n            str, ``\"rgb(...)\"`` or ``\"rgba(...)\"``\n\n        '''\n        if self.a == 1.0:\n            return \"rgb(%d, %d, %d)\" % (self.r, self.g, self.b)\n        else:\n            return \"rgba(%d, %d, %d, %s)\" % (self.r, self.g, self.b, self.a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_hsl(self):\n        ''' Return a corresponding HSL color for this RGB color.\n\n        Returns:\n            :class:`~bokeh.colors.rgb.RGB`\n\n        '''\n        from .hsl import HSL # prevent circular import\n        h, l, s = colorsys.rgb_to_hls(float(self.r)/255, float(self.g)/255, float(self.b)/255)\n        return HSL(round(h*360), s, l, self.a)", "response": "Return a corresponding HSL color for this RGB color."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a result into a Future by collapsing any futures inside result.", "response": "def yield_for_all_futures(result):\n    \"\"\" Converts result into a Future by collapsing any futures inside result.\n\n    If result is a Future we yield until it's done, then if the value inside\n    the Future is another Future we yield until it's done as well, and so on.\n    \"\"\"\n    while True:\n\n        # This is needed for Tornado >= 4.5 where convert_yielded will no\n        # longer raise BadYieldError on None\n        if result is None:\n            break\n\n        try:\n            future = gen.convert_yielded(result)\n        except gen.BadYieldError:\n            # result is not a yieldable thing, we are done\n            break\n        else:\n            result = yield future\n\n    raise gen.Return(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_all_callbacks(self):\n        for cb_id in list(self._next_tick_callback_removers.keys()):\n            self.remove_next_tick_callback(cb_id)\n        for cb_id in list(self._timeout_callback_removers.keys()):\n            self.remove_timeout_callback(cb_id)\n        for cb_id in list(self._periodic_callback_removers.keys()):\n            self.remove_periodic_callback(cb_id)", "response": "Removes all registered callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_next_tick_callback(self, callback, callback_id=None):\n        def wrapper(*args, **kwargs):\n            # this 'removed' flag is a hack because Tornado has no way\n            # to remove a \"next tick\" callback added with\n            # IOLoop.add_callback. So instead we make our wrapper skip\n            # invoking the callback.\n            if not wrapper.removed:\n                self.remove_next_tick_callback(callback_id)\n                return callback(*args, **kwargs)\n            else:\n                return None\n\n        wrapper.removed = False\n\n        def remover():\n            wrapper.removed = True\n\n        callback_id = self._assign_remover(callback, callback_id, self._next_tick_callback_removers, remover)\n        self._loop.add_callback(wrapper)\n        return callback_id", "response": "Adds a callback to be run on the next tick. Returns an ID that can be used with remove_next_tick_callback."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a callback to be run once after timeout_milliseconds. Returns an ID that can be used with remove_timeout_callback.", "response": "def add_timeout_callback(self, callback, timeout_milliseconds, callback_id=None):\n        \"\"\" Adds a callback to be run once after timeout_milliseconds.\n        Returns an ID that can be used with remove_timeout_callback.\"\"\"\n        def wrapper(*args, **kwargs):\n            self.remove_timeout_callback(callback_id)\n            return callback(*args, **kwargs)\n\n        handle = None\n\n        def remover():\n            if handle is not None:\n                self._loop.remove_timeout(handle)\n\n        callback_id = self._assign_remover(callback, callback_id, self._timeout_callback_removers, remover)\n        handle = self._loop.call_later(timeout_milliseconds / 1000.0, wrapper)\n        return callback_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_periodic_callback(self, callback, period_milliseconds, callback_id=None):\n\n        cb = _AsyncPeriodic(callback, period_milliseconds, io_loop=self._loop)\n        callback_id = self._assign_remover(callback, callback_id, self._periodic_callback_removers, cb.stop)\n        cb.start()\n        return callback_id", "response": "Adds a callback to be run every period_milliseconds until it is removed. Returns an ID that can be used with remove_periodic_callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlinks to a Bokeh Github issue.", "response": "def bokeh_commit(name, rawtext, text, lineno, inliner, options=None, content=None):\n    ''' Link to a Bokeh Github issue.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    '''\n    app = inliner.document.settings.env.app\n    node = _make_gh_link_node(app, rawtext, 'commit', 'commit ', 'commit', text, options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bokeh_issue(name, rawtext, text, lineno, inliner, options=None, content=None):\n    ''' Link to a Bokeh Github issue.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    '''\n    app = inliner.document.settings.env.app\n    try:\n        issue_num = int(text)\n        if issue_num <= 0:\n            raise ValueError\n    except ValueError:\n        msg = inliner.reporter.error(\n            'Github issue number must be a number greater than or equal to 1; '\n            '\"%s\" is invalid.' % text, line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n    node = _make_gh_link_node(app, rawtext, 'issue', '#', 'issues', str(issue_num), options)\n    return [node], []", "response": "Link to a Bokeh Github issue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bokeh_tree(name, rawtext, text, lineno, inliner, options=None, content=None):\n    ''' Link to a URL in the Bokeh GitHub tree, pointing to appropriate tags\n    for releases, or to master otherwise.\n\n    The link text is simply the URL path supplied, so typical usage might\n    look like:\n\n    .. code-block:: none\n\n        All of the examples are located in the :bokeh-tree:`examples`\n        subdirectory of your Bokeh checkout.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    '''\n    app = inliner.document.settings.env.app\n\n    tag = app.env.config['version']\n    if '-' in tag:\n        tag = 'master'\n\n    url = \"%s/tree/%s/%s\" % (_BOKEH_GH, tag, text)\n    options = options or {}\n    set_classes(options)\n    node = nodes.reference(rawtext, text, refuri=url, **options)\n    return [node], []", "response": "Link to a URL in the Bokeh GitHub tree pointing to appropriate tags\n    for releases or to master otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequiring Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_role('bokeh-commit', bokeh_commit)\n    app.add_role('bokeh-issue', bokeh_issue)\n    app.add_role('bokeh-pull', bokeh_pull)\n    app.add_role('bokeh-tree', bokeh_tree)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_gh_link_node(app, rawtext, role, kind, api_type, id, options=None):\n    ''' Return a link to a Bokeh Github resource.\n\n    Args:\n        app (Sphinx app) : current app\n        rawtext (str) : text being replaced with link node.\n        role (str) : role name\n        kind (str) : resource type (issue, pull, etc.)\n        api_type (str) : type for api link\n        id : (str) : id of the resource to link to\n        options (dict) : options dictionary passed to role function\n\n    '''\n    url = \"%s/%s/%s\" % (_BOKEH_GH, api_type, id)\n    options = options or {}\n    set_classes(options)\n    node = nodes.reference(\n        rawtext, kind + utils.unescape(id), refuri=url, **options)\n    return node", "response": "Return a link node to a Bokeh Github resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._document_patched`` if it exists.\n\n        '''\n        super(DocumentPatchedEvent, self).dispatch(receiver)\n        if hasattr(receiver, '_document_patched'):\n            receiver._document_patched(self)", "response": "Dispatch handling of this event to a receiver."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._document_model_dhanged`` if it\n        exists.\n\n        '''\n        super(ModelChangedEvent, self).dispatch(receiver)\n        if hasattr(receiver, '_document_model_changed'):\n            receiver._document_model_changed(self)", "response": "Dispatch handling of this event to a receiver."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a JSON representation of this event suitable for sending to clients.", "response": "def generate(self, references, buffers):\n        ''' Create a JSON representation of this event suitable for sending\n        to clients.\n\n        Args:\n            references (dict[str, Model]) :\n                If the event requires references to certain models in order to\n                function, they may be collected here.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n            buffers (set) :\n                If the event needs to supply any additional Bokeh protocol\n                buffers, they may be added to this set.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n        '''\n        from ..model import collect_models\n\n        if self.hint is not None:\n            return self.hint.generate(references, buffers)\n\n        value = self.serializable_new\n\n        # the new value is an object that may have\n        # not-yet-in-the-remote-doc references, and may also\n        # itself not be in the remote doc yet.  the remote may\n        # already have some of the references, but\n        # unfortunately we don't have an easy way to know\n        # unless we were to check BEFORE the attr gets changed\n        # (we need the old _all_models before setting the\n        # property). So we have to send all the references the\n        # remote could need, even though it could be inefficient.\n        # If it turns out we need to fix this we could probably\n        # do it by adding some complexity.\n        value_refs = set(collect_models(value))\n\n        # we know we don't want a whole new copy of the obj we're patching\n        # unless it's also the new value\n        if self.model != value:\n            value_refs.discard(self.model)\n\n        references.update(value_refs)\n\n        return { 'kind'  : 'ModelChanged',\n                 'model' : self.model.ref,\n                 'attr'  : self.attr,\n                 'new'   : value }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch handling of this event to a receiver.", "response": "def dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._column_data_changed`` if it exists.\n\n        '''\n        super(ColumnDataChangedEvent, self).dispatch(receiver)\n        if hasattr(receiver, '_column_data_changed'):\n            receiver._column_data_changed(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(self, references, buffers):\n        ''' Create a JSON representation of this event suitable for sending\n        to clients.\n\n        .. code-block:: python\n\n            {\n                'kind'          : 'ColumnDataChanged'\n                'column_source' : <reference to a CDS>\n                'new'           : <new data to steam to column_source>\n                'cols'          : <specific columns to update>\n            }\n\n        Args:\n            references (dict[str, Model]) :\n                If the event requires references to certain models in order to\n                function, they may be collected here.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n            buffers (set) :\n                If the event needs to supply any additional Bokeh protocol\n                buffers, they may be added to this set.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n\n        '''\n        from ..util.serialization import transform_column_source_data\n\n        data_dict = transform_column_source_data(self.column_source.data, buffers=buffers, cols=self.cols)\n\n        return { 'kind'          : 'ColumnDataChanged',\n                 'column_source' : self.column_source.ref,\n                 'new'           : data_dict,\n                 'cols'          : self.cols}", "response": "Generate a JSON representation of this event suitable for sending to Bokeh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndispatching handling of this event to a receiver.", "response": "def dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._columns_streamed`` if it exists.\n\n        '''\n        super(ColumnsStreamedEvent, self).dispatch(receiver)\n        if hasattr(receiver, '_columns_streamed'):\n            receiver._columns_streamed(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(self, references, buffers):\n        ''' Create a JSON representation of this event suitable for sending\n        to clients.\n\n        .. code-block:: python\n\n            {\n                'kind'          : 'ColumnsStreamed'\n                'column_source' : <reference to a CDS>\n                'data'          : <new data to steam to column_source>\n                'rollover'      : <rollover limit>\n            }\n\n        Args:\n            references (dict[str, Model]) :\n                If the event requires references to certain models in order to\n                function, they may be collected here.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n            buffers (set) :\n                If the event needs to supply any additional Bokeh protocol\n                buffers, they may be added to this set.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n        '''\n        return { 'kind'          : 'ColumnsStreamed',\n                 'column_source' : self.column_source.ref,\n                 'data'          : self.data,\n                 'rollover'      : self.rollover }", "response": "Generate a JSON representation of this event suitable for sending to clients."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._columns_patched`` if it exists.\n\n        '''\n        super(ColumnsPatchedEvent, self).dispatch(receiver)\n        if hasattr(receiver, '_columns_patched'):\n            receiver._columns_patched(self)", "response": "Dispatch handling of this event to a receiver."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(self, references, buffers):\n        ''' Create a JSON representation of this event suitable for sending\n        to clients.\n\n        .. code-block:: python\n\n            {\n                'kind'  : 'RootAdded'\n                'title' : <reference to a Model>\n            }\n\n        Args:\n            references (dict[str, Model]) :\n                If the event requires references to certain models in order to\n                function, they may be collected here.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n            buffers (set) :\n                If the event needs to supply any additional Bokeh protocol\n                buffers, they may be added to this set.\n\n                **This is an \"out\" parameter**. The values it contains will be\n                modified in-place.\n\n        '''\n        references.update(self.model.references())\n        return { 'kind'  : 'RootAdded',\n                 'model' : self.model.ref }", "response": "Generate a JSON representation of this event suitable for sending to clients."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndispatching handling of this event to a receiver.", "response": "def dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._session_callback_added`` if\n        it exists.\n\n        '''\n        super(SessionCallbackAdded, self).dispatch(receiver)\n        if hasattr(receiver, '_session_callback_added'):\n            receiver._session_callback_added(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch(self, receiver):\n        ''' Dispatch handling of this event to a receiver.\n\n        This method will invoke ``receiver._session_callback_removed`` if\n        it exists.\n\n        '''\n        super(SessionCallbackRemoved, self).dispatch(receiver)\n        if hasattr(receiver, '_session_callback_removed'):\n            receiver._session_callback_removed(self)", "response": "Dispatch handling of this event to a receiver."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a useful report after setuptools output describing where and how BokehJS is installed.", "response": "def show_bokehjs(bokehjs_action, develop=False):\n    ''' Print a useful report after setuptools output describing where and how\n    BokehJS is installed.\n\n    Args:\n        bokehjs_action (str) : one of 'built', 'installed', or 'packaged'\n            how (or if) BokehJS was installed into the python source tree\n\n        develop (bool, optional) :\n            whether the command was for \"develop\" mode (default: False)\n\n    Returns:\n        None\n\n    '''\n    print()\n    if develop:\n        print(\"Installed Bokeh for DEVELOPMENT:\")\n    else:\n        print(\"Installed Bokeh:\")\n    if bokehjs_action in ['built', 'installed']:\n        print(\"  - using %s built BokehJS from bokehjs/build\\n\" % (bright(yellow(\"NEWLY\")) if bokehjs_action=='built' else bright(yellow(\"PREVIOUSLY\"))))\n    else:\n        print(\"  - using %s BokehJS, located in 'bokeh.server.static'\\n\" % bright(yellow(\"PACKAGED\")))\n    print()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_help(bokehjs_action):\n    ''' Print information about extra Bokeh-specific command line options.\n\n    Args:\n        bokehjs_action (str) : one of 'built', 'installed', or 'packaged'\n            how (or if) BokehJS was installed into the python source tree\n\n    Returns:\n        None\n\n    '''\n    print()\n    if bokehjs_action in ['built', 'installed']:\n        print(\"Bokeh-specific options available with 'install' or 'develop':\")\n        print()\n        print(\"  --build-js          build and install a fresh BokehJS\")\n        print(\"  --install-js        install only last previously built BokehJS\")\n    else:\n        print(\"Bokeh is using PACKAGED BokehJS, located in 'bokeh.server.static'\")\n        print()\n        print(\"No extra Bokeh-specific options are available.\")\n    print()", "response": "Prints information about extra BokehJS - specific command line options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a new BokehJS and install it.", "response": "def build_or_install_bokehjs():\n    ''' Build a new BokehJS (and install it) or install a previously build\n    BokehJS.\n\n    If no options ``--build-js`` or ``--install-js`` are detected, the\n    user is prompted for what to do.\n\n    If ``--existing-js`` is detected, then this setup.py is being run from a\n    packaged sdist, no action is taken.\n\n    Note that ``-build-js`` is only compatible with the following ``setup.py``\n    commands: install, develop, sdist, egg_info, build\n\n    Returns:\n        str : one of 'built', 'installed', 'packaged'\n            How (or if) BokehJS was installed into the python source tree\n\n    '''\n\n    # This happens when building from inside a published, pre-packaged sdist\n    # The --existing-js option is not otherwise documented\n    if '--existing-js' in sys.argv:\n        sys.argv.remove('--existing-js')\n        return \"packaged\"\n\n    if '--build-js' not in sys.argv and '--install-js' not in sys.argv:\n        jsbuild = jsbuild_prompt()\n\n    elif '--build-js' in sys.argv:\n        jsbuild = True\n        sys.argv.remove('--build-js')\n\n    # must be \"--install-js\"\n    else:\n        jsbuild = False\n        sys.argv.remove('--install-js')\n\n    jsbuild_ok = ('install', 'develop', 'sdist', 'egg_info', 'build')\n    if jsbuild and not any(arg in sys.argv for arg in jsbuild_ok):\n        print(\"Error: Option '--build-js' only valid with 'install', 'develop', 'sdist', or 'build', exiting.\")\n        sys.exit(1)\n\n    if jsbuild:\n        build_js()\n        install_js()\n        return \"built\"\n    else:\n        install_js()\n        return \"installed\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fixup_building_sdist():\n    ''' Check for 'sdist' and ensure we always build BokehJS when packaging\n\n    Source distributions do not ship with BokehJS source code, but must ship\n    with a pre-built BokehJS library. This function modifies ``sys.argv`` as\n    necessary so that ``--build-js`` IS present, and ``--install-js` is NOT.\n\n    Returns:\n        None\n\n    '''\n    if \"sdist\" in sys.argv:\n        if \"--install-js\" in sys.argv:\n            print(\"Removing '--install-js' incompatible with 'sdist'\")\n            sys.argv.remove('--install-js')\n        if \"--build-js\" not in sys.argv:\n            print(\"Adding '--build-js' required for 'sdist'\")\n            sys.argv.append('--build-js')", "response": "Check for sdist and ensure we always build BokehJS when packaging\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fixup_for_packaged():\n    ''' If we are installing FROM an sdist, then a pre-built BokehJS is\n    already installed in the python source tree.\n\n    The command line options ``--build-js`` or ``--install-js`` are\n    removed from ``sys.argv``, with a warning.\n\n    Also adds ``--existing-js`` to ``sys.argv`` to signal that BokehJS is\n    already packaged.\n\n    Returns:\n        None\n\n    '''\n    if exists(join(ROOT, 'PKG-INFO')):\n        if \"--build-js\" in sys.argv or \"--install-js\" in sys.argv:\n            print(SDIST_BUILD_WARNING)\n            if \"--build-js\" in sys.argv:\n                sys.argv.remove('--build-js')\n            if \"--install-js\" in sys.argv:\n                sys.argv.remove('--install-js')\n        if \"--existing-js\" not in sys.argv:\n            sys.argv.append('--existing-js')", "response": "Fixup for packaged BokehJS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jsbuild_prompt():\n    ''' Prompt users whether to build a new BokehJS or install an existing one.\n\n    Returns:\n        bool : True, if a new build is requested, False otherwise\n\n    '''\n    print(BOKEHJS_BUILD_PROMPT)\n    mapping = {\"1\": True, \"2\": False}\n    value = input(\"Choice? \")\n    while value not in mapping:\n        print(\"Input '%s' not understood. Valid choices: 1, 2\\n\" % value)\n        value = input(\"Choice? \")\n    return mapping[value]", "response": "Prompt users whether to build a new BokehJS or install an existing BokehJS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_js():\n    ''' Build BokehJS files (CSS, JS, etc) under the ``bokehjs`` source\n    subdirectory.\n\n    Also prints a table of statistics about the generated assets (file sizes,\n    etc.) or any error messages if the build fails.\n\n    Note this function only builds BokehJS assets, it does not install them\n    into the python source tree.\n\n    '''\n    print(\"Building BokehJS... \", end=\"\")\n    sys.stdout.flush()\n    os.chdir('bokehjs')\n\n    cmd = [\"node\", \"make\", 'build', '--emit-error']\n\n    t0 = time.time()\n    try:\n        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    except OSError as e:\n        print(BUILD_EXEC_FAIL_MSG % (cmd, e))\n        sys.exit(1)\n    finally:\n        os.chdir('..')\n\n    result = proc.wait()\n    t1 = time.time()\n\n    if result != 0:\n        indented_msg = \"\"\n        outmsg = proc.stdout.read().decode('ascii', errors='ignore')\n        outmsg = \"\\n\".join(\"    \" + x for x in outmsg.split(\"\\n\"))\n        errmsg = proc.stderr.read().decode('ascii', errors='ignore')\n        errmsg = \"\\n\".join(\"    \" + x for x in errmsg.split(\"\\n\"))\n        print(BUILD_FAIL_MSG % (red(outmsg), red(errmsg)))\n        sys.exit(1)\n\n    indented_msg = \"\"\n    msg = proc.stdout.read().decode('ascii', errors='ignore')\n    pat = re.compile(r\"(\\[.*\\]) (.*)\", re.DOTALL)\n    for line in msg.strip().split(\"\\n\"):\n        m = pat.match(line)\n        if not m: continue # skip generate.py output lines\n        stamp, txt = m.groups()\n        indented_msg += \"   \" + dim(green(stamp)) + \" \" + dim(txt) + \"\\n\"\n    msg = \"\\n\".join(\"    \" + x for x in msg.split(\"\\n\"))\n    print(BUILD_SUCCESS_MSG % indented_msg)\n    print(\"Build time: %s\" % bright(yellow(\"%0.1f seconds\" % (t1-t0))))\n    print()\n    print(\"Build artifact sizes:\")\n    try:\n        def size(*path):\n            return os.stat(join(\"bokehjs\", \"build\", *path)).st_size / 2**10\n\n        print(\"  - bokeh.js              : %6.1f KB\" % size(\"js\", \"bokeh.js\"))\n        print(\"  - bokeh.css             : %6.1f KB\" % size(\"css\", \"bokeh.css\"))\n        print(\"  - bokeh.min.js          : %6.1f KB\" % size(\"js\", \"bokeh.min.js\"))\n        print(\"  - bokeh.min.css         : %6.1f KB\" % size(\"css\", \"bokeh.min.css\"))\n\n        print(\"  - bokeh-widgets.js      : %6.1f KB\" % size(\"js\", \"bokeh-widgets.js\"))\n        print(\"  - bokeh-widgets.css     : %6.1f KB\" % size(\"css\", \"bokeh-widgets.css\"))\n        print(\"  - bokeh-widgets.min.js  : %6.1f KB\" % size(\"js\", \"bokeh-widgets.min.js\"))\n        print(\"  - bokeh-widgets.min.css : %6.1f KB\" % size(\"css\", \"bokeh-widgets.min.css\"))\n\n        print(\"  - bokeh-tables.js       : %6.1f KB\" % size(\"js\", \"bokeh-tables.js\"))\n        print(\"  - bokeh-tables.css      : %6.1f KB\" % size(\"css\", \"bokeh-tables.css\"))\n        print(\"  - bokeh-tables.min.js   : %6.1f KB\" % size(\"js\", \"bokeh-tables.min.js\"))\n        print(\"  - bokeh-tables.min.css  : %6.1f KB\" % size(\"css\", \"bokeh-tables.min.css\"))\n\n        print(\"  - bokeh-api.js          : %6.1f KB\" % size(\"js\", \"bokeh-api.js\"))\n        print(\"  - bokeh-api.min.js      : %6.1f KB\" % size(\"js\", \"bokeh-api.min.js\"))\n    except Exception as e:\n        print(BUILD_SIZE_FAIL_MSG % e)\n        sys.exit(1)", "response": "Builds the BokehJS assets under the bokehjs source directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy built BokehJS files into the Python source tree.", "response": "def install_js():\n    ''' Copy built BokehJS files into the Python source tree.\n\n    Returns:\n        None\n\n    '''\n    target_jsdir = join(SERVER, 'static', 'js')\n    target_cssdir = join(SERVER, 'static', 'css')\n    target_tslibdir = join(SERVER, 'static', 'lib')\n\n    STATIC_ASSETS = [\n        join(JS,  'bokeh.js'),\n        join(JS,  'bokeh.min.js'),\n        join(CSS, 'bokeh.css'),\n        join(CSS, 'bokeh.min.css'),\n    ]\n    if not all(exists(a) for a in STATIC_ASSETS):\n        print(BOKEHJS_INSTALL_FAIL)\n        sys.exit(1)\n\n    if exists(target_jsdir):\n        shutil.rmtree(target_jsdir)\n    shutil.copytree(JS, target_jsdir)\n\n    if exists(target_cssdir):\n        shutil.rmtree(target_cssdir)\n    shutil.copytree(CSS, target_cssdir)\n\n    if exists(target_tslibdir):\n        shutil.rmtree(target_tslibdir)\n    if exists(TSLIB):\n        # keep in sync with bokehjs/src/compiler/compile.ts\n        lib = {\n            \"lib.es5.d.ts\",\n            \"lib.dom.d.ts\",\n            \"lib.es2015.core.d.ts\",\n            \"lib.es2015.promise.d.ts\",\n            \"lib.es2015.symbol.d.ts\",\n            \"lib.es2015.iterable.d.ts\",\n        }\n        shutil.copytree(TSLIB, target_tslibdir, ignore=lambda _, files: [ f for f in files if f not in lib ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping axial coordinates to cartesian coordinates of the binning of the Bokeh entry.", "response": "def axial_to_cartesian(q, r, size, orientation, aspect_scale=1):\n    ''' Map axial *(q,r)* coordinates to cartesian *(x,y)* coordinates of\n    tiles centers.\n\n    This function can be useful for positioning other Bokeh glyphs with\n    cartesian coordinates in relation to a hex tiling.\n\n    This function was adapted from:\n\n        https://www.redblobgames.com/grids/hexagons/#hex-to-pixel\n\n    Args:\n        q (array[float]) :\n            A NumPy array of q-coordinates for binning\n\n        r (array[float]) :\n            A NumPy array of r-coordinates for binning\n\n        size (float) :\n            The size of the hexagonal tiling.\n\n            The size is defined as the distance from the center of a hexagon\n            to the top corner for \"pointytop\" orientation, or from the center\n            to a side corner for \"flattop\" orientation.\n\n        orientation (str) :\n            Whether the hex tile orientation should be \"pointytop\" or\n            \"flattop\".\n\n        aspect_scale (float, optional) :\n            Scale the hexagons in the \"cross\" dimension.\n\n            For \"pointytop\" orientations, hexagons are scaled in the horizontal\n            direction. For \"flattop\", they are scaled in vertical direction.\n\n            When working with a plot with ``aspect_scale != 1``, it may be\n            useful to set this value to match the plot.\n\n    Returns:\n        (array[int], array[int])\n\n    '''\n    if orientation == \"pointytop\":\n        x = size * np.sqrt(3) * (q + r/2.0) / aspect_scale\n        y = -size * 3/2.0 * r\n    else:\n        x = size * 3/2.0 * q\n        y = -size * np.sqrt(3) * (r + q/2.0) * aspect_scale\n\n    return (x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a cartesian point to axial coordinates of the enclosing ArcGIS module.", "response": "def cartesian_to_axial(x, y, size, orientation, aspect_scale=1):\n    ''' Map Cartesion *(x,y)* points to axial *(q,r)* coordinates of enclosing\n    tiles.\n\n    This function was adapted from:\n\n        https://www.redblobgames.com/grids/hexagons/#pixel-to-hex\n\n    Args:\n        x (array[float]) :\n            A NumPy array of x-coordinates to convert\n\n        y (array[float]) :\n            A NumPy array of y-coordinates to convert\n\n        size (float) :\n            The size of the hexagonal tiling.\n\n            The size is defined as the distance from the center of a hexagon\n            to the top corner for \"pointytop\" orientation, or from the center\n            to a side corner for \"flattop\" orientation.\n\n        orientation (str) :\n            Whether the hex tile orientation should be \"pointytop\" or\n            \"flattop\".\n\n        aspect_scale (float, optional) :\n            Scale the hexagons in the \"cross\" dimension.\n\n            For \"pointytop\" orientations, hexagons are scaled in the horizontal\n            direction. For \"flattop\", they are scaled in vertical direction.\n\n            When working with a plot with ``aspect_scale != 1``, it may be\n            useful to set this value to match the plot.\n\n    Returns:\n        (array[int], array[int])\n\n    '''\n    HEX_FLAT = [2.0/3.0, 0.0, -1.0/3.0, np.sqrt(3.0)/3.0]\n    HEX_POINTY = [np.sqrt(3.0)/3.0, -1.0/3.0, 0.0, 2.0/3.0]\n\n    coords = HEX_FLAT if orientation == 'flattop' else HEX_POINTY\n\n    x =  x / size * (aspect_scale if orientation == \"pointytop\" else 1)\n    y = -y / size / (aspect_scale if orientation == \"flattop\" else 1)\n\n    q = coords[0] * x + coords[1] * y\n    r = coords[2] * x + coords[3] * y\n\n    return _round_hex(q, r)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform an equal - weight binning of data points into hexagonal tiles.", "response": "def hexbin(x, y, size, orientation=\"pointytop\", aspect_scale=1):\n    ''' Perform an equal-weight binning of data points into hexagonal tiles.\n\n    For more sophisticated use cases, e.g. weighted binning or scaling\n    individual tiles proportional to some other quantity, consider using\n    HoloViews.\n\n    Args:\n        x (array[float]) :\n            A NumPy array of x-coordinates for binning\n\n        y (array[float]) :\n            A NumPy array of y-coordinates for binning\n\n        size (float) :\n            The size of the hexagonal tiling.\n\n            The size is defined as the distance from the center of a hexagon\n            to the top corner for \"pointytop\" orientation, or from the center\n            to a side corner for \"flattop\" orientation.\n\n        orientation (str, optional) :\n            Whether the hex tile orientation should be \"pointytop\" or\n            \"flattop\". (default: \"pointytop\")\n\n        aspect_scale (float, optional) :\n            Match a plot's aspect ratio scaling.\n\n            When working with a plot with ``aspect_scale != 1``, this\n            parameter can be set to match the plot, in order to draw\n            regular hexagons (instead of \"stretched\" ones).\n\n            This is roughly equivalent to binning in \"screen space\", and\n            it may be better to use axis-aligned rectangular bins when\n            plot aspect scales are not one.\n\n    Returns:\n        DataFrame\n\n        The resulting DataFrame will have columns *q* and *r* that specify\n        hexagon tile locations in axial coordinates, and a column *counts* that\n        provides the count for each tile.\n\n    .. warning::\n        Hex binning only functions on linear scales, i.e. not on log plots.\n\n    '''\n    pd = import_required('pandas','hexbin requires pandas to be installed')\n\n    q, r = cartesian_to_axial(x, y, size, orientation, aspect_scale=aspect_scale)\n\n    df = pd.DataFrame(dict(r=r, q=q))\n    return df.groupby(['q', 'r']).size().reset_index(name='counts')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrounds floating point axial hex coordinates to integer * q * r *.", "response": "def _round_hex(q, r):\n    ''' Round floating point axial hex coordinates to integer *(q,r)*\n    coordinates.\n\n    This code was adapted from:\n\n        https://www.redblobgames.com/grids/hexagons/#rounding\n\n    Args:\n        q (array[float]) :\n            NumPy array of Floating point axial *q* coordinates to round\n\n        r (array[float]) :\n            NumPy array of Floating point axial *q* coordinates to round\n\n    Returns:\n        (array[int], array[int])\n\n    '''\n    x = q\n    z = r\n    y = -x-z\n\n    rx = np.round(x)\n    ry = np.round(y)\n    rz = np.round(z)\n\n    dx = np.abs(rx - x)\n    dy = np.abs(ry - y)\n    dz = np.abs(rz - z)\n\n    cond = (dx > dy) & (dx > dz)\n    q = np.where(cond              , -(ry + rz), rx)\n    r = np.where(~cond & ~(dy > dz), -(rx + ry), rz)\n\n    return q.astype(int), r.astype(int)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to determine the version from the parent directory name.", "response": "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\"version\": dirname[len(parentdir_prefix):],\n                    \"full-revisionid\": None,\n                    \"dirty\": False, \"error\": None, \"date\": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\"Tried directories %s but none started with prefix %s\" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_pep440_pre(pieces):\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%d\" % pieces[\"distance\"]\n    else:\n        # exception #1\n        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n    return rendered", "response": "Render the pep440 pre tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap(cls, value):\n        ''' Some property types need to wrap their values in special containers, etc.\n\n        '''\n        if isinstance(value, list):\n            if isinstance(value, PropertyValueList):\n                return value\n            else:\n                return PropertyValueList(value)\n        else:\n            return value", "response": "Wrap the value in special containers etc."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap(cls, value):\n        ''' Some property types need to wrap their values in special containers, etc.\n\n        '''\n        if isinstance(value, dict):\n            if isinstance(value, PropertyValueDict):\n                return value\n            else:\n                return PropertyValueDict(value)\n        else:\n            return value", "response": "Wrap the value in special containers etc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(self, json, models=None):\n        ''' Decodes column source data encoded as lists or base64 strings.\n        '''\n        if json is None:\n            return None\n        elif not isinstance(json, dict):\n            raise DeserializationError(\"%s expected a dict or None, got %s\" % (self, json))\n        new_data = {}\n        for key, value in json.items():\n            key = self.keys_type.from_json(key, models)\n            if isinstance(value, dict) and '__ndarray__' in value:\n                new_data[key] = decode_base64_dict(value)\n            elif isinstance(value, list) and any(isinstance(el, dict) and '__ndarray__' in el for el in value):\n                new_list = []\n                for el in value:\n                    if isinstance(el, dict) and '__ndarray__' in el:\n                        el = decode_base64_dict(el)\n                    elif isinstance(el, list):\n                        el = self.values_type.from_json(el)\n                    new_list.append(el)\n                new_data[key] = new_list\n            else:\n                new_data[key] = self.values_type.from_json(value, models)\n        return new_data", "response": "Decodes column source data encoded as lists or base64 strings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap(cls, value):\n        ''' Some property types need to wrap their values in special containers, etc.\n\n        '''\n        if isinstance(value, dict):\n            if isinstance(value, PropertyValueColumnData):\n                return value\n            else:\n                return PropertyValueColumnData(value)\n        else:\n            return value", "response": "Wrap the value in special containers etc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert any recognized timedelta value to floating point absolute milliseconds.", "response": "def convert_timedelta_type(obj):\n    ''' Convert any recognized timedelta value to floating point absolute\n    milliseconds.\n\n    Arg:\n        obj (object) : the object to convert\n\n    Returns:\n        float : milliseconds\n\n    '''\n    if isinstance(obj, dt.timedelta):\n        return obj.total_seconds() * 1000.\n    elif isinstance(obj, np.timedelta64):\n        return (obj / NP_MS_DELTA)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts any recognized date time or datetime value to floating point milliseconds since epoch.", "response": "def convert_datetime_type(obj):\n    ''' Convert any recognized date, time, or datetime value to floating point\n    milliseconds since epoch.\n\n    Arg:\n        obj (object) : the object to convert\n\n    Returns:\n        float : milliseconds\n\n    '''\n    # Pandas NaT\n    if pd and obj is pd.NaT:\n        return np.nan\n\n    # Pandas Period\n    if pd and isinstance(obj, pd.Period):\n        return obj.to_timestamp().value / 10**6.0\n\n    # Pandas Timestamp\n    if pd and isinstance(obj, _pd_timestamp): return obj.value / 10**6.0\n\n    # Pandas Timedelta\n    elif pd and isinstance(obj, pd.Timedelta): return obj.value / 10**6.0\n\n    # Datetime (datetime is a subclass of date)\n    elif isinstance(obj, dt.datetime):\n        diff = obj.replace(tzinfo=None) - DT_EPOCH\n        return diff.total_seconds() * 1000.\n\n    # Date\n    elif isinstance(obj, dt.date):\n        return (dt.datetime(*obj.timetuple()[:6]) - DT_EPOCH).total_seconds() * 1000\n\n    # NumPy datetime64\n    elif isinstance(obj, np.datetime64):\n        epoch_delta = obj - NP_EPOCH\n        return (epoch_delta / NP_MS_DELTA)\n\n    # Time\n    elif isinstance(obj, dt.time):\n        return (obj.hour * 3600 + obj.minute * 60 + obj.second) * 1000 + obj.microsecond / 1000."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts NumPy datetime arrays to milliseconds since epoch.", "response": "def convert_datetime_array(array):\n    ''' Convert NumPy datetime arrays to arrays to milliseconds since epoch.\n\n    Args:\n        array : (obj)\n            A NumPy array of datetime to convert\n\n            If the value passed in is not a NumPy array, it will be returned as-is.\n\n    Returns:\n        array\n\n    '''\n\n    if not isinstance(array, np.ndarray):\n        return array\n\n    try:\n        dt2001 = np.datetime64('2001')\n        legacy_datetime64 = (dt2001.astype('int64') ==\n                             dt2001.astype('datetime64[ms]').astype('int64'))\n    except AttributeError as e:\n        if e.args == (\"'module' object has no attribute 'datetime64'\",):\n            # for compatibility with PyPy that doesn't have datetime64\n            if 'PyPy' in sys.version:\n                legacy_datetime64 = False\n                pass\n            else:\n                raise e\n        else:\n            raise e\n\n    # not quite correct, truncates to ms..\n    if array.dtype.kind == 'M':\n        if legacy_datetime64:\n            if array.dtype == np.dtype('datetime64[ns]'):\n                array = array.astype('int64') / 10**6.0\n        else:\n            array =  array.astype('datetime64[us]').astype('int64') / 1000.\n\n    elif array.dtype.kind == 'm':\n        array = array.astype('timedelta64[us]').astype('int64') / 1000.\n\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_id():\n    ''' Return a new unique ID for a Bokeh object.\n\n    Normally this function will return simple monotonically increasing integer\n    IDs (as strings) for identifying Bokeh objects within a Document. However,\n    if it is desirable to have globally unique for every object, this behavior\n    can be overridden by setting the environment variable ``BOKEH_SIMPLE_IDS=no``.\n\n    Returns:\n        str\n\n    '''\n    global _simple_id\n\n    if settings.simple_ids(True):\n        with _simple_id_lock:\n            _simple_id += 1\n            return str(_simple_id)\n    else:\n        return make_globally_unique_id()", "response": "Returns a unique ID for a Bokeh object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform a NumPy array into a list of values", "response": "def transform_array_to_list(array):\n    ''' Transforms a NumPy array into a list of values\n\n    Args:\n        array (np.nadarray) : the NumPy array series to transform\n\n    Returns:\n        list or dict\n\n    '''\n    if (array.dtype.kind in ('u', 'i', 'f') and (~np.isfinite(array)).any()):\n        transformed = array.astype('object')\n        transformed[np.isnan(array)] = 'NaN'\n        transformed[np.isposinf(array)] = 'Infinity'\n        transformed[np.isneginf(array)] = '-Infinity'\n        return transformed.tolist()\n    elif (array.dtype.kind == 'O' and pd and pd.isnull(array).any()):\n        transformed = array.astype('object')\n        transformed[pd.isnull(array)] = 'NaN'\n        return transformed.tolist()\n    return array.tolist()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_series(series, force_list=False, buffers=None):\n    ''' Transforms a Pandas series into serialized form\n\n    Args:\n        series (pd.Series) : the Pandas series to transform\n        force_list (bool, optional) : whether to only output to standard lists\n            This function can encode some dtypes using a binary encoding, but\n            setting this argument to True will override that and cause only\n            standard Python lists to be emitted. (default: False)\n\n        buffers (set, optional) :\n            If binary buffers are desired, the buffers parameter may be\n            provided, and any columns that may be sent as binary buffers\n            will be added to the set. If None, then only base64 encoding\n            will be used (default: None)\n\n            If force_list is True, then this value will be ignored, and\n            no buffers will be generated.\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n    Returns:\n        list or dict\n\n    '''\n    # not checking for pd here, this function should only be called if it\n    # is already known that series is a Pandas Series type\n    if isinstance(series, pd.PeriodIndex):\n        vals = series.to_timestamp().values\n    else:\n        vals = series.values\n    return transform_array(vals, force_list=force_list, buffers=buffers)", "response": "Transforms a Pandas Series into a list of base64 encoded version of the entry in the tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a NumPy array into a serialized form.", "response": "def serialize_array(array, force_list=False, buffers=None):\n    ''' Transforms a NumPy array into serialized form.\n\n    Args:\n        array (np.ndarray) : the NumPy array to transform\n        force_list (bool, optional) : whether to only output to standard lists\n            This function can encode some dtypes using a binary encoding, but\n            setting this argument to True will override that and cause only\n            standard Python lists to be emitted. (default: False)\n\n        buffers (set, optional) :\n            If binary buffers are desired, the buffers parameter may be\n            provided, and any columns that may be sent as binary buffers\n            will be added to the set. If None, then only base64 encoding\n            will be used (default: None)\n\n            If force_list is True, then this value will be ignored, and\n            no buffers will be generated.\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n    Returns:\n        list or dict\n\n    '''\n    if isinstance(array, np.ma.MaskedArray):\n        array = array.filled(np.nan)  # Set masked values to nan\n    if (array_encoding_disabled(array) or force_list):\n        return transform_array_to_list(array)\n    if not array.flags['C_CONTIGUOUS']:\n        array = np.ascontiguousarray(array)\n    if buffers is None:\n        return encode_base64_dict(array)\n    else:\n        return encode_binary_dict(array, buffers)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform ColumnSourceData to a JSON compatible format", "response": "def transform_column_source_data(data, buffers=None, cols=None):\n    ''' Transform ``ColumnSourceData`` data to a serialized format\n\n    Args:\n        data (dict) : the mapping of names to data columns to transform\n\n        buffers (set, optional) :\n            If binary buffers are desired, the buffers parameter may be\n            provided, and any columns that may be sent as binary buffers\n            will be added to the set. If None, then only base64 encoding\n            will be used (default: None)\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n        cols (list[str], optional) :\n            Optional list of subset of columns to transform. If None, all\n            columns will be transformed (default: None)\n\n    Returns:\n        JSON compatible dict\n\n    '''\n    to_transform = set(data) if cols is None else set(cols)\n\n    data_copy = {}\n    for key in to_transform:\n        if pd and isinstance(data[key], (pd.Series, pd.Index)):\n            data_copy[key] = transform_series(data[key], buffers=buffers)\n        elif isinstance(data[key], np.ndarray):\n            data_copy[key] = transform_array(data[key], buffers=buffers)\n        else:\n            data_copy[key] = traverse_data(data[key], buffers=buffers)\n\n    return data_copy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode a numpy array as an unencoded binary buffer.", "response": "def encode_binary_dict(array, buffers):\n    ''' Send a numpy array as an unencoded binary buffer\n\n    The encoded format is a dict with the following structure:\n\n    .. code:: python\n\n        {\n            '__buffer__' :  << an ID to locate the buffer >>,\n            'shape'      : << array shape >>,\n            'dtype'      : << dtype name >>,\n            'order'      : << byte order at origin (little or big)>>\n        }\n\n    Args:\n        array (np.ndarray) : an array to encode\n\n        buffers (set) :\n            Set to add buffers to\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n    Returns:\n        dict\n\n    '''\n    buffer_id = make_id()\n    buf = (dict(id=buffer_id), array.tobytes())\n    buffers.append(buf)\n\n    return {\n        '__buffer__'  : buffer_id,\n        'shape'       : array.shape,\n        'dtype'       : array.dtype.name,\n        'order'       : sys.byteorder\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode a base64 encoded array into a NumPy array.", "response": "def decode_base64_dict(data):\n    ''' Decode a base64 encoded array into a NumPy array.\n\n    Args:\n        data (dict) : encoded array data to decode\n\n    Data should have the format encoded by :func:`encode_base64_dict`.\n\n    Returns:\n        np.ndarray\n\n    '''\n    b64 = base64.b64decode(data['__ndarray__'])\n    array = np.copy(np.frombuffer(b64, dtype=data['dtype']))\n    if len(data['shape']) > 1:\n        array = array.reshape(data['shape'])\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_py_func(cls, code):\n        ''' Create a ``CustomJSHover`` instance from a Python functions. The\n        function is translated to JavaScript using PScript.\n\n        The python functions must have no positional arguments. It is\n        possible to pass Bokeh models (e.g. a ``ColumnDataSource``) as keyword\n        arguments to the functions.\n\n        The ``code`` function namespace will contain the variable ``value``\n        (the untransformed value) at render time as well as ``format`` and\n        ``special_vars`` as described in the class description.\n\n        Args:\n            code (function) : a scalar function to transform a single ``value``\n\n        Returns:\n            CustomJSHover\n\n        '''\n        from bokeh.util.deprecation import deprecated\n        deprecated(\"'from_py_func' is deprecated and will be removed in an eventual 2.0 release. \"\n                   \"Use CustomJSHover directly instead.\")\n\n        if not isinstance(code, FunctionType):\n            raise ValueError('CustomJSHover.from_py_func only accepts function objects.')\n\n        pscript = import_required('pscript',\n                                  'To use Python functions for CustomJSHover, you need PScript ' +\n                                  '(\"conda install -c conda-forge pscript\" or \"pip install pscript\")')\n\n        def pscript_compile(code):\n            sig = signature(code)\n\n            all_names, default_values = get_param_info(sig)\n\n            if len(all_names) - len(default_values) != 0:\n                raise ValueError(\"Function may only contain keyword arguments.\")\n\n            if default_values and not any(isinstance(value, Model) for value in default_values):\n                raise ValueError(\"Default value must be a Bokeh Model.\")\n\n            func_kwargs = dict(zip(all_names, default_values))\n\n            # Wrap the code attr in a function named `code` and call it\n            # with arguments that match the `args` attr\n            code = pscript.py2js(code, 'transformer') + 'return transformer(%s);\\n' % ', '.join(all_names)\n            return code, func_kwargs\n\n        jsfunc, func_kwargs = pscript_compile(code)\n\n        return cls(code=jsfunc, args=func_kwargs)", "response": "Create a CustomJSHover instance from a Python function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_coffeescript(cls, code, args={}):\n        ''' Create a CustomJSHover instance from a CoffeeScript snippet. The\n        function bodies are translated to JavaScript functions using node and\n        therefore require return statements.\n\n        The ``code`` snippet namespace will contain the variable ``value`` (the\n        untransformed value) at render time as well as ``special_vars`` and\n        ``format`` as described in the class description.\n\n        Example:\n\n        .. code-block:: coffeescript\n\n            formatter = CustomJSHover.from_coffeescript(\"return value + \" total\")\n\n        Args:\n            code (str) :\n                A coffeescript snippet to transform a single ``value`` value\n\n        Returns:\n            CustomJSHover\n\n        '''\n        compiled = nodejs_compile(code, lang=\"coffeescript\", file=\"???\")\n        if \"error\" in compiled:\n            raise CompilationError(compiled.error)\n\n        return cls(code=compiled.code, args=args)", "response": "Create a CustomJSHover instance from a CoffeeScript snippet."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_node(\n        bokehjs_content,\n        html=(\n            html_visit_bokehjs_content,\n            html_depart_bokehjs_content\n        )\n    )\n    app.add_directive('bokehjs-content', BokehJSContent)", "response": "Required Sphinx extension setup function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a node for the code block", "response": "def get_codeblock_node(self, code, language):\n        \"\"\"this is copied from sphinx.directives.code.CodeBlock.run\n\n        it has been changed to accept code and language as an arguments instead\n        of reading from self\n\n        \"\"\"\n\n        # type: () -> List[nodes.Node]\n        document = self.state.document\n        location = self.state_machine.get_source_and_line(self.lineno)\n\n        linespec = self.options.get('emphasize-lines')\n        if linespec:\n            try:\n                nlines = len(code.split('\\n'))\n                hl_lines = parselinenos(linespec, nlines)\n                if any(i >= nlines for i in hl_lines):\n                    log.warning(__('line number spec is out of range(1-%d): %r') %\n                                   (nlines, self.options['emphasize-lines']),\n                                   location=location)\n\n                hl_lines = [x + 1 for x in hl_lines if x < nlines]\n            except ValueError as err:\n                return [document.reporter.warning(str(err), line=self.lineno)]\n        else:\n            hl_lines = None\n\n        if 'dedent' in self.options:\n            location = self.state_machine.get_source_and_line(self.lineno)\n            lines = code.split('\\n')\n            lines = dedent_lines(lines, self.options['dedent'], location=location)\n            code = '\\n'.join(lines)\n\n        literal = nodes.literal_block(code, code)\n        literal['language'] = language\n        literal['linenos'] = 'linenos' in self.options or \\\n                             'lineno-start' in self.options\n        literal['classes'] += self.options.get('class', [])\n        extra_args = literal['highlight_args'] = {}\n        if hl_lines is not None:\n            extra_args['hl_lines'] = hl_lines\n        if 'lineno-start' in self.options:\n            extra_args['linenostart'] = self.options['lineno-start']\n        set_source_info(self, literal)\n\n        caption = self.options.get('caption')\n        if caption:\n            try:\n                literal = container_wrapper(self, literal, caption)\n            except ValueError as exc:\n                return [document.reporter.warning(text_type(exc), line=self.lineno)]\n\n        # literal will be note_implicit_target that is linked from caption and numref.\n        # when options['name'] is provided, it should be primary ID.\n        self.add_name(literal)\n\n        return [literal]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the code language of the current page.", "response": "def get_code_language(self):\n        \"\"\"\n        This is largely copied from bokeh.sphinxext.bokeh_plot.run\n        \"\"\"\n        js_source = self.get_js_source()\n        if self.options.get(\"include_html\", False):\n            resources = get_sphinx_resources(include_bokehjs_api=True)\n            html_source = BJS_HTML.render(\n                css_files=resources.css_files,\n                js_files=resources.js_files,\n                bjs_script=js_source)\n            return [html_source, \"html\"]\n        else:\n            return [js_source, \"javascript\"]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autoload_static(model, resources, script_path):\n    ''' Return JavaScript code and a script tag that can be used to embed\n    Bokeh Plots.\n\n    The data for the plot is stored directly in the returned JavaScript code.\n\n    Args:\n        model (Model or Document) :\n\n        resources (Resources) :\n\n        script_path (str) :\n\n    Returns:\n        (js, tag) :\n            JavaScript code to be saved at ``script_path`` and a ``<script>``\n            tag to load it\n\n    Raises:\n        ValueError\n\n    '''\n    # TODO: maybe warn that it's not exactly useful, but technically possible\n    # if resources.mode == 'inline':\n    #     raise ValueError(\"autoload_static() requires non-inline resources\")\n\n    if isinstance(model, Model):\n        models = [model]\n    elif isinstance (model, Document):\n        models = model.roots\n    else:\n        raise ValueError(\"autoload_static expects a single Model or Document\")\n\n    with OutputDocumentFor(models):\n        (docs_json, [render_item]) = standalone_docs_json_and_render_items([model])\n\n    bundle = bundle_all_models() or \"\"\n    script = script_for_render_items(docs_json, [render_item])\n\n    (modelid, elementid) = list(render_item.roots.to_json().items())[0]\n\n    js = wrap_in_onload(AUTOLOAD_JS.render(\n        js_urls = resources.js_files,\n        css_urls = resources.css_files,\n        js_raw = resources.js_raw + [bundle, script],\n        css_raw = resources.css_raw_str,\n        elementid = elementid,\n    ))\n\n    tag = AUTOLOAD_TAG.render(\n        src_path = script_path,\n        elementid = elementid,\n    )\n\n    return encode_utf8(js), encode_utf8(tag)", "response": "Loads the Bokeh Plots from a single model or document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef components(models, wrap_script=True, wrap_plot_info=True, theme=FromCurdoc):\n    ''' Return HTML components to embed a Bokeh plot. The data for the plot is\n    stored directly in the returned HTML.\n\n    An example can be found in examples/embed/embed_multiple.py\n\n    The returned components assume that BokehJS resources are **already loaded**.\n    The html template in which they will be embedded needs to include the following\n    links and scripts tags. The widgets and tables resources are only necessary if\n    the components make use of widgets and tables.\n\n    .. code-block:: html\n\n        <link\n            href=\"http://cdn.pydata.org/bokeh/release/bokeh-x.y.z.min.css\"\n            rel=\"stylesheet\" type=\"text/css\">\n        <link\n            href=\"http://cdn.pydata.org/bokeh/release/bokeh-widgets-x.y.z.min.css\"\n            rel=\"stylesheet\" type=\"text/css\">\n        <link\n            href=\"http://cdn.pydata.org/bokeh/release/bokeh-tables-x.y.z.min.css\"\n            rel=\"stylesheet\" type=\"text/css\">\n\n        <script src=\"http://cdn.pydata.org/bokeh/release/bokeh-x.y.z.min.js\"></script>\n        <script src=\"http://cdn.pydata.org/bokeh/release/bokeh-widgets-x.y.z.min.js\"></script>\n        <script src=\"http://cdn.pydata.org/bokeh/release/bokeh-tables-x.y.z.min.js\"></script>\n\n    Note that in Jupyter Notebooks, it is not possible to use components and show in\n    the same notebook cell.\n\n    Args:\n        models (Model|list|dict|tuple) :\n            A single Model, a list/tuple of Models, or a dictionary of keys and Models.\n\n        wrap_script (boolean, optional) :\n            If True, the returned javascript is wrapped in a script tag.\n            (default: True)\n\n        wrap_plot_info (boolean, optional) : If True, returns ``<div>`` strings.\n            Otherwise, return dicts that can be used to build your own divs.\n            (default: True)\n\n            If False, the returned dictionary contains the following information:\n\n            .. code-block:: python\n\n                {\n                    'modelid':  'The model ID, used with Document.get_model_by_id',\n                    'elementid': 'The css identifier the BokehJS will look for to target the plot',\n                    'docid': 'Used by Bokeh to find the doc embedded in the returned script',\n                }\n\n        theme (Theme, optional) :\n            Defaults to the ``Theme`` instance in the current document.\n            Setting this to ``None`` uses the default theme or the theme\n            already specified in the document. Any other value must be an\n            instance of the ``Theme`` class.\n\n    Returns:\n        UTF-8 encoded *(script, div[s])* or *(raw_script, plot_info[s])*\n\n    Examples:\n\n        With default wrapping parameter values:\n\n        .. code-block:: python\n\n            components(plot)\n            # => (script, plot_div)\n\n            components((plot1, plot2))\n            # => (script, (plot1_div, plot2_div))\n\n            components({\"Plot 1\": plot1, \"Plot 2\": plot2})\n            # => (script, {\"Plot 1\": plot1_div, \"Plot 2\": plot2_div})\n\n    Examples:\n\n        With wrapping parameters set to ``False``:\n\n        .. code-block:: python\n\n            components(plot, wrap_script=False, wrap_plot_info=False)\n            # => (javascript, plot_dict)\n\n            components((plot1, plot2), wrap_script=False, wrap_plot_info=False)\n            # => (javascript, (plot1_dict, plot2_dict))\n\n            components({\"Plot 1\": plot1, \"Plot 2\": plot2}, wrap_script=False, wrap_plot_info=False)\n            # => (javascript, {\"Plot 1\": plot1_dict, \"Plot 2\": plot2_dict})\n\n    '''\n    # 1) Convert single items and dicts into list\n\n    was_single_object = isinstance(models, Model) or isinstance(models, Document)\n\n    models = _check_models_or_docs(models)\n\n    # now convert dict to list, saving keys in the same order\n    model_keys = None\n    dict_type = None\n    if isinstance(models, dict):\n        model_keys = models.keys()\n        dict_type = models.__class__\n        values = []\n        # don't just use .values() to ensure we are in the same order as key list\n        for k in model_keys:\n            values.append(models[k])\n        models = values\n\n    # 2) Append models to one document. Either pre-existing or new and render\n    with OutputDocumentFor(models, apply_theme=theme):\n        (docs_json, [render_item]) = standalone_docs_json_and_render_items(models)\n\n    script  = bundle_all_models() or \"\"\n    script += script_for_render_items(docs_json, [render_item])\n    if wrap_script:\n        script = wrap_in_script_tag(script)\n    script = encode_utf8(script)\n\n    def div_for_root(root):\n        return ROOT_DIV.render(root=root, macros=MACROS)\n\n    if wrap_plot_info:\n        results = list(div_for_root(root) for root in render_item.roots)\n    else:\n        results = render_item.roots\n\n    # 3) convert back to the input shape\n\n    if was_single_object:\n        result = results[0]\n    elif model_keys is not None:\n        result = dict_type(zip(model_keys, results))\n    else:\n        result = tuple(results)\n\n    return script, result", "response": "Return HTML components to embed a Bokeh plot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_html(models,\n              resources,\n              title=None,\n              template=FILE,\n              template_variables={},\n              theme=FromCurdoc,\n              suppress_callback_warning=False,\n              _always_new=False):\n    ''' Return an HTML document that embeds Bokeh Model or Document objects.\n\n    The data for the plot is stored directly in the returned HTML, with\n    support for customizing the JS/CSS resources independently and\n    customizing the jinja2 template.\n\n    Args:\n        models (Model or Document or seq[Model]) : Bokeh object or objects to render\n            typically a Model or Document\n\n        resources (Resources or tuple(JSResources or None, CSSResources or None)) :\n            A resource configuration for Bokeh JS & CSS assets.\n\n        title (str, optional) :\n            A title for the HTML document ``<title>`` tags or None. (default: None)\n\n            If None, attempt to automatically find the Document title from the given\n            plot objects.\n\n        template (Template, optional) : HTML document template (default: FILE)\n            A Jinja2 Template, see bokeh.core.templates.FILE for the required\n            template parameters\n\n        template_variables (dict, optional) : variables to be used in the Jinja2\n            template. If used, the following variable names will be overwritten:\n            title, bokeh_js, bokeh_css, plot_script, plot_div\n\n        theme (Theme, optional) :\n            Defaults to the ``Theme`` instance in the current document.\n            Setting this to ``None`` uses the default theme or the theme\n            already specified in the document. Any other value must be an\n            instance of the ``Theme`` class.\n\n        suppress_callback_warning (bool, optional) :\n            Normally generating standalone HTML from a Bokeh Document that has\n            Python callbacks will result in a warning stating that the callbacks\n            cannot function. However, this warning can be suppressed by setting\n            this value to True (default: False)\n\n    Returns:\n        UTF-8 encoded HTML\n\n    '''\n    if isinstance(models, Model):\n        models = [models]\n\n    if isinstance(models, Document):\n        models = models.roots\n\n    with OutputDocumentFor(models, apply_theme=theme, always_new=_always_new) as doc:\n        (docs_json, render_items) = standalone_docs_json_and_render_items(models, suppress_callback_warning=suppress_callback_warning)\n        title = _title_from_models(models, title)\n        bundle = bundle_for_objs_and_resources([doc], resources)\n        return html_page_for_render_items(bundle, docs_json, render_items, title=title,\n                                          template=template, template_variables=template_variables)", "response": "Returns an HTML document that embeds a Bokeh Model or Document object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a JSON block that can be used to embed a Bokeh object into a standalone Bokeh document.", "response": "def json_item(model, target=None, theme=FromCurdoc):\n    ''' Return a JSON block that can be used to embed standalone Bokeh content.\n\n    Args:\n        model (Model) :\n            The Bokeh object to embed\n\n        target (string, optional)\n            A div id to embed the model into. If None, the target id must\n            be supplied in the JavaScript call.\n\n        theme (Theme, optional) :\n            Defaults to the ``Theme`` instance in the current document.\n            Setting this to ``None`` uses the default theme or the theme\n            already specified in the document. Any other value must be an\n            instance of the ``Theme`` class.\n\n    Returns:\n        JSON-like\n\n    This function returns a JSON block that can be consumed by the BokehJS\n    function ``Bokeh.embed.embed_item``. As an example, a Flask endpoint for\n    ``/plot`` might return the following content to embed a Bokeh plot into\n    a div with id *\"myplot\"*:\n\n    .. code-block:: python\n\n        @app.route('/plot')\n        def plot():\n            p = make_plot('petal_width', 'petal_length')\n            return json.dumps(json_item(p, \"myplot\"))\n\n    Then a web page can retrieve this JSON and embed the plot by calling\n    ``Bokeh.embed.embed_item``:\n\n    .. code-block:: html\n\n        <script>\n        fetch('/plot')\n            .then(function(response) { return response.json(); })\n            .then(function(item) { Bokeh.embed.embed_item(item); })\n        </script>\n\n    Alternatively, if is more convenient to supply the target div id directly\n    in the page source, that is also possible. If `target_id` is omitted in the\n    call to this function:\n\n    .. code-block:: python\n\n        return json.dumps(json_item(p))\n\n    Then the value passed to ``embed_item`` is used:\n\n    .. code-block:: javascript\n\n        Bokeh.embed.embed_item(item, \"myplot\");\n\n    '''\n    with OutputDocumentFor([model], apply_theme=theme) as doc:\n        doc.title = \"\"\n        docs_json = standalone_docs_json([model])\n\n    doc = list(docs_json.values())[0]\n    root_id = doc['roots']['root_ids'][0]\n\n    return {\n        'target_id' : target,\n        'root_id'   : root_id,\n        'doc'       : doc,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_document_events(events, use_buffers=True):\n    ''' Create a JSON string describing a patch to be applied as well as\n    any optional buffers.\n\n    Args:\n      events : list of events to be translated into patches\n\n    Returns:\n      str, list :\n        JSON string which can be applied to make the given updates to obj\n        as well as any optional buffers\n\n    '''\n\n    json_events = []\n    references = set()\n\n    buffers = [] if use_buffers else None\n\n    for event in events:\n        json_events.append(event.generate(references, buffers))\n\n    json = {\n        'events'     : json_events,\n        'references' : references_json(references),\n    }\n\n    return serialize_json(json), buffers if use_buffers else []", "response": "Create a JSON string describing a patch to be applied to make the given updates to obj\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying the callback with the same parameters.", "response": "def _copy_with_changed_callback(self, new_callback):\n        ''' Dev API used to wrap the callback with decorators. '''\n        return PeriodicCallback(self._document, new_callback, self._period, self._id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _copy_with_changed_callback(self, new_callback):\n        ''' Dev API used to wrap the callback with decorators. '''\n        return TimeoutCallback(self._document, new_callback, self._timeout, self._id)", "response": "Copy the timeout callback with the same document and id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_cache_key(custom_models):\n    ''' Generate a key to cache a custom extension implementation with.\n\n    There is no metadata other than the Model classes, so this is the only\n    base to generate a cache key.\n\n    We build the model keys from the list of ``model.full_name``. This is\n    not ideal but possibly a better solution can be found found later.\n\n    '''\n    model_names = {model.full_name for model in custom_models.values()}\n    encoded_names = \",\".join(sorted(model_names)).encode('utf-8')\n    return hashlib.sha256(encoded_names).hexdigest()", "response": "Generate a cache key for a list of custom models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bundle_models(models):\n    custom_models = _get_custom_models(models)\n    if custom_models is None:\n        return None\n\n    key = calc_cache_key(custom_models)\n    bundle = _bundle_cache.get(key, None)\n    if bundle is None:\n        try:\n            _bundle_cache[key] = bundle = _bundle_models(custom_models)\n        except CompilationError as error:\n            print(\"Compilation failed:\", file=sys.stderr)\n            print(str(error), file=sys.stderr)\n            sys.exit(1)\n    return bundle", "response": "Create a bundle of selected models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_custom_models(models):\n    if models is None:\n        models = Model.model_class_reverse_map.values()\n\n    custom_models = OrderedDict()\n    for cls in models:\n        impl = getattr(cls, \"__implementation__\", None)\n\n        if impl is not None:\n            model = CustomModel(cls)\n            custom_models[model.full_name] = model\n\n    if not custom_models:\n        return None\n    return custom_models", "response": "Returns a dict of custom models for models with a custom __implementation__ attribute"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the compiled implementation of the supplied models.", "response": "def _compile_models(custom_models):\n    \"\"\"Returns the compiled implementation of supplied `models`. \"\"\"\n    ordered_models = sorted(custom_models.values(), key=lambda model: model.full_name)\n    custom_impls = {}\n\n    dependencies = []\n    for model in ordered_models:\n        dependencies.extend(list(model.dependencies.items()))\n\n    if dependencies:\n        dependencies = sorted(dependencies, key=lambda name_version: name_version[0])\n        _run_npmjs([\"install\", \"--no-progress\"] + [ name + \"@\" + version for (name, version) in dependencies ])\n\n    for model in ordered_models:\n        impl = model.implementation\n        compiled = _CACHING_IMPLEMENTATION(model, impl)\n        if compiled is None:\n            compiled = nodejs_compile(impl.code, lang=impl.lang, file=impl.file)\n\n        if \"error\" in compiled:\n            raise CompilationError(compiled.error)\n\n        custom_impls[model.full_name] = compiled\n\n    return custom_impls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _bundle_models(custom_models):\n    exports = []\n    modules = []\n\n    def read_json(name):\n        with io.open(join(bokehjs_dir, \"js\", name + \".json\"), encoding=\"utf-8\") as f:\n            return json.loads(f.read())\n\n    bundles = [\"bokeh\", \"bokeh-api\", \"bokeh-widgets\", \"bokeh-tables\", \"bokeh-gl\"]\n    known_modules = set(sum([ read_json(name) for name in bundles ], []))\n    custom_impls = _compile_models(custom_models)\n\n    extra_modules = {}\n\n    def resolve_modules(to_resolve, root):\n        resolved = {}\n        for module in to_resolve:\n            if module.startswith((\"./\", \"../\")):\n                def mkpath(module, ext=\"\"):\n                    return abspath(join(root, *module.split(\"/\")) + ext)\n\n                if module.endswith(exts):\n                    path = mkpath(module)\n                    if not exists(path):\n                        raise RuntimeError(\"no such module: %s\" % module)\n                else:\n                    for ext in exts:\n                        path = mkpath(module, ext)\n                        if exists(path):\n                            break\n                    else:\n                        raise RuntimeError(\"no such module: %s\" % module)\n\n                impl = FromFile(path)\n                compiled = nodejs_compile(impl.code, lang=impl.lang, file=impl.file)\n\n                if \"error\" in compiled:\n                    raise CompilationError(compiled.error)\n\n                if impl.lang == \"less\":\n                    code = _style_template % dict(css=json.dumps(compiled.code))\n                    deps = []\n                else:\n                    code = compiled.code\n                    deps = compiled.deps\n\n                sig = hashlib.sha256(code.encode('utf-8')).hexdigest()\n                resolved[module] = sig\n\n                deps_map = resolve_deps(deps, dirname(path))\n\n                if sig not in extra_modules:\n                    extra_modules[sig] = True\n                    modules.append((sig, code, deps_map))\n            else:\n                index = module + (\"\" if module.endswith(\"/\") else \"/\") + \"index\"\n                if index not in known_modules:\n                    raise RuntimeError(\"no such module: %s\" % module)\n\n        return resolved\n\n    def resolve_deps(deps, root):\n        custom_modules = set(model.module for model in custom_models.values())\n        missing = set(deps) - known_modules - custom_modules\n        return resolve_modules(missing, root)\n\n    for model in custom_models.values():\n        compiled = custom_impls[model.full_name]\n        deps_map = resolve_deps(compiled.deps, model.path)\n\n        exports.append((model.name, model.module))\n        modules.append((model.module, compiled.code, deps_map))\n\n    # sort everything by module name\n    exports = sorted(exports, key=lambda spec: spec[1])\n    modules = sorted(modules, key=lambda spec: spec[0])\n\n    for i, (module, code, deps) in enumerate(modules):\n        for name, ref in deps.items():\n            code = code.replace(\"\"\"require(\"%s\")\"\"\" % name, \"\"\"require(\"%s\")\"\"\" % ref)\n            code = code.replace(\"\"\"require('%s')\"\"\" % name, \"\"\"require('%s')\"\"\" % ref)\n        modules[i] = (module, code)\n\n    sep = \",\\n\"\n\n    exports = sep.join(_export_template % dict(name=name, module=module) for (name, module) in exports)\n    modules = sep.join(_module_template % dict(module=module, source=code) for (module, code) in modules)\n\n    content = _plugin_template % dict(prelude=_plugin_prelude, exports=exports, modules=modules)\n    return _plugin_umd % dict(content=content)", "response": "Create a JavaScript bundle with selected models."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef die(message, status=1):\n    ''' Print an error message and exit.\n\n    This function will call ``sys.exit`` with the given ``status`` and the\n    process will terminate.\n\n    Args:\n        message (str) : error message to print\n\n        status (int) : the exit status to pass to ``sys.exit``\n\n    '''\n    print(message, file=sys.stderr)\n    sys.exit(status)", "response": "Print an error message and exit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a single Bokeh application using a single handler for a script notebook or directory.", "response": "def build_single_handler_application(path, argv=None):\n    ''' Return a Bokeh application built using a single handler for a script,\n    notebook, or directory.\n\n    In general a Bokeh :class:`~bokeh.application.application.Application` may\n    have any number of handlers to initialize :class:`~bokeh.document.Document`\n    objects for new client sessions. However, in many cases only a single\n    handler is needed. This function examines the ``path`` provided, and\n    returns an ``Application`` initialized with one of the following handlers:\n\n    * :class:`~bokeh.application.handlers.script.ScriptHandler` when ``path``\n      is to a ``.py`` script.\n\n    * :class:`~bokeh.application.handlers.notebook.NotebookHandler` when\n      ``path`` is to an ``.ipynb`` Jupyter notebook.\n\n    * :class:`~bokeh.application.handlers.directory.DirectoryHandler` when\n      ``path`` is to a directory containing a ``main.py`` script.\n\n    Args:\n        path (str) : path to a file or directory for creating a Bokeh\n            application.\n\n        argv (seq[str], optional) : command line arguments to pass to the\n            application handler\n\n    Returns:\n        :class:`~bokeh.application.application.Application`\n\n    Raises:\n        RuntimeError\n\n    Notes:\n        If ``path`` ends with a file ``main.py`` then a warning will be printed\n        regarding running directory-style apps by passing the directory instead.\n\n    '''\n    argv = argv or []\n    path = os.path.abspath(path)\n\n    # There are certainly race conditions here if the file/directory is deleted\n    # in between the isdir/isfile tests and subsequent code. But it would be a\n    # failure if they were not there to begin with, too (just a different error)\n    if os.path.isdir(path):\n        handler = DirectoryHandler(filename=path, argv=argv)\n    elif os.path.isfile(path):\n        if path.endswith(\".ipynb\"):\n            handler = NotebookHandler(filename=path, argv=argv)\n        elif path.endswith(\".py\"):\n            if path.endswith(\"main.py\"):\n                warnings.warn(DIRSTYLE_MAIN_WARNING)\n            handler = ScriptHandler(filename=path, argv=argv)\n        else:\n            raise ValueError(\"Expected a '.py' script or '.ipynb' notebook, got: '%s'\" % path)\n    else:\n        raise ValueError(\"Path for Bokeh server application does not exist: %s\" % path)\n\n    if handler.failed:\n        raise RuntimeError(\"Error loading %s:\\n\\n%s\\n%s \" % (path, handler.error, handler.error_detail))\n\n    application = Application(handler)\n\n    return application"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_single_handler_applications(paths, argvs=None):\n    ''' Return a dictionary mapping routes to Bokeh applications built using\n    single handlers, for specified files or directories.\n\n    This function iterates over ``paths`` and ``argvs`` and calls\n    :func:`~bokeh.command.util.build_single_handler_application` on each\n    to generate the mapping.\n\n    Args:\n        path (seq[str]) : paths to files or directories for creating Bokeh\n            applications.\n\n        argvs (dict[str, list[str]], optional) : mapping of paths to command\n            line arguments to pass to the handler for each path\n\n    Returns:\n        dict[str, Application]\n\n    Raises:\n        RuntimeError\n\n    '''\n    applications = {}\n    argvs = {} or argvs\n\n    for path in paths:\n        application = build_single_handler_application(path, argvs.get(path, []))\n\n        route = application.handlers[0].url_path()\n\n        if not route:\n            if '/' in applications:\n                raise RuntimeError(\"Don't know the URL path to use for %s\" % (path))\n            route = '/'\n        applications[route] = application\n\n    return applications", "response": "Returns a dictionary mapping routes to Bokeh applications built using single handlers for specified files or directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndistancing between two points.", "response": "def distance(p1, p2):\n    \"\"\"Distance between (lat1, lon1) and (lat2, lon2). \"\"\"\n    R = 6371\n\n    lat1, lon1 = p1\n    lat2, lon2 = p2\n\n    phi1 = radians(lat1)\n    phi2 = radians(lat2)\n    delta_lat = radians(lat2 - lat1)\n    delta_lon = radians(lon2 - lon1)\n\n    a = haversin(delta_lat) + cos(phi1) * cos(phi2) * haversin(delta_lon)\n    return 2 * R * atan2(sqrt(a), sqrt(1 - a))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequire Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n\n    # These two are deprecated and no longer have any effect, to be removed 2.0\n    app.add_config_value('bokeh_plot_pyfile_include_dirs', [], 'html')\n    app.add_config_value('bokeh_plot_use_relative_paths', False, 'html')\n\n    app.add_directive('bokeh-plot', BokehPlotDirective)\n    app.add_config_value('bokeh_missing_google_api_key_ok', True, 'html')\n    app.connect('builder-inited', builder_inited)\n    app.connect('build-finished', build_finished)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind a socket to a port on an address.", "response": "def bind_sockets(address, port):\n    ''' Bind a socket to a port on an address.\n\n    Args:\n        address (str) :\n            An address to bind a port on, e.g. ``\"localhost\"``\n\n        port (int) :\n            A port number to bind.\n\n            Pass 0 to have the OS automatically choose a free port.\n\n    This function returns a 2-tuple with the new socket as the first element,\n    and the port that was bound as the second. (Useful when passing 0 as a port\n    number to bind any free port.)\n\n    Returns:\n        (socket, port)\n\n    '''\n    ss = netutil.bind_sockets(port=port or 0, address=address)\n    assert len(ss)\n    ports = {s.getsockname()[1] for s in ss}\n    assert len(ports) == 1, \"Multiple ports assigned??\"\n    actual_port = ports.pop()\n    if port:\n        assert actual_port == port\n    return ss, actual_port"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking a given request host against a whitelist.", "response": "def check_whitelist(host, whitelist):\n    ''' Check a given request host against a whitelist.\n\n    Args:\n        host (str) :\n            A host string to compare against a whitelist.\n\n            If the host does not specify a port, then ``\":80\"`` is implicitly\n            assumed.\n\n        whitelist (seq[str]) :\n            A list of host patterns to match against\n\n    Returns:\n        ``True``, if ``host`` matches any pattern in ``whitelist``, otherwise\n        ``False``\n\n     '''\n    if ':' not in host:\n        host = host + ':80'\n\n    if host in whitelist:\n        return True\n\n    return any(match_host(host, pattern) for pattern in whitelist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_host(host, pattern):\n    ''' Match a host string against a pattern\n\n    Args:\n        host (str)\n            A hostname to compare to the given pattern\n\n        pattern (str)\n            A string representing a hostname pattern, possibly including\n            wildcards for ip address octets or ports.\n\n    This function will return ``True`` if the hostname matches the pattern,\n    including any wildcards. If the pattern contains a port, the host string\n    must also contain a matching port.\n\n    Returns:\n        bool\n\n    Examples:\n\n        >>> match_host('192.168.0.1:80', '192.168.0.1:80')\n        True\n        >>> match_host('192.168.0.1:80', '192.168.0.1')\n        True\n        >>> match_host('192.168.0.1:80', '192.168.0.1:8080')\n        False\n        >>> match_host('192.168.0.1', '192.168.0.2')\n        False\n        >>> match_host('192.168.0.1', '192.168.*.*')\n        True\n        >>> match_host('alice', 'alice')\n        True\n        >>> match_host('alice:80', 'alice')\n        True\n        >>> match_host('alice', 'bob')\n        False\n        >>> match_host('foo.example.com', 'foo.example.com.net')\n        False\n        >>> match_host('alice', '*')\n        True\n        >>> match_host('alice', '*:*')\n        True\n        >>> match_host('alice:80', '*')\n        True\n        >>> match_host('alice:80', '*:80')\n        True\n        >>> match_host('alice:8080', '*:80')\n        False\n\n    '''\n    if ':' in host:\n        host, host_port = host.rsplit(':', 1)\n    else:\n        host_port = None\n\n    if ':' in pattern:\n        pattern, pattern_port = pattern.rsplit(':', 1)\n        if pattern_port == '*':\n            pattern_port = None\n    else:\n        pattern_port = None\n\n    if pattern_port is not None and host_port != pattern_port:\n        return False\n\n    host = host.split('.')\n    pattern = pattern.split('.')\n\n    if len(pattern) > len(host):\n        return False\n\n    for h, p in zip(host, pattern):\n        if h == p or p == '*':\n            continue\n        else:\n            return False\n    return True", "response": "Match a host string against a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef notebook_type(self, notebook_type):\n        ''' Notebook type, acceptable values are 'jupyter' as well as any names\n        defined by external notebook hooks that have been installed.\n\n        '''\n        if notebook_type is None or not isinstance(notebook_type, string_types):\n            raise ValueError(\"Notebook type must be a string\")\n        self._notebook_type = notebook_type.lower()", "response": "Sets the notebook type acceptable values are jupyter and any names\n        defined by external notebook hooks that have been installed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output_file(self, filename, title=\"Bokeh Plot\", mode=\"cdn\", root_dir=None):\n        ''' Configure output to a standalone HTML file.\n\n        Calling ``output_file`` not clear the effects of any other calls to\n        ``output_notebook``, etc. It adds an additional output destination\n        (publishing to HTML files). Any other active output modes continue\n        to be active.\n\n        Args:\n            filename (str) : a filename for saving the HTML document\n\n            title (str, optional) : a title for the HTML document\n\n            mode (str, optional) : how to include BokehJS (default: ``'cdn'``)\n\n                One of: ``'inline'``, ``'cdn'``, ``'relative(-dev)'`` or\n                ``'absolute(-dev)'``. See :class:`~bokeh.resources.Resources`\n                for more details.\n\n            root_dir (str, optional) : root dir to use for absolute resources\n                (default: None)\n\n                This value is ignored for other resource types, e.g. ``INLINE`` or ``CDN``.\n\n        .. warning::\n            The specified output file will be overwritten on every save, e.g.,\n            every time ``show()`` or ``save()`` is called.\n\n        '''\n        self._file = {\n            'filename'  : filename,\n            'resources' : Resources(mode=mode, root_dir=root_dir),\n            'title'     : title\n        }\n\n        if os.path.isfile(filename):\n            log.info(\"Session output file '%s' already exists, will be overwritten.\" % filename)", "response": "Configure output to a standalone HTML file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(obj, filename=None, resources=None, title=None, template=None, state=None, **kwargs):\n    ''' Save an HTML file with the data for the current document.\n\n    Will fall back to the default output state (or an explicitly provided\n    :class:`State` object) for ``filename``, ``resources``, or ``title`` if they\n    are not provided. If the filename is not given and not provided via output state,\n    it is derived from the script name (e.g. ``/foo/myplot.py`` will create\n    ``/foo/myplot.html``)\n\n    Args:\n        obj (LayoutDOM object) : a Layout (Row/Column), Plot or Widget object to display\n\n        filename (str, optional) : filename to save document under (default: None)\n            If None, use the default state configuration.\n\n        resources (Resources, optional) : A Resources config to use (default: None)\n            If None, use the default state configuration, if there is one.\n            otherwise use ``resources.INLINE``.\n\n        title (str, optional) : a title for the HTML document (default: None)\n            If None, use the default state title value, if there is one.\n            Otherwise, use \"Bokeh Plot\"\n\n         state (State, optional) :\n            A :class:`State` object. If None, then the current default\n            implicit state is used. (default: None).\n\n    Returns:\n        str: the filename where the HTML file is saved.\n\n    '''\n\n    if state is None:\n        state = curstate()\n\n    filename, resources, title = _get_save_args(state, filename, resources, title)\n    _save_helper(obj, filename, resources, title, template)\n    return abspath(filename)", "response": "Save an HTML file with the data for the current document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the sitemap page name to the sitemap_links list.", "response": "def html_page_context(app, pagename, templatename, context, doctree):\n    ''' Collect page names for the sitemap as HTML pages are built.\n\n    '''\n    site = context['SITEMAP_BASE_URL']\n    version = context['version']\n    app.sitemap_links.add(site + version + '/' + pagename + \".html\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a sitemap. txt from the collected HTML page links.", "response": "def build_finished(app, exception):\n    ''' Generate a ``sitemap.txt`` from the collected HTML page links.\n\n    '''\n    filename = join(app.outdir, \"sitemap.txt\")\n\n    links_iter = status_iterator(sorted(app.sitemap_links),\n                                 'adding links to sitemap... ',\n                                 'brown',\n                                 len(app.sitemap_links),\n                                 app.verbosity)\n\n    try:\n        with open(filename, 'w') as f:\n            for link in links_iter:\n                f.write(\"%s\\n\" % link)\n    except OSError as e:\n        raise SphinxError('cannot write sitemap.txt, reason: %s' % e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequiring Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.connect('html-page-context', html_page_context)\n    app.connect('build-finished',    build_finished)\n    app.sitemap_links = set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the internal state of the object.", "response": "def initialize(self, io_loop):\n        ''' Start a Bokeh Server Tornado Application on a given Tornado IOLoop.\n\n        '''\n        self._loop = io_loop\n\n        for app_context in self._applications.values():\n            app_context._loop = self._loop\n\n        self._clients = set()\n\n        self._stats_job = PeriodicCallback(self._log_stats,\n                                           self._stats_log_frequency_milliseconds)\n\n        if self._mem_log_frequency_milliseconds > 0:\n            self._mem_job = PeriodicCallback(self._log_mem,\n                                             self._mem_log_frequency_milliseconds)\n        else:\n            self._mem_job = None\n\n\n        self._cleanup_job = PeriodicCallback(self._cleanup_sessions,\n                                             self._check_unused_sessions_milliseconds)\n\n        if self._keep_alive_milliseconds > 0:\n            self._ping_job = PeriodicCallback(self._keep_alive, self._keep_alive_milliseconds)\n        else:\n            self._ping_job = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprovides a : class : ~bokeh. resources. Resources that provides BokehJS resources from.", "response": "def resources(self, absolute_url=None):\n        ''' Provide a :class:`~bokeh.resources.Resources` that specifies where\n        Bokeh application sessions should load BokehJS resources from.\n\n        Args:\n            absolute_url (bool):\n                An absolute URL prefix to use for locating resources. If None,\n                relative URLs are used (default: None)\n\n        '''\n        if absolute_url:\n            return Resources(mode=\"server\", root_url=absolute_url + self._prefix, path_versioner=StaticHandler.append_version)\n        return Resources(mode=\"server\", root_url=self._prefix, path_versioner=StaticHandler.append_version)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n        ''' Start the Bokeh Server application.\n\n        Starting the Bokeh Server Tornado application will run periodic\n        callbacks for stats logging, cleanup, pinging, etc. Additionally, any\n        startup hooks defined by the configured Bokeh applications will be run.\n\n        '''\n        self._stats_job.start()\n        if self._mem_job is not None:\n            self._mem_job.start()\n        self._cleanup_job.start()\n        if self._ping_job is not None:\n            self._ping_job.start()\n\n        for context in self._applications.values():\n            context.run_load_hook()", "response": "Start the Bokeh Server Tornado application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, wait=True):\n        ''' Stop the Bokeh Server application.\n\n        Args:\n            wait (bool): whether to wait for orderly cleanup (default: True)\n\n        Returns:\n            None\n\n        '''\n\n        # TODO should probably close all connections and shut down all sessions here\n        for context in self._applications.values():\n            context.run_unload_hook()\n\n        self._stats_job.stop()\n        if self._mem_job is not None:\n            self._mem_job.stop()\n        self._cleanup_job.stop()\n        if self._ping_job is not None:\n            self._ping_job.stop()\n\n        self._clients.clear()", "response": "Stop the Bokeh Server application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_session(self, app_path, session_id):\n        ''' Get an active a session by name application path and session ID.\n\n        Args:\n            app_path (str) :\n                The configured application path for the application to return\n                a session for.\n\n            session_id (str) :\n                The session ID of the session to retrieve.\n\n        Returns:\n            ServerSession\n\n        '''\n        if app_path not in self._applications:\n            raise ValueError(\"Application %s does not exist on this server\" % app_path)\n        return self._applications[app_path].get_session(session_id)", "response": "Returns an active session by name application path and session ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sessions(self, app_path):\n        ''' Gets all currently active sessions for an application.\n\n        Args:\n            app_path (str) :\n                The configured application path for the application to return\n                sessions for.\n\n        Returns:\n            list[ServerSession]\n\n        '''\n        if app_path not in self._applications:\n            raise ValueError(\"Application %s does not exist on this server\" % app_path)\n        return list(self._applications[app_path].sessions)", "response": "Returns all currently active sessions for an application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying a collection of Bokeh models and yield any that match the a selector.", "response": "def find(objs, selector, context=None):\n    ''' Query a collection of Bokeh models and yield any that match the\n    a selector.\n\n    Args:\n        obj (Model) : object to test\n        selector (JSON-like) : query selector\n        context (dict) : kwargs to supply callable query attributes\n\n    Yields:\n        Model : objects that match the query\n\n    Queries are specified as selectors similar to MongoDB style query\n    selectors, as described for :func:`~bokeh.core.query.match`.\n\n    Examples:\n\n        .. code-block:: python\n\n            # find all objects with type Grid\n            find(p.references(), {'type': Grid})\n\n            # find all objects with type Grid or Axis\n            find(p.references(), {OR: [\n                {'type': Grid}, {'type': Axis}\n            ]})\n\n            # same query, using IN operator\n            find(p.references(), {'type': {IN: [Grid, Axis]}})\n\n            # find all plot objects on the 'left' layout of the Plot\n            # here layout is a method that takes a plot as context\n            find(p.references(), {'layout': 'left'}, {'plot': p})\n\n    '''\n    return (obj for obj in objs if match(obj, selector, context))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests whether a given object matches a given selector.", "response": "def match(obj, selector, context=None):\n    ''' Test whether a given Bokeh model matches a given selector.\n\n    Args:\n        obj (Model) : object to test\n        selector (JSON-like) : query selector\n        context (dict) : kwargs to supply callable query attributes\n\n    Returns:\n        bool : True if the object matches, False otherwise\n\n    In general, the selectors have the form:\n\n    .. code-block:: python\n\n        { attrname : predicate }\n\n    Where a predicate is constructed from the operators ``EQ``, ``GT``, etc.\n    and is used to compare against values of model attributes named\n    ``attrname``.\n\n    For example:\n\n    .. code-block:: python\n\n        >>> from bokeh.plotting import figure\n        >>> p = figure(plot_width=400)\n\n        >>> match(p, {'plot_width': {EQ: 400}})\n        True\n\n        >>> match(p, {'plot_width': {GT: 500}})\n        False\n\n    There are two selector keys that are handled especially. The first\n    is 'type', which will do an isinstance check:\n\n    .. code-block:: python\n\n        >>> from bokeh.plotting import figure\n        >>> from bokeh.models import Axis\n        >>> p = figure()\n\n        >>> match(p.xaxis[0], {'type': Axis})\n        True\n\n        >>> match(p.title, {'type': Axis})\n        False\n\n    There is also a ``'tags'`` attribute that ``Model`` objects have, that\n    is a list of user-supplied values. The ``'tags'`` selector key can be\n    used to query against this list of tags. An object matches if any of the\n    tags in the selector match any of the tags on the object:\n\n    .. code-block:: python\n\n        >>> from bokeh.plotting import figure\n        >>> p = figure(tags = [\"my plot\", 10])\n\n        >>> match(p, {'tags': \"my plot\"})\n        True\n\n        >>> match(p, {'tags': [\"my plot\", 10]})\n        True\n\n        >>> match(p, {'tags': [\"foo\"]})\n        False\n\n    '''\n    context = context or {}\n    for key, val in selector.items():\n\n        # test attributes\n        if isinstance(key, string_types):\n\n            # special case 'type'\n            if key == \"type\":\n                # type supports IN, check for that first\n                if isinstance(val, dict) and list(val.keys()) == [IN]:\n                    if not any(isinstance(obj, x) for x in val[IN]): return False\n                # otherwise just check the type of the object against val\n                elif not isinstance(obj, val): return False\n\n            # special case 'tag'\n            elif key == 'tags':\n                if isinstance(val, string_types):\n                    if val not in obj.tags: return False\n                else:\n                    try:\n                        if not set(val) & set(obj.tags): return False\n                    except TypeError:\n                        if val not in obj.tags: return False\n\n            # if the object doesn't have the attr, it doesn't match\n            elif not hasattr(obj, key): return False\n\n            # if the value to check is a dict, recurse\n            else:\n                attr = getattr(obj, key)\n                if callable(attr):\n                    try:\n                        if not attr(val, **context): return False\n                    except:\n                        return False\n\n                elif isinstance(val, dict):\n                    if not match(attr, val, context): return False\n\n                else:\n                    if attr != val: return False\n\n        # test OR conditionals\n        elif key is OR:\n            if not _or(obj, val): return False\n\n        # test operands\n        elif key in _operators:\n            if not _operators[key](obj, val): return False\n\n        else:\n            raise ValueError(\"malformed query selector\")\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrequiring Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_config_value('bokeh_gallery_dir', join(\"docs\", \"gallery\"), 'html')\n    app.connect('config-inited', config_inited_handler)\n    app.add_directive('bokeh-gallery', BokehGalleryDirective)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default_filename(ext):\n    ''' Generate a default filename with a given extension, attempting to use\n    the filename of the currently running process, if possible.\n\n    If the filename of the current process is not available (or would not be\n    writable), then a temporary file with the given extension is returned.\n\n    Args:\n        ext (str) : the desired extension for the filename\n\n    Returns:\n        str\n\n    Raises:\n        RuntimeError\n            If the extensions requested is \".py\"\n\n    '''\n    if ext == \"py\":\n        raise RuntimeError(\"asked for a default filename with 'py' extension\")\n\n    filename = detect_current_filename()\n\n    if filename is None:\n        return temp_filename(ext)\n\n    basedir = dirname(filename) or getcwd()\n\n    if _no_access(basedir) or _shares_exec_prefix(basedir):\n        return temp_filename(ext)\n\n    name, _ = splitext(basename(filename))\n    return join(basedir, name + \".\" + ext)", "response": "Generate a default filename with a given extension."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_current_filename():\n    ''' Attempt to return the filename of the currently running Python process\n\n    Returns None if the filename cannot be detected.\n    '''\n    import inspect\n\n    filename = None\n    frame = inspect.currentframe()\n    try:\n        while frame.f_back and frame.f_globals.get('name') != '__main__':\n            frame = frame.f_back\n\n        filename = frame.f_globals.get('__file__')\n    finally:\n        del frame\n\n    return filename", "response": "Attempt to return the filename of the currently running Python process\n\n    Returns None if the filename cannot be detected."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the given base dir is not accessible or writeable", "response": "def _no_access(basedir):\n    ''' Return True if the given base dir is not accessible or writeable\n\n    '''\n    import os\n    return not os.access(basedir, os.W_OK | os.X_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _shares_exec_prefix(basedir):\n    ''' Whether a give base directory is on the system exex prefix\n\n    '''\n    import sys\n    prefix = sys.exec_prefix\n    return (prefix is not None and basedir.startswith(prefix))", "response": "Whether a give base directory is on the system exex prefix\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequires Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_node(bokeh_palette_group, html=(html_visit_bokeh_palette_group, None))\n    app.add_directive('bokeh-palette-group', BokehPaletteGroupDirective)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef other_args(cls):\n        ''' Return args for ``-o`` / ``--output`` to specify where output\n        should be written, and for a ``--args`` to pass on any additional\n        command line args to the subcommand.\n\n        Subclasses should append these to their class ``args``.\n\n        Example:\n\n            .. code-block:: python\n\n                class Foo(FileOutputSubcommand):\n\n                    args = (\n\n                        FileOutputSubcommand.files_arg(\"FOO\"),\n\n                        # more args for Foo\n\n                    ) + FileOutputSubcommand.other_args()\n\n        '''\n        return (\n            (('-o', '--output'), dict(\n                metavar='FILENAME',\n                action='append',\n                type=str,\n                help=\"Name of the output file or - for standard output.\"\n            )),\n\n            ('--args', dict(\n                metavar='COMMAND-LINE-ARGS',\n                nargs=argparse.REMAINDER,\n                help=\"Any command line arguments remaining are passed on to the application handler\",\n            )),\n        )", "response": "Return args for the other command line args for the specified base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a kwargs dict and a prefix and a default value looks for different color and alpha fields of the given prefix and fills in the default value alpha is 1. 0.", "response": "def _pop_colors_and_alpha(glyphclass, kwargs, prefix=\"\", default_alpha=1.0):\n    \"\"\"\n    Given a kwargs dict, a prefix, and a default value, looks for different\n    color and alpha fields of the given prefix, and fills in the default value\n    if it doesn't exist.\n    \"\"\"\n    result = dict()\n\n    # TODO: The need to do this and the complexity of managing this kind of\n    # thing throughout the codebase really suggests that we need to have\n    # a real stylesheet class, where defaults and Types can declaratively\n    # substitute for this kind of imperative logic.\n    color = kwargs.pop(prefix + \"color\", get_default_color())\n    for argname in (\"fill_color\", \"line_color\"):\n        if argname not in glyphclass.properties():\n            continue\n        result[argname] = kwargs.pop(prefix + argname, color)\n\n    # NOTE: text fill color should really always default to black, hard coding\n    # this here now until the stylesheet solution exists\n    if \"text_color\" in glyphclass.properties():\n        result[\"text_color\"] = kwargs.pop(prefix + \"text_color\", \"black\")\n\n    alpha = kwargs.pop(prefix + \"alpha\", default_alpha)\n    for argname in (\"fill_alpha\", \"line_alpha\", \"text_alpha\"):\n        if argname not in glyphclass.properties():\n            continue\n        result[argname] = kwargs.pop(prefix + argname, alpha)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _tool_from_string(name):\n    known_tools = sorted(_known_tools.keys())\n\n    if name in known_tools:\n        tool_fn = _known_tools[name]\n\n        if isinstance(tool_fn, string_types):\n            tool_fn = _known_tools[tool_fn]\n\n        return tool_fn()\n    else:\n        matches, text = difflib.get_close_matches(name.lower(), known_tools), \"similar\"\n\n        if not matches:\n            matches, text = known_tools, \"possible\"\n\n        raise ValueError(\"unexpected tool name '%s', %s tools are %s\" % (name, text, nice_join(matches)))", "response": "Takes a string and returns a corresponding Tool instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding tools to the object tree.", "response": "def _process_tools_arg(plot, tools, tooltips=None):\n    \"\"\" Adds tools to the plot object\n\n    Args:\n        plot (Plot): instance of a plot object\n        tools (seq[Tool or str]|str): list of tool types or string listing the\n            tool names. Those are converted using the _tool_from_string\n            function. I.e.: `wheel_zoom,box_zoom,reset`.\n        tooltips (string or seq[tuple[str, str]], optional):\n            tooltips to use to configure a HoverTool\n\n    Returns:\n        list of Tools objects added to plot, map of supplied string names to tools\n    \"\"\"\n    tool_objs = []\n    tool_map = {}\n    temp_tool_str = \"\"\n    repeated_tools = []\n\n    if isinstance(tools, (list, tuple)):\n        for tool in tools:\n            if isinstance(tool, Tool):\n                tool_objs.append(tool)\n            elif isinstance(tool, string_types):\n                temp_tool_str += tool + ','\n            else:\n                raise ValueError(\"tool should be a string or an instance of Tool class\")\n        tools = temp_tool_str\n\n    for tool in re.split(r\"\\s*,\\s*\", tools.strip()):\n        # re.split will return empty strings; ignore them.\n        if tool == \"\":\n            continue\n\n        tool_obj = _tool_from_string(tool)\n        tool_objs.append(tool_obj)\n        tool_map[tool] = tool_obj\n\n    for typename, group in itertools.groupby(\n            sorted(tool.__class__.__name__ for tool in tool_objs)):\n        if len(list(group)) > 1:\n            repeated_tools.append(typename)\n\n    if repeated_tools:\n        warnings.warn(\"%s are being repeated\" % \",\".join(repeated_tools))\n\n    if tooltips is not None:\n        for tool_obj in tool_objs:\n            if isinstance(tool_obj, HoverTool):\n                tool_obj.tooltips = tooltips\n                break\n        else:\n            tool_objs.append(HoverTool(tooltips=tooltips))\n\n    return tool_objs, tool_map"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_active_tools(toolbar, tool_map, active_drag, active_inspect, active_scroll, active_tap):\n    if active_drag in ['auto', None] or isinstance(active_drag, Tool):\n        toolbar.active_drag = active_drag\n    elif active_drag in tool_map:\n        toolbar.active_drag = tool_map[active_drag]\n    else:\n        raise ValueError(\"Got unknown %r for 'active_drag', which was not a string supplied in 'tools' argument\" % active_drag)\n\n    if active_inspect in ['auto', None] or isinstance(active_inspect, Tool) or all(isinstance(t, Tool) for t in active_inspect):\n        toolbar.active_inspect = active_inspect\n    elif active_inspect in tool_map:\n        toolbar.active_inspect = tool_map[active_inspect]\n    else:\n        raise ValueError(\"Got unknown %r for 'active_inspect', which was not a string supplied in 'tools' argument\" % active_scroll)\n\n    if active_scroll in ['auto', None] or isinstance(active_scroll, Tool):\n        toolbar.active_scroll = active_scroll\n    elif active_scroll in tool_map:\n        toolbar.active_scroll = tool_map[active_scroll]\n    else:\n        raise ValueError(\"Got unknown %r for 'active_scroll', which was not a string supplied in 'tools' argument\" % active_scroll)\n\n    if active_tap in ['auto', None] or isinstance(active_tap, Tool):\n        toolbar.active_tap = active_tap\n    elif active_tap in tool_map:\n        toolbar.active_tap = tool_map[active_tap]\n    else:\n        raise ValueError(\"Got unknown %r for 'active_tap', which was not a string supplied in 'tools' argument\" % active_tap)", "response": "Adds tools to the object holding the active_drag active_inspect active_tap and active_drag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a CustomJS instance from a Python function.", "response": "def from_py_func(cls, func):\n        \"\"\" Create a ``CustomJS`` instance from a Python function. The\n        function is translated to JavaScript using PScript.\n        \"\"\"\n        from bokeh.util.deprecation import deprecated\n        deprecated(\"'from_py_func' is deprecated and will be removed in an eventual 2.0 release. \"\n                   \"Use CustomJS directly instead.\")\n\n        if not isinstance(func, FunctionType):\n            raise ValueError('CustomJS.from_py_func needs function object.')\n        pscript = import_required('pscript',\n                                  'To use Python functions for CustomJS, you need PScript ' +\n                                  '(\"conda install -c conda-forge pscript\" or \"pip install pscript\")')\n        # Collect default values\n        default_values = func.__defaults__  # Python 2.6+\n        default_names = func.__code__.co_varnames[:len(default_values)]\n        args = dict(zip(default_names, default_values))\n        args.pop('window', None)  # Clear window, so we use the global window object\n        # Get JS code, we could rip out the function def, or just\n        # call the function. We do the latter.\n        code = pscript.py2js(func, 'cb') + 'cb(%s);\\n' % ', '.join(default_names)\n        return cls(code=code, args=args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_message(self, message, binary=False, locked=True):\n        ''' Write a message to the websocket after obtaining the appropriate\n        Bokeh Document lock.\n\n        '''\n        def write_message_unlocked():\n            if self._socket.protocol is None:\n                # Tornado is maybe supposed to do this, but in fact it\n                # tries to do _socket.protocol.write_message when protocol\n                # is None and throws AttributeError or something. So avoid\n                # trying to write to the closed socket. There doesn't seem\n                # to be an obvious public function to check if the socket\n                # is closed.\n                raise WebSocketError(\"Connection to the server has been closed\")\n\n            future = self._socket.write_message(message, binary)\n\n            # don't yield this future or we're blocking on ourselves!\n            raise gen.Return(future)\n\n        if locked:\n            with (yield self.write_lock.acquire()):\n                write_message_unlocked()\n        else:\n            write_message_unlocked()", "response": "Write a message to the websocket after obtaining the appropriate Bokeh Document lock."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncollecting all external resources set on resource_attr attribute of all models.", "response": "def _collect_external_resources(self, resource_attr):\n        \"\"\" Collect external resources set on resource_attr attribute of all models.\"\"\"\n\n        external_resources = []\n\n        for _, cls in sorted(Model.model_class_reverse_map.items(), key=lambda arg: arg[0]):\n            external = getattr(cls, resource_attr, None)\n\n            if isinstance(external, string_types):\n                if external not in external_resources:\n                    external_resources.append(external)\n            elif isinstance(external, list):\n                for e in external:\n                    if e not in external_resources:\n                        external_resources.append(e)\n\n        return external_resources"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef py_log_level(self, default='none'):\n        ''' Set the log level for python Bokeh code.\n\n        '''\n        level = self._get_str(\"PY_LOG_LEVEL\", default, \"debug\")\n        LEVELS = {'trace': logging.TRACE,\n                  'debug': logging.DEBUG,\n                  'info' : logging.INFO,\n                  'warn' : logging.WARNING,\n                  'error': logging.ERROR,\n                  'fatal': logging.CRITICAL,\n                  'none' : None}\n        return LEVELS[level]", "response": "Get the log level for Python Bokeh code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef secret_key_bytes(self):\n        ''' Return the secret_key, converted to bytes and cached.\n\n        '''\n        if not hasattr(self, '_secret_key_bytes'):\n            key = self.secret_key()\n            if key is None:\n                self._secret_key_bytes = None\n            else:\n                self._secret_key_bytes = codecs.encode(key, \"utf-8\")\n        return self._secret_key_bytes", "response": "Return the secret_key converted to bytes and cached."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bokehjssrcdir(self):\n        ''' The absolute path of the BokehJS source code in the installed\n        Bokeh source tree.\n\n        '''\n        if self._is_dev or self.debugjs:\n            bokehjssrcdir = abspath(join(ROOT_DIR, '..', 'bokehjs', 'src'))\n\n            if isdir(bokehjssrcdir):\n                return bokehjssrcdir\n\n        return None", "response": "The absolute path of the BokehJS source code in the installed\n        Bokeh source tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef css_files(self):\n        ''' The CSS files in the BokehJS directory.\n\n        '''\n        bokehjsdir = self.bokehjsdir()\n        js_files = []\n        for root, dirnames, files in os.walk(bokehjsdir):\n            for fname in files:\n                if fname.endswith(\".css\"):\n                    js_files.append(join(root, fname))\n        return js_files", "response": "Returns a list of CSS files in the BokehJS directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a serialized JSON representation of objects suitable to be sent to BokehJS.", "response": "def serialize_json(obj, pretty=None, indent=None, **kwargs):\n    ''' Return a serialized JSON representation of objects, suitable to\n    send to BokehJS.\n\n    This function is typically used to serialize single python objects in\n    the manner expected by BokehJS. In particular, many datetime values are\n    automatically normalized to an expected format. Some Bokeh objects can\n    also be passed, but note that Bokeh models are typically properly\n    serialized in the context of an entire Bokeh document.\n\n    The resulting JSON always has sorted keys. By default. the output is\n    as compact as possible unless pretty output or indentation is requested.\n\n    Args:\n        obj (obj) : the object to serialize to JSON format\n\n        pretty (bool, optional) :\n\n            Whether to generate prettified output. If ``True``, spaces are\n            added after added after separators, and indentation and newlines\n            are applied. (default: False)\n\n            Pretty output can also be enabled with the environment variable\n            ``BOKEH_PRETTY``, which overrides this argument, if set.\n\n        indent (int or None, optional) :\n\n            Amount of indentation to use in generated JSON output. If ``None``\n            then no indentation is used, unless pretty output is enabled,\n            in which case two spaces are used. (default: None)\n\n    Any additional keyword arguments are passed to ``json.dumps``, except for\n    some that  are computed internally, and cannot be overridden:\n\n    * allow_nan\n    * indent\n    * separators\n    * sort_keys\n\n    Examples:\n\n        .. code-block:: python\n\n            >>> data = dict(b=np.datetime64('2017-01-01'), a = np.arange(3))\n\n            >>>print(serialize_json(data))\n            {\"a\":[0,1,2],\"b\":1483228800000.0}\n\n            >>> print(serialize_json(data, pretty=True))\n            {\n              \"a\": [\n                0,\n                1,\n                2\n              ],\n              \"b\": 1483228800000.0\n            }\n\n    '''\n\n    # these args to json.dumps are computed internally and should not be passed along\n    for name in ['allow_nan', 'separators', 'sort_keys']:\n        if name in kwargs:\n            raise ValueError(\"The value of %r is computed internally, overriding is not permissable.\" % name)\n\n    if pretty is None:\n        pretty = settings.pretty(False)\n\n    if pretty:\n        separators=(\",\", \": \")\n    else:\n        separators=(\",\", \":\")\n\n    if pretty and indent is None:\n        indent = 2\n\n    return json.dumps(obj, cls=BokehJSONEncoder, allow_nan=False, indent=indent, separators=separators, sort_keys=True, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform_python_types(self, obj):\n        ''' Handle special scalars such as (Python, NumPy, or Pandas)\n        datetimes, or Decimal values.\n\n        Args:\n            obj (obj) :\n\n                The object to encode. Anything not specifically handled in\n                this method is passed on to the default system JSON encoder.\n\n        '''\n\n        # date/time values that get serialized as milliseconds\n        if is_datetime_type(obj):\n            return convert_datetime_type(obj)\n\n        if is_timedelta_type(obj):\n            return convert_timedelta_type(obj)\n\n        # slice objects\n        elif isinstance(obj, slice):\n            return dict(start=obj.start, stop=obj.stop, step=obj.step)\n\n        # NumPy scalars\n        elif np.issubdtype(type(obj), np.floating):\n            return float(obj)\n        elif np.issubdtype(type(obj), np.integer):\n            return int(obj)\n        elif np.issubdtype(type(obj), np.bool_):\n            return bool(obj)\n\n        # Decimal values\n        elif isinstance(obj, decimal.Decimal):\n            return float(obj)\n\n        # RelativeDelta gets serialized as a dict\n        elif rd and isinstance(obj, rd.relativedelta):\n            return dict(years=obj.years,\n                    months=obj.months,\n                    days=obj.days,\n                    hours=obj.hours,\n                    minutes=obj.minutes,\n                    seconds=obj.seconds,\n                    microseconds=obj.microseconds)\n\n        else:\n            return super(BokehJSONEncoder, self).default(obj)", "response": "Transform Python types such as datetime timedelta objects and datetime. Decimal values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, obj):\n        ''' The required ``default`` method for ``JSONEncoder`` subclasses.\n\n        Args:\n            obj (obj) :\n\n                The object to encode. Anything not specifically handled in\n                this method is passed on to the default system JSON encoder.\n\n        '''\n\n        from ..model import Model\n        from ..colors import Color\n        from .has_props import HasProps\n\n        # array types -- use force_list here, only binary\n        # encoding CDS columns for now\n        if pd and isinstance(obj, (pd.Series, pd.Index)):\n            return transform_series(obj, force_list=True)\n        elif isinstance(obj, np.ndarray):\n            return transform_array(obj, force_list=True)\n        elif isinstance(obj, collections.deque):\n            return list(map(self.default, obj))\n        elif isinstance(obj, Model):\n            return obj.ref\n        elif isinstance(obj, HasProps):\n            return obj.properties_with_values(include_defaults=False)\n        elif isinstance(obj, Color):\n            return obj.to_css()\n\n        else:\n            return self.transform_python_types(obj)", "response": "The default encoder for the JSON encoder class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, handler):\n        ''' Add a handler to the pipeline used to initialize new documents.\n\n        Args:\n            handler (Handler) : a handler for this Application to use to\n                process Documents\n\n        '''\n        self._handlers.append(handler)\n\n        # make sure there is at most one static path\n        static_paths = set(h.static_path() for h in self.handlers)\n        static_paths.discard(None)\n        if len(static_paths) > 1:\n            raise RuntimeError(\"More than one static path requested for app: %r\" % list(static_paths))\n        elif len(static_paths) == 1:\n            self._static_path = static_paths.pop()\n        else:\n            self._static_path = None", "response": "Add a handler to the pipeline used to initialize new documents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initialize_document(self, doc):\n        ''' Fills in a new document using the Application's handlers.\n\n        '''\n        for h in self._handlers:\n            # TODO (havocp) we need to check the 'failed' flag on each handler\n            # and build a composite error display. In develop mode, we want to\n            # somehow get these errors to the client.\n            h.modify_document(doc)\n            if h.failed:\n                log.error(\"Error running application handler %r: %s %s \", h, h.error, h.error_detail)\n\n        if settings.perform_document_validation():\n            doc.validate()", "response": "Initializes a new document using the handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_session_created(self, session_context):\n        ''' Invoked to execute code when a new session is created.\n\n        This method calls ``on_session_created`` on each handler, in order,\n        with the session context passed as the only argument.\n\n        May return a ``Future`` which will delay session creation until the\n        ``Future`` completes.\n\n        '''\n        for h in self._handlers:\n            result = h.on_session_created(session_context)\n            yield yield_for_all_futures(result)\n        raise gen.Return(None)", "response": "Invoked to execute code when a new session is created."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _select_helper(args, kwargs):\n    if len(args) > 1:\n        raise TypeError(\"select accepts at most ONE positional argument.\")\n\n    if len(args) > 0 and len(kwargs) > 0:\n        raise TypeError(\"select accepts EITHER a positional argument, OR keyword arguments (not both).\")\n\n    if len(args) == 0 and len(kwargs) == 0:\n        raise TypeError(\"select requires EITHER a positional argument, OR keyword arguments.\")\n\n    if args:\n        arg = args[0]\n        if isinstance(arg, dict):\n            selector = arg\n        elif isinstance(arg, string_types):\n            selector = dict(name=arg)\n        elif isinstance(arg, type) and issubclass(arg, Model):\n            selector = {\"type\": arg}\n        else:\n            raise TypeError(\"selector must be a dictionary, string or plot object.\")\n\n    elif 'selector' in kwargs:\n        if len(kwargs) == 1:\n            selector = kwargs['selector']\n        else:\n            raise TypeError(\"when passing 'selector' keyword arg, not other keyword args may be present\")\n\n    else:\n        selector = kwargs\n\n    return selector", "response": "Allow flexible selector syntax."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select(self, *args, **kwargs):\n        ''' Query this object and all of its references for objects that\n        match the given selector.\n\n        There are a few different ways to call the ``select`` method.\n        The most general is to supply a JSON-like query dictionary as the\n        single argument or as keyword arguments:\n\n        Args:\n            selector (JSON-like) : some sample text\n\n        Keyword Arguments:\n            kwargs : query dict key/values as keyword arguments\n\n        Additionally, for compatibility with ``Model.select``, a selector\n        dict may be passed as ``selector`` keyword argument, in which case\n        the value of ``kwargs['selector']`` is used for the query.\n\n        For convenience, queries on just names can be made by supplying\n        the ``name`` string as the single parameter:\n\n        Args:\n            name (str) : the name to query on\n\n        Also queries on just type can be made simply by supplying the\n        ``Model`` subclass as the single parameter:\n\n        Args:\n            type (Model) : the type to query on\n\n        Returns:\n            seq[Model]\n\n        Examples:\n\n            .. code-block:: python\n\n                # These three are equivalent\n                p.select(selector={\"type\": HoverTool})\n                p.select({\"type\": HoverTool})\n                p.select(HoverTool)\n\n                # These two are also equivalent\n                p.select({\"name\": \"mycircle\"})\n                p.select(\"mycircle\")\n\n                # Keyword arguments can be supplied in place of selector dict\n                p.select({\"name\": \"foo\", \"type\": HoverTool})\n                p.select(name=\"foo\", type=HoverTool)\n\n        '''\n\n        selector = _select_helper(args, kwargs)\n\n        # Want to pass selector that is a dictionary\n        return _list_attr_splat(find(self.references(), selector, {'plot': self}))", "response": "Query this object and all of its references for objects that have the given selector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hover(self):\n        ''' Splattable list of :class:`~bokeh.models.tools.HoverTool` objects.\n\n        '''\n        hovers = [obj for obj in self.tools if isinstance(obj, HoverTool)]\n        return _list_attr_splat(hovers)", "response": "Splattable list of HoverTool objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_layout(self, obj, place='center'):\n        ''' Adds an object to the plot in a specified place.\n\n        Args:\n            obj (Renderer) : the object to add to the Plot\n            place (str, optional) : where to add the object (default: 'center')\n                Valid places are: 'left', 'right', 'above', 'below', 'center'.\n\n        Returns:\n            None\n\n        '''\n        valid_places = ['left', 'right', 'above', 'below', 'center']\n        if place not in valid_places:\n            raise ValueError(\n                \"Invalid place '%s' specified. Valid place values are: %s\" % (place, nice_join(valid_places))\n            )\n\n        getattr(self, place).append(obj)", "response": "Adds an object to the plot in a specified place."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds tools to the plot.", "response": "def add_tools(self, *tools):\n        ''' Adds tools to the plot.\n\n        Args:\n            *tools (Tool) : the tools to add to the Plot\n\n        Returns:\n            None\n\n        '''\n        for tool in tools:\n            if not isinstance(tool, Tool):\n                raise ValueError(\"All arguments to add_tool must be Tool subclasses.\")\n\n            self.toolbar.tools.append(tool)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_glyph(self, source_or_glyph, glyph=None, **kw):\n        ''' Adds a glyph to the plot with associated data sources and ranges.\n\n        This function will take care of creating and configuring a Glyph object,\n        and then add it to the plot's list of renderers.\n\n        Args:\n            source (DataSource) : a data source for the glyphs to all use\n            glyph (Glyph) : the glyph to add to the Plot\n\n\n        Keyword Arguments:\n            Any additional keyword arguments are passed on as-is to the\n            Glyph initializer.\n\n        Returns:\n            GlyphRenderer\n\n        '''\n        if glyph is not None:\n            source = source_or_glyph\n        else:\n            source, glyph = ColumnDataSource(), source_or_glyph\n\n        if not isinstance(source, DataSource):\n            raise ValueError(\"'source' argument to add_glyph() must be DataSource subclass\")\n\n        if not isinstance(glyph, Glyph):\n            raise ValueError(\"'glyph' argument to add_glyph() must be Glyph subclass\")\n\n        g = GlyphRenderer(data_source=source, glyph=glyph, **kw)\n        self.renderers.append(g)\n        return g", "response": "Adds a glyph to the plot with associated data sources and ranges."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_tile(self, tile_source, **kw):\n        ''' Adds new ``TileRenderer`` into ``Plot.renderers``\n\n        Args:\n            tile_source (TileSource) : a tile source instance which contain tileset configuration\n\n        Keyword Arguments:\n            Additional keyword arguments are passed on as-is to the tile renderer\n\n        Returns:\n            TileRenderer : TileRenderer\n\n        '''\n        tile_renderer = TileRenderer(tile_source=tile_source, **kw)\n        self.renderers.append(tile_renderer)\n        return tile_renderer", "response": "Adds a new TileRenderer to the list of available tileset resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a row of Bokeh Layout DOMs.", "response": "def row(*args, **kwargs):\n    \"\"\" Create a row of Bokeh Layout objects. Forces all objects to\n    have the same sizing_mode, which is required for complex layouts to work.\n\n    Args:\n        children (list of :class:`~bokeh.models.layouts.LayoutDOM` ): A list of instances for\n            the row. Can be any of the following - :class:`~bokeh.models.plots.Plot`,\n            :class:`~bokeh.models.widgets.widget.Widget`,\n            :class:`~bokeh.models.layouts.Row`,\n            :class:`~bokeh.models.layouts.Column`,\n            :class:`~bokeh.models.tools.ToolbarBox`,\n            :class:`~bokeh.models.layouts.Spacer`.\n\n        sizing_mode (``\"fixed\"``, ``\"stretch_both\"``, ``\"scale_width\"``, ``\"scale_height\"``, ``\"scale_both\"`` ): How\n            will the items in the layout resize to fill the available space.\n            Default is ``\"fixed\"``. For more information on the different\n            modes see :attr:`~bokeh.models.layouts.LayoutDOM.sizing_mode`\n            description on :class:`~bokeh.models.layouts.LayoutDOM`.\n\n    Returns:\n        Row: A row of LayoutDOM objects all with the same sizing_mode.\n\n    Examples:\n\n        >>> row([plot_1, plot_2])\n        >>> row(children=[widget_box_1, plot_1], sizing_mode='stretch_both')\n    \"\"\"\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _handle_children(*args, children=children)\n\n    row_children = []\n    for item in children:\n        if isinstance(item, LayoutDOM):\n            if sizing_mode is not None and _has_auto_sizing(item):\n                item.sizing_mode = sizing_mode\n            row_children.append(item)\n        else:\n            raise ValueError(\"\"\"Only LayoutDOM items can be inserted into a row. Tried to insert: %s of type %s\"\"\" % (item, type(item)))\n\n    return Row(children=row_children, sizing_mode=sizing_mode, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef column(*args, **kwargs):\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _handle_children(*args, children=children)\n\n    col_children = []\n    for item in children:\n        if isinstance(item, LayoutDOM):\n            if sizing_mode is not None and _has_auto_sizing(item):\n                item.sizing_mode = sizing_mode\n            col_children.append(item)\n        else:\n            raise ValueError(\"\"\"Only LayoutDOM items can be inserted into a column. Tried to insert: %s of type %s\"\"\" % (item, type(item)))\n\n    return Column(children=col_children, sizing_mode=sizing_mode, **kwargs)", "response": "Create a column of Bokeh LayoutDOM objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef widgetbox(*args, **kwargs):\n\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _handle_children(*args, children=children)\n\n    col_children = []\n    for item in children:\n        if isinstance(item, LayoutDOM):\n            if sizing_mode is not None and _has_auto_sizing(item):\n                item.sizing_mode = sizing_mode\n            col_children.append(item)\n        else:\n            raise ValueError(\"\"\"Only LayoutDOM items can be inserted into a widget box. Tried to insert: %s of type %s\"\"\" % (item, type(item)))\n    return WidgetBox(children=col_children, sizing_mode=sizing_mode, **kwargs)", "response": "Create a column of bokeh widgets with predefined styling."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Bokeh layout for the given set of items.", "response": "def layout(*args, **kwargs):\n    \"\"\" Create a grid-based arrangement of Bokeh Layout objects.\n\n    Args:\n        children (list of lists of :class:`~bokeh.models.layouts.LayoutDOM` ): A list of lists of instances\n            for a grid layout. Can be any of the following - :class:`~bokeh.models.plots.Plot`,\n            :class:`~bokeh.models.widgets.widget.Widget`,\n            :class:`~bokeh.models.layouts.Row`,\n            :class:`~bokeh.models.layouts.Column`,\n            :class:`~bokeh.models.tools.ToolbarBox`,\n            :class:`~bokeh.models.layouts.Spacer`.\n\n        sizing_mode (``\"fixed\"``, ``\"stretch_both\"``, ``\"scale_width\"``, ``\"scale_height\"``, ``\"scale_both\"`` ): How\n            will the items in the layout resize to fill the available space.\n            Default is ``\"fixed\"``. For more information on the different\n            modes see :attr:`~bokeh.models.layouts.LayoutDOM.sizing_mode`\n            description on :class:`~bokeh.models.layouts.LayoutDOM`.\n\n    Returns:\n        Column: A column of ``Row`` layouts of the children, all with the same sizing_mode.\n\n    Examples:\n\n        >>> layout([[plot_1, plot_2], [plot_3, plot_4]])\n        >>> layout(\n                children=[\n                    [widget_1, plot_1],\n                    [slider],\n                    [widget_2, plot_2, plot_3]\n                ],\n                sizing_mode='fixed',\n            )\n\n    \"\"\"\n    sizing_mode = kwargs.pop('sizing_mode', None)\n    children = kwargs.pop('children', None)\n\n    children = _handle_children(*args, children=children)\n\n    # Make the grid\n    return _create_grid(children, sizing_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a grid of plots for all the items in the canvases.", "response": "def gridplot(children, sizing_mode=None, toolbar_location='above', ncols=None,\n             plot_width=None, plot_height=None, toolbar_options=None, merge_tools=True):\n    ''' Create a grid of plots rendered on separate canvases.\n\n    The ``gridplot`` function builds a single toolbar for all the plots in the\n    grid. ``gridplot`` is designed to layout a set of plots. For general\n    grid layout, use the :func:`~bokeh.layouts.layout` function.\n\n    Args:\n        children (list of lists of :class:`~bokeh.models.plots.Plot` ): An\n            array of plots to display in a grid, given as a list of lists of Plot\n            objects. To leave a position in the grid empty, pass None for that\n            position in the children list. OR list of :class:`~bokeh.models.plots.Plot` if called with\n            ncols. OR an instance of GridSpec.\n\n        sizing_mode (``\"fixed\"``, ``\"stretch_both\"``, ``\"scale_width\"``, ``\"scale_height\"``, ``\"scale_both\"`` ): How\n            will the items in the layout resize to fill the available space.\n            Default is ``\"fixed\"``. For more information on the different\n            modes see :attr:`~bokeh.models.layouts.LayoutDOM.sizing_mode`\n            description on :class:`~bokeh.models.layouts.LayoutDOM`.\n\n        toolbar_location (``above``, ``below``, ``left``, ``right`` ): Where the\n            toolbar will be located, with respect to the grid. Default is\n            ``above``. If set to None, no toolbar will be attached to the grid.\n\n        ncols (int, optional): Specify the number of columns you would like in your grid.\n            You must only pass an un-nested list of plots (as opposed to a list of lists of plots)\n            when using ncols.\n\n        plot_width (int, optional): The width you would like all your plots to be\n\n        plot_height (int, optional): The height you would like all your plots to be.\n\n        toolbar_options (dict, optional) : A dictionary of options that will be\n            used to construct the grid's toolbar (an instance of\n            :class:`~bokeh.models.tools.ToolbarBox`). If none is supplied,\n            ToolbarBox's defaults will be used.\n\n        merge_tools (``True``, ``False``): Combine tools from all child plots into\n            a single toolbar.\n\n    Returns:\n        Row or Column: A row or column containing the grid toolbar and the grid\n            of plots (depending on whether the toolbar is left/right or\n            above/below. The grid is always a Column of Rows of plots.\n\n    Examples:\n\n        >>> gridplot([[plot_1, plot_2], [plot_3, plot_4]])\n        >>> gridplot([plot_1, plot_2, plot_3, plot_4], ncols=2, plot_width=200, plot_height=100)\n        >>> gridplot(\n                children=[[plot_1, plot_2], [None, plot_3]],\n                toolbar_location='right'\n                sizing_mode='fixed',\n                toolbar_options=dict(logo='gray')\n            )\n\n    '''\n    if toolbar_options is None:\n        toolbar_options = {}\n\n    if toolbar_location:\n        if not hasattr(Location, toolbar_location):\n            raise ValueError(\"Invalid value of toolbar_location: %s\" % toolbar_location)\n\n    children = _handle_children(children=children)\n    if ncols:\n        if any(isinstance(child, list) for child in children):\n            raise ValueError(\"Cannot provide a nested list when using ncols\")\n        children = list(_chunks(children, ncols))\n\n    # Additional children set-up for grid plot\n    if not children:\n        children = []\n\n    # Make the grid\n    tools = []\n    items = []\n\n    for y, row in enumerate(children):\n        for x, item in enumerate(row):\n            if item is None:\n                continue\n            elif isinstance(item, LayoutDOM):\n                if merge_tools:\n                    for plot in item.select(dict(type=Plot)):\n                        tools += plot.toolbar.tools\n                        plot.toolbar_location = None\n\n                if isinstance(item, Plot):\n                    if plot_width is not None:\n                        item.plot_width = plot_width\n                    if plot_height is not None:\n                        item.plot_height = plot_height\n\n                if sizing_mode is not None and _has_auto_sizing(item):\n                    item.sizing_mode = sizing_mode\n\n                items.append((item, y, x))\n            else:\n                raise ValueError(\"Only LayoutDOM items can be inserted into a grid\")\n\n    if not merge_tools or not toolbar_location:\n        return GridBox(children=items, sizing_mode=sizing_mode)\n\n    grid = GridBox(children=items)\n    proxy = ProxyToolbar(tools=tools, **toolbar_options)\n    toolbar = ToolbarBox(toolbar=proxy, toolbar_location=toolbar_location)\n\n    if toolbar_location == 'above':\n        return Column(children=[toolbar, grid], sizing_mode=sizing_mode)\n    elif toolbar_location == 'below':\n        return Column(children=[grid, toolbar], sizing_mode=sizing_mode)\n    elif toolbar_location == 'left':\n        return Row(children=[toolbar, grid], sizing_mode=sizing_mode)\n    elif toolbar_location == 'right':\n        return Row(children=[grid, toolbar], sizing_mode=sizing_mode)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_grid(iterable, sizing_mode, layer=0):\n    return_list = []\n    for item in iterable:\n        if isinstance(item, list):\n            return_list.append(_create_grid(item, sizing_mode, layer+1))\n        elif isinstance(item, LayoutDOM):\n            if sizing_mode is not None and _has_auto_sizing(item):\n                item.sizing_mode = sizing_mode\n            return_list.append(item)\n        else:\n            raise ValueError(\n                \"\"\"Only LayoutDOM items can be inserted into a layout.\n                Tried to insert: %s of type %s\"\"\" % (item, type(item))\n            )\n    if layer % 2 == 0:\n        return column(children=return_list, sizing_mode=sizing_mode)\n    return row(children=return_list, sizing_mode=sizing_mode)", "response": "Recursively create a grid from input lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields successive n - sized chunks from list l.", "response": "def _chunks(l, ncols):\n    \"\"\"Yield successive n-sized chunks from list, l.\"\"\"\n    assert isinstance(ncols, int), \"ncols must be an integer\"\n    for i in range(0, len(l), ncols):\n        yield l[i: i+ncols]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps a callback function to execute without first obtaining the document lock. Args: func (callable) : The function to wrap Returns: callable : a function wrapped to execute without a |Document| lock. While inside an unlocked callback, it is completely *unsafe* to modify ``curdoc()``. The value of ``curdoc()`` inside the callback will be a specially wrapped version of |Document| that only allows safe operations, which are: * :func:`~bokeh.document.Document.add_next_tick_callback` * :func:`~bokeh.document.Document.remove_next_tick_callback` Only these may be used safely without taking the document lock. To make other changes to the document, you must add a next tick callback and make your changes to ``curdoc()`` from that second callback. Attempts to otherwise access or change the Document will result in an exception being raised.", "response": "def without_document_lock(func):\n    ''' Wrap a callback function to execute without first obtaining the\n    document lock.\n\n    Args:\n        func (callable) : The function to wrap\n\n    Returns:\n        callable : a function wrapped to execute without a |Document| lock.\n\n    While inside an unlocked callback, it is completely *unsafe* to modify\n    ``curdoc()``. The value of ``curdoc()`` inside the callback will be a\n    specially wrapped version of |Document| that only allows safe operations,\n    which are:\n\n    * :func:`~bokeh.document.Document.add_next_tick_callback`\n    * :func:`~bokeh.document.Document.remove_next_tick_callback`\n\n    Only these may be used safely without taking the document lock. To make\n    other changes to the document, you must add a next tick callback and make\n    your changes to ``curdoc()`` from that second callback.\n\n    Attempts to otherwise access or change the Document will result in an\n    exception being raised.\n\n    '''\n    @wraps(func)\n    def wrapper(*args, **kw):\n        return func(*args, **kw)\n    wrapper.nolock = True\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a script tag that embeds content from a Bokeh server.", "response": "def server_document(url=\"default\", relative_urls=False, resources=\"default\", arguments=None):\n    ''' Return a script tag that embeds content from a Bokeh server.\n\n    Bokeh apps embedded using these methods will NOT set the browser window title.\n\n    Args:\n        url (str, optional) :\n            A URL to a Bokeh application on a Bokeh server (default: \"default\")\n\n            If ``\"default\"`` the default URL ``{DEFAULT_SERVER_HTTP_URL}`` will be used.\n\n        relative_urls (bool, optional) :\n            Whether to use relative URLs for resources.\n\n            If ``True`` the links generated for resources such a BokehJS\n            JavaScript and CSS will be relative links.\n\n            This should normally be set to ``False``, but must be set to\n            ``True`` in situations where only relative URLs will work. E.g.\n            when running the Bokeh behind reverse-proxies under certain\n            configurations\n\n        resources (str) : A string specifying what resources need to be loaded\n            along with the document.\n\n            If ``default`` then the default JS/CSS bokeh files will be loaded.\n\n            If None then none of the resource files will be loaded. This is\n            useful if you prefer to serve those resource files via other means\n            (e.g. from a caching server). Be careful, however, that the resource\n            files you'll load separately are of the same version as that of the\n            server's, otherwise the rendering may not work correctly.\n\n       arguments (dict[str, str], optional) :\n            A dictionary of key/values to be passed as HTTP request arguments\n            to Bokeh application code (default: None)\n\n    Returns:\n        A ``<script>`` tag that will embed content from a Bokeh Server.\n\n    '''\n    url = _clean_url(url)\n\n    app_path = _get_app_path(url)\n\n    elementid = make_id()\n    src_path = _src_path(url, elementid)\n\n    src_path += _process_app_path(app_path)\n    src_path += _process_relative_urls(relative_urls, url)\n    src_path += _process_resources(resources)\n    src_path += _process_arguments(arguments)\n\n    tag = AUTOLOAD_TAG.render(\n        src_path  = src_path,\n        app_path  = app_path,\n        elementid = elementid,\n    )\n\n    return encode_utf8(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a script tag that embeds content from a specific existing session on a Bokeh Server.", "response": "def server_session(model=None, session_id=None, url=\"default\", relative_urls=False, resources=\"default\"):\n    ''' Return a script tag that embeds content from a specific existing session on\n    a Bokeh server.\n\n    This function is typically only useful for serving from a a specific session\n    that was previously created using the ``bokeh.client`` API.\n\n    Bokeh apps embedded using these methods will NOT set the browser window title.\n\n    .. note::\n        Typically you will not want to save or re-use the output of this\n        function for different or multiple page loads.\n\n    Args:\n        model (Model or None, optional) :\n            The object to render from the session, or None. (default: None)\n\n            If None, the entire document will be rendered.\n\n        session_id (str) :\n            A server session ID\n\n        url (str, optional) :\n            A URL to a Bokeh application on a Bokeh server (default: \"default\")\n\n            If ``\"default\"`` the default URL ``{DEFAULT_SERVER_HTTP_URL}`` will be used.\n\n        relative_urls (bool, optional) :\n            Whether to use relative URLs for resources.\n\n            If ``True`` the links generated for resources such a BokehJS\n            JavaScript and CSS will be relative links.\n\n            This should normally be set to ``False``, but must be set to\n            ``True`` in situations where only relative URLs will work. E.g.\n            when running the Bokeh behind reverse-proxies under certain\n            configurations\n\n        resources (str) : A string specifying what resources need to be loaded\n            along with the document.\n\n            If ``default`` then the default JS/CSS bokeh files will be loaded.\n\n            If None then none of the resource files will be loaded. This is\n            useful if you prefer to serve those resource files via other means\n            (e.g. from a caching server). Be careful, however, that the resource\n            files you'll load separately are of the same version as that of the\n            server's, otherwise the rendering may not work correctly.\n\n    Returns:\n        A ``<script>`` tag that will embed content from a Bokeh Server.\n\n        .. warning::\n            It is typically a bad idea to re-use the same ``session_id`` for\n            every page load. This is likely to create scalability and security\n            problems, and will cause \"shared Google doc\" behavior, which is\n            probably not desired.\n\n    '''\n    if session_id is None:\n        raise ValueError(\"Must supply a session_id\")\n\n    url = _clean_url(url)\n\n    app_path = _get_app_path(url)\n\n    elementid = make_id()\n    modelid = \"\" if model is None else model.id\n    src_path = _src_path(url, elementid)\n\n    src_path += _process_app_path(app_path)\n    src_path += _process_relative_urls(relative_urls, url)\n    src_path += _process_session_id(session_id)\n    src_path += _process_resources(resources)\n\n    tag = AUTOLOAD_TAG.render(\n        src_path  = src_path,\n        app_path  = app_path,\n        elementid = elementid,\n        modelid   = modelid,\n    )\n\n    return encode_utf8(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproduce a canonical Bokeh server URL.", "response": "def _clean_url(url):\n    ''' Produce a canonical Bokeh server URL.\n\n    Args:\n        url (str)\n            A URL to clean, or \"defatul\". If \"default\" then the\n            ``BOKEH_SERVER_HTTP_URL`` will be returned.\n\n    Returns:\n        str\n\n    '''\n    if url == 'default':\n        url = DEFAULT_SERVER_HTTP_URL\n\n    if url.startswith(\"ws\"):\n        raise ValueError(\"url should be the http or https URL for the server, not the websocket URL\")\n\n    return url.rstrip(\"/\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_app_path(url):\n    ''' Extract the app path from a Bokeh server URL\n\n    Args:\n        url (str) :\n\n    Returns:\n        str\n\n    '''\n    app_path = urlparse(url).path.rstrip(\"/\")\n    if not app_path.startswith(\"/\"):\n        app_path = \"/\" + app_path\n    return app_path", "response": "Extract the app path from a Bokeh server URL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn user - supplied HTML arguments to add to a Bokeh server URL.", "response": "def _process_arguments(arguments):\n    ''' Return user-supplied HTML arguments to add to a Bokeh server URL.\n\n    Args:\n        arguments (dict[str, object]) :\n            Key/value pairs to add to the URL\n\n    Returns:\n        str\n\n    '''\n    if arguments is None: return \"\"\n    result = \"\"\n    for key, value in arguments.items():\n        if not key.startswith(\"bokeh-\"):\n            result += \"&{}={}\".format(quote_plus(str(key)), quote_plus(str(value)))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement a check_origin policy for Tornado to call.", "response": "def check_origin(self, origin):\n        ''' Implement a check_origin policy for Tornado to call.\n\n        The supplied origin will be compared to the Bokeh server whitelist. If the\n        origin is not allow, an error will be logged and ``False`` will be returned.\n\n        Args:\n            origin (str) :\n                The URL of the connection origin\n\n        Returns:\n            bool, True if the connection is allowed, False otherwise\n\n        '''\n        from ..util import check_whitelist\n        parsed_origin = urlparse(origin)\n        origin_host = parsed_origin.netloc.lower()\n\n        allowed_hosts = self.application.websocket_origins\n        if settings.allowed_ws_origin():\n            allowed_hosts = set(settings.allowed_ws_origin())\n\n        allowed = check_whitelist(origin_host, allowed_hosts)\n        if allowed:\n            return True\n        else:\n            log.error(\"Refusing websocket connection from Origin '%s'; \\\n                      use --allow-websocket-origin=%s or set BOKEH_ALLOW_WS_ORIGIN=%s to permit this; currently we allow origins %r\",\n                      origin, origin_host, origin_host, allowed_hosts)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self):\n        ''' Initialize a connection to a client.\n\n        Returns:\n            None\n\n        '''\n        log.info('WebSocket connection opened')\n\n        proto_version = self.get_argument(\"bokeh-protocol-version\", default=None)\n        if proto_version is None:\n            self.close()\n            raise ProtocolError(\"No bokeh-protocol-version specified\")\n\n        session_id = self.get_argument(\"bokeh-session-id\", default=None)\n        if session_id is None:\n            self.close()\n            raise ProtocolError(\"No bokeh-session-id specified\")\n\n        if not check_session_id_signature(session_id,\n                                          signed=self.application.sign_sessions,\n                                          secret_key=self.application.secret_key):\n            log.error(\"Session id had invalid signature: %r\", session_id)\n            raise ProtocolError(\"Invalid session ID\")\n\n        def on_fully_opened(future):\n            e = future.exception()\n            if e is not None:\n                # this isn't really an error (unless we have a\n                # bug), it just means a client disconnected\n                # immediately, most likely.\n                log.debug(\"Failed to fully open connection %r\", e)\n\n        future = self._async_open(session_id, proto_version)\n        self.application.io_loop.add_future(future, on_fully_opened)", "response": "Initialize a connection to a client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _async_open(self, session_id, proto_version):\n        ''' Perform the specific steps needed to open a connection to a Bokeh session\n\n        Specifically, this method coordinates:\n\n        * Getting a session for a session ID (creating a new one if needed)\n        * Creating a protocol receiver and hander\n        * Opening a new ServerConnection and sending it an ACK\n\n        Args:\n            session_id (str) :\n                A session ID to for a session to connect to\n\n                If no session exists with the given ID, a new session is made\n\n            proto_version (str):\n                The protocol version requested by the connecting client.\n\n        Returns:\n            None\n\n        '''\n        try:\n            yield self.application_context.create_session_if_needed(session_id, self.request)\n            session = self.application_context.get_session(session_id)\n\n            protocol = Protocol(proto_version)\n            self.receiver = Receiver(protocol)\n            log.debug(\"Receiver created for %r\", protocol)\n\n            self.handler = ProtocolHandler()\n            log.debug(\"ProtocolHandler created for %r\", protocol)\n\n            self.connection = self.application.new_connection(protocol, self, self.application_context, session)\n            log.info(\"ServerConnection created\")\n\n        except ProtocolError as e:\n            log.error(\"Could not create new server session, reason: %s\", e)\n            self.close()\n            raise e\n\n        msg = self.connection.protocol.create('ACK')\n        yield self.send_message(msg)\n\n        raise gen.Return(None)", "response": "Open a new connection to a Bokeh session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess an individual wire protocol fragment.", "response": "def on_message(self, fragment):\n        ''' Process an individual wire protocol fragment.\n\n        The websocket RFC specifies opcodes for distinguishing text frames\n        from binary frames. Tornado passes us either a text or binary string\n        depending on that opcode, we have to look at the type of the fragment\n        to see what we got.\n\n        Args:\n            fragment (unicode or bytes) : wire fragment to process\n\n        '''\n\n        # We shouldn't throw exceptions from on_message because the caller is\n        # just Tornado and it doesn't know what to do with them other than\n        # report them as an unhandled Future\n\n        try:\n            message = yield self._receive(fragment)\n        except Exception as e:\n            # If you go look at self._receive, it's catching the\n            # expected error types... here we have something weird.\n            log.error(\"Unhandled exception receiving a message: %r: %r\", e, fragment, exc_info=True)\n            self._internal_error(\"server failed to parse a message\")\n\n        try:\n            if message:\n                if _message_test_port is not None:\n                    _message_test_port.received.append(message)\n                work = yield self._handle(message)\n                if work:\n                    yield self._schedule(work)\n        except Exception as e:\n            log.error(\"Handler or its work threw an exception: %r: %r\", e, message, exc_info=True)\n            self._internal_error(\"server failed to handle a message\")\n\n        raise gen.Return(None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the connected client.", "response": "def send_message(self, message):\n        ''' Send a Bokeh Server protocol message to the connected client.\n\n        Args:\n            message (Message) : a message to send\n\n        '''\n        try:\n            if _message_test_port is not None:\n                _message_test_port.sent.append(message)\n            yield message.send(self)\n        except (WebSocketClosedError, StreamClosedError): # Tornado 4.x may raise StreamClosedError\n            # on_close() is / will be called anyway\n            log.warning(\"Failed sending message as connection was closed\")\n        raise gen.Return(None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides parent write_message with a version that acquires a write lock before writing.", "response": "def write_message(self, message, binary=False, locked=True):\n        ''' Override parent write_message with a version that acquires a\n        write lock before writing.\n\n        '''\n        if locked:\n            with (yield self.write_lock.acquire()):\n                yield super(WSHandler, self).write_message(message, binary)\n        else:\n            yield super(WSHandler, self).write_message(message, binary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_close(self):\n        ''' Clean up when the connection is closed.\n\n        '''\n        log.info('WebSocket connection closed: code=%s, reason=%r', self.close_code, self.close_reason)\n        if self.connection is not None:\n            self.application.client_lost(self.connection)", "response": "Clean up when the connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bundle_for_objs_and_resources(objs, resources):\n    ''' Generate rendered CSS and JS resources suitable for the given\n    collection of Bokeh objects\n\n    Args:\n        objs (seq[Model or Document]) :\n\n        resources (BaseResources or tuple[BaseResources])\n\n    Returns:\n        tuple\n\n    '''\n    if isinstance(resources, BaseResources):\n        js_resources = css_resources = resources\n    elif isinstance(resources, tuple) and len(resources) == 2 and all(r is None or isinstance(r, BaseResources) for r in resources):\n        js_resources, css_resources = resources\n\n        if js_resources and not css_resources:\n            warn('No Bokeh CSS Resources provided to template. If required you will need to provide them manually.')\n\n        if css_resources and not js_resources:\n            warn('No Bokeh JS Resources provided to template. If required you will need to provide them manually.')\n    else:\n        raise ValueError(\"expected Resources or a pair of optional Resources, got %r\" % resources)\n\n    from copy import deepcopy\n\n    # XXX: force all components on server and in notebook, because we don't know in advance what will be used\n    use_widgets = _use_widgets(objs) if objs else True\n    use_tables  = _use_tables(objs)  if objs else True\n    use_gl      = _use_gl(objs)      if objs else True\n\n    if js_resources:\n        js_resources = deepcopy(js_resources)\n        if not use_widgets and \"bokeh-widgets\" in js_resources.js_components:\n            js_resources.js_components.remove(\"bokeh-widgets\")\n        if not use_tables and \"bokeh-tables\" in js_resources.js_components:\n            js_resources.js_components.remove(\"bokeh-tables\")\n        if not use_gl and \"bokeh-gl\" in js_resources.js_components:\n            js_resources.js_components.remove(\"bokeh-gl\")\n        bokeh_js = js_resources.render_js()\n    else:\n        bokeh_js = None\n\n    models = [ obj.__class__ for obj in _all_objs(objs) ] if objs else None\n    custom_bundle = bundle_models(models)\n\n    if custom_bundle is not None:\n        custom_bundle = wrap_in_script_tag(custom_bundle)\n\n        if bokeh_js is not None:\n            bokeh_js += \"\\n\" + custom_bundle\n        else:\n            bokeh_js = custom_bundle\n\n    if css_resources:\n        css_resources = deepcopy(css_resources)\n        if not use_widgets and \"bokeh-widgets\" in css_resources.css_components:\n            css_resources.css_components.remove(\"bokeh-widgets\")\n        if not use_tables and \"bokeh-tables\" in css_resources.css_components:\n            css_resources.css_components.remove(\"bokeh-tables\")\n        bokeh_css = css_resources.render_css()\n    else:\n        bokeh_css = None\n\n    return bokeh_js, bokeh_css", "response": "Generates rendered CSS and JS resources suitable for the given Bokeh objects and resources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _use_widgets(objs):\n    ''' Whether a collection of Bokeh objects contains a any Widget\n\n    Args:\n        objs (seq[Model or Document]) :\n\n    Returns:\n        bool\n\n    '''\n    from ..models.widgets import Widget\n    return _any(objs, lambda obj: isinstance(obj, Widget))", "response": "Whether a collection of Bokeh objects contains a any Widget"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_prop_descriptor_to_class(self, class_name, new_class_attrs, names_with_refs, container_names, dataspecs):\n        ''' ``MetaHasProps`` calls this during class creation as it iterates\n        over properties to add, to update its registry of new properties.\n\n        The parameters passed in are mutable and this function is expected to\n        update them accordingly.\n\n        Args:\n            class_name (str) :\n                name of the class this descriptor is added to\n\n            new_class_attrs(dict[str, PropertyDescriptor]) :\n                mapping of attribute names to PropertyDescriptor that this\n                function will update\n\n            names_with_refs (set[str]) :\n                set of all property names for properties that also have\n                references, that this function will update\n\n            container_names (set[str]) :\n                set of all property names for properties that are\n                container props, that this function will update\n\n            dataspecs(dict[str, PropertyDescriptor]) :\n                mapping of attribute names to PropertyDescriptor for DataSpec\n                properties that this function will update\n\n        Return:\n            None\n\n        '''\n        from .bases import ContainerProperty\n        from .dataspec import DataSpec\n        name = self.name\n        if name in new_class_attrs:\n            raise RuntimeError(\"Two property generators both created %s.%s\" % (class_name, name))\n        new_class_attrs[name] = self\n\n        if self.has_ref:\n            names_with_refs.add(name)\n\n        if isinstance(self, BasicPropertyDescriptor):\n            if isinstance(self.property, ContainerProperty):\n                container_names.add(name)\n\n            if isinstance(self.property, DataSpec):\n                dataspecs[name] = self", "response": "MetaHasProps calls this during class creation as it iterates over properties to add to the registry of new properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nproduce the value as it should be serialized.", "response": "def serializable_value(self, obj):\n        ''' Produce the value as it should be serialized.\n\n        Sometimes it is desirable for the serialized value to differ from\n        the ``__get__`` in order for the ``__get__`` value to appear simpler\n        for user or developer convenience.\n\n        Args:\n            obj (HasProps) : the object to get the serialized attribute for\n\n        Returns:\n            JSON-like\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n        return self.property.serialize_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value of this property from a JSON value.", "response": "def set_from_json(self, obj, json, models=None, setter=None):\n        '''Sets the value of this property from a JSON value.\n\n        Args:\n            obj: (HasProps) : instance to set the property value on\n\n            json: (JSON-value) : value to set to the attribute to\n\n            models (dict or None, optional) :\n                Mapping of model ids to models (default: None)\n\n                This is needed in cases where the attributes to update also\n                have values that have references.\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        self._internal_set(obj, json, setter=setter)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef instance_default(self, obj):\n        ''' Get the default value that will be used for a specific instance.\n\n        Args:\n            obj (HasProps) : The instance to get the default value for.\n\n        Returns:\n            object\n\n        '''\n        return self.property.themed_default(obj.__class__, self.name, obj.themed_values())", "response": "Get the default value that will be used for a specific instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value of this property from a JSON value.", "response": "def set_from_json(self, obj, json, models=None, setter=None):\n        ''' Sets the value of this property from a JSON value.\n\n        This method first\n\n        Args:\n            obj (HasProps) :\n\n            json (JSON-dict) :\n\n            models(seq[Model], optional) :\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        return super(BasicPropertyDescriptor, self).set_from_json(obj,\n                                                        self.property.from_json(json, models),\n                                                        models, setter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a change event notification if the property is set to a value is not equal to old.", "response": "def trigger_if_changed(self, obj, old):\n        ''' Send a change event notification if the property is set to a\n        value is not equal to ``old``.\n\n        Args:\n            obj (HasProps)\n                The object the property is being set on.\n\n            old (obj) :\n                The previous value of the property to compare\n\n        Returns:\n            None\n\n        '''\n        new_value = self.__get__(obj, obj.__class__)\n        if not self.property.matches(old, new_value):\n            self._trigger(obj, old, new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get(self, obj):\n        ''' Internal implementation of instance attribute access for the\n        ``BasicPropertyDescriptor`` getter.\n\n        If the value has not been explicitly set by a user, return that\n        value. Otherwise, return the default.\n\n        Args:\n            obj (HasProps) : the instance to get a value of this property for\n\n        Returns:\n            object\n\n        Raises:\n            RuntimeError\n                If the |HasProps| instance has not yet been initialized, or if\n                this descriptor is on a class that is not a |HasProps|.\n\n        '''\n        if not hasattr(obj, '_property_values'):\n            raise RuntimeError(\"Cannot get a property value '%s' from a %s instance before HasProps.__init__\" %\n                               (self.name, obj.__class__.__name__))\n\n        if self.name not in obj._property_values:\n            return self._get_default(obj)\n        else:\n            return obj._property_values[self.name]", "response": "Internal implementation of the base class attribute getter for the\n            class attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_default(self, obj):\n        ''' Internal implementation of instance attribute access for default\n        values.\n\n        Handles bookeeping around |PropertyContainer| value, etc.\n\n        '''\n        if self.name in obj._property_values:\n            # this shouldn't happen because we should have checked before _get_default()\n            raise RuntimeError(\"Bokeh internal error, does not handle the case of self.name already in _property_values\")\n\n        is_themed = obj.themed_values() is not None and self.name in obj.themed_values()\n\n        default = self.instance_default(obj)\n\n        if is_themed:\n            unstable_dict = obj._unstable_themed_values\n        else:\n            unstable_dict = obj._unstable_default_values\n\n        if self.name in unstable_dict:\n            return unstable_dict[self.name]\n\n        if self.property._may_have_unstable_default():\n            if isinstance(default, PropertyValueContainer):\n                default._register_owner(obj, self)\n            unstable_dict[self.name] = default\n\n        return default", "response": "Internal implementation of instance attribute access for defaultama values. Handles bookeeping around |PropertyContainer| value etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _notify_mutated(self, obj, old, hint=None):\n        ''' A method to call when a container is mutated \"behind our back\"\n        and we detect it with our |PropertyContainer| wrappers.\n\n        Args:\n            obj (HasProps) :\n                The object who's container value was mutated\n\n            old (object) :\n                The \"old\" value of the container\n\n                In this case, somewhat weirdly, ``old`` is a copy and the\n                new value should already be set unless we change it due to\n                validation.\n\n            hint (event hint or None, optional)\n                An optional update event hint, e.g. ``ColumnStreamedEvent``\n                (default: None)\n\n                Update event hints are usually used at times when better\n                update performance can be obtained by special-casing in\n                some way (e.g. streaming or patching column data sources)\n\n        Returns:\n            None\n\n        '''\n        value = self.__get__(obj, obj.__class__)\n\n        # re-validate because the contents of 'old' have changed,\n        # in some cases this could give us a new object for the value\n        value = self.property.prepare_value(obj, self.name, value)\n\n        self._real_set(obj, old, value, hint=hint)", "response": "A method to call when a container is mutated behind our back"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _trigger(self, obj, old, value, hint=None, setter=None):\n        ''' Unconditionally send a change event notification for the property.\n\n        Args:\n            obj (HasProps)\n                The object the property is being set on.\n\n            old (obj) :\n                The previous value of the property\n\n            new (obj) :\n                The new value of the property\n\n            hint (event hint or None, optional)\n                An optional update event hint, e.g. ``ColumnStreamedEvent``\n                (default: None)\n\n                Update event hints are usually used at times when better\n                update performance can be obtained by special-casing in\n                some way (e.g. streaming or patching column data sources)\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n\n        Returns:\n            None\n\n        '''\n        if hasattr(obj, 'trigger'):\n            obj.trigger(self.name, old, value, hint, setter)", "response": "Internal method that sends a change event notification for the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_from_json(self, obj, json, models=None, setter=None):\n        ''' Sets the value of this property from a JSON value.\n\n        This method first\n\n        Args:\n            obj (HasProps) :\n\n            json (JSON-dict) :\n\n            models(seq[Model], optional) :\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        if isinstance(json, dict):\n            # we want to try to keep the \"format\" of the data spec as string, dict, or number,\n            # assuming the serialized dict is compatible with that.\n            old = getattr(obj, self.name)\n            if old is not None:\n                try:\n                    self.property._type.validate(old, False)\n                    if 'value' in json:\n                        json = json['value']\n                except ValueError:\n                    if isinstance(old, string_types) and 'field' in json:\n                        json = json['field']\n                # leave it as a dict if 'old' was a dict\n\n        super(DataSpecPropertyDescriptor, self).set_from_json(obj, json, models, setter)", "response": "Sets the value of this property from a JSON value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_from_json(self, obj, json, models=None, setter=None):\n        ''' Sets the value of this property from a JSON value.\n\n        This method first separately extracts and removes any ``units`` field\n        in the JSON, and sets the associated units property directly. The\n        remaining JSON is then passed to the superclass ``set_from_json`` to\n        be handled.\n\n        Args:\n            obj: (HasProps) : instance to set the property value on\n\n            json: (JSON-value) : value to set to the attribute to\n\n            models (dict or None, optional) :\n                Mapping of model ids to models (default: None)\n\n                This is needed in cases where the attributes to update also\n                have values that have references.\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        json = self._extract_units(obj, json)\n        super(UnitsSpecPropertyDescriptor, self).set_from_json(obj, json, models, setter)", "response": "Sets the value of this property from a JSON value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_notebook_hook(notebook_type, load, show_doc, show_app, overwrite=False):\n    ''' Install a new notebook display hook.\n\n    Bokeh comes with support for Jupyter notebooks built-in. However, there are\n    other kinds of notebooks in use by different communities. This function\n    provides a mechanism for other projects to instruct Bokeh how to display\n    content in other notebooks.\n\n    This function is primarily of use to developers wishing to integrate Bokeh\n    with new notebook types.\n\n    Args:\n        notebook_type (str) :\n            A name for the notebook type, e.e. ``'Jupyter'`` or ``'Zeppelin'``\n\n            If the name has previously been installed, a ``RuntimeError`` will\n            be raised, unless ``overwrite=True``\n\n        load (callable) :\n            A function for loading BokehJS in a notebook type. The function\n            will be called with the following arguments:\n\n            .. code-block:: python\n\n                load(\n                    resources,   # A Resources object for how to load BokehJS\n                    verbose,     # Whether to display verbose loading banner\n                    hide_banner, # Whether to hide the output banner entirely\n                    load_timeout # Time after which to report a load fail error\n                )\n\n        show_doc (callable) :\n            A function for displaying Bokeh standalone documents in the\n            notebook type. This function will be called with the following\n            arguments:\n\n            .. code-block:: python\n\n                show_doc(\n                    obj,            # the Bokeh object to display\n                    state,          # current bokeh.io \"state\"\n                    notebook_handle # whether a notebook handle was requested\n                )\n\n            If the notebook platform is capable of supporting in-place updates\n            to plots then this function may return an opaque notebook handle\n            that can  be used for that purpose. The handle will be returned by\n            ``show()``, and can be used by as appropriate to update plots, etc.\n            by additional functions in the library that installed the hooks.\n\n        show_app (callable) :\n            A function for displaying Bokeh applications in the notebook\n            type. This function will be called with the following arguments:\n\n            .. code-block:: python\n\n                show_app(\n                    app,          # the Bokeh Application to display\n                    state,        # current bokeh.io \"state\"\n                    notebook_url, # URL to the current active notebook page\n                    **kw          # any backend-specific keywords passed as-is\n                )\n\n        overwrite (bool, optional) :\n            Whether to allow an existing hook to be overwritten by a new\n            definition (default: False)\n\n    Returns:\n        None\n\n    Raises:\n        RuntimeError\n            If ``notebook_type`` is already installed and ``overwrite=False``\n\n    '''\n    if notebook_type in _HOOKS and not overwrite:\n        raise RuntimeError(\"hook for notebook type %r already exists\" % notebook_type)\n    _HOOKS[notebook_type] = dict(load=load, doc=show_doc, app=show_app)", "response": "Installs a new notebook display hook for the given notebook type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push_notebook(document=None, state=None, handle=None):\n    ''' Update Bokeh plots in a Jupyter notebook output cells with new data\n    or property values.\n\n    When working the the notebook, the ``show`` function can be passed the\n    argument ``notebook_handle=True``, which will cause it to return a\n    handle object that can be used to update the Bokeh output later. When\n    ``push_notebook`` is called, any property updates (e.g. plot titles or\n    data source values, etc.) since the last call to ``push_notebook`` or\n    the original ``show`` call are applied to the Bokeh output in the\n    previously rendered Jupyter output cell.\n\n    Several example notebooks can be found in the GitHub repository in\n    the :bokeh-tree:`examples/howto/notebook_comms` directory.\n\n    Args:\n\n        document (Document, optional) :\n            A :class:`~bokeh.document.Document` to push from. If None,\n            uses ``curdoc()``. (default: None)\n\n        state (State, optional) :\n            A :class:`State` object. If None, then the current default\n            state (set by ``output_file``, etc.) is used. (default: None)\n\n    Returns:\n        None\n\n    Examples:\n\n        Typical usage is typically similar to this:\n\n        .. code-block:: python\n\n            from bokeh.plotting import figure\n            from bokeh.io import output_notebook, push_notebook, show\n\n            output_notebook()\n\n            plot = figure()\n            plot.circle([1,2,3], [4,6,5])\n\n            handle = show(plot, notebook_handle=True)\n\n            # Update the plot title in the earlier cell\n            plot.title.text = \"New Title\"\n            push_notebook(handle=handle)\n\n    '''\n    from ..protocol import Protocol\n\n    if state is None:\n        state = curstate()\n\n    if not document:\n        document = state.document\n\n    if not document:\n        warn(\"No document to push\")\n        return\n\n    if handle is None:\n        handle = state.last_comms_handle\n\n    if not handle:\n        warn(\"Cannot find a last shown plot to update. Call output_notebook() and show(..., notebook_handle=True) before push_notebook()\")\n        return\n\n    events = list(handle.doc._held_events)\n\n    # This is to avoid having an exception raised for attempting to create a\n    # PATCH-DOC with no events. In the notebook, we just want to silently\n    # ignore calls to push_notebook when there are no new events\n    if len(events) == 0:\n        return\n\n    handle.doc._held_events = []\n    msg = Protocol(\"1.0\").create(\"PATCH-DOC\", events)\n\n    handle.comms.send(msg.header_json)\n    handle.comms.send(msg.metadata_json)\n    handle.comms.send(msg.content_json)\n    for header, payload in msg.buffers:\n        handle.comms.send(json.dumps(header))\n        handle.comms.send(buffers=[payload])", "response": "Pushes a new Jupyter notebook output cell with new data or property values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns an installed notebook hook with supplied arguments.", "response": "def run_notebook_hook(notebook_type, action, *args, **kw):\n    ''' Run an installed notebook hook with supplied arguments.\n\n    Args:\n        noteboook_type (str) :\n            Name of an existing installed notebook hook\n\n        actions (str) :\n            Name of the hook action to execute, ``'doc'`` or ``'app'``\n\n    All other arguments and keyword arguments are passed to the hook action\n    exactly as supplied.\n\n    Returns:\n        Result of the hook action, as-is\n\n    Raises:\n        RuntimeError\n            If the hook or specific action is not installed\n\n    '''\n    if notebook_type not in _HOOKS:\n        raise RuntimeError(\"no display hook installed for notebook type %r\" % notebook_type)\n    if _HOOKS[notebook_type][action] is None:\n        raise RuntimeError(\"notebook hook for %r did not install %r action\" % notebook_type, action)\n    return _HOOKS[notebook_type][action](*args, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef destroy_server(server_id):\n    ''' Given a UUID id of a div removed or replaced in the Jupyter\n    notebook, destroy the corresponding server sessions and stop it.\n\n    '''\n    server = curstate().uuid_to_server.get(server_id, None)\n    if server is None:\n        log.debug(\"No server instance found for uuid: %r\" % server_id)\n        return\n\n    try:\n        for session in server.get_sessions():\n            session.destroy()\n        server.stop()\n        del curstate().uuid_to_server[server_id]\n\n    except Exception as e:\n        log.debug(\"Could not destroy server for id %r: %s\" % (server_id, e))", "response": "Destroy the server instance with the given UUID id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing the IPython notebook for displaying Bokeh JS and CSS plots.", "response": "def load_notebook(resources=None, verbose=False, hide_banner=False, load_timeout=5000):\n    ''' Prepare the IPython notebook for displaying Bokeh plots.\n\n    Args:\n        resources (Resource, optional) :\n            how and where to load BokehJS from (default: CDN)\n\n        verbose (bool, optional) :\n            whether to report detailed settings (default: False)\n\n        hide_banner (bool, optional):\n            whether to hide the Bokeh banner (default: False)\n\n        load_timeout (int, optional) :\n            Timeout in milliseconds when plots assume load timed out (default: 5000)\n\n    .. warning::\n        Clearing the output cell containing the published BokehJS\n        resources HTML code may cause Bokeh CSS styling to be removed.\n\n    Returns:\n        None\n\n    '''\n\n    global _NOTEBOOK_LOADED\n\n    from .. import __version__\n    from ..core.templates import NOTEBOOK_LOAD\n    from ..util.serialization import make_id\n    from ..resources import CDN\n    from ..util.compiler import bundle_all_models\n\n    if resources is None:\n        resources = CDN\n\n    if not hide_banner:\n\n        if resources.mode == 'inline':\n            js_info = 'inline'\n            css_info = 'inline'\n        else:\n            js_info = resources.js_files[0] if len(resources.js_files) == 1 else resources.js_files\n            css_info = resources.css_files[0] if len(resources.css_files) == 1 else resources.css_files\n\n        warnings = [\"Warning: \" + msg['text'] for msg in resources.messages if msg['type'] == 'warn']\n        if _NOTEBOOK_LOADED and verbose:\n            warnings.append('Warning: BokehJS previously loaded')\n\n        element_id = make_id()\n\n        html = NOTEBOOK_LOAD.render(\n            element_id    = element_id,\n            verbose       = verbose,\n            js_info       = js_info,\n            css_info      = css_info,\n            bokeh_version = __version__,\n            warnings      = warnings,\n        )\n\n    else:\n        element_id = None\n\n    _NOTEBOOK_LOADED = resources\n\n    custom_models_js = bundle_all_models() or \"\"\n\n    nb_js = _loading_js(resources, element_id, custom_models_js, load_timeout, register_mime=True)\n    jl_js = _loading_js(resources, element_id, custom_models_js, load_timeout, register_mime=False)\n\n    if not hide_banner:\n        publish_display_data({'text/html': html})\n    publish_display_data({\n        JS_MIME_TYPE   : nb_js,\n        LOAD_MIME_TYPE : jl_js\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_app(app, state, notebook_url, port=0, **kw):\n    ''' Embed a Bokeh server application in a Jupyter Notebook output cell.\n\n    Args:\n        app (Application or callable) :\n            A Bokeh Application to embed inline in a Jupyter notebook.\n\n        state (State) :\n            ** Unused **\n\n        notebook_url (str or callable) :\n            The URL of the notebook server that is running the embedded app.\n\n            If ``notebook_url`` is a string, the value string is parsed to\n            construct the origin and full server URLs.\n\n            If notebook_url is a callable, it must accept one parameter,\n            which will be the server port, or None. If passed a port,\n            the callable must generate the server URL, otherwise if passed\n            None, it must generate the origin URL for the server.\n\n        port (int) :\n            A port for the embedded server will listen on.\n\n            By default the port is 0, which results in the server listening\n            on a random dynamic port.\n\n    Any additional keyword arguments are passed to :class:`~bokeh.server.Server` (added in version 1.1)\n\n    Returns:\n        None\n\n    '''\n    logging.basicConfig()\n\n    from tornado.ioloop import IOLoop\n    from ..server.server import Server\n\n    loop = IOLoop.current()\n\n    if callable(notebook_url):\n        origin = notebook_url(None)\n    else:\n        origin = _origin_url(notebook_url)\n\n    server = Server({\"/\": app}, io_loop=loop, port=port,  allow_websocket_origin=[origin], **kw)\n\n    server_id = uuid4().hex\n    curstate().uuid_to_server[server_id] = server\n\n    server.start()\n\n    if callable(notebook_url):\n        url = notebook_url(server.port)\n    else:\n        url = _server_url(notebook_url, server.port)\n\n    logging.debug(\"Server URL is %s\" % url)\n    logging.debug(\"Origin URL is %s\" % origin)\n\n    from ..embed import server_document\n    script = server_document(url, resources=None)\n\n    publish_display_data({\n        HTML_MIME_TYPE: script,\n        EXEC_MIME_TYPE: \"\"\n    }, metadata={\n        EXEC_MIME_TYPE: {\"server_id\": server_id}\n    })", "response": "Embed a Bokeh server application in a Jupyter Notebook output cell."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clamp(value, maximum=None):\n        ''' Clamp numeric values to be non-negative, an optionally, less than a\n        given maximum.\n\n        Args:\n            value (float) :\n                A number to clamp.\n\n            maximum (float, optional) :\n                A max bound to to clamp to. If None, there is no upper bound,\n                and values are only clamped to be non-negative. (default: None)\n\n        Returns:\n            float\n\n        '''\n        value = max(value, 0)\n\n        if maximum is not None:\n            return min(value, maximum)\n        else:\n            return value", "response": "Clamp numeric values to be non - negative an optionally less than a\n            given maximum."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndarkens (reduce the luminance) of this color. Args: amount (float) : Amount to reduce the luminance by (clamped above zero) Returns: Color", "response": "def darken(self, amount):\n        ''' Darken (reduce the luminance) of this color.\n\n        Args:\n            amount (float) :\n                Amount to reduce the luminance by (clamped above zero)\n\n        Returns:\n            Color\n\n        '''\n        hsl = self.to_hsl()\n        hsl.l = self.clamp(hsl.l - amount)\n        return self.from_hsl(hsl)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlightening (increase the luminance) of this color. Args: amount (float) : Amount to increase the luminance by (clamped above zero) Returns: Color", "response": "def lighten(self, amount):\n        ''' Lighten (increase the luminance) of this color.\n\n        Args:\n            amount (float) :\n                Amount to increase the luminance by (clamped above zero)\n\n        Returns:\n            Color\n\n        '''\n        hsl = self.to_hsl()\n        hsl.l = self.clamp(hsl.l + amount, 1)\n        return self.from_hsl(hsl)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset up a handler for button state changes.", "response": "def on_click(self, handler):\n        \"\"\" Set up a handler for button state changes (clicks).\n\n        Args:\n            handler (func) : handler function to call when button is toggled.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.on_change('active', lambda attr, old, new: handler(new))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_click(self, handler):\n        ''' Set up a handler for button or menu item clicks.\n\n        Args:\n            handler (func) : handler function to call when button is activated.\n\n        Returns:\n            None\n\n        '''\n        self.on_event(ButtonClick, handler)\n        self.on_event(MenuItemClick, handler)", "response": "Set up a handler for button or menu item clicks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset up a JavaScript handler for button or menu item clicks.", "response": "def js_on_click(self, handler):\n        ''' Set up a JavaScript handler for button or menu item clicks. '''\n        self.js_on_event(ButtonClick, handler)\n        self.js_on_event(MenuItemClick, handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_optional(mod_name):\n    ''' Attempt to import an optional dependency.\n\n    Silently returns None if the requested module is not available.\n\n    Args:\n        mod_name (str) : name of the optional module to try to import\n\n    Returns:\n        imported module or None, if import fails\n\n    '''\n    try:\n        return import_module(mod_name)\n    except ImportError:\n        pass\n    except Exception:\n        msg = \"Failed to import optional module `{}`\".format(mod_name)\n        log.exception(msg)", "response": "Attempt to import an optional dependency."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detect_phantomjs(version='2.1'):\n    ''' Detect if PhantomJS is avaiable in PATH, at a minimum version.\n\n    Args:\n        version (str, optional) :\n            Required minimum version for PhantomJS (mostly for testing)\n\n    Returns:\n        str, path to PhantomJS\n\n    '''\n    if settings.phantomjs_path() is not None:\n        phantomjs_path = settings.phantomjs_path()\n    else:\n        if hasattr(shutil, \"which\"):\n            phantomjs_path = shutil.which(\"phantomjs\") or \"phantomjs\"\n        else:\n            # Python 2 relies on Environment variable in PATH - attempt to use as follows\n            phantomjs_path = \"phantomjs\"\n\n    try:\n        proc = Popen([phantomjs_path, \"--version\"], stdout=PIPE, stderr=PIPE)\n        proc.wait()\n        out = proc.communicate()\n\n        if len(out[1]) > 0:\n            raise RuntimeError('Error encountered in PhantomJS detection: %r' % out[1].decode('utf8'))\n\n        required = V(version)\n        installed = V(out[0].decode('utf8'))\n        if installed < required:\n            raise RuntimeError('PhantomJS version to old. Version>=%s required, installed: %s' % (required, installed))\n\n    except OSError:\n        raise RuntimeError('PhantomJS is not present in PATH or BOKEH_PHANTOMJS_PATH. Try \"conda install phantomjs\" or \\\n            \"npm install -g phantomjs-prebuilt\"')\n\n    return phantomjs_path", "response": "Detect if PhantomJS is avaiable in PATH at a minimum version."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconsume individual protocol message fragments.", "response": "def consume(self, fragment):\n        ''' Consume individual protocol message fragments.\n\n        Args:\n            fragment (``JSON``) :\n                A message fragment to assemble. When a complete message is\n                assembled, the receiver state will reset to begin consuming a\n                new message.\n\n        '''\n        self._current_consumer(fragment)\n        raise gen.Return(self._message)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequire Sphinx extension setup function.", "response": "def setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_autodocumenter(ColorDocumenter)\n    app.add_autodocumenter(EnumDocumenter)\n    app.add_autodocumenter(PropDocumenter)\n    app.add_autodocumenter(ModelDocumenter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bounce(sequence):\n    ''' Return a driver function that can advance a \"bounced\" sequence\n    of values.\n\n    .. code-block:: none\n\n        seq = [0, 1, 2, 3]\n\n        # bounce(seq) => [0, 1, 2, 3, 3, 2, 1, 0, 0, 1, 2, ...]\n\n    Args:\n        sequence (seq) : a sequence of values for the driver to bounce\n\n    '''\n    N = len(sequence)\n    def f(i):\n        div, mod = divmod(i, N)\n        if div % 2 == 0:\n            return sequence[mod]\n        else:\n            return sequence[N-mod-1]\n    return partial(force, sequence=_advance(f))", "response": "Returns a driver function that can bounce a sequence of values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a driver function that can advance a sequence of cosine values.", "response": "def cosine(w, A=1, phi=0, offset=0):\n    ''' Return a driver function that can advance a sequence of cosine values.\n\n    .. code-block:: none\n\n        value = A * cos(w*i + phi) + offset\n\n    Args:\n        w (float) : a frequency for the cosine driver\n        A (float) : an amplitude for the cosine driver\n        phi (float) : a phase offset to start the cosine driver with\n        offset (float) : a global offset to add to the driver values\n\n    '''\n    from math import cos\n    def f(i):\n        return A * cos(w*i + phi) + offset\n    return partial(force, sequence=_advance(f))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a function that can advance a sequence of linear values.", "response": "def linear(m=1, b=0):\n    ''' Return a driver function that can advance a sequence of linear values.\n\n    .. code-block:: none\n\n        value = m * i + b\n\n    Args:\n        m (float) : a slope for the linear driver\n        x (float) : an offset for the linear driver\n\n    '''\n    def f(i):\n        return m * i + b\n    return partial(force, sequence=_advance(f))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a driver function that can advance a repeated of values.", "response": "def repeat(sequence):\n    ''' Return a driver function that can advance a repeated of values.\n\n    .. code-block:: none\n\n        seq = [0, 1, 2, 3]\n\n        # repeat(seq) => [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, ...]\n\n    Args:\n        sequence (seq) : a sequence of values for the driver to bounce\n\n    '''\n    N = len(sequence)\n    def f(i):\n        return sequence[i%N]\n    return partial(force, sequence=_advance(f))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sine(w, A=1, phi=0, offset=0):\n    ''' Return a driver function that can advance a sequence of sine values.\n\n    .. code-block:: none\n\n        value = A * sin(w*i + phi) + offset\n\n    Args:\n        w (float) : a frequency for the sine driver\n        A (float) : an amplitude for the sine driver\n        phi (float) : a phase offset to start the sine driver with\n        offset (float) : a global offset to add to the driver values\n\n    '''\n    from math import sin\n    def f(i):\n        return A * sin(w*i + phi) + offset\n    return partial(force, sequence=_advance(f))", "response": "Returns a function that can advance a sequence of sine values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup(app):\n    ''' Required Sphinx extension setup function. '''\n    app.add_node(\n        collapsible_code_block,\n        html=(\n            html_visit_collapsible_code_block,\n            html_depart_collapsible_code_block\n        )\n    )\n    app.add_directive('collapsible-code-block', CollapsibleCodeBlock)", "response": "Required Sphinx extension setup function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collect_filtered_models(discard, *input_values):\n    ''' Collect a duplicate-free list of all other Bokeh models referred to by\n    this model, or by any of its references, etc, unless filtered-out by the\n    provided callable.\n\n    Iterate over ``input_values`` and descend through their structure\n    collecting all nested ``Models`` on the go.\n\n    Args:\n        *discard (Callable[[Model], bool])\n            a callable which accepts a *Model* instance as its single argument\n            and returns a boolean stating whether to discard the instance. The\n            latter means that the instance will not be added to collected\n            models nor will its references be explored.\n\n        *input_values (Model)\n            Bokeh models to collect other models from\n\n    Returns:\n        None\n\n    '''\n\n    ids = set([])\n    collected = []\n    queued = []\n\n    def queue_one(obj):\n        if obj.id not in ids and not (callable(discard) and discard(obj)):\n            queued.append(obj)\n\n    for value in input_values:\n        _visit_value_and_its_immediate_references(value, queue_one)\n\n    while queued:\n        obj = queued.pop(0)\n        if obj.id not in ids:\n            ids.add(obj.id)\n            collected.append(obj)\n            _visit_immediate_value_references(obj, queue_one)\n\n    return collected", "response": "Collect a duplicate - free list of all other Bokeh models referred to by the base class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_class(view_model_name):\n    ''' Look up a Bokeh model class, given its view model name.\n\n    Args:\n        view_model_name (str) :\n            A view model name for a Bokeh model to look up\n\n    Returns:\n        Model: the model class corresponding to ``view_model_name``\n\n    Raises:\n        KeyError, if the model cannot be found\n\n    Example:\n\n        .. code-block:: python\n\n            >>> from bokeh.model import get_class\n            >>> get_class(\"Range1d\")\n            <class 'bokeh.models.ranges.Range1d'>\n\n    '''\n\n    # in order to look up from the model catalog that MetaModel maintains, it\n    # has to be creates first. These imports ensure that all built-in Bokeh\n    # models are represented in the catalog.\n    from . import models; models\n    from .plotting import Figure; Figure\n\n    d = MetaModel.model_class_reverse_map\n    if view_model_name in d:\n        return d[view_model_name]\n    else:\n        raise KeyError(\"View model name '%s' not found\" % view_model_name)", "response": "Look up a Bokeh model class given its view model name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _visit_immediate_value_references(value, visitor):\n    ''' Visit all references to another Model without recursing into any\n    of the child Model; may visit the same Model more than once if\n    it's referenced more than once. Does not visit the passed-in value.\n\n    '''\n    if isinstance(value, HasProps):\n        for attr in value.properties_with_refs():\n            child = getattr(value, attr)\n            _visit_value_and_its_immediate_references(child, visitor)\n    else:\n        _visit_value_and_its_immediate_references(value, visitor)", "response": "Visit all references to another Model without recursing into any\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ref(self):\n        ''' A Bokeh protocol \"reference\" to this model, i.e. a dict of the\n        form:\n\n        .. code-block:: python\n\n            {\n                'type' : << view model name >>\n                'id'   : << unique model id >>\n            }\n\n        Additionally there may be a `subtype` field if this model is a subtype.\n\n        '''\n        if \"__subtype__\" in self.__class__.__dict__:\n            return {\n                'type'    : self.__view_model__,\n                'subtype' : self.__subtype__,\n                'id'      : self.id,\n            }\n        else:\n            return {\n                'type' : self.__view_model__,\n                'id'   : self.id,\n            }", "response": "A dict of the Bokeh protocol reference to this model i. e. a dict of the Bokeh protocol type name id and subtype."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlink two Bokeh model properties using JavaScript.", "response": "def js_link(self, attr, other, other_attr):\n        ''' Link two Bokeh model properties using JavaScript.\n\n        This is a convenience method that simplifies adding a CustomJS callback\n        to update one Bokeh model property whenever another changes value.\n\n        Args:\n\n            attr (str) :\n                The name of a Bokeh property on this model\n\n            other (Model):\n                A Bokeh model to link to self.attr\n\n            other_attr (str) :\n                The property on ``other`` to link together\n\n        Added in version 1.1\n\n        Raises:\n\n            ValueError\n\n        Examples:\n\n            This code with ``js_link``:\n\n            .. code :: python\n\n                select.js_link('value', plot, 'sizing_mode')\n\n            is equivalent to the following:\n\n            .. code:: python\n\n                from bokeh.models import CustomJS\n                select.js_on_change('value',\n                    CustomJS(args=dict(other=plot),\n                             code=\"other.sizing_mode = this.value\"\n                    )\n                )\n\n        '''\n        if attr not in self.properties():\n            raise ValueError(\"%r is not a property of self (%r)\" % (attr, self))\n\n        if not isinstance(other, Model):\n            raise ValueError(\"'other' is not a Bokeh model: %r\" % other)\n\n        if other_attr not in other.properties():\n            raise ValueError(\"%r is not a property of other (%r)\" % (other_attr, other))\n\n        from bokeh.models.callbacks import CustomJS\n        cb = CustomJS(args=dict(other=other), code=\"other.%s = this.%s\" % (other_attr, attr))\n\n        self.js_on_change(attr, cb)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef js_on_change(self, event, *callbacks):\n        ''' Attach a ``CustomJS`` callback to an arbitrary BokehJS model event.\n\n        On the BokehJS side, change events for model properties have the\n        form ``\"change:property_name\"``. As a convenience, if the event name\n        passed to this method is also the name of a property on the model,\n        then it will be prefixed with ``\"change:\"`` automatically:\n\n        .. code:: python\n\n            # these two are equivalent\n            source.js_on_change('data', callback)\n            source.js_on_change('change:data', callback)\n\n        However, there are other kinds of events that can be useful to respond\n        to, in addition to property change events. For example to run a\n        callback whenever data is streamed to a ``ColumnDataSource``, use the\n        ``\"stream\"`` event on the source:\n\n        .. code:: python\n\n            source.js_on_change('streaming', callback)\n\n        '''\n        if len(callbacks) == 0:\n            raise ValueError(\"js_on_change takes an event name and one or more callbacks, got only one parameter\")\n\n        # handle any CustomJS callbacks here\n        from bokeh.models.callbacks import CustomJS\n        if not all(isinstance(x, CustomJS) for x in callbacks):\n            raise ValueError(\"not all callback values are CustomJS instances\")\n\n        if event in self.properties():\n            event = \"change:%s\" % event\n\n        if event not in self.js_property_callbacks:\n            self.js_property_callbacks[event] = []\n        for callback in callbacks:\n            if callback in self.js_property_callbacks[event]:\n                continue\n            self.js_property_callbacks[event].append(callback)", "response": "Attach a CustomJS callback to an arbitrary BokehJS model event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a callback on this object to trigger when attr changes.", "response": "def on_change(self, attr, *callbacks):\n        ''' Add a callback on this object to trigger when ``attr`` changes.\n\n        Args:\n            attr (str) : an attribute name on this object\n            *callbacks (callable) : callback functions to register\n\n        Returns:\n            None\n\n        Example:\n\n        .. code-block:: python\n\n            widget.on_change('value', callback1, callback2, ..., callback_n)\n\n        '''\n        if attr not in self.properties():\n            raise ValueError(\"attempted to add a callback on nonexistent %s.%s property\" % (self.__class__.__name__, attr))\n        super(Model, self).on_change(attr, *callbacks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates objects that match a given selector with the specified attribute / value updates.", "response": "def set_select(self, selector, updates):\n        ''' Update objects that match a given selector with the specified\n        attribute/value updates.\n\n        Args:\n            selector (JSON-like) :\n            updates (dict) :\n\n        Returns:\n            None\n\n        '''\n        for obj in self.select(selector):\n            for key, val in updates.items():\n                setattr(obj, key, val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON string encoding the attributes of this object.", "response": "def to_json_string(self, include_defaults):\n        ''' Returns a JSON string encoding the attributes of this object.\n\n        References to other objects are serialized as references\n        (just the object ID and type info), so the deserializer\n        will need to separately have the full attributes of those\n        other objects.\n\n        There's no corresponding ``from_json_string()`` because to\n        deserialize an object is normally done in the context of a\n        Document (since the Document can resolve references).\n\n        For most purposes it's best to serialize and deserialize\n        entire documents.\n\n        Args:\n            include_defaults (bool) : whether to include attributes\n                that haven't been changed from the default\n\n        '''\n        json_like = self._to_json_like(include_defaults=include_defaults)\n        json_like['id'] = self.id\n        # serialize_json \"fixes\" the JSON from _to_json_like by converting\n        # all types into plain JSON types # (it converts Model into refs,\n        # for example).\n        return serialize_json(json_like)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattach a model to a Bokeh |Document|.", "response": "def _attach_document(self, doc):\n        ''' Attach a model to a Bokeh |Document|.\n\n        This private interface should only ever called by the Document\n        implementation to set the private ._document field properly\n\n        '''\n        if self._document is not None and self._document is not doc:\n            raise RuntimeError(\"Models must be owned by only a single document, %r is already in a doc\" % (self))\n        doc.theme.apply_to_model(self)\n        self._document = doc\n        self._update_event_callbacks()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of the attributes of this object in order to be JSON - compatible.", "response": "def _to_json_like(self, include_defaults):\n        ''' Returns a dictionary of the attributes of this object, in\n        a layout corresponding to what BokehJS expects at unmarshalling time.\n\n        This method does not convert \"Bokeh types\" into \"plain JSON types,\"\n        for example each child Model will still be a Model, rather\n        than turning into a reference, numpy isn't handled, etc.\n        That's what \"json like\" means.\n\n        This method should be considered \"private\" or \"protected\",\n        for use internal to Bokeh; use ``to_json()`` instead because\n        it gives you only plain JSON-compatible types.\n\n        Args:\n            include_defaults (bool) : whether to include attributes\n                that haven't been changed from the default.\n\n        '''\n        all_attrs = self.properties_with_values(include_defaults=include_defaults)\n\n        # If __subtype__ is defined, then this model may introduce properties\n        # that don't exist on __view_model__ in bokehjs. Don't serialize such\n        # properties.\n        subtype = getattr(self.__class__, \"__subtype__\", None)\n        if subtype is not None and subtype != self.__class__.__view_model__:\n            attrs = {}\n            for attr, value in all_attrs.items():\n                if attr in self.__class__.__dict__:\n                    continue\n                else:\n                    attrs[attr] = value\n        else:\n            attrs = all_attrs\n\n        for (k, v) in attrs.items():\n            # we can't serialize Infinity, we send it as None and\n            # the other side has to fix it up. This transformation\n            # can't be in our json_encoder because the json\n            # module checks for inf before it calls the custom\n            # encoder.\n            if isinstance(v, float) and v == float('inf'):\n                attrs[k] = None\n\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new GMap object for plotting.", "response": "def gmap(google_api_key, map_options, **kwargs):\n    ''' Create a new :class:`~bokeh.plotting.gmap.GMap` for plotting.\n\n    Args:\n        google_api_key (str):\n            Google requires an API key be supplied for maps to function. See:\n\n            https://developers.google.com/maps/documentation/javascript/get-api-key\n\n        map_options: (GMapOptions)\n            Configuration specific to a Google Map\n\n    In addition to the standard :class:`~bokeh.plotting.gmap.GMap` keyword\n    arguments (e.g. ``plot_width`` or ``sizing_mode``), the following\n    additional options can be passed as well:\n\n    .. bokeh-options:: GMapFigureOptions\n        :module: bokeh.plotting.gmap\n\n    Returns:\n       GMap\n\n    '''\n\n    return GMap(api_key=google_api_key, map_options=map_options, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self):\n        ''' Return a copy of this color value.\n\n        Returns:\n            HSL\n\n        '''\n        return HSL(self.h, self.s, self.l, self.a)", "response": "Return a copy of this color value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the CSS representation of this HSL color.", "response": "def to_css(self):\n        ''' Generate the CSS representation of this HSL color.\n\n        Returns:\n            str, ``\"hsl(...)\"`` or ``\"hsla(...)\"``\n\n        '''\n        if self.a == 1.0:\n            return \"hsl(%d, %s%%, %s%%)\" % (self.h, self.s*100, self.l*100)\n        else:\n            return \"hsla(%d, %s%%, %s%%, %s)\" % (self.h, self.s*100, self.l*100, self.a)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_rgb(self):\n        ''' Return a corresponding :class:`~bokeh.colors.rgb.RGB` color for\n        this HSL color.\n\n        Returns:\n            HSL\n\n        '''\n        from .rgb import RGB # prevent circular import\n        r, g, b = colorsys.hls_to_rgb(float(self.h)/360, self.l, self.s)\n        return RGB(round(r*255), round(g*255), round(b*255), self.a)", "response": "Return a corresponding RGB color for this HSL color."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serverdir():\n    path = join(ROOT_DIR, 'server')\n    path = normpath(path)\n    if sys.platform == 'cygwin': path = realpath(path)\n    return path", "response": "Get the location of the server subpackage"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bokehjsdir(dev=False):\n    dir1 = join(ROOT_DIR, '..', 'bokehjs', 'build')\n    dir2 = join(serverdir(), 'static')\n    if dev and isdir(dir1):\n        return dir1\n    else:\n        return dir2", "response": "Get the location of the bokehjs source files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n        ''' Install the Bokeh Server and its background tasks on a Tornado\n        ``IOLoop``.\n\n        This method does *not* block and does *not* affect the state of the\n        Tornado ``IOLoop``  You must start and stop the loop yourself, i.e.\n        this method is typically useful when you are already explicitly\n        managing an ``IOLoop`` yourself.\n\n        To start a Bokeh server and immediately \"run forever\" in a blocking\n        manner, see :func:`~bokeh.server.server.BaseServer.run_until_shutdown`.\n\n        '''\n        assert not self._started, \"Already started\"\n        self._started = True\n        self._tornado.start()", "response": "Start the Bokeh Server and its background tasks on a Tornado\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self, wait=True):\n        ''' Stop the Bokeh Server.\n\n        This stops and removes all Bokeh Server ``IOLoop`` callbacks, as well\n        as stops the ``HTTPServer`` that this instance was configured with.\n\n        Args:\n            fast (bool):\n                Whether to wait for orderly cleanup (default: True)\n\n        Returns:\n            None\n\n        '''\n        assert not self._stopped, \"Already stopped\"\n        self._stopped = True\n        self._tornado.stop(wait)\n        self._http.stop()", "response": "Stop the Bokeh Server.\n            This stops the HTTP Server and Tornado callbacks as well as the HTTP Server callbacks as well as the HTTP Server that this instance was configured with."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_until_shutdown(self):\n        ''' Run the Bokeh Server until shutdown is requested by the user,\n        either via a Keyboard interrupt (Ctrl-C) or SIGTERM.\n\n        Calling this method will start the Tornado ``IOLoop`` and block\n        all execution in the calling process.\n\n        Returns:\n            None\n\n        '''\n        if not self._started:\n            self.start()\n        # Install shutdown hooks\n        atexit.register(self._atexit)\n        signal.signal(signal.SIGTERM, self._sigterm)\n        try:\n            self._loop.start()\n        except KeyboardInterrupt:\n            print(\"\\nInterrupted, shutting down\")\n        self.stop()", "response": "Run the Bokeh Server until shutdown is requested by the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all currently active sessions for applications.", "response": "def get_sessions(self, app_path=None):\n        ''' Gets all currently active sessions for applications.\n\n        Args:\n            app_path (str, optional) :\n                The configured application path for the application to return\n                sessions for. If None, return active sessions for all\n                applications. (default: None)\n\n        Returns:\n            list[ServerSession]\n\n        '''\n        if app_path is not None:\n            return self._tornado.get_sessions(app_path)\n        all_sessions = []\n        for path in self._tornado.app_paths:\n            all_sessions += self._tornado.get_sessions(path)\n        return all_sessions"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens an app in a browser window or tab.", "response": "def show(self, app_path, browser=None, new='tab'):\n        ''' Opens an app in a browser window or tab.\n\n        This method is useful for testing or running Bokeh server applications\n        on a local machine but should not call when running Bokeh server for\n        an actual deployment.\n\n        Args:\n            app_path (str) : the app path to open\n                The part of the URL after the hostname:port, with leading slash.\n\n            browser (str, optional) : browser to show with (default: None)\n                For systems that support it, the **browser** argument allows\n                specifying which browser to display in, e.g. \"safari\", \"firefox\",\n                \"opera\", \"windows-default\" (see the ``webbrowser`` module\n                documentation in the standard lib for more details).\n\n            new (str, optional) : window or tab (default: \"tab\")\n                If ``new`` is 'tab', then opens a new tab.\n                If ``new`` is 'window', then opens a new window.\n\n        Returns:\n            None\n\n        '''\n        if not app_path.startswith(\"/\"):\n            raise ValueError(\"app_path must start with a /\")\n\n\n        address_string = 'localhost'\n        if self.address is not None and self.address != '':\n            address_string = self.address\n        url = \"http://%s:%d%s%s\" % (address_string, self.port, self.prefix, app_path)\n\n        from bokeh.util.browser import view\n        view(url, browser=browser, new=new)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a fresh module to run in.", "response": "def new_module(self):\n        ''' Make a fresh module to run in.\n\n        Returns:\n            Module\n\n        '''\n        self.reset_run_errors()\n\n        if self._code is None:\n            return None\n\n        module_name = 'bk_script_' + make_id().replace('-', '')\n        module = ModuleType(str(module_name)) # str needed for py2.7\n        module.__dict__['__file__'] = os.path.abspath(self._path)\n\n        return module"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, module, post_check):\n        ''' Execute the configured source code in a module and run any post\n        checks.\n\n        Args:\n            module (Module) : a module to execute the configured code in.\n\n            post_check(callable) : a function that can raise an exception\n                if expected post-conditions are not met after code execution.\n\n        '''\n        try:\n            # Simulate the sys.path behaviour decribed here:\n            #\n            # https://docs.python.org/2/library/sys.html#sys.path\n            _cwd = os.getcwd()\n            _sys_path = list(sys.path)\n            _sys_argv = list(sys.argv)\n            sys.path.insert(0, os.path.dirname(self._path))\n            sys.argv = [os.path.basename(self._path)] + self._argv\n\n            exec(self._code, module.__dict__)\n            post_check()\n\n        except Exception as e:\n            self._failed = True\n            self._error_detail = traceback.format_exc()\n\n            _exc_type, _exc_value, exc_traceback = sys.exc_info()\n            filename, line_number, func, txt = traceback.extract_tb(exc_traceback)[-1]\n\n            self._error = \"%s\\nFile \\\"%s\\\", line %d, in %s:\\n%s\" % (str(e), os.path.basename(filename), line_number, func, txt)\n\n        finally:\n            # undo sys.path, CWD fixups\n            os.chdir(_cwd)\n            sys.path = _sys_path\n            sys.argv = _sys_argv\n            self.ran = True", "response": "Execute the configured source code in a module and run any post - conditions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a blocking loop that runs and executes event callbacks until the connection is closed.", "response": "def loop_until_closed(self):\n        ''' Execute a blocking loop that runs and executes event callbacks\n        until the connection is closed (e.g. by hitting Ctrl-C).\n\n        While this method can be used to run Bokeh application code \"outside\"\n        the Bokeh server, this practice is HIGHLY DISCOURAGED for any real\n        use case.\n\n        '''\n        if isinstance(self._state, NOT_YET_CONNECTED):\n            # we don't use self._transition_to_disconnected here\n            # because _transition is a coroutine\n            self._tell_session_about_disconnect()\n            self._state = DISCONNECTED()\n        else:\n            def closed():\n                return isinstance(self._state, DISCONNECTED)\n            self._loop_until(closed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pull_doc(self, document):\n        ''' Pull a document from the server, overwriting the passed-in document\n\n        Args:\n            document : (Document)\n              The document to overwrite with server content.\n\n        Returns:\n            None\n\n        '''\n        msg = self._protocol.create('PULL-DOC-REQ')\n        reply = self._send_message_wait_for_reply(msg)\n        if reply is None:\n            raise RuntimeError(\"Connection to server was lost\")\n        elif reply.header['msgtype'] == 'ERROR':\n            raise RuntimeError(\"Failed to pull document: \" + reply.content['text'])\n        else:\n            reply.push_to_document(document)", "response": "Pull a document from the server overwriting the passed - in document\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push_doc(self, document):\n        ''' Push a document to the server, overwriting any existing server-side doc.\n\n        Args:\n            document : (Document)\n                A Document to push to the server\n\n        Returns:\n            The server reply\n\n        '''\n        msg = self._protocol.create('PUSH-DOC', document)\n        reply = self._send_message_wait_for_reply(msg)\n        if reply is None:\n            raise RuntimeError(\"Connection to server was lost\")\n        elif reply.header['msgtype'] == 'ERROR':\n            raise RuntimeError(\"Failed to push document: \" + reply.content['text'])\n        else:\n            return reply", "response": "Push a document to the server overwriting any existing server - side doc."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nask for information about the server.", "response": "def request_server_info(self):\n        ''' Ask for information about the server.\n\n        Returns:\n            A dictionary of server attributes.\n\n        '''\n        if self._server_info is None:\n            self._server_info = self._send_request_server_info()\n        return self._server_info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport the LayoutDOM object or document as a PNG.", "response": "def export_png(obj, filename=None, height=None, width=None, webdriver=None, timeout=5):\n    ''' Export the ``LayoutDOM`` object or document as a PNG.\n\n    If the filename is not given, it is derived from the script name (e.g.\n    ``/foo/myplot.py`` will create ``/foo/myplot.png``)\n\n    Args:\n        obj (LayoutDOM or Document) : a Layout (Row/Column), Plot or Widget\n            object or Document to export.\n\n        filename (str, optional) : filename to save document under (default: None)\n            If None, infer from the filename.\n\n        height (int) : the desired height of the exported layout obj only if\n            it's a Plot instance. Otherwise the height kwarg is ignored.\n\n        width (int) : the desired width of the exported layout obj only if\n            it's a Plot instance. Otherwise the width kwarg is ignored.\n\n        webdriver (selenium.webdriver) : a selenium webdriver instance to use\n            to export the image.\n\n        timeout (int) : the maximum amount of time (in seconds) to wait for\n            Bokeh to initialize (default: 5) (Added in 1.1.1).\n\n    Returns:\n        filename (str) : the filename where the static file is saved.\n\n    If you would like to access an Image object directly, rather than save a\n    file to disk, use the lower-level :func:`~bokeh.io.export.get_screenshot_as_png`\n    function.\n\n    .. warning::\n        Responsive sizing_modes may generate layouts with unexpected size and\n        aspect ratios. It is recommended to use the default ``fixed`` sizing mode.\n\n    '''\n\n    image = get_screenshot_as_png(obj, height=height, width=width, driver=webdriver, timeout=timeout)\n\n    if filename is None:\n        filename = default_filename(\"png\")\n\n    if image.width == 0 or image.height == 0:\n        raise ValueError(\"unable to save an empty image\")\n\n    image.save(filename)\n\n    return abspath(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_svgs(obj, filename=None, height=None, width=None, webdriver=None, timeout=5):\n    ''' Export the SVG-enabled plots within a layout. Each plot will result\n    in a distinct SVG file.\n\n    If the filename is not given, it is derived from the script name\n    (e.g. ``/foo/myplot.py`` will create ``/foo/myplot.svg``)\n\n    Args:\n        obj (LayoutDOM object) : a Layout (Row/Column), Plot or Widget object to display\n\n        filename (str, optional) : filename to save document under (default: None)\n            If None, infer from the filename.\n\n        height (int) : the desired height of the exported layout obj only if\n            it's a Plot instance. Otherwise the height kwarg is ignored.\n\n        width (int) : the desired width of the exported layout obj only if\n            it's a Plot instance. Otherwise the width kwarg is ignored.\n\n        webdriver (selenium.webdriver) : a selenium webdriver instance to use\n            to export the image.\n\n        timeout (int) : the maximum amount of time (in seconds) to wait for\n            Bokeh to initialize (default: 5) (Added in 1.1.1).\n\n    Returns:\n        filenames (list(str)) : the list of filenames where the SVGs files are\n        saved.\n\n    .. warning::\n        Responsive sizing_modes may generate layouts with unexpected size and\n        aspect ratios. It is recommended to use the default ``fixed`` sizing mode.\n\n    '''\n    svgs = get_svgs(obj, height=height, width=width, driver=webdriver, timeout=timeout)\n\n    if len(svgs) == 0:\n        log.warning(\"No SVG Plots were found.\")\n        return\n\n    if filename is None:\n        filename = default_filename(\"svg\")\n\n    filenames = []\n\n    for i, svg in enumerate(svgs):\n        if i == 0:\n            filename = filename\n        else:\n            idx = filename.find(\".svg\")\n            filename = filename[:idx] + \"_{}\".format(i) + filename[idx:]\n\n        with io.open(filename, mode=\"w\", encoding=\"utf-8\") as f:\n            f.write(svg)\n\n        filenames.append(filename)\n\n    return filenames", "response": "Export the SVG - enabled plots within a layout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a screenshot of a LayoutDOM object.", "response": "def get_screenshot_as_png(obj, driver=None, timeout=5, **kwargs):\n    ''' Get a screenshot of a ``LayoutDOM`` object.\n\n    Args:\n        obj (LayoutDOM or Document) : a Layout (Row/Column), Plot or Widget\n            object or Document to export.\n\n        driver (selenium.webdriver) : a selenium webdriver instance to use\n            to export the image.\n\n        timeout (int) : the maximum amount of time to wait for initialization.\n            It will be used as a timeout for loading Bokeh, then when waiting for\n            the layout to be rendered.\n\n    Returns:\n        cropped_image (PIL.Image.Image) : a pillow image loaded from PNG.\n\n    .. warning::\n        Responsive sizing_modes may generate layouts with unexpected size and\n        aspect ratios. It is recommended to use the default ``fixed`` sizing mode.\n\n    '''\n    Image = import_required('PIL.Image',\n                            'To use bokeh.io.export_png you need pillow ' +\n                            '(\"conda install pillow\" or \"pip install pillow\")')\n\n    with _tmp_html() as tmp:\n        html = get_layout_html(obj, **kwargs)\n        with io.open(tmp.path, mode=\"w\", encoding=\"utf-8\") as file:\n            file.write(decode_utf8(html))\n\n        web_driver = driver if driver is not None else webdriver_control.get()\n\n        web_driver.get(\"file:///\" + tmp.path)\n        web_driver.maximize_window()\n\n        ## resize for PhantomJS compat\n        web_driver.execute_script(\"document.body.style.width = '100%';\")\n\n        wait_until_render_complete(web_driver, timeout)\n\n        png = web_driver.get_screenshot_as_png()\n\n        b_rect = web_driver.execute_script(_BOUNDING_RECT_SCRIPT)\n\n    image = Image.open(io.BytesIO(png))\n    cropped_image = _crop_image(image, **b_rect)\n\n    return cropped_image"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _crop_image(image, left=0, top=0, right=0, bottom=0, **kwargs):\n    ''' Crop the border from the layout\n\n    '''\n    return image.crop((left, top, right, bottom))", "response": "Crops the border from the layout\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a Pandas DataFrame to a dict of columns suitable for creating a ColumnDataSource.", "response": "def _data_from_df(df):\n        ''' Create a ``dict`` of columns from a Pandas ``DataFrame``,\n        suitable for creating a ColumnDataSource.\n\n        Args:\n            df (DataFrame) : data to convert\n\n        Returns:\n            dict[str, np.array]\n\n        '''\n        _df = df.copy()\n\n        # Flatten columns\n        if isinstance(df.columns, pd.MultiIndex):\n            try:\n                _df.columns = ['_'.join(col) for col in _df.columns.values]\n            except TypeError:\n                raise TypeError('Could not flatten MultiIndex columns. '\n                                'use string column names or flatten manually')\n        # Transform columns CategoricalIndex in list\n        if isinstance(df.columns, pd.CategoricalIndex):\n            _df.columns = df.columns.tolist()\n        # Flatten index\n        index_name = ColumnDataSource._df_index_name(df)\n        if index_name == 'index':\n            _df.index = pd.Index(_df.index.values)\n        else:\n            _df.index = pd.Index(_df.index.values, name=index_name)\n        _df.reset_index(inplace=True)\n\n        tmp_data = {c: v.values for c, v in _df.iteritems()}\n\n        new_data = {}\n        for k, v in tmp_data.items():\n            new_data[k] = v\n\n        return new_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _df_index_name(df):\n        ''' Return the Bokeh-appropriate column name for a ``DataFrame`` index\n\n        If there is no named index, then `\"index\" is returned.\n\n        If there is a single named index, then ``df.index.name`` is returned.\n\n        If there is a multi-index, and the index names are all strings, then\n        the names are joined with '_' and the result is returned, e.g. for a\n        multi-index ``['ind1', 'ind2']`` the result will be \"ind1_ind2\".\n        Otherwise if any index name is not a string, the fallback name \"index\"\n        is returned.\n\n        Args:\n            df (DataFrame) : the ``DataFrame`` to find an index name for\n\n        Returns:\n            str\n\n        '''\n        if df.index.name:\n            return df.index.name\n        elif df.index.names:\n            try:\n                return \"_\".join(df.index.names)\n            except TypeError:\n                return \"index\"\n        else:\n            return \"index\"", "response": "Return the Bokeh - appropriate column name for a DataFrame index\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new column of data to the data source.", "response": "def add(self, data, name=None):\n        ''' Appends a new column of data to the data source.\n\n        Args:\n            data (seq) : new data to add\n            name (str, optional) : column name to use.\n                If not supplied, generate a name of the form \"Series ####\"\n\n        Returns:\n            str:  the column name used\n\n        '''\n        if name is None:\n            n = len(self.data)\n            while \"Series %d\"%n in self.data:\n                n += 1\n            name = \"Series %d\"%n\n        self.data[name] = data\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a column of data.", "response": "def remove(self, name):\n        ''' Remove a column of data.\n\n        Args:\n            name (str) : name of the column to remove\n\n        Returns:\n            None\n\n        .. note::\n            If the column name does not exist, a warning is issued.\n\n        '''\n        try:\n            del self.data[name]\n        except (ValueError, KeyError):\n            import warnings\n            warnings.warn(\"Unable to find column '%s' in data source\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstreams the data from a Bokeh server application to a new set of items.", "response": "def _stream(self, new_data, rollover=None, setter=None):\n        ''' Internal implementation to efficiently update data source columns\n        with new append-only data. The internal implementation adds the setter\n        attribute.  [https://github.com/bokeh/bokeh/issues/6577]\n\n        In cases where it is necessary to update data columns in, this method\n        can efficiently send only the new data, instead of requiring the\n        entire data set to be re-sent.\n\n        Args:\n            new_data (dict[str, seq] or DataFrame or Series) : a mapping of\n                column names to sequences of new data to append to each column,\n                a pandas DataFrame, or a pandas Series in case of a single row -\n                in this case the Series index is used as column names\n\n                All columns of the data source must be present in ``new_data``,\n                with identical-length append data.\n\n            rollover (int, optional) : A maximum column size, above which data\n                from the start of the column begins to be discarded. If None,\n                then columns will continue to grow unbounded (default: None)\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n        Returns:\n            None\n\n        Raises:\n            ValueError\n\n        Example:\n\n        .. code-block:: python\n\n            source = ColumnDataSource(data=dict(foo=[], bar=[]))\n\n            # has new, identical-length updates for all columns in source\n            new_data = {\n                'foo' : [10, 20],\n                'bar' : [100, 200],\n            }\n\n            source.stream(new_data)\n\n        '''\n        needs_length_check = True\n\n        if pd and isinstance(new_data, pd.Series):\n            new_data = new_data.to_frame().T\n\n        if pd and isinstance(new_data, pd.DataFrame):\n            needs_length_check = False # DataFrame lengths equal by definition\n            _df = new_data\n            newkeys = set(_df.columns)\n            index_name = ColumnDataSource._df_index_name(_df)\n            newkeys.add(index_name)\n            new_data = dict(_df.iteritems())\n            new_data[index_name] = _df.index.values\n        else:\n            newkeys = set(new_data.keys())\n\n        oldkeys = set(self.data.keys())\n\n        if newkeys != oldkeys:\n            missing = oldkeys - newkeys\n            extra = newkeys - oldkeys\n            if missing and extra:\n                raise ValueError(\n                    \"Must stream updates to all existing columns (missing: %s, extra: %s)\" % (\", \".join(sorted(missing)), \", \".join(sorted(extra)))\n                )\n            elif missing:\n                raise ValueError(\"Must stream updates to all existing columns (missing: %s)\" % \", \".join(sorted(missing)))\n            else:\n                raise ValueError(\"Must stream updates to all existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n\n        import numpy as np\n        if needs_length_check:\n            lengths = set()\n            arr_types = (np.ndarray, pd.Series) if pd else np.ndarray\n            for k, x in new_data.items():\n                if isinstance(x, arr_types):\n                    if len(x.shape) != 1:\n                        raise ValueError(\"stream(...) only supports 1d sequences, got ndarray with size %r\" % (x.shape,))\n                    lengths.add(x.shape[0])\n                else:\n                    lengths.add(len(x))\n\n            if len(lengths) > 1:\n                raise ValueError(\"All streaming column updates must be the same length\")\n\n        # slightly awkward that we have to call convert_datetime_array here ourselves\n        # but the downstream code expects things to already be ms-since-epoch\n        for key, values in new_data.items():\n            if pd and isinstance(values, (pd.Series, pd.Index)):\n                values = values.values\n            old_values = self.data[key]\n            # Apply the transformation if the new data contains datetimes\n            # but the current data has already been transformed\n            if (isinstance(values, np.ndarray) and values.dtype.kind.lower() == 'm' and\n                isinstance(old_values, np.ndarray) and old_values.dtype.kind.lower() != 'm'):\n                new_data[key] = convert_datetime_array(values)\n            else:\n                new_data[key] = values\n\n        self.data._stream(self.document, self, new_data, rollover, setter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef patch(self, patches, setter=None):\n        ''' Efficiently update data source columns at specific locations\n\n        If it is only necessary to update a small subset of data in a\n        ``ColumnDataSource``, this method can be used to efficiently update only\n        the subset, instead of requiring the entire data set to be sent.\n\n        This method should be passed a dictionary that maps column names to\n        lists of tuples that describe a patch change to apply. To replace\n        individual items in columns entirely, the tuples should be of the\n        form:\n\n        .. code-block:: python\n\n            (index, new_value)  # replace a single column value\n\n            # or\n\n            (slice, new_values) # replace several column values\n\n        Values at an index or slice will be replaced with the corresponding\n        new values.\n\n        In the case of columns whose values are other arrays or lists, (e.g.\n        image or patches glyphs), it is also possible to patch \"subregions\".\n        In this case the first item of the tuple should be a whose first\n        element is the index of the array item in the CDS patch, and whose\n        subsequent elements are integer indices or slices into the array item:\n\n        .. code-block:: python\n\n            # replace the entire 10th column of the 2nd array:\n\n              +----------------- index of item in column data source\n              |\n              |       +--------- row subindex into array item\n              |       |\n              |       |       +- column subindex into array item\n              V       V       V\n            ([2, slice(None), 10], new_values)\n\n        Imagining a list of 2d NumPy arrays, the patch above is roughly\n        equivalent to:\n\n        .. code-block:: python\n\n            data = [arr1, arr2, ...]  # list of 2d arrays\n\n            data[2][:, 10] = new_data\n\n        There are some limitations to the kinds of slices and data that can\n        be accepted.\n\n        * Negative ``start``, ``stop``, or ``step`` values for slices will\n          result in a ``ValueError``.\n\n        * In a slice, ``start > stop`` will result in a ``ValueError``\n\n        * When patching 1d or 2d subitems, the subitems must be NumPy arrays.\n\n        * New values must be supplied as a **flattened one-dimensional array**\n          of the appropriate size.\n\n        Args:\n            patches (dict[str, list[tuple]]) : lists of patches for each column\n\n        Returns:\n            None\n\n        Raises:\n            ValueError\n\n        Example:\n\n        The following example shows how to patch entire column elements. In this case,\n\n        .. code-block:: python\n\n            source = ColumnDataSource(data=dict(foo=[10, 20, 30], bar=[100, 200, 300]))\n\n            patches = {\n                'foo' : [ (slice(2), [11, 12]) ],\n                'bar' : [ (0, 101), (2, 301) ],\n            }\n\n            source.patch(patches)\n\n        After this operation, the value of the ``source.data`` will be:\n\n        .. code-block:: python\n\n            dict(foo=[11, 12, 30], bar=[101, 200, 301])\n\n        For a more comprehensive complete example, see :bokeh-tree:`examples/howto/patch_app.py`.\n\n        '''\n        import numpy as np\n\n        extra = set(patches.keys()) - set(self.data.keys())\n\n        if extra:\n            raise ValueError(\"Can only patch existing columns (extra: %s)\" % \", \".join(sorted(extra)))\n\n        for name, patch in patches.items():\n\n            col_len = len(self.data[name])\n\n            for ind, value in patch:\n\n                # integer index, patch single value of 1d column\n                if isinstance(ind, int):\n                    if ind > col_len or ind < 0:\n                        raise ValueError(\"Out-of bounds index (%d) in patch for column: %s\" % (ind, name))\n\n                # slice index, patch multiple values of 1d column\n                elif isinstance(ind, slice):\n                    _check_slice(ind)\n                    if ind.stop is not None and ind.stop > col_len:\n                        raise ValueError(\"Out-of bounds slice index stop (%d) in patch for column: %s\" % (ind.stop, name))\n\n                # multi-index, patch sub-regions of \"n-d\" column\n                elif isinstance(ind, (list, tuple)):\n                    if len(ind) == 0:\n                        raise ValueError(\"Empty (length zero) patch multi-index\")\n\n                    if len(ind) == 1:\n                        raise ValueError(\"Patch multi-index must contain more than one subindex\")\n\n                    if not isinstance(ind[0], int):\n                        raise ValueError(\"Initial patch sub-index may only be integer, got: %s\" % ind[0])\n\n                    if ind[0] > col_len or ind[0] < 0:\n                        raise ValueError(\"Out-of bounds initial sub-index (%d) in patch for column: %s\" % (ind, name))\n\n                    if not isinstance(self.data[name][ind[0]], np.ndarray):\n                        raise ValueError(\"Can only sub-patch into columns with NumPy array items\")\n\n                    if len(self.data[name][ind[0]].shape) != (len(ind)-1):\n                        raise ValueError(\"Shape mismatch between patch slice and sliced data\")\n\n                    elif isinstance(ind[0], slice):\n                        _check_slice(ind[0])\n                        if ind[0].stop is not None and ind[0].stop > col_len:\n                            raise ValueError(\"Out-of bounds initial slice sub-index stop (%d) in patch for column: %s\" % (ind.stop, name))\n\n                    # Note: bounds of sub-indices after the first are not checked!\n                    for subind in ind[1:]:\n                        if not isinstance(subind, (int, slice)):\n                            raise ValueError(\"Invalid patch sub-index: %s\" % subind)\n                        if isinstance(subind, slice):\n                            _check_slice(subind)\n\n                else:\n                    raise ValueError(\"Invalid patch index: %s\" % ind)\n\n        self.data._patch(self.document, self, patches, setter)", "response": "Efficiently updates the data source columns at specific locations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef silence(warning, silence=True):\n    ''' Silence a particular warning on all Bokeh models.\n\n    Args:\n        warning (Warning) : Bokeh warning to silence\n        silence (bool) : Whether or not to silence the warning\n\n    Returns:\n        A set containing the all silenced warnings\n\n    This function adds or removes warnings from a set of silencers which\n    is referred to when running ``check_integrity``. If a warning\n    is added to the silencers - then it will never be raised.\n\n    .. code-block:: python\n\n        >>> from bokeh.core.validation.warnings import EMPTY_LAYOUT\n        >>> bokeh.core.validation.silence(EMPTY_LAYOUT, True)\n        {1002}\n\n    To turn a warning back on use the same method but with the silence\n    argument set to false\n\n    .. code-block:: python\n\n        >>> bokeh.core.validation.silence(EMPTY_LAYOUT, False)\n        set()\n\n    '''\n    if not isinstance(warning, int):\n        raise ValueError('Input to silence should be a warning object '\n                         '- not of type {}'.format(type(warning)))\n    if silence:\n        __silencers__.add(warning)\n    elif warning in __silencers__:\n        __silencers__.remove(warning)\n    return __silencers__", "response": "silence a particular warning on all Bokeh models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_integrity(models):\n    ''' Apply validation and integrity checks to a collection of Bokeh models.\n\n    Args:\n        models (seq[Model]) : a collection of Models to test\n\n    Returns:\n        None\n\n    This function will emit log warning and error messages for all error or\n    warning conditions that are detected. For example, layouts without any\n    children will trigger a warning:\n\n    .. code-block:: python\n\n        >>> empty_row = Row\n\n        >>> check_integrity([empty_row])\n        W-1002 (EMPTY_LAYOUT): Layout has no children: Row(id='2404a029-c69b-4e30-9b7d-4b7b6cdaad5b', ...)\n\n    '''\n    messages = dict(error=[], warning=[])\n\n    for model in models:\n        validators = []\n        for name in dir(model):\n            if not name.startswith(\"_check\"): continue\n            obj = getattr(model, name)\n            if getattr(obj, \"validator_type\", None):\n                validators.append(obj)\n        for func in validators:\n            messages[func.validator_type].extend(func())\n\n    for msg in sorted(messages['error']):\n        log.error(\"E-%d (%s): %s: %s\" % msg)\n\n    for msg in sorted(messages['warning']):\n        code, name, desc, obj = msg\n        if code not in __silencers__:\n            log.warning(\"W-%d (%s): %s: %s\" % msg)", "response": "Apply validation and integrity checks to a collection of Bokeh models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply this theme to a model.", "response": "def apply_to_model(self, model):\n        ''' Apply this theme to a model.\n\n        .. warning::\n            Typically, don't call this method directly. Instead, set the theme\n            on the :class:`~bokeh.document.Document` the model is a part of.\n\n        '''\n        model.apply_theme(self._for_class(model.__class__))\n\n        # a little paranoia because it would be Bad(tm) to mess\n        # this up... would be nicer if python had a way to freeze\n        # the dict.\n        if len(_empty_dict) > 0:\n            raise RuntimeError(\"Somebody put stuff in _empty_dict\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind or create a (possibly temporary) Document to use for serializing Bokeh content. Typical usage is similar to: .. code-block:: python with OutputDocumentFor(models): (docs_json, [render_item]) = standalone_docs_json_and_render_items(models) Inside the context manager, the models will be considered to be part of a single Document, with any theme specified, which can thus be serialized as a unit. Where possible, OutputDocumentFor attempts to use an existing Document. However, this is not possible in three cases: * If passed a series of models that have no Document at all, a new Document will be created, and all the models will be added as roots. After the context manager exits, the new Document will continue to be the models' document. * If passed a subset of Document.roots, then OutputDocumentFor temporarily \"re-homes\" the models in a new bare Document that is only available inside the context manager. * If passed a list of models that have differnet documents, then OutputDocumentFor temporarily \"re-homes\" the models in a new bare Document that is only available inside the context manager. OutputDocumentFor will also perfom document validation before yielding, if ``settings.perform_document_validation()`` is True. objs (seq[Model]) : a sequence of Models that will be serialized, and need a common document apply_theme (Theme or FromCurdoc or None, optional): Sets the theme for the doc while inside this context manager. (default: None) If None, use whatever theme is on the document that is found or created If FromCurdoc, use curdoc().theme, restoring any previous theme afterwards If a Theme instance, use that theme, restoring any previous theme afterwards always_new (bool, optional) : Always return a new document, even in cases where it is otherwise possible to use an existing document on models. Yields: Document", "response": "def OutputDocumentFor(objs, apply_theme=None, always_new=False):\n    ''' Find or create a (possibly temporary) Document to use for serializing\n    Bokeh content.\n\n    Typical usage is similar to:\n\n    .. code-block:: python\n\n         with OutputDocumentFor(models):\n            (docs_json, [render_item]) = standalone_docs_json_and_render_items(models)\n\n    Inside the context manager, the models will be considered to be part of a single\n    Document, with any theme specified, which can thus be serialized as a unit. Where\n    possible, OutputDocumentFor attempts to use an existing Document. However, this is\n    not possible in three cases:\n\n    * If passed a series of models that have no Document at all, a new Document will\n      be created, and all the models will be added as roots. After the context manager\n      exits, the new Document will continue to be the models' document.\n\n    * If passed a subset of Document.roots, then OutputDocumentFor temporarily \"re-homes\"\n      the models in a new bare Document that is only available inside the context manager.\n\n    * If passed a list of models that have differnet documents, then OutputDocumentFor\n      temporarily \"re-homes\" the models in a new bare Document that is only available\n      inside the context manager.\n\n    OutputDocumentFor will also perfom document validation before yielding, if\n    ``settings.perform_document_validation()`` is True.\n\n\n        objs (seq[Model]) :\n            a sequence of Models that will be serialized, and need a common document\n\n        apply_theme (Theme or FromCurdoc or None, optional):\n            Sets the theme for the doc while inside this context manager. (default: None)\n\n            If None, use whatever theme is on the document that is found or created\n\n            If FromCurdoc, use curdoc().theme, restoring any previous theme afterwards\n\n            If a Theme instance, use that theme, restoring any previous theme afterwards\n\n        always_new (bool, optional) :\n            Always return a new document, even in cases where it is otherwise possible\n            to use an existing document on models.\n\n    Yields:\n        Document\n\n    '''\n    # Note: Comms handling relies on the fact that the new_doc returned\n    # has models with the same IDs as they were started with\n\n    if not isinstance(objs, collections_abc.Sequence) or len(objs) == 0 or not all(isinstance(x, Model) for x in objs):\n        raise ValueError(\"OutputDocumentFor expects a sequence of Models\")\n\n    def finish(): pass\n\n    docs = set(x.document for x in objs)\n    if None in docs: docs.remove(None)\n\n    if always_new:\n        def finish(): # NOQA\n            _dispose_temp_doc(objs)\n        doc = _create_temp_doc(objs)\n\n    else:\n        if len(docs) == 0:\n            doc = Document()\n            for model in objs:\n                doc.add_root(model)\n\n        # handle a single shared document\n        elif len(docs) == 1:\n            doc = docs.pop()\n\n            # we are not using all the roots, make a quick clone for outputting purposes\n            if set(objs) != set(doc.roots):\n                def finish(): # NOQA\n                    _dispose_temp_doc(objs)\n                doc = _create_temp_doc(objs)\n\n            # we are using all the roots of a single doc, just use doc as-is\n            pass\n\n        # models have mixed docs, just make a quick clone\n        else:\n            def finish(): # NOQA\n                _dispose_temp_doc(objs)\n            doc = _create_temp_doc(objs)\n\n    if settings.perform_document_validation():\n        doc.validate()\n\n    _set_temp_theme(doc, apply_theme)\n\n    yield doc\n\n    _unset_temp_theme(doc)\n\n    finish()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef submodel_has_python_callbacks(models):\n    ''' Traverses submodels to check for Python (event) callbacks\n\n    '''\n    has_python_callback = False\n    for model in collect_models(models):\n        if len(model._callbacks) > 0 or len(model._event_callbacks) > 0:\n            has_python_callback = True\n            break\n\n    return has_python_callback", "response": "Checks if a list of models contains Python callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_networkx(graph, layout_function, **kwargs):\n        '''\n        Generate a ``GraphRenderer`` from a ``networkx.Graph`` object and networkx\n        layout function. Any keyword arguments will be passed to the\n        layout function.\n\n        Only two dimensional layouts are supported.\n\n        Args:\n            graph (networkx.Graph) : a networkx graph to render\n            layout_function (function or dict) : a networkx layout function or mapping of node keys to positions.\n            The position is a two element sequence containing the x and y coordinate.\n\n        Returns:\n            instance (GraphRenderer)\n\n        .. note::\n            Node and edge attributes may be lists or tuples. However, a given\n            attribute must either have *all* lists or tuple values, or *all*\n            scalar values, for nodes or edges it is defined on.\n\n        .. warning::\n            Node attributes labeled 'index' and edge attributes labeled 'start' or 'end' are ignored.\n            If you want to convert these attributes, please re-label them to other names.\n\n        Raises:\n            ValueError\n\n        '''\n\n        # inline import to prevent circular imports\n        from ..models.renderers import GraphRenderer\n        from ..models.graphs import StaticLayoutProvider\n\n        # Handles nx 1.x vs 2.x data structure change\n        # Convert node attributes\n        node_dict = dict()\n        node_attr_keys = [attr_key for node in list(graph.nodes(data=True))\n                          for attr_key in node[1].keys()]\n        node_attr_keys = list(set(node_attr_keys))\n\n        for attr_key in node_attr_keys:\n            values = [node_attr[attr_key] if attr_key in node_attr.keys() else None\n                      for _, node_attr in graph.nodes(data=True)]\n\n            values = _handle_sublists(values)\n\n            node_dict[attr_key] = values\n\n        if 'index' in node_attr_keys:\n            from warnings import warn\n            warn(\"Converting node attributes labeled 'index' are skipped. \"\n                 \"If you want to convert these attributes, please re-label with other names.\")\n\n        node_dict['index'] = list(graph.nodes())\n\n        # Convert edge attributes\n        edge_dict = dict()\n        edge_attr_keys = [attr_key for edge in graph.edges(data=True)\n                          for attr_key in edge[2].keys()]\n        edge_attr_keys = list(set(edge_attr_keys))\n\n        for attr_key in edge_attr_keys:\n            values = [edge_attr[attr_key] if attr_key in edge_attr.keys() else None\n                      for _, _, edge_attr in graph.edges(data=True)]\n\n            values = _handle_sublists(values)\n\n            edge_dict[attr_key] = values\n\n        if 'start' in edge_attr_keys or 'end' in edge_attr_keys:\n            from warnings import warn\n            warn(\"Converting edge attributes labeled 'start' or 'end' are skipped. \"\n                 \"If you want to convert these attributes, please re-label them with other names.\")\n\n        edge_dict['start'] = [x[0] for x in graph.edges()]\n        edge_dict['end'] = [x[1] for x in graph.edges()]\n\n        node_source = ColumnDataSource(data=node_dict)\n        edge_source = ColumnDataSource(data=edge_dict)\n\n        graph_renderer = GraphRenderer()\n        graph_renderer.node_renderer.data_source.data = node_source.data\n        graph_renderer.edge_renderer.data_source.data = edge_source.data\n\n        if callable(layout_function):\n            graph_layout = layout_function(graph, **kwargs)\n        else:\n            graph_layout = layout_function\n\n            node_keys = graph_renderer.node_renderer.data_source.data['index']\n            if set(node_keys) != set(layout_function.keys()):\n                from warnings import warn\n                warn(\"Node keys in 'layout_function' don't match node keys in the graph. \"\n                     \"These nodes may not be displayed correctly.\")\n\n        graph_renderer.layout_provider = StaticLayoutProvider(graph_layout=graph_layout)\n\n        return graph_renderer", "response": "Generate a GraphRenderer from a networkx. Graph object and a networkx layout function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enumeration(*values, **kwargs):\n    ''' Create an |Enumeration| object from a sequence of values.\n\n    Call ``enumeration`` with a sequence of (unique) strings to create an\n    Enumeration object:\n\n    .. code-block:: python\n\n        #: Specify the horizontal alignment for rendering text\n        TextAlign = enumeration(\"left\", \"right\", \"center\")\n\n    Args:\n        values (str) : string enumeration values, passed as positional arguments\n\n            The order of arguments is the order of the enumeration, and the\n            first element will be considered the default value when used\n            to create |Enum| properties.\n\n    Keyword Args:\n        case_sensitive (bool, optional) :\n            Whether validation should consider case or not (default: True)\n\n        quote (bool, optional):\n            Whther values should be quoted in the string representations\n            (default: False)\n\n    Raises:\n        ValueError if values empty, if any value is not a string or not unique\n\n    Returns:\n        Enumeration\n\n    '''\n    if not (values and all(isinstance(value, string_types) and value for value in values)):\n        raise ValueError(\"expected a non-empty sequence of strings, got %s\" % values)\n\n    if len(values) != len(set(values)):\n        raise ValueError(\"enumeration items must be unique, got %s\" % values)\n\n    attrs = {value: value for value in values}\n    attrs.update({\n        \"_values\": list(values),\n        \"_default\": values[0],\n        \"_case_sensitive\": kwargs.get(\"case_sensitive\", True),\n        \"_quote\": kwargs.get(\"quote\", False),\n    })\n\n    return type(str(\"Enumeration\"), (Enumeration,), attrs)()", "response": "Create an enumeration object from a sequence of unique strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_session_id(secret_key=settings.secret_key_bytes(), signed=settings.sign_sessions()):\n    secret_key = _ensure_bytes(secret_key)\n    if signed:\n        # note: '-' can also be in the base64 encoded signature\n        base_id = _get_random_string(secret_key=secret_key)\n        return base_id + '-' + _signature(base_id, secret_key)\n    else:\n        return _get_random_string(secret_key=secret_key)", "response": "Generate a random session ID for the Bokeh application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the signature of a session ID. Returns True if it s valid.", "response": "def check_session_id_signature(session_id, secret_key=settings.secret_key_bytes(),\n                               signed=settings.sign_sessions()):\n    \"\"\"Check the signature of a session ID, returning True if it's valid.\n\n    The server uses this function to check whether a session ID\n    was generated with the correct secret key. If signed sessions are disabled,\n    this function always returns True.\n\n    Args:\n        session_id (str) : The session ID to check\n        secret_key (str, optional) : Secret key (default: value of 'BOKEH_SECRET_KEY' env var)\n        signed (bool, optional) : Whether to check anything (default: value of\n                                  'BOKEH_SIGN_SESSIONS' env var)\n\n    \"\"\"\n    secret_key = _ensure_bytes(secret_key)\n    if signed:\n        pieces = session_id.split('-', 1)\n        if len(pieces) != 2:\n            return False\n        base_id = pieces[0]\n        provided_signature = pieces[1]\n        expected_signature = _signature(base_id, secret_key)\n        # hmac.compare_digest() uses a string compare algorithm that doesn't\n        # short-circuit so we don't allow timing analysis\n        # encode_utf8 is used to ensure that strings have same encoding\n        return hmac.compare_digest(encode_utf8(expected_signature), encode_utf8(provided_signature))\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a securely generated random string.", "response": "def _get_random_string(length=44,\n                       allowed_chars='abcdefghijklmnopqrstuvwxyz'\n                       'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n                       secret_key=settings.secret_key_bytes()):\n    \"\"\"\n    Return a securely generated random string.\n    With the a-z, A-Z, 0-9 character set:\n    Length 12 is a 71-bit value. log_2((26+26+10)^12) =~ 71\n    Length 44 is a 261-bit value. log_2((26+26+10)^44) = 261\n    \"\"\"\n    secret_key = _ensure_bytes(secret_key)\n    _reseed_if_needed(using_sysrandom, secret_key)\n    return ''.join(random.choice(allowed_chars) for i in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notebook_content(model, notebook_comms_target=None, theme=FromCurdoc):\n    ''' Return script and div that will display a Bokeh plot in a Jupyter\n    Notebook.\n\n    The data for the plot is stored directly in the returned HTML.\n\n    Args:\n        model (Model) : Bokeh object to render\n\n        notebook_comms_target (str, optional) :\n            A target name for a Jupyter Comms object that can update\n            the document that is rendered to this notebook div\n\n        theme (Theme, optional) :\n            Defaults to the ``Theme`` instance in the current document.\n            Setting this to ``None`` uses the default theme or the theme\n            already specified in the document. Any other value must be an\n            instance of the ``Theme`` class.\n\n    Returns:\n        script, div, Document\n\n    .. note::\n        Assumes :func:`~bokeh.io.notebook.load_notebook` or the equivalent\n        has already been executed.\n\n    '''\n\n    if not isinstance(model, Model):\n        raise ValueError(\"notebook_content expects a single Model instance\")\n\n    # Comms handling relies on the fact that the new_doc returned here\n    # has models with the same IDs as they were started with\n    with OutputDocumentFor([model], apply_theme=theme, always_new=True) as new_doc:\n        (docs_json, [render_item]) = standalone_docs_json_and_render_items([model])\n\n    div = div_for_render_item(render_item)\n\n    render_item = render_item.to_json()\n    if notebook_comms_target:\n        render_item[\"notebook_comms_target\"] = notebook_comms_target\n\n    script = DOC_NB_JS.render(\n        docs_json=serialize_json(docs_json),\n        render_items=serialize_json([render_item]),\n    )\n\n    return encode_utf8(script), encode_utf8(div), new_doc", "response": "Return a script and div that will display a Bokeh plot in a Jupyter Notebook."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_py_func(cls, func, v_func):\n        ''' Create a ``CustomJSTransform`` instance from a pair of Python\n        functions. The function is translated to JavaScript using PScript.\n\n        The python functions must have no positional arguments. It's\n        possible to pass Bokeh models (e.g. a ``ColumnDataSource``) as keyword\n        arguments to the functions.\n\n        The ``func`` function namespace will contain the variable ``x`` (the\n        untransformed value) at render time. The ``v_func`` function namespace\n        will contain the variable ``xs`` (the untransformed vector) at render\n        time.\n\n        .. warning::\n            The vectorized function, ``v_func``, must return an array of the\n            same length as the input ``xs`` array.\n\n        Example:\n\n        .. code-block:: python\n\n            def transform():\n                from pscript.stubs import Math\n                return Math.cos(x)\n\n            def v_transform():\n                from pscript.stubs import Math\n                return [Math.cos(x) for x in xs]\n\n            customjs_transform = CustomJSTransform.from_py_func(transform, v_transform)\n\n        Args:\n            func (function) : a scalar function to transform a single ``x`` value\n\n            v_func (function) : a vectorized function to transform a vector ``xs``\n\n        Returns:\n            CustomJSTransform\n\n        '''\n        from bokeh.util.deprecation import deprecated\n        deprecated(\"'from_py_func' is deprecated and will be removed in an eventual 2.0 release. \"\n                   \"Use CustomJSTransform directly instead.\")\n\n        if not isinstance(func, FunctionType) or not isinstance(v_func, FunctionType):\n            raise ValueError('CustomJSTransform.from_py_func only accepts function objects.')\n\n        pscript = import_required(\n            'pscript',\n            dedent(\"\"\"\\\n                To use Python functions for CustomJSTransform, you need PScript\n                '(\"conda install -c conda-forge pscript\" or \"pip install pscript\")\"\"\")\n            )\n\n        def pscript_compile(func):\n            sig = signature(func)\n\n            all_names, default_values = get_param_info(sig)\n\n            if len(all_names) - len(default_values) != 0:\n                raise ValueError(\"Function may only contain keyword arguments.\")\n\n            if default_values and not any(isinstance(value, Model) for value in default_values):\n                raise ValueError(\"Default value must be a Bokeh Model.\")\n\n            func_kwargs = dict(zip(all_names, default_values))\n\n            # Wrap the code attr in a function named `formatter` and call it\n            # with arguments that match the `args` attr\n            code = pscript.py2js(func, 'transformer') + 'return transformer(%s);\\n' % ', '.join(all_names)\n            return code, func_kwargs\n\n        jsfunc, func_kwargs = pscript_compile(func)\n        v_jsfunc, v_func_kwargs = pscript_compile(v_func)\n\n        # Have to merge the function arguments\n        func_kwargs.update(v_func_kwargs)\n\n        return cls(func=jsfunc, v_func=v_jsfunc, args=func_kwargs)", "response": "Create a CustomJSTransform instance from a pair of Python functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a CustomJSTransform instance from a pair of CoffeeScript functions and a function.", "response": "def from_coffeescript(cls, func, v_func, args={}):\n        ''' Create a ``CustomJSTransform`` instance from a pair of CoffeeScript\n        snippets. The function bodies are translated to JavaScript functions\n        using node and therefore require return statements.\n\n        The ``func`` snippet namespace will contain the variable ``x`` (the\n        untransformed value) at render time. The ``v_func`` snippet namespace\n        will contain the variable ``xs`` (the untransformed vector) at render\n        time.\n\n        Example:\n\n        .. code-block:: coffeescript\n\n            func = \"return Math.cos(x)\"\n            v_func = \"return [Math.cos(x) for x in xs]\"\n\n            transform = CustomJSTransform.from_coffeescript(func, v_func)\n\n        Args:\n            func (str) : a coffeescript snippet to transform a single ``x`` value\n\n            v_func (str) : a coffeescript snippet function to transform a vector ``xs``\n\n        Returns:\n            CustomJSTransform\n\n        '''\n        compiled = nodejs_compile(func, lang=\"coffeescript\", file=\"???\")\n        if \"error\" in compiled:\n            raise CompilationError(compiled.error)\n\n        v_compiled = nodejs_compile(v_func, lang=\"coffeescript\", file=\"???\")\n        if \"error\" in v_compiled:\n            raise CompilationError(v_compiled.error)\n\n        return cls(func=compiled.code, v_func=v_compiled.code, args=args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abstract(cls):\n    ''' A decorator to mark abstract base classes derived from |HasProps|.\n\n    '''\n    if not issubclass(cls, HasProps):\n        raise TypeError(\"%s is not a subclass of HasProps\" % cls.__name__)\n\n    # running python with -OO will discard docstrings -> __doc__ is None\n    if cls.__doc__ is not None:\n        cls.__doc__ += _ABSTRACT_ADMONITION\n\n    return cls", "response": "A decorator to mark abstract base classes derived from |HasProps|.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accumulate_from_superclasses(cls, propname):\n    ''' Traverse the class hierarchy and accumulate the special sets of names\n    ``MetaHasProps`` stores on classes:\n\n    Args:\n        name (str) : name of the special attribute to collect.\n\n            Typically meaningful values are: ``__container_props__``,\n            ``__properties__``, ``__properties_with_refs__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasattr() would also look at base\n    # classes, and the cache must be separate for each class\n    if cachename not in cls.__dict__:\n        s = set()\n        for c in inspect.getmro(cls):\n            if issubclass(c, HasProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                s.update(base)\n        setattr(cls, cachename, s)\n    return cls.__dict__[cachename]", "response": "Traverse the class hierarchy and accumulate the special sets of names\n            MetaHasProps stores on classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accumulate_dict_from_superclasses(cls, propname):\n    ''' Traverse the class hierarchy and accumulate the special dicts\n    ``MetaHasProps`` stores on classes:\n\n    Args:\n        name (str) : name of the special attribute to collect.\n\n            Typically meaningful values are: ``__dataspecs__``,\n            ``__overridden_defaults__``\n\n    '''\n    cachename = \"__cached_all\" + propname\n    # we MUST use cls.__dict__ NOT hasattr(). hasattr() would also look at base\n    # classes, and the cache must be separate for each class\n    if cachename not in cls.__dict__:\n        d = dict()\n        for c in inspect.getmro(cls):\n            if issubclass(c, HasProps) and hasattr(c, propname):\n                base = getattr(c, propname)\n                for k,v in base.items():\n                    if k not in d:\n                        d[k] = v\n        setattr(cls, cachename, d)\n    return cls.__dict__[cachename]", "response": "Traverse the class hierarchy and accumulate the special dicts\n archive on classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the properties of this object are structurally equal False otherwise.", "response": "def equals(self, other):\n        ''' Structural equality of models.\n\n        Args:\n            other (HasProps) : the other instance to compare to\n\n        Returns:\n            True, if properties are structurally equal, otherwise False\n\n        '''\n\n        # NOTE: don't try to use this to implement __eq__. Because then\n        # you will be tempted to implement __hash__, which would interfere\n        # with mutability of models. However, not implementing __hash__\n        # will make bokeh unusable in Python 3, where proper implementation\n        # of __hash__ is required when implementing __eq__.\n        if not isinstance(other, self.__class__):\n            return False\n        else:\n            return self.properties_with_values() == other.properties_with_values()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a property value on this object from a JSON - value.", "response": "def set_from_json(self, name, json, models=None, setter=None):\n        ''' Set a property value on this object from JSON.\n\n        Args:\n            name: (str) : name of the attribute to set\n\n            json: (JSON-value) : value to set to the attribute to\n\n            models (dict or None, optional) :\n                Mapping of model ids to models (default: None)\n\n                This is needed in cases where the attributes to update also\n                have values that have references.\n\n            setter(ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        if name in self.properties():\n            log.trace(\"Patching attribute %r of %r with %r\", name, self, json)\n            descriptor = self.lookup(name)\n            descriptor.set_from_json(self, json, models, setter)\n        else:\n            log.warning(\"JSON had attr %r on obj %r, which is a client-only or invalid attribute that shouldn't have been sent\", name, self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the object s properties from a JSON - dict.", "response": "def update_from_json(self, json_attributes, models=None, setter=None):\n        ''' Updates the object's properties from a JSON attributes dictionary.\n\n        Args:\n            json_attributes: (JSON-dict) : attributes and values to update\n\n            models (dict or None, optional) :\n                Mapping of model ids to models (default: None)\n\n                This is needed in cases where the attributes to update also\n                have values that have references.\n\n            setter(ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        for k, v in json_attributes.items():\n            self.set_from_json(k, v, models, setter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect the names of properties defined on this class.", "response": "def properties(cls, with_bases=True):\n        ''' Collect the names of properties on this class.\n\n        This method *optionally* traverses the class hierarchy and includes\n        properties defined on any parent classes.\n\n        Args:\n            with_bases (bool, optional) :\n                Whether to include properties defined on parent classes in\n                the results. (default: True)\n\n        Returns:\n           set[str] : property names\n\n        '''\n        if with_bases:\n            return accumulate_from_superclasses(cls, \"__properties__\")\n        else:\n            return set(cls.__properties__)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncollect a dict mapping property names to their values.", "response": "def properties_with_values(self, include_defaults=True):\n        ''' Collect a dict mapping property names to their values.\n\n        This method *always* traverses the class hierarchy and includes\n        properties defined on any parent classes.\n\n        Non-serializable properties are skipped and property values are in\n        \"serialized\" format which may be slightly different from the values\n        you would normally read from the properties; the intent of this method\n        is to return the information needed to losslessly reconstitute the\n        object instance.\n\n        Args:\n            include_defaults (bool, optional) :\n                Whether to include properties that haven't been explicitly set\n                since the object was created. (default: True)\n\n        Returns:\n           dict : mapping from property names to their values\n\n        '''\n        return self.query_properties_with_values(lambda prop: prop.serialized, include_defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the properties values of |HasProps| instances with a predicate.", "response": "def query_properties_with_values(self, query, include_defaults=True):\n        ''' Query the properties values of |HasProps| instances with a\n        predicate.\n\n        Args:\n            query (callable) :\n                A callable that accepts property descriptors and returns True\n                or False\n\n            include_defaults (bool, optional) :\n                Whether to include properties that have not been explicitly\n                set by a user (default: True)\n\n        Returns:\n            dict : mapping of property names and values for matching properties\n\n        '''\n        themed_keys = set()\n        result = dict()\n        if include_defaults:\n            keys = self.properties()\n        else:\n            # TODO (bev) For now, include unstable default values. Things rely on Instances\n            # always getting serialized, even defaults, and adding unstable defaults here\n            # accomplishes that. Unmodified defaults for property value containers will be\n            # weeded out below.\n            keys = set(self._property_values.keys()) | set(self._unstable_default_values.keys())\n            if self.themed_values():\n                themed_keys = set(self.themed_values().keys())\n                keys |= themed_keys\n\n        for key in keys:\n            descriptor = self.lookup(key)\n            if not query(descriptor):\n                continue\n\n            value = descriptor.serializable_value(self)\n            if not include_defaults and key not in themed_keys:\n                if isinstance(value, PropertyValueContainer) and key in self._unstable_default_values:\n                    continue\n            result[key] = value\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a set of theme values which will be used rather than the application - set values.", "response": "def apply_theme(self, property_values):\n        ''' Apply a set of theme values which will be used rather than\n        defaults, but will not override application-set values.\n\n        The passed-in dictionary may be kept around as-is and shared with\n        other instances to save memory (so neither the caller nor the\n        |HasProps| instance should modify it).\n\n        Args:\n            property_values (dict) : theme values to use in place of defaults\n\n        Returns:\n            None\n\n        '''\n        old_dict = self.themed_values()\n\n        # if the same theme is set again, it should reuse the same dict\n        if old_dict is property_values:\n            return\n\n        removed = set()\n        # we're doing a little song-and-dance to avoid storing __themed_values__ or\n        # an empty dict, if there's no theme that applies to this HasProps instance.\n        if old_dict is not None:\n            removed.update(set(old_dict.keys()))\n        added = set(property_values.keys())\n        old_values = dict()\n        for k in added.union(removed):\n            old_values[k] = getattr(self, k)\n\n        if len(property_values) > 0:\n            setattr(self, '__themed_values__', property_values)\n        elif hasattr(self, '__themed_values__'):\n            delattr(self, '__themed_values__')\n\n        # Property container values might be cached even if unmodified. Invalidate\n        # any cached values that are not modified at this point.\n        for k, v in old_values.items():\n            if k in self._unstable_themed_values:\n                del self._unstable_themed_values[k]\n\n        # Emit any change notifications that result\n        for k, v in old_values.items():\n            descriptor = self.lookup(k)\n            descriptor.trigger_if_changed(self, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nindent all the lines in a given block of text by a specified amount.", "response": "def indent(text, n=2, ch=\" \"):\n    ''' Indent all the lines in a given block of text by a specified amount.\n\n    Args:\n        text (str) :\n            The text to indent\n\n        n (int, optional) :\n            The amount to indent each line by (default: 2)\n\n        ch (char, optional) :\n            What character to fill the indentation with (default: \" \")\n\n    '''\n    padding = ch * n\n    return \"\\n\".join(padding+line for line in text.split(\"\\n\"))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining together sequences of strings into English - friendly phrases using the conjunction or when appropriate.", "response": "def nice_join(seq, sep=\", \", conjuction=\"or\"):\n    ''' Join together sequences of strings into English-friendly phrases using\n    the conjunction ``or`` when appropriate.\n\n    Args:\n        seq (seq[str]) : a sequence of strings to nicely join\n        sep (str, optional) : a sequence delimiter to use (default: \", \")\n        conjunction (str or None, optional) : a conjuction to use for the last\n            two items, or None to reproduce basic join behaviour (default: \"or\")\n\n    Returns:\n        a joined string\n\n    Examples:\n        >>> nice_join([\"a\", \"b\", \"c\"])\n        'a, b or c'\n\n    '''\n    seq = [str(x) for x in seq]\n\n    if len(seq) <= 1 or conjuction is None:\n        return sep.join(seq)\n    else:\n        return \"%s %s %s\" % (sep.join(seq[:-1]), conjuction, seq[-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts CamelCase to snake_case.", "response": "def snakify(name, sep='_'):\n    ''' Convert CamelCase to snake_case. '''\n    name = re.sub(\"([A-Z]+)([A-Z][a-z])\", r\"\\1%s\\2\" % sep, name)\n    name = re.sub(\"([a-z\\\\d])([A-Z])\", r\"\\1%s\\2\" % sep, name)\n    return name.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls any on_session_destroyed callbacks defined on the Document", "response": "def _on_session_destroyed(session_context):\n    '''\n    Calls any on_session_destroyed callbacks defined on the Document\n    '''\n    callbacks = session_context._document.session_destroyed_callbacks\n    session_context._document.session_destroyed_callbacks = set()\n    for callback in callbacks:\n        try:\n            callback(session_context)\n        except Exception as e:\n            log.warning('DocumentLifeCycleHandler on_session_destroyed '\n                        'callback %s failed with following error: %s'\n                        % (callback, e))\n    if callbacks:\n        # If any session callbacks were defined garbage collect after deleting all references\n        del callback\n        del callbacks\n\n        import gc\n        gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pull_session(session_id=None, url='default', io_loop=None, arguments=None):\n    ''' Create a session by loading the current server-side document.\n\n    ``session.document`` will be a fresh document loaded from\n    the server. While the connection to the server is open,\n    changes made on the server side will be applied to this\n    document, and changes made on the client side will be\n    synced to the server.\n\n    If you don't plan to modify ``session.document`` you probably\n    don't need to use this function; instead you can directly\n    ``show_session()`` or ``server_session()`` without downloading\n    the session's document into your process first. It's much\n    more efficient to avoid downloading the session if you don't need\n    to.\n\n    In a production scenario, the ``session_id`` should be\n    unique for each browser tab, which keeps users from\n    stomping on each other. It's neither scalable nor secure to\n    use predictable session IDs or to share session IDs across\n    users.\n\n    For a notebook running on a single machine, ``session_id``\n    could be something human-readable such as ``\"default\"`` for\n    convenience.\n\n    If you allow ``pull_session()`` to generate a unique\n    ``session_id``, you can obtain the generated ID with the\n    ``id`` property on the returned ``ClientSession``.\n\n    Args:\n        session_id (string, optional) :\n            The name of the session, None to autogenerate a random one (default: None)\n\n        url : (str, optional): The URL to a Bokeh application on a Bokeh server\n                can also be `\"default\"` which will connect to the default app URL\n\n        io_loop (``tornado.ioloop.IOLoop``, optional) :\n            The ``IOLoop`` to use for the websocket\n\n        arguments (dict[str, str], optional) :\n            A dictionary of key/values to be passed as HTTP request arguments\n            to Bokeh application code (default: None)\n\n            Note that should only be provided when pulling new sessions.\n            If ``session_id`` is not None, or a session with ``session_id``\n            already exists, these arguments will have no effect.\n\n    Returns:\n        ClientSession :\n            A new ``ClientSession`` connected to the server\n\n    '''\n\n    coords = _SessionCoordinates(session_id=session_id, url=url)\n    session = ClientSession(session_id=session_id, websocket_url=websocket_url_for_server_url(coords.url), io_loop=io_loop, arguments=arguments)\n    session.pull()\n    return session", "response": "Create a new session from the server - side document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new ClientSession connected to the server with the given document.", "response": "def push_session(document, session_id=None, url='default', io_loop=None):\n    ''' Create a session by pushing the given document to the server,\n    overwriting any existing server-side document.\n\n    ``session.document`` in the returned session will be your supplied\n    document. While the connection to the server is open, changes made on the\n    server side will be applied to this document, and changes made on the\n    client side will be synced to the server.\n\n    In a production scenario, the ``session_id`` should be unique for each\n    browser tab, which keeps users from stomping on each other. It's neither\n    scalable nor secure to use predictable session IDs or to share session\n    IDs across users.\n\n    For a notebook running on a single machine, ``session_id`` could be\n    something human-readable such as ``\"default\"`` for convenience.\n\n    If you allow ``push_session()`` to generate a unique ``session_id``, you\n    can obtain the generated ID with the ``id`` property on the returned\n    ``ClientSession``.\n\n    Args:\n        document : (bokeh.document.Document)\n            The document to be pushed and set as session.document\n\n        session_id : (string, optional)\n            The name of the session, None to autogenerate a random one (default: None)\n\n        url : (str, optional): The URL to a Bokeh application on a Bokeh server\n            can also be `\"default\"` which will connect to the default app URL\n\n        io_loop : (tornado.ioloop.IOLoop, optional)\n            The IOLoop to use for the websocket\n\n    Returns:\n        ClientSession\n            A new ClientSession connected to the server\n\n    '''\n    coords = _SessionCoordinates(session_id=session_id, url=url)\n    session = ClientSession(session_id=coords.session_id, websocket_url=websocket_url_for_server_url(coords.url), io_loop=io_loop)\n    session.push(document)\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_session(session_id=None, url='default', session=None, browser=None, new=\"tab\", controller=None):\n        ''' Open a browser displaying a session document.\n\n        If you have a session from ``pull_session()`` or ``push_session`` you\n        can ``show_session(session=mysession)``. If you don't need to open a\n        connection to the server yourself, you can show a new session in a\n        browser by providing just the ``url``.\n\n        Args:\n            session_id (string, optional) :\n               The name of the session, None to autogenerate a random one (default: None)\n\n            url : (str, optional): The URL to a Bokeh application on a Bokeh server\n                can also be `\"default\"` which will connect to the default app URL\n\n            session (ClientSession, optional) : session to get session ID and server URL from\n                If you specify this, you don't need to specify session_id and url\n\n            browser (str, optional) : browser to show with (default: None)\n                For systems that support it, the **browser** argument allows\n                specifying which browser to display in, e.g. \"safari\", \"firefox\",\n                \"opera\", \"windows-default\" (see the ``webbrowser`` module\n                documentation in the standard lib for more details).\n\n            new (str, optional) : new file output mode (default: \"tab\")\n                For file-based output, opens or raises the browser window\n                showing the current output file.  If **new** is 'tab', then\n                opens a new tab. If **new** is 'window', then opens a new window.\n\n        '''\n        if session is not None:\n            server_url = server_url_for_websocket_url(session._connection.url)\n            session_id = session.id\n        else:\n            coords = _SessionCoordinates(session_id=session_id, url=url)\n            server_url = coords.url\n            session_id = coords.session_id\n\n        if controller is None:\n            from bokeh.util.browser import get_browser_controller\n            controller = get_browser_controller(browser=browser)\n\n        controller.open(server_url + \"?bokeh-session-id=\" + quote_plus(session_id),\n                        new=NEW_PARAM[new])", "response": "Open a browser showing a session document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loop_until_closed(self, suppress_warning=False):\n        ''' Execute a blocking loop that runs and executes event callbacks\n        until the connection is closed (e.g. by hitting Ctrl-C).\n\n        While this method can be used to run Bokeh application code \"outside\"\n        the Bokeh server, this practice is HIGHLY DISCOURAGED for any real\n        use case. This function is intented to facilitate testing ONLY.\n\n        '''\n\n        suppress_warning # shut up flake\n\n        from bokeh.util.deprecation import deprecated\n        deprecated(\"ClientSession.loop_until_closed is deprecated, and will be removed in an eventual 2.0 release. \"\n                   \"Run Bokeh applications directly on a Bokeh server instead. See:\\n\\n\"\n                   \"    https//docs.bokeh.org/en/latest/docs/user_guide/server.html\\n\")\n\n        self._connection.loop_until_closed()", "response": "Execute a blocking loop that runs and executes event callbacks\n        until the connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pull(self):\n        ''' Pull the server's state and set it as session.document.\n\n        If this is called more than once, session.document will be the same\n        object instance but its contents will be overwritten.\n\n        Automatically calls :func:`connect` before pulling.\n\n        '''\n        self.connect()\n        if not self.connected:\n            raise IOError(\"Cannot pull session document because we failed to connect to the server (to start the server, try the 'bokeh serve' command)\")\n\n        if self.document is None:\n            doc = Document()\n        else:\n            doc = self.document\n        self._connection.pull_doc(doc)\n        if self.document is None:\n            self._attach_document(doc)", "response": "Pull the server s state and set it as session. document.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push(self, document=None):\n        ''' Push the given document to the server and record it as session.document.\n\n        If this is called more than once, the Document has to be the same (or None\n        to mean \"session.document\").\n\n        .. note::\n            Automatically calls :func:`~connect` before pushing.\n\n        Args:\n            document (:class:`~bokeh.document.Document`, optional) :\n                The document which will be kept in sync with the server document.\n                None to use session.document or create a new document.\n\n        '''\n        if self.document is None:\n            if document is None:\n                doc = Document()\n            else:\n                doc = document\n        else:\n            if document is None:\n                doc = self.document\n            else:\n                raise ValueError(\"Cannot push() a different document from existing session.document\")\n\n        self.connect()\n        if not self.connected:\n            raise IOError(\"Cannot push session document because we failed to connect to the server (to start the server, try the 'bokeh serve' command)\")\n        self._connection.push_doc(doc)\n        if self._document is None:\n            self._attach_document(doc)", "response": "Push the given document to the server and record it as session. document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens a browser displaying this session.", "response": "def show(self, obj=None, browser=None, new=\"tab\"):\n        ''' Open a browser displaying this session.\n\n        Args:\n            obj (LayoutDOM object, optional) : a Layout (Row/Column),\n                Plot or Widget object to display. The object will be added\n                to the session's document.\n\n            browser (str, optional) : browser to show with (default: None)\n                For systems that support it, the **browser** argument allows\n                specifying which browser to display in, e.g. \"safari\", \"firefox\",\n                \"opera\", \"windows-default\" (see the ``webbrowser`` module\n                documentation in the standard lib for more details).\n\n            new (str, optional) : new file output mode (default: \"tab\")\n                For file-based output, opens or raises the browser window\n                showing the current output file.  If **new** is 'tab', then\n                opens a new tab. If **new** is 'window', then opens a new window.\n\n        '''\n        if obj and obj not in self.document.roots:\n            self.document.add_root(obj)\n        show_session(session=self, browser=browser, new=new)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling by the client when the connection is disconnected.", "response": "def _notify_disconnected(self):\n        ''' Called by the ClientConnection we are using to notify us of disconnect.\n\n        '''\n        if self.document is not None:\n            self.document.remove_on_change(self)\n            self._callbacks.remove_all_callbacks()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassemble a new message from JSON fragments.", "response": "def assemble(cls, header_json, metadata_json, content_json):\n        ''' Creates a new message, assembled from JSON fragments.\n\n        Args:\n            header_json (``JSON``) :\n\n            metadata_json (``JSON``) :\n\n            content_json (``JSON``) :\n\n        Returns:\n            Message subclass\n\n        Raises:\n            MessageError\n\n        '''\n\n        try:\n            header = json_decode(header_json)\n        except ValueError:\n            raise MessageError(\"header could not be decoded\")\n\n        try:\n            metadata = json_decode(metadata_json)\n        except ValueError:\n            raise MessageError(\"metadata could not be decoded\")\n\n        try:\n            content = json_decode(content_json)\n        except ValueError:\n            raise MessageError(\"content could not be decoded\")\n\n        msg = cls(header, metadata, content)\n\n        msg._header_json = header_json\n        msg._metadata_json = metadata_json\n        msg._content_json = content_json\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_buffer(self, buf_header, buf_payload):\n        ''' Associate a buffer header and payload with this message.\n\n        Args:\n            buf_header (``JSON``) : a buffer header\n            buf_payload (``JSON`` or bytes) : a buffer payload\n\n        Returns:\n            None\n\n        Raises:\n            MessageError\n\n        '''\n        if 'num_buffers' in self._header:\n            self._header['num_buffers'] += 1\n        else:\n            self._header['num_buffers'] = 1\n\n        self._header_json = None\n\n        self._buffers.append((buf_header, buf_payload))", "response": "Associate a buffer header and payload with this message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assemble_buffer(self, buf_header, buf_payload):\n        ''' Add a buffer header and payload that we read from the socket.\n\n        This differs from add_buffer() because we're validating vs.\n        the header's num_buffers, instead of filling in the header.\n\n        Args:\n            buf_header (``JSON``) : a buffer header\n            buf_payload (``JSON`` or bytes) : a buffer payload\n\n        Returns:\n            None\n\n        Raises:\n            ProtocolError\n        '''\n        if self.header.get('num_buffers', 0) <= len(self._buffers):\n            raise ProtocolError(\"too many buffers received expecting \" + str(self.header['num_buffers']))\n        self._buffers.append((buf_header, buf_payload))", "response": "Assemble a buffer header and payload."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_buffers(self, conn, locked=True):\n        ''' Write any buffer headers and payloads to the given connection.\n\n        Args:\n            conn (object) :\n                May be any object with a ``write_message`` method. Typically,\n                a Tornado ``WSHandler`` or ``WebSocketClientConnection``\n\n            locked (bool) :\n\n        Returns:\n            int : number of bytes sent\n\n        '''\n        if conn is None:\n            raise ValueError(\"Cannot write_buffers to connection None\")\n        sent = 0\n        for header, payload in self._buffers:\n            yield conn.write_message(header, locked=locked)\n            yield conn.write_message(payload, binary=True, locked=locked)\n            sent += (len(header) + len(payload))\n        raise gen.Return(sent)", "response": "Write any buffered messages to the given connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_header(cls, request_id=None):\n        ''' Return a message header fragment dict.\n\n        Args:\n            request_id (str or None) :\n                Message ID of the message this message replies to\n\n        Returns:\n            dict : a message header\n\n        '''\n        header = {\n            'msgid'   : bkserial.make_id(),\n            'msgtype' : cls.msgtype\n        }\n        if request_id is not None:\n            header['reqid'] = request_id\n        return header", "response": "Create a message header fragment dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the message on the given connection.", "response": "def send(self, conn):\n        ''' Send the message on the given connection.\n\n        Args:\n            conn (WebSocketHandler) : a WebSocketHandler to send messages\n\n        Returns:\n            int : number of bytes sent\n\n        '''\n        if conn is None:\n            raise ValueError(\"Cannot send to connection None\")\n\n        with (yield conn.write_lock.acquire()):\n            sent = 0\n\n            yield conn.write_message(self.header_json, locked=False)\n            sent += len(self.header_json)\n\n            # uncomment this to make it a lot easier to reproduce lock-related bugs\n            #yield gen.sleep(0.1)\n\n            yield conn.write_message(self.metadata_json, locked=False)\n            sent += len(self.metadata_json)\n\n            # uncomment this to make it a lot easier to reproduce lock-related bugs\n            #yield gen.sleep(0.1)\n\n            yield conn.write_message(self.content_json, locked=False)\n            sent += len(self.content_json)\n\n            sent += yield self.write_buffers(conn, locked=False)\n\n            raise gen.Return(sent)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if all required parts of a message are present.", "response": "def complete(self):\n        ''' Returns whether all required parts of a message are present.\n\n        Returns:\n            bool : True if the message is complete, False otherwise\n\n        '''\n        return self.header is not None and \\\n            self.metadata is not None and \\\n            self.content is not None and \\\n            self.header.get('num_buffers', 0) == len(self._buffers)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nissues a nicely formatted deprecation warning.", "response": "def deprecated(since_or_msg, old=None, new=None, extra=None):\n    \"\"\" Issue a nicely formatted deprecation warning. \"\"\"\n\n    if isinstance(since_or_msg, tuple):\n        if old is None or new is None:\n            raise ValueError(\"deprecated entity and a replacement are required\")\n\n        if len(since_or_msg) != 3 or not all(isinstance(x, int) and x >=0 for x in since_or_msg):\n            raise ValueError(\"invalid version tuple: %r\" % (since_or_msg,))\n\n        since = \"%d.%d.%d\" % since_or_msg\n        message = \"%(old)s was deprecated in Bokeh %(since)s and will be removed, use %(new)s instead.\"\n        message = message % dict(old=old, since=since, new=new)\n        if extra is not None:\n            message += \" \" + extra.strip()\n    elif isinstance(since_or_msg, six.string_types):\n        if not (old is None and new is None and extra is None):\n            raise ValueError(\"deprecated(message) signature doesn't allow extra arguments\")\n\n        message = since_or_msg\n    else:\n        raise ValueError(\"expected a version tuple or string message\")\n\n    warn(message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    ''' Execute the \"bokeh\" command line program.\n\n    '''\n    import sys\n    from bokeh.command.bootstrap import main as _main\n\n   # Main entry point (see setup.py)\n    _main(sys.argv)", "response": "Execute the bokeh command line program."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetach the session from the user.", "response": "def detach_session(self):\n        \"\"\"Allow the session to be discarded and don't get change notifications from it anymore\"\"\"\n        if self._session is not None:\n            self._session.unsubscribe(self)\n            self._session = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a PATCH - DOC message to the server returning a Future that s completed when it s written out.", "response": "def send_patch_document(self, event):\n        \"\"\" Sends a PATCH-DOC message, returning a Future that's completed when it's written out. \"\"\"\n        msg = self.protocol.create('PATCH-DOC', [event])\n        return self._socket.send_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_references_json(references_json, references, setter=None):\n    ''' Given a JSON representation of the models in a graph, and new model\n    objects, set the properties on the models from the JSON\n\n    Args:\n        references_json (``JSON``)\n            JSON specifying attributes and values to initialize new model\n            objects with.\n\n        references (dict[str, Model])\n            A dictionary mapping model IDs to newly created (but not yet\n            initialized) Bokeh models.\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n        setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n    '''\n\n    for obj in references_json:\n        obj_id = obj['id']\n        obj_attrs = obj['attributes']\n\n        instance = references[obj_id]\n\n        # We want to avoid any Model specific initialization that happens with\n        # Slider(...) when reconstituting from JSON, but we do need to perform\n        # general HasProps machinery that sets properties, so call it explicitly\n        HasProps.__init__(instance)\n\n        instance.update_from_json(obj_attrs, models=references, setter=setter)", "response": "Given a JSON representation of the models in a graph and a dictionary of model IDs and model objects initialize the properties on the models in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef instantiate_references_json(references_json):\n    ''' Given a JSON representation of all the models in a graph, return a\n    dict of new model objects.\n\n    Args:\n        references_json (``JSON``)\n            JSON specifying new Bokeh models to create\n\n    Returns:\n        dict[str, Model]\n\n    '''\n\n    # Create all instances, but without setting their props\n    references = {}\n    for obj in references_json:\n        obj_id = obj['id']\n        obj_type = obj.get('subtype', obj['type'])\n\n        cls = get_class(obj_type)\n        instance = cls.__new__(cls, id=obj_id)\n        if instance is None:\n            raise RuntimeError('Error loading model from JSON (type: %s, id: %s)' % (obj_type, obj_id))\n        references[instance.id] = instance\n\n    return references", "response": "Given a JSON representation of all the models in a graph return a dictionary of new model objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef references_json(references):\n    ''' Given a list of all models in a graph, return JSON representing\n    them and their properties.\n\n    Args:\n        references (seq[Model]) :\n            A list of models to convert to JSON\n\n    Returns:\n        list\n\n    '''\n\n    references_json = []\n    for r in references:\n        ref = r.ref\n        ref['attributes'] = r._to_json_like(include_defaults=False)\n        references_json.append(ref)\n\n    return references_json", "response": "Given a list of all models in a graph return JSON representing them and their properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bokeh_palette(name, rawtext, text, lineno, inliner, options=None, content=None):\n    ''' Generate an inline visual representations of a single color palette.\n\n    This function evaluates the expression ``\"palette = %s\" % text``, in the\n    context of a ``globals`` namespace that has previously imported all of\n    ``bokeh.plotting``. The resulting value for ``palette`` is used to\n    construct a sequence of HTML ``<span>`` elements for each color.\n\n    If evaluating the palette expression fails or does not produce a list or\n    tuple of all strings, then a SphinxError is raised to terminate the build.\n\n    For details on the arguments to this function, consult the Docutils docs:\n\n    http://docutils.sourceforge.net/docs/howto/rst-roles.html#define-the-role-function\n\n    '''\n    try:\n        exec(\"palette = %s\" % text, _globals)\n    except Exception as e:\n        raise SphinxError(\"cannot evaluate palette expression '%r', reason: %s\" % (text, e))\n    p = _globals.get('palette', None)\n    if not isinstance(p, (list, tuple)) or not all(isinstance(x, str) for x in p):\n        raise SphinxError(\"palette expression '%r' generated invalid or no output: %s\" % (text, p))\n    w = 20 if len(p) < 15 else 10 if len(p) < 32 else 5 if len(p) < 64 else 2 if len(p) < 128 else 1\n    html = PALETTE_DETAIL.render(palette=p, width=w)\n    node = nodes.raw('', html, format=\"html\")\n    return [node], []", "response": "Generate an inline visual representation of a single color palette."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a DataSpec dict to generate a CumSum expression for a ColumnDataSource.", "response": "def cumsum(field, include_zero=False):\n    ''' Create a Create a ``DataSpec`` dict to generate a ``CumSum`` expression\n    for a ``ColumnDataSource``.\n\n    Examples:\n\n        .. code-block:: python\n\n            p.wedge(start_angle=cumsum('angle', include_zero=True),\n                    end_angle=cumsum('angle'),\n                    ...)\n\n        will generate a ``CumSum`` expressions that sum the ``\"angle\"`` column\n        of a data source. For the ``start_angle`` value, the cumulative sums\n        will start with a zero value. For ``start_angle``, no initial zero will\n        be added (i.e. the sums will start with the first angle value, and\n        include the last).\n\n    '''\n    return expr(CumSum(field=field, include_zero=include_zero))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dodge(field_name, value, range=None):\n    ''' Create a ``DataSpec`` dict that applies a client-side ``Jitter``\n    transformation to a ``ColumnDataSource`` column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        value (float) : the fixed offset to add to column data\n\n        range (Range, optional) : a range to use for computing synthetic\n            coordinates when necessary, e.g. a ``FactorRange`` when the\n            column data is categorical (default: None)\n\n    Returns:\n        dict\n\n    '''\n    return field(field_name, Dodge(value=value, range=range))", "response": "Creates a DataSpec dict that applies a client - side Jitter transformation to a column."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a DataSpec dict that applies a client - side CategoricalColorMapper transformation to a columnDataSource.", "response": "def factor_cmap(field_name, palette, factors, start=0, end=None, nan_color=\"gray\"):\n    ''' Create a ``DataSpec`` dict that applies a client-side\n    ``CategoricalColorMapper`` transformation to a ``ColumnDataSource``\n    column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        palette (seq[color]) : a list of colors to use for colormapping\n\n        factors (seq) : a sequences of categorical factors corresponding to\n            the palette\n\n        start (int, optional) : a start slice index to apply when the column\n            data has factors with multiple levels. (default: 0)\n\n        end (int, optional) : an end slice index to apply when the column\n            data has factors with multiple levels. (default: None)\n\n        nan_color (color, optional) : a default color to use when mapping data\n            from a column does not succeed (default: \"gray\")\n\n    Returns:\n        dict\n\n    '''\n    return field(field_name, CategoricalColorMapper(palette=palette,\n                                                    factors=factors,\n                                                    start=start,\n                                                    end=end,\n                                                    nan_color=nan_color))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef factor_hatch(field_name, patterns, factors, start=0, end=None):\n    ''' Create a ``DataSpec`` dict that applies a client-side\n    ``CategoricalPatternMapper`` transformation to a ``ColumnDataSource``\n    column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        patterns (seq[string]) : a list of hatch patterns to use to map to\n\n        factors (seq) : a sequences of categorical factors corresponding to\n            the palette\n\n        start (int, optional) : a start slice index to apply when the column\n            data has factors with multiple levels. (default: 0)\n\n        end (int, optional) : an end slice index to apply when the column\n            data has factors with multiple levels. (default: None)\n\n    Returns:\n        dict\n\n    Added in version 1.1.1\n\n    '''\n    return field(field_name, CategoricalPatternMapper(patterns=patterns,\n                                                      factors=factors,\n                                                      start=start,\n                                                      end=end))", "response": "Creates a DataSpec dict that applies a client - side CategoricalPatternMapper transformation to a column - source column."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a DataSpec dict that applies a client - side CategoricalMarkerMapper transformation to a columnDataSource column.", "response": "def factor_mark(field_name, markers, factors, start=0, end=None):\n    ''' Create a ``DataSpec`` dict that applies a client-side\n    ``CategoricalMarkerMapper`` transformation to a ``ColumnDataSource``\n    column.\n\n    .. note::\n        This transform is primarily only useful with ``scatter``, which\n        can be parameterized by glyph type.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        markers (seq[string]) : a list of markers to use to map to\n\n        factors (seq) : a sequences of categorical factors corresponding to\n            the palette\n\n        start (int, optional) : a start slice index to apply when the column\n            data has factors with multiple levels. (default: 0)\n\n        end (int, optional) : an end slice index to apply when the column\n            data has factors with multiple levels. (default: None)\n\n    Returns:\n        dict\n\n    '''\n    return field(field_name, CategoricalMarkerMapper(markers=markers,\n                                                     factors=factors,\n                                                     start=start,\n                                                     end=end))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jitter(field_name, width, mean=0, distribution=\"uniform\", range=None):\n    ''' Create a ``DataSpec`` dict that applies a client-side ``Jitter``\n    transformation to a ``ColumnDataSource`` column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        width (float) : the width of the random distribution to apply\n\n        mean (float, optional) : an offset to apply (default: 0)\n\n        distribution (str, optional) : ``\"uniform\"`` or ``\"normal\"``\n            (default: ``\"uniform\"``)\n\n        range (Range, optional) : a range to use for computing synthetic\n            coordinates when necessary, e.g. a ``FactorRange`` when the\n            column data is categorical (default: None)\n\n    Returns:\n        dict\n\n    '''\n    return field(field_name, Jitter(mean=mean,\n                                    width=width,\n                                    distribution=distribution,\n                                    range=range))", "response": "Creates a DataSpec dict that applies a client - side jitter transformation to a synthetic node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a DataSpec dict that applies a LinearColorMapper transformation to a ColumnDataSource column.", "response": "def linear_cmap(field_name, palette, low, high, low_color=None, high_color=None, nan_color=\"gray\"):\n    ''' Create a ``DataSpec`` dict that applyies a client-side\n    ``LinearColorMapper`` transformation to a ``ColumnDataSource`` column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        palette (seq[color]) : a list of colors to use for colormapping\n\n        low (float) : a minimum value of the range to map into the palette.\n            Values below this are clamped to ``low``.\n\n        high (float) : a maximum value of the range to map into the palette.\n            Values above this are clamped to ``high``.\n\n        low_color (color, optional) : color to be used if data is lower than\n            ``low`` value. If None, values lower than ``low`` are mapped to the\n            first color in the palette. (default: None)\n\n        high_color (color, optional) : color to be used if data is higher than\n            ``high`` value. If None, values higher than ``high`` are mapped to\n            the last color in the palette. (default: None)\n\n        nan_color (color, optional) : a default color to use when mapping data\n            from a column does not succeed (default: \"gray\")\n\n    '''\n    return field(field_name, LinearColorMapper(palette=palette,\n                                               low=low,\n                                               high=high,\n                                               nan_color=nan_color,\n                                               low_color=low_color,\n                                               high_color=high_color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a DataSpec dict that applies a client - side LogColorMapper transformation to a column.", "response": "def log_cmap(field_name, palette, low, high, low_color=None, high_color=None, nan_color=\"gray\"):\n    ''' Create a ``DataSpec`` dict that applies a client-side ``LogColorMapper``\n    transformation to a ``ColumnDataSource`` column.\n\n    Args:\n        field_name (str) : a field name to configure ``DataSpec`` with\n\n        palette (seq[color]) : a list of colors to use for colormapping\n\n        low (float) : a minimum value of the range to map into the palette.\n            Values below this are clamped to ``low``.\n\n        high (float) : a maximum value of the range to map into the palette.\n            Values above this are clamped to ``high``.\n\n        low_color (color, optional) : color to be used if data is lower than\n            ``low`` value. If None, values lower than ``low`` are mapped to the\n            first color in the palette. (default: None)\n\n        high_color (color, optional) : color to be used if data is higher than\n            ``high`` value. If None, values higher than ``high`` are mapped to\n            the last color in the palette. (default: None)\n\n        nan_color (color, optional) : a default color to use when mapping data\n            from a column does not succeed (default: \"gray\")\n\n    '''\n    return field(field_name, LogColorMapper(palette=palette,\n                                            low=low,\n                                            high=high,\n                                            nan_color=nan_color,\n                                            low_color=low_color,\n                                            high_color=high_color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_browser_controller(browser=None):\n    ''' Return a browser controller.\n\n    Args:\n        browser (str or None) : browser name, or ``None`` (default: ``None``)\n            If passed the string ``'none'``, a dummy web browser controller\n            is returned\n\n            Otherwise, use the value to select an appropriate controller using\n            the ``webbrowser`` standard library module. In the value is\n            ``None`` then a system default is used.\n\n    .. note::\n        If the environment variable ``BOKEH_BROWSER`` is set, it will take\n        precedence.\n\n    Returns:\n        controller : a web browser controller\n\n    '''\n    browser = settings.browser(browser)\n\n    if browser is not None:\n        if browser == 'none':\n            controller = DummyWebBrowser()\n        else:\n            controller = webbrowser.get(browser)\n    else:\n        controller = webbrowser\n\n    return controller", "response": "Return a web browser controller."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef view(location, browser=None, new=\"same\", autoraise=True):\n        ''' Open a browser to view the specified location.\n\n        Args:\n            location (str) : Location to open\n                If location does not begin with \"http:\" it is assumed\n                to be a file path on the local filesystem.\n            browser (str or None) : what browser to use (default: None)\n                If ``None``, use the system default browser.\n            new (str) : How to open the location. Valid values are:\n\n                ``'same'`` - open in the current tab\n\n                ``'tab'`` - open a new tab in the current window\n\n                ``'window'`` - open in a new window\n            autoraise (bool) : Whether to automatically raise the location\n                in a new browser window (default: True)\n\n        Returns:\n            None\n\n        '''\n        try:\n            new = { \"same\": 0, \"window\": 1, \"tab\": 2 }[new]\n        except KeyError:\n            raise RuntimeError(\"invalid 'new' value passed to view: %r, valid values are: 'same', 'window', or 'tab'\" % new)\n\n        if location.startswith(\"http\"):\n            url = location\n        else:\n            url = \"file://\" + abspath(location)\n\n        try:\n            controller = get_browser_controller(browser)\n            controller.open(url, new=new, autoraise=autoraise)\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            pass", "response": "Open a browser to view the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_py_func(cls, func):\n        ''' Create a ``CustomJSFilter`` instance from a Python function. The\n        function is translated to JavaScript using PScript.\n\n        The ``func`` function namespace will contain the variable ``source``\n        at render time. This will be the data source associated with the ``CDSView``\n        that this filter is added to.\n        '''\n        from bokeh.util.deprecation import deprecated\n        deprecated(\"'from_py_func' is deprecated and will be removed in an eventual 2.0 release. \"\n                   \"Use CustomJSFilter directly instead.\")\n\n        if not isinstance(func, FunctionType):\n            raise ValueError('CustomJSFilter.from_py_func only accepts function objects.')\n\n        pscript = import_required(\n            'pscript',\n            dedent(\"\"\"\\\n                To use Python functions for CustomJSFilter, you need PScript\n                '(\"conda install -c conda-forge pscript\" or \"pip install pscript\")\"\"\")\n            )\n\n        argspec = inspect.getargspec(func)\n\n        default_names = argspec.args\n        default_values = argspec.defaults or []\n\n        if len(default_names) - len(default_values) != 0:\n            raise ValueError(\"Function may only contain keyword arguments.\")\n\n        # should the following be all of the values need to be Models?\n        if default_values and not any(isinstance(value, Model) for value in default_values):\n            raise ValueError(\"Default value must be a plot object.\")\n\n        func_kwargs = dict(zip(default_names, default_values))\n        code = pscript.py2js(func, 'filter') + 'return filter(%s);\\n' % ', '.join(default_names)\n\n        return cls(code=code, args=func_kwargs)", "response": "Create a CustomJSFilter instance from a Python function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef streamlines(x, y, u, v, density=1):\n    ''' Return streamlines of a vector flow.\n\n    * x and y are 1d arrays defining an *evenly spaced* grid.\n    * u and v are 2d arrays (shape [y,x]) giving velocities.\n    * density controls the closeness of the streamlines. For different\n      densities in each direction, use a tuple or list [densityx, densityy].\n\n    '''\n\n    ## Set up some constants - size of the grid used.\n    NGX = len(x)\n    NGY = len(y)\n\n    ## Constants used to convert between grid index coords and user coords.\n    DX = x[1]-x[0]\n    DY = y[1]-y[0]\n    XOFF = x[0]\n    YOFF = y[0]\n\n    ## Now rescale velocity onto axes-coordinates\n    u = u / (x[-1]-x[0])\n    v = v / (y[-1]-y[0])\n    speed = np.sqrt(u*u+v*v)\n    ## s (path length) will now be in axes-coordinates, but we must\n    ## rescale u for integrations.\n    u *= NGX\n    v *= NGY\n    ## Now u and v in grid-coordinates.\n\n    NBX = int(30*density)\n    NBY = int(30*density)\n    blank = np.zeros((NBY,NBX))\n\n    bx_spacing = NGX/float(NBX-1)\n    by_spacing = NGY/float(NBY-1)\n\n    def blank_pos(xi, yi):\n        return int((xi / bx_spacing) + 0.5), \\\n               int((yi / by_spacing) + 0.5)\n\n    def value_at(a, xi, yi):\n        if type(xi) == np.ndarray:\n            x = xi.astype(np.int)\n            y = yi.astype(np.int)\n        else:\n            x = np.int(xi)\n            y = np.int(yi)\n        a00 = a[y,x]\n        a01 = a[y,x+1]\n        a10 = a[y+1,x]\n        a11 = a[y+1,x+1]\n        xt = xi - x\n        yt = yi - y\n        a0 = a00*(1-xt) + a01*xt\n        a1 = a10*(1-xt) + a11*xt\n        return a0*(1-yt) + a1*yt\n\n    def rk4_integrate(x0, y0):\n        ## This function does RK4 forward and back trajectories from\n        ## the initial conditions, with the odd 'blank array'\n        ## termination conditions. TODO tidy the integration loops.\n\n        def f(xi, yi):\n            dt_ds = 1./value_at(speed, xi, yi)\n            ui = value_at(u, xi, yi)\n            vi = value_at(v, xi, yi)\n            return ui*dt_ds, vi*dt_ds\n\n        def g(xi, yi):\n            dt_ds = 1./value_at(speed, xi, yi)\n            ui = value_at(u, xi, yi)\n            vi = value_at(v, xi, yi)\n            return -ui*dt_ds, -vi*dt_ds\n\n        check = lambda xi, yi: xi>=0 and xi<NGX-1 and yi>=0 and yi<NGY-1\n\n        bx_changes = []\n        by_changes = []\n\n        ## Integrator function\n        def rk4(x0, y0, f):\n            ds = 0.01 #min(1./NGX, 1./NGY, 0.01)\n            stotal = 0\n            xi = x0\n            yi = y0\n            xb, yb = blank_pos(xi, yi)\n            xf_traj = []\n            yf_traj = []\n            while check(xi, yi):\n                # Time step. First save the point.\n                xf_traj.append(xi)\n                yf_traj.append(yi)\n                # Next, advance one using RK4\n                try:\n                    k1x, k1y = f(xi, yi)\n                    k2x, k2y = f(xi + .5*ds*k1x, yi + .5*ds*k1y)\n                    k3x, k3y = f(xi + .5*ds*k2x, yi + .5*ds*k2y)\n                    k4x, k4y = f(xi + ds*k3x, yi + ds*k3y)\n                except IndexError:\n                    # Out of the domain on one of the intermediate steps\n                    break\n                xi += ds*(k1x+2*k2x+2*k3x+k4x) / 6.\n                yi += ds*(k1y+2*k2y+2*k3y+k4y) / 6.\n                # Final position might be out of the domain\n                if not check(xi, yi): break\n                stotal += ds\n                # Next, if s gets to thres, check blank.\n                new_xb, new_yb = blank_pos(xi, yi)\n                if new_xb != xb or new_yb != yb:\n                    # New square, so check and colour. Quit if required.\n                    if blank[new_yb,new_xb] == 0:\n                        blank[new_yb,new_xb] = 1\n                        bx_changes.append(new_xb)\n                        by_changes.append(new_yb)\n                        xb = new_xb\n                        yb = new_yb\n                    else:\n                        break\n                if stotal > 2:\n                    break\n            return stotal, xf_traj, yf_traj\n\n        integrator = rk4\n\n        sf, xf_traj, yf_traj = integrator(x0, y0, f)\n        sb, xb_traj, yb_traj = integrator(x0, y0, g)\n        stotal = sf + sb\n        x_traj = xb_traj[::-1] + xf_traj[1:]\n        y_traj = yb_traj[::-1] + yf_traj[1:]\n\n        ## Tests to check length of traj. Remember, s in units of axes.\n        if len(x_traj) < 1: return None\n        if stotal > .2:\n            initxb, inityb = blank_pos(x0, y0)\n            blank[inityb, initxb] = 1\n            return x_traj, y_traj\n        else:\n            for xb, yb in zip(bx_changes, by_changes):\n                blank[yb, xb] = 0\n            return None\n\n    ## A quick function for integrating trajectories if blank==0.\n    trajectories = []\n    def traj(xb, yb):\n        if xb < 0 or xb >= NBX or yb < 0 or yb >= NBY:\n            return\n        if blank[yb, xb] == 0:\n            t = rk4_integrate(xb*bx_spacing, yb*by_spacing)\n            if t is not None:\n                trajectories.append(t)\n\n    ## Now we build up the trajectory set. I've found it best to look\n    ## for blank==0 along the edges first, and work inwards.\n    for indent in range((max(NBX,NBY))//2):\n        for xi in range(max(NBX,NBY)-2*indent):\n            traj(xi+indent, indent)\n            traj(xi+indent, NBY-1-indent)\n            traj(indent, xi+indent)\n            traj(NBX-1-indent, xi+indent)\n\n    xs = [np.array(t[0])*DX+XOFF for t in trajectories]\n    ys = [np.array(t[1])*DY+YOFF for t in trajectories]\n\n    return xs, ys", "response": "Return a streamline of a vector flow."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_event(div, attributes=[]):\n    style = 'float: left; clear: left; font-size: 10pt'\n    return CustomJS(args=dict(div=div), code=\"\"\"\n        var attrs = %s;\n        var args = [];\n        for (var i = 0; i<attrs.length; i++ ) {\n            var val = JSON.stringify(cb_obj[attrs[i]], function(key, val) {\n                return val.toFixed ? Number(val.toFixed(2)) : val;\n            })\n            args.push(attrs[i] + '=' + val)\n        }\n        var line = \"<span style=%r><b>\" + cb_obj.event_name + \"</b>(\" + args.join(\", \") + \")</span>\\\\n\";\n        var text = div.text.concat(line);\n        var lines = text.split(\"\\\\n\")\n        if (lines.length > 35)\n            lines.shift();\n        div.text = lines.join(\"\\\\n\");\n    \"\"\" % (attributes, style))", "response": "Function to build a suitable CustomJS to display the current event in the div model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a Python callback that returns a Python function that prints the events.", "response": "def print_event(attributes=[]):\n    \"\"\"\n    Function that returns a Python callback to pretty print the events.\n    \"\"\"\n    def python_callback(event):\n        cls_name = event.__class__.__name__\n        attrs = ', '.join(['{attr}={val}'.format(attr=attr, val=event.__dict__[attr])\n                       for attr in attributes])\n        print('{cls_name}({attrs})'.format(cls_name=cls_name, attrs=attrs))\n    return python_callback"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new Message instance for the given type.", "response": "def create(self, msgtype, *args, **kwargs):\n        ''' Create a new Message instance for the given type.\n\n        Args:\n            msgtype (str) :\n\n        '''\n        if msgtype not in self._messages:\n            raise ProtocolError(\"Unknown message type %r for protocol version %s\" % (msgtype, self._version))\n        return self._messages[msgtype].create(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assemble(self, header_json, metadata_json, content_json):\n        ''' Create a Message instance assembled from json fragments.\n\n        Args:\n            header_json (``JSON``) :\n\n            metadata_json (``JSON``) :\n\n            content_json (``JSON``) :\n\n        Returns:\n            message\n\n        '''\n        header = json_decode(header_json)\n        if 'msgtype' not in header:\n            log.error(\"Bad header with no msgtype was: %r\", header)\n            raise ProtocolError(\"No 'msgtype' in header\")\n        return self._messages[header['msgtype']].assemble(\n            header_json, metadata_json, content_json\n        )", "response": "Assemble a message from json fragments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to combine a new event with a list of previous events. The ``old_event`` will be scanned in reverse, and ``.combine(new_event)`` will be called on each. If a combination can be made, the function will return immediately. Otherwise, ``new_event`` will be appended to ``old_events``. Args: new_event (DocumentChangedEvent) : The new event to attempt to combine old_events (list[DocumentChangedEvent]) A list of previous events to attempt to combine new_event with **This is an \"out\" parameter**. The values it contains will be modified in-place. Returns: None", "response": "def _combine_document_events(new_event, old_events):\n    ''' Attempt to combine a new event with a list of previous events.\n\n    The ``old_event`` will be scanned in reverse, and ``.combine(new_event)``\n    will be called on each. If a combination can be made, the function\n    will return immediately. Otherwise, ``new_event`` will be appended to\n    ``old_events``.\n\n    Args:\n        new_event (DocumentChangedEvent) :\n            The new event to attempt to combine\n\n        old_events (list[DocumentChangedEvent])\n            A list of previous events to attempt to combine new_event with\n\n            **This is an \"out\" parameter**. The values it contains will be\n            modified in-place.\n\n    Returns:\n        None\n\n    '''\n    for event in reversed(old_events):\n        if event.combine(new_event):\n            return\n\n    # no combination was possible\n    old_events.append(new_event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds callback to be invoked once on the next tick of the event loop.", "response": "def add_next_tick_callback(self, callback):\n        ''' Add callback to be invoked once on the next tick of the event loop.\n\n        Args:\n            callback (callable) :\n                A callback function to execute on the next tick.\n\n        Returns:\n            NextTickCallback : can be used with ``remove_next_tick_callback``\n\n        .. note::\n            Next tick callbacks only work within the context of a Bokeh server\n            session. This function will no effect when Bokeh outputs to\n            standalone HTML or Jupyter notebook cells.\n\n        '''\n        from ..server.callbacks import NextTickCallback\n        cb = NextTickCallback(self, None)\n        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_next_tick_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_periodic_callback(self, callback, period_milliseconds):\n        ''' Add a callback to be invoked on a session periodically.\n\n        Args:\n            callback (callable) :\n                A callback function to execute periodically\n\n            period_milliseconds (int) :\n                Number of milliseconds between each callback execution.\n\n        Returns:\n            PeriodicCallback : can be used with ``remove_periodic_callback``\n\n        .. note::\n            Periodic callbacks only work within the context of a Bokeh server\n            session. This function will no effect when Bokeh outputs to\n            standalone HTML or Jupyter notebook cells.\n\n        '''\n        from ..server.callbacks import PeriodicCallback\n        cb = PeriodicCallback(self,\n                              None,\n                              period_milliseconds)\n        return self._add_session_callback(cb, callback, one_shot=False, originator=self.add_periodic_callback)", "response": "Add a callback to be invoked on a session periodically."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_root(self, model, setter=None):\n        ''' Add a model as a root of this Document.\n\n        Any changes to this model (including to other models referred to\n        by it) will trigger ``on_change`` callbacks registered on this\n        document.\n\n        Args:\n            model (Model) :\n                The model to add as a root of this document.\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        '''\n        if model in self._roots:\n            return\n        self._push_all_models_freeze()\n        # TODO (bird) Should we do some kind of reporting of how many\n        # LayoutDOM's are in the document roots? In vanilla bokeh cases e.g.\n        # output_file more than one LayoutDOM is probably not going to go\n        # well. But in embedded cases, you may well want more than one.\n        try:\n            self._roots.append(model)\n        finally:\n            self._pop_all_models_freeze()\n        self._trigger_on_change(RootAddedEvent(self, model, setter))", "response": "Add a model as a root of this document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_timeout_callback(self, callback, timeout_milliseconds):\n        ''' Add callback to be invoked once, after a specified timeout passes.\n\n        Args:\n            callback (callable) :\n                A callback function to execute after timeout\n\n            timeout_milliseconds (int) :\n                Number of milliseconds before callback execution.\n\n        Returns:\n            TimeoutCallback : can be used with ``remove_timeout_callback``\n\n        .. note::\n            Timeout callbacks only work within the context of a Bokeh server\n            session. This function will no effect when Bokeh outputs to\n            standalone HTML or Jupyter notebook cells.\n\n        '''\n        from ..server.callbacks import TimeoutCallback\n        cb = TimeoutCallback(self,\n                             None,\n                             timeout_milliseconds)\n        return self._add_session_callback(cb, callback, one_shot=True, originator=self.add_timeout_callback)", "response": "Add a callback to be invoked once after a specified timeout passes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a JSON patch to any resulting events and returns the new state of the new state.", "response": "def apply_json_patch(self, patch, setter=None):\n        ''' Apply a JSON patch object and process any resulting events.\n\n        Args:\n            patch (JSON-data) :\n                The JSON-object containing the patch to apply.\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        Returns:\n            None\n\n        '''\n        references_json = patch['references']\n        events_json = patch['events']\n        references = instantiate_references_json(references_json)\n\n        # Use our existing model instances whenever we have them\n        for obj in references.values():\n            if obj.id in self._all_models:\n                references[obj.id] = self._all_models[obj.id]\n\n        # The model being changed isn't always in references so add it in\n        for event_json in events_json:\n            if 'model' in event_json:\n                model_id = event_json['model']['id']\n                if model_id in self._all_models:\n                    references[model_id] = self._all_models[model_id]\n\n        initialize_references_json(references_json, references, setter)\n\n        for event_json in events_json:\n\n            if event_json['kind'] == 'ModelChanged':\n                patched_id = event_json['model']['id']\n                if patched_id not in self._all_models:\n                    if patched_id not in self._all_former_model_ids:\n                        raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(patched_id)))\n                    else:\n                        log.warning(\"Cannot apply patch to %s which is not in the document anymore\" % (str(patched_id)))\n                        break\n                patched_obj = self._all_models[patched_id]\n                attr = event_json['attr']\n                value = event_json['new']\n                patched_obj.set_from_json(attr, value, models=references, setter=setter)\n\n            elif event_json['kind'] == 'ColumnDataChanged':\n                source_id = event_json['column_source']['id']\n                if source_id not in self._all_models:\n                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n                source = self._all_models[source_id]\n                value = event_json['new']\n                source.set_from_json('data', value, models=references, setter=setter)\n\n            elif event_json['kind'] == 'ColumnsStreamed':\n                source_id = event_json['column_source']['id']\n                if source_id not in self._all_models:\n                    raise RuntimeError(\"Cannot stream to %s which is not in the document\" % (str(source_id)))\n                source = self._all_models[source_id]\n                data = event_json['data']\n                rollover = event_json.get('rollover', None)\n                source._stream(data, rollover, setter)\n\n            elif event_json['kind'] == 'ColumnsPatched':\n                source_id = event_json['column_source']['id']\n                if source_id not in self._all_models:\n                    raise RuntimeError(\"Cannot apply patch to %s which is not in the document\" % (str(source_id)))\n                source = self._all_models[source_id]\n                patches = event_json['patches']\n                source.patch(patches, setter)\n\n            elif event_json['kind'] == 'RootAdded':\n                root_id = event_json['model']['id']\n                root_obj = references[root_id]\n                self.add_root(root_obj, setter)\n\n            elif event_json['kind'] == 'RootRemoved':\n                root_id = event_json['model']['id']\n                root_obj = references[root_id]\n                self.remove_root(root_obj, setter)\n\n            elif event_json['kind'] == 'TitleChanged':\n                self._set_title(event_json['title'], setter)\n\n            else:\n                raise RuntimeError(\"Unknown patch event \" + repr(event_json))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all content from the document but do not reset title.", "response": "def clear(self):\n        ''' Remove all content from the document but do not reset title.\n\n        Returns:\n            None\n\n        '''\n        self._push_all_models_freeze()\n        try:\n            while len(self._roots) > 0:\n                r = next(iter(self._roots))\n                self.remove_root(r)\n        finally:\n            self._pop_all_models_freeze()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_modules(self):\n        ''' Clean up after any modules created by this Document when its session is\n        destroyed.\n\n        '''\n        from gc import get_referrers\n        from types import FrameType\n\n        log.debug(\"Deleting %s modules for %s\" % (len(self._modules), self))\n\n        for module in self._modules:\n\n            # Modules created for a Document should have three referrers at this point:\n            #\n            # - sys.modules\n            # - self._modules\n            # - a frame object\n            #\n            # This function will take care of removing these expected references.\n            #\n            # If there are any additional referrers, this probably means the module will be\n            # leaked. Here we perform a detailed check that the only referrers are expected\n            # ones. Otherwise issue an error log message with details.\n            referrers = get_referrers(module)\n            referrers = [x for x in referrers if x is not sys.modules]\n            referrers = [x for x in referrers if x is not self._modules]\n            referrers = [x for x in referrers if not isinstance(x, FrameType)]\n            if len(referrers) != 0:\n                log.error(\"Module %r has extra unexpected referrers! This could indicate a serious memory leak. Extra referrers: %r\" % (module, referrers))\n\n            # remove the reference from sys.modules\n            if module.__name__ in sys.modules:\n                del sys.modules[module.__name__]\n\n        # remove the reference from self._modules\n        self._modules = None", "response": "Delete all modules created by this Document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a document from a JSON - encoded document.", "response": "def from_json(cls, json):\n        ''' Load a document from JSON.\n\n        json (JSON-data) :\n            A JSON-encoded document to create a new Document from.\n\n        Returns:\n            Document :\n\n        '''\n        roots_json = json['roots']\n        root_ids = roots_json['root_ids']\n        references_json = roots_json['references']\n\n        references = instantiate_references_json(references_json)\n        initialize_references_json(references_json, references)\n\n        doc = Document()\n        for r in root_ids:\n            doc.add_root(references[r])\n\n        doc.title = json['title']\n\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nactivating a document hold.", "response": "def hold(self, policy=\"combine\"):\n        ''' Activate a document hold.\n\n        While a hold is active, no model changes will be applied, or trigger\n        callbacks. Once ``unhold`` is called, the events collected during the\n        hold will be applied according to the hold policy.\n\n        Args:\n            hold ('combine' or 'collect', optional)\n                Whether events collected during a hold should attempt to be\n                combined (default: 'combine')\n\n                When set to ``'collect'`` all events will be collected and\n                replayed in order as-is when ``unhold`` is called.\n\n                When set to ``'combine'`` Bokeh will attempt to combine\n                compatible events together. Typically, different events that\n                change the same property on the same mode can be combined.\n                For example, if the following sequence occurs:\n\n                .. code-block:: python\n\n                    doc.hold('combine')\n                    slider.value = 10\n                    slider.value = 11\n                    slider.value = 12\n\n                Then only *one* callback, for the last ``slider.value = 12``\n                will be triggered.\n\n        Returns:\n            None\n\n        .. note::\n            ``hold`` only applies to document change events, i.e. setting\n            properties on models. It does not apply to events such as\n            ``ButtonClick``, etc.\n\n        '''\n        if self._hold is not None and self._hold != policy:\n            log.warning(\"hold already active with '%s', ignoring '%s'\" % (self._hold, policy))\n            return\n        if policy not in HoldPolicy:\n            raise ValueError(\"Unknown hold policy %r\" % policy)\n        self._hold = policy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning off any active document hold and apply any collected events.", "response": "def unhold(self):\n        ''' Turn off any active document hold and apply any collected events.\n\n        Returns:\n            None\n\n        '''\n        # no-op if we are already no holding\n        if self._hold is None: return\n\n        self._hold = None\n        events = list(self._held_events)\n        self._held_events = []\n\n        for event in events:\n            self._trigger_on_change(event)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_change(self, *callbacks):\n        ''' Provide callbacks to invoke if the document or any Model reachable\n        from its roots changes.\n\n        '''\n        for callback in callbacks:\n\n            if callback in self._callbacks: continue\n\n            _check_callback(callback, ('event',))\n\n            self._callbacks[callback] = callback", "response": "Provide callbacks to invoke if the document or any Model reachable\n            from its roots changes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nproviding callbacks to invoke when the session serving the Document is destroyed by the user.", "response": "def on_session_destroyed(self, *callbacks):\n        ''' Provide callbacks to invoke when the session serving the Document\n        is destroyed\n\n        '''\n        for callback in callbacks:\n            _check_callback(callback, ('session_context',))\n            self._session_destroyed_callbacks.add(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a model as a root model from this Document.", "response": "def remove_root(self, model, setter=None):\n        ''' Remove a model as root model from this Document.\n\n        Changes to this model may still trigger ``on_change`` callbacks\n        on this document, if the model is still referred to by other\n        root models.\n\n        Args:\n            model (Model) :\n                The model to add as a root of this document.\n\n            setter (ClientSession or ServerSession or None, optional) :\n                This is used to prevent \"boomerang\" updates to Bokeh apps.\n                (default: None)\n\n                In the context of a Bokeh server application, incoming updates\n                to properties will be annotated with the session that is\n                doing the updating. This value is propagated through any\n                subsequent change notifications that the update triggers.\n                The session can compare the event setter to itself, and\n                suppress any updates that originate from itself.\n\n        '''\n        if model not in self._roots:\n            return # TODO (bev) ValueError?\n        self._push_all_models_freeze()\n        try:\n            self._roots.remove(model)\n        finally:\n            self._pop_all_models_freeze()\n        self._trigger_on_change(RootRemovedEvent(self, model, setter))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_with_json(self, json):\n        ''' Overwrite everything in this document with the JSON-encoded\n        document.\n\n        json (JSON-data) :\n            A JSON-encoded document to overwrite this one.\n\n        Returns:\n            None\n\n        '''\n        replacement = self.from_json(json)\n        replacement._destructively_move(self)", "response": "Overwrite everything in this document with the JSON - encoded version of the document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries this document for objects that match the given selector.", "response": "def select(self, selector):\n        ''' Query this document for objects that match the given selector.\n\n        Args:\n            selector (JSON-like query dictionary) : you can query by type or by\n                name, e.g. ``{\"type\": HoverTool}``, ``{\"name\": \"mycircle\"}``\n\n        Returns:\n            seq[Model]\n\n        '''\n        if self._is_single_string_selector(selector, 'name'):\n            # special-case optimization for by-name query\n            return self._all_models_by_name.get_all(selector['name'])\n        else:\n            return find(self._all_models.values(), selector)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery this document for objects that match the given selector. Returns None if no matching object is found.", "response": "def select_one(self, selector):\n        ''' Query this document for objects that match the given selector.\n        Raises an error if more than one object is found.  Returns\n        single matching object, or None if nothing is found\n\n        Args:\n            selector (JSON-like query dictionary) : you can query by type or by\n                name, e.g. ``{\"type\": HoverTool}``, ``{\"name\": \"mycircle\"}``\n\n        Returns:\n            Model or None\n\n        '''\n        result = list(self.select(selector))\n        if len(result) > 1:\n            raise ValueError(\"Found more than one model matching %s: %r\" % (selector, result))\n        if len(result) == 0:\n            return None\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the document to a JSON string.", "response": "def to_json_string(self, indent=None):\n        ''' Convert the document to a JSON string.\n\n        Args:\n            indent (int or None, optional) : number of spaces to indent, or\n                None to suppress all newlines and indentation (default: None)\n\n        Returns:\n            str\n\n        '''\n        root_ids = []\n        for r in self._roots:\n            root_ids.append(r.id)\n\n        root_references = self._all_models.values()\n\n        json = {\n            'title' : self.title,\n            'roots' : {\n                'root_ids' : root_ids,\n                'references' : references_json(root_references)\n            },\n            'version' : __version__\n        }\n\n        return serialize_json(json, indent=indent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming integrity checks on the modes in this document.", "response": "def validate(self):\n        ''' Perform integrity checks on the modes in this document.\n\n        Returns:\n            None\n\n        '''\n        for r in self.roots:\n            refs = r.references()\n            check_integrity(refs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_session_callback(self, callback_obj, callback, one_shot, originator):\n        ''' Internal implementation for adding session callbacks.\n\n        Args:\n            callback_obj (SessionCallback) :\n                A session callback object that wraps a callable and is\n                passed to ``trigger_on_change``.\n\n            callback (callable) :\n                A callable to execute when session events happen.\n\n            one_shot (bool) :\n                Whether the callback should immediately auto-remove itself\n                after one execution.\n\n        Returns:\n            SessionCallback : passed in as ``callback_obj``.\n\n        Raises:\n            ValueError, if the callback has been previously added\n\n        '''\n        if one_shot:\n            @wraps(callback)\n            def remove_then_invoke(*args, **kwargs):\n                if callback_obj in self._session_callbacks:\n                    self._remove_session_callback(callback_obj, originator)\n                return callback(*args, **kwargs)\n            actual_callback = remove_then_invoke\n        else:\n            actual_callback = callback\n\n        callback_obj._callback = self._wrap_with_self_as_curdoc(actual_callback)\n        self._session_callbacks.add(callback_obj)\n        self._callback_objs_by_callable[originator][callback].add(callback_obj)\n\n        # emit event so the session is notified of the new callback\n        self._trigger_on_change(SessionCallbackAdded(self, callback_obj))\n\n        return callback_obj", "response": "Internal implementation for adding a session callback."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _destructively_move(self, dest_doc):\n        ''' Move all data in this doc to the dest_doc, leaving this doc empty.\n\n        Args:\n            dest_doc (Document) :\n                The Bokeh document to populate with data from this one\n\n        Returns:\n            None\n\n        '''\n\n        if dest_doc is self:\n            raise RuntimeError(\"Attempted to overwrite a document with itself\")\n\n        dest_doc.clear()\n        # we have to remove ALL roots before adding any\n        # to the new doc or else models referenced from multiple\n        # roots could be in both docs at once, which isn't allowed.\n        roots = []\n        self._push_all_models_freeze()\n        try:\n            while self.roots:\n                r = next(iter(self.roots))\n                self.remove_root(r)\n                roots.append(r)\n        finally:\n            self._pop_all_models_freeze()\n        for r in roots:\n            if r.document is not None:\n                raise RuntimeError(\"Somehow we didn't detach %r\" % (r))\n        if len(self._all_models) != 0:\n            raise RuntimeError(\"_all_models still had stuff in it: %r\" % (self._all_models))\n        for r in roots:\n            dest_doc.add_root(r)\n\n        dest_doc.title = self.title", "response": "Move all data in this doc to dest_doc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _notify_change(self, model, attr, old, new, hint=None, setter=None, callback_invoker=None):\n        ''' Called by Model when it changes\n\n        '''\n        # if name changes, update by-name index\n        if attr == 'name':\n            if old is not None:\n                self._all_models_by_name.remove_value(old, model)\n            if new is not None:\n                self._all_models_by_name.add_value(new, model)\n\n        if hint is None:\n            serializable_new = model.lookup(attr).serializable_value(model)\n        else:\n            serializable_new = None\n\n        event = ModelChangedEvent(self, model, attr, old, new, serializable_new, hint, setter, callback_invoker)\n        self._trigger_on_change(event)", "response": "Called by Model when it changes\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a callback from the list of callbacks that were added earlier with add_periodic_callback or add_timeout_callback or add_next_tick_callback.", "response": "def _remove_session_callback(self, callback_obj, originator):\n        ''' Remove a callback added earlier with ``add_periodic_callback``,\n        ``add_timeout_callback``, or ``add_next_tick_callback``.\n\n        Returns:\n            None\n\n        Raises:\n            KeyError, if the callback was never added\n\n        '''\n        try:\n            callback_objs = [callback_obj]\n            self._session_callbacks.remove(callback_obj)\n            for cb, cb_objs in list(self._callback_objs_by_callable[originator].items()):\n                try:\n                    cb_objs.remove(callback_obj)\n                    if not cb_objs:\n                        del self._callback_objs_by_callable[originator][cb]\n                except KeyError:\n                    pass\n        except KeyError:\n            raise ValueError(\"callback already ran or was already removed, cannot be removed again\")\n        # emit event so the session is notified and can remove the callback\n        for callback_obj in callback_objs:\n            self._trigger_on_change(SessionCallbackRemoved(self, callback_obj))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_callback(callback, fargs, what=\"Callback functions\"):\n    '''Bokeh-internal function to check callback signature'''\n    sig = signature(callback)\n    formatted_args = format_signature(sig)\n    error_msg = what + \" must have signature func(%s), got func%s\"\n\n    all_names, default_values = get_param_info(sig)\n\n    nargs = len(all_names) - len(default_values)\n    if nargs != len(fargs):\n        raise ValueError(error_msg % (\", \".join(fargs), formatted_args))", "response": "Bokeh - internal function to check callback signature"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a callback to trigger when attr changes.", "response": "def on_change(self, attr, *callbacks):\n        ''' Add a callback on this object to trigger when ``attr`` changes.\n\n        Args:\n            attr (str) : an attribute name on this object\n            callback (callable) : a callback function to register\n\n        Returns:\n            None\n\n        '''\n        if len(callbacks) == 0:\n            raise ValueError(\"on_change takes an attribute name and one or more callbacks, got only one parameter\")\n\n        _callbacks = self._callbacks.setdefault(attr, [])\n        for callback in callbacks:\n\n            if callback in _callbacks:\n                continue\n\n            _check_callback(callback, ('attr', 'old', 'new'))\n\n            _callbacks.append(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_on_change(self, attr, *callbacks):\n        ''' Remove a callback from this object '''\n        if len(callbacks) == 0:\n            raise ValueError(\"remove_on_change takes an attribute name and one or more callbacks, got only one parameter\")\n        _callbacks = self._callbacks.setdefault(attr, [])\n        for callback in callbacks:\n            _callbacks.remove(callback)", "response": "Removes a callback from this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntriggering callbacks for attr on this object.", "response": "def trigger(self, attr, old, new, hint=None, setter=None):\n        ''' Trigger callbacks for ``attr`` on this object.\n\n        Args:\n            attr (str) :\n            old (object) :\n            new (object) :\n\n        Returns:\n            None\n\n        '''\n        def invoke():\n            callbacks = self._callbacks.get(attr)\n            if callbacks:\n                for callback in callbacks:\n                    callback(attr, old, new)\n        if hasattr(self, '_document') and self._document is not None:\n            self._document._notify_change(self, attr, old, new, hint, setter, invoke)\n        else:\n            invoke()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload larger data sets for various Bokeh examples.", "response": "def download(progress=True):\n    ''' Download larger data sets for various Bokeh examples.\n\n    '''\n    data_dir = external_data_dir(create=True)\n    print(\"Using data directory: %s\" % data_dir)\n\n    s3 = 'https://bokeh-sampledata.s3.amazonaws.com'\n    files = [\n        (s3, 'CGM.csv'),\n        (s3, 'US_Counties.zip'),\n        (s3, 'us_cities.json'),\n        (s3, 'unemployment09.csv'),\n        (s3, 'AAPL.csv'),\n        (s3, 'FB.csv'),\n        (s3, 'GOOG.csv'),\n        (s3, 'IBM.csv'),\n        (s3, 'MSFT.csv'),\n        (s3, 'WPP2012_SA_DB03_POPULATION_QUINQUENNIAL.zip'),\n        (s3, 'gapminder_fertility.csv'),\n        (s3, 'gapminder_population.csv'),\n        (s3, 'gapminder_life_expectancy.csv'),\n        (s3, 'gapminder_regions.csv'),\n        (s3, 'world_cities.zip'),\n        (s3, 'airports.json'),\n        (s3, 'movies.db.zip'),\n        (s3, 'airports.csv'),\n        (s3, 'routes.csv'),\n        (s3, 'haarcascade_frontalface_default.xml'),\n    ]\n\n    for base_url, filename in files:\n        _download_file(base_url, filename, data_dir, progress=progress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(argv):\n    ''' Execute the Bokeh command.\n\n    Args:\n        argv (seq[str]) : a list of command line arguments to process\n\n    Returns:\n        None\n\n    The first item in ``argv`` is typically \"bokeh\", and the second should\n    be the name of one of the available subcommands:\n\n    * :ref:`html <bokeh.command.subcommands.html>`\n    * :ref:`info <bokeh.command.subcommands.info>`\n    * :ref:`json <bokeh.command.subcommands.json>`\n    * :ref:`png <bokeh.command.subcommands.png>`\n    * :ref:`sampledata <bokeh.command.subcommands.sampledata>`\n    * :ref:`secret <bokeh.command.subcommands.secret>`\n    * :ref:`serve <bokeh.command.subcommands.serve>`\n    * :ref:`static <bokeh.command.subcommands.static>`\n    * :ref:`svg <bokeh.command.subcommands.svg>`\n\n    '''\n    if len(argv) == 1:\n        die(\"ERROR: Must specify subcommand, one of: %s\" % nice_join(x.name for x in subcommands.all))\n\n    parser = argparse.ArgumentParser(\n        prog=argv[0],\n        epilog=\"See '<command> --help' to read about a specific subcommand.\")\n\n    # we don't use settings.version() because the point of this option\n    # is to report the actual version of Bokeh, while settings.version()\n    # lets people change the version used for CDN for example.\n    parser.add_argument('-v', '--version', action='version', version=__version__)\n\n    subs = parser.add_subparsers(help=\"Sub-commands\")\n\n    for cls in subcommands.all:\n        subparser = subs.add_parser(cls.name, help=cls.help)\n        subcommand = cls(parser=subparser)\n        subparser.set_defaults(invoke=subcommand.invoke)\n\n    args = parser.parse_args(argv[1:])\n    try:\n        args.invoke(args)\n    except Exception as e:\n        die(\"ERROR: \" + str(e))", "response": "Main entry point for the bokeh - get - tree - tree command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef html_page_for_render_items(bundle, docs_json, render_items, title, template=None, template_variables={}):\n    ''' Render an HTML page from a template and Bokeh render items.\n\n    Args:\n        bundle (tuple):\n            a tuple containing (bokehjs, bokehcss)\n\n        docs_json (JSON-like):\n            Serialized Bokeh Document\n\n        render_items (RenderItems)\n            Specific items to render from the document and where\n\n        title (str or None)\n            A title for the HTML page. If None, DEFAULT_TITLE is used\n\n        template (str or Template or None, optional) :\n            A Template to be used for the HTML page. If None, FILE is used.\n\n        template_variables (dict, optional):\n            Any Additional variables to pass to the template\n\n    Returns:\n        str\n\n    '''\n    if title is None:\n        title = DEFAULT_TITLE\n\n    bokeh_js, bokeh_css = bundle\n\n    json_id = make_id()\n    json = escape(serialize_json(docs_json), quote=False)\n    json = wrap_in_script_tag(json, \"application/json\", json_id)\n\n    script = wrap_in_script_tag(script_for_render_items(json_id, render_items))\n\n    context = template_variables.copy()\n\n    context.update(dict(\n        title = title,\n        bokeh_js = bokeh_js,\n        bokeh_css = bokeh_css,\n        plot_script = json + script,\n        docs = render_items,\n        base = FILE,\n        macros = MACROS,\n    ))\n\n    if len(render_items) == 1:\n        context[\"doc\"] = context[\"docs\"][0]\n        context[\"roots\"] = context[\"doc\"].roots\n\n    # XXX: backwards compatibility, remove for 1.0\n    context[\"plot_div\"] = \"\\n\".join(div_for_render_item(item) for item in render_items)\n\n    if template is None:\n        template = FILE\n    elif isinstance(template, string_types):\n        template = _env.from_string(\"{% extends base %}\\n\" + template)\n\n    html = template.render(context)\n    return encode_utf8(html)", "response": "Render an HTML page from a template and Bokeh render items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_hosted_zip(data_url, save_dir, exclude_term=None):\n\n    zip_name = os.path.join(save_dir, 'temp.zip')\n\n    # get the zip file\n    try:\n        print('Downloading %r to %r' % (data_url, zip_name))\n        zip_name, hdrs = urllib.request.urlretrieve(url=data_url, filename=zip_name)\n        print('Download successfully completed')\n    except IOError as e:\n        print(\"Could not successfully retrieve %r\" % data_url)\n        raise e\n\n    # extract, then remove temp file\n    extract_zip(zip_name=zip_name, exclude_term=exclude_term)\n    os.unlink(zip_name)\n    print(\"Extraction Complete\")", "response": "Downloads then extracts a zip file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract a zip file to its containing directory.", "response": "def extract_zip(zip_name, exclude_term=None):\n    \"\"\"Extracts a zip file to its containing directory.\"\"\"\n\n    zip_dir = os.path.dirname(os.path.abspath(zip_name))\n\n    try:\n        with zipfile.ZipFile(zip_name) as z:\n\n            # write each zipped file out if it isn't a directory\n            files = [zip_file for zip_file in z.namelist() if not zip_file.endswith('/')]\n\n            print('Extracting %i files from %r.' % (len(files), zip_name))\n            for zip_file in files:\n\n                # remove any provided extra directory term from zip file\n                if exclude_term:\n                    dest_file = zip_file.replace(exclude_term, '')\n                else:\n                    dest_file = zip_file\n\n                dest_file = os.path.normpath(os.path.join(zip_dir, dest_file))\n                dest_dir = os.path.dirname(dest_file)\n\n                # make directory if it does not exist\n                if not os.path.isdir(dest_dir):\n                    os.makedirs(dest_dir)\n\n                # read file from zip, then write to new directory\n                data = z.read(zip_file)\n                with open(dest_file, 'wb') as f:\n                    f.write(encode_utf8(data))\n\n    except zipfile.error as e:\n        print(\"Bad zipfile (%r): %s\" % (zip_name, e))\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the configured main. py or main. ipynb to modify the document.", "response": "def modify_document(self, doc):\n        ''' Execute the configured ``main.py`` or ``main.ipynb`` to modify the\n        document.\n\n        This method will also search the app directory for any theme or\n        template files, and automatically configure the document with them\n        if they are found.\n\n        '''\n        if self._lifecycle_handler.failed:\n            return\n        # Note: we do NOT copy self._theme, which assumes the Theme\n        # class is immutable (has no setters)\n        if self._theme is not None:\n            doc.theme = self._theme\n\n        if self._template is not None:\n            doc.template = self._template\n\n        # This internal handler should never add a template\n        self._main_handler.modify_document(doc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef markers():\n    ''' Prints a list of valid marker types for scatter()\n\n    Returns:\n        None\n    '''\n    print(\"Available markers: \\n\\n - \" + \"\\n - \".join(list(MarkerType)))\n    print()\n    print(\"Shortcuts: \\n\\n\" + \"\\n\".join(\" %r: %s\" % item for item in _MARKER_SHORTCUTS.items()))", "response": "Prints a list of valid marker types for scatter"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scatter(self, *args, **kwargs):\n        ''' Creates a scatter plot of the given x and y items.\n\n        Args:\n            x (str or seq[float]) : values or field names of center x coordinates\n\n            y (str or seq[float]) : values or field names of center y coordinates\n\n            size (str or list[float]) : values or field names of sizes in screen units\n\n            marker (str, or list[str]): values or field names of marker types\n\n            color (color value, optional): shorthand to set both fill and line color\n\n            source (:class:`~bokeh.models.sources.ColumnDataSource`) : a user-supplied data source.\n                An attempt will be made to convert the object to :class:`~bokeh.models.sources.ColumnDataSource`\n                if needed. If none is supplied, one is created for the user automatically.\n\n            **kwargs: :ref:`userguide_styling_line_properties` and :ref:`userguide_styling_fill_properties`\n\n        Examples:\n\n            >>> p.scatter([1,2,3],[4,5,6], marker=\"square\", fill_color=\"red\")\n            >>> p.scatter(\"data1\", \"data2\", marker=\"mtype\", source=data_source, ...)\n\n        .. note::\n            When passing ``marker=\"circle\"`` it is also possible to supply a\n            ``radius`` value in data-space units. When configuring marker type\n            from a data source column, *all* markers incuding circles may only\n            be configured with ``size`` in screen units.\n\n        '''\n        marker_type = kwargs.pop(\"marker\", \"circle\")\n\n        if isinstance(marker_type, string_types) and marker_type in _MARKER_SHORTCUTS:\n            marker_type = _MARKER_SHORTCUTS[marker_type]\n\n        # The original scatter implementation allowed circle scatters to set a\n        # radius. We will leave this here for compatibility but note that it\n        # only works when the marker type is \"circle\" (and not referencing a\n        # data source column). Consider deprecating in the future.\n        if marker_type == \"circle\" and \"radius\" in kwargs:\n            return self.circle(*args, **kwargs)\n        else:\n            return self._scatter(*args, marker=marker_type, **kwargs)", "response": "Creates a scatter plot of the given x and y items."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a simple equal-weight hexagonal binning. A :class:`~bokeh.models._glyphs.HexTile` glyph will be added to display the binning. The :class:`~bokeh.models.sources.ColumnDataSource` for the glyph will have columns ``q``, ``r``, and ``count``, where ``q`` and ``r`` are `axial coordinates`_ for a tile, and ``count`` is the associated bin count. It is often useful to set ``match_aspect=True`` on the associated plot, so that hexagonal tiles are all regular (i.e. not \"stretched\") in screen space. For more sophisticated use-cases, e.g. weighted binning or individually scaling hex tiles, use :func:`hex_tile` directly, or consider a higher level library such as HoloViews. Args: x (array[float]) : A NumPy array of x-coordinates to bin into hexagonal tiles. y (array[float]) : A NumPy array of y-coordinates to bin into hexagonal tiles size (float) : The size of the hexagonal tiling to use. The size is defined as distance from the center of a hexagon to a corner. In case the aspect scaling is not 1-1, then specifically `size` is the distance from the center to the \"top\" corner with the `\"pointytop\"` orientation, and the distance from the center to a \"side\" corner with the \"flattop\" orientation. orientation (\"pointytop\" or \"flattop\", optional) : Whether the hexagonal tiles should be oriented with a pointed corner on top, or a flat side on top. (default: \"pointytop\") palette (str or seq[color], optional) : A palette (or palette name) to use to colormap the bins according to count. (default: 'Viridis256') If ``fill_color`` is supplied, it overrides this value. line_color (color, optional) : The outline color for hex tiles, or None (default: None) fill_color (color, optional) : An optional fill color for hex tiles, or None. If None, then the ``palette`` will be used to color map the tiles by count. (default: None) aspect_scale (float) : Match a plot's aspect ratio scaling. When working with a plot with ``aspect_scale != 1``, this parameter can be set to match the plot, in order to draw regular hexagons (instead of \"stretched\" ones). This is roughly equivalent to binning in \"screen space\", and it may be better to use axis-aligned rectangular bins when plot aspect scales are not one. Any additional keyword arguments are passed to :func:`hex_tile`. Returns (Glyphrender, DataFrame) A tuple with the ``HexTile`` renderer generated to display the binning, and a Pandas ``DataFrame`` with columns ``q``, ``r``, and ``count``, where ``q`` and ``r`` are `axial coordinates`_ for a tile, and ``count`` is the associated bin count. Example: .. bokeh-plot:: :source-position: above import numpy as np from bokeh.models import HoverTool from bokeh.plotting import figure, show x = 2 + 2*np.random.standard_normal(500) y = 2 + 2*np.random.standard_normal(500) p = figure(match_aspect=True, tools=\"wheel_zoom,reset\") p.background_fill_color = '#440154' p.grid.visible = False p.hexbin(x, y, size=0.5, hover_color=\"pink\", hover_alpha=0.8) hover = HoverTool(tooltips=[(\"count\", \"@c\"), (\"(q,r)\", \"(@q, @r)\")]) p.add_tools(hover) show(p) .. _axial coordinates: https://www.redblobgames.com/grids/hexagons/#coordinates-axial", "response": "def hexbin(self, x, y, size, orientation=\"pointytop\", palette=\"Viridis256\", line_color=None, fill_color=None, aspect_scale=1, **kwargs):\n        ''' Perform a simple equal-weight hexagonal binning.\n\n        A :class:`~bokeh.models._glyphs.HexTile` glyph will be added to display\n        the binning. The :class:`~bokeh.models.sources.ColumnDataSource` for\n        the glyph will have columns ``q``, ``r``, and ``count``, where ``q``\n        and ``r`` are `axial coordinates`_ for a tile, and ``count`` is the\n        associated bin count.\n\n        It is often useful to set ``match_aspect=True`` on the associated plot,\n        so that hexagonal tiles are all regular (i.e. not \"stretched\") in\n        screen space.\n\n        For more sophisticated use-cases, e.g. weighted binning or individually\n        scaling hex tiles, use :func:`hex_tile` directly, or consider a higher\n        level library such as HoloViews.\n\n        Args:\n            x (array[float]) :\n                A NumPy array of x-coordinates to bin into hexagonal tiles.\n\n            y (array[float]) :\n                A NumPy array of y-coordinates to bin into hexagonal tiles\n\n            size (float) :\n                The size of the hexagonal tiling to use. The size is defined as\n                distance from the center of a hexagon to a corner.\n\n                In case the aspect scaling is not 1-1, then specifically `size`\n                is the distance from the center to the \"top\" corner with the\n                `\"pointytop\"` orientation, and the distance from the center to\n                a \"side\" corner with the \"flattop\" orientation.\n\n            orientation (\"pointytop\" or \"flattop\", optional) :\n                Whether the hexagonal tiles should be oriented with a pointed\n                corner on top, or a flat side on top. (default: \"pointytop\")\n\n            palette (str or seq[color], optional) :\n                A palette (or palette name) to use to colormap the bins according\n                to count. (default: 'Viridis256')\n\n                If ``fill_color`` is supplied, it overrides this value.\n\n            line_color (color, optional) :\n                The outline color for hex tiles, or None (default: None)\n\n            fill_color (color, optional) :\n                An optional fill color for hex tiles, or None. If None, then\n                the ``palette`` will be used to color map the tiles by\n                count. (default: None)\n\n            aspect_scale (float) :\n                Match a plot's aspect ratio scaling.\n\n                When working with a plot with ``aspect_scale != 1``, this\n                parameter can be set to match the plot, in order to draw\n                regular hexagons (instead of \"stretched\" ones).\n\n                This is roughly equivalent to binning in \"screen space\", and\n                it may be better to use axis-aligned rectangular bins when\n                plot aspect scales are not one.\n\n        Any additional keyword arguments are passed to :func:`hex_tile`.\n\n        Returns\n            (Glyphrender, DataFrame)\n                A tuple with the ``HexTile`` renderer generated to display the\n                binning, and a Pandas ``DataFrame`` with columns ``q``, ``r``,\n                and ``count``, where ``q`` and ``r`` are `axial coordinates`_\n                for a tile, and ``count`` is the associated bin count.\n\n        Example:\n\n            .. bokeh-plot::\n                :source-position: above\n\n                import numpy as np\n                from bokeh.models import HoverTool\n                from bokeh.plotting import figure, show\n\n                x = 2 + 2*np.random.standard_normal(500)\n                y = 2 + 2*np.random.standard_normal(500)\n\n                p = figure(match_aspect=True, tools=\"wheel_zoom,reset\")\n                p.background_fill_color = '#440154'\n                p.grid.visible = False\n\n                p.hexbin(x, y, size=0.5, hover_color=\"pink\", hover_alpha=0.8)\n\n                hover = HoverTool(tooltips=[(\"count\", \"@c\"), (\"(q,r)\", \"(@q, @r)\")])\n                p.add_tools(hover)\n\n                show(p)\n\n        .. _axial coordinates: https://www.redblobgames.com/grids/hexagons/#coordinates-axial\n\n        '''\n        from ..util.hex import hexbin\n\n        bins = hexbin(x, y, size, orientation, aspect_scale=aspect_scale)\n\n        if fill_color is None:\n            fill_color = linear_cmap('c', palette, 0, max(bins.counts))\n\n        source = ColumnDataSource(data=dict(q=bins.q, r=bins.r, c=bins.counts))\n\n        r = self.hex_tile(q=\"q\", r=\"r\", size=size, orientation=orientation, aspect_scale=aspect_scale,\n                          source=source, line_color=line_color, fill_color=fill_color, **kwargs)\n\n        return (r, bins)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate multiple HArea renderers for levels stacked left to right.", "response": "def harea_stack(self, stackers, **kw):\n        ''' Generate multiple ``HArea`` renderers for levels stacked left\n        to right.\n\n        Args:\n            stackers (seq[str]) : a list of data source field names to stack\n                successively for ``x1`` and ``x2`` harea coordinates.\n\n                Additionally, the ``name`` of the renderer will be set to\n                the value of each successive stacker (this is useful with the\n                special hover variable ``$name``)\n\n        Any additional keyword arguments are passed to each call to ``harea``.\n        If a keyword value is a list or tuple, then each call will get one\n        value from the sequence.\n\n        Returns:\n            list[GlyphRenderer]\n\n        Examples:\n\n            Assuming a ``ColumnDataSource`` named ``source`` with columns\n            *2016* and *2017*, then the following call to ``harea_stack`` will\n            will create two ``HArea`` renderers that stack:\n\n            .. code-block:: python\n\n                p.harea_stack(['2016', '2017'], y='y', color=['blue', 'red'], source=source)\n\n            This is equivalent to the following two separate calls:\n\n            .. code-block:: python\n\n                p.harea(x1=stack(),       x2=stack('2016'),         y='y', color='blue', source=source, name='2016')\n                p.harea(x1=stack('2016'), x2=stack('2016', '2017'), y='y', color='red',  source=source, name='2017')\n\n        '''\n        result = []\n        for kw in _double_stack(stackers, \"x1\", \"x2\", **kw):\n            result.append(self.harea(**kw))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hbar_stack(self, stackers, **kw):\n        ''' Generate multiple ``HBar`` renderers for levels stacked left to right.\n\n        Args:\n            stackers (seq[str]) : a list of data source field names to stack\n                successively for ``left`` and ``right`` bar coordinates.\n\n                Additionally, the ``name`` of the renderer will be set to\n                the value of each successive stacker (this is useful with the\n                special hover variable ``$name``)\n\n        Any additional keyword arguments are passed to each call to ``hbar``.\n        If a keyword value is a list or tuple, then each call will get one\n        value from the sequence.\n\n        Returns:\n            list[GlyphRenderer]\n\n        Examples:\n\n            Assuming a ``ColumnDataSource`` named ``source`` with columns\n            *2106* and *2017*, then the following call to ``hbar_stack`` will\n            will create two ``HBar`` renderers that stack:\n\n            .. code-block:: python\n\n                p.hbar_stack(['2016', '2017'], x=10, width=0.9, color=['blue', 'red'], source=source)\n\n            This is equivalent to the following two separate calls:\n\n            .. code-block:: python\n\n                p.hbar(bottom=stack(),       top=stack('2016'),         x=10, width=0.9, color='blue', source=source, name='2016')\n                p.hbar(bottom=stack('2016'), top=stack('2016', '2017'), x=10, width=0.9, color='red',  source=source, name='2017')\n\n        '''\n        result = []\n        for kw in _double_stack(stackers, \"left\", \"right\", **kw):\n            result.append(self.hbar(**kw))\n        return result", "response": "Generates multiple HBar renderers for levels stacked left to right."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef line_stack(self, x, y, **kw):\n        ''' Generate multiple ``Line`` renderers for lines stacked vertically\n        or horizontally.\n\n        Args:\n            x (seq[str]) :\n\n            y (seq[str]) :\n\n        Additionally, the ``name`` of the renderer will be set to\n        the value of each successive stacker (this is useful with the\n        special hover variable ``$name``)\n\n        Any additional keyword arguments are passed to each call to ``hbar``.\n        If a keyword value is a list or tuple, then each call will get one\n        value from the sequence.\n\n        Returns:\n            list[GlyphRenderer]\n\n        Examples:\n\n            Assuming a ``ColumnDataSource`` named ``source`` with columns\n            *2106* and *2017*, then the following call to ``line_stack`` with\n            stackers for the y-coordinates will will create two ``Line``\n            renderers that stack:\n\n            .. code-block:: python\n\n                p.line_stack(['2016', '2017'], x='x', color=['blue', 'red'], source=source)\n\n            This is equivalent to the following two separate calls:\n\n            .. code-block:: python\n\n                p.line(y=stack('2016'),         x='x', color='blue', source=source, name='2016')\n                p.line(y=stack('2016', '2017'), x='x', color='red',  source=source, name='2017')\n\n        '''\n        if all(isinstance(val, (list, tuple)) for val in (x,y)):\n            raise ValueError(\"Only one of x or y may be a list of stackers\")\n\n        result = []\n\n        if isinstance(y, (list, tuple)):\n            kw['x'] = x\n            for kw in _single_stack(y, \"y\", **kw):\n                result.append(self.line(**kw))\n            return result\n\n        if isinstance(x, (list, tuple)):\n            kw['y'] = y\n            for kw in _single_stack(x, \"x\", **kw):\n                result.append(self.line(**kw))\n            return result\n\n        return [self.line(x, y, **kw)]", "response": "Generates multiple Line renderers for lines stacked vertically by y - coordinates or horizontally."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef varea_stack(self, stackers, **kw):\n        ''' Generate multiple ``VArea`` renderers for levels stacked bottom\n        to top.\n\n        Args:\n            stackers (seq[str]) : a list of data source field names to stack\n                successively for ``y1`` and ``y1`` varea coordinates.\n\n                Additionally, the ``name`` of the renderer will be set to\n                the value of each successive stacker (this is useful with the\n                special hover variable ``$name``)\n\n        Any additional keyword arguments are passed to each call to ``varea``.\n        If a keyword value is a list or tuple, then each call will get one\n        value from the sequence.\n\n        Returns:\n            list[GlyphRenderer]\n\n        Examples:\n\n            Assuming a ``ColumnDataSource`` named ``source`` with columns\n            *2016* and *2017*, then the following call to ``varea_stack`` will\n            will create two ``VArea`` renderers that stack:\n\n            .. code-block:: python\n\n                p.varea_stack(['2016', '2017'], x='x', color=['blue', 'red'], source=source)\n\n            This is equivalent to the following two separate calls:\n\n            .. code-block:: python\n\n                p.varea(y1=stack(),       y2=stack('2016'),         x='x', color='blue', source=source, name='2016')\n                p.varea(y1=stack('2016'), y2=stack('2016', '2017'), x='x', color='red',  source=source, name='2017')\n\n        '''\n        result = []\n        for kw in _double_stack(stackers, \"y1\", \"y2\", **kw):\n            result.append(self.varea(**kw))\n        return result", "response": "Generates multiple VArea renderers for levels stacked bottom\n            to top."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates multiple VBar renderers for levels stacked bottom to top.", "response": "def vbar_stack(self, stackers, **kw):\n        ''' Generate multiple ``VBar`` renderers for levels stacked bottom\n        to top.\n\n        Args:\n            stackers (seq[str]) : a list of data source field names to stack\n                successively for ``left`` and ``right`` bar coordinates.\n\n                Additionally, the ``name`` of the renderer will be set to\n                the value of each successive stacker (this is useful with the\n                special hover variable ``$name``)\n\n        Any additional keyword arguments are passed to each call to ``vbar``.\n        If a keyword value is a list or tuple, then each call will get one\n        value from the sequence.\n\n        Returns:\n            list[GlyphRenderer]\n\n        Examples:\n\n            Assuming a ``ColumnDataSource`` named ``source`` with columns\n            *2016* and *2017*, then the following call to ``vbar_stack`` will\n            will create two ``VBar`` renderers that stack:\n\n            .. code-block:: python\n\n                p.vbar_stack(['2016', '2017'], x=10, width=0.9, color=['blue', 'red'], source=source)\n\n            This is equivalent to the following two separate calls:\n\n            .. code-block:: python\n\n                p.vbar(bottom=stack(),       top=stack('2016'),         x=10, width=0.9, color='blue', source=source, name='2016')\n                p.vbar(bottom=stack('2016'), top=stack('2016', '2017'), x=10, width=0.9, color='red',  source=source, name='2017')\n\n        '''\n        result = []\n        for kw in _double_stack(stackers, \"bottom\", \"top\", **kw):\n            result.append(self.vbar(**kw))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef graph(self, node_source, edge_source, layout_provider, **kwargs):\n        ''' Creates a network graph using the given node, edge and layout provider.\n\n        Args:\n            node_source (:class:`~bokeh.models.sources.ColumnDataSource`) : a user-supplied data source\n                for the graph nodes. An attempt will be made to convert the object to\n                :class:`~bokeh.models.sources.ColumnDataSource` if needed. If none is supplied, one is created\n                for the user automatically.\n\n            edge_source (:class:`~bokeh.models.sources.ColumnDataSource`) : a user-supplied data source\n                for the graph edges. An attempt will be made to convert the object to\n                :class:`~bokeh.models.sources.ColumnDataSource` if needed. If none is supplied, one is created\n                for the user automatically.\n\n            layout_provider (:class:`~bokeh.models.graphs.LayoutProvider`) : a ``LayoutProvider`` instance to\n                provide the graph coordinates in Cartesian space.\n\n            **kwargs: :ref:`userguide_styling_line_properties` and :ref:`userguide_styling_fill_properties`\n\n        '''\n        kw = _graph(node_source, edge_source, **kwargs)\n        graph_renderer = GraphRenderer(layout_provider=layout_provider, **kw)\n        self.renderers.append(graph_renderer)\n        return graph_renderer", "response": "Creates a network graph using the given node and edge data sources."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef server_url_for_websocket_url(url):\n    ''' Convert an ``ws(s)`` URL for a Bokeh server into the appropriate\n    ``http(s)`` URL for the websocket endpoint.\n\n    Args:\n        url (str):\n            An ``ws(s)`` URL ending in ``/ws``\n\n    Returns:\n        str:\n            The corresponding ``http(s)`` URL.\n\n    Raises:\n        ValueError:\n            If the input URL is not of the proper form.\n\n    '''\n    if url.startswith(\"ws:\"):\n        reprotocoled = \"http\" + url[2:]\n    elif url.startswith(\"wss:\"):\n        reprotocoled = \"https\" + url[3:]\n    else:\n        raise ValueError(\"URL has non-websocket protocol \" + url)\n    if not reprotocoled.endswith(\"/ws\"):\n        raise ValueError(\"websocket URL does not end in /ws\")\n    return reprotocoled[:-2]", "response": "Convert an ws URL for a Bokeh server into the appropriate\n    HTTP URL for the websocket endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef websocket_url_for_server_url(url):\n    ''' Convert an ``http(s)`` URL for a Bokeh server websocket endpoint into\n    the appropriate ``ws(s)`` URL\n\n    Args:\n        url (str):\n            An ``http(s)`` URL\n\n    Returns:\n        str:\n            The corresponding ``ws(s)`` URL ending in ``/ws``\n\n    Raises:\n        ValueError:\n            If the input URL is not of the proper form.\n\n    '''\n    if url.startswith(\"http:\"):\n        reprotocoled = \"ws\" + url[4:]\n    elif url.startswith(\"https:\"):\n        reprotocoled = \"wss\" + url[5:]\n    else:\n        raise ValueError(\"URL has unknown protocol \" + url)\n    if reprotocoled.endswith(\"/\"):\n        return reprotocoled + \"ws\"\n    else:\n        return reprotocoled + \"/ws\"", "response": "Convert an HTTP URL for a Bokeh server websocket endpoint into a corresponding ws URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef without_property_validation(input_function):\n    ''' Turn off property validation during update callbacks\n\n    Example:\n        .. code-block:: python\n\n            @without_property_validation\n            def update(attr, old, new):\n                # do things without validation\n\n    See Also:\n        :class:`~bokeh.core.properties.validate`: context mangager for more fine-grained control\n\n    '''\n    @wraps(input_function)\n    def func(*args, **kwargs):\n        with validate(False):\n            return input_function(*args, **kwargs)\n    return func", "response": "Decorator to turn off property validation during update callbacks\nInsights is used to update the object with validate = False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_env():\n    ''' Get the correct Jinja2 Environment, also for frozen scripts.\n    '''\n    if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):\n        # PyInstaller uses _MEIPASS and only works with jinja2.FileSystemLoader\n        templates_path = join(sys._MEIPASS, 'bokeh', 'core', '_templates')\n    else:\n        # Non-frozen Python and cx_Freeze can use __file__ directly\n        templates_path = join(dirname(__file__), '_templates')\n\n    return Environment(loader=FileSystemLoader(templates_path))", "response": "Get the correct Jinja2 Environment also for frozen scripts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parallel_plot(df, color=None, palette=None):\n    npts = df.shape[0]\n    ndims = len(df.columns)\n\n    if color is None:\n        color = np.ones(npts)\n    if palette is None:\n        palette = ['#ff0000']\n\n    cmap = LinearColorMapper(high=color.min(),\n                             low=color.max(),\n                             palette=palette)\n\n    data_source = ColumnDataSource(dict(\n        xs=np.arange(ndims)[None, :].repeat(npts, axis=0).tolist(),\n        ys=np.array((df-df.min())/(df.max()-df.min())).tolist(),\n        color=color))\n\n    p = figure(x_range=(-1, ndims),\n               y_range=(0, 1),\n               width=1000,\n               tools=\"pan, box_zoom\")\n\n    # Create x axis ticks from columns contained in dataframe\n    fixed_x_ticks = FixedTicker(\n        ticks=np.arange(ndims), minor_ticks=[])\n    formatter_x_ticks = FuncTickFormatter(\n        code=\"return columns[index]\", args={\"columns\": df.columns})\n    p.xaxis.ticker = fixed_x_ticks\n    p.xaxis.formatter = formatter_x_ticks\n\n    p.yaxis.visible = False\n    p.y_range.start = 0\n    p.y_range.end = 1\n    p.y_range.bounds = (-0.1, 1.1) # add a little padding around y axis\n    p.xgrid.visible = False\n    p.ygrid.visible = False\n\n    # Create extra y axis for each dataframe column\n    tickformatter = BasicTickFormatter(precision=1)\n    for index, col in enumerate(df.columns):\n        start = df[col].min()\n        end = df[col].max()\n        bound_min = start + abs(end-start) * (p.y_range.bounds[0] - p.y_range.start)\n        bound_max = end + abs(end-start) * (p.y_range.bounds[1] - p.y_range.end)\n        p.extra_y_ranges.update(\n            {col: Range1d(start=bound_min, end=bound_max, bounds=(bound_min, bound_max))})\n\n        fixedticks = FixedTicker(\n            ticks=np.linspace(start, end, 8), minor_ticks=[])\n\n        p.add_layout(LinearAxis(fixed_location=index, y_range_name=col,\n                                ticker=fixedticks, formatter=tickformatter), 'right')\n\n    # create the data renderer ( MultiLine )\n    # specify selected and non selected style\n    non_selected_line_style = dict(line_color='grey', line_width=0.1, line_alpha=0.5)\n\n    selected_line_style = dict(line_color={'field': 'color', 'transform': cmap}, line_width=1)\n\n    parallel_renderer = p.multi_line(\n        xs=\"xs\", ys=\"ys\", source=data_source, **non_selected_line_style)\n\n    # Specify selection style\n    selected_lines = MultiLine(**selected_line_style)\n\n    # Specify non selection style\n    nonselected_lines = MultiLine(**non_selected_line_style)\n\n    parallel_renderer.selection_glyph = selected_lines\n    parallel_renderer.nonselection_glyph = nonselected_lines\n    p.y_range.start = p.y_range.bounds[0]\n    p.y_range.end = p.y_range.bounds[1]\n\n    rect_source = ColumnDataSource({\n        'x': [], 'y': [], 'width': [], 'height': []\n    })\n\n    # add rectangle selections\n    selection_renderer = p.rect(x='x', y='y', width='width', height='height',\n                                source=rect_source,\n                                fill_alpha=0.7, fill_color='#009933')\n    selection_tool = ParallelSelectionTool(\n        renderer_select=selection_renderer, renderer_data=parallel_renderer,\n        box_width=10)\n    # custom resets (reset only axes not selections)\n    reset_axes = ParallelResetTool()\n\n    # add tools and activate selection ones\n    p.add_tools(selection_tool, reset_axes)\n    p.toolbar.active_drag = selection_tool\n    return p", "response": "Create a parallel coordinate plot from a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndelegating a received message to the appropriate handler.", "response": "def handle(self, message, connection):\n        ''' Delegate a received message to the appropriate handler.\n\n        Args:\n            message (Message) :\n                The message that was receive that needs to be handled\n\n            connection (ServerConnection) :\n                The connection that received this message\n\n        Raises:\n            ProtocolError\n\n        '''\n\n        handler = self._handlers.get((message.msgtype, message.revision))\n\n        if handler is None:\n            handler = self._handlers.get(message.msgtype)\n\n        if handler is None:\n            raise ProtocolError(\"%s not expected on server\" % message)\n\n        try:\n            work = yield handler(message, connection)\n        except Exception as e:\n            log.error(\"error handling message %r: %r\", message, e)\n            log.debug(\"  message header %r content %r\", message.header, message.content, exc_info=1)\n            work = connection.error(message, repr(e))\n        raise gen.Return(work)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting shell current working directory.", "response": "def set_cwd(self, dirname):\n        \"\"\"Set shell current working directory.\"\"\"\n        # Replace single for double backslashes on Windows\n        if os.name == 'nt':\n            dirname = dirname.replace(u\"\\\\\", u\"\\\\\\\\\")\n\n        if not self.external_kernel:\n            code = u\"get_ipython().kernel.set_cwd(u'''{}''')\".format(dirname)\n            if self._reading:\n                self.kernel_client.input(u'!' + code)\n            else:\n                self.silent_execute(code)\n            self._cwd = dirname"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_bracket_matcher_color_scheme(self, color_scheme):\n        bsh = sh.BaseSH(parent=self, color_scheme=color_scheme)\n        mpcolor = bsh.get_matched_p_color()\n        self._bracket_matcher.format.setBackground(mpcolor)", "response": "Set color scheme for matched parentheses."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the color scheme of the shell.", "response": "def set_color_scheme(self, color_scheme, reset=True):\n        \"\"\"Set color scheme of the shell.\"\"\"\n        self.set_bracket_matcher_color_scheme(color_scheme)\n        self.style_sheet, dark_color = create_qss_style(color_scheme)\n        self.syntax_style = color_scheme\n        self._style_sheet_changed()\n        self._syntax_style_changed()\n        if reset:\n            self.reset(clear=True)\n        if not dark_color:\n            self.silent_execute(\"%colors linux\")\n        else:\n            self.silent_execute(\"%colors lightbg\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef long_banner(self):\n        # Default banner\n        try:\n            from IPython.core.usage import quick_guide\n        except Exception:\n            quick_guide = ''\n        banner_parts = [\n            'Python %s\\n' % self.interpreter_versions['python_version'],\n            'Type \"copyright\", \"credits\" or \"license\" for more information.\\n\\n',\n            'IPython %s -- An enhanced Interactive Python.\\n' % \\\n            self.interpreter_versions['ipython_version'],\n            quick_guide\n        ]\n        banner = ''.join(banner_parts)\n\n        # Pylab additions\n        pylab_o = self.additional_options['pylab']\n        autoload_pylab_o = self.additional_options['autoload_pylab']\n        mpl_installed = programs.is_module_installed('matplotlib')\n        if mpl_installed and (pylab_o and autoload_pylab_o):\n            pylab_message = (\"\\nPopulating the interactive namespace from \"\n                             \"numpy and matplotlib\\n\")\n            banner = banner + pylab_message\n\n        # Sympy additions\n        sympy_o = self.additional_options['sympy']\n        if sympy_o:\n            lines = \"\"\"\nThese commands were executed:\n>>> from __future__ import division\n>>> from sympy import *\n>>> x, y, z, t = symbols('x y z t')\n>>> k, m, n = symbols('k m n', integer=True)\n>>> f, g, h = symbols('f g h', cls=Function)\n\"\"\"\n            banner = banner + lines\n        if (pylab_o and sympy_o):\n            lines = \"\"\"\nWarning: pylab (numpy and matplotlib) and symbolic math (sympy) are both \nenabled at the same time. Some pylab functions are going to be overrided by \nthe sympy module (e.g. plot)\n\"\"\"\n            banner = banner + lines\n        return banner", "response": "Return a long banner for IPython widgets with pylab message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_namespace(self, warning=False, message=False):\n        reset_str = _(\"Remove all variables\")\n        warn_str = _(\"All user-defined variables will be removed. \"\n                     \"Are you sure you want to proceed?\")\n        kernel_env = self.kernel_manager._kernel_spec.env\n\n        if warning:\n            box = MessageCheckBox(icon=QMessageBox.Warning, parent=self)\n            box.setWindowTitle(reset_str)\n            box.set_checkbox_text(_(\"Don't show again.\"))\n            box.setStandardButtons(QMessageBox.Yes | QMessageBox.No)\n            box.setDefaultButton(QMessageBox.Yes)\n\n            box.set_checked(False)\n            box.set_check_visible(True)\n            box.setText(warn_str)\n\n            answer = box.exec_()\n\n            # Update checkbox based on user interaction\n            CONF.set('ipython_console', 'show_reset_namespace_warning',\n                     not box.is_checked())\n            self.ipyclient.reset_warning = not box.is_checked()\n\n            if answer != QMessageBox.Yes:\n                return\n\n        try:\n            if self._reading:\n                self.dbg_exec_magic('reset', '-f')\n            else:\n                if message:\n                    self.reset()\n                    self._append_html(_(\"<br><br>Removing all variables...\"\n                                        \"\\n<hr>\"),\n                                      before_prompt=False)\n                self.silent_execute(\"%reset -f\")\n                if kernel_env.get('SPY_AUTOLOAD_PYLAB_O') == 'True':\n                    self.silent_execute(\"from pylab import *\")\n                if kernel_env.get('SPY_SYMPY_O') == 'True':\n                    sympy_init = \"\"\"\n                        from __future__ import division\n                        from sympy import *\n                        x, y, z, t = symbols('x y z t')\n                        k, m, n = symbols('k m n', integer=True)\n                        f, g, h = symbols('f g h', cls=Function)\n                        init_printing()\"\"\"\n                    self.silent_execute(dedent(sympy_init))\n                if kernel_env.get('SPY_RUN_CYTHON') == 'True':\n                    self.silent_execute(\"%reload_ext Cython\")\n                self.refresh_namespacebrowser()\n\n                if not self.external_kernel:\n                    self.silent_execute(\n                        'get_ipython().kernel.close_all_mpl_figures()')\n        except AttributeError:\n            pass", "response": "Reset the namespace by removing all names defined by the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_shortcuts(self):\n        inspect = config_shortcut(self._control.inspect_current_object,\n                                  context='Console',\n                                  name='Inspect current object', parent=self)\n        clear_console = config_shortcut(self.clear_console, context='Console',\n                                        name='Clear shell', parent=self)\n        restart_kernel = config_shortcut(self.ipyclient.restart_kernel,\n                                         context='ipython_console',\n                                         name='Restart kernel', parent=self)\n        new_tab = config_shortcut(lambda: self.new_client.emit(),\n                                  context='ipython_console', name='new tab',\n                                  parent=self)\n        reset_namespace = config_shortcut(lambda: self._reset_namespace(),\n                                          context='ipython_console',\n                                          name='reset namespace', parent=self)\n        array_inline = config_shortcut(self._control.enter_array_inline,\n                                       context='array_builder',\n                                       name='enter array inline', parent=self)\n        array_table = config_shortcut(self._control.enter_array_table,\n                                      context='array_builder',\n                                      name='enter array table', parent=self)\n        clear_line = config_shortcut(self.ipyclient.clear_line,\n                                     context='console', name='clear line',\n                                     parent=self)\n\n        return [inspect, clear_console, restart_kernel, new_tab,\n                reset_namespace, array_inline, array_table, clear_line]", "response": "Create shortcuts for ipyconsole."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef silent_execute(self, code):\n        try:\n            self.kernel_client.execute(to_text_string(code), silent=True)\n        except AttributeError:\n            pass", "response": "Execute code in the kernel without increasing the prompt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle kernel methods and kernel reply messages.", "response": "def handle_exec_method(self, msg):\n        \"\"\"\n        Handle data returned by silent executions of kernel methods\n\n        This is based on the _handle_exec_callback of RichJupyterWidget.\n        Therefore this is licensed BSD.\n        \"\"\"\n        user_exp = msg['content'].get('user_expressions')\n        if not user_exp:\n            return\n        for expression in user_exp:\n            if expression in self._kernel_methods:\n                # Process kernel reply\n                method = self._kernel_methods[expression]\n                reply = user_exp[expression]\n                data = reply.get('data')\n                if 'get_namespace_view' in method:\n                    if data is not None and 'text/plain' in data:\n                        literal = ast.literal_eval(data['text/plain'])\n                        view = ast.literal_eval(literal)\n                    else:\n                        view = None\n                    self.sig_namespace_view.emit(view)\n                elif 'get_var_properties' in method:\n                    if data is not None and 'text/plain' in data:\n                        literal = ast.literal_eval(data['text/plain'])\n                        properties = ast.literal_eval(literal)\n                    else:\n                        properties = None\n                    self.sig_var_properties.emit(properties)\n                elif 'get_cwd' in method:\n                    if data is not None and 'text/plain' in data:\n                        self._cwd = ast.literal_eval(data['text/plain'])\n                        if PY2:\n                            self._cwd = encoding.to_unicode_from_fs(self._cwd)\n                    else:\n                        self._cwd = ''\n                    self.sig_change_cwd.emit(self._cwd)\n                elif 'get_syspath' in method:\n                    if data is not None and 'text/plain' in data:\n                        syspath = ast.literal_eval(data['text/plain'])\n                    else:\n                        syspath = None\n                    self.sig_show_syspath.emit(syspath)\n                elif 'get_env' in method:\n                    if data is not None and 'text/plain' in data:\n                        env = ast.literal_eval(data['text/plain'])\n                    else:\n                        env = None\n                    self.sig_show_env.emit(env)\n                elif 'getattr' in method:\n                    if data is not None and 'text/plain' in data:\n                        is_spyder_kernel = data['text/plain']\n                        if 'SpyderKernel' in is_spyder_kernel:\n                            self.sig_is_spykernel.emit(self)\n                else:\n                    if data is not None and 'text/plain' in data:\n                        self._kernel_reply = ast.literal_eval(data['text/plain'])\n                    else:\n                        self._kernel_reply = None\n                    self.sig_got_reply.emit()\n\n                # Remove method after being processed\n                self._kernel_methods.pop(expression)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_mpl_backend(self, command):\n        if command.startswith('%matplotlib') and \\\n          len(command.splitlines()) == 1:\n            if not 'inline' in command:\n                self.silent_execute(command)", "response": "Send a command to the kernel to change the local version of the MPL backend."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _context_menu_make(self, pos):\n        menu = super(ShellWidget, self)._context_menu_make(pos)\n        return self.ipyclient.add_actions_to_context_menu(menu)", "response": "Reimplement the IPython context menu"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _banner_default(self):\n        # Don't change banner for external kernels\n        if self.external_kernel:\n            return ''\n        show_banner_o = self.additional_options['show_banner']\n        if show_banner_o:\n            return self.long_banner()\n        else:\n            return self.short_banner()", "response": "Return the default banner for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrefreshes the highlighting with the current syntax style by class.", "response": "def _syntax_style_changed(self):\n        \"\"\"Refresh the highlighting with the current syntax style by class.\"\"\"\n        if self._highlighter is None:\n            # ignore premature calls\n            return\n        if self.syntax_style:\n            self._highlighter._style = create_style_class(self.syntax_style)\n            self._highlighter._clear_caches()\n        else:\n            self._highlighter.set_style_sheet(self.style_sheet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemit a signal when the prompt is ready.", "response": "def _prompt_started_hook(self):\n        \"\"\"Emit a signal when the prompt is ready.\"\"\"\n        if not self._reading:\n            self._highlighter.highlighting_on = True\n            self.sig_prompt_ready.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef focusInEvent(self, event):\n        self.focus_changed.emit()\n        return super(ShellWidget, self).focusInEvent(event)", "response": "Reimplement Qt method to send focus change notification"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef focusOutEvent(self, event):\n        self.focus_changed.emit()\n        return super(ShellWidget, self).focusOutEvent(event)", "response": "Reimplement Qt method to send focus change notification"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a panel at the specified position.", "response": "def register(self, panel, position=Panel.Position.LEFT):\n        \"\"\"\n        Installs a panel on the editor.\n\n        :param panel: Panel to install\n        :param position: Position where the panel must be installed.\n        :return: The installed panel\n        \"\"\"\n        assert panel is not None\n        pos_to_string = {\n            Panel.Position.BOTTOM: 'bottom',\n            Panel.Position.LEFT: 'left',\n            Panel.Position.RIGHT: 'right',\n            Panel.Position.TOP: 'top',\n            Panel.Position.FLOATING: 'floating'\n        }\n        logger.debug('adding panel %s at %s' % (panel.name,\n                                                pos_to_string[position]))\n        panel.order_in_zone = len(self._panels[position])\n        self._panels[position][panel.name] = panel\n        panel.position = position\n        panel.on_install(self.editor)\n        logger.debug('panel %s installed' % panel.name)\n        return panel"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the specified panel from the cache.", "response": "def remove(self, name_or_klass):\n        \"\"\"\n        Removes the specified panel.\n\n        :param name_or_klass: Name or class of the panel to remove.\n        :return: The removed panel\n        \"\"\"\n        logger.debug('removing panel %s' % name_or_klass)\n        panel = self.get(name_or_klass)\n        panel.on_uninstall()\n        panel.hide()\n        panel.setParent(None)\n        return self._panels[panel.position].pop(panel.name, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self):\n        for i in range(4):\n            while len(self._panels[i]):\n                key = sorted(list(self._panels[i].keys()))[0]\n                panel = self.remove(key)\n                panel.setParent(None)\n                panel.deleteLater()", "response": "Removes all panels from the CodeEditor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a specific panel instance.", "response": "def get(self, name_or_klass):\n        \"\"\"\n        Gets a specific panel instance.\n\n        :param name_or_klass: Name or class of the panel to retrieve.\n        :return: The specified panel instance.\n        \"\"\"\n        if not is_text_string(name_or_klass):\n            name_or_klass = name_or_klass.__name__\n        for zone in range(4):\n            try:\n                panel = self._panels[zone][name_or_klass]\n            except KeyError:\n                pass\n            else:\n                return panel\n        raise KeyError(name_or_klass)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh(self):\n        logger.debug('Refresh panels')\n        self.resize()\n        self._update(self.editor.contentsRect(), 0,\n                     force_update_margins=True)", "response": "Refreshes the editor panels"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compute_zones_sizes(self):\n        # Left panels\n        left = 0\n        for panel in self.panels_for_zone(Panel.Position.LEFT):\n            if not panel.isVisible():\n                continue\n            size_hint = panel.sizeHint()\n            left += size_hint.width()\n        # Right panels\n        right = 0\n        for panel in self.panels_for_zone(Panel.Position.RIGHT):\n            if not panel.isVisible():\n                continue\n            size_hint = panel.sizeHint()\n            right += size_hint.width()\n        # Top panels\n        top = 0\n        for panel in self.panels_for_zone(Panel.Position.TOP):\n            if not panel.isVisible():\n                continue\n            size_hint = panel.sizeHint()\n            top += size_hint.height()\n        # Bottom panels\n        bottom = 0\n        for panel in self.panels_for_zone(Panel.Position.BOTTOM):\n            if not panel.isVisible():\n                continue\n            size_hint = panel.sizeHint()\n            bottom += size_hint.height()\n        self._top, self._left, self._right, self._bottom = (\n            top, left, right, bottom)\n        return bottom, left, right, top", "response": "Compute panel zone sizes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind a python - like module path based on an import line.", "response": "def python_like_mod_finder(import_line, alt_path=None,\r\n                           stop_token=None):\r\n    \"\"\"\r\n    Locate a module path based on an import line in an python-like file\r\n\r\n    import_line is the line of source code containing the import\r\n    alt_path specifies an alternate base path for the module\r\n    stop_token specifies the desired name to stop on\r\n\r\n    This is used to a find the path to python-like modules\r\n    (e.g. cython and enaml) for a goto definition.\r\n    \"\"\"\r\n    if stop_token and '.' in stop_token:\r\n        stop_token = stop_token.split('.')[-1]\r\n    tokens = re.split(r'\\W', import_line)\r\n    if tokens[0] in ['from', 'import']:\r\n        # find the base location\r\n        try:\r\n            _, path, _ = imp.find_module(tokens[1])\r\n        except ImportError:\r\n            if alt_path:\r\n                path = osp.join(alt_path, tokens[1])\r\n            else:\r\n                path = None\r\n        if path:\r\n            path = osp.realpath(path)\r\n            if not tokens[1] == stop_token:\r\n                for part in tokens[2:]:\r\n                    if part in ['import', 'cimport', 'as']:\r\n                        break\r\n                    path = osp.join(path, part)\r\n                    if part == stop_token:\r\n                        break\r\n            # from package import module\r\n            if stop_token and not stop_token in path:\r\n                for ext in python_like_exts():\r\n                    fname = '%s%s' % (stop_token, ext)\r\n                    if osp.exists(osp.join(path, fname)):\r\n                        return osp.join(path, fname)\r\n            # from module import name\r\n            for ext in python_like_exts():\r\n                fname = '%s%s' % (path, ext)\r\n                if osp.exists(fname):\r\n                    return fname\r\n            # if it is a file, return it\r\n            if osp.exists(path) and not osp.isdir(path):\r\n                return path\r\n            # default to the package file\r\n            path = osp.join(path, '__init__.py')\r\n            if osp.exists(path):\r\n                return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_definition_with_regex(source, token, start_line=-1):\r\n    if not token:\r\n        return None\r\n    if DEBUG_EDITOR:\r\n        t0 = time.time()\r\n    patterns = [  # python / cython keyword definitions\r\n                r'^c?import.*\\W{0}{1}',\r\n                r'from.*\\W{0}\\W.*c?import ',\r\n                r'from .* c?import.*\\W{0}{1}',\r\n                r'class\\s*{0}{1}',\r\n                r'c?p?def[^=]*\\W{0}{1}',\r\n                r'cdef.*\\[.*\\].*\\W{0}{1}',\r\n                # enaml keyword definitions\r\n                r'enamldef.*\\W{0}{1}',\r\n                r'attr.*\\W{0}{1}',\r\n                r'event.*\\W{0}{1}',\r\n                r'id\\s*:.*\\W{0}{1}']\r\n\r\n    matches = get_matches(patterns, source, token, start_line)\r\n\r\n    if not matches:\r\n        patterns = [r'.*\\Wself.{0}{1}[^=!<>]*=[^=]',\r\n                    r'.*\\W{0}{1}[^=!<>]*=[^=]',\r\n                    r'self.{0}{1}[^=!<>]*=[^=]',\r\n                    r'{0}{1}[^=!<>]*=[^=]']\r\n        matches = get_matches(patterns, source, token, start_line)\r\n    # find the one closest to the start line (prefer before the start line)\r\n    if matches:\r\n        min_dist = len(source.splitlines())\r\n        best_ind = 0\r\n        for match in matches:\r\n            dist = abs(start_line - match)\r\n            if match <= start_line or not best_ind:\r\n                if dist < min_dist:\r\n                    min_dist = dist\r\n                    best_ind = match\r\n    if matches:\r\n        if DEBUG_EDITOR:\r\n            log_dt(LOG_FILENAME, 'regex definition match', t0)\r\n        return best_ind\r\n    else:\r\n        if DEBUG_EDITOR:\r\n            log_dt(LOG_FILENAME, 'regex definition failed match', t0)\r\n        return None", "response": "Find the definition of an object within a source closest to a given line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef python_like_exts():\r\n    exts = []\r\n    for lang in languages.PYTHON_LIKE_LANGUAGES:\r\n        exts.extend(list(languages.ALL_LANGUAGES[lang]))\r\n    return ['.' + ext for ext in exts]", "response": "Returns a list of all python - like extensions"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all editable extensions", "response": "def all_editable_exts():\r\n    \"\"\"Return a list of all editable extensions\"\"\"\r\n    exts = []\r\n    for (language, extensions) in languages.ALL_LANGUAGES.items():\r\n        exts.extend(list(extensions))\r\n    return ['.' + ext for ext in exts]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _complete_path(path=None):\r\n    if not path:\r\n        return _listdir('.')\r\n    dirname, rest = os.path.split(path)\r\n    tmp = dirname if dirname else '.'\r\n    res = [p for p in _listdir(tmp) if p.startswith(rest)]\r\n    # more than one match, or single match which does not exist (typo)\r\n    if len(res) > 1 or not os.path.exists(path):\r\n        return res\r\n    # resolved to a single directory, so return list of files below it\r\n    if os.path.isdir(path):\r\n        return [p for p in _listdir(path)]\r\n    # exact file match terminates this completion\r\n    return [path + ' ']", "response": "Perform completion of filesystem path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_completions(self, info):\r\n        if not info['obj']:\r\n            return\r\n        items = []\r\n        obj = info['obj']\r\n        if info['context']:\r\n            lexer = find_lexer_for_filename(info['filename'])\r\n            # get a list of token matches for the current object\r\n            tokens = lexer.get_tokens(info['source_code'])\r\n            for (context, token) in tokens:\r\n                token = token.strip()\r\n                if (context in info['context'] and\r\n                        token.startswith(obj) and\r\n                        obj != token):\r\n                    items.append(token)\r\n            # add in keywords if not in a string\r\n            if context not in Token.Literal.String:\r\n                try:\r\n                    keywords = get_keywords(lexer)\r\n                    items.extend(k for k in keywords if k.startswith(obj))\r\n                except Exception:\r\n                    pass\r\n        else:\r\n            tokens = set(re.findall(info['id_regex'], info['source_code']))\r\n            items = [item for item in tokens if\r\n                 item.startswith(obj) and len(item) > len(obj)]\r\n            if '.' in obj:\r\n                start = obj.rfind('.') + 1\r\n            else:\r\n                start = 0\r\n\r\n            items = [i[start:len(obj)] + i[len(obj):].split('.')[0]\r\n                 for i in items]\r\n        # get path completions\r\n        # get last word back to a space or a quote character\r\n        match = re.search(r'''[ \"\\']([\\w\\.\\\\\\\\/]+)\\Z''', info['line'])\r\n        if match:\r\n            items += _complete_path(match.groups()[0])\r\n        return [(i, '') for i in sorted(items)]", "response": "Return a list of tuples of completion type and token matches based on python - like identifiers and whitespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_definition(self, info):\r\n        if not info['is_python_like']:\r\n            return\r\n        token = info['obj']\r\n        lines = info['lines']\r\n        source_code = info['source_code']\r\n        filename = info['filename']\r\n\r\n        line_nr = None\r\n        if token is None:\r\n            return\r\n        if '.' in token:\r\n            token = token.split('.')[-1]\r\n\r\n        line_nr = get_definition_with_regex(source_code, token,\r\n                                            len(lines))\r\n        if line_nr is None:\r\n            return\r\n        line = info['line']\r\n        exts = python_like_exts()\r\n        if not osp.splitext(filename)[-1] in exts:\r\n            return filename, line_nr\r\n        if line.startswith('import ') or line.startswith('from '):\r\n            alt_path = osp.dirname(filename)\r\n            source_file = python_like_mod_finder(line, alt_path=alt_path,\r\n                                                 stop_token=token)\r\n            if (not source_file or\r\n                    not osp.splitext(source_file)[-1] in exts):\r\n                line_nr = get_definition_with_regex(source_code, token,\r\n                                                    line_nr)\r\n                return filename, line_nr\r\n            mod_name = osp.basename(source_file).split('.')[0]\r\n            if mod_name == token or mod_name == '__init__':\r\n                return source_file, 1\r\n            else:\r\n                with open(filename, 'rb') as fid:\r\n                    code = fid.read()\r\n                code = encoding.decode(code)[0]\r\n                line_nr = get_definition_with_regex(code, token)\r\n\r\n        return filename, line_nr", "response": "Find the definition for an object within a set of source code"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a formatted calltip and docstring from Fallback", "response": "def get_info(self, info):\r\n        \"\"\"Get a formatted calltip and docstring from Fallback\"\"\"\r\n        if info['docstring']:\r\n            if info['filename']:\r\n                filename = os.path.basename(info['filename'])\r\n                filename = os.path.splitext(filename)[0]\r\n            else:\r\n                filename = '<module>'\r\n            resp = dict(docstring=info['docstring'],\r\n                        name=filename,\r\n                        note='',\r\n                        argspec='',\r\n                        calltip=None)\r\n            return resp\r\n        else:\r\n            return default_info_response()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the editor dialog and returns a tuple of dialog and func", "response": "def create_dialog(obj, obj_name):\r\n    \"\"\"Creates the editor dialog and returns a tuple (dialog, func) where func\r\n    is the function to be called with the dialog instance as argument, after \r\n    quitting the dialog box\r\n    \r\n    The role of this intermediate function is to allow easy monkey-patching.\r\n    (uschmitt suggested this indirection here so that he can monkey patch \r\n    oedit to show eMZed related data)\r\n    \"\"\"\r\n    # Local import\r\n    from spyder_kernels.utils.nsview import (ndarray, FakeObject,\r\n                                             Image, is_known_type, DataFrame,\r\n                                             Series)\r\n    from spyder.plugins.variableexplorer.widgets.texteditor import TextEditor\r\n    from spyder.plugins.variableexplorer.widgets.collectionseditor import (\r\n            CollectionsEditor)\r\n    from spyder.plugins.variableexplorer.widgets.arrayeditor import (\r\n            ArrayEditor)\r\n    if DataFrame is not FakeObject:\r\n        from spyder.plugins.variableexplorer.widgets.dataframeeditor import (\r\n                DataFrameEditor)\r\n\r\n    conv_func = lambda data: data\r\n    readonly = not is_known_type(obj)\r\n    if isinstance(obj, ndarray) and ndarray is not FakeObject:\r\n        dialog = ArrayEditor()\r\n        if not dialog.setup_and_check(obj, title=obj_name,\r\n                                      readonly=readonly):\r\n            return\r\n    elif isinstance(obj, Image) and Image is not FakeObject \\\r\n      and ndarray is not FakeObject:\r\n        dialog = ArrayEditor()\r\n        import numpy as np\r\n        data = np.array(obj)\r\n        if not dialog.setup_and_check(data, title=obj_name,\r\n                                      readonly=readonly):\r\n            return\r\n        from spyder.pil_patch import Image\r\n        conv_func = lambda data: Image.fromarray(data, mode=obj.mode)\r\n    elif isinstance(obj, (DataFrame, Series)) and DataFrame is not FakeObject:\r\n        dialog = DataFrameEditor()\r\n        if not dialog.setup_and_check(obj):\r\n            return\r\n    elif is_text_string(obj):\r\n        dialog = TextEditor(obj, title=obj_name, readonly=readonly)\r\n    else:\r\n        dialog = CollectionsEditor()\r\n        dialog.setup(obj, title=obj_name, readonly=readonly)\r\n\r\n    def end_func(dialog):\r\n        return conv_func(dialog.get_value())\r\n\r\n    return dialog, end_func"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits the object obj in a GUI - based editor and return the edited copy", "response": "def oedit(obj, modal=True, namespace=None):\r\n    \"\"\"Edit the object 'obj' in a GUI-based editor and return the edited copy\r\n    (if Cancel is pressed, return None)\r\n\r\n    The object 'obj' is a container\r\n    \r\n    Supported container types:\r\n    dict, list, set, tuple, str/unicode or numpy.array\r\n    \r\n    (instantiate a new QApplication if necessary,\r\n    so it can be called directly from the interpreter)\r\n    \"\"\"\r\n    # Local import\r\n    from spyder.utils.qthelpers import qapplication\r\n    app = qapplication()\r\n    \r\n    if modal:\r\n        obj_name = ''\r\n    else:\r\n        assert is_text_string(obj)\r\n        obj_name = obj\r\n        if namespace is None:\r\n            namespace = globals()\r\n        keeper.set_namespace(namespace)\r\n        obj = namespace[obj_name]\r\n        # keep QApplication reference alive in the Python interpreter:\r\n        namespace['__qapp__'] = app\r\n    \r\n    result = create_dialog(obj, obj_name)\r\n    if result is None:\r\n        return\r\n    dialog, end_func = result\r\n    \r\n    if modal:\r\n        if dialog.exec_():\r\n            return end_func(dialog)\r\n    else:\r\n        keeper.create_dialog(dialog, obj_name, end_func)\r\n        import os\r\n        if os.name == 'nt':\r\n            app.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_item_children(item):\r\n    children = [item.child(index) for index in range(item.childCount())]\r\n    for child in children[:]:\r\n        others = get_item_children(child)\r\n        if others is not None:\r\n            children += others\r\n    return sorted(children, key=lambda child: child.line)", "response": "Return a sorted list of all the children items of item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind and return the item that is located at the specified line", "response": "def item_at_line(root_item, line):\r\n    \"\"\"\r\n    Find and return the item of the outline explorer under which is located\r\n    the specified 'line' of the editor.\r\n    \"\"\"\r\n    previous_item = root_item\r\n    item = root_item\r\n    for item in get_item_children(root_item):\r\n        if item.line > line:\r\n            return previous_item\r\n        previous_item = item\r\n    else:\r\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __hide_or_show_root_items(self, item):\r\n        for _it in self.get_top_level_items():\r\n            _it.setHidden(_it is not item and not self.show_all_files)", "response": "hide or show all items except item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_current_editor(self, editor, update):\r\n        editor_id = editor.get_id()\r\n        if editor_id in list(self.editor_ids.values()):\r\n            item = self.editor_items[editor_id]\r\n            if not self.freeze:\r\n                self.scrollToItem(item)\r\n                self.root_item_selected(item)\r\n                self.__hide_or_show_root_items(item)\r\n            if update:\r\n                self.save_expanded_state()\r\n                tree_cache = self.editor_tree_cache[editor_id]\r\n                self.populate_branch(editor, item, tree_cache)\r\n                self.restore_expanded_state()\r\n        else:\r\n            root_item = FileRootItem(editor.fname, self, editor.is_python())\r\n            root_item.set_text(fullpath=self.show_fullpath)\r\n            tree_cache = self.populate_branch(editor, root_item)\r\n            self.__hide_or_show_root_items(root_item)\r\n            self.root_item_selected(root_item)\r\n            self.editor_items[editor_id] = root_item\r\n            self.editor_tree_cache[editor_id] = tree_cache\r\n            self.resizeColumnToContents(0)\r\n        if editor not in self.editor_ids:\r\n            self.editor_ids[editor] = editor_id\r\n            self.ordered_editor_ids.append(editor_id)\r\n            self.__sort_toplevel_items()\r\n        self.current_editor = editor", "response": "Bind editor instance to current state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the outline explorer tree with the new filename", "response": "def file_renamed(self, editor, new_filename):\r\n        \"\"\"File was renamed, updating outline explorer tree\"\"\"\r\n        if editor is None:\r\n            # This is needed when we can't find an editor to attach\r\n            # the outline explorer to.\r\n            # Fix issue 8813\r\n            return\r\n        editor_id = editor.get_id()\r\n        if editor_id in list(self.editor_ids.values()):\r\n            root_item = self.editor_items[editor_id]\r\n            root_item.set_path(new_filename, fullpath=self.show_fullpath)\r\n            self.__sort_toplevel_items()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_editor_ids_order(self, ordered_editor_ids):\r\n        if self.ordered_editor_ids != ordered_editor_ids:\r\n            self.ordered_editor_ids = ordered_editor_ids\r\n            if self.sort_files_alphabetically is False:\r\n                self.__sort_toplevel_items()", "response": "Order the root file items in the Outline Explorer following the list of editor ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsorts the items in alphabetical order.", "response": "def __sort_toplevel_items(self):\r\n        \"\"\"\r\n        Sort the root file items in alphabetical order if\r\n        'sort_files_alphabetically' is True, else order the items as\r\n        specified in the 'self.ordered_editor_ids' list.\r\n        \"\"\"\r\n        if self.show_all_files is False:\r\n            return\r\n\r\n        current_ordered_items = [self.topLevelItem(index) for index in\r\n                                 range(self.topLevelItemCount())]\r\n        if self.sort_files_alphabetically:\r\n            new_ordered_items = sorted(\r\n                current_ordered_items,\r\n                key=lambda item: osp.basename(item.path.lower()))\r\n        else:\r\n            new_ordered_items = [\r\n                self.editor_items.get(e_id) for e_id in\r\n                self.ordered_editor_ids if\r\n                self.editor_items.get(e_id) is not None]\r\n\r\n        if current_ordered_items != new_ordered_items:\r\n            selected_items = self.selectedItems()\r\n            self.save_expanded_state()\r\n            for index in range(self.topLevelItemCount()):\r\n                self.takeTopLevelItem(0)\r\n            for index, item in enumerate(new_ordered_items):\r\n                self.insertTopLevelItem(index, item)\r\n            self.restore_expanded_state()\r\n            self.clearSelection()\r\n            if selected_items:\r\n                selected_items[-1].setSelected(True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npopulate the tree cache with the contents of the given root item.", "response": "def populate_branch(self, editor, root_item, tree_cache=None):\r\n        \"\"\"\r\n        Generates an outline of the editor's content and stores the result\r\n        in a cache.\r\n        \"\"\"\r\n        if tree_cache is None:\r\n            tree_cache = {}\r\n        \r\n        # Removing cached items for which line is > total line nb\r\n        for _l in list(tree_cache.keys()):\r\n            if _l >= editor.get_line_count():\r\n                # Checking if key is still in tree cache in case one of its \r\n                # ancestors was deleted in the meantime (deleting all children):\r\n                if _l in tree_cache:\r\n                    remove_from_tree_cache(tree_cache, line=_l)\r\n                    \r\n        ancestors = [(root_item, 0)]\r\n        cell_ancestors = [(root_item, 0)]\r\n        previous_item = None\r\n        previous_level = None\r\n        prev_cell_level = None\r\n        prev_cell_item = None\r\n\r\n        oe_data = editor.get_outlineexplorer_data()\r\n        for block_nb in range(editor.get_line_count()):\r\n            line_nb = block_nb+1\r\n            data = oe_data.get(block_nb)\r\n            level = None if data is None else data.fold_level\r\n            citem, clevel, _d = tree_cache.get(line_nb, (None, None, \"\"))\r\n            \r\n            # Skip iteration if line is not the first line of a foldable block\r\n            if level is None:\r\n                if citem is not None:\r\n                    remove_from_tree_cache(tree_cache, line=line_nb)\r\n                continue\r\n            \r\n            # Searching for class/function statements\r\n            not_class_nor_function = data.is_not_class_nor_function()\r\n            if not not_class_nor_function:\r\n                class_name = data.get_class_name()\r\n                if class_name is None:\r\n                    func_name = data.get_function_name()\r\n                    if func_name is None:\r\n                        if citem is not None:\r\n                            remove_from_tree_cache(tree_cache, line=line_nb)\r\n                        continue\r\n\r\n            # Skip iteration for if/else/try/for/etc foldable blocks.\r\n            if not_class_nor_function and not data.is_comment():\r\n                if citem is not None:\r\n                    remove_from_tree_cache(tree_cache, line=line_nb)\r\n                continue\r\n\r\n            if citem is not None:\r\n                cname = to_text_string(citem.text(0))\r\n                cparent = citem.parent\r\n\r\n            # Blocks for Cell Groups.\r\n            if (data is not None and data.def_type == data.CELL and\r\n                    self.group_cells):\r\n                preceding = (root_item if previous_item is None\r\n                             else previous_item)\r\n                cell_level = data.cell_level\r\n                if prev_cell_level is not None:\r\n                    if cell_level == prev_cell_level:\r\n                        pass\r\n                    elif cell_level > prev_cell_level:\r\n                        cell_ancestors.append((prev_cell_item,\r\n                                               prev_cell_level))\r\n                    else:\r\n                        while (len(cell_ancestors) > 1 and\r\n                               cell_level <= prev_cell_level):\r\n                            cell_ancestors.pop(-1)\r\n                            _item, prev_cell_level = cell_ancestors[-1]\r\n                parent, _level = cell_ancestors[-1]\r\n                if citem is not None:\r\n                    if data.text == cname and level == clevel:\r\n                        previous_level = clevel\r\n                        previous_item = citem\r\n                        continue\r\n                    else:\r\n                        remove_from_tree_cache(tree_cache, line=line_nb)\r\n                item = CellItem(data.def_name, line_nb, parent, preceding)\r\n                item.setup()\r\n                debug = \"%s -- %s/%s\" % (str(item.line).rjust(6),\r\n                                         to_text_string(item.parent().text(0)),\r\n                                         to_text_string(item.text(0)))\r\n                tree_cache[line_nb] = (item, level, debug)\r\n                ancestors = [(item, 0)]\r\n                prev_cell_level = cell_level\r\n                prev_cell_item = item\r\n                previous_item = item\r\n                continue\r\n\r\n            # Blocks for Code Groups.\r\n            if previous_level is not None:\r\n                if level == previous_level:\r\n                    pass\r\n                elif level > previous_level:\r\n                    ancestors.append((previous_item, previous_level))\r\n                else:\r\n                    while len(ancestors) > 1 and level <= previous_level:\r\n                        ancestors.pop(-1)\r\n                        _item, previous_level = ancestors[-1]\r\n            parent, _level = ancestors[-1]\r\n\r\n            preceding = root_item if previous_item is None else previous_item\r\n            if not_class_nor_function and data.is_comment():\r\n                if not self.show_comments:\r\n                    if citem is not None:\r\n                        remove_from_tree_cache(tree_cache, line=line_nb)\r\n                    continue\r\n                if citem is not None:\r\n                    if data.text == cname and level == clevel:\r\n                        previous_level = clevel\r\n                        previous_item = citem\r\n                        continue\r\n                    else:\r\n                        remove_from_tree_cache(tree_cache, line=line_nb)\r\n                if data.def_type == data.CELL:\r\n                    item = CellItem(data.def_name, line_nb, parent, preceding)\r\n                else:\r\n                    item = CommentItem(data.text, line_nb, parent, preceding)\r\n            elif class_name is not None:\r\n                if citem is not None:\r\n                    if (class_name == cname and level == clevel and\r\n                            parent is cparent):\r\n                        previous_level = clevel\r\n                        previous_item = citem\r\n                        continue\r\n                    else:\r\n                        remove_from_tree_cache(tree_cache, line=line_nb)\r\n                item = ClassItem(class_name, line_nb, parent, preceding)\r\n            else:\r\n                if citem is not None:\r\n                    if (func_name == cname and level == clevel and\r\n                            parent is cparent):\r\n                        previous_level = clevel\r\n                        previous_item = citem\r\n                        continue\r\n                    else:\r\n                        remove_from_tree_cache(tree_cache, line=line_nb)\r\n                item = FunctionItem(func_name, line_nb, parent, preceding)\r\n                \r\n            item.setup()\r\n            debug = \"%s -- %s/%s\" % (str(item.line).rjust(6),\r\n                                     to_text_string(item.parent().text(0)),\r\n                                     to_text_string(item.text(0)))\r\n            tree_cache[line_nb] = (item, level, debug)\r\n            previous_level = level\r\n            previous_item = item\r\n            \r\n        return tree_cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollapses the root item and all its children", "response": "def root_item_selected(self, item):\r\n        \"\"\"Root item has been selected: expanding it and collapsing others\"\"\"\r\n        if self.show_all_files:\r\n            return\r\n        for root_item in self.get_top_level_items():\r\n            if root_item is item:\r\n                self.expandItem(root_item)\r\n            else:\r\n                self.collapseItem(root_item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the root item of the specified item.", "response": "def get_root_item(self, item):\r\n        \"\"\"Return the root item of the specified item.\"\"\"\r\n        root_item = item\r\n        while isinstance(root_item.parent(), QTreeWidgetItem):\r\n            root_item = root_item.parent()\r\n        return root_item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_visible_items(self):\r\n        items = []\r\n        iterator = QTreeWidgetItemIterator(self)\r\n        while iterator.value():\r\n            item = iterator.value()\r\n            if not item.isHidden():\r\n                if item.parent():\r\n                    if item.parent().isExpanded():\r\n                        items.append(item)\r\n                else:\r\n                    items.append(item)\r\n            iterator += 1\r\n        return items", "response": "Return a list of all visible items in the treewidget."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef activated(self, item):\r\n        editor_item = self.editor_items.get(\r\n            self.editor_ids.get(self.current_editor))\r\n        line = 0\r\n        if item == editor_item:\r\n            line = 1\r\n        elif isinstance(item, TreeItem):\r\n            line = item.line\r\n\r\n        self.freeze = True\r\n        root_item = self.get_root_item(item)\r\n        if line:\r\n            self.parent().edit_goto.emit(root_item.path, line, item.text(0))\r\n        else:\r\n            self.parent().edit.emit(root_item.path)\r\n        self.freeze = False\r\n\r\n        parent = self.current_editor.parent()\r\n        for editor_id, i_item in list(self.editor_items.items()):\r\n            if i_item is root_item:\r\n                for editor, _id in list(self.editor_ids.items()):\r\n                    if _id == editor_id and editor.parent() is parent:\r\n                        self.current_editor = editor\r\n                        break\r\n                break", "response": "Double - click event"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_options(self):\r\n        return dict(\r\n            show_fullpath=self.treewidget.show_fullpath,\r\n            show_all_files=self.treewidget.show_all_files,\r\n            group_cells=self.treewidget.group_cells,\r\n            show_comments=self.treewidget.show_comments,\r\n            sort_files_alphabetically=(\r\n                self.treewidget.sort_files_alphabetically),\r\n            expanded_state=self.treewidget.get_expanded_state(),\r\n            scrollbar_position=self.treewidget.get_scrollbar_position(),\r\n            visibility=self.isVisible()\r\n            )", "response": "Returns the options of the outline explorer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_to_distribution(dist):\n    try:\n        dist.add_qt_bindings()\n    except AttributeError:\n        raise ImportError(\"This script requires guidata 1.5+\")\n    for _modname in ('spyder', 'spyderplugins'):\n        dist.add_module_data_files(_modname, (\"\", ),\n                                   ('.png', '.svg', '.html', '.png', '.txt',\n                                    '.js', '.inv', '.ico', '.css', '.doctree',\n                                    '.qm', '.py',),\n                                   copy_to_root=False)", "response": "Add package to py2exe distribution object\n    Extension to guidata. disthelpers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets version information for Spyder components used by Spyder", "response": "def get_versions(reporev=True):\n    \"\"\"Get version information for components used by Spyder\"\"\"\n    import sys\n    import platform\n\n    import qtpy\n    import qtpy.QtCore\n\n    revision = None\n    if reporev:\n        from spyder.utils import vcs\n        revision, branch = vcs.get_git_revision(os.path.dirname(__dir__))\n\n    if not sys.platform == 'darwin':  # To avoid a crash with our Mac app\n        system = platform.system()\n    else:\n        system = 'Darwin'\n\n    return {\n        'spyder': __version__,\n        'python': platform.python_version(),  # \"2.7.3\"\n        'bitness': 64 if sys.maxsize > 2**32 else 32,\n        'qt': qtpy.QtCore.__version__,\n        'qt_api': qtpy.API_NAME,      # PyQt5\n        'qt_api_ver': qtpy.PYQT_VERSION,\n        'system': system,   # Linux, Windows, ...\n        'release': platform.release(),  # XP, 10.6, 2.2.0, etc.\n        'revision': revision,  # '9fdf926eccce'\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True is datatype dtype is a number kind", "response": "def is_number(dtype):\r\n    \"\"\"Return True is datatype dtype is a number kind\"\"\"\r\n    return is_float(dtype) or ('int' in dtype.name) or ('long' in dtype.name) \\\r\n           or ('short' in dtype.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_idx_rect(index_list):\r\n    rows, cols = list(zip(*[(i.row(), i.column()) for i in index_list]))\r\n    return ( min(rows), max(rows), min(cols), max(cols) )", "response": "Extract the boundaries from a list of indexes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef columnCount(self, qindex=QModelIndex()):\r\n        if self.total_cols <= self.cols_loaded:\r\n            return self.total_cols\r\n        else:\r\n            return self.cols_loaded", "response": "Returns the number of columns in the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rowCount(self, qindex=QModelIndex()):\r\n        if self.total_rows <= self.rows_loaded:\r\n            return self.total_rows\r\n        else:\r\n            return self.rows_loaded", "response": "Returns the number of rows in the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self, index, role=Qt.DisplayRole):\r\n        if not index.isValid():\r\n            return to_qvariant()\r\n        value = self.get_value(index)\r\n        if is_binary_string(value):\r\n            try:\r\n                value = to_text_string(value, 'utf8')\r\n            except:\r\n                pass\r\n        if role == Qt.DisplayRole:\r\n            if value is np.ma.masked:\r\n                return ''\r\n            else:\r\n                try:\r\n                    return to_qvariant(self._format % value)\r\n                except TypeError:\r\n                    self.readonly = True\r\n                    return repr(value)\r\n        elif role == Qt.TextAlignmentRole:\r\n            return to_qvariant(int(Qt.AlignCenter|Qt.AlignVCenter))\r\n        elif role == Qt.BackgroundColorRole and self.bgcolor_enabled \\\r\n          and value is not np.ma.masked:\r\n            try:\r\n                hue = (self.hue0 +\r\n                       self.dhue * (float(self.vmax) - self.color_func(value))\r\n                       / (float(self.vmax) - self.vmin))\r\n                hue = float(np.abs(hue))\r\n                color = QColor.fromHsvF(hue, self.sat, self.val, self.alp)\r\n                return to_qvariant(color)\r\n            except TypeError:\r\n                return to_qvariant()\r\n        elif role == Qt.FontRole:\r\n            return to_qvariant(get_font(font_size_delta=DEFAULT_SMALL_DELTA))\r\n        return to_qvariant()", "response": "Returns the data for the item at the given index in the given role"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the data of the item at the given index to the given value.", "response": "def setData(self, index, value, role=Qt.EditRole):\r\n        \"\"\"Cell content change\"\"\"\r\n        if not index.isValid() or self.readonly:\r\n            return False\r\n        i = index.row()\r\n        j = index.column()\r\n        value = from_qvariant(value, str)\r\n        dtype = self._data.dtype.name\r\n        if dtype == \"bool\":\r\n            try:\r\n                val = bool(float(value))\r\n            except ValueError:\r\n                val = value.lower() == \"true\"\r\n        elif dtype.startswith(\"string\") or dtype.startswith(\"bytes\"):\r\n            val = to_binary_string(value, 'utf8')\r\n        elif dtype.startswith(\"unicode\") or dtype.startswith(\"str\"):\r\n            val = to_text_string(value)\r\n        else:\r\n            if value.lower().startswith('e') or value.lower().endswith('e'):\r\n                return False\r\n            try:\r\n                val = complex(value)\r\n                if not val.imag:\r\n                    val = val.real\r\n            except ValueError as e:\r\n                QMessageBox.critical(self.dialog, \"Error\",\r\n                                     \"Value error: %s\" % str(e))\r\n                return False\r\n        try:\r\n            self.test_array[0] = val  # will raise an Exception eventually\r\n        except OverflowError as e:\r\n            print(\"OverflowError: \" + str(e))  # spyder: test-skip\r\n            QMessageBox.critical(self.dialog, \"Error\",\r\n                                 \"Overflow error: %s\" % str(e))\r\n            return False\r\n\r\n        # Add change to self.changes\r\n        self.changes[(i, j)] = val\r\n        self.dataChanged.emit(index, index)\r\n        if not is_string(val):\r\n            if val > self.vmax:\r\n                self.vmax = val\r\n            if val < self.vmin:\r\n                self.vmin = val\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef headerData(self, section, orientation, role=Qt.DisplayRole):\r\n        if role != Qt.DisplayRole:\r\n            return to_qvariant()\r\n        labels = self.xlabels if orientation == Qt.Horizontal else self.ylabels\r\n        if labels is None:\r\n            return to_qvariant(int(section))\r\n        else:\r\n            return to_qvariant(labels[section])", "response": "Returns the data for the header of the specified section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createEditor(self, parent, option, index):\r\n        model = index.model()\r\n        value = model.get_value(index)\r\n        if model._data.dtype.name == \"bool\":\r\n            value = not value\r\n            model.setData(index, to_qvariant(value))\r\n            return\r\n        elif value is not np.ma.masked:\r\n            editor = QLineEdit(parent)\r\n            editor.setFont(get_font(font_size_delta=DEFAULT_SMALL_DELTA))\r\n            editor.setAlignment(Qt.AlignCenter)\r\n            if is_number(self.dtype):\r\n                validator = QDoubleValidator(editor)\r\n                validator.setLocale(QLocale('C'))\r\n                editor.setValidator(validator)\r\n            editor.returnPressed.connect(self.commitAndCloseEditor)\r\n            return editor", "response": "Create editor widget for the given index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncommit and close editor", "response": "def commitAndCloseEditor(self):\r\n        \"\"\"Commit and close editor\"\"\"\r\n        editor = self.sender()\r\n        # Avoid a segfault with PyQt5. Variable value won't be changed\r\n        # but at least Spyder won't crash. It seems generated by a bug in sip.\r\n        try:\r\n            self.commitData.emit(editor)\r\n        except AttributeError:\r\n            pass\r\n        self.closeEditor.emit(editor, QAbstractItemDelegate.NoHint)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset editor widget s data", "response": "def setEditorData(self, editor, index):\r\n        \"\"\"Set editor widget's data\"\"\"\r\n        text = from_qvariant(index.model().data(index, Qt.DisplayRole), str)\r\n        editor.setText(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resize_to_contents(self):\r\n        QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))\r\n        self.resizeColumnsToContents()\r\n        self.model().fetch_more(columns=True)\r\n        self.resizeColumnsToContents()\r\n        QApplication.restoreOverrideCursor()", "response": "Resize cells to contents"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sel_to_text(self, cell_range):\r\n        if not cell_range:\r\n            return\r\n        row_min, row_max, col_min, col_max = get_idx_rect(cell_range)\r\n        if col_min == 0 and col_max == (self.model().cols_loaded-1):\r\n            # we've selected a whole column. It isn't possible to\r\n            # select only the first part of a column without loading more, \r\n            # so we can treat it as intentional and copy the whole thing\r\n            col_max = self.model().total_cols-1\r\n        if row_min == 0 and row_max == (self.model().rows_loaded-1):\r\n            row_max = self.model().total_rows-1\r\n        \r\n        _data = self.model().get_data()\r\n        if PY3:\r\n            output = io.BytesIO()\r\n        else:\r\n            output = io.StringIO()\r\n        try:\r\n            np.savetxt(output, _data[row_min:row_max+1, col_min:col_max+1],\r\n                       delimiter='\\t', fmt=self.model().get_format())\r\n        except:\r\n            QMessageBox.warning(self, _(\"Warning\"),\r\n                                _(\"It was not possible to copy values for \"\r\n                                  \"this array\"))\r\n            return\r\n        contents = output.getvalue().decode('utf-8')\r\n        output.close()\r\n        return contents", "response": "Copy an array portion to a unicode string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\r\n        cliptxt = self._sel_to_text( self.selectedIndexes() )\r\n        clipboard = QApplication.clipboard()\r\n        clipboard.setText(cliptxt)", "response": "Copy text to clipboard"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\naccept changes in the model and update the data array with the new ones.", "response": "def accept_changes(self):\r\n        \"\"\"Accept changes\"\"\"\r\n        for (i, j), value in list(self.model.changes.items()):\r\n            self.data[i, j] = value\r\n        if self.old_data_shape is not None:\r\n            self.data.shape = self.old_data_shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_and_check(self, data, title='', readonly=False,\r\n                        xlabels=None, ylabels=None):\r\n        \"\"\"\r\n        Setup ArrayEditor:\r\n        return False if data is not supported, True otherwise\r\n        \"\"\"\r\n        self.data = data\r\n        readonly = readonly or not self.data.flags.writeable\r\n        is_record_array = data.dtype.names is not None\r\n        is_masked_array = isinstance(data, np.ma.MaskedArray)\r\n\r\n        if data.ndim > 3:\r\n            self.error(_(\"Arrays with more than 3 dimensions are not \"\r\n                         \"supported\"))\r\n            return False\r\n        if xlabels is not None and len(xlabels) != self.data.shape[1]:\r\n            self.error(_(\"The 'xlabels' argument length do no match array \"\r\n                         \"column number\"))\r\n            return False\r\n        if ylabels is not None and len(ylabels) != self.data.shape[0]:\r\n            self.error(_(\"The 'ylabels' argument length do no match array row \"\r\n                         \"number\"))\r\n            return False\r\n        if not is_record_array:\r\n            dtn = data.dtype.name\r\n            if dtn not in SUPPORTED_FORMATS and not dtn.startswith('str') \\\r\n               and not dtn.startswith('unicode'):\r\n                arr = _(\"%s arrays\") % data.dtype.name\r\n                self.error(_(\"%s are currently not supported\") % arr)\r\n                return False\r\n        \r\n        self.layout = QGridLayout()\r\n        self.setLayout(self.layout)\r\n        self.setWindowIcon(ima.icon('arredit'))\r\n        if title:\r\n            title = to_text_string(title) + \" - \" + _(\"NumPy array\")\r\n        else:\r\n            title = _(\"Array editor\")\r\n        if readonly:\r\n            title += ' (' + _('read only') + ')'\r\n        self.setWindowTitle(title)\r\n        self.resize(600, 500)\r\n        \r\n        # Stack widget\r\n        self.stack = QStackedWidget(self)\r\n        if is_record_array:\r\n            for name in data.dtype.names:\r\n                self.stack.addWidget(ArrayEditorWidget(self, data[name],\r\n                                                   readonly, xlabels, ylabels))\r\n        elif is_masked_array:\r\n            self.stack.addWidget(ArrayEditorWidget(self, data, readonly,\r\n                                                   xlabels, ylabels))\r\n            self.stack.addWidget(ArrayEditorWidget(self, data.data, readonly,\r\n                                                   xlabels, ylabels))\r\n            self.stack.addWidget(ArrayEditorWidget(self, data.mask, readonly,\r\n                                                   xlabels, ylabels))\r\n        elif data.ndim == 3:\r\n            pass\r\n        else:\r\n            self.stack.addWidget(ArrayEditorWidget(self, data, readonly,\r\n                                                   xlabels, ylabels))\r\n        self.arraywidget = self.stack.currentWidget()\r\n        if self.arraywidget:\r\n            self.arraywidget.model.dataChanged.connect(\r\n                                                    self.save_and_close_enable)\r\n        self.stack.currentChanged.connect(self.current_widget_changed)\r\n        self.layout.addWidget(self.stack, 1, 0)\r\n\r\n        # Buttons configuration\r\n        btn_layout = QHBoxLayout()\r\n        if is_record_array or is_masked_array or data.ndim == 3:\r\n            if is_record_array:\r\n                btn_layout.addWidget(QLabel(_(\"Record array fields:\")))\r\n                names = []\r\n                for name in data.dtype.names:\r\n                    field = data.dtype.fields[name]\r\n                    text = name\r\n                    if len(field) >= 3:\r\n                        title = field[2]\r\n                        if not is_text_string(title):\r\n                            title = repr(title)\r\n                        text += ' - '+title\r\n                    names.append(text)\r\n            else:\r\n                names = [_('Masked data'), _('Data'), _('Mask')]\r\n            if data.ndim == 3:\r\n                # QSpinBox\r\n                self.index_spin = QSpinBox(self, keyboardTracking=False)\r\n                self.index_spin.valueChanged.connect(self.change_active_widget)\r\n                # QComboBox\r\n                names = [str(i) for i in range(3)]\r\n                ra_combo = QComboBox(self)\r\n                ra_combo.addItems(names)\r\n                ra_combo.currentIndexChanged.connect(self.current_dim_changed)    \r\n                # Adding the widgets to layout\r\n                label = QLabel(_(\"Axis:\"))\r\n                btn_layout.addWidget(label)\r\n                btn_layout.addWidget(ra_combo)\r\n                self.shape_label = QLabel()\r\n                btn_layout.addWidget(self.shape_label)\r\n                label = QLabel(_(\"Index:\"))\r\n                btn_layout.addWidget(label)\r\n                btn_layout.addWidget(self.index_spin)\r\n                self.slicing_label = QLabel()\r\n                btn_layout.addWidget(self.slicing_label)\r\n                # set the widget to display when launched\r\n                self.current_dim_changed(self.last_dim)\r\n            else:\r\n                ra_combo = QComboBox(self)\r\n                ra_combo.currentIndexChanged.connect(self.stack.setCurrentIndex)\r\n                ra_combo.addItems(names)\r\n                btn_layout.addWidget(ra_combo)\r\n            if is_masked_array:\r\n                label = QLabel(_(\"<u>Warning</u>: changes are applied separately\"))\r\n                label.setToolTip(_(\"For performance reasons, changes applied \"\\\r\n                                   \"to masked array won't be reflected in \"\\\r\n                                   \"array's data (and vice-versa).\"))\r\n                btn_layout.addWidget(label)\r\n\r\n        btn_layout.addStretch()\r\n\r\n        if not readonly:\r\n            self.btn_save_and_close = QPushButton(_('Save and Close'))\r\n            self.btn_save_and_close.setDisabled(True)\r\n            self.btn_save_and_close.clicked.connect(self.accept)\r\n            btn_layout.addWidget(self.btn_save_and_close)\r\n\r\n        self.btn_close = QPushButton(_('Close'))\r\n        self.btn_close.setAutoDefault(True)\r\n        self.btn_close.setDefault(True)\r\n        self.btn_close.clicked.connect(self.reject)\r\n        btn_layout.addWidget(self.btn_close)\r\n        self.layout.addLayout(btn_layout, 2, 0)\r\n\r\n        self.setMinimumSize(400, 300)\r\n        \r\n        # Make the dialog act as a window\r\n        self.setWindowFlags(Qt.Window)\r\n        \r\n        return True", "response": "Setup array editor and check if array is not supported"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the active widget of the current item.", "response": "def change_active_widget(self, index):\r\n        \"\"\"\r\n        This is implemented for handling negative values in index for\r\n        3d arrays, to give the same behavior as slicing\r\n        \"\"\"\r\n        string_index = [':']*3\r\n        string_index[self.last_dim] = '<font color=red>%i</font>'\r\n        self.slicing_label.setText((r\"Slicing: [\" + \", \".join(string_index) +\r\n                                \"]\") % index)\r\n        if index < 0:\r\n            data_index = self.data.shape[self.last_dim] + index\r\n        else:\r\n            data_index = index\r\n        slice_index = [slice(None)]*3\r\n        slice_index[self.last_dim] = data_index\r\n\r\n        stack_index = self.dim_indexes[self.last_dim].get(data_index)\r\n        if stack_index is None:\r\n            stack_index = self.stack.count()\r\n            try:\r\n                self.stack.addWidget(ArrayEditorWidget(\r\n                    self, self.data[tuple(slice_index)]))\r\n            except IndexError:  # Handle arrays of size 0 in one axis\r\n                self.stack.addWidget(ArrayEditorWidget(self, self.data))\r\n            self.dim_indexes[self.last_dim][data_index] = stack_index\r\n            self.stack.update()\r\n        self.stack.setCurrentIndex(stack_index)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reject(self):\r\n        if self.arraywidget is not None:\r\n            for index in range(self.stack.count()):\r\n                self.stack.widget(index).reject_changes()\r\n        QDialog.reject(self)", "response": "Reimplement Qt method reject"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_lexer_for_filename(filename):\n    filename = filename or ''\n    root, ext = os.path.splitext(filename)\n    if ext in custom_extension_lexer_mapping:\n        lexer = get_lexer_by_name(custom_extension_lexer_mapping[ext])\n    else:\n        try:\n            lexer = get_lexer_for_filename(filename)\n        except Exception:\n            return TextLexer()\n    return lexer", "response": "Get a Pygments Lexer given a filename."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the keywords for a given lexer.", "response": "def get_keywords(lexer):\n    \"\"\"Get the keywords for a given lexer.\n    \"\"\"\n    if not hasattr(lexer, 'tokens'):\n        return []\n    if 'keywords' in lexer.tokens:\n        try:\n            return lexer.tokens['keywords'][0][0].words\n        except:\n            pass\n    keywords = []\n    for vals in lexer.tokens.values():\n        for val in vals:\n            try:\n                if isinstance(val[0], words):\n                    keywords.extend(val[0].words)\n                else:\n                    ini_val = val[0]\n                    if ')\\\\b' in val[0] or ')(\\\\s+)' in val[0]:\n                        val = re.sub(r'\\\\.', '', val[0])\n                        val = re.sub(r'[^0-9a-zA-Z|]+', '', val)\n                        if '|' in ini_val:\n                            keywords.extend(val.split('|'))\n                        else:\n                            keywords.append(val)\n            except Exception:\n                continue\n    return keywords"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract all words from a source code file to be used in code completion similar to VSCode.", "response": "def get_words(file_path=None, content=None, extension=None):\n    \"\"\"\n    Extract all words from a source code file to be used in code completion.\n\n    Extract the list of words that contains the file in the editor,\n    to carry out the inline completion similar to VSCode.\n    \"\"\"\n    if (file_path is None and (content is None or extension is None) or\n                    file_path and content and extension):\n        error_msg = ('Must provide `file_path` or `content` and `extension`')\n        raise Exception(error_msg)\n\n    if file_path and content is None and extension is None:\n        extension = os.path.splitext(file_path)[1]\n        with open(file_path) as infile:\n            content = infile.read()\n\n    if extension in ['.css']:\n        regex = re.compile(r'([^a-zA-Z-])')\n    elif extension in ['.R', '.c', '.md', '.cpp', '.java', '.py']:\n        regex = re.compile(r'([^a-zA-Z_])')\n    else:\n        regex = re.compile(r'([^a-zA-Z])')\n\n    words = sorted(set(regex.sub(r' ', content).split()))\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_parent_until(path):\n    dirname = osp.dirname(path)\n    try:\n        mod = osp.basename(path)\n        mod = osp.splitext(mod)[0]\n        imp.find_module(mod, [dirname])\n    except ImportError:\n        return\n    items = [mod]\n    while 1:\n        items.append(osp.basename(dirname))\n        try:\n            dirname = osp.dirname(dirname)\n            imp.find_module('__init__', [dirname + os.sep])\n        except ImportError:\n            break\n    return '.'.join(reversed(items))", "response": "Given a file path determine the full module path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_docstring(self):\n        left = self.position\n        while left:\n            if self.source_code[left: left + 3] in ['\"\"\"', \"'''\"]:\n                left += 3\n                break\n            left -= 1\n        right = self.position\n        while right < len(self.source_code):\n            if self.source_code[right - 3: right] in ['\"\"\"', \"'''\"]:\n                right -= 3\n                break\n            right += 1\n        if left and right < len(self.source_code):\n            return self.source_code[left: right]\n        return ''", "response": "Find the docstring we are currently in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_connection_settings(self):\n        existing_kernel = CONF.get(\"existing-kernel\", \"settings\", {})\n\n        connection_file_path = existing_kernel.get(\"json_file_path\", \"\")\n        is_remote = existing_kernel.get(\"is_remote\", False)\n        username = existing_kernel.get(\"username\", \"\")\n        hostname = existing_kernel.get(\"hostname\", \"\")\n        port = str(existing_kernel.get(\"port\", 22))\n        is_ssh_kf = existing_kernel.get(\"is_ssh_keyfile\", False)\n        ssh_kf = existing_kernel.get(\"ssh_key_file_path\", \"\")\n\n        if connection_file_path != \"\":\n            self.cf.setText(connection_file_path)\n        if username != \"\":\n            self.un.setText(username)\n        if hostname != \"\":\n            self.hn.setText(hostname)\n        if ssh_kf != \"\":\n            self.kf.setText(ssh_kf)\n        self.rm_group.setChecked(is_remote)\n        self.pn.setText(port)\n        self.kf_radio.setChecked(is_ssh_kf)\n        self.pw_radio.setChecked(not is_ssh_kf)\n\n        try:\n            import keyring\n            ssh_passphrase = keyring.get_password(\"spyder_remote_kernel\",\n                                                  \"ssh_key_passphrase\")\n            ssh_password = keyring.get_password(\"spyder_remote_kernel\",\n                                                \"ssh_password\")\n            if ssh_passphrase:\n                self.kfp.setText(ssh_passphrase)\n            if ssh_password:\n                self.pw.setText(ssh_password)\n        except Exception:\n            pass", "response": "Load the user s previously - saved kernel connection settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves user s kernel connection settings.", "response": "def save_connection_settings(self):\n        \"\"\"Save user's kernel connection settings.\"\"\"\n\n        if not self.save_layout.isChecked():\n            return\n\n        is_ssh_key = bool(self.kf_radio.isChecked())\n        connection_settings = {\n            \"json_file_path\": self.cf.text(),\n            \"is_remote\": self.rm_group.isChecked(),\n            \"username\": self.un.text(),\n            \"hostname\": self.hn.text(),\n            \"port\": self.pn.text(),\n            \"is_ssh_keyfile\": is_ssh_key,\n            \"ssh_key_file_path\": self.kf.text()\n        }\n        CONF.set(\"existing-kernel\", \"settings\", connection_settings)\n\n        try:\n            import keyring\n            if is_ssh_key:\n                keyring.set_password(\"spyder_remote_kernel\",\n                                     \"ssh_key_passphrase\",\n                                     self.kfp.text())\n            else:\n                keyring.set_password(\"spyder_remote_kernel\",\n                                     \"ssh_password\",\n                                     self.pw.text())\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns color depending on value type", "response": "def get_color(value, alpha):\r\n    \"\"\"Return color depending on value type\"\"\"\r\n    color = QColor()\r\n    for typ in COLORS:\r\n        if isinstance(value, typ):\r\n            color = QColor(COLORS[typ])\r\n    color.setAlphaF(alpha)\r\n    return color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the column separator", "response": "def get_col_sep(self):\r\n        \"\"\"Return the column separator\"\"\"\r\n        if self.tab_btn.isChecked():\r\n            return u\"\\t\"\r\n        elif self.ws_btn.isChecked():\r\n            return None\r\n        return to_text_string(self.line_edt.text())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the row separator", "response": "def get_row_sep(self):\r\n        \"\"\"Return the row separator\"\"\"\r\n        if self.eol_btn.isChecked():\r\n            return u\"\\n\"\r\n        return to_text_string(self.line_edt_row.text())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_as_data(self, as_data):\r\n        self._as_data = as_data\r\n        self.asDataChanged.emit(as_data)", "response": "Set if data type conversion is needed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _display_data(self, index):\r\n        return to_qvariant(self._data[index.row()][index.column()])", "response": "Return a data element"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a model data element", "response": "def data(self, index, role=Qt.DisplayRole):\r\n        \"\"\"Return a model data element\"\"\"\r\n        if not index.isValid():\r\n            return to_qvariant()\r\n        if role == Qt.DisplayRole:\r\n            return self._display_data(index)\r\n        elif role == Qt.BackgroundColorRole:\r\n            return to_qvariant(get_color(self._data[index.row()][index.column()], .2))\r\n        elif role == Qt.TextAlignmentRole:\r\n            return to_qvariant(int(Qt.AlignRight|Qt.AlignVCenter))\r\n        return to_qvariant()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_data_type(self, index, **kwargs):\r\n        if not index.isValid():\r\n            return False\r\n        try:\r\n            if kwargs['atype'] == \"date\":\r\n                self._data[index.row()][index.column()] = \\\r\n                    datestr_to_datetime(self._data[index.row()][index.column()],\r\n                                    kwargs['dayfirst']).date()\r\n            elif kwargs['atype'] == \"perc\":\r\n                _tmp = self._data[index.row()][index.column()].replace(\"%\", \"\")\r\n                self._data[index.row()][index.column()] = eval(_tmp)/100.\r\n            elif kwargs['atype'] == \"account\":\r\n                _tmp = self._data[index.row()][index.column()].replace(\",\", \"\")\r\n                self._data[index.row()][index.column()] = eval(_tmp)\r\n            elif kwargs['atype'] == \"unicode\":\r\n                self._data[index.row()][index.column()] = to_text_string(\r\n                    self._data[index.row()][index.column()])\r\n            elif kwargs['atype'] == \"int\":\r\n                self._data[index.row()][index.column()] = int(\r\n                    self._data[index.row()][index.column()])\r\n            elif kwargs['atype'] == \"float\":\r\n                self._data[index.row()][index.column()] = float(\r\n                    self._data[index.row()][index.column()])\r\n            self.dataChanged.emit(index, index)\r\n        except Exception as instance:\r\n            print(instance)", "response": "Parse a type to an other type"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _shape_text(self, text, colsep=u\"\\t\", rowsep=u\"\\n\",\r\n                    transpose=False, skiprows=0, comments='#'):\r\n        \"\"\"Decode the shape of the given text\"\"\"\r\n        assert colsep != rowsep\r\n        out = []\r\n        text_rows = text.split(rowsep)[skiprows:]\r\n        for row in text_rows:\r\n            stripped = to_text_string(row).strip()\r\n            if len(stripped) == 0 or stripped.startswith(comments):\r\n                continue\r\n            line = to_text_string(row).split(colsep)\r\n            line = [try_to_parse(to_text_string(x)) for x in line]\r\n            out.append(line)\r\n        # Replace missing elements with np.nan's or None's\r\n        if programs.is_module_installed('numpy'):\r\n            from numpy import nan\r\n            out = list(zip_longest(*out, fillvalue=nan))\r\n        else:\r\n            out = list(zip_longest(*out, fillvalue=None))\r\n        # Tranpose the last result to get the expected one\r\n        out = [[r[col] for r in out] for col in range(len(out[0]))]\r\n        if transpose:\r\n            return [[r[col] for r in out] for col in range(len(out[0]))]\r\n        return out", "response": "Decode the shape of the given text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nput data into table model", "response": "def process_data(self, text, colsep=u\"\\t\", rowsep=u\"\\n\",\r\n                     transpose=False, skiprows=0, comments='#'):\r\n        \"\"\"Put data into table model\"\"\"\r\n        data = self._shape_text(text, colsep, rowsep, transpose, skiprows,\r\n                                comments)\r\n        self._model = PreviewTableModel(data)\r\n        self.setModel(self._model)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_to_type(self,**kwargs):\r\n        indexes = self.selectedIndexes()\r\n        if not indexes: return\r\n        for index in indexes:\r\n            self.model().parse_data_type(index, **kwargs)", "response": "Parse to a given type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_data(self, text, colsep=u\"\\t\", rowsep=u\"\\n\",\r\n                  transpose=False, skiprows=0, comments='#'):\r\n        \"\"\"Open clipboard text as table\"\"\"\r\n        if pd:\r\n            self.pd_text = text\r\n            self.pd_info = dict(sep=colsep, lineterminator=rowsep,\r\n                skiprows=skiprows, comment=comments)\r\n            if colsep is None:\r\n                self.pd_info = dict(lineterminator=rowsep, skiprows=skiprows,\r\n                    comment=comments, delim_whitespace=True)\r\n        self._table_view.process_data(text, colsep, rowsep, transpose,\r\n                                      skiprows, comments)", "response": "Open clipboard text as table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproceed to a given step", "response": "def _set_step(self, step):\r\n        \"\"\"Proceed to a given step\"\"\"\r\n        new_tab = self.tab_widget.currentIndex() + step\r\n        assert new_tab < self.tab_widget.count() and new_tab >= 0\r\n        if new_tab == self.tab_widget.count()-1:\r\n            try:\r\n                self.table_widget.open_data(self._get_plain_text(),\r\n                                        self.text_widget.get_col_sep(),\r\n                                        self.text_widget.get_row_sep(),\r\n                                        self.text_widget.trnsp_box.isChecked(),\r\n                                        self.text_widget.get_skiprows(),\r\n                                        self.text_widget.get_comments())\r\n                self.done_btn.setEnabled(True)\r\n                self.done_btn.setDefault(True)\r\n                self.fwd_btn.setEnabled(False)\r\n                self.back_btn.setEnabled(True)\r\n            except (SyntaxError, AssertionError) as error:\r\n                QMessageBox.critical(self, _(\"Import wizard\"),\r\n                            _(\"<b>Unable to proceed to next step</b>\"\r\n                              \"<br><br>Please check your entries.\"\r\n                              \"<br><br>Error message:<br>%s\") % str(error))\r\n                return\r\n        elif new_tab == 0:\r\n            self.done_btn.setEnabled(False)\r\n            self.fwd_btn.setEnabled(True)\r\n            self.back_btn.setEnabled(False)\r\n        self._focus_tab(new_tab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreduces the alist dimension if needed", "response": "def _simplify_shape(self, alist, rec=0):\r\n        \"\"\"Reduce the alist dimension if needed\"\"\"\r\n        if rec != 0:\r\n            if len(alist) == 1:\r\n                return alist[-1]\r\n            return alist\r\n        if len(alist) == 1:\r\n            return self._simplify_shape(alist[-1], 1)\r\n        return [self._simplify_shape(al, 1) for al in alist]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns clipboard processed as data", "response": "def _get_table_data(self):\r\n        \"\"\"Return clipboard processed as data\"\"\"\r\n        data = self._simplify_shape(\r\n                self.table_widget.get_data())\r\n        if self.table_widget.array_btn.isChecked():\r\n            return array(data)\r\n        elif pd and self.table_widget.df_btn.isChecked():\r\n            info = self.table_widget.pd_info\r\n            buf = io.StringIO(self.table_widget.pd_text)\r\n            return pd.read_csv(buf, **info)\r\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process(self):\r\n        var_name = self.name_edt.text()\r\n        try:\r\n            self.var_name = str(var_name)\r\n        except UnicodeEncodeError:\r\n            self.var_name = to_text_string(var_name)\r\n        if self.text_widget.get_as_data():\r\n            self.clip_data = self._get_table_data()\r\n        elif self.text_widget.get_as_code():\r\n            self.clip_data = try_to_eval(\r\n                to_text_string(self._get_plain_text()))\r\n        else:\r\n            self.clip_data = to_text_string(self._get_plain_text())\r\n        self.accept()", "response": "Process the data from clipboard"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets Spyder breakpoints into a debugging session", "response": "def set_spyder_breakpoints(self, force=False):\n        \"\"\"Set Spyder breakpoints into a debugging session\"\"\"\n        if self._reading or force:\n            breakpoints_dict = CONF.get('run', 'breakpoints', {})\n\n            # We need to enclose pickled values in a list to be able to\n            # send them to the kernel in Python 2\n            serialiazed_breakpoints = [pickle.dumps(breakpoints_dict,\n                                                    protocol=PICKLE_PROTOCOL)]\n            breakpoints = to_text_string(serialiazed_breakpoints)\n\n            cmd = u\"!get_ipython().kernel._set_spyder_breakpoints({})\"\n            self.kernel_client.input(cmd.format(breakpoints))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun an IPython magic while debugging.", "response": "def dbg_exec_magic(self, magic, args=''):\n        \"\"\"Run an IPython magic while debugging.\"\"\"\n        code = \"!get_ipython().kernel.shell.run_line_magic('{}', '{}')\".format(\n                    magic, args)\n        self.kernel_client.input(code)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh_from_pdb(self, pdb_state):\n        if 'step' in pdb_state and 'fname' in pdb_state['step']:\n            fname = pdb_state['step']['fname']\n            lineno = pdb_state['step']['lineno']\n            self.sig_pdb_step.emit(fname, lineno)\n\n        if 'namespace_view' in pdb_state:\n            self.sig_namespace_view.emit(ast.literal_eval(\n                    pdb_state['namespace_view']))\n\n        if 'var_properties' in pdb_state:\n            self.sig_var_properties.emit(ast.literal_eval(\n                    pdb_state['var_properties']))", "response": "Refresh Variable Explorer and Editor from a Pdb session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_input_request(self, msg):\n        if self._hidden:\n            raise RuntimeError('Request for raw input during hidden execution.')\n\n        # Make sure that all output from the SUB channel has been processed\n        # before entering readline mode.\n        self.kernel_client.iopub_channel.flush()\n\n        def callback(line):\n            # Save history to browse it later\n            if not (len(self._control.history) > 0\n                    and self._control.history[-1] == line):\n                # do not save pdb commands\n                cmd = line.split(\" \")[0]\n                if \"do_\" + cmd not in dir(pdb.Pdb):\n                    self._control.history.append(line)\n\n            # This is the Spyder addition: add a %plot magic to display\n            # plots while debugging\n            if line.startswith('%plot '):\n                line = line.split()[-1]\n                code = \"__spy_code__ = get_ipython().run_cell('%s')\" % line\n                self.kernel_client.input(code)\n            else:\n                self.kernel_client.input(line)\n        if self._reading:\n            self._reading = False\n        self._readline(msg['content']['prompt'], callback=callback,\n                       password=msg['content']['password'])", "response": "Handle a raw input request from the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _event_filter_console_keypress(self, event):\n        key = event.key()\n        if self._reading:\n            self._control.current_prompt_pos = self._prompt_pos\n            if key == Qt.Key_Up:\n                self._control.browse_history(backward=True)\n                return True\n            elif key == Qt.Key_Down:\n                self._control.browse_history(backward=False)\n                return True\n            elif key in (Qt.Key_Return, Qt.Key_Enter):\n                self._control.reset_search_pos()\n            else:\n                self._control.hist_wholeline = False\n            return super(DebuggingWidget,\n                         self)._event_filter_console_keypress(event)\n        else:\n            return super(DebuggingWidget,\n                         self)._event_filter_console_keypress(event)", "response": "Handle Key_Up / Key_Down while debugging."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the global maximum and minimum.", "response": "def global_max(col_vals, index):\r\n    \"\"\"Returns the global maximum and minimum.\"\"\"\r\n    col_vals_without_None = [x for x in col_vals if x is not None]\r\n    max_col, min_col = zip(*col_vals_without_None)\r\n    return max(max_col), min(min_col)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _axis(self, axis):\r\n        return self.df.columns if axis == 0 else self.df.index", "response": "Returns the corresponding labels taking into account the axis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _axis_levels(self, axis):\r\n        ax = self._axis(axis)\r\n        return 1 if not hasattr(ax, 'levels') else len(ax.levels)", "response": "Returns the number of levels in the given axis"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef header(self, axis, x, level=0):\r\n        ax = self._axis(axis)\r\n        return ax.values[x] if not hasattr(ax, 'levels') \\\r\n            else ax.values[x][level]", "response": "Returns the values of the labels corresponding to the header of columns or rows x."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates self. max_min_col with the maximum and minimum number in each column. Returns self. max_min_col.", "response": "def max_min_col_update(self):\r\n        \"\"\"\r\n        Determines the maximum and minimum number in each column.\r\n\r\n        The result is a list whose k-th entry is [vmax, vmin], where vmax and\r\n        vmin denote the maximum and minimum of the k-th column (ignoring NaN). \r\n        This list is stored in self.max_min_col.\r\n\r\n        If the k-th column has a non-numerical dtype, then the k-th entry\r\n        is set to None. If the dtype is complex, then compute the maximum and\r\n        minimum of the absolute values. If vmax equals vmin, then vmin is \r\n        decreased by one.\r\n        \"\"\"\r\n        if self.df.shape[0] == 0: # If no rows to compute max/min then return\r\n            return\r\n        self.max_min_col = []\r\n        for dummy, col in self.df.iteritems():\r\n            if col.dtype in REAL_NUMBER_TYPES + COMPLEX_NUMBER_TYPES:\r\n                if col.dtype in REAL_NUMBER_TYPES:\r\n                    vmax = col.max(skipna=True)\r\n                    vmin = col.min(skipna=True)\r\n                else:\r\n                    vmax = col.abs().max(skipna=True)\r\n                    vmin = col.abs().min(skipna=True)\r\n                if vmax != vmin:\r\n                    max_min = [vmax, vmin]\r\n                else:\r\n                    max_min = [vmax, vmin - 1]\r\n            else:\r\n                max_min = None\r\n            self.max_min_col.append(max_min)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef colum_avg(self, state):\r\n        self.colum_avg_enabled = state > 0\r\n        if self.colum_avg_enabled:\r\n            self.return_max = lambda col_vals, index: col_vals[index]\r\n        else:\r\n            self.return_max = global_max\r\n        self.reset()", "response": "Toggle colum average color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the background color depending on value.", "response": "def get_bgcolor(self, index):\r\n        \"\"\"Background color depending on value.\"\"\"\r\n        column = index.column()\r\n        if not self.bgcolor_enabled:\r\n            return\r\n        value = self.get_value(index.row(), column)\r\n        if self.max_min_col[column] is None or isna(value):\r\n            color = QColor(BACKGROUND_NONNUMBER_COLOR)\r\n            if is_text_string(value):\r\n                color.setAlphaF(BACKGROUND_STRING_ALPHA)\r\n            else:\r\n                color.setAlphaF(BACKGROUND_MISC_ALPHA)\r\n        else:\r\n            if isinstance(value, COMPLEX_NUMBER_TYPES):\r\n                color_func = abs\r\n            else:\r\n                color_func = float\r\n            vmax, vmin = self.return_max(self.max_min_col, column)\r\n            hue = (BACKGROUND_NUMBER_MINHUE + BACKGROUND_NUMBER_HUERANGE *\r\n                   (vmax - color_func(value)) / (vmax - vmin))\r\n            hue = float(abs(hue))\r\n            if hue > 1:\r\n                hue = 1\r\n            color = QColor.fromHsvF(hue, BACKGROUND_NUMBER_SATURATION,\r\n                                    BACKGROUND_NUMBER_VALUE,\r\n                                    BACKGROUND_NUMBER_ALPHA)\r\n        return color"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the DataFrame.", "response": "def get_value(self, row, column):\r\n        \"\"\"Return the value of the DataFrame.\"\"\"\r\n        # To increase the performance iat is used but that requires error\r\n        # handling, so fallback uses iloc\r\n        try:\r\n            value = self.df.iat[row, column]\r\n        except OutOfBoundsDatetime:\r\n            value = self.df.iloc[:, column].astype(str).iat[row]\r\n        except:\r\n            value = self.df.iloc[row, column]\r\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self, index, role=Qt.DisplayRole):\r\n        if not index.isValid():\r\n            return to_qvariant()\r\n        if role == Qt.DisplayRole or role == Qt.EditRole:\r\n            column = index.column()\r\n            row = index.row()\r\n            value = self.get_value(row, column)\r\n            if isinstance(value, float):\r\n                try:\r\n                    return to_qvariant(self._format % value)\r\n                except (ValueError, TypeError):\r\n                    # may happen if format = '%d' and value = NaN;\r\n                    # see issue 4139\r\n                    return to_qvariant(DEFAULT_FORMAT % value)\r\n            elif is_type_text_string(value):\r\n                # Don't perform any conversion on strings\r\n                # because it leads to differences between\r\n                # the data present in the dataframe and\r\n                # what is shown by Spyder\r\n                return value\r\n            else:\r\n                try:\r\n                    return to_qvariant(to_text_string(value))\r\n                except Exception:\r\n                    self.display_error_idxs.append(index)\r\n                    return u'Display Error!'\r\n        elif role == Qt.BackgroundColorRole:\r\n            return to_qvariant(self.get_bgcolor(index))\r\n        elif role == Qt.FontRole:\r\n            return to_qvariant(get_font(font_size_delta=DEFAULT_SMALL_DELTA))\r\n        elif role == Qt.ToolTipRole:\r\n            if index in self.display_error_idxs:\r\n                return _(\"It is not possible to display this value because\\n\"\r\n                         \"an error ocurred while trying to do it\")\r\n        return to_qvariant()", "response": "Returns the data at the given index in the given role"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flags(self, index):\r\n        return Qt.ItemFlags(QAbstractTableModel.flags(self, index) |\r\n                            Qt.ItemIsEditable)", "response": "Return the flags for the item at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setData(self, index, value, role=Qt.EditRole, change_type=None):\r\n        column = index.column()\r\n        row = index.row()\r\n\r\n        if index in self.display_error_idxs:\r\n            return False\r\n        if change_type is not None:\r\n            try:\r\n                value = self.data(index, role=Qt.DisplayRole)\r\n                val = from_qvariant(value, str)\r\n                if change_type is bool:\r\n                    val = bool_false_check(val)\r\n                self.df.iloc[row, column] = change_type(val)\r\n            except ValueError:\r\n                self.df.iloc[row, column] = change_type('0')\r\n        else:\r\n            val = from_qvariant(value, str)\r\n            current_value = self.get_value(row, column)\r\n            if isinstance(current_value, (bool, np.bool_)):\r\n                val = bool_false_check(val)\r\n            supported_types = (bool, np.bool_) + REAL_NUMBER_TYPES\r\n            if (isinstance(current_value, supported_types) or\r\n                    is_text_string(current_value)):\r\n                try:\r\n                    self.df.iloc[row, column] = current_value.__class__(val)\r\n                except (ValueError, OverflowError) as e:\r\n                    QMessageBox.critical(self.dialog, \"Error\",\r\n                                         str(type(e).__name__) + \": \" + str(e))\r\n                    return False\r\n            else:\r\n                QMessageBox.critical(self.dialog, \"Error\",\r\n                                     \"Editing dtype {0!s} not yet supported.\"\r\n                                     .format(type(current_value).__name__))\r\n                return False\r\n        self.max_min_col_update()\r\n        self.dataChanged.emit(index, index)\r\n        return True", "response": "Change the value of the item at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of columns in the DataFrame.", "response": "def columnCount(self, index=QModelIndex()):\r\n        \"\"\"DataFrame column number\"\"\"\r\n        # Avoid a \"Qt exception in virtual methods\" generated in our\r\n        # tests on Windows/Python 3.7\r\n        # See PR 8910\r\n        try:\r\n            # This is done to implement series\r\n            if len(self.df.shape) == 1:\r\n                return 2\r\n            elif self.total_cols <= self.cols_loaded:\r\n                return self.total_cols\r\n            else:\r\n                return self.cols_loaded\r\n        except AttributeError:\r\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_more_data(self, value, rows=False, columns=False):\r\n        try:\r\n            if rows and value == self.verticalScrollBar().maximum():\r\n                self.model().fetch_more(rows=rows)\r\n                self.sig_fetch_more_rows.emit()\r\n            if columns and value == self.horizontalScrollBar().maximum():\r\n                self.model().fetch_more(columns=columns)\r\n                self.sig_fetch_more_columns.emit()\r\n\r\n        except NameError:\r\n            # Needed to handle a NameError while fetching data when closing\r\n            # See issue 7880\r\n            pass", "response": "Load more rows and columns to display."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sortByColumn(self, index):\r\n        if self.sort_old == [None]:\r\n            self.header_class.setSortIndicatorShown(True)\r\n        sort_order = self.header_class.sortIndicatorOrder()\r\n        self.sig_sort_by_column.emit()\r\n        if not self.model().sort(index, sort_order):\r\n            if len(self.sort_old) != 2:\r\n                self.header_class.setSortIndicatorShown(False)\r\n            else:\r\n                self.header_class.setSortIndicator(self.sort_old[0],\r\n                                                   self.sort_old[1])\r\n            return\r\n        self.sort_old = [index, self.header_class.sortIndicatorOrder()]", "response": "Implement a column sort."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\r\n        if not self.selectedIndexes():\r\n            return\r\n        (row_min, row_max,\r\n         col_min, col_max) = get_idx_rect(self.selectedIndexes())\r\n        index = header = False\r\n        df = self.model().df\r\n        obj = df.iloc[slice(row_min, row_max + 1),\r\n                      slice(col_min, col_max + 1)]\r\n        output = io.StringIO()\r\n        obj.to_csv(output, sep='\\t', index=index, header=header)\r\n        if not PY2:\r\n            contents = output.getvalue()\r\n        else:\r\n            contents = output.getvalue().decode('utf-8')\r\n        output.close()\r\n        clipboard = QApplication.clipboard()\r\n        clipboard.setText(contents)", "response": "Copy text to clipboard"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rowCount(self, index=None):\r\n        if self.axis == 0:\r\n            return max(1, self._shape[0])\r\n        else:\r\n            if self.total_rows <= self.rows_loaded:\r\n                return self.total_rows\r\n            else:\r\n                return self.rows_loaded", "response": "Get the number of rows in the header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef columnCount(self, index=QModelIndex()):\r\n        if self.axis == 0:\r\n            if self.total_cols <= self.cols_loaded:\r\n                return self.total_cols\r\n            else:\r\n                return self.cols_loaded\r\n        else:\r\n            return max(1, self._shape[1])", "response": "Returns the number of columns in the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget more columns or rows or rows based on axis.", "response": "def fetch_more(self, rows=False, columns=False):\r\n        \"\"\"Get more columns or rows (based on axis).\"\"\"\r\n        if  self.axis == 1 and self.total_rows > self.rows_loaded:\r\n            reminder = self.total_rows - self.rows_loaded\r\n            items_to_fetch = min(reminder, ROWS_TO_LOAD)\r\n            self.beginInsertRows(QModelIndex(), self.rows_loaded,\r\n                                 self.rows_loaded + items_to_fetch - 1)\r\n            self.rows_loaded += items_to_fetch\r\n            self.endInsertRows()\r\n        if self.axis == 0 and self.total_cols > self.cols_loaded:\r\n            reminder = self.total_cols - self.cols_loaded\r\n            items_to_fetch = min(reminder, COLS_TO_LOAD)\r\n            self.beginInsertColumns(QModelIndex(), self.cols_loaded,\r\n                                    self.cols_loaded + items_to_fetch - 1)\r\n            self.cols_loaded += items_to_fetch\r\n            self.endInsertColumns()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the information to put in the header.", "response": "def headerData(self, section, orientation, role):\r\n        \"\"\"Get the information to put in the header.\"\"\"\r\n        if role == Qt.TextAlignmentRole:\r\n            if orientation == Qt.Horizontal:\r\n                return Qt.AlignCenter | Qt.AlignBottom\r\n            else:\r\n                return Qt.AlignRight | Qt.AlignVCenter\r\n        if role != Qt.DisplayRole and role != Qt.ToolTipRole:\r\n            return None\r\n        if self.axis == 1 and self._shape[1] <= 1:\r\n            return None\r\n        orient_axis = 0 if orientation == Qt.Horizontal else 1\r\n        if self.model.header_shape[orient_axis] > 1:\r\n            header = section\r\n        else:\r\n            header = self.model.header(self.axis, section)\r\n\r\n            # Don't perform any conversion on strings\r\n            # because it leads to differences between\r\n            # the data present in the dataframe and\r\n            # what is shown by Spyder\r\n            if not is_type_text_string(header):\r\n                header = to_text_string(header)\r\n\r\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the data for the header.", "response": "def data(self, index, role):\r\n        \"\"\"\r\n        Get the data for the header.\r\n\r\n        This is used when a header has levels.\r\n        \"\"\"\r\n        if not index.isValid() or \\\r\n           index.row() >= self._shape[0] or \\\r\n           index.column() >= self._shape[1]:\r\n            return None\r\n        row, col = ((index.row(), index.column()) if self.axis == 0\r\n                    else (index.column(), index.row()))\r\n        if role != Qt.DisplayRole:\r\n            return None\r\n        if self.axis == 0 and self._shape[0] <= 1:\r\n            return None\r\n\r\n        header = self.model.header(self.axis, col, row)\r\n\r\n        # Don't perform any conversion on strings\r\n        # because it leads to differences between\r\n        # the data present in the dataframe and\r\n        # what is shown by Spyder\r\n        if not is_type_text_string(header):\r\n            header = to_text_string(header)\r\n\r\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the header data for the given orientation", "response": "def headerData(self, section, orientation, role):\r\n        \"\"\"\r\n        Get the text to put in the header of the levels of the indexes.\r\n\r\n        By default it returns 'Index i', where i is the section in the index\r\n        \"\"\"\r\n        if role == Qt.TextAlignmentRole:\r\n            if orientation == Qt.Horizontal:\r\n                return Qt.AlignCenter | Qt.AlignBottom\r\n            else:\r\n                return Qt.AlignRight | Qt.AlignVCenter\r\n        if role != Qt.DisplayRole and role != Qt.ToolTipRole:\r\n            return None\r\n        if self.model.header_shape[0] <= 1 and orientation == Qt.Horizontal:\r\n            if self.model.name(1,section):\r\n                return self.model.name(1,section)\r\n            return _('Index')\r\n        elif self.model.header_shape[0] <= 1:\r\n            return None\r\n        elif self.model.header_shape[1] <= 1 and orientation == Qt.Vertical:\r\n            return None\r\n        return _('Index') + ' ' + to_text_string(section)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the data for the highest level of the user.", "response": "def data(self, index, role):\r\n        \"\"\"Get the information of the levels.\"\"\"\r\n        if not index.isValid():\r\n            return None\r\n        if role == Qt.FontRole:\r\n            return self._font\r\n        label = ''\r\n        if index.column() == self.model.header_shape[1] - 1:\r\n            label = str(self.model.name(0, index.row()))\r\n        elif index.row() == self.model.header_shape[0] - 1:\r\n            label = str(self.model.name(1, index.column()))\r\n        if role == Qt.DisplayRole and label:\r\n            return label\r\n        elif role == Qt.ForegroundRole:\r\n            return self._foreground\r\n        elif role == Qt.BackgroundRole:\r\n            return self._background\r\n        elif role == Qt.BackgroundRole:\r\n            return self._palette.window()\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_and_check(self, data, title=''):\r\n        self._selection_rec = False\r\n        self._model = None\r\n\r\n        self.layout = QGridLayout()\r\n        self.layout.setSpacing(0)\r\n        self.layout.setContentsMargins(0, 0, 0, 0)\r\n        self.setLayout(self.layout)\r\n        self.setWindowIcon(ima.icon('arredit'))\r\n        if title:\r\n            title = to_text_string(title) + \" - %s\" % data.__class__.__name__\r\n        else:\r\n            title = _(\"%s editor\") % data.__class__.__name__\r\n        if isinstance(data, Series):\r\n            self.is_series = True\r\n            data = data.to_frame()\r\n        elif isinstance(data, Index):\r\n            data = DataFrame(data)\r\n\r\n        self.setWindowTitle(title)\r\n        self.resize(600, 500)\r\n\r\n        self.hscroll = QScrollBar(Qt.Horizontal)\r\n        self.vscroll = QScrollBar(Qt.Vertical)\r\n\r\n        # Create the view for the level\r\n        self.create_table_level()\r\n\r\n        # Create the view for the horizontal header\r\n        self.create_table_header()\r\n\r\n        # Create the view for the vertical index\r\n        self.create_table_index()\r\n\r\n        # Create the model and view of the data\r\n        self.dataModel = DataFrameModel(data, parent=self)\r\n        self.dataModel.dataChanged.connect(self.save_and_close_enable)\r\n        self.create_data_table()\r\n\r\n        self.layout.addWidget(self.hscroll, 2, 0, 1, 2)\r\n        self.layout.addWidget(self.vscroll, 0, 2, 2, 1)\r\n\r\n        # autosize columns on-demand\r\n        self._autosized_cols = set()\r\n        self._max_autosize_ms = None\r\n        self.dataTable.installEventFilter(self)\r\n\r\n        avg_width = self.fontMetrics().averageCharWidth()\r\n        self.min_trunc = avg_width * 12  # Minimum size for columns\r\n        self.max_width = avg_width * 64  # Maximum size for columns\r\n\r\n        self.setLayout(self.layout)\r\n        self.setMinimumSize(400, 300)\r\n        # Make the dialog act as a window\r\n        self.setWindowFlags(Qt.Window)\r\n        btn_layout = QHBoxLayout()\r\n\r\n        btn = QPushButton(_(\"Format\"))\r\n        # disable format button for int type\r\n        btn_layout.addWidget(btn)\r\n        btn.clicked.connect(self.change_format)\r\n        btn = QPushButton(_('Resize'))\r\n        btn_layout.addWidget(btn)\r\n        btn.clicked.connect(self.resize_to_contents)\r\n\r\n        bgcolor = QCheckBox(_('Background color'))\r\n        bgcolor.setChecked(self.dataModel.bgcolor_enabled)\r\n        bgcolor.setEnabled(self.dataModel.bgcolor_enabled)\r\n        bgcolor.stateChanged.connect(self.change_bgcolor_enable)\r\n        btn_layout.addWidget(bgcolor)\r\n\r\n        self.bgcolor_global = QCheckBox(_('Column min/max'))\r\n        self.bgcolor_global.setChecked(self.dataModel.colum_avg_enabled)\r\n        self.bgcolor_global.setEnabled(not self.is_series and\r\n                                       self.dataModel.bgcolor_enabled)\r\n        self.bgcolor_global.stateChanged.connect(self.dataModel.colum_avg)\r\n        btn_layout.addWidget(self.bgcolor_global)\r\n\r\n        btn_layout.addStretch()\r\n\r\n        self.btn_save_and_close = QPushButton(_('Save and Close'))\r\n        self.btn_save_and_close.setDisabled(True)\r\n        self.btn_save_and_close.clicked.connect(self.accept)\r\n        btn_layout.addWidget(self.btn_save_and_close)\r\n\r\n        self.btn_close = QPushButton(_('Close'))\r\n        self.btn_close.setAutoDefault(True)\r\n        self.btn_close.setDefault(True)\r\n        self.btn_close.clicked.connect(self.reject)\r\n        btn_layout.addWidget(self.btn_close)\r\n\r\n        btn_layout.setContentsMargins(4, 4, 4, 4)\r\n        self.layout.addLayout(btn_layout, 4, 0, 1, 2)\r\n        self.setModel(self.dataModel)\r\n        self.resizeColumnsToContents()\r\n\r\n        return True", "response": "Setup DataFrameEditor and check if data is supported"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_and_close_enable(self, top_left, bottom_right):\r\n        self.btn_save_and_close.setEnabled(True)\r\n        self.btn_save_and_close.setAutoDefault(True)\r\n        self.btn_save_and_close.setDefault(True)", "response": "Handle the data change event to enable the save and close button."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_table_level(self):\r\n        self.table_level = QTableView()\r\n        self.table_level.setEditTriggers(QTableWidget.NoEditTriggers)\r\n        self.table_level.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_level.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_level.setFrameStyle(QFrame.Plain)\r\n        self.table_level.horizontalHeader().sectionResized.connect(\r\n                                                        self._index_resized)\r\n        self.table_level.verticalHeader().sectionResized.connect(\r\n                                                        self._header_resized)\r\n        self.table_level.setItemDelegate(QItemDelegate())\r\n        self.layout.addWidget(self.table_level, 0, 0)\r\n        self.table_level.setContentsMargins(0, 0, 0, 0)\r\n        self.table_level.horizontalHeader().sectionClicked.connect(\r\n                                                            self.sortByIndex)", "response": "Create the table level that will hold the level model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_table_header(self):\r\n        self.table_header = QTableView()\r\n        self.table_header.verticalHeader().hide()\r\n        self.table_header.setEditTriggers(QTableWidget.NoEditTriggers)\r\n        self.table_header.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_header.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_header.setHorizontalScrollMode(QTableView.ScrollPerPixel)\r\n        self.table_header.setHorizontalScrollBar(self.hscroll)\r\n        self.table_header.setFrameStyle(QFrame.Plain)\r\n        self.table_header.horizontalHeader().sectionResized.connect(\r\n                                                        self._column_resized)\r\n        self.table_header.setItemDelegate(QItemDelegate())\r\n        self.layout.addWidget(self.table_header, 0, 1)", "response": "Create the QTableView that will hold the header model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the QTableView that will hold the index model.", "response": "def create_table_index(self):\r\n        \"\"\"Create the QTableView that will hold the index model.\"\"\"\r\n        self.table_index = QTableView()\r\n        self.table_index.horizontalHeader().hide()\r\n        self.table_index.setEditTriggers(QTableWidget.NoEditTriggers)\r\n        self.table_index.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_index.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.table_index.setVerticalScrollMode(QTableView.ScrollPerPixel)\r\n        self.table_index.setVerticalScrollBar(self.vscroll)\r\n        self.table_index.setFrameStyle(QFrame.Plain)\r\n        self.table_index.verticalHeader().sectionResized.connect(\r\n                                                            self._row_resized)\r\n        self.table_index.setItemDelegate(QItemDelegate())\r\n        self.layout.addWidget(self.table_index, 1, 0)\r\n        self.table_index.setContentsMargins(0, 0, 0, 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the QTableView that will hold the data model.", "response": "def create_data_table(self):\r\n        \"\"\"Create the QTableView that will hold the data model.\"\"\"\r\n        self.dataTable = DataFrameView(self, self.dataModel,\r\n                                       self.table_header.horizontalHeader(),\r\n                                       self.hscroll, self.vscroll)\r\n        self.dataTable.verticalHeader().hide()\r\n        self.dataTable.horizontalHeader().hide()\r\n        self.dataTable.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.dataTable.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\r\n        self.dataTable.setHorizontalScrollMode(QTableView.ScrollPerPixel)\r\n        self.dataTable.setVerticalScrollMode(QTableView.ScrollPerPixel)\r\n        self.dataTable.setFrameStyle(QFrame.Plain)\r\n        self.dataTable.setItemDelegate(QItemDelegate())\r\n        self.layout.addWidget(self.dataTable, 1, 1)\r\n        self.setFocusProxy(self.dataTable)\r\n        self.dataTable.sig_sort_by_column.connect(self._sort_update)\r\n        self.dataTable.sig_fetch_more_columns.connect(self._fetch_more_columns)\r\n        self.dataTable.sig_fetch_more_rows.connect(self._fetch_more_rows)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sortByIndex(self, index):\r\n        self.table_level.horizontalHeader().setSortIndicatorShown(True)\r\n        sort_order = self.table_level.horizontalHeader().sortIndicatorOrder()\r\n        self.table_index.model().sort(index, sort_order)\r\n        self._sort_update()", "response": "Implement a Index sort."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _column_resized(self, col, old_width, new_width):\r\n        self.dataTable.setColumnWidth(col, new_width)\r\n        self._update_layout()", "response": "Update the column width."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _row_resized(self, row, old_height, new_height):\r\n        self.dataTable.setRowHeight(row, new_height)\r\n        self._update_layout()", "response": "Update the row height."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _index_resized(self, col, old_width, new_width):\r\n        self.table_index.setColumnWidth(col, new_width)\r\n        self._update_layout()", "response": "Resize the corresponding column of the index section selected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting the model in the given table.", "response": "def _reset_model(self, table, model):\r\n        \"\"\"Set the model in the given table.\"\"\"\r\n        old_sel_model = table.selectionModel()\r\n        table.setModel(model)\r\n        if old_sel_model:\r\n            del old_sel_model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setModel(self, model, relayout=True):\r\n        self._model = model\r\n        sel_model = self.dataTable.selectionModel()\r\n        sel_model.currentColumnChanged.connect(\r\n                self._resizeCurrentColumnToContents)\r\n\r\n        # Asociate the models (level, vertical index and horizontal header)\r\n        # with its corresponding view.\r\n        self._reset_model(self.table_level, DataFrameLevelModel(model,\r\n                                                                self.palette(),\r\n                                                                self.font()))\r\n        self._reset_model(self.table_header, DataFrameHeaderModel(\r\n                                                            model,\r\n                                                            0,\r\n                                                            self.palette()))\r\n        self._reset_model(self.table_index, DataFrameHeaderModel(\r\n                                                            model,\r\n                                                            1,\r\n                                                            self.palette()))\r\n\r\n        # Needs to be called after setting all table models\r\n        if relayout:\r\n            self._update_layout()", "response": "Set the model for the data header index and level views."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eventFilter(self, obj, event):\r\n        if obj == self.dataTable and event.type() == QEvent.Resize:\r\n            self._resizeVisibleColumnsToContents()\r\n        return False", "response": "Override eventFilter to catch resize event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resizeColumnsToContents(self):\r\n        self._autosized_cols = set()\r\n        self._resizeColumnsToContents(self.table_level,\r\n                                      self.table_index, self._max_autosize_ms)\r\n        self._update_layout()", "response": "Resize the columns to its contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_bgcolor_enable(self, state):\r\n        self.dataModel.bgcolor(state)\r\n        self.bgcolor_global.setEnabled(not self.is_series and state > 0)", "response": "Change the bgcolor enable state of the related calendars"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef change_format(self):\r\n        format, valid = QInputDialog.getText(self, _('Format'),\r\n                                             _(\"Float formatting\"),\r\n                                             QLineEdit.Normal,\r\n                                             self.dataModel.get_format())\r\n        if valid:\r\n            format = str(format)\r\n            try:\r\n                format % 1.1\r\n            except:\r\n                msg = _(\"Format ({}) is incorrect\").format(format)\r\n                QMessageBox.critical(self, _(\"Error\"), msg)\r\n                return\r\n            if not format.startswith('%'):\r\n                msg = _(\"Format ({}) should start with '%'\").format(format)\r\n                QMessageBox.critical(self, _(\"Error\"), msg)\r\n                return\r\n            self.dataModel.set_format(format)\r\n            self.sig_option_changed.emit('dataframe_format', format)", "response": "Change the format of the data model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_value(self):\r\n        # It is import to avoid accessing Qt C++ object as it has probably\r\n        # already been destroyed, due to the Qt.WA_DeleteOnClose attribute\r\n        df = self.dataModel.get_data()\r\n        if self.is_series:\r\n            return df.iloc[:, 0]\r\n        else:\r\n            return df", "response": "Return modified Dataframe -- this is *not* a copy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the column width of the header.", "response": "def _update_header_size(self):\r\n        \"\"\"Update the column width of the header.\"\"\"\r\n        column_count = self.table_header.model().columnCount()\r\n        for index in range(0, column_count):\r\n            if index < column_count:\r\n                column_width = self.dataTable.columnWidth(index)\r\n                self.table_header.setColumnWidth(index, column_width)\r\n            else:\r\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup(self, check_all=None, exclude_private=None,\r\n              exclude_uppercase=None, exclude_capitalized=None,\r\n              exclude_unsupported=None, excluded_names=None,\r\n              minmax=None, dataframe_format=None):\r\n        \"\"\"\r\n        Setup the namespace browser with provided settings.\r\n\r\n        Args:\r\n            dataframe_format (string): default floating-point format for \r\n                DataFrame editor\r\n        \"\"\"\r\n        assert self.shellwidget is not None\r\n        \r\n        self.check_all = check_all\r\n        self.exclude_private = exclude_private\r\n        self.exclude_uppercase = exclude_uppercase\r\n        self.exclude_capitalized = exclude_capitalized\r\n        self.exclude_unsupported = exclude_unsupported\r\n        self.excluded_names = excluded_names\r\n        self.minmax = minmax\r\n        self.dataframe_format = dataframe_format\r\n        \r\n        if self.editor is not None:\r\n            self.editor.setup_menu(minmax)\r\n            self.editor.set_dataframe_format(dataframe_format)\r\n            self.exclude_private_action.setChecked(exclude_private)\r\n            self.exclude_uppercase_action.setChecked(exclude_uppercase)\r\n            self.exclude_capitalized_action.setChecked(exclude_capitalized)\r\n            self.exclude_unsupported_action.setChecked(exclude_unsupported)\r\n            self.refresh_table()\r\n            return\r\n\r\n        self.editor = RemoteCollectionsEditorTableView(\r\n                        self,\r\n                        data=None,\r\n                        minmax=minmax,\r\n                        shellwidget=self.shellwidget,\r\n                        dataframe_format=dataframe_format)\r\n\r\n        self.editor.sig_option_changed.connect(self.sig_option_changed.emit)\r\n        self.editor.sig_files_dropped.connect(self.import_data)\r\n        self.editor.sig_free_memory.connect(self.sig_free_memory.emit)\r\n\r\n        self.setup_option_actions(exclude_private, exclude_uppercase,\r\n                                  exclude_capitalized, exclude_unsupported)\r\n\r\n        # Setup toolbar layout.\r\n\r\n        self.tools_layout = QHBoxLayout()\r\n        toolbar = self.setup_toolbar()\r\n        for widget in toolbar:\r\n            self.tools_layout.addWidget(widget)\r\n        self.tools_layout.addStretch()\r\n        self.setup_options_button()\r\n\r\n        # Setup layout.\r\n\r\n        layout = create_plugin_layout(self.tools_layout, self.editor)\r\n        self.setLayout(layout)\r\n\r\n        self.sig_option_changed.connect(self.option_changed)", "response": "Setup the browser with provided settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_option_actions(self, exclude_private, exclude_uppercase,\r\n                             exclude_capitalized, exclude_unsupported):\r\n        \"\"\"Setup the actions to show in the cog menu.\"\"\"\r\n        self.setup_in_progress = True\r\n\r\n        self.exclude_private_action = create_action(self,\r\n                _(\"Exclude private references\"),\r\n                tip=_(\"Exclude references which name starts\"\r\n                            \" with an underscore\"),\r\n                toggled=lambda state:\r\n                self.sig_option_changed.emit('exclude_private', state))\r\n        self.exclude_private_action.setChecked(exclude_private)\r\n        \r\n        self.exclude_uppercase_action = create_action(self,\r\n                _(\"Exclude all-uppercase references\"),\r\n                tip=_(\"Exclude references which name is uppercase\"),\r\n                toggled=lambda state:\r\n                self.sig_option_changed.emit('exclude_uppercase', state))\r\n        self.exclude_uppercase_action.setChecked(exclude_uppercase)\r\n        \r\n        self.exclude_capitalized_action = create_action(self,\r\n                _(\"Exclude capitalized references\"),\r\n                tip=_(\"Exclude references which name starts with an \"\r\n                      \"uppercase character\"),\r\n                toggled=lambda state:\r\n                self.sig_option_changed.emit('exclude_capitalized', state))\r\n        self.exclude_capitalized_action.setChecked(exclude_capitalized)\r\n        \r\n        self.exclude_unsupported_action = create_action(self,\r\n                _(\"Exclude unsupported data types\"),\r\n                tip=_(\"Exclude references to unsupported data types\"\r\n                            \" (i.e. which won't be handled/saved correctly)\"),\r\n                toggled=lambda state:\r\n                self.sig_option_changed.emit('exclude_unsupported', state))\r\n        self.exclude_unsupported_action.setChecked(exclude_unsupported)\r\n\r\n        self.actions = [\r\n            self.exclude_private_action, self.exclude_uppercase_action,\r\n            self.exclude_capitalized_action, self.exclude_unsupported_action]\r\n        if is_module_installed('numpy'):\r\n            self.actions.extend([MENU_SEPARATOR, self.editor.minmax_action])\r\n\r\n        self.setup_in_progress = False", "response": "Setup the actions to show in the cog menu."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_options_button(self):\r\n        if not self.options_button:\r\n            self.options_button = create_toolbutton(\r\n                self, text=_('Options'), icon=ima.icon('tooloptions'))\r\n\r\n            actions = self.actions + [MENU_SEPARATOR] + self.plugin_actions\r\n            self.options_menu = QMenu(self)\r\n            add_actions(self.options_menu, actions)\r\n            self.options_button.setMenu(self.options_menu)\r\n\r\n        if self.tools_layout.itemAt(self.tools_layout.count() - 1) is None:\r\n            self.tools_layout.insertWidget(\r\n                self.tools_layout.count() - 1, self.options_button)\r\n        else:\r\n            self.tools_layout.addWidget(self.options_button)", "response": "Add the cog menu button to the toolbar."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns dict editor view settings", "response": "def get_view_settings(self):\r\n        \"\"\"Return dict editor view settings\"\"\"\r\n        settings = {}\r\n        for name in REMOTE_SETTINGS:\r\n            settings[name] = getattr(self, name)\r\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimports data from text file.", "response": "def import_data(self, filenames=None):\r\n        \"\"\"Import data from text file.\"\"\"\r\n        title = _(\"Import data\")\r\n        if filenames is None:\r\n            if self.filename is None:\r\n                basedir = getcwd_or_home()\r\n            else:\r\n                basedir = osp.dirname(self.filename)\r\n            filenames, _selfilter = getopenfilenames(self, title, basedir,\r\n                                                     iofunctions.load_filters)\r\n            if not filenames:\r\n                return\r\n        elif is_text_string(filenames):\r\n            filenames = [filenames]\r\n\r\n        for filename in filenames:\r\n            self.filename = to_text_string(filename)\r\n            ext = osp.splitext(self.filename)[1].lower()\r\n\r\n            if ext not in iofunctions.load_funcs:\r\n                buttons = QMessageBox.Yes | QMessageBox.Cancel\r\n                answer = QMessageBox.question(self, title,\r\n                            _(\"<b>Unsupported file extension '%s'</b><br><br>\"\r\n                              \"Would you like to import it anyway \"\r\n                              \"(by selecting a known file format)?\"\r\n                              ) % ext, buttons)\r\n                if answer == QMessageBox.Cancel:\r\n                    return\r\n                formats = list(iofunctions.load_extensions.keys())\r\n                item, ok = QInputDialog.getItem(self, title,\r\n                                                _('Open file as:'),\r\n                                                formats, 0, False)\r\n                if ok:\r\n                    ext = iofunctions.load_extensions[to_text_string(item)]\r\n                else:\r\n                    return\r\n\r\n            load_func = iofunctions.load_funcs[ext]\r\n                \r\n            # 'import_wizard' (self.setup_io)\r\n            if is_text_string(load_func):\r\n                # Import data with import wizard\r\n                error_message = None\r\n                try:\r\n                    text, _encoding = encoding.read(self.filename)\r\n                    base_name = osp.basename(self.filename)\r\n                    editor = ImportWizard(self, text, title=base_name,\r\n                                  varname=fix_reference_name(base_name))\r\n                    if editor.exec_():\r\n                        var_name, clip_data = editor.get_data()\r\n                        self.editor.new_value(var_name, clip_data)\r\n                except Exception as error:\r\n                    error_message = str(error)\r\n            else:\r\n                QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))\r\n                QApplication.processEvents()\r\n                error_message = self.shellwidget.load_data(self.filename, ext)\r\n                self.shellwidget._kernel_reply = None\r\n                QApplication.restoreOverrideCursor()\r\n                QApplication.processEvents()\r\n    \r\n            if error_message is not None:\r\n                QMessageBox.critical(self, title,\r\n                                     _(\"<b>Unable to load '%s'</b>\"\r\n                                       \"<br><br>Error message:<br>%s\"\r\n                                       ) % (self.filename, error_message))\r\n            self.refresh_table()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves data to a file.", "response": "def save_data(self, filename=None):\r\n        \"\"\"Save data\"\"\"\r\n        if filename is None:\r\n            filename = self.filename\r\n            if filename is None:\r\n                filename = getcwd_or_home()\r\n            filename, _selfilter = getsavefilename(self, _(\"Save data\"),\r\n                                                   filename,\r\n                                                   iofunctions.save_filters)\r\n            if filename:\r\n                self.filename = filename\r\n            else:\r\n                return False\r\n        QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))\r\n        QApplication.processEvents()\r\n\r\n        error_message = self.shellwidget.save_namespace(self.filename)\r\n        self.shellwidget._kernel_reply = None\r\n\r\n        QApplication.restoreOverrideCursor()\r\n        QApplication.processEvents()\r\n        if error_message is not None:\r\n            if 'Some objects could not be saved:' in error_message:\r\n                save_data_message = (\r\n                    _('<b>Some objects could not be saved:</b>')\r\n                    + '<br><br><code>{obj_list}</code>'.format(\r\n                        obj_list=error_message.split(': ')[1]))\r\n            else:\r\n                save_data_message = _(\r\n                    '<b>Unable to save current workspace</b>'\r\n                    '<br><br>Error message:<br>') + error_message\r\n            QMessageBox.critical(self, _(\"Save data\"), save_data_message)\r\n        self.save_button.setEnabled(self.filename is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid(self):\r\n        for lineedit in self.lineedits:\r\n            if lineedit in self.validate_data and lineedit.isEnabled():\r\n                validator, invalid_msg = self.validate_data[lineedit]\r\n                text = to_text_string(lineedit.text())\r\n                if not validator(text):\r\n                    QMessageBox.critical(self, self.get_name(),\r\n                                     \"%s:<br><b>%s</b>\" % (invalid_msg, text),\r\n                                     QMessageBox.Ok)\r\n                    return False\r\n        return True", "response": "Return True if all contents are valid"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads settings from a configuration file.", "response": "def load_from_conf(self):\r\n        \"\"\"Load settings from configuration file\"\"\"\r\n        for checkbox, (option, default) in list(self.checkboxes.items()):\r\n            checkbox.setChecked(self.get_option(option, default))\r\n            # QAbstractButton works differently for PySide and PyQt\r\n            if not API == 'pyside':\r\n                checkbox.clicked.connect(lambda _foo, opt=option:\r\n                                         self.has_been_modified(opt))\r\n            else:\r\n                checkbox.clicked.connect(lambda opt=option:\r\n                                         self.has_been_modified(opt))\r\n        for radiobutton, (option, default) in list(self.radiobuttons.items()):\r\n            radiobutton.setChecked(self.get_option(option, default))\r\n            radiobutton.toggled.connect(lambda _foo, opt=option:\r\n                                        self.has_been_modified(opt))\r\n            if radiobutton.restart_required:\r\n                self.restart_options[option] = radiobutton.label_text\r\n        for lineedit, (option, default) in list(self.lineedits.items()):\r\n            lineedit.setText(self.get_option(option, default))\r\n            lineedit.textChanged.connect(lambda _foo, opt=option:\r\n                                         self.has_been_modified(opt))\r\n            if lineedit.restart_required:\r\n                self.restart_options[option] = lineedit.label_text\r\n        for textedit, (option, default) in list(self.textedits.items()):\r\n            textedit.setPlainText(self.get_option(option, default))\r\n            textedit.textChanged.connect(lambda opt=option:\r\n                                         self.has_been_modified(opt))\r\n            if textedit.restart_required:\r\n                self.restart_options[option] = textedit.label_text\r\n        for spinbox, (option, default) in list(self.spinboxes.items()):\r\n            spinbox.setValue(self.get_option(option, default))\r\n            spinbox.valueChanged.connect(lambda _foo, opt=option:\r\n                                         self.has_been_modified(opt))\r\n        for combobox, (option, default) in list(self.comboboxes.items()):\r\n            value = self.get_option(option, default)\r\n            for index in range(combobox.count()):\r\n                data = from_qvariant(combobox.itemData(index), to_text_string)\r\n                # For PyQt API v2, it is necessary to convert `data` to\r\n                # unicode in case the original type was not a string, like an\r\n                # integer for example (see qtpy.compat.from_qvariant):\r\n                if to_text_string(data) == to_text_string(value):\r\n                    break\r\n            else:\r\n                if combobox.count() == 0:\r\n                    index = None\r\n            if index:\r\n                combobox.setCurrentIndex(index)\r\n            combobox.currentIndexChanged.connect(lambda _foo, opt=option:\r\n                                                 self.has_been_modified(opt))\r\n            if combobox.restart_required:\r\n                self.restart_options[option] = combobox.label_text\r\n\r\n        for (fontbox, sizebox), option in list(self.fontboxes.items()):\r\n            font = self.get_font(option)\r\n            fontbox.setCurrentFont(font)\r\n            sizebox.setValue(font.pointSize())\r\n            if option is None:\r\n                property = 'plugin_font'\r\n            else:\r\n                property = option\r\n            fontbox.currentIndexChanged.connect(lambda _foo, opt=property:\r\n                                                self.has_been_modified(opt))\r\n            sizebox.valueChanged.connect(lambda _foo, opt=property:\r\n                                         self.has_been_modified(opt))\r\n        for clayout, (option, default) in list(self.coloredits.items()):\r\n            property = to_qvariant(option)\r\n            edit = clayout.lineedit\r\n            btn = clayout.colorbtn\r\n            edit.setText(self.get_option(option, default))\r\n            # QAbstractButton works differently for PySide and PyQt\r\n            if not API == 'pyside':\r\n                btn.clicked.connect(lambda _foo, opt=option:\r\n                                    self.has_been_modified(opt))\r\n            else:\r\n                btn.clicked.connect(lambda opt=option:\r\n                                    self.has_been_modified(opt))\r\n            edit.textChanged.connect(lambda _foo, opt=option:\r\n                                     self.has_been_modified(opt))\r\n        for (clayout, cb_bold, cb_italic\r\n             ), (option, default) in list(self.scedits.items()):\r\n            edit = clayout.lineedit\r\n            btn = clayout.colorbtn\r\n            color, bold, italic = self.get_option(option, default)\r\n            edit.setText(color)\r\n            cb_bold.setChecked(bold)\r\n            cb_italic.setChecked(italic)\r\n            edit.textChanged.connect(lambda _foo, opt=option:\r\n                                     self.has_been_modified(opt))\r\n            # QAbstractButton works differently for PySide and PyQt\r\n            if not API == 'pyside':\r\n                btn.clicked.connect(lambda _foo, opt=option:\r\n                                    self.has_been_modified(opt))\r\n                cb_bold.clicked.connect(lambda _foo, opt=option:\r\n                                        self.has_been_modified(opt))\r\n                cb_italic.clicked.connect(lambda _foo, opt=option:\r\n                                          self.has_been_modified(opt))\r\n            else:\r\n                btn.clicked.connect(lambda opt=option:\r\n                                    self.has_been_modified(opt))\r\n                cb_bold.clicked.connect(lambda opt=option:\r\n                                        self.has_been_modified(opt))\r\n                cb_italic.clicked.connect(lambda opt=option:\r\n                                          self.has_been_modified(opt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves settings to configuration file", "response": "def save_to_conf(self):\r\n        \"\"\"Save settings to configuration file\"\"\"\r\n        for checkbox, (option, _default) in list(self.checkboxes.items()):\r\n            self.set_option(option, checkbox.isChecked())\r\n        for radiobutton, (option, _default) in list(self.radiobuttons.items()):\r\n            self.set_option(option, radiobutton.isChecked())\r\n        for lineedit, (option, _default) in list(self.lineedits.items()):\r\n            self.set_option(option, to_text_string(lineedit.text()))\r\n        for textedit, (option, _default) in list(self.textedits.items()):\r\n            self.set_option(option, to_text_string(textedit.toPlainText()))\r\n        for spinbox, (option, _default) in list(self.spinboxes.items()):\r\n            self.set_option(option, spinbox.value())\r\n        for combobox, (option, _default) in list(self.comboboxes.items()):\r\n            data = combobox.itemData(combobox.currentIndex())\r\n            self.set_option(option, from_qvariant(data, to_text_string))\r\n        for (fontbox, sizebox), option in list(self.fontboxes.items()):\r\n            font = fontbox.currentFont()\r\n            font.setPointSize(sizebox.value())\r\n            self.set_font(font, option)\r\n        for clayout, (option, _default) in list(self.coloredits.items()):\r\n            self.set_option(option, to_text_string(clayout.lineedit.text()))\r\n        for (clayout, cb_bold, cb_italic), (option, _default) in list(self.scedits.items()):\r\n            color = to_text_string(clayout.lineedit.text())\r\n            bold = cb_bold.isChecked()\r\n            italic = cb_italic.isChecked()\r\n            self.set_option(option, (color, bold, italic))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting a directory in the user s home directory.", "response": "def select_directory(self, edit):\r\n        \"\"\"Select directory\"\"\"\r\n        basedir = to_text_string(edit.text())\r\n        if not osp.isdir(basedir):\r\n            basedir = getcwd_or_home()\r\n        title = _(\"Select directory\")\r\n        directory = getexistingdirectory(self, title, basedir)\r\n        if directory:\r\n            edit.setText(directory)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_file(self, edit, filters=None):\r\n        basedir = osp.dirname(to_text_string(edit.text()))\r\n        if not osp.isdir(basedir):\r\n            basedir = getcwd_or_home()\r\n        if filters is None:\r\n            filters = _(\"All files (*)\")\r\n        title = _(\"Select file\")\r\n        filename, _selfilter = getopenfilename(self, title, basedir, filters)\r\n        if filename:\r\n            edit.setText(filename)", "response": "Select a file from the list of items in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a combobox with the given text and choices and option.", "response": "def create_combobox(self, text, choices, option, default=NoDefault,\r\n                        tip=None, restart=False):\r\n        \"\"\"choices: couples (name, key)\"\"\"\r\n        label = QLabel(text)\r\n        combobox = QComboBox()\r\n        if tip is not None:\r\n            combobox.setToolTip(tip)\r\n        for name, key in choices:\r\n            if not (name is None and key is None):\r\n                combobox.addItem(name, to_qvariant(key))\r\n        # Insert separators\r\n        count = 0\r\n        for index, item in enumerate(choices):\r\n            name, key = item\r\n            if name is None and key is None:\r\n                combobox.insertSeparator(index + count)\r\n                count += 1\r\n        self.comboboxes[combobox] = (option, default)\r\n        layout = QHBoxLayout()\r\n        layout.addWidget(label)\r\n        layout.addWidget(combobox)\r\n        layout.addStretch(1)\r\n        layout.setContentsMargins(0, 0, 0, 0)\r\n        widget = QWidget(self)\r\n        widget.label = label\r\n        widget.combobox = combobox\r\n        widget.setLayout(layout)\r\n        combobox.restart_required = restart\r\n        combobox.label_text = text\r\n        return widget"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_file_combobox(self, text, choices, option, default=NoDefault,\r\n                             tip=None, restart=False, filters=None,\r\n                             adjust_to_contents=False,\r\n                             default_line_edit=False):\r\n        \"\"\"choices: couples (name, key)\"\"\"\r\n        combobox = FileComboBox(self, adjust_to_contents=adjust_to_contents,\r\n                                default_line_edit=default_line_edit)\r\n        combobox.restart_required = restart\r\n        combobox.label_text = text\r\n        edit = combobox.lineEdit()\r\n        edit.label_text = text\r\n        edit.restart_required = restart\r\n        self.lineedits[edit] = (option, default)\r\n\r\n        if tip is not None:\r\n            combobox.setToolTip(tip)\r\n        combobox.addItems(choices)\r\n\r\n        msg = _('Invalid file path')\r\n        self.validate_data[edit] = (osp.isfile, msg)\r\n        browse_btn = QPushButton(ima.icon('FileIcon'), '', self)\r\n        browse_btn.setToolTip(_(\"Select file\"))\r\n        browse_btn.clicked.connect(lambda: self.select_file(edit, filters))\r\n\r\n        layout = QGridLayout()\r\n        layout.addWidget(combobox, 0, 0, 0, 9)\r\n        layout.addWidget(browse_btn, 0, 10)\r\n        layout.setContentsMargins(0, 0, 0, 0)\r\n        widget = QWidget(self)\r\n        widget.combobox = combobox\r\n        widget.browse_btn = browse_btn\r\n        widget.setLayout(layout)\r\n\r\n        return widget", "response": "Create a new file combobox with the given text and choices."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_fontgroup(self, option=None, text=None, title=None,\r\n                         tip=None, fontfilters=None, without_group=False):\r\n        \"\"\"Option=None -> setting plugin font\"\"\"\r\n\r\n        if title:\r\n            fontlabel = QLabel(title)\r\n        else:\r\n            fontlabel = QLabel(_(\"Font\"))\r\n        fontbox = QFontComboBox()\r\n\r\n        if fontfilters is not None:\r\n            fontbox.setFontFilters(fontfilters)\r\n\r\n        sizelabel = QLabel(\"  \"+_(\"Size\"))\r\n        sizebox = QSpinBox()\r\n        sizebox.setRange(7, 100)\r\n        self.fontboxes[(fontbox, sizebox)] = option\r\n        layout = QHBoxLayout()\r\n\r\n        for subwidget in (fontlabel, fontbox, sizelabel, sizebox):\r\n            layout.addWidget(subwidget)\r\n        layout.addStretch(1)\r\n\r\n        widget = QWidget(self)\r\n        widget.fontlabel = fontlabel\r\n        widget.sizelabel = sizelabel        \r\n        widget.fontbox = fontbox\r\n        widget.sizebox = sizebox\r\n        widget.setLayout(layout)\r\n\r\n        if not without_group:\r\n            if text is None:\r\n                text = _(\"Font style\")\r\n\r\n            group = QGroupBox(text)\r\n            group.setLayout(layout)\r\n\r\n            if tip is not None:\r\n                group.setToolTip(tip)\r\n\r\n            return group\r\n        else:\r\n            return widget", "response": "Create a font group with the given options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate simple tab page", "response": "def create_tab(self, *widgets):\r\n        \"\"\"Create simple tab widget page: widgets added in a vertical layout\"\"\"\r\n        widget = QWidget()\r\n        layout = QVBoxLayout()\r\n        for widg in widgets:\r\n            layout.addWidget(widg)\r\n        layout.addStretch(1)\r\n        widget.setLayout(layout)\r\n        return widget"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prompt_restart_required(self):\r\n        restart_opts = self.restart_options\r\n        changed_opts = self.changed_options\r\n        options = [restart_opts[o] for o in changed_opts if o in restart_opts]\r\n\r\n        if len(options) == 1:\r\n            msg_start = _(\"Spyder needs to restart to change the following \"\r\n                          \"setting:\")\r\n        else:\r\n            msg_start = _(\"Spyder needs to restart to change the following \"\r\n                          \"settings:\")\r\n        msg_end = _(\"Do you wish to restart now?\")\r\n\r\n        msg_options = u\"\"\r\n        for option in options:\r\n            msg_options += u\"<li>{0}</li>\".format(option)\r\n\r\n        msg_title = _(\"Information\")\r\n        msg = u\"{0}<ul>{1}</ul><br>{2}\".format(msg_start, msg_options, msg_end)\r\n        answer = QMessageBox.information(self, msg_title, msg,\r\n                                         QMessageBox.Yes | QMessageBox.No)\r\n        if answer == QMessageBox.Yes:\r\n            self.restart()", "response": "Prompt the user with a request to restart."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the custom defined stylesheet.", "response": "def _refresh(self):\n        \"\"\"After an application style change, the paintEvent updates the\n        custom defined stylesheet.\n        \"\"\"\n        padding = self.height()\n        css_base = \"\"\"QLineEdit {{\n                                 border: none;\n                                 padding-right: {padding}px;\n                                 }}\n                   \"\"\"\n        css_oxygen = \"\"\"QLineEdit {{background: transparent;\n                                   border: none;\n                                   padding-right: {padding}px;\n                                   }}\n                     \"\"\"\n        if self._application_style == 'oxygen':\n            css_template = css_oxygen\n        else:\n            css_template = css_base\n\n        css = css_template.format(padding=padding)\n        self.setStyleSheet(css)\n        self.update()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the status and set_status to update the icons to display.", "response": "def update_status(self, value, value_set):\n        \"\"\"Update the status and set_status to update the icons to display.\"\"\"\n        self._status = value\n        self._status_set = value_set\n        self.repaint()\n        self.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef paintEvent(self, event):\n        super(IconLineEdit, self).paintEvent(event)\n        painter = QPainter(self)\n\n        rect = self.geometry()\n        space = int((rect.height())/6)\n        h = rect.height() - space\n        w = rect.width() - h\n\n        if self._icon_visible:\n            if self._status and self._status_set:\n                pixmap = self._set_icon.pixmap(h, h)\n            elif self._status:\n                pixmap = self._valid_icon.pixmap(h, h)\n            else:\n                pixmap = self._invalid_icon.pixmap(h, h)\n\n            painter.drawPixmap(w, space, pixmap)\n\n        application_style = QApplication.style().objectName()\n        if self._application_style != application_style:\n            self._application_style = application_style\n            self._refresh()\n\n        # Small hack to gurantee correct padding on Spyder start\n        if self._paint_count < 5:\n            self._paint_count += 1\n            self._refresh()", "response": "Override. paintEvent to include a validation icon to the left of the line edit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_plugin(self):\r\n        self.main.restore_scrollbar_position.connect(\r\n                                               self.restore_scrollbar_position)\r\n        self.main.add_dockwidget(self)", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nemit the explorer is_visible signal if enable is True", "response": "def visibility_changed(self, enable):\r\n        \"\"\"DockWidget visibility has changed\"\"\"\r\n        super(SpyderPluginWidget, self).visibility_changed(enable)\r\n        if enable:\r\n            self.explorer.is_visible.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore_scrollbar_position(self):\r\n        scrollbar_pos = self.get_option('scrollbar_position', None)\r\n        if scrollbar_pos is not None:\r\n            self.explorer.treewidget.set_scrollbar_position(scrollbar_pos)", "response": "Restoring scrollbar position after main window is visible"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving configuration of the current window to the file system.", "response": "def save_config(self):\r\n        \"\"\"Save configuration: tree widget state\"\"\"\r\n        for option, value in list(self.explorer.get_options().items()):\r\n            self.set_option(option, value)\r\n        self.set_option('expanded_state',\r\n                        self.explorer.treewidget.get_expanded_state())\r\n        self.set_option('scrollbar_position',\r\n                        self.explorer.treewidget.get_scrollbar_position())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config(self):\r\n        expanded_state = self.get_option('expanded_state', None)\r\n        # Sometimes the expanded state option may be truncated in .ini file\r\n        # (for an unknown reason), in this case it would be converted to a\r\n        # string by 'userconfig':\r\n        if is_text_string(expanded_state):\r\n            expanded_state = None\r\n        if expanded_state is not None:\r\n            self.explorer.treewidget.set_expanded_state(expanded_state)", "response": "Load configuration from file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndoubling - click event", "response": "def activated(self, item):\r\n        \"\"\"Double-click event\"\"\"\r\n        data = self.data.get(id(item))\r\n        if data is not None:\r\n            fname, lineno = data\r\n            self.sig_edit_goto.emit(fname, lineno, '')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_obsolete_items(self):\r\n        self.rdata = [(filename, data) for filename, data in self.rdata\r\n                      if is_module_or_package(filename)]", "response": "Removes obsolete items from the data list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if an update is available.", "response": "def check_update_available(self):\n        \"\"\"Checks if there is an update available.\n\n        It takes as parameters the current version of Spyder and a list of\n        valid cleaned releases in chronological order.\n        Example: ['2.3.2', '2.3.3' ...] or with github ['2.3.4', '2.3.3' ...]\n        \"\"\"\n        # Don't perform any check for development versions\n        if 'dev' in self.version:\n            return (False, latest_release)\n\n        # Filter releases\n        if is_stable_version(self.version):\n            releases = [r for r in self.releases if is_stable_version(r)]\n        else:\n            releases = [r for r in self.releases\n                        if not is_stable_version(r) or r in self.version]\n\n        latest_release = releases[-1]\n\n        return (check_version(self.version, latest_release, '<'),\n                latest_release)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        if is_anaconda():\n            self.url = 'https://repo.anaconda.com/pkgs/main'\n            if os.name == 'nt':\n                self.url += '/win-64/repodata.json'\n            elif sys.platform == 'darwin':\n                self.url += '/osx-64/repodata.json'\n            else:\n                self.url += '/linux-64/repodata.json'\n        else:\n            self.url = ('https://api.github.com/repos/'\n                        'spyder-ide/spyder/releases')\n        self.update_available = False\n        self.latest_release = __version__\n\n        error_msg = None\n\n        try:\n            if hasattr(ssl, '_create_unverified_context'):\n                # Fix for issue # 2685 [Works only with Python >=2.7.9]\n                # More info: https://www.python.org/dev/peps/pep-0476/#opting-out\n                context = ssl._create_unverified_context()\n                page = urlopen(self.url, context=context)\n            else:\n                page = urlopen(self.url)\n            try:\n                data = page.read()\n\n                # Needed step for python3 compatibility\n                if not is_text_string(data):\n                    data = data.decode()\n                data = json.loads(data)\n\n                if is_anaconda():\n                    if self.releases is None:\n                        self.releases = []\n                        for item in data['packages']:\n                            if ('spyder' in item and\n                                    not re.search(r'spyder-[a-zA-Z]', item)):\n                                self.releases.append(item.split('-')[1])\n                    result = self.check_update_available()\n                else:\n                    if self.releases is None:\n                        self.releases = [item['tag_name'].replace('v', '')\n                                         for item in data]\n                        self.releases = list(reversed(self.releases))\n\n                result = self.check_update_available()\n                self.update_available, self.latest_release = result\n            except Exception:\n                error_msg = _('Unable to retrieve information.')\n        except HTTPError:\n            error_msg = _('Unable to retrieve information.')\n        except URLError:\n            error_msg = _('Unable to connect to the internet. <br><br>Make '\n                          'sure the connection is working properly.')\n        except Exception:\n            error_msg = _('Unable to check for updates.')\n\n        # Don't show dialog when starting up spyder and an error occur\n        if not (self.startup and error_msg is not None):\n            self.error = error_msg\n            self.sig_ready.emit()", "response": "Main method of the WorkerUpdates worker"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate shortcuts for this widget", "response": "def create_shortcuts(self, parent):\r\n        \"\"\"Create shortcuts for this widget\"\"\"\r\n        # Configurable\r\n        findnext = config_shortcut(self.find_next, context='_',\r\n                                   name='Find next', parent=parent)\r\n        findprev = config_shortcut(self.find_previous, context='_',\r\n                                   name='Find previous', parent=parent)\r\n        togglefind = config_shortcut(self.show, context='_',\r\n                                     name='Find text', parent=parent)\r\n        togglereplace = config_shortcut(self.show_replace,\r\n                                        context='_', name='Replace text',\r\n                                        parent=parent)\r\n        hide = config_shortcut(self.hide, context='_', name='hide find and replace',\r\n                               parent=self)\r\n\r\n        return [findnext, findprev, togglefind, togglereplace, hide]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef toggle_highlighting(self, state):\r\n        if self.editor is not None:\r\n            if state:\r\n                self.highlight_matches()\r\n            else:\r\n                self.clear_matches()", "response": "Toggle the highlight all results feature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride Qt Method show", "response": "def show(self, hide_replace=True):\r\n        \"\"\"Overrides Qt Method\"\"\"\r\n        QWidget.show(self)\r\n        self.visibility_changed.emit(True)\r\n        self.change_number_matches()\r\n        if self.editor is not None:\r\n            if hide_replace:\r\n                if self.replace_widgets[0].isVisible():\r\n                    self.hide_replace()\r\n            text = self.editor.get_selected_text()\r\n            # When selecting several lines, and replace box is activated the\r\n            # text won't be replaced for the selection\r\n            if hide_replace or len(text.splitlines())<=1:\r\n                highlighted = True\r\n                # If no text is highlighted for search, use whatever word is\r\n                # under the cursor\r\n                if not text:\r\n                    highlighted = False\r\n                    try:\r\n                        cursor = self.editor.textCursor()\r\n                        cursor.select(QTextCursor.WordUnderCursor)\r\n                        text = to_text_string(cursor.selectedText())\r\n                    except AttributeError:\r\n                        # We can't do this for all widgets, e.g. WebView's\r\n                        pass\r\n    \r\n                # Now that text value is sorted out, use it for the search\r\n                if text and not self.search_text.currentText() or highlighted:\r\n                    self.search_text.setEditText(text)\r\n                    self.search_text.lineEdit().selectAll()\r\n                    self.refresh()\r\n                else:\r\n                    self.search_text.lineEdit().selectAll()\r\n            self.search_text.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hide(self):\r\n        for widget in self.replace_widgets:\r\n            widget.hide()\r\n        QWidget.hide(self)\r\n        self.visibility_changed.emit(False)\r\n        if self.editor is not None:\r\n            self.editor.setFocus()\r\n            self.clear_matches()", "response": "Overrides Qt Method hide"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrefreshes the list of items in the current tab.", "response": "def refresh(self):\r\n        \"\"\"Refresh widget\"\"\"\r\n        if self.isHidden():\r\n            if self.editor is not None:\r\n                self.clear_matches()\r\n            return\r\n        state = self.editor is not None\r\n        for widget in self.widgets:\r\n            widget.setEnabled(state)\r\n        if state:\r\n            self.find()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_editor(self, editor, refresh=True):\r\n        self.editor = editor\r\n        # Note: This is necessary to test widgets/editor.py\r\n        # in Qt builds that don't have web widgets\r\n        try:\r\n            from qtpy.QtWebEngineWidgets import QWebEngineView\r\n        except ImportError:\r\n            QWebEngineView = type(None)\r\n        self.words_button.setVisible(not isinstance(editor, QWebEngineView))\r\n        self.re_button.setVisible(not isinstance(editor, QWebEngineView))\r\n        from spyder.plugins.editor.widgets.codeeditor import CodeEditor\r\n        self.is_code_editor = isinstance(editor, CodeEditor)\r\n        self.highlight_button.setVisible(self.is_code_editor)\r\n        if refresh:\r\n            self.refresh()\r\n        if self.isHidden() and editor is not None:\r\n            self.clear_matches()", "response": "Sets the associated editor for this text entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind text has been edited", "response": "def text_has_been_edited(self, text):\r\n        \"\"\"Find text has been edited (this slot won't be triggered when \r\n        setting the search pattern combo box text programmatically)\"\"\"\r\n        self.find(changed=True, forward=True, start_highlight_timer=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, changed=True, forward=True,\r\n             rehighlight=True, start_highlight_timer=False, multiline_replace_check=True):\r\n        \"\"\"Call the find function\"\"\"\r\n        # When several lines are selected in the editor and replace box is activated, \r\n        # dynamic search is deactivated to prevent changing the selection. Otherwise\r\n        # we show matching items.\r\n        if multiline_replace_check and self.replace_widgets[0].isVisible() and \\\r\n           len(to_text_string(self.editor.get_selected_text()).splitlines())>1:\r\n            return None\r\n        text = self.search_text.currentText()\r\n        if len(text) == 0:\r\n            self.search_text.lineEdit().setStyleSheet(\"\")\r\n            if not self.is_code_editor:\r\n                # Clears the selection for WebEngine\r\n                self.editor.find_text('')\r\n            self.change_number_matches()\r\n            return None\r\n        else:\r\n            case = self.case_button.isChecked()\r\n            words = self.words_button.isChecked()\r\n            regexp = self.re_button.isChecked()\r\n            found = self.editor.find_text(text, changed, forward, case=case,\r\n                                          words=words, regexp=regexp)\r\n\r\n            stylesheet = self.STYLE[found]\r\n            tooltip = self.TOOLTIP[found]\r\n            if not found and regexp:\r\n                error_msg = regexp_error_msg(text)\r\n                if error_msg:  # special styling for regexp errors\r\n                    stylesheet = self.STYLE['regexp_error']\r\n                    tooltip = self.TOOLTIP['regexp_error'] + ': ' + error_msg\r\n            self.search_text.lineEdit().setStyleSheet(stylesheet)\r\n            self.search_text.setToolTip(tooltip)\r\n\r\n            if self.is_code_editor and found:\r\n                block = self.editor.textCursor().block()\r\n                TextHelper(self.editor).unfold_if_colapsed(block)\r\n\r\n                if rehighlight or not self.editor.found_results:\r\n                    self.highlight_timer.stop()\r\n                    if start_highlight_timer:\r\n                        self.highlight_timer.start()\r\n                    else:\r\n                        self.highlight_matches()\r\n            else:\r\n                self.clear_matches()\r\n\r\n            number_matches = self.editor.get_number_matches(text, case=case,\r\n                                                            regexp=regexp)\r\n            if hasattr(self.editor, 'get_match_number'):\r\n                match_number = self.editor.get_match_number(text, case=case,\r\n                                                            regexp=regexp)\r\n            else:\r\n                match_number = 0\r\n            self.change_number_matches(current_match=match_number,\r\n                                       total_matches=number_matches)\r\n            return found", "response": "Find the next item in the search text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace and find in the current selection", "response": "def replace_find_selection(self, focus_replace_text=False):\r\n        \"\"\"Replace and find in the current selection\"\"\"\r\n        if self.editor is not None:\r\n            replace_text = to_text_string(self.replace_text.currentText())\r\n            search_text = to_text_string(self.search_text.currentText())\r\n            case = self.case_button.isChecked()\r\n            words = self.words_button.isChecked()\r\n            re_flags = re.MULTILINE if case else re.IGNORECASE|re.MULTILINE\r\n\r\n            re_pattern = None\r\n            if self.re_button.isChecked():\r\n                pattern = search_text\r\n            else:\r\n                pattern = re.escape(search_text)\r\n                replace_text = re.escape(replace_text)\r\n            if words:  # match whole words only\r\n                pattern = r'\\b{pattern}\\b'.format(pattern=pattern)\r\n\r\n            # Check regexp before proceeding\r\n            try:\r\n                re_pattern = re.compile(pattern, flags=re_flags)\r\n                # Check if replace_text can be substituted in re_pattern\r\n                # Fixes issue #7177\r\n                re_pattern.sub(replace_text, '')\r\n            except re.error as e:\r\n                # Do nothing with an invalid regexp\r\n                return\r\n\r\n            selected_text = to_text_string(self.editor.get_selected_text())\r\n            replacement = re_pattern.sub(replace_text, selected_text)\r\n            if replacement != selected_text:\r\n                cursor = self.editor.textCursor()\r\n                cursor.beginEditBlock()\r\n                cursor.removeSelectedText()\r\n                if not self.re_button.isChecked():\r\n                    replacement = re.sub(r'\\\\(?![nrtf])(.)', r'\\1', replacement)\r\n                cursor.insertText(replacement)\r\n                cursor.endEditBlock()\r\n            if focus_replace_text:\r\n                self.replace_text.setFocus()\r\n            else:\r\n                self.editor.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange number of match and total matches.", "response": "def change_number_matches(self, current_match=0, total_matches=0):\r\n        \"\"\"Change number of match and total matches.\"\"\"\r\n        if current_match and total_matches:\r\n            matches_string = u\"{} {} {}\".format(current_match, _(u\"of\"),\r\n                                               total_matches)\r\n            self.number_matches_text.setText(matches_string)\r\n        elif total_matches:\r\n            matches_string = u\"{} {}\".format(total_matches, _(u\"matches\"))\r\n            self.number_matches_text.setText(matches_string)\r\n        else:\r\n            self.number_matches_text.setText(_(u\"no matches\"))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmonkeying patching rope. base. project. Project and pycore. PyCore for compatibility with py2exe and cx_Freeze.", "response": "def apply():\r\n    \"\"\"Monkey patching rope\r\n\r\n    See [1], [2], [3], [4] and [5] in module docstring.\"\"\"\r\n    from spyder.utils.programs import is_module_installed\r\n    if is_module_installed('rope', '<0.9.4'):\r\n        import rope\r\n        raise ImportError(\"rope %s can't be patched\" % rope.VERSION)\r\n\r\n    # [1] Patching project.Project for compatibility with py2exe/cx_Freeze\r\n    #     distributions\r\n    from spyder.config.base import is_py2exe_or_cx_Freeze\r\n    if is_py2exe_or_cx_Freeze():\r\n        from rope.base import project\r\n        class PatchedProject(project.Project):\r\n            def _default_config(self):\r\n                # py2exe/cx_Freeze distribution\r\n                from spyder.config.base import get_module_source_path\r\n                fname = get_module_source_path('spyder',\r\n                                               'default_config.py')\r\n                return open(fname, 'rb').read()\r\n        project.Project = PatchedProject\r\n    \r\n    # Patching pycore.PyCore...\r\n    from rope.base import pycore\r\n    class PatchedPyCore(pycore.PyCore):\r\n        # [2] ...so that forced builtin modules (i.e. modules that were \r\n        # declared as 'extension_modules' in rope preferences) will be indeed\r\n        # recognized as builtins by rope, as expected\r\n        # \r\n        # This patch is included in rope 0.9.4+ but applying it anyway is ok\r\n        def get_module(self, name, folder=None):\r\n            \"\"\"Returns a `PyObject` if the module was found.\"\"\"\r\n            # check if this is a builtin module\r\n            pymod = self._builtin_module(name)\r\n            if pymod is not None:\r\n                return pymod\r\n            module = self.find_module(name, folder)\r\n            if module is None:\r\n                raise pycore.ModuleNotFoundError(\r\n                                            'Module %s not found' % name)\r\n            return self.resource_to_pyobject(module)\r\n        # [3] ...to avoid considering folders without __init__.py as Python\r\n        # packages\r\n        def _find_module_in_folder(self, folder, modname):\r\n            module = folder\r\n            packages = modname.split('.')\r\n            for pkg in packages[:-1]:\r\n                if  module.is_folder() and module.has_child(pkg):\r\n                    module = module.get_child(pkg)\r\n                else:\r\n                    return None\r\n            if module.is_folder():\r\n                if module.has_child(packages[-1]) and \\\r\n                   module.get_child(packages[-1]).is_folder() and \\\r\n                   module.get_child(packages[-1]).has_child('__init__.py'):\r\n                    return module.get_child(packages[-1])\r\n                elif module.has_child(packages[-1] + '.py') and \\\r\n                     not module.get_child(packages[-1] + '.py').is_folder():\r\n                    return module.get_child(packages[-1] + '.py')\r\n    pycore.PyCore = PatchedPyCore\r\n\r\n    # [2] Patching BuiltinName for the go to definition feature to simply work \r\n    # with forced builtins\r\n    from rope.base import builtins, libutils, pyobjects\r\n    import inspect\r\n    import os.path as osp\r\n    class PatchedBuiltinName(builtins.BuiltinName):\r\n        def _pycore(self):\r\n            p = self.pyobject\r\n            while p.parent is not None:\r\n                p = p.parent\r\n            if isinstance(p, builtins.BuiltinModule) and p.pycore is not None:\r\n                return p.pycore\r\n        def get_definition_location(self):\r\n            if not inspect.isbuiltin(self.pyobject):\r\n                _lines, lineno = inspect.getsourcelines(self.pyobject.builtin)\r\n                path = inspect.getfile(self.pyobject.builtin)\r\n                if path.endswith('pyc') and osp.isfile(path[:-1]):\r\n                    path = path[:-1]\r\n                pycore = self._pycore()\r\n                if pycore and pycore.project:\r\n                    resource = libutils.path_to_resource(pycore.project, path)\r\n                    module = pyobjects.PyModule(pycore, None, resource)\r\n                    return (module, lineno)\r\n            return (None, None)\r\n    builtins.BuiltinName = PatchedBuiltinName\r\n    \r\n    # [4] Patching several PyDocExtractor methods:\r\n    # 1. get_doc:\r\n    # To force rope to return the docstring of any object which has one, even\r\n    # if it's not an instance of AbstractFunction, AbstractClass, or\r\n    # AbstractModule.\r\n    # Also, to use utils.dochelpers.getdoc to get docs from forced builtins.\r\n    #\r\n    # 2. _get_class_docstring and _get_single_function_docstring:\r\n    # To not let rope add a 2 spaces indentation to every docstring, which was\r\n    # breaking our rich text mode. The only value that we are modifying is the\r\n    # 'indents' keyword of those methods, from 2 to 0.\r\n    #\r\n    # 3. get_calltip\r\n    # To easily get calltips of forced builtins\r\n    from rope.contrib import codeassist\r\n    from spyder_kernels.utils.dochelpers import getdoc\r\n    from rope.base import exceptions\r\n    class PatchedPyDocExtractor(codeassist.PyDocExtractor):\r\n        def get_builtin_doc(self, pyobject):\r\n            buitin = pyobject.builtin\r\n            return getdoc(buitin)\r\n            \r\n        def get_doc(self, pyobject):\r\n            if hasattr(pyobject, 'builtin'):\r\n                doc = self.get_builtin_doc(pyobject)\r\n                return doc\r\n            elif isinstance(pyobject, builtins.BuiltinModule):\r\n                docstring = pyobject.get_doc()\r\n                if docstring is not None:\r\n                    docstring = self._trim_docstring(docstring)\r\n                else:\r\n                    docstring = ''\r\n                # TODO: Add a module_name key, so that the name could appear\r\n                # on the OI text filed but not be used by sphinx to render\r\n                # the page\r\n                doc = {'name': '',\r\n                       'argspec': '',\r\n                       'note': '',\r\n                       'docstring': docstring\r\n                       }\r\n                return doc\r\n            elif isinstance(pyobject, pyobjects.AbstractFunction):\r\n                return self._get_function_docstring(pyobject)\r\n            elif isinstance(pyobject, pyobjects.AbstractClass):\r\n                return self._get_class_docstring(pyobject)\r\n            elif isinstance(pyobject, pyobjects.AbstractModule):\r\n                return self._trim_docstring(pyobject.get_doc())\r\n            elif pyobject.get_doc() is not None:  # Spyder patch\r\n                return self._trim_docstring(pyobject.get_doc())\r\n            return None\r\n\r\n        def get_calltip(self, pyobject, ignore_unknown=False, remove_self=False):\r\n            if hasattr(pyobject, 'builtin'):\r\n                doc = self.get_builtin_doc(pyobject)\r\n                return doc['name'] + doc['argspec']\r\n            try:\r\n                if isinstance(pyobject, pyobjects.AbstractClass):\r\n                    pyobject = pyobject['__init__'].get_object()\r\n                if not isinstance(pyobject, pyobjects.AbstractFunction):\r\n                    pyobject = pyobject['__call__'].get_object()\r\n            except exceptions.AttributeNotFoundError:\r\n                return None\r\n            if ignore_unknown and not isinstance(pyobject, pyobjects.PyFunction):\r\n                return\r\n            if isinstance(pyobject, pyobjects.AbstractFunction):\r\n                result = self._get_function_signature(pyobject, add_module=True)\r\n                if remove_self and self._is_method(pyobject):\r\n                    return result.replace('(self)', '()').replace('(self, ', '(')\r\n                return result\r\n        \r\n        def _get_class_docstring(self, pyclass):\r\n            contents = self._trim_docstring(pyclass.get_doc(), indents=0)\r\n            supers = [super.get_name() for super in pyclass.get_superclasses()]\r\n            doc = 'class %s(%s):\\n\\n' % (pyclass.get_name(), ', '.join(supers)) + contents\r\n\r\n            if '__init__' in pyclass:\r\n                init = pyclass['__init__'].get_object()\r\n                if isinstance(init, pyobjects.AbstractFunction):\r\n                    doc += '\\n\\n' + self._get_single_function_docstring(init)\r\n            return doc\r\n            \r\n        def _get_single_function_docstring(self, pyfunction):\r\n            docs = pyfunction.get_doc()\r\n            docs = self._trim_docstring(docs, indents=0)\r\n            return docs\r\n    codeassist.PyDocExtractor = PatchedPyDocExtractor\r\n\r\n\r\n    # [5] Get the right matplotlib docstrings for Help\r\n    try:\r\n        import matplotlib as mpl\r\n        mpl.rcParams['docstring.hardcopy'] = True\r\n    except:\r\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paintEvent(self, event):\n        painter = QPainter(self)\n\n        color = QColor(self.color)\n        color.setAlphaF(.5)\n        painter.setPen(color)\n        offset = self.editor.document().documentMargin() + \\\n            self.editor.contentOffset().x()\n\n        for _, line_number, block in self.editor.visible_blocks:\n\n            indentation = TextBlockHelper.get_fold_lvl(block)\n            ref_lvl = indentation\n            block = block.next()\n            last_line = block.blockNumber()\n            lvl = TextBlockHelper.get_fold_lvl(block)\n            if ref_lvl == lvl:  # for zone set programmatically such as imports\n                # in pyqode.python\n                ref_lvl -= 1\n\n            while (block.isValid() and\n                   TextBlockHelper.get_fold_lvl(block) > ref_lvl):\n                last_line = block.blockNumber()\n                block = block.next()\n\n            end_of_sub_fold = block\n            if last_line:\n                block = block.document().findBlockByNumber(last_line)\n                while ((block.blockNumber()) and (block.text().strip() == ''\n                       or block.text().strip().startswith('#'))):\n                    block = block.previous()\n                    last_line = block.blockNumber()\n\n            block = self.editor.document().findBlockByNumber(line_number)\n            top = int(self.editor.blockBoundingGeometry(block).translated(\n                self.editor.contentOffset()).top())\n            bottom = top + int(self.editor.blockBoundingRect(block).height())\n\n            indentation = TextBlockHelper.get_fold_lvl(block)\n\n            for i in range(1, indentation):\n                if (line_number > last_line and\n                        TextBlockHelper.get_fold_lvl(end_of_sub_fold) <= i):\n                    continue\n                else:\n                    x = self.editor.fontMetrics().width(i * self.i_width *\n                                                        '9') + offset\n                    painter.drawLine(x, top, x, bottom)", "response": "Override Qt method. Draws the event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_plugin_actions(self):\r\n        return [self.rich_text_action, self.plain_text_action,\r\n                self.show_source_action, MENU_SEPARATOR,\r\n                self.auto_import_action]", "response": "Return a list of actions related to the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.focus_changed.connect(self.main.plugin_focus_changed)\r\n        self.main.add_dockwidget(self)\r\n        self.main.console.set_help(self)\r\n\r\n        self.internal_shell = self.main.console.shell\r\n        self.console = self.main.console"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_font(self):\r\n        color_scheme = self.get_color_scheme()\r\n        font = self.get_plugin_font()\r\n        rich_font = self.get_plugin_font(rich_text=True)\r\n\r\n        self.set_plain_text_font(font, color_scheme=color_scheme)\r\n        self.set_rich_text_font(rich_font)", "response": "Update font from Preferences"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying configuration file s plugin settings", "response": "def apply_plugin_settings(self, options):\r\n        \"\"\"Apply configuration file's plugin settings\"\"\"\r\n        color_scheme_n = 'color_scheme_name'\r\n        color_scheme_o = self.get_color_scheme()\r\n        connect_n = 'connect_to_oi'\r\n        wrap_n = 'wrap'\r\n        wrap_o = self.get_option(wrap_n)\r\n        self.wrap_action.setChecked(wrap_o)\r\n        math_n = 'math'\r\n        math_o = self.get_option(math_n)\r\n\r\n        if color_scheme_n in options:\r\n            self.set_plain_text_color_scheme(color_scheme_o)\r\n        if wrap_n in options:\r\n            self.toggle_wrap_mode(wrap_o)\r\n        if math_n in options:\r\n            self.toggle_math_mode(math_o)\r\n\r\n        # To make auto-connection changes take place instantly\r\n        self.main.editor.apply_plugin_settings(options=[connect_n])\r\n        self.main.ipyconsole.apply_plugin_settings(options=[connect_n])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset rich text mode font", "response": "def set_rich_text_font(self, font):\r\n        \"\"\"Set rich text mode font\"\"\"\r\n        self.rich_text.set_font(font, fixed_font=self.get_plugin_font())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_plain_text_font(self, font, color_scheme=None):\r\n        self.plain_text.set_font(font, color_scheme=color_scheme)", "response": "Set plain text mode font"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef switch_to_plain_text(self):\r\n        self.rich_help = False\r\n        self.plain_text.show()\r\n        self.rich_text.hide()\r\n        self.plain_text_action.setChecked(True)", "response": "Switch to plain text mode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nswitching to rich text mode", "response": "def switch_to_rich_text(self):\r\n        \"\"\"Switch to rich text mode\"\"\"\r\n        self.rich_help = True\r\n        self.plain_text.hide()\r\n        self.rich_text.show()\r\n        self.rich_text_action.setChecked(True)\r\n        self.show_source_action.setChecked(False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting plain text docs", "response": "def set_plain_text(self, text, is_code):\r\n        \"\"\"Set plain text docs\"\"\"\r\n\r\n        # text is coming from utils.dochelpers.getdoc\r\n        if type(text) is dict:\r\n            name = text['name']\r\n            if name:\r\n                rst_title = ''.join(['='*len(name), '\\n', name, '\\n',\r\n                                    '='*len(name), '\\n\\n'])\r\n            else:\r\n                rst_title = ''\r\n\r\n            if text['argspec']:\r\n                definition = ''.join(['Definition: ', name, text['argspec'],\r\n                                      '\\n'])\r\n            else:\r\n                definition = ''\r\n\r\n            if text['note']:\r\n                note = ''.join(['Type: ', text['note'], '\\n\\n----\\n\\n'])\r\n            else:\r\n                note = ''\r\n\r\n            full_text = ''.join([rst_title, definition, note,\r\n                                 text['docstring']])\r\n        else:\r\n            full_text = text\r\n\r\n        self.plain_text.set_text(full_text, is_code)\r\n        self.save_text([self.plain_text.set_text, full_text, is_code])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_rich_text(self, text, collapse=False, img_path=''):\r\n        self.switch_to_plugin()\r\n        self.switch_to_rich_text()\r\n        context = generate_context(collapse=collapse, img_path=img_path,\r\n                                   css_path=self.css_path)\r\n        self.render_sphinx_doc(text, context)", "response": "Show text in rich mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows text in plain mode", "response": "def show_plain_text(self, text):\r\n        \"\"\"Show text in plain mode\"\"\"\r\n        self.switch_to_plugin()\r\n        self.switch_to_plain_text()\r\n        self.set_plain_text(text, is_code=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing the Spyder tutorial in the Help plugin opening it if needed", "response": "def show_tutorial(self):\r\n        \"\"\"Show the Spyder tutorial in the Help plugin, opening it if needed\"\"\"\r\n        self.switch_to_plugin()\r\n        tutorial_path = get_module_source_path('spyder.plugins.help.utils')\r\n        tutorial = osp.join(tutorial_path, 'tutorial.rst')\r\n        text = open(tutorial).read()\r\n        self.show_rich_text(text, collapse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_object_text(self, text, force_refresh=False, ignore_unknown=False):\r\n        if (self.locked and not force_refresh):\r\n            return\r\n        self.switch_to_console_source()\r\n\r\n        add_to_combo = True\r\n        if text is None:\r\n            text = to_text_string(self.combo.currentText())\r\n            add_to_combo = False\r\n\r\n        found = self.show_help(text, ignore_unknown=ignore_unknown)\r\n        if ignore_unknown and not found:\r\n            return\r\n\r\n        if add_to_combo:\r\n            self.combo.add_text(text)\r\n        if found:\r\n            self.save_history()\r\n\r\n        if self.dockwidget is not None:\r\n            self.dockwidget.blockSignals(True)\r\n        self.__eventually_raise_help(text, force=force_refresh)\r\n        if self.dockwidget is not None:\r\n            self.dockwidget.blockSignals(False)", "response": "Set object analyzed by Help"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the docstrings of the object in the Editor plugin", "response": "def set_editor_doc(self, doc, force_refresh=False):\r\n        \"\"\"\r\n        Use the help plugin to show docstring dictionary computed\r\n        with introspection plugin from the Editor plugin\r\n        \"\"\"\r\n        if (self.locked and not force_refresh):\r\n            return\r\n        self.switch_to_editor_source()\r\n        self._last_editor_doc = doc\r\n        self.object_edit.setText(doc['obj_text'])\r\n\r\n        if self.rich_help:\r\n            self.render_sphinx_doc(doc)\r\n        else:\r\n            self.set_plain_text(doc, is_code=False)\r\n\r\n        if self.dockwidget is not None:\r\n            self.dockwidget.blockSignals(True)\r\n        self.__eventually_raise_help(doc['docstring'], force=force_refresh)\r\n        if self.dockwidget is not None:\r\n            self.dockwidget.blockSignals(False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_history(self, obj=None):\r\n        if osp.isfile(self.LOG_PATH):\r\n            history = [line.replace('\\n', '')\r\n                       for line in open(self.LOG_PATH, 'r').readlines()]\r\n        else:\r\n            history = []\r\n        return history", "response": "Load a list of user - defined user - defined attributes from a text file in user home directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave history to a text file in user home directory", "response": "def save_history(self):\r\n        \"\"\"Save history to a text file in user home directory\"\"\"\r\n        # Don't fail when saving search history to disk\r\n        # See issues 8878 and 6864\r\n        try:\r\n            search_history = [to_text_string(self.combo.itemText(index))\r\n                              for index in range(self.combo.count())]\r\n            search_history = '\\n'.join(search_history)\r\n            open(self.LOG_PATH, 'w').write(search_history)\r\n        except (UnicodeEncodeError, UnicodeDecodeError, EnvironmentError):\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toggle_plain_text(self, checked):\r\n        if checked:\r\n            self.docstring = checked\r\n            self.switch_to_plain_text()\r\n            self.force_refresh()\r\n        self.set_option('rich_mode', not checked)", "response": "Toggle plain text docstring"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toggle_show_source(self, checked):\r\n        if checked:\r\n            self.switch_to_plain_text()\r\n        self.docstring = not checked\r\n        self.force_refresh()\r\n        self.set_option('rich_mode', not checked)", "response": "Toggle show source code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toggle_rich_text(self, checked):\r\n        if checked:\r\n            self.docstring = not checked\r\n            self.switch_to_rich_text()\r\n        self.set_option('rich_mode', checked)", "response": "Toggle between sphinxified docstrings or plain ones"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntoggling automatic import feature", "response": "def toggle_auto_import(self, checked):\r\n        \"\"\"Toggle automatic import feature\"\"\"\r\n        self.combo.validate_current_text()\r\n        self.set_option('automatic_import', checked)\r\n        self.force_refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_lock_icon(self):\r\n        icon = ima.icon('lock') if self.locked else ima.icon('lock_open')\r\n        self.locked_button.setIcon(icon)\r\n        tip = _(\"Unlock\") if self.locked else _(\"Lock\")\r\n        self.locked_button.setToolTip(tip)", "response": "Update locked state icon"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_shell(self):\r\n        if (not hasattr(self.shell, 'get_doc') or\r\n                (hasattr(self.shell, 'is_running') and\r\n                 not self.shell.is_running())):\r\n            self.shell = None\r\n            if self.main.ipyconsole is not None:\r\n                shell = self.main.ipyconsole.get_current_shellwidget()\r\n                if shell is not None and shell.kernel_client is not None:\r\n                    self.shell = shell\r\n            if self.shell is None:\r\n                self.shell = self.internal_shell\r\n        return self.shell", "response": "Returns the first running shell or None if it has been terminated"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_sphinx_doc(self, doc, context=None, css_path=CSS_PATH):\r\n        # Math rendering option could have changed\r\n        if self.main.editor is not None:\r\n            fname = self.main.editor.get_current_filename()\r\n            dname = osp.dirname(fname)\r\n        else:\r\n            dname = ''\r\n        self._sphinx_thread.render(doc, context, self.get_option('math'),\r\n                                   dname, css_path=self.css_path)", "response": "Transform doc string dictionary to HTML and show it"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_sphinx_thread_html_ready(self, html_text):\r\n        self._sphinx_thread.wait()\r\n        self.set_rich_text_html(html_text, QUrl.fromLocalFile(self.css_path))", "response": "Called when the thread is ready to be parsed and we want to set our sphinx documentation based on the result of the html_text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays error message on Sphinx rich text failure", "response": "def _on_sphinx_thread_error_msg(self, error_msg):\r\n        \"\"\" Display error message on Sphinx rich text failure\"\"\"\r\n        self._sphinx_thread.wait()\r\n        self.plain_text_action.setChecked(True)\r\n        sphinx_ver = programs.get_module_version('sphinx')\r\n        QMessageBox.critical(self,\r\n                    _('Help'),\r\n                    _(\"The following error occured when calling \"\r\n                      \"<b>Sphinx %s</b>. <br>Incompatible Sphinx \"\r\n                      \"version or doc string decoding failed.\"\r\n                      \"<br><br>Error message:<br>%s\"\r\n                      ) % (sphinx_ver, error_msg))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_help(self, obj_text, ignore_unknown=False):\r\n        shell = self.get_shell()\r\n        if shell is None:\r\n            return\r\n        obj_text = to_text_string(obj_text)\r\n\r\n        if not shell.is_defined(obj_text):\r\n            if self.get_option('automatic_import') and \\\r\n               self.internal_shell.is_defined(obj_text, force_import=True):\r\n                shell = self.internal_shell\r\n            else:\r\n                shell = None\r\n                doc = None\r\n                source_text = None\r\n\r\n        if shell is not None:\r\n            doc = shell.get_doc(obj_text)\r\n            source_text = shell.get_source(obj_text)\r\n\r\n        is_code = False\r\n\r\n        if self.rich_help:\r\n            self.render_sphinx_doc(doc, css_path=self.css_path)\r\n            return doc is not None\r\n        elif self.docstring:\r\n            hlp_text = doc\r\n            if hlp_text is None:\r\n                hlp_text = source_text\r\n                if hlp_text is None:\r\n                    hlp_text = self.no_doc_string\r\n                    if ignore_unknown:\r\n                        return False\r\n        else:\r\n            hlp_text = source_text\r\n            if hlp_text is None:\r\n                hlp_text = doc\r\n                if hlp_text is None:\r\n                    hlp_text = _(\"No source code available.\")\r\n                    if ignore_unknown:\r\n                        return False\r\n            else:\r\n                is_code = True\r\n        self.set_plain_text(hlp_text, is_code=is_code)\r\n        return True", "response": "Show help for the given object text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the textCursor is in the decoration.", "response": "def contains_cursor(self, cursor):\n        \"\"\"\n        Checks if the textCursor is in the decoration.\n\n        :param cursor: The text cursor to test\n        :type cursor: QtGui.QTextCursor\n\n        :returns: True if the cursor is over the selection\n        \"\"\"\n        start = self.cursor.selectionStart()\n        end = self.cursor.selectionEnd()\n        if cursor.atBlockEnd():\n            end -= 1\n        return start <= cursor.position() <= end"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_line(self):\n        self.cursor.movePosition(self.cursor.StartOfBlock)\n        text = self.cursor.block().text()\n        lindent = len(text) - len(text.lstrip())\n        self.cursor.setPosition(self.cursor.block().position() + lindent)\n        self.cursor.movePosition(self.cursor.EndOfBlock,\n                                 self.cursor.KeepAnchor)", "response": "Select the entire line but starts at the first non - whitespace character\n        and stops at the first non - whitespace character\n        and starts at the first non - whitespace character\n        and stops at the first non - whitespace character\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_as_underlined(self, color=Qt.blue):\n        self.format.setUnderlineStyle(\n            QTextCharFormat.SingleUnderline)\n        self.format.setUnderlineColor(color)", "response": "Underlines the text.\n\n        :param color: underline color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunderline text as a spellcheck error.", "response": "def set_as_spell_check(self, color=Qt.blue):\n        \"\"\"\n        Underlines text as a spellcheck error.\n\n        :param color: Underline color\n        :type color: QtGui.QColor\n        \"\"\"\n        self.format.setUnderlineStyle(\n            QTextCharFormat.SpellCheckUnderline)\n        self.format.setUnderlineColor(color)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhighlighting text as a syntax error.", "response": "def set_as_error(self, color=Qt.red):\n        \"\"\"\n        Highlights text as a syntax error.\n\n        :param color: Underline color\n        :type color: QtGui.QColor\n        \"\"\"\n        self.format.setUnderlineStyle(\n            QTextCharFormat.WaveUnderline)\n        self.format.setUnderlineColor(color)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhighlight text as a syntax warning.", "response": "def set_as_warning(self, color=QColor(\"orange\")):\n        \"\"\"\n        Highlights text as a syntax warning.\n\n        :param color: Underline color\n        :type color: QtGui.QColor\n        \"\"\"\n        self.format.setUnderlineStyle(\n            QTextCharFormat.WaveUnderline)\n        self.format.setUnderlineColor(color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_threads(self, parent):\r\n        logger.debug(\"Call ThreadManager's 'close_threads'\")\r\n        if parent is None:\r\n            # Closing all threads\r\n            self.pending_threads = []\r\n            threadlist = []\r\n            for threads in list(self.started_threads.values()):\r\n                threadlist += threads\r\n        else:\r\n            parent_id = id(parent)\r\n            self.pending_threads = [(_th, _id) for (_th, _id)\r\n                                    in self.pending_threads\r\n                                    if _id != parent_id]\r\n            threadlist = self.started_threads.get(parent_id, [])\r\n        for thread in threadlist:\r\n            logger.debug(\"Waiting for thread %r to finish\" % thread)\r\n            while thread.isRunning():\r\n                # We can't terminate thread safely, so we simply wait...\r\n                QApplication.processEvents()", "response": "Close all threads associated to parent_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new thread to the queue", "response": "def add_thread(self, checker, end_callback, source_code, parent):\r\n        \"\"\"Add thread to queue\"\"\"\r\n        parent_id = id(parent)\r\n        thread = AnalysisThread(self, checker, source_code)\r\n        self.end_callbacks[id(thread)] = end_callback\r\n        self.pending_threads.append((thread, parent_id))\r\n        logger.debug(\"Added thread %r to queue\" % thread)\r\n        QTimer.singleShot(50, self.update_queue)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the queue with the threads that have finished.", "response": "def update_queue(self):\r\n        \"\"\"Update queue\"\"\"\r\n        started = 0\r\n        for parent_id, threadlist in list(self.started_threads.items()):\r\n            still_running = []\r\n            for thread in threadlist:\r\n                if thread.isFinished():\r\n                    end_callback = self.end_callbacks.pop(id(thread))\r\n                    if thread.results is not None:\r\n                        #  The thread was executed successfully\r\n                        end_callback(thread.results)\r\n                    thread.setParent(None)\r\n                    thread = None\r\n                else:\r\n                    still_running.append(thread)\r\n                    started += 1\r\n            threadlist = None\r\n            if still_running:\r\n                self.started_threads[parent_id] = still_running\r\n            else:\r\n                self.started_threads.pop(parent_id)\r\n        logger.debug(\"Updating queue:\")\r\n        logger.debug(\"    started: %d\" % started)\r\n        logger.debug(\"    pending: %d\" % len(self.pending_threads))\r\n        if self.pending_threads and started < self.max_simultaneous_threads:\r\n            thread, parent_id = self.pending_threads.pop(0)\r\n            thread.finished.connect(self.update_queue)\r\n            threadlist = self.started_threads.get(parent_id, [])\r\n            self.started_threads[parent_id] = threadlist+[thread]\r\n            logger.debug(\"===>starting: %r\" % thread)\r\n            thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_todo_finder(self):\r\n        if self.editor.is_python():\r\n            self.threadmanager.add_thread(codeanalysis.find_tasks,\r\n                                          self.todo_finished,\r\n                                          self.get_source_code(), self)", "response": "Run todo finder threadmanager"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_todo_results(self, results):\r\n        self.todo_results = results\r\n        self.editor.process_todo(results)", "response": "Set todo results and update markers in editor"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbookmarks list has changed.", "response": "def bookmarks_changed(self):\r\n        \"\"\"Bookmarks list has changed.\"\"\"\r\n        bookmarks = self.editor.get_bookmarks()\r\n        if self.editor.bookmarks != bookmarks:\r\n            self.editor.bookmarks = bookmarks\r\n            self.sig_save_bookmarks.emit(self.filename, repr(bookmarks))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_id_list(self):\r\n        self.id_list = [id(self.editor.tabs.widget(_i))\r\n                        for _i in range(self.editor.tabs.count())]", "response": "Update list of corresponpding ids and tabs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrefresh the list of all the items in the history.", "response": "def refresh(self):\r\n        \"\"\"Remove editors that are not longer open.\"\"\"\r\n        self._update_id_list()\r\n        for _id in self.history[:]:\r\n            if _id not in self.id_list:\r\n                self.history.remove(_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(self, i, tab_index):\r\n        _id = id(self.editor.tabs.widget(tab_index))\r\n        self.history.insert(i, _id)", "response": "Insert the widget at the given tab index in the position i."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, tab_index):\r\n        _id = id(self.editor.tabs.widget(tab_index))\r\n        if _id in self.history:\r\n            self.history.remove(_id)", "response": "Removes the widget at the corresponding tab_index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_and_append(self, index):\r\n        while index in self:\r\n            self.remove(index)\r\n        self.append(index)", "response": "Remove previous entrances of a tab and add it as the latest."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill ListWidget with the tabs texts.", "response": "def load_data(self):\r\n        \"\"\"Fill ListWidget with the tabs texts.\r\n\r\n        Add elements in inverse order of stack_history.\r\n        \"\"\"\r\n\r\n        for index in reversed(self.stack_history):\r\n            text = self.tabs.tabText(index)\r\n            text = text.replace('&', '')\r\n            item = QListWidgetItem(ima.icon('TextFileIcon'), text)\r\n            self.addItem(item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef item_selected(self, item=None):\r\n        if item is None:\r\n            item = self.currentItem()\r\n\r\n        # stack history is in inverse order\r\n        try:\r\n            index = self.stack_history[-(self.currentRow()+1)]\r\n        except IndexError:\r\n            pass\r\n        else:\r\n            self.editor.set_stack_index(index)\r\n            self.editor.current_changed(index)\r\n        self.hide()", "response": "Change to the selected document and hide this widget."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove selected row a number of steps.", "response": "def select_row(self, steps):\r\n        \"\"\"Move selected row a number of steps.\r\n\r\n        Iterates in a cyclic behaviour.\r\n        \"\"\"\r\n        row = (self.currentRow() + steps) % self.count()\r\n        self.setCurrentRow(row)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_dialog_position(self):\r\n        left = self.editor.geometry().width()/2 - self.width()/2\r\n        top = self.editor.tabs.tabBar().geometry().height()\r\n\r\n        self.move(self.editor.mapToGlobal(QPoint(left, top)))", "response": "Positions the tab switcher in the top - center of the editor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keyReleaseEvent(self, event):\r\n        if self.isVisible():\r\n            qsc = get_shortcut(context='Editor', name='Go to next file')\r\n\r\n            for key in qsc.split('+'):\r\n                key = key.lower()\r\n                if ((key == 'ctrl' and event.key() == Qt.Key_Control) or\r\n                   (key == 'alt' and event.key() == Qt.Key_Alt)):\r\n                        self.item_selected()\r\n        event.accept()", "response": "Reimplement Qt method.\r\n\r\n        Handle \"most recent used\" tab behavior,\r\n        When ctrl is released and tab_switcher is visible, tab will be changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keyPressEvent(self, event):\r\n        if event.key() == Qt.Key_Down:\r\n            self.select_row(1)\r\n        elif event.key() == Qt.Key_Up:\r\n            self.select_row(-1)", "response": "Reimplement Qt method to allow cyclic behavior."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_shortcuts(self):\r\n        # --- Configurable shortcuts\r\n        inspect = config_shortcut(self.inspect_current_object, context='Editor',\r\n                                  name='Inspect current object', parent=self)\r\n        set_breakpoint = config_shortcut(self.set_or_clear_breakpoint,\r\n                                         context='Editor', name='Breakpoint',\r\n                                         parent=self)\r\n        set_cond_breakpoint = config_shortcut(\r\n                                    self.set_or_edit_conditional_breakpoint,\r\n                                    context='Editor',\r\n                                    name='Conditional breakpoint',\r\n                                    parent=self)\r\n        gotoline = config_shortcut(self.go_to_line, context='Editor',\r\n                                   name='Go to line', parent=self)\r\n        tab = config_shortcut(lambda: self.tab_navigation_mru(forward=False),\r\n                              context='Editor',\r\n                              name='Go to previous file', parent=self)\r\n        tabshift = config_shortcut(self.tab_navigation_mru, context='Editor',\r\n                                   name='Go to next file', parent=self)\r\n        prevtab = config_shortcut(lambda: self.tabs.tab_navigate(-1),\r\n                                  context='Editor',\r\n                                  name='Cycle to previous file', parent=self)\r\n        nexttab = config_shortcut(lambda: self.tabs.tab_navigate(1),\r\n                                  context='Editor',\r\n                                  name='Cycle to next file', parent=self)\r\n        run_selection = config_shortcut(self.run_selection, context='Editor',\r\n                                        name='Run selection', parent=self)\r\n        new_file = config_shortcut(lambda : self.sig_new_file[()].emit(),\r\n                                   context='Editor', name='New file',\r\n                                   parent=self)\r\n        open_file = config_shortcut(lambda : self.plugin_load[()].emit(),\r\n                                    context='Editor', name='Open file',\r\n                                    parent=self)\r\n        save_file = config_shortcut(self.save, context='Editor',\r\n                                    name='Save file', parent=self)\r\n        save_all = config_shortcut(self.save_all, context='Editor',\r\n                                   name='Save all', parent=self)\r\n        save_as = config_shortcut(lambda : self.sig_save_as.emit(),\r\n                                  context='Editor', name='Save As',\r\n                                  parent=self)\r\n        close_all = config_shortcut(self.close_all_files, context='Editor',\r\n                                    name='Close all', parent=self)\r\n        prev_edit_pos = config_shortcut(lambda : self.sig_prev_edit_pos.emit(),\r\n                                        context=\"Editor\",\r\n                                        name=\"Last edit location\",\r\n                                        parent=self)\r\n        prev_cursor = config_shortcut(lambda : self.sig_prev_cursor.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"Previous cursor position\",\r\n                                      parent=self)\r\n        next_cursor = config_shortcut(lambda : self.sig_next_cursor.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"Next cursor position\",\r\n                                      parent=self)\r\n        zoom_in_1 = config_shortcut(lambda : self.zoom_in.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"zoom in 1\",\r\n                                      parent=self)\r\n        zoom_in_2 = config_shortcut(lambda : self.zoom_in.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"zoom in 2\",\r\n                                      parent=self)\r\n        zoom_out = config_shortcut(lambda : self.zoom_out.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"zoom out\",\r\n                                      parent=self)\r\n        zoom_reset = config_shortcut(lambda: self.zoom_reset.emit(),\r\n                                      context=\"Editor\",\r\n                                      name=\"zoom reset\",\r\n                                      parent=self)\r\n        close_file_1 = config_shortcut(self.close_file,\r\n                                      context=\"Editor\",\r\n                                      name=\"close file 1\",\r\n                                      parent=self)\r\n        close_file_2 = config_shortcut(self.close_file,\r\n                                      context=\"Editor\",\r\n                                      name=\"close file 2\",\r\n                                      parent=self)\r\n        run_cell = config_shortcut(self.run_cell,\r\n                                      context=\"Editor\",\r\n                                      name=\"run cell\",\r\n                                      parent=self)\r\n        run_cell_and_advance = config_shortcut(self.run_cell_and_advance,\r\n                                      context=\"Editor\",\r\n                                      name=\"run cell and advance\",\r\n                                      parent=self)\r\n        go_to_next_cell = config_shortcut(self.advance_cell,\r\n                                          context=\"Editor\",\r\n                                          name=\"go to next cell\",\r\n                                          parent=self)\r\n        go_to_previous_cell = config_shortcut(lambda: self.advance_cell(reverse=True),\r\n                                              context=\"Editor\",\r\n                                              name=\"go to previous cell\",\r\n                                              parent=self)\r\n        re_run_last_cell = config_shortcut(self.re_run_last_cell,\r\n                                      context=\"Editor\",\r\n                                      name=\"re-run last cell\",\r\n                                      parent=self)\r\n        prev_warning = config_shortcut(lambda: self.sig_prev_warning.emit(),\r\n                                       context=\"Editor\",\r\n                                       name=\"Previous warning\",\r\n                                       parent=self)\r\n        next_warning = config_shortcut(lambda: self.sig_next_warning.emit(),\r\n                                       context=\"Editor\",\r\n                                       name=\"Next warning\",\r\n                                       parent=self)\r\n        split_vertically = config_shortcut(lambda: self.sig_split_vertically.emit(),\r\n                                           context=\"Editor\",\r\n                                           name=\"split vertically\",\r\n                                           parent=self)\r\n        split_horizontally = config_shortcut(lambda: self.sig_split_horizontally.emit(),\r\n                                             context=\"Editor\",\r\n                                             name=\"split horizontally\",\r\n                                             parent=self)\r\n        close_split = config_shortcut(self.close_split,\r\n                                      context=\"Editor\",\r\n                                      name=\"close split panel\",\r\n                                      parent=self)\r\n\r\n        # Return configurable ones\r\n        return [inspect, set_breakpoint, set_cond_breakpoint, gotoline, tab,\r\n                tabshift, run_selection, new_file, open_file, save_file,\r\n                save_all, save_as, close_all, prev_edit_pos, prev_cursor,\r\n                next_cursor, zoom_in_1, zoom_in_2, zoom_out, zoom_reset,\r\n                close_file_1, close_file_2, run_cell, run_cell_and_advance,\r\n                go_to_next_cell, go_to_previous_cell, re_run_last_cell,\r\n                prev_warning, next_warning, split_vertically,\r\n                split_horizontally, close_split,\r\n                prevtab, nexttab]", "response": "Create local shortcuts and shortcuts for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the fname label.", "response": "def update_fname_label(self):\r\n        \"\"\"Upadte file name label.\"\"\"\r\n        filename = to_text_string(self.get_current_filename())\r\n        if len(filename) > 100:\r\n            shorten_filename = u'...' + filename[-100:]\r\n        else:\r\n            shorten_filename = filename\r\n        self.fname_label.setText(shorten_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef closeEvent(self, event):\r\n        self.threadmanager.close_all_threads()\r\n        self.analysis_timer.timeout.disconnect(self.analyze_script)\r\n\r\n        # Remove editor references from the outline explorer settings\r\n        if self.outlineexplorer is not None:\r\n            for finfo in self.data:\r\n                self.outlineexplorer.remove_editor(finfo.editor.oe_proxy)\r\n\r\n        QWidget.closeEvent(self, event)", "response": "Overrides QWidget. closeEvent to disconnect threads and threads from the threadmanager and the analysis timer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclone EditorStack from other instance", "response": "def clone_from(self, other):\r\n        \"\"\"Clone EditorStack from other instance\"\"\"\r\n        for other_finfo in other.data:\r\n            self.clone_editor_from(other_finfo, set_current=True)\r\n        self.set_stack_index(other.get_stack_index())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens file list management dialog box", "response": "def open_fileswitcher_dlg(self):\r\n        \"\"\"Open file list management dialog box\"\"\"\r\n        if not self.tabs.count():\r\n            return\r\n        if self.fileswitcher_dlg is not None and \\\r\n          self.fileswitcher_dlg.is_visible:\r\n            self.fileswitcher_dlg.hide()\r\n            self.fileswitcher_dlg.is_visible = False\r\n            return\r\n        self.fileswitcher_dlg = FileSwitcher(self, self, self.tabs, self.data,\r\n                                             ima.icon('TextFileIcon'))\r\n        self.fileswitcher_dlg.sig_goto_file.connect(self.set_stack_index)\r\n        self.fileswitcher_dlg.show()\r\n        self.fileswitcher_dlg.is_visible = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngo to line dialog", "response": "def go_to_line(self, line=None):\r\n        \"\"\"Go to line dialog\"\"\"\r\n        if line is not None:\r\n            # When this method is called from the flileswitcher, a line\r\n            # number is specified, so there is no need for the dialog.\r\n            self.get_current_editor().go_to_line(line)\r\n        else:\r\n            if self.data:\r\n                self.get_current_editor().exec_gotolinedialog()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset or clear breakpoint", "response": "def set_or_clear_breakpoint(self):\r\n        \"\"\"Set/clear breakpoint\"\"\"\r\n        if self.data:\r\n            editor = self.get_current_editor()\r\n            editor.debugger.toogle_breakpoint()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the bookmark current position to given slot.", "response": "def set_bookmark(self, slot_num):\r\n        \"\"\"Bookmark current position to given slot.\"\"\"\r\n        if self.data:\r\n            editor = self.get_current_editor()\r\n            editor.add_bookmark(slot_num)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninspects current object in the Help plugin", "response": "def inspect_current_object(self):\r\n        \"\"\"Inspect current object in the Help plugin\"\"\"\r\n        editor = self.get_current_editor()\r\n        editor.sig_display_signature.connect(self.display_signature_help)\r\n        line, col = editor.get_cursor_line_column()\r\n        editor.request_hover(line, col)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tab_tip(self, filename, is_modified=None, is_readonly=None):\r\n        text = u\"%s \u2014 %s\"\r\n        text = self.__modified_readonly_title(text,\r\n                                              is_modified, is_readonly)\r\n        if self.tempfile_path is not None\\\r\n           and filename == encoding.to_unicode_from_fs(self.tempfile_path):\r\n            temp_file_str = to_text_string(_(\"Temporary file\"))\r\n            return text % (temp_file_str, self.tempfile_path)\r\n        else:\r\n            return text % (osp.basename(filename), osp.dirname(filename))", "response": "Return tab menu title"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __setup_menu(self):\r\n        self.menu.clear()\r\n        if self.data:\r\n            actions = self.menu_actions\r\n        else:\r\n            actions = (self.new_action, self.open_action)\r\n            self.setFocus() # --> Editor.__get_focus_editortabwidget\r\n        add_actions(self.menu, list(actions) + self.__get_split_actions())\r\n        self.close_action.setEnabled(self.is_closable)", "response": "Setup tab context menu before showing it"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the first file in the list that contains the filename. Returns None if the filename is not found in the list.", "response": "def has_filename(self, filename):\r\n        \"\"\"Return the self.data index position for the filename.\r\n\r\n        Args:\r\n            filename: Name of the file to search for in self.data.\r\n\r\n        Returns:\r\n            The self.data index for the filename.  Returns None\r\n            if the filename is not found in self.data.\r\n        \"\"\"\r\n        fixpath = lambda path: osp.normcase(osp.realpath(path))\r\n        for index, finfo in enumerate(self.data):\r\n            if fixpath(filename) == fixpath(finfo.filename):\r\n                return index\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_current_filename(self, filename, focus=True):\r\n        index = self.has_filename(filename)\r\n        if index is not None:\r\n            if focus:\r\n                self.set_stack_index(index)\r\n            editor = self.data[index].editor\r\n            if focus:\r\n                editor.setFocus()\r\n            else:\r\n                self.stack_history.remove_and_append(index)\r\n\r\n            return editor", "response": "Set current filename and return the associated editor instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns if a file is opened in the editor stack.", "response": "def is_file_opened(self, filename=None):\r\n        \"\"\"Return if filename is in the editor stack.\r\n\r\n        Args:\r\n            filename: Name of the file to search for.  If filename is None,\r\n                then checks if any file is open.\r\n\r\n        Returns:\r\n            True: If filename is None and a file is open.\r\n            False: If filename is None and no files are open.\r\n            None: If filename is not None and the file isn't found.\r\n            integer: Index of file name in editor stack.\r\n        \"\"\"\r\n        if filename is None:\r\n            # Is there any file opened?\r\n            return len(self.data) > 0\r\n        else:\r\n            return self.has_filename(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_index_from_filename(self, filename):\r\n        filenames = [d.filename for d in self.data]\r\n        return filenames.index(filename)", "response": "Returns the position index of a file in the tab bar of the editorstack of the editorstack of its name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreordering editorstack. data so that the tab bar when tabs are moved.", "response": "def move_editorstack_data(self, start, end):\r\n        \"\"\"Reorder editorstack.data so it is synchronized with the tab bar when\r\n        tabs are moved.\"\"\"\r\n        if start < 0 or end < 0:\r\n            return\r\n        else:\r\n            steps = abs(end - start)\r\n            direction = (end-start) // steps  # +1 for right, -1 for left\r\n\r\n        data = self.data\r\n        self.blockSignals(True)\r\n\r\n        for i in range(start, end, direction):\r\n            data[i], data[i+direction] = data[i+direction], data[i]\r\n\r\n        self.blockSignals(False)\r\n        self.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close_file(self, index=None, force=False):\r\n        current_index = self.get_stack_index()\r\n        count = self.get_stack_count()\r\n\r\n        if index is None:\r\n            if count > 0:\r\n                index = current_index\r\n            else:\r\n                self.find_widget.set_editor(None)\r\n                return\r\n\r\n        new_index = None\r\n        if count > 1:\r\n            if current_index == index:\r\n                new_index = self._get_previous_file_index()\r\n            else:\r\n                new_index = current_index\r\n\r\n        is_ok = force or self.save_if_changed(cancelable=True, index=index)\r\n        if is_ok:\r\n            finfo = self.data[index]\r\n            self.threadmanager.close_threads(finfo)\r\n            # Removing editor reference from outline explorer settings:\r\n            if self.outlineexplorer is not None:\r\n                self.outlineexplorer.remove_editor(finfo.editor.oe_proxy)\r\n\r\n            filename = self.data[index].filename\r\n            self.remove_from_data(index)\r\n            finfo.editor.notify_close()\r\n\r\n            # We pass self object ID as a QString, because otherwise it would\r\n            # depend on the platform: long for 64bit, int for 32bit. Replacing\r\n            # by long all the time is not working on some 32bit platforms\r\n            # (see Issue 1094, Issue 1098)\r\n            self.sig_close_file.emit(str(id(self)), filename)\r\n\r\n            self.opened_files_list_changed.emit()\r\n            self.update_code_analysis_actions.emit()\r\n            self._refresh_outlineexplorer()\r\n            self.refresh_file_dependent_actions.emit()\r\n            self.update_plugin_title.emit()\r\n\r\n            editor = self.get_current_editor()\r\n            if editor:\r\n                editor.setFocus()\r\n\r\n            if new_index is not None:\r\n                if index < new_index:\r\n                    new_index -= 1\r\n                self.set_stack_index(new_index)\r\n\r\n            self.add_last_closed_file(finfo.filename)\r\n\r\n        if self.get_stack_count() == 0 and self.create_new_file_if_empty:\r\n            self.sig_new_file[()].emit()\r\n            return False\r\n        self.__modify_stack_title()\r\n        return is_ok", "response": "Close file (index=None -> close current file)\r\n        Keep current file index unchanged (if current file\r\n        that is being closed)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef poll_open_file_languages(self):\r\n        languages = []\r\n        for index in range(self.get_stack_count()):\r\n            languages.append(\r\n                self.tabs.widget(index).language.lower())\r\n        return set(languages)", "response": "Get list of current opened files languages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notify_server_ready(self, language, config):\r\n        for index in range(self.get_stack_count()):\r\n            editor = self.tabs.widget(index)\r\n            if editor.language.lower() == language:\r\n                editor.start_lsp_services(config)", "response": "Notify language server availability to code editors."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses all files opened to the right", "response": "def close_all_right(self):\r\n        \"\"\" Close all files opened to the right \"\"\"\r\n        num = self.get_stack_index()\r\n        n = self.get_stack_count()\r\n        for i in range(num, n-1):\r\n            self.close_file(num+1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose all files but the current one", "response": "def close_all_but_this(self):\r\n        \"\"\"Close all files but the current one\"\"\"\r\n        self.close_all_right()\r\n        for i in range(0, self.get_stack_count()-1  ):\r\n            self.close_file(0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting open tabs alphabetically.", "response": "def sort_file_tabs_alphabetically(self):\r\n        \"\"\"Sort open tabs alphabetically.\"\"\"\r\n        while self.sorted() is False:\r\n            for i in range(0, self.tabs.tabBar().count()):\r\n                if(self.tabs.tabBar().tabText(i) >\r\n                        self.tabs.tabBar().tabText(i + 1)):\r\n                    self.tabs.tabBar().moveTab(i, i + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new entry to the last closed file list.", "response": "def add_last_closed_file(self, fname):\r\n        \"\"\"Add to last closed file list.\"\"\"\r\n        if fname in self.last_closed_files:\r\n            self.last_closed_files.remove(fname)\r\n        self.last_closed_files.insert(0, fname)\r\n        if len(self.last_closed_files) > 10:\r\n            self.last_closed_files.pop(-1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nask user to save file if modified.", "response": "def save_if_changed(self, cancelable=False, index=None):\r\n        \"\"\"Ask user to save file if modified.\r\n\r\n        Args:\r\n            cancelable: Show Cancel button.\r\n            index: File to check for modification.\r\n\r\n        Returns:\r\n            False when save() fails or is cancelled.\r\n            True when save() is successful, there are no modifications,\r\n                or user selects No or NoToAll.\r\n\r\n        This function controls the message box prompt for saving\r\n        changed files.  The actual save is performed in save() for\r\n        each index processed. This function also removes autosave files\r\n        corresponding to files the user chooses not to save.\r\n        \"\"\"\r\n        if index is None:\r\n            indexes = list(range(self.get_stack_count()))\r\n        else:\r\n            indexes = [index]\r\n        buttons = QMessageBox.Yes | QMessageBox.No\r\n        if cancelable:\r\n            buttons |= QMessageBox.Cancel\r\n        unsaved_nb = 0\r\n        for index in indexes:\r\n            if self.data[index].editor.document().isModified():\r\n                unsaved_nb += 1\r\n        if not unsaved_nb:\r\n            # No file to save\r\n            return True\r\n        if unsaved_nb > 1:\r\n            buttons |= QMessageBox.YesToAll | QMessageBox.NoToAll\r\n        yes_all = no_all = False\r\n        for index in indexes:\r\n            self.set_stack_index(index)\r\n            finfo = self.data[index]\r\n            if finfo.filename == self.tempfile_path or yes_all:\r\n                if not self.save(index):\r\n                    return False\r\n            elif no_all:\r\n                self.autosave.remove_autosave_file(finfo)\r\n            elif (finfo.editor.document().isModified() and\r\n                  self.save_dialog_on_tests):\r\n\r\n                self.msgbox = QMessageBox(\r\n                        QMessageBox.Question,\r\n                        self.title,\r\n                        _(\"<b>%s</b> has been modified.\"\r\n                          \"<br>Do you want to save changes?\"\r\n                         ) % osp.basename(finfo.filename),\r\n                          buttons,\r\n                          parent=self)\r\n\r\n                answer = self.msgbox.exec_()\r\n                if answer == QMessageBox.Yes:\r\n                    if not self.save(index):\r\n                        return False\r\n                elif answer == QMessageBox.No:\r\n                    self.autosave.remove_autosave_file(finfo)\r\n                elif answer == QMessageBox.YesToAll:\r\n                    if not self.save(index):\r\n                        return False\r\n                    yes_all = True\r\n                elif answer == QMessageBox.NoToAll:\r\n                    self.autosave.remove_autosave_file(finfo)\r\n                    no_all = True\r\n                elif answer == QMessageBox.Cancel:\r\n                    return False\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the text of the file to the specified file.", "response": "def _write_to_file(self, fileinfo, filename):\r\n        \"\"\"Low-level function for writing text of editor to file.\r\n\r\n        Args:\r\n            fileinfo: FileInfo object associated to editor to be saved\r\n            filename: str with filename to save to\r\n\r\n        This is a low-level function that only saves the text to file in the\r\n        correct encoding without doing any error handling.\r\n        \"\"\"\r\n        txt = to_text_string(fileinfo.editor.get_text_with_eol())\r\n        fileinfo.encoding = encoding.write(txt, filename, fileinfo.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, index=None, force=False):\r\n        if index is None:\r\n            # Save the currently edited file\r\n            if not self.get_stack_count():\r\n                return\r\n            index = self.get_stack_index()\r\n\r\n        finfo = self.data[index]\r\n        if not (finfo.editor.document().isModified() or\r\n                finfo.newly_created) and not force:\r\n            return True\r\n        if not osp.isfile(finfo.filename) and not force:\r\n            # File has not been saved yet\r\n            return self.save_as(index=index)\r\n        if self.always_remove_trailing_spaces:\r\n            self.remove_trailing_spaces(index)\r\n        if self.convert_eol_on_save:\r\n            # hack to account for the fact that the config file saves\r\n            # CR/LF/CRLF while set_os_eol_chars wants the os.name value.\r\n            osname_lookup = {'LF': 'posix', 'CRLF': 'nt', 'CR': 'mac'}\r\n            osname = osname_lookup[self.convert_eol_on_save_to]\r\n            self.set_os_eol_chars(osname=osname)\r\n        try:\r\n            self._write_to_file(finfo, finfo.filename)\r\n            self.autosave.remove_autosave_file(finfo)\r\n            finfo.newly_created = False\r\n            self.encoding_changed.emit(finfo.encoding)\r\n            finfo.lastmodified = QFileInfo(finfo.filename).lastModified()\r\n\r\n            # We pass self object ID as a QString, because otherwise it would\r\n            # depend on the platform: long for 64bit, int for 32bit. Replacing\r\n            # by long all the time is not working on some 32bit platforms\r\n            # (see Issue 1094, Issue 1098)\r\n            # The filename is passed instead of an index in case the tabs\r\n            # have been rearranged (see issue 5703).\r\n            self.file_saved.emit(str(id(self)),\r\n                                 finfo.filename, finfo.filename)\r\n\r\n            finfo.editor.document().setModified(False)\r\n            finfo.editor.document().changed_since_autosave = False\r\n            self.modification_changed(index=index)\r\n            self.analyze_script(index)\r\n\r\n            #XXX CodeEditor-only: re-scan the whole text to rebuild outline\r\n            # explorer data from scratch (could be optimized because\r\n            # rehighlighting text means searching for all syntax coloring\r\n            # patterns instead of only searching for class/def patterns which\r\n            # would be sufficient for outline explorer data.\r\n            finfo.editor.rehighlight()\r\n\r\n            self._refresh_outlineexplorer(index)\r\n\r\n            finfo.editor.notify_save()\r\n            return True\r\n        except EnvironmentError as error:\r\n            self.msgbox = QMessageBox(\r\n                    QMessageBox.Critical,\r\n                    _(\"Save Error\"),\r\n                    _(\"<b>Unable to save file '%s'</b>\"\r\n                      \"<br><br>Error message:<br>%s\"\r\n                      ) % (osp.basename(finfo.filename),\r\n                                        str(error)),\r\n                    parent=self)\r\n            self.msgbox.exec_()\r\n            return False", "response": "Write text of editor to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a file was just saved in another editorstack.", "response": "def file_saved_in_other_editorstack(self, original_filename, filename):\r\n        \"\"\"\r\n        File was just saved in another editorstack, let's synchronize!\r\n        This avoids file being automatically reloaded.\r\n\r\n        The original filename is passed instead of an index in case the tabs\r\n        on the editor stacks were moved and are now in a different order - see\r\n        issue 5703.\r\n        Filename is passed in case file was just saved as another name.\r\n        \"\"\"\r\n        index = self.has_filename(original_filename)\r\n        if index is None:\r\n            return\r\n        finfo = self.data[index]\r\n        finfo.newly_created = False\r\n        finfo.filename = to_text_string(filename)\r\n        finfo.lastmodified = QFileInfo(finfo.filename).lastModified()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_savename(self, original_filename):\r\n        if self.edit_filetypes is None:\r\n            self.edit_filetypes = get_edit_filetypes()\r\n        if self.edit_filters is None:\r\n            self.edit_filters = get_edit_filters()\r\n\r\n        # Don't use filters on KDE to not make the dialog incredible\r\n        # slow\r\n        # Fixes issue 4156\r\n        if is_kde_desktop() and not is_anaconda():\r\n            filters = ''\r\n            selectedfilter = ''\r\n        else:\r\n            filters = self.edit_filters\r\n            selectedfilter = get_filter(self.edit_filetypes,\r\n                                        osp.splitext(original_filename)[1])\r\n\r\n        self.redirect_stdio.emit(False)\r\n        filename, _selfilter = getsavefilename(self, _(\"Save file\"),\r\n                                    original_filename,\r\n                                    filters=filters,\r\n                                    selectedfilter=selectedfilter,\r\n                                    options=QFileDialog.HideNameFilterDetails)\r\n        self.redirect_stdio.emit(True)\r\n        if filename:\r\n            return osp.normpath(filename)\r\n        return None", "response": "Select a name to save a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a new file as...", "response": "def save_as(self, index=None):\r\n        \"\"\"Save file as...\r\n\r\n        Args:\r\n            index: self.data index for the file to save.\r\n\r\n        Returns:\r\n            False if no file name was selected or if save() was unsuccessful.\r\n            True is save() was successful.\r\n\r\n        Gets the new file name from select_savename().  If no name is chosen,\r\n        then the save_as() aborts.  Otherwise, the current stack is checked\r\n        to see if the selected name already exists and, if so, then the tab\r\n        with that name is closed.\r\n\r\n        The current stack (self.data) and current tabs are updated with the\r\n        new name and other file info.  The text is written with the new\r\n        name using save() and the name change is propagated to the other stacks\r\n        via the file_renamed_in_data signal.\r\n        \"\"\"\r\n        if index is None:\r\n            # Save the currently edited file\r\n            index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        # The next line is necessary to avoid checking if the file exists\r\n        # While running __check_file_status\r\n        # See issues 3678 and 3026\r\n        finfo.newly_created = True\r\n        original_filename = finfo.filename\r\n        filename = self.select_savename(original_filename)\r\n        if filename:\r\n            ao_index = self.has_filename(filename)\r\n            # Note: ao_index == index --> saving an untitled file\r\n            if ao_index is not None and ao_index != index:\r\n                if not self.close_file(ao_index):\r\n                    return\r\n                if ao_index < index:\r\n                    index -= 1\r\n\r\n            new_index = self.rename_in_data(original_filename,\r\n                                            new_filename=filename)\r\n\r\n            # We pass self object ID as a QString, because otherwise it would\r\n            # depend on the platform: long for 64bit, int for 32bit. Replacing\r\n            # by long all the time is not working on some 32bit platforms\r\n            # (see Issue 1094, Issue 1098)\r\n            self.file_renamed_in_data.emit(str(id(self)),\r\n                                           original_filename, filename)\r\n\r\n            ok = self.save(index=new_index, force=True)\r\n            self.refresh(new_index)\r\n            self.set_stack_index(new_index)\r\n            return ok\r\n        else:\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_copy_as(self, index=None):\r\n        if index is None:\r\n            # Save the currently edited file\r\n            index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        original_filename = finfo.filename\r\n        filename = self.select_savename(original_filename)\r\n        if filename:\r\n            ao_index = self.has_filename(filename)\r\n            # Note: ao_index == index --> saving an untitled file\r\n            if ao_index is not None and ao_index != index:\r\n                if not self.close_file(ao_index):\r\n                    return\r\n                if ao_index < index:\r\n                    index -= 1\r\n            try:\r\n                self._write_to_file(finfo, filename)\r\n                # open created copy file\r\n                self.plugin_load.emit(filename)\r\n                return True\r\n            except EnvironmentError as error:\r\n                self.msgbox = QMessageBox(\r\n                    QMessageBox.Critical,\r\n                    _(\"Save Error\"),\r\n                    _(\"<b>Unable to save file '%s'</b>\"\r\n                      \"<br><br>Error message:<br>%s\"\r\n                      ) % (osp.basename(finfo.filename),\r\n                                        str(error)),\r\n                    parent=self)\r\n                self.msgbox.exec_()\r\n        else:\r\n            return False", "response": "Save a copy of a file as..."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_all(self):\r\n        for index in range(self.get_stack_count()):\r\n            if self.data[index].editor.document().isModified():\r\n                self.save(index)", "response": "Save all opened files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nanalyzing current script with todos", "response": "def analyze_script(self, index=None):\r\n        \"\"\"Analyze current script with todos\"\"\"\r\n        if self.is_analysis_done:\r\n            return\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        if self.data:\r\n            finfo = self.data[index]\r\n            if self.todolist_enabled:\r\n                finfo.run_todo_finder()\r\n        self.is_analysis_done = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_todo_results(self, filename, todo_results):\r\n        index = self.has_filename(filename)\r\n        if index is None:\r\n            return\r\n        self.data[index].set_todo_results(todo_results)", "response": "Synchronize todo results between editorstacks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstack index has changed", "response": "def current_changed(self, index):\r\n        \"\"\"Stack index has changed\"\"\"\r\n#        count = self.get_stack_count()\r\n#        for btn in (self.filelist_btn, self.previous_btn, self.next_btn):\r\n#            btn.setEnabled(count > 1)\r\n\r\n        editor = self.get_current_editor()\r\n        if editor.lsp_ready and not editor.document_opened:\r\n            editor.document_did_open()\r\n        if index != -1:\r\n            editor.setFocus()\r\n            logger.debug(\"Set focus to: %s\" % editor.filename)\r\n        else:\r\n            self.reset_statusbar.emit()\r\n        self.opened_files_list_changed.emit()\r\n\r\n        self.stack_history.refresh()\r\n        self.stack_history.remove_and_append(index)\r\n\r\n        # Needed to avoid an error generated after moving/renaming\r\n        # files outside Spyder while in debug mode.\r\n        # See issue 8749.\r\n        try:\r\n            logger.debug(\"Current changed: %d - %s\" %\r\n                         (index, self.data[index].editor.filename))\r\n        except IndexError:\r\n            pass\r\n\r\n        self.update_plugin_title.emit()\r\n        if editor is not None:\r\n            # Needed in order to handle the close of files open in a directory\r\n            # that has been renamed. See issue 5157\r\n            try:\r\n                self.current_file_changed.emit(self.data[index].filename,\r\n                                               editor.get_position('cursor'))\r\n            except IndexError:\r\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tab_navigation_mru(self, forward=True):\r\n        self.tabs_switcher = TabSwitcherWidget(self, self.stack_history,\r\n                                               self.tabs)\r\n        self.tabs_switcher.show()\r\n        self.tabs_switcher.select_row(1 if forward else -1)\r\n        self.tabs_switcher.setFocus()", "response": "Tab navigation with most recently used behaviour."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef focus_changed(self):\r\n        fwidget = QApplication.focusWidget()\r\n        for finfo in self.data:\r\n            if fwidget is finfo.editor:\r\n                self.refresh()\r\n        self.editor_focus_changed.emit()", "response": "Editor focus has changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrefreshes the outline explorer panel", "response": "def _refresh_outlineexplorer(self, index=None, update=True, clear=False):\r\n        \"\"\"Refresh outline explorer panel\"\"\"\r\n        oe = self.outlineexplorer\r\n        if oe is None:\r\n            return\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        if self.data:\r\n            finfo = self.data[index]\r\n            oe.setEnabled(True)\r\n            if finfo.editor.oe_proxy is None:\r\n                finfo.editor.oe_proxy = OutlineExplorerProxyEditor(\r\n                    finfo.editor, finfo.filename)\r\n            oe.set_current_editor(finfo.editor.oe_proxy,\r\n                                  update=update, clear=clear)\r\n            if index != self.get_stack_index():\r\n                # The last file added to the outline explorer is not the\r\n                # currently focused one in the editor stack. Therefore,\r\n                # we need to force a refresh of the outline explorer to set\r\n                # the current editor to the currently focused one in the\r\n                # editor stack. See PR #8015.\r\n                self._refresh_outlineexplorer(update=False)\r\n                return\r\n        self._sync_outlineexplorer_file_order()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sync_outlineexplorer_file_order(self):\r\n        if self.outlineexplorer is not None:\r\n            self.outlineexplorer.treewidget.set_editor_ids_order(\r\n                [finfo.editor.get_document_id() for finfo in self.data])", "response": "Order the root file items of the outline explorer as in the current tabbar."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __refresh_statusbar(self, index):\r\n        finfo = self.data[index]\r\n        self.encoding_changed.emit(finfo.encoding)\r\n        # Refresh cursor position status:\r\n        line, index = finfo.editor.get_cursor_line_column()\r\n        self.sig_editor_cursor_position_changed.emit(line, index)", "response": "Refreshes the statusbar widgets with the current index"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __check_file_status(self, index):\r\n        if self.__file_status_flag:\r\n            # Avoid infinite loop: when the QMessageBox.question pops, it\r\n            # gets focus and then give it back to the CodeEditor instance,\r\n            # triggering a refresh cycle which calls this method\r\n            return\r\n        self.__file_status_flag = True\r\n\r\n        finfo = self.data[index]\r\n        name = osp.basename(finfo.filename)\r\n\r\n        if finfo.newly_created:\r\n            # File was just created (not yet saved): do nothing\r\n            # (do not return because of the clean-up at the end of the method)\r\n            pass\r\n\r\n        elif not osp.isfile(finfo.filename):\r\n            # File doesn't exist (removed, moved or offline):\r\n            self.msgbox = QMessageBox(\r\n                    QMessageBox.Warning,\r\n                    self.title,\r\n                    _(\"<b>%s</b> is unavailable \"\r\n                      \"(this file may have been removed, moved \"\r\n                      \"or renamed outside Spyder).\"\r\n                      \"<br>Do you want to close it?\") % name,\r\n                    QMessageBox.Yes | QMessageBox.No,\r\n                    self)\r\n            answer = self.msgbox.exec_()\r\n            if answer == QMessageBox.Yes:\r\n                self.close_file(index)\r\n            else:\r\n                finfo.newly_created = True\r\n                finfo.editor.document().setModified(True)\r\n                self.modification_changed(index=index)\r\n\r\n        else:\r\n            # Else, testing if it has been modified elsewhere:\r\n            lastm = QFileInfo(finfo.filename).lastModified()\r\n            if to_text_string(lastm.toString()) \\\r\n               != to_text_string(finfo.lastmodified.toString()):\r\n                if finfo.editor.document().isModified():\r\n                    self.msgbox = QMessageBox(\r\n                        QMessageBox.Question,\r\n                        self.title,\r\n                        _(\"<b>%s</b> has been modified outside Spyder.\"\r\n                          \"<br>Do you want to reload it and lose all \"\r\n                          \"your changes?\") % name,\r\n                        QMessageBox.Yes | QMessageBox.No,\r\n                        self)\r\n                    answer = self.msgbox.exec_()\r\n                    if answer == QMessageBox.Yes:\r\n                        self.reload(index)\r\n                    else:\r\n                        finfo.lastmodified = lastm\r\n                else:\r\n                    self.reload(index)\r\n\r\n        # Finally, resetting temporary flag:\r\n        self.__file_status_flag = False", "response": "Check if a file has been changed in any way outside Spyder"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self, index=None):\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        # Set current editor\r\n        if self.get_stack_count():\r\n            index = self.get_stack_index()\r\n            finfo = self.data[index]\r\n            editor = finfo.editor\r\n            editor.setFocus()\r\n            self._refresh_outlineexplorer(index, update=False)\r\n            self.__refresh_statusbar(index)\r\n            self.__refresh_readonly(index)\r\n            self.__check_file_status(index)\r\n            self.__modify_stack_title()\r\n            self.update_plugin_title.emit()\r\n        else:\r\n            editor = None\r\n        # Update the modification-state-dependent parameters\r\n        self.modification_changed()\r\n        # Update FindReplace binding\r\n        self.find_widget.set_editor(editor, refresh=False)", "response": "Refresh the tabwidget with the current index."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the tab title depending on the modification state of the current file.", "response": "def modification_changed(self, state=None, index=None, editor_id=None):\r\n        \"\"\"\r\n        Current editor's modification state has changed\r\n        --> change tab title depending on new modification state\r\n        --> enable/disable save/save all actions\r\n        \"\"\"\r\n        if editor_id is not None:\r\n            for index, _finfo in enumerate(self.data):\r\n                if id(_finfo.editor) == editor_id:\r\n                    break\r\n        # This must be done before refreshing save/save all actions:\r\n        # (otherwise Save/Save all actions will always be enabled)\r\n        self.opened_files_list_changed.emit()\r\n        # --\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        if index == -1:\r\n            return\r\n        finfo = self.data[index]\r\n        if state is None:\r\n            state = finfo.editor.document().isModified() or finfo.newly_created\r\n        self.set_stack_title(index, state)\r\n        # Toggle save/save all actions state\r\n        self.save_action.setEnabled(state)\r\n        self.refresh_save_all_action.emit()\r\n        # Refreshing eol mode\r\n        eol_chars = finfo.editor.get_line_separator()\r\n        self.refresh_eol_chars(eol_chars)\r\n        self.stack_history.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreloading file from disk", "response": "def reload(self, index):\r\n        \"\"\"Reload file from disk\"\"\"\r\n        finfo = self.data[index]\r\n        txt, finfo.encoding = encoding.read(finfo.filename)\r\n        finfo.lastmodified = QFileInfo(finfo.filename).lastModified()\r\n        position = finfo.editor.get_position('cursor')\r\n        finfo.editor.set_text(txt)\r\n        finfo.editor.document().setModified(False)\r\n        finfo.editor.document().changed_since_autosave = False\r\n        finfo.editor.set_cursor_position(position)\r\n\r\n        #XXX CodeEditor-only: re-scan the whole text to rebuild outline\r\n        # explorer data from scratch (could be optimized because\r\n        # rehighlighting text means searching for all syntax coloring\r\n        # patterns instead of only searching for class/def patterns which\r\n        # would be sufficient for outline explorer data.\r\n        finfo.editor.rehighlight()\r\n\r\n        self._refresh_outlineexplorer(index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef revert(self):\r\n        index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        filename = finfo.filename\r\n        if finfo.editor.document().isModified():\r\n            self.msgbox = QMessageBox(\r\n                    QMessageBox.Warning,\r\n                    self.title,\r\n                    _(\"All changes to <b>%s</b> will be lost.\"\r\n                      \"<br>Do you want to revert file from disk?\"\r\n                      ) % osp.basename(filename),\r\n                    QMessageBox.Yes | QMessageBox.No,\r\n                    self)\r\n            answer = self.msgbox.exec_()\r\n            if answer != QMessageBox.Yes:\r\n                return\r\n        self.reload(index)", "response": "Revert file from disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_new_editor(self, fname, enc, txt, set_current, new=False,\r\n                          cloned_from=None, add_where='end'):\r\n        \"\"\"\r\n        Create a new editor instance\r\n        Returns finfo object (instead of editor as in previous releases)\r\n        \"\"\"\r\n        editor = codeeditor.CodeEditor(self)\r\n        editor.go_to_definition.connect(\r\n            lambda fname, line, column: self.sig_go_to_definition.emit(\r\n                fname, line, column))\r\n\r\n        finfo = FileInfo(fname, enc, editor, new, self.threadmanager)\r\n\r\n        self.add_to_data(finfo, set_current, add_where)\r\n        finfo.send_to_help.connect(self.send_to_help)\r\n        finfo.todo_results_changed.connect(\r\n                                      lambda: self.todo_results_changed.emit())\r\n        finfo.edit_goto.connect(lambda fname, lineno, name:\r\n                                self.edit_goto.emit(fname, lineno, name))\r\n        finfo.sig_save_bookmarks.connect(lambda s1, s2:\r\n                                         self.sig_save_bookmarks.emit(s1, s2))\r\n        editor.sig_run_selection.connect(self.run_selection)\r\n        editor.sig_run_cell.connect(self.run_cell)\r\n        editor.sig_run_cell_and_advance.connect(self.run_cell_and_advance)\r\n        editor.sig_re_run_last_cell.connect(self.re_run_last_cell)\r\n        editor.sig_new_file.connect(self.sig_new_file.emit)\r\n        editor.sig_breakpoints_saved.connect(self.sig_breakpoints_saved)\r\n        language = get_file_language(fname, txt)\r\n        editor.setup_editor(\r\n                linenumbers=self.linenumbers_enabled,\r\n                show_blanks=self.blanks_enabled,\r\n                scroll_past_end=self.scrollpastend_enabled,\r\n                edge_line=self.edgeline_enabled,\r\n                edge_line_columns=self.edgeline_columns, language=language,\r\n                markers=self.has_markers(), font=self.default_font,\r\n                color_scheme=self.color_scheme,\r\n                wrap=self.wrap_enabled, tab_mode=self.tabmode_enabled,\r\n                intelligent_backspace=self.intelligent_backspace_enabled,\r\n                highlight_current_line=self.highlight_current_line_enabled,\r\n                highlight_current_cell=self.highlight_current_cell_enabled,\r\n                occurrence_highlighting=self.occurrence_highlighting_enabled,\r\n                occurrence_timeout=self.occurrence_highlighting_timeout,\r\n                close_parentheses=self.close_parentheses_enabled,\r\n                close_quotes=self.close_quotes_enabled,\r\n                add_colons=self.add_colons_enabled,\r\n                auto_unindent=self.auto_unindent_enabled,\r\n                indent_chars=self.indent_chars,\r\n                tab_stop_width_spaces=self.tab_stop_width_spaces,\r\n                cloned_from=cloned_from,\r\n                filename=fname,\r\n                show_class_func_dropdown=self.show_class_func_dropdown,\r\n                indent_guides=self.indent_guides)\r\n        if cloned_from is None:\r\n            editor.set_text(txt)\r\n            editor.document().setModified(False)\r\n            editor.document().changed_since_autosave = False\r\n        finfo.text_changed_at.connect(\r\n                                    lambda fname, position:\r\n                                    self.text_changed_at.emit(fname, position))\r\n        editor.sig_cursor_position_changed.connect(\r\n                                           self.editor_cursor_position_changed)\r\n        editor.textChanged.connect(self.start_stop_analysis_timer)\r\n        editor.sig_perform_lsp_request.connect(\r\n            lambda lang, method, params: self.perform_lsp_request.emit(\r\n                lang, method, params))\r\n        editor.modificationChanged.connect(\r\n                     lambda state: self.modification_changed(state,\r\n                                                    editor_id=id(editor)))\r\n        editor.focus_in.connect(self.focus_changed)\r\n        editor.zoom_in.connect(lambda: self.zoom_in.emit())\r\n        editor.zoom_out.connect(lambda: self.zoom_out.emit())\r\n        editor.zoom_reset.connect(lambda: self.zoom_reset.emit())\r\n        editor.sig_eol_chars_changed.connect(lambda eol_chars: self.refresh_eol_chars(eol_chars))\r\n\r\n        self.find_widget.set_editor(editor)\r\n\r\n        self.refresh_file_dependent_actions.emit()\r\n        self.modification_changed(index=self.data.index(finfo))\r\n\r\n        # Needs to reset the highlighting on startup in case the PygmentsSH\r\n        # is in use\r\n        editor.run_pygments_highlighter()\r\n        options = {\r\n            'language': editor.language,\r\n            'filename': editor.filename,\r\n            'codeeditor': editor\r\n        }\r\n        self.sig_open_file.emit(options)\r\n        if self.get_stack_index() == 0:\r\n            self.current_changed(0)\r\n\r\n        return finfo", "response": "Create a new file editor instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a message to the help widget", "response": "def send_to_help(self, name, signature, force=False):\r\n        \"\"\"qstr1: obj_text, qstr2: argpspec, qstr3: note, qstr4: doc_text\"\"\"\r\n        if not force and not self.help_enabled:\r\n            return\r\n        if self.help is not None \\\r\n          and (force or self.help.dockwidget.isVisible()):\r\n            signature = to_text_string(signature)\r\n            signature = unicodedata.normalize(\"NFKD\", signature)\r\n            parts = signature.split('\\n\\n')\r\n            definition = parts[0]\r\n            documentation = '\\n\\n'.join(parts[1:])\r\n            args = ''\r\n            if '(' in definition:\r\n                args = definition[definition.find('('):]\r\n\r\n            doc = {'obj_text': '', 'name': name,\r\n                   'argspec': args, 'note': '',\r\n                   'docstring': documentation}\r\n            self.help.set_editor_doc(doc, force_refresh=force)\r\n            editor = self.get_current_editor()\r\n            editor.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating new file with given filename encoding and text.", "response": "def new(self, filename, encoding, text, default_content=False,\r\n            empty=False):\r\n        \"\"\"\r\n        Create new filename with *encoding* and *text*\r\n        \"\"\"\r\n        finfo = self.create_new_editor(filename, encoding, text,\r\n                                       set_current=False, new=True)\r\n        finfo.editor.set_cursor_position('eof')\r\n        if not empty:\r\n            finfo.editor.insert_text(os.linesep)\r\n        if default_content:\r\n            finfo.default = True\r\n            finfo.editor.document().setModified(False)\r\n        return finfo"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a file and create an editor instance and return it", "response": "def load(self, filename, set_current=True, add_where='end'):\r\n        \"\"\"\r\n        Load filename, create an editor instance and return it\r\n        *Warning* This is loading file, creating editor but not executing\r\n        the source code analysis -- the analysis must be done by the editor\r\n        plugin (in case multiple editorstack instances are handled)\r\n        \"\"\"\r\n        filename = osp.abspath(to_text_string(filename))\r\n        self.starting_long_process.emit(_(\"Loading %s...\") % filename)\r\n        text, enc = encoding.read(filename)\r\n        finfo = self.create_new_editor(filename, enc, text, set_current,\r\n                                       add_where=add_where)\r\n        index = self.data.index(finfo)\r\n        self._refresh_outlineexplorer(index, update=True)\r\n        self.ending_long_process.emit(\"\")\r\n        if self.isVisible() and self.checkeolchars_enabled \\\r\n           and sourcecode.has_mixed_eol_chars(text):\r\n            name = osp.basename(filename)\r\n            self.msgbox = QMessageBox(\r\n                    QMessageBox.Warning,\r\n                    self.title,\r\n                    _(\"<b>%s</b> contains mixed end-of-line \"\r\n                      \"characters.<br>Spyder will fix this \"\r\n                      \"automatically.\") % name,\r\n                    QMessageBox.Ok,\r\n                    self)\r\n            self.msgbox.exec_()\r\n            self.set_os_eol_chars(index)\r\n        self.is_analysis_done = False\r\n        return finfo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the EOL character(s) based on the operating system.", "response": "def set_os_eol_chars(self, index=None, osname=None):\r\n        \"\"\"Sets the EOL character(s) based on the operating system.\r\n\r\n        If `osname` is None, then the default line endings for the current\r\n        operating system (`os.name` value) will be used.\r\n\r\n        `osname` can be one of:\r\n            ('posix', 'nt', 'java')\r\n        \"\"\"\r\n        if osname is None:\r\n            osname = os.name\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        eol_chars = sourcecode.get_eol_chars_from_os_name(osname)\r\n        finfo.editor.set_eol_chars(eol_chars)\r\n        finfo.editor.document().setModified(True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_trailing_spaces(self, index=None):\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        finfo.editor.remove_trailing_spaces()", "response": "Remove trailing spaces from the current tab."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces tab characters by spaces", "response": "def fix_indentation(self, index=None):\r\n        \"\"\"Replace tab characters by spaces\"\"\"\r\n        if index is None:\r\n            index = self.get_stack_index()\r\n        finfo = self.data[index]\r\n        finfo.editor.fix_indentation()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_selection(self):\r\n        text = self.get_current_editor().get_selection_as_executable_code()\r\n        if text:\r\n            self.exec_in_extconsole.emit(text.rstrip(), self.focus_to_editor)\r\n            return\r\n        editor = self.get_current_editor()\r\n        line = editor.get_current_line()\r\n        text = line.lstrip()\r\n        if text:\r\n            self.exec_in_extconsole.emit(text, self.focus_to_editor)\r\n        if editor.is_cursor_on_last_line() and text:\r\n            editor.append(editor.get_line_separator())\r\n        editor.move_cursor_to_next('line', 'down')", "response": "Runs selected text or current line in console."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadvance to the next cell.", "response": "def advance_cell(self, reverse=False):\r\n        \"\"\"Advance to the next cell.\r\n\r\n        reverse = True --> go to previous cell.\r\n        \"\"\"\r\n        if not reverse:\r\n            move_func = self.get_current_editor().go_to_next_cell\r\n        else:\r\n            move_func = self.get_current_editor().go_to_previous_cell\r\n\r\n        if self.focus_to_editor:\r\n            move_func()\r\n        else:\r\n            term = QApplication.focusWidget()\r\n            move_func()\r\n            term.setFocus()\r\n            term = QApplication.focusWidget()\r\n            move_func()\r\n            term.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef re_run_last_cell(self):\r\n        text, line = (self.get_current_editor()\r\n                      .get_last_cell_as_executable_code())\r\n        self._run_cell_text(text, line)", "response": "Run the previous cell again."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _run_cell_text(self, text, line):\r\n        finfo = self.get_current_finfo()\r\n        editor = self.get_current_editor()\r\n        oe_data = editor.highlighter.get_outlineexplorer_data()\r\n        try:\r\n            cell_name = oe_data.get(line-1).def_name\r\n        except AttributeError:\r\n            cell_name = ''\r\n        if finfo.editor.is_python() and text:\r\n            self.run_cell_in_ipyclient.emit(text, cell_name,\r\n                                            finfo.filename,\r\n                                            self.run_cell_copy)\r\n        editor.setFocus()", "response": "Run cell code in the console."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dragEnterEvent(self, event):\r\n        source = event.mimeData()\r\n        # The second check is necessary on Windows, where source.hasUrls()\r\n        # can return True but source.urls() is []\r\n        # The third check is needed since a file could be dropped from\r\n        # compressed files. In Windows mimedata2url(source) returns None\r\n        # Fixes issue 5218\r\n        if source.hasUrls() and source.urls() and mimedata2url(source):\r\n            all_urls = mimedata2url(source)\r\n            text = [encoding.is_text_file(url) for url in all_urls]\r\n            if any(text):\r\n                event.acceptProposedAction()\r\n            else:\r\n                event.ignore()\r\n        elif source.hasText():\r\n            event.acceptProposedAction()\r\n        elif os.name == 'nt':\r\n            # This covers cases like dragging from compressed files,\r\n            # which can be opened by the Editor if they are plain\r\n            # text, but doesn't come with url info.\r\n            # Fixes Issue 2032\r\n            event.acceptProposedAction()\r\n        else:\r\n            event.ignore()", "response": "Reimplement Qt method\r\n            Inform Qt about the types of data that the widget accepts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split(self, orientation=Qt.Vertical):\r\n        self.setOrientation(orientation)\r\n        self.editorstack.set_orientation(orientation)\r\n        editorsplitter = EditorSplitter(self.parent(), self.plugin,\r\n                    self.menu_actions,\r\n                    register_editorstack_cb=self.register_editorstack_cb,\r\n                    unregister_editorstack_cb=self.unregister_editorstack_cb)\r\n        self.addWidget(editorsplitter)\r\n        editorsplitter.destroyed.connect(lambda: self.editorsplitter_closed())\r\n        current_editor = editorsplitter.editorstack.get_current_editor()\r\n        if current_editor is not None:\r\n            current_editor.setFocus()", "response": "Create and attach a new EditorSplitter to the current EditorSplitter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the editor stacks for this splitter and every first child.", "response": "def iter_editorstacks(self):\r\n        \"\"\"Return the editor stacks for this splitter and every first child.\r\n\r\n        Note: If a splitter contains more than one splitter as a direct\r\n              child, only the first child's editor stack is included.\r\n\r\n        Returns:\r\n            List of tuples containing (EditorStack instance, orientation).\r\n        \"\"\"\r\n        editorstacks = [(self.widget(0), self.orientation())]\r\n        if self.count() > 1:\r\n            editorsplitter = self.widget(1)\r\n            editorstacks += editorsplitter.iter_editorstacks()\r\n        return editorstacks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_layout_settings(self):\r\n        splitsettings = []\r\n        for editorstack, orientation in self.iter_editorstacks():\r\n            clines = []\r\n            cfname = ''\r\n            # XXX - this overrides value from the loop to always be False?\r\n            orientation = False\r\n            if hasattr(editorstack, 'data'):\r\n                clines = [finfo.editor.get_cursor_line_number()\r\n                          for finfo in editorstack.data]\r\n                cfname = editorstack.get_current_filename()\r\n            splitsettings.append((orientation == Qt.Vertical, cfname, clines))\r\n        return dict(hexstate=qbytearray_to_str(self.saveState()),\r\n                    sizes=self.sizes(), splitsettings=splitsettings)", "response": "Return the layout state for this splitter and its children."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestores the layout state for the splitter panels.", "response": "def set_layout_settings(self, settings, dont_goto=None):\r\n        \"\"\"Restore layout state for the splitter panels.\r\n\r\n        Apply the settings to restore a saved layout within the editor.  If\r\n        the splitsettings key doesn't exist, then return without restoring\r\n        any settings.\r\n\r\n        The current EditorSplitter (self) calls split() for each element\r\n        in split_settings, thus recreating the splitter panels from the saved\r\n        state.  split() also clones the editorstack, which is then\r\n        iterated over to restore the saved line numbers on each file.\r\n\r\n        The size and positioning of each splitter panel is restored from\r\n        hexstate.\r\n\r\n        Args:\r\n            settings: A dictionary with keys {hexstate, sizes, orientation}\r\n                    that define the layout for the EditorSplitter panels.\r\n            dont_goto: Defaults to None, which positions the cursor to the\r\n                    end of the editor.  If there's a value, positions the\r\n                    cursor on the saved line number for each editor.\r\n        \"\"\"\r\n        splitsettings = settings.get('splitsettings')\r\n        if splitsettings is None:\r\n            return\r\n        splitter = self\r\n        editor = None\r\n        for index, (is_vertical, cfname, clines) in enumerate(splitsettings):\r\n            if index > 0:\r\n                splitter.split(Qt.Vertical if is_vertical else Qt.Horizontal)\r\n                splitter = splitter.widget(1)\r\n            editorstack = splitter.widget(0)\r\n            for index, finfo in enumerate(editorstack.data):\r\n                editor = finfo.editor\r\n                # TODO: go_to_line is not working properly (the line it jumps\r\n                # to is not the corresponding to that file). This will be fixed\r\n                # in a future PR (which will fix issue #3857)\r\n                if dont_goto is not None:\r\n                    # skip go to line for first file because is already there\r\n                    pass\r\n                else:\r\n                    try:\r\n                        editor.go_to_line(clines[index])\r\n                    except IndexError:\r\n                        pass\r\n        hexstate = settings.get('hexstate')\r\n        if hexstate is not None:\r\n            self.restoreState( QByteArray().fromHex(\r\n                    str(hexstate).encode('utf-8')) )\r\n        sizes = settings.get('sizes')\r\n        if sizes is not None:\r\n            self.setSizes(sizes)\r\n        if editor is not None:\r\n            editor.clearFocus()\r\n            editor.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd toolbars to a menu.", "response": "def add_toolbars_to_menu(self, menu_title, actions):\r\n        \"\"\"Add toolbars to a menu.\"\"\"\r\n        # Six is the position of the view menu in menus list\r\n        # that you can find in plugins/editor.py setup_other_windows.\r\n        view_menu = self.menus[6]\r\n        if actions == self.toolbars and view_menu:\r\n            toolbars = []\r\n            for toolbar in self.toolbars:\r\n                action = toolbar.toggleViewAction()\r\n                toolbars.append(action)\r\n            add_actions(view_menu, toolbars)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the last visible toolbars from the. ini file.", "response": "def load_toolbars(self):\r\n        \"\"\"Loads the last visible toolbars from the .ini file.\"\"\"\r\n        toolbars_names = CONF.get('main', 'last_visible_toolbars', default=[])\r\n        if toolbars_names:\r\n            dic = {}\r\n            for toolbar in self.toolbars:\r\n                dic[toolbar.objectName()] = toolbar\r\n                toolbar.toggleViewAction().setChecked(False)\r\n                toolbar.setVisible(False)\r\n            for name in toolbars_names:\r\n                if name in dic:\r\n                    dic[name].toggleViewAction().setChecked(True)\r\n                    dic[name].setVisible(True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_saved_in_editorstack(self, editorstack_id_str,\r\n                                  original_filename, filename):\r\n        \"\"\"A file was saved in editorstack, this notifies others\"\"\"\r\n        for editorstack in self.editorstacks:\r\n            if str(id(editorstack)) != editorstack_id_str:\r\n                editorstack.file_saved_in_other_editorstack(original_filename,\r\n                                                            filename)", "response": "A file was saved in editorstack this notifies others"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_renamed_in_data_in_editorstack(self, editorstack_id_str,\r\n                                            original_filename, filename):\r\n        \"\"\"A file was renamed in data in editorstack, this notifies others\"\"\"\r\n        for editorstack in self.editorstacks:\r\n            if str(id(editorstack)) != editorstack_id_str:\r\n                editorstack.rename_in_data(original_filename, filename)", "response": "A file was renamed in data in editorstack this notifies others"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds in files callback", "response": "def findinfiles_callback(self):\r\n        \"\"\"Find in files callback\"\"\"\r\n        widget = QApplication.focusWidget()\r\n        if not self.ismaximized:\r\n            self.dockwidget.setVisible(True)\r\n            self.dockwidget.raise_()\r\n        text = ''\r\n        try:\r\n            if widget.has_selected_text():\r\n                text = widget.get_selected_text()\r\n        except AttributeError:\r\n            # This is not a text widget deriving from TextEditBaseWidget\r\n            pass\r\n        self.findinfiles.set_search_text(text)\r\n        if text:\r\n            self.findinfiles.find()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_plugin(self):\r\n        self.main.add_dockwidget(self)\r\n        self.findinfiles.result_browser.sig_edit_goto.connect(\r\n                                                         self.main.editor.load)\r\n        self.findinfiles.find_options.redirect_stdio.connect(\r\n                                        self.main.redirect_internalshell_stdio)\r\n        self.main.workingdirectory.refresh_findinfiles.connect(self.refreshdir)\r\n        self.main.projects.sig_project_loaded.connect(self.set_project_path)\r\n        self.main.projects.sig_project_closed.connect(self.unset_project_path)\r\n        self.main.editor.open_file_update.connect(self.set_current_opened_file)\r\n\r\n        findinfiles_action = create_action(\r\n                                   self, _(\"&Find in files\"),\r\n                                   icon=ima.icon('findf'),\r\n                                   triggered=self.switch_to_plugin,\r\n                                   shortcut=QKeySequence(self.shortcut),\r\n                                   context=Qt.WidgetShortcut,\r\n                                   tip=_(\"Search text in multiple files\"))\r\n\r\n        self.main.search_menu_actions += [MENU_SEPARATOR, findinfiles_action]\r\n        self.main.search_toolbar_actions += [MENU_SEPARATOR,\r\n                                             findinfiles_action]\r\n        self.refreshdir()", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef closing_plugin(self, cancelable=False):\r\n        self.findinfiles.closing_widget()  # stop search thread and clean-up\r\n        options = self.findinfiles.find_options.get_options(to_save=True)\r\n        if options is not None:\r\n            (search_text, text_re,\r\n             exclude, exclude_idx, exclude_re,\r\n             more_options, case_sensitive,\r\n             path_history) = options\r\n            hist_limit = 15\r\n            search_text = search_text[:hist_limit]\r\n            exclude = exclude[:hist_limit]\r\n            path_history = path_history[-hist_limit:]\r\n            self.set_option('search_text', search_text)\r\n            self.set_option('search_text_regexp', text_re)\r\n            self.set_option('exclude', exclude)\r\n            self.set_option('exclude_idx', exclude_idx)\r\n            self.set_option('exclude_regexp', exclude_re)\r\n            self.set_option('more_options', more_options)\r\n            self.set_option('case_sensitive', case_sensitive)\r\n            self.set_option('path_history', path_history)\r\n        return True", "response": "Perform actions before parent main window is closed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _draw_fold_region_background(self, block, painter):\n        r = FoldScope(block)\n        th = TextHelper(self.editor)\n        start, end = r.get_range(ignore_blank_lines=True)\n        if start > 0:\n            top = th.line_pos_from_number(start)\n        else:\n            top = 0\n        bottom = th.line_pos_from_number(end + 1)\n        h = bottom - top\n        if h == 0:\n            h = self.sizeHint().height()\n        w = self.sizeHint().width()\n        self._draw_rect(QRectF(0, top, w, h), painter)", "response": "Draw the fold region when the mouse is over and non collapsed\n        indicator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing the fold zone background rectangle using the current style primitive color.", "response": "def _draw_rect(self, rect, painter):\n        \"\"\"\n        Draw the background rectangle using the current style primitive color.\n\n        :param rect: The fold zone rect to draw\n\n        :param painter: The widget's painter.\n        \"\"\"\n        c = self.editor.sideareas_color\n        grad = QLinearGradient(rect.topLeft(),\n                                     rect.topRight())\n        if sys.platform == 'darwin':\n            grad.setColorAt(0, c.lighter(100))\n            grad.setColorAt(1, c.lighter(110))\n            outline = c.darker(110)\n        else:\n            grad.setColorAt(0, c.lighter(110))\n            grad.setColorAt(1, c.lighter(130))\n            outline = c.darker(100)\n        painter.fillRect(rect, grad)\n        painter.setPen(QPen(outline))\n        painter.drawLine(rect.topLeft() +\n                         QPointF(1, 0),\n                         rect.topRight() -\n                         QPointF(1, 0))\n        painter.drawLine(rect.bottomLeft() +\n                         QPointF(1, 0),\n                         rect.bottomRight() -\n                         QPointF(1, 0))\n        painter.drawLine(rect.topRight() +\n                         QPointF(0, 1),\n                         rect.bottomRight() -\n                         QPointF(0, 1))\n        painter.drawLine(rect.topLeft() +\n                         QPointF(0, 1),\n                         rect.bottomLeft() -\n                         QPointF(0, 1))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw the fold indicator.", "response": "def _draw_fold_indicator(self, top, mouse_over, collapsed, painter):\n        \"\"\"\n        Draw the fold indicator/trigger (arrow).\n\n        :param top: Top position\n        :param mouse_over: Whether the mouse is over the indicator\n        :param collapsed: Whether the trigger is collapsed or not.\n        :param painter: QPainter\n        \"\"\"\n        rect = QRect(0, top, self.sizeHint().width(),\n                            self.sizeHint().height())\n        if self._native_icons:\n            opt = QStyleOptionViewItem()\n\n            opt.rect = rect\n            opt.state = (QStyle.State_Active |\n                         QStyle.State_Item |\n                         QStyle.State_Children)\n            if not collapsed:\n                opt.state |= QStyle.State_Open\n            if mouse_over:\n                opt.state |= (QStyle.State_MouseOver |\n                              QStyle.State_Enabled |\n                              QStyle.State_Selected)\n                opt.palette.setBrush(QPalette.Window,\n                                     self.palette().highlight())\n            opt.rect.translate(-2, 0)\n            self.style().drawPrimitive(QStyle.PE_IndicatorBranch,\n                                       opt, painter, self)\n        else:\n            index = 0\n            if not collapsed:\n                index = 2\n            if mouse_over:\n                index += 1\n            ima.icon(self._indicators_icons[index]).paint(painter, rect)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_parent_scope(block):\n        original = block\n        if not TextBlockHelper.is_fold_trigger(block):\n            # search level of next non blank line\n            while block.text().strip() == '' and block.isValid():\n                block = block.next()\n            ref_lvl = TextBlockHelper.get_fold_lvl(block) - 1\n            block = original\n            while (block.blockNumber() and\n                   (not TextBlockHelper.is_fold_trigger(block) or\n                    TextBlockHelper.get_fold_lvl(block) > ref_lvl)):\n                block = block.previous()\n        return block", "response": "Find parent scope of the block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing scope decorations on the editor.", "response": "def _clear_scope_decos(self):\n        \"\"\"Clear scope decorations (on the editor)\"\"\"\n        for deco in self._scope_decos:\n            self.editor.decorations.remove(deco)\n        self._scope_decos[:] = []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_scope_highlight_color(self):\n        color = self.editor.sideareas_color\n        if color.lightness() < 128:\n            color = drift_color(color, 130)\n        else:\n            color = drift_color(color, 105)\n        return color", "response": "Gets the base scope highlight color"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _decorate_block(self, start, end):\n        color = self._get_scope_highlight_color()\n        draw_order = DRAW_ORDERS.get('codefolding')\n        d = TextDecoration(self.editor.document(), start_line=start,\n                           end_line=end+1, draw_order=draw_order)\n        d.set_background(color)\n        d.set_full_width(True, clear=False)\n        self.editor.decorations.add(d)\n        self._scope_decos.append(d)", "response": "Create a decoration and add it to the editor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _highlight_block(self, block):\n        scope = FoldScope(block)\n        if (self._current_scope is None or\n                self._current_scope.get_range() != scope.get_range()):\n            self._current_scope = scope\n            self._clear_scope_decos()\n            # highlight current scope with darker or lighter color\n            start, end = scope.get_range()\n            if not TextBlockHelper.is_collapsed(block):\n                self._decorate_block(start, end)", "response": "Highlights the current fold scope."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mouseMoveEvent(self, event):\n        super(FoldingPanel, self).mouseMoveEvent(event)\n        th = TextHelper(self.editor)\n        line = th.line_nbr_from_position(event.pos().y())\n        if line >= 0:\n            block = FoldScope.find_parent_scope(\n                self.editor.document().findBlockByNumber(line-1))\n            if TextBlockHelper.is_fold_trigger(block):\n                if self._mouse_over_line is None:\n                    # mouse enter fold scope\n                    QApplication.setOverrideCursor(\n                        QCursor(Qt.PointingHandCursor))\n                if self._mouse_over_line != block.blockNumber() and \\\n                        self._mouse_over_line is not None:\n                    # fold scope changed, a previous block was highlighter so\n                    # we quickly update our highlighting\n                    self._mouse_over_line = block.blockNumber()\n                    self._highlight_block(block)\n                else:\n                    # same fold scope, request highlight\n                    self._mouse_over_line = block.blockNumber()\n                    self._highlight_runner.request_job(\n                        self._highlight_block, block)\n                self._highight_block = block\n            else:\n                # no fold scope to highlight, cancel any pending requests\n                self._highlight_runner.cancel_requests()\n                self._mouse_over_line = None\n                QApplication.restoreOverrideCursor()\n            self.repaint()", "response": "Detect mouser over indicator and highlight the current scope in the folding panel"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mousePressEvent(self, event):\n        if self._mouse_over_line is not None:\n            block = self.editor.document().findBlockByNumber(\n                self._mouse_over_line)\n            self.toggle_fold_trigger(block)", "response": "Folds the pressed indicator if any."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _show_previous_blank_lines(block):\n        # set previous blank lines visibles\n        pblock = block.previous()\n        while (pblock.text().strip() == '' and\n               pblock.blockNumber() >= 0):\n            pblock.setVisible(True)\n            pblock = pblock.previous()", "response": "Show the previous blank lines in the block"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefreshing the decorations colors.", "response": "def refresh_decorations(self, force=False):\n        \"\"\"\n        Refresh decorations colors. This function is called by the syntax\n        highlighter when the style changed so that we may update our\n        decorations colors according to the new style.\n        \"\"\"\n        cursor = self.editor.textCursor()\n        if (self._prev_cursor is None or force or\n                self._prev_cursor.blockNumber() != cursor.blockNumber()):\n            for deco in self._block_decos:\n                self.editor.decorations.remove(deco)\n            for deco in self._block_decos:\n                deco.set_outline(drift_color(\n                    self._get_scope_highlight_color(), 110))\n                deco.set_background(self._get_scope_highlight_color())\n                self.editor.decorations.add(deco)\n        self._prev_cursor = cursor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrefreshes the editor content and scollbars", "response": "def _refresh_editor_and_scrollbars(self):\n        \"\"\"\n        Refrehes editor content and scollbars.\n\n        We generate a fake resize event to refresh scroll bar.\n\n        We have the same problem as described here:\n        http://www.qtcentre.org/threads/44803 and we apply the same solution\n        (don't worry, there is no visual effect, the editor does not grow up\n        at all, even with a value = 500)\n        \"\"\"\n        TextHelper(self.editor).mark_whole_doc_dirty()\n        self.editor.repaint()\n        s = self.editor.size()\n        s.setWidth(s.width() + 1)\n        self.editor.resizeEvent(QResizeEvent(self.editor.size(), s))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollapse all triggers and makes all blocks with fold level > 0 invisible.", "response": "def collapse_all(self):\n        \"\"\"\n        Collapses all triggers and makes all blocks with fold level > 0\n        invisible.\n        \"\"\"\n        self._clear_block_deco()\n        block = self.editor.document().firstBlock()\n        last = self.editor.document().lastBlock()\n        while block.isValid():\n            lvl = TextBlockHelper.get_fold_lvl(block)\n            trigger = TextBlockHelper.is_fold_trigger(block)\n            if trigger:\n                if lvl == 0:\n                    self._show_previous_blank_lines(block)\n                TextBlockHelper.set_collapsed(block, True)\n            block.setVisible(lvl == 0)\n            if block == last and block.text().strip() == '':\n                block.setVisible(True)\n                self._show_previous_blank_lines(block)\n            block = block.next()\n        self._refresh_editor_and_scrollbars()\n        tc = self.editor.textCursor()\n        tc.movePosition(tc.Start)\n        self.editor.setTextCursor(tc)\n        self.collapse_all_triggered.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clear_block_deco(self):\n        for deco in self._block_decos:\n            self.editor.decorations.remove(deco)\n        self._block_decos[:] = []", "response": "Clear the folded block decorations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_all(self):\n        block = self.editor.document().firstBlock()\n        while block.isValid():\n            TextBlockHelper.set_collapsed(block, False)\n            block.setVisible(True)\n            block = block.next()\n        self._clear_block_deco()\n        self._refresh_editor_and_scrollbars()\n        self.expand_all_triggered.emit()", "response": "Expands all fold triggers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntoggles the current fold trigger.", "response": "def _on_action_toggle(self):\n        \"\"\"Toggle the current fold trigger.\"\"\"\n        block = FoldScope.find_parent_scope(self.editor.textCursor().block())\n        self.toggle_fold_trigger(block)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _highlight_caret_scope(self):\n        cursor = self.editor.textCursor()\n        block_nbr = cursor.blockNumber()\n        if self._block_nbr != block_nbr:\n            block = FoldScope.find_parent_scope(\n                self.editor.textCursor().block())\n            try:\n                s = FoldScope(block)\n            except ValueError:\n                self._clear_scope_decos()\n            else:\n                self._mouse_over_line = block.blockNumber()\n                if TextBlockHelper.is_fold_trigger(block):\n                    self._highlight_block(block)\n        self._block_nbr = block_nbr", "response": "Highlight the scope of the current caret position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_menu_actions(self, menu_actions):\n        if self.menu_actions is not None:\n            add_actions(self.menu, self.menu_actions)", "response": "Add options to corner menu."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_tab(self, index_from, index_to):\n        filename = self.filenames.pop(index_from)\n        editor = self.editors.pop(index_from)\n\n        self.filenames.insert(index_to, filename)\n        self.editors.insert(index_to, editor)", "response": "Move tab.\n\n        (tabs themselves have already been moved by the history.tabwidget)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding new history tab.", "response": "def add_history(self, filename, color_scheme, font, wrap):\n        \"\"\"\n        Add new history tab.\n\n        Args:\n            filename (str): file to be loaded in a new tab.\n        \"\"\"\n        filename = encoding.to_unicode_from_fs(filename)\n        if filename in self.filenames:\n            return\n        editor = codeeditor.CodeEditor(self)\n        if osp.splitext(filename)[1] == '.py':\n            language = 'py'\n        else:\n            language = 'bat'\n        editor.setup_editor(linenumbers=False,\n                            language=language,\n                            scrollflagarea=False,\n                            show_class_func_dropdown=False)\n        editor.focus_changed.connect(lambda: self.focus_changed.emit())\n        editor.setReadOnly(True)\n\n        editor.set_font(font, color_scheme)\n        editor.toggle_wrap_mode(wrap)\n\n        text, _ = encoding.read(filename)\n        editor.set_text(text)\n        editor.set_cursor_position('eof')\n\n        self.editors.append(editor)\n        self.filenames.append(filename)\n        index = self.tabwidget.addTab(editor, osp.basename(filename))\n        self.find_widget.set_editor(editor)\n        self.tabwidget.setTabToolTip(index, filename)\n        self.tabwidget.setCurrentIndex(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append_to_history(self, filename, command, go_to_eof):\n        if not is_text_string(filename): # filename is a QString\n            filename = to_text_string(filename.toUtf8(), 'utf-8')\n        command = to_text_string(command)\n        index = self.filenames.index(filename)\n        self.editors[index].append(command)\n        if go_to_eof:\n            self.editors[index].set_cursor_position('eof')\n        self.tabwidget.setCurrentIndex(index)", "response": "Append an entry to the history."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(req=None, method=None, requires_response=True):\n    if req is None:\n        return functools.partial(request, method=method,\n                                 requires_response=requires_response)\n\n    @functools.wraps(req)\n    def wrapper(self, *args, **kwargs):\n        if self.lsp_ready:\n            params = req(self, *args, **kwargs)\n            if params is not None:\n                self.emit_request(method, params, requires_response)\n    return wrapper", "response": "Decorator that calls req and then emits its results to the LSP server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclass decorator that allows to map LSP method names to class methods.", "response": "def class_register(cls):\n    \"\"\"Class decorator that allows to map LSP method names to class methods.\"\"\"\n    cls.handler_registry = {}\n    for method_name in dir(cls):\n        method = getattr(cls, method_name)\n        if hasattr(method, '_handle'):\n            cls.handler_registry.update({method._handle: method_name})\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_font(self):\r\n        font = self.get_plugin_font()\r\n        for client in self.clients:\r\n            client.set_font(font)", "response": "Update font from Preferences"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_plugin_settings(self, options):\r\n        font_n = 'plugin_font'\r\n        font_o = self.get_plugin_font()\r\n        help_n = 'connect_to_oi'\r\n        help_o = CONF.get('help', 'connect/ipython_console')\r\n        color_scheme_n = 'color_scheme_name'\r\n        color_scheme_o = CONF.get('appearance', 'selected')\r\n        show_time_n = 'show_elapsed_time'\r\n        show_time_o = self.get_option(show_time_n)\r\n        reset_namespace_n = 'show_reset_namespace_warning'\r\n        reset_namespace_o = self.get_option(reset_namespace_n)\r\n        ask_before_restart_n = 'ask_before_restart'\r\n        ask_before_restart_o = self.get_option(ask_before_restart_n)\r\n        for client in self.clients:\r\n            control = client.get_control()\r\n            if font_n in options:\r\n                client.set_font(font_o)\r\n            if help_n in options and control is not None:\r\n                control.set_help_enabled(help_o)\r\n            if color_scheme_n in options:\r\n                client.set_color_scheme(color_scheme_o)\r\n            if show_time_n in options:\r\n                client.show_time_action.setChecked(show_time_o)\r\n                client.set_elapsed_time_visible(show_time_o)\r\n            if reset_namespace_n in options:\r\n                client.reset_warning = reset_namespace_o\r\n            if ask_before_restart_n in options:\r\n                client.ask_before_restart = ask_before_restart_o", "response": "Applies configuration file s plugin settings to the given options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntoggle view of a single user.", "response": "def toggle_view(self, checked):\r\n        \"\"\"Toggle view\"\"\"\r\n        if checked:\r\n            self.dockwidget.show()\r\n            self.dockwidget.raise_()\r\n            # Start a client in case there are none shown\r\n            if not self.clients:\r\n                if self.main.is_setting_up:\r\n                    self.create_new_client(give_focus=False)\r\n                else:\r\n                    self.create_new_client(give_focus=True)\r\n        else:\r\n            self.dockwidget.hide()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef closing_plugin(self, cancelable=False):\r\n        self.mainwindow_close = True\r\n        for client in self.clients:\r\n            client.shutdown()\r\n            client.remove_stderr_file()\r\n            client.dialog_manager.close_all()\r\n            client.close()\r\n        return True", "response": "Perform actions before parent main window is closed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh the tabwidget with the new information.", "response": "def refresh_plugin(self):\r\n        \"\"\"Refresh tabwidget\"\"\"\r\n        client = None\r\n        if self.tabwidget.count():\r\n            client = self.tabwidget.currentWidget()\r\n\r\n            # Decide what to show for each client\r\n            if client.info_page != client.blank_page:\r\n                # Show info_page if it has content\r\n                client.set_info_page()\r\n                client.shellwidget.hide()\r\n                client.layout.addWidget(self.infowidget)\r\n                self.infowidget.show()\r\n            else:\r\n                self.infowidget.hide()\r\n                client.shellwidget.show()\r\n\r\n            # Give focus to the control widget of the selected tab\r\n            control = client.get_control()\r\n            control.setFocus()\r\n\r\n            # Create corner widgets\r\n            buttons = [[b, -7] for b in client.get_toolbar_buttons()]\r\n            buttons = sum(buttons, [])[:-1]\r\n            widgets = [client.create_time_label()] + buttons\r\n        else:\r\n            control = None\r\n            widgets = []\r\n        self.find_widget.set_editor(control)\r\n        self.tabwidget.set_corner_widgets({Qt.TopRightCorner: widgets})\r\n        if client:\r\n            sw = client.shellwidget\r\n            self.main.variableexplorer.set_shellwidget_from_id(id(sw))\r\n            self.main.plots.set_shellwidget_from_id(id(sw))\r\n            self.main.help.set_shell(sw)\r\n        self.update_tabs_text()\r\n        self.sig_update_plugin_title.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of actions related to the plugin.", "response": "def get_plugin_actions(self):\r\n        \"\"\"Return a list of actions related to plugin.\"\"\"\r\n        create_client_action = create_action(\r\n                                   self,\r\n                                   _(\"New console (default settings)\"),\r\n                                   icon=ima.icon('ipython_console'),\r\n                                   triggered=self.create_new_client,\r\n                                   context=Qt.WidgetWithChildrenShortcut)\r\n        self.register_shortcut(create_client_action, context=\"ipython_console\",\r\n                               name=\"New tab\")\r\n\r\n        create_pylab_action = create_action(\r\n                                   self,\r\n                                   _(\"New Pylab console (data plotting)\"),\r\n                                   icon=ima.icon('ipython_console'),\r\n                                   triggered=self.create_pylab_client,\r\n                                   context=Qt.WidgetWithChildrenShortcut)\r\n\r\n        create_sympy_action = create_action(\r\n                                   self,\r\n                                   _(\"New SymPy console (symbolic math)\"),\r\n                                   icon=ima.icon('ipython_console'),\r\n                                   triggered=self.create_sympy_client,\r\n                                   context=Qt.WidgetWithChildrenShortcut)\r\n\r\n        create_cython_action = create_action(\r\n                                   self,\r\n                                   _(\"New Cython console (Python with \"\r\n                                     \"C extensions)\"),\r\n                                   icon=ima.icon('ipython_console'),\r\n                                   triggered=self.create_cython_client,\r\n                                   context=Qt.WidgetWithChildrenShortcut)\r\n        special_console_action_group = QActionGroup(self)\r\n        special_console_actions = (create_pylab_action, create_sympy_action,\r\n                                   create_cython_action)\r\n        add_actions(special_console_action_group, special_console_actions)\r\n        special_console_menu = QMenu(_(\"New special console\"), self)\r\n        add_actions(special_console_menu, special_console_actions)\r\n\r\n        restart_action = create_action(self, _(\"Restart kernel\"),\r\n                                       icon=ima.icon('restart'),\r\n                                       triggered=self.restart_kernel,\r\n                                       context=Qt.WidgetWithChildrenShortcut)\r\n\r\n        reset_action = create_action(self, _(\"Remove all variables\"),\r\n                                     icon=ima.icon('editdelete'),\r\n                                     triggered=self.reset_kernel,\r\n                                     context=Qt.WidgetWithChildrenShortcut)\r\n\r\n        if self.interrupt_action is None:\r\n            self.interrupt_action = create_action(\r\n                self, _(\"Interrupt kernel\"),\r\n                icon=ima.icon('stop'),\r\n                triggered=self.interrupt_kernel,\r\n                context=Qt.WidgetWithChildrenShortcut)\r\n\r\n        self.register_shortcut(restart_action, context=\"ipython_console\",\r\n                               name=\"Restart kernel\")\r\n\r\n        connect_to_kernel_action = create_action(self,\r\n               _(\"Connect to an existing kernel\"), None, None,\r\n               _(\"Open a new IPython console connected to an existing kernel\"),\r\n               triggered=self.create_client_for_kernel)\r\n        \r\n        rename_tab_action = create_action(self, _(\"Rename tab\"),\r\n                                       icon=ima.icon('rename'),\r\n                                       triggered=self.tab_name_editor)\r\n        \r\n        # Add the action to the 'Consoles' menu on the main window\r\n        main_consoles_menu = self.main.consoles_menu_actions\r\n        main_consoles_menu.insert(0, create_client_action)\r\n        main_consoles_menu += [special_console_menu, connect_to_kernel_action,\r\n                               MENU_SEPARATOR,\r\n                               self.interrupt_action, restart_action,\r\n                               reset_action]\r\n\r\n        # Plugin actions\r\n        self.menu_actions = [create_client_action, special_console_menu,\r\n                             connect_to_kernel_action,\r\n                             MENU_SEPARATOR,\r\n                             self.interrupt_action,\r\n                             restart_action, reset_action, rename_tab_action]\r\n\r\n        self.update_execution_state_kernel()\r\n\r\n        # Check for a current client. Since it manages more actions.\r\n        client = self.get_current_client()\r\n        if client:\r\n            return client.get_options_menu()\r\n        return self.menu_actions"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.main.add_dockwidget(self)\r\n\r\n        self.focus_changed.connect(self.main.plugin_focus_changed)\r\n        self.edit_goto.connect(self.main.editor.load)\r\n        self.edit_goto[str, int, str, bool].connect(\r\n                         lambda fname, lineno, word, processevents:\r\n                         self.main.editor.load(fname, lineno, word,\r\n                                               processevents=processevents))\r\n        self.main.editor.breakpoints_saved.connect(self.set_spyder_breakpoints)\r\n        self.main.editor.run_in_current_ipyclient.connect(self.run_script)\r\n        self.main.editor.run_cell_in_ipyclient.connect(self.run_cell)\r\n        self.main.workingdirectory.set_current_console_wd.connect(\r\n                                     self.set_current_client_working_directory)\r\n\r\n        self.tabwidget.currentChanged.connect(self.update_working_directory)\r\n\r\n        self._remove_old_stderr_files()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns current client with focus if any", "response": "def get_focus_client(self):\r\n        \"\"\"Return current client with focus, if any\"\"\"\r\n        widget = QApplication.focusWidget()\r\n        for client in self.get_clients():\r\n            if widget is client or widget is client.get_control():\r\n                return client"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_script(self, filename, wdir, args, debug, post_mortem,\r\n                   current_client, clear_variables):\r\n        \"\"\"Run script in current or dedicated client\"\"\"\r\n        norm = lambda text: remove_backslashes(to_text_string(text))\r\n\r\n        # Run Cython files in a dedicated console\r\n        is_cython = osp.splitext(filename)[1] == '.pyx'\r\n        if is_cython:\r\n            current_client = False\r\n\r\n        # Select client to execute code on it\r\n        is_new_client = False\r\n        if current_client:\r\n            client = self.get_current_client()\r\n        else:\r\n            client = self.get_client_for_file(filename)\r\n            if client is None:\r\n                self.create_client_for_file(filename, is_cython=is_cython)\r\n                client = self.get_current_client()\r\n                is_new_client = True\r\n\r\n        if client is not None:\r\n            # Internal kernels, use runfile\r\n            if client.get_kernel() is not None:\r\n                line = \"%s('%s'\" % ('debugfile' if debug else 'runfile',\r\n                                    norm(filename))\r\n                if args:\r\n                    line += \", args='%s'\" % norm(args)\r\n                if wdir:\r\n                    line += \", wdir='%s'\" % norm(wdir)\r\n                if post_mortem:\r\n                    line += \", post_mortem=True\"\r\n                line += \")\"\r\n            else: # External kernels, use %run\r\n                line = \"%run \"\r\n                if debug:\r\n                    line += \"-d \"\r\n                line += \"\\\"%s\\\"\" % to_text_string(filename)\r\n                if args:\r\n                    line += \" %s\" % norm(args)\r\n\r\n            try:\r\n                if client.shellwidget._executing:\r\n                    # Don't allow multiple executions when there's\r\n                    # still an execution taking place\r\n                    # Fixes issue 7293\r\n                    pass\r\n                elif client.shellwidget._reading:\r\n                    client.shellwidget._append_html(\r\n                        _(\"<br><b>Please exit from debugging before trying to \"\r\n                          \"run a file in this console.</b>\\n<hr><br>\"),\r\n                        before_prompt=True)\r\n                    return\r\n                elif current_client:\r\n                    self.execute_code(line, current_client, clear_variables)\r\n                else:\r\n                    if is_new_client:\r\n                        client.shellwidget.silent_execute('%clear')\r\n                    else:\r\n                        client.shellwidget.execute('%clear')\r\n                    client.shellwidget.sig_prompt_ready.connect(\r\n                            lambda: self.execute_code(line, current_client,\r\n                                                      clear_variables))\r\n            except AttributeError:\r\n                pass\r\n            self.switch_to_plugin()\r\n        else:\r\n            #XXX: not sure it can really happen\r\n            QMessageBox.warning(self, _('Warning'),\r\n                _(\"No IPython console is currently available to run <b>%s</b>.\"\r\n                  \"<br><br>Please open a new one and try again.\"\r\n                  ) % osp.basename(filename), QMessageBox.Ok)", "response": "Run a script in a dedicated console or in the current console"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a cell in current or dedicated client.", "response": "def run_cell(self, code, cell_name, filename, run_cell_copy):\r\n        \"\"\"Run cell in current or dedicated client.\"\"\"\r\n\r\n        def norm(text):\r\n            return remove_backslashes(to_text_string(text))\r\n\r\n        self.run_cell_filename = filename\r\n\r\n        # Select client to execute code on it\r\n        client = self.get_client_for_file(filename)\r\n        if client is None:\r\n            client = self.get_current_client()\r\n\r\n        is_internal_kernel = False\r\n        if client is not None:\r\n            # Internal kernels, use runcell\r\n            if client.get_kernel() is not None and not run_cell_copy:\r\n                line = (to_text_string(\"{}('{}','{}')\")\r\n                            .format(to_text_string('runcell'),\r\n                                (to_text_string(cell_name).replace(\"\\\\\",\"\\\\\\\\\")\r\n                                    .replace(\"'\", r\"\\'\")),\r\n                                norm(filename).replace(\"'\", r\"\\'\")))\r\n                is_internal_kernel = True\r\n\r\n            # External kernels and run_cell_copy, just execute the code\r\n            else:\r\n                line = code.strip()\r\n\r\n            try:\r\n                if client.shellwidget._executing:\r\n                    # Don't allow multiple executions when there's\r\n                    # still an execution taking place\r\n                    # Fixes issue 7293\r\n                    pass\r\n                elif client.shellwidget._reading:\r\n                    client.shellwidget._append_html(\r\n                        _(\"<br><b>Exit the debugger before trying to \"\r\n                          \"run a cell in this console.</b>\\n<hr><br>\"),\r\n                        before_prompt=True)\r\n                    return\r\n                else:\r\n                    if is_internal_kernel:\r\n                        client.shellwidget.silent_execute(\r\n                            to_text_string('get_ipython().cell_code = '\r\n                                           '\"\"\"{}\"\"\"')\r\n                                .format(to_text_string(code)\r\n                                .replace('\\\\', r'\\\\')\r\n                                .replace('\"\"\"', r'\\\"\\\"\\\"')))\r\n                    self.execute_code(line)\r\n            except AttributeError:\r\n                pass\r\n            self.visibility_changed(True)\r\n            self.raise_()\r\n        else:\r\n            # XXX: not sure it can really happen\r\n            QMessageBox.warning(self, _('Warning'),\r\n                                _(\"No IPython console is currently available \"\r\n                                  \"to run <b>{}</b>.<br><br>Please open a new \"\r\n                                  \"one and try again.\"\r\n                                  ).format(osp.basename(filename)),\r\n                                QMessageBox.Ok)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets current client working directory.", "response": "def set_current_client_working_directory(self, directory):\r\n        \"\"\"Set current client working directory.\"\"\"\r\n        shellwidget = self.get_current_shellwidget()\r\n        if shellwidget is not None:\r\n            shellwidget.set_cwd(directory)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the current working directory.", "response": "def set_working_directory(self, dirname):\r\n        \"\"\"Set current working directory.\r\n        In the workingdirectory and explorer plugins.\r\n        \"\"\"\r\n        if dirname:\r\n            self.main.workingdirectory.chdir(dirname, refresh_explorer=True,\r\n                                             refresh_console=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new client and add it to the list of active clients.", "response": "def create_new_client(self, give_focus=True, filename='', is_cython=False,\r\n                          is_pylab=False, is_sympy=False, given_name=None):\r\n        \"\"\"Create a new client\"\"\"\r\n        self.master_clients += 1\r\n        client_id = dict(int_id=to_text_string(self.master_clients),\r\n                         str_id='A')\r\n        cf = self._new_connection_file()\r\n        show_elapsed_time = self.get_option('show_elapsed_time')\r\n        reset_warning = self.get_option('show_reset_namespace_warning')\r\n        ask_before_restart = self.get_option('ask_before_restart')\r\n        client = ClientWidget(self, id_=client_id,\r\n                              history_filename=get_conf_path('history.py'),\r\n                              config_options=self.config_options(),\r\n                              additional_options=self.additional_options(\r\n                                      is_pylab=is_pylab,\r\n                                      is_sympy=is_sympy),\r\n                              interpreter_versions=self.interpreter_versions(),\r\n                              connection_file=cf,\r\n                              menu_actions=self.menu_actions,\r\n                              options_button=self.options_button,\r\n                              show_elapsed_time=show_elapsed_time,\r\n                              reset_warning=reset_warning,\r\n                              given_name=given_name,\r\n                              ask_before_restart=ask_before_restart,\r\n                              css_path=self.css_path)\r\n\r\n        # Change stderr_dir if requested\r\n        if self.test_dir is not None:\r\n            client.stderr_dir = self.test_dir\r\n\r\n        self.add_tab(client, name=client.get_name(), filename=filename)\r\n\r\n        if cf is None:\r\n            error_msg = self.permission_error_msg.format(jupyter_runtime_dir())\r\n            client.show_kernel_error(error_msg)\r\n            return\r\n\r\n        # Check if ipykernel is present in the external interpreter.\r\n        # Else we won't be able to create a client\r\n        if not CONF.get('main_interpreter', 'default'):\r\n            pyexec = CONF.get('main_interpreter', 'executable')\r\n            has_spyder_kernels = programs.is_module_installed(\r\n                                                        'spyder_kernels',\r\n                                                        interpreter=pyexec,\r\n                                                        version='>=1.0.0')\r\n            if not has_spyder_kernels:\r\n                client.show_kernel_error(\r\n                        _(\"Your Python environment or installation doesn't \"\r\n                          \"have the <tt>spyder-kernels</tt> module or the \"\r\n                          \"right version of it installed. \"\r\n                          \"Without this module is not possible for \"\r\n                          \"Spyder to create a console for you.<br><br>\"\r\n                          \"You can install it by running in a system terminal:\"\r\n                          \"<br><br>\"\r\n                          \"<tt>conda install spyder-kernels</tt>\"\r\n                          \"<br><br>or<br><br>\"\r\n                          \"<tt>pip install spyder-kernels</tt>\"))\r\n                return\r\n\r\n        self.connect_client_to_kernel(client, is_cython=is_cython,\r\n                                      is_pylab=is_pylab, is_sympy=is_sympy)\r\n        if client.shellwidget.kernel_manager is None:\r\n            return\r\n        self.register_client(client)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_client_for_kernel(self):\r\n        connect_output = KernelConnectionDialog.get_connection_parameters(self)\r\n        (connection_file, hostname, sshkey, password, ok) = connect_output\r\n        if not ok:\r\n            return\r\n        else:\r\n            self._create_client_for_kernel(connection_file, hostname, sshkey,\r\n                                           password)", "response": "Create a client connected to an existing kernel"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects a client to its kernel", "response": "def connect_client_to_kernel(self, client, is_cython=False,\r\n                                 is_pylab=False, is_sympy=False):\r\n        \"\"\"Connect a client to its kernel\"\"\"\r\n        connection_file = client.connection_file\r\n        stderr_handle = None if self.test_no_stderr else client.stderr_handle\r\n        km, kc = self.create_kernel_manager_and_kernel_client(\r\n                     connection_file,\r\n                     stderr_handle,\r\n                     is_cython=is_cython,\r\n                     is_pylab=is_pylab,\r\n                     is_sympy=is_sympy)\r\n\r\n        # An error occurred if this is True\r\n        if is_string(km) and kc is None:\r\n            client.shellwidget.kernel_manager = None\r\n            client.show_kernel_error(km)\r\n            return\r\n\r\n        # This avoids a recurrent, spurious NameError when running our\r\n        # tests in our CIs\r\n        if not self.testing:\r\n            kc.started_channels.connect(\r\n                lambda c=client: self.process_started(c))\r\n            kc.stopped_channels.connect(\r\n                lambda c=client: self.process_finished(c))\r\n        kc.start_channels(shell=True, iopub=True)\r\n\r\n        shellwidget = client.shellwidget\r\n        shellwidget.kernel_manager = km\r\n        shellwidget.kernel_client = kc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle %edit magic petitions.", "response": "def edit_file(self, filename, line):\r\n        \"\"\"Handle %edit magic petitions.\"\"\"\r\n        if encoding.is_text_file(filename):\r\n            # The default line number sent by ipykernel is always the last\r\n            # one, but we prefer to use the first.\r\n            self.edit_goto.emit(filename, 1, '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_options(self):\r\n        # ---- Jupyter config ----\r\n        try:\r\n            full_cfg = load_pyconfig_files(['jupyter_qtconsole_config.py'],\r\n                                           jupyter_config_dir())\r\n\r\n            # From the full config we only select the JupyterWidget section\r\n            # because the others have no effect here.\r\n            cfg = Config({'JupyterWidget': full_cfg.JupyterWidget})\r\n        except:\r\n            cfg = Config()\r\n\r\n        # ---- Spyder config ----\r\n        spy_cfg = Config()\r\n\r\n        # Make the pager widget a rich one (i.e a QTextEdit)\r\n        spy_cfg.JupyterWidget.kind = 'rich'\r\n\r\n        # Gui completion widget\r\n        completion_type_o = self.get_option('completion_type')\r\n        completions = {0: \"droplist\", 1: \"ncurses\", 2: \"plain\"}\r\n        spy_cfg.JupyterWidget.gui_completion = completions[completion_type_o]\r\n\r\n        # Pager\r\n        pager_o = self.get_option('use_pager')\r\n        if pager_o:\r\n            spy_cfg.JupyterWidget.paging = 'inside'\r\n        else:\r\n            spy_cfg.JupyterWidget.paging = 'none'\r\n\r\n        # Calltips\r\n        calltips_o = self.get_option('show_calltips')\r\n        spy_cfg.JupyterWidget.enable_calltips = calltips_o\r\n\r\n        # Buffer size\r\n        buffer_size_o = self.get_option('buffer_size')\r\n        spy_cfg.JupyterWidget.buffer_size = buffer_size_o\r\n\r\n        # Prompts\r\n        in_prompt_o = self.get_option('in_prompt')\r\n        out_prompt_o = self.get_option('out_prompt')\r\n        if in_prompt_o:\r\n            spy_cfg.JupyterWidget.in_prompt = in_prompt_o\r\n        if out_prompt_o:\r\n            spy_cfg.JupyterWidget.out_prompt = out_prompt_o\r\n\r\n        # Style\r\n        color_scheme = CONF.get('appearance', 'selected')\r\n        style_sheet = create_qss_style(color_scheme)[0]\r\n        spy_cfg.JupyterWidget.style_sheet = style_sheet\r\n        spy_cfg.JupyterWidget.syntax_style = color_scheme\r\n\r\n        # Merge QtConsole and Spyder configs. Spyder prefs will have\r\n        # prevalence over QtConsole ones\r\n        cfg._merge(spy_cfg)\r\n        return cfg", "response": "Generate a Trailets Config instance for each section of the config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpreter_versions(self):\r\n        if CONF.get('main_interpreter', 'default'):\r\n            from IPython.core import release\r\n            versions = dict(\r\n                python_version = sys.version.split(\"\\n\")[0].strip(),\r\n                ipython_version = release.version\r\n            )\r\n        else:\r\n            import subprocess\r\n            versions = {}\r\n            pyexec = CONF.get('main_interpreter', 'executable')\r\n            py_cmd = \"%s -c 'import sys; print(sys.version.split(\\\"\\\\n\\\")[0])'\" % \\\r\n                     pyexec\r\n            ipy_cmd = \"%s -c 'import IPython.core.release as r; print(r.version)'\" \\\r\n                      % pyexec\r\n            for cmd in [py_cmd, ipy_cmd]:\r\n                try:\r\n                    proc = programs.run_shell_command(cmd)\r\n                    output, _err = proc.communicate()\r\n                except subprocess.CalledProcessError:\r\n                    output = ''\r\n                output = output.decode().split('\\n')[0].strip()\r\n                if 'IPython' in cmd:\r\n                    versions['ipython_version'] = output\r\n                else:\r\n                    versions['python_version'] = output\r\n\r\n        return versions", "response": "Returns a dictionary of Python and IPython versions used by clients"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of additional options for shell widgets that are not defined in JupyterWidget config", "response": "def additional_options(self, is_pylab=False, is_sympy=False):\r\n        \"\"\"\r\n        Additional options for shell widgets that are not defined\r\n        in JupyterWidget config options\r\n        \"\"\"\r\n        options = dict(\r\n            pylab=self.get_option('pylab'),\r\n            autoload_pylab=self.get_option('pylab/autoload'),\r\n            sympy=self.get_option('symbolic_math'),\r\n            show_banner=self.get_option('show_banner')\r\n        )\r\n\r\n        if is_pylab is True:\r\n            options['autoload_pylab'] = True\r\n            options['sympy'] = False\r\n        if is_sympy is True:\r\n            options['autoload_pylab'] = False\r\n            options['sympy'] = True\r\n\r\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_client(self, client, give_focus=True):\r\n        client.configure_shellwidget(give_focus=give_focus)\r\n\r\n        # Local vars\r\n        shellwidget = client.shellwidget\r\n        control = shellwidget._control\r\n        page_control = shellwidget._page_control\r\n\r\n        # Create new clients with Ctrl+T shortcut\r\n        shellwidget.new_client.connect(self.create_new_client)\r\n\r\n        # For tracebacks\r\n        control.go_to_error.connect(self.go_to_error)\r\n\r\n        shellwidget.sig_pdb_step.connect(\r\n                              lambda fname, lineno, shellwidget=shellwidget:\r\n                              self.pdb_has_stopped(fname, lineno, shellwidget))\r\n\r\n        # To handle %edit magic petitions\r\n        shellwidget.custom_edit_requested.connect(self.edit_file)\r\n\r\n        # Set shell cwd according to preferences\r\n        cwd_path = ''\r\n        if CONF.get('workingdir', 'console/use_project_or_home_directory'):\r\n            cwd_path = get_home_dir()\r\n            if (self.main.projects is not None and\r\n                    self.main.projects.get_active_project() is not None):\r\n                cwd_path = self.main.projects.get_active_project_path()\r\n        elif CONF.get('workingdir', 'console/use_fixed_directory'):\r\n            cwd_path = CONF.get('workingdir', 'console/fixed_directory')\r\n\r\n        if osp.isdir(cwd_path) and self.main is not None:\r\n            shellwidget.set_cwd(cwd_path)\r\n            if give_focus:\r\n                # Syncronice cwd with explorer and cwd widget\r\n                shellwidget.get_cwd()\r\n\r\n        # Connect text widget to Help\r\n        if self.main.help is not None:\r\n            control.set_help(self.main.help)\r\n            control.set_help_enabled(CONF.get('help', 'connect/ipython_console'))\r\n\r\n        # Connect client to our history log\r\n        if self.main.historylog is not None:\r\n            self.main.historylog.add_history(client.history_filename)\r\n            client.append_to_history.connect(\r\n                self.main.historylog.append_to_history)\r\n        \r\n        # Set font for client\r\n        client.set_font( self.get_plugin_font() )\r\n        \r\n        # Connect focus signal to client's control widget\r\n        control.focus_changed.connect(lambda: self.focus_changed.emit())\r\n        \r\n        shellwidget.sig_change_cwd.connect(self.set_working_directory)\r\n\r\n        # Update the find widget if focus changes between control and\r\n        # page_control\r\n        self.find_widget.set_editor(control)\r\n        if page_control:\r\n            page_control.focus_changed.connect(lambda: self.focus_changed.emit())\r\n            control.visibility_changed.connect(self.refresh_plugin)\r\n            page_control.visibility_changed.connect(self.refresh_plugin)\r\n            page_control.show_find_widget.connect(self.find_widget.show)", "response": "Register a new client with the shellwidget"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing a client tab from the given index or the current tab.", "response": "def close_client(self, index=None, client=None, force=False):\r\n        \"\"\"Close client tab from index or widget (or close current tab)\"\"\"\r\n        if not self.tabwidget.count():\r\n            return\r\n        if client is not None:\r\n            index = self.tabwidget.indexOf(client)\r\n            # if index is not found in tabwidget it's because this client was\r\n            # already closed and the call was performed by the exit callback\r\n            if index == -1:\r\n                return\r\n        if index is None and client is None:\r\n            index = self.tabwidget.currentIndex()\r\n        if index is not None:\r\n            client = self.tabwidget.widget(index)\r\n\r\n        # Needed to handle a RuntimeError. See issue 5568.\r\n        try:\r\n            # Close client\r\n            client.stop_button_click_handler()\r\n        except RuntimeError:\r\n            pass\r\n\r\n        # Disconnect timer needed to update elapsed time\r\n        try:\r\n            client.timer.timeout.disconnect(client.show_time)\r\n        except (RuntimeError, TypeError):\r\n            pass\r\n\r\n        # Check if related clients or kernels are opened\r\n        # and eventually ask before closing them\r\n        if not self.mainwindow_close and not force:\r\n            close_all = True\r\n            if self.get_option('ask_before_closing'):\r\n                close = QMessageBox.question(self, self.get_plugin_title(),\r\n                                       _(\"Do you want to close this console?\"),\r\n                                       QMessageBox.Yes | QMessageBox.No)\r\n                if close == QMessageBox.No:\r\n                    return\r\n            if len(self.get_related_clients(client)) > 0:\r\n                close_all = QMessageBox.question(self, self.get_plugin_title(),\r\n                         _(\"Do you want to close all other consoles connected \"\r\n                           \"to the same kernel as this one?\"),\r\n                           QMessageBox.Yes | QMessageBox.No)\r\n\r\n            client.shutdown()\r\n            if close_all == QMessageBox.Yes:\r\n                self.close_related_clients(client)\r\n\r\n        # if there aren't related clients we can remove stderr_file\r\n        related_clients = self.get_related_clients(client)\r\n        if len(related_clients) == 0 and osp.exists(client.stderr_file):\r\n            client.remove_stderr_file()\r\n\r\n        client.dialog_manager.close_all()\r\n        client.close()\r\n\r\n        # Note: client index may have changed after closing related widgets\r\n        self.tabwidget.removeTab(self.tabwidget.indexOf(client))\r\n        self.clients.remove(client)\r\n\r\n        # This is needed to prevent that hanged consoles make reference\r\n        # to an index that doesn't exist. See issue 4881\r\n        try:\r\n            self.filenames.pop(index)\r\n        except IndexError:\r\n            pass\r\n\r\n        self.update_tabs_text()\r\n\r\n        # Create a new client if the console is about to become empty\r\n        if not self.tabwidget.count() and self.create_new_client_if_empty:\r\n            self.create_new_client()\r\n\r\n        self.sig_update_plugin_title.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the index of the client with the given id", "response": "def get_client_index_from_id(self, client_id):\r\n        \"\"\"Return client index from id\"\"\"\r\n        for index, client in enumerate(self.clients):\r\n            if id(client) == client_id:\r\n                return index"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all other clients that are connected to the same kernel as client.", "response": "def get_related_clients(self, client):\r\n        \"\"\"\r\n        Get all other clients that are connected to the same kernel as `client`\r\n        \"\"\"\r\n        related_clients = []\r\n        for cl in self.get_clients():\r\n            if cl.connection_file == client.connection_file and \\\r\n              cl is not client:\r\n                related_clients.append(cl)\r\n        return related_clients"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close_related_clients(self, client):\r\n        related_clients = self.get_related_clients(client)\r\n        for cl in related_clients:\r\n            self.close_client(client=cl, force=True)", "response": "Close all related clients except itself"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestart the console with the current console and the current interpreter", "response": "def restart(self):\r\n        \"\"\"\r\n        Restart the console\r\n\r\n        This is needed when we switch projects to update PYTHONPATH\r\n        and the selected interpreter\r\n        \"\"\"\r\n        self.master_clients = 0\r\n        self.create_new_client_if_empty = False\r\n        for i in range(len(self.clients)):\r\n            client = self.clients[-1]\r\n            try:\r\n                client.shutdown()\r\n            except Exception as e:\r\n                QMessageBox.warning(self, _('Warning'),\r\n                    _(\"It was not possible to restart the IPython console \"\r\n                      \"when switching to this project. The error was<br><br>\"\r\n                      \"<tt>{0}</tt>\").format(e), QMessageBox.Ok)\r\n            self.close_client(client=client, force=True)\r\n        self.create_new_client(give_focus=False)\r\n        self.create_new_client_if_empty = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pdb_has_stopped(self, fname, lineno, shellwidget):\r\n        # This is a unique form of the edit_goto signal that is intended to\r\n        # prevent keyboard input from accidentally entering the editor\r\n        # during repeated, rapid entry of debugging commands.\r\n        self.edit_goto[str, int, str, bool].emit(fname, lineno, '', False)\r\n        self.activateWindow()\r\n        shellwidget._control.setFocus()", "response": "Called by the debugger when the debugger has just stopped at the given line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_client_from_path(self, path):\r\n        self.create_new_client()\r\n        sw = self.get_current_shellwidget()\r\n        sw.set_cwd(path)", "response": "Create a new client with its cwd pointing to path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_client_for_file(self, filename, is_cython=False):\r\n        # Create client\r\n        self.create_new_client(filename=filename, is_cython=is_cython)\r\n\r\n        # Don't increase the count of master clients\r\n        self.master_clients -= 1\r\n\r\n        # Rename client tab with filename\r\n        client = self.get_current_client()\r\n        client.allow_rename = False\r\n        tab_text = self.disambiguate_fname(filename)\r\n        self.rename_client_tab(client, tab_text)", "response": "Create a new client to execute code related to a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the client associated with a given file.", "response": "def get_client_for_file(self, filename):\r\n        \"\"\"Get client associated with a given file.\"\"\"\r\n        client = None\r\n        for idx, cl in enumerate(self.get_clients()):\r\n            if self.filenames[idx] == filename:\r\n                self.tabwidget.setCurrentIndex(idx)\r\n                client = cl\r\n                break\r\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_elapsed_time(self, client):\r\n        related_clients = self.get_related_clients(client)\r\n        for cl in related_clients:\r\n            if cl.timer is not None:\r\n                client.create_time_label()\r\n                client.t0 = cl.t0\r\n                client.timer.timeout.connect(client.show_time)\r\n                client.timer.start(1000)\r\n                break", "response": "Set elapsed time for slave clients."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntunneling connections to a kernel via ssh.", "response": "def tunnel_to_kernel(self, connection_info, hostname, sshkey=None,\r\n                         password=None, timeout=10):\r\n        \"\"\"\r\n        Tunnel connections to a kernel via ssh.\r\n\r\n        Remote ports are specified in the connection info ci.\r\n        \"\"\"\r\n        lports = zmqtunnel.select_random_ports(4)\r\n        rports = (connection_info['shell_port'], connection_info['iopub_port'],\r\n                  connection_info['stdin_port'], connection_info['hb_port'])\r\n        remote_ip = connection_info['ip']\r\n        for lp, rp in zip(lports, rports):\r\n            self.ssh_tunnel(lp, rp, hostname, remote_ip, sshkey, password,\r\n                            timeout)\r\n        return tuple(lports)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a kernel spec for our own kernels", "response": "def create_kernel_spec(self, is_cython=False,\r\n                           is_pylab=False, is_sympy=False):\r\n        \"\"\"Create a kernel spec for our own kernels\"\"\"\r\n        # Before creating our kernel spec, we always need to\r\n        # set this value in spyder.ini\r\n        CONF.set('main', 'spyder_pythonpath',\r\n                 self.main.get_spyder_pythonpath())\r\n        return SpyderKernelSpec(is_cython=is_cython,\r\n                                is_pylab=is_pylab,\r\n                                is_sympy=is_sympy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_kernel_manager_and_kernel_client(self, connection_file,\r\n                                                stderr_handle,\r\n                                                is_cython=False,\r\n                                                is_pylab=False,\r\n                                                is_sympy=False):\r\n        \"\"\"Create kernel manager and client.\"\"\"\r\n        # Kernel spec\r\n        kernel_spec = self.create_kernel_spec(is_cython=is_cython,\r\n                                              is_pylab=is_pylab,\r\n                                              is_sympy=is_sympy)\r\n\r\n        # Kernel manager\r\n        try:\r\n            kernel_manager = QtKernelManager(connection_file=connection_file,\r\n                                             config=None, autorestart=True)\r\n        except Exception:\r\n            error_msg = _(\"The error is:<br><br>\"\r\n                          \"<tt>{}</tt>\").format(traceback.format_exc())\r\n            return (error_msg, None)\r\n        kernel_manager._kernel_spec = kernel_spec\r\n\r\n        kwargs = {}\r\n        if os.name == 'nt':\r\n            # avoid closing fds on win+Python 3.7\r\n            # which prevents interrupts\r\n            # jupyter_client > 5.2.3 will do this by default\r\n            kwargs['close_fds'] = False\r\n        # Catch any error generated when trying to start the kernel\r\n        # See issue 7302\r\n        try:\r\n            kernel_manager.start_kernel(stderr=stderr_handle, **kwargs)\r\n        except Exception:\r\n            error_msg = _(\"The error is:<br><br>\"\r\n                          \"<tt>{}</tt>\").format(traceback.format_exc())\r\n            return (error_msg, None)\r\n\r\n        # Kernel client\r\n        kernel_client = kernel_manager.client()\r\n\r\n        # Increase time to detect if a kernel is alive\r\n        # See Issue 3444\r\n        kernel_client.hb_channel.time_to_dead = 18.0\r\n\r\n        return kernel_manager, kernel_client", "response": "Create a new kernel manager and a kernel client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrestart kernel of current client.", "response": "def restart_kernel(self):\r\n        \"\"\"Restart kernel of current client.\"\"\"\r\n        client = self.get_current_client()\r\n        if client is not None:\r\n            self.switch_to_plugin()\r\n            client.restart_kernel()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_kernel(self):\r\n        client = self.get_current_client()\r\n        if client is not None:\r\n            self.switch_to_plugin()\r\n            client.reset_namespace()", "response": "Reset kernel of current client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninterrupting kernel of current client.", "response": "def interrupt_kernel(self):\r\n        \"\"\"Interrupt kernel of current client.\"\"\"\r\n        client = self.get_current_client()\r\n        if client is not None:\r\n            self.switch_to_plugin()\r\n            client.stop_button_click_handler()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_execution_state_kernel(self):\r\n        client = self.get_current_client()\r\n        if client is not None:\r\n            executing = client.stop_button.isEnabled()\r\n            self.interrupt_action.setEnabled(executing)", "response": "Update actions following the execution state of the kernel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect_external_kernel(self, shellwidget):\r\n        sw = shellwidget\r\n        kc = shellwidget.kernel_client\r\n        if self.main.help is not None:\r\n            self.main.help.set_shell(sw)\r\n        if self.main.variableexplorer is not None:\r\n            self.main.variableexplorer.add_shellwidget(sw)\r\n            sw.set_namespace_view_settings()\r\n            sw.refresh_namespacebrowser()\r\n            kc.stopped_channels.connect(lambda :\r\n                self.main.variableexplorer.remove_shellwidget(id(sw)))", "response": "Connect an external kernel to the Variable Explorer and Help."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd tab to the list of tabs.", "response": "def add_tab(self, widget, name, filename=''):\r\n        \"\"\"Add tab\"\"\"\r\n        self.clients.append(widget)\r\n        index = self.tabwidget.addTab(widget, name)\r\n        self.filenames.insert(index, filename)\r\n        self.tabwidget.setCurrentIndex(index)\r\n        if self.dockwidget and not self.main.is_setting_up:\r\n            self.switch_to_plugin()\r\n        self.activateWindow()\r\n        widget.get_control().setFocus()\r\n        self.update_tabs_text()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves tab from one tab to another", "response": "def move_tab(self, index_from, index_to):\r\n        \"\"\"\r\n        Move tab (tabs themselves have already been moved by the tabwidget)\r\n        \"\"\"\r\n        filename = self.filenames.pop(index_from)\r\n        client = self.clients.pop(index_from)\r\n        self.filenames.insert(index_to, filename)\r\n        self.clients.insert(index_to, client)\r\n        self.update_tabs_text()\r\n        self.sig_update_plugin_title.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disambiguate_fname(self, fname):\r\n        files_path_list = [filename for filename in self.filenames\r\n                           if filename]\r\n        return sourcecode.disambiguate_fname(files_path_list, fname)", "response": "Generate a file name without ambiguation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the text from the tabs.", "response": "def update_tabs_text(self):\r\n        \"\"\"Update the text from the tabs.\"\"\"\r\n        # This is needed to prevent that hanged consoles make reference\r\n        # to an index that doesn't exist. See issue 4881\r\n        try:\r\n            for index, fname in enumerate(self.filenames):\r\n                client = self.clients[index]\r\n                if fname:\r\n                    self.rename_client_tab(client,\r\n                                           self.disambiguate_fname(fname))\r\n                else:\r\n                    self.rename_client_tab(client, None)\r\n        except IndexError:\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenames the client s tab.", "response": "def rename_client_tab(self, client, given_name):\r\n        \"\"\"Rename client's tab\"\"\"\r\n        index = self.get_client_index_from_id(id(client))\r\n\r\n        if given_name is not None:\r\n            client.given_name = given_name\r\n        self.tabwidget.setTabText(index, client.get_name())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rename_tabs_after_change(self, given_name):\r\n        client = self.get_current_client()\r\n\r\n        # Prevent renames that want to assign the same name of\r\n        # a previous tab\r\n        repeated = False\r\n        for cl in self.get_clients():\r\n            if id(client) != id(cl) and given_name == cl.given_name:\r\n                repeated = True\r\n                break\r\n\r\n        # Rename current client tab to add str_id\r\n        if client.allow_rename and not u'/' in given_name and not repeated:\r\n            self.rename_client_tab(client, given_name)\r\n        else:\r\n            self.rename_client_tab(client, None)\r\n\r\n        # Rename related clients\r\n        if client.allow_rename and not u'/' in given_name and not repeated:\r\n            for cl in self.get_related_clients(client):\r\n                self.rename_client_tab(cl, given_name)", "response": "Rename tabs after a change in name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntriggering the tab name editor.", "response": "def tab_name_editor(self):\r\n        \"\"\"Trigger the tab name editor.\"\"\"\r\n        index = self.tabwidget.currentIndex()\r\n        self.tabwidget.tabBar().tab_name_editor.edit_tab(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef go_to_error(self, text):\r\n        match = get_error_match(to_text_string(text))\r\n        if match:\r\n            fname, lnb = match.groups()\r\n            if (\"<ipython-input-\" in fname and\r\n                    self.run_cell_filename is not None):\r\n                fname = self.run_cell_filename\r\n            self.edit_goto.emit(osp.abspath(fname), int(lnb), '')", "response": "Go to error if relevant"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_intro(self):\r\n        from IPython.core.usage import interactive_usage\r\n        self.main.help.show_rich_text(interactive_usage)", "response": "Show intro to IPython help"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow IPython Cheat Sheet", "response": "def show_quickref(self):\r\n        \"\"\"Show IPython Cheat Sheet\"\"\"\r\n        from IPython.core.usage import quick_reference\r\n        self.main.help.show_plain_text(quick_reference)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a new connection file based on the current kernel version", "response": "def _new_connection_file(self):\r\n        \"\"\"\r\n        Generate a new connection file\r\n\r\n        Taken from jupyter_client/console_app.py\r\n        Licensed under the BSD license\r\n        \"\"\"\r\n        # Check if jupyter_runtime_dir exists (Spyder addition)\r\n        if not osp.isdir(jupyter_runtime_dir()):\r\n            try:\r\n                os.makedirs(jupyter_runtime_dir())\r\n            except (IOError, OSError):\r\n                return None\r\n        cf = ''\r\n        while not cf:\r\n            ident = str(uuid.uuid4()).split('-')[-1]\r\n            cf = os.path.join(jupyter_runtime_dir(), 'kernel-%s.json' % ident)\r\n            cf = cf if not os.path.exists(cf) else ''\r\n        return cf"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _remove_old_stderr_files(self):\r\n        if os.name == 'nt':\r\n            tmpdir = get_temp_dir()\r\n            for fname in os.listdir(tmpdir):\r\n                if osp.splitext(fname)[1] == '.stderr':\r\n                    try:\r\n                        os.remove(osp.join(tmpdir, fname))\r\n                    except Exception:\r\n                        pass", "response": "Remove stderr files left by previous Spyder instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrotate the kill ring then yank back the new top. Returns None if no kill ring is available.", "response": "def rotate(self):\n        \"\"\" Rotate the kill ring, then yank back the new top.\n\n        Returns\n        -------\n        A text string or None.\n        \"\"\"\n        self._index -= 1\n        if self._index >= 0:\n            return self._ring[self._index]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkilling the selected text from the give cursor.", "response": "def kill_cursor(self, cursor):\n        \"\"\" Kills the text selected by the give cursor.\n        \"\"\"\n        text = cursor.selectedText()\n        if text:\n            cursor.removeSelectedText()\n            self.kill(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef yank(self):\n        text = self._ring.yank()\n        if text:\n            self._skip_cursor = True\n            cursor = self._text_edit.textCursor()\n            cursor.insertText(text)\n            self._prev_yank = text", "response": "Yank back the most recently killed text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_in_external_file_explorer(fnames=None):\r\n    if not isinstance(fnames, (tuple, list)):\r\n        fnames = [fnames]\r\n    for fname in fnames:\r\n        open_file_in_external_explorer(fname)", "response": "Show files in external file explorer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes path making absolute and removing symlinks", "response": "def fixpath(path):\r\n    \"\"\"Normalize path fixing case, making absolute and removing symlinks\"\"\"\r\n    norm = osp.normcase if os.name == 'nt' else osp.normpath\r\n    return norm(osp.abspath(osp.realpath(path)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new Python script", "response": "def create_script(fname):\r\n    \"\"\"Create a new Python script\"\"\"\r\n    text = os.linesep.join([\"# -*- coding: utf-8 -*-\", \"\", \"\"])\r\n    try:\r\n        encoding.write(to_text_string(text), fname, 'utf-8')\r\n    except EnvironmentError as error:\r\n        QMessageBox.critical(_(\"Save Error\"),\r\n                             _(\"<b>Unable to save file '%s'</b>\"\r\n                               \"<br><br>Error message:<br>%s\"\r\n                               ) % (osp.basename(fname), str(error)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listdir(path, include=r'.', exclude=r'\\.pyc$|^\\.', show_all=False,\r\n            folders_only=False):\r\n    \"\"\"List files and directories\"\"\"\r\n    namelist = []\r\n    dirlist = [to_text_string(osp.pardir)]\r\n    for item in os.listdir(to_text_string(path)):\r\n        if re.search(exclude, item) and not show_all:\r\n            continue\r\n        if osp.isdir(osp.join(path, item)):\r\n            dirlist.append(item)\r\n        elif folders_only:\r\n            continue\r\n        elif re.search(include, item) or show_all:\r\n            namelist.append(item)\r\n    return sorted(dirlist, key=str_lower) + \\\r\n           sorted(namelist, key=str_lower)", "response": "List files and directories in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if path has subdirectories", "response": "def has_subdirectories(path, include, exclude, show_all):\r\n    \"\"\"Return True if path has subdirectories\"\"\"\r\n    try:\r\n        # > 1 because of '..'\r\n        return len( listdir(path, include, exclude,\r\n                            show_all, folders_only=True) ) > 1\r\n    except (IOError, OSError):\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_view(self):\r\n        self.install_model()\r\n        self.fsmodel.directoryLoaded.connect(\r\n            lambda: self.resizeColumnToContents(0))\r\n        self.setAnimated(False)\r\n        self.setSortingEnabled(True)\r\n        self.sortByColumn(0, Qt.AscendingOrder)\r\n        self.fsmodel.modelReset.connect(self.reset_icon_provider)\r\n        self.reset_icon_provider()\r\n        # Disable the view of .spyproject. \r\n        self.filter_directories()", "response": "Setup view of the current model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset single click to open items.", "response": "def set_single_click_to_open(self, value):\r\n        \"\"\"Set single click to open items.\"\"\"\r\n        self.single_click_to_open = value\r\n        self.parent_widget.sig_option_changed.emit('single_click_to_open',\r\n                                                   value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_name_filters(self, name_filters):\r\n        self.name_filters = name_filters\r\n        self.fsmodel.setNameFilters(name_filters)", "response": "Set the name filters for this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_show_all(self, state):\r\n        if state:\r\n            self.fsmodel.setNameFilters([])\r\n        else:\r\n            self.fsmodel.setNameFilters(self.name_filters)", "response": "Toggle show all files state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the filename associated with the given index", "response": "def get_filename(self, index):\r\n        \"\"\"Return filename associated with *index*\"\"\"\r\n        if index:\r\n            return osp.normpath(to_text_string(self.fsmodel.filePath(index)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns dirname associated with index", "response": "def get_dirname(self, index):\r\n        \"\"\"Return dirname associated with *index*\"\"\"\r\n        fname = self.get_filename(index)\r\n        if fname:\r\n            if osp.isdir(fname):\r\n                return fname\r\n            else:\r\n                return osp.dirname(fname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_common_actions(self):\r\n        # Filters\r\n        filters_action = create_action(self, _(\"Edit filename filters...\"),\r\n                                       None, ima.icon('filter'),\r\n                                       triggered=self.edit_filter)\r\n        # Show all files\r\n        all_action = create_action(self, _(\"Show all files\"),\r\n                                   toggled=self.toggle_all)\r\n        all_action.setChecked(self.show_all)\r\n        self.toggle_all(self.show_all)\r\n\r\n        # Show all files\r\n        single_click_to_open = create_action(\r\n            self,\r\n            _(\"Single click to open\"),\r\n            toggled=self.set_single_click_to_open,\r\n        )\r\n        single_click_to_open.setChecked(self.single_click_to_open)\r\n        return [filters_action, all_action, single_click_to_open]", "response": "Setup common actions for the context menu."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toggle_all(self, checked):\r\n        self.parent_widget.sig_option_changed.emit('show_all', checked)\r\n        self.show_all = checked\r\n        self.set_show_all(checked)", "response": "Toggle all files mode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning actions for submenu New...", "response": "def create_file_new_actions(self, fnames):\r\n        \"\"\"Return actions for submenu 'New...'\"\"\"\r\n        if not fnames:\r\n            return []\r\n        new_file_act = create_action(self, _(\"File...\"), \r\n                                     icon=ima.icon('filenew'),\r\n                                     triggered=lambda:\r\n                                     self.new_file(fnames[-1]))\r\n        new_module_act = create_action(self, _(\"Module...\"),\r\n                                       icon=ima.icon('spyder'),\r\n                                       triggered=lambda:\r\n                                         self.new_module(fnames[-1]))\r\n        new_folder_act = create_action(self, _(\"Folder...\"),\r\n                                       icon=ima.icon('folder_new'),\r\n                                       triggered=lambda:\r\n                                        self.new_folder(fnames[-1]))\r\n        new_package_act = create_action(self, _(\"Package...\"),\r\n                                        icon=ima.icon('package_new'),\r\n                                        triggered=lambda:\r\n                                         self.new_package(fnames[-1]))\r\n        return [new_file_act, new_folder_act, None,\r\n                new_module_act, new_package_act]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_file_manage_actions(self, fnames):\r\n        only_files = all([osp.isfile(_fn) for _fn in fnames])\r\n        only_modules = all([osp.splitext(_fn)[1] in ('.py', '.pyw', '.ipy')\r\n                            for _fn in fnames])\r\n        only_notebooks = all([osp.splitext(_fn)[1] == '.ipynb'\r\n                              for _fn in fnames])\r\n        only_valid = all([encoding.is_text_file(_fn) for _fn in fnames])\r\n        run_action = create_action(self, _(\"Run\"), icon=ima.icon('run'),\r\n                                   triggered=self.run)\r\n        edit_action = create_action(self, _(\"Edit\"), icon=ima.icon('edit'),\r\n                                    triggered=self.clicked)\r\n        move_action = create_action(self, _(\"Move...\"),\r\n                                    icon=\"move.png\",\r\n                                    triggered=self.move)\r\n        delete_action = create_action(self, _(\"Delete...\"),\r\n                                      icon=ima.icon('editdelete'),\r\n                                      triggered=self.delete)\r\n        rename_action = create_action(self, _(\"Rename...\"),\r\n                                      icon=ima.icon('rename'),\r\n                                      triggered=self.rename)\r\n        open_external_action = create_action(self, _(\"Open With OS\"), \r\n                                             triggered=self.open_external)\r\n        ipynb_convert_action = create_action(self, _(\"Convert to Python script\"),\r\n                                             icon=ima.icon('python'),\r\n                                             triggered=self.convert_notebooks)\r\n        copy_file_clipboard_action = (\r\n            create_action(self, _(\"Copy\"),\r\n                          QKeySequence(get_shortcut('explorer', 'copy file')),\r\n                          icon=ima.icon('editcopy'),\r\n                          triggered=self.copy_file_clipboard))\r\n        save_file_clipboard_action = (\r\n            create_action(self, _(\"Paste\"),\r\n                          QKeySequence(get_shortcut('explorer', 'paste file')),\r\n                          icon=ima.icon('editpaste'),\r\n                          triggered=self.save_file_clipboard))\r\n        copy_absolute_path_action = (\r\n            create_action(self, _(\"Copy Absolute Path\"), QKeySequence(\r\n                get_shortcut('explorer', 'copy absolute path')),\r\n                          triggered=self.copy_absolute_path))\r\n        copy_relative_path_action = (\r\n            create_action(self, _(\"Copy Relative Path\"), QKeySequence(\r\n                get_shortcut('explorer', 'copy relative path')),\r\n                          triggered=self.copy_relative_path))\r\n        \r\n        actions = []\r\n        if only_modules:\r\n            actions.append(run_action)\r\n        if only_valid and only_files:\r\n            actions.append(edit_action)\r\n        \r\n        if sys.platform == 'darwin':\r\n            text=_(\"Show in Finder\")\r\n        else:\r\n            text=_(\"Show in Folder\")\r\n        external_fileexp_action = create_action(self, text, \r\n                                triggered=self.show_in_external_file_explorer)        \r\n        actions += [delete_action, rename_action]\r\n        basedir = fixpath(osp.dirname(fnames[0]))\r\n        if all([fixpath(osp.dirname(_fn)) == basedir for _fn in fnames]):\r\n            actions.append(move_action)\r\n        actions += [None]\r\n        actions += [copy_file_clipboard_action, save_file_clipboard_action,\r\n                    copy_absolute_path_action, copy_relative_path_action]\r\n        if not QApplication.clipboard().mimeData().hasUrls():\r\n            save_file_clipboard_action.setDisabled(True)\r\n        actions += [None]\r\n        if only_files:\r\n            actions.append(open_external_action)\r\n        actions.append(external_fileexp_action)\r\n        actions.append([None])\r\n        if only_notebooks and nbexporter is not None:\r\n            actions.append(ipynb_convert_action)\r\n\r\n        # VCS support is quite limited for now, so we are enabling the VCS\r\n        # related actions only when a single file/folder is selected:\r\n        dirname = fnames[0] if osp.isdir(fnames[0]) else osp.dirname(fnames[0])\r\n        if len(fnames) == 1 and vcs.is_vcs_repository(dirname):\r\n            commit_slot = lambda : self.vcs_command([dirname], 'commit')\r\n            browse_slot = lambda : self.vcs_command([dirname], 'browse')\r\n            vcs_ci = create_action(self, _(\"Commit\"),\r\n                                   icon=ima.icon('vcs_commit'),\r\n                                   triggered=commit_slot)\r\n            vcs_log = create_action(self, _(\"Browse repository\"),\r\n                                    icon=ima.icon('vcs_browse'),\r\n                                    triggered=browse_slot)\r\n            actions += [None, vcs_ci, vcs_log]\r\n\r\n        return actions", "response": "Return file management actions"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a list of actions that can be performed on a folder.", "response": "def create_folder_manage_actions(self, fnames):\r\n        \"\"\"Return folder management actions\"\"\"\r\n        actions = []\r\n        if os.name == 'nt':\r\n            _title = _(\"Open command prompt here\")\r\n        else:\r\n            _title = _(\"Open terminal here\")\r\n        _title = _(\"Open IPython console here\")\r\n        action = create_action(self, _title,\r\n                               triggered=lambda:\r\n                               self.open_interpreter(fnames))\r\n        actions.append(action)\r\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates context menu actions", "response": "def create_context_menu_actions(self):\r\n        \"\"\"Create context menu actions\"\"\"\r\n        actions = []\r\n        fnames = self.get_selected_filenames()\r\n        new_actions = self.create_file_new_actions(fnames)\r\n        if len(new_actions) > 1:\r\n            # Creating a submenu only if there is more than one entry\r\n            new_act_menu = QMenu(_('New'), self)\r\n            add_actions(new_act_menu, new_actions)\r\n            actions.append(new_act_menu)\r\n        else:\r\n            actions += new_actions\r\n        import_actions = self.create_file_import_actions(fnames)\r\n        if len(import_actions) > 1:\r\n            # Creating a submenu only if there is more than one entry\r\n            import_act_menu = QMenu(_('Import'), self)\r\n            add_actions(import_act_menu, import_actions)\r\n            actions.append(import_act_menu)\r\n        else:\r\n            actions += import_actions\r\n        if actions:\r\n            actions.append(None)\r\n        if fnames:\r\n            actions += self.create_file_manage_actions(fnames)\r\n        if actions:\r\n            actions.append(None)\r\n        if fnames and all([osp.isdir(_fn) for _fn in fnames]):\r\n            actions += self.create_folder_manage_actions(fnames)\r\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect item was double - clicked or enter or return was pressed", "response": "def clicked(self):\r\n        \"\"\"Selected item was double-clicked or enter/return was pressed\"\"\"\r\n        fnames = self.get_selected_filenames()\r\n        for fname in fnames:\r\n            if osp.isdir(fname):\r\n                self.directory_clicked(fname)\r\n            else:\r\n                self.open([fname])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dragMoveEvent(self, event):\r\n        if (event.mimeData().hasFormat(\"text/plain\")):\r\n            event.setDropAction(Qt.MoveAction)\r\n            event.accept()\r\n        else:\r\n            event.ignore()", "response": "Drag and Drop - Move event."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef startDrag(self, dropActions):\r\n        data = QMimeData()\r\n        data.setUrls([QUrl(fname) for fname in self.get_selected_filenames()])\r\n        drag = QDrag(self)\r\n        drag.setMimeData(data)\r\n        drag.exec_()", "response": "Reimplement Qt Method - handle drag event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, fnames=None):\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        for fname in fnames:\r\n            if osp.isfile(fname) and encoding.is_text_file(fname):\r\n                self.parent_widget.sig_open_file.emit(fname)\r\n            else:\r\n                self.open_outside_spyder([fname])", "response": "Open files with the appropriate application"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_external(self, fnames=None):\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        for fname in fnames:\r\n            self.open_outside_spyder([fname])", "response": "Open files with default application"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_outside_spyder(self, fnames):\r\n        for path in sorted(fnames):\r\n            path = file_uri(path)\r\n            ok = programs.start_file(path)\r\n            if not ok:\r\n                self.sig_edit.emit(path)", "response": "Open files outside Spyder with the appropriate application"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving whole directory tree", "response": "def remove_tree(self, dirname):\r\n        \"\"\"Remove whole directory tree\r\n        Reimplemented in project explorer widget\"\"\"\r\n        while osp.exists(dirname):\r\n            try:\r\n                shutil.rmtree(dirname, onerror=misc.onerror)\r\n            except Exception as e:\r\n                # This handles a Windows problem with shutil.rmtree.\r\n                # See issue #8567.\r\n                if type(e).__name__ == \"OSError\":\r\n                    error_path = to_text_string(e.filename)\r\n                    shutil.rmtree(error_path, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a file and return True if successful False otherwise.", "response": "def delete_file(self, fname, multiple, yes_to_all):\r\n        \"\"\"Delete file\"\"\"\r\n        if multiple:\r\n            buttons = QMessageBox.Yes|QMessageBox.YesToAll| \\\r\n                      QMessageBox.No|QMessageBox.Cancel\r\n        else:\r\n            buttons = QMessageBox.Yes|QMessageBox.No\r\n        if yes_to_all is None:\r\n            answer = QMessageBox.warning(self, _(\"Delete\"),\r\n                                 _(\"Do you really want \"\r\n                                   \"to delete <b>%s</b>?\"\r\n                                   ) % osp.basename(fname), buttons)\r\n            if answer == QMessageBox.No:\r\n                return yes_to_all\r\n            elif answer == QMessageBox.Cancel:\r\n                return False\r\n            elif answer == QMessageBox.YesToAll:\r\n                yes_to_all = True\r\n        try:\r\n            if osp.isfile(fname):\r\n                misc.remove_file(fname)\r\n                self.sig_removed.emit(fname)\r\n            else:\r\n                self.remove_tree(fname)\r\n                self.sig_removed_tree.emit(fname)\r\n            return yes_to_all\r\n        except EnvironmentError as error:\r\n            action_str = _('delete')\r\n            QMessageBox.critical(self, _(\"Project Explorer\"),\r\n                            _(\"<b>Unable to %s <i>%s</i></b>\"\r\n                              \"<br><br>Error message:<br>%s\"\r\n                              ) % (action_str, fname, to_text_string(error)))\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, fnames=None):\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        multiple = len(fnames) > 1\r\n        yes_to_all = None\r\n        for fname in fnames:\r\n            spyproject_path = osp.join(fname,'.spyproject')\r\n            if osp.isdir(fname) and osp.exists(spyproject_path):\r\n                QMessageBox.information(self, _('File Explorer'),\r\n                                        _(\"The current directory contains a \"\r\n                                        \"project.<br><br>\"\r\n                                        \"If you want to delete\"\r\n                                        \" the project, please go to \"\r\n                                        \"<b>Projects</b> &raquo; <b>Delete \"\r\n                                        \"Project</b>\"))\r\n            else:    \r\n                yes_to_all = self.delete_file(fname, multiple, yes_to_all)\r\n                if yes_to_all is not None and not yes_to_all:\r\n                    # Canceled\r\n                    break", "response": "Delete files in the selected directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_notebook(self, fname):\r\n        try: \r\n            script = nbexporter().from_filename(fname)[0]\r\n        except Exception as e:\r\n            QMessageBox.critical(self, _('Conversion error'), \r\n                                 _(\"It was not possible to convert this \"\r\n                                 \"notebook. The error is:\\n\\n\") + \\\r\n                                 to_text_string(e))\r\n            return\r\n        self.sig_new_file.emit(script)", "response": "Convert an IPython notebook to a Python script in editor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_notebooks(self):\r\n        fnames = self.get_selected_filenames()\r\n        if not isinstance(fnames, (tuple, list)):\r\n            fnames = [fnames]\r\n        for fname in fnames:\r\n            self.convert_notebook(fname)", "response": "Convert IPython notebooks to Python scripts in editor"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenames a file and return the path.", "response": "def rename_file(self, fname):\r\n        \"\"\"Rename file\"\"\"\r\n        path, valid = QInputDialog.getText(self, _('Rename'),\r\n                              _('New name:'), QLineEdit.Normal,\r\n                              osp.basename(fname))\r\n        if valid:\r\n            path = osp.join(osp.dirname(fname), to_text_string(path))\r\n            if path == fname:\r\n                return\r\n            if osp.exists(path):\r\n                if QMessageBox.warning(self, _(\"Rename\"),\r\n                         _(\"Do you really want to rename <b>%s</b> and \"\r\n                           \"overwrite the existing file <b>%s</b>?\"\r\n                           ) % (osp.basename(fname), osp.basename(path)),\r\n                         QMessageBox.Yes|QMessageBox.No) == QMessageBox.No:\r\n                    return\r\n            try:\r\n                misc.rename_file(fname, path)\r\n                if osp.isfile(fname):\r\n                    self.sig_renamed.emit(fname, path)\r\n                else:\r\n                    self.sig_renamed_tree.emit(fname, path)\r\n                return path\r\n            except EnvironmentError as error:\r\n                QMessageBox.critical(self, _(\"Rename\"),\r\n                            _(\"<b>Unable to rename file <i>%s</i></b>\"\r\n                              \"<br><br>Error message:<br>%s\"\r\n                              ) % (osp.basename(fname), to_text_string(error)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenames files in the current node", "response": "def rename(self, fnames=None):\r\n        \"\"\"Rename files\"\"\"\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        if not isinstance(fnames, (tuple, list)):\r\n            fnames = [fnames]\r\n        for fname in fnames:\r\n            self.rename_file(fname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving files or directories.", "response": "def move(self, fnames=None, directory=None):\r\n        \"\"\"Move files/directories\"\"\"\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        orig = fixpath(osp.dirname(fnames[0]))\r\n        while True:\r\n            self.redirect_stdio.emit(False)\r\n            if directory is None:\r\n                folder = getexistingdirectory(self, _(\"Select directory\"),\r\n                                              orig)\r\n            else:\r\n                folder = directory\r\n            self.redirect_stdio.emit(True)\r\n            if folder:\r\n                folder = fixpath(folder)\r\n                if folder != orig:\r\n                    break\r\n            else:\r\n                return\r\n        for fname in fnames:\r\n            basename = osp.basename(fname)\r\n            try:\r\n                misc.move_file(fname, osp.join(folder, basename))\r\n            except EnvironmentError as error:\r\n                QMessageBox.critical(self, _(\"Error\"),\r\n                                     _(\"<b>Unable to move <i>%s</i></b>\"\r\n                                       \"<br><br>Error message:<br>%s\"\r\n                                       ) % (basename, to_text_string(error)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_folder(self, basedir):\r\n        title = _('New folder')\r\n        subtitle = _('Folder name:')\r\n        self.create_new_folder(basedir, title, subtitle, is_package=False)", "response": "Create a new folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new package in the specified basedir.", "response": "def new_package(self, basedir):\r\n        \"\"\"New package\"\"\"\r\n        title = _('New package')\r\n        subtitle = _('Package name:')\r\n        self.create_new_folder(basedir, title, subtitle, is_package=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new file with the given title and filters", "response": "def create_new_file(self, current_path, title, filters, create_func):\r\n        \"\"\"Create new file\r\n        Returns True if successful\"\"\"\r\n        if current_path is None:\r\n            current_path = ''\r\n        if osp.isfile(current_path):\r\n            current_path = osp.dirname(current_path)\r\n        self.redirect_stdio.emit(False)\r\n        fname, _selfilter = getsavefilename(self, title, current_path, filters)\r\n        self.redirect_stdio.emit(True)\r\n        if fname:\r\n            try:\r\n                create_func(fname)\r\n                return fname\r\n            except EnvironmentError as error:\r\n                QMessageBox.critical(self, _(\"New file\"),\r\n                                     _(\"<b>Unable to create file <i>%s</i>\"\r\n                                       \"</b><br><br>Error message:<br>%s\"\r\n                                       ) % (fname, to_text_string(error)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new file and open it", "response": "def new_file(self, basedir):\r\n        \"\"\"New file\"\"\"\r\n        title = _(\"New file\")\r\n        filters = _(\"All files\")+\" (*)\"\r\n        def create_func(fname):\r\n            \"\"\"File creation callback\"\"\"\r\n            if osp.splitext(fname)[1] in ('.py', '.pyw', '.ipy'):\r\n                create_script(fname)\r\n            else:\r\n                with open(fname, 'wb') as f:\r\n                    f.write(to_binary_string(''))\r\n        fname = self.create_new_file(basedir, title, filters, create_func)\r\n        if fname is not None:\r\n            self.open([fname])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new module and emit it to signal_create_module", "response": "def new_module(self, basedir):\r\n        \"\"\"New module\"\"\"\r\n        title = _(\"New module\")\r\n        filters = _(\"Python scripts\")+\" (*.py *.pyw *.ipy)\"\r\n\r\n        def create_func(fname):\r\n            self.sig_create_module.emit(fname)\r\n\r\n        self.create_new_file(basedir, title, filters, create_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy absolute or relative path to given file ( s ).", "response": "def copy_path(self, fnames=None, method=\"absolute\"):\r\n        \"\"\"Copy absolute or relative path to given file(s)/folders(s).\"\"\"\r\n        cb = QApplication.clipboard()\r\n        explorer_dir = self.fsmodel.rootPath()\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        if not isinstance(fnames, (tuple, list)):\r\n            fnames = [fnames]\r\n        fnames = [_fn.replace(os.sep, \"/\") for _fn in fnames]\r\n        if len(fnames) > 1:\r\n            if method == \"absolute\":\r\n                clipboard_files = ',\\n'.join('\"' + _fn + '\"' for _fn in fnames)\r\n            elif method == \"relative\":\r\n                clipboard_files = ',\\n'.join('\"' +\r\n                                             osp.relpath(_fn, explorer_dir).\r\n                                             replace(os.sep, \"/\") + '\"'\r\n                                             for _fn in fnames)\r\n        else:\r\n            if method == \"absolute\":\r\n                clipboard_files = fnames[0]\r\n            elif method == \"relative\":\r\n                clipboard_files = (osp.relpath(fnames[0], explorer_dir).\r\n                                   replace(os.sep, \"/\"))\r\n        copied_from = self.parent_widget.__class__.__name__\r\n        if copied_from == 'ProjectExplorerWidget' and method == 'relative':\r\n            clipboard_files = [path.strip(',\"') for path in\r\n                               clipboard_files.splitlines()]\r\n            clipboard_files = ['/'.join(path.strip('/').split('/')[1:]) for\r\n                               path in clipboard_files]\r\n            if len(clipboard_files) > 1:\r\n                clipboard_files = ',\\n'.join('\"' + _fn + '\"' for _fn in\r\n                                             clipboard_files)\r\n            else:\r\n                clipboard_files = clipboard_files[0]\r\n        cb.setText(clipboard_files, mode=cb.Clipboard)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_file_clipboard(self, fnames=None):\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        if not isinstance(fnames, (tuple, list)):\r\n            fnames = [fnames]\r\n        try:\r\n            file_content = QMimeData()\r\n            file_content.setUrls([QUrl.fromLocalFile(_fn) for _fn in fnames])\r\n            cb = QApplication.clipboard()\r\n            cb.setMimeData(file_content, mode=cb.Clipboard)\r\n        except Exception as e:\r\n            QMessageBox.critical(self,\r\n                                 _('File/Folder copy error'),\r\n                                 _(\"Cannot copy this type of file(s) or \"\r\n                                     \"folder(s). The error was:\\n\\n\")\r\n                                 + to_text_string(e))", "response": "Copy file to clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npastes file from clipboard into file / project explorer directory.", "response": "def save_file_clipboard(self, fnames=None):\r\n        \"\"\"Paste file from clipboard into file/project explorer directory.\"\"\"\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        if not isinstance(fnames, (tuple, list)):\r\n            fnames = [fnames]\r\n        if len(fnames) >= 1:\r\n            try:\r\n                selected_item = osp.commonpath(fnames)\r\n            except AttributeError:\r\n                #  py2 does not have commonpath\r\n                if len(fnames) > 1:\r\n                    selected_item = osp.normpath(\r\n                            osp.dirname(osp.commonprefix(fnames)))\r\n                else:\r\n                    selected_item = fnames[0]\r\n            if osp.isfile(selected_item):\r\n                parent_path = osp.dirname(selected_item)\r\n            else:\r\n                parent_path = osp.normpath(selected_item)\r\n            cb_data = QApplication.clipboard().mimeData()\r\n            if cb_data.hasUrls():\r\n                urls = cb_data.urls()\r\n                for url in urls:\r\n                    source_name = url.toLocalFile()\r\n                    base_name = osp.basename(source_name)\r\n                    if osp.isfile(source_name):\r\n                        try:\r\n                            while base_name in os.listdir(parent_path):\r\n                                file_no_ext, file_ext = osp.splitext(base_name)\r\n                                end_number = re.search(r'\\d+$', file_no_ext)\r\n                                if end_number:\r\n                                    new_number = int(end_number.group()) + 1\r\n                                else:\r\n                                    new_number = 1\r\n                                left_string = re.sub(r'\\d+$', '', file_no_ext)\r\n                                left_string += str(new_number)\r\n                                base_name = left_string + file_ext\r\n                                destination = osp.join(parent_path, base_name)\r\n                            else:\r\n                                destination = osp.join(parent_path, base_name)\r\n                            shutil.copy(source_name, destination)\r\n                        except Exception as e:\r\n                            QMessageBox.critical(self, _('Error pasting file'),\r\n                                                 _(\"Unsupported copy operation\"\r\n                                                   \". The error was:\\n\\n\")\r\n                                                 + to_text_string(e))\r\n                    else:\r\n                        try:\r\n                            while base_name in os.listdir(parent_path):\r\n                                end_number = re.search(r'\\d+$', base_name)\r\n                                if end_number:\r\n                                    new_number = int(end_number.group()) + 1\r\n                                else:\r\n                                    new_number = 1\r\n                                left_string = re.sub(r'\\d+$', '', base_name)\r\n                                base_name = left_string + str(new_number)\r\n                                destination = osp.join(parent_path, base_name)\r\n                            else:\r\n                                destination = osp.join(parent_path, base_name)\r\n                            if osp.realpath(destination).startswith(\r\n                                    osp.realpath(source_name) + os.sep):\r\n                                QMessageBox.critical(self,\r\n                                                     _('Recursive copy'),\r\n                                                     _(\"Source is an ancestor\"\r\n                                                       \" of destination\"\r\n                                                       \" folder.\"))\r\n                                continue\r\n                            shutil.copytree(source_name, destination)\r\n                        except Exception as e:\r\n                            QMessageBox.critical(self,\r\n                                                 _('Error pasting folder'),\r\n                                                 _(\"Unsupported copy\"\r\n                                                   \" operation. The error was:\"\r\n                                                   \"\\n\\n\") + to_text_string(e))\r\n            else:\r\n                QMessageBox.critical(self, _(\"No file in clipboard\"),\r\n                                     _(\"No file in the clipboard. Please copy\"\r\n                                       \" a file to the clipboard first.\"))\r\n        else:\r\n            if QApplication.clipboard().mimeData().hasUrls():\r\n                QMessageBox.critical(self, _('Blank area'),\r\n                                     _(\"Cannot paste in the blank area.\"))\r\n            else:\r\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_shortcuts(self):\r\n        # Configurable\r\n        copy_clipboard_file = config_shortcut(self.copy_file_clipboard,\r\n                                              context='explorer',\r\n                                              name='copy file', parent=self)\r\n        paste_clipboard_file = config_shortcut(self.save_file_clipboard,\r\n                                               context='explorer',\r\n                                               name='paste file', parent=self)\r\n        copy_absolute_path = config_shortcut(self.copy_absolute_path,\r\n                                             context='explorer',\r\n                                             name='copy absolute path',\r\n                                             parent=self)\r\n        copy_relative_path = config_shortcut(self.copy_relative_path,\r\n                                             context='explorer',\r\n                                             name='copy relative path',\r\n                                             parent=self)\r\n        return [copy_clipboard_file, paste_clipboard_file, copy_absolute_path,\r\n                copy_relative_path]", "response": "Create shortcuts for this file explorer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vcs_command(self, fnames, action):\r\n        try:\r\n            for path in sorted(fnames):\r\n                vcs.run_vcs_tool(path, action)\r\n        except vcs.ActionToolNotFound as error:\r\n            msg = _(\"For %s support, please install one of the<br/> \"\r\n                    \"following tools:<br/><br/>  %s\")\\\r\n                        % (error.vcsname, ', '.join(error.tools))\r\n            QMessageBox.critical(self, _(\"Error\"),\r\n                _(\"\"\"<b>Unable to find external program.</b><br><br>%s\"\"\")\r\n                    % to_text_string(msg))", "response": "VCS action (commit, browse)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_scrollbar_position(self, position):\r\n        # Scrollbars will be restored after the expanded state\r\n        self._scrollbar_positions = position\r\n        if self._to_be_loaded is not None and len(self._to_be_loaded) == 0:\r\n            self.restore_scrollbar_positions()", "response": "Set the position of the scrollbar in the current page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestore scrollbar positions once tree is loaded", "response": "def restore_scrollbar_positions(self):\r\n        \"\"\"Restore scrollbar positions once tree is loaded\"\"\"\r\n        hor, ver = self._scrollbar_positions\r\n        self.horizontalScrollBar().setValue(hor)\r\n        self.verticalScrollBar().setValue(ver)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_expanded_state(self):\r\n        model = self.model()\r\n        # If model is not installed, 'model' will be None: this happens when\r\n        # using the Project Explorer without having selected a workspace yet\r\n        if model is not None:\r\n            self.__expanded_state = []\r\n            for idx in model.persistentIndexList():\r\n                if self.isExpanded(idx):\r\n                    self.__expanded_state.append(self.get_filename(idx))", "response": "Save all items expanded state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore_directory_state(self, fname):\r\n        root = osp.normpath(to_text_string(fname))\r\n        if not osp.exists(root):\r\n            # Directory has been (re)moved outside Spyder\r\n            return\r\n        for basename in os.listdir(root):\r\n            path = osp.normpath(osp.join(root, basename))\r\n            if osp.isdir(path) and path in self.__expanded_state:\r\n                self.__expanded_state.pop(self.__expanded_state.index(path))\r\n                if self._to_be_loaded is None:\r\n                    self._to_be_loaded = []\r\n                self._to_be_loaded.append(path)\r\n                self.setExpanded(self.get_index(path), True)\r\n        if not self.__expanded_state:\r\n            self.fsmodel.directoryLoaded.disconnect(self.restore_directory_state)", "response": "Restore the expanded state of a directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef follow_directories_loaded(self, fname):\r\n        if self._to_be_loaded is None:\r\n            return\r\n        path = osp.normpath(to_text_string(fname))\r\n        if path in self._to_be_loaded:\r\n            self._to_be_loaded.remove(path)\r\n        if self._to_be_loaded is not None and len(self._to_be_loaded) == 0:\r\n            self.fsmodel.directoryLoaded.disconnect(\r\n                                        self.follow_directories_loaded)\r\n            if self._scrollbar_positions is not None:\r\n                # The tree view need some time to render branches:\r\n                QTimer.singleShot(50, self.restore_scrollbar_positions)", "response": "Follow directories loaded during startup"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore all items expanded state", "response": "def restore_expanded_state(self):\r\n        \"\"\"Restore all items expanded state\"\"\"\r\n        if self.__expanded_state is not None:\r\n            # In the old project explorer, the expanded state was a dictionnary:\r\n            if isinstance(self.__expanded_state, list):\r\n                self.fsmodel.directoryLoaded.connect(\r\n                                                  self.restore_directory_state)\r\n                self.fsmodel.directoryLoaded.connect(\r\n                                                self.follow_directories_loaded)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering the directories to show", "response": "def filter_directories(self):\r\n        \"\"\"Filter the directories to show\"\"\"\r\n        index = self.get_index('.spyproject')\r\n        if index is not None:\r\n            self.setRowHidden(index.row(), index.parent(), True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_filter(self, root_path, path_list):\r\n        self.root_path = osp.normpath(to_text_string(root_path))\r\n        self.path_list = [osp.normpath(to_text_string(p)) for p in path_list]\r\n        self.invalidateFilter()", "response": "Setup proxy model filter parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the data for the object at the given index", "response": "def data(self, index, role):\r\n        \"\"\"Show tooltip with full path only for the root directory\"\"\"\r\n        if role == Qt.ToolTipRole:\r\n            root_dir = self.path_list[0].split(osp.sep)[-1]\r\n            if index.data() == root_dir:\r\n                return osp.join(self.root_path, root_dir)\r\n        return QSortFilterProxyModel.data(self, index, role)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_root_path(self, root_path):\r\n        self.root_path = root_path\r\n        self.install_model()\r\n        index = self.fsmodel.setRootPath(root_path)\r\n        self.proxymodel.setup_filter(self.root_path, [])\r\n        self.setRootIndex(self.proxymodel.mapFromSource(index))", "response": "Set the root path of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_index(self, filename):\r\n        index = self.fsmodel.index(filename)\r\n        if index.isValid() and index.model() is self.fsmodel:\r\n            return self.proxymodel.mapFromSource(index)", "response": "Return index associated with filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning filename from index", "response": "def get_filename(self, index):\r\n        \"\"\"Return filename from index\"\"\"\r\n        if index:\r\n            path = self.fsmodel.filePath(self.proxymodel.mapToSource(index))\r\n            return osp.normpath(to_text_string(path))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_common_actions(self):\r\n        actions = super(ExplorerTreeWidget, self).setup_common_actions()\r\n        if self.show_cd_only is None:\r\n            # Enabling the 'show current directory only' option but do not\r\n            # allow the user to disable it\r\n            self.show_cd_only = True\r\n        else:\r\n            # Show current directory only\r\n            cd_only_action = create_action(self,\r\n                                           _(\"Show current directory only\"),\r\n                                           toggled=self.toggle_show_cd_only)\r\n            cd_only_action.setChecked(self.show_cd_only)\r\n            self.toggle_show_cd_only(self.show_cd_only)\r\n            actions.append(cd_only_action)\r\n        return actions", "response": "Setup context menu common actions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntoggling show current directory only mode", "response": "def toggle_show_cd_only(self, checked):\r\n        \"\"\"Toggle show current directory only mode\"\"\"\r\n        self.parent_widget.sig_option_changed.emit('show_cd_only', checked)\r\n        self.show_cd_only = checked\r\n        if checked:\r\n            if self.__last_folder is not None:\r\n                self.set_current_folder(self.__last_folder)\r\n        elif self.__original_root_index is not None:\r\n            self.setRootIndex(self.__original_root_index)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting current folder and return associated model index", "response": "def set_current_folder(self, folder):\r\n        \"\"\"Set current folder and return associated model index\"\"\"\r\n        index = self.fsmodel.setRootPath(folder)\r\n        self.__last_folder = folder\r\n        if self.show_cd_only:\r\n            if self.__original_root_index is None:\r\n                self.__original_root_index = self.rootIndex()\r\n            self.setRootIndex(index)\r\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrefreshing the list of all the related objects in the current folder.", "response": "def refresh(self, new_path=None, force_current=False):\r\n        \"\"\"Refresh widget\r\n        force=False: won't refresh widget if path has not changed\"\"\"\r\n        if new_path is None:\r\n            new_path = getcwd_or_home()\r\n        if force_current:\r\n            index = self.set_current_folder(new_path)\r\n            self.expand(index)\r\n            self.setCurrentIndex(index)\r\n        self.set_previous_enabled.emit(\r\n                             self.histindex is not None and self.histindex > 0)\r\n        self.set_next_enabled.emit(self.histindex is not None and \\\r\n                                   self.histindex < len(self.history)-1)\r\n        # Disable the view of .spyproject. \r\n        self.filter_directories()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngo to parent directory", "response": "def go_to_parent_directory(self):\r\n        \"\"\"Go to parent directory\"\"\"\r\n        self.chdir(osp.abspath(osp.join(getcwd_or_home(), os.pardir)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the current working directory.", "response": "def chdir(self, directory=None, browsing_history=False):\r\n        \"\"\"Set directory as working directory\"\"\"\r\n        if directory is not None:\r\n            directory = osp.abspath(to_text_string(directory))\r\n        if browsing_history:\r\n            directory = self.history[self.histindex]\r\n        elif directory in self.history:\r\n            self.histindex = self.history.index(directory)\r\n        else:\r\n            if self.histindex is None:\r\n                self.history = []\r\n            else:\r\n                self.history = self.history[:self.histindex+1]\r\n            if len(self.history) == 0 or \\\r\n               (self.history and self.history[-1] != directory):\r\n                self.history.append(directory)\r\n            self.histindex = len(self.history)-1\r\n        directory = to_text_string(directory)\r\n        try:\r\n            PermissionError\r\n            FileNotFoundError\r\n        except NameError:\r\n            PermissionError = OSError\r\n            if os.name == 'nt':\r\n                FileNotFoundError = WindowsError\r\n            else:\r\n                FileNotFoundError = IOError\r\n        try:\r\n            os.chdir(directory)\r\n            self.sig_open_dir.emit(directory)\r\n            self.refresh(new_path=directory, force_current=True)\r\n        except PermissionError:\r\n            QMessageBox.critical(self.parent_widget, \"Error\",\r\n                                 _(\"You don't have the right permissions to \"\r\n                                   \"open this directory\"))\r\n        except FileNotFoundError:\r\n            # Handle renaming directories on the fly. See issue #5183\r\n            self.history.pop(self.histindex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the data at the given index", "response": "def data(self, index, role=Qt.DisplayRole):\r\n        \"\"\"Return data at table index\"\"\"\r\n        if not index.isValid():\r\n            return to_qvariant()\r\n        if role == Qt.DisplayRole:\r\n            if index.column() == 0:\r\n                value = osp.basename(self.get_value(index))\r\n                return to_qvariant(value)\r\n            else:\r\n                value = self.get_value(index)\r\n                return to_qvariant(value)\r\n        elif role == Qt.TextAlignmentRole:\r\n            return to_qvariant(int(Qt.AlignLeft|Qt.AlignVCenter))\r\n        elif role == Qt.ToolTipRole:\r\n            if index.column() == 0:\r\n                value = self.get_value(index)\r\n                return to_qvariant(value)\r\n            else:\r\n                return to_qvariant()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the list of languages we need to start servers and create clients for.", "response": "def get_languages(self):\n        \"\"\"\n        Get the list of languages we need to start servers and create\n        clients for.\n        \"\"\"\n        languages = ['python']\n        all_options = CONF.options(self.CONF_SECTION)\n        for option in all_options:\n            if option in [l.lower() for l in LSP_LANGUAGES]:\n                languages.append(option)\n        return languages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_root_path(self, language):\n        path = None\n\n        # Get path of the current project\n        if self.main and self.main.projects:\n            path = self.main.projects.get_active_project_path()\n\n        # If there's no project, use the output of getcwd_or_home.\n        if not path:\n            # We can't use getcwd_or_home for Python because if it\n            # returns home and you have a lot of Python files on it\n            # then computing Rope completions takes a long time\n            # and blocks the PyLS server.\n            # Instead we use an empty directory inside our config one,\n            # just like we did for Rope in Spyder 3.\n            if language == 'python':\n                path = get_conf_path('lsp_root_path')\n                if not osp.exists(path):\n                    os.mkdir(path)\n            else:\n                path = getcwd_or_home()\n\n        return path", "response": "Get the root path for the LSP server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reinitialize_all_clients(self):\n        for language in self.clients:\n            language_client = self.clients[language]\n            if language_client['status'] == self.RUNNING:\n                folder = self.get_root_path(language)\n                instance = language_client['instance']\n                instance.folder = folder\n                instance.initialize()", "response": "Send a new initialize message to each LSP server when the project s project s project root path has changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_client(self, language):\n        started = False\n        if language in self.clients:\n            language_client = self.clients[language]\n            queue = self.register_queue[language]\n\n            # Don't start LSP services when testing unless we demand\n            # them.\n            if running_under_pytest():\n                if not os.environ.get('SPY_TEST_USE_INTROSPECTION'):\n                    return started\n\n            # Start client\n            started = language_client['status'] == self.RUNNING\n            if language_client['status'] == self.STOPPED:\n                config = language_client['config']\n\n                if not config['external']:\n                    port = select_port(default_port=config['port'])\n                    config['port'] = port\n\n                language_client['instance'] = LSPClient(\n                    parent=self,\n                    server_settings=config,\n                    folder=self.get_root_path(language),\n                    language=language\n                )\n\n                # Connect signals emitted by the client to the methods that\n                # can handle them\n                if self.main and self.main.editor:\n                    language_client['instance'].sig_initialize.connect(\n                        self.main.editor.register_lsp_server_settings)\n\n                logger.info(\"Starting LSP client for {}...\".format(language))\n                language_client['instance'].start()\n                language_client['status'] = self.RUNNING\n                for entry in queue:\n                    language_client.register_file(*entry)\n                self.register_queue[language] = []\n        return started", "response": "Start an LSP client for a given language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_python_config(self):\n        python_config = PYTHON_CONFIG.copy()\n\n        # Server options\n        cmd = self.get_option('advanced/command_launch')\n        host = self.get_option('advanced/host')\n        port = self.get_option('advanced/port')\n\n        # Pycodestyle\n        cs_exclude = self.get_option('pycodestyle/exclude').split(',')\n        cs_filename = self.get_option('pycodestyle/filename').split(',')\n        cs_select = self.get_option('pycodestyle/select').split(',')\n        cs_ignore = self.get_option('pycodestyle/ignore').split(',')\n        cs_max_line_length = self.get_option('pycodestyle/max_line_length')\n\n        pycodestyle = {\n            'enabled': self.get_option('pycodestyle'),\n            'exclude': [exclude.strip() for exclude in cs_exclude],\n            'filename': [filename.strip() for filename in cs_filename],\n            'select': [select.strip() for select in cs_select],\n            'ignore': [ignore.strip() for ignore in cs_ignore],\n            'hangClosing': False,\n            'maxLineLength': cs_max_line_length\n        }\n\n        # Linting - Pyflakes\n        pyflakes = {\n            'enabled': self.get_option('pyflakes')\n        }\n\n        # Pydocstyle\n        convention = self.get_option('pydocstyle/convention')\n\n        if convention == 'Custom':\n            ds_ignore = self.get_option('pydocstyle/ignore').split(',')\n            ds_select = self.get_option('pydocstyle/select').split(',')\n            ds_add_ignore = []\n            ds_add_select = []\n        else:\n            ds_ignore = []\n            ds_select = []\n            ds_add_ignore = self.get_option('pydocstyle/ignore').split(',')\n            ds_add_select = self.get_option('pydocstyle/select').split(',')\n\n        pydocstyle = {\n            'enabled': self.get_option('pydocstyle'),\n            'convention': convention,\n            'addIgnore': [ignore.strip() for ignore in ds_add_ignore],\n            'addSelect': [select.strip() for select in ds_add_select],\n            'ignore': [ignore.strip() for ignore in ds_ignore],\n            'select': [select.strip() for select in ds_select],\n            'match': self.get_option('pydocstyle/match'),\n            'matchDir': self.get_option('pydocstyle/match_dir')\n        }\n\n        # Code completion\n        jedi_completion = {\n            'enabled': self.get_option('code_completion'),\n            'include_params': False\n        }\n\n        jedi_signature_help = {\n            'enabled': self.get_option('jedi_signature_help')\n        }\n\n        jedi_definition = {\n            'enabled': self.get_option('jedi_definition'),\n            'follow_imports': self.get_option('jedi_definition/follow_imports')\n        }\n\n        # Advanced\n        external_server = self.get_option('advanced/external')\n\n        # Setup options in json\n        python_config['cmd'] = cmd\n        if host in self.LOCALHOST:\n            python_config['args'] = '--host {host} --port {port} --tcp'\n        else:\n            python_config['args'] = ''\n        python_config['external'] = external_server\n        python_config['host'] = host\n        python_config['port'] = port\n\n        plugins = python_config['configurations']['pyls']['plugins']\n        plugins['pycodestyle'] = pycodestyle\n        plugins['pyflakes'] = pyflakes\n        plugins['pydocstyle'] = pydocstyle\n        plugins['jedi_completion'] = jedi_completion\n        plugins['jedi_signature_help'] = jedi_signature_help\n        plugins['preload']['modules'] = self.get_option('preload_modules')\n        plugins['jedi_definition'] = jedi_definition\n\n        return python_config", "response": "Generate a Python server configuration for our current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a unicode version of string decoded using the file system encoding.", "response": "def to_unicode_from_fs(string):\r\n    \"\"\"\r\n    Return a unicode version of string decoded using the file system encoding.\r\n    \"\"\"\r\n    if not is_string(string): # string is a QString\r\n        string = to_text_string(string.toUtf8(), 'utf-8')\r\n    else:\r\n        if is_binary_string(string):\r\n            try:\r\n                unic = string.decode(FS_ENCODING)\r\n            except (UnicodeError, TypeError):\r\n                pass\r\n            else:\r\n                return unic\r\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_fs_from_unicode(unic):\r\n    if is_unicode(unic):\r\n        try:\r\n            string = unic.encode(FS_ENCODING)\r\n        except (UnicodeError, TypeError):\r\n            pass\r\n        else:\r\n            return string\r\n    return unic", "response": "Returns a byte string version of the given unicode string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to get the coding of a text.", "response": "def get_coding(text, force_chardet=False):\r\n    \"\"\"\r\n    Function to get the coding of a text.\r\n    @param text text to inspect (string)\r\n    @return coding string\r\n    \"\"\"\r\n    if not force_chardet:\r\n        for line in text.splitlines()[:2]:\r\n            try:\r\n                result = CODING_RE.search(to_text_string(line))\r\n            except UnicodeDecodeError:\r\n                # This could fail because to_text_string assume the text\r\n                # is utf8-like and we don't know the encoding to give\r\n                # it to to_text_string\r\n                pass\r\n            else:\r\n                if result:\r\n                    codec = result.group(1)\r\n                    # sometimes we find a false encoding that can\r\n                    # result in errors\r\n                    if codec in CODECS:\r\n                        return codec\r\n\r\n    # Fallback using chardet\r\n    if is_binary_string(text):\r\n        detector = UniversalDetector()\r\n        for line in text.splitlines()[:2]:\r\n            detector.feed(line)\r\n            if detector.done: break\r\n\r\n        detector.close()\r\n        return detector.result['encoding']\r\n\r\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(text):\r\n    try:\r\n        if text.startswith(BOM_UTF8):\r\n            # UTF-8 with BOM\r\n            return to_text_string(text[len(BOM_UTF8):], 'utf-8'), 'utf-8-bom'\r\n        elif text.startswith(BOM_UTF16):\r\n            # UTF-16 with BOM\r\n            return to_text_string(text[len(BOM_UTF16):], 'utf-16'), 'utf-16'\r\n        elif text.startswith(BOM_UTF32):\r\n            # UTF-32 with BOM\r\n            return to_text_string(text[len(BOM_UTF32):], 'utf-32'), 'utf-32'\r\n        coding = get_coding(text)\r\n        if coding:\r\n            return to_text_string(text, coding), coding\r\n    except (UnicodeError, LookupError):\r\n        pass\r\n    # Assume UTF-8\r\n    try:\r\n        return to_text_string(text, 'utf-8'), 'utf-8-guessed'\r\n    except (UnicodeError, LookupError):\r\n        pass\r\n    # Assume Latin-1 (behaviour before 3.7.1)\r\n    return to_text_string(text, \"latin-1\"), 'latin-1-guessed'", "response": "Function to decode a text string into a tuple of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_unicode(string):\r\n    if not is_unicode(string):\r\n        for codec in CODECS:\r\n            try:\r\n                unic = to_text_string(string, codec)\r\n            except UnicodeError:\r\n                pass\r\n            except TypeError:\r\n                break\r\n            else:\r\n                return unic\r\n    return string", "response": "Convert a string to unicode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite text to file filename assuming encoding in an atomic way", "response": "def write(text, filename, encoding='utf-8', mode='wb'):\r\n    \"\"\"\r\n    Write 'text' to file ('filename') assuming 'encoding' in an atomic way\r\n    Return (eventually new) encoding\r\n    \"\"\"\r\n    text, encoding = encode(text, encoding)\r\n    if 'a' in mode:\r\n        with open(filename, mode) as textfile:\r\n            textfile.write(text)\r\n    else:\r\n        with atomic_write(filename,\r\n                          overwrite=True,\r\n                          mode=mode) as textfile:\r\n            textfile.write(text)\r\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite lines to file filename assuming encoding return", "response": "def writelines(lines, filename, encoding='utf-8', mode='wb'):\r\n    \"\"\"\r\n    Write 'lines' to file ('filename') assuming 'encoding'\r\n    Return (eventually new) encoding\r\n    \"\"\"\r\n    return write(os.linesep.join(lines), filename, encoding, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading text from file filename and return it and encoding", "response": "def read(filename, encoding='utf-8'):\r\n    \"\"\"\r\n    Read text from file ('filename')\r\n    Return text and encoding\r\n    \"\"\"\r\n    text, encoding = decode( open(filename, 'rb').read() )\r\n    return text, encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readlines(filename, encoding='utf-8'):\r\n    text, encoding = read(filename, encoding)\r\n    return text.split(os.linesep), encoding", "response": "Read lines from file filename and return them as a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all file type extensions supported by Pygments", "response": "def _get_pygments_extensions():\n    \"\"\"Return all file type extensions supported by Pygments\"\"\"\n    # NOTE: Leave this import here to keep startup process fast!\n    import pygments.lexers as lexers\n\n    extensions = []\n    for lx in lexers.get_all_lexers():\n        lexer_exts = lx[2]\n\n        if lexer_exts:\n            # Reference: This line was included for leaving untrimmed the\n            # extensions not starting with `*`\n            other_exts = [le for le in lexer_exts if not le.startswith('*')]\n            # Reference: This commented line was replaced by the following one\n            # to trim only extensions that start with '*'\n            # lexer_exts = [le[1:] for le in lexer_exts]\n            lexer_exts = [le[1:] for le in lexer_exts if le.startswith('*')]\n            lexer_exts = [le for le in lexer_exts if not le.endswith('_*')]\n            extensions = extensions + list(lexer_exts) + list(other_exts)\n\n    return sorted(list(set(extensions)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_filter(filetypes, ext):\n    if not ext:\n        return ALL_FILTER\n    for title, ftypes in filetypes:\n        if ext in ftypes:\n            return _create_filter(title, ftypes)\n    else:\n        return ''", "response": "Return filter associated to file extension"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_edit_filetypes():\n    # The filter details are not hidden on Windows, so we can't use\n    # all Pygments extensions on that platform\n    if os.name == 'nt':\n        supported_exts = []\n    else:\n        try:\n            supported_exts = _get_pygments_extensions()\n        except Exception:\n            supported_exts = []\n\n    # NOTE: Try to not add too much extensions to this list to not\n    # make the filter look too big on Windows\n    favorite_exts = ['.py', '.R', '.jl', '.ipynb', '.md', '.pyw', '.pyx',\n                     '.c', '.cpp', '.json', '.dat', '.csv', '.tsv', '.txt',\n                     '.ini', '.html', '.js', '.h', '.bat']\n\n    other_exts = [ext for ext in supported_exts if ext not in favorite_exts]\n    all_exts = tuple(favorite_exts + other_exts)\n    text_filetypes = (_(\"Supported text files\"), all_exts)\n    return [text_filetypes] + EDIT_FILETYPES", "response": "Get all file types supported by the Editor"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetects if we are running in an Ubuntu - based distribution", "response": "def is_ubuntu():\n    \"\"\"Detect if we are running in an Ubuntu-based distribution\"\"\"\n    if sys.platform.startswith('linux') and osp.isfile('/etc/lsb-release'):\n        release_info = open('/etc/lsb-release').read()\n        if 'Ubuntu' in release_info:\n            return True\n        else:\n            return False\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_gtk_desktop():\n    if sys.platform.startswith('linux'):\n        xdg_desktop = os.environ.get('XDG_CURRENT_DESKTOP', '')\n        if xdg_desktop:\n            gtk_desktops = ['Unity', 'GNOME', 'XFCE']\n            if any([xdg_desktop.startswith(d) for d in gtk_desktops]):\n                return True\n            else:\n                return False\n        else:\n            return False\n    else:\n        return False", "response": "Detect if we are running in a Gtk - based desktop"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_kde_desktop():\n    if sys.platform.startswith('linux'):\n        xdg_desktop = os.environ.get('XDG_CURRENT_DESKTOP', '')\n        if xdg_desktop:\n            if 'KDE' in xdg_desktop:\n                return True\n            else:\n                return False\n        else:\n            return False\n    else:\n        return False", "response": "Detect if we are running in a KDE desktop"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns PYTHONPATH list as relative paths", "response": "def _get_relative_pythonpath(self):\r\n        \"\"\"Return PYTHONPATH list as relative paths\"\"\"\r\n        # Workaround to replace os.path.relpath (new in Python v2.6):\r\n        offset = len(self.root_path)+len(os.pathsep)\r\n        return [path[offset:] for path in self.pythonpath]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets PYTHONPATH list relative paths", "response": "def _set_relative_pythonpath(self, value):\r\n        \"\"\"Set PYTHONPATH list relative paths\"\"\"\r\n        self.pythonpath = [osp.abspath(osp.join(self.root_path, path))\r\n                           for path in value]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if dirname is in project s PYTHONPATH", "response": "def is_in_pythonpath(self, dirname):\r\n        \"\"\"Return True if dirname is in project's PYTHONPATH\"\"\"\r\n        return fixpath(dirname) in [fixpath(_p) for _p in self.pythonpath]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_from_pythonpath(self, path):\r\n        pathlist = self.get_pythonpath()\r\n        if path in pathlist:\r\n            pathlist.pop(pathlist.index(path))\r\n            self.set_pythonpath(pathlist)\r\n            return True\r\n        else:\r\n            return False", "response": "Remove path from project s PYTHONPATH Return True if path was removed False if it was not found"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd path to the project s PYTHONPATH Return True if path was added False if it was already there", "response": "def add_to_pythonpath(self, path):\r\n        \"\"\"Add path to project's PYTHONPATH\r\n        Return True if path was added, False if it was already there\"\"\"\r\n        pathlist = self.get_pythonpath()\r\n        if path in pathlist:\r\n            return False\r\n        else:\r\n            pathlist.insert(0, path)\r\n            self.set_pythonpath(pathlist)\r\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_package_data(name, extlist):\n    flist = []\n    # Workaround to replace os.path.relpath (not available until Python 2.6):\n    offset = len(name)+len(os.pathsep)\n    for dirpath, _dirnames, filenames in os.walk(name):\n        for fname in filenames:\n            if not fname.startswith('.') and osp.splitext(fname)[1] in extlist:\n                flist.append(osp.join(dirpath, fname)[offset:])\n    return flist", "response": "Return data files for a given package with extensions in extlist"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of subpackages of package name", "response": "def get_subpackages(name):\n    \"\"\"Return subpackages of package *name*\"\"\"\n    splist = []\n    for dirpath, _dirnames, _filenames in os.walk(name):\n        if osp.isfile(osp.join(dirpath, '__init__.py')):\n            splist.append(\".\".join(dirpath.split(os.sep)))\n    return splist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the path to the Python documentation file if available", "response": "def get_python_doc_path():\r\n    \"\"\"\r\n    Return Python documentation path\r\n    (Windows: return the PythonXX.chm path if available)\r\n    \"\"\"\r\n    if os.name == 'nt':\r\n        doc_path = osp.join(sys.prefix, \"Doc\")\r\n        if not osp.isdir(doc_path):\r\n            return\r\n        python_chm = [path for path in os.listdir(doc_path)\r\n                      if re.match(r\"(?i)Python[0-9]{3,6}.chm\", path)]\r\n        if python_chm:\r\n            return file_uri(osp.join(doc_path, python_chm[0]))\r\n    else:\r\n        vinf = sys.version_info\r\n        doc_path = '/usr/share/doc/python%d.%d/html' % (vinf[0], vinf[1])\r\n    python_doc = osp.join(doc_path, \"index.html\")\r\n    if osp.isfile(python_doc):\r\n        return file_uri(python_doc)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the OpenGL implementation used by Spyder.", "response": "def set_opengl_implementation(option):\r\n    \"\"\"\r\n    Set the OpenGL implementation used by Spyder.\r\n\r\n    See issue 7447 for the details.\r\n    \"\"\"\r\n    if option == 'software':\r\n        QCoreApplication.setAttribute(Qt.AA_UseSoftwareOpenGL)\r\n        if QQuickWindow is not None:\r\n            QQuickWindow.setSceneGraphBackend(QSGRendererInterface.Software)\r\n    elif option == 'desktop':\r\n        QCoreApplication.setAttribute(Qt.AA_UseDesktopOpenGL)\r\n        if QQuickWindow is not None:\r\n            QQuickWindow.setSceneGraphBackend(QSGRendererInterface.OpenGL)\r\n    elif option == 'gles':\r\n        QCoreApplication.setAttribute(Qt.AA_UseOpenGLES)\r\n        if QQuickWindow is not None:\r\n            QQuickWindow.setSceneGraphBackend(QSGRendererInterface.OpenGL)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_logging(cli_options):\r\n    if cli_options.debug_info or get_debug_level() > 0:\r\n        levels = {2: logging.INFO, 3: logging.DEBUG}\r\n        log_level = levels[get_debug_level()]\r\n        log_format = '%(asctime)s [%(levelname)s] [%(name)s] -> %(message)s'\r\n\r\n        if cli_options.debug_output == 'file':\r\n            log_file = 'spyder-debug.log'\r\n        else:\r\n            log_file = None\r\n\r\n        logging.basicConfig(level=log_level,\r\n                            format=log_format,\r\n                            filename=log_file,\r\n                            filemode='w+')", "response": "Setup logging with cli options defined by the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef qt_message_handler(msg_type, msg_log_context, msg_string):\r\n    BLACKLIST = [\r\n        'QMainWidget::resizeDocks: all sizes need to be larger than 0',\r\n    ]\r\n    if DEV or msg_string not in BLACKLIST:\r\n        print(msg_string)", "response": "This function is called by Qt when a message is received from the console."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize Qt and set up the mainloop", "response": "def initialize():\r\n    \"\"\"Initialize Qt, patching sys.exit and eventually setting up ETS\"\"\"\r\n    # This doesn't create our QApplication, just holds a reference to\r\n    # MAIN_APP, created above to show our splash screen as early as\r\n    # possible\r\n    app = qapplication()\r\n\r\n    # --- Set application icon\r\n    app.setWindowIcon(APP_ICON)\r\n\r\n    #----Monkey patching QApplication\r\n    class FakeQApplication(QApplication):\r\n        \"\"\"Spyder's fake QApplication\"\"\"\r\n        def __init__(self, args):\r\n            self = app  # analysis:ignore\r\n        @staticmethod\r\n        def exec_():\r\n            \"\"\"Do nothing because the Qt mainloop is already running\"\"\"\r\n            pass\r\n    from qtpy import QtWidgets\r\n    QtWidgets.QApplication = FakeQApplication\r\n\r\n    # ----Monkey patching sys.exit\r\n    def fake_sys_exit(arg=[]):\r\n        pass\r\n    sys.exit = fake_sys_exit\r\n\r\n    # ----Monkey patching sys.excepthook to avoid crashes in PyQt 5.5+\r\n    if PYQT5:\r\n        def spy_excepthook(type_, value, tback):\r\n            sys.__excepthook__(type_, value, tback)\r\n        sys.excepthook = spy_excepthook\r\n\r\n    # Removing arguments from sys.argv as in standard Python interpreter\r\n    sys.argv = ['']\r\n\r\n    # Selecting Qt4 backend for Enthought Tool Suite (if installed)\r\n    try:\r\n        from enthought.etsconfig.api import ETSConfig\r\n        ETSConfig.toolkit = 'qt4'\r\n    except ImportError:\r\n        pass\r\n\r\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_spyder(app, options, args):\r\n    #TODO: insert here\r\n    # Main window\r\n    main = MainWindow(options)\r\n    try:\r\n        main.setup()\r\n    except BaseException:\r\n        if main.console is not None:\r\n            try:\r\n                main.console.shell.exit_interpreter()\r\n            except BaseException:\r\n                pass\r\n        raise\r\n\r\n    main.show()\r\n    main.post_visible_setup()\r\n\r\n    if main.console:\r\n        main.console.shell.interpreter.namespace['spy'] = \\\r\n                                                    Spy(app=app, window=main)\r\n\r\n    # Open external files passed as args\r\n    if args:\r\n        for a in args:\r\n            main.open_external_file(a)\r\n\r\n    # Don't show icons in menus for Mac\r\n    if sys.platform == 'darwin':\r\n        QCoreApplication.setAttribute(Qt.AA_DontShowIconsInMenus, True)\r\n\r\n    # Open external files with our Mac app\r\n    if running_in_mac_app():\r\n        app.sig_open_external_file.connect(main.open_external_file)\r\n\r\n    # To give focus again to the last focused widget after restoring\r\n    # the window\r\n    app.focusChanged.connect(main.change_last_focused_widget)\r\n\r\n    if not running_under_pytest():\r\n        app.exec_()\r\n    return main", "response": "Create and show Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and return a new toolbar with the given title and object_name and iconsize", "response": "def create_toolbar(self, title, object_name, iconsize=24):\r\n        \"\"\"Create and return toolbar with *title* and *object_name*\"\"\"\r\n        toolbar = self.addToolBar(title)\r\n        toolbar.setObjectName(object_name)\r\n        toolbar.setIconSize(QSize(iconsize, iconsize))\r\n        self.toolbarslist.append(toolbar)\r\n        return toolbar"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup(self):\r\n        logger.info(\"*** Start of MainWindow setup ***\")\r\n\r\n        logger.info(\"Applying theme configuration...\")\r\n        ui_theme = CONF.get('appearance', 'ui_theme')\r\n        color_scheme = CONF.get('appearance', 'selected')\r\n\r\n        if ui_theme == 'dark':\r\n            dark_qss = qdarkstyle.load_stylesheet_from_environment()\r\n            self.setStyleSheet(dark_qss)\r\n            self.statusBar().setStyleSheet(dark_qss)\r\n            css_path = DARK_CSS_PATH\r\n        elif ui_theme == 'automatic':\r\n            if not is_dark_font_color(color_scheme):\r\n                dark_qss = qdarkstyle.load_stylesheet_from_environment()\r\n                self.setStyleSheet(dark_qss)\r\n                self.statusBar().setStyleSheet(dark_qss)\r\n                css_path = DARK_CSS_PATH\r\n            else:\r\n                css_path = CSS_PATH\r\n        else:\r\n            css_path = CSS_PATH\r\n\r\n        logger.info(\"Creating core actions...\")\r\n        self.close_dockwidget_action = create_action(\r\n            self, icon=ima.icon('close_pane'),\r\n            text=_(\"Close current pane\"),\r\n            triggered=self.close_current_dockwidget,\r\n            context=Qt.ApplicationShortcut\r\n        )\r\n        self.register_shortcut(self.close_dockwidget_action, \"_\",\r\n                               \"Close pane\")\r\n        self.lock_interface_action = create_action(\r\n            self,\r\n            _(\"Lock panes and toolbars\"),\r\n            toggled=self.toggle_lock,\r\n            context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.lock_interface_action, \"_\",\r\n                               \"Lock unlock panes\")\r\n        # custom layouts shortcuts\r\n        self.toggle_next_layout_action = create_action(self,\r\n                                    _(\"Use next layout\"),\r\n                                    triggered=self.toggle_next_layout,\r\n                                    context=Qt.ApplicationShortcut)\r\n        self.toggle_previous_layout_action = create_action(self,\r\n                                    _(\"Use previous layout\"),\r\n                                    triggered=self.toggle_previous_layout,\r\n                                    context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.toggle_next_layout_action, \"_\",\r\n                               \"Use next layout\")\r\n        self.register_shortcut(self.toggle_previous_layout_action, \"_\",\r\n                               \"Use previous layout\")\r\n        # File switcher shortcuts\r\n        self.file_switcher_action = create_action(\r\n                                    self,\r\n                                    _('File switcher...'),\r\n                                    icon=ima.icon('filelist'),\r\n                                    tip=_('Fast switch between files'),\r\n                                    triggered=self.open_fileswitcher,\r\n                                    context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.file_switcher_action, context=\"_\",\r\n                               name=\"File switcher\")\r\n        self.symbol_finder_action = create_action(\r\n                                    self, _('Symbol finder...'),\r\n                                    icon=ima.icon('symbol_find'),\r\n                                    tip=_('Fast symbol search in file'),\r\n                                    triggered=self.open_symbolfinder,\r\n                                    context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.symbol_finder_action, context=\"_\",\r\n                               name=\"symbol finder\", add_sc_to_tip=True)\r\n        self.file_toolbar_actions = [self.file_switcher_action,\r\n                                     self.symbol_finder_action]\r\n\r\n        def create_edit_action(text, tr_text, icon):\r\n            textseq = text.split(' ')\r\n            method_name = textseq[0].lower()+\"\".join(textseq[1:])\r\n            action = create_action(self, tr_text,\r\n                                   icon=icon,\r\n                                   triggered=self.global_callback,\r\n                                   data=method_name,\r\n                                   context=Qt.WidgetShortcut)\r\n            self.register_shortcut(action, \"Editor\", text)\r\n            return action\r\n\r\n        self.undo_action = create_edit_action('Undo', _('Undo'),\r\n                                              ima.icon('undo'))\r\n        self.redo_action = create_edit_action('Redo', _('Redo'),\r\n                                              ima.icon('redo'))\r\n        self.copy_action = create_edit_action('Copy', _('Copy'),\r\n                                              ima.icon('editcopy'))\r\n        self.cut_action = create_edit_action('Cut', _('Cut'),\r\n                                             ima.icon('editcut'))\r\n        self.paste_action = create_edit_action('Paste', _('Paste'),\r\n                                               ima.icon('editpaste'))\r\n        self.selectall_action = create_edit_action(\"Select All\",\r\n                                                   _(\"Select All\"),\r\n                                                   ima.icon('selectall'))\r\n\r\n        self.edit_menu_actions = [self.undo_action, self.redo_action,\r\n                                  None, self.cut_action, self.copy_action,\r\n                                  self.paste_action, self.selectall_action]\r\n\r\n        namespace = None\r\n        logger.info(\"Creating toolbars...\")\r\n        # File menu/toolbar\r\n        self.file_menu = self.menuBar().addMenu(_(\"&File\"))\r\n        self.file_toolbar = self.create_toolbar(_(\"File toolbar\"),\r\n                                                \"file_toolbar\")\r\n\r\n        # Edit menu/toolbar\r\n        self.edit_menu = self.menuBar().addMenu(_(\"&Edit\"))\r\n        self.edit_toolbar = self.create_toolbar(_(\"Edit toolbar\"),\r\n                                                \"edit_toolbar\")\r\n\r\n        # Search menu/toolbar\r\n        self.search_menu = self.menuBar().addMenu(_(\"&Search\"))\r\n        self.search_toolbar = self.create_toolbar(_(\"Search toolbar\"),\r\n                                                    \"search_toolbar\")\r\n\r\n        # Source menu/toolbar\r\n        self.source_menu = self.menuBar().addMenu(_(\"Sour&ce\"))\r\n        self.source_toolbar = self.create_toolbar(_(\"Source toolbar\"),\r\n                                                    \"source_toolbar\")\r\n\r\n        # Run menu/toolbar\r\n        self.run_menu = self.menuBar().addMenu(_(\"&Run\"))\r\n        self.run_toolbar = self.create_toolbar(_(\"Run toolbar\"),\r\n                                                \"run_toolbar\")\r\n\r\n        # Debug menu/toolbar\r\n        self.debug_menu = self.menuBar().addMenu(_(\"&Debug\"))\r\n        self.debug_toolbar = self.create_toolbar(_(\"Debug toolbar\"),\r\n                                                    \"debug_toolbar\")\r\n\r\n        # Consoles menu/toolbar\r\n        self.consoles_menu = self.menuBar().addMenu(_(\"C&onsoles\"))\r\n        self.consoles_menu.aboutToShow.connect(\r\n                self.update_execution_state_kernel)\r\n\r\n        # Projects menu\r\n        self.projects_menu = self.menuBar().addMenu(_(\"&Projects\"))\r\n        self.projects_menu.aboutToShow.connect(self.valid_project)\r\n        # Tools menu\r\n        self.tools_menu = self.menuBar().addMenu(_(\"&Tools\"))\r\n\r\n        # View menu\r\n        self.view_menu = self.menuBar().addMenu(_(\"&View\"))\r\n\r\n        # Help menu\r\n        self.help_menu = self.menuBar().addMenu(_(\"&Help\"))\r\n\r\n        # Status bar\r\n        status = self.statusBar()\r\n        status.setObjectName(\"StatusBar\")\r\n        status.showMessage(_(\"Welcome to Spyder!\"), 5000)\r\n\r\n        logger.info(\"Creating Tools menu...\")\r\n        # Tools + External Tools\r\n        prefs_action = create_action(self, _(\"Pre&ferences\"),\r\n                                        icon=ima.icon('configure'),\r\n                                        triggered=self.edit_preferences,\r\n                                        context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(prefs_action, \"_\", \"Preferences\",\r\n                               add_sc_to_tip=True)\r\n        spyder_path_action = create_action(self,\r\n                                _(\"PYTHONPATH manager\"),\r\n                                None, icon=ima.icon('pythonpath'),\r\n                                triggered=self.path_manager_callback,\r\n                                tip=_(\"Python Path Manager\"),\r\n                                menurole=QAction.ApplicationSpecificRole)\r\n        reset_spyder_action = create_action(\r\n            self, _(\"Reset Spyder to factory defaults\"),\r\n            triggered=self.reset_spyder)\r\n        self.tools_menu_actions = [prefs_action, spyder_path_action]\r\n        if WinUserEnvDialog is not None:\r\n            winenv_action = create_action(self,\r\n                    _(\"Current user environment variables...\"),\r\n                    icon='win_env.png',\r\n                    tip=_(\"Show and edit current user environment \"\r\n                            \"variables in Windows registry \"\r\n                            \"(i.e. for all sessions)\"),\r\n                    triggered=self.win_env)\r\n            self.tools_menu_actions.append(winenv_action)\r\n        self.tools_menu_actions += [MENU_SEPARATOR, reset_spyder_action]\r\n\r\n        # External Tools submenu\r\n        self.external_tools_menu = QMenu(_(\"External Tools\"))\r\n        self.external_tools_menu_actions = []\r\n        # WinPython control panel\r\n        self.wp_action = create_action(self, _(\"WinPython control panel\"),\r\n                    icon=get_icon('winpython.svg'),\r\n                    triggered=lambda:\r\n                    programs.run_python_script('winpython', 'controlpanel'))\r\n        if os.name == 'nt' and is_module_installed('winpython'):\r\n            self.external_tools_menu_actions.append(self.wp_action)\r\n\r\n        # Qt-related tools\r\n        additact = []\r\n        for name in (\"designer-qt4\", \"designer\"):\r\n            qtdact = create_program_action(self, _(\"Qt Designer\"), name)\r\n            if qtdact:\r\n                break\r\n        for name in (\"linguist-qt4\", \"linguist\"):\r\n            qtlact = create_program_action(self, _(\"Qt Linguist\"), \"linguist\")\r\n            if qtlact:\r\n                break\r\n        args = ['-no-opengl'] if os.name == 'nt' else []\r\n        for act in (qtdact, qtlact):\r\n            if act:\r\n                additact.append(act)\r\n        if additact and is_module_installed('winpython'):\r\n            self.external_tools_menu_actions += [None] + additact\r\n\r\n        # Guidata and Sift\r\n        logger.info(\"Creating guidata and sift entries...\")\r\n        gdgq_act = []\r\n        # Guidata and Guiqwt don't support PyQt5 yet and they fail\r\n        # with an AssertionError when imported using those bindings\r\n        # (see issue 2274)\r\n        try:\r\n            from guidata import configtools\r\n            from guidata import config       # analysis:ignore\r\n            guidata_icon = configtools.get_icon('guidata.svg')\r\n            guidata_act = create_python_script_action(self,\r\n                                    _(\"guidata examples\"), guidata_icon,\r\n                                    \"guidata\",\r\n                                    osp.join(\"tests\", \"__init__\"))\r\n            gdgq_act += [guidata_act]\r\n        except:\r\n            pass\r\n        try:\r\n            from guidata import configtools\r\n            from guiqwt import config  # analysis:ignore\r\n            guiqwt_icon = configtools.get_icon('guiqwt.svg')\r\n            guiqwt_act = create_python_script_action(self,\r\n                            _(\"guiqwt examples\"), guiqwt_icon, \"guiqwt\",\r\n                            osp.join(\"tests\", \"__init__\"))\r\n            if guiqwt_act:\r\n                gdgq_act += [guiqwt_act]\r\n            sift_icon = configtools.get_icon('sift.svg')\r\n            sift_act = create_python_script_action(self, _(\"Sift\"),\r\n                        sift_icon, \"guiqwt\", osp.join(\"tests\", \"sift\"))\r\n            if sift_act:\r\n                gdgq_act += [sift_act]\r\n        except:\r\n            pass\r\n        if gdgq_act:\r\n            self.external_tools_menu_actions += [None] + gdgq_act\r\n\r\n        # Maximize current plugin\r\n        self.maximize_action = create_action(self, '',\r\n                                        triggered=self.maximize_dockwidget,\r\n                                        context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.maximize_action, \"_\", \"Maximize pane\")\r\n        self.__update_maximize_action()\r\n\r\n        # Fullscreen mode\r\n        self.fullscreen_action = create_action(self,\r\n                                        _(\"Fullscreen mode\"),\r\n                                        triggered=self.toggle_fullscreen,\r\n                                        context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.fullscreen_action, \"_\",\r\n                               \"Fullscreen mode\", add_sc_to_tip=True)\r\n\r\n        # Main toolbar\r\n        self.main_toolbar_actions = [self.maximize_action,\r\n                                     self.fullscreen_action,\r\n                                     None,\r\n                                     prefs_action, spyder_path_action]\r\n\r\n        self.main_toolbar = self.create_toolbar(_(\"Main toolbar\"),\r\n                                                \"main_toolbar\")\r\n\r\n        # Internal console plugin\r\n        logger.info(\"Loading internal console...\")\r\n        from spyder.plugins.console.plugin import Console\r\n        self.console = Console(self, namespace, exitfunc=self.closing,\r\n                            profile=self.profile,\r\n                            multithreaded=self.multithreaded,\r\n                            message=_(\"Spyder Internal Console\\n\\n\"\r\n                                    \"This console is used to report application\\n\"\r\n                                    \"internal errors and to inspect Spyder\\n\"\r\n                                    \"internals with the following commands:\\n\"\r\n                                    \"  spy.app, spy.window, dir(spy)\\n\\n\"\r\n                                    \"Please don't use it to run your code\\n\\n\"))\r\n        self.console.register_plugin()\r\n\r\n        # Language Server Protocol Client initialization\r\n        self.set_splash(_(\"Starting Language Server Protocol manager...\"))\r\n        from spyder.plugins.editor.lsp.manager import LSPManager\r\n        self.lspmanager = LSPManager(self)\r\n\r\n        # Working directory plugin\r\n        logger.info(\"Loading working directory...\")\r\n        from spyder.plugins.workingdirectory.plugin import WorkingDirectory\r\n        self.workingdirectory = WorkingDirectory(self, self.init_workdir, main=self)\r\n        self.workingdirectory.register_plugin()\r\n        self.toolbarslist.append(self.workingdirectory.toolbar)\r\n\r\n        # Help plugin\r\n        if CONF.get('help', 'enable'):\r\n            self.set_splash(_(\"Loading help...\"))\r\n            from spyder.plugins.help.plugin import Help\r\n            self.help = Help(self, css_path=css_path)\r\n            self.help.register_plugin()\r\n\r\n        # Outline explorer widget\r\n        if CONF.get('outline_explorer', 'enable'):\r\n            self.set_splash(_(\"Loading outline explorer...\"))\r\n            from spyder.plugins.outlineexplorer.plugin import OutlineExplorer\r\n            self.outlineexplorer = OutlineExplorer(self)\r\n            self.outlineexplorer.register_plugin()\r\n\r\n        # Editor plugin\r\n        self.set_splash(_(\"Loading editor...\"))\r\n        from spyder.plugins.editor.plugin import Editor\r\n        self.editor = Editor(self)\r\n        self.editor.register_plugin()\r\n\r\n        # Start LSP client\r\n        self.set_splash(_(\"Launching LSP Client for Python...\"))\r\n        self.lspmanager.start_client(language='python')\r\n\r\n        # Populating file menu entries\r\n        quit_action = create_action(self, _(\"&Quit\"),\r\n                                    icon=ima.icon('exit'),\r\n                                    tip=_(\"Quit\"),\r\n                                    triggered=self.console.quit,\r\n                                    context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(quit_action, \"_\", \"Quit\")\r\n        restart_action = create_action(self, _(\"&Restart\"),\r\n                                       icon=ima.icon('restart'),\r\n                                       tip=_(\"Restart\"),\r\n                                       triggered=self.restart,\r\n                                       context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(restart_action, \"_\", \"Restart\")\r\n\r\n        self.file_menu_actions += [self.file_switcher_action,\r\n                                   self.symbol_finder_action, None,\r\n                                   restart_action, quit_action]\r\n        self.set_splash(\"\")\r\n\r\n        # Namespace browser\r\n        self.set_splash(_(\"Loading namespace browser...\"))\r\n        from spyder.plugins.variableexplorer.plugin import VariableExplorer\r\n        self.variableexplorer = VariableExplorer(self)\r\n        self.variableexplorer.register_plugin()\r\n\r\n        # Figure browser\r\n        self.set_splash(_(\"Loading figure browser...\"))\r\n        from spyder.plugins.plots.plugin import Plots\r\n        self.plots = Plots(self)\r\n        self.plots.register_plugin()\r\n\r\n        # History log widget\r\n        if CONF.get('historylog', 'enable'):\r\n            self.set_splash(_(\"Loading history plugin...\"))\r\n            from spyder.plugins.history.plugin import HistoryLog\r\n            self.historylog = HistoryLog(self)\r\n            self.historylog.register_plugin()\r\n\r\n        # IPython console\r\n        self.set_splash(_(\"Loading IPython console...\"))\r\n        from spyder.plugins.ipythonconsole.plugin import IPythonConsole\r\n        self.ipyconsole = IPythonConsole(self, css_path=css_path)\r\n        self.ipyconsole.register_plugin()\r\n\r\n        # Explorer\r\n        if CONF.get('explorer', 'enable'):\r\n            self.set_splash(_(\"Loading file explorer...\"))\r\n            from spyder.plugins.explorer.plugin import Explorer\r\n            self.explorer = Explorer(self)\r\n            self.explorer.register_plugin()\r\n\r\n        # Online help widget\r\n        try:    # Qt >= v4.4\r\n            from spyder.plugins.onlinehelp.plugin import OnlineHelp\r\n        except ImportError:    # Qt < v4.4\r\n            OnlineHelp = None  # analysis:ignore\r\n        if CONF.get('onlinehelp', 'enable') and OnlineHelp is not None:\r\n            self.set_splash(_(\"Loading online help...\"))\r\n            self.onlinehelp = OnlineHelp(self)\r\n            self.onlinehelp.register_plugin()\r\n\r\n        # Project explorer widget\r\n        self.set_splash(_(\"Loading project explorer...\"))\r\n        from spyder.plugins.projects.plugin import Projects\r\n        self.projects = Projects(self)\r\n        self.projects.register_plugin()\r\n        self.project_path = self.projects.get_pythonpath(at_start=True)\r\n\r\n        # Find in files\r\n        if CONF.get('find_in_files', 'enable'):\r\n            from spyder.plugins.findinfiles.plugin import FindInFiles\r\n            self.findinfiles = FindInFiles(self)\r\n            self.findinfiles.register_plugin()\r\n\r\n        # Load other plugins (former external plugins)\r\n        # TODO: Use this bucle to load all internall plugins and remove\r\n        # duplicated code\r\n        other_plugins = ['breakpoints', 'profiler', 'pylint']\r\n        for plugin_name in other_plugins:\r\n            if CONF.get(plugin_name, 'enable'):\r\n                module = importlib.import_module(\r\n                        'spyder.plugins.{}'.format(plugin_name))\r\n                plugin = module.PLUGIN_CLASS(self)\r\n                if plugin.check_compatibility()[0]:\r\n                    self.thirdparty_plugins.append(plugin)\r\n                    plugin.register_plugin()\r\n\r\n        # Third-party plugins\r\n        self.set_splash(_(\"Loading third-party plugins...\"))\r\n        for mod in get_spyderplugins_mods():\r\n            try:\r\n                plugin = mod.PLUGIN_CLASS(self)\r\n                if plugin.check_compatibility()[0]:\r\n                    self.thirdparty_plugins.append(plugin)\r\n                    plugin.register_plugin()\r\n            except Exception as error:\r\n                print(\"%s: %s\" % (mod, str(error)), file=STDERR)\r\n                traceback.print_exc(file=STDERR)\r\n\r\n        self.set_splash(_(\"Setting up main window...\"))\r\n\r\n        # Help menu\r\n        trouble_action = create_action(self,\r\n                                        _(\"Troubleshooting...\"),\r\n                                        triggered=self.trouble_guide)\r\n        dep_action = create_action(self, _(\"Dependencies...\"),\r\n                                    triggered=self.show_dependencies,\r\n                                    icon=ima.icon('advanced'))\r\n        report_action = create_action(self,\r\n                                        _(\"Report issue...\"),\r\n                                        icon=ima.icon('bug'),\r\n                                        triggered=self.report_issue)\r\n        support_action = create_action(self,\r\n                                        _(\"Spyder support...\"),\r\n                                        triggered=self.google_group)\r\n        self.check_updates_action = create_action(self,\r\n                                                _(\"Check for updates...\"),\r\n                                                triggered=self.check_updates)\r\n\r\n        # Spyder documentation\r\n        spyder_doc = 'https://docs.spyder-ide.org/'\r\n        doc_action = create_action(self, _(\"Spyder documentation\"),\r\n                                   icon=ima.icon('DialogHelpButton'),\r\n                                   triggered=lambda:\r\n                                   programs.start_file(spyder_doc))\r\n        self.register_shortcut(doc_action, \"_\",\r\n                               \"spyder documentation\")\r\n\r\n        if self.help is not None:\r\n            tut_action = create_action(self, _(\"Spyder tutorial\"),\r\n                                       triggered=self.help.show_tutorial)\r\n        else:\r\n            tut_action = None\r\n\r\n        shortcuts_action = create_action(self, _(\"Shortcuts Summary\"),\r\n                                         shortcut=\"Meta+F1\",\r\n                                         triggered=self.show_shortcuts_dialog)\r\n\r\n        #----- Tours\r\n        self.tour = tour.AnimatedTour(self)\r\n        self.tours_menu = QMenu(_(\"Interactive tours\"), self)\r\n        self.tour_menu_actions = []\r\n        # TODO: Only show intro tour for now. When we are close to finish\r\n        # 3.0, we will finish and show the other tour\r\n        self.tours_available = tour.get_tours(0)\r\n\r\n        for i, tour_available in enumerate(self.tours_available):\r\n            self.tours_available[i]['last'] = 0\r\n            tour_name = tour_available['name']\r\n\r\n            def trigger(i=i, self=self):  # closure needed!\r\n                return lambda: self.show_tour(i)\r\n\r\n            temp_action = create_action(self, tour_name, tip=\"\",\r\n                                        triggered=trigger())\r\n            self.tour_menu_actions += [temp_action]\r\n\r\n        self.tours_menu.addActions(self.tour_menu_actions)\r\n\r\n        self.help_menu_actions = [doc_action, tut_action, shortcuts_action,\r\n                                  self.tours_menu,\r\n                                  MENU_SEPARATOR, trouble_action,\r\n                                  report_action, dep_action,\r\n                                  self.check_updates_action, support_action,\r\n                                  MENU_SEPARATOR]\r\n        # Python documentation\r\n        if get_python_doc_path() is not None:\r\n            pydoc_act = create_action(self, _(\"Python documentation\"),\r\n                                triggered=lambda:\r\n                                programs.start_file(get_python_doc_path()))\r\n            self.help_menu_actions.append(pydoc_act)\r\n        # IPython documentation\r\n        if self.help is not None:\r\n            ipython_menu = QMenu(_(\"IPython documentation\"), self)\r\n            intro_action = create_action(self, _(\"Intro to IPython\"),\r\n                                        triggered=self.ipyconsole.show_intro)\r\n            quickref_action = create_action(self, _(\"Quick reference\"),\r\n                                    triggered=self.ipyconsole.show_quickref)\r\n            guiref_action = create_action(self, _(\"Console help\"),\r\n                                        triggered=self.ipyconsole.show_guiref)\r\n            add_actions(ipython_menu, (intro_action, guiref_action,\r\n                                        quickref_action))\r\n            self.help_menu_actions.append(ipython_menu)\r\n        # Windows-only: documentation located in sys.prefix/Doc\r\n        ipm_actions = []\r\n        def add_ipm_action(text, path):\r\n            \"\"\"Add installed Python module doc action to help submenu\"\"\"\r\n            # QAction.triggered works differently for PySide and PyQt\r\n            path = file_uri(path)\r\n            if not API == 'pyside':\r\n                slot=lambda _checked, path=path: programs.start_file(path)\r\n            else:\r\n                slot=lambda path=path: programs.start_file(path)\r\n            action = create_action(self, text,\r\n                    icon='%s.png' % osp.splitext(path)[1][1:],\r\n                    triggered=slot)\r\n            ipm_actions.append(action)\r\n        sysdocpth = osp.join(sys.prefix, 'Doc')\r\n        if osp.isdir(sysdocpth): # exists on Windows, except frozen dist.\r\n            for docfn in os.listdir(sysdocpth):\r\n                pt = r'([a-zA-Z\\_]*)(doc)?(-dev)?(-ref)?(-user)?.(chm|pdf)'\r\n                match = re.match(pt, docfn)\r\n                if match is not None:\r\n                    pname = match.groups()[0]\r\n                    if pname not in ('Python', ):\r\n                        add_ipm_action(pname, osp.join(sysdocpth, docfn))\r\n        # Installed Python modules submenu (Windows only)\r\n        if ipm_actions:\r\n            pymods_menu = QMenu(_(\"Installed Python modules\"), self)\r\n            add_actions(pymods_menu, ipm_actions)\r\n            self.help_menu_actions.append(pymods_menu)\r\n        # Online documentation\r\n        web_resources = QMenu(_(\"Online documentation\"), self)\r\n        webres_actions = create_module_bookmark_actions(self,\r\n                                                        self.BOOKMARKS)\r\n        webres_actions.insert(2, None)\r\n        webres_actions.insert(5, None)\r\n        webres_actions.insert(8, None)\r\n        add_actions(web_resources, webres_actions)\r\n        self.help_menu_actions.append(web_resources)\r\n        # Qt assistant link\r\n        if sys.platform.startswith('linux') and not PYQT5:\r\n            qta_exe = \"assistant-qt4\"\r\n        else:\r\n            qta_exe = \"assistant\"\r\n        qta_act = create_program_action(self, _(\"Qt documentation\"),\r\n                                        qta_exe)\r\n        if qta_act:\r\n            self.help_menu_actions += [qta_act, None]\r\n        # About Spyder\r\n        about_action = create_action(self,\r\n                                _(\"About %s...\") % \"Spyder\",\r\n                                icon=ima.icon('MessageBoxInformation'),\r\n                                triggered=self.about)\r\n        self.help_menu_actions += [MENU_SEPARATOR, about_action]\r\n\r\n        # Status bar widgets\r\n        from spyder.widgets.status import MemoryStatus, CPUStatus\r\n        self.mem_status = MemoryStatus(self, status)\r\n        self.cpu_status = CPUStatus(self, status)\r\n        self.apply_statusbar_settings()\r\n\r\n        # ----- View\r\n        # View menu\r\n        self.plugins_menu = QMenu(_(\"Panes\"), self)\r\n\r\n        self.toolbars_menu = QMenu(_(\"Toolbars\"), self)\r\n        self.quick_layout_menu = QMenu(_(\"Window layouts\"), self)\r\n        self.quick_layout_set_menu()\r\n\r\n        self.view_menu.addMenu(self.plugins_menu)  # Panes\r\n        add_actions(self.view_menu, (self.lock_interface_action,\r\n                                     self.close_dockwidget_action,\r\n                                     self.maximize_action,\r\n                                     MENU_SEPARATOR))\r\n        self.show_toolbars_action = create_action(self,\r\n                                _(\"Show toolbars\"),\r\n                                triggered=self.show_toolbars,\r\n                                context=Qt.ApplicationShortcut)\r\n        self.register_shortcut(self.show_toolbars_action, \"_\",\r\n                               \"Show toolbars\")\r\n        self.view_menu.addMenu(self.toolbars_menu)\r\n        self.view_menu.addAction(self.show_toolbars_action)\r\n        add_actions(self.view_menu, (MENU_SEPARATOR,\r\n                                     self.quick_layout_menu,\r\n                                     self.toggle_previous_layout_action,\r\n                                     self.toggle_next_layout_action,\r\n                                     MENU_SEPARATOR,\r\n                                     self.fullscreen_action))\r\n        if set_attached_console_visible is not None:\r\n            cmd_act = create_action(self,\r\n                                _(\"Attached console window (debugging)\"),\r\n                                toggled=set_attached_console_visible)\r\n            cmd_act.setChecked(is_attached_console_visible())\r\n            add_actions(self.view_menu, (MENU_SEPARATOR, cmd_act))\r\n\r\n        # Adding external tools action to \"Tools\" menu\r\n        if self.external_tools_menu_actions:\r\n            external_tools_act = create_action(self, _(\"External Tools\"))\r\n            external_tools_act.setMenu(self.external_tools_menu)\r\n            self.tools_menu_actions += [None, external_tools_act]\r\n\r\n        # Filling out menu/toolbar entries:\r\n        add_actions(self.file_menu, self.file_menu_actions)\r\n        add_actions(self.edit_menu, self.edit_menu_actions)\r\n        add_actions(self.search_menu, self.search_menu_actions)\r\n        add_actions(self.source_menu, self.source_menu_actions)\r\n        add_actions(self.run_menu, self.run_menu_actions)\r\n        add_actions(self.debug_menu, self.debug_menu_actions)\r\n        add_actions(self.consoles_menu, self.consoles_menu_actions)\r\n        add_actions(self.projects_menu, self.projects_menu_actions)\r\n        add_actions(self.tools_menu, self.tools_menu_actions)\r\n        add_actions(self.external_tools_menu,\r\n                    self.external_tools_menu_actions)\r\n        add_actions(self.help_menu, self.help_menu_actions)\r\n\r\n        add_actions(self.main_toolbar, self.main_toolbar_actions)\r\n        add_actions(self.file_toolbar, self.file_toolbar_actions)\r\n        add_actions(self.edit_toolbar, self.edit_toolbar_actions)\r\n        add_actions(self.search_toolbar, self.search_toolbar_actions)\r\n        add_actions(self.source_toolbar, self.source_toolbar_actions)\r\n        add_actions(self.debug_toolbar, self.debug_toolbar_actions)\r\n        add_actions(self.run_toolbar, self.run_toolbar_actions)\r\n\r\n        # Apply all defined shortcuts (plugins + 3rd-party plugins)\r\n        self.apply_shortcuts()\r\n\r\n        # Emitting the signal notifying plugins that main window menu and\r\n        # toolbar actions are all defined:\r\n        self.all_actions_defined.emit()\r\n\r\n        # Window set-up\r\n        logger.info(\"Setting up window...\")\r\n        self.setup_layout(default=False)\r\n\r\n        # Show and hide shortcuts in menus for Mac.\r\n        # This is a workaround because we can't disable shortcuts\r\n        # by setting context=Qt.WidgetShortcut there\r\n        if sys.platform == 'darwin':\r\n            for name in ['file', 'edit', 'search', 'source', 'run', 'debug',\r\n                         'projects', 'tools', 'plugins']:\r\n                menu_object = getattr(self, name + '_menu')\r\n                menu_object.aboutToShow.connect(\r\n                    lambda name=name: self.show_shortcuts(name))\r\n                menu_object.aboutToHide.connect(\r\n                    lambda name=name: self.hide_shortcuts(name))\r\n\r\n        if self.splash is not None:\r\n            self.splash.hide()\r\n\r\n        # Enabling tear off for all menus except help menu\r\n        if CONF.get('main', 'tear_off_menus'):\r\n            for child in self.menuBar().children():\r\n                if isinstance(child, QMenu) and child != self.help_menu:\r\n                    child.setTearOffEnabled(True)\r\n\r\n        # Menu about to show\r\n        for child in self.menuBar().children():\r\n            if isinstance(child, QMenu):\r\n                try:\r\n                    child.aboutToShow.connect(self.update_edit_menu)\r\n                    child.aboutToShow.connect(self.update_search_menu)\r\n                except TypeError:\r\n                    pass\r\n\r\n        logger.info(\"*** End of MainWindow setup ***\")\r\n        self.is_starting_up = False", "response": "Setup the main window"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_visible_setup(self):\r\n        self.restore_scrollbar_position.emit()\r\n\r\n        # [Workaround for Issue 880]\r\n        # QDockWidget objects are not painted if restored as floating\r\n        # windows, so we must dock them before showing the mainwindow,\r\n        # then set them again as floating windows here.\r\n        for widget in self.floating_dockwidgets:\r\n            widget.setFloating(True)\r\n\r\n        # In MacOS X 10.7 our app is not displayed after initialized (I don't\r\n        # know why because this doesn't happen when started from the terminal),\r\n        # so we need to resort to this hack to make it appear.\r\n        if running_in_mac_app():\r\n            idx = __file__.index(MAC_APP_NAME)\r\n            app_path = __file__[:idx]\r\n            subprocess.call(['open', app_path + MAC_APP_NAME])\r\n\r\n        # Server to maintain just one Spyder instance and open files in it if\r\n        # the user tries to start other instances with\r\n        # $ spyder foo.py\r\n        if (CONF.get('main', 'single_instance') and not self.new_instance\r\n                and self.open_files_server):\r\n            t = threading.Thread(target=self.start_open_files_server)\r\n            t.setDaemon(True)\r\n            t.start()\r\n\r\n            # Connect the window to the signal emmited by the previous server\r\n            # when it gets a client connected to it\r\n            self.sig_open_external_file.connect(self.open_external_file)\r\n\r\n        # Create Plugins and toolbars submenus\r\n        self.create_plugins_menu()\r\n        self.create_toolbars_menu()\r\n\r\n        # Update toolbar visibility status\r\n        self.toolbars_visible = CONF.get('main', 'toolbars_visible')\r\n        self.load_last_visible_toolbars()\r\n\r\n        # Update lock status\r\n        self.lock_interface_action.setChecked(self.interface_locked)\r\n\r\n        # Hide Internal Console so that people don't use it instead of\r\n        # the External or IPython ones\r\n        if self.console.dockwidget.isVisible() and DEV is None:\r\n            self.console.toggle_view_action.setChecked(False)\r\n            self.console.dockwidget.hide()\r\n\r\n        # Show Help and Consoles by default\r\n        plugins_to_show = [self.ipyconsole]\r\n        if self.help is not None:\r\n            plugins_to_show.append(self.help)\r\n        for plugin in plugins_to_show:\r\n            if plugin.dockwidget.isVisible():\r\n                plugin.dockwidget.raise_()\r\n\r\n        # Show history file if no console is visible\r\n        if not self.ipyconsole.isvisible:\r\n            self.historylog.add_history(get_conf_path('history.py'))\r\n\r\n        if self.open_project:\r\n            self.projects.open_project(self.open_project)\r\n        else:\r\n            # Load last project if a project was active when Spyder\r\n            # was closed\r\n            self.projects.reopen_last_project()\r\n\r\n            # If no project is active, load last session\r\n            if self.projects.get_active_project() is None:\r\n                self.editor.setup_open_files()\r\n\r\n        # Check for spyder updates\r\n        if DEV is None and CONF.get('main', 'check_updates_on_startup'):\r\n            self.give_updates_feedback = False\r\n            self.check_updates(startup=True)\r\n\r\n        # Show dialog with missing dependencies\r\n        self.report_missing_dependencies()\r\n\r\n        # Raise the menuBar to the top of the main window widget's stack\r\n        # (Fixes issue 3887)\r\n        self.menuBar().raise_()\r\n        self.is_setting_up = False", "response": "Create the main window and the main window s show method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing a QMessageBox with a list of missing hard dependencies", "response": "def report_missing_dependencies(self):\r\n        \"\"\"Show a QMessageBox with a list of missing hard dependencies\"\"\"\r\n        missing_deps = dependencies.missing_dependencies()\r\n        if missing_deps:\r\n            QMessageBox.critical(self, _('Error'),\r\n                _(\"<b>You have missing dependencies!</b>\"\r\n                  \"<br><br><tt>%s</tt><br><br>\"\r\n                  \"<b>Please install them to avoid this message.</b>\"\r\n                  \"<br><br>\"\r\n                  \"<i>Note</i>: Spyder could work without some of these \"\r\n                  \"dependencies, however to have a smooth experience when \"\r\n                  \"using Spyder we <i>strongly</i> recommend you to install \"\r\n                  \"all the listed missing dependencies.<br><br>\"\r\n                  \"Failing to install these dependencies might result in bugs. \"\r\n                  \"Please be sure that any found bugs are not the direct \"\r\n                  \"result of missing dependencies, prior to reporting a new \"\r\n                  \"issue.\"\r\n                  ) % missing_deps, QMessageBox.Ok)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_window_settings(self, prefix, default=False, section='main'):\r\n        get_func = CONF.get_default if default else CONF.get\r\n        window_size = get_func(section, prefix+'size')\r\n        prefs_dialog_size = get_func(section, prefix+'prefs_dialog_size')\r\n        if default:\r\n            hexstate = None\r\n        else:\r\n            hexstate = get_func(section, prefix+'state', None)\r\n        pos = get_func(section, prefix+'position')\r\n\r\n        # It's necessary to verify if the window/position value is valid\r\n        # with the current screen. See issue 3748\r\n        width = pos[0]\r\n        height = pos[1]\r\n        screen_shape = QApplication.desktop().geometry()\r\n        current_width = screen_shape.width()\r\n        current_height = screen_shape.height()\r\n        if current_width < width or current_height < height:\r\n            pos = CONF.get_default(section, prefix+'position')\r\n\r\n        is_maximized =  get_func(section, prefix+'is_maximized')\r\n        is_fullscreen = get_func(section, prefix+'is_fullscreen')\r\n        return hexstate, window_size, prefs_dialog_size, pos, is_maximized, \\\r\n               is_fullscreen", "response": "Load window layout settings from userconfig - based configuration with prefix * prefix* under section *section*"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current window settings Symetric to the set_window_settings setter.", "response": "def get_window_settings(self):\r\n        \"\"\"Return current window settings\r\n        Symetric to the 'set_window_settings' setter\"\"\"\r\n        window_size = (self.window_size.width(), self.window_size.height())\r\n        is_fullscreen = self.isFullScreen()\r\n        if is_fullscreen:\r\n            is_maximized = self.maximized_flag\r\n        else:\r\n            is_maximized = self.isMaximized()\r\n        pos = (self.window_position.x(), self.window_position.y())\r\n        prefs_dialog_size = (self.prefs_dialog_size.width(),\r\n                             self.prefs_dialog_size.height())\r\n        hexstate = qbytearray_to_str(self.saveState())\r\n        return (hexstate, window_size, prefs_dialog_size, pos, is_maximized,\r\n                is_fullscreen)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting window settings Symetric to the 'get_window_settings' accessor", "response": "def set_window_settings(self, hexstate, window_size, prefs_dialog_size,\r\n                            pos, is_maximized, is_fullscreen):\r\n        \"\"\"Set window settings\r\n        Symetric to the 'get_window_settings' accessor\"\"\"\r\n        self.setUpdatesEnabled(False)\r\n        self.window_size = QSize(window_size[0], window_size[1]) # width,height\r\n        self.prefs_dialog_size = QSize(prefs_dialog_size[0],\r\n                                       prefs_dialog_size[1]) # width,height\r\n        self.window_position = QPoint(pos[0], pos[1]) # x,y\r\n        self.setWindowState(Qt.WindowNoState)\r\n        self.resize(self.window_size)\r\n        self.move(self.window_position)\r\n\r\n        # Window layout\r\n        if hexstate:\r\n            self.restoreState( QByteArray().fromHex(\r\n                    str(hexstate).encode('utf-8')) )\r\n            # [Workaround for Issue 880]\r\n            # QDockWidget objects are not painted if restored as floating\r\n            # windows, so we must dock them before showing the mainwindow.\r\n            for widget in self.children():\r\n                if isinstance(widget, QDockWidget) and widget.isFloating():\r\n                    self.floating_dockwidgets.append(widget)\r\n                    widget.setFloating(False)\r\n\r\n        # Is fullscreen?\r\n        if is_fullscreen:\r\n            self.setWindowState(Qt.WindowFullScreen)\r\n        self.__update_fullscreen_action()\r\n\r\n        # Is maximized?\r\n        if is_fullscreen:\r\n            self.maximized_flag = is_maximized\r\n        elif is_maximized:\r\n            self.setWindowState(Qt.WindowMaximized)\r\n        self.setUpdatesEnabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_current_window_settings(self, prefix, section='main',\r\n                                     none_state=False):\r\n        \"\"\"Save current window settings with *prefix* in\r\n        the userconfig-based configuration, under *section*\"\"\"\r\n        win_size = self.window_size\r\n        prefs_size = self.prefs_dialog_size\r\n\r\n        CONF.set(section, prefix+'size', (win_size.width(), win_size.height()))\r\n        CONF.set(section, prefix+'prefs_dialog_size',\r\n                 (prefs_size.width(), prefs_size.height()))\r\n        CONF.set(section, prefix+'is_maximized', self.isMaximized())\r\n        CONF.set(section, prefix+'is_fullscreen', self.isFullScreen())\r\n        pos = self.window_position\r\n        CONF.set(section, prefix+'position', (pos.x(), pos.y()))\r\n        self.maximize_dockwidget(restore=True)# Restore non-maximized layout\r\n        if none_state:\r\n            CONF.set(section, prefix + 'state', None)\r\n        else:\r\n            qba = self.saveState()\r\n            CONF.set(section, prefix + 'state', qbytearray_to_str(qba))\r\n        CONF.set(section, prefix+'statusbar',\r\n                    not self.statusBar().isHidden())", "response": "Save current window settings with prefix in\r\n        the userconfig - based configuration under section with prefix * prefix* in\r\n        the userconfig - based configuration under section with prefix * prefix*"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_default_layouts(self, index, settings):\r\n        self.setUpdatesEnabled(False)\r\n\r\n        first_spyder_run = bool(self.first_spyder_run)  # Store copy\r\n\r\n        if first_spyder_run:\r\n            self.set_window_settings(*settings)\r\n        else:\r\n            if self.last_plugin:\r\n                if self.last_plugin.ismaximized:\r\n                    self.maximize_dockwidget(restore=True)\r\n\r\n            if not (self.isMaximized() or self.maximized_flag):\r\n                self.showMaximized()\r\n\r\n            min_width = self.minimumWidth()\r\n            max_width = self.maximumWidth()\r\n            base_width = self.width()\r\n            self.setFixedWidth(base_width)\r\n\r\n        # IMPORTANT: order has to be the same as defined in the config file\r\n        MATLAB, RSTUDIO, VERTICAL, HORIZONTAL = range(self.DEFAULT_LAYOUTS)\r\n\r\n        # Define widgets locally\r\n        editor = self.editor\r\n        console_ipy = self.ipyconsole\r\n        console_int = self.console\r\n        outline = self.outlineexplorer\r\n        explorer_project = self.projects\r\n        explorer_file = self.explorer\r\n        explorer_variable = self.variableexplorer\r\n        plots = self.plots\r\n        history = self.historylog\r\n        finder = self.findinfiles\r\n        help_plugin = self.help\r\n        helper = self.onlinehelp\r\n        plugins = self.thirdparty_plugins\r\n\r\n        # Stored for tests\r\n        global_hidden_widgets = [finder, console_int, explorer_project,\r\n                                 helper] + plugins\r\n        global_hidden_toolbars = [self.source_toolbar, self.edit_toolbar,\r\n                                  self.search_toolbar]\r\n        # Layout definition\r\n        # --------------------------------------------------------------------\r\n        # Layouts are organized by columns, each column is organized by rows.\r\n        # Widths have to add 1.0 (except if hidden), height per column has to\r\n        # add 1.0 as well\r\n\r\n        # Spyder Default Initial Layout\r\n        s_layout = {\r\n            'widgets': [\r\n                # Column 0\r\n                [[explorer_project]],\r\n                # Column 1\r\n                [[editor]],\r\n                # Column 2\r\n                [[outline]],\r\n                # Column 3\r\n                [[help_plugin, explorer_variable, plots,     # Row 0\r\n                  helper, explorer_file, finder] + plugins,\r\n                 [console_int, console_ipy, history]]        # Row 1\r\n                ],\r\n            'width fraction': [0.05,            # Column 0 width\r\n                               0.55,            # Column 1 width\r\n                               0.05,            # Column 2 width\r\n                               0.45],           # Column 3 width\r\n            'height fraction': [[1.0],          # Column 0, row heights\r\n                                [1.0],          # Column 1, row heights\r\n                                [1.0],          # Column 2, row heights\r\n                                [0.46, 0.54]],  # Column 3, row heights\r\n            'hidden widgets': [outline] + global_hidden_widgets,\r\n            'hidden toolbars': [],\r\n        }\r\n\r\n        # RStudio\r\n        r_layout = {\r\n            'widgets': [\r\n                # column 0\r\n                [[editor],                            # Row 0\r\n                 [console_ipy, console_int]],         # Row 1\r\n                # column 1\r\n                [[explorer_variable, plots, history,  # Row 0\r\n                  outline, finder] + plugins,\r\n                 [explorer_file, explorer_project,    # Row 1\r\n                  help_plugin, helper]]\r\n                ],\r\n            'width fraction': [0.55,            # Column 0 width\r\n                               0.45],           # Column 1 width\r\n            'height fraction': [[0.55, 0.45],   # Column 0, row heights\r\n                                [0.55, 0.45]],  # Column 1, row heights\r\n            'hidden widgets': [outline] + global_hidden_widgets,\r\n            'hidden toolbars': [],\r\n        }\r\n\r\n        # Matlab\r\n        m_layout = {\r\n            'widgets': [\r\n                # column 0\r\n                [[explorer_file, explorer_project],\r\n                 [outline]],\r\n                # column 1\r\n                [[editor],\r\n                 [console_ipy, console_int]],\r\n                # column 2\r\n                [[explorer_variable, plots, finder] + plugins,\r\n                 [history, help_plugin, helper]]\r\n                ],\r\n            'width fraction': [0.10,            # Column 0 width\r\n                               0.45,            # Column 1 width\r\n                               0.45],           # Column 2 width\r\n            'height fraction': [[0.55, 0.45],   # Column 0, row heights\r\n                                [0.55, 0.45],   # Column 1, row heights\r\n                                [0.55, 0.45]],  # Column 2, row heights\r\n            'hidden widgets': global_hidden_widgets,\r\n            'hidden toolbars': [],\r\n        }\r\n\r\n        # Vertically split\r\n        v_layout = {\r\n            'widgets': [\r\n                # column 0\r\n                [[editor],                                  # Row 0\r\n                 [console_ipy, console_int, explorer_file,  # Row 1\r\n                  explorer_project, help_plugin, explorer_variable, plots,\r\n                  history, outline, finder, helper] + plugins]\r\n                ],\r\n            'width fraction': [1.0],            # Column 0 width\r\n            'height fraction': [[0.55, 0.45]],  # Column 0, row heights\r\n            'hidden widgets': [outline] + global_hidden_widgets,\r\n            'hidden toolbars': [],\r\n        }\r\n\r\n        # Horizontally split\r\n        h_layout = {\r\n            'widgets': [\r\n                # column 0\r\n                [[editor]],                                 # Row 0\r\n                # column 1\r\n                [[console_ipy, console_int, explorer_file,  # Row 0\r\n                  explorer_project, help_plugin, explorer_variable, plots,\r\n                  history, outline, finder, helper] + plugins]\r\n                ],\r\n            'width fraction': [0.55,      # Column 0 width\r\n                               0.45],     # Column 1 width\r\n            'height fraction': [[1.0],    # Column 0, row heights\r\n                                [1.0]],   # Column 1, row heights\r\n            'hidden widgets': [outline] + global_hidden_widgets,\r\n            'hidden toolbars': []\r\n        }\r\n\r\n        # Layout selection\r\n        layouts = {\r\n            'default': s_layout,\r\n            RSTUDIO: r_layout,\r\n            MATLAB: m_layout,\r\n            VERTICAL: v_layout,\r\n            HORIZONTAL: h_layout,\r\n        }\r\n\r\n        layout = layouts[index]\r\n\r\n        # Remove None from widgets layout\r\n        widgets_layout = layout['widgets']\r\n        widgets_layout_clean = []\r\n        for column in widgets_layout:\r\n            clean_col = []\r\n            for row in column:\r\n                clean_row = [w for w in row if w is not None]\r\n                if clean_row:\r\n                    clean_col.append(clean_row)\r\n            if clean_col:\r\n                widgets_layout_clean.append(clean_col)\r\n\r\n        # Flatten widgets list\r\n        widgets = []\r\n        for column in widgets_layout_clean:\r\n            for row in column:\r\n                for widget in row:\r\n                    widgets.append(widget)\r\n\r\n        # Make every widget visible\r\n        for widget in widgets:\r\n            widget.toggle_view(True)\r\n            widget.toggle_view_action.setChecked(True)\r\n\r\n        # We use both directions to ensure proper update when moving from\r\n        # 'Horizontal Split' to 'Spyder Default'\r\n        # This also seems to help on random cases where the display seems\r\n        # 'empty'\r\n        for direction in (Qt.Vertical, Qt.Horizontal):\r\n            # Arrange the widgets in one direction\r\n            for idx in range(len(widgets) - 1):\r\n                first, second = widgets[idx], widgets[idx+1]\r\n                if first is not None and second is not None:\r\n                    self.splitDockWidget(first.dockwidget, second.dockwidget,\r\n                                         direction)\r\n\r\n        # Arrange the widgets in the other direction\r\n        for column in widgets_layout_clean:\r\n            for idx in range(len(column) - 1):\r\n                first_row, second_row = column[idx], column[idx+1]\r\n                self.splitDockWidget(first_row[0].dockwidget,\r\n                                     second_row[0].dockwidget,\r\n                                     Qt.Vertical)\r\n\r\n        # Tabify\r\n        for column in widgets_layout_clean:\r\n            for row in column:\r\n                for idx in range(len(row) - 1):\r\n                    first, second = row[idx], row[idx+1]\r\n                    self.tabify_plugins(first, second)\r\n\r\n                # Raise front widget per row\r\n                row[0].dockwidget.show()\r\n                row[0].dockwidget.raise_()\r\n\r\n        # Set dockwidget widths\r\n        width_fractions = layout['width fraction']\r\n        if len(width_fractions) > 1:\r\n            _widgets = [col[0][0].dockwidget for col in widgets_layout]\r\n            self.resizeDocks(_widgets, width_fractions, Qt.Horizontal)\r\n\r\n        # Set dockwidget heights\r\n        height_fractions = layout['height fraction']\r\n        for idx, column in enumerate(widgets_layout_clean):\r\n            if len(column) > 1:\r\n                _widgets = [row[0].dockwidget for row in column]\r\n                self.resizeDocks(_widgets, height_fractions[idx], Qt.Vertical)\r\n\r\n        # Hide toolbars\r\n        hidden_toolbars = global_hidden_toolbars + layout['hidden toolbars']\r\n        for toolbar in hidden_toolbars:\r\n            if toolbar is not None:\r\n                toolbar.close()\r\n\r\n        # Hide widgets\r\n        hidden_widgets = layout['hidden widgets']\r\n        for widget in hidden_widgets:\r\n            if widget is not None:\r\n                widget.dockwidget.close()\r\n\r\n        if first_spyder_run:\r\n            self.first_spyder_run = False\r\n        else:\r\n            self.setMinimumWidth(min_width)\r\n            self.setMaximumWidth(max_width)\r\n\r\n            if not (self.isMaximized() or self.maximized_flag):\r\n                self.showMaximized()\r\n\r\n        self.setUpdatesEnabled(True)\r\n        self.sig_layout_setup_ready.emit(layout)\r\n\r\n        return layout", "response": "Setup default layouts when run for the first time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_window_layout(self):\r\n        answer = QMessageBox.warning(self, _(\"Warning\"),\r\n                     _(\"Window layout will be reset to default settings: \"\r\n                       \"this affects window position, size and dockwidgets.\\n\"\r\n                       \"Do you want to continue?\"),\r\n                     QMessageBox.Yes | QMessageBox.No)\r\n        if answer == QMessageBox.Yes:\r\n            self.setup_layout(default=True)", "response": "Reset window layout to default settings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nswitches to a quick layout number.", "response": "def quick_layout_switch(self, index):\r\n        \"\"\"Switch to quick layout number *index*\"\"\"\r\n        section = 'quick_layouts'\r\n\r\n        try:\r\n            settings = self.load_window_settings('layout_{}/'.format(index),\r\n                                                 section=section)\r\n            (hexstate, window_size, prefs_dialog_size, pos, is_maximized,\r\n             is_fullscreen) = settings\r\n\r\n            # The defaults layouts will always be regenerated unless there was\r\n            # an overwrite, either by rewriting with same name, or by deleting\r\n            # and then creating a new one\r\n            if hexstate is None:\r\n                # The value for hexstate shouldn't be None for a custom saved\r\n                # layout (ie, where the index is greater than the number of\r\n                # defaults).  See issue 6202.\r\n                if index != 'default' and index >= self.DEFAULT_LAYOUTS:\r\n                    QMessageBox.critical(\r\n                            self, _(\"Warning\"),\r\n                            _(\"Error opening the custom layout.  Please close\"\r\n                              \" Spyder and try again.  If the issue persists,\"\r\n                              \" then you must use 'Reset to Spyder default' \"\r\n                              \"from the layout menu.\"))\r\n                    return\r\n                self.setup_default_layouts(index, settings)\r\n        except cp.NoOptionError:\r\n            QMessageBox.critical(self, _(\"Warning\"),\r\n                                 _(\"Quick switch layout #%s has not yet \"\r\n                                   \"been defined.\") % str(index))\r\n            return\r\n            # TODO: is there any real use in calling the previous layout\r\n            # setting?\r\n            # self.previous_layout_settings = self.get_window_settings()\r\n        self.set_window_settings(*settings)\r\n        self.current_quick_layout = index\r\n\r\n        # make sure the flags are correctly set for visible panes\r\n        for plugin in (self.widgetlist + self.thirdparty_plugins):\r\n            action = plugin.toggle_view_action\r\n            action.setChecked(plugin.dockwidget.isVisible())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the text displayed in the menu entry.", "response": "def _update_show_toolbars_action(self):\r\n        \"\"\"Update the text displayed in the menu entry.\"\"\"\r\n        if self.toolbars_visible:\r\n            text = _(\"Hide toolbars\")\r\n            tip = _(\"Hide toolbars\")\r\n        else:\r\n            text = _(\"Show toolbars\")\r\n            tip = _(\"Show toolbars\")\r\n        self.show_toolbars_action.setText(text)\r\n        self.show_toolbars_action.setToolTip(tip)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_visible_toolbars(self):\r\n        toolbars = []\r\n        for toolbar in self.visible_toolbars:\r\n            toolbars.append(toolbar.objectName())\r\n        CONF.set('main', 'last_visible_toolbars', toolbars)", "response": "Saves the name of the visible toolbars in the. ini file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollecting the visible toolbars.", "response": "def get_visible_toolbars(self):\r\n        \"\"\"Collects the visible toolbars.\"\"\"\r\n        toolbars = []\r\n        for toolbar in self.toolbarslist:\r\n            if toolbar.toggleViewAction().isChecked():\r\n                toolbars.append(toolbar)\r\n        self.visible_toolbars = toolbars"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the last visible toolbars from the. ini file.", "response": "def load_last_visible_toolbars(self):\r\n        \"\"\"Loads the last visible toolbars from the .ini file.\"\"\"\r\n        toolbars_names = CONF.get('main', 'last_visible_toolbars', default=[])\r\n\r\n        if toolbars_names:\r\n            dic = {}\r\n            for toolbar in self.toolbarslist:\r\n                dic[toolbar.objectName()] = toolbar\r\n\r\n            toolbars = []\r\n            for name in toolbars_names:\r\n                if name in dic:\r\n                    toolbars.append(dic[name])\r\n            self.visible_toolbars = toolbars\r\n        else:\r\n            self.get_visible_toolbars()\r\n        self._update_show_toolbars_action()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_toolbars(self):\r\n        value = not self.toolbars_visible\r\n        CONF.set('main', 'toolbars_visible', value)\r\n        if value:\r\n            self.save_visible_toolbars()\r\n        else:\r\n            self.get_visible_toolbars()\r\n\r\n        for toolbar in self.visible_toolbars:\r\n            toolbar.toggleViewAction().setChecked(value)\r\n            toolbar.setVisible(value)\r\n\r\n        self.toolbars_visible = value\r\n        self._update_show_toolbars_action()", "response": "Show or hide toolbars."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef valid_project(self):\r\n        try:\r\n            path = self.projects.get_active_project_path()\r\n        except AttributeError:\r\n            return\r\n\r\n        if bool(path):\r\n            if not self.projects.is_valid_project(path):\r\n                if path:\r\n                    QMessageBox.critical(\r\n                        self,\r\n                        _('Error'),\r\n                        _(\"<b>{}</b> is no longer a valid Spyder project! \"\r\n                          \"Since it is the current active project, it will \"\r\n                          \"be closed automatically.\").format(path))\r\n                self.projects.close_project()", "response": "Handle an invalid active project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_shortcuts(self, menu):\r\n        for element in getattr(self, menu + '_menu_actions'):\r\n            if element and isinstance(element, QAction):\r\n                if element._shown_shortcut is not None:\r\n                    element.setShortcut(element._shown_shortcut)", "response": "Show action shortcuts in menu"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hide_shortcuts(self, menu):\r\n        for element in getattr(self, menu + '_menu_actions'):\r\n            if element and isinstance(element, QAction):\r\n                if element._shown_shortcut is not None:\r\n                    element.setShortcut(QKeySequence())", "response": "Hide action shortcuts in menu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget properties of focus widget Returns widget textedit properties", "response": "def get_focus_widget_properties(self):\r\n        \"\"\"Get properties of focus widget\r\n        Returns tuple (widget, properties) where properties is a tuple of\r\n        booleans: (is_console, not_readonly, readwrite_editor)\"\"\"\r\n        from spyder.plugins.editor.widgets.editor import TextEditBaseWidget\r\n        from spyder.plugins.ipythonconsole.widgets import ControlWidget\r\n        widget = QApplication.focusWidget()\r\n\r\n        textedit_properties = None\r\n        if isinstance(widget, (TextEditBaseWidget, ControlWidget)):\r\n            console = isinstance(widget, ControlWidget)\r\n            not_readonly = not widget.isReadOnly()\r\n            readwrite_editor = not_readonly and not console\r\n            textedit_properties = (console, not_readonly, readwrite_editor)\r\n        return widget, textedit_properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating edit menu with new properties", "response": "def update_edit_menu(self):\r\n        \"\"\"Update edit menu\"\"\"\r\n        widget, textedit_properties = self.get_focus_widget_properties()\r\n        if textedit_properties is None: # widget is not an editor/console\r\n            return\r\n        # !!! Below this line, widget is expected to be a QPlainTextEdit\r\n        #     instance\r\n        console, not_readonly, readwrite_editor = textedit_properties\r\n\r\n        # Editor has focus and there is no file opened in it\r\n        if not console and not_readonly and not self.editor.is_file_opened():\r\n            return\r\n\r\n        # Disabling all actions to begin with\r\n        for child in self.edit_menu.actions():\r\n            child.setEnabled(False)\r\n\r\n        self.selectall_action.setEnabled(True)\r\n\r\n        # Undo, redo\r\n        self.undo_action.setEnabled( readwrite_editor \\\r\n                                     and widget.document().isUndoAvailable() )\r\n        self.redo_action.setEnabled( readwrite_editor \\\r\n                                     and widget.document().isRedoAvailable() )\r\n\r\n        # Copy, cut, paste, delete\r\n        has_selection = widget.has_selected_text()\r\n        self.copy_action.setEnabled(has_selection)\r\n        self.cut_action.setEnabled(has_selection and not_readonly)\r\n        self.paste_action.setEnabled(not_readonly)\r\n\r\n        # Comment, uncomment, indent, unindent...\r\n        if not console and not_readonly:\r\n            # This is the editor and current file is writable\r\n            for action in self.editor.edit_menu_actions:\r\n                action.setEnabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the search menu with the new values", "response": "def update_search_menu(self):\r\n        \"\"\"Update search menu\"\"\"\r\n        # Disabling all actions except the last one\r\n        # (which is Find in files) to begin with\r\n        for child in self.search_menu.actions()[:-1]:\r\n            child.setEnabled(False)\r\n\r\n        widget, textedit_properties = self.get_focus_widget_properties()\r\n        if textedit_properties is None: # widget is not an editor/console\r\n            return\r\n\r\n        # !!! Below this line, widget is expected to be a QPlainTextEdit\r\n        #     instance\r\n        console, not_readonly, readwrite_editor = textedit_properties\r\n\r\n        # Find actions only trigger an effect in the Editor\r\n        if not console:\r\n            for action in self.search_menu.actions():\r\n                try:\r\n                    action.setEnabled(True)\r\n                except RuntimeError:\r\n                    pass\r\n\r\n        # Disable the replace action for read-only files\r\n        self.search_menu_actions[3].setEnabled(readwrite_editor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the splash message", "response": "def set_splash(self, message):\r\n        \"\"\"Set splash message\"\"\"\r\n        if self.splash is None:\r\n            return\r\n        if message:\r\n            logger.info(message)\r\n        self.splash.show()\r\n        self.splash.showMessage(message, Qt.AlignBottom | Qt.AlignCenter |\r\n                                Qt.AlignAbsolute, QColor(Qt.white))\r\n        QApplication.processEvents()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef moveEvent(self, event):\r\n        if not self.isMaximized() and not self.fullscreen_flag:\r\n            self.window_position = self.pos()\r\n        QMainWindow.moveEvent(self, event)\r\n\r\n        # To be used by the tour to be able to move\r\n        self.sig_moved.emit(event)", "response": "Reimplement Qt method moveEvent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef closing(self, cancelable=False):\r\n        if self.already_closed or self.is_starting_up:\r\n            return True\r\n        if cancelable and CONF.get('main', 'prompt_on_exit'):\r\n            reply = QMessageBox.critical(self, 'Spyder',\r\n                                         'Do you really want to exit?',\r\n                                         QMessageBox.Yes, QMessageBox.No)\r\n            if reply == QMessageBox.No:\r\n                return False\r\n        prefix = 'window' + '/'\r\n        self.save_current_window_settings(prefix)\r\n        if CONF.get('main', 'single_instance') and self.open_files_server:\r\n            self.open_files_server.close()\r\n        for plugin in (self.widgetlist + self.thirdparty_plugins):\r\n            plugin.close_window()\r\n            if not plugin.closing_plugin(cancelable):\r\n                return False\r\n        self.dialog_manager.close_all()\r\n        if self.toolbars_visible:\r\n            self.save_visible_toolbars()\r\n        self.lspmanager.shutdown()\r\n        self.already_closed = True\r\n        return True", "response": "Close all open files and plugins and dialog manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a dockwidget and toggleViewAction", "response": "def add_dockwidget(self, child):\r\n        \"\"\"Add QDockWidget and toggleViewAction\"\"\"\r\n        dockwidget, location = child.create_dockwidget()\r\n        if CONF.get('main', 'vertical_dockwidget_titlebars'):\r\n            dockwidget.setFeatures(dockwidget.features()|\r\n                                   QDockWidget.DockWidgetVerticalTitleBar)\r\n        self.addDockWidget(location, dockwidget)\r\n        self.widgetlist.append(child)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlocking and unlock dockwidgets and toolbars", "response": "def toggle_lock(self, value):\r\n        \"\"\"Lock/Unlock dockwidgets and toolbars\"\"\"\r\n        self.interface_locked = value\r\n        CONF.set('main', 'panes_locked', value)\r\n\r\n        # Apply lock to panes\r\n        for plugin in (self.widgetlist + self.thirdparty_plugins):\r\n            if self.interface_locked:\r\n                if plugin.dockwidget.isFloating():\r\n                    plugin.dockwidget.setFloating(False)\r\n                plugin.dockwidget.setTitleBarWidget(QWidget())\r\n            else:\r\n                plugin.dockwidget.set_title_bar()\r\n\r\n        # Apply lock to toolbars\r\n        for toolbar in self.toolbarslist:\r\n            if self.interface_locked:\r\n                toolbar.setMovable(False)\r\n            else:\r\n                toolbar.setMovable(True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maximize_dockwidget(self, restore=False):\r\n        if self.state_before_maximizing is None:\r\n            if restore:\r\n                return\r\n\r\n            # Select plugin to maximize\r\n            self.state_before_maximizing = self.saveState()\r\n            focus_widget = QApplication.focusWidget()\r\n            for plugin in (self.widgetlist + self.thirdparty_plugins):\r\n                plugin.dockwidget.hide()\r\n                if plugin.isAncestorOf(focus_widget):\r\n                    self.last_plugin = plugin\r\n\r\n            # Only plugins that have a dockwidget are part of widgetlist,\r\n            # so last_plugin can be None after the above \"for\" cycle.\r\n            # For example, this happens if, after Spyder has started, focus\r\n            # is set to the Working directory toolbar (which doesn't have\r\n            # a dockwidget) and then you press the Maximize button\r\n            if self.last_plugin is None:\r\n                # Using the Editor as default plugin to maximize\r\n                self.last_plugin = self.editor\r\n\r\n            # Maximize last_plugin\r\n            self.last_plugin.dockwidget.toggleViewAction().setDisabled(True)\r\n            self.setCentralWidget(self.last_plugin)\r\n            self.last_plugin.ismaximized = True\r\n\r\n            # Workaround to solve an issue with editor's outline explorer:\r\n            # (otherwise the whole plugin is hidden and so is the outline explorer\r\n            #  and the latter won't be refreshed if not visible)\r\n            self.last_plugin.show()\r\n            self.last_plugin.visibility_changed(True)\r\n            if self.last_plugin is self.editor:\r\n                # Automatically show the outline if the editor was maximized:\r\n                self.addDockWidget(Qt.RightDockWidgetArea,\r\n                                   self.outlineexplorer.dockwidget)\r\n                self.outlineexplorer.dockwidget.show()\r\n        else:\r\n            # Restore original layout (before maximizing current dockwidget)\r\n            self.last_plugin.dockwidget.setWidget(self.last_plugin)\r\n            self.last_plugin.dockwidget.toggleViewAction().setEnabled(True)\r\n            self.setCentralWidget(None)\r\n            self.last_plugin.ismaximized = False\r\n            self.restoreState(self.state_before_maximizing)\r\n            self.state_before_maximizing = None\r\n            self.last_plugin.get_focus_widget().setFocus()\r\n        self.__update_maximize_action()", "response": "Shortcut: Ctrl+Alt+Shift+M\r\n        First call: maximize current dockwidget\r\n        Second call (or restore=True): restore original window layout"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd widget actions to toolbar", "response": "def add_to_toolbar(self, toolbar, widget):\r\n        \"\"\"Add widget actions to toolbar\"\"\"\r\n        actions = widget.toolbar_actions\r\n        if actions is not None:\r\n            add_actions(toolbar, actions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef about(self):\r\n        versions = get_versions()\r\n        # Show Git revision for development version\r\n        revlink = ''\r\n        if versions['revision']:\r\n            rev = versions['revision']\r\n            revlink = \" (<a href='https://github.com/spyder-ide/spyder/\"\\\r\n                      \"commit/%s'>Commit: %s</a>)\" % (rev, rev)\r\n        msgBox = QMessageBox(self)\r\n        msgBox.setText(\r\n            \"\"\"\r\n            <b>Spyder {spyder_ver}</b> {revision}\r\n            <br>The Scientific Python Development Environment |\r\n            <a href=\"{website_url}\">Spyder-IDE.org</a>\r\n            <br>Copyright &copy; 2009-2019 Spyder Project Contributors and\r\n            <a href=\"{github_url}/blob/master/AUTHORS.txt\">others</a>\r\n            <br>Distributed under the terms of the\r\n            <a href=\"{github_url}/blob/master/LICENSE.txt\">MIT License</a>.\r\n\r\n            <p>Created by Pierre Raybaut; current maintainer is Carlos Cordoba.\r\n            <br>Developed by the\r\n            <a href=\"{github_url}/graphs/contributors\">international\r\n            Spyder community</a>.\r\n            <br>Many thanks to all the Spyder beta testers and dedicated users.\r\n\r\n            <p>For help with Spyder errors and crashes, please read our\r\n            <a href=\"{trouble_url}\">Troubleshooting Guide</a>, and for bug\r\n            reports and feature requests, visit our\r\n            <a href=\"{github_url}\">Github site</a>.\r\n            For project discussion, see our\r\n            <a href=\"{forum_url}\">Google Group</a>.\r\n            <p>This project is part of a larger effort to promote and\r\n            facilitate the use of Python for scientific and engineering\r\n            software development.\r\n            The popular Python distributions\r\n            <a href=\"https://www.anaconda.com/download/\">Anaconda</a> and\r\n            <a href=\"https://winpython.github.io/\">WinPython</a>\r\n            also contribute to this plan.\r\n\r\n            <p>Python {python_ver} {bitness}-bit | Qt {qt_ver} |\r\n            {qt_api} {qt_api_ver} | {os_name} {os_ver}\r\n\r\n            <small><p>Certain source files under other compatible permissive\r\n            licenses and/or originally by other authors.\r\n            Spyder 3 theme icons derived from\r\n            <a href=\"https://fontawesome.com/\">Font Awesome</a> 4.7\r\n            (&copy; 2016 David Gandy; SIL OFL 1.1) and\r\n            <a href=\"http://materialdesignicons.com/\">Material Design</a>\r\n            (&copy; 2014 Austin Andrews; SIL OFL 1.1).\r\n            Most Spyder 2 theme icons sourced from the\r\n            <a href=\"https://www.everaldo.com\">Crystal Project iconset</a>\r\n            (&copy; 2006-2007 Everaldo Coelho; LGPL 2.1+).\r\n            Other icons from\r\n            <a href=\"http://p.yusukekamiyamane.com/\">Yusuke Kamiyamane</a>\r\n            (&copy; 2013 Yusuke Kamiyamane; CC-BY 3.0),\r\n            the <a href=\"http://www.famfamfam.com/lab/icons/silk/\">FamFamFam\r\n            Silk icon set</a> 1.3 (&copy; 2006 Mark James; CC-BY 2.5), and\r\n            the <a href=\"https://www.kde.org/\">KDE Oxygen icons</a>\r\n            (&copy; 2007 KDE Artists; LGPL 3.0+).</small>\r\n\r\n            <p>See the <a href=\"{github_url}/blob/master/NOTICE.txt\">NOTICE</a>\r\n            file for full legal information.\r\n            \"\"\"\r\n            .format(spyder_ver=versions['spyder'],\r\n                    revision=revlink,\r\n                    website_url=__website_url__,\r\n                    github_url=__project_url__,\r\n                    trouble_url=__trouble_url__,\r\n                    forum_url=__forum_url__,\r\n                    python_ver=versions['python'],\r\n                    bitness=versions['bitness'],\r\n                    qt_ver=versions['qt'],\r\n                    qt_api=versions['qt_api'],\r\n                    qt_api_ver=versions['qt_api_ver'],\r\n                    os_name=versions['system'],\r\n                    os_ver=versions['release'])\r\n        )\r\n        msgBox.setWindowTitle(_(\"About %s\") % \"Spyder\")\r\n        msgBox.setStandardButtons(QMessageBox.Ok)\r\n\r\n        from spyder.config.gui import is_dark_interface\r\n        if PYQT5:\r\n            if is_dark_interface():\r\n                icon_filename = \"spyder.svg\"\r\n            else:\r\n                icon_filename = \"spyder_dark.svg\"\r\n        else:\r\n            if is_dark_interface():\r\n                icon_filename = \"spyder.png\"\r\n            else:\r\n                icon_filename = \"spyder_dark.png\"\r\n        app_icon = QIcon(get_image_path(icon_filename))\r\n        msgBox.setIconPixmap(app_icon.pixmap(QSize(64, 64)))\r\n\r\n        msgBox.setTextInteractionFlags(\r\n            Qt.LinksAccessibleByMouse | Qt.TextSelectableByMouse)\r\n        msgBox.exec_()", "response": "Create About Spyder dialog with general information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow Spyder s Dependencies dialog box", "response": "def show_dependencies(self):\r\n        \"\"\"Show Spyder's Dependencies dialog box\"\"\"\r\n        from spyder.widgets.dependencies import DependenciesDialog\r\n        dlg = DependenciesDialog(self)\r\n        dlg.set_data(dependencies.DEPENDENCIES)\r\n        dlg.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a single issue and return it", "response": "def render_issue(self, description='', traceback=''):\r\n        \"\"\"Render issue before sending it to Github\"\"\"\r\n        # Get component versions\r\n        versions = get_versions()\r\n\r\n        # Get git revision for development version\r\n        revision = ''\r\n        if versions['revision']:\r\n            revision = versions['revision']\r\n\r\n        # Make a description header in case no description is supplied\r\n        if not description:\r\n            description = \"### What steps reproduce the problem?\"\r\n\r\n        # Make error section from traceback and add appropriate reminder header\r\n        if traceback:\r\n            error_section = (\"### Traceback\\n\"\r\n                             \"```python-traceback\\n\"\r\n                             \"{}\\n\"\r\n                             \"```\".format(traceback))\r\n        else:\r\n            error_section = ''\r\n        issue_template = \"\"\"\\\r\n## Description\r\n\r\n{description}\r\n\r\n{error_section}\r\n\r\n## Versions\r\n\r\n* Spyder version: {spyder_version} {commit}\r\n* Python version: {python_version}\r\n* Qt version: {qt_version}\r\n* {qt_api_name} version: {qt_api_version}\r\n* Operating System: {os_name} {os_version}\r\n\r\n### Dependencies\r\n\r\n```\r\n{dependencies}\r\n```\r\n\"\"\".format(description=description,\r\n           error_section=error_section,\r\n           spyder_version=versions['spyder'],\r\n           commit=revision,\r\n           python_version=versions['python'],\r\n           qt_version=versions['qt'],\r\n           qt_api_name=versions['qt_api'],\r\n           qt_api_version=versions['qt_api_ver'],\r\n           os_name=versions['system'],\r\n           os_version=versions['release'],\r\n           dependencies=dependencies.status())\r\n\r\n        return issue_template"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef report_issue(self, body=None, title=None, open_webpage=False):\r\n        if body is None:\r\n            from spyder.widgets.reporterror import SpyderErrorDialog\r\n            report_dlg = SpyderErrorDialog(self, is_report=True)\r\n            report_dlg.show()\r\n        else:\r\n            if open_webpage:\r\n                if PY3:\r\n                    from urllib.parse import quote\r\n                else:\r\n                    from urllib import quote     # analysis:ignore\r\n                from qtpy.QtCore import QUrlQuery\r\n\r\n                url = QUrl(__project_url__ + '/issues/new')\r\n                query = QUrlQuery()\r\n                query.addQueryItem(\"body\", quote(body))\r\n                if title:\r\n                    query.addQueryItem(\"title\", quote(title))\r\n                url.setQuery(query)\r\n                QDesktopServices.openUrl(url)", "response": "Report a Spyder issue to github generating body text if needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef global_callback(self):\r\n        widget = QApplication.focusWidget()\r\n        action = self.sender()\r\n        callback = from_qvariant(action.data(), to_text_string)\r\n        from spyder.plugins.editor.widgets.editor import TextEditBaseWidget\r\n        from spyder.plugins.ipythonconsole.widgets import ControlWidget\r\n\r\n        if isinstance(widget, (TextEditBaseWidget, ControlWidget)):\r\n            getattr(widget, callback)()\r\n        else:\r\n            return", "response": "Global callback for Spyder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute lines in IPython console and eventually set focus_to_editor to the Editor.", "response": "def execute_in_external_console(self, lines, focus_to_editor):\r\n        \"\"\"\r\n        Execute lines in IPython console and eventually set focus\r\n        to the Editor.\r\n        \"\"\"\r\n        console = self.ipyconsole\r\n        console.switch_to_plugin()\r\n        console.execute_code(lines)\r\n        if focus_to_editor:\r\n            self.editor.switch_to_plugin()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_file(self, fname, external=False):\r\n        fname = to_text_string(fname)\r\n        ext = osp.splitext(fname)[1]\r\n        if encoding.is_text_file(fname):\r\n            self.editor.load(fname)\r\n        elif self.variableexplorer is not None and ext in IMPORT_EXT:\r\n            self.variableexplorer.import_data(fname)\r\n        elif not external:\r\n            fname = file_uri(fname)\r\n            programs.start_file(fname)", "response": "Open a file with the appropriate application\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen an external file that can be handled by the Editor or the variable explorer inside Spyder.", "response": "def open_external_file(self, fname):\r\n        \"\"\"\r\n        Open external files that can be handled either by the Editor or the\r\n        variable explorer inside Spyder.\r\n        \"\"\"\r\n        fname = encoding.to_unicode_from_fs(fname)\r\n        if osp.isfile(fname):\r\n            self.open_file(fname, external=True)\r\n        elif osp.isfile(osp.join(CWD, fname)):\r\n            self.open_file(osp.join(CWD, fname), external=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds Spyder path to sys. path.", "response": "def add_path_to_sys_path(self):\r\n        \"\"\"Add Spyder path to sys.path\"\"\"\r\n        for path in reversed(self.get_spyder_pythonpath()):\r\n            sys.path.insert(1, path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving Spyder path from sys. path.", "response": "def remove_path_from_sys_path(self):\r\n        \"\"\"Remove Spyder path from sys.path\"\"\"\r\n        for path in self.path + self.project_path:\r\n            while path in sys.path:\r\n                sys.path.remove(path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pythonpath_changed(self):\r\n        self.remove_path_from_sys_path()\r\n        self.project_path = self.projects.get_pythonpath()\r\n        self.add_path_to_sys_path()\r\n        self.sig_pythonpath_changed.emit()", "response": "Projects PYTHONPATH contribution has changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies settings changed in Preferences dialog box box", "response": "def apply_settings(self):\r\n        \"\"\"Apply settings changed in 'Preferences' dialog box\"\"\"\r\n        qapp = QApplication.instance()\r\n        # Set 'gtk+' as the default theme in Gtk-based desktops\r\n        # Fixes Issue 2036\r\n        if is_gtk_desktop() and ('GTK+' in QStyleFactory.keys()):\r\n            try:\r\n                qapp.setStyle('gtk+')\r\n            except:\r\n                pass\r\n        else:\r\n            style_name = CONF.get('appearance', 'windows_style',\r\n                                  self.default_style)\r\n            style = QStyleFactory.create(style_name)\r\n            if style is not None:\r\n                style.setProperty('name', style_name)\r\n                qapp.setStyle(style)\r\n\r\n        default = self.DOCKOPTIONS\r\n        if CONF.get('main', 'vertical_tabs'):\r\n            default = default|QMainWindow.VerticalTabs\r\n        if CONF.get('main', 'animated_docks'):\r\n            default = default|QMainWindow.AnimatedDocks\r\n        self.setDockOptions(default)\r\n\r\n        self.apply_panes_settings()\r\n        self.apply_statusbar_settings()\r\n\r\n        if CONF.get('main', 'use_custom_cursor_blinking'):\r\n            qapp.setCursorFlashTime(CONF.get('main', 'custom_cursor_blinking'))\r\n        else:\r\n            qapp.setCursorFlashTime(self.CURSORBLINK_OSDEFAULT)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_panes_settings(self):\r\n        for plugin in (self.widgetlist + self.thirdparty_plugins):\r\n            features = plugin.FEATURES\r\n            if CONF.get('main', 'vertical_dockwidget_titlebars'):\r\n                features = features | QDockWidget.DockWidgetVerticalTitleBar\r\n            plugin.dockwidget.setFeatures(features)\r\n            plugin.update_margins()", "response": "Update dockwidgets features settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_statusbar_settings(self):\r\n        show_status_bar = CONF.get('main', 'show_status_bar')\r\n        self.statusBar().setVisible(show_status_bar)\r\n\r\n        if show_status_bar:\r\n            for widget, name in ((self.mem_status, 'memory_usage'),\r\n                                 (self.cpu_status, 'cpu_usage')):\r\n                if widget is not None:\r\n                    widget.setVisible(CONF.get('main', '%s/enable' % name))\r\n                    widget.set_interval(CONF.get('main', '%s/timeout' % name))\r\n        else:\r\n            return", "response": "Update status bar widgets settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters QAction or QShortcut to Spyder main application", "response": "def register_shortcut(self, qaction_or_qshortcut, context, name,\r\n                          add_sc_to_tip=False):\r\n        \"\"\"\r\n        Register QAction or QShortcut to Spyder main application,\r\n        with shortcut (context, name, default)\r\n        \"\"\"\r\n        self.shortcut_data.append( (qaction_or_qshortcut, context,\r\n                                    name, add_sc_to_tip) )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_shortcuts(self):\r\n        toberemoved = []\r\n        for index, (qobject, context, name,\r\n                    add_sc_to_tip) in enumerate(self.shortcut_data):\r\n            keyseq = QKeySequence( get_shortcut(context, name) )\r\n            try:\r\n                if isinstance(qobject, QAction):\r\n                    if sys.platform == 'darwin' and \\\r\n                      qobject._shown_shortcut == 'missing':\r\n                        qobject._shown_shortcut = keyseq\r\n                    else:\r\n                        qobject.setShortcut(keyseq)\r\n                    if add_sc_to_tip:\r\n                        add_shortcut_to_tooltip(qobject, context, name)\r\n                elif isinstance(qobject, QShortcut):\r\n                    qobject.setKey(keyseq)\r\n            except RuntimeError:\r\n                # Object has been deleted\r\n                toberemoved.append(index)\r\n        for index in sorted(toberemoved, reverse=True):\r\n            self.shortcut_data.pop(index)", "response": "Apply shortcuts settings to all widgets and plugins"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset Spyder and restart application.", "response": "def reset_spyder(self):\r\n        \"\"\"\r\n        Quit and reset Spyder and then Restart application.\r\n        \"\"\"\r\n        answer = QMessageBox.warning(self, _(\"Warning\"),\r\n             _(\"Spyder will restart and reset to default settings: <br><br>\"\r\n               \"Do you want to continue?\"),\r\n             QMessageBox.Yes | QMessageBox.No)\r\n        if answer == QMessageBox.Yes:\r\n            self.restart(reset=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nquits and Restart Spyder application. If reset True it allows to reset spyder on restart.", "response": "def restart(self, reset=False):\r\n        \"\"\"\r\n        Quit and Restart Spyder application.\r\n\r\n        If reset True it allows to reset spyder on restart.\r\n        \"\"\"\r\n        # Get start path to use in restart script\r\n        spyder_start_directory = get_module_path('spyder')\r\n        restart_script = osp.join(spyder_start_directory, 'app', 'restart.py')\r\n\r\n        # Get any initial argument passed when spyder was started\r\n        # Note: Variables defined in bootstrap.py and spyder/app/start.py\r\n        env = os.environ.copy()\r\n        bootstrap_args = env.pop('SPYDER_BOOTSTRAP_ARGS', None)\r\n        spyder_args = env.pop('SPYDER_ARGS')\r\n\r\n        # Get current process and python running spyder\r\n        pid = os.getpid()\r\n        python = sys.executable\r\n\r\n        # Check if started with bootstrap.py\r\n        if bootstrap_args is not None:\r\n            spyder_args = bootstrap_args\r\n            is_bootstrap = True\r\n        else:\r\n            is_bootstrap = False\r\n\r\n        # Pass variables as environment variables (str) to restarter subprocess\r\n        env['SPYDER_ARGS'] = spyder_args\r\n        env['SPYDER_PID'] = str(pid)\r\n        env['SPYDER_IS_BOOTSTRAP'] = str(is_bootstrap)\r\n        env['SPYDER_RESET'] = str(reset)\r\n\r\n        if DEV:\r\n            if os.name == 'nt':\r\n                env['PYTHONPATH'] = ';'.join(sys.path)\r\n            else:\r\n                env['PYTHONPATH'] = ':'.join(sys.path)\r\n\r\n        # Build the command and popen arguments depending on the OS\r\n        if os.name == 'nt':\r\n            # Hide flashing command prompt\r\n            startupinfo = subprocess.STARTUPINFO()\r\n            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\r\n            shell = False\r\n        else:\r\n            startupinfo = None\r\n            shell = True\r\n\r\n        command = '\"{0}\" \"{1}\"'\r\n        command = command.format(python, restart_script)\r\n\r\n        try:\r\n            if self.closing(True):\r\n                subprocess.Popen(command, shell=shell, env=env,\r\n                                 startupinfo=startupinfo)\r\n                self.console.quit()\r\n        except Exception as error:\r\n            # If there is an error with subprocess, Spyder should not quit and\r\n            # the error can be inspected in the internal console\r\n            print(error)  # spyder: test-skip\r\n            print(command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open_fileswitcher(self, symbol=False):\r\n        if self.fileswitcher is not None and \\\r\n          self.fileswitcher.is_visible:\r\n            self.fileswitcher.hide()\r\n            self.fileswitcher.is_visible = False\r\n            return\r\n        if symbol:\r\n            self.fileswitcher.plugin = self.editor\r\n            self.fileswitcher.set_search_text('@')\r\n        else:\r\n            self.fileswitcher.set_search_text('')\r\n        self.fileswitcher.show()\r\n        self.fileswitcher.is_visible = True", "response": "Open file list management dialog box."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_to_fileswitcher(self, plugin, tabs, data, icon):\r\n        if self.fileswitcher is None:\r\n            from spyder.widgets.fileswitcher import FileSwitcher\r\n            self.fileswitcher = FileSwitcher(self, plugin, tabs, data, icon)\r\n        else:\r\n            self.fileswitcher.add_plugin(plugin, tabs, data, icon)\r\n\r\n        self.fileswitcher.sig_goto_file.connect(\r\n                plugin.get_current_tab_manager().set_stack_index)", "response": "Add a plugin to the File Switcher."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_updates_ready(self):\r\n        from spyder.widgets.helperwidgets import MessageCheckBox\r\n\r\n        # feedback` = False is used on startup, so only positive feedback is\r\n        # given. `feedback` = True is used when after startup (when using the\r\n        # menu action, and gives feeback if updates are, or are not found.\r\n        feedback = self.give_updates_feedback\r\n\r\n        # Get results from worker\r\n        update_available = self.worker_updates.update_available\r\n        latest_release = self.worker_updates.latest_release\r\n        error_msg = self.worker_updates.error\r\n\r\n        url_r = __project_url__ + '/releases'\r\n        url_i = 'https://docs.spyder-ide.org/installation.html'\r\n\r\n        # Define the custom QMessageBox\r\n        box = MessageCheckBox(icon=QMessageBox.Information,\r\n                              parent=self)\r\n        box.setWindowTitle(_(\"Spyder updates\"))\r\n        box.set_checkbox_text(_(\"Check for updates on startup\"))\r\n        box.setStandardButtons(QMessageBox.Ok)\r\n        box.setDefaultButton(QMessageBox.Ok)\r\n\r\n        # Adjust the checkbox depending on the stored configuration\r\n        section, option = 'main', 'check_updates_on_startup'\r\n        check_updates = CONF.get(section, option)\r\n        box.set_checked(check_updates)\r\n\r\n        if error_msg is not None:\r\n            msg = error_msg\r\n            box.setText(msg)\r\n            box.set_check_visible(False)\r\n            box.exec_()\r\n            check_updates = box.is_checked()\r\n        else:\r\n            if update_available:\r\n                anaconda_msg = ''\r\n                if 'Anaconda' in sys.version or 'conda-forge' in sys.version:\r\n                    anaconda_msg = _(\"<hr><b>IMPORTANT NOTE:</b> It seems \"\r\n                                     \"that you are using Spyder with \"\r\n                                     \"<b>Anaconda/Miniconda</b>. Please \"\r\n                                     \"<b>don't</b> use <code>pip</code> to \"\r\n                                     \"update it as that will probably break \"\r\n                                     \"your installation.<br><br>\"\r\n                                     \"Instead, please wait until new conda \"\r\n                                     \"packages are available and use \"\r\n                                     \"<code>conda</code> to perform the \"\r\n                                     \"update.<hr>\")\r\n                msg = _(\"<b>Spyder %s is available!</b> <br><br>Please use \"\r\n                        \"your package manager to update Spyder or go to our \"\r\n                        \"<a href=\\\"%s\\\">Releases</a> page to download this \"\r\n                        \"new version. <br><br>If you are not sure how to \"\r\n                        \"proceed to update Spyder please refer to our \"\r\n                        \" <a href=\\\"%s\\\">Installation</a> instructions.\"\r\n                        \"\") % (latest_release, url_r, url_i)\r\n                msg += '<br>' + anaconda_msg\r\n                box.setText(msg)\r\n                box.set_check_visible(True)\r\n                box.exec_()\r\n                check_updates = box.is_checked()\r\n            elif feedback:\r\n                msg = _(\"Spyder is up to date.\")\r\n                box.setText(msg)\r\n                box.set_check_visible(False)\r\n                box.exec_()\r\n                check_updates = box.is_checked()\r\n\r\n        # Update checkbox based on user interaction\r\n        CONF.set(section, option, check_updates)\r\n\r\n        # Enable check_updates_action after the thread has finished\r\n        self.check_updates_action.setDisabled(False)\r\n\r\n        # Provide feeback when clicking menu if check on startup is on\r\n        self.give_updates_feedback = True", "response": "Called by WorkerUpdates when ready"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a thread and check for spyder updates on github releases.", "response": "def check_updates(self, startup=False):\r\n        \"\"\"\r\n        Check for spyder updates on github releases using a QThread.\r\n        \"\"\"\r\n        from spyder.workers.updates import WorkerUpdates\r\n\r\n        # Disable check_updates_action while the thread is working\r\n        self.check_updates_action.setDisabled(True)\r\n\r\n        if self.thread_updates is not None:\r\n            self.thread_updates.terminate()\r\n\r\n        self.thread_updates = QThread(self)\r\n        self.worker_updates = WorkerUpdates(self, startup=startup)\r\n        self.worker_updates.sig_ready.connect(self._check_updates_ready)\r\n        self.worker_updates.sig_ready.connect(self.thread_updates.quit)\r\n        self.worker_updates.moveToThread(self.thread_updates)\r\n        self.thread_updates.started.connect(self.worker_updates.start)\r\n        self.thread_updates.start()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the user configuration into the associated. ini file", "response": "def _save(self):\r\n        \"\"\"\r\n        Save config into the associated .ini file\r\n        \"\"\"\r\n        # See Issue 1086 and 1242 for background on why this\r\n        # method contains all the exception handling.\r\n        fname = self.filename()\r\n\r\n        def _write_file(fname):\r\n            if PY2:\r\n                # Python 2\r\n                with codecs.open(fname, 'w', encoding='utf-8') as configfile:\r\n                    self._write(configfile)\r\n            else:\r\n                # Python 3\r\n                with open(fname, 'w', encoding='utf-8') as configfile:\r\n                    self.write(configfile)\r\n\r\n        try:  # the \"easy\" way\r\n            _write_file(fname)\r\n        except EnvironmentError:\r\n            try:  # the \"delete and sleep\" way\r\n                if osp.isfile(fname):\r\n                    os.remove(fname)\r\n                time.sleep(0.05)\r\n                _write_file(fname)\r\n            except Exception as e:\r\n                print(\"Failed to write user configuration file to disk, with \"\r\n                      \"the exception shown below\")  # spyder: test-skip\r\n                print(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filename(self):\r\n        # Needs to be done this way to be used by the project config.\r\n        # To fix on a later PR\r\n        self._filename = getattr(self, '_filename', None)\r\n        self._root_path = getattr(self, '_root_path', None)\r\n\r\n        if self._filename is None and self._root_path is None:\r\n            return self._filename_global()\r\n        else:\r\n            return self._filename_projects()", "response": "Defines the name of the configuration file to use."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _filename_global(self):\r\n        if self.subfolder is None:\r\n            config_file = osp.join(get_home_dir(), '.%s.ini' % self.name)\r\n            return config_file\r\n        else:\r\n            folder = get_conf_path()\r\n            # Save defaults in a \"defaults\" dir of .spyder2 to not pollute it\r\n            if 'defaults' in self.name:\r\n                folder = osp.join(folder, 'defaults')\r\n                if not osp.isdir(folder):\r\n                    os.mkdir(folder)\r\n            config_file = osp.join(folder, '%s.ini' % self.name)\r\n            return config_file", "response": "Create a. ini filename located in user home directory and stores the global spyder preferences."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_version(self, version='0.0.0', save=True):\r\n        self.set(self.DEFAULT_SECTION_NAME, 'version', version, save=save)", "response": "Set the version of the current application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload config from the associated. ini file", "response": "def load_from_ini(self):\r\n        \"\"\"\r\n        Load config from the associated .ini file\r\n        \"\"\"\r\n        try:\r\n            if PY2:\r\n                # Python 2\r\n                fname = self.filename()\r\n                if osp.isfile(fname):\r\n                    try:\r\n                        with codecs.open(fname, encoding='utf-8') as configfile:\r\n                            self.readfp(configfile)\r\n                    except IOError:\r\n                        print(\"Failed reading file\", fname)  # spyder: test-skip\r\n            else:\r\n                # Python 3\r\n                self.read(self.filename(), encoding='utf-8')\r\n        except cp.MissingSectionHeaderError:\r\n            print(\"Warning: File contains no section headers.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the defaults after a change in version", "response": "def _update_defaults(self, defaults, old_version, verbose=False):\r\n        \"\"\"Update defaults after a change in version\"\"\"\r\n        old_defaults = self._load_old_defaults(old_version)\r\n        for section, options in defaults:\r\n            for option in options:\r\n                new_value = options[ option ]\r\n                try:\r\n                    old_value = old_defaults.get(section, option)\r\n                except (cp.NoSectionError, cp.NoOptionError):\r\n                    old_value = None\r\n                if old_value is None or \\\r\n                  to_text_string(new_value) != old_value:\r\n                    self._set(section, option, new_value, verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves deprecated options which are present in the. ini file but not in defaults.", "response": "def _remove_deprecated_options(self, old_version):\r\n        \"\"\"\r\n        Remove options which are present in the .ini file but not in defaults\r\n        \"\"\"\r\n        old_defaults = self._load_old_defaults(old_version)\r\n        for section in old_defaults.sections():\r\n            for option, _ in old_defaults.items(section, raw=self.raw):\r\n                if self.get_default(section, option) is NoDefault:\r\n                    try:\r\n                        self.remove_option(section, option)\r\n                        if len(self.items(section, raw=self.raw)) == 0:\r\n                            self.remove_section(section)\r\n                    except cp.NoSectionError:\r\n                        self.remove_section(section)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_as_defaults(self):\r\n        self.defaults = []\r\n        for section in self.sections():\r\n            secdict = {}\r\n            for option, value in self.items(section, raw=self.raw):\r\n                secdict[option] = value\r\n            self.defaults.append( (section, secdict) )", "response": "Set the defaults from the current config"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset_to_defaults(self, save=True, verbose=False, section=None):\r\n        for sec, options in self.defaults:\r\n            if section == None or section == sec:\r\n                for option in options:\r\n                    value = options[ option ]\r\n                    self._set(sec, option, value, verbose)\r\n        if save:\r\n            self._save()", "response": "Reset config to default values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_section_option(self, section, option):\r\n        if section is None:\r\n            section = self.DEFAULT_SECTION_NAME\r\n        elif not is_text_string(section):\r\n            raise RuntimeError(\"Argument 'section' must be a string\")\r\n        if not is_text_string(option):\r\n            raise RuntimeError(\"Argument 'option' must be a string\")\r\n        return section", "response": "Private method to check the section and option types\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the default value for a given option in a given section.", "response": "def get_default(self, section, option):\r\n        \"\"\"\r\n        Get Default value for a given (section, option)\r\n        -> useful for type checking in 'get' method\r\n        \"\"\"\r\n        section = self._check_section_option(section, option)\r\n        for sec, options in self.defaults:\r\n            if sec == section:\r\n                if option in options:\r\n                    return options[ option ]\r\n        else:\r\n            return NoDefault"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, section, option, default=NoDefault):\r\n        section = self._check_section_option(section, option)\r\n\r\n        if not self.has_section(section):\r\n            if default is NoDefault:\r\n                raise cp.NoSectionError(section)\r\n            else:\r\n                self.add_section(section)\r\n        \r\n        if not self.has_option(section, option):\r\n            if default is NoDefault:\r\n                raise cp.NoOptionError(option, section)\r\n            else:\r\n                self.set(section, option, default)\r\n                return default\r\n            \r\n        value = cp.ConfigParser.get(self, section, option, raw=self.raw)\r\n        # Use type of default_value to parse value correctly\r\n        default_value = self.get_default(section, option)\r\n        if isinstance(default_value, bool):\r\n            value = ast.literal_eval(value)\r\n        elif isinstance(default_value, float):\r\n            value = float(value)\r\n        elif isinstance(default_value, int):\r\n            value = int(value)\r\n        elif is_text_string(default_value):\r\n            if PY2:\r\n                try:\r\n                    value = value.decode('utf-8')\r\n                    try:\r\n                        # Some str config values expect to be eval after decoding\r\n                        new_value = ast.literal_eval(value)\r\n                        if is_text_string(new_value):\r\n                            value = new_value\r\n                    except (SyntaxError, ValueError):\r\n                        pass\r\n                except (UnicodeEncodeError, UnicodeDecodeError):\r\n                    pass\r\n        else:\r\n            try:\r\n                # lists, tuples, ...\r\n                value = ast.literal_eval(value)\r\n            except (SyntaxError, ValueError):\r\n                pass\r\n        return value", "response": "Get an option from a section."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the default value for a given option in a given section.", "response": "def set_default(self, section, option, default_value):\r\n        \"\"\"\r\n        Set Default value for a given (section, option)\r\n        -> called when a new (section, option) is set and no default exists\r\n        \"\"\"\r\n        section = self._check_section_option(section, option)\r\n        for sec, options in self.defaults:\r\n            if sec == section:\r\n                options[ option ] = default_value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, section, option, value, verbose=False, save=True):\r\n        section = self._check_section_option(section, option)\r\n        default_value = self.get_default(section, option)\r\n        if default_value is NoDefault:\r\n            # This let us save correctly string value options with\r\n            # no config default that contain non-ascii chars in\r\n            # Python 2\r\n            if PY2 and is_text_string(value):\r\n                value = repr(value)\r\n            default_value = value\r\n            self.set_default(section, option, default_value)\r\n        if isinstance(default_value, bool):\r\n            value = bool(value)\r\n        elif isinstance(default_value, float):\r\n            value = float(value)\r\n        elif isinstance(default_value, int):\r\n            value = int(value)\r\n        elif not is_text_string(default_value):\r\n            value = repr(value)\r\n        self._set(section, option, value, verbose)\r\n        if save:\r\n            self._save()", "response": "Set an option in a given section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a temporary Spyder directory.", "response": "def get_temp_dir(suffix=None):\r\n    \"\"\"\r\n    Return temporary Spyder directory, checking previously that it exists.\r\n    \"\"\"\r\n    to_join = [tempfile.gettempdir()]\r\n\r\n    if os.name == 'nt':\r\n        to_join.append('spyder')\r\n    else:\r\n        username = encoding.to_unicode_from_fs(getuser())\r\n        to_join.append('spyder-' + username)\r\n\r\n    if suffix is not None:\r\n        to_join.append(suffix)\r\n\r\n    tempdir = osp.join(*to_join)\r\n\r\n    if not osp.isdir(tempdir):\r\n        os.mkdir(tempdir)\r\n\r\n    return tempdir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_program_installed(basename):\r\n    for path in os.environ[\"PATH\"].split(os.pathsep):\r\n        abspath = osp.join(path, basename)\r\n        if osp.isfile(abspath):\r\n            return abspath", "response": "Returns the absolute path of the given program if it is installed in the PATH."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a program in PATH and return absolute path", "response": "def find_program(basename):\r\n    \"\"\"\r\n    Find program in PATH and return absolute path\r\n\r\n    Try adding .exe or .bat to basename on Windows platforms\r\n    (return None if not found)\r\n    \"\"\"\r\n    names = [basename]\r\n    if os.name == 'nt':\r\n        # Windows platforms\r\n        extensions = ('.exe', '.bat', '.cmd')\r\n        if not basename.endswith(extensions):\r\n            names = [basename+ext for ext in extensions]+[basename]\r\n    for name in names:\r\n        path = is_program_installed(name)\r\n        if path:\r\n            return path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef alter_subprocess_kwargs_by_platform(**kwargs):\r\n    kwargs.setdefault('close_fds', os.name == 'posix')\r\n    if os.name == 'nt':\r\n        CONSOLE_CREATION_FLAGS = 0  # Default value\r\n        # See: https://msdn.microsoft.com/en-us/library/windows/desktop/ms684863%28v=vs.85%29.aspx\r\n        CREATE_NO_WINDOW = 0x08000000\r\n        # We \"or\" them together\r\n        CONSOLE_CREATION_FLAGS |= CREATE_NO_WINDOW\r\n        kwargs.setdefault('creationflags', CONSOLE_CREATION_FLAGS)\r\n    return kwargs", "response": "Given a dict populate kwargs to create a generally\r\n    useful default setup for running subprocess processes\r\n    on different platforms"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_shell_command(cmdstr, **subprocess_kwargs):\r\n    if 'shell' in subprocess_kwargs and not subprocess_kwargs['shell']:\r\n        raise ProgramError(\r\n                'The \"shell\" kwarg may be omitted, but if '\r\n                'provided it must be True.')\r\n    else:\r\n        subprocess_kwargs['shell'] = True\r\n\r\n    if 'executable' not in subprocess_kwargs:\r\n        subprocess_kwargs['executable'] = os.getenv('SHELL')\r\n\r\n    for stream in ['stdin', 'stdout', 'stderr']:\r\n        subprocess_kwargs.setdefault(stream, subprocess.PIPE)\r\n    subprocess_kwargs = alter_subprocess_kwargs_by_platform(\r\n            **subprocess_kwargs)\r\n    return subprocess.Popen(cmdstr, **subprocess_kwargs)", "response": "Executes a shell command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_program(program, args=None, **subprocess_kwargs):\r\n    if 'shell' in subprocess_kwargs and subprocess_kwargs['shell']:\r\n        raise ProgramError(\r\n                \"This function is only for non-shell programs, \"\r\n                \"use run_shell_command() instead.\")\r\n    fullcmd = find_program(program)\r\n    if not fullcmd:\r\n        raise ProgramError(\"Program %s was not found\" % program)\r\n    # As per subprocess, we make a complete list of prog+args\r\n    fullcmd = [fullcmd] + (args or [])\r\n    for stream in ['stdin', 'stdout', 'stderr']:\r\n        subprocess_kwargs.setdefault(stream, subprocess.PIPE)\r\n    subprocess_kwargs = alter_subprocess_kwargs_by_platform(\r\n            **subprocess_kwargs)\r\n    return subprocess.Popen(fullcmd, **subprocess_kwargs)", "response": "Runs a program in a separate process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngeneralizes os. startfile for all platforms supported by Qt", "response": "def start_file(filename):\r\n    \"\"\"\r\n    Generalized os.startfile for all platforms supported by Qt\r\n\r\n    This function is simply wrapping QDesktopServices.openUrl\r\n\r\n    Returns True if successfull, otherwise returns False.\r\n    \"\"\"\r\n    from qtpy.QtCore import QUrl\r\n    from qtpy.QtGui import QDesktopServices\r\n\r\n    # We need to use setUrl instead of setPath because this is the only\r\n    # cross-platform way to open external files. setPath fails completely on\r\n    # Mac and doesn't open non-ascii files on Linux.\r\n    # Fixes Issue 740\r\n    url = QUrl()\r\n    url.setUrl(filename)\r\n    return QDesktopServices.openUrl(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef python_script_exists(package=None, module=None):\r\n    assert module is not None\r\n    try:\r\n        if package is None:\r\n            path = imp.find_module(module)[1]\r\n        else:\r\n            path = osp.join(imp.find_module(package)[1], module)+'.py'\r\n    except ImportError:\r\n        return\r\n    if not osp.isfile(path):\r\n        path += 'w'\r\n    if osp.isfile(path):\r\n        return path", "response": "Returns absolute path if Python script exists otherwise return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a Python script in a separate process", "response": "def run_python_script(package=None, module=None, args=[], p_args=[]):\r\n    \"\"\"\r\n    Run Python script in a separate process\r\n    package=None -> module is in sys.path (standard library modules)\r\n    \"\"\"\r\n    assert module is not None\r\n    assert isinstance(args, (tuple, list)) and isinstance(p_args, (tuple, list))\r\n    path = python_script_exists(package, module)\r\n    run_program(sys.executable, p_args + [path] + args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting the string text using shell - like syntax", "response": "def shell_split(text):\r\n    \"\"\"\r\n    Split the string `text` using shell-like syntax\r\n\r\n    This avoids breaking single/double-quoted strings (e.g. containing\r\n    strings with spaces). This function is almost equivalent to the shlex.split\r\n    function (see standard library `shlex`) except that it is supporting\r\n    unicode strings (shlex does not support unicode until Python 2.7.3).\r\n    \"\"\"\r\n    assert is_text_string(text)  # in case a QString is passed...\r\n    pattern = r'(\\s+|(?<!\\\\)\".*?(?<!\\\\)\"|(?<!\\\\)\\'.*?(?<!\\\\)\\')'\r\n    out = []\r\n    for token in re.split(pattern, text):\r\n        if token.strip():\r\n            out.append(token.strip('\"').strip(\"'\"))\r\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_python_args(fname, python_args, interact, debug, end_args):\r\n    p_args = []\r\n    if python_args is not None:\r\n        p_args += python_args.split()\r\n    if interact:\r\n        p_args.append('-i')\r\n    if debug:\r\n        p_args.extend(['-m', 'pdb'])\r\n    if fname is not None:\r\n        if os.name == 'nt' and debug:\r\n            # When calling pdb on Windows, one has to replace backslashes by\r\n            # slashes to avoid confusion with escape characters (otherwise, \r\n            # for example, '\\t' will be interpreted as a tabulation):\r\n            p_args.append(osp.normpath(fname).replace(os.sep, '/'))\r\n        else:\r\n            p_args.append(fname)\r\n    if end_args:\r\n        p_args.extend(shell_split(end_args))\r\n    return p_args", "response": "Construct the list of arguments to pass to the Python interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_python_script_in_terminal(fname, wdir, args, interact,\r\n                                  debug, python_args, executable=None):\r\n    \"\"\"\r\n    Run Python script in an external system terminal.\r\n\r\n    :str wdir: working directory, may be empty.\r\n    \"\"\"\r\n    if executable is None:\r\n        executable = get_python_executable()\r\n\r\n    # If fname or python_exe contains spaces, it can't be ran on Windows, so we\r\n    # have to enclose them in quotes. Also wdir can come with / as os.sep, so\r\n    # we need to take care of it.\r\n    if os.name == 'nt':\r\n        fname = '\"' + fname + '\"'\r\n        wdir = wdir.replace('/', '\\\\')\r\n        executable = '\"' + executable + '\"'\r\n\r\n    p_args = [executable]\r\n    p_args += get_python_args(fname, python_args, interact, debug, args)\r\n\r\n    if os.name == 'nt':\r\n        cmd = 'start cmd.exe /c \"cd %s && ' % wdir + ' '.join(p_args) + '\"'\r\n        # Command line and cwd have to be converted to the filesystem\r\n        # encoding before passing them to subprocess, but only for\r\n        # Python 2.\r\n        # See https://bugs.python.org/issue1759845#msg74142 and Issue 1856\r\n        if PY2:\r\n            cmd = encoding.to_fs_from_unicode(cmd)\r\n            wdir = encoding.to_fs_from_unicode(wdir)\r\n        try:\r\n            run_shell_command(cmd, cwd=wdir)\r\n        except WindowsError:\r\n            from qtpy.QtWidgets import QMessageBox\r\n            from spyder.config.base import _\r\n            QMessageBox.critical(None, _('Run'),\r\n                                 _(\"It was not possible to run this file in \"\r\n                                   \"an external terminal\"),\r\n                                 QMessageBox.Ok)\r\n    elif os.name == 'posix':\r\n        programs = [{'cmd': 'gnome-terminal',\r\n                     'wdir-option': '--working-directory',\r\n                     'execute-option': '-x'},\r\n                    {'cmd': 'konsole',\r\n                     'wdir-option': '--workdir',\r\n                     'execute-option': '-e'},\r\n                    {'cmd': 'xfce4-terminal',\r\n                     'wdir-option': '--working-directory',\r\n                     'execute-option': '-x'},\r\n                    {'cmd': 'xterm',\r\n                     'wdir-option': None,\r\n                     'execute-option': '-e'},]\r\n        for program in programs:\r\n            if is_program_installed(program['cmd']):\r\n                arglist = []\r\n                if program['wdir-option'] and wdir:\r\n                    arglist += [program['wdir-option'], wdir]\r\n                arglist.append(program['execute-option'])\r\n                arglist += p_args\r\n                if wdir:\r\n                    run_program(program['cmd'], arglist, cwd=wdir)\r\n                else:\r\n                    run_program(program['cmd'], arglist)\r\n                return\r\n        # TODO: Add a fallback to OSX\r\n    else:\r\n        raise NotImplementedError", "response": "Runs a Python script in an external system terminal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_version(actver, version, cmp_op):\r\n    if isinstance(actver, tuple):\r\n        actver = '.'.join([str(i) for i in actver])\r\n\r\n    # Hacks needed so that LooseVersion understands that (for example)\r\n    # version = '3.0.0' is in fact bigger than actver = '3.0.0rc1'\r\n    if is_stable_version(version) and not is_stable_version(actver) and \\\r\n      actver.startswith(version) and version != actver:\r\n        version = version + 'zz'\r\n    elif is_stable_version(actver) and not is_stable_version(version) and \\\r\n      version.startswith(actver) and version != actver:\r\n        actver = actver + 'zz'\r\n\r\n    try:\r\n        if cmp_op == '>':\r\n            return LooseVersion(actver) > LooseVersion(version)\r\n        elif cmp_op == '>=':\r\n            return LooseVersion(actver) >= LooseVersion(version)\r\n        elif cmp_op == '=':\r\n            return LooseVersion(actver) == LooseVersion(version)\r\n        elif cmp_op == '<':\r\n            return LooseVersion(actver) < LooseVersion(version)\r\n        elif cmp_op == '<=':\r\n            return LooseVersion(actver) <= LooseVersion(version)\r\n        else:\r\n            return False\r\n    except TypeError:\r\n        return True", "response": "Check the version of an active module against a required version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_module_installed(module_name, version=None, installed_version=None,\r\n                        interpreter=None):\r\n    \"\"\"\r\n    Return True if module *module_name* is installed\r\n\r\n    If version is not None, checking module version\r\n    (module must have an attribute named '__version__')\r\n\r\n    version may starts with =, >=, > or < to specify the exact requirement ;\r\n    multiple conditions may be separated by ';' (e.g. '>=0.13;<1.0')\r\n\r\n    interpreter: check if a module is installed with a given version\r\n    in a determined interpreter\r\n    \"\"\"\r\n    if interpreter:\r\n        if osp.isfile(interpreter) and ('python' in interpreter):\r\n            checkver = inspect.getsource(check_version)\r\n            get_modver = inspect.getsource(get_module_version)\r\n            stable_ver = inspect.getsource(is_stable_version)\r\n            ismod_inst = inspect.getsource(is_module_installed)\r\n\r\n            f = tempfile.NamedTemporaryFile('wt', suffix='.py', \r\n                                            dir=get_temp_dir(), delete=False) \r\n            try:\r\n                script = f.name\r\n                f.write(\"# -*- coding: utf-8 -*-\" + \"\\n\\n\")\r\n                f.write(\"from distutils.version import LooseVersion\" + \"\\n\")\r\n                f.write(\"import re\" + \"\\n\\n\")\r\n                f.write(stable_ver + \"\\n\")\r\n                f.write(checkver + \"\\n\")\r\n                f.write(get_modver + \"\\n\")\r\n                f.write(ismod_inst + \"\\n\")\r\n                if version:\r\n                    f.write(\"print(is_module_installed('%s','%s'))\"\\\r\n                            % (module_name, version))\r\n                else:\r\n                    f.write(\"print(is_module_installed('%s'))\" % module_name)\r\n\r\n                # We need to flush and sync changes to ensure that the content\r\n                # of the file is in disk before running the script\r\n                f.flush()\r\n                os.fsync(f)\r\n                f.close()\r\n                try:\r\n                    proc = run_program(interpreter, [script])\r\n                    output, _err = proc.communicate()\r\n                except subprocess.CalledProcessError:\r\n                    return True\r\n                return eval(output.decode())\r\n            finally:\r\n                if not f.closed:\r\n                    f.close()\r\n                os.remove(script)\r\n        else:\r\n            # Try to not take a wrong decision if there is no interpreter\r\n            # available (needed for the change_pystartup method of ExtConsole\r\n            # config page)\r\n            return True\r\n    else:\r\n        if installed_version is None:\r\n            try:\r\n                actver = get_module_version(module_name)\r\n            except:\r\n                # Module is not installed\r\n                return False\r\n        else:\r\n            actver = installed_version\r\n        if actver is None and version is not None:\r\n            return False\r\n        elif version is None:\r\n            return True\r\n        else:\r\n            if ';' in version:\r\n                output = True\r\n                for ver in version.split(';'):\r\n                    output = output and is_module_installed(module_name, ver)\r\n                return output\r\n            match = re.search(r'[0-9]', version)\r\n            assert match is not None, \"Invalid version number\"\r\n            symb = version[:match.start()]\r\n            if not symb:\r\n                symb = '='\r\n            assert symb in ('>=', '>', '=', '<', '<='),\\\r\n                    \"Invalid version condition '%s'\" % symb\r\n            version = version[match.start():]\r\n            \r\n            return check_version(actver, version, symb)", "response": "Returns True if module module_name is installed with the given version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the python interpreter file has a valid name.", "response": "def is_python_interpreter_valid_name(filename):\r\n    \"\"\"Check that the python interpreter file has a valid name.\"\"\"\r\n    pattern = r'.*python(\\d\\.?\\d*)?(w)?(.exe)?$'\r\n    if re.match(pattern, filename, flags=re.I) is None:\r\n        return False\r\n    else:\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_python_interpreter(filename):\r\n    real_filename = os.path.realpath(filename)  # To follow symlink if existent\r\n    if (not osp.isfile(real_filename) or \r\n        not is_python_interpreter_valid_name(filename)):\r\n        return False\r\n    elif is_pythonw(filename):\r\n        if os.name == 'nt':\r\n            # pythonw is a binary on Windows\r\n            if not encoding.is_text_file(real_filename):\r\n                return True\r\n            else:\r\n                return False\r\n        elif sys.platform == 'darwin':\r\n            # pythonw is a text file in Anaconda but a binary in\r\n            # the system\r\n            if is_anaconda() and encoding.is_text_file(real_filename):\r\n                return True\r\n            elif not encoding.is_text_file(real_filename):\r\n                return True\r\n            else:\r\n                return False\r\n        else:\r\n            # There's no pythonw in other systems\r\n            return False\r\n    elif encoding.is_text_file(real_filename):\r\n        # At this point we can't have a text file\r\n        return False\r\n    else:\r\n        return check_python_help(filename)", "response": "Evaluate wether a file is a python interpreter or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the python interpreter has pythonw.", "response": "def is_pythonw(filename):\r\n    \"\"\"Check that the python interpreter has 'pythonw'.\"\"\"\r\n    pattern = r'.*python(\\d\\.?\\d*)?w(.exe)?$'\r\n    if re.match(pattern, filename, flags=re.I) is None:\r\n        return False\r\n    else:\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the python interpreter can execute help.", "response": "def check_python_help(filename):\r\n    \"\"\"Check that the python interpreter can execute help.\"\"\"\r\n    try:\r\n        proc = run_program(filename, [\"-h\"])\r\n        output = to_text_string(proc.communicate()[0])\r\n        valid = (\"Options and arguments (and corresponding environment \"\r\n                 \"variables)\")\r\n        if 'usage:' in output and valid in output:\r\n            return True\r\n        else:\r\n            return False\r\n    except:\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sizeHint(self):\n        fm = QFontMetrics(self.editor.font())\n        size_hint = QSize(fm.height(), fm.height())\n        if size_hint.width() > 16:\n            size_hint.setWidth(16)\n        return size_hint", "response": "Override Qt method.\n\n        Returns the widget size hint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _draw_breakpoint_icon(self, top, painter, icon_name):\n        rect = QRect(0, top, self.sizeHint().width(),\n                     self.sizeHint().height())\n        try:\n            icon = self.icons[icon_name]\n        except KeyError as e:\n            debug_print(\"Breakpoint icon doen't exist, {}\".format(e))\n        else:\n            icon.paint(painter, rect)", "response": "Draw the given breakpoint icon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding Qt method. Paint breakpoints icons.", "response": "def paintEvent(self, event):\n        \"\"\"Override Qt method.\n\n        Paint breakpoints icons.\n        \"\"\"\n        super(DebuggerPanel, self).paintEvent(event)\n        painter = QPainter(self)\n        painter.fillRect(event.rect(), self.editor.sideareas_color)\n\n        for top, line_number, block in self.editor.visible_blocks:\n            if self.line_number_hint == line_number:\n                self._draw_breakpoint_icon(top, painter, 'transparent')\n            if self._current_line_arrow == line_number and not self.stop:\n                self._draw_breakpoint_icon(top, painter, 'arrow')\n\n            data = block.userData()\n            if data is None or not data.breakpoint:\n                continue\n\n            if data.breakpoint_condition is None:\n                self._draw_breakpoint_icon(top, painter, 'breakpoint')\n            else:\n                self._draw_breakpoint_icon(top, painter, 'condition')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mousePressEvent(self, event):\n        line_number = self.editor.get_linenumber_from_mouse_event(event)\n        shift = event.modifiers() & Qt.ShiftModifier\n        self.editor.debugger.toogle_breakpoint(line_number,\n                                               edit_condition=shift)", "response": "Override Qt method\n\n        Add or remove breakpoints by single click."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mouseMoveEvent(self, event):\n        self.line_number_hint = self.editor.get_linenumber_from_mouse_event(\n            event)\n        self.update()", "response": "Override Qt method. mouseMoveEvent Draw semitransparent breakpoint hint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_state_changed(self, state):\n        if state:\n            self.editor.sig_breakpoints_changed.connect(self.repaint)\n            self.editor.sig_debug_stop.connect(self.set_current_line_arrow)\n            self.editor.sig_debug_stop[()].connect(self.stop_clean)\n            self.editor.sig_debug_start.connect(self.start_clean)\n        else:\n            self.editor.sig_breakpoints_changed.disconnect(self.repaint)\n            self.editor.sig_debug_stop.disconnect(self.set_current_line_arrow)\n            self.editor.sig_debug_stop[()].disconnect(self.stop_clean)\n            self.editor.sig_debug_start.disconnect(self.start_clean)", "response": "Change visibility and connect and disconnect signal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        if not self._started:\n            self.sig_started.emit(self)\n            self._started = True", "response": "Start the worker (emits sig_started signal with worker as arg)."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start(self):\n        error = None\n        output = None\n\n        try:\n            output = self.func(*self.args, **self.kwargs)\n        except Exception as err:\n            error = err\n\n        if not self._is_finished:\n            self.sig_finished.emit(self, output, error)\n        self._is_finished = True", "response": "Start the process worker for given method args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_encoding(self):\n        enco = 'utf-8'\n\n        #  Currently only cp1252 is allowed?\n        if WIN:\n            import ctypes\n            codepage = to_text_string(ctypes.cdll.kernel32.GetACP())\n            # import locale\n            # locale.getpreferredencoding()  # Differences?\n            enco = 'cp' + codepage\n        return enco", "response": "Return the encoding to use."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_environment(self, environ):\n        if environ:\n            q_environ = self._process.processEnvironment()\n            for k, v in environ.items():\n                q_environ.insert(k, v)\n            self._process.setProcessEnvironment(q_environ)", "response": "Set the environment on the QProcess."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef communicate(self):\n        self._communicate_first = True\n        self._process.waitForFinished()\n\n        enco = self._get_encoding()\n        if self._partial_stdout is None:\n            raw_stdout = self._process.readAllStandardOutput()\n            stdout = handle_qbytearray(raw_stdout, enco)\n        else:\n            stdout = self._partial_stdout\n\n        raw_stderr = self._process.readAllStandardError()\n        stderr = handle_qbytearray(raw_stderr, enco)\n        result = [stdout.encode(enco), stderr.encode(enco)]\n\n        if PY2:\n            stderr = stderr.decode()\n        result[-1] = ''\n\n        self._result = result\n\n        if not self._fired:\n            self.sig_finished.emit(self, result[0], result[-1])\n\n        self._fired = True\n\n        return result", "response": "Retrieve information from the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clean_workers(self):\n        while self._bag_collector:\n            self._bag_collector.popleft()\n        self._timer_worker_delete.stop()", "response": "Delete periodically workers in workers bag."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _start(self, worker=None):\n        if worker:\n            self._queue_workers.append(worker)\n\n        if self._queue_workers and self._running_threads < self._max_threads:\n            #print('Queue: {0} Running: {1} Workers: {2} '\n            #       'Threads: {3}'.format(len(self._queue_workers),\n            #                                 self._running_threads,\n            #                                 len(self._workers),\n            #                                 len(self._threads)))\n            self._running_threads += 1\n            worker = self._queue_workers.popleft()\n            thread = QThread()\n            if isinstance(worker, PythonWorker):\n                worker.moveToThread(thread)\n                worker.sig_finished.connect(thread.quit)\n                thread.started.connect(worker._start)\n                thread.start()\n            elif isinstance(worker, ProcessWorker):\n                thread.quit()\n                worker._start()\n            self._threads.append(thread)\n        else:\n            self._timer.start()\n\n        if self._workers:\n            for w in self._workers:\n                if w.is_finished():\n                    self._bag_collector.append(w)\n                    self._workers.remove(w)\n\n        if self._threads:\n            for t in self._threads:\n                if t.isFinished():\n                    self._threads.remove(t)\n                    self._running_threads -= 1\n\n        if len(self._threads) == 0 and len(self._workers) == 0:\n            self._timer.stop()\n            self._timer_worker_delete.start()", "response": "Start threads and check for inactive workers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_python_worker(self, func, *args, **kwargs):\n        worker = PythonWorker(func, args, kwargs)\n        self._create_worker(worker)\n        return worker", "response": "Create a new python worker instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new process worker instance.", "response": "def create_process_worker(self, cmd_list, environ=None):\n        \"\"\"Create a new process worker instance.\"\"\"\n        worker = ProcessWorker(cmd_list, environ=environ)\n        self._create_worker(worker)\n        return worker"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nterminate all worker processes and threads.", "response": "def terminate_all(self):\n        \"\"\"Terminate all worker processes.\"\"\"\n        for worker in self._workers:\n            worker.terminate()\n\n        # for thread in self._threads:\n        #     try:\n        #         thread.terminate()\n        #         thread.wait()\n        #     except Exception:\n        #         pass\n        self._queue_workers = deque()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gather_file_data(name):\n    res = {'name': name}\n    try:\n        res['mtime'] = osp.getmtime(name)\n        res['size'] = osp.getsize(name)\n    except OSError:\n        pass\n    return res", "response": "Gather data about a given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_data_to_str(data):\n    if not data:\n        return _('<i>File name not recorded</i>')\n    res = data['name']\n    try:\n        mtime_as_str = time.strftime('%Y-%m-%d %H:%M:%S',\n                                     time.localtime(data['mtime']))\n        res += '<br><i>{}</i>: {}'.format(_('Last modified'), mtime_as_str)\n        res += '<br><i>{}</i>: {} {}'.format(\n                _('Size'), data['size'], _('bytes'))\n    except KeyError:\n        res += '<br>' + _('<i>File no longer exists</i>')\n    return res", "response": "Convert file data to a string for display."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates temporary files to simulate a recovery use case.", "response": "def make_temporary_files(tempdir):\n    \"\"\"\n    Make temporary files to simulate a recovery use case.\n\n    Create a directory under tempdir containing some original files and another\n    directory with autosave files. Return a tuple with the name of the\n    directory with the original files, the name of the directory with the\n    autosave files, and the autosave mapping.\n    \"\"\"\n    orig_dir = osp.join(tempdir, 'orig')\n    os.mkdir(orig_dir)\n    autosave_dir = osp.join(tempdir, 'autosave')\n    os.mkdir(autosave_dir)\n    autosave_mapping = {}\n\n    # ham.py: Both original and autosave files exist, mentioned in mapping\n    orig_file = osp.join(orig_dir, 'ham.py')\n    with open(orig_file, 'w') as f:\n        f.write('ham = \"original\"\\n')\n    autosave_file = osp.join(autosave_dir, 'ham.py')\n    with open(autosave_file, 'w') as f:\n        f.write('ham = \"autosave\"\\n')\n    autosave_mapping[orig_file] = autosave_file\n\n    # spam.py: Only autosave file exists, mentioned in mapping\n    orig_file = osp.join(orig_dir, 'spam.py')\n    autosave_file = osp.join(autosave_dir, 'spam.py')\n    with open(autosave_file, 'w') as f:\n        f.write('spam = \"autosave\"\\n')\n    autosave_mapping[orig_file] = autosave_file\n\n    # eggs.py: Only original files exists, mentioned in mapping\n    orig_file = osp.join(orig_dir, 'eggs.py')\n    with open(orig_file, 'w') as f:\n        f.write('eggs = \"original\"\\n')\n    autosave_file = osp.join(autosave_dir, 'eggs.py')\n    autosave_mapping[orig_file] = autosave_file\n\n    # cheese.py: Only autosave file exists, not mentioned in mapping\n    autosave_file = osp.join(autosave_dir, 'cheese.py')\n    with open(autosave_file, 'w') as f:\n        f.write('cheese = \"autosave\"\\n')\n\n    return orig_dir, autosave_dir, autosave_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gather_data(self):\n        self.data = []\n        try:\n            FileNotFoundError\n        except NameError:  # Python 2\n            FileNotFoundError = OSError\n        # In Python 3, easier to use os.scandir()\n        try:\n            for name in os.listdir(self.autosave_dir):\n                full_name = osp.join(self.autosave_dir, name)\n                if osp.isdir(full_name):\n                    continue\n                for orig, autosave in self.autosave_mapping.items():\n                    if autosave == full_name:\n                        orig_dict = gather_file_data(orig)\n                        break\n                else:\n                    orig_dict = None\n                autosave_dict = gather_file_data(full_name)\n                self.data.append((orig_dict, autosave_dict))\n        except FileNotFoundError:  # autosave dir does not exist\n            pass\n        self.data.sort(key=recovery_data_key_function)\n        self.num_enabled = len(self.data)", "response": "Gather data about files which may be recovered."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_label(self):\n        txt = _('Autosave files found. What would you like to do?\\n\\n'\n                'This dialog will be shown again on next startup if any '\n                'autosave files are not restored, moved or deleted.')\n        label = QLabel(txt, self)\n        label.setWordWrap(True)\n        self.layout.addWidget(label)", "response": "Add label with explanation at top of dialog window."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a label to specified cell in table.", "response": "def add_label_to_table(self, row, col, txt):\n        \"\"\"Add a label to specified cell in table.\"\"\"\n        label = QLabel(txt)\n        label.setMargin(5)\n        label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)\n        self.table.setCellWidget(row, col, label)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding table with info about files to be recovered.", "response": "def add_table(self):\n        \"\"\"Add table with info about files to be recovered.\"\"\"\n        table = QTableWidget(len(self.data), 3, self)\n        self.table = table\n\n        labels = [_('Original file'), _('Autosave file'), _('Actions')]\n        table.setHorizontalHeaderLabels(labels)\n        table.verticalHeader().hide()\n\n        table.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\n        table.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOff)\n        table.setSelectionMode(QTableWidget.NoSelection)\n\n        # Show horizontal grid lines\n        table.setShowGrid(False)\n        table.setStyleSheet('::item { border-bottom: 1px solid gray }')\n\n        for idx, (original, autosave) in enumerate(self.data):\n            self.add_label_to_table(idx, 0, file_data_to_str(original))\n            self.add_label_to_table(idx, 1, file_data_to_str(autosave))\n\n            widget = QWidget()\n            layout = QHBoxLayout()\n\n            tooltip = _('Recover the autosave file to its original location, '\n                        'replacing the original if it exists.')\n            button = QPushButton(_('Restore'))\n            button.setToolTip(tooltip)\n            button.clicked.connect(\n                    lambda checked, my_idx=idx: self.restore(my_idx))\n            layout.addWidget(button)\n\n            tooltip = _('Delete the autosave file.')\n            button = QPushButton(_('Discard'))\n            button.setToolTip(tooltip)\n            button.clicked.connect(\n                    lambda checked, my_idx=idx: self.discard(my_idx))\n            layout.addWidget(button)\n\n            tooltip = _('Display the autosave file (and the original, if it '\n                        'exists) in Spyder\\'s Editor. You will have to move '\n                        'or delete it manually.')\n            button = QPushButton(_('Open'))\n            button.setToolTip(tooltip)\n            button.clicked.connect(\n                    lambda checked, my_idx=idx: self.open_files(my_idx))\n            layout.addWidget(button)\n\n            widget.setLayout(layout)\n            self.table.setCellWidget(idx, 2, widget)\n\n        table.resizeRowsToContents()\n        table.resizeColumnsToContents()\n\n        # Need to add the \"+ 2\" because otherwise the table scrolls a tiny\n        # amount; no idea why\n        width = table.horizontalHeader().length() + 2\n        height = (table.verticalHeader().length()\n                  + table.horizontalHeader().height() + 2)\n        table.setFixedSize(width, height)\n        self.layout.addWidget(table)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_cancel_button(self):\n        button_box = QDialogButtonBox(QDialogButtonBox.Cancel, self)\n        button_box.rejected.connect(self.reject)\n        self.layout.addWidget(button_box)", "response": "Add a cancel button at the bottom of the dialog window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_plugin(self):\r\n        self.redirect_stdio.connect(self.main.redirect_internalshell_stdio)\r\n        self.main.console.shell.refresh.connect(self.refresh_plugin)\r\n        iconsize = 24 \r\n        self.toolbar.setIconSize(QSize(iconsize, iconsize))\r\n        self.main.addToolBar(self.toolbar)", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_wdhistory(self, workdir=None):\r\n        if osp.isfile(self.LOG_PATH):\r\n            wdhistory, _ = encoding.readlines(self.LOG_PATH)\r\n            wdhistory = [name for name in wdhistory if os.path.isdir(name)]\r\n        else:\r\n            if workdir is None:\r\n                workdir = get_home_dir()\r\n            wdhistory = [ workdir ]\r\n        return wdhistory", "response": "Load history from a text file in user home directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_wdhistory(self):\r\n        text = [ to_text_string( self.pathedit.itemText(index) ) \\\r\n                 for index in range(self.pathedit.count()) ]\r\n        try:\r\n            encoding.writelines(text, self.LOG_PATH)\r\n        except EnvironmentError:\r\n            pass", "response": "Save history to a text file in user home directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_directory(self):\r\n        self.redirect_stdio.emit(False)\r\n        directory = getexistingdirectory(self.main, _(\"Select directory\"),\r\n                                         getcwd_or_home())\r\n        if directory:\r\n            self.chdir(directory)\r\n        self.redirect_stdio.emit(True)", "response": "Select the main directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging working directory to parent directory", "response": "def parent_directory(self):\r\n        \"\"\"Change working directory to parent directory\"\"\"\r\n        self.chdir(os.path.join(getcwd_or_home(), os.path.pardir))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chdir(self, directory, browsing_history=False,\r\n              refresh_explorer=True, refresh_console=True):\r\n        \"\"\"Set directory as working directory\"\"\"\r\n        if directory:\r\n            directory = osp.abspath(to_text_string(directory))\r\n\r\n        # Working directory history management\r\n        if browsing_history:\r\n            directory = self.history[self.histindex]\r\n        elif directory in self.history:\r\n            self.histindex = self.history.index(directory)\r\n        else:\r\n            if self.histindex is None:\r\n                self.history = []\r\n            else:\r\n                self.history = self.history[:self.histindex+1]\r\n            self.history.append(directory)\r\n            self.histindex = len(self.history)-1\r\n        \r\n        # Changing working directory\r\n        try:\r\n            os.chdir(directory)\r\n            if refresh_explorer:\r\n                self.set_explorer_cwd.emit(directory)\r\n            if refresh_console:\r\n                self.set_current_console_wd.emit(directory)\r\n            self.refresh_findinfiles.emit()\r\n        except OSError:\r\n            self.history.pop(self.histindex)\r\n        self.refresh_plugin()", "response": "Change the working directory of the current instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef toogle_breakpoint(self, line_number=None, condition=None,\n                          edit_condition=False):\n        \"\"\"Add/remove breakpoint.\"\"\"\n        if not self.editor.is_python_like():\n            return\n        if line_number is None:\n            block = self.editor.textCursor().block()\n        else:\n            block = self.editor.document().findBlockByNumber(line_number-1)\n        data = block.userData()\n        if not data:\n            data = BlockUserData(self.editor)\n            data.breakpoint = True\n        elif not edit_condition:\n            data.breakpoint = not data.breakpoint\n            data.breakpoint_condition = None\n        if condition is not None:\n            data.breakpoint_condition = condition\n        if edit_condition:\n            condition = data.breakpoint_condition\n            condition, valid = QInputDialog.getText(self.editor,\n                                                    _('Breakpoint'),\n                                                    _(\"Condition:\"),\n                                                    QLineEdit.Normal,\n                                                    condition)\n            if not valid:\n                return\n            data.breakpoint = True\n            data.breakpoint_condition = str(condition) if condition else None\n        if data.breakpoint:\n            text = to_text_string(block.text()).strip()\n            if len(text) == 0 or text.startswith(('#', '\"', \"'\")):\n                data.breakpoint = False\n        block.setUserData(data)\n        self.editor.sig_flags_changed.emit()\n        self.editor.sig_breakpoints_changed.emit()", "response": "Add or remove breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets breakpoints from the editor", "response": "def get_breakpoints(self):\n        \"\"\"Get breakpoints\"\"\"\n        breakpoints = []\n        block = self.editor.document().firstBlock()\n        for line_number in range(1, self.editor.document().blockCount()+1):\n            data = block.userData()\n            if data and data.breakpoint:\n                breakpoints.append((line_number, data.breakpoint_condition))\n            block = block.next()\n        return breakpoints"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear_breakpoints(self):\n        self.breakpoints = []\n        for data in self.editor.blockuserdata_list[:]:\n            data.breakpoint = False\n            # data.breakpoint_condition = None  # not necessary, but logical\n            if data.is_empty():\n                # This is not calling the __del__ in BlockUserData.  Not\n                # sure if it's supposed to or not, but that seems to be the\n                # intent.\n                del data", "response": "Clear breakpoints from blockuserdata list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the breakpoints for this log entry.", "response": "def set_breakpoints(self, breakpoints):\n        \"\"\"Set breakpoints\"\"\"\n        self.clear_breakpoints()\n        for line_number, condition in breakpoints:\n            self.toogle_breakpoint(line_number, condition)\n        self.breakpoints = self.get_breakpoints()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef breakpoints_changed(self):\n        breakpoints = self.get_breakpoints()\n        if self.breakpoints != breakpoints:\n            self.breakpoints = breakpoints\n            self.save_breakpoints()", "response": "Check if breakpoints have changed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether a string has open quotes.", "response": "def unmatched_quotes_in_line(text):\n    \"\"\"Return whether a string has open quotes.\n\n    This simply counts whether the number of quote characters of either\n    type in the string is odd.\n\n    Take from the IPython project (in IPython/core/completer.py in v0.13)\n    Spyder team: Add some changes to deal with escaped quotes\n\n    - Copyright (C) 2008-2011 IPython Development Team\n    - Copyright (C) 2001-2007 Fernando Perez. <fperez@colorado.edu>\n    - Copyright (C) 2001 Python Software Foundation, www.python.org\n\n    Distributed under the terms of the BSD License.\n    \"\"\"\n    # We check \" first, then ', so complex cases with nested quotes will\n    # get the \" to take precedence.\n    text = text.replace(\"\\\\'\", \"\")\n    text = text.replace('\\\\\"', '')\n    if text.count('\"') % 2:\n        return '\"'\n    elif text.count(\"'\") % 2:\n        return \"'\"\n    else:\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_state_changed(self, state):\n        if state:\n            self.editor.sig_key_pressed.connect(self._on_key_pressed)\n        else:\n            self.editor.sig_key_pressed.disconnect(self._on_key_pressed)", "response": "Connect or disconnect sig_key_pressed signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncontrolling how to automatically insert quotes in various situations.", "response": "def _autoinsert_quotes(self, key):\n        \"\"\"Control how to automatically insert quotes in various situations.\"\"\"\n        char = {Qt.Key_QuoteDbl: '\"', Qt.Key_Apostrophe: '\\''}[key]\n\n        line_text = self.editor.get_text('sol', 'eol')\n        line_to_cursor = self.editor.get_text('sol', 'cursor')\n        cursor = self.editor.textCursor()\n        last_three = self.editor.get_text('sol', 'cursor')[-3:]\n        last_two = self.editor.get_text('sol', 'cursor')[-2:]\n        trailing_text = self.editor.get_text('cursor', 'eol').strip()\n\n        if self.editor.has_selected_text():\n            text = self.editor.get_selected_text()\n            self.editor.insert_text(\"{0}{1}{0}\".format(char, text))\n            # keep text selected, for inserting multiple quotes\n            cursor.movePosition(QTextCursor.Left, QTextCursor.MoveAnchor, 1)\n            cursor.movePosition(QTextCursor.Left, QTextCursor.KeepAnchor,\n                                len(text))\n            self.editor.setTextCursor(cursor)\n        elif self.editor.in_comment():\n            self.editor.insert_text(char)\n        elif (len(trailing_text) > 0 and\n                not unmatched_quotes_in_line(line_to_cursor) == char and\n                not trailing_text[0] in (',', ':', ';', ')', ']', '}')):\n            self.editor.insert_text(char)\n        elif (unmatched_quotes_in_line(line_text) and\n                (not last_three == 3*char)):\n            self.editor.insert_text(char)\n        # Move to the right if we are before a quote\n        elif self.editor.next_char() == char:\n            cursor.movePosition(QTextCursor.NextCharacter,\n                                QTextCursor.KeepAnchor, 1)\n            cursor.clearSelection()\n            self.editor.setTextCursor(cursor)\n        # Automatic insertion of triple double quotes (for docstrings)\n        elif last_three == 3*char:\n            self.editor.insert_text(3*char)\n            cursor = self.editor.textCursor()\n            cursor.movePosition(QTextCursor.PreviousCharacter,\n                                QTextCursor.KeepAnchor, 3)\n            cursor.clearSelection()\n            self.editor.setTextCursor(cursor)\n        # If last two chars are quotes, just insert one more because most\n        # probably the user wants to write a docstring\n        elif last_two == 2*char:\n            self.editor.insert_text(char)\n            self.editor.delayed_popup_docstring()\n        # Automatic insertion of quotes\n        else:\n            self.editor.insert_text(2*char)\n            cursor = self.editor.textCursor()\n            cursor.movePosition(QTextCursor.PreviousCharacter)\n            self.editor.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef populate(combobox, data):\n    combobox.clear()\n    combobox.addItem(\"<None>\", 0)\n\n    # First create a list of fully-qualified names.\n    cb_data = []\n    for item in data:\n        fqn = item.name\n        for parent in reversed(item.parents):\n            fqn = parent.name + \".\" + fqn\n\n        cb_data.append((fqn, item))\n\n    for fqn, item in sorted(cb_data, key=operator.itemgetter(0)):\n        # Set the icon. Just threw this in here, streight from editortools.py\n        icon = None\n        if item.def_type == OED.FUNCTION_TOKEN:\n            if item.name.startswith('__'):\n                icon = ima.icon('private2')\n            elif item.name.startswith('_'):\n                icon = ima.icon('private1')\n            else:\n                icon = ima.icon('method')\n        else:\n            icon = ima.icon('class')\n\n        # Add the combobox item\n        if icon is not None:\n            combobox.addItem(icon, fqn, item)\n        else:\n            combobox.addItem(fqn, item)", "response": "Populate the given combobox with the class or function names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the class or function definition ranges.", "response": "def _get_fold_levels(editor):\n    \"\"\"\n    Return a list of all the class/function definition ranges.\n\n    Parameters\n    ----------\n    editor : :class:`spyder.plugins.editor.widgets.codeeditor.CodeEditor`\n\n    Returns\n    -------\n    folds : list of :class:`FoldScopeHelper`\n        A list of all the class or function defintion fold points.\n    \"\"\"\n    block = editor.document().firstBlock()\n    oed = editor.get_outlineexplorer_data()\n\n    folds = []\n    parents = []\n    prev = None\n\n    while block.isValid():\n        if TextBlockHelper.is_fold_trigger(block):\n            try:\n                data = oed[block.firstLineNumber()]\n\n                if data.def_type in (OED.CLASS, OED.FUNCTION):\n                    fsh = FoldScopeHelper(FoldScope(block), data)\n\n                    # Determine the parents of the item using a stack.\n                    _adjust_parent_stack(fsh, prev, parents)\n\n                    # Update the parents of this FoldScopeHelper item\n                    fsh.parents = copy.copy(parents)\n                    folds.append(fsh)\n                    prev = fsh\n            except KeyError:\n                pass\n\n        block = block.next()\n\n    return folds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _adjust_parent_stack(fsh, prev, parents):\n    if prev is None:\n        return\n\n    if fsh.fold_scope.trigger_level < prev.fold_scope.trigger_level:\n        diff = prev.fold_scope.trigger_level - fsh.fold_scope.trigger_level\n        del parents[-diff:]\n    elif fsh.fold_scope.trigger_level > prev.fold_scope.trigger_level:\n        parents.append(prev)\n    elif fsh.fold_scope.trigger_level == prev.fold_scope.trigger_level:\n        pass", "response": "Adjust the parent stack in - place as the trigger level changes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit out classes and methods into two separate lists.", "response": "def _split_classes_and_methods(folds):\n    \"\"\"\n    Split out classes and methods into two separate lists.\n\n    Parameters\n    ----------\n    folds : list of :class:`FoldScopeHelper`\n        The result of :func:`_get_fold_levels`.\n\n    Returns\n    -------\n    classes, functions: list of :class:`FoldScopeHelper`\n        Two separate lists of :class:`FoldScopeHelper` objects. The former\n        contains only class definitions while the latter contains only\n        function/method definitions.\n    \"\"\"\n    classes = []\n    functions = []\n    for fold in folds:\n        if fold.def_type == OED.FUNCTION_TOKEN:\n            functions.append(fold)\n        elif fold.def_type == OED.CLASS_TOKEN:\n            classes.append(fold)\n\n    return classes, functions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_parents(folds, linenum):\n    # Note: this might be able to be sped up by finding some kind of\n    # abort-early condition.\n    parents = []\n    for fold in folds:\n        start, end = fold.range\n        if linenum >= start and linenum <= end:\n            parents.append(fold)\n        else:\n            continue\n\n    return parents", "response": "Get the parents at a given linenum."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_selected_cb(parents, combobox):\n    if parents is not None and len(parents) == 0:\n        combobox.setCurrentIndex(0)\n    else:\n        item = parents[-1]\n        for i in range(combobox.count()):\n            if combobox.itemData(i) == item:\n                combobox.setCurrentIndex(i)\n                break", "response": "Updates the combobox with the selected item based on the parents."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the internal data values.", "response": "def _update_data(self):\n        \"\"\"Update the internal data values.\"\"\"\n        _old = self.folds\n        self.folds = _get_fold_levels(self.editor)\n\n        # only update our dropdown lists if the folds have changed.\n        if self.folds != _old:\n            self.classes, self.funcs = _split_classes_and_methods(self.folds)\n            self.populate_dropdowns()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove the cursor to the selected definition.", "response": "def combobox_activated(self):\n        \"\"\"Move the cursor to the selected definition.\"\"\"\n        sender = self.sender()\n        data = sender.itemData(sender.currentIndex())\n\n        if isinstance(data, FoldScopeHelper):\n            self.editor.go_to_line(data.line + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the dropdowns to reflect the current class and function.", "response": "def update_selected(self, linenum):\n        \"\"\"Updates the dropdowns to reflect the current class and function.\"\"\"\n        self.parents = _get_parents(self.funcs, linenum)\n        update_selected_cb(self.parents, self.method_cb)\n\n        self.parents = _get_parents(self.classes, linenum)\n        update_selected_cb(self.parents, self.class_cb)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_palette(self, background, foreground):\r\n        palette = QPalette()\r\n        palette.setColor(QPalette.Base, background)\r\n        palette.setColor(QPalette.Text, foreground)\r\n        self.setPalette(palette)\r\n\r\n        # Set the right background color when changing color schemes\r\n        # or creating new Editor windows. This seems to be a Qt bug.\r\n        # Fixes Issue 2028 and 8069\r\n        if self.objectName():\r\n            style = \"QPlainTextEdit#%s {background: %s; color: %s;}\" % \\\r\n                    (self.objectName(), background.name(), foreground.name())\r\n            self.setStyleSheet(style)", "response": "Set text editor palette colors background color and caret color and caret text cursor color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset extra selections for a key.", "response": "def set_extra_selections(self, key, extra_selections):\r\n        \"\"\"Set extra selections for a key.\r\n\r\n        Also assign draw orders to leave current_cell and current_line\r\n        in the backgrund (and avoid them to cover other decorations)\r\n\r\n        NOTE: This will remove previous decorations added to  the same key.\r\n\r\n        Args:\r\n            key (str) name of the extra selections group.\r\n            extra_selections (list of sourcecode.api.TextDecoration).\r\n        \"\"\"\r\n        # use draw orders to highlight current_cell and current_line first\r\n        draw_order = DRAW_ORDERS.get(key)\r\n        if draw_order is None:\r\n            draw_order = DRAW_ORDERS.get('on_top')\r\n\r\n        for selection in extra_selections:\r\n            selection.draw_order = draw_order\r\n\r\n        self.clear_extra_selections(key)\r\n        self.extra_selections_dict[key] = extra_selections"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_extra_selections(self):\r\n        extra_selections = []\r\n\r\n        for key, extra in list(self.extra_selections_dict.items()):\r\n            extra_selections.extend(extra)\r\n        self.decorations.add(extra_selections)", "response": "Add extra selections to DecorationsManager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_extra_selections(self, key):\r\n        for decoration in self.extra_selections_dict.get(key, []):\r\n            self.decorations.remove(decoration)\r\n        self.extra_selections_dict[key] = []", "response": "Removes all extra selections added through set_extra_selections."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cursor_position_changed(self):\r\n        if self.bracepos is not None:\r\n            self.__highlight(self.bracepos, cancel=True)\r\n            self.bracepos = None\r\n        cursor = self.textCursor()\r\n        if cursor.position() == 0:\r\n            return\r\n        cursor.movePosition(QTextCursor.PreviousCharacter,\r\n                            QTextCursor.KeepAnchor)\r\n        text = to_text_string(cursor.selectedText())\r\n        pos1 = cursor.position()\r\n        if text in (')', ']', '}'):\r\n            pos2 = self.find_brace_match(pos1, text, forward=False)\r\n        elif text in ('(', '[', '{'):\r\n            pos2 = self.find_brace_match(pos1, text, forward=True)\r\n        else:\r\n            return\r\n        if pos2 is not None:\r\n            self.bracepos = (pos1, pos2)\r\n            self.__highlight(self.bracepos, color=self.matched_p_color)\r\n        else:\r\n            self.bracepos = (pos1,)\r\n            self.__highlight(self.bracepos, color=self.unmatched_p_color)", "response": "Highlights the current line if the cursor position has changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets wrap mode of the text.", "response": "def set_wrap_mode(self, mode=None):\r\n        \"\"\"\r\n        Set wrap mode\r\n        Valid *mode* values: None, 'word', 'character'\r\n        \"\"\"\r\n        if mode == 'word':\r\n            wrap_mode = QTextOption.WrapAtWordBoundaryOrAnywhere\r\n        elif mode == 'character':\r\n            wrap_mode = QTextOption.WrapAnywhere\r\n        else:\r\n            wrap_mode = QTextOption.NoWrap\r\n        self.setWordWrapMode(wrap_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn selected text as a processed text and to be executable in a Python interpreter", "response": "def get_selection_as_executable_code(self):\r\n        \"\"\"Return selected text as a processed text,\r\n        to be executable in a Python/IPython interpreter\"\"\"\r\n        ls = self.get_line_separator()\r\n\r\n        _indent = lambda line: len(line)-len(line.lstrip())\r\n\r\n        line_from, line_to = self.get_selection_bounds()\r\n        text = self.get_selected_text()\r\n        if not text:\r\n            return\r\n\r\n        lines = text.split(ls)\r\n        if len(lines) > 1:\r\n            # Multiline selection -> eventually fixing indentation\r\n            original_indent = _indent(self.get_text_line(line_from))\r\n            text = (\" \"*(original_indent-_indent(lines[0])))+text\r\n\r\n        # If there is a common indent to all lines, find it.\r\n        # Moving from bottom line to top line ensures that blank\r\n        # lines inherit the indent of the line *below* it,\r\n        # which is the desired behavior.\r\n        min_indent = 999\r\n        current_indent = 0\r\n        lines = text.split(ls)\r\n        for i in range(len(lines)-1, -1, -1):\r\n            line = lines[i]\r\n            if line.strip():\r\n                current_indent = _indent(line)\r\n                min_indent = min(current_indent, min_indent)\r\n            else:\r\n                lines[i] = ' ' * current_indent\r\n        if min_indent:\r\n            lines = [line[min_indent:] for line in lines]\r\n\r\n        # Remove any leading whitespace or comment lines\r\n        # since they confuse the reserved word detector that follows below\r\n        lines_removed = 0\r\n        while lines:\r\n            first_line = lines[0].lstrip()\r\n            if first_line == '' or first_line[0] == '#':\r\n                lines_removed += 1\r\n                lines.pop(0)\r\n            else:\r\n                break\r\n\r\n        # Add an EOL character after the last line of code so that it gets\r\n        # evaluated automatically by the console and any quote characters\r\n        # are separated from the triple quotes of runcell\r\n        lines.append(ls)\r\n\r\n        # Add removed lines back to have correct traceback line numbers\r\n        leading_lines_str = ls * lines_removed\r\n\r\n        return leading_lines_str + ls.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_cell_separator(self, cursor=None, block=None):\r\n        assert cursor is not None or block is not None\r\n        if cursor is not None:\r\n            cursor0 = QTextCursor(cursor)\r\n            cursor0.select(QTextCursor.BlockUnderCursor)\r\n            text = to_text_string(cursor0.selectedText())\r\n        else:\r\n            text = to_text_string(block.text())\r\n        if self.cell_separators is None:\r\n            return False\r\n        else:\r\n            return text.lstrip().startswith(self.cell_separators)", "response": "Return True if cursor is on a block separator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_current_cell(self):\r\n        cursor = self.textCursor()\r\n        cursor.movePosition(QTextCursor.StartOfBlock)\r\n        cur_pos = prev_pos = cursor.position()\r\n\r\n        # Moving to the next line that is not a separator, if we are\r\n        # exactly at one of them\r\n        while self.is_cell_separator(cursor):\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                return cursor, False\r\n        prev_pos = cur_pos\r\n        # If not, move backwards to find the previous separator\r\n        while not self.is_cell_separator(cursor):\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                if self.is_cell_separator(cursor):\r\n                    return cursor, False\r\n                else:\r\n                    break\r\n        cursor.setPosition(prev_pos)\r\n        cell_at_file_start = cursor.atStart()\r\n        # Once we find it (or reach the beginning of the file)\r\n        # move to the next separator (or the end of the file)\r\n        # so we can grab the cell contents\r\n        while not self.is_cell_separator(cursor):\r\n            cursor.movePosition(QTextCursor.NextBlock,\r\n                                QTextCursor.KeepAnchor)\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                cursor.movePosition(QTextCursor.EndOfBlock,\r\n                                    QTextCursor.KeepAnchor)\r\n                break\r\n            prev_pos = cur_pos\r\n        cell_at_file_end = cursor.atEnd()\r\n        return cursor, cell_at_file_start and cell_at_file_end", "response": "Select the current cell under cursor returns the textCursor and a boolean indicating if the entire file is selected"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_current_cell_in_visible_portion(self):\r\n        cursor = self.textCursor()\r\n        cursor.movePosition(QTextCursor.StartOfBlock)\r\n        cur_pos = prev_pos = cursor.position()\r\n\r\n        beg_pos = self.cursorForPosition(QPoint(0, 0)).position()\r\n        bottom_right = QPoint(self.viewport().width() - 1,\r\n                              self.viewport().height() - 1)\r\n        end_pos = self.cursorForPosition(bottom_right).position()\r\n\r\n        # Moving to the next line that is not a separator, if we are\r\n        # exactly at one of them\r\n        while self.is_cell_separator(cursor):\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                return cursor, False, False\r\n        prev_pos = cur_pos\r\n        # If not, move backwards to find the previous separator\r\n        while not self.is_cell_separator(cursor)\\\r\n          and cursor.position() >= beg_pos:\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                if self.is_cell_separator(cursor):\r\n                    return cursor, False, False\r\n                else:\r\n                    break\r\n        cell_at_screen_start = cursor.position() <= beg_pos\r\n        cursor.setPosition(prev_pos)\r\n        cell_at_file_start = cursor.atStart()\r\n        # Selecting cell header\r\n        if not cell_at_file_start:\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            cursor.movePosition(QTextCursor.NextBlock,\r\n                                QTextCursor.KeepAnchor)\r\n        # Once we find it (or reach the beginning of the file)\r\n        # move to the next separator (or the end of the file)\r\n        # so we can grab the cell contents\r\n        while not self.is_cell_separator(cursor)\\\r\n          and cursor.position() <= end_pos:\r\n            cursor.movePosition(QTextCursor.NextBlock,\r\n                                QTextCursor.KeepAnchor)\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                cursor.movePosition(QTextCursor.EndOfBlock,\r\n                                    QTextCursor.KeepAnchor)\r\n                break\r\n            prev_pos = cur_pos\r\n        cell_at_file_end = cursor.atEnd()\r\n        cell_at_screen_end = cursor.position() >= end_pos\r\n        return cursor,\\\r\n               cell_at_file_start and cell_at_file_end,\\\r\n               cell_at_screen_start and cell_at_screen_end", "response": "Select the current cell in the visible portion of the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef go_to_next_cell(self):\r\n        cursor = self.textCursor()\r\n        cursor.movePosition(QTextCursor.NextBlock)\r\n        cur_pos = prev_pos = cursor.position()\r\n        while not self.is_cell_separator(cursor):\r\n            # Moving to the next code cell\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                return\r\n        self.setTextCursor(cursor)", "response": "Go to the next cell of lines"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef go_to_previous_cell(self):\r\n        cursor = self.textCursor()\r\n        cur_pos = prev_pos = cursor.position()\r\n\r\n        if self.is_cell_separator(cursor):\r\n            # Move to the previous cell\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            cur_pos = prev_pos = cursor.position()\r\n\r\n        while not self.is_cell_separator(cursor):\r\n            # Move to the previous cell or the beginning of the current cell\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            prev_pos = cur_pos\r\n            cur_pos = cursor.position()\r\n            if cur_pos == prev_pos:\r\n                return\r\n\r\n        self.setTextCursor(cursor)", "response": "Go to the previous cell of lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrestores cursor selection from position bounds", "response": "def __restore_selection(self, start_pos, end_pos):\r\n        \"\"\"Restore cursor selection from position bounds\"\"\"\r\n        cursor = self.textCursor()\r\n        cursor.setPosition(start_pos)\r\n        cursor.setPosition(end_pos, QTextCursor.KeepAnchor)\r\n        self.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nduplicate current line or selected text", "response": "def __duplicate_line_or_selection(self, after_current_line=True):\r\n        \"\"\"Duplicate current line or selected text\"\"\"\r\n        cursor = self.textCursor()\r\n        cursor.beginEditBlock()\r\n        start_pos, end_pos = self.__save_selection()\r\n        if to_text_string(cursor.selectedText()):\r\n            cursor.setPosition(end_pos)\r\n            # Check if end_pos is at the start of a block: if so, starting\r\n            # changes from the previous block\r\n            cursor.movePosition(QTextCursor.StartOfBlock,\r\n                                QTextCursor.KeepAnchor)\r\n            if not to_text_string(cursor.selectedText()):\r\n                cursor.movePosition(QTextCursor.PreviousBlock)\r\n                end_pos = cursor.position()\r\n\r\n        cursor.setPosition(start_pos)\r\n        cursor.movePosition(QTextCursor.StartOfBlock)\r\n        while cursor.position() <= end_pos:\r\n            cursor.movePosition(QTextCursor.EndOfBlock, QTextCursor.KeepAnchor)\r\n            if cursor.atEnd():\r\n                cursor_temp = QTextCursor(cursor)\r\n                cursor_temp.clearSelection()\r\n                cursor_temp.insertText(self.get_line_separator())\r\n                break\r\n            cursor.movePosition(QTextCursor.NextBlock, QTextCursor.KeepAnchor)\r\n        text = cursor.selectedText()\r\n        cursor.clearSelection()\r\n\r\n        if not after_current_line:\r\n            # Moving cursor before current line/selected text\r\n            cursor.setPosition(start_pos)\r\n            cursor.movePosition(QTextCursor.StartOfBlock)\r\n            start_pos += len(text)\r\n            end_pos += len(text)\r\n\r\n        cursor.insertText(text)\r\n        cursor.endEditBlock()\r\n        self.setTextCursor(cursor)\r\n        self.__restore_selection(start_pos, end_pos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves current line or selected text", "response": "def __move_line_or_selection(self, after_current_line=True):\r\n        \"\"\"Move current line or selected text\"\"\"\r\n        cursor = self.textCursor()\r\n        cursor.beginEditBlock()\r\n        start_pos, end_pos = self.__save_selection()\r\n        last_line = False\r\n\r\n        # ------ Select text\r\n\r\n        # Get selection start location\r\n        cursor.setPosition(start_pos)\r\n        cursor.movePosition(QTextCursor.StartOfBlock)\r\n        start_pos = cursor.position()\r\n\r\n        # Get selection end location\r\n        cursor.setPosition(end_pos)\r\n        if not cursor.atBlockStart() or end_pos == start_pos:\r\n            cursor.movePosition(QTextCursor.EndOfBlock)\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n        end_pos = cursor.position()\r\n\r\n        # Check if selection ends on the last line of the document\r\n        if cursor.atEnd():\r\n            if not cursor.atBlockStart() or end_pos == start_pos:\r\n                last_line = True\r\n\r\n        # ------ Stop if at document boundary\r\n\r\n        cursor.setPosition(start_pos)\r\n        if cursor.atStart() and not after_current_line:\r\n            # Stop if selection is already at top of the file while moving up\r\n            cursor.endEditBlock()\r\n            self.setTextCursor(cursor)\r\n            self.__restore_selection(start_pos, end_pos)\r\n            return\r\n\r\n        cursor.setPosition(end_pos, QTextCursor.KeepAnchor)\r\n        if last_line and after_current_line:\r\n            # Stop if selection is already at end of the file while moving down\r\n            cursor.endEditBlock()\r\n            self.setTextCursor(cursor)\r\n            self.__restore_selection(start_pos, end_pos)\r\n            return\r\n\r\n        # ------ Move text\r\n\r\n        sel_text = to_text_string(cursor.selectedText())\r\n        cursor.removeSelectedText()\r\n\r\n\r\n        if after_current_line:\r\n            # Shift selection down\r\n            text = to_text_string(cursor.block().text())\r\n            sel_text = os.linesep + sel_text[0:-1]  # Move linesep at the start\r\n            cursor.movePosition(QTextCursor.EndOfBlock)\r\n            start_pos += len(text)+1\r\n            end_pos += len(text)\r\n            if not cursor.atEnd():\r\n                end_pos += 1\r\n        else:\r\n            # Shift selection up\r\n            if last_line:\r\n                # Remove the last linesep and add it to the selected text\r\n                cursor.deletePreviousChar()\r\n                sel_text = sel_text + os.linesep\r\n                cursor.movePosition(QTextCursor.StartOfBlock)\r\n                end_pos += 1\r\n            else:\r\n                cursor.movePosition(QTextCursor.PreviousBlock)\r\n            text = to_text_string(cursor.block().text())\r\n            start_pos -= len(text)+1\r\n            end_pos -= len(text)+1\r\n\r\n        cursor.insertText(sel_text)\r\n\r\n        cursor.endEditBlock()\r\n        self.setTextCursor(cursor)\r\n        self.__restore_selection(start_pos, end_pos)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef go_to_new_line(self):\r\n        self.stdkey_end(False, False)\r\n        self.insert_text(self.get_line_separator())", "response": "Go to the end of the current line and create a new line"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends current selection to complete lines", "response": "def extend_selection_to_complete_lines(self):\r\n        \"\"\"Extend current selection to complete lines\"\"\"\r\n        cursor = self.textCursor()\r\n        start_pos, end_pos = cursor.selectionStart(), cursor.selectionEnd()\r\n        cursor.setPosition(start_pos)\r\n        cursor.setPosition(end_pos, QTextCursor.KeepAnchor)\r\n        if cursor.atBlockStart():\r\n            cursor.movePosition(QTextCursor.PreviousBlock,\r\n                                QTextCursor.KeepAnchor)\r\n            cursor.movePosition(QTextCursor.EndOfBlock,\r\n                                QTextCursor.KeepAnchor)\r\n        self.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncate_selection(self, position_from):\r\n        position_from = self.get_position(position_from)\r\n        cursor = self.textCursor()\r\n        start, end = cursor.selectionStart(), cursor.selectionEnd()\r\n        if start < end:\r\n            start = max([position_from, start])\r\n        else:\r\n            end = max([position_from, end])\r\n        self.set_selection(start, end)", "response": "Unselect read - only parts in shell like prompt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hide_tooltip_if_necessary(self, key):\r\n        try:\r\n            calltip_char = self.get_character(self.calltip_position)\r\n            before = self.is_cursor_before(self.calltip_position,\r\n                                           char_offset=1)\r\n            other = key in (Qt.Key_ParenRight, Qt.Key_Period, Qt.Key_Tab)\r\n            if calltip_char not in ('?', '(') or before or other:\r\n                QToolTip.hideText()\r\n        except (IndexError, TypeError):\r\n            QToolTip.hideText()", "response": "Hide calltip when necessary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsmart HOME feature: cursor is first moved at indentation position, then at the start of the line", "response": "def stdkey_home(self, shift, ctrl, prompt_pos=None):\r\n        \"\"\"Smart HOME feature: cursor is first moved at\r\n        indentation position, then at the start of the line\"\"\"\r\n        move_mode = self.__get_move_mode(shift)\r\n        if ctrl:\r\n            self.moveCursor(QTextCursor.Start, move_mode)\r\n        else:\r\n            cursor = self.textCursor()\r\n            if prompt_pos is None:\r\n                start_position = self.get_position('sol')\r\n            else:\r\n                start_position = self.get_position(prompt_pos)\r\n            text = self.get_text(start_position, 'eol')\r\n            indent_pos = start_position+len(text)-len(text.lstrip())\r\n            if cursor.position() != indent_pos:\r\n                cursor.setPosition(indent_pos, move_mode)\r\n            else:\r\n                cursor.setPosition(start_position, move_mode)\r\n            self.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wheelEvent(self, event):\r\n        # This feature is disabled on MacOS, see Issue 1510\r\n        if sys.platform != 'darwin':\r\n            if event.modifiers() & Qt.ControlModifier:\r\n                if hasattr(event, 'angleDelta'):\r\n                    if event.angleDelta().y() < 0:\r\n                        self.zoom_out.emit()\r\n                    elif event.angleDelta().y() > 0:\r\n                        self.zoom_in.emit()\r\n                elif hasattr(event, 'delta'):\r\n                    if event.delta() < 0:\r\n                        self.zoom_out.emit()\r\n                    elif event.delta() > 0:\r\n                        self.zoom_in.emit()\r\n                return\r\n        QPlainTextEdit.wheelEvent(self, event)\r\n        self.highlight_current_cell()", "response": "Reimplemented to emit zoom in and zoom out signals when Ctrl is pressed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_options(argv=None):\n    parser = argparse.ArgumentParser(usage=\"spyder [options] files\")\n    parser.add_argument('--new-instance', action='store_true', default=False,\n                      help=\"Run a new instance of Spyder, even if the single \"\n                           \"instance mode has been turned on (default)\")\n    parser.add_argument('--defaults', dest=\"reset_to_defaults\",\n                      action='store_true', default=False,\n                      help=\"Reset configuration settings to defaults\")\n    parser.add_argument('--reset', dest=\"reset_config_files\",\n                      action='store_true', default=False,\n                      help=\"Remove all configuration files!\")\n    parser.add_argument('--optimize', action='store_true', default=False,\n                      help=\"Optimize Spyder bytecode (this may require \"\n                           \"administrative privileges)\")\n    parser.add_argument('-w', '--workdir', dest=\"working_directory\", default=None,\n                      help=\"Default working directory\")\n    parser.add_argument('--hide-console', action='store_true', default=False,\n                      help=\"Hide parent console window (Windows)\")\n    parser.add_argument('--show-console', action='store_true', default=False,\n                      help=\"(Deprecated) Does nothing, now the default behavior \"\n                      \"is to show the console\")\n    parser.add_argument('--multithread', dest=\"multithreaded\",\n                      action='store_true', default=False,\n                      help=\"Internal console is executed in another thread \"\n                           \"(separate from main application thread)\")\n    parser.add_argument('--profile', action='store_true', default=False,\n                      help=\"Profile mode (internal test, \"\n                           \"not related with Python profiling)\")\n    parser.add_argument('--window-title', type=str, default=None,\n                      help=\"String to show in the main window title\")\n    parser.add_argument('-p', '--project', default=None, type=str,\n                      dest=\"project\",\n                      help=\"Path that contains an Spyder project\")\n    parser.add_argument('--opengl', default=None,\n                      dest=\"opengl_implementation\",\n                      choices=['software', 'desktop', 'gles'],\n                      help=(\"OpenGL implementation to pass to Qt\")\n                      )\n    parser.add_argument('--debug-info', default=None,\n                        dest=\"debug_info\",\n                        choices=['minimal', 'verbose'],\n                        help=(\"Level of internal debugging info to give. \"\n                              \"'minimal' only logs a small amount of \"\n                              \"confirmation messages and 'verbose' logs a \"\n                              \"lot of detailed information.\")\n                       )\n    parser.add_argument('--debug-output', default='terminal',\n                        dest=\"debug_output\",\n                        choices=['terminal', 'file'],\n                        help=(\"Print internal debugging info either to the \"\n                              \"terminal or to a file called spyder-debug.log \"\n                              \"in your current working directory. Default is \"\n                              \"'terminal'.\")\n                       )\n    parser.add_argument('files', nargs='*')\n    options = parser.parse_args(argv)\n    args = options.files\n    return options, args", "response": "Convert options into commands and message structures"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a list of files opened by the project.", "response": "def set_recent_files(self, recent_files):\r\n        \"\"\"Set a list of files opened by the project.\"\"\"\r\n        for recent_file in recent_files[:]:\r\n            if not os.path.isfile(recent_file):\r\n                recent_files.remove(recent_file)\r\n        try:\r\n            self.CONF[WORKSPACE].set('main', 'recent_files',\r\n                                     list(OrderedDict.fromkeys(recent_files)))\r\n        except EnvironmentError:\r\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_recent_files(self):\r\n        try:\r\n            recent_files = self.CONF[WORKSPACE].get('main', 'recent_files',\r\n                                                    default=[])\r\n        except EnvironmentError:\r\n            return []\r\n\r\n        for recent_file in recent_files[:]:\r\n            if not os.path.isfile(recent_file):\r\n                recent_files.remove(recent_file)\r\n        return list(OrderedDict.fromkeys(recent_files))", "response": "Return a list of files opened by the project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the project root path.", "response": "def set_root_path(self, root_path):\r\n        \"\"\"Set project root path.\"\"\"\r\n        if self.name is None:\r\n            self.name = osp.basename(root_path)\r\n        self.root_path = to_text_string(root_path)\r\n        config_path = self.__get_project_config_path()\r\n        if osp.exists(config_path):\r\n            self.load()\r\n        else:\r\n            if not osp.isdir(self.root_path):\r\n                os.mkdir(self.root_path)\r\n            self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rename(self, new_name):\r\n        old_name = self.name\r\n        self.name = new_name\r\n        pypath = self.relative_pythonpath  # ??\r\n        self.root_path = self.root_path[:-len(old_name)]+new_name\r\n        self.relative_pythonpath = pypath  # ??\r\n        self.save()", "response": "Rename project and rename its root path accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text_to_url(self, text):\r\n        if text.startswith('/'):\r\n            text = text[1:]\r\n        return QUrl(self.home_url.toString()+text+'.html')", "response": "Convert text address into QUrl object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstructs current editorstack to autosave all files where necessary.", "response": "def do_autosave(self):\n        \"\"\"Instruct current editorstack to autosave files where necessary.\"\"\"\n        logger.debug('Autosave triggered')\n        stack = self.editor.get_current_editorstack()\n        stack.autosave.autosave_all()\n        self.start_autosave_timer()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noffers to recover files from autosave.", "response": "def try_recover_from_autosave(self):\n        \"\"\"Offer to recover files from autosave.\"\"\"\n        autosave_dir = get_conf_path('autosave')\n        autosave_mapping = CONF.get('editor', 'autosave_mapping', {})\n        dialog = RecoveryDialog(autosave_dir, autosave_mapping,\n                                parent=self.editor)\n        dialog.exec_if_nonempty()\n        self.recover_files_to_open = dialog.files_to_open[:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_unique_autosave_filename(self, filename, autosave_dir):\n        basename = osp.basename(filename)\n        autosave_filename = osp.join(autosave_dir, basename)\n        if autosave_filename in self.name_mapping.values():\n            counter = 0\n            root, ext = osp.splitext(basename)\n            while autosave_filename in self.name_mapping.values():\n                counter += 1\n                autosave_basename = '{}-{}{}'.format(root, counter, ext)\n                autosave_filename = osp.join(autosave_dir, autosave_basename)\n        return autosave_filename", "response": "Create unique autosave file name for specified file name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_autosave_file(self, fileinfo):\n        filename = fileinfo.filename\n        if filename not in self.name_mapping:\n            return\n        autosave_filename = self.name_mapping[filename]\n        try:\n            os.remove(autosave_filename)\n        except EnvironmentError as error:\n            action = (_('Error while removing autosave file {}')\n                      .format(autosave_filename))\n            msgbox = AutosaveErrorDialog(action, error)\n            msgbox.exec_if_enabled()\n        del self.name_mapping[filename]\n        self.stack.sig_option_changed.emit(\n                'autosave_mapping', self.name_mapping)\n        logger.debug('Removing autosave file %s', autosave_filename)", "response": "Remove the named autosave file for the specified file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_autosave_filename(self, filename):\n        try:\n            autosave_filename = self.name_mapping[filename]\n        except KeyError:\n            autosave_dir = get_conf_path('autosave')\n            if not osp.isdir(autosave_dir):\n                try:\n                    os.mkdir(autosave_dir)\n                except EnvironmentError as error:\n                    action = _('Error while creating autosave directory')\n                    msgbox = AutosaveErrorDialog(action, error)\n                    msgbox.exec_if_enabled()\n            autosave_filename = self.create_unique_autosave_filename(\n                    filename, autosave_dir)\n            self.name_mapping[filename] = autosave_filename\n            self.stack.sig_option_changed.emit(\n                    'autosave_mapping', self.name_mapping)\n            logger.debug('New autosave file name')\n        return autosave_filename", "response": "Returns name of autosave file for specified file name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autosave(self, index):\n        finfo = self.stack.data[index]\n        document = finfo.editor.document()\n        if not document.changed_since_autosave or finfo.newly_created:\n            return\n        autosave_filename = self.get_autosave_filename(finfo.filename)\n        logger.debug('Autosaving %s to %s', finfo.filename, autosave_filename)\n        try:\n            self.stack._write_to_file(finfo, autosave_filename)\n            document.changed_since_autosave = False\n        except EnvironmentError as error:\n            action = (_('Error while autosaving {} to {}')\n                      .format(finfo.filename, autosave_filename))\n            msgbox = AutosaveErrorDialog(action, error)\n            msgbox.exec_if_enabled()", "response": "Autosave a file with the given index into the current file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef autosave_all(self):\n        for index in range(self.stack.get_stack_count()):\n            self.autosave(index)", "response": "Autosave all opened files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a temporary CONF element.", "response": "def tmpconfig(request):\n    \"\"\"\n    Fixtures that returns a temporary CONF element.\n    \"\"\"\n    SUBFOLDER = tempfile.mkdtemp()\n    CONF = UserConfig('spyder-test',\n                      defaults=DEFAULTS,\n                      version=CONF_VERSION,\n                      subfolder=SUBFOLDER,\n                      raw_mode=True,\n                      )\n\n    def fin():\n        \"\"\"\n        Fixture finalizer to delete the temporary CONF element.\n        \"\"\"\n        shutil.rmtree(SUBFOLDER)\n\n    request.addfinalizer(fin)\n    return CONF"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging the last error in a file.", "response": "def log_last_error(fname, context=None):\r\n    \"\"\"Log last error in filename *fname* -- *context*: string (optional)\"\"\"\r\n    fd = open(fname, 'a')\r\n    log_time(fd)\r\n    if context:\r\n        print(\"Context\", file=fd)\r\n        print(\"-------\", file=fd)\r\n        print(\"\", file=fd)\r\n        if PY2:\r\n            print(u' '.join(context).encode('utf-8').strip(), file=fd)\r\n        else:\r\n            print(context, file=fd)\r\n        print(\"\", file=fd)\r\n        print(\"Traceback\", file=fd)\r\n        print(\"---------\", file=fd)\r\n        print(\"\", file=fd)\r\n    traceback.print_exc(file=fd)\r\n    print(\"\", file=fd)\r\n    print(\"\", file=fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_methods_calls(fname, some_class, prefix=None):\r\n    # test if file is writable\r\n    open(fname, 'a').close()\r\n    FILENAME = fname\r\n    CLASS = some_class\r\n\r\n    PREFIX = \"--[ %(asked)s / %(called)s / %(defined)s ]--\"\r\n    if prefix != None:\r\n        PREFIX = prefix\r\n    MAXWIDTH = {'o_O': 10}  # hack with editable closure dict, to align names\r\n               \r\n    def format_prefix(method, methodobj):\r\n        \"\"\"\r\n        --[ ShellBase / Internal / BaseEdit ]------- get_position\r\n        \"\"\"\r\n        classnames = {\r\n            'asked': CLASS.__name__,\r\n            'called': methodobj.__class__.__name__,\r\n            'defined': get_class_that_defined(method)\r\n        }\r\n        line = PREFIX % classnames\r\n        MAXWIDTH['o_O'] = max(len(line), MAXWIDTH['o_O'])\r\n        return line.ljust(MAXWIDTH['o_O'], '-')\r\n       \r\n    import types\r\n    def __getattribute__(self, name):\r\n        attr = object.__getattribute__(self, name)\r\n        if type(attr) is not types.MethodType:\r\n            return attr\r\n        else:\r\n            def newfunc(*args, **kwargs):\r\n                log = open(FILENAME, 'a')\r\n                prefix = format_prefix(attr, self)\r\n                log.write('%s %s\\n' % (prefix, name))\r\n                log.close()\r\n                result = attr(*args, **kwargs)\r\n                return result\r\n            return newfunc\r\n \r\n    some_class.__getattribute__ = __getattribute__", "response": "Log all methods called by some_class in a single file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npaint the scroll flag area for the current event.", "response": "def paintEvent(self, event):\n        \"\"\"\n        Override Qt method.\n        Painting the scroll flag area\n        \"\"\"\n        make_flag = self.make_flag_qrect\n\n        # Fill the whole painting area\n        painter = QPainter(self)\n        painter.fillRect(event.rect(), self.editor.sideareas_color)\n\n        # Paint warnings and todos\n        block = self.editor.document().firstBlock()\n        for line_number in range(self.editor.document().blockCount()+1):\n            data = block.userData()\n            if data:\n                if data.code_analysis:\n                    # Paint the warnings\n                    color = self.editor.warning_color\n                    for source, code, severity, message in data.code_analysis:\n                        error = severity == DiagnosticSeverity.ERROR\n                        if error:\n                            color = self.editor.error_color\n                            break\n                    self.set_painter(painter, color)\n                    painter.drawRect(make_flag(line_number))\n                if data.todo:\n                    # Paint the todos\n                    self.set_painter(painter, self.editor.todo_color)\n                    painter.drawRect(make_flag(line_number))\n                if data.breakpoint:\n                    # Paint the breakpoints\n                    self.set_painter(painter, self.editor.breakpoint_color)\n                    painter.drawRect(make_flag(line_number))\n            block = block.next()\n\n        # Paint the occurrences\n        if self.editor.occurrences:\n            self.set_painter(painter, self.editor.occurrence_color)\n            for line_number in self.editor.occurrences:\n                painter.drawRect(make_flag(line_number))\n\n        # Paint the found results\n        if self.editor.found_results:\n            self.set_painter(painter, self.editor.found_results_color)\n            for line_number in self.editor.found_results:\n                painter.drawRect(make_flag(line_number))\n\n        # Paint the slider range\n        if not self._unit_testing:\n            alt = QApplication.queryKeyboardModifiers() & Qt.AltModifier\n        else:\n            alt = self._alt_key_is_down\n        cursor_pos = self.mapFromGlobal(QCursor().pos())\n        is_over_self = self.rect().contains(cursor_pos)\n        is_over_editor = self.editor.rect().contains(\n                self.editor.mapFromGlobal(QCursor().pos()))\n        # We use QRect.contains instead of QWidget.underMouse method to\n        # determined if the cursor is over the editor or the flag scrollbar\n        # because the later gives a wrong result when a mouse button\n        # is pressed.\n        if ((is_over_self or (alt and is_over_editor)) and self.slider):\n            pen_color = QColor(Qt.gray)\n            pen_color.setAlphaF(.85)\n            painter.setPen(pen_color)\n            brush_color = QColor(Qt.gray)\n            brush_color.setAlphaF(.5)\n            painter.setBrush(QBrush(brush_color))\n            painter.drawRect(self.make_slider_range(cursor_pos))\n            self._range_indicator_is_visible = True\n        else:\n            self._range_indicator_is_visible = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding Qt method to handle key press events.", "response": "def keyPressEvent(self, event):\n        \"\"\"Override Qt method\"\"\"\n        if event.key() == Qt.Key_Alt:\n            self._alt_key_is_down = True\n            self.update()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_scrollbar_position_height(self):\n        vsb = self.editor.verticalScrollBar()\n        style = vsb.style()\n        opt = QStyleOptionSlider()\n        vsb.initStyleOption(opt)\n\n        # Get the area in which the slider handle may move.\n        groove_rect = style.subControlRect(\n                QStyle.CC_ScrollBar, opt, QStyle.SC_ScrollBarGroove, self)\n\n        return float(groove_rect.height())", "response": "Return the pixel span height of the scrollbar area in which\n        the slider handle may move"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value span height of the scrollbar", "response": "def get_scrollbar_value_height(self):\n        \"\"\"Return the value span height of the scrollbar\"\"\"\n        vsb = self.editor.verticalScrollBar()\n        return vsb.maximum()-vsb.minimum()+vsb.pageStep()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts value to position in pixels", "response": "def value_to_position(self, y):\n        \"\"\"Convert value to position in pixels\"\"\"\n        vsb = self.editor.verticalScrollBar()\n        return (y-vsb.minimum())*self.get_scale_factor()+self.offset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef position_to_value(self, y):\n        vsb = self.editor.verticalScrollBar()\n        return vsb.minimum()+max([0, (y-self.offset)/self.get_scale_factor()])", "response": "Convert position in pixels to value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake the slider range for the current item.", "response": "def make_slider_range(self, cursor_pos):\n        \"\"\"Make slider range QRect\"\"\"\n        # The slider range indicator position follows the mouse vertical\n        # position while its height corresponds to the part of the file that\n        # is currently visible on screen.\n\n        vsb = self.editor.verticalScrollBar()\n        groove_height = self.get_scrollbar_position_height()\n        slider_height = self.value_to_position(vsb.pageStep())-self.offset\n\n        # Calcul the minimum and maximum y-value to constraint the slider\n        # range indicator position to the height span of the scrollbar area\n        # where the slider may move.\n        min_ypos = self.offset\n        max_ypos = groove_height + self.offset - slider_height\n\n        # Determine the bounded y-position of the slider rect.\n        slider_y = max(min_ypos, min(max_ypos, cursor_pos.y()-slider_height/2))\n\n        return QRect(1, slider_y, self.WIDTH-2, slider_height)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_painter(self, painter, light_color):\n        painter.setPen(QColor(light_color).darker(120))\n        painter.setBrush(QBrush(QColor(light_color)))", "response": "Set scroll flag area painter pen and brush colors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_first_registration(self):\n        self.main.tabify_plugins(self.main.help, self)\n        self.dockwidget.hide()", "response": "Action to be performed on first plugin registration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_plugin(self):\n        self.profiler.datatree.sig_edit_goto.connect(self.main.editor.load)\n        self.profiler.redirect_stdio.connect(\n            self.main.redirect_internalshell_stdio)\n        self.main.add_dockwidget(self)\n\n        profiler_act = create_action(self, _(\"Profile\"),\n                                     icon=self.get_plugin_icon(),\n                                     triggered=self.run_profiler)\n        profiler_act.setEnabled(is_profiler_installed())\n        self.register_shortcut(profiler_act, context=\"Profiler\",\n                               name=\"Run profiler\")\n        \n        self.main.run_menu_actions += [profiler_act]\n        self.main.editor.pythonfile_dependent_actions += [profiler_act]", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the physical memory usage of a single page on Windows platforms only", "response": "def windows_memory_usage():\r\n    \"\"\"Return physical memory usage (float)\r\n    Works on Windows platforms only\"\"\"\r\n    from ctypes import windll, Structure, c_uint64, sizeof, byref\r\n    from ctypes.wintypes import DWORD\r\n    class MemoryStatus(Structure):\r\n        _fields_ = [('dwLength', DWORD),\r\n                    ('dwMemoryLoad',DWORD),\r\n                    ('ullTotalPhys', c_uint64),\r\n                    ('ullAvailPhys', c_uint64),\r\n                    ('ullTotalPageFile', c_uint64),\r\n                    ('ullAvailPageFile', c_uint64),\r\n                    ('ullTotalVirtual', c_uint64),\r\n                    ('ullAvailVirtual', c_uint64),\r\n                    ('ullAvailExtendedVirtual', c_uint64),]\r\n    memorystatus = MemoryStatus()\r\n    # MSDN documetation states that dwLength must be set to MemoryStatus\r\n    # size before calling GlobalMemoryStatusEx\r\n    # https://msdn.microsoft.com/en-us/library/aa366770(v=vs.85)\r\n    memorystatus.dwLength = sizeof(memorystatus)\r\n    windll.kernel32.GlobalMemoryStatusEx(byref(memorystatus))\r\n    return float(memorystatus.dwMemoryLoad)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the physical memory usage of the given object.", "response": "def psutil_phymem_usage():\r\n    \"\"\"\r\n    Return physical memory usage (float)\r\n    Requires the cross-platform psutil (>=v0.3) library\r\n    (https://github.com/giampaolo/psutil)\r\n    \"\"\"\r\n    import psutil\r\n    # This is needed to avoid a deprecation warning error with\r\n    # newer psutil versions\r\n    try:\r\n        percent = psutil.virtual_memory().percent\r\n    except:\r\n        percent = psutil.phymem_usage().percent\r\n    return percent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef drift_color(base_color, factor=110):\n    base_color = QColor(base_color)\n    if base_color.lightness() > 128:\n        return base_color.darker(factor)\n    else:\n        if base_color == QColor('#000000'):\n            return drift_color(QColor('#101010'), factor + 20)\n        else:\n            return base_color.lighter(factor + 10)", "response": "Returns a color that is lighter or darker than the base color."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_block_symbol_data(editor, block):\n    def list_symbols(editor, block, character):\n        \"\"\"\n        Retuns  a list of symbols found in the block text\n\n        :param editor: code editor instance\n        :param block: block to parse\n        :param character: character to look for.\n        \"\"\"\n        text = block.text()\n        symbols = []\n        cursor = QTextCursor(block)\n        cursor.movePosition(cursor.StartOfBlock)\n        pos = text.find(character, 0)\n        cursor.movePosition(cursor.Right, cursor.MoveAnchor, pos)\n\n        while pos != -1:\n            if not TextHelper(editor).is_comment_or_string(cursor):\n                # skips symbols in string literal or comment\n                info = ParenthesisInfo(pos, character)\n                symbols.append(info)\n            pos = text.find(character, pos + 1)\n            cursor.movePosition(cursor.StartOfBlock)\n            cursor.movePosition(cursor.Right, cursor.MoveAnchor, pos)\n        return symbols\n\n    parentheses = sorted(\n        list_symbols(editor, block, '(') + list_symbols(editor, block, ')'),\n        key=lambda x: x.position)\n    square_brackets = sorted(\n        list_symbols(editor, block, '[') + list_symbols(editor, block, ']'),\n        key=lambda x: x.position)\n    braces = sorted(\n        list_symbols(editor, block, '{') + list_symbols(editor, block, '}'),\n        key=lambda x: x.position)\n    return parentheses, square_brackets, braces", "response": "Gets the list of ParenthesisInfo for specific text block."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keep_tc_pos(func):\n    @functools.wraps(func)\n    def wrapper(editor, *args, **kwds):\n        \"\"\" Decorator \"\"\"\n        sb = editor.verticalScrollBar()\n        spos = sb.sliderPosition()\n        pos = editor.textCursor().position()\n        retval = func(editor, *args, **kwds)\n        text_cursor = editor.textCursor()\n        text_cursor.setPosition(pos)\n        editor.setTextCursor(text_cursor)\n        sb.setSliderPosition(spos)\n        return retval\n    return wrapper", "response": "Decorator that keeps the text cursor position and restore it when the wrapped function exits."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_wait_cursor(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        QApplication.setOverrideCursor(\n            QCursor(Qt.WaitCursor))\n        try:\n            ret_val = func(*args, **kwargs)\n        finally:\n            QApplication.restoreOverrideCursor()\n        return ret_val\n    return wrapper", "response": "A decorator that adds a wait cursor while the wrapped function is running."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_empty(self):\n        return (not self.breakpoint and not self.code_analysis\n                and not self.todo and not self.bookmarks)", "response": "Return whether the block of user data is empty."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting a job execution.", "response": "def request_job(self, job, *args, **kwargs):\n        \"\"\"\n        Request a job execution.\n\n        The job will be executed after the delay specified in the\n        DelayJobRunner contructor elapsed if no other job is requested until\n        then.\n\n        :param job: job.\n        :type job: callable\n        :param args: job's position arguments\n        :param kwargs: job's keyworded arguments\n        \"\"\"\n        self.cancel_requests()\n        self._job = job\n        self._args = args\n        self._kwargs = kwargs\n        self._timer.start(self.delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _exec_requested_job(self):\n        self._timer.stop()\n        self._job(*self._args, **self._kwargs)", "response": "Execute the requested job after the timer has timeout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef goto_line(self, line, column=0, end_column=0, move=True, word=''):\n        line = min(line, self.line_count())\n        text_cursor = self._move_cursor_to(line)\n        if column:\n            text_cursor.movePosition(text_cursor.Right, text_cursor.MoveAnchor,\n                                     column)\n        if end_column:\n            text_cursor.movePosition(text_cursor.Right, text_cursor.KeepAnchor,\n                                     end_column)\n        if move:\n            block = text_cursor.block()\n            self.unfold_if_colapsed(block)\n            self._editor.setTextCursor(text_cursor)\n\n            if self._editor.isVisible():\n                self._editor.centerCursor()\n            else:\n                self._editor.focus_in.connect(\n                    self._editor.center_cursor_on_next_focus)\n            if word and to_text_string(word) in to_text_string(block.text()):\n                self._editor.find(word, QTextDocument.FindCaseSensitively)\n        return text_cursor", "response": "Moves the text cursor to the specified position."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unfold_if_colapsed(self, block):\n        try:\n            folding_panel = self._editor.panels.get('FoldingPanel')\n        except KeyError:\n            pass\n        else:\n            from spyder.plugins.editor.utils.folding import FoldScope\n            if not block.isVisible():\n                block = FoldScope.find_parent_scope(block)\n                if TextBlockHelper.is_collapsed(block):\n                    folding_panel.toggle_fold_trigger(block)", "response": "Unfold parent fold trigger if the block is collapsed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef word_under_cursor(self, select_whole_word=False, text_cursor=None):\n        editor = self._editor\n        if not text_cursor:\n            text_cursor = editor.textCursor()\n        word_separators = editor.word_separators\n        end_pos = start_pos = text_cursor.position()\n        # select char by char until we are at the original cursor position.\n        while not text_cursor.atStart():\n            text_cursor.movePosition(\n                text_cursor.Left, text_cursor.KeepAnchor, 1)\n            try:\n                char = text_cursor.selectedText()[0]\n                word_separators = editor.word_separators\n                selected_txt = text_cursor.selectedText()\n                if (selected_txt in word_separators and\n                        (selected_txt != \"n\" and selected_txt != \"t\") or\n                        char.isspace()):\n                    break  # start boundary found\n            except IndexError:\n                break  # nothing selectable\n            start_pos = text_cursor.position()\n            text_cursor.setPosition(start_pos)\n        if select_whole_word:\n            # select the resot of the word\n            text_cursor.setPosition(end_pos)\n            while not text_cursor.atEnd():\n                text_cursor.movePosition(text_cursor.Right,\n                                         text_cursor.KeepAnchor, 1)\n                char = text_cursor.selectedText()[0]\n                selected_txt = text_cursor.selectedText()\n                if (selected_txt in word_separators and\n                        (selected_txt != \"n\" and selected_txt != \"t\") or\n                        char.isspace()):\n                    break  # end boundary found\n                end_pos = text_cursor.position()\n                text_cursor.setPosition(end_pos)\n        # now that we habe the boundaries, we can select the text\n        text_cursor.setPosition(start_pos)\n        text_cursor.setPosition(end_pos, text_cursor.KeepAnchor)\n        return text_cursor", "response": "Gets the word under cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting the word under the mouse cursor.", "response": "def word_under_mouse_cursor(self):\n        \"\"\"\n        Selects the word under the **mouse** cursor.\n\n        :return: A QTextCursor with the word under mouse cursor selected.\n        \"\"\"\n        editor = self._editor\n        text_cursor = editor.cursorForPosition(editor._last_mouse_pos)\n        text_cursor = self.word_under_cursor(True, text_cursor)\n        return text_cursor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the QTextCursor position.", "response": "def cursor_position(self):\n        \"\"\"\n        Returns the QTextCursor position. The position is a tuple made up of\n        the line number (0 based) and the column number (0 based).\n\n        :return: tuple(line, column)\n        \"\"\"\n        return (self._editor.textCursor().blockNumber(),\n                self._editor.textCursor().columnNumber())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the text of the specified line.", "response": "def line_text(self, line_nbr):\n        \"\"\"\n        Gets the text of the specified line.\n\n        :param line_nbr: The line number of the text to get\n\n        :return: Entire line's text\n        :rtype: str\n        \"\"\"\n        doc = self._editor.document()\n        block = doc.findBlockByNumber(line_nbr)\n        return block.text()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_line_text(self, line_nbr, new_text):\n        editor = self._editor\n        text_cursor = self._move_cursor_to(line_nbr)\n        text_cursor.select(text_cursor.LineUnderCursor)\n        text_cursor.insertText(new_text)\n        editor.setTextCursor(text_cursor)", "response": "Replace an entire line with new_text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_last_line(self):\n        editor = self._editor\n        text_cursor = editor.textCursor()\n        text_cursor.movePosition(text_cursor.End, text_cursor.MoveAnchor)\n        text_cursor.select(text_cursor.LineUnderCursor)\n        text_cursor.removeSelectedText()\n        text_cursor.deletePreviousChar()\n        editor.setTextCursor(text_cursor)", "response": "Removes the last line of the document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving trailing whitespaces and ensure one single blank line at the end of the QTextDocument.", "response": "def clean_document(self):\n        \"\"\"\n        Removes trailing whitespaces and ensure one single blank line at the\n        end of the QTextDocument.\n\n        FIXME: It was deprecated in pyqode, maybe It should be deleted\n        \"\"\"\n        editor = self._editor\n        value = editor.verticalScrollBar().value()\n        pos = self.cursor_position()\n        editor.textCursor().beginEditBlock()\n\n        # cleanup whitespaces\n        editor._cleaning = True\n        eaten = 0\n        removed = set()\n        for line in editor._modified_lines:\n            # parse line before and line after modified line (for cases where\n            # key_delete or key_return has been pressed)\n            for j in range(-1, 2):\n                # skip current line\n                if line + j != pos[0]:\n                    if line + j >= 0:\n                        txt = self.line_text(line + j)\n                        stxt = txt.rstrip()\n                        if txt != stxt:\n                            self.set_line_text(line + j, stxt)\n                        removed.add(line + j)\n        editor._modified_lines -= removed\n\n        # ensure there is only one blank line left at the end of the file\n        i = self.line_count()\n        while i:\n            line = self.line_text(i - 1)\n            if line.strip():\n                break\n            self.remove_last_line()\n            i -= 1\n        if self.line_text(self.line_count() - 1):\n            editor.appendPlainText('')\n\n        # restore cursor and scrollbars\n        text_cursor = editor.textCursor()\n        doc = editor.document()\n        assert isinstance(doc, QTextDocument)\n        text_cursor = self._move_cursor_to(pos[0])\n        text_cursor.movePosition(text_cursor.StartOfLine,\n                                 text_cursor.MoveAnchor)\n        cpos = text_cursor.position()\n        text_cursor.select(text_cursor.LineUnderCursor)\n        if text_cursor.selectedText():\n            text_cursor.setPosition(cpos)\n            offset = pos[1] - eaten\n            text_cursor.movePosition(text_cursor.Right, text_cursor.MoveAnchor,\n                                     offset)\n        else:\n            text_cursor.setPosition(cpos)\n        editor.setTextCursor(text_cursor)\n        editor.verticalScrollBar().setValue(value)\n\n        text_cursor.endEditBlock()\n        editor._cleaning = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting an entire line.", "response": "def select_whole_line(self, line=None, apply_selection=True):\n        \"\"\"\n        Selects an entire line.\n\n        :param line: Line to select. If None, the current line will be selected\n        :param apply_selection: True to apply selection on the text editor\n            widget, False to just return the text cursor without setting it\n            on the editor.\n        :return: QTextCursor\n        \"\"\"\n        if line is None:\n            line = self.current_line_nbr()\n        return self.select_lines(line, line, apply_selection=apply_selection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the selected lines boundaries start line end line", "response": "def selection_range(self):\n        \"\"\"\n        Returns the selected lines boundaries (start line, end line)\n\n        :return: tuple(int, int)\n        \"\"\"\n        editor = self._editor\n        doc = editor.document()\n        start = doc.findBlock(\n            editor.textCursor().selectionStart()).blockNumber()\n        end = doc.findBlock(\n            editor.textCursor().selectionEnd()).blockNumber()\n        text_cursor = QTextCursor(editor.textCursor())\n        text_cursor.setPosition(editor.textCursor().selectionEnd())\n        if text_cursor.columnNumber() == 0 and start != end:\n            end -= 1\n        return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef line_pos_from_number(self, line_number):\n        editor = self._editor\n        block = editor.document().findBlockByNumber(line_number)\n        if block.isValid():\n            return int(editor.blockBoundingGeometry(block).translated(\n                editor.contentOffset()).top())\n        if line_number <= 0:\n            return 0\n        else:\n            return int(editor.blockBoundingGeometry(\n                block.previous()).translated(editor.contentOffset()).bottom())", "response": "Computes the line position on Y - Axis at the center of the line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the line number from the y_pos.", "response": "def line_nbr_from_position(self, y_pos):\n        \"\"\"\n        Returns the line number from the y_pos.\n\n        :param y_pos: Y pos in the editor\n        :return: Line number (0 based), -1 if out of range\n        \"\"\"\n        editor = self._editor\n        height = editor.fontMetrics().height()\n        for top, line, block in editor.visible_blocks:\n            if top <= y_pos <= top + height:\n                return line\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmarks the whole document as dirty.", "response": "def mark_whole_doc_dirty(self):\n        \"\"\"\n        Marks the whole document as dirty to force a full refresh. **SLOW**\n        \"\"\"\n        text_cursor = self._editor.textCursor()\n        text_cursor.select(text_cursor.Document)\n        self._editor.document().markContentsDirty(text_cursor.selectionStart(),\n                                                  text_cursor.selectionEnd())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the character that is on the right of the text cursor.", "response": "def get_right_character(self, cursor=None):\n        \"\"\"\n        Gets the character that is on the right of the text cursor.\n\n        :param cursor: QTextCursor that defines the position where the search\n            will start.\n        \"\"\"\n        next_char = self.get_right_word(cursor=cursor)\n        if len(next_char):\n            next_char = next_char[0]\n        else:\n            next_char = None\n        return next_char"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_text(self, text, keep_position=True):\n        text_cursor = self._editor.textCursor()\n        if keep_position:\n            s = text_cursor.selectionStart()\n            e = text_cursor.selectionEnd()\n        text_cursor.insertText(text)\n        if keep_position:\n            text_cursor.setPosition(s)\n            text_cursor.setPosition(e, text_cursor.KeepAnchor)\n        self._editor.setTextCursor(text_cursor)", "response": "Inserts text at the cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_selection(self):\n        text_cursor = self._editor.textCursor()\n        text_cursor.clearSelection()\n        self._editor.setTextCursor(text_cursor)", "response": "Clears text cursor selection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving the cursor on the right.", "response": "def move_right(self, keep_anchor=False, nb_chars=1):\n        \"\"\"\n        Moves the cursor on the right.\n\n        :param keep_anchor: True to keep anchor (to select text) or False to\n            move the anchor (no selection)\n        :param nb_chars: Number of characters to move.\n        \"\"\"\n        text_cursor = self._editor.textCursor()\n        text_cursor.movePosition(\n            text_cursor.Right, text_cursor.KeepAnchor if keep_anchor else\n            text_cursor.MoveAnchor, nb_chars)\n        self._editor.setTextCursor(text_cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting the extended word under cursor.", "response": "def select_extended_word(self, continuation_chars=('.',)):\n        \"\"\"\n        Performs extended word selection. Extended selection consists in\n        selecting the word under cursor and any other words that are linked\n        by a ``continuation_chars``.\n\n        :param continuation_chars: the list of characters that may extend a\n            word.\n        \"\"\"\n        cursor = self._editor.textCursor()\n        original_pos = cursor.position()\n        start_pos = None\n        end_pos = None\n        # go left\n        stop = False\n        seps = self._editor.word_separators + [' ']\n        while not stop:\n            cursor.clearSelection()\n            cursor.movePosition(cursor.Left, cursor.KeepAnchor)\n            char = cursor.selectedText()\n            if cursor.atBlockStart():\n                stop = True\n                start_pos = cursor.position()\n            elif char in seps and char not in continuation_chars:\n                stop = True\n                start_pos = cursor.position() + 1\n        # go right\n        cursor.setPosition(original_pos)\n        stop = False\n        while not stop:\n            cursor.clearSelection()\n            cursor.movePosition(cursor.Right, cursor.KeepAnchor)\n            char = cursor.selectedText()\n            if cursor.atBlockEnd():\n                stop = True\n                end_pos = cursor.position()\n                if char in seps:\n                    end_pos -= 1\n            elif char in seps and char not in continuation_chars:\n                stop = True\n                end_pos = cursor.position() - 1\n        if start_pos and end_pos:\n            cursor.setPosition(start_pos)\n            cursor.movePosition(cursor.Right, cursor.KeepAnchor,\n                                end_pos - start_pos)\n            self._editor.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state of the user - related entry - set in the block.", "response": "def set_state(block, state):\n        \"\"\"\n        Sets the user state, generally used for syntax highlighting.\n\n        :param block: block to modify\n        :param state: new state value.\n        :return:\n        \"\"\"\n        if block is None:\n            return\n        user_state = block.userState()\n        if user_state == -1:\n            user_state = 0\n        higher_part = user_state & 0x7FFF0000\n        state &= 0x0000FFFF\n        state |= higher_part\n        block.setUserState(state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the fold level of the current entry in the block.", "response": "def set_fold_lvl(block, val):\n        \"\"\"\n        Sets the block fold level.\n\n        :param block: block to modify\n        :param val: The new fold level [0-7]\n        \"\"\"\n        if block is None:\n            return\n        state = block.userState()\n        if state == -1:\n            state = 0\n        if val >= 0x3FF:\n            val = 0x3FF\n        state &= 0x7C00FFFF\n        state |= val << 16\n        block.setUserState(state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_fold_trigger(block):\n        if block is None:\n            return False\n        state = block.userState()\n        if state == -1:\n            state = 0\n        return bool(state & 0x04000000)", "response": "Checks if the block is a fold trigger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_fold_trigger(block, val):\n        if block is None:\n            return\n        state = block.userState()\n        if state == -1:\n            state = 0\n        state &= 0x7BFFFFFF\n        state |= int(val) << 26\n        block.setUserState(state)", "response": "Sets the fold trigger flag in a log entry block."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the block is expanded or collased.", "response": "def is_collapsed(block):\n        \"\"\"\n        Checks if the block is expanded or collased.\n\n        :param block: QTextBlock\n        :return: False for an open trigger, True for for closed trigger\n        \"\"\"\n        if block is None:\n            return False\n        state = block.userState()\n        if state == -1:\n            state = 0\n        return bool(state & 0x08000000)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_collapsed(block, val):\n        if block is None:\n            return\n        state = block.userState()\n        if state == -1:\n            state = 0\n        state &= 0x77FFFFFF\n        state |= int(val) << 27\n        block.setUserState(state)", "response": "Sets the fold trigger state collapsed or expanded."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the first little chunk of a file.", "response": "def get_starting_chunk(filename, length=1024):\n    \"\"\"\n    :param filename: File to open and get the first little chunk of.\n    :param length: Number of bytes to read, default 1024.\n    :returns: Starting chunk of bytes.\n    \"\"\"\n    # Ensure we open the file in binary mode\n    with open(filename, 'rb') as f:\n        chunk = f.read(length)\n        return chunk"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_binary_string(bytes_to_check):\n\n    # Empty files are considered text files\n    if not bytes_to_check:\n        return False\n\n    # Now check for a high percentage of ASCII control characters\n    # Binary if control chars are > 30% of the string\n    low_chars = bytes_to_check.translate(None, _printable_ascii)\n    nontext_ratio1 = float(len(low_chars)) / float(len(bytes_to_check))\n    logger.debug('nontext_ratio1: %(nontext_ratio1)r', locals())\n\n    # and check for a low percentage of high ASCII characters:\n    # Binary if high ASCII chars are < 5% of the string\n    # From: https://en.wikipedia.org/wiki/UTF-8\n    # If the bytes are random, the chances of a byte with the high bit set\n    # starting a valid UTF-8 character is only 6.64%. The chances of finding 7\n    # of these without finding an invalid sequence is actually lower than the\n    # chance of the first three bytes randomly being the UTF-8 BOM.\n\n    high_chars = bytes_to_check.translate(None, _printable_high_ascii)\n    nontext_ratio2 = float(len(high_chars)) / float(len(bytes_to_check))\n    logger.debug('nontext_ratio2: %(nontext_ratio2)r', locals())\n\n    is_likely_binary = (\n        (nontext_ratio1 > 0.3 and nontext_ratio2 < 0.05) or\n        (nontext_ratio1 > 0.8 and nontext_ratio2 > 0.8)\n    )\n    logger.debug('is_likely_binary: %(is_likely_binary)r', locals())\n\n    # then check for binary for possible encoding detection with chardet\n    detected_encoding = chardet.detect(bytes_to_check)\n    logger.debug('detected_encoding: %(detected_encoding)r', locals())\n\n    # finally use all the check to decide binary or text\n    decodable_as_unicode = False\n    if (detected_encoding['confidence'] > 0.9 and\n            detected_encoding['encoding'] != 'ascii'):\n        try:\n            try:\n                bytes_to_check.decode(encoding=detected_encoding['encoding'])\n            except TypeError:\n                # happens only on Python 2.6\n                unicode(bytes_to_check, encoding=detected_encoding['encoding'])  # noqa\n            decodable_as_unicode = True\n            logger.debug('success: decodable_as_unicode: '\n                         '%(decodable_as_unicode)r', locals())\n        except LookupError:\n            logger.debug('failure: could not look up encoding %(encoding)s',\n                         detected_encoding)\n        except UnicodeDecodeError:\n            logger.debug('failure: decodable_as_unicode: '\n                         '%(decodable_as_unicode)r', locals())\n\n    logger.debug('failure: decodable_as_unicode: '\n                 '%(decodable_as_unicode)r', locals())\n    if is_likely_binary:\n        if decodable_as_unicode:\n            return False\n        else:\n            return True\n    else:\n        if decodable_as_unicode:\n            return False\n        else:\n            if b'\\x00' in bytes_to_check or b'\\xff' in bytes_to_check:\n                # Check for NULL bytes last\n                logger.debug('has nulls:' + repr(b'\\x00' in bytes_to_check))\n                return True\n        return False", "response": "Checks if a chunk of bytes is a binary string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_value(self, value):\n        self.value = value\n        if self.isVisible():\n            self.label_value.setText(value)", "response": "Set formatted text value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides Qt method to starts timers if widget is not visible.", "response": "def setVisible(self, value):\n        \"\"\"Override Qt method to stops timers if widget is not visible.\"\"\"\n        if self.timer is not None:\n            if value:\n                self.timer.start(self._interval)\n            else:\n                self.timer.stop()\n        super(BaseTimerStatus, self).setVisible(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets timer interval ( ms ).", "response": "def set_interval(self, interval):\n        \"\"\"Set timer interval (ms).\"\"\"\n        self._interval = interval\n        if self.timer is not None:\n            self.timer.setInterval(interval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef warning(message, css_path=CSS_PATH):\n    env = Environment()\n    env.loader = FileSystemLoader(osp.join(CONFDIR_PATH, 'templates'))\n    warning = env.get_template(\"warning.html\")\n    return warning.render(css_path=css_path, text=message)", "response": "Print a warning message on the rich text view"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef usage(title, message, tutorial_message, tutorial, css_path=CSS_PATH):\n    env = Environment()\n    env.loader = FileSystemLoader(osp.join(CONFDIR_PATH, 'templates'))\n    usage = env.get_template(\"usage.html\")\n    return usage.render(css_path=css_path, title=title, intro_message=message,\n                        tutorial_message=tutorial_message, tutorial=tutorial)", "response": "Print a usage message on the rich text view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_context(name='', argspec='', note='', math=False, collapse=False,\n                     img_path='', css_path=CSS_PATH):\n    \"\"\"\n    Generate the html_context dictionary for our Sphinx conf file.\n    \n    This is a set of variables to be passed to the Jinja template engine and\n    that are used to control how the webpage is rendered in connection with\n    Sphinx\n\n    Parameters\n    ----------\n    name : str\n        Object's name.\n    note : str\n        A note describing what type has the function or method being\n        introspected\n    argspec : str\n        Argspec of the the function or method being introspected\n    math : bool\n        Turn on/off Latex rendering on the OI. If False, Latex will be shown in\n        plain text.\n    collapse : bool\n        Collapse sections\n    img_path : str\n        Path for images relative to the file containing the docstring\n\n    Returns\n    -------\n    A dict of strings to be used by Jinja to generate the webpage\n    \"\"\"\n\n    if img_path and os.name == 'nt':\n        img_path = img_path.replace('\\\\', '/')\n\n    context = \\\n    {\n      # Arg dependent variables\n      'math_on': 'true' if math else '',\n      'name': name,\n      'argspec': argspec,\n      'note': note,\n      'collapse': collapse,\n      'img_path': img_path,\n      # Static variables\n      'css_path': css_path,\n      'js_path': JS_PATH,\n      'jquery_path': JQUERY_PATH,\n      'mathjax_path': MATHJAX_PATH,\n      'right_sphinx_version': '' if sphinx.__version__ < \"1.1\" else 'true',\n      'platform': sys.platform\n    }\n    \n    return context", "response": "Generate the html_context dictionary for our Sphinx conf file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sphinxify(docstring, context, buildername='html'):\n\n    srcdir = mkdtemp()\n    srcdir = encoding.to_unicode_from_fs(srcdir)\n    destdir = osp.join(srcdir, '_build')\n\n    rst_name = osp.join(srcdir, 'docstring.rst')\n    if buildername == 'html':\n        suffix = '.html'\n    else:\n        suffix = '.txt'\n    output_name = osp.join(destdir, 'docstring' + suffix)\n\n    # This is needed so users can type \\\\ on latex eqnarray envs inside raw\n    # docstrings\n    if context['right_sphinx_version'] and context['math_on']:\n        docstring = docstring.replace('\\\\\\\\', '\\\\\\\\\\\\\\\\')\n    \n    # Add a class to several characters on the argspec. This way we can\n    # highlight them using css, in a similar way to what IPython does.\n    # NOTE: Before doing this, we escape common html chars so that they\n    # don't interfere with the rest of html present in the page\n    argspec = escape(context['argspec'])\n    for char in ['=', ',', '(', ')', '*', '**']:\n        argspec = argspec.replace(char,\n                         '<span class=\"argspec-highlight\">' + char + '</span>')\n    context['argspec'] = argspec\n\n    doc_file = codecs.open(rst_name, 'w', encoding='utf-8')\n    doc_file.write(docstring)\n    doc_file.close()\n    \n    temp_confdir = False\n    if temp_confdir:\n        # TODO: This may be inefficient. Find a faster way to do it.\n        confdir = mkdtemp()\n        confdir = encoding.to_unicode_from_fs(confdir)\n        generate_configuration(confdir)\n    else:\n        confdir = osp.join(get_module_source_path('spyder.plugins.help.utils'))\n\n    confoverrides = {'html_context': context}\n\n    doctreedir = osp.join(srcdir, 'doctrees')\n\n    sphinx_app = Sphinx(srcdir, confdir, destdir, doctreedir, buildername,\n                        confoverrides, status=None, warning=None,\n                        freshenv=True, warningiserror=False, tags=None)\n    try:\n        sphinx_app.build(None, [rst_name])\n    except SystemMessage:\n        output = _(\"It was not possible to generate rich text help for this \"\n                    \"object.</br>\"\n                    \"Please see it in plain text.\")\n        return warning(output)\n\n    # TODO: Investigate if this is necessary/important for us\n    if osp.exists(output_name):\n        output = codecs.open(output_name, 'r', encoding='utf-8').read()\n        output = output.replace('<pre>', '<pre class=\"literal-block\">')\n    else:\n        output = _(\"It was not possible to generate rich text help for this \"\n                    \"object.</br>\"\n                    \"Please see it in plain text.\")\n        return warning(output)\n\n    if temp_confdir:\n        shutil.rmtree(confdir, ignore_errors=True)\n    shutil.rmtree(srcdir, ignore_errors=True)\n\n    return output", "response": "Runs Sphinx on a docstring and outputs the processed documentation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_configuration(directory):\n    \n    # conf.py file for Sphinx\n    conf = osp.join(get_module_source_path('spyder.plugins.help.utils'),\n                    'conf.py')\n\n    # Docstring layout page (in Jinja):\n    layout = osp.join(osp.join(CONFDIR_PATH, 'templates'), 'layout.html')\n    \n    os.makedirs(osp.join(directory, 'templates'))\n    os.makedirs(osp.join(directory, 'static'))\n    shutil.copy(conf, directory)\n    shutil.copy(layout, osp.join(directory, 'templates'))\n    open(osp.join(directory, '__init__.py'), 'w').write('')\n    open(osp.join(directory, 'static', 'empty'), 'w').write('')", "response": "Generates a Sphinx configuration in directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the end of line status.", "response": "def update_eol(self, os_name):\n        \"\"\"Update end of line status.\"\"\"\n        os_name = to_text_string(os_name)\n        value = {\"nt\": \"CRLF\", \"posix\": \"LF\"}.get(os_name, \"CR\")\n        self.set_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating encoding of current file.", "response": "def update_encoding(self, encoding):\n        \"\"\"Update encoding of current file.\"\"\"\n        value = str(encoding).upper()\n        self.set_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve all Variable Explorer configuration settings. Specifically return the settings in CONF_SECTION with keys in AttributeNames REMOTE_SETTINGS and the setting dataframe_format.", "response": "def get_settings(self):\r\n        \"\"\"\r\n        Retrieve all Variable Explorer configuration settings.\r\n        \r\n        Specifically, return the settings in CONF_SECTION with keys in \r\n        REMOTE_SETTINGS, and the setting 'dataframe_format'.\r\n        \r\n        Returns:\r\n            dict: settings\r\n        \"\"\"\r\n        settings = {}\r\n        for name in REMOTE_SETTINGS:\r\n            settings[name] = self.get_option(name)\r\n\r\n        # dataframe_format is stored without percent sign in config\r\n        # to avoid interference with ConfigParser's interpolation\r\n        name = 'dataframe_format'\r\n        settings[name] = '%{0}'.format(self.get_option(name))\r\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_option(self, option_name, new_value):\r\n        if option_name == 'dataframe_format':\r\n            assert new_value.startswith('%')\r\n            new_value = new_value[1:]\r\n        self.sig_option_changed.emit(option_name, new_value)", "response": "Change a config option."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_shellwidget(self, shellwidget):\r\n        shellwidget_id = id(shellwidget)\r\n        if shellwidget_id not in self.shellwidgets:\r\n            self.options_button.setVisible(True)\r\n            nsb = NamespaceBrowser(self, options_button=self.options_button)\r\n            nsb.set_shellwidget(shellwidget)\r\n            nsb.setup(**self.get_settings())\r\n            nsb.sig_option_changed.connect(self.change_option)\r\n            nsb.sig_free_memory.connect(self.free_memory)\r\n            self.add_widget(nsb)\r\n            self.shellwidgets[shellwidget_id] = nsb\r\n            self.set_shellwidget_from_id(shellwidget_id)\r\n            return nsb", "response": "Add a new shell with variable explorer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_data(self, fname):\r\n        if self.count():\r\n            nsb = self.current_widget()\r\n            nsb.refresh_table()\r\n            nsb.import_data(filenames=fname)\r\n            if self.dockwidget and not self.ismaximized:\r\n                self.dockwidget.setVisible(True)\r\n                self.dockwidget.raise_()", "response": "Import data in current namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_valid(self, qstr=None):\n        if not self.help.source_is_console():\n            return True\n        if qstr is None:\n            qstr = self.currentText()\n        if not re.search(r'^[a-zA-Z0-9_\\.]*$', str(qstr), 0):\n            return False\n        objtxt = to_text_string(qstr)\n        shell_is_defined = False\n        if self.help.get_option('automatic_import'):\n            shell = self.help.internal_shell\n            if shell is not None:\n                shell_is_defined = shell.is_defined(objtxt, force_import=True)\n        if not shell_is_defined:\n            shell = self.help.get_shell()\n            if shell is not None:\n                try:\n                    shell_is_defined = shell.is_defined(objtxt)\n                except socket.error:\n                    shell = self.help.get_shell()\n                    try:\n                        shell_is_defined = shell.is_defined(objtxt)\n                    except socket.error:\n                        # Well... too bad!\n                        pass\n        return shell_is_defined", "response": "Return True if string is valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, qstr, editing=True):\n        valid = self.is_valid(qstr)\n        if self.hasFocus() and valid is not None:\n            if editing and not valid:\n                # Combo box text is being modified: invalidate the entry\n                self.show_tip(self.tips[valid])\n                self.valid.emit(False, False)\n            else:\n                # A new item has just been selected\n                if valid:\n                    self.selected()\n                else:\n                    self.valid.emit(False, False)", "response": "Reimplemented to avoid formatting actions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset font for this object", "response": "def set_font(self, font, fixed_font=None):\n        \"\"\"Set font\"\"\"\n        self.webview.set_font(font, fixed_font=fixed_font)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_font(self, font, color_scheme=None):\n        self.editor.set_font(font, color_scheme=color_scheme)", "response": "Set font in the editor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_tasks(source_code):\r\n    results = []\r\n    for line, text in enumerate(source_code.splitlines()):\r\n        for todo in re.findall(TASKS_PATTERN, text):\r\n            todo_text = (todo[-1].strip(' :').capitalize() if todo[-1]\r\n                         else todo[-2])\r\n            results.append((todo_text, line + 1))\r\n    return results", "response": "Find tasks in source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks source code with pyflakes. Returns an empty list if pyflakes is not installed.", "response": "def check_with_pyflakes(source_code, filename=None):\r\n    \"\"\"Check source code with pyflakes\r\n    Returns an empty list if pyflakes is not installed\"\"\"\r\n    try:\r\n        if filename is None:\r\n            filename = '<string>'\r\n        try:\r\n            source_code += '\\n'\r\n        except TypeError:\r\n            # Python 3\r\n            source_code += to_binary_string('\\n')\r\n            \r\n        import _ast\r\n        from pyflakes.checker import Checker\r\n        # First, compile into an AST and handle syntax errors.\r\n        try:\r\n            tree = compile(source_code, filename, \"exec\", _ast.PyCF_ONLY_AST)\r\n        except SyntaxError as value:\r\n            # If there's an encoding problem with the file, the text is None.\r\n            if value.text is None:\r\n                results = []\r\n            else:\r\n                results = [(value.args[0], value.lineno)]\r\n        except (ValueError, TypeError):\r\n            # Example of ValueError: file contains invalid \\x escape character\r\n            # (see https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=674797)\r\n            # Example of TypeError: file contains null character\r\n            # (see https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=674796)\r\n            results = []\r\n        else:\r\n            # Okay, it's syntactically valid.  Now check it.\r\n            w = Checker(tree, filename)\r\n            w.messages.sort(key=lambda x: x.lineno)\r\n            results = []\r\n            coding = encoding.get_coding(source_code)\r\n            lines = source_code.splitlines()\r\n            for warning in w.messages:\r\n                if 'analysis:ignore' not in \\\r\n                   to_text_string(lines[warning.lineno-1], coding):\r\n                    results.append((warning.message % warning.message_args,\r\n                                    warning.lineno))\r\n    except Exception:\r\n        # Never return None to avoid lock in spyder/widgets/editor.py\r\n        # See Issue 1547\r\n        results = []\r\n        if DEBUG_EDITOR:\r\n            traceback.print_exc()  # Print exception in internal console\r\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns checker executable in the form of a list of arguments Taxonomy for subprocess. Popen", "response": "def get_checker_executable(name):\r\n    \"\"\"Return checker executable in the form of a list of arguments\r\n    for subprocess.Popen\"\"\"\r\n    if programs.is_program_installed(name):\r\n        # Checker is properly installed\r\n        return [name]\r\n    else:\r\n        path1 = programs.python_script_exists(package=None,\r\n                                              module=name+'_script')\r\n        path2 = programs.python_script_exists(package=None, module=name)\r\n        if path1 is not None:  # checker_script.py is available\r\n            # Checker script is available but has not been installed\r\n            # (this may work with pyflakes)\r\n            return [sys.executable, path1]\r\n        elif path2 is not None:  # checker.py is available\r\n            # Checker package is available but its script has not been\r\n            # installed (this works with pycodestyle but not with pyflakes)\r\n            return [sys.executable, path2]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck source code with checker defined with args * Returns an empty list if checker is not installed", "response": "def check(args, source_code, filename=None, options=None):\r\n    \"\"\"Check source code with checker defined with *args* (list)\r\n    Returns an empty list if checker is not installed\"\"\"\r\n    if args is None:\r\n        return []\r\n    if options is not None:\r\n        args += options\r\n    if any(['pyflakes' in arg for arg in args]):\r\n        #  Pyflakes requires an ending new line (pycodestyle don't! -- see Issue 1123)\r\n        #  Note: this code is not used right now as it is faster to invoke \r\n        #  pyflakes in current Python interpreter (see `check_with_pyflakes` \r\n        #  function above) than calling it through a subprocess\r\n        source_code += '\\n'\r\n    if filename is None:\r\n        # Creating a temporary file because file does not exist yet \r\n        # or is not up-to-date\r\n        tempfd = tempfile.NamedTemporaryFile(suffix=\".py\", delete=False)\r\n        tempfd.write(source_code)\r\n        tempfd.close()\r\n        args.append(tempfd.name)\r\n    else:\r\n        args.append(filename)\r\n    cmd = args[0]\r\n    cmdargs = args[1:]\r\n    proc = programs.run_program(cmd, cmdargs)\r\n    output = proc.communicate()[0].strip().decode().splitlines()\r\n    if filename is None:\r\n        os.unlink(tempfd.name)\r\n    results = []\r\n    coding = encoding.get_coding(source_code)\r\n    lines = source_code.splitlines()\r\n    for line in output:\r\n        lineno = int(re.search(r'(\\:[\\d]+\\:)', line).group()[1:-1])\r\n        try:\r\n            text = to_text_string(lines[lineno-1], coding)\r\n        except TypeError:\r\n            text = to_text_string(lines[lineno-1])\r\n        except UnicodeDecodeError:\r\n            # Needed to handle UnicodeDecodeError and force the use\r\n            # of chardet to detect enconding. See issue 6970\r\n            coding = encoding.get_coding(source_code, force_chardet=True)\r\n            text = to_text_string(lines[lineno-1], coding)\r\n        if 'analysis:ignore' not in text:\r\n            message = line[line.find(': ')+2:]\r\n            results.append((message, lineno))\r\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck source code with pycodestyle", "response": "def check_with_pep8(source_code, filename=None):\r\n    \"\"\"Check source code with pycodestyle\"\"\"\r\n    try:\r\n        args = get_checker_executable('pycodestyle')\r\n        results = check(args, source_code, filename=filename, options=['-r'])\r\n    except Exception:\r\n        # Never return None to avoid lock in spyder/widgets/editor.py\r\n        # See Issue 1547\r\n        results = []\r\n        if DEBUG_EDITOR:\r\n            traceback.print_exc()  # Print exception in internal console\r\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_image_label(name, default=\"not_found.png\"):\r\n    label = QLabel()\r\n    label.setPixmap(QPixmap(get_image_path(name, default)))\r\n    return label", "response": "Return image inside a QLabel object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef qapplication(translate=True, test_time=3):\r\n    if running_in_mac_app():\r\n        SpyderApplication = MacApplication\r\n    else:\r\n        SpyderApplication = QApplication\r\n    \r\n    app = SpyderApplication.instance()\r\n    if app is None:\r\n        # Set Application name for Gnome 3\r\n        # https://groups.google.com/forum/#!topic/pyside/24qxvwfrRDs\r\n        app = SpyderApplication(['Spyder'])\r\n\r\n        # Set application name for KDE (See issue 2207)\r\n        app.setApplicationName('Spyder')\r\n    if translate:\r\n        install_translator(app)\r\n\r\n    test_ci = os.environ.get('TEST_CI_WIDGETS', None)\r\n    if test_ci is not None:\r\n        timer_shutdown = QTimer(app)\r\n        timer_shutdown.timeout.connect(app.quit)\r\n        timer_shutdown.start(test_time*1000)\r\n    return app", "response": "Returns a new QApplication instance if it doesn t already exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_uri(fname):\r\n    if os.name == 'nt':\r\n        # Local file\r\n        if re.search(r'^[a-zA-Z]:', fname):\r\n            return 'file:///' + fname\r\n        # UNC based path\r\n        else:\r\n            return 'file://' + fname\r\n    else:\r\n        return 'file://' + fname", "response": "Select the right file uri scheme according to the operating system"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_translator(qapp):\r\n    global QT_TRANSLATOR\r\n    if QT_TRANSLATOR is None:\r\n        qt_translator = QTranslator()\r\n        if qt_translator.load(\"qt_\"+QLocale.system().name(),\r\n                      QLibraryInfo.location(QLibraryInfo.TranslationsPath)):\r\n            QT_TRANSLATOR = qt_translator # Keep reference alive\r\n    if QT_TRANSLATOR is not None:\r\n        qapp.installTranslator(QT_TRANSLATOR)", "response": "Install Qt translator to the QApplication instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keybinding(attr):\r\n    ks = getattr(QKeySequence, attr)\r\n    return from_qvariant(QKeySequence.keyBindings(ks)[0], str)", "response": "Return the first keybinding of the given attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mimedata2url(source, extlist=None):\r\n    pathlist = []\r\n    if source.hasUrls():\r\n        for url in source.urls():\r\n            path = _process_mime_path(to_text_string(url.toString()), extlist)\r\n            if path is not None:\r\n                pathlist.append(path)\r\n    elif source.hasText():\r\n        for rawpath in to_text_string(source.text()).splitlines():\r\n            path = _process_mime_path(rawpath, extlist)\r\n            if path is not None:\r\n                pathlist.append(path)\r\n    if pathlist:\r\n        return pathlist", "response": "Extract url list from MIME data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a QKeyEvent instance into a tuple", "response": "def keyevent2tuple(event):\r\n    \"\"\"Convert QKeyEvent instance into a tuple\"\"\"\r\n    return (event.type(), event.key(), event.modifiers(), event.text(),\r\n            event.isAutoRepeat(), event.count())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_toolbutton(parent, text=None, shortcut=None, icon=None, tip=None,\r\n                      toggled=None, triggered=None,\r\n                      autoraise=True, text_beside_icon=False):\r\n    \"\"\"Create a QToolButton\"\"\"\r\n    button = QToolButton(parent)\r\n    if text is not None:\r\n        button.setText(text)\r\n    if icon is not None:\r\n        if is_text_string(icon):\r\n            icon = get_icon(icon)\r\n        button.setIcon(icon)\r\n    if text is not None or tip is not None:\r\n        button.setToolTip(text if tip is None else tip)\r\n    if text_beside_icon:\r\n        button.setToolButtonStyle(Qt.ToolButtonTextBesideIcon)\r\n    button.setAutoRaise(autoraise)\r\n    if triggered is not None:\r\n        button.clicked.connect(triggered)\r\n    if toggled is not None:\r\n        button.toggled.connect(toggled)\r\n        button.setCheckable(True)\r\n    if shortcut is not None:\r\n        button.setShortcut(shortcut)\r\n    return button", "response": "Create a new QToolButton with the given text icon and tip."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef action2button(action, autoraise=True, text_beside_icon=False, parent=None):\r\n    if parent is None:\r\n        parent = action.parent()\r\n    button = QToolButton(parent)\r\n    button.setDefaultAction(action)\r\n    button.setAutoRaise(autoraise)\r\n    if text_beside_icon:\r\n        button.setToolButtonStyle(Qt.ToolButtonTextBesideIcon)\r\n    return button", "response": "Create a QToolButton directly from a QAction object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling or disable actions", "response": "def toggle_actions(actions, enable):\r\n    \"\"\"Enable/disable actions\"\"\"\r\n    if actions is not None:\r\n        for action in actions:\r\n            if action is not None:\r\n                action.setEnabled(enable)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_action(parent, text, shortcut=None, icon=None, tip=None,\r\n                  toggled=None, triggered=None, data=None, menurole=None,\r\n                  context=Qt.WindowShortcut):\r\n    \"\"\"Create a QAction\"\"\"\r\n    action = SpyderAction(text, parent)\r\n    if triggered is not None:\r\n        action.triggered.connect(triggered)\r\n    if toggled is not None:\r\n        action.toggled.connect(toggled)\r\n        action.setCheckable(True)\r\n    if icon is not None:\r\n        if is_text_string(icon):\r\n            icon = get_icon(icon)\r\n        action.setIcon(icon)\r\n    if tip is not None:\r\n        action.setToolTip(tip)\r\n        action.setStatusTip(tip)\r\n    if data is not None:\r\n        action.setData(to_qvariant(data))\r\n    if menurole is not None:\r\n        action.setMenuRole(menurole)\r\n\r\n    # Workround for Mac because setting context=Qt.WidgetShortcut\r\n    # there doesn't have any effect\r\n    if sys.platform == 'darwin':\r\n        action._shown_shortcut = None\r\n        if context == Qt.WidgetShortcut:\r\n            if shortcut is not None:\r\n                action._shown_shortcut = shortcut\r\n            else:\r\n                # This is going to be filled by\r\n                # main.register_shortcut\r\n                action._shown_shortcut = 'missing'\r\n        else:\r\n            if shortcut is not None:\r\n                action.setShortcut(shortcut)\r\n            action.setShortcutContext(context)\r\n    else:\r\n        if shortcut is not None:\r\n            action.setShortcut(shortcut)\r\n        action.setShortcutContext(context)\r\n\r\n    return action", "response": "Create a QAction object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the shortcut associated with a given action to its tooltip", "response": "def add_shortcut_to_tooltip(action, context, name):\r\n    \"\"\"Add the shortcut associated with a given action to its tooltip\"\"\"\r\n    action.setToolTip(action.toolTip() + ' (%s)' %\r\n                      get_shortcut(context=context, name=name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds actions to a QMenu or QToolBar.", "response": "def add_actions(target, actions, insert_before=None):\r\n    \"\"\"Add actions to a QMenu or a QToolBar.\"\"\"\r\n    previous_action = None\r\n    target_actions = list(target.actions())\r\n    if target_actions:\r\n        previous_action = target_actions[-1]\r\n        if previous_action.isSeparator():\r\n            previous_action = None\r\n    for action in actions:\r\n        if (action is None) and (previous_action is not None):\r\n            if insert_before is None:\r\n                target.addSeparator()\r\n            else:\r\n                target.insertSeparator(insert_before)\r\n        elif isinstance(action, QMenu):\r\n            if insert_before is None:\r\n                target.addMenu(action)\r\n            else:\r\n                target.insertMenu(insert_before, action)\r\n        elif isinstance(action, QAction):\r\n            if isinstance(action, SpyderAction):\r\n                if isinstance(target, QMenu) or not isinstance(target, QToolBar):\r\n                    try:\r\n                        action = action.no_icon_action\r\n                    except RuntimeError:\r\n                        continue\r\n            if insert_before is None:\r\n                # This is needed in order to ignore adding an action whose\r\n                # wrapped C/C++ object has been deleted. See issue 5074\r\n                try:\r\n                    target.addAction(action)\r\n                except RuntimeError:\r\n                    continue\r\n            else:\r\n                target.insertAction(insert_before, action)\r\n        previous_action = action"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates bookmark actions depending on module installation", "response": "def create_module_bookmark_actions(parent, bookmarks):\r\n    \"\"\"\r\n    Create bookmark actions depending on module installation:\r\n    bookmarks = ((module_name, url, title), ...)\r\n    \"\"\"\r\n    actions = []\r\n    for key, url, title in bookmarks:\r\n        # Create actions for scientific distros only if Spyder is installed\r\n        # under them\r\n        create_act = True\r\n        if key == 'winpython':\r\n            if not programs.is_module_installed(key):\r\n                create_act = False\r\n        if create_act:\r\n            act = create_bookmark_action(parent, url, title)\r\n            actions.append(act)\r\n    return actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates action to run a program", "response": "def create_program_action(parent, text, name, icon=None, nt_name=None):\r\n    \"\"\"Create action to run a program\"\"\"\r\n    if is_text_string(icon):\r\n        icon = get_icon(icon)\r\n    if os.name == 'nt' and nt_name is not None:\r\n        name = nt_name\r\n    path = programs.find_program(name)\r\n    if path is not None:\r\n        return create_action(parent, text, icon=icon,\r\n                             triggered=lambda: programs.run_program(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates action to run a GUI based Python script", "response": "def create_python_script_action(parent, text, icon, package, module, args=[]):\r\n    \"\"\"Create action to run a GUI based Python script\"\"\"\r\n    if is_text_string(icon):\r\n        icon = get_icon(icon)\r\n    if programs.python_script_exists(package, module):\r\n        return create_action(parent, text, icon=icon,\r\n                             triggered=lambda:\r\n                             programs.run_python_script(package, module, args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn file type icon", "response": "def get_filetype_icon(fname):\r\n    \"\"\"Return file type icon\"\"\"\r\n    ext = osp.splitext(fname)[1]\r\n    if ext.startswith('.'):\r\n        ext = ext[1:]\r\n    return get_icon( \"%s.png\" % ext, ima.icon('FileIcon') )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_std_icons():\r\n    app = qapplication()\r\n    dialog = ShowStdIcons(None)\r\n    dialog.show()\r\n    sys.exit(app.exec_())", "response": "Show all standard Icons\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the spacing of the tools_layout.", "response": "def calc_tools_spacing(tools_layout):\r\n    \"\"\"\r\n    Return a spacing (int) or None if we don't have the appropriate metrics\r\n    to calculate the spacing.\r\n\r\n    We're trying to adapt the spacing below the tools_layout spacing so that\r\n    the main_widget has the same vertical position as the editor widgets\r\n    (which have tabs above).\r\n\r\n    The required spacing is\r\n\r\n        spacing = tabbar_height - tools_height + offset\r\n\r\n    where the tabbar_heights were empirically determined for a combination of\r\n    operating systems and styles. Offsets were manually adjusted, so that the\r\n    heights of main_widgets and editor widgets match. This is probably\r\n    caused by a still not understood element of the layout and style metrics.\r\n    \"\"\"\r\n    metrics = {  # (tabbar_height, offset)\r\n        'nt.fusion': (32, 0),\r\n        'nt.windowsvista': (21, 3),\r\n        'nt.windowsxp': (24, 0),\r\n        'nt.windows': (21, 3),\r\n        'posix.breeze': (28, -1),\r\n        'posix.oxygen': (38, -2),\r\n        'posix.qtcurve': (27, 0),\r\n        'posix.windows': (26, 0),\r\n        'posix.fusion': (32, 0),\r\n    }\r\n\r\n    style_name = qapplication().style().property('name')\r\n    key = '%s.%s' % (os.name, style_name)\r\n\r\n    if key in metrics:\r\n        tabbar_height, offset = metrics[key]\r\n        tools_height = tools_layout.sizeHint().height()\r\n        spacing = tabbar_height - tools_height + offset\r\n        return max(spacing, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a layout for a set of controls above a main widget.", "response": "def create_plugin_layout(tools_layout, main_widget=None):\r\n    \"\"\"\r\n    Returns a layout for a set of controls above a main widget. This is a\r\n    standard layout for many plugin panes (even though, it's currently\r\n    more often applied not to the pane itself but with in the one widget\r\n    contained in the pane.\r\n\r\n    tools_layout: a layout containing the top toolbar\r\n    main_widget: the main widget. Can be None, if you want to add this\r\n        manually later on.\r\n    \"\"\"\r\n    layout = QVBoxLayout()\r\n    layout.setContentsMargins(0, 0, 0, 0)\r\n    spacing = calc_tools_spacing(tools_layout)\r\n    if spacing is not None:\r\n        layout.setSpacing(spacing)\r\n\r\n    layout.addLayout(tools_layout)\r\n    if main_widget is not None:\r\n        layout.addWidget(main_widget)\r\n    return layout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(modname, features, required_version, installed_version=None,\r\n        optional=False):\r\n    \"\"\"Add Spyder dependency\"\"\"\r\n    global DEPENDENCIES\r\n    for dependency in DEPENDENCIES:\r\n        if dependency.modname == modname:\r\n            raise ValueError(\"Dependency has already been registered: %s\"\\\r\n                             % modname)\r\n    DEPENDENCIES += [Dependency(modname, features, required_version,\r\n                                installed_version, optional)]", "response": "Add a Spyder dependency to the list of dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(modname):\r\n    for dependency in DEPENDENCIES:\r\n        if dependency.modname == modname:\r\n            return dependency.check()\r\n    else:\r\n        raise RuntimeError(\"Unkwown dependency %s\" % modname)", "response": "Check if required dependency is installed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(deps=DEPENDENCIES, linesep=os.linesep):\r\n    maxwidth = 0\r\n    col1 = []\r\n    col2 = []\r\n    for dependency in deps:\r\n        title1 = dependency.modname\r\n        title1 += ' ' + dependency.required_version\r\n        col1.append(title1)\r\n        maxwidth = max([maxwidth, len(title1)])\r\n        col2.append(dependency.get_installed_version())\r\n    text = \"\"\r\n    for index in range(len(deps)):\r\n        text += col1[index].ljust(maxwidth) + ':  ' + col2[index] + linesep\r\n    return text[:-1]", "response": "Return a status of the dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the status of missing dependencies.", "response": "def missing_dependencies():\r\n    \"\"\"Return the status of missing dependencies (if any)\"\"\"\r\n    missing_deps = []\r\n    for dependency in DEPENDENCIES:\r\n        if not dependency.check() and not dependency.optional:\r\n            missing_deps.append(dependency)\r\n    if missing_deps:\r\n        return status(deps=missing_deps, linesep='<br>')\r\n    else:\r\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self):\r\n        return programs.is_module_installed(self.modname,\r\n                                            self.required_version,\r\n                                            self.installed_version)", "response": "Check if dependency is installed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_installed_version(self):\r\n        if self.check():\r\n            return '%s (%s)' % (self.installed_version, self.OK)\r\n        else:\r\n            return '%s (%s)' % (self.installed_version, self.NOK)", "response": "Return the installed version of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_spyderplugins_mods(io=False):\r\n    # Create user directory\r\n    user_plugin_path = osp.join(get_conf_path(), USER_PLUGIN_DIR)\r\n    if not osp.isdir(user_plugin_path):\r\n        os.makedirs(user_plugin_path)\r\n\r\n    modlist, modnames = [], []\r\n\r\n    # The user plugins directory is given the priority when looking for modules\r\n    for plugin_path in [user_plugin_path] + sys.path:\r\n        _get_spyderplugins(plugin_path, io, modnames, modlist)\r\n    return modlist", "response": "Import modules from plugins package and return the list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan the directory plugin_path for plugin packages and loads them.", "response": "def _get_spyderplugins(plugin_path, is_io, modnames, modlist):\r\n    \"\"\"Scan the directory `plugin_path` for plugin packages and loads them.\"\"\"\r\n    if not osp.isdir(plugin_path):\r\n        return\r\n\r\n    for name in os.listdir(plugin_path):\r\n        # This is needed in order to register the spyder_io_hdf5 plugin.\r\n        # See issue 4487\r\n        # Is this a Spyder plugin?\r\n        if not name.startswith(PLUGIN_PREFIX):\r\n            continue\r\n\r\n        # Ensure right type of plugin\r\n        if is_io != name.startswith(IO_PREFIX):\r\n            continue\r\n\r\n        # Skip names that end in certain suffixes\r\n        forbidden_suffixes = ['dist-info', 'egg.info', 'egg-info', 'egg-link',\r\n                              'kernels']\r\n        if any([name.endswith(s) for s in forbidden_suffixes]):\r\n            continue\r\n\r\n        # Import the plugin\r\n        _import_plugin(name, plugin_path, modnames, modlist)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _import_plugin(module_name, plugin_path, modnames, modlist):\r\n    if module_name in modnames:\r\n        return\r\n    try:\r\n        # First add a mock module with the LOCALEPATH attribute so that the\r\n        # helper method can find the locale on import\r\n        mock = _ModuleMock()\r\n        mock.LOCALEPATH = osp.join(plugin_path, module_name, 'locale')\r\n        sys.modules[module_name] = mock\r\n\r\n        if osp.isdir(osp.join(plugin_path, module_name)):\r\n            module = _import_module_from_path(module_name, plugin_path)\r\n        else:\r\n            module = None\r\n\r\n        # Then restore the actual loaded module instead of the mock\r\n        if module and getattr(module, 'PLUGIN_CLASS', False):\r\n            sys.modules[module_name] = module\r\n            modlist.append(module)\r\n            modnames.append(module_name)\r\n    except Exception:\r\n        sys.stderr.write(\"ERROR: 3rd party plugin import failed for \"\r\n                         \"`{0}`\\n\".format(module_name))\r\n        traceback.print_exc(file=sys.stderr)", "response": "Import the plugin module_name from plugin_path add it to modlist and adds its name to modnames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport module_name from plugin_path. Returns None if no module is found.", "response": "def _import_module_from_path(module_name, plugin_path):\r\n    \"\"\"Imports `module_name` from `plugin_path`.\r\n\r\n    Return None if no module is found.\r\n    \"\"\"\r\n    module = None\r\n    try:\r\n        if PY2:\r\n            info = imp.find_module(module_name, [plugin_path])\r\n            if info:\r\n                module = imp.load_module(module_name, *info)\r\n        else:  # Python 3.4+\r\n            spec = importlib.machinery.PathFinder.find_spec(\r\n                module_name,\r\n                [plugin_path])\r\n            if spec:\r\n                module = spec.loader.load_module(module_name)\r\n    except Exception:\r\n        pass\r\n\r\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget standard platform icon", "response": "def get_std_icon(name, size=None):\n    \"\"\"Get standard platform icon\n    Call 'show_std_icons()' for details\"\"\"\n    if not name.startswith('SP_'):\n        name = 'SP_' + name\n    icon = QWidget().style().standardIcon(getattr(QStyle, name))\n    if size is None:\n        return icon\n    else:\n        return QIcon(icon.pixmap(size, size))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_icon(name, default=None, resample=False):\n\n    icon_path = get_image_path(name, default=None)\n    if icon_path is not None:\n        icon = QIcon(icon_path)\n    elif isinstance(default, QIcon):\n        icon = default\n    elif default is None:\n        try:\n            icon = get_std_icon(name[:-4])\n        except AttributeError:\n            icon = QIcon(get_image_path(name, default))\n    else:\n        icon = QIcon(get_image_path(name, default))\n    if resample:\n        icon0 = QIcon()\n        for size in (16, 24, 32, 48, 96, 128, 256, 512):\n            icon0.addPixmap(icon.pixmap(size, size))\n        return icon0\n    else:\n        return icon", "response": "Return image inside a QIcon object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_icon_by_extension(fname, scale_factor):\n    application_icons = {}\n    application_icons.update(BIN_FILES)\n    application_icons.update(DOCUMENT_FILES)\n    if osp.isdir(fname):\n        return icon('DirOpenIcon', scale_factor)\n    else:\n        basename = osp.basename(fname)\n        __, extension = osp.splitext(basename.lower())\n        mime_type, __ = mime.guess_type(basename)\n        icon_by_extension = icon('FileIcon', scale_factor)\n\n        if extension in OFFICE_FILES:\n            icon_by_extension = icon(OFFICE_FILES[extension], scale_factor)\n\n        if extension in LANGUAGE_ICONS:\n            icon_by_extension = icon(LANGUAGE_ICONS[extension], scale_factor)\n        else:\n            if extension == '.ipynb':\n                if is_dark_interface():\n                    icon_by_extension = QIcon(\n                        get_image_path('notebook_dark.svg'))\n                else:\n                    icon_by_extension = QIcon(\n                        get_image_path('notebook_light.svg'))\n            elif mime_type is not None:\n                try:\n                    # Fix for issue 5080. Even though\n                    # mimetypes.guess_type documentation states that\n                    # the return value will be None or a tuple of\n                    # the form type/subtype, in the Windows registry,\n                    # .sql has a mimetype of text\\plain\n                    # instead of text/plain therefore mimetypes is\n                    # returning it incorrectly.\n                    file_type, bin_name = mime_type.split('/')\n                except ValueError:\n                    file_type = 'text'\n                if file_type == 'text':\n                    icon_by_extension = icon('TextFileIcon', scale_factor)\n                elif file_type == 'audio':\n                    icon_by_extension = icon('AudioFileIcon', scale_factor)\n                elif file_type == 'video':\n                    icon_by_extension = icon('VideoFileIcon', scale_factor)\n                elif file_type == 'image':\n                    icon_by_extension = icon('ImageFileIcon', scale_factor)\n                elif file_type == 'application':\n                    if bin_name in application_icons:\n                        icon_by_extension = icon(\n                            application_icons[bin_name], scale_factor)\n    return icon_by_extension", "response": "Return the icon depending on the file extension"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accept(self):\n        AutosaveErrorDialog.show_errors = not self.dismiss_box.isChecked()\n        return QDialog.accept(self)", "response": "Override QDialog. accept to update show_errors and hide dialog box."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_common_actions(self):\r\n        self.collapse_all_action = create_action(self,\r\n                                     text=_('Collapse all'),\r\n                                     icon=ima.icon('collapse'),\r\n                                     triggered=self.collapseAll)\r\n        self.expand_all_action = create_action(self,\r\n                                     text=_('Expand all'),\r\n                                     icon=ima.icon('expand'),\r\n                                     triggered=self.expandAll)\r\n        self.restore_action = create_action(self,\r\n                                     text=_('Restore'),\r\n                                     tip=_('Restore original tree layout'),\r\n                                     icon=ima.icon('restore'),\r\n                                     triggered=self.restore)\r\n        self.collapse_selection_action = create_action(self,\r\n                                     text=_('Collapse selection'),\r\n                                     icon=ima.icon('collapse_selection'),\r\n                                     triggered=self.collapse_selection)\r\n        self.expand_selection_action = create_action(self,\r\n                                     text=_('Expand selection'),\r\n                                     icon=ima.icon('expand_selection'),\r\n                                     triggered=self.expand_selection)\r\n        return [self.collapse_all_action, self.expand_all_action,\r\n                self.restore_action, None,\r\n                self.collapse_selection_action, self.expand_selection_action]", "response": "Setup common actions for the context menu"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_menu_actions(self):\r\n        items = self.selectedItems()\r\n        actions = self.get_actions_from_items(items)\r\n        if actions:\r\n            actions.append(None)\r\n        actions += self.common_actions\r\n        return actions", "response": "Returns a list of menu actions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef item_selection_changed(self):\r\n        is_selection = len(self.selectedItems()) > 0\r\n        self.expand_selection_action.setEnabled(is_selection)\r\n        self.collapse_selection_action.setEnabled(is_selection)", "response": "Item selection has changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_items(self):\r\n        itemlist = []\r\n        def add_to_itemlist(item):\r\n            for index in range(item.childCount()):\r\n                citem = item.child(index)\r\n                itemlist.append(citem)\r\n                add_to_itemlist(citem)\r\n        for tlitem in self.get_top_level_items():\r\n            add_to_itemlist(tlitem)\r\n        return itemlist", "response": "Return items ( excluding top level items"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_expanded_state(self):\r\n        self.__expanded_state = {}\r\n        def add_to_state(item):\r\n            user_text = get_item_user_text(item)\r\n            self.__expanded_state[hash(user_text)] = item.isExpanded()\r\n        def browse_children(item):\r\n            add_to_state(item)\r\n            for index in range(item.childCount()):\r\n                citem = item.child(index)\r\n                user_text = get_item_user_text(citem)\r\n                self.__expanded_state[hash(user_text)] = citem.isExpanded()\r\n                browse_children(citem)\r\n        for tlitem in self.get_top_level_items():\r\n            browse_children(tlitem)", "response": "Save all items expanded state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore_expanded_state(self):\r\n        if self.__expanded_state is None:\r\n            return\r\n        for item in self.get_items()+self.get_top_level_items():\r\n            user_text = get_item_user_text(item)\r\n            is_expanded = self.__expanded_state.get(hash(user_text))\r\n            if is_expanded is not None:\r\n                item.setExpanded(is_expanded)", "response": "Restore all items expanded state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsorting the tree wrt the top level items.", "response": "def sort_top_level_items(self, key):\r\n        \"\"\"Sorting tree wrt top level items\"\"\"\r\n        self.save_expanded_state()\r\n        items = sorted([self.takeTopLevelItem(0)\r\n                        for index in range(self.topLevelItemCount())], key=key)\r\n        for index, item in enumerate(items):\r\n            self.insertTopLevelItem(index, item)\r\n        self.restore_expanded_state()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding Qt method to update the context menu", "response": "def contextMenuEvent(self, event):\r\n        \"\"\"Override Qt method\"\"\"\r\n        self.update_menu()\r\n        self.menu.popup(event.globalPos())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stdlib_modules():\n    modules = list(sys.builtin_module_names)\n    for path in sys.path[1:]:\n        if 'site-packages' not in path:\n            modules += module_list(path)\n    \n    modules = set(modules)\n    if '__init__' in modules:\n        modules.remove('__init__')\n    modules = list(modules)\n    return modules", "response": "Returns a list containing the names of all the modules available in the IPython standard library."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints the editor fold tree to stdout for debugging purpose.", "response": "def print_tree(editor, file=sys.stdout, print_blocks=False, return_list=False):\n    \"\"\"\n    Prints the editor fold tree to stdout, for debugging purpose.\n\n    :param editor: CodeEditor instance.\n    :param file: file handle where the tree will be printed. Default is stdout.\n    :param print_blocks: True to print all blocks, False to only print blocks\n        that are fold triggers\n    \"\"\"\n    output_list = []\n\n    block = editor.document().firstBlock()\n    while block.isValid():\n        trigger = TextBlockHelper().is_fold_trigger(block)\n        trigger_state = TextBlockHelper().is_collapsed(block)\n        lvl = TextBlockHelper().get_fold_lvl(block)\n        visible = 'V' if block.isVisible() else 'I'\n        if trigger:\n            trigger = '+' if trigger_state else '-'\n            if return_list:\n                output_list.append([block.blockNumber() + 1, lvl, visible])\n            else:\n                print('l%d:%s%s%s' %\n                      (block.blockNumber() + 1, lvl, trigger, visible),\n                      file=file)\n        elif print_blocks:\n            if return_list:\n                output_list.append([block.blockNumber() + 1, lvl, visible])\n            else:\n                print('l%d:%s%s' %\n                      (block.blockNumber() + 1, lvl, visible), file=file)\n        block = block.next()\n\n    if return_list:\n        return output_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a list of lists into a dict of environment variables.", "response": "def listdict2envdict(listdict):\r\n    \"\"\"Dict of lists --> Dict\"\"\"\r\n    for key in listdict:\r\n        if isinstance(listdict[key], list):\r\n            listdict[key] = os.path.pathsep.join(listdict[key])\r\n    return listdict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning Windows environment variable editor", "response": "def main():\r\n    \"\"\"Run Windows environment variable editor\"\"\"\r\n    from spyder.utils.qthelpers import qapplication\r\n    app = qapplication()\r\n    if os.name == 'nt':\r\n        dialog = WinUserEnvDialog()\r\n    else:\r\n        dialog = EnvDialog()\r\n    dialog.show()\r\n    app.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keyPressEvent(self, event):\r\n        if event.key() in [Qt.Key_Enter, Qt.Key_Return]:\r\n            self._parent.process_text()\r\n            if self._parent.is_valid():\r\n                self._parent.keyPressEvent(event)\r\n        else:\r\n            QLineEdit.keyPressEvent(self, event)", "response": "Override Qt method to handle key press events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef event(self, event):\r\n        if event.type() == QEvent.KeyPress:\r\n            if (event.key() == Qt.Key_Tab or event.key() == Qt.Key_Space):\r\n                text = self.text()\r\n                cursor = self.cursorPosition()\r\n                # fix to include in \"undo/redo\" history\r\n                if cursor != 0 and text[cursor-1] == ' ':\r\n                    text = text[:cursor-1] + ROW_SEPARATOR + ' ' +\\\r\n                        text[cursor:]\r\n                else:\r\n                    text = text[:cursor] + ' ' + text[cursor:]\r\n                self.setCursorPosition(cursor)\r\n                self.setText(text)\r\n                self.setCursorPosition(cursor + 1)\r\n                return False\r\n        return QWidget.event(self, event)", "response": "Override Qt method to modify the text of the current line with the event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keyPressEvent(self, event):\r\n        if event.key() in [Qt.Key_Enter, Qt.Key_Return]:\r\n            QTableWidget.keyPressEvent(self, event)\r\n            # To avoid having to enter one final tab\r\n            self.setDisabled(True)\r\n            self.setDisabled(False)\r\n            self._parent.keyPressEvent(event)\r\n        else:\r\n            QTableWidget.keyPressEvent(self, event)", "response": "Override. keyPressEvent to handle enter and return key events."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_headers(self):\r\n        rows = self.rowCount()\r\n        cols = self.columnCount()\r\n\r\n        for r in range(rows):\r\n            self.setVerticalHeaderItem(r, QTableWidgetItem(str(r)))\r\n        for c in range(cols):\r\n            self.setHorizontalHeaderItem(c, QTableWidgetItem(str(c)))\r\n            self.setColumnWidth(c, 40)", "response": "Reset the column and row numbering in the headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the entered array in a parseable form.", "response": "def text(self):\r\n        \"\"\"\r\n        Return the entered array in a parseable form.\r\n        \"\"\"\r\n        text = []\r\n        rows = self.rowCount()\r\n        cols = self.columnCount()\r\n\r\n        # handle empty table case\r\n        if rows == 2 and cols == 2:\r\n            item = self.item(0, 0)\r\n            if item is None:\r\n                return ''\r\n\r\n        for r in range(rows - 1):\r\n            for c in range(cols - 1):\r\n                item = self.item(r, c)\r\n                if item is not None:\r\n                    value = item.text()\r\n                else:\r\n                    value = '0'\r\n\r\n                if not value.strip():\r\n                    value = '0'\r\n\r\n                text.append(' ')\r\n                text.append(value)\r\n            text.append(ROW_SEPARATOR)\r\n\r\n        return ''.join(text[:-1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keyPressEvent(self, event):\r\n        QToolTip.hideText()\r\n        ctrl = event.modifiers() & Qt.ControlModifier\r\n\r\n        if event.key() in [Qt.Key_Enter, Qt.Key_Return]:\r\n            if ctrl:\r\n                self.process_text(array=False)\r\n            else:\r\n                self.process_text(array=True)\r\n            self.accept()\r\n        else:\r\n            QDialog.keyPressEvent(self, event)", "response": "Override Qt method to handle key press events."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef event(self, event):\r\n        if event.type() == QEvent.KeyPress and event.key() == Qt.Key_Tab:\r\n            return False\r\n        return QWidget.event(self, event)", "response": "Returns True if event is a tab key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing the text of the current widget.", "response": "def process_text(self, array=True):\r\n        \"\"\"\r\n        Construct the text based on the entered content in the widget.\r\n        \"\"\"\r\n        if array:\r\n            prefix = 'np.array([['\r\n        else:\r\n            prefix = 'np.matrix([['\r\n\r\n        suffix = ']])'\r\n        values = self._widget.text().strip()\r\n\r\n        if values != '':\r\n            # cleans repeated spaces\r\n            exp = r'(\\s*)' + ROW_SEPARATOR + r'(\\s*)'\r\n            values = re.sub(exp, ROW_SEPARATOR, values)\r\n            values = re.sub(r\"\\s+\", \" \", values)\r\n            values = re.sub(r\"]$\", \"\", values)\r\n            values = re.sub(r\"^\\[\", \"\", values)\r\n            values = re.sub(ROW_SEPARATOR + r'*$', '', values)\r\n\r\n            # replaces spaces by commas\r\n            values = values.replace(' ',  ELEMENT_SEPARATOR)\r\n\r\n            # iterate to find number of rows and columns\r\n            new_values = []\r\n            rows = values.split(ROW_SEPARATOR)\r\n            nrows = len(rows)\r\n            ncols = []\r\n            for row in rows:\r\n                new_row = []\r\n                elements = row.split(ELEMENT_SEPARATOR)\r\n                ncols.append(len(elements))\r\n                for e in elements:\r\n                    num = e\r\n\r\n                    # replaces not defined values\r\n                    if num in NAN_VALUES:\r\n                        num = 'np.nan'\r\n\r\n                    # Convert numbers to floating point\r\n                    if self._force_float:\r\n                        try:\r\n                            num = str(float(e))\r\n                        except:\r\n                            pass\r\n                    new_row.append(num)\r\n                new_values.append(ELEMENT_SEPARATOR.join(new_row))\r\n            new_values = ROW_SEPARATOR.join(new_values)\r\n            values = new_values\r\n\r\n            # Check validity\r\n            if len(set(ncols)) == 1:\r\n                self._valid = True\r\n            else:\r\n                self._valid = False\r\n\r\n            # Single rows are parsed as 1D arrays/matrices\r\n            if nrows == 1:\r\n                prefix = prefix[:-1]\r\n                suffix = suffix.replace(\"]])\", \"])\")\r\n\r\n            # Fix offset\r\n            offset = self._offset\r\n            braces = BRACES.replace(' ', '\\n' + ' '*(offset + len(prefix) - 1))\r\n\r\n            values = values.replace(ROW_SEPARATOR,  braces)\r\n            text = \"{0}{1}{2}\".format(prefix, values, suffix)\r\n\r\n            self._text = text\r\n        else:\r\n            self._text = ''\r\n        self.update_warning()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the icon and tip based on the validity of the array content.", "response": "def update_warning(self):\r\n        \"\"\"\r\n        Updates the icon and tip based on the validity of the array content.\r\n        \"\"\"\r\n        widget = self._button_warning\r\n        if not self.is_valid():\r\n            tip = _('Array dimensions not valid')\r\n            widget.setIcon(ima.icon('MessageBoxWarning'))\r\n            widget.setToolTip(tip)\r\n            QToolTip.showText(self._widget.mapToGlobal(QPoint(0, 5)), tip)\r\n        else:\r\n            self._button_warning.setToolTip('')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves selected language setting and save to language configuration file.", "response": "def _save_lang(self):\n        \"\"\"\n        Get selected language setting and save to language configuration file.\n        \"\"\"\n        for combobox, (option, _default) in list(self.comboboxes.items()):\n            if option == 'interface_language':\n                data = combobox.itemData(combobox.currentIndex())\n                value = from_qvariant(data, to_text_string)\n                break\n        try:\n            save_lang_conf(value)\n            self.set_option('interface_language', value)\n        except Exception:\n            QMessageBox.critical(\n                self, _(\"Error\"),\n                _(\"We're sorry but the following error occurred while trying \"\n                  \"to set your selected language:<br><br>\"\n                  \"<tt>{}</tt>\").format(traceback.format_exc()),\n                QMessageBox.Ok)\n            return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if path has write access", "response": "def is_writable(path):\r\n    \"\"\"Check if path has write access\"\"\"\r\n    try:\r\n        testfile = tempfile.TemporaryFile(dir=path)\r\n        testfile.close()\r\n    except OSError as e:\r\n        if e.errno == errno.EACCES:  # 13\r\n            return False\r\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all available project types.", "response": "def _get_project_types(self):\r\n        \"\"\"Get all available project types.\"\"\"\r\n        project_types = get_available_project_types()\r\n        projects = []\r\n\r\n        for project in project_types:\r\n            projects.append(project.PROJECT_TYPE_NAME)\r\n\r\n        return projects"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates text of location.", "response": "def update_location(self, text=''):\r\n        \"\"\"Update text of location.\"\"\"\r\n        self.text_project_name.setEnabled(self.radio_new_dir.isChecked())\r\n        name = self.text_project_name.text().strip()\r\n\r\n        if name and self.radio_new_dir.isChecked():\r\n            path = osp.join(self.location, name)\r\n            self.button_create.setDisabled(os.path.isdir(path))\r\n        elif self.radio_from_dir.isChecked():\r\n            self.button_create.setEnabled(True)\r\n            path = self.location\r\n        else:\r\n            self.button_create.setEnabled(False)\r\n            path = self.location\r\n        \r\n        self.text_location.setText(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset shell styles font", "response": "def set_font(self, font):\r\n        \"\"\"Set shell styles font\"\"\"\r\n        self.setFont(font)\r\n        self.set_pythonshell_font(font)\r\n        cursor = self.textCursor()\r\n        cursor.select(QTextCursor.Document)\r\n        charformat = QTextCharFormat()\r\n        charformat.setFontFamily(font.family())\r\n        charformat.setFontPointSize(font.pointSize())\r\n        cursor.mergeCharFormat(charformat)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_context_menu(self):\r\n        self.menu = QMenu(self)\r\n        self.cut_action = create_action(self, _(\"Cut\"),\r\n                                        shortcut=keybinding('Cut'),\r\n                                        icon=ima.icon('editcut'),\r\n                                        triggered=self.cut)\r\n        self.copy_action = create_action(self, _(\"Copy\"),\r\n                                         shortcut=keybinding('Copy'),\r\n                                         icon=ima.icon('editcopy'),\r\n                                         triggered=self.copy)\r\n        paste_action = create_action(self, _(\"Paste\"),\r\n                                     shortcut=keybinding('Paste'),\r\n                                     icon=ima.icon('editpaste'),\r\n                                     triggered=self.paste)\r\n        save_action = create_action(self, _(\"Save history log...\"),\r\n                                    icon=ima.icon('filesave'),\r\n                                    tip=_(\"Save current history log (i.e. all \"\r\n                                          \"inputs and outputs) in a text file\"),\r\n                                    triggered=self.save_historylog)\r\n        self.delete_action = create_action(self, _(\"Delete\"),\r\n                                    shortcut=keybinding('Delete'),\r\n                                    icon=ima.icon('editdelete'),\r\n                                    triggered=self.delete)\r\n        selectall_action = create_action(self, _(\"Select All\"),\r\n                                    shortcut=keybinding('SelectAll'),\r\n                                    icon=ima.icon('selectall'),\r\n                                    triggered=self.selectAll)\r\n        add_actions(self.menu, (self.cut_action, self.copy_action,\r\n                                paste_action, self.delete_action, None,\r\n                                selectall_action, None, save_action) )", "response": "Setup shell context menu"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _select_input(self):\r\n        line, index = self.get_position('eof')\r\n        if self.current_prompt_pos is None:\r\n            pline, pindex = line, index\r\n        else:\r\n            pline, pindex = self.current_prompt_pos\r\n        self.setSelection(pline, pindex, line, index)", "response": "Select current line without selecting console prompt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_input_buffer(self):\r\n        input_buffer = ''\r\n        if self.current_prompt_pos is not None:\r\n            input_buffer = self.get_text(self.current_prompt_pos, 'eol')\r\n            input_buffer = input_buffer.replace(os.linesep, '\\n')\r\n        return input_buffer", "response": "Return the input buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_prompt(self, prompt):\r\n        if self.get_cursor_line_column()[1] != 0:\r\n            self.write('\\n')\r\n        self.write(prompt, prompt=True)\r\n        # now we update our cursor giving end of prompt\r\n        self.current_prompt_pos = self.get_position('cursor')\r\n        self.ensureCursorVisible()\r\n        self.new_input_line = False", "response": "Print a new prompt and save its line index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_selection(self):\r\n        if self.current_prompt_pos is None:\r\n            self.set_cursor_position('eof')\r\n        else:\r\n            self.truncate_selection(self.current_prompt_pos)", "response": "Check if selected text is r or w remove read - only parts of selection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying text to clipboard... or keyboard interrupt", "response": "def copy(self):\r\n        \"\"\"Copy text to clipboard... or keyboard interrupt\"\"\"\r\n        if self.has_selected_text():\r\n            ConsoleBaseWidget.copy(self)\r\n        elif not sys.platform == 'darwin':\r\n            self.interrupt()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_historylog(self):\r\n        title = _(\"Save history log\")\r\n        self.redirect_stdio.emit(False)\r\n        filename, _selfilter = getsavefilename(self, title,\r\n                    self.historylog_filename, \"%s (*.log)\" % _(\"History logs\"))\r\n        self.redirect_stdio.emit(True)\r\n        if filename:\r\n            filename = osp.normpath(filename)\r\n            try:\r\n                encoding.write(to_text_string(self.get_text_with_eol()),\r\n                               filename)\r\n                self.historylog_filename = filename\r\n                CONF.set('main', 'historylog_filename', filename)\r\n            except EnvironmentError:\r\n                pass", "response": "Save current history log"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_new_line(self):\r\n        self.set_cursor_position('eof')\r\n        self.current_prompt_pos = self.get_position('cursor')\r\n        self.new_input_line = False", "response": "On new input line"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preprocess_keyevent(self, event):\r\n        # Copy must be done first to be able to copy read-only text parts\r\n        # (otherwise, right below, we would remove selection\r\n        #  if not on current line)\r\n        ctrl = event.modifiers() & Qt.ControlModifier\r\n        meta = event.modifiers() & Qt.MetaModifier    # meta=ctrl in OSX\r\n        if event.key() == Qt.Key_C and \\\r\n          ((Qt.MetaModifier | Qt.ControlModifier) & event.modifiers()):\r\n            if meta and sys.platform == 'darwin':\r\n                self.interrupt()\r\n            elif ctrl:\r\n                self.copy()\r\n            event.accept()\r\n            return True\r\n        \r\n        if self.new_input_line and ( len(event.text()) or event.key() in \\\r\n           (Qt.Key_Up, Qt.Key_Down, Qt.Key_Left, Qt.Key_Right) ):\r\n            self.on_new_line()\r\n        \r\n        return False", "response": "Pre - process a keypress event and return True if event is accepted False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef postprocess_keyevent(self, event):\r\n        event, text, key, ctrl, shift = restore_keyevent(event)\r\n        \r\n        # Is cursor on the last line? and after prompt?\r\n        if len(text):\r\n            #XXX: Shouldn't it be: `if len(unicode(text).strip(os.linesep))` ?\r\n            if self.has_selected_text():\r\n                self.check_selection()\r\n            self.restrict_cursor_position(self.current_prompt_pos, 'eof')\r\n            \r\n        cursor_position = self.get_position('cursor')\r\n\r\n        if key in (Qt.Key_Return, Qt.Key_Enter):\r\n            if self.is_cursor_on_last_line():\r\n                self._key_enter()\r\n            # add and run selection\r\n            else:\r\n                self.insert_text(self.get_selected_text(), at_end=True)\r\n            \r\n        elif key == Qt.Key_Insert and not shift and not ctrl:\r\n            self.setOverwriteMode(not self.overwriteMode())\r\n            \r\n        elif key == Qt.Key_Delete:\r\n            if self.has_selected_text():\r\n                self.check_selection()\r\n                self.remove_selected_text()\r\n            elif self.is_cursor_on_last_line():\r\n                self.stdkey_clear()\r\n            \r\n        elif key == Qt.Key_Backspace:\r\n            self._key_backspace(cursor_position)\r\n            \r\n        elif key == Qt.Key_Tab:\r\n            self._key_tab()\r\n            \r\n        elif key == Qt.Key_Space and ctrl:\r\n            self._key_ctrl_space()\r\n\r\n        elif key == Qt.Key_Left:\r\n            if self.current_prompt_pos == cursor_position:\r\n                # Avoid moving cursor on prompt\r\n                return\r\n            method = self.extend_selection_to_next if shift \\\r\n                     else self.move_cursor_to_next\r\n            method('word' if ctrl else 'character', direction='left')\r\n                \r\n        elif key == Qt.Key_Right:\r\n            if self.is_cursor_at_end():\r\n                return\r\n            method = self.extend_selection_to_next if shift \\\r\n                     else self.move_cursor_to_next\r\n            method('word' if ctrl else 'character', direction='right')\r\n\r\n        elif (key == Qt.Key_Home) or ((key == Qt.Key_Up) and ctrl):\r\n            self._key_home(shift, ctrl)\r\n\r\n        elif (key == Qt.Key_End) or ((key == Qt.Key_Down) and ctrl):\r\n            self._key_end(shift, ctrl)\r\n\r\n        elif key == Qt.Key_Up:\r\n            if not self.is_cursor_on_last_line():\r\n                self.set_cursor_position('eof')\r\n            y_cursor = self.get_coordinates(cursor_position)[1]\r\n            y_prompt = self.get_coordinates(self.current_prompt_pos)[1]\r\n            if y_cursor > y_prompt:\r\n                self.stdkey_up(shift)\r\n            else:\r\n                self.browse_history(backward=True)\r\n                \r\n        elif key == Qt.Key_Down:\r\n            if not self.is_cursor_on_last_line():\r\n                self.set_cursor_position('eof')\r\n            y_cursor = self.get_coordinates(cursor_position)[1]\r\n            y_end = self.get_coordinates('eol')[1]\r\n            if y_cursor < y_end:\r\n                self.stdkey_down(shift)\r\n            else:\r\n                self.browse_history(backward=False)\r\n            \r\n        elif key in (Qt.Key_PageUp, Qt.Key_PageDown):\r\n            #XXX: Find a way to do this programmatically instead of calling\r\n            # widget keyhandler (this won't work if the *event* is coming from\r\n            # the event queue - i.e. if the busy buffer is ever implemented)\r\n            ConsoleBaseWidget.keyPressEvent(self, event)\r\n\r\n        elif key == Qt.Key_Escape and shift:\r\n            self.clear_line()\r\n\r\n        elif key == Qt.Key_Escape:\r\n            self._key_escape()\r\n                \r\n        elif key == Qt.Key_L and ctrl:\r\n            self.clear_terminal()\r\n            \r\n        elif key == Qt.Key_V and ctrl:\r\n            self.paste()\r\n            \r\n        elif key == Qt.Key_X and ctrl:\r\n            self.cut()\r\n            \r\n        elif key == Qt.Key_Z and ctrl:\r\n            self.undo()\r\n            \r\n        elif key == Qt.Key_Y and ctrl:\r\n            self.redo()\r\n            \r\n        elif key == Qt.Key_A and ctrl:\r\n            self.selectAll()\r\n                \r\n        elif key == Qt.Key_Question and not self.has_selected_text():\r\n            self._key_question(text)\r\n            \r\n        elif key == Qt.Key_ParenLeft and not self.has_selected_text():\r\n            self._key_parenleft(text)\r\n            \r\n        elif key == Qt.Key_Period and not self.has_selected_text():\r\n            self._key_period(text)\r\n\r\n        elif len(text) and not self.isReadOnly():\r\n            self.hist_wholeline = False\r\n            self.insert_text(text)\r\n            self._key_other(text)\r\n                \r\n        else:\r\n            # Let the parent widget handle the key press event\r\n            ConsoleBaseWidget.keyPressEvent(self, event)", "response": "This method is called when the user has pressed a keypress event in InternalShell."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the history from a. py file in user home directory.", "response": "def load_history(self):\r\n        \"\"\"Load history from a .py file in user home directory\"\"\"\r\n        if osp.isfile(self.history_filename):\r\n            rawhistory, _ = encoding.readlines(self.history_filename)\r\n            rawhistory = [line.replace('\\n', '') for line in rawhistory]\r\n            if rawhistory[1] != self.INITHISTORY[1]:\r\n                rawhistory[1] = self.INITHISTORY[1]\r\n        else:\r\n            rawhistory = self.INITHISTORY\r\n        history = [line for line in rawhistory \\\r\n                   if line and not line.startswith('#')]\r\n\r\n        # Truncating history to X entries:\r\n        while len(history) >= CONF.get('historylog', 'max_entries'):\r\n            del history[0]\r\n            while rawhistory[0].startswith('#'):\r\n                del rawhistory[0]\r\n            del rawhistory[0]\r\n\r\n        # Saving truncated history:\r\n        try:\r\n            encoding.writelines(rawhistory, self.history_filename)\r\n        except EnvironmentError:\r\n            pass\r\n\r\n        return history"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite text to the output of the specified object.", "response": "def write(self, text, flush=False, error=False, prompt=False):\r\n        \"\"\"Simulate stdout and stderr\"\"\"\r\n        if prompt:\r\n            self.flush()\r\n        if not is_string(text):\r\n            # This test is useful to discriminate QStrings from decoded str\r\n            text = to_text_string(text)\r\n        self.__buffer.append(text)\r\n        ts = time.time()\r\n        if flush or prompt:\r\n            self.flush(error=error, prompt=prompt)\r\n        elif ts - self.__timestamp > 0.05:\r\n            self.flush(error=error)\r\n            self.__timestamp = ts\r\n            # Timer to flush strings cached by last write() operation in series\r\n            self.__flushtimer.start(50)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush(self, error=False, prompt=False):\r\n        # Fix for Issue 2452 \r\n        if PY3:\r\n            try:\r\n                text = \"\".join(self.__buffer)\r\n            except TypeError:\r\n                text = b\"\".join(self.__buffer)\r\n                try:\r\n                    text = text.decode( locale.getdefaultlocale()[1] )\r\n                except:\r\n                    pass\r\n        else:\r\n            text = \"\".join(self.__buffer)\r\n\r\n        self.__buffer = []\r\n        self.insert_text(text, at_end=True, error=error, prompt=prompt)\r\n        QCoreApplication.processEvents()\r\n        self.repaint()\r\n        # Clear input buffer:\r\n        self.new_input_line = True", "response": "Flush buffer write text to console"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts text at the current cursor position at_end or at the end of the command line", "response": "def insert_text(self, text, at_end=False, error=False, prompt=False):\r\n        \"\"\"\r\n        Insert text at the current cursor position\r\n        or at the end of the command line\r\n        \"\"\"\r\n        if at_end:\r\n            # Insert text at the end of the command line\r\n            self.append_text_to_shell(text, error, prompt)\r\n        else:\r\n            # Insert text at current cursor position\r\n            ConsoleBaseWidget.insert_text(self, text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dropEvent(self, event):\r\n        if (event.mimeData().hasFormat(\"text/plain\")):\r\n            text = to_text_string(event.mimeData().text())\r\n            if self.new_input_line:\r\n                self.on_new_line()\r\n            self.insert_text(text, at_end=True)\r\n            self.setFocus()\r\n            event.setDropAction(Qt.MoveAction)\r\n            event.accept()\r\n        else:\r\n            event.ignore()", "response": "Drag and Drop - Drop event."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_without_prompts(self):\r\n        text = self.get_selected_text()\r\n        lines = text.split(os.linesep)\r\n        for index, line in enumerate(lines):\r\n            if line.startswith('>>> ') or line.startswith('... '):\r\n                lines[index] = line[4:]\r\n        text = os.linesep.join(lines)\r\n        QApplication.clipboard().setText(text)", "response": "Copy text to clipboard without prompts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nactioning for Backspace key", "response": "def _key_backspace(self, cursor_position):\r\n        \"\"\"Action for Backspace key\"\"\"\r\n        if self.has_selected_text():\r\n            self.check_selection()\r\n            self.remove_selected_text()\r\n        elif self.current_prompt_pos == cursor_position:\r\n            # Avoid deleting prompt\r\n            return\r\n        elif self.is_cursor_on_last_line():\r\n            self.stdkey_backspace()\r\n            if self.is_completion_widget_visible():\r\n                # Removing only last character because if there was a selection\r\n                # the completion widget would have been canceled\r\n                self.completion_text = self.completion_text[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nactioning for TAB key", "response": "def _key_tab(self):\r\n        \"\"\"Action for TAB key\"\"\"\r\n        if self.is_cursor_on_last_line():\r\n            empty_line = not self.get_current_line_to_cursor().strip()\r\n            if empty_line:\r\n                self.stdkey_tab()\r\n            else:\r\n                self.show_code_completion()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef paste(self):\r\n        text = to_text_string(QApplication.clipboard().text())\r\n        if len(text.splitlines()) > 1:\r\n            # Multiline paste\r\n            if self.new_input_line:\r\n                self.on_new_line()\r\n            self.remove_selected_text() # Remove selection, eventually\r\n            end = self.get_current_line_from_cursor()\r\n            lines = self.get_current_line_to_cursor() + text + end\r\n            self.clear_line()\r\n            self.execute_lines(lines)\r\n            self.move_cursor(-len(end))\r\n        else:\r\n            # Standard paste\r\n            ShellBaseWidget.paste(self)", "response": "Reimplemented slot to handle multiline paste action"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_completion_list(self, completions, completion_text=\"\"):\r\n        if not completions:\r\n            return\r\n        if not isinstance(completions[0], tuple):\r\n            completions = [(c, '') for c in completions]\r\n        if len(completions) == 1 and completions[0][0] == completion_text:\r\n            return\r\n        self.completion_text = completion_text\r\n        # Sorting completion list (entries starting with underscore are\r\n        # put at the end of the list):\r\n        underscore = set([(comp, t) for (comp, t) in completions\r\n                          if comp.startswith('_')])\r\n\r\n        completions = sorted(set(completions) - underscore,\r\n                             key=lambda x: str_lower(x[0]))\r\n        completions += sorted(underscore, key=lambda x: str_lower(x[0]))\r\n        self.show_completion_widget(completions)", "response": "Display the possible completions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a completion list based on the current line of text", "response": "def show_code_completion(self):\r\n        \"\"\"Display a completion list based on the current line\"\"\"\r\n        # Note: unicode conversion is needed only for ExternalShellBase\r\n        text = to_text_string(self.get_current_line_to_cursor())\r\n        last_obj = self.get_last_obj()\r\n        if not text:\r\n            return\r\n\r\n        obj_dir = self.get_dir(last_obj)\r\n        if last_obj and obj_dir and text.endswith('.'):\r\n            self.show_completion_list(obj_dir)\r\n            return\r\n        \r\n        # Builtins and globals\r\n        if not text.endswith('.') and last_obj \\\r\n           and re.match(r'[a-zA-Z_0-9]*$', last_obj):\r\n            b_k_g = dir(builtins)+self.get_globals_keys()+keyword.kwlist\r\n            for objname in b_k_g:\r\n                if objname.startswith(last_obj) and objname != last_obj:\r\n                    self.show_completion_list(b_k_g, completion_text=last_obj)\r\n                    return\r\n            else:\r\n                return\r\n        \r\n        # Looking for an incomplete completion\r\n        if last_obj is None:\r\n            last_obj = text\r\n        dot_pos = last_obj.rfind('.')\r\n        if dot_pos != -1:\r\n            if dot_pos == len(last_obj)-1:\r\n                completion_text = \"\"\r\n            else:\r\n                completion_text = last_obj[dot_pos+1:]\r\n                last_obj = last_obj[:dot_pos]\r\n            completions = self.get_dir(last_obj)\r\n            if completions is not None:\r\n                self.show_completion_list(completions,\r\n                                          completion_text=completion_text)\r\n                return\r\n        \r\n        # Looking for ' or \": filename completion\r\n        q_pos = max([text.rfind(\"'\"), text.rfind('\"')])\r\n        if q_pos != -1:\r\n            completions = self.get_cdlistdir()\r\n            if completions:\r\n                self.show_completion_list(completions,\r\n                                          completion_text=text[q_pos+1:])\r\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncommands to start kernels", "response": "def argv(self):\n        \"\"\"Command to start kernels\"\"\"\n        # Python interpreter used to start kernels\n        if CONF.get('main_interpreter', 'default'):\n            pyexec = get_python_executable()\n        else:\n            # Avoid IPython adding the virtualenv on which Spyder is running\n            # to the kernel sys.path\n            os.environ.pop('VIRTUAL_ENV', None)\n            pyexec = CONF.get('main_interpreter', 'executable')\n            if not is_python_interpreter(pyexec):\n                pyexec = get_python_executable()\n                CONF.set('main_interpreter', 'executable', '')\n                CONF.set('main_interpreter', 'default', True)\n                CONF.set('main_interpreter', 'custom', False)\n\n        # Fixes Issue #3427\n        if os.name == 'nt':\n            dir_pyexec = osp.dirname(pyexec)\n            pyexec_w = osp.join(dir_pyexec, 'pythonw.exe')\n            if osp.isfile(pyexec_w):\n                pyexec = pyexec_w\n\n        # Command used to start kernels\n        kernel_cmd = [\n            pyexec,\n            '-m',\n            'spyder_kernels.console',\n            '-f',\n            '{connection_file}'\n        ]\n\n        return kernel_cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_common_actions(self):\r\n        actions = FilteredDirView.setup_common_actions(self)\r\n\r\n        # Toggle horizontal scrollbar\r\n        hscrollbar_action = create_action(self, _(\"Show horizontal scrollbar\"),\r\n                                          toggled=self.toggle_hscrollbar)\r\n        hscrollbar_action.setChecked(self.show_hscrollbar)\r\n        self.toggle_hscrollbar(self.show_hscrollbar)\r\n\r\n        return actions + [hscrollbar_action]", "response": "Setup context menu common actions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dropEvent(self, event):\r\n        event.ignore()\r\n        action = event.dropAction()\r\n        if action not in (Qt.MoveAction, Qt.CopyAction):\r\n            return\r\n\r\n        # QTreeView must not remove the source items even in MoveAction mode:\r\n        # event.setDropAction(Qt.CopyAction)\r\n\r\n        dst = self.get_filename(self.indexAt(event.pos()))\r\n        yes_to_all, no_to_all = None, None\r\n        src_list = [to_text_string(url.toString())\r\n                    for url in event.mimeData().urls()]\r\n        if len(src_list) > 1:\r\n            buttons = QMessageBox.Yes|QMessageBox.YesToAll| \\\r\n                      QMessageBox.No|QMessageBox.NoToAll|QMessageBox.Cancel\r\n        else:\r\n            buttons = QMessageBox.Yes|QMessageBox.No\r\n        for src in src_list:\r\n            if src == dst:\r\n                continue\r\n            dst_fname = osp.join(dst, osp.basename(src))\r\n            if osp.exists(dst_fname):\r\n                if yes_to_all is not None or no_to_all is not None:\r\n                    if no_to_all:\r\n                        continue\r\n                elif osp.isfile(dst_fname):\r\n                    answer = QMessageBox.warning(self, _('Project explorer'),\r\n                              _('File <b>%s</b> already exists.<br>'\r\n                                'Do you want to overwrite it?') % dst_fname,\r\n                              buttons)\r\n                    if answer == QMessageBox.No:\r\n                        continue\r\n                    elif answer == QMessageBox.Cancel:\r\n                        break\r\n                    elif answer == QMessageBox.YesToAll:\r\n                        yes_to_all = True\r\n                    elif answer == QMessageBox.NoToAll:\r\n                        no_to_all = True\r\n                        continue\r\n                else:\r\n                    QMessageBox.critical(self, _('Project explorer'),\r\n                                         _('Folder <b>%s</b> already exists.'\r\n                                           ) % dst_fname, QMessageBox.Ok)\r\n                    event.setDropAction(Qt.CopyAction)\r\n                    return\r\n            try:\r\n                if action == Qt.CopyAction:\r\n                    if osp.isfile(src):\r\n                        shutil.copy(src, dst)\r\n                    else:\r\n                        shutil.copytree(src, dst)\r\n                else:\r\n                    if osp.isfile(src):\r\n                        misc.move_file(src, dst)\r\n                    else:\r\n                        shutil.move(src, dst)\r\n                    self.parent_widget.removed.emit(src)\r\n            except EnvironmentError as error:\r\n                if action == Qt.CopyAction:\r\n                    action_str = _('copy')\r\n                else:\r\n                    action_str = _('move')\r\n                QMessageBox.critical(self, _(\"Project Explorer\"),\r\n                                     _(\"<b>Unable to %s <i>%s</i></b>\"\r\n                                       \"<br><br>Error message:<br>%s\"\r\n                                       ) % (action_str, src,\r\n                                            to_text_string(error)))", "response": "Reimplement Qt method to remove items from the treeview."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, fnames=None):\r\n        if fnames is None:\r\n            fnames = self.get_selected_filenames()\r\n        multiple = len(fnames) > 1\r\n        yes_to_all = None\r\n        for fname in fnames:\r\n            if fname == self.proxymodel.path_list[0]:\r\n                self.sig_delete_project.emit()\r\n            else:\r\n                yes_to_all = self.delete_file(fname, multiple, yes_to_all)\r\n                if yes_to_all is not None and not yes_to_all:\r\n                    # Canceled\r\n                    break", "response": "Delete files in the selected directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_project_dir(self, directory):\r\n        if directory is not None:\r\n            self.treewidget.set_root_path(osp.dirname(directory))\r\n            self.treewidget.set_folder_names([osp.basename(directory)])\r\n        self.treewidget.setup_project_view()\r\n        try:\r\n            self.treewidget.setExpanded(self.treewidget.get_index(directory),\r\n                                        True)\r\n        except TypeError:\r\n            pass", "response": "Set the project directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start_interpreter(self, namespace):\r\n        self.clear()\r\n        \r\n        if self.interpreter is not None:\r\n            self.interpreter.closing()\r\n        self.interpreter = Interpreter(namespace, self.exitfunc,\r\n                                       SysOutput, WidgetProxy,\r\n                                       get_debug_level())\r\n        self.interpreter.stdout_write.data_avail.connect(self.stdout_avail)\r\n        self.interpreter.stderr_write.data_avail.connect(self.stderr_avail)\r\n        self.interpreter.widget_proxy.sig_set_readonly.connect(self.setReadOnly)\r\n        self.interpreter.widget_proxy.sig_new_prompt.connect(self.new_prompt)\r\n        self.interpreter.widget_proxy.sig_edit.connect(self.edit_script)\r\n        self.interpreter.widget_proxy.sig_wait_input.connect(self.wait_input)\r\n        if self.multithreaded:\r\n            self.interpreter.start()\r\n        \r\n        # Interpreter banner\r\n        banner = create_banner(self.message)\r\n        self.write(banner, prompt=True)\r\n\r\n        # Initial commands\r\n        for cmd in self.commands:\r\n            self.run_command(cmd, history=False, new_prompt=False)\r\n                \r\n        # First prompt\r\n        self.new_prompt(self.interpreter.p1)\r\n        self.refresh.emit()\r\n\r\n        return self.interpreter", "response": "Start a new Python interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stdout_avail(self):\r\n        data = self.interpreter.stdout_write.empty_queue()\r\n        if data:\r\n            self.write(data)", "response": "Check if stdout is available in stdout and write it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stderr_avail(self):\r\n        data = self.interpreter.stderr_write.empty_queue()\r\n        if data:\r\n            self.write(data, error=True)\r\n            self.flush(error=True)", "response": "Check if data is available in stderr and write it to the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_input(self, prompt=''):\r\n        self.new_prompt(prompt)\r\n        self.setFocus()\r\n        self.input_mode = True\r\n        self.input_loop = QEventLoop()\r\n        self.input_loop.exec_()\r\n        self.input_loop = None", "response": "Wait for input (raw_input support)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nend of wait_input mode", "response": "def end_input(self, cmd):\r\n        \"\"\"End of wait_input mode\"\"\"\r\n        self.input_mode = False\r\n        self.input_loop.exit()\r\n        self.interpreter.widget_proxy.end_input(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhelps on Spyder console", "response": "def help(self):\r\n        \"\"\"Help on Spyder console\"\"\"\r\n        QMessageBox.about(self, _(\"Help\"),\r\n                          \"\"\"<b>%s</b>\r\n                          <p><i>%s</i><br>    edit foobar.py\r\n                          <p><i>%s</i><br>    xedit foobar.py\r\n                          <p><i>%s</i><br>    run foobar.py\r\n                          <p><i>%s</i><br>    clear x, y\r\n                          <p><i>%s</i><br>    !ls\r\n                          <p><i>%s</i><br>    object?\r\n                          <p><i>%s</i><br>    result = oedit(object)\r\n                          \"\"\" % (_('Shell special commands:'),\r\n                                 _('Internal editor:'),\r\n                                 _('External editor:'),\r\n                                 _('Run script:'),\r\n                                 _('Remove references:'),\r\n                                 _('System commands:'),\r\n                                 _('Python help:'),\r\n                                 _('GUI-based editor:')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_with_external_spyder(self, text):\r\n        match = get_error_match(to_text_string(text))\r\n        if match:\r\n            fname, lnb = match.groups()\r\n            builtins.open_in_spyder(fname, int(lnb))", "response": "Open file in external Spyder s editor if available"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef external_editor(self, filename, goto=-1):\r\n        editor_path = CONF.get('internal_console', 'external_editor/path')\r\n        goto_option = CONF.get('internal_console', 'external_editor/gotoline')\r\n        try:\r\n            args = [filename]\r\n            if goto > 0 and goto_option:\r\n                args.append('%s%d'.format(goto_option, goto))\r\n            programs.run_program(editor_path, args)\r\n        except OSError:\r\n            self.write_error(\"External editor was not found:\"\r\n                             \" %s\\n\" % editor_path)", "response": "Edit in an external editor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_enter(self, command):\r\n        if self.profile:\r\n            # Simple profiling test\r\n            t0 = time()\r\n            for _ in range(10):\r\n                self.execute_command(command)\r\n            self.insert_text(u\"\\n<\u0394t>=%dms\\n\" % (1e2*(time()-t0)))\r\n            self.new_prompt(self.interpreter.p1)\r\n        else:\r\n            self.execute_command(command)\r\n        self.__flush_eventqueue()", "response": "Execute a command and wait for the next entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflushes the keyboard event queue.", "response": "def __flush_eventqueue(self):\r\n        \"\"\"Flush keyboard event queue\"\"\"\r\n        while self.eventqueue:\r\n            past_event = self.eventqueue.pop(0)\r\n            self.postprocess_keyevent(past_event)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a set of lines as single command", "response": "def execute_lines(self, lines):\r\n        \"\"\"\r\n        Execute a set of lines as multiple command\r\n        lines: multiple lines of text to be executed as single commands\r\n        \"\"\"\r\n        for line in lines.splitlines():\r\n            stripped_line = line.strip()\r\n            if stripped_line.startswith('#'):\r\n                continue\r\n            self.write(line+os.linesep, flush=True)\r\n            self.execute_command(line+\"\\n\")\r\n            self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_command(self, cmd):\r\n        if self.input_mode:\r\n            self.end_input(cmd)\r\n            return\r\n        if cmd.endswith('\\n'):\r\n            cmd = cmd[:-1]\r\n        # cls command\r\n        if cmd == 'cls':\r\n            self.clear_terminal()\r\n            return\r\n        self.run_command(cmd)", "response": "Execute a command with no arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_command(self, cmd, history=True, new_prompt=True):\r\n        if not cmd:\r\n            cmd = ''\r\n        else:\r\n            if history:\r\n                self.add_to_history(cmd)\r\n        if not self.multithreaded:\r\n            if 'input' not in cmd:\r\n                self.interpreter.stdin_write.write(\r\n                                                to_binary_string(cmd + '\\n'))\r\n                self.interpreter.run_line()\r\n                self.refresh.emit()\r\n            else:\r\n                self.write(_('In order to use commands like \"raw_input\" '\r\n                             'or \"input\" run Spyder with the multithread '\r\n                             'option (--multithread) from a system terminal'),\r\n                           error=True)\r\n        else:\r\n            self.interpreter.stdin_write.write(to_binary_string(cmd + '\\n'))", "response": "Run command in interpreter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dir(self, objtxt):\r\n        obj, valid = self._eval(objtxt)\r\n        if valid:\r\n            return getobjdir(obj)", "response": "Return dir for object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_arglist(self, objtxt):\r\n        obj, valid = self._eval(objtxt)\r\n        if valid:\r\n            return getargtxt(obj)", "response": "Get func / method argument list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_doc(self, objtxt):\r\n        obj, valid = self._eval(objtxt)\r\n        if valid:\r\n            return getdoc(obj)", "response": "Get object documentation dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_defined(self, objtxt, force_import=False):\r\n        return self.interpreter.is_defined(objtxt, force_import)", "response": "Return True if object is defined in the current interpreter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef paintEvent(self, event):\n        painter = QPainter(self)\n        size = self.size()\n\n        color = QColor(self.color)\n        color.setAlphaF(.5)\n        painter.setPen(color)\n\n        for column in self.columns:\n            x = self.editor.fontMetrics().width(column * '9')\n            painter.drawLine(x, 0, x, size.height())", "response": "Override Qt method. Draws the event to the QPainter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_columns(self, columns):\n        if isinstance(columns, tuple):\n            self.columns = columns\n        elif is_text_string(columns):\n            self.columns = tuple(int(e) for e in columns.split(','))\n\n        self.update()", "response": "Set edge line columns values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend the args passed to the Spyder executable to the current instance.", "response": "def send_args_to_spyder(args):\r\n    \"\"\"\r\n    Simple socket client used to send the args passed to the Spyder \r\n    executable to an already running instance.\r\n\r\n    Args can be Python scripts or files with these extensions: .spydata, .mat,\r\n    .npy, or .h5, which can be imported by the Variable Explorer.\r\n    \"\"\"\r\n    port = CONF.get('main', 'open_files_port')\r\n\r\n    # Wait ~50 secs for the server to be up\r\n    # Taken from https://stackoverflow.com/a/4766598/438386\r\n    for _x in range(200):\r\n        try:\r\n            for arg in args:\r\n                client = socket.socket(socket.AF_INET, socket.SOCK_STREAM,\r\n                                       socket.IPPROTO_TCP)\r\n                client.connect((\"127.0.0.1\", port))\r\n                if is_unicode(arg):\r\n                    arg = arg.encode('utf-8')\r\n                client.send(osp.abspath(arg))\r\n                client.close()\r\n        except socket.error:\r\n            time.sleep(0.25)\r\n            continue\r\n        break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart Spyder application. If single instance mode is turned on (default behavior) and an instance of Spyder is already running, this will just parse and send command line options to the application.", "response": "def main():\r\n    \"\"\"\r\n    Start Spyder application.\r\n\r\n    If single instance mode is turned on (default behavior) and an instance of\r\n    Spyder is already running, this will just parse and send command line\r\n    options to the application.\r\n    \"\"\"\r\n    # Parse command line options\r\n    if running_under_pytest():\r\n        try:\r\n            from unittest.mock import Mock\r\n        except ImportError:\r\n            from mock import Mock # Python 2\r\n\r\n        options = Mock()\r\n        options.new_instance = False\r\n        options.reset_config_files = False\r\n        options.debug_info = None\r\n        args = None\r\n    else:\r\n        options, args = get_options()\r\n\r\n    # Store variable to be used in self.restart (restart spyder instance)\r\n    os.environ['SPYDER_ARGS'] = str(sys.argv[1:])\r\n\r\n    #==========================================================================\r\n    # Proper high DPI scaling is available in Qt >= 5.6.0. This attibute must\r\n    # be set before creating the application.\r\n    #==========================================================================\r\n    if CONF.get('main', 'high_dpi_custom_scale_factor'):\r\n        factors = str(CONF.get('main', 'high_dpi_custom_scale_factors'))\r\n        f = list(filter(None, factors.split(';')))\r\n        if len(f) == 1:\r\n            os.environ['QT_SCALE_FACTOR'] = f[0]\r\n        else:\r\n            os.environ['QT_SCREEN_SCALE_FACTORS'] = factors\r\n    else:\r\n        os.environ['QT_SCALE_FACTOR'] = ''\r\n        os.environ['QT_SCREEN_SCALE_FACTORS'] = ''\r\n\r\n    if sys.platform == 'darwin':\r\n        # Prevent Spyder from crashing in macOS if locale is not defined\r\n        LANG = os.environ.get('LANG')\r\n        LC_ALL = os.environ.get('LC_ALL')\r\n        if bool(LANG) and not bool(LC_ALL):\r\n            LC_ALL = LANG\r\n        elif not bool(LANG) and bool(LC_ALL):\r\n            LANG = LC_ALL\r\n        else:\r\n            LANG = LC_ALL = 'en_US.UTF-8'\r\n\r\n        os.environ['LANG'] = LANG\r\n        os.environ['LC_ALL'] = LC_ALL\r\n\r\n        # Don't show useless warning in the terminal where Spyder\r\n        # was started\r\n        # See issue 3730\r\n        os.environ['EVENT_NOKQUEUE'] = '1'\r\n    else:\r\n        # Prevent our kernels to crash when Python fails to identify\r\n        # the system locale.\r\n        # Fixes issue 7051.\r\n        try:\r\n            from locale import getlocale\r\n            getlocale()\r\n        except ValueError:\r\n            # This can fail on Windows. See issue 6886\r\n            try:\r\n                os.environ['LANG'] = 'C'\r\n                os.environ['LC_ALL'] = 'C'\r\n            except Exception:\r\n                pass\r\n\r\n    if options.debug_info:\r\n        levels = {'minimal': '2', 'verbose': '3'}\r\n        os.environ['SPYDER_DEBUG'] = levels[options.debug_info]\r\n\r\n    if CONF.get('main', 'single_instance') and not options.new_instance \\\r\n      and not options.reset_config_files and not running_in_mac_app():\r\n        # Minimal delay (0.1-0.2 secs) to avoid that several\r\n        # instances started at the same time step in their\r\n        # own foots while trying to create the lock file\r\n        time.sleep(random.randrange(1000, 2000, 90)/10000.)\r\n\r\n        # Lock file creation\r\n        lock_file = get_conf_path('spyder.lock')\r\n        lock = lockfile.FilesystemLock(lock_file)\r\n\r\n        # Try to lock spyder.lock. If it's *possible* to do it, then\r\n        # there is no previous instance running and we can start a\r\n        # new one. If *not*, then there is an instance already\r\n        # running, which is locking that file\r\n        try:\r\n            lock_created = lock.lock()\r\n        except:\r\n            # If locking fails because of errors in the lockfile\r\n            # module, try to remove a possibly stale spyder.lock.\r\n            # This is reported to solve all problems with\r\n            # lockfile (See issue 2363)\r\n            try:\r\n                if os.name == 'nt':\r\n                    if osp.isdir(lock_file):\r\n                        import shutil\r\n                        shutil.rmtree(lock_file, ignore_errors=True)\r\n                else:\r\n                    if osp.islink(lock_file):\r\n                        os.unlink(lock_file)\r\n            except:\r\n                pass\r\n\r\n            # Then start Spyder as usual and *don't* continue\r\n            # executing this script because it doesn't make\r\n            # sense\r\n            from spyder.app import mainwindow\r\n            if running_under_pytest():\r\n                return mainwindow.main()\r\n            else:\r\n                mainwindow.main()\r\n                return\r\n\r\n        if lock_created:\r\n            # Start a new instance\r\n            from spyder.app import mainwindow\r\n            if running_under_pytest():\r\n                return mainwindow.main()\r\n            else:\r\n                mainwindow.main()\r\n        else:\r\n            # Pass args to Spyder or print an informative\r\n            # message\r\n            if args:\r\n                send_args_to_spyder(args)\r\n            else:\r\n                print(\"Spyder is already running. If you want to open a new \\n\"\r\n                      \"instance, please pass to it the --new-instance option\")\r\n    else:\r\n        from spyder.app import mainwindow\r\n        if running_under_pytest():\r\n            return mainwindow.main()\r\n        else:\r\n            mainwindow.main()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_search_regex(query, ignore_case=True):\n    regex_text = [char for char in query if char != ' ']\n    regex_text = '.*'.join(regex_text)\n\n    regex = r'({0})'.format(regex_text)\n\n    if ignore_case:\n        pattern = re.compile(regex, re.IGNORECASE)\n    else:\n        pattern = re.compile(regex)\n\n    return pattern", "response": "Returns a compiled regex pattern to search for query letters in order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple with the enriched text and the score for the match.", "response": "def get_search_score(query, choice, ignore_case=True, apply_regex=True,\n                     template='{}'):\n    \"\"\"Returns a tuple with the enriched text (if a template is provided) and\n    a score for the match.\n\n    Parameters\n    ----------\n    query : str\n        String with letters to search in choice (in order of appearance).\n    choice : str\n        Sentence/words in which to search for the 'query' letters.\n    ignore_case : bool, optional\n        Optional value perform a case insensitive search (True by default).\n    apply_regex : bool, optional\n        Optional value (True by default) to perform a regex search. Useful\n        when this function is called directly.\n    template : str, optional\n        Optional template string to surround letters found in choices. This is\n        useful when using a rich text editor ('{}' by default).\n        Examples: '<b>{}</b>', '<code>{}</code>', '<i>{}</i>'\n\n    Returns\n    -------\n    results : tuple\n        Tuples where the first item is the text (enriched if a template was\n        used) and the second item is a search score.\n\n    Notes\n    -----\n    The score is given according the following precedence (high to low):\n\n    - Letters in one word and no spaces with exact match.\n      Example: 'up' in 'up stroke'\n    - Letters in one word and no spaces with partial match.\n      Example: 'up' in 'upstream stroke'\n    - Letters in one word but with skip letters.\n      Example: 'cls' in 'close up'\n    - Letters in two or more words\n      Example: 'cls' in 'car lost'\n    \"\"\"\n    original_choice = choice\n    result = (original_choice, NOT_FOUND_SCORE)\n\n    # Handle empty string case\n    if not query:\n        return result\n\n    if ignore_case:\n        query = query.lower()\n        choice = choice.lower()\n\n    if apply_regex:\n        pattern = get_search_regex(query, ignore_case=ignore_case)\n        r = re.search(pattern, choice)\n        if r is None:\n            return result\n    else:\n        sep = u'-'  # Matches will be replaced by this character\n        let = u'x'  # Nonmatches (except spaed) will be replaced by this\n        score = 0\n\n        exact_words = [query == word for word in choice.split(u' ')]\n        partial_words = [query in word for word in choice.split(u' ')]\n\n        if any(exact_words) or any(partial_words):\n            pos_start = choice.find(query)\n            pos_end = pos_start + len(query)\n            score += pos_start\n            text = choice.replace(query, sep*len(query), 1)\n\n            enriched_text = original_choice[:pos_start] +\\\n                template.format(original_choice[pos_start:pos_end]) +\\\n                original_choice[pos_end:]\n\n        if any(exact_words):\n            # Check if the query words exists in a word with exact match\n            score += 1\n        elif any(partial_words):\n            # Check if the query words exists in a word with partial match\n            score += 100\n        else:\n            # Check letter by letter\n            text = [l for l in original_choice]\n            if ignore_case:\n                temp_text = [l.lower() for l in original_choice]\n            else:\n                temp_text = text[:]\n\n            # Give points to start of string\n            score += temp_text.index(query[0])\n\n            # Find the query letters and replace them by `sep`, also apply\n            # template as needed for enricching the letters in the text\n            enriched_text = text[:]\n            for char in query:\n                if char != u'' and char in temp_text:\n                    index = temp_text.index(char)\n                    enriched_text[index] = template.format(text[index])\n                    text[index] = sep\n                    temp_text = [u' ']*(index + 1) + temp_text[index+1:]\n\n        enriched_text = u''.join(enriched_text)\n\n        patterns_text = []\n        for i, char in enumerate(text):\n            if char != u' ' and char != sep:\n                new_char = let\n            else:\n                new_char = char\n            patterns_text.append(new_char)\n        patterns_text = u''.join(patterns_text)\n        for i in reversed(range(1, len(query) + 1)):\n            score += (len(query) - patterns_text.count(sep*i))*100000\n\n        temp = patterns_text.split(sep)\n        while u'' in temp:\n            temp.remove(u'')\n        if not patterns_text.startswith(sep):\n            temp = temp[1:]\n        if not patterns_text.endswith(sep):\n            temp = temp[:-1]\n\n        for pat in temp:\n            score += pat.count(u' ')*10000\n            score += pat.count(let)*100\n\n    return original_choice, enriched_text, score"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for query inside choices and return a list of tuples where the first item is the enriched text and the score is a better match.", "response": "def get_search_scores(query, choices, ignore_case=True, template='{}',\n                      valid_only=False, sort=False):\n    \"\"\"Search for query inside choices and return a list of tuples.\n\n    Returns a list of tuples of text with the enriched text (if a template is\n    provided) and a score for the match. Lower scores imply a better match.\n\n    Parameters\n    ----------\n    query : str\n        String with letters to search in each choice (in order of appearance).\n    choices : list of str\n        List of sentences/words in which to search for the 'query' letters.\n    ignore_case : bool, optional\n        Optional value perform a case insensitive search (True by default).\n    template : str, optional\n        Optional template string to surround letters found in choices. This is\n        useful when using a rich text editor ('{}' by default).\n        Examples: '<b>{}</b>', '<code>{}</code>', '<i>{}</i>'\n\n    Returns\n    -------\n    results : list of tuples\n        List of tuples where the first item is the text (enriched if a\n        template was used) and a search score. Lower scores means better match.\n    \"\"\"\n    # First remove spaces from query\n    query = query.replace(' ', '')\n    pattern = get_search_regex(query, ignore_case)\n    results = []\n\n    for choice in choices:\n        r = re.search(pattern, choice)\n        if query and r:\n            result = get_search_score(query, choice, ignore_case=ignore_case,\n                                      apply_regex=False, template=template)\n        else:\n            if query:\n                result = (choice, choice, NOT_FOUND_SCORE)\n            else:\n                result = (choice, choice, NO_SCORE)\n\n        if valid_only:\n            if result[-1] != NOT_FOUND_SCORE:\n                results.append(result)\n        else:\n            results.append(result)\n\n    if sort:\n        results = sorted(results, key=lambda row: row[-1])\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if text is the beginning of the function definition.", "response": "def is_start_of_function(text):\r\n    \"\"\"Return True if text is the beginning of the function definition.\"\"\"\r\n    if isinstance(text, str) or isinstance(text, unicode):\r\n        function_prefix = ['def', 'async def']\r\n        text = text.lstrip()\r\n\r\n        for prefix in function_prefix:\r\n            if text.startswith(prefix):\r\n                return True\r\n\r\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_indent(text):\r\n    indent = ''\r\n\r\n    ret = re.match(r'(\\s*)', text)\r\n    if ret:\r\n        indent = ret.group(1)\r\n\r\n    return indent", "response": "Get indent of text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_function_definition_from_first_line(self):\r\n        document = self.code_editor.document()\r\n        cursor = QTextCursor(\r\n            document.findBlockByLineNumber(self.line_number_cursor - 1))\r\n\r\n        func_text = ''\r\n        func_indent = ''\r\n\r\n        is_first_line = True\r\n        line_number = cursor.blockNumber() + 1\r\n\r\n        number_of_lines = self.code_editor.blockCount()\r\n        remain_lines = number_of_lines - line_number + 1\r\n        number_of_lines_of_function = 0\r\n\r\n        for __ in range(min(remain_lines, 20)):\r\n            cur_text = to_text_string(cursor.block().text()).rstrip()\r\n\r\n            if is_first_line:\r\n                if not is_start_of_function(cur_text):\r\n                    return None\r\n\r\n                func_indent = get_indent(cur_text)\r\n                is_first_line = False\r\n            else:\r\n                cur_indent = get_indent(cur_text)\r\n                if cur_indent <= func_indent:\r\n                    return None\r\n                if is_start_of_function(cur_text):\r\n                    return None\r\n                if cur_text.strip == '':\r\n                    return None\r\n\r\n            if cur_text[-1] == '\\\\':\r\n                cur_text = cur_text[:-1]\r\n\r\n            func_text += cur_text\r\n            number_of_lines_of_function += 1\r\n\r\n            if cur_text.endswith(':'):\r\n                return func_text, number_of_lines_of_function\r\n\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n\r\n        return None", "response": "Get function definition when the cursor is located on the first def line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets func def when the cursor is located below the last line.", "response": "def get_function_definition_from_below_last_line(self):\r\n        \"\"\"Get func def when the cursor is located below the last def line.\"\"\"\r\n        cursor = self.code_editor.textCursor()\r\n        func_text = ''\r\n        is_first_line = True\r\n        line_number = cursor.blockNumber() + 1\r\n        number_of_lines_of_function = 0\r\n\r\n        for idx in range(min(line_number, 20)):\r\n            if cursor.block().blockNumber() == 0:\r\n                return None\r\n\r\n            cursor.movePosition(QTextCursor.PreviousBlock)\r\n            prev_text = to_text_string(cursor.block().text()).rstrip()\r\n\r\n            if is_first_line:\r\n                if not prev_text.endswith(':'):\r\n                    return None\r\n                is_first_line = False\r\n            elif prev_text.endswith(':') or prev_text == '':\r\n                return None\r\n\r\n            if prev_text[-1] == '\\\\':\r\n                prev_text = prev_text[:-1]\r\n\r\n            func_text = prev_text + func_text\r\n\r\n            number_of_lines_of_function += 1\r\n            if is_start_of_function(prev_text):\r\n                return func_text, number_of_lines_of_function\r\n\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_function_body(self, func_indent):\r\n        cursor = self.code_editor.textCursor()\r\n        line_number = cursor.blockNumber() + 1\r\n        number_of_lines = self.code_editor.blockCount()\r\n        body_list = []\r\n\r\n        for idx in range(number_of_lines - line_number + 1):\r\n            text = to_text_string(cursor.block().text())\r\n            text_indent = get_indent(text)\r\n\r\n            if text.strip() == '':\r\n                pass\r\n            elif len(text_indent) <= len(func_indent):\r\n                break\r\n\r\n            body_list.append(text)\r\n\r\n            cursor.movePosition(QTextCursor.NextBlock)\r\n\r\n        return '\\n'.join(body_list)", "response": "Get the function body text."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite docstring to editor.", "response": "def write_docstring(self):\r\n        \"\"\"Write docstring to editor.\"\"\"\r\n        line_to_cursor = self.code_editor.get_text('sol', 'cursor')\r\n        if self.is_beginning_triple_quotes(line_to_cursor):\r\n            cursor = self.code_editor.textCursor()\r\n            prev_pos = cursor.position()\r\n\r\n            quote = line_to_cursor[-1]\r\n            docstring_type = CONF.get('editor', 'docstring_type')\r\n            docstring = self._generate_docstring(docstring_type, quote)\r\n\r\n            if docstring:\r\n                self.code_editor.insert_text(docstring)\r\n\r\n                cursor = self.code_editor.textCursor()\r\n                cursor.setPosition(prev_pos, QTextCursor.KeepAnchor)\r\n                cursor.movePosition(QTextCursor.NextBlock)\r\n                cursor.movePosition(QTextCursor.EndOfLine,\r\n                                    QTextCursor.KeepAnchor)\r\n                cursor.clearSelection()\r\n                self.code_editor.setTextCursor(cursor)\r\n                return True\r\n\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite docstring to editor at mouse position.", "response": "def write_docstring_at_first_line_of_function(self):\r\n        \"\"\"Write docstring to editor at mouse position.\"\"\"\r\n        result = self.get_function_definition_from_first_line()\r\n        editor = self.code_editor\r\n        if result:\r\n            func_text, number_of_line_func = result\r\n            line_number_function = (self.line_number_cursor +\r\n                                    number_of_line_func - 1)\r\n\r\n            cursor = editor.textCursor()\r\n            line_number_cursor = cursor.blockNumber() + 1\r\n            offset = line_number_function - line_number_cursor\r\n            if offset > 0:\r\n                for __ in range(offset):\r\n                    cursor.movePosition(QTextCursor.NextBlock)\r\n            else:\r\n                for __ in range(abs(offset)):\r\n                    cursor.movePosition(QTextCursor.PreviousBlock)\r\n            cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.MoveAnchor)\r\n            editor.setTextCursor(cursor)\r\n\r\n            indent = get_indent(func_text)\r\n            editor.insert_text('\\n{}{}\"\"\"'.format(indent, editor.indent_chars))\r\n            self.write_docstring()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_docstring_for_shortcut(self):\r\n        # cursor placed below function definition\r\n        result = self.get_function_definition_from_below_last_line()\r\n        if result is not None:\r\n            __, number_of_lines_of_function = result\r\n            cursor = self.code_editor.textCursor()\r\n            for __ in range(number_of_lines_of_function):\r\n                cursor.movePosition(QTextCursor.PreviousBlock)\r\n\r\n            self.code_editor.setTextCursor(cursor)\r\n\r\n        cursor = self.code_editor.textCursor()\r\n        self.line_number_cursor = cursor.blockNumber() + 1\r\n\r\n        self.write_docstring_at_first_line_of_function()", "response": "Write docstring to editor by shortcut of code editor."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a docstring of numpy type.", "response": "def _generate_numpy_doc(self, func_info):\r\n        \"\"\"Generate a docstring of numpy type.\"\"\"\r\n        numpy_doc = ''\r\n\r\n        arg_names = func_info.arg_name_list\r\n        arg_types = func_info.arg_type_list\r\n        arg_values = func_info.arg_value_list\r\n\r\n        if len(arg_names) > 0 and arg_names[0] == 'self':\r\n            del arg_names[0]\r\n            del arg_types[0]\r\n            del arg_values[0]\r\n\r\n        indent1 = func_info.func_indent + self.code_editor.indent_chars\r\n        indent2 = func_info.func_indent + self.code_editor.indent_chars * 2\r\n\r\n        numpy_doc += '\\n{}\\n'.format(indent1)\r\n\r\n        if len(arg_names) > 0:\r\n            numpy_doc += '\\n{}Parameters'.format(indent1)\r\n            numpy_doc += '\\n{}----------\\n'.format(indent1)\r\n\r\n        arg_text = ''\r\n        for arg_name, arg_type, arg_value in zip(arg_names, arg_types,\r\n                                                 arg_values):\r\n            arg_text += '{}{} : '.format(indent1, arg_name)\r\n            if arg_type:\r\n                arg_text += '{}'.format(arg_type)\r\n            else:\r\n                arg_text += 'TYPE'\r\n\r\n            if arg_value:\r\n                arg_text += ', optional'\r\n\r\n            arg_text += '\\n{}DESCRIPTION.'.format(indent2)\r\n\r\n            if arg_value:\r\n                arg_value = arg_value.replace(self.quote3, self.quote3_other)\r\n                arg_text += ' The default is {}.'.format(arg_value)\r\n\r\n            arg_text += '\\n'\r\n\r\n        numpy_doc += arg_text\r\n\r\n        if func_info.raise_list:\r\n            numpy_doc += '\\n{}Raises'.format(indent1)\r\n            numpy_doc += '\\n{}------'.format(indent1)\r\n            for raise_type in func_info.raise_list:\r\n                numpy_doc += '\\n{}{}'.format(indent1, raise_type)\r\n                numpy_doc += '\\n{}DESCRIPTION.'.format(indent2)\r\n            numpy_doc += '\\n'\r\n\r\n        numpy_doc += '\\n'\r\n        if func_info.has_yield:\r\n            header = '{0}Yields\\n{0}------\\n'.format(indent1)\r\n        else:\r\n            header = '{0}Returns\\n{0}-------\\n'.format(indent1)\r\n\r\n        return_type_annotated = func_info.return_type_annotated\r\n        if return_type_annotated:\r\n            return_section = '{}{}{}'.format(header, indent1,\r\n                                             return_type_annotated)\r\n            return_section += '\\n{}DESCRIPTION.'.format(indent2)\r\n        else:\r\n            return_element_type = indent1 + '{return_type}\\n' + indent2 + \\\r\n                'DESCRIPTION.'\r\n            placeholder = return_element_type.format(return_type='TYPE')\r\n            return_element_name = indent1 + '{return_name} : ' + \\\r\n                placeholder.lstrip()\r\n\r\n            try:\r\n                return_section = self._generate_docstring_return_section(\r\n                    func_info.return_value_in_body, header,\r\n                    return_element_name, return_element_type, placeholder,\r\n                    indent1)\r\n            except (ValueError, IndexError):\r\n                return_section = '{}{}None.'.format(header, indent1)\r\n\r\n        numpy_doc += return_section\r\n        numpy_doc += '\\n\\n{}{}'.format(indent1, self.quote3)\r\n\r\n        return numpy_doc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_top_level_bracket_locations(string_toparse):\r\n        bracket_stack = []\r\n        replace_args_list = []\r\n        bracket_type = None\r\n        literal_type = ''\r\n        brackets = {'(': ')', '[': ']', '{': '}'}\r\n        for idx, character in enumerate(string_toparse):\r\n            if (not bracket_stack and character in brackets.keys()\r\n                    or character == bracket_type):\r\n                bracket_stack.append(idx)\r\n                bracket_type = character\r\n            elif bracket_type and character == brackets[bracket_type]:\r\n                begin_idx = bracket_stack.pop()\r\n                if not bracket_stack:\r\n                    if not literal_type:\r\n                        if bracket_type == '(':\r\n                            literal_type = '(None)'\r\n                        elif bracket_type == '[':\r\n                            literal_type = '[list]'\r\n                        elif bracket_type == '{':\r\n                            if idx - begin_idx <= 1:\r\n                                literal_type = '{dict}'\r\n                            else:\r\n                                literal_type = '{set}'\r\n                    replace_args_list.append(\r\n                        (string_toparse[begin_idx:idx + 1],\r\n                         literal_type, 1))\r\n                    bracket_type = None\r\n                    literal_type = ''\r\n            elif len(bracket_stack) == 1:\r\n                if bracket_type == '(' and character == ',':\r\n                    literal_type = '(tuple)'\r\n                elif bracket_type == '{' and character == ':':\r\n                    literal_type = '{dict}'\r\n                elif bracket_type == '(' and character == ':':\r\n                    literal_type = '[slice]'\r\n\r\n        if bracket_stack:\r\n            raise IndexError('Bracket mismatch')\r\n        for replace_args in replace_args_list:\r\n            string_toparse = string_toparse.replace(*replace_args)\r\n        return string_toparse", "response": "Get the locations of top - level brackets in a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_return_elements(return_vals_group, return_element_name,\r\n                              return_element_type, placeholder):\r\n        \"\"\"Return the appropriate text for a group of return elements.\"\"\"\r\n        all_eq = (return_vals_group.count(return_vals_group[0])\r\n                  == len(return_vals_group))\r\n        if all([{'[list]', '(tuple)', '{dict}', '{set}'}.issuperset(\r\n                return_vals_group)]) and all_eq:\r\n            return return_element_type.format(\r\n                return_type=return_vals_group[0][1:-1])\r\n        # Output placeholder if special Python chars present in name\r\n        py_chars = {' ', '+', '-', '*', '/', '%', '@', '<', '>', '&', '|', '^',\r\n                    '~', '=', ',', ':', ';', '#', '(', '[', '{', '}', ']',\r\n                    ')', }\r\n        if any([any([py_char in return_val for py_char in py_chars])\r\n                for return_val in return_vals_group]):\r\n            return placeholder\r\n        # Output str type and no name if only string literals\r\n        if all(['\"' in return_val or '\\'' in return_val\r\n                for return_val in return_vals_group]):\r\n            return return_element_type.format(return_type='str')\r\n        # Output bool type and no name if only bool literals\r\n        if {'True', 'False'}.issuperset(return_vals_group):\r\n            return return_element_type.format(return_type='bool')\r\n        # Output numeric types and no name if only numeric literals\r\n        try:\r\n            [float(return_val) for return_val in return_vals_group]\r\n            num_not_int = 0\r\n            for return_val in return_vals_group:\r\n                try:\r\n                    int(return_val)\r\n                except ValueError:  # If not an integer (EAFP)\r\n                    num_not_int = num_not_int + 1\r\n            if num_not_int == 0:\r\n                return return_element_type.format(return_type='int')\r\n            elif num_not_int == len(return_vals_group):\r\n                return return_element_type.format(return_type='float')\r\n            else:\r\n                return return_element_type.format(return_type='numeric')\r\n        except ValueError:  # Not a numeric if float conversion didn't work\r\n            pass\r\n        # If names are not equal, don't contain \".\" or are a builtin\r\n        if ({'self', 'cls', 'None'}.isdisjoint(return_vals_group) and all_eq\r\n                and all(['.' not in return_val\r\n                         for return_val in return_vals_group])):\r\n            return return_element_name.format(return_name=return_vals_group[0])\r\n        return placeholder", "response": "Parse a group of return elements into a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the docstring for a function or method returns section.", "response": "def _generate_docstring_return_section(self, return_vals, header,\r\n                                           return_element_name,\r\n                                           return_element_type,\r\n                                           placeholder, indent):\r\n        \"\"\"Generate the Returns section of a function/method docstring.\"\"\"\r\n        # If all return values are None, return none\r\n        non_none_vals = [return_val for return_val in return_vals\r\n                         if return_val and return_val != 'None']\r\n        if not non_none_vals:\r\n            return header + indent + 'None.'\r\n\r\n        # Get only values with matching brackets that can be cleaned up\r\n        non_none_vals = [return_val.strip(' ()\\t\\n').rstrip(',')\r\n                         for return_val in non_none_vals]\r\n        non_none_vals = [re.sub('([\\\"\\'])(?:(?=(\\\\\\\\?))\\\\2.)*?\\\\1',\r\n                                '\"string\"', return_val)\r\n                         for return_val in non_none_vals]\r\n        unambiguous_vals = []\r\n        for return_val in non_none_vals:\r\n            try:\r\n                cleaned_val = self.find_top_level_bracket_locations(return_val)\r\n            except IndexError:\r\n                continue\r\n            unambiguous_vals.append(cleaned_val)\r\n        if not unambiguous_vals:\r\n            return header + placeholder\r\n\r\n        # If remaining are a mix of tuples and not, return single placeholder\r\n        single_vals, tuple_vals = [], []\r\n        for return_val in unambiguous_vals:\r\n            (tuple_vals.append(return_val) if ',' in return_val\r\n             else single_vals.append(return_val))\r\n        if single_vals and tuple_vals:\r\n            return header + placeholder\r\n\r\n        # If return values are tuples of different length, return a placeholder\r\n        if tuple_vals:\r\n            num_elements = [return_val.count(',') + 1\r\n                            for return_val in tuple_vals]\r\n            if num_elements.count(num_elements[0]) != len(num_elements):\r\n                return header + placeholder\r\n            num_elements = num_elements[0]\r\n        else:\r\n            num_elements = 1\r\n\r\n        # If all have the same len but some ambiguous return that placeholders\r\n        if len(unambiguous_vals) != len(non_none_vals):\r\n            return header + '\\n'.join(\r\n                [placeholder for __ in range(num_elements)])\r\n\r\n        # Handle tuple (or single) values position by position\r\n        return_vals_grouped = zip(*[\r\n            [return_element.strip() for return_element in\r\n             return_val.split(',')]\r\n            for return_val in unambiguous_vals])\r\n        return_elements_out = []\r\n        for return_vals_group in return_vals_grouped:\r\n            return_elements_out.append(\r\n                self.parse_return_elements(return_vals_group,\r\n                                           return_element_name,\r\n                                           return_element_type,\r\n                                           placeholder))\r\n\r\n        return header + '\\n'.join(return_elements_out)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_char_in_pairs(pos_char, pairs):\r\n        for pos_left, pos_right in pairs.items():\r\n            if pos_left < pos_char < pos_right:\r\n                return True\r\n\r\n        return False", "response": "Return True if the charactor is in pairs of brackets or quotes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_quote_position(text):\r\n        pos = {}\r\n        is_found_left_quote = False\r\n\r\n        for idx, character in enumerate(text):\r\n            if is_found_left_quote is False:\r\n                if character == \"'\" or character == '\"':\r\n                    is_found_left_quote = True\r\n                    quote = character\r\n                    left_pos = idx\r\n            else:\r\n                if character == quote and text[idx - 1] != '\\\\':\r\n                    pos[left_pos] = idx\r\n                    is_found_left_quote = False\r\n\r\n        if is_found_left_quote:\r\n            raise IndexError(\"No matching close quote at: \" + str(left_pos))\r\n\r\n        return pos", "response": "Find the start and end position of pairs of quotes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_bracket_position(self, text, bracket_left, bracket_right,\r\n                               pos_quote):\r\n        \"\"\"Return the start and end position of pairs of brackets.\r\n\r\n        https://stackoverflow.com/questions/29991917/\r\n        indices-of-matching-parentheses-in-python\r\n        \"\"\"\r\n        pos = {}\r\n        pstack = []\r\n\r\n        for idx, character in enumerate(text):\r\n            if character == bracket_left and \\\r\n                    not self.is_char_in_pairs(idx, pos_quote):\r\n                pstack.append(idx)\r\n            elif character == bracket_right and \\\r\n                    not self.is_char_in_pairs(idx, pos_quote):\r\n                if len(pstack) == 0:\r\n                    raise IndexError(\r\n                        \"No matching closing parens at: \" + str(idx))\r\n                pos[pstack.pop()] = idx\r\n\r\n        if len(pstack) > 0:\r\n            raise IndexError(\r\n                \"No matching opening parens at: \" + str(pstack.pop()))\r\n\r\n        return pos", "response": "Find the start and end position of pairs of brackets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting argument text to name type value.", "response": "def split_arg_to_name_type_value(self, args_list):\r\n        \"\"\"Split argument text to name, type, value.\"\"\"\r\n        for arg in args_list:\r\n            arg_type = None\r\n            arg_value = None\r\n\r\n            has_type = False\r\n            has_value = False\r\n\r\n            pos_colon = arg.find(':')\r\n            pos_equal = arg.find('=')\r\n\r\n            if pos_equal > -1:\r\n                has_value = True\r\n\r\n            if pos_colon > -1:\r\n                if not has_value:\r\n                    has_type = True\r\n                elif pos_equal > pos_colon:  # exception for def foo(arg1=\":\")\r\n                    has_type = True\r\n\r\n            if has_value and has_type:\r\n                arg_name = arg[0:pos_colon].strip()\r\n                arg_type = arg[pos_colon + 1:pos_equal].strip()\r\n                arg_value = arg[pos_equal + 1:].strip()\r\n            elif not has_value and has_type:\r\n                arg_name = arg[0:pos_colon].strip()\r\n                arg_type = arg[pos_colon + 1:].strip()\r\n            elif has_value and not has_type:\r\n                arg_name = arg[0:pos_equal].strip()\r\n                arg_value = arg[pos_equal + 1:].strip()\r\n            else:\r\n                arg_name = arg.strip()\r\n\r\n            self.arg_name_list.append(arg_name)\r\n            self.arg_type_list.append(arg_type)\r\n            self.arg_value_list.append(arg_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_args_text_to_list(self, args_text):\r\n        args_list = []\r\n        idx_find_start = 0\r\n        idx_arg_start = 0\r\n\r\n        try:\r\n            pos_quote = self._find_quote_position(args_text)\r\n            pos_round = self._find_bracket_position(args_text, '(', ')',\r\n                                                    pos_quote)\r\n            pos_curly = self._find_bracket_position(args_text, '{', '}',\r\n                                                    pos_quote)\r\n            pos_square = self._find_bracket_position(args_text, '[', ']',\r\n                                                     pos_quote)\r\n        except IndexError:\r\n            return None\r\n\r\n        while True:\r\n            pos_comma = args_text.find(',', idx_find_start)\r\n\r\n            if pos_comma == -1:\r\n                break\r\n\r\n            idx_find_start = pos_comma + 1\r\n\r\n            if self.is_char_in_pairs(pos_comma, pos_round) or \\\r\n                    self.is_char_in_pairs(pos_comma, pos_curly) or \\\r\n                    self.is_char_in_pairs(pos_comma, pos_square) or \\\r\n                    self.is_char_in_pairs(pos_comma, pos_quote):\r\n                continue\r\n\r\n            args_list.append(args_text[idx_arg_start:pos_comma])\r\n            idx_arg_start = pos_comma + 1\r\n\r\n        if idx_arg_start < len(args_text):\r\n            args_list.append(args_text[idx_arg_start:])\r\n\r\n        return args_list", "response": "Split the text including multiple arguments to list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_def(self, text):\r\n        self.__init__()\r\n\r\n        if not is_start_of_function(text):\r\n            return\r\n\r\n        self.func_indent = get_indent(text)\r\n\r\n        text = text.strip()\r\n        text = text.replace('\\r\\n', '')\r\n        text = text.replace('\\n', '')\r\n\r\n        return_type_re = re.search(r'->[ ]*([a-zA-Z0-9_,()\\[\\] ]*):$', text)\r\n        if return_type_re:\r\n            self.return_type_annotated = return_type_re.group(1)\r\n            text_end = text.rfind(return_type_re.group(0))\r\n        else:\r\n            self.return_type_annotated = None\r\n            text_end = len(text)\r\n\r\n        pos_args_start = text.find('(') + 1\r\n        pos_args_end = text.rfind(')', pos_args_start, text_end)\r\n\r\n        self.args_text = text[pos_args_start:pos_args_end]\r\n\r\n        args_list = self.split_args_text_to_list(self.args_text)\r\n        if args_list is not None:\r\n            self.has_info = True\r\n            self.split_arg_to_name_type_value(args_list)", "response": "Parse the function definition text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the function body text.", "response": "def parse_body(self, text):\r\n        \"\"\"Parse the function body text.\"\"\"\r\n        re_raise = re.findall(r'[ \\t]raise ([a-zA-Z0-9_]*)', text)\r\n        if len(re_raise) > 0:\r\n            self.raise_list = [x.strip() for x in re_raise]\r\n            # remove duplicates from list while keeping it in the order\r\n            # in python 2.7\r\n            # stackoverflow.com/questions/7961363/removing-duplicates-in-lists\r\n            self.raise_list = list(OrderedDict.fromkeys(self.raise_list))\r\n\r\n        re_yield = re.search(r'[ \\t]yield ', text)\r\n        if re_yield:\r\n            self.has_yield = True\r\n\r\n        # get return value\r\n        pattern_return = r'return |yield '\r\n        line_list = text.split('\\n')\r\n        is_found_return = False\r\n        line_return_tmp = ''\r\n\r\n        for line in line_list:\r\n            line = line.strip()\r\n\r\n            if is_found_return is False:\r\n                if re.match(pattern_return, line):\r\n                    is_found_return = True\r\n\r\n            if is_found_return:\r\n                line_return_tmp += line\r\n                # check the integrity of line\r\n                try:\r\n                    pos_quote = self._find_quote_position(line_return_tmp)\r\n\r\n                    if line_return_tmp[-1] == '\\\\':\r\n                        line_return_tmp = line_return_tmp[:-1]\r\n                        continue\r\n\r\n                    self._find_bracket_position(line_return_tmp, '(', ')',\r\n                                                pos_quote)\r\n                    self._find_bracket_position(line_return_tmp, '{', '}',\r\n                                                pos_quote)\r\n                    self._find_bracket_position(line_return_tmp, '[', ']',\r\n                                                pos_quote)\r\n                except IndexError:\r\n                    continue\r\n\r\n                return_value = re.sub(pattern_return, '', line_return_tmp)\r\n                self.return_value_in_body.append(return_value)\r\n\r\n                is_found_return = False\r\n                line_return_tmp = ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclosing the instance if key is not enter key.", "response": "def keyPressEvent(self, event):\r\n        \"\"\"Close the instance if key is not enter key.\"\"\"\r\n        key = event.key()\r\n        if key not in (Qt.Key_Enter, Qt.Key_Return):\r\n            self.code_editor.keyPressEvent(event)\r\n            self.close()\r\n        else:\r\n            super(QMenuOnlyForEnter, self).keyPressEvent(event)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a process is running on windows systems based on the pid.", "response": "def _is_pid_running_on_windows(pid):\r\n    \"\"\"Check if a process is running on windows systems based on the pid.\"\"\"\r\n    pid = str(pid)\r\n\r\n    # Hide flashing command prompt\r\n    startupinfo = subprocess.STARTUPINFO()\r\n    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\r\n\r\n    process = subprocess.Popen(r'tasklist /fi \"PID eq {0}\"'.format(pid),\r\n                               stdout=subprocess.PIPE,\r\n                               stderr=subprocess.STDOUT,\r\n                               startupinfo=startupinfo)\r\n    stdoutdata, stderrdata = process.communicate()\r\n    stdoutdata = to_text_string(stdoutdata)\r\n    process.kill()\r\n    check = pid in stdoutdata\r\n\r\n    return check"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _show_message(self, text):\r\n        self.splash.showMessage(text, Qt.AlignBottom | Qt.AlignCenter |\r\n                                Qt.AlignAbsolute, QColor(Qt.white))", "response": "Show message on splash screen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nanimating dots at the end of the splash screen message.", "response": "def animate_ellipsis(self):\r\n        \"\"\"Animate dots at the end of the splash screen message.\"\"\"\r\n        ellipsis = self.ellipsis.pop(0)\r\n        text = ' '*len(ellipsis) + self.splash_text + ellipsis\r\n        self.ellipsis.append(ellipsis)\r\n        self._show_message(text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the text in the bottom of the Splash screen.", "response": "def set_splash_message(self, text):\r\n        \"\"\"Sets the text in the bottom of the Splash screen.\"\"\"\r\n        self.splash_text = text\r\n        self._show_message(text)\r\n        self.timer_ellipsis.start(500)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef launch_error_message(self, error_type, error=None):\r\n        messages = {CLOSE_ERROR: _(\"It was not possible to close the previous \"\r\n                                   \"Spyder instance.\\nRestart aborted.\"),\r\n                    RESET_ERROR: _(\"Spyder could not reset to factory \"\r\n                                   \"defaults.\\nRestart aborted.\"),\r\n                    RESTART_ERROR: _(\"It was not possible to restart Spyder.\\n\"\r\n                                     \"Operation aborted.\")}\r\n        titles = {CLOSE_ERROR: _(\"Spyder exit error\"),\r\n                  RESET_ERROR: _(\"Spyder reset error\"),\r\n                  RESTART_ERROR: _(\"Spyder restart error\")}\r\n\r\n        if error:\r\n            e = error.__repr__()\r\n            message = messages[error_type] + \"\\n\\n{0}\".format(e)\r\n        else:\r\n            message = messages[error_type]\r\n\r\n        title = titles[error_type]\r\n        self.splash.hide()\r\n        QMessageBox.warning(self, title, message, QMessageBox.Ok)\r\n        raise RuntimeError(message)", "response": "Launch a message box with a predefined error message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of actions related to the plugin", "response": "def get_plugin_actions(self):\r\n        \"\"\"Return a list of actions related to plugin\"\"\"\r\n        self.history_action = create_action(self, _(\"History...\"),\r\n                                       None, ima.icon('history'),\r\n                                       _(\"Set history maximum entries\"),\r\n                                       triggered=self.change_history_depth)\r\n        self.wrap_action = create_action(self, _(\"Wrap lines\"),\r\n                                    toggled=self.toggle_wrap_mode)\r\n        self.wrap_action.setChecked( self.get_option('wrap') )\r\n        self.linenumbers_action = create_action(\r\n                self, _(\"Show line numbers\"), toggled=self.toggle_line_numbers)\r\n        self.linenumbers_action.setChecked(self.get_option('line_numbers'))\r\n\r\n        menu_actions = [self.history_action, self.wrap_action,\r\n                        self.linenumbers_action]\r\n        return menu_actions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.focus_changed.connect(self.main.plugin_focus_changed)\r\n        self.main.add_dockwidget(self)\r\n#        self.main.console.set_historylog(self)\r\n        self.main.console.shell.refresh.connect(self.refresh_plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates font from preferences", "response": "def update_font(self):\r\n        \"\"\"Update font from Preferences\"\"\"\r\n        color_scheme = self.get_color_scheme()\r\n        font = self.get_plugin_font()\r\n        for editor in self.editors:\r\n            editor.set_font(font, color_scheme)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies configuration file s plugin settings to the current configuration file s editor settings.", "response": "def apply_plugin_settings(self, options):\r\n        \"\"\"Apply configuration file's plugin settings\"\"\"\r\n        color_scheme_n = 'color_scheme_name'\r\n        color_scheme_o = self.get_color_scheme()\r\n        font_n = 'plugin_font'\r\n        font_o = self.get_plugin_font()\r\n        wrap_n = 'wrap'\r\n        wrap_o = self.get_option(wrap_n)\r\n        self.wrap_action.setChecked(wrap_o)\r\n        linenb_n = 'line_numbers'\r\n        linenb_o = self.get_option(linenb_n)\r\n        for editor in self.editors:\r\n            if font_n in options:\r\n                scs = color_scheme_o if color_scheme_n in options else None\r\n                editor.set_font(font_o, scs)\r\n            elif color_scheme_n in options:\r\n                editor.set_color_scheme(color_scheme_o)\r\n            if wrap_n in options:\r\n                editor.toggle_wrap_mode(wrap_o)\r\n            if linenb_n in options:\r\n                editor.toggle_line_numbers(linenumbers=linenb_o, markers=False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_history(self, filename):\r\n        filename = encoding.to_unicode_from_fs(filename)\r\n        if filename in self.filenames:\r\n            return\r\n        editor = codeeditor.CodeEditor(self)\r\n        if osp.splitext(filename)[1] == '.py':\r\n            language = 'py'\r\n        else:\r\n            language = 'bat'\r\n        editor.setup_editor(linenumbers=self.get_option('line_numbers'),\r\n                            language=language,\r\n                            scrollflagarea=False)\r\n        editor.focus_changed.connect(lambda: self.focus_changed.emit())\r\n        editor.setReadOnly(True)\r\n        color_scheme = self.get_color_scheme()\r\n        editor.set_font( self.get_plugin_font(), color_scheme )\r\n        editor.toggle_wrap_mode( self.get_option('wrap') )\r\n\r\n        # Avoid a possible error when reading the history file\r\n        try:\r\n            text, _ = encoding.read(filename)\r\n        except (IOError, OSError):\r\n            text = \"# Previous history could not be read from disk, sorry\\n\\n\"\r\n        text = normalize_eols(text)\r\n        linebreaks = [m.start() for m in re.finditer('\\n', text)]\r\n        maxNline = self.get_option('max_entries')\r\n        if len(linebreaks) > maxNline:\r\n            text = text[linebreaks[-maxNline - 1] + 1:]\r\n            # Avoid an error when trying to write the trimmed text to\r\n            # disk.\r\n            # See issue 9093\r\n            try:\r\n                encoding.write(text, filename)\r\n            except (IOError, OSError):\r\n                pass\r\n        editor.set_text(text)\r\n        editor.set_cursor_position('eof')\r\n\r\n        self.editors.append(editor)\r\n        self.filenames.append(filename)\r\n        index = self.tabwidget.addTab(editor, osp.basename(filename))\r\n        self.find_widget.set_editor(editor)\r\n        self.tabwidget.setTabToolTip(index, filename)\r\n        self.tabwidget.setCurrentIndex(index)", "response": "Add new history tab\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef document_did_save_notification(self, params):\n        text = None\n        if 'text' in params:\n            text = params['text']\n        params = {\n            'textDocument': {\n                'uri': path_as_uri(params['file'])\n            }\n        }\n        if text is not None:\n            params['text'] = text\n        return params", "response": "Handle the textDocument / didSave notification received from an LSP server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverloading method to handle links ourselves", "response": "def acceptNavigationRequest(self, url, navigation_type, isMainFrame):\r\n        \"\"\"\r\n        Overloaded method to handle links ourselves\r\n        \"\"\"\r\n        if navigation_type == QWebEnginePage.NavigationTypeLinkClicked:\r\n            self.linkClicked.emit(url)\r\n            return False\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding text in the page.", "response": "def find_text(self, text, changed=True,\r\n                  forward=True, case=False, words=False,\r\n                  regexp=False):\r\n        \"\"\"Find text\"\"\"\r\n        if not WEBENGINE:\r\n            findflag = QWebEnginePage.FindWrapsAroundDocument\r\n        else:\r\n            findflag = 0\r\n\r\n        if not forward:\r\n            findflag = findflag | QWebEnginePage.FindBackward\r\n        if case:\r\n            findflag = findflag | QWebEnginePage.FindCaseSensitively\r\n\r\n        return self.findText(text, QWebEnginePage.FindFlags(findflag))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply zoom factor to the related object.", "response": "def apply_zoom_factor(self):\r\n        \"\"\"Apply zoom factor\"\"\"\r\n        if hasattr(self, 'setZoomFactor'):\r\n            # Assuming Qt >=v4.5\r\n            self.setZoomFactor(self.zoom_factor)\r\n        else:\r\n            # Qt v4.4\r\n            self.setTextSizeMultiplier(self.zoom_factor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setHtml(self, html, baseUrl=QUrl()):\r\n        if WEBENGINE:\r\n            self.setEnabled(False)\r\n            super(WebView, self).setHtml(html, baseUrl)\r\n            self.setEnabled(True)\r\n        else:\r\n            super(WebView, self).setHtml(html, baseUrl)", "response": "Override Qt method to set html on the WebView."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef go_to(self, url_or_text):\r\n        if is_text_string(url_or_text):\r\n            url = QUrl(url_or_text)\r\n        else:\r\n            url = url_or_text\r\n        self.webview.load(url)", "response": "Go to page address or text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload URL from combo box first item", "response": "def url_combo_activated(self, valid):\r\n        \"\"\"Load URL from combo box first item\"\"\"\r\n        text = to_text_string(self.url_combo.currentText())\r\n        self.go_to(self.text_to_url(text))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize plugin: connect signals, setup actions, etc. It must be run at the end of __init__", "response": "def initialize_plugin(self):\n        \"\"\"\n        Initialize plugin: connect signals, setup actions, etc.\n\n        It must be run at the end of __init__\n        \"\"\"\n        self.create_toggle_view_action()\n\n        self.plugin_actions = self.get_plugin_actions() + [MENU_SEPARATOR,\n                                                           self.undock_action]\n        add_actions(self.options_menu, self.plugin_actions)\n        self.options_button.setMenu(self.options_menu)\n        self.options_menu.aboutToShow.connect(self.refresh_actions)\n\n        self.sig_show_message.connect(self.show_message)\n        self.sig_update_plugin_title.connect(self.update_plugin_title)\n        self.sig_option_changed.connect(self.set_option)\n        self.setWindowTitle(self.get_plugin_title())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters QAction or QShortcut to Spyder main application.", "response": "def register_shortcut(self, qaction_or_qshortcut, context, name,\n                          add_sc_to_tip=False):\n        \"\"\"\n        Register QAction or QShortcut to Spyder main application.\n\n        if add_sc_to_tip is True, the shortcut is added to the\n        action's tooltip\n        \"\"\"\n        self.main.register_shortcut(qaction_or_qshortcut, context,\n                                    name, add_sc_to_tip)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_widget_shortcuts(self, widget):\n        for qshortcut, context, name in widget.get_shortcut_data():\n            self.register_shortcut(qshortcut, context, name)", "response": "Register widget shortcuts.\n\n        Widget interface must have a method called 'get_shortcut_data'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visibility_changed(self, enable):\n        if self.dockwidget is None:\n            return\n        if enable:\n            self.dockwidget.raise_()\n            widget = self.get_focus_widget()\n            if widget is not None and self.undocked_window is not None:\n                widget.setFocus()\n        visible = self.dockwidget.isVisible() or self.ismaximized\n        if self.DISABLE_ACTIONS_WHEN_HIDDEN:\n            toggle_actions(self.plugin_actions, visible)\n        self.isvisible = enable and visible\n        if self.isvisible:\n            self.refresh_plugin()", "response": "Check if the visibility of the dock widget has changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a plugin option in configuration file.", "response": "def set_option(self, option, value):\n        \"\"\"\n        Set a plugin option in configuration file.\n\n        Note: Use sig_option_changed to call it from widgets of the\n              same or another plugin.\n        \"\"\"\n        CONF.set(self.CONF_SECTION, str(option), value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef starting_long_process(self, message):\n        self.show_message(message)\n        QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))\n        QApplication.processEvents()", "response": "Show message in main window s status bar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ending_long_process(self, message=\"\"):\n        QApplication.restoreOverrideCursor()\n        self.show_message(message, timeout=2000)\n        QApplication.processEvents()", "response": "This method is called when the main window is ending long process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh the actions list for the current instance of the class.", "response": "def refresh_actions(self):\n        \"\"\"\n        Create options menu.\n        \"\"\"\n        self.options_menu.clear()\n\n        # Decide what additional actions to show\n        if self.undocked_window is None:\n            additional_actions = [MENU_SEPARATOR,\n                                  self.undock_action,\n                                  self.close_plugin_action]\n        else:\n            additional_actions = [MENU_SEPARATOR,\n                                  self.dock_action]\n\n        # Create actions list\n        self.plugin_actions = self.get_plugin_actions() + additional_actions\n        add_actions(self.options_menu, self.plugin_actions)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keyPressEvent(self, event):\n        event, text, key, ctrl, shift = restore_keyevent(event)\n        if key == Qt.Key_ParenLeft and not self.has_selected_text() \\\n          and self.help_enabled and not self.parent()._reading:\n            self._key_paren_left(text)\n        else:\n            # Let the parent widget handle the key press event\n            QTextEdit.keyPressEvent(self, event)", "response": "Reimplement Qt Method - Basic keypress event handler"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef focusInEvent(self, event):\n        self.focus_changed.emit()\n        return super(PageControlWidget, self).focusInEvent(event)", "response": "Reimplement Qt method to send focus change notification"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the screen resolution of the primary screen.", "response": "def get_screen_resolution(self):\n        \"\"\"Return the screen resolution of the primary screen.\"\"\"\n        widget = QDesktopWidget()\n        geometry = widget.availableGeometry(widget.primaryScreen())\n        return geometry.width(), geometry.height()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the currently visible fig_browser in the stack widget and refresh the actions of the cog menu button and move it to the layout of the current widget.", "response": "def set_current_widget(self, fig_browser):\n        \"\"\"\n        Set the currently visible fig_browser in the stack widget, refresh the\n        actions of the cog menu button and move it to the layout of the new\n        fig_browser.\n        \"\"\"\n        self.stack.setCurrentWidget(fig_browser)\n        # We update the actions of the options button (cog menu) and\n        # we move it to the layout of the current widget.\n        self.refresh_actions()\n        fig_browser.setup_options_button()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister shell with figure explorer. This function opens a new FigureBrowser for browsing the figures in the shell.", "response": "def add_shellwidget(self, shellwidget):\n        \"\"\"\n        Register shell with figure explorer.\n\n        This function opens a new FigureBrowser for browsing the figures\n        in the shell.\n        \"\"\"\n        shellwidget_id = id(shellwidget)\n        if shellwidget_id not in self.shellwidgets:\n            self.options_button.setVisible(True)\n            fig_browser = FigureBrowser(\n                self, options_button=self.options_button,\n                background_color=MAIN_BG_COLOR)\n            fig_browser.set_shellwidget(shellwidget)\n            fig_browser.setup(**self.get_settings())\n            fig_browser.sig_option_changed.connect(\n                self.sig_option_changed.emit)\n            fig_browser.thumbnails_sb.redirect_stdio.connect(\n                self.main.redirect_internalshell_stdio)\n            self.register_widget_shortcuts(fig_browser)\n            self.add_widget(fig_browser)\n            self.shellwidgets[shellwidget_id] = fig_browser\n            self.set_shellwidget_from_id(shellwidget_id)\n            return fig_browser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply configuration file s plugin settings", "response": "def apply_plugin_settings(self, options):\n        \"\"\"Apply configuration file's plugin settings\"\"\"\n        for fig_browser in list(self.shellwidgets.values()):\n            fig_browser.setup(**self.get_settings())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flags(self, index):\r\n        if not index.isValid():\r\n            return Qt.ItemIsEnabled\r\n        column = index.column()\r\n        if column in [0]:\r\n            return Qt.ItemFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable |\r\n                                Qt.ItemIsUserCheckable | Qt.ItemIsEditable)\r\n        else:\r\n            return Qt.ItemFlags(Qt.ItemIsEnabled)", "response": "Override Qt method to return the flags of the item with the given index"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noverrides Qt method to return the data in the given role", "response": "def data(self, index, role=Qt.DisplayRole):\r\n        \"\"\"Override Qt method\"\"\"\r\n        if not index.isValid() or not 0 <= index.row() < len(self._rows):\r\n            return to_qvariant()\r\n        row = index.row()\r\n        column = index.column()\r\n\r\n        name, state = self.row(row)\r\n\r\n        if role == Qt.DisplayRole or role == Qt.EditRole:\r\n            if column == 0:\r\n                return to_qvariant(name)\r\n        elif role == Qt.CheckStateRole:\r\n            if column == 0:\r\n                if state:\r\n                    return Qt.Checked\r\n                else:\r\n                    return Qt.Unchecked\r\n            if column == 1:\r\n                return to_qvariant(state)\r\n        return to_qvariant()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setData(self, index, value, role):\r\n        row = index.row()\r\n        name, state = self.row(row)\r\n\r\n        if role == Qt.CheckStateRole:\r\n            self.set_row(row, [name, not state])\r\n            self._parent.setCurrentIndex(index)\r\n            self._parent.setFocus()\r\n            self.dataChanged.emit(index, index)\r\n            return True\r\n        elif role == Qt.EditRole:\r\n            self.set_row(row, [from_qvariant(value, to_text_string), state])\r\n            self.dataChanged.emit(index, index)\r\n            return True\r\n        return True", "response": "Override Qt method to set the data for the related object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisable empty layout name possibility", "response": "def check_text(self, text):\r\n        \"\"\"Disable empty layout name possibility\"\"\"\r\n        if to_text_string(text) == u'':\r\n            self.button_ok.setEnabled(False)\r\n        else:\r\n            self.button_ok.setEnabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef temp_fail_retry(error, fun, *args):\r\n    while 1:\r\n        try:\r\n            return fun(*args)\r\n        except error as e:\r\n            eintr = errno.WSAEINTR if os.name == 'nt' else errno.EINTR\r\n            if e.args[0] == eintr:\r\n                continue\r\n            raise", "response": "Retry to execute a function ignoring EINTR error."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_packet(sock, data, already_pickled=False):\r\n    if already_pickled:\r\n        sent_data = data\r\n    else:\r\n        sent_data = pickle.dumps(data, PICKLE_HIGHEST_PROTOCOL)\r\n    sent_data = struct.pack(\"l\", len(sent_data)) + sent_data\r\n    nsend = len(sent_data)\r\n    while nsend > 0:\r\n        nsend -= temp_fail_retry(socket.error, sock.send, sent_data)", "response": "Write data to socket sock."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_packet(sock, timeout=None):\r\n    sock.settimeout(timeout)\r\n    dlen, data = None, None\r\n    try:\r\n        if os.name == 'nt':\r\n            #  Windows implementation\r\n            datalen = sock.recv(SZ)\r\n            dlen, = struct.unpack(\"l\", datalen)\r\n            data = b''\r\n            while len(data) < dlen:\r\n                data += sock.recv(dlen)\r\n        else:\r\n            #  Linux/MacOSX implementation\r\n            #  Thanks to eborisch:\r\n            #  See issue 1106\r\n            datalen = temp_fail_retry(socket.error, sock.recv,\r\n                                      SZ, socket.MSG_WAITALL)\r\n            if len(datalen) == SZ:\r\n                dlen, = struct.unpack(\"l\", datalen)\r\n                data = temp_fail_retry(socket.error, sock.recv,\r\n                                       dlen, socket.MSG_WAITALL)\r\n    except socket.timeout:\r\n        raise\r\n    except socket.error:\r\n        data = None\r\n    finally:\r\n        sock.settimeout(None)\r\n    if data is not None:\r\n        try:\r\n            return pickle.loads(data)\r\n        except Exception:\r\n            # Catch all exceptions to avoid locking spyder\r\n            if DEBUG_EDITOR:\r\n                traceback.print_exc(file=STDERR)\r\n            return", "response": "Reads a packet from socket sock and returns it as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gettime_s(text):\r\n    pattern = r'([+-]?\\d+\\.?\\d*) ?([munsecinh]+)'\r\n    matches = re.findall(pattern, text)\r\n    if len(matches) == 0:\r\n        return None\r\n    time = 0.\r\n    for res in matches:\r\n        tmp = float(res[0])\r\n        if res[1] == 'ns':\r\n            tmp *= 1e-9\r\n        elif res[1] == 'us':\r\n            tmp *= 1e-6\r\n        elif res[1] == 'ms':\r\n            tmp *= 1e-3\r\n        elif res[1] == 'min':\r\n            tmp *= 60\r\n        elif res[1] == 'h':\r\n            tmp *= 3600\r\n        time += tmp\r\n    return time", "response": "Parse a string and return a time in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples where the first element is the number of words in the sequence n.", "response": "def primes(n):\r\n    \"\"\"\r\n    Simple test function\r\n    Taken from http://www.huyng.com/posts/python-performance-analysis/\r\n    \"\"\"\r\n    if n==2:\r\n        return [2]\r\n    elif n<2:\r\n        return []\r\n    s=list(range(3,n+1,2))\r\n    mroot = n ** 0.5\r\n    half=(n+1)//2-1\r\n    i=0\r\n    m=3\r\n    while m <= mroot:\r\n        if s[i]:\r\n            j=(m*m-3)//2\r\n            s[j]=0\r\n            while j<half:\r\n                s[j]=0\r\n                j+=m\r\n        i=i+1\r\n        m=2*i+3\r\n    return [2]+[x for x in s if x]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_data(self):\r\n        title = _( \"Save profiler result\")\r\n        filename, _selfilter = getsavefilename(\r\n                self, title, getcwd_or_home(),\r\n                _(\"Profiler result\")+\" (*.Result)\")\r\n        if filename:\r\n            self.datatree.save_data(filename)", "response": "Save data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_item_data(self, item, filename, line_number):\r\n        set_item_user_text(item, '%s%s%d' % (filename, self.SEP, line_number))", "response": "Set tree item user data filename and line number"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget tree item user data", "response": "def get_item_data(self, item):\r\n        \"\"\"Get tree item user data: (filename, line_number)\"\"\"\r\n        filename, line_number_str = get_item_user_text(item).split(self.SEP)\r\n        return filename, int(line_number_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_view(self):\r\n        self.clear()\r\n        self.item_depth = 0   # To be use for collapsing/expanding one level\r\n        self.item_list = []  # To be use for collapsing/expanding one level\r\n        self.items_to_be_shown = {}\r\n        self.current_view_depth = 0", "response": "Clean the tree and view parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_data(self, profdatafile):\r\n        import pstats\r\n        try:\r\n            stats_indi = [pstats.Stats(profdatafile), ]\r\n        except (OSError, IOError):\r\n            return\r\n        self.profdata = stats_indi[0]\r\n        \r\n        if self.compare_file is not None:\r\n            try:\r\n                stats_indi.append(pstats.Stats(self.compare_file))\r\n            except (OSError, IOError) as e:\r\n                QMessageBox.critical(\r\n                    self, _(\"Error\"),\r\n                    _(\"Error when trying to load profiler results\"))\r\n                logger.debug(\"Error when calling pstats, {}\".format(e))\r\n                self.compare_file = None\r\n        map(lambda x: x.calc_callees(), stats_indi)\r\n        self.profdata.calc_callees()\r\n        self.stats1 = stats_indi\r\n        self.stats = stats_indi[0].stats", "response": "Load profiler data saved by profile module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a function without a caller", "response": "def find_root(self):\r\n        \"\"\"Find a function without a caller\"\"\"\r\n        self.profdata.sort_stats(\"cumulative\")\r\n        for func in self.profdata.fcn_list:\r\n            if ('~', 0) != func[0:2] and not func[2].startswith(\r\n                    '<built-in method exec>'):\r\n                # This skips the profiler function at the top of the list\r\n                # it does only occur in Python 3\r\n                return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_tree(self):\r\n        self.initialize_view() # Clear before re-populating\r\n        self.setItemsExpandable(True)\r\n        self.setSortingEnabled(False)\r\n        rootkey = self.find_root()  # This root contains profiler overhead\r\n        if rootkey:\r\n            self.populate_tree(self, self.find_callees(rootkey))\r\n            self.resizeColumnToContents(0)\r\n            self.setSortingEnabled(True)\r\n            self.sortItems(1, Qt.AscendingOrder) # FIXME: hardcoded index\r\n            self.change_view(1)", "response": "Populate the tree with profiler data and display it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef function_info(self, functionKey):\r\n        node_type = 'function'\r\n        filename, line_number, function_name = functionKey\r\n        if function_name == '<module>':\r\n            modulePath, moduleName = osp.split(filename)\r\n            node_type = 'module'\r\n            if moduleName == '__init__.py':\r\n                modulePath, moduleName = osp.split(modulePath)\r\n            function_name = '<' + moduleName + '>'\r\n        if not filename or filename == '~':\r\n            file_and_line = '(built-in)'\r\n            node_type = 'builtin'\r\n        else:\r\n            if function_name == '__init__':\r\n                node_type = 'constructor'                \r\n            file_and_line = '%s : %d' % (filename, line_number)\r\n        return filename, line_number, function_name, file_and_line, node_type", "response": "Returns processed information about the function s name and file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets format and units for data coming from profiler task.", "response": "def format_measure(measure):\r\n        \"\"\"Get format and units for data coming from profiler task.\"\"\"\r\n        # Convert to a positive value.\r\n        measure = abs(measure)\r\n\r\n        # For number of calls\r\n        if isinstance(measure, int):\r\n            return to_text_string(measure)\r\n\r\n        # For time measurements\r\n        if 1.e-9 < measure <= 1.e-6:\r\n            measure = u\"{0:.2f} ns\".format(measure / 1.e-9)\r\n        elif 1.e-6 < measure <= 1.e-3:\r\n            measure = u\"{0:.2f} us\".format(measure / 1.e-6)\r\n        elif 1.e-3 < measure <= 1:\r\n            measure = u\"{0:.2f} ms\".format(measure / 1.e-3)\r\n        elif 1 < measure <= 60:\r\n            measure = u\"{0:.2f} sec\".format(measure)\r\n        elif 60 < measure <= 3600:\r\n            m, s = divmod(measure, 3600)\r\n            if s > 60:\r\n                m, s = divmod(measure, 60)\r\n                s = to_text_string(s).split(\".\")[-1]\r\n            measure = u\"{0:.0f}.{1:.2s} min\".format(m, s)\r\n        else:\r\n            h, m = divmod(measure, 3600)\r\n            if m > 60:\r\n                m /= 60\r\n            measure = u\"{0:.0f}h:{1:.0f}min\".format(h, m)\r\n        return measure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string formatted delta for the values in x.", "response": "def color_string(self, x):\r\n        \"\"\"Return a string formatted delta for the values in x.\r\n\r\n        Args:\r\n            x: 2-item list of integers (representing number of calls) or\r\n               2-item list of floats (representing seconds of runtime).\r\n\r\n        Returns:\r\n            A list with [formatted x[0], [color, formatted delta]], where\r\n            color reflects whether x[1] is lower, greater, or the same as\r\n            x[0].\r\n        \"\"\"\r\n        diff_str = \"\"\r\n        color = \"black\"\r\n\r\n        if len(x) == 2 and self.compare_file is not None:\r\n            difference = x[0] - x[1]\r\n            if difference:\r\n                color, sign = ('green', '-') if difference < 0 else ('red', '+')\r\n                diff_str = '{}{}'.format(sign, self.format_measure(difference))\r\n        return [self.format_measure(x[0]), [diff_str, color]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the output of the format_output method.", "response": "def format_output(self, child_key):\r\n        \"\"\" Formats the data.\r\n\r\n        self.stats1 contains a list of one or two pstat.Stats() instances, with\r\n        the first being the current run and the second, the saved run, if it\r\n        exists.  Each Stats instance is a dictionary mapping a function to\r\n        5 data points - cumulative calls, number of calls, total time,\r\n        cumulative time, and callers.\r\n\r\n        format_output() converts the number of calls, total time, and\r\n        cumulative time to a string format for the child_key parameter.\r\n        \"\"\"\r\n        data = [x.stats.get(child_key, [0, 0, 0, 0, {}]) for x in self.stats1]\r\n        return (map(self.color_string, islice(zip(*data), 1, 4)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_recursive(self, child_item):\r\n        ancestor = child_item.parent()\r\n        # FIXME: indexes to data should be defined by a dictionary on init\r\n        while ancestor:\r\n            if (child_item.data(0, Qt.DisplayRole\r\n                                ) == ancestor.data(0, Qt.DisplayRole) and\r\n                child_item.data(7, Qt.DisplayRole\r\n                                ) == ancestor.data(7, Qt.DisplayRole)):\r\n                return True\r\n            else:\r\n                ancestor = ancestor.parent()\r\n        return False", "response": "Returns True is a function is a descendant of itself."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_items(self, maxlevel):\r\n        itemlist = []\r\n        def add_to_itemlist(item, maxlevel, level=1):\r\n            level += 1\r\n            for index in range(item.childCount()):\r\n                citem = item.child(index)\r\n                itemlist.append(citem)\r\n                if level <= maxlevel:\r\n                    add_to_itemlist(citem, maxlevel, level)\r\n        for tlitem in self.get_top_level_items():\r\n            itemlist.append(tlitem)\r\n            if maxlevel > 0:\r\n                add_to_itemlist(tlitem, maxlevel=maxlevel)\r\n        return itemlist", "response": "Return all items with a level > = maxlevel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the view depth by expand or collapsing all same - level nodes", "response": "def change_view(self, change_in_depth):\r\n        \"\"\"Change the view depth by expand or collapsing all same-level nodes\"\"\"\r\n        self.current_view_depth += change_in_depth\r\n        if self.current_view_depth < 0:\r\n            self.current_view_depth = 0\r\n        self.collapseAll()\r\n        if self.current_view_depth > 0:\r\n            for item in self.get_items(maxlevel=self.current_view_depth-1):\r\n                item.setExpanded(True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a QSS stylesheet with the given color scheme settings.", "response": "def create_qss_style(color_scheme):\n    \"\"\"Returns a QSS stylesheet with Spyder color scheme settings.\n\n    The stylesheet can contain classes for:\n        Qt: QPlainTextEdit, QFrame, QWidget, etc\n       Pygments: .c, .k, .o, etc. (see PygmentsHighlighter)\n        IPython: .error, .in-prompt, .out-prompt, etc\n    \"\"\"\n\n    def give_font_weight(is_bold):\n        if is_bold:\n            return 'bold'\n        else:\n            return 'normal'\n\n    def give_font_style(is_italic):\n        if is_italic:\n            return 'italic'\n        else:\n            return 'normal'\n\n    color_scheme = get_color_scheme(color_scheme)\n    fon_c, fon_fw, fon_fs = color_scheme['normal']\n    font_color =  fon_c\n    if dark_color(font_color):\n        in_prompt_color = 'navy'\n        out_prompt_color = 'darkred'\n    else:\n        in_prompt_color = 'lime'\n        out_prompt_color = 'red'\n    background_color = color_scheme['background']\n    error_color = 'red'\n    in_prompt_number_font_weight = 'bold'\n    out_prompt_number_font_weight = 'bold'\n    inverted_background_color = font_color\n    inverted_font_color = background_color\n\n    sheet = \"\"\"QPlainTextEdit, QTextEdit, ControlWidget {{\n                                          color: {} ;\n                                          background-color: {};\n                                         }}\n              .error {{ color: {}; }}\n              .in-prompt {{ color: {}; }}\n              .in-prompt-number {{ color: {}; font-weight: {}; }}\n              .out-prompt {{ color: {}; }}\n              .out-prompt-number {{ color: {}; font-weight: {}; }}\n              .inverted {{ color: {}; background-color: {}; }}\n              \"\"\"\n\n    sheet_formatted = sheet.format(font_color, background_color,\n                                   error_color,\n                                   in_prompt_color, in_prompt_color,\n                                   in_prompt_number_font_weight,\n                                   out_prompt_color, out_prompt_color,\n                                   out_prompt_number_font_weight,\n                                   inverted_background_color,\n                                   inverted_font_color)\n\n    return (sheet_formatted, dark_color(font_color))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_pygments_dict(color_scheme_name):\n\n    def give_font_weight(is_bold):\n        if is_bold:\n            return 'bold'\n        else:\n            return ''\n\n    def give_font_style(is_italic):\n        if is_italic:\n            return 'italic'\n        else:\n            return ''\n\n    color_scheme = get_color_scheme(color_scheme_name)\n\n    fon_c, fon_fw, fon_fs = color_scheme['normal']\n    font_color =  fon_c\n    font_font_weight = give_font_weight(fon_fw)\n    font_font_style = give_font_style(fon_fs)\n    key_c, key_fw, key_fs = color_scheme['keyword']\n    keyword_color =  key_c\n    keyword_font_weight = give_font_weight(key_fw)\n    keyword_font_style = give_font_style(key_fs)\n    bui_c, bui_fw, bui_fs = color_scheme['builtin']\n    builtin_color =  bui_c\n    builtin_font_weight = give_font_weight(bui_fw)\n    builtin_font_style = give_font_style(bui_fs)\n    str_c, str_fw, str_fs = color_scheme['string']\n    string_color =  str_c\n    string_font_weight = give_font_weight(str_fw)\n    string_font_style = give_font_style(str_fs)\n    num_c, num_fw, num_fs = color_scheme['number']\n    number_color =  num_c\n    number_font_weight = give_font_weight(num_fw)\n    number_font_style = give_font_style(num_fs)\n    com_c, com_fw, com_fs = color_scheme['comment']\n    comment_color =  com_c\n    comment_font_weight = give_font_weight(com_fw)\n    comment_font_style = give_font_style(com_fs)\n    def_c, def_fw, def_fs = color_scheme['definition']\n    definition_color =  def_c\n    definition_font_weight = give_font_weight(def_fw)\n    definition_font_style = give_font_style(def_fs)\n    ins_c, ins_fw, ins_fs = color_scheme['instance']\n    instance_color =  ins_c\n    instance_font_weight = give_font_weight(ins_fw)\n    instance_font_style = give_font_style(ins_fs)\n\n    font_token = font_font_style + ' ' + font_font_weight + ' ' + font_color\n    definition_token = (definition_font_style + ' ' + definition_font_weight +\n                        ' ' + definition_color)\n    builtin_token = (builtin_font_style + ' ' + builtin_font_weight + ' ' +\n                     builtin_color)\n    instance_token = (instance_font_style + ' ' + instance_font_weight + ' ' +\n                      instance_color)\n    keyword_token = (keyword_font_style + ' ' + keyword_font_weight + ' ' +\n                     keyword_color)\n    comment_token = (comment_font_style + ' ' + comment_font_weight + ' ' +\n                     comment_color)\n    string_token = (string_font_style + ' ' + string_font_weight + ' ' +\n                    string_color)\n    number_token = (number_font_style + ' ' + number_font_weight + ' ' +\n                    number_color)\n\n    syntax_style_dic = {Name: font_token.strip(),\n                        Name.Class: definition_token.strip(),\n                        Name.Function: definition_token.strip(),\n                        Name.Builtin: builtin_token.strip(),\n                        Name.Builtin.Pseudo: instance_token.strip(),\n                        Keyword: keyword_token.strip(),\n                        Keyword.Type: builtin_token.strip(),\n                        Comment: comment_token.strip(),\n                        String: string_token.strip(),\n                        Number: number_token.strip(),\n                        Punctuation: font_token.strip(),\n                        Operator.Word: keyword_token.strip()}\n\n    return syntax_style_dic", "response": "Create a dictionary that saves the given color scheme as a\n    Pygments style."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __remove_pyc_pyo(fname):\r\n    if osp.splitext(fname)[1] == '.py':\r\n        for ending in ('c', 'o'):\r\n            if osp.exists(fname+ending):\r\n                os.remove(fname+ending)", "response": "Eventually remove. pyc and. pyo files associated to a Python script"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_file(source, dest):\r\n    import shutil\r\n    shutil.copy(source, dest)\r\n    remove_file(source)", "response": "Move file from source to dest."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef onerror(function, path, excinfo):\r\n    if not os.access(path, os.W_OK):\r\n        # Is the error an access error?\r\n        os.chmod(path, stat.S_IWUSR)\r\n        function(path)\r\n    else:\r\n        raise", "response": "Error handler for\r\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind and return a non used port", "response": "def select_port(default_port=20128):\r\n    \"\"\"Find and return a non used port\"\"\"\r\n    import socket\r\n    while True:\r\n        try:\r\n            sock = socket.socket(socket.AF_INET,\r\n                                 socket.SOCK_STREAM,\r\n                                 socket.IPPROTO_TCP)\r\n#            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\r\n            sock.bind( (\"127.0.0.1\", default_port) )\r\n        except socket.error as _msg:  # analysis:ignore\r\n            default_port += 1\r\n        else:\r\n            break\r\n        finally:\r\n            sock.close()\r\n            sock = None\r\n    return default_port"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn number of source code lines for all files in path ending with extensions and excluded_dirnames.", "response": "def count_lines(path, extensions=None, excluded_dirnames=None):\r\n    \"\"\"Return number of source code lines for all filenames in subdirectories\r\n    of *path* with names ending with *extensions*\r\n    Directory names *excluded_dirnames* will be ignored\"\"\"\r\n    if extensions is None:\r\n        extensions = ['.py', '.pyw', '.ipy', '.enaml', '.c', '.h', '.cpp',\r\n                      '.hpp', '.inc', '.', '.hh', '.hxx', '.cc', '.cxx',\r\n                      '.cl', '.f', '.for', '.f77', '.f90', '.f95', '.f2k',\r\n                      '.f03', '.f08']\r\n    if excluded_dirnames is None:\r\n        excluded_dirnames = ['build', 'dist', '.hg', '.svn']\r\n    def get_filelines(path):\r\n        dfiles, dlines = 0, 0\r\n        if osp.splitext(path)[1] in extensions:\r\n            dfiles = 1\r\n            with open(path, 'rb') as textfile:\r\n                dlines = len(textfile.read().strip().splitlines())\r\n        return dfiles, dlines\r\n    lines = 0\r\n    files = 0\r\n    if osp.isdir(path):\r\n        for dirpath, dirnames, filenames in os.walk(path):\r\n            for d in dirnames[:]:\r\n                if d in excluded_dirnames:\r\n                    dirnames.remove(d)\r\n            if excluded_dirnames is None or \\\r\n               osp.dirname(dirpath) not in excluded_dirnames:\r\n                for fname in filenames:\r\n                    dfiles, dlines = get_filelines(osp.join(dirpath, fname))\r\n                    files += dfiles\r\n                    lines += dlines\r\n    else:\r\n        dfiles, dlines = get_filelines(path)\r\n        files += dfiles\r\n        lines += dlines\r\n    return files, lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove backslashes in path", "response": "def remove_backslashes(path):\r\n    \"\"\"Remove backslashes in *path*\r\n\r\n    For Windows platforms only.\r\n    Returns the path unchanged on other platforms.\r\n\r\n    This is especially useful when formatting path strings on\r\n    Windows platforms for which folder paths may contain backslashes\r\n    and provoke unicode decoding errors in Python 3 (or in Python 2\r\n    when future 'unicode_literals' symbol has been imported).\"\"\"\r\n    if os.name == 'nt':\r\n        # Removing trailing single backslash\r\n        if path.endswith('\\\\') and not path.endswith('\\\\\\\\'):\r\n            path = path[:-1]\r\n        # Replacing backslashes by slashes\r\n        path = path.replace('\\\\', '/')\r\n        path = path.replace('/\\'', '\\\\\\'')\r\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef monkeypatch_method(cls, patch_name):\r\n    # This function's code was inspired from the following thread:\r\n    # \"[Python-Dev] Monkeypatching idioms -- elegant or ugly?\"\r\n    # by Robert Brewer <fumanchu at aminus.org>\r\n    # (Tue Jan 15 19:13:25 CET 2008)\r\n    \"\"\"\r\n    Add the decorated method to the given class; replace as needed.\r\n\r\n    If the named method already exists on the given class, it will\r\n    be replaced, and a reference to the old method is created as\r\n    cls._old<patch_name><name>. If the \"_old_<patch_name>_<name>\" attribute\r\n    already exists, KeyError is raised.\r\n    \"\"\"\r\n    def decorator(func):\r\n        fname = func.__name__\r\n        old_func = getattr(cls, fname, None)\r\n        if old_func is not None:\r\n            # Add the old func to a list of old funcs.\r\n            old_ref = \"_old_%s_%s\" % (patch_name, fname)\r\n\r\n            old_attr = getattr(cls, old_ref, None)\r\n            if old_attr is None:\r\n                setattr(cls, old_ref, old_func)\r\n            else:\r\n                raise KeyError(\"%s.%s already exists.\"\r\n                               % (cls.__name__, old_ref))\r\n        setattr(cls, fname, func)\r\n        return func\r\n    return decorator", "response": "Monkeypatch the named method on the given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the common path for all paths in pathlist", "response": "def get_common_path(pathlist):\r\n    \"\"\"Return common path for all paths in pathlist\"\"\"\r\n    common = osp.normpath(osp.commonprefix(pathlist))\r\n    if len(common) > 1:\r\n        if not osp.isdir(common):\r\n            return abspardir(common)\r\n        else:\r\n            for path in pathlist:\r\n                if not osp.isdir(osp.join(common, path[len(common)+1:])):\r\n                    # `common` is not the real common prefix\r\n                    return abspardir(common)\r\n            else:\r\n                return osp.abspath(common)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string describing why the pattern is invalid.", "response": "def regexp_error_msg(pattern):\r\n    \"\"\"\r\n    Return None if the pattern is a valid regular expression or\r\n    a string describing why the pattern is invalid.\r\n    \"\"\"\r\n    try:\r\n        re.compile(pattern)\r\n    except re.error as e:\r\n        return str(e)\r\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the start and end line of the fold region.", "response": "def get_range(self, ignore_blank_lines=True):\n        \"\"\"\n        Gets the fold region range (start and end line).\n\n        .. note:: Start line do no encompass the trigger line.\n\n        :param ignore_blank_lines: True to ignore blank lines at the end of the\n            scope (the method will rewind to find that last meaningful block\n            that is part of the fold scope).\n        :returns: tuple(int, int)\n        \"\"\"\n        ref_lvl = self.trigger_level\n        first_line = self._trigger.blockNumber()\n        block = self._trigger.next()\n        last_line = block.blockNumber()\n        lvl = self.scope_level\n        if ref_lvl == lvl:  # for zone set programmatically such as imports\n                            # in pyqode.python\n            ref_lvl -= 1\n        while (block.isValid() and\n                TextBlockHelper.get_fold_lvl(block) > ref_lvl):\n            last_line = block.blockNumber()\n            block = block.next()\n\n        if ignore_blank_lines and last_line:\n            block = block.document().findBlockByNumber(last_line)\n            while block.blockNumber() and block.text().strip() == '':\n                block = block.previous()\n                last_line = block.blockNumber()\n        return first_line, last_line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blocks(self, ignore_blank_lines=True):\n        start, end = self.get_range(ignore_blank_lines=ignore_blank_lines)\n        block = self._trigger.next()\n        while block.blockNumber() <= end and block.isValid():\n            yield block\n            block = block.next()", "response": "This generator generates the list of blocks under the fold\n        region. This generator returns the list of blocks that are part of the fold\n        region."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the parent scope.", "response": "def parent(self):\n        \"\"\"\n        Return the parent scope.\n\n        :return: FoldScope or None\n        \"\"\"\n        if TextBlockHelper.get_fold_lvl(self._trigger) > 0 and \\\n                self._trigger.blockNumber():\n            block = self._trigger.previous()\n            ref_lvl = self.trigger_level - 1\n            while (block.blockNumber() and\n                    (not TextBlockHelper.is_fold_trigger(block) or\n                     TextBlockHelper.get_fold_lvl(block) > ref_lvl)):\n                block = block.previous()\n            try:\n                return FoldScope(block)\n            except ValueError:\n                return None\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the scope text.", "response": "def text(self, max_lines=sys.maxsize):\n        \"\"\"\n        Get the scope text, with a possible maximum number of lines.\n\n        :param max_lines: limit the number of lines returned to a maximum.\n        :return: str\n        \"\"\"\n        ret_val = []\n        block = self._trigger.next()\n        _, end = self.get_range()\n        while (block.isValid() and block.blockNumber() <= end and\n               len(ret_val) < max_lines):\n            ret_val.append(block.text())\n            block = block.next()\n        return '\\n'.join(ret_val)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_fold_level(self, prev_block, block):\n        text = block.text()\n        prev_lvl = TextBlockHelper().get_fold_lvl(prev_block)\n        # round down to previous indentation guide to ensure contiguous block\n        # fold level evolution.\n        indent_len = 0\n        if (prev_lvl and prev_block is not None and\n           not self.editor.is_comment(prev_block)):\n            # ignore commented lines (could have arbitary indentation)\n            prev_text = prev_block.text()\n            indent_len = (len(prev_text) - len(prev_text.lstrip())) // prev_lvl\n        if indent_len == 0:\n            indent_len = len(self.editor.indent_chars)\n\n        return (len(text) - len(text.lstrip())) // indent_len", "response": "Detects fold level by looking at the indentation guide."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, extension):\n        logger.debug('adding extension {}'.format(extension.name))\n        self._extensions[extension.name] = extension\n        extension.on_install(self.editor)\n        return extension", "response": "Adds an extension to the editor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving an extension from the editor.", "response": "def remove(self, name_or_klass):\n        \"\"\"\n        Remove a extension from the editor.\n\n        :param name_or_klass: The name (or class) of the extension to remove.\n        :returns: The removed extension.\n        \"\"\"\n        logger.debug('removing extension {}'.format(name_or_klass))\n        extension = self.get(name_or_klass)\n        extension.on_uninstall()\n        self._extensions.pop(extension.name)\n        return extension"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all extensions from the editor.", "response": "def clear(self):\n        \"\"\"\n        Remove all extensions from the editor.\n\n        All extensions are removed fromlist and deleted.\n        \"\"\"\n        while len(self._extensions):\n            key = sorted(list(self._extensions.keys()))[0]\n            self.remove(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an extension by name or class.", "response": "def get(self, name_or_klass):\n        \"\"\"\n        Get a extension by name (or class).\n\n        :param name_or_klass: The name or the class of the extension to get\n        :type name_or_klass: str or type\n        :rtype: spyder.api.mode.EditorExtension\n        \"\"\"\n        if not isinstance(name_or_klass, str):\n            name_or_klass = name_or_klass.__name__\n        return self._extensions[name_or_klass]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset color scheme (foreground and background).", "response": "def set_color_scheme(self, foreground_color, background_color):\n        \"\"\"Set color scheme (foreground and background).\"\"\"\n        if dark_color(foreground_color):\n            self.default_foreground_color = 30\n        else:\n            self.default_foreground_color = 37\n\n        if dark_color(background_color):\n            self.default_background_color = 47\n        else:\n            self.default_background_color = 40"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting font style with the following attributes : foreground_color background_color italic bold and underline and underline.", "response": "def set_style(self):\n        \"\"\"\n        Set font style with the following attributes:\n        'foreground_color', 'background_color', 'italic',\n        'bold' and 'underline'\n        \"\"\"\n        if self.current_format is None:\n            assert self.base_format is not None\n            self.current_format = QTextCharFormat(self.base_format)\n        # Foreground color\n        if self.foreground_color is None:\n            qcolor = self.base_format.foreground()\n        else:\n            cstr = self.ANSI_COLORS[self.foreground_color-30][self.intensity]\n            qcolor = QColor(cstr)\n        self.current_format.setForeground(qcolor)\n        # Background color\n        if self.background_color is None:\n            qcolor = self.base_format.background()\n        else:\n            cstr = self.ANSI_COLORS[self.background_color-40][self.intensity]\n            qcolor = QColor(cstr)\n        self.current_format.setBackground(qcolor)\n\n        font = self.current_format.font()\n        # Italic\n        if self.italic is None:\n            italic = self.base_format.fontItalic()\n        else:\n            italic = self.italic\n        font.setItalic(italic)\n        # Bold\n        if self.bold is None:\n            bold = self.base_format.font().bold()\n        else:\n            bold = self.bold\n        font.setBold(bold)\n        # Underline\n        if self.underline is None:\n            underline = self.base_format.font().underline()\n        else:\n            underline = self.underline\n        font.setUnderline(underline)\n        self.current_format.setFont(font)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset color scheme of the console ( foreground and background.", "response": "def set_color_scheme(self, foreground_color, background_color):\n        \"\"\"Set color scheme of the console (foreground and background).\"\"\"\n        self.ansi_handler.set_color_scheme(foreground_color, background_color)\n\n        background_color = QColor(background_color)\n        foreground_color = QColor(foreground_color)\n\n        self.set_palette(background=background_color,\n                         foreground=foreground_color)\n\n        self.set_pythonshell_font()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_text(self, text):\n        # Eventually this maybe should wrap to insert_text_to if\n        # backspace-handling is required\n        self.textCursor().insertText(text, self.default_style.format)", "response": "Reimplement TextEditBaseWidget method insert_text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend text to the Python shell.", "response": "def append_text_to_shell(self, text, error, prompt):\n        \"\"\"\n        Append text to Python shell\n        In a way, this method overrides the method 'insert_text' when text is\n        inserted at the end of the text widget for a Python shell\n\n        Handles error messages and show blue underlined links\n        Handles ANSI color sequences\n        Handles ANSI FF sequence\n        \"\"\"\n        cursor = self.textCursor()\n        cursor.movePosition(QTextCursor.End)\n        if '\\r' in text:    # replace \\r\\n with \\n\n            text = text.replace('\\r\\n', '\\n')\n            text = text.replace('\\r', '\\n')\n        while True:\n            index = text.find(chr(12))\n            if index == -1:\n                break\n            text = text[index+1:]\n            self.clear()\n        if error:\n            is_traceback = False\n            for text in text.splitlines(True):\n                if (text.startswith('  File')\n                        and not text.startswith('  File \"<')):\n                    is_traceback = True\n                    # Show error links in blue underlined text\n                    cursor.insertText('  ', self.default_style.format)\n                    cursor.insertText(text[2:],\n                                      self.traceback_link_style.format)\n                else:\n                    # Show error/warning messages in red\n                    cursor.insertText(text, self.error_style.format)\n            self.exception_occurred.emit(text, is_traceback)\n        elif prompt:\n            # Show prompt in green\n            insert_text_to(cursor, text, self.prompt_style.format)\n        else:\n            # Show other outputs in black\n            last_end = 0\n            for match in self.COLOR_PATTERN.finditer(text):\n                insert_text_to(cursor, text[last_end:match.start()],\n                               self.default_style.format)\n                last_end = match.end()\n                try:\n                    for code in [int(_c) for _c in match.group(1).split(';')]:\n                        self.ansi_handler.set_code(code)\n                except ValueError:\n                    pass\n                self.default_style.format = self.ansi_handler.get_format()\n            insert_text_to(cursor, text[last_end:], self.default_style.format)\n#            # Slower alternative:\n#            segments = self.COLOR_PATTERN.split(text)\n#            cursor.insertText(segments.pop(0), self.default_style.format)\n#            if segments:\n#                for ansi_tags, text in zip(segments[::2], segments[1::2]):\n#                    for ansi_tag in ansi_tags.split(';'):\n#                        self.ansi_handler.set_code(int(ansi_tag))\n#                    self.default_style.format = self.ansi_handler.get_format()\n#                    cursor.insertText(text, self.default_style.format)\n        self.set_cursor_position('eof')\n        self.setCurrentCharFormat(self.default_style.format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.pylint.treewidget.sig_edit_goto.connect(self.main.editor.load)\r\n        self.pylint.redirect_stdio.connect(\r\n            self.main.redirect_internalshell_stdio)\r\n        self.main.add_dockwidget(self)\r\n        \r\n        pylint_act = create_action(self, _(\"Run static code analysis\"),\r\n                                   triggered=self.run_pylint)\r\n        pylint_act.setEnabled(is_module_installed('pylint'))\r\n        self.register_shortcut(pylint_act, context=\"Pylint\",\r\n                               name=\"Run analysis\")\r\n        \r\n        self.main.source_menu_actions += [MENU_SEPARATOR, pylint_act]\r\n        self.main.editor.pythonfile_dependent_actions += [pylint_act]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning pylint code analysis", "response": "def run_pylint(self):\r\n        \"\"\"Run pylint code analysis\"\"\"\r\n        if (self.get_option('save_before', True)\r\n                and not self.main.editor.save()):\r\n            return\r\n        self.switch_to_plugin()\r\n        self.analyze(self.main.editor.get_current_filename())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_font(self, font, option):\n        # Update fonts in all plugins\n        set_font(font, option=option)\n        plugins = self.main.widgetlist + self.main.thirdparty_plugins\n        for plugin in plugins:\n            plugin.update_font()", "response": "Set global font used in Spyder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable or disable the Qt style combobox.", "response": "def update_qt_style_combobox(self):\n        \"\"\"Enable/disable the Qt style combobox.\"\"\"\n        if is_dark_interface():\n            self.style_combobox.setEnabled(False)\n        else:\n            self.style_combobox.setEnabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_combobox(self):\n        index = self.current_scheme_index\n        self.schemes_combobox.blockSignals(True)\n        names = self.get_option(\"names\")\n        try:\n            names.pop(names.index(u'Custom'))\n        except ValueError:\n            pass\n        custom_names = self.get_option(\"custom_names\", [])\n\n        # Useful for retrieving the actual data\n        for n in names + custom_names:\n            self.scheme_choices_dict[self.get_option('{0}/name'.format(n))] = n\n\n        if custom_names:\n            choices = names + [None] + custom_names\n        else:\n            choices = names\n\n        combobox = self.schemes_combobox\n        combobox.clear()\n\n        for name in choices:\n            if name is None:\n                continue\n            combobox.addItem(self.get_option('{0}/name'.format(name)), name)\n\n        if custom_names:\n            combobox.insertSeparator(len(names))\n\n        self.schemes_combobox.blockSignals(False)\n        self.schemes_combobox.setCurrentIndex(index)", "response": "Recreates the combobox contents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the enable status of delete and reset buttons.", "response": "def update_buttons(self):\n        \"\"\"Updates the enable status of delete and reset buttons.\"\"\"\n        current_scheme = self.current_scheme\n        names = self.get_option(\"names\")\n        try:\n            names.pop(names.index(u'Custom'))\n        except ValueError:\n            pass\n        delete_enabled = current_scheme not in names\n        self.delete_button.setEnabled(delete_enabled)\n        self.reset_button.setEnabled(not delete_enabled)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_preview(self, index=None, scheme_name=None):\n        text = ('\"\"\"A string\"\"\"\\n\\n'\n                '# A comment\\n\\n'\n                '# %% A cell\\n\\n'\n                'class Foo(object):\\n'\n                '    def __init__(self):\\n'\n                '        bar = 42\\n'\n                '        print(bar)\\n'\n                )\n        show_blanks = CONF.get('editor', 'blank_spaces')\n        update_scrollbar = CONF.get('editor', 'scroll_past_end')\n        if scheme_name is None:\n            scheme_name = self.current_scheme\n        self.preview_editor.setup_editor(linenumbers=True,\n                                         markers=True,\n                                         tab_mode=False,\n                                         font=get_font(),\n                                         show_blanks=show_blanks,\n                                         color_scheme=scheme_name,\n                                         scroll_past_end=update_scrollbar)\n        self.preview_editor.set_text(text)\n        self.preview_editor.set_language('Python')", "response": "Update the color scheme of the preview editor and adds text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_new_scheme(self):\n        names = self.get_option('names')\n        custom_names = self.get_option('custom_names', [])\n\n        # Get the available number this new color scheme\n        counter = len(custom_names) - 1\n        custom_index = [int(n.split('-')[-1]) for n in custom_names]\n        for i in range(len(custom_names)):\n            if custom_index[i] != i:\n                counter = i - 1\n                break\n        custom_name = \"custom-{0}\".format(counter+1)\n\n        # Add the config settings, based on the current one.\n        custom_names.append(custom_name)\n        self.set_option('custom_names', custom_names)\n        for key in syntaxhighlighters.COLOR_SCHEME_KEYS:\n            name = \"{0}/{1}\".format(custom_name, key)\n            default_name = \"{0}/{1}\".format(self.current_scheme, key)\n            option = self.get_option(default_name)\n            self.set_option(name, option)\n        self.set_option('{0}/name'.format(custom_name), custom_name)\n\n        # Now they need to be loaded! how to make a partial load_from_conf?\n        dlg = self.scheme_editor_dialog\n        dlg.add_color_scheme_stack(custom_name, custom=True)\n        dlg.set_scheme(custom_name)\n        self.load_from_conf()\n\n        if dlg.exec_():\n            # This is needed to have the custom name updated on the combobox\n            name = dlg.get_scheme_name()\n            self.set_option('{0}/name'.format(custom_name), name)\n\n            # The +1 is needed because of the separator in the combobox\n            index = (names + custom_names).index(custom_name) + 1\n            self.update_combobox()\n            self.schemes_combobox.setCurrentIndex(index)\n        else:\n            # Delete the config ....\n            custom_names.remove(custom_name)\n            self.set_option('custom_names', custom_names)\n            dlg.delete_color_scheme_stack(custom_name)", "response": "Creates a new color scheme with a custom name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_scheme(self):\n        scheme_name = self.current_scheme\n\n        answer = QMessageBox.warning(self, _(\"Warning\"),\n                                     _(\"Are you sure you want to delete \"\n                                       \"this scheme?\"),\n                                     QMessageBox.Yes | QMessageBox.No)\n        if answer == QMessageBox.Yes:\n            # Put the combobox in Spyder by default, when deleting a scheme\n            names = self.get_option('names')\n            self.set_scheme('spyder')\n            self.schemes_combobox.setCurrentIndex(names.index('spyder'))\n            self.set_option('selected', 'spyder')\n\n            # Delete from custom_names\n            custom_names = self.get_option('custom_names', [])\n            if scheme_name in custom_names:\n                custom_names.remove(scheme_name)\n            self.set_option('custom_names', custom_names)\n\n            # Delete config options\n            for key in syntaxhighlighters.COLOR_SCHEME_KEYS:\n                option = \"{0}/{1}\".format(scheme_name, key)\n                CONF.remove_option(self.CONF_SECTION, option)\n            CONF.remove_option(self.CONF_SECTION,\n                               \"{0}/name\".format(scheme_name))\n\n            self.update_combobox()\n            self.update_preview()", "response": "Deletes the currently selected custom color scheme."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset_to_default(self):\n        # Checks that this is indeed a default scheme\n        scheme = self.current_scheme\n        names = self.get_option('names')\n        if scheme in names:\n            for key in syntaxhighlighters.COLOR_SCHEME_KEYS:\n                option = \"{0}/{1}\".format(scheme, key)\n                value = CONF.get_default(self.CONF_SECTION, option)\n                self.set_option(option, value)\n\n            self.load_from_conf()", "response": "Restore initial values for default color schemes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the current stack by scheme_name.", "response": "def set_scheme(self, scheme_name):\n        \"\"\"Set the current stack by 'scheme_name'.\"\"\"\n        self.stack.setCurrentIndex(self.order.index(scheme_name))\n        self.last_used_scheme = scheme_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the values of the last edited color scheme.", "response": "def get_edited_color_scheme(self):\n        \"\"\"\n        Get the values of the last edited color scheme to be used in an instant\n        preview in the preview editor, without using `apply`.\n        \"\"\"\n        color_scheme = {}\n        scheme_name = self.last_used_scheme\n\n        for key in self.widgets[scheme_name]:\n            items = self.widgets[scheme_name][key]\n\n            if len(items) == 1:\n                # ColorLayout\n                value = items[0].text()\n            else:\n                # ColorLayout + checkboxes\n                value = (items[0].text(), items[1].isChecked(),\n                         items[2].isChecked())\n\n            color_scheme[key] = value\n\n        return color_scheme"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a stack for a given scheme and connects the CONF values.", "response": "def add_color_scheme_stack(self, scheme_name, custom=False):\n        \"\"\"Add a stack for a given scheme and connects the CONF values.\"\"\"\n        color_scheme_groups = [\n            (_('Text'), [\"normal\", \"comment\", \"string\", \"number\", \"keyword\",\n                         \"builtin\", \"definition\", \"instance\", ]),\n            (_('Highlight'), [\"currentcell\", \"currentline\", \"occurrence\",\n                              \"matched_p\", \"unmatched_p\", \"ctrlclick\"]),\n            (_('Background'), [\"background\", \"sideareas\"])\n            ]\n\n        parent = self.parent\n        line_edit = parent.create_lineedit(_(\"Scheme name:\"),\n                                           '{0}/name'.format(scheme_name))\n\n        self.widgets[scheme_name] = {}\n\n        # Widget setup\n        line_edit.label.setAlignment(Qt.AlignRight | Qt.AlignVCenter)\n        self.setWindowTitle(_('Color scheme editor'))\n\n        # Layout\n        name_layout = QHBoxLayout()\n        name_layout.addWidget(line_edit.label)\n        name_layout.addWidget(line_edit.textbox)\n        self.scheme_name_textbox[scheme_name] = line_edit.textbox\n\n        if not custom:\n            line_edit.textbox.setDisabled(True)\n        if not self.isVisible():\n            line_edit.setVisible(False)\n\n        cs_layout = QVBoxLayout()\n        cs_layout.addLayout(name_layout)\n\n        h_layout = QHBoxLayout()\n        v_layout = QVBoxLayout()\n\n        for index, item in enumerate(color_scheme_groups):\n            group_name, keys = item\n            group_layout = QGridLayout()\n\n            for row, key in enumerate(keys):\n                option = \"{0}/{1}\".format(scheme_name, key)\n                value = self.parent.get_option(option)\n                name = syntaxhighlighters.COLOR_SCHEME_KEYS[key]\n\n                if is_text_string(value):\n                    label, clayout = parent.create_coloredit(\n                        name,\n                        option,\n                        without_layout=True,\n                        )\n                    label.setAlignment(Qt.AlignRight | Qt.AlignVCenter)\n                    group_layout.addWidget(label, row+1, 0)\n                    group_layout.addLayout(clayout, row+1, 1)\n\n                    # Needed to update temp scheme to obtain instant preview\n                    self.widgets[scheme_name][key] = [clayout]\n                else:\n                    label, clayout, cb_bold, cb_italic = parent.create_scedit(\n                        name,\n                        option,\n                        without_layout=True,\n                        )\n                    label.setAlignment(Qt.AlignRight | Qt.AlignVCenter)\n                    group_layout.addWidget(label, row+1, 0)\n                    group_layout.addLayout(clayout, row+1, 1)\n                    group_layout.addWidget(cb_bold, row+1, 2)\n                    group_layout.addWidget(cb_italic, row+1, 3)\n\n                    # Needed to update temp scheme to obtain instant preview\n                    self.widgets[scheme_name][key] = [clayout, cb_bold,\n                                                      cb_italic]\n\n            group_box = QGroupBox(group_name)\n            group_box.setLayout(group_layout)\n\n            if index == 0:\n                h_layout.addWidget(group_box)\n            else:\n                v_layout.addWidget(group_box)\n\n        h_layout.addLayout(v_layout)\n        cs_layout.addLayout(h_layout)\n\n        stackitem = QWidget()\n        stackitem.setLayout(cs_layout)\n        self.stack.addWidget(stackitem)\n        self.order.append(scheme_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove stack widget by scheme_name.", "response": "def delete_color_scheme_stack(self, scheme_name):\n        \"\"\"Remove stack widget by 'scheme_name'.\"\"\"\n        self.set_scheme(scheme_name)\n        widget = self.stack.currentWidget()\n        self.stack.removeWidget(widget)\n        index = self.order.index(scheme_name)\n        self.order.pop(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plugin_actions(self):\r\n        self.new_project_action = create_action(self,\r\n                                    _(\"New Project...\"),\r\n                                    triggered=self.create_new_project)\r\n        self.open_project_action = create_action(self,\r\n                                    _(\"Open Project...\"),\r\n                                    triggered=lambda v: self.open_project())\r\n        self.close_project_action = create_action(self,\r\n                                    _(\"Close Project\"),\r\n                                    triggered=self.close_project)\r\n        self.delete_project_action = create_action(self,\r\n                                    _(\"Delete Project\"),\r\n                                    triggered=self.delete_project)\r\n        self.clear_recent_projects_action =\\\r\n            create_action(self, _(\"Clear this list\"),\r\n                          triggered=self.clear_recent_projects)\r\n        self.edit_project_preferences_action =\\\r\n            create_action(self, _(\"Project Preferences\"),\r\n                          triggered=self.edit_project_preferences)\r\n        self.recent_project_menu = QMenu(_(\"Recent Projects\"), self)\r\n\r\n        if self.main is not None:\r\n            self.main.projects_menu_actions += [self.new_project_action,\r\n                                                MENU_SEPARATOR,\r\n                                                self.open_project_action,\r\n                                                self.close_project_action,\r\n                                                self.delete_project_action,\r\n                                                MENU_SEPARATOR,\r\n                                                self.recent_project_menu,\r\n                                                self.toggle_view_action]\r\n\r\n        self.setup_menu_actions()\r\n        return []", "response": "Returns a list of actions related to the plugin"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_plugin(self):\r\n        ipyconsole = self.main.ipyconsole\r\n        treewidget = self.explorer.treewidget\r\n        lspmgr = self.main.lspmanager\r\n\r\n        self.main.add_dockwidget(self)\r\n        self.explorer.sig_open_file.connect(self.main.open_file)\r\n        self.register_widget_shortcuts(treewidget)\r\n\r\n        treewidget.sig_delete_project.connect(self.delete_project)\r\n        treewidget.sig_edit.connect(self.main.editor.load)\r\n        treewidget.sig_removed.connect(self.main.editor.removed)\r\n        treewidget.sig_removed_tree.connect(self.main.editor.removed_tree)\r\n        treewidget.sig_renamed.connect(self.main.editor.renamed)\r\n        treewidget.sig_renamed_tree.connect(self.main.editor.renamed_tree)\r\n        treewidget.sig_create_module.connect(self.main.editor.new)\r\n        treewidget.sig_new_file.connect(\r\n            lambda t: self.main.editor.new(text=t))\r\n        treewidget.sig_open_interpreter.connect(\r\n            ipyconsole.create_client_from_path)\r\n        treewidget.redirect_stdio.connect(\r\n            self.main.redirect_internalshell_stdio)\r\n        treewidget.sig_run.connect(\r\n            lambda fname:\r\n            ipyconsole.run_script(fname, osp.dirname(fname), '', False, False,\r\n                                  False, True))\r\n\r\n        # New project connections. Order matters!\r\n        self.sig_project_loaded.connect(\r\n            lambda v: self.main.workingdirectory.chdir(v))\r\n        self.sig_project_loaded.connect(\r\n            lambda v: self.main.set_window_title())\r\n        self.sig_project_loaded.connect(lspmgr.reinitialize_all_clients)\r\n        self.sig_project_loaded.connect(\r\n            lambda v: self.main.editor.setup_open_files())\r\n        self.sig_project_loaded.connect(self.update_explorer)\r\n        self.sig_project_closed[object].connect(\r\n            lambda v: self.main.workingdirectory.chdir(\r\n                self.get_last_working_dir()))\r\n        self.sig_project_closed.connect(\r\n            lambda v: self.main.set_window_title())\r\n        self.sig_project_closed.connect(lspmgr.reinitialize_all_clients)\r\n        self.sig_project_closed.connect(\r\n            lambda v: self.main.editor.setup_open_files())\r\n        self.recent_project_menu.aboutToShow.connect(self.setup_menu_actions)\r\n\r\n        self.main.pythonpath_changed()\r\n        self.main.restore_scrollbar_position.connect(\r\n                                               self.restore_scrollbar_position)\r\n        self.sig_pythonpath_changed.connect(self.main.pythonpath_changed)\r\n        self.main.editor.set_projects(self)", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform actions before parent main window is closed", "response": "def closing_plugin(self, cancelable=False):\r\n        \"\"\"Perform actions before parent main window is closed\"\"\"\r\n        self.save_config()\r\n        self.explorer.closing_widget()\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_project_actions(self):\r\n        if self.recent_projects:\r\n            self.clear_recent_projects_action.setEnabled(True)\r\n        else:\r\n            self.clear_recent_projects_action.setEnabled(False)\r\n\r\n        active = bool(self.get_active_project_path())\r\n        self.close_project_action.setEnabled(active)\r\n        self.delete_project_action.setEnabled(active)\r\n        self.edit_project_preferences_action.setEnabled(active)", "response": "Update actions of the Projects menu"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting Spyder active project preferences", "response": "def edit_project_preferences(self):\r\n        \"\"\"Edit Spyder active project preferences\"\"\"\r\n        from spyder.plugins.projects.confpage import ProjectPreferences\r\n        if self.project_active:\r\n            active_project = self.project_list[0]\r\n            dlg = ProjectPreferences(self, active_project)\r\n#            dlg.size_change.connect(self.set_project_prefs_size)\r\n#            if self.projects_prefs_dialog_size is not None:\r\n#                dlg.resize(self.projects_prefs_dialog_size)\r\n            dlg.show()\r\n#        dlg.check_all_settings()\r\n#        dlg.pages_widget.currentChanged.connect(self.__preference_page_changed)\r\n            dlg.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_project(self, path):\r\n        self.open_project(path=path)\r\n        self.setup_menu_actions()\r\n        self.add_to_recent(path)", "response": "Create a new project."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_project(self, path=None, restart_consoles=True,\r\n                     save_previous_files=True):\r\n        \"\"\"Open the project located in `path`\"\"\"\r\n        self.switch_to_plugin()\r\n        if path is None:\r\n            basedir = get_home_dir()\r\n            path = getexistingdirectory(parent=self,\r\n                                        caption=_(\"Open project\"),\r\n                                        basedir=basedir)\r\n            path = encoding.to_unicode_from_fs(path)\r\n            if not self.is_valid_project(path):\r\n                if path:\r\n                    QMessageBox.critical(self, _('Error'),\r\n                                _(\"<b>%s</b> is not a Spyder project!\") % path)\r\n                return\r\n        else:\r\n            path = encoding.to_unicode_from_fs(path)\r\n\r\n        self.add_to_recent(path)\r\n\r\n        # A project was not open before\r\n        if self.current_active_project is None:\r\n            if save_previous_files and self.main.editor is not None:\r\n                self.main.editor.save_open_files()\r\n            if self.main.editor is not None:\r\n                self.main.editor.set_option('last_working_dir',\r\n                                            getcwd_or_home())\r\n            if self.get_option('visible_if_project_open'):\r\n                self.show_explorer()\r\n        else:\r\n            # We are switching projects\r\n            if self.main.editor is not None:\r\n                self.set_project_filenames(\r\n                    self.main.editor.get_open_filenames())\r\n\r\n        self.current_active_project = EmptyProject(path)\r\n        self.latest_project = EmptyProject(path)\r\n        self.set_option('current_project_path', self.get_active_project_path())\r\n\r\n        self.setup_menu_actions()\r\n        self.sig_project_loaded.emit(path)\r\n        self.sig_pythonpath_changed.emit()\r\n\r\n        if restart_consoles:\r\n            self.restart_consoles()", "response": "Open the project located in path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_project(self):\r\n        if self.current_active_project:\r\n            self.switch_to_plugin()\r\n            if self.main.editor is not None:\r\n                self.set_project_filenames(\r\n                    self.main.editor.get_open_filenames())\r\n            path = self.current_active_project.root_path\r\n            self.current_active_project = None\r\n            self.set_option('current_project_path', None)\r\n            self.setup_menu_actions()\r\n\r\n            self.sig_project_closed.emit(path)\r\n            self.sig_pythonpath_changed.emit()\r\n\r\n            if self.dockwidget is not None:\r\n                self.set_option('visible_if_project_open',\r\n                                self.dockwidget.isVisible())\r\n                self.dockwidget.close()\r\n\r\n            self.explorer.clear()\r\n            self.restart_consoles()", "response": "Close current project and return to a window without an active project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_project(self):\r\n        if self.current_active_project:\r\n            self.switch_to_plugin()\r\n            path = self.current_active_project.root_path\r\n            buttons = QMessageBox.Yes | QMessageBox.No\r\n            answer = QMessageBox.warning(\r\n                self,\r\n                _(\"Delete\"),\r\n                _(\"Do you really want to delete <b>{filename}</b>?<br><br>\"\r\n                  \"<b>Note:</b> This action will only delete the project. \"\r\n                  \"Its files are going to be preserved on disk.\"\r\n                  ).format(filename=osp.basename(path)),\r\n                buttons)\r\n            if answer == QMessageBox.Yes:\r\n                try:\r\n                    self.close_project()\r\n                    shutil.rmtree(osp.join(path, '.spyproject'))\r\n                except EnvironmentError as error:\r\n                    QMessageBox.critical(\r\n                        self,\r\n                        _(\"Project Explorer\"),\r\n                        _(\"<b>Unable to delete <i>{varpath}</i></b>\"\r\n                          \"<br><br>The error message was:<br>{error}\"\r\n                          ).format(varpath=path, error=to_text_string(error)))", "response": "Delete the current project without deleting the files in the directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreopening the active project when Spyder was closed last time.", "response": "def reopen_last_project(self):\r\n        \"\"\"\r\n        Reopen the active project when Spyder was closed last time, if any\r\n        \"\"\"\r\n        current_project_path = self.get_option('current_project_path',\r\n                                               default=None)\r\n\r\n        # Needs a safer test of project existence!\r\n        if current_project_path and \\\r\n          self.is_valid_project(current_project_path):\r\n            self.open_project(path=current_project_path,\r\n                              restart_consoles=False,\r\n                              save_previous_files=False)\r\n            self.load_config()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the list of recent filenames of a project", "response": "def get_project_filenames(self):\r\n        \"\"\"Get the list of recent filenames of a project\"\"\"\r\n        recent_files = []\r\n        if self.current_active_project:\r\n            recent_files = self.current_active_project.get_recent_files()\r\n        elif self.latest_project:\r\n            recent_files = self.latest_project.get_recent_files()\r\n        return recent_files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the list of open file names in a project", "response": "def set_project_filenames(self, recent_files):\r\n        \"\"\"Set the list of open file names in a project\"\"\"\r\n        if (self.current_active_project\r\n                and self.is_valid_project(\r\n                        self.current_active_project.root_path)):\r\n            self.current_active_project.set_recent_files(recent_files)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting path of the active project", "response": "def get_active_project_path(self):\r\n        \"\"\"Get path of the active project\"\"\"\r\n        active_project_path = None\r\n        if self.current_active_project:\r\n            active_project_path = self.current_active_project.root_path\r\n        return active_project_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pythonpath(self, at_start=False):\r\n        if at_start:\r\n            current_path = self.get_option('current_project_path',\r\n                                           default=None)\r\n        else:\r\n            current_path = self.get_active_project_path()\r\n        if current_path is None:\r\n            return []\r\n        else:\r\n            return [current_path]", "response": "Get project path as a list to be added to PYTHONPATH"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the configuration of the current active project.", "response": "def save_config(self):\r\n        \"\"\"\r\n        Save configuration: opened projects & tree widget state.\r\n\r\n        Also save whether dock widget is visible if a project is open.\r\n        \"\"\"\r\n        self.set_option('recent_projects', self.recent_projects)\r\n        self.set_option('expanded_state',\r\n                        self.explorer.treewidget.get_expanded_state())\r\n        self.set_option('scrollbar_position',\r\n                        self.explorer.treewidget.get_scrollbar_position())\r\n        if self.current_active_project and self.dockwidget:\r\n            self.set_option('visible_if_project_open',\r\n                            self.dockwidget.isVisible())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a directory is a valid Spyder project", "response": "def is_valid_project(self, path):\r\n        \"\"\"Check if a directory is a valid Spyder project\"\"\"\r\n        spy_project_dir = osp.join(path, '.spyproject')\r\n        if osp.isdir(path) and osp.isdir(spy_project_dir):\r\n            return True\r\n        else:\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_to_recent(self, project):\r\n        if project not in self.recent_projects:\r\n            self.recent_projects.insert(0, project)\r\n            self.recent_projects = self.recent_projects[:10]", "response": "Add an entry to recent projects"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_attached_console_visible(state):\r\n    flag = {True: SW_SHOW, False: SW_HIDE}\r\n    return bool(ShowWindow(console_window_handle, flag[state]))", "response": "Show or hide system console window attached to current process. Returns it s previous state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first installed font family in family list", "response": "def get_family(families):\n    \"\"\"Return the first installed font family in family list\"\"\"\n    if not isinstance(families, list):\n        families = [ families ]\n    for family in families:\n        if font_is_installed(family):\n            return family\n    else:\n        print(\"Warning: None of the following fonts is installed: %r\" % families)  # spyder: test-skip\n        return QFont().family()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_font(section='appearance', option='font', font_size_delta=0):\n    font = FONT_CACHE.get((section, option))\n\n    if font is None:\n        families = CONF.get(section, option+\"/family\", None)\n\n        if families is None:\n            return QFont()\n\n        family = get_family(families)\n        weight = QFont.Normal\n        italic = CONF.get(section, option+'/italic', False)\n\n        if CONF.get(section, option+'/bold', False):\n            weight = QFont.Bold\n\n        size = CONF.get(section, option+'/size', 9) + font_size_delta\n        font = QFont(family, size, weight)\n        font.setItalic(italic)\n        FONT_CACHE[(section, option)] = font\n\n    size = CONF.get(section, option+'/size', 9) + font_size_delta\n    font.setPointSize(size)\n    return font", "response": "Get console font properties depending on OS and user options"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_font(font, section='appearance', option='font'):\n    CONF.set(section, option+'/family', to_text_string(font.family()))\n    CONF.set(section, option+'/size', float(font.pointSize()))\n    CONF.set(section, option+'/italic', int(font.italic()))\n    CONF.set(section, option+'/bold', int(font.bold()))\n    FONT_CACHE[(section, option)] = font", "response": "Set font in the specified section"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fixed_shortcut(keystr, parent, action):\n    sc = QShortcut(QKeySequence(keystr), parent, action)\n    sc.setContext(Qt.WidgetWithChildrenShortcut)\n    return sc", "response": "Define a fixed shortcut according to a keysequence string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a Shortcut namedtuple for a widget", "response": "def config_shortcut(action, context, name, parent):\n    \"\"\"\n    Create a Shortcut namedtuple for a widget\n    \n    The data contained in this tuple will be registered in\n    our shortcuts preferences page\n    \"\"\"\n    keystr = get_shortcut(context, name)\n    qsc = QShortcut(QKeySequence(keystr), parent, action)\n    qsc.setContext(Qt.WidgetWithChildrenShortcut)\n    sc = Shortcut(data=(qsc, context, name))\n    return sc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_shortcuts():\n    for context_name, keystr in CONF.items('shortcuts'):\n        context, name = context_name.split(\"/\", 1)\n        yield context, name, keystr", "response": "Iterate over keyboard shortcuts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_color_scheme(name):\n    color_scheme = {}\n    for key in sh.COLOR_SCHEME_KEYS:\n        color_scheme[key] = CONF.get(\"appearance\", \"%s/%s\" % (name, key))\n    return color_scheme", "response": "Get syntax color scheme"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets syntax color scheme for a single resource.", "response": "def set_color_scheme(name, color_scheme, replace=True):\n    \"\"\"Set syntax color scheme\"\"\"\n    section = \"appearance\"\n    names = CONF.get(\"appearance\", \"names\", [])\n    for key in sh.COLOR_SCHEME_KEYS:\n        option = \"%s/%s\" % (name, key)\n        value = CONF.get(section, option, default=None)\n        if value is None or replace or name not in names:\n            CONF.set(section, option, color_scheme[key])\n    names.append(to_text_string(name))\n    CONF.set(section, \"names\", sorted(list(set(names))))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset color scheme to default values", "response": "def set_default_color_scheme(name, replace=True):\n    \"\"\"Reset color scheme to default values\"\"\"\n    assert name in sh.COLOR_SCHEME_NAMES\n    set_color_scheme(name, sh.get_color_scheme(name), replace=replace)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the font color used in the color scheme is dark.", "response": "def is_dark_font_color(color_scheme):\n    \"\"\"Check if the font color used in the color scheme is dark.\"\"\"\n    color_scheme = get_color_scheme(color_scheme)\n    font_color, fon_fw, fon_fs = color_scheme['normal']\n    return dark_color(font_color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering mouse press events.", "response": "def eventFilter(self, obj, event):\n        \"\"\"Filter mouse press events.\n\n        Events that are captured and not propagated return True. Events that\n        are not captured and are propagated return False.\n        \"\"\"\n        event_type = event.type()\n        if event_type == QEvent.MouseButtonPress:\n            self.tab_pressed(event)\n            return False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tab_pressed(self, event):\n        self.from_index = self.dock_tabbar.tabAt(event.pos())\n        self.dock_tabbar.setCurrentIndex(self.from_index)\n\n        if event.button() == Qt.RightButton:\n            if self.from_index == -1:\n                self.show_nontab_menu(event)\n            else:\n                self.show_tab_menu(event)", "response": "Method called when a tab from a QTabBar has been pressed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_nontab_menu(self, event):\n        menu = self.main.createPopupMenu()\n        menu.exec_(self.dock_tabbar.mapToGlobal(event.pos()))", "response": "Show the context menu assigned to nontabs section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling an event filter to capture mouse events in the tabs of the dockwidgets.", "response": "def install_tab_event_filter(self, value):\n        \"\"\"\n        Install an event filter to capture mouse events in the tabs of a\n        QTabBar holding tabified dockwidgets.\n        \"\"\"\n        dock_tabbar = None\n        tabbars = self.main.findChildren(QTabBar)\n        for tabbar in tabbars:\n            for tab in range(tabbar.count()):\n                title = tabbar.tabText(tab)\n                if title == self.title:\n                    dock_tabbar = tabbar\n                    break\n        if dock_tabbar is not None:\n            self.dock_tabbar = dock_tabbar\n            # Install filter only once per QTabBar\n            if getattr(self.dock_tabbar, 'filter', None) is None:\n                self.dock_tabbar.filter = TabFilter(self.dock_tabbar,\n                                                    self.main)\n                self.dock_tabbar.installEventFilter(self.dock_tabbar.filter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all bookmarks from config.", "response": "def _load_all_bookmarks():\n    \"\"\"Load all bookmarks from config.\"\"\"\n    slots = CONF.get('editor', 'bookmarks', {})\n    for slot_num in list(slots.keys()):\n        if not osp.isfile(slots[slot_num][0]):\n            slots.pop(slot_num)\n    return slots"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_bookmarks(filename):\n    bookmarks = _load_all_bookmarks()\n    return {k: v for k, v in bookmarks.items() if v[0] == filename}", "response": "Load all bookmarks for a specific file from config."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads all bookmarks but those from a specific file.", "response": "def load_bookmarks_without_file(filename):\n    \"\"\"Load all bookmarks but those from a specific file.\"\"\"\n    bookmarks = _load_all_bookmarks()\n    return {k: v for k, v in bookmarks.items() if v[0] != filename}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_bookmarks(filename, bookmarks):\n    if not osp.isfile(filename):\n        return\n    slots = load_bookmarks_without_file(filename)\n    for slot_num, content in bookmarks.items():\n        slots[slot_num] = [filename, content[0], content[1]]\n    CONF.set('editor', 'bookmarks', slots)", "response": "Save all bookmarks from specific file to config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef report_open_file(self, options):\r\n        filename = options['filename']\r\n        logger.debug('Call LSP for %s' % filename)\r\n        language = options['language']\r\n        callback = options['codeeditor']\r\n        stat = self.main.lspmanager.start_client(language.lower())\r\n        self.main.lspmanager.register_file(\r\n            language.lower(), filename, callback)\r\n        if stat:\r\n            if language.lower() in self.lsp_editor_settings:\r\n                self.lsp_server_ready(\r\n                    language.lower(), self.lsp_editor_settings[\r\n                        language.lower()])\r\n            else:\r\n                editor = self.get_current_editor()\r\n                editor.lsp_ready = False", "response": "Request to start a LSP server to attend a language."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters LSP server settings.", "response": "def register_lsp_server_settings(self, settings, language):\r\n        \"\"\"Register LSP server settings.\"\"\"\r\n        self.lsp_editor_settings[language] = settings\r\n        logger.debug('LSP server settings for {!s} are: {!r}'.format(\r\n            language, settings))\r\n        self.lsp_server_ready(language, self.lsp_editor_settings[language])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnotify all stackeditors about LSP server availability.", "response": "def lsp_server_ready(self, language, configuration):\r\n        \"\"\"Notify all stackeditors about LSP server availability.\"\"\"\r\n        for editorstack in self.editorstacks:\r\n            editorstack.notify_server_ready(language, configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visibility_changed(self, enable):\r\n        SpyderPluginWidget.visibility_changed(self, enable)\r\n        if self.dockwidget is None:\r\n            return\r\n        if self.dockwidget.isWindow():\r\n            self.dock_toolbar.show()\r\n        else:\r\n            self.dock_toolbar.hide()\r\n        if enable:\r\n            self.refresh_plugin()\r\n        self.sig_update_plugin_title.emit()", "response": "Called when the visibility of dockwidget has changed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef closing_plugin(self, cancelable=False):\r\n        state = self.splitter.saveState()\r\n        self.set_option('splitter_state', qbytearray_to_str(state))\r\n        filenames = []\r\n        editorstack = self.editorstacks[0]\r\n\r\n        active_project_path = None\r\n        if self.projects is not None:\r\n             active_project_path = self.projects.get_active_project_path()\r\n        if not active_project_path:\r\n            self.set_open_filenames()\r\n        else:\r\n            self.projects.set_project_filenames(\r\n                [finfo.filename for finfo in editorstack.data])\r\n\r\n        self.set_option('layout_settings',\r\n                        self.editorsplitter.get_layout_settings())\r\n        self.set_option('windows_layout_settings',\r\n                    [win.get_layout_settings() for win in self.editorwindows])\r\n#        self.set_option('filenames', filenames)\r\n        self.set_option('recent_files', self.recent_files)\r\n\r\n        # Stop autosave timer before closing windows\r\n        self.autosave.stop_autosave_timer()\r\n\r\n        try:\r\n            if not editorstack.save_if_changed(cancelable) and cancelable:\r\n                return False\r\n            else:\r\n                for win in self.editorwindows[:]:\r\n                    win.close()\r\n                return True\r\n        except IndexError:\r\n            return True", "response": "Perform actions before parent main window is closed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_plugin_actions(self):\r\n        # ---- File menu and toolbar ----\r\n        self.new_action = create_action(\r\n                self,\r\n                _(\"&New file...\"),\r\n                icon=ima.icon('filenew'), tip=_(\"New file\"),\r\n                triggered=self.new,\r\n                context=Qt.WidgetShortcut\r\n        )\r\n        self.register_shortcut(self.new_action, context=\"Editor\",\r\n                               name=\"New file\", add_sc_to_tip=True)\r\n\r\n        self.open_last_closed_action = create_action(\r\n                self,\r\n                _(\"O&pen last closed\"),\r\n                tip=_(\"Open last closed\"),\r\n                triggered=self.open_last_closed\r\n        )\r\n        self.register_shortcut(self.open_last_closed_action, context=\"Editor\",\r\n                               name=\"Open last closed\")\r\n\r\n        self.open_action = create_action(self, _(\"&Open...\"),\r\n                icon=ima.icon('fileopen'), tip=_(\"Open file\"),\r\n                triggered=self.load,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.open_action, context=\"Editor\",\r\n                               name=\"Open file\", add_sc_to_tip=True)\r\n\r\n        self.revert_action = create_action(self, _(\"&Revert\"),\r\n                icon=ima.icon('revert'), tip=_(\"Revert file from disk\"),\r\n                triggered=self.revert)\r\n\r\n        self.save_action = create_action(self, _(\"&Save\"),\r\n                icon=ima.icon('filesave'), tip=_(\"Save file\"),\r\n                triggered=self.save,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.save_action, context=\"Editor\",\r\n                               name=\"Save file\", add_sc_to_tip=True)\r\n\r\n        self.save_all_action = create_action(self, _(\"Sav&e all\"),\r\n                icon=ima.icon('save_all'), tip=_(\"Save all files\"),\r\n                triggered=self.save_all,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.save_all_action, context=\"Editor\",\r\n                               name=\"Save all\", add_sc_to_tip=True)\r\n\r\n        save_as_action = create_action(self, _(\"Save &as...\"), None,\r\n                ima.icon('filesaveas'), tip=_(\"Save current file as...\"),\r\n                triggered=self.save_as,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(save_as_action, \"Editor\", \"Save As\")\r\n\r\n        save_copy_as_action = create_action(self, _(\"Save copy as...\"), None,\r\n                ima.icon('filesaveas'), _(\"Save copy of current file as...\"),\r\n                triggered=self.save_copy_as)\r\n\r\n        print_preview_action = create_action(self, _(\"Print preview...\"),\r\n                tip=_(\"Print preview...\"), triggered=self.print_preview)\r\n        self.print_action = create_action(self, _(\"&Print...\"),\r\n                icon=ima.icon('print'), tip=_(\"Print current file...\"),\r\n                triggered=self.print_file)\r\n        # Shortcut for close_action is defined in widgets/editor.py\r\n        self.close_action = create_action(self, _(\"&Close\"),\r\n                icon=ima.icon('fileclose'), tip=_(\"Close current file\"),\r\n                triggered=self.close_file)\r\n\r\n        self.close_all_action = create_action(self, _(\"C&lose all\"),\r\n                icon=ima.icon('filecloseall'), tip=_(\"Close all opened files\"),\r\n                triggered=self.close_all_files,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.close_all_action, context=\"Editor\",\r\n                               name=\"Close all\")\r\n\r\n        # ---- Find menu and toolbar ----\r\n        _text = _(\"&Find text\")\r\n        find_action = create_action(self, _text, icon=ima.icon('find'),\r\n                                    tip=_text, triggered=self.find,\r\n                                    context=Qt.WidgetShortcut)\r\n        self.register_shortcut(find_action, context=\"_\",\r\n                               name=\"Find text\", add_sc_to_tip=True)\r\n        find_next_action = create_action(self, _(\"Find &next\"),\r\n                                         icon=ima.icon('findnext'),\r\n                                         triggered=self.find_next,\r\n                                         context=Qt.WidgetShortcut)\r\n        self.register_shortcut(find_next_action, context=\"_\",\r\n                               name=\"Find next\")\r\n        find_previous_action = create_action(self, _(\"Find &previous\"),\r\n                                             icon=ima.icon('findprevious'),\r\n                                             triggered=self.find_previous,\r\n                                             context=Qt.WidgetShortcut)\r\n        self.register_shortcut(find_previous_action, context=\"_\",\r\n                               name=\"Find previous\")\r\n        _text = _(\"&Replace text\")\r\n        replace_action = create_action(self, _text, icon=ima.icon('replace'),\r\n                                       tip=_text, triggered=self.replace,\r\n                                       context=Qt.WidgetShortcut)\r\n        self.register_shortcut(replace_action, context=\"_\",\r\n                               name=\"Replace text\")\r\n\r\n        # ---- Debug menu and toolbar ----\r\n        set_clear_breakpoint_action = create_action(self,\r\n                                    _(\"Set/Clear breakpoint\"),\r\n                                    icon=ima.icon('breakpoint_big'),\r\n                                    triggered=self.set_or_clear_breakpoint,\r\n                                    context=Qt.WidgetShortcut)\r\n        self.register_shortcut(set_clear_breakpoint_action, context=\"Editor\",\r\n                               name=\"Breakpoint\")\r\n        set_cond_breakpoint_action = create_action(self,\r\n                            _(\"Set/Edit conditional breakpoint\"),\r\n                            icon=ima.icon('breakpoint_cond_big'),\r\n                            triggered=self.set_or_edit_conditional_breakpoint,\r\n                            context=Qt.WidgetShortcut)\r\n        self.register_shortcut(set_cond_breakpoint_action, context=\"Editor\",\r\n                               name=\"Conditional breakpoint\")\r\n        clear_all_breakpoints_action = create_action(self,\r\n                                    _('Clear breakpoints in all files'),\r\n                                    triggered=self.clear_all_breakpoints)\r\n        self.winpdb_action = create_action(self, _(\"Debug with winpdb\"),\r\n                                           triggered=self.run_winpdb)\r\n        self.winpdb_action.setEnabled(WINPDB_PATH is not None and PY2)\r\n\r\n        # --- Debug toolbar ---\r\n        debug_action = create_action(self, _(\"&Debug\"),\r\n                                     icon=ima.icon('debug'),\r\n                                     tip=_(\"Debug file\"),\r\n                                     triggered=self.debug_file)\r\n        self.register_shortcut(debug_action, context=\"_\", name=\"Debug\",\r\n                               add_sc_to_tip=True)\r\n\r\n        debug_next_action = create_action(self, _(\"Step\"),\r\n               icon=ima.icon('arrow-step-over'), tip=_(\"Run current line\"),\r\n               triggered=lambda: self.debug_command(\"next\"))\r\n        self.register_shortcut(debug_next_action, \"_\", \"Debug Step Over\",\r\n                               add_sc_to_tip=True)\r\n\r\n        debug_continue_action = create_action(self, _(\"Continue\"),\r\n               icon=ima.icon('arrow-continue'),\r\n               tip=_(\"Continue execution until next breakpoint\"),\r\n               triggered=lambda: self.debug_command(\"continue\"))\r\n        self.register_shortcut(debug_continue_action, \"_\", \"Debug Continue\",\r\n                               add_sc_to_tip=True)\r\n\r\n        debug_step_action = create_action(self, _(\"Step Into\"),\r\n               icon=ima.icon('arrow-step-in'),\r\n               tip=_(\"Step into function or method of current line\"),\r\n               triggered=lambda: self.debug_command(\"step\"))\r\n        self.register_shortcut(debug_step_action, \"_\", \"Debug Step Into\",\r\n                               add_sc_to_tip=True)\r\n\r\n        debug_return_action = create_action(self, _(\"Step Return\"),\r\n               icon=ima.icon('arrow-step-out'),\r\n               tip=_(\"Run until current function or method returns\"),\r\n               triggered=lambda: self.debug_command(\"return\"))\r\n        self.register_shortcut(debug_return_action, \"_\", \"Debug Step Return\",\r\n                               add_sc_to_tip=True)\r\n\r\n        debug_exit_action = create_action(self, _(\"Stop\"),\r\n               icon=ima.icon('stop_debug'), tip=_(\"Stop debugging\"),\r\n               triggered=lambda: self.debug_command(\"exit\"))\r\n        self.register_shortcut(debug_exit_action, \"_\", \"Debug Exit\",\r\n                               add_sc_to_tip=True)\r\n\r\n        # --- Run toolbar ---\r\n        run_action = create_action(self, _(\"&Run\"), icon=ima.icon('run'),\r\n                                   tip=_(\"Run file\"),\r\n                                   triggered=self.run_file)\r\n        self.register_shortcut(run_action, context=\"_\", name=\"Run\",\r\n                               add_sc_to_tip=True)\r\n\r\n        configure_action = create_action(self, _(\"&Configuration per file...\"),\r\n                                         icon=ima.icon('run_settings'),\r\n                               tip=_(\"Run settings\"),\r\n                               menurole=QAction.NoRole,\r\n                               triggered=self.edit_run_configurations)\r\n        self.register_shortcut(configure_action, context=\"_\",\r\n                               name=\"Configure\", add_sc_to_tip=True)\r\n\r\n        re_run_action = create_action(self, _(\"Re-run &last script\"),\r\n                                      icon=ima.icon('run_again'),\r\n                            tip=_(\"Run again last file\"),\r\n                            triggered=self.re_run_file)\r\n        self.register_shortcut(re_run_action, context=\"_\",\r\n                               name=\"Re-run last script\",\r\n                               add_sc_to_tip=True)\r\n\r\n        run_selected_action = create_action(self, _(\"Run &selection or \"\r\n                                                    \"current line\"),\r\n                                            icon=ima.icon('run_selection'),\r\n                                            tip=_(\"Run selection or \"\r\n                                                  \"current line\"),\r\n                                            triggered=self.run_selection,\r\n                                            context=Qt.WidgetShortcut)\r\n        self.register_shortcut(run_selected_action, context=\"Editor\",\r\n                               name=\"Run selection\", add_sc_to_tip=True)\r\n\r\n        run_cell_action = create_action(self,\r\n                            _(\"Run cell\"),\r\n                            icon=ima.icon('run_cell'),\r\n                            shortcut=QKeySequence(RUN_CELL_SHORTCUT),\r\n                            tip=_(\"Run current cell (Ctrl+Enter)\\n\"\r\n                                  \"[Use #%% to create cells]\"),\r\n                            triggered=self.run_cell,\r\n                            context=Qt.WidgetShortcut)\r\n\r\n        run_cell_advance_action = create_action(self,\r\n                   _(\"Run cell and advance\"),\r\n                   icon=ima.icon('run_cell_advance'),\r\n                   shortcut=QKeySequence(RUN_CELL_AND_ADVANCE_SHORTCUT),\r\n                   tip=_(\"Run current cell and go to the next one \"\r\n                         \"(Shift+Enter)\"),\r\n                   triggered=self.run_cell_and_advance,\r\n                   context=Qt.WidgetShortcut)\r\n\r\n        re_run_last_cell_action = create_action(self,\r\n                   _(\"Re-run last cell\"),\r\n                   tip=_(\"Re run last cell \"),\r\n                   triggered=self.re_run_last_cell,\r\n                   context=Qt.WidgetShortcut)\r\n        self.register_shortcut(re_run_last_cell_action,\r\n                               context=\"Editor\",\r\n                               name='re-run last cell',\r\n                               add_sc_to_tip=True)\r\n\r\n        # --- Source code Toolbar ---\r\n        self.todo_list_action = create_action(self,\r\n                _(\"Show todo list\"), icon=ima.icon('todo_list'),\r\n                tip=_(\"Show comments list (TODO/FIXME/XXX/HINT/TIP/@todo/\"\r\n                      \"HACK/BUG/OPTIMIZE/!!!/???)\"),\r\n                triggered=self.go_to_next_todo)\r\n        self.todo_menu = QMenu(self)\r\n        self.todo_menu.setStyleSheet(\"QMenu {menu-scrollable: 1;}\")\r\n        self.todo_list_action.setMenu(self.todo_menu)\r\n        self.todo_menu.aboutToShow.connect(self.update_todo_menu)\r\n\r\n        self.warning_list_action = create_action(self,\r\n                _(\"Show warning/error list\"), icon=ima.icon('wng_list'),\r\n                tip=_(\"Show code analysis warnings/errors\"),\r\n                triggered=self.go_to_next_warning)\r\n        self.warning_menu = QMenu(self)\r\n        self.warning_menu.setStyleSheet(\"QMenu {menu-scrollable: 1;}\")\r\n        self.warning_list_action.setMenu(self.warning_menu)\r\n        self.warning_menu.aboutToShow.connect(self.update_warning_menu)\r\n        self.previous_warning_action = create_action(self,\r\n                _(\"Previous warning/error\"), icon=ima.icon('prev_wng'),\r\n                tip=_(\"Go to previous code analysis warning/error\"),\r\n                triggered=self.go_to_previous_warning,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.previous_warning_action,\r\n                               context=\"Editor\",\r\n                               name=\"Previous warning\",\r\n                               add_sc_to_tip=True)\r\n        self.next_warning_action = create_action(self,\r\n                _(\"Next warning/error\"), icon=ima.icon('next_wng'),\r\n                tip=_(\"Go to next code analysis warning/error\"),\r\n                triggered=self.go_to_next_warning,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.next_warning_action,\r\n                               context=\"Editor\",\r\n                               name=\"Next warning\",\r\n                               add_sc_to_tip=True)\r\n\r\n        self.previous_edit_cursor_action = create_action(self,\r\n                _(\"Last edit location\"), icon=ima.icon('last_edit_location'),\r\n                tip=_(\"Go to last edit location\"),\r\n                triggered=self.go_to_last_edit_location,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.previous_edit_cursor_action,\r\n                               context=\"Editor\",\r\n                               name=\"Last edit location\",\r\n                               add_sc_to_tip=True)\r\n        self.previous_cursor_action = create_action(self,\r\n                _(\"Previous cursor position\"), icon=ima.icon('prev_cursor'),\r\n                tip=_(\"Go to previous cursor position\"),\r\n                triggered=self.go_to_previous_cursor_position,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.previous_cursor_action,\r\n                               context=\"Editor\",\r\n                               name=\"Previous cursor position\",\r\n                               add_sc_to_tip=True)\r\n        self.next_cursor_action = create_action(self,\r\n                _(\"Next cursor position\"), icon=ima.icon('next_cursor'),\r\n                tip=_(\"Go to next cursor position\"),\r\n                triggered=self.go_to_next_cursor_position,\r\n                context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.next_cursor_action,\r\n                               context=\"Editor\",\r\n                               name=\"Next cursor position\",\r\n                               add_sc_to_tip=True)\r\n\r\n        # --- Edit Toolbar ---\r\n        self.toggle_comment_action = create_action(self,\r\n                _(\"Comment\")+\"/\"+_(\"Uncomment\"), icon=ima.icon('comment'),\r\n                tip=_(\"Comment current line or selection\"),\r\n                triggered=self.toggle_comment, context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.toggle_comment_action, context=\"Editor\",\r\n                               name=\"Toggle comment\")\r\n        blockcomment_action = create_action(self, _(\"Add &block comment\"),\r\n                tip=_(\"Add block comment around \"\r\n                            \"current line or selection\"),\r\n                triggered=self.blockcomment, context=Qt.WidgetShortcut)\r\n        self.register_shortcut(blockcomment_action, context=\"Editor\",\r\n                               name=\"Blockcomment\")\r\n        unblockcomment_action = create_action(self,\r\n                _(\"R&emove block comment\"),\r\n                tip = _(\"Remove comment block around \"\r\n                              \"current line or selection\"),\r\n                triggered=self.unblockcomment, context=Qt.WidgetShortcut)\r\n        self.register_shortcut(unblockcomment_action, context=\"Editor\",\r\n                               name=\"Unblockcomment\")\r\n\r\n        # ----------------------------------------------------------------------\r\n        # The following action shortcuts are hard-coded in CodeEditor\r\n        # keyPressEvent handler (the shortcut is here only to inform user):\r\n        # (context=Qt.WidgetShortcut -> disable shortcut for other widgets)\r\n        self.indent_action = create_action(self,\r\n                _(\"Indent\"), \"Tab\", icon=ima.icon('indent'),\r\n                tip=_(\"Indent current line or selection\"),\r\n                triggered=self.indent, context=Qt.WidgetShortcut)\r\n        self.unindent_action = create_action(self,\r\n                _(\"Unindent\"), \"Shift+Tab\", icon=ima.icon('unindent'),\r\n                tip=_(\"Unindent current line or selection\"),\r\n                triggered=self.unindent, context=Qt.WidgetShortcut)\r\n\r\n        self.text_uppercase_action = create_action(self,\r\n                _(\"Toggle Uppercase\"),\r\n                tip=_(\"Change to uppercase current line or selection\"),\r\n                triggered=self.text_uppercase, context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.text_uppercase_action, context=\"Editor\",\r\n                               name=\"transform to uppercase\")\r\n\r\n        self.text_lowercase_action = create_action(self,\r\n                _(\"Toggle Lowercase\"),\r\n                tip=_(\"Change to lowercase current line or selection\"),\r\n                triggered=self.text_lowercase, context=Qt.WidgetShortcut)\r\n        self.register_shortcut(self.text_lowercase_action, context=\"Editor\",\r\n                               name=\"transform to lowercase\")\r\n        # ----------------------------------------------------------------------\r\n\r\n        self.win_eol_action = create_action(self,\r\n                           _(\"Carriage return and line feed (Windows)\"),\r\n                           toggled=lambda checked: self.toggle_eol_chars('nt', checked))\r\n        self.linux_eol_action = create_action(self,\r\n                           _(\"Line feed (UNIX)\"),\r\n                           toggled=lambda checked: self.toggle_eol_chars('posix', checked))\r\n        self.mac_eol_action = create_action(self,\r\n                           _(\"Carriage return (Mac)\"),\r\n                           toggled=lambda checked: self.toggle_eol_chars('mac', checked))\r\n        eol_action_group = QActionGroup(self)\r\n        eol_actions = (self.win_eol_action, self.linux_eol_action,\r\n                       self.mac_eol_action)\r\n        add_actions(eol_action_group, eol_actions)\r\n        eol_menu = QMenu(_(\"Convert end-of-line characters\"), self)\r\n        add_actions(eol_menu, eol_actions)\r\n\r\n        trailingspaces_action = create_action(self,\r\n                                      _(\"Remove trailing spaces\"),\r\n                                      triggered=self.remove_trailing_spaces)\r\n\r\n        # Checkable actions\r\n        showblanks_action = self._create_checkable_action(\r\n                _(\"Show blank spaces\"), 'blank_spaces', 'set_blanks_enabled')\r\n\r\n        scrollpastend_action = self._create_checkable_action(\r\n                 _(\"Scroll past the end\"), 'scroll_past_end',\r\n                 'set_scrollpastend_enabled')\r\n\r\n        showindentguides_action = self._create_checkable_action(\r\n                _(\"Show indent guides.\"), 'indent_guides', 'set_indent_guides')\r\n\r\n        show_classfunc_dropdown_action = self._create_checkable_action(\r\n                _(\"Show selector for classes and functions.\"),\r\n                'show_class_func_dropdown', 'set_classfunc_dropdown_visible')\r\n\r\n        showcode_analysis_pep8_action = self._create_checkable_action(\r\n                _(\"Show code style warnings (pep8)\"),\r\n                'code_analysis/pep8', 'set_pep8_enabled')\r\n\r\n        self.checkable_actions = {\r\n                'blank_spaces': showblanks_action,\r\n                'scroll_past_end': scrollpastend_action,\r\n                'indent_guides': showindentguides_action,\r\n                'show_class_func_dropdown': show_classfunc_dropdown_action,\r\n                'code_analysis/pep8': showcode_analysis_pep8_action}\r\n\r\n        fixindentation_action = create_action(self, _(\"Fix indentation\"),\r\n                      tip=_(\"Replace tab characters by space characters\"),\r\n                      triggered=self.fix_indentation)\r\n\r\n        gotoline_action = create_action(self, _(\"Go to line...\"),\r\n                                        icon=ima.icon('gotoline'),\r\n                                        triggered=self.go_to_line,\r\n                                        context=Qt.WidgetShortcut)\r\n        self.register_shortcut(gotoline_action, context=\"Editor\",\r\n                               name=\"Go to line\")\r\n\r\n        workdir_action = create_action(self,\r\n                _(\"Set console working directory\"),\r\n                icon=ima.icon('DirOpenIcon'),\r\n                tip=_(\"Set current console (and file explorer) working \"\r\n                            \"directory to current script directory\"),\r\n                triggered=self.__set_workdir)\r\n\r\n        self.max_recent_action = create_action(self,\r\n            _(\"Maximum number of recent files...\"),\r\n            triggered=self.change_max_recent_files)\r\n        self.clear_recent_action = create_action(self,\r\n            _(\"Clear this list\"), tip=_(\"Clear recent files list\"),\r\n            triggered=self.clear_recent_files)\r\n\r\n        # ---- File menu/toolbar construction ----\r\n        self.recent_file_menu = QMenu(_(\"Open &recent\"), self)\r\n        self.recent_file_menu.aboutToShow.connect(self.update_recent_file_menu)\r\n\r\n        file_menu_actions = [self.new_action,\r\n                             MENU_SEPARATOR,\r\n                             self.open_action,\r\n                             self.open_last_closed_action,\r\n                             self.recent_file_menu,\r\n                             MENU_SEPARATOR,\r\n                             MENU_SEPARATOR,\r\n                             self.save_action,\r\n                             self.save_all_action,\r\n                             save_as_action,\r\n                             save_copy_as_action,\r\n                             self.revert_action,\r\n                             MENU_SEPARATOR,\r\n                             print_preview_action,\r\n                             self.print_action,\r\n                             MENU_SEPARATOR,\r\n                             self.close_action,\r\n                             self.close_all_action,\r\n                             MENU_SEPARATOR]\r\n\r\n        self.main.file_menu_actions += file_menu_actions\r\n        file_toolbar_actions = ([self.new_action, self.open_action,\r\n                                self.save_action, self.save_all_action] +\r\n                                self.main.file_toolbar_actions)\r\n\r\n        self.main.file_toolbar_actions = file_toolbar_actions\r\n\r\n        # ---- Find menu/toolbar construction ----\r\n        self.main.search_menu_actions = [find_action,\r\n                                         find_next_action,\r\n                                         find_previous_action,\r\n                                         replace_action]\r\n        self.main.search_toolbar_actions = [find_action,\r\n                                            find_next_action,\r\n                                            replace_action]\r\n\r\n        # ---- Edit menu/toolbar construction ----\r\n        self.edit_menu_actions = [self.toggle_comment_action,\r\n                                  blockcomment_action, unblockcomment_action,\r\n                                  self.indent_action, self.unindent_action,\r\n                                  self.text_uppercase_action,\r\n                                  self.text_lowercase_action]\r\n        self.main.edit_menu_actions += [MENU_SEPARATOR] + self.edit_menu_actions\r\n        edit_toolbar_actions = [self.toggle_comment_action,\r\n                                self.unindent_action, self.indent_action]\r\n        self.main.edit_toolbar_actions += edit_toolbar_actions\r\n\r\n        # ---- Search menu/toolbar construction ----\r\n        self.main.search_menu_actions += [gotoline_action]\r\n        self.main.search_toolbar_actions += [gotoline_action]\r\n\r\n        # ---- Run menu/toolbar construction ----\r\n        run_menu_actions = [run_action, run_cell_action,\r\n                            run_cell_advance_action,\r\n                            re_run_last_cell_action, MENU_SEPARATOR,\r\n                            run_selected_action, re_run_action,\r\n                            configure_action, MENU_SEPARATOR]\r\n        self.main.run_menu_actions += run_menu_actions\r\n        run_toolbar_actions = [run_action, run_cell_action,\r\n                               run_cell_advance_action, run_selected_action,\r\n                               re_run_action]\r\n        self.main.run_toolbar_actions += run_toolbar_actions\r\n\r\n        # ---- Debug menu/toolbar construction ----\r\n        # NOTE: 'list_breakpoints' is used by the breakpoints\r\n        # plugin to add its \"List breakpoints\" action to this\r\n        # menu\r\n        debug_menu_actions = [debug_action,\r\n                              debug_next_action,\r\n                              debug_step_action,\r\n                              debug_return_action,\r\n                              debug_continue_action,\r\n                              debug_exit_action,\r\n                              MENU_SEPARATOR,\r\n                              set_clear_breakpoint_action,\r\n                              set_cond_breakpoint_action,\r\n                              clear_all_breakpoints_action,\r\n                              'list_breakpoints',\r\n                              MENU_SEPARATOR,\r\n                              self.winpdb_action]\r\n        self.main.debug_menu_actions += debug_menu_actions\r\n        debug_toolbar_actions = [debug_action, debug_next_action,\r\n                                 debug_step_action, debug_return_action,\r\n                                 debug_continue_action, debug_exit_action]\r\n        self.main.debug_toolbar_actions += debug_toolbar_actions\r\n\r\n        # ---- Source menu/toolbar construction ----\r\n        source_menu_actions = [eol_menu,\r\n                               showblanks_action,\r\n                               scrollpastend_action,\r\n                               showindentguides_action,\r\n                               show_classfunc_dropdown_action,\r\n                               showcode_analysis_pep8_action,\r\n                               trailingspaces_action,\r\n                               fixindentation_action,\r\n                               MENU_SEPARATOR,\r\n                               self.todo_list_action,\r\n                               self.warning_list_action,\r\n                               self.previous_warning_action,\r\n                               self.next_warning_action,\r\n                               MENU_SEPARATOR,\r\n                               self.previous_edit_cursor_action,\r\n                               self.previous_cursor_action,\r\n                               self.next_cursor_action]\r\n        self.main.source_menu_actions += source_menu_actions\r\n\r\n        source_toolbar_actions = [self.todo_list_action,\r\n                                  self.warning_list_action,\r\n                                  self.previous_warning_action,\r\n                                  self.next_warning_action,\r\n                                  MENU_SEPARATOR,\r\n                                  self.previous_edit_cursor_action,\r\n                                  self.previous_cursor_action,\r\n                                  self.next_cursor_action]\r\n        self.main.source_toolbar_actions += source_toolbar_actions\r\n\r\n        # ---- Dock widget and file dependent actions ----\r\n        self.dock_toolbar_actions = (file_toolbar_actions +\r\n                                     [MENU_SEPARATOR] +\r\n                                     source_toolbar_actions +\r\n                                     [MENU_SEPARATOR] +\r\n                                     run_toolbar_actions +\r\n                                     [MENU_SEPARATOR] +\r\n                                     debug_toolbar_actions +\r\n                                     [MENU_SEPARATOR] +\r\n                                     edit_toolbar_actions)\r\n        self.pythonfile_dependent_actions = [run_action, configure_action,\r\n                                             set_clear_breakpoint_action,\r\n                                             set_cond_breakpoint_action,\r\n                                             debug_action, run_selected_action,\r\n                                             run_cell_action,\r\n                                             run_cell_advance_action,\r\n                                             re_run_last_cell_action,\r\n                                             blockcomment_action,\r\n                                             unblockcomment_action,\r\n                                             self.winpdb_action]\r\n        self.cythonfile_compatible_actions = [run_action, configure_action]\r\n        self.file_dependent_actions = self.pythonfile_dependent_actions + \\\r\n                [self.save_action, save_as_action, save_copy_as_action,\r\n                 print_preview_action, self.print_action,\r\n                 self.save_all_action, gotoline_action, workdir_action,\r\n                 self.close_action, self.close_all_action,\r\n                 self.toggle_comment_action, self.revert_action,\r\n                 self.indent_action, self.unindent_action]\r\n        self.stack_menu_actions = [gotoline_action, workdir_action]\r\n\r\n        return self.file_dependent_actions", "response": "Return a list of actions related to the plugin"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.main.restore_scrollbar_position.connect(\r\n            self.restore_scrollbar_position)\r\n        self.main.console.edit_goto.connect(self.load)\r\n        self.exec_in_extconsole.connect(self.main.execute_in_external_console)\r\n        self.redirect_stdio.connect(self.main.redirect_internalshell_stdio)\r\n        self.open_dir.connect(self.main.workingdirectory.chdir)\r\n        self.set_help(self.main.help)\r\n        if self.main.outlineexplorer is not None:\r\n            self.set_outlineexplorer(self.main.outlineexplorer)\r\n        editorstack = self.get_current_editorstack()\r\n        if not editorstack.data:\r\n            self.__load_temp_file()\r\n        self.main.add_dockwidget(self)\r\n        self.main.add_to_fileswitcher(self, editorstack.tabs, editorstack.data,\r\n                                      ima.icon('TextFileIcon'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates font from Preferences", "response": "def update_font(self):\r\n        \"\"\"Update font from Preferences\"\"\"\r\n        font = self.get_plugin_font()\r\n        color_scheme = self.get_color_scheme()\r\n        for editorstack in self.editorstacks:\r\n            editorstack.set_default_font(font, color_scheme)\r\n            completion_size = CONF.get('main', 'completion/size')\r\n            for finfo in editorstack.data:\r\n                comp_widget = finfo.editor.completion_widget\r\n                comp_widget.setup_appearance(completion_size, font)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _toggle_checkable_action(self, checked, editorstack_method, conf_name):\r\n        if self.editorstacks:\r\n            for editorstack in self.editorstacks:\r\n                try:\r\n                    editorstack.__getattribute__(editorstack_method)(checked)\r\n                except AttributeError as e:\r\n                    logger.error(e, exc_info=True)\r\n                # Run code analysis when `set_pep8_enabled` is toggled\r\n                if editorstack_method == 'set_pep8_enabled':\r\n                    # TODO: Connect this to the LSP\r\n                    #for finfo in editorstack.data:\r\n                    #    finfo.run_code_analysis(\r\n                    #            self.get_option('code_analysis/pyflakes'),\r\n                    #            checked)\r\n                    pass\r\n        CONF.set('editor', conf_name, checked)", "response": "Handles the toogle of a checkable action."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef received_sig_option_changed(self, option, value):\r\n        if option == 'autosave_mapping':\r\n            for editorstack in self.editorstacks:\r\n                if editorstack != self.sender():\r\n                    editorstack.autosave_mapping = value\r\n        self.sig_option_changed.emit(option, value)", "response": "Called when a signal is received when an option being changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the given editorstack only if it s not the last remaining", "response": "def unregister_editorstack(self, editorstack):\r\n        \"\"\"Removing editorstack only if it's not the last remaining\"\"\"\r\n        self.remove_last_focus_editorstack(editorstack)\r\n        if len(self.editorstacks) > 1:\r\n            index = self.editorstacks.index(editorstack)\r\n            self.editorstacks.pop(index)\r\n            return True\r\n        else:\r\n            # editorstack was not removed!\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_other_windows(self):\r\n\r\n        self.toolbar_list = ((_(\"File toolbar\"), \"file_toolbar\",\r\n                              self.main.file_toolbar_actions),\r\n                             (_(\"Search toolbar\"), \"search_toolbar\",\r\n                              self.main.search_menu_actions),\r\n                             (_(\"Source toolbar\"), \"source_toolbar\",\r\n                              self.main.source_toolbar_actions),\r\n                             (_(\"Run toolbar\"), \"run_toolbar\",\r\n                              self.main.run_toolbar_actions),\r\n                             (_(\"Debug toolbar\"), \"debug_toolbar\",\r\n                              self.main.debug_toolbar_actions),\r\n                             (_(\"Edit toolbar\"), \"edit_toolbar\",\r\n                              self.main.edit_toolbar_actions))\r\n        self.menu_list = ((_(\"&File\"), self.main.file_menu_actions),\r\n                          (_(\"&Edit\"), self.main.edit_menu_actions),\r\n                          (_(\"&Search\"), self.main.search_menu_actions),\r\n                          (_(\"Sour&ce\"), self.main.source_menu_actions),\r\n                          (_(\"&Run\"), self.main.run_menu_actions),\r\n                          (_(\"&Tools\"), self.main.tools_menu_actions),\r\n                          (_(\"&View\"), []),\r\n                          (_(\"&Help\"), self.main.help_menu_actions))\r\n        # Create pending new windows:\r\n        for layout_settings in self.editorwindows_to_be_created:\r\n            win = self.create_new_window()\r\n            win.set_layout_settings(layout_settings)", "response": "Setup toolbars and menus for other windows"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_current_filename(self, filename, editorwindow=None, focus=True):\r\n        editorstack = self.get_current_editorstack(editorwindow)\r\n        return editorstack.set_current_filename(filename, focus)", "response": "Set focus to filename if this file has been opened."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables or disable file dependent actions", "response": "def refresh_file_dependent_actions(self):\r\n        \"\"\"Enable/disable file dependent actions\r\n        (only if dockwidget is visible)\"\"\"\r\n        if self.dockwidget and self.dockwidget.isVisible():\r\n            enable = self.get_current_editor() is not None\r\n            for action in self.file_dependent_actions:\r\n                action.setEnabled(enable)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenable Save All action if there are files to be saved", "response": "def refresh_save_all_action(self):\r\n        \"\"\"Enable 'Save All' if there are files to be saved\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack:\r\n            state = any(finfo.editor.document().isModified() or finfo.newly_created\r\n                        for finfo in editorstack.data)\r\n            self.save_all_action.setEnabled(state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating warning list menu", "response": "def update_warning_menu(self):\r\n        \"\"\"Update warning list menu\"\"\"\r\n        editor = self.get_current_editor()\r\n        check_results = editor.get_current_warnings()\r\n        self.warning_menu.clear()\r\n        filename = self.get_current_filename()\r\n        for message, line_number in check_results:\r\n            error = 'syntax' in message\r\n            text = message[:1].upper() + message[1:]\r\n            icon = ima.icon('error') if error else ima.icon('warning')\r\n            slot = lambda _checked, _l=line_number: self.load(filename, goto=_l)\r\n            action = create_action(self, text=text, icon=icon, triggered=slot)\r\n            self.warning_menu.addAction(action)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates todo list menu", "response": "def update_todo_menu(self):\r\n        \"\"\"Update todo list menu\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        results = editorstack.get_todo_results()\r\n        self.todo_menu.clear()\r\n        filename = self.get_current_filename()\r\n        for text, line0 in results:\r\n            icon = ima.icon('todo')\r\n            slot = lambda _checked, _l=line0: self.load(filename, goto=_l)\r\n            action = create_action(self, text=text, icon=icon, triggered=slot)\r\n            self.todo_menu.addAction(action)\r\n        self.update_todo_actions()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the todo results of the editorstacks with the new values.", "response": "def todo_results_changed(self):\r\n        \"\"\"\r\n        Synchronize todo results between editorstacks\r\n        Refresh todo list navigation buttons\r\n        \"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        results = editorstack.get_todo_results()\r\n        index = editorstack.get_stack_index()\r\n        if index != -1:\r\n            filename = editorstack.data[index].filename\r\n            for other_editorstack in self.editorstacks:\r\n                if other_editorstack is not editorstack:\r\n                    other_editorstack.set_todo_results(filename, results)\r\n        self.update_todo_actions()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef opened_files_list_changed(self):\r\n        # Refresh Python file dependent actions:\r\n        editor = self.get_current_editor()\r\n        if editor:\r\n            python_enable = editor.is_python()\r\n            cython_enable = python_enable or (\r\n                programs.is_module_installed('Cython') and editor.is_cython())\r\n            for action in self.pythonfile_dependent_actions:\r\n                if action in self.cythonfile_compatible_actions:\r\n                    enable = cython_enable\r\n                else:\r\n                    enable = python_enable\r\n                if action is self.winpdb_action:\r\n                    action.setEnabled(enable and WINPDB_PATH is not None)\r\n                else:\r\n                    action.setEnabled(enable)\r\n            self.open_file_update.emit(self.get_current_filename())", "response": "Updates the action list with the new values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_code_analysis_actions(self):\r\n        editor = self.get_current_editor()\r\n        # To fix an error at startup\r\n        if editor is None:\r\n            return\r\n        results = editor.get_current_warnings()\r\n        # Update code analysis buttons\r\n        state = (self.get_option('code_analysis/pyflakes') \\\r\n                 or self.get_option('code_analysis/pep8')) \\\r\n                 and results is not None and len(results)\r\n        for action in (self.warning_list_action, self.previous_warning_action,\r\n                       self.next_warning_action):\r\n            if state is not None:\r\n                action.setEnabled(state)", "response": "Update actions in the warnings menu."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreceives bookmark changes and save them.", "response": "def save_bookmarks(self, filename, bookmarks):\r\n        \"\"\"Receive bookmark changes and save them.\"\"\"\r\n        filename = to_text_string(filename)\r\n        bookmarks = to_text_string(bookmarks)\r\n        filename = osp.normpath(osp.abspath(filename))\r\n        bookmarks = eval(bookmarks)\r\n        save_bookmarks(filename, bookmarks)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __load_temp_file(self):\r\n        if not osp.isfile(self.TEMPFILE_PATH):\r\n            # Creating temporary file\r\n            default = ['# -*- coding: utf-8 -*-',\r\n                       '\"\"\"', _(\"Spyder Editor\"), '',\r\n                       _(\"This is a temporary script file.\"),\r\n                       '\"\"\"', '', '']\r\n            text = os.linesep.join([encoding.to_unicode(qstr)\r\n                                    for qstr in default])\r\n            try:\r\n                encoding.write(to_text_string(text), self.TEMPFILE_PATH,\r\n                               'utf-8')\r\n            except EnvironmentError:\r\n                self.new()\r\n                return\r\n\r\n        self.load(self.TEMPFILE_PATH)", "response": "Load a temporary file from a text file in user home directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __set_workdir(self):\r\n        fname = self.get_current_filename()\r\n        if fname is not None:\r\n            directory = osp.dirname(osp.abspath(fname))\r\n            self.open_dir.emit(directory)", "response": "Set current script directory as working directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new entry to the recent file list", "response": "def __add_recent_file(self, fname):\r\n        \"\"\"Add to recent file list\"\"\"\r\n        if fname is None:\r\n            return\r\n        if fname in self.recent_files:\r\n            self.recent_files.remove(fname)\r\n        self.recent_files.insert(0, fname)\r\n        if len(self.recent_files) > self.get_option('max_recent_files'):\r\n            self.recent_files.pop(-1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _clone_file_everywhere(self, finfo):\r\n        for editorstack in self.editorstacks[1:]:\r\n            editor = editorstack.clone_editor_from(finfo, set_current=False)\r\n            self.register_widget_shortcuts(editor)", "response": "Cloning from the first editorstack in which every new editor is created"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new(self, fname=None, editorstack=None, text=None):\r\n        # If no text is provided, create default content\r\n        empty = False\r\n        try:\r\n            if text is None:\r\n                default_content = True\r\n                text, enc = encoding.read(self.TEMPLATE_PATH)\r\n                enc_match = re.search(r'-*- coding: ?([a-z0-9A-Z\\-]*) -*-',\r\n                                      text)\r\n                if enc_match:\r\n                    enc = enc_match.group(1)\r\n                # Initialize template variables\r\n                # Windows\r\n                username = encoding.to_unicode_from_fs(\r\n                                os.environ.get('USERNAME', ''))\r\n                # Linux, Mac OS X\r\n                if not username:\r\n                    username = encoding.to_unicode_from_fs(\r\n                                   os.environ.get('USER', '-'))\r\n                VARS = {\r\n                    'date': time.ctime(),\r\n                    'username': username,\r\n                }\r\n                try:\r\n                    text = text % VARS\r\n                except Exception:\r\n                    pass\r\n            else:\r\n                default_content = False\r\n                enc = encoding.read(self.TEMPLATE_PATH)[1]\r\n        except (IOError, OSError):\r\n            text = ''\r\n            enc = 'utf-8'\r\n            default_content = True\r\n            empty = True\r\n\r\n        create_fname = lambda n: to_text_string(_(\"untitled\")) + (\"%d.py\" % n)\r\n        # Creating editor widget\r\n        if editorstack is None:\r\n            current_es = self.get_current_editorstack()\r\n        else:\r\n            current_es = editorstack\r\n        created_from_here = fname is None\r\n        if created_from_here:\r\n            while True:\r\n                fname = create_fname(self.untitled_num)\r\n                self.untitled_num += 1\r\n                if not osp.isfile(fname):\r\n                    break\r\n            basedir = getcwd_or_home()\r\n\r\n            if self.main.projects.get_active_project() is not None:\r\n                basedir = self.main.projects.get_active_project_path()\r\n            else:\r\n                c_fname = self.get_current_filename()\r\n                if c_fname is not None and c_fname != self.TEMPFILE_PATH:\r\n                    basedir = osp.dirname(c_fname)\r\n            fname = osp.abspath(osp.join(basedir, fname))\r\n        else:\r\n            # QString when triggered by a Qt signal\r\n            fname = osp.abspath(to_text_string(fname))\r\n            index = current_es.has_filename(fname)\r\n            if index is not None and not current_es.close_file(index):\r\n                return\r\n\r\n        # Creating the editor widget in the first editorstack (the one that\r\n        # can't be destroyed), then cloning this editor widget in all other\r\n        # editorstacks:\r\n        finfo = self.editorstacks[0].new(fname, enc, text, default_content,\r\n                                         empty)\r\n        finfo.path = self.main.get_spyder_pythonpath()\r\n        self._clone_file_everywhere(finfo)\r\n        current_editor = current_es.set_current_filename(finfo.filename)\r\n        self.register_widget_shortcuts(current_editor)\r\n        if not created_from_here:\r\n            self.save(force=True)", "response": "Create a new file and return a dictionary of the created file attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_recent_file_menu(self):\r\n        recent_files = []\r\n        for fname in self.recent_files:\r\n            if self.is_file_opened(fname) is None and osp.isfile(fname):\r\n                recent_files.append(fname)\r\n        self.recent_file_menu.clear()\r\n        if recent_files:\r\n            for fname in recent_files:\r\n                action = create_action(self, fname,\r\n                                       icon=ima.icon('FileIcon'),\r\n                                       triggered=self.load)\r\n                action.setData(to_qvariant(fname))\r\n                self.recent_file_menu.addAction(action)\r\n        self.clear_recent_action.setEnabled(len(recent_files) > 0)\r\n        add_actions(self.recent_file_menu, (None, self.max_recent_action,\r\n                                            self.clear_recent_action))", "response": "Update the recent file menu"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, filenames=None, goto=None, word='',\r\n             editorwindow=None, processevents=True, start_column=None,\r\n             set_focus=True, add_where='end'):\r\n        \"\"\"\r\n        Load a text file\r\n        editorwindow: load in this editorwindow (useful when clicking on\r\n        outline explorer with multiple editor windows)\r\n        processevents: determines if processEvents() should be called at the\r\n        end of this method (set to False to prevent keyboard events from\r\n        creeping through to the editor during debugging)\r\n        \"\"\"\r\n        # Switch to editor before trying to load a file\r\n        try:\r\n            self.switch_to_plugin()\r\n        except AttributeError:\r\n            pass\r\n\r\n        editor0 = self.get_current_editor()\r\n        if editor0 is not None:\r\n            position0 = editor0.get_position('cursor')\r\n            filename0 = self.get_current_filename()\r\n        else:\r\n            position0, filename0 = None, None\r\n        if not filenames:\r\n            # Recent files action\r\n            action = self.sender()\r\n            if isinstance(action, QAction):\r\n                filenames = from_qvariant(action.data(), to_text_string)\r\n        if not filenames:\r\n            basedir = getcwd_or_home()\r\n            if self.edit_filetypes is None:\r\n                self.edit_filetypes = get_edit_filetypes()\r\n            if self.edit_filters is None:\r\n                self.edit_filters = get_edit_filters()\r\n\r\n            c_fname = self.get_current_filename()\r\n            if c_fname is not None and c_fname != self.TEMPFILE_PATH:\r\n                basedir = osp.dirname(c_fname)\r\n            self.redirect_stdio.emit(False)\r\n            parent_widget = self.get_current_editorstack()\r\n            if filename0 is not None:\r\n                selectedfilter = get_filter(self.edit_filetypes,\r\n                                            osp.splitext(filename0)[1])\r\n            else:\r\n                selectedfilter = ''\r\n            if not running_under_pytest():\r\n                filenames, _sf = getopenfilenames(\r\n                                    parent_widget,\r\n                                    _(\"Open file\"), basedir,\r\n                                    self.edit_filters,\r\n                                    selectedfilter=selectedfilter,\r\n                                    options=QFileDialog.HideNameFilterDetails)\r\n            else:\r\n                # Use a Qt (i.e. scriptable) dialog for pytest\r\n                dialog = QFileDialog(parent_widget, _(\"Open file\"),\r\n                                     options=QFileDialog.DontUseNativeDialog)\r\n                if dialog.exec_():\r\n                    filenames = dialog.selectedFiles()\r\n            self.redirect_stdio.emit(True)\r\n            if filenames:\r\n                filenames = [osp.normpath(fname) for fname in filenames]\r\n            else:\r\n                return\r\n\r\n        focus_widget = QApplication.focusWidget()\r\n        if self.editorwindows and not self.dockwidget.isVisible():\r\n            # We override the editorwindow variable to force a focus on\r\n            # the editor window instead of the hidden editor dockwidget.\r\n            # See PR #5742.\r\n            if editorwindow not in self.editorwindows:\r\n                editorwindow = self.editorwindows[0]\r\n            editorwindow.setFocus()\r\n            editorwindow.raise_()\r\n        elif (self.dockwidget and not self.ismaximized\r\n              and not self.dockwidget.isAncestorOf(focus_widget)\r\n              and not isinstance(focus_widget, CodeEditor)):\r\n            self.dockwidget.setVisible(True)\r\n            self.dockwidget.setFocus()\r\n            self.dockwidget.raise_()\r\n\r\n        def _convert(fname):\r\n            fname = osp.abspath(encoding.to_unicode_from_fs(fname))\r\n            if os.name == 'nt' and len(fname) >= 2 and fname[1] == ':':\r\n                fname = fname[0].upper()+fname[1:]\r\n            return fname\r\n\r\n        if hasattr(filenames, 'replaceInStrings'):\r\n            # This is a QStringList instance (PyQt API #1), converting to list:\r\n            filenames = list(filenames)\r\n        if not isinstance(filenames, list):\r\n            filenames = [_convert(filenames)]\r\n        else:\r\n            filenames = [_convert(fname) for fname in list(filenames)]\r\n        if isinstance(goto, int):\r\n            goto = [goto]\r\n        elif goto is not None and len(goto) != len(filenames):\r\n            goto = None\r\n\r\n        for index, filename in enumerate(filenames):\r\n            # -- Do not open an already opened file\r\n            focus = set_focus and index == 0\r\n            current_editor = self.set_current_filename(filename,\r\n                                                       editorwindow,\r\n                                                       focus=focus)\r\n            if current_editor is None:\r\n                # -- Not a valid filename:\r\n                if not osp.isfile(filename):\r\n                    continue\r\n                # --\r\n                current_es = self.get_current_editorstack(editorwindow)\r\n                # Creating the editor widget in the first editorstack\r\n                # (the one that can't be destroyed), then cloning this\r\n                # editor widget in all other editorstacks:\r\n                finfo = self.editorstacks[0].load(\r\n                    filename, set_current=False, add_where=add_where)\r\n                finfo.path = self.main.get_spyder_pythonpath()\r\n                self._clone_file_everywhere(finfo)\r\n                current_editor = current_es.set_current_filename(filename,\r\n                                                                 focus=focus)\r\n                current_editor.debugger.load_breakpoints()\r\n                current_editor.set_bookmarks(load_bookmarks(filename))\r\n                self.register_widget_shortcuts(current_editor)\r\n                current_es.analyze_script()\r\n                self.__add_recent_file(filename)\r\n            if goto is not None: # 'word' is assumed to be None as well\r\n                current_editor.go_to_line(goto[index], word=word,\r\n                                          start_column=start_column)\r\n                position = current_editor.get_position('cursor')\r\n                self.cursor_moved(filename0, position0, filename, position)\r\n            current_editor.clearFocus()\r\n            current_editor.setFocus()\r\n            current_editor.window().raise_()\r\n            if processevents:\r\n                QApplication.processEvents()\r\n            else:\r\n                # processevents is false only when calling from debugging\r\n                current_editor.sig_debug_stop.emit(goto[index])\r\n                current_sw = self.main.ipyconsole.get_current_shellwidget()\r\n                current_sw.sig_prompt_ready.connect(\r\n                    current_editor.sig_debug_stop[()].emit)", "response": "Load a text file into the editor window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_preview(self):\r\n        from qtpy.QtPrintSupport import QPrintPreviewDialog\r\n\r\n        editor = self.get_current_editor()\r\n        printer = Printer(mode=QPrinter.HighResolution,\r\n                          header_font=self.get_plugin_font('printer_header'))\r\n        preview = QPrintPreviewDialog(printer, self)\r\n        preview.setWindowFlags(Qt.Window)\r\n        preview.paintRequested.connect(lambda printer: editor.print_(printer))\r\n        self.redirect_stdio.emit(False)\r\n        preview.exec_()\r\n        self.redirect_stdio.emit(True)", "response": "Print preview for current file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, index=None, force=False):\r\n        editorstack = self.get_current_editorstack()\r\n        return editorstack.save(index=index, force=force)", "response": "Save file in the current editorstack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the currently edited file as the currently edited file", "response": "def save_as(self):\r\n        \"\"\"Save *as* the currently edited file\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack.save_as():\r\n            fname = editorstack.get_current_filename()\r\n            self.__add_recent_file(fname)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreopen the last closed tab.", "response": "def open_last_closed(self):\r\n        \"\"\" Reopens the last closed tab.\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        last_closed_files = editorstack.get_last_closed_files()\r\n        if (len(last_closed_files) > 0):\r\n            file_to_open = last_closed_files[0]\r\n            last_closed_files.remove(file_to_open)\r\n            editorstack.set_last_closed_files(last_closed_files)\r\n            self.load(file_to_open)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_file_from_name(self, filename):\r\n        filename = osp.abspath(to_text_string(filename))\r\n        index = self.editorstacks[0].has_filename(filename)\r\n        if index is not None:\r\n            self.editorstacks[0].close_file(index)", "response": "Close file from its name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef removed_tree(self, dirname):\r\n        dirname = osp.abspath(to_text_string(dirname))\r\n        for fname in self.get_filenames():\r\n            if osp.abspath(fname).startswith(dirname):\r\n                self.close_file_from_name(fname)", "response": "Close all files in the tree that are not in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfile was renamed in file explorer widget or in project explorer", "response": "def renamed(self, source, dest):\r\n        \"\"\"File was renamed in file explorer widget or in project explorer\"\"\"\r\n        filename = osp.abspath(to_text_string(source))\r\n        index = self.editorstacks[0].has_filename(filename)\r\n        if index is not None:\r\n            for editorstack in self.editorstacks:\r\n                editorstack.rename_in_data(filename,\r\n                                           new_filename=to_text_string(dest))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun winpdb to debug current file", "response": "def run_winpdb(self):\r\n        \"\"\"Run winpdb to debug current file\"\"\"\r\n        if self.save():\r\n            fname = self.get_current_filename()\r\n            runconf = get_run_configuration(fname)\r\n            if runconf is None:\r\n                args = []\r\n                wdir = None\r\n            else:\r\n                args = runconf.get_arguments().split()\r\n                wdir = runconf.get_working_directory()\r\n            # Handle the case where wdir comes back as an empty string\r\n            # when the working directory dialog checkbox is unchecked.\r\n            # (subprocess \"cwd\" default is None, so empty str\r\n            # must be changed to None in this case.)\r\n            programs.run_program(WINPDB_PATH, [fname] + args, cwd=wdir or None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cursor_moved(self, filename0, position0, filename1, position1):\r\n        if position0 is not None:\r\n            self.add_cursor_position_to_history(filename0, position0)\r\n        self.add_cursor_position_to_history(filename1, position1)", "response": "Add cursor position to history."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening go to line dialog", "response": "def go_to_line(self, line=None):\r\n        \"\"\"Open 'go to line' dialog\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack is not None:\r\n            editorstack.go_to_line(line)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset or Clear breakpoint", "response": "def set_or_clear_breakpoint(self):\r\n        \"\"\"Set/Clear breakpoint\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack is not None:\r\n            self.switch_to_plugin()\r\n            editorstack.set_or_clear_breakpoint()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset or edit a conditional breakpoint", "response": "def set_or_edit_conditional_breakpoint(self):\r\n        \"\"\"Set/Edit conditional breakpoint\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack is not None:\r\n            self.switch_to_plugin()\r\n            editorstack.set_or_edit_conditional_breakpoint()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_all_breakpoints(self):\r\n        self.switch_to_plugin()\r\n        clear_all_breakpoints()\r\n        self.breakpoints_saved.emit()\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack is not None:\r\n            for data in editorstack.data:\r\n                data.editor.debugger.clear_breakpoints()\r\n        self.refresh_plugin()", "response": "Clear all breakpoints in all files"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a single breakpoint from the debugger", "response": "def clear_breakpoint(self, filename, lineno):\r\n        \"\"\"Remove a single breakpoint\"\"\"\r\n        clear_breakpoint(filename, lineno)\r\n        self.breakpoints_saved.emit()\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack is not None:\r\n            index = self.is_file_opened(filename)\r\n            if index is not None:\r\n                editorstack.data[index].editor.debugger.toogle_breakpoint(\r\n                        lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a file inside the current interpreter or in a new one", "response": "def run_file(self, debug=False):\r\n        \"\"\"Run script inside current interpreter or in a new one\"\"\"\r\n        editorstack = self.get_current_editorstack()\r\n        if editorstack.save():\r\n            editor = self.get_current_editor()\r\n            fname = osp.abspath(self.get_current_filename())\r\n\r\n            # Get fname's dirname before we escape the single and double\r\n            # quotes (Fixes Issue #6771)\r\n            dirname = osp.dirname(fname)\r\n\r\n            # Escape single and double quotes in fname and dirname\r\n            # (Fixes Issue #2158)\r\n            fname = fname.replace(\"'\", r\"\\'\").replace('\"', r'\\\"')\r\n            dirname = dirname.replace(\"'\", r\"\\'\").replace('\"', r'\\\"')\r\n\r\n            runconf = get_run_configuration(fname)\r\n            if runconf is None:\r\n                dialog = RunConfigOneDialog(self)\r\n                dialog.size_change.connect(lambda s: self.set_dialog_size(s))\r\n                if self.dialog_size is not None:\r\n                    dialog.resize(self.dialog_size)\r\n                dialog.setup(fname)\r\n                if CONF.get('run', 'open_at_least_once',\r\n                            not running_under_pytest()):\r\n                    # Open Run Config dialog at least once: the first time\r\n                    # a script is ever run in Spyder, so that the user may\r\n                    # see it at least once and be conscious that it exists\r\n                    show_dlg = True\r\n                    CONF.set('run', 'open_at_least_once', False)\r\n                else:\r\n                    # Open Run Config dialog only\r\n                    # if ALWAYS_OPEN_FIRST_RUN_OPTION option is enabled\r\n                    show_dlg = CONF.get('run', ALWAYS_OPEN_FIRST_RUN_OPTION)\r\n                if show_dlg and not dialog.exec_():\r\n                    return\r\n                runconf = dialog.get_configuration()\r\n\r\n            args = runconf.get_arguments()\r\n            python_args = runconf.get_python_arguments()\r\n            interact = runconf.interact\r\n            post_mortem = runconf.post_mortem\r\n            current = runconf.current\r\n            systerm = runconf.systerm\r\n            clear_namespace = runconf.clear_namespace\r\n\r\n            if runconf.file_dir:\r\n                wdir = dirname\r\n            elif runconf.cw_dir:\r\n                wdir = ''\r\n            elif osp.isdir(runconf.dir):\r\n                wdir = runconf.dir\r\n            else:\r\n                wdir = ''\r\n\r\n            python = True # Note: in the future, it may be useful to run\r\n            # something in a terminal instead of a Python interp.\r\n            self.__last_ec_exec = (fname, wdir, args, interact, debug,\r\n                                   python, python_args, current, systerm,\r\n                                   post_mortem, clear_namespace)\r\n            self.re_run_file()\r\n            if not interact and not debug:\r\n                # If external console dockwidget is hidden, it will be\r\n                # raised in top-level and so focus will be given to the\r\n                # current external shell automatically\r\n                # (see SpyderPluginWidget.visibility_changed method)\r\n                editor.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave current line and position as bookmark.", "response": "def save_bookmark(self, slot_num):\r\n        \"\"\"Save current line and position as bookmark.\"\"\"\r\n        bookmarks = CONF.get('editor', 'bookmarks')\r\n        editorstack = self.get_current_editorstack()\r\n        if slot_num in bookmarks:\r\n            filename, line_num, column = bookmarks[slot_num]\r\n            if osp.isfile(filename):\r\n                index = editorstack.has_filename(filename)\r\n                if index is not None:\r\n                    block = (editorstack.tabs.widget(index).document()\r\n                             .findBlockByNumber(line_num))\r\n                    block.userData().bookmarks.remove((slot_num, column))\r\n        if editorstack is not None:\r\n            self.switch_to_plugin()\r\n            editorstack.set_bookmark(slot_num)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_bookmark(self, slot_num):\r\n        bookmarks = CONF.get('editor', 'bookmarks')\r\n        if slot_num in bookmarks:\r\n            filename, line_num, column = bookmarks[slot_num]\r\n        else:\r\n            return\r\n        if not osp.isfile(filename):\r\n            self.last_edit_cursor_pos = None\r\n            return\r\n        self.load(filename)\r\n        editor = self.get_current_editor()\r\n        if line_num < editor.document().lineCount():\r\n            linelength = len(editor.document()\r\n                             .findBlockByNumber(line_num).text())\r\n            if column <= linelength:\r\n                editor.go_to_line(line_num + 1, column)\r\n            else:\r\n                # Last column\r\n                editor.go_to_line(line_num + 1, linelength)", "response": "Load a bookmarked file and position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nzoom in or out by factor", "response": "def zoom(self, factor):\r\n        \"\"\"Zoom in/out/reset\"\"\"\r\n        editor = self.get_current_editorstack().get_current_editor()\r\n        if factor == 0:\r\n            font = self.get_plugin_font()\r\n            editor.set_font(font)\r\n        else:\r\n            font = editor.font()\r\n            size = font.pointSize() + factor\r\n            if size > 0:\r\n                font.setPointSize(size)\r\n                editor.set_font(font)\r\n        editor.update_tab_stop_width_spaces()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying configuration file s plugin settings to the given options.", "response": "def apply_plugin_settings(self, options):\r\n        \"\"\"Apply configuration file's plugin settings\"\"\"\r\n        if self.editorstacks is not None:\r\n            # --- syntax highlight and text rendering settings\r\n            color_scheme_n = 'color_scheme_name'\r\n            color_scheme_o = self.get_color_scheme()\r\n            currentline_n = 'highlight_current_line'\r\n            currentline_o = self.get_option(currentline_n)\r\n            currentcell_n = 'highlight_current_cell'\r\n            currentcell_o = self.get_option(currentcell_n)\r\n            occurrence_n = 'occurrence_highlighting'\r\n            occurrence_o = self.get_option(occurrence_n)\r\n            occurrence_timeout_n = 'occurrence_highlighting/timeout'\r\n            occurrence_timeout_o = self.get_option(occurrence_timeout_n)\r\n            focus_to_editor_n = 'focus_to_editor'\r\n            focus_to_editor_o = self.get_option(focus_to_editor_n)\r\n\r\n            for editorstack in self.editorstacks:\r\n                if color_scheme_n in options:\r\n                    editorstack.set_color_scheme(color_scheme_o)\r\n                if currentline_n in options:\r\n                    editorstack.set_highlight_current_line_enabled(\r\n                                                                currentline_o)\r\n                if currentcell_n in options:\r\n                    editorstack.set_highlight_current_cell_enabled(\r\n                                                                currentcell_o)\r\n                if occurrence_n in options:\r\n                    editorstack.set_occurrence_highlighting_enabled(occurrence_o)\r\n                if occurrence_timeout_n in options:\r\n                    editorstack.set_occurrence_highlighting_timeout(\r\n                                                           occurrence_timeout_o)\r\n                if focus_to_editor_n in options:\r\n                    editorstack.set_focus_to_editor(focus_to_editor_o)\r\n\r\n            # --- everything else\r\n            tabbar_n = 'show_tab_bar'\r\n            tabbar_o = self.get_option(tabbar_n)\r\n            classfuncdropdown_n = 'show_class_func_dropdown'\r\n            classfuncdropdown_o = self.get_option(classfuncdropdown_n)\r\n            linenb_n = 'line_numbers'\r\n            linenb_o = self.get_option(linenb_n)\r\n            blanks_n = 'blank_spaces'\r\n            blanks_o = self.get_option(blanks_n)\r\n            scrollpastend_n = 'scroll_past_end'\r\n            scrollpastend_o = self.get_option(scrollpastend_n)\r\n            edgeline_n = 'edge_line'\r\n            edgeline_o = self.get_option(edgeline_n)\r\n            edgelinecols_n = 'edge_line_columns'\r\n            edgelinecols_o = self.get_option(edgelinecols_n)\r\n            wrap_n = 'wrap'\r\n            wrap_o = self.get_option(wrap_n)\r\n            indentguides_n = 'indent_guides'\r\n            indentguides_o = self.get_option(indentguides_n)\r\n            tabindent_n = 'tab_always_indent'\r\n            tabindent_o = self.get_option(tabindent_n)\r\n            ibackspace_n = 'intelligent_backspace'\r\n            ibackspace_o = self.get_option(ibackspace_n)\r\n            removetrail_n = 'always_remove_trailing_spaces'\r\n            removetrail_o = self.get_option(removetrail_n)\r\n            converteol_n = 'convert_eol_on_save'\r\n            converteol_o = self.get_option(converteol_n)\r\n            converteolto_n = 'convert_eol_on_save_to'\r\n            converteolto_o = self.get_option(converteolto_n)\r\n            runcellcopy_n = 'run_cell_copy'\r\n            runcellcopy_o = self.get_option(runcellcopy_n)\r\n            closepar_n = 'close_parentheses'\r\n            closepar_o = self.get_option(closepar_n)\r\n            close_quotes_n = 'close_quotes'\r\n            close_quotes_o = self.get_option(close_quotes_n)\r\n            add_colons_n = 'add_colons'\r\n            add_colons_o = self.get_option(add_colons_n)\r\n            autounindent_n = 'auto_unindent'\r\n            autounindent_o = self.get_option(autounindent_n)\r\n            indent_chars_n = 'indent_chars'\r\n            indent_chars_o = self.get_option(indent_chars_n)\r\n            tab_stop_width_spaces_n = 'tab_stop_width_spaces'\r\n            tab_stop_width_spaces_o = self.get_option(tab_stop_width_spaces_n)\r\n            help_n = 'connect_to_oi'\r\n            help_o = CONF.get('help', 'connect/editor')\r\n            todo_n = 'todo_list'\r\n            todo_o = self.get_option(todo_n)\r\n\r\n            finfo = self.get_current_finfo()\r\n\r\n\r\n            for editorstack in self.editorstacks:\r\n                if tabbar_n in options:\r\n                    editorstack.set_tabbar_visible(tabbar_o)\r\n                if linenb_n in options:\r\n                    editorstack.set_linenumbers_enabled(linenb_o,\r\n                                                        current_finfo=finfo)\r\n                if edgeline_n in options:\r\n                    editorstack.set_edgeline_enabled(edgeline_o)\r\n                if edgelinecols_n in options:\r\n                    editorstack.set_edgeline_columns(edgelinecols_o)\r\n                if wrap_n in options:\r\n                    editorstack.set_wrap_enabled(wrap_o)\r\n                if tabindent_n in options:\r\n                    editorstack.set_tabmode_enabled(tabindent_o)\r\n                if ibackspace_n in options:\r\n                    editorstack.set_intelligent_backspace_enabled(ibackspace_o)\r\n                if removetrail_n in options:\r\n                    editorstack.set_always_remove_trailing_spaces(removetrail_o)\r\n                if converteol_n in options:\r\n                    editorstack.set_convert_eol_on_save(converteol_o)\r\n                if converteolto_n in options:\r\n                    editorstack.set_convert_eol_on_save_to(converteolto_o)\r\n                if runcellcopy_n in options:\r\n                    editorstack.set_run_cell_copy(runcellcopy_o)\r\n                if closepar_n in options:\r\n                    editorstack.set_close_parentheses_enabled(closepar_o)\r\n                if close_quotes_n in options:\r\n                    editorstack.set_close_quotes_enabled(close_quotes_o)\r\n                if add_colons_n in options:\r\n                    editorstack.set_add_colons_enabled(add_colons_o)\r\n                if autounindent_n in options:\r\n                    editorstack.set_auto_unindent_enabled(autounindent_o)\r\n                if indent_chars_n in options:\r\n                    editorstack.set_indent_chars(indent_chars_o)\r\n                if tab_stop_width_spaces_n in options:\r\n                    editorstack.set_tab_stop_width_spaces(tab_stop_width_spaces_o)\r\n                if help_n in options:\r\n                    editorstack.set_help_enabled(help_o)\r\n                if todo_n in options:\r\n                    editorstack.set_todolist_enabled(todo_o,\r\n                                                     current_finfo=finfo)\r\n\r\n            for name, action in self.checkable_actions.items():\r\n                if name in options:\r\n                    state = self.get_option(name)\r\n                    action.setChecked(state)\r\n                    action.trigger()\r\n\r\n            # Multiply by 1000 to convert seconds to milliseconds\r\n            self.autosave.interval = (\r\n                    self.get_option('autosave_interval') * 1000)\r\n            self.autosave.enabled = self.get_option('autosave_enabled')\r\n\r\n            # We must update the current editor after the others:\r\n            # (otherwise, code analysis buttons state would correspond to the\r\n            #  last editor instead of showing the one of the current editor)\r\n            if finfo is not None:\r\n                # TODO: Connect this to the LSP\r\n                if todo_n in options and todo_o:\r\n                    finfo.run_todo_finder()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_open_filenames(self):\r\n        editorstack = self.editorstacks[0]\r\n        filenames = []\r\n        filenames += [finfo.filename for finfo in editorstack.data]\r\n        return filenames", "response": "Get the list of open files in the current stack"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the opened files on editor based on active project.", "response": "def set_open_filenames(self):\r\n        \"\"\"\r\n        Set the recent opened files on editor based on active project.\r\n\r\n        If no project is active, then editor filenames are saved, otherwise\r\n        the opened filenames are stored in the project config info.\r\n        \"\"\"\r\n        if self.projects is not None:\r\n            if not self.projects.get_active_project():\r\n                filenames = self.get_open_filenames()\r\n                self.set_option('filenames', filenames)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_open_files(self):\r\n        self.set_create_new_file_if_empty(False)\r\n        active_project_path = None\r\n        if self.projects is not None:\r\n            active_project_path = self.projects.get_active_project_path()\r\n\r\n        if active_project_path:\r\n            filenames = self.projects.get_project_filenames()\r\n        else:\r\n            filenames = self.get_option('filenames', default=[])\r\n        self.close_all_files()\r\n\r\n        all_filenames = self.autosave.recover_files_to_open + filenames\r\n        if all_filenames and any([osp.isfile(f) for f in all_filenames]):\r\n            layout = self.get_option('layout_settings', None)\r\n            # Check if no saved layout settings exist, e.g. clean prefs file\r\n            # If not, load with default focus/layout, to fix issue #8458 .\r\n            if layout:\r\n                is_vertical, cfname, clines = layout.get('splitsettings')[0]\r\n                if cfname in filenames:\r\n                    index = filenames.index(cfname)\r\n                    # First we load the last focused file.\r\n                    self.load(filenames[index], goto=clines[index], set_focus=True)\r\n                    # Then we load the files located to the left of the last\r\n                    # focused file in the tabbar, while keeping the focus on\r\n                    # the last focused file.\r\n                    if index > 0:\r\n                        self.load(filenames[index::-1], goto=clines[index::-1],\r\n                                  set_focus=False, add_where='start')\r\n                    # Then we load the files located to the right of the last\r\n                    # focused file in the tabbar, while keeping the focus on\r\n                    # the last focused file.\r\n                    if index < (len(filenames) - 1):\r\n                        self.load(filenames[index+1:], goto=clines[index:],\r\n                                  set_focus=False, add_where='end')\r\n                    # Finally we load any recovered files at the end of the tabbar,\r\n                    # while keeping focus on the last focused file.\r\n                    if self.autosave.recover_files_to_open:\r\n                        self.load(self.autosave.recover_files_to_open,\r\n                                  set_focus=False, add_where='end')\r\n                else:\r\n                    if filenames:\r\n                        self.load(filenames, goto=clines)\r\n                    if self.autosave.recover_files_to_open:\r\n                        self.load(self.autosave.recover_files_to_open)\r\n            else:\r\n                if filenames:\r\n                    self.load(filenames)\r\n                if self.autosave.recover_files_to_open:\r\n                    self.load(self.autosave.recover_files_to_open)\r\n\r\n            if self.__first_open_files_setup:\r\n                self.__first_open_files_setup = False\r\n                if layout is not None:\r\n                    self.editorsplitter.set_layout_settings(\r\n                        layout,\r\n                        dont_goto=filenames[0])\r\n                win_layout = self.get_option('windows_layout_settings', [])\r\n                if win_layout:\r\n                    for layout_settings in win_layout:\r\n                        self.editorwindows_to_be_created.append(\r\n                            layout_settings)\r\n                self.set_last_focus_editorstack(self, self.editorstacks[0])\r\n        else:\r\n            self.__load_temp_file()\r\n        self.set_create_new_file_if_empty(True)", "response": "Open the list of saved files per project and open any files that the user selected in the recovery dialog."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nguess filename based on sys. path.", "response": "def guess_filename(filename):\r\n    \"\"\"Guess filename\"\"\"\r\n    if osp.isfile(filename):\r\n        return filename\r\n    if not filename.endswith('.py'):\r\n        filename += '.py'\r\n    for path in [getcwd_or_home()] + sys.path:\r\n        fname = osp.join(path, filename)\r\n        if osp.isfile(fname):\r\n            return fname\r\n        elif osp.isfile(fname+'.py'):\r\n            return fname+'.py'\r\n        elif osp.isfile(fname+'.pyw'):\r\n            return fname+'.pyw'\r\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting stds to the standard output of the current process.", "response": "def redirect_stds(self):\r\n        \"\"\"Redirects stds\"\"\"\r\n        if not self.debug:\r\n            sys.stdout = self.stdout_write\r\n            sys.stderr = self.stderr_write\r\n            sys.stdin = self.stdin_read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore_stds(self):\r\n        if not self.debug:\r\n            sys.stdout = self.initial_stdout\r\n            sys.stderr = self.initial_stderr\r\n            sys.stdin = self.initial_stdin", "response": "Restore standard streams and sys. stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a command in the interpreter", "response": "def run_command(self, cmd, new_prompt=True):\r\n        \"\"\"Run command in interpreter\"\"\"\r\n        if cmd == 'exit()':\r\n            self.exit_flag = True\r\n            self.write('\\n')\r\n            return\r\n        # -- Special commands type I\r\n        #    (transformed into commands executed in the interpreter)\r\n        # ? command\r\n        special_pattern = r\"^%s (?:r\\')?(?:u\\')?\\\"?\\'?([a-zA-Z0-9_\\.]+)\"\r\n        run_match = re.match(special_pattern % 'run', cmd)\r\n        help_match = re.match(r'^([a-zA-Z0-9_\\.]+)\\?$', cmd)\r\n        cd_match = re.match(r\"^\\!cd \\\"?\\'?([a-zA-Z0-9_ \\.]+)\", cmd)\r\n        if help_match:\r\n            cmd = 'help(%s)' % help_match.group(1)\r\n        # run command\r\n        elif run_match:\r\n            filename = guess_filename(run_match.groups()[0])\r\n            cmd = \"runfile('%s', args=None)\" % remove_backslashes(filename)\r\n        # !cd system command\r\n        elif cd_match:\r\n            cmd = 'import os; os.chdir(r\"%s\")' % cd_match.groups()[0].strip()\r\n        # -- End of Special commands type I\r\n            \r\n        # -- Special commands type II\r\n        #    (don't need code execution in interpreter)\r\n        xedit_match = re.match(special_pattern % 'xedit', cmd)\r\n        edit_match = re.match(special_pattern % 'edit', cmd)\r\n        clear_match = re.match(r\"^clear ([a-zA-Z0-9_, ]+)\", cmd)\r\n        # (external) edit command\r\n        if xedit_match:\r\n            filename = guess_filename(xedit_match.groups()[0])\r\n            self.widget_proxy.edit(filename, external_editor=True)\r\n        # local edit command\r\n        elif edit_match:\r\n            filename = guess_filename(edit_match.groups()[0])\r\n            if osp.isfile(filename):\r\n                self.widget_proxy.edit(filename)\r\n            else:\r\n                self.stderr_write.write(\r\n                                \"No such file or directory: %s\\n\" % filename)\r\n        # remove reference (equivalent to MATLAB's clear command)\r\n        elif clear_match:\r\n            varnames = clear_match.groups()[0].replace(' ', '').split(',')\r\n            for varname in varnames:\r\n                try:\r\n                    self.namespace.pop(varname)\r\n                except KeyError:\r\n                    pass\r\n        # Execute command\r\n        elif cmd.startswith('!'):\r\n            # System ! command\r\n            pipe = programs.run_shell_command(cmd[1:])\r\n            txt_out = encoding.transcode( pipe.stdout.read().decode() )\r\n            txt_err = encoding.transcode( pipe.stderr.read().decode().rstrip() )\r\n            if txt_err:\r\n                self.stderr_write.write(txt_err)\r\n            if txt_out:\r\n                self.stdout_write.write(txt_out)\r\n            self.stdout_write.write('\\n')\r\n            self.more = False\r\n        # -- End of Special commands type II\r\n        else:\r\n            # Command executed in the interpreter\r\n#            self.widget_proxy.set_readonly(True)\r\n            self.more = self.push(cmd)\r\n#            self.widget_proxy.set_readonly(False)\r\n        \r\n        if new_prompt:\r\n            self.widget_proxy.new_prompt(self.p2 if self.more else self.p1)\r\n        if not self.more:\r\n            self.resetbuffer()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execfile(self, filename):\r\n        source = open(filename, 'r').read()\r\n        try:\r\n            try:\r\n                name = filename.encode('ascii')\r\n            except UnicodeEncodeError:\r\n                name = '<executed_script>'\r\n            code = compile(source, name, \"exec\")\r\n        except (OverflowError, SyntaxError):\r\n            InteractiveConsole.showsyntaxerror(self, filename)\r\n        else:\r\n            self.runcode(code)", "response": "Execute a file and return the code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef runfile(self, filename, args=None):\r\n        if args is not None and not is_text_string(args):\r\n            raise TypeError(\"expected a character buffer object\")\r\n        self.namespace['__file__'] = filename\r\n        sys.argv = [filename]\r\n        if args is not None:\r\n            for arg in args.split():\r\n                sys.argv.append(arg)\r\n        self.execfile(filename)\r\n        sys.argv = ['']\r\n        self.namespace.pop('__file__')", "response": "Run filename with arguments args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eval(self, text):\r\n        assert is_text_string(text)\r\n        try:\r\n            return eval(text, self.locals), True\r\n        except:\r\n            return None, False", "response": "Evaluate text and return obj valid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if object is defined", "response": "def is_defined(self, objtxt, force_import=False):\r\n        \"\"\"Return True if object is defined\"\"\"\r\n        return isdefined(objtxt, force_import=force_import,\r\n                         namespace=self.locals)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef logger_init(level):\n    levellist = [logging.ERROR, logging.WARNING, logging.INFO, logging.DEBUG]\n    handler = logging.StreamHandler()\n    fmt = ('%(levelname) -10s %(asctime)s %(name) -30s %(funcName) '\n           '-35s %(lineno) -5d: %(message)s')\n    handler.setFormatter(logging.Formatter(fmt))\n    logger = logging.root\n    logger.addHandler(handler)\n    logger.setLevel(levellist[level])", "response": "Initialize the logger for this thread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore(self):\n        signal.signal(signal.SIGINT, self.original_sigint)\n        signal.signal(signal.SIGTERM, self.original_sigterm)\n        if os.name == 'nt':\n            signal.signal(signal.SIGBREAK, self.original_sigbreak)", "response": "Restore signal handlers to their original settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow warning using Tkinter if available", "response": "def show_warning(message):\r\n    \"\"\"Show warning using Tkinter if available\"\"\"\r\n    try:\r\n        # If Tkinter is installed (highly probable), showing an error pop-up\r\n        import Tkinter, tkMessageBox\r\n        root = Tkinter.Tk()\r\n        root.withdraw()\r\n        tkMessageBox.showerror(\"Spyder\", message)\r\n    except ImportError:\r\n        pass\r\n    raise RuntimeError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_path():\r\n    dirname = osp.abspath(osp.join(osp.dirname(__file__), osp.pardir))\r\n    if dirname not in sys.path:\r\n        show_warning(\"Spyder must be installed properly \"\r\n                     \"(e.g. from source: 'python setup.py install'),\\n\"\r\n                     \"or directory '%s' must be in PYTHONPATH \"\r\n                     \"environment variable.\" % dirname)", "response": "Check sys. path is Spyder properly installed?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking Qt binding requirements", "response": "def check_qt():\r\n    \"\"\"Check Qt binding requirements\"\"\"\r\n    qt_infos = dict(pyqt5=(\"PyQt5\", \"5.6\"))\r\n    try:\r\n        import qtpy\r\n        package_name, required_ver = qt_infos[qtpy.API]\r\n        actual_ver = qtpy.PYQT_VERSION\r\n        if LooseVersion(actual_ver) < LooseVersion(required_ver):\r\n            show_warning(\"Please check Spyder installation requirements:\\n\"\r\n                         \"%s %s+ is required (found v%s).\"\r\n                         % (package_name, required_ver, actual_ver))\r\n    except ImportError:\r\n        show_warning(\"Failed to import qtpy.\\n\"\r\n                     \"Please check Spyder installation requirements:\\n\\n\"\r\n                     \"qtpy 1.2.0+ and\\n\"\r\n                     \"%s %s+\\n\\n\"\r\n                     \"are required to run Spyder.\"\r\n                     % (qt_infos['pyqt5']))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_spyder_kernels():\r\n    try:\r\n        import spyder_kernels\r\n        required_ver = '1.0.0'\r\n        actual_ver = spyder_kernels.__version__\r\n        if LooseVersion(actual_ver) < LooseVersion(required_ver):\r\n            show_warning(\"Please check Spyder installation requirements:\\n\"\r\n                         \"spyder-kernels >= 1.0 is required (found %s).\"\r\n                         % actual_ver)\r\n    except ImportError:\r\n        show_warning(\"Failed to import spyder-kernels.\\n\"\r\n                     \"Please check Spyder installation requirements:\\n\\n\"\r\n                     \"spyder-kernels >= 1.0 is required\")", "response": "Check Spyder - kernel requirements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters plugin in Spyder s main window", "response": "def register_plugin(self):\r\n        \"\"\"Register plugin in Spyder's main window\"\"\"\r\n        self.breakpoints.edit_goto.connect(self.main.editor.load)\r\n        #self.redirect_stdio.connect(self.main.redirect_internalshell_stdio)\r\n        self.breakpoints.clear_all_breakpoints.connect(\r\n                                        self.main.editor.clear_all_breakpoints)\r\n        self.breakpoints.clear_breakpoint.connect(\r\n            self.main.editor.clear_breakpoint)\r\n        self.main.editor.breakpoints_saved.connect(self.breakpoints.set_data)\r\n        self.breakpoints.set_or_edit_conditional_breakpoint.connect(\r\n                           self.main.editor.set_or_edit_conditional_breakpoint)\r\n        \r\n        self.main.add_dockwidget(self)\r\n        \r\n        list_action = create_action(self, _(\"List breakpoints\"),\r\n                                   triggered=self.show)\r\n        list_action.setEnabled(True)\r\n        pos = self.main.debug_menu_actions.index('list_breakpoints')\r\n        self.main.debug_menu_actions.insert(pos, list_action)\r\n        self.main.editor.pythonfile_dependent_actions += [list_action]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the lock of the given name is held or not.", "response": "def isLocked(name):\r\n    \"\"\"Determine if the lock of the given name is held or not.\r\n\r\n    @type name: C{str}\r\n    @param name: The filesystem path to the lock to test\r\n\r\n    @rtype: C{bool}\r\n    @return: True if the lock is held, False otherwise.\r\n    \"\"\"\r\n    l = FilesystemLock(name)\r\n    result = None\r\n    try:\r\n        result = l.lock()\r\n    finally:\r\n        if result:\r\n            l.unlock()\r\n    return not result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lock(self):\r\n        clean = True\r\n        while True:\r\n            try:\r\n                symlink(str(os.getpid()), self.name)\r\n            except OSError as e:\r\n                if _windows and e.errno in (errno.EACCES, errno.EIO):\r\n                    # The lock is in the middle of being deleted because we're\r\n                    # on Windows where lock removal isn't atomic.  Give up, we\r\n                    # don't know how long this is going to take.\r\n                    return False\r\n                if e.errno == errno.EEXIST:\r\n                    try:\r\n                        pid = readlink(self.name)\r\n                    except OSError as e:\r\n                        if e.errno == errno.ENOENT:\r\n                            # The lock has vanished, try to claim it in the\r\n                            # next iteration through the loop.\r\n                            continue\r\n                        raise\r\n                    except IOError as e:\r\n                        if _windows and e.errno == errno.EACCES:\r\n                            # The lock is in the middle of being\r\n                            # deleted because we're on Windows where\r\n                            # lock removal isn't atomic.  Give up, we\r\n                            # don't know how long this is going to\r\n                            # take.\r\n                            return False\r\n                        raise\r\n                    try:\r\n                        if kill is not None:\r\n                            kill(int(pid), 0)\r\n                        # Verify that the running process corresponds to\r\n                        # a Spyder one\r\n                        p = psutil.Process(int(pid))\r\n\r\n                        # Valid names for main script\r\n                        names = set(['spyder', 'spyder3', 'spyder.exe',\r\n                                     'spyder3.exe', 'bootstrap.py',\r\n                                     'spyder-script.py'])\r\n                        if running_under_pytest():\r\n                            names.add('runtests.py')\r\n\r\n                        # Check the first three command line arguments\r\n                        arguments = set(os.path.basename(arg)\r\n                                        for arg in p.cmdline()[:3])\r\n                        conditions = [names & arguments]\r\n                        if not any(conditions):\r\n                            raise(OSError(errno.ESRCH, 'No such process'))\r\n                    except OSError as e:\r\n                        if e.errno == errno.ESRCH:\r\n                            # The owner has vanished, try to claim it in the\r\n                            # next iteration through the loop.\r\n                            try:\r\n                                rmlink(self.name)\r\n                            except OSError as e:\r\n                                if e.errno == errno.ENOENT:\r\n                                    # Another process cleaned up the lock.\r\n                                    # Race them to acquire it in the next\r\n                                    # iteration through the loop.\r\n                                    continue\r\n                                raise\r\n                            clean = False\r\n                            continue\r\n                        raise\r\n                    return False\r\n                raise\r\n            self.locked = True\r\n            self.clean = clean\r\n            return True", "response": "Returns True if the lock is acquired False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing this lock. This deletes the directory with the given name. @raise: Any exception os.readlink() may raise, or ValueError if the lock is not owned by this process.", "response": "def unlock(self):\r\n        \"\"\"\r\n        Release this lock.\r\n\r\n        This deletes the directory with the given name.\r\n\r\n        @raise: Any exception os.readlink() may raise, or\r\n        ValueError if the lock is not owned by this process.\r\n        \"\"\"\r\n        pid = readlink(self.name)\r\n        if int(pid) != os.getpid():\r\n            raise ValueError(\"Lock %r not owned by this process\" % (self.name,))\r\n        rmlink(self.name)\r\n        self.locked = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting thread to render a given documentation", "response": "def render(self, doc, context=None, math_option=False, img_path='',\n               css_path=CSS_PATH):\n        \"\"\"Start thread to render a given documentation\"\"\"\n        # If the thread is already running wait for it to finish before\n        # starting it again.\n        if self.wait():\n            self.doc = doc\n            self.context = context\n            self.math_option = math_option\n            self.img_path = img_path\n            self.css_path = css_path\n            # This causes run() to be executed in separate thread\n            self.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self, index, role=Qt.DisplayRole):\n        row = index.row()\n        if not index.isValid() or not (0 <= row < len(self.servers)):\n            return to_qvariant()\n\n        server = self.servers[row]\n        column = index.column()\n\n        if role == Qt.DisplayRole:\n            if column == LANGUAGE:\n                return to_qvariant(server.language)\n            elif column == ADDR:\n                text = '{0}:{1}'.format(server.host, server.port)\n                return to_qvariant(text)\n            elif column == CMD:\n                text = '&nbsp;<tt style=\"color:{0}\">{{0}} {{1}}</tt>'\n                text = text.format(self.text_color)\n                if server.external:\n                    text = '&nbsp;<tt>External server</tt>'\n                return to_qvariant(text.format(server.cmd, server.args))\n        elif role == Qt.TextAlignmentRole:\n            return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))\n        return to_qvariant()", "response": "Return the data for the current item in the table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the data for the header of the user.", "response": "def headerData(self, section, orientation, role=Qt.DisplayRole):\n        \"\"\"Qt Override.\"\"\"\n        if role == Qt.TextAlignmentRole:\n            if orientation == Qt.Horizontal:\n                return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))\n            return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))\n        if role != Qt.DisplayRole:\n            return to_qvariant()\n        if orientation == Qt.Horizontal:\n            if section == LANGUAGE:\n                return to_qvariant(_(\"Language\"))\n            elif section == ADDR:\n                return to_qvariant(_(\"Address\"))\n            elif section == CMD:\n                return to_qvariant(_(\"Command to execute\"))\n        return to_qvariant()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef focusInEvent(self, e):\n        super(LSPServerTable, self).focusInEvent(e)\n        self.selectRow(self.currentIndex().row())", "response": "Override focusInEvent to select the item in the LSP Server table."}
