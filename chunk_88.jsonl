{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the size of a SPICE cell of any data type.", "response": "def size(cell):\n    \"\"\"\n    Return the size (maximum cardinality) of a SPICE cell of any\n    data type.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/size_c.html\n\n    :param cell: Input cell.\n    :type cell: spiceypy.utils.support_types.SpiceCell\n    :return: The size of the input cell.\n    :rtype: int\n    \"\"\"\n    assert isinstance(cell, stypes.SpiceCell)\n    return libspice.size_c(ctypes.byref(cell))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sphcyl(radius, colat, slon):\n    radius = ctypes.c_double(radius)\n    colat = ctypes.c_double(colat)\n    slon = ctypes.c_double(slon)\n    r = ctypes.c_double()\n    lon = ctypes.c_double()\n    z = ctypes.c_double()\n    libspice.sphcyl_c(radius, colat, slon, ctypes.byref(r), ctypes.byref(lon),\n                      ctypes.byref(z))\n    return r.value, lon.value, z.value", "response": "This routine converts from spherical coordinates to cylindrical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts from spherical coordinates to latitudinal coordinates.", "response": "def sphlat(r, colat, lons):\n    \"\"\"\n    Convert from spherical coordinates to latitudinal coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/sphlat_c.html\n\n    :param r: Distance of the point from the origin.\n    :type r: float\n    :param colat: Angle of the point from positive z axis (radians).\n    :type colat: float\n    :param lons: Angle of the point from the XZ plane (radians).\n    :type lons: float\n    :return:\n            Distance of a point from the origin,\n            Angle of the point from the XZ plane in radians,\n            Angle of the point from the XY plane in radians.\n    :rtype: tuple\n    \"\"\"\n    r = ctypes.c_double(r)\n    colat = ctypes.c_double(colat)\n    lons = ctypes.c_double(lons)\n    radius = ctypes.c_double()\n    lon = ctypes.c_double()\n    lat = ctypes.c_double()\n    libspice.sphcyl_c(r, colat, lons, ctypes.byref(radius), ctypes.byref(lon),\n                      ctypes.byref(lat))\n    return radius.value, lon.value, lat.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting from spherical coordinates to rectangular coordinates.", "response": "def sphrec(r, colat, lon):\n    \"\"\"\n    Convert from spherical coordinates to rectangular coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/sphrec_c.html\n\n    :param r: Distance of a point from the origin.\n    :type r: float\n    :param colat: Angle of the point from the positive Z-axis.\n    :type colat: float\n    :param lon: Angle of the point from the XZ plane in radians.\n    :type lon: float\n    :return: Rectangular coordinates of the point.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    r = ctypes.c_double(r)\n    colat = ctypes.c_double(colat)\n    lon = ctypes.c_double(lon)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.sphrec_c(r, colat, lon, rectan)\n    return stypes.cVectorToPython(rectan)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spkacs(targ, et, ref, abcorr, obs):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obs = ctypes.c_int(obs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    dlt = ctypes.c_double()\n    libspice.spkacs_c(targ, et, ref, abcorr, obs, starg, ctypes.byref(lt),\n                      ctypes.byref(dlt))\n    return stypes.cVectorToPython(starg), lt.value, dlt.value", "response": "Return the state of a target body relative to an observer epoch optionally corrected for light time\n    and stellar aberration expressed relative to an inertial reference frame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the position of a target body relative to an observer et optionally corrected for light time and stellar aberration.", "response": "def spkapo(targ, et, ref, sobs, abcorr):\n    \"\"\"\n    Return the position of a target body relative to an observer,\n    optionally corrected for light time and stellar aberration.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkapo_c.html\n\n    :param targ: Target body.\n    :type targ: int\n    :param et: Observer epoch.\n    :type et: float\n    :param ref: Inertial reference frame of observer's state.\n    :type ref: str\n    :param sobs: State of observer wrt. solar system barycenter.\n    :type sobs: 6-Element Array of floats\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :return:\n            Position of target,\n            One way light time between observer and target.\n    :rtype: tuple\n    \"\"\"\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    sobs = stypes.toDoubleVector(sobs)\n    ptarg = stypes.emptyDoubleVector(3)\n    lt = ctypes.c_double()\n    libspice.spkapo_c(targ, et, ref, sobs, abcorr, ptarg, ctypes.byref(lt))\n    return stypes.cVectorToPython(ptarg), lt.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spkapp(targ, et, ref, sobs, abcorr):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    sobs = stypes.toDoubleVector(sobs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkapp_c(targ, et, ref, sobs, abcorr, starg, ctypes.byref(lt))\n    return stypes.cVectorToPython(starg), lt.value", "response": "This routine computes the state of a target body relative to an observer epoch ref sobs optionally corrected for light time between observer and target."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the state of target relative to the solar system barycenter and the state of the target relative to the observer relative to the SSB.", "response": "def spkaps(targ, et, ref, abcorr, stobs, accobs):\n    \"\"\"\n    Given the state and acceleration of an observer relative to the\n    solar system barycenter, return the state (position and velocity)\n    of a target body relative to the observer, optionally corrected\n    for light time and stellar aberration. All input and output\n    vectors are expressed relative to an inertial reference frame.\n\n    This routine supersedes :func:`spkapp`.\n\n    SPICE users normally should call the high-level API routines\n    :func:`spkezr` or :func:`spkez` rather than this routine.\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkaps_c.html\n\n    :param targ: Target body.\n    :type targ: int\n    :param et: Observer epoch.\n    :type et: float\n    :param ref: Inertial reference frame of output state.\n    :type ref: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param stobs: State of the observer relative to the SSB.\n    :type stobs: 6-Element Array of floats\n    :param accobs: Acceleration of the observer relative to the SSB.\n    :type accobs: 6-Element Array of floats\n    :return:\n             State of target,\n             One way light time between observer and target,\n             Derivative of light time with respect to time.\n    :rtype: tuple\n    \"\"\"\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    stobs = stypes.toDoubleVector(stobs)\n    accobs = stypes.toDoubleVector(accobs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    dlt = ctypes.c_double()\n    libspice.spkaps_c(targ, et, ref, abcorr, stobs, accobs, starg,\n                      ctypes.byref(lt), ctypes.byref(dlt))\n    return stypes.cVectorToPython(starg), lt.value, dlt.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spk14a(handle, ncsets, coeffs, epochs):\n    handle = ctypes.c_int(handle)\n    ncsets = ctypes.c_int(ncsets)\n    coeffs = stypes.toDoubleVector(coeffs)\n    epochs = stypes.toDoubleVector(epochs)\n    libspice.spk14a_c(handle, ncsets, coeffs, epochs)", "response": "Add data to a type 14 SPK segment associated with handle. See spk14b and spk14e."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spk14b(handle, segid, body, center, framename, first, last, chbdeg):\n    handle = ctypes.c_int(handle)\n    segid = stypes.stringToCharP(segid)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    framename = stypes.stringToCharP(framename)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    chbdeg = ctypes.c_int(chbdeg)\n    libspice.spk14b_c(handle, segid, body, center, framename, first, last,\n                      chbdeg)", "response": "This routine creates a type 14 SPK segment in the SPK file associated with the SPK file associated with the handle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the coverage window for a specified ephemeris object in a specified SPK file.", "response": "def spkcov(spk, idcode, cover=None):\n    \"\"\"\n    Find the coverage window for a specified ephemeris object in a\n    specified SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkcov_c.html\n\n    :param spk: Name of SPK file.\n    :type spk: str\n    :param idcode: ID code of ephemeris object.\n    :type idcode: int\n    :param cover: Optional SPICE Window giving coverage in \"spk\" for \"idcode\".\n    :type cover: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    spk = stypes.stringToCharP(spk)\n    idcode = ctypes.c_int(idcode)\n    if cover is None:\n        cover = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(cover, stypes.SpiceCell)\n        assert cover.is_double()\n    libspice.spkcov_c(spk, idcode, ctypes.byref(cover))\n    return cover"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the state of a specified target relative to an observer where the observer has constant position in a specified reference frame.", "response": "def spkcpo(target, et, outref, refloc, abcorr, obspos, obsctr, obsref):\n    \"\"\"\n    Return the state of a specified target relative to an \"observer,\"\n    where the observer has constant position in a specified reference\n    frame. The observer's position is provided by the calling program\n    rather than by loaded SPK files.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkcpo_c.html\n\n    :param target: Name of target ephemeris object.\n    :type target: str\n    :param et: Observation epoch.\n    :type et: float\n    :param outref: Reference frame of output state.\n    :type outref: str\n    :param refloc: Output reference frame evaluation locus.\n    :type refloc: str\n    :param abcorr: Aberration correction.\n    :type abcorr: str\n    :param obspos: Observer position relative to center of motion.\n    :type obspos: 3-Element Array of floats\n    :param obsctr: Center of motion of observer.\n    :type obsctr: str\n    :param obsref: Frame of observer position.\n    :type obsref: str\n    :return:\n            State of target with respect to observer,\n            One way light time between target and observer.\n    :rtype: tuple\n    \"\"\"\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    outref = stypes.stringToCharP(outref)\n    refloc = stypes.stringToCharP(refloc)\n    abcorr = stypes.stringToCharP(abcorr)\n    obspos = stypes.toDoubleVector(obspos)\n    obsctr = stypes.stringToCharP(obsctr)\n    obsref = stypes.stringToCharP(obsref)\n    state = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkcpo_c(target, et, outref, refloc, abcorr, obspos, obsctr,\n                      obsref, state, ctypes.byref(lt))\n    return stypes.cVectorToPython(state), lt.value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spkcpt(trgpos, trgctr, trgref, et, outref, refloc, abcorr, obsrvr):\n    trgpos = stypes.toDoubleVector(trgpos)\n    trgctr = stypes.stringToCharP(trgctr)\n    trgref = stypes.stringToCharP(trgref)\n    et = ctypes.c_double(et)\n    outref = stypes.stringToCharP(outref)\n    refloc = stypes.stringToCharP(refloc)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    state = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkcpt_c(trgpos, trgctr, trgref, et, outref, refloc, abcorr,\n                      obsrvr, state, ctypes.byref(lt))\n    return stypes.cVectorToPython(state), lt.value", "response": "Return the state relative to a specified target with respect to an observer of a specified target."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the state of a specified target relative to an observer and where the observer has constant velocity in a specified reference frame.", "response": "def spkcvo(target, et, outref, refloc, abcorr, obssta, obsepc, obsctr, obsref):\n    \"\"\"\n    Return the state of a specified target relative to an \"observer,\"\n    where the observer has constant velocity in a specified reference\n    frame.  The observer's state is provided by the calling program\n    rather than by loaded SPK files.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkcvo_c.html\n\n    :param target: Name of target ephemeris object.\n    :type target: str\n    :param et: Observation epoch.\n    :type et: float\n    :param outref: Reference frame of output state.\n    :type outref: str\n    :param refloc: Output reference frame evaluation locus.\n    :type refloc: str\n    :param abcorr: Aberration correction.\n    :type abcorr: str\n    :param obssta: Observer state relative to center of motion.\n    :type obssta: 6-Element Array of floats\n    :param obsepc: Epoch of observer state.\n    :type obsepc: float\n    :param obsctr: Center of motion of observer.\n    :type obsctr: str\n    :param obsref: Frame of observer state.\n    :type obsref: str\n    :return:\n            State of target with respect to observer,\n            One way light time between target and observer.\n    :rtype: tuple\n    \"\"\"\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    outref = stypes.stringToCharP(outref)\n    refloc = stypes.stringToCharP(refloc)\n    abcorr = stypes.stringToCharP(abcorr)\n    obssta = stypes.toDoubleVector(obssta)\n    obsepc = ctypes.c_double(obsepc)\n    obsctr = stypes.stringToCharP(obsctr)\n    obsref = stypes.stringToCharP(obsref)\n    state = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkcvo_c(target, et, outref, refloc, abcorr, obssta, obsepc,\n                      obsctr, obsref, state, ctypes.byref(lt))\n    return stypes.cVectorToPython(state), lt.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spkcvt(trgsta, trgepc, trgctr, trgref, et, outref, refloc, abcorr, obsrvr):\n    trgpos = stypes.toDoubleVector(trgsta)\n    trgepc = ctypes.c_double(trgepc)\n    trgctr = stypes.stringToCharP(trgctr)\n    trgref = stypes.stringToCharP(trgref)\n    et = ctypes.c_double(et)\n    outref = stypes.stringToCharP(outref)\n    refloc = stypes.stringToCharP(refloc)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    state = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkcvt_c(trgpos, trgepc, trgctr, trgref, et, outref, refloc,\n                      abcorr, obsrvr, state, ctypes.byref(lt))\n    return stypes.cVectorToPython(state), lt.value", "response": "Return the state of a target with respect to a specified observer of a specified target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spkez(targ, et, ref, abcorr, obs):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obs = ctypes.c_int(obs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkez_c(targ, et, ref, abcorr, obs, starg, ctypes.byref(lt))\n    return stypes.cVectorToPython(starg), lt.value", "response": "Return the state of a target body containing a target body relative to an observer body optionally corrected for light\n    time between observer body and target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spkezp(targ, et, ref, abcorr, obs):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obs = ctypes.c_int(obs)\n    ptarg = stypes.emptyDoubleVector(3)\n    lt = ctypes.c_double()\n    libspice.spkezp_c(targ, et, ref, abcorr, obs, ptarg, ctypes.byref(lt))\n    return stypes.cVectorToPython(ptarg), lt.value", "response": "Return the position of a target body relative to an observer body optionally corrected for light time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spkezr(targ, et, ref, abcorr, obs):\n    targ = stypes.stringToCharP(targ)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obs = stypes.stringToCharP(obs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    if hasattr(et, \"__iter__\"):\n        states = []\n        times = []\n        for t in et:\n            libspice.spkezr_c(targ, ctypes.c_double(t), ref, abcorr, obs, starg, ctypes.byref(lt))\n            checkForSpiceError(None)\n            states.append(stypes.cVectorToPython(starg))\n            times.append(lt.value)\n        return states, times\n    else:\n        libspice.spkezr_c(targ, ctypes.c_double(et), ref, abcorr, obs, starg, ctypes.byref(lt))\n        return stypes.cVectorToPython(starg), lt.value", "response": "Return the state of a target body and one way light time between an observer body and target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spkgeo(targ, et, ref, obs):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    obs = ctypes.c_int(obs)\n    state = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    libspice.spkgeo_c(targ, et, ref, obs, state, ctypes.byref(lt))\n    return stypes.cVectorToPython(state), lt.value", "response": "Compute the geometric state of a target\n    relative to an observing body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spkgps(targ, et, ref, obs):\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    obs = ctypes.c_int(obs)\n    position = stypes.emptyDoubleVector(3)\n    lt = ctypes.c_double()\n    libspice.spkgps_c(targ, et, ref, obs, position, ctypes.byref(lt))\n    return stypes.cVectorToPython(position), lt.value", "response": "Compute the geometric position of a target body relative to an arbitrary target epoch and a reference frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spklef(filename):\n    filename = stypes.stringToCharP(filename)\n    handle = ctypes.c_int()\n    libspice.spklef_c(filename, ctypes.byref(handle))\n    return handle.value", "response": "Load an ephemeris file and return its handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spkltc(targ, et, ref, abcorr, stobs):\n    assert len(stobs) == 6\n    targ = stypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    stobs = stypes.toDoubleVector(stobs)\n    starg = stypes.emptyDoubleVector(6)\n    lt = ctypes.c_double()\n    dlt = ctypes.c_double()\n    libspice.spkltc_c(targ, et, ref, abcorr, stobs, starg, ctypes.byref(lt),\n                      ctypes.byref(dlt))\n    return stypes.cVectorToPython(starg), lt.value, dlt.value", "response": "Return the state of a target body relative to an observer epoch optionally corrected for light time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the set of ID codes of all objects in a specified SPK file.", "response": "def spkobj(spk, outCell=None):\n    \"\"\"\n    Find the set of ID codes of all objects in a specified SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkobj_c.html\n\n    :param spk: Name of SPK file.\n    :type spk: str\n    :param outCell: Optional Spice Int Cell.\n    :type outCell: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    spk = stypes.stringToCharP(spk)\n    if not outCell:\n        outCell = stypes.SPICEINT_CELL(1000)\n    assert isinstance(outCell, stypes.SpiceCell)\n    assert outCell.dtype == 2\n    libspice.spkobj_c(spk, ctypes.byref(outCell))\n    return outCell"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening an existing SPK file for subsequent write.", "response": "def spkopa(filename):\n    \"\"\"\n    Open an existing SPK file for subsequent write.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkopa_c.html\n\n    :param filename: The name of an existing SPK file.\n    :type filename: str\n    :return: A handle attached to the SPK file opened to append.\n    :rtype: int\n    \"\"\"\n    filename = stypes.stringToCharP(filename)\n    handle = ctypes.c_int()\n    libspice.spkopa_c(filename, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new SPK file and return the handle of the opened file.", "response": "def spkopn(filename, ifname, ncomch):\n    \"\"\"\n    Create a new SPK file, returning the handle of the opened file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkopn_c.html\n\n    :param filename: The name of the new SPK file to be created.\n    :type filename: str\n    :param ifname: The internal filename for the SPK file.\n    :type ifname: str\n    :param ncomch: The number of characters to reserve for comments.\n    :type ncomch: int\n    :return: The handle of the opened SPK file.\n    :rtype: int\n    \"\"\"\n    filename = stypes.stringToCharP(filename)\n    ifname = stypes.stringToCharP(ifname)\n    ncomch = ctypes.c_int(ncomch)\n    handle = ctypes.c_int()\n    libspice.spkopn_c(filename, ifname, ncomch, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spkpds(body, center, framestr, typenum, first, last):\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    framestr = stypes.stringToCharP(framestr)\n    typenum = ctypes.c_int(typenum)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    descr = stypes.emptyDoubleVector(5)\n    libspice.spkpds_c(body, center, framestr, typenum, first, last, descr)\n    return stypes.cVectorToPython(descr)", "response": "This routine creates a SPK segment descriptor for a NAIF body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the position of a target body relative to an observer body optionally corrected for light time between observer and target.", "response": "def spkpos(targ, et, ref, abcorr, obs):\n    \"\"\"\n    Return the position of a target body relative to an observing\n    body, optionally corrected for light time (planetary aberration)\n    and stellar aberration.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkpos_c.html\n\n    :param targ: Target body name.\n    :type targ: str\n    :param et: Observer epoch.\n    :type et: Union[float,Iterable[float]]\n    :param ref: Reference frame of output position vector.\n    :type ref: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obs: Observing body name.\n    :type obs: str\n    :return:\n            Position of target,\n            One way light time between observer and target.\n    :rtype: tuple\n    \"\"\"\n    targ = stypes.stringToCharP(targ)\n    ref = stypes.stringToCharP(ref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obs = stypes.stringToCharP(obs)\n    ptarg = stypes.emptyDoubleVector(3)\n    lt = ctypes.c_double()\n    if hasattr(et, \"__iter__\"):\n        ptargs = []\n        lts    = []\n        for t in et:\n            libspice.spkpos_c(targ, t, ref, abcorr, obs, ptarg, ctypes.byref(lt))\n            checkForSpiceError(None)\n            ptargs.append(stypes.cVectorToPython(ptarg))\n            lts.append(lt.value)\n        return ptargs, lts\n    else:\n        libspice.spkpos_c(targ, et, ref, abcorr, obs, ptarg, ctypes.byref(lt))\n        return stypes.cVectorToPython(ptarg), lt.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spkpvn(handle, descr, et):\n    handle = ctypes.c_int(handle)\n    descr = stypes.toDoubleVector(descr)\n    et = ctypes.c_double(et)\n    ref = ctypes.c_int()\n    state = stypes.emptyDoubleVector(6)\n    center = ctypes.c_int()\n    libspice.spkpvn_c(handle, descr, et, ctypes.byref(ref), state,\n                      ctypes.byref(center))\n    return ref.value, stypes.cVectorToPython(state), center.value", "response": "Return the state vector and position of the target body relative to its center of state vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spksfs(body, et, idlen):\n    # spksfs has a Parameter SIDLEN,\n    # sounds like an optional but is that possible?\n    \"\"\"\n    Search through loaded SPK files to find the highest-priority segment\n    applicable to the body and time specified.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spksfs_c.html\n\n    :param body: Body ID.\n    :type body: int\n    :param et: Ephemeris time.\n    :type et: float\n    :param idlen: Length of output segment ID string.\n    :type idlen: int\n    :return:\n            Handle of file containing the applicable segment,\n            Descriptor of the applicable segment,\n            Identifier of the applicable segment.\n    :rtype: tuple\n    \"\"\"\n    body = ctypes.c_int(body)\n    et = ctypes.c_double(et)\n    idlen = ctypes.c_int(idlen)\n    handle = ctypes.c_int()\n    descr = stypes.emptyDoubleVector(5)\n    identstring = stypes.stringToCharP(idlen)\n    found = ctypes.c_int()\n    libspice.spksfs_c(body, et, idlen, ctypes.byref(handle), descr, identstring,\n                      ctypes.byref(found))\n    return handle.value, stypes.cVectorToPython(descr), \\\n           stypes.toPythonString(identstring), bool(found.value)", "response": "Search through loaded SPK files to find the highest - priority segment containing the body and time specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the state of a target body relative to the solar system barycenter.", "response": "def spkssb(targ, et, ref):\n    \"\"\"\n    Return the state (position and velocity) of a target body\n    relative to the solar system barycenter.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkssb_c.html\n\n    :param targ: Target body.\n    :type targ: int\n    :param et: Target epoch.\n    :type et: float\n    :param ref: Target reference frame.\n    :type ref: str\n    :return: State of target.\n    :rtype: 6-Element Array of floats\n    \"\"\"\n    targ = ctypes.c_int(targ)\n    et = ctypes.c_double(et)\n    ref = stypes.stringToCharP(ref)\n    starg = stypes.emptyDoubleVector(6)\n    libspice.spkssb_c(targ, et, ref, starg)\n    return stypes.cVectorToPython(starg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting a subset of the data in an SPK segment into a separate segment.", "response": "def spksub(handle, descr, identin, begin, end, newh):\n    \"\"\"\n    Extract a subset of the data in an SPK segment into a\n    separate segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spksub_c.html\n\n    :param handle: Handle of source segment.\n    :type handle: int\n    :param descr: Descriptor of source segment.\n    :type descr: 5-Element Array of floats\n    :param identin: Indentifier of source segment.\n    :type identin: str\n    :param begin: Beginning (initial epoch) of subset.\n    :type begin: int\n    :param end: End (fincal epoch) of subset.\n    :type end: int\n    :param newh: Handle of new segment.\n    :type newh: int\n    \"\"\"\n    assert len(descr) is 5\n    handle = ctypes.c_int(handle)\n    descr = stypes.toDoubleVector(descr)\n    identin = stypes.stringToCharP(identin)\n    begin = ctypes.c_double(begin)\n    end = ctypes.c_double(end)\n    newh = ctypes.c_int(newh)\n    libspice.spksub_c(handle, descr, identin, begin, end, newh)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunpack the contents of an SPK segment descriptor.", "response": "def spkuds(descr):\n    \"\"\"\n    Unpack the contents of an SPK segment descriptor.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkuds_c.html\n\n    :param descr: An SPK segment descriptor.\n    :type descr: 5-Element Array of floats\n    :return:\n            The NAIF ID code for the body of the segment,\n            The center of motion for body,\n            The ID code for the frame of this segment,\n            The type of SPK segment,\n            The first epoch for which the segment is valid,\n            The last  epoch for which the segment is valid,\n            Beginning DAF address of the segment,\n            Ending DAF address of the segment.\n    :rtype: tuple\n    \"\"\"\n    assert len(descr) is 5\n    descr = stypes.toDoubleVector(descr)\n    body = ctypes.c_int()\n    center = ctypes.c_int()\n    framenum = ctypes.c_int()\n    typenum = ctypes.c_int()\n    first = ctypes.c_double()\n    last = ctypes.c_double()\n    begin = ctypes.c_int()\n    end = ctypes.c_int()\n    libspice.spkuds_c(descr, ctypes.byref(body), ctypes.byref(center),\n                      ctypes.byref(framenum), ctypes.byref(typenum),\n                      ctypes.byref(first), ctypes.byref(last),\n                      ctypes.byref(begin), ctypes.byref(end))\n    return body.value, center.value, framenum.value, typenum.value, \\\n           first.value, last.value, begin.value, end.value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spkw02(handle, body, center, inframe, first, last, segid, intlen, n, polydg,\n           cdata, btime):\n    \"\"\"\n    Write a type 2 segment to an SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw02_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param intlen: Length of time covered by logical record.\n    :type intlen: float\n    :param n: Number of coefficient sets.\n    :type n: int\n    :param polydg: Chebyshev polynomial degree.\n    :type polydg: int\n    :param cdata: Array of Chebyshev coefficients.\n    :type cdata: Array of floats\n    :param btime: Begin time of first logical record.\n    :type btime: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    intlen = ctypes.c_double(intlen)\n    n = ctypes.c_int(n)\n    polydg = ctypes.c_int(polydg)\n    cdata = stypes.toDoubleVector(cdata)\n    btime = ctypes.c_double(btime)\n    libspice.spkw02_c(handle, body, center, inframe, first, last, segid, intlen,\n                      n, polydg, cdata, btime)", "response": "Write a type 2 segment to an SPK file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite an SPK segment of type 5 given a time-ordered set of discrete states and epochs, and the gravitational parameter of a central body. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw05_c.html :param handle: Handle of an SPK file open for writing. :type handle: int :param body: Body code for ephemeris object. :type body: int :param center: Body code for the center of motion of the body. :type center: int :param inframe: The reference frame of the states. :type inframe: str :param first: First valid time for which states can be computed. :type first: float :param last: Last valid time for which states can be computed. :type last: float :param segid: Segment identifier. :type segid: str :param gm: Gravitational parameter of central body. :type gm: float :param n: Number of states and epochs. :type n: int :param states: States. :type states: Nx6-Element Array of floats :param epochs: Epochs. :type epochs: Array of floats", "response": "def spkw05(handle, body, center, inframe, first, last, segid, gm, n, states,\n           epochs):\n    # see libspice args for solution to array[][N] problem\n    \"\"\"\n    Write an SPK segment of type 5 given a time-ordered set of\n    discrete states and epochs, and the gravitational parameter\n    of a central body.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw05_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param gm: Gravitational parameter of central body.\n    :type gm: float\n    :param n: Number of states and epochs.\n    :type n: int\n    :param states: States.\n    :type states: Nx6-Element Array of floats\n    :param epochs: Epochs.\n    :type epochs: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    gm = ctypes.c_double(gm)\n    n = ctypes.c_int(n)\n    states = stypes.toDoubleMatrix(states)\n    epochs = stypes.toDoubleVector(epochs)\n    libspice.spkw05_c(handle, body, center, inframe, first, last, segid, gm, n,\n                      states, epochs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a type 8 segment to an SPK file.", "response": "def spkw08(handle, body, center, inframe, first, last, segid, degree, n, states,\n           epoch1, step):\n    # see libspice args for solution to array[][N] problem\n    \"\"\"\n    Write a type 8 segment to an SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw08_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: NAIF code for an ephemeris object.\n    :type body: int\n    :param center: NAIF code for center of motion of \"body\".\n    :type center: int\n    :param inframe: Reference frame name.\n    :type inframe: str\n    :param first: Start time of interval covered by segment.\n    :type first: float\n    :param last: End time of interval covered by segment.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param degree: Degree of interpolating polynomials.\n    :type degree: int\n    :param n: Number of states.\n    :type n: int\n    :param states: Array of states.\n    :type states: Nx6-Element Array of floats\n    :param epoch1: Epoch of first state in states array.\n    :type epoch1: float\n    :param step: Time step separating epochs of states.\n    :type step: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    degree = ctypes.c_int(degree)\n    n = ctypes.c_int(n)\n    states = stypes.toDoubleMatrix(states)  # X by 6 array\n    epoch1 = ctypes.c_double(epoch1)\n    step = ctypes.c_double(step)\n    libspice.spkw08_c(handle, body, center, inframe, first, last, segid, degree,\n                      n, states, epoch1, step)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spkw09(handle, body, center, inframe, first, last, segid, degree, n, states,\n           epochs):\n    \"\"\"\n    Write a type 9 segment to an SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw09_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: NAIF code for an ephemeris object.\n    :type body: int\n    :param center: NAIF code for center of motion of \"body\".\n    :type center: int\n    :param inframe: Reference frame name.\n    :type inframe: str\n    :param first: Start time of interval covered by segment.\n    :type first: float\n    :param last: End time of interval covered by segment.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param degree: Degree of interpolating polynomials.\n    :type degree: int\n    :param n: Number of states.\n    :type n: int\n    :param states: Array of states.\n    :type states: Nx6-Element Array of floats\n    :param epochs: Array of epochs corresponding to states.\n    :type epochs: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    degree = ctypes.c_int(degree)\n    n = ctypes.c_int(n)\n    states = stypes.toDoubleMatrix(states)  # X by 6 array\n    epochs = stypes.toDoubleVector(epochs)\n    libspice.spkw09_c(handle, body, center, inframe, first, last, segid, degree,\n                      n, states, epochs)", "response": "Write a type 9 segment to an SPK file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting an SPK type 10 segment to the DAF file.", "response": "def spkw10(handle, body, center, inframe, first, last, segid, consts, n, elems,\n           epochs):\n    \"\"\"\n    Write an SPK type 10 segment to the DAF open and attached to\n    the input handle.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw10_c.html\n\n    :param handle: The handle of a DAF file open for writing.\n    :type handle: int\n    :param body: The NAIF ID code for the body of the segment.\n    :type body: int\n    :param center: The center of motion for body.\n    :type center: int\n    :param inframe: The reference frame for this segment.\n    :type inframe: str\n    :param first: The first epoch for which the segment is valid.\n    :type first: float\n    :param last: The last  epoch for which the segment is valid.\n    :type last: float\n    :param segid: The string to use for segment identifier.\n    :type segid: str\n    :param consts: The array of geophysical constants for the segment.\n    :type consts: 8-Element Array of floats\n    :param n: The number of element/epoch pairs to be stored.\n    :type n: int\n    :param elems: The collection of \"two-line\" element sets.\n    :type elems: Array of floats\n    :param epochs: The epochs associated with the element sets.\n    :type epochs: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    consts = stypes.toDoubleVector(consts)\n    n = ctypes.c_int(n)\n    elems = stypes.toDoubleVector(elems)\n    epochs = stypes.toDoubleVector(epochs)\n    libspice.spkw10_c(handle, body, center, inframe, first, last, segid, consts,\n                      n, elems, epochs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spkw12(handle, body, center, inframe, first, last, segid, degree, n, states,\n           epoch0, step):\n    \"\"\"\n    Write a type 12 segment to an SPK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw12_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: NAIF code for an ephemeris object.\n    :type body: int\n    :param center: NAIF code for center of motion of body.\n    :type center: int\n    :param inframe: Reference frame name.\n    :type inframe: str\n    :param first: Start time of interval covered by segment.\n    :type first: float\n    :param last: End time of interval covered by segment.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param degree: Degree of interpolating polynomials.\n    :type degree: int\n    :param n: Number of states.\n    :type n: int\n    :param states: Array of states.\n    :type states: Nx6-Element Array of floats\n    :param epoch0: Epoch of first state in states array.\n    :type epoch0: float\n    :param step: Time step separating epochs of states.\n    :type step: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    degree = ctypes.c_int(degree)\n    n = ctypes.c_int(n)\n    states = stypes.toDoubleMatrix(states)  # X by 6 array\n    epoch0 = ctypes.c_double(epoch0)\n    step = ctypes.c_double(step)\n    libspice.spkw12_c(handle, body, center, inframe, first, last, segid, degree,\n                      n, states, epoch0, step)", "response": "Write a type 12 segment to an SPK file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite an SPK segment of type 15 given a type 15 data record. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw15_c.html :param handle: Handle of an SPK file open for writing. :type handle: int :param body: Body code for ephemeris object. :type body: int :param center: Body code for the center of motion of the body. :type center: int :param inframe: The reference frame of the states. :type inframe: str :param first: First valid time for which states can be computed. :type first: float :param last: Last valid time for which states can be computed. :type last: float :param segid: Segment identifier. :type segid: str :param epoch: Epoch of the periapse. :type epoch: float :param tp: Trajectory pole vector. :type tp: 3-Element Array of floats :param pa: Periapsis vector. :type pa: 3-Element Array of floats :param p: Semi-latus rectum. :type p: float :param ecc: Eccentricity. :type ecc: float :param j2flg: J2 processing flag. :type j2flg: float :param pv: Central body pole vector. :type pv: 3-Element Array of floats :param gm: Central body GM. :type gm: float :param j2: Central body J2. :type j2: float :param radius: Equatorial radius of central body. :type radius: float", "response": "def spkw15(handle, body, center, inframe, first, last, segid, epoch, tp, pa, p,\n           ecc, j2flg, pv, gm, j2, radius):\n    \"\"\"\n    Write an SPK segment of type 15 given a type 15 data record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw15_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param epoch: Epoch of the periapse.\n    :type epoch: float\n    :param tp: Trajectory pole vector.\n    :type tp: 3-Element Array of floats\n    :param pa: Periapsis vector.\n    :type pa: 3-Element Array of floats\n    :param p: Semi-latus rectum.\n    :type p: float\n    :param ecc: Eccentricity.\n    :type ecc: float\n    :param j2flg: J2 processing flag.\n    :type j2flg: float\n    :param pv: Central body pole vector.\n    :type pv: 3-Element Array of floats\n    :param gm: Central body GM.\n    :type gm: float\n    :param j2: Central body J2.\n    :type j2: float\n    :param radius: Equatorial radius of central body.\n    :type radius: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    epoch = ctypes.c_double(epoch)\n    tp = stypes.toDoubleVector(tp)\n    pa = stypes.toDoubleVector(pa)\n    p = ctypes.c_double(p)\n    ecc = ctypes.c_double(ecc)\n    j2flg = ctypes.c_double(j2flg)\n    pv = stypes.toDoubleVector(pv)\n    gm = ctypes.c_double(gm)\n    j2 = ctypes.c_double(j2)\n    radius = ctypes.c_double(radius)\n    libspice.spkw15_c(handle, body, center, inframe, first, last, segid, epoch,\n                      tp, pa, p, ecc, j2flg, pv, gm, j2, radius)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spkw17(handle, body, center, inframe, first, last, segid, epoch, eqel,\n           rapol, decpol):\n    \"\"\"\n    Write an SPK segment of type 17 given a type 17 data record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw17_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param epoch: Epoch of elements in seconds past J2000.\n    :type epoch: float\n    :param eqel: Array of equinoctial elements.\n    :type eqel: 9-Element Array of floats\n    :param rapol: Right Ascension of the pole of the reference plane.\n    :type rapol: float\n    :param decpol: Declination of the pole of the reference plane.\n    :type decpol: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    body = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    epoch = ctypes.c_double(epoch)\n    eqel = stypes.toDoubleVector(eqel)\n    rapol = ctypes.c_double(rapol)\n    decpol = ctypes.c_double(decpol)\n    libspice.spkw17_c(handle, body, center, inframe, first, last, segid, epoch,\n                      eqel, rapol, decpol)", "response": "Write an SPK segment of type 17 given a type 17 data record."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites an 18 segment to an SPK file.", "response": "def spkw18(handle, subtyp, body, center, inframe, first, last, segid, degree, packts, epochs):\n    \"\"\"\n    Write a type 18 segment to an SPK file.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw18_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param subtyp: SPK type 18 subtype code.\n    :type subtyp: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param degree:  Degree of interpolating polynomials.\n    :type degree: int\n    :param packts: data packets\n    :type packts: 2D Array of floats\n    :param epochs: Array of epochs corresponding to states.\n    :type epochs: N-Element Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    subtyp = ctypes.c_int(subtyp)\n    body   = ctypes.c_int(body)\n    center = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first  = ctypes.c_double(first)\n    last   = ctypes.c_double(last)\n    segid  = stypes.stringToCharP(segid)\n    degree = ctypes.c_int(degree)\n    n = ctypes.c_int(len(packts))\n    packts = stypes.toDoubleMatrix(packts)\n    epochs = stypes.toDoubleVector(epochs)\n    libspice.spkw18_c(handle, subtyp, body, center, inframe, first, last, segid, degree, n, packts, epochs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a type 20 segment to an SPK file.", "response": "def spkw20(handle, body, center, inframe, first, last, segid, intlen, n, polydg, cdata, dscale, tscale, initjd, initfr):\n    \"\"\"\n    Write a type 20 segment to an SPK file.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/spkw20_c.html\n\n    :param handle: Handle of an SPK file open for writing.\n    :type handle: int\n    :param body: Body code for ephemeris object.\n    :type body: int\n    :param center: Body code for the center of motion of the body.\n    :type center: int\n    :param inframe: The reference frame of the states.\n    :type inframe: str\n    :param first: First valid time for which states can be computed.\n    :type first: float\n    :param last: Last valid time for which states can be computed.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param intlen: Length of time covered by logical record (days).\n    :param n: Number of logical records in segment.\n    :param polydg: Chebyshev polynomial degree.\n    :param cdata: Array of Chebyshev coefficients and positions.\n    :param dscale: Distance scale of data.\n    :param tscale: Time scale of data.\n    :param initjd: Integer part of begin time (TDB Julian date) of first record.\n    :param initfr: Fractional part of begin time (TDB Julian date) of first record.\n    \"\"\"\n    handle  = ctypes.c_int(handle)\n    body    = ctypes.c_int(body)\n    center  = ctypes.c_int(center)\n    inframe = stypes.stringToCharP(inframe)\n    first   = ctypes.c_double(first)\n    last    = ctypes.c_double(last)\n    segid   = stypes.stringToCharP(segid)\n    intlen  = ctypes.c_double(intlen)\n    n       = ctypes.c_int(n)\n    polydg  = ctypes.c_int(polydg)\n    cdata   = stypes.toDoubleVector(cdata)\n    dscale  = ctypes.c_double(dscale)\n    tscale  = ctypes.c_double(tscale)\n    initjd  = ctypes.c_double(initjd)\n    initfr  = ctypes.c_double(initfr)\n    libspice.spkw20_c(handle, body, center, inframe, first, last, segid, intlen, n, polydg, cdata, dscale, tscale, initjd, initfr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef srfc2s(code, bodyid, srflen=_default_len_out):\n    code   = ctypes.c_int(code)\n    bodyid = ctypes.c_int(bodyid)\n    srfstr = stypes.stringToCharP(srflen)\n    srflen = ctypes.c_int(srflen)\n    isname = ctypes.c_int()\n    libspice.srfc2s_c(code, bodyid, srflen, srfstr, ctypes.byref(isname))\n    return stypes.toPythonString(srfstr), bool(isname.value)", "response": "Translate a surface ID code together with a body ID code and return a string representation of the code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef srfcss(code, bodstr, srflen=_default_len_out):\n    code = ctypes.c_int(code)\n    bodstr = stypes.stringToCharP(bodstr)\n    srfstr = stypes.stringToCharP(srflen)\n    srflen = ctypes.c_int(srflen)\n    isname = ctypes.c_int()\n    libspice.srfcss_c(code, bodstr, srflen, srfstr, ctypes.byref(isname))\n    return stypes.toPythonString(srfstr), bool(isname.value)", "response": "Translate a surface ID code together with a body string and to the \n    corresponding surface name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef srfnrm(method, target, et, fixref, srfpts):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et     = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    npts   = ctypes.c_int(len(srfpts))\n    srfpts = stypes.toDoubleMatrix(srfpts)\n    normls = stypes.emptyDoubleMatrix(3, npts.value)\n    libspice.srfnrm_c(method, target, et, fixref, npts, srfpts, normls)\n    return stypes.cMatrixToNumpy(normls)", "response": "Compute the unit length outward surface normal vectors for a specified target body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef srfrec(body, longitude, latitude):\n    body = ctypes.c_int(body)\n    longitude = ctypes.c_double(longitude)\n    latitude = ctypes.c_double(latitude)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.srfrec_c(body, longitude, latitude, rectan)\n    return stypes.cVectorToPython(rectan)", "response": "Convert planetocentric latitude and longitude of a surface\n    point on a specified body to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntranslating a surface string together with a body string and return the corresponding surface ID code.", "response": "def srfs2c(srfstr, bodstr):\n    \"\"\"\n    Translate a surface string, together with a body string, to the \n    corresponding surface ID code. The input strings may contain \n    names or integer ID codes.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/srfs2c_c.html\n    \n    :param srfstr: Surface name or ID string.\n    :type srfstr: str\n    :param bodstr: Body name or ID string.\n    :type bodstr: str\n    :return: Integer surface ID code.\n    :rtype: int\n    \"\"\"\n    srfstr = stypes.stringToCharP(srfstr)\n    bodstr = stypes.stringToCharP(bodstr)\n    code   = ctypes.c_int()\n    isname = ctypes.c_int()\n    libspice.srfs2c_c(srfstr, bodstr, ctypes.byref(code), ctypes.byref(isname))\n    return code.value, bool(isname.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate a surface string together with a body ID code.", "response": "def srfscc(srfstr, bodyid):\n    \"\"\"\n    Translate a surface string, together with a body ID code, to the \n    corresponding surface ID code. The input surface string may \n    contain a name or an integer ID code. \n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/srfscc_c.html\n    \n    :param srfstr: Surface name or ID string.\n    :type srfstr: str\n    :param bodyid: ID code of body associated with surface. \n    :type bodyid: int \n    :return: Integer surface ID code.\n    :rtype: int\n    \"\"\"\n    srfstr = stypes.stringToCharP(srfstr)\n    bodyid = ctypes.c_int(bodyid)\n    code = ctypes.c_int()\n    isname = ctypes.c_int()\n    libspice.srfscc_c(srfstr, bodyid, ctypes.byref(code), ctypes.byref(isname))\n    return code.value, bool(isname.value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef srfxpt(method, target, et, abcorr, obsrvr, dref, dvec):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    dref = stypes.stringToCharP(dref)\n    dvec = stypes.toDoubleVector(dvec)\n    spoint = stypes.emptyDoubleVector(3)\n    trgepc = ctypes.c_double()\n    dist = ctypes.c_double()\n    obspos = stypes.emptyDoubleVector(3)\n    found = ctypes.c_int()\n    if hasattr(et, \"__iter__\"):\n        spoints = []\n        dists = []\n        trgepcs = []\n        obsposs = []\n        founds = []\n        for t in et:\n            libspice.srfxpt_c(method, target, t, abcorr, obsrvr, dref, dvec,\n                              spoint, ctypes.byref(dist), ctypes.byref(trgepc),\n                              obspos, ctypes.byref(found))\n            checkForSpiceError(None)\n            spoints.append(stypes.cVectorToPython(spoint))\n            dists.append(dist.value)\n            trgepcs.append(trgepc.value)\n            obsposs.append(stypes.cVectorToPython(obspos))\n            founds.append(bool(found.value))\n        return spoints, dists, trgepcs, obsposs, founds\n    else:\n        et = ctypes.c_double(et)\n        libspice.srfxpt_c(method, target, et, abcorr, obsrvr, dref, dvec, spoint,\n                          ctypes.byref(dist), ctypes.byref(trgepc), obspos, ctypes.byref(found))\n        return stypes.cVectorToPython(spoint), dist.value, trgepc.value, stypes.cVectorToPython(obspos), bool(found.value)", "response": "This routine computes the surface intercept point on a target body at a specified epoch and optionally corrected for light time and stellar aberration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ssize(newsize, cell):\n    assert isinstance(cell, stypes.SpiceCell)\n    newsize = ctypes.c_int(newsize)\n    libspice.ssize_c(newsize, ctypes.byref(cell))\n    return cell", "response": "Set the size of a CSPICE cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stelab(pobj, vobs):\n    pobj = stypes.toDoubleVector(pobj)\n    vobs = stypes.toDoubleVector(vobs)\n    appobj = stypes.emptyDoubleVector(3)\n    libspice.stelab_c(pobj, vobs, appobj)\n    return stypes.cVectorToPython(appobj)", "response": "Correct the apparent position of an object for stellar aberration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stpool(item, nth, contin, lenout=_default_len_out):\n    item = stypes.stringToCharP(item)\n    contin = stypes.stringToCharP(contin)\n    nth = ctypes.c_int(nth)\n    strout = stypes.stringToCharP(lenout)\n    lenout = ctypes.c_int(lenout)\n    found = ctypes.c_int()\n    sizet = ctypes.c_int()\n    libspice.stpool_c(item, nth, contin, lenout, strout, ctypes.byref(sizet),\n                      ctypes.byref(found))\n    return stypes.toPythonString(strout), sizet.value, bool(found.value)", "response": "Retrieve the nth string from the kernel pool variable where the nth string may be continued across several components of the kernel pool variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef datetime2et(dt):\n    lt = ctypes.c_double()\n    if hasattr(dt, \"__iter__\"):\n        ets    = []\n        for t in dt:\n            libspice.utc2et_c(stypes.stringToCharP(t.isoformat()),ctypes.byref(lt))\n            checkForSpiceError(None)\n            ets.append(lt.value)\n        return ets\n    dt = stypes.stringToCharP(dt.isoformat())\n    et = ctypes.c_double()\n    libspice.utc2et_c(dt, ctypes.byref(et))\n    return et.value", "response": "Convert a standard Python datetime to a double precision value \n    representing the number of TDB seconds past the J2000 epoch \n    corresponding to the input epoch."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the rectangular coordinates of the sub - observer point on the target body at a specified epoch optionally corrected for the light time and stellar aberration.", "response": "def subpnt(method, target, et, fixref, abcorr, obsrvr):\n    \"\"\"\n    Compute the rectangular coordinates of the sub-observer point on\n    a target body at a specified epoch, optionally corrected for\n    light time and stellar aberration.\n\n    This routine supersedes :func:`subpt`.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/subpnt_c.html\n\n    :param method: Computation method.\n    :type method: str\n    :param target: Name of target body.\n    :type target: str\n    :param et: Epoch in ephemeris seconds past J2000 TDB.\n    :type et: float\n    :param fixref: Body-fixed, body-centered target body frame.\n    :type fixref: str\n    :param abcorr: Aberration correction.\n    :type abcorr: str\n    :param obsrvr: Name of observing body.\n    :type obsrvr: str\n    :return:\n            Sub-observer point on the target body,\n            Sub-observer point epoch,\n            Vector from observer to sub-observer point.\n    :rtype: tuple\n    \"\"\"\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.emptyDoubleVector(3)\n    trgepc = ctypes.c_double(0)\n    srfvec = stypes.emptyDoubleVector(3)\n    libspice.subpnt_c(method, target, et, fixref, abcorr, obsrvr, spoint,\n                      ctypes.byref(trgepc), srfvec)\n    return stypes.cVectorToPython(spoint), trgepc.value, stypes.cVectorToPython(\n            srfvec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subpt(method, target, et, abcorr, obsrvr):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.emptyDoubleVector(3)\n    alt = ctypes.c_double()\n    if hasattr(et, \"__iter__\"):\n        points = []\n        alts = []\n        for t in et:\n            libspice.subpt_c(method, target, ctypes.c_double(t), abcorr, obsrvr, spoint, ctypes.byref(alt))\n            checkForSpiceError(None)\n            points.append(stypes.cVectorToPython(spoint))\n            alts.append(alt.value)\n        return points, alts\n    else:\n        et = ctypes.c_double(et)\n        libspice.subpt_c(method, target, et, abcorr, obsrvr, spoint, ctypes.byref(alt))\n        return stypes.cVectorToPython(spoint), alt.value", "response": "Return the rectangular coordinates of the sub - observer point on the target body at a particular epoch and optionally corrected for stellar aberration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the coordinates of the sub - solar point on a target body at a specified epoch.", "response": "def subsol(method, target, et, abcorr, obsrvr):\n    \"\"\"\n    Deprecated: This routine has been superseded by the CSPICE\n    routine :func:`subslr`. This routine is supported for purposes of\n    backward compatibility only.\n\n    Determine the coordinates of the sub-solar point on a target\n    body as seen by a specified observer at a specified epoch,\n    optionally corrected for planetary (light time) and stellar\n    aberration.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/subsol_c.html\n\n    :param method: Computation method.\n    :type method: str\n    :param target: Name of target body.\n    :type target: str\n    :param et: Epoch in ephemeris seconds past J2000 TDB.\n    :type et: float\n    :param abcorr: Aberration correction.\n    :type abcorr: str\n    :param obsrvr: Name of observing body.\n    :type obsrvr: str\n    :return: Sub-solar point on the target body.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.emptyDoubleVector(3)\n    libspice.subsol_c(method, target, et, abcorr, obsrvr, spoint)\n    return stypes.cVectorToPython(spoint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sumad(array):\n    n = ctypes.c_int(len(array))\n    array = stypes.toDoubleVector(array)\n    return libspice.sumad_c(array, n)", "response": "Return the sum of the elements of a double precision array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the sum of the elements of an integer array.", "response": "def sumai(array):\n    \"\"\"\n    Return the sum of the elements of an integer array.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/sumai_c.html\n\n    :param array: Input Array.\n    :type array: Array of ints\n    :return: The sum of the array.\n    :rtype: int\n    \"\"\"\n    n = ctypes.c_int(len(array))\n    array = stypes.toIntVector(array)\n    return libspice.sumai_c(array, n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef surfnm(a, b, c, point):\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    point = stypes.toDoubleVector(point)\n    normal = stypes.emptyDoubleVector(3)\n    libspice.surfnm_c(a, b, c, point, normal)\n    return stypes.cVectorToPython(normal)", "response": "This routine computes the outward pointing unit normal vector\n    from a point on the surface of an ellipsoid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining the intersection of a line - of - sight vector with the last three points on the ellipsoid.", "response": "def surfpt(positn, u, a, b, c):\n    \"\"\"\n    Determine the intersection of a line-of-sight vector with the\n    surface of an ellipsoid.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/surfpt_c.html\n\n    :param positn: Position of the observer in body-fixed frame.\n    :type positn: 3-Element Array of floats\n    :param u: Vector from the observer in some direction.\n    :type u: 3-Element Array of floats\n    :param a: Length of the ellisoid semi-axis along the x-axis.\n    :type a: float\n    :param b: Length of the ellisoid semi-axis along the y-axis.\n    :type b: float\n    :param c: Length of the ellisoid semi-axis along the z-axis.\n    :type c: float\n    :return: Point on the ellipsoid pointed to by u.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    positn = stypes.toDoubleVector(positn)\n    u = stypes.toDoubleVector(u)\n    point = stypes.emptyDoubleVector(3)\n    found = ctypes.c_int()\n    libspice.surfpt_c(positn, u, a, b, c, point, ctypes.byref(found))\n    return stypes.cVectorToPython(point), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the state of the surfaces in a specified ray and direction vector.", "response": "def surfpv(stvrtx, stdir, a, b, c):\n    \"\"\"\n    Find the state (position and velocity) of the surface intercept\n    defined by a specified ray, ray velocity, and ellipsoid.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/surfpv_c.html\n\n    :param stvrtx: State of ray's vertex.\n    :type stvrtx: 6-Element Array of floats\n    :param stdir: State of ray's direction vector.\n    :type stdir: 6-Element Array of floats\n    :param a: Length of the ellisoid semi-axis along the x-axis.\n    :type a: float\n    :param b: Length of the ellisoid semi-axis along the y-axis.\n    :type b: float\n    :param c: Length of the ellisoid semi-axis along the z-axis.\n    :type c: float\n    :return: State of surface intercept.\n    :rtype: list\n    \"\"\"\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    stvrtx = stypes.toDoubleVector(stvrtx)\n    stdir = stypes.toDoubleVector(stdir)\n    stx = stypes.emptyDoubleVector(6)\n    found = ctypes.c_int()\n    libspice.surfpv_c(stvrtx, stdir, a, b, c, stx, ctypes.byref(found))\n    return stypes.cVectorToPython(stx), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef swpool(agent, nnames, lenvals, names):\n    agent = stypes.stringToCharP(agent)\n    nnames = ctypes.c_int(nnames)\n    lenvals = ctypes.c_int(lenvals)\n    names = stypes.listToCharArray(names)\n    libspice.swpool_c(agent, nnames, lenvals, names)", "response": "Add a name to the list of agents to notify when a member of\n    kernel variables is updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sxform(instring, tostring, et):\n    instring = stypes.stringToCharP(instring)\n    tostring = stypes.stringToCharP(tostring)\n    xform = stypes.emptyDoubleMatrix(x=6, y=6)\n    if hasattr(et, \"__iter__\"):\n        xforms = []\n        for t in et:\n            libspice.sxform_c(instring, tostring, ctypes.c_double(t), xform)\n            checkForSpiceError(None)\n            xforms.append(stypes.cMatrixToNumpy(xform))\n        return xforms\n    else:\n        et = ctypes.c_double(et)\n        libspice.sxform_c(instring, tostring, et, xform)\n        return stypes.cMatrixToNumpy(xform)", "response": "Return the state transformation matrix from one frame to\n    another at a specified epoch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the kernel pool size limitations.", "response": "def szpool(name):\n    \"\"\"\n    Return the kernel pool size limitations.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/szpool_c.html\n\n    :param name: Name of the parameter to be returned.\n    :type name: str\n    :return: Value of parameter specified by name,\n    :rtype: int\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    n = ctypes.c_int()\n    found = ctypes.c_int(0)\n    libspice.szpool_c(name, ctypes.byref(n), ctypes.byref(found))\n    return n.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef termpt(method, ilusrc, target, et, fixref, abcorr, corloc, obsrvr, refvec, rolstp,\n           ncuts, schstp, soltol, maxn):\n    \"\"\"\n    Find terminator points on a target body. The caller specifies\n    half-planes, bounded by the illumination source center-target center\n    vector, in which to search for terminator points.\n\n    The terminator can be either umbral or penumbral. The umbral \n    terminator is the boundary of the region on the target surface \n    where no light from the source is visible. The penumbral \n    terminator is the boundary of the region on the target surface \n    where none of the light from the source is blocked by the target \n    itself.\n\n    The surface of the target body may be represented either by a \n    triaxial ellipsoid or by topographic data.  \n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/termpt_c.html\n\n    :param method: Computation method. \n    :type method: str\n    :param ilusrc: Illumination source.\n    :type ilusrc: str\n    :param target: Name of target body.\n    :type target: str\n    :param et: Epoch in ephemeris seconds past J2000 TDB.\n    :type et: float\n    :param fixref: Body-fixed, body-centered target body frame.\n    :type fixref: str\n    :param abcorr: Aberration correction. \n    :type abcorr: str\n    :param corloc: Aberration correction locus.\n    :type corloc: str\n    :param obsrvr: Name of observing body.\n    :type obsrvr: str\n    :param refvec: Reference vector for cutting half-planes.\n    :type refvec: 3-Element Array of floats\n    :param rolstp: Roll angular step for cutting half-planes. \n    :type rolstp: float\n    :param ncuts: Number of cutting half-planes. \n    :type ncuts: int\n    :param schstp: Angular step size for searching. \n    :type schstp: float\n    :param soltol: Solution convergence tolerance. \n    :type soltol: float\n    :param maxn: Maximum number of entries in output arrays. \n    :type maxn: int\n    :return: Counts of terminator points corresponding to cuts, Terminator points, Times associated with terminator points, Terminator vectors emanating from the observer\n    :rtype: tuple\n    \"\"\"\n    method = stypes.stringToCharP(method)\n    ilusrc = stypes.stringToCharP(ilusrc)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    corloc = stypes.stringToCharP(corloc)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    refvec = stypes.toDoubleVector(refvec)\n    rolstp = ctypes.c_double(rolstp)\n    ncuts = ctypes.c_int(ncuts)\n    schstp = ctypes.c_double(schstp)\n    soltol = ctypes.c_double(soltol)\n    maxn = ctypes.c_int(maxn)\n    npts = stypes.emptyIntVector(maxn.value)\n    points = stypes.emptyDoubleMatrix(3, maxn.value)\n    epochs = stypes.emptyDoubleVector(maxn)\n    trmvcs = stypes.emptyDoubleMatrix(3, maxn.value)\n    libspice.termpt_c(method, ilusrc, target, et, fixref,\n                      abcorr, corloc, obsrvr, refvec,\n                      rolstp, ncuts, schstp, soltol,\n                      maxn, npts, points, epochs, trmvcs)\n    # Clip the empty elements out of returned results\n    npts = stypes.cVectorToPython(npts)\n    valid_points = numpy.where(npts >= 1)\n    return npts[valid_points], stypes.cMatrixToNumpy(points)[valid_points], \\\n           stypes.cVectorToPython(epochs)[valid_points], \\\n           stypes.cMatrixToNumpy(trmvcs)[valid_points]", "response": "This function returns a list of termpt terminator points on a target body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timdef(action, item, lenout, value=None):\n    action = stypes.stringToCharP(action)\n    item = stypes.stringToCharP(item)\n    lenout = ctypes.c_int(lenout)\n    if value is None:\n        value = stypes.stringToCharP(lenout)\n    else:\n        value = stypes.stringToCharP(value)\n    libspice.timdef_c(action, item, lenout, value)\n    return stypes.toPythonString(value)", "response": "Return the default value associated with a specified default item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a 3x3 matrix that transforms positions in inertial coordinates to positions in body - equator - and - prime - meridian coordinates.", "response": "def tipbod(ref, body, et):\n    \"\"\"\n    Return a 3x3 matrix that transforms positions in inertial\n    coordinates to positions in body-equator-and-prime-meridian\n    coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/tipbod_c.html\n\n    :param ref: ID of inertial reference frame to transform from.\n    :type ref: str\n    :param body: ID code of body.\n    :type body: int\n    :param et: Epoch of transformation.\n    :type et: float\n    :return: Transformation (position), inertial to prime meridian.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    ref = stypes.stringToCharP(ref)\n    body = ctypes.c_int(body)\n    et = ctypes.c_double(et)\n    retmatrix = stypes.emptyDoubleMatrix()\n    libspice.tipbod_c(ref, body, et, retmatrix)\n    return stypes.cMatrixToNumpy(retmatrix)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tisbod(ref, body, et):\n    ref = stypes.stringToCharP(ref)\n    body = ctypes.c_int(body)\n    et = ctypes.c_double(et)\n    retmatrix = stypes.emptyDoubleMatrix(x=6, y=6)\n    libspice.tisbod_c(ref, body, et, retmatrix)\n    return stypes.cMatrixToNumpy(retmatrix)", "response": "Return a 6x6 matrix that transforms states in inertial coordinates to states in body - equator - and - prime - meridian coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tkvrsn(item):\n    item = stypes.stringToCharP(item)\n    return stypes.toPythonString(libspice.tkvrsn_c(item))", "response": "Return the latest version string for the given item such as the Toolkit or an entry point name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tparse(instring, lenout=_default_len_out):\n    errmsg = stypes.stringToCharP(lenout)\n    lenout = ctypes.c_int(lenout)\n    instring = stypes.stringToCharP(instring)\n    sp2000 = ctypes.c_double()\n    libspice.tparse_c(instring, lenout, ctypes.byref(sp2000), errmsg)\n    return sp2000.value, stypes.toPythonString(errmsg)", "response": "Parse a time string and return the UTC seconds past the J2000."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a sample time string create a time format picture that describes sample and return whether the sample parsed successfully and a diagnostic string that represents sample.", "response": "def tpictr(sample, lenout=_default_len_out, lenerr=_default_len_out):\n    \"\"\"\n    Given a sample time string, create a time format picture\n    suitable for use by the routine timout.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/tpictr_c.html\n\n    :param sample: A sample time string.\n    :type sample: str\n    :param lenout: The length for the output picture string.\n    :type lenout: int\n    :param lenerr: The length for the output error string.\n    :type lenerr: int\n    :return:\n            A format picture that describes sample,\n            Flag indicating whether sample parsed successfully,\n            Diagnostic returned if sample cannot be parsed\n    :rtype: tuple\n    \"\"\"\n    sample = stypes.stringToCharP(sample)\n    pictur = stypes.stringToCharP(lenout)\n    errmsg = stypes.stringToCharP(lenerr)\n    lenout = ctypes.c_int(lenout)\n    lenerr = ctypes.c_int(lenerr)\n    ok = ctypes.c_int()\n    libspice.tpictr_c(sample, lenout, lenerr, pictur, ctypes.byref(ok), errmsg)\n    return stypes.toPythonString(pictur), ok.value, stypes.toPythonString(\n            errmsg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trcdep():\n    depth = ctypes.c_int()\n    libspice.trcdep_c(ctypes.byref(depth))\n    return depth.value", "response": "Return the number of modules in the traceback representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trcnam(index, namlen=_default_len_out):\n    index = ctypes.c_int(index)\n    name = stypes.stringToCharP(namlen)\n    namlen = ctypes.c_int(namlen)\n    libspice.trcnam_c(index, namlen, name)\n    return stypes.toPythonString(name)", "response": "Return the name of the module in the trace representation at the specified position in the traceback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the transformation to the right - handed frame having a given vector as a specified axis and having a second given given vector as a specified coordinate plane.", "response": "def twovec(axdef, indexa, plndef, indexp):\n    \"\"\"\n    Find the transformation to the right-handed frame having a\n    given vector as a specified axis and having a second given\n    vector lying in a specified coordinate plane.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/twovec_c.html\n\n    :param axdef: Vector defining a principal axis.\n    :type axdef: 3-Element Array of floats\n    :param indexa: Principal axis number of axdef (X=1, Y=2, Z=3).\n    :type indexa: int\n    :param plndef: Vector defining (with axdef) a principal plane.\n    :type plndef: 3-Element Array of floats\n    :param indexp: Second axis number (with indexa) of principal plane.\n    :type indexp: int\n    :return: Output rotation matrix.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    axdef = stypes.toDoubleVector(axdef)\n    indexa = ctypes.c_int(indexa)\n    plndef = stypes.toDoubleVector(plndef)\n    indexp = ctypes.c_int(indexp)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.twovec_c(axdef, indexa, plndef, indexp, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ucase(inchar, lenout=None):\n    if lenout is None:\n        lenout = len(inchar) + 1\n    inchar = stypes.stringToCharP(inchar)\n    outchar = stypes.stringToCharP(\" \" * lenout)\n    lenout = ctypes.c_int(lenout)\n    libspice.ucase_c(inchar, lenout, outchar)\n    return stypes.toPythonString(outchar)", "response": "Convert the characters in a string to uppercase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the normalized cross product of two 3 - vectors.", "response": "def ucrss(v1, v2):\n    \"\"\"\n    Compute the normalized cross product of two 3-vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ucrss_c.html\n\n    :param v1: Left vector for cross product.\n    :type v1: 3-Element Array of floats\n    :param v2: Right vector for cross product.\n    :type v2: 3-Element Array of floats\n    :return: Normalized cross product v1xv2 / abs(v1xv2).\n    :rtype: Array of floats\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.ucrss_c(v1, v2, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nspicing private routine intended solely for the support of SPICE routines. Users should not call this routine directly due to the volatile nature of this routine. This routine calculates the derivative of 'udfunc' with respect to time for 'et', then determines if the derivative has a negative value. Use the @spiceypy.utils.callbacks.SpiceUDFUNS dectorator to wrap a given python function that takes one parameter (float) and returns a float. For example:: @spiceypy.utils.callbacks.SpiceUDFUNS def udfunc(et_in): pos, new_et = spice.spkpos(\"MERCURY\", et_in, \"J2000\", \"LT+S\", \"MOON\") return new_et deriv = spice.uddf(udfunc, et, 1.0) https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/uddc_c.html :param udfunc: Name of the routine that computes the scalar value of interest. :type udfunc: ctypes.CFunctionType :param x: Independent variable of 'udfunc'. :type x: float :param dx: Interval from 'x' for derivative calculation. :type dx: float :return: Boolean indicating if the derivative is negative. :rtype: bool", "response": "def uddc(udfunc, x, dx):\n    \"\"\"\n    SPICE private routine intended solely for the support of SPICE\n    routines. Users should not call this routine directly due to the\n    volatile nature of this routine.\n\n    This routine calculates the derivative of 'udfunc' with respect\n    to time for 'et', then determines if the derivative has a\n    negative value.\n\n    Use the @spiceypy.utils.callbacks.SpiceUDFUNS dectorator to wrap\n    a given python function that takes one parameter (float) and\n    returns a float. For example::\n\n        @spiceypy.utils.callbacks.SpiceUDFUNS\n        def udfunc(et_in):\n            pos, new_et = spice.spkpos(\"MERCURY\", et_in, \"J2000\", \"LT+S\", \"MOON\")\n            return new_et\n\n        deriv = spice.uddf(udfunc, et, 1.0)\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/uddc_c.html\n\n    :param udfunc: Name of the routine that computes the scalar value of interest.\n    :type udfunc: ctypes.CFunctionType\n    :param x: Independent variable of 'udfunc'.\n    :type x: float\n    :param dx: Interval from 'x' for derivative calculation.\n    :type dx: float\n    :return: Boolean indicating if the derivative is negative.\n    :rtype: bool\n    \"\"\"\n    x = ctypes.c_double(x)\n    dx = ctypes.c_double(dx)\n    isdescr = ctypes.c_int()\n    libspice.uddc_c(udfunc, x, dx, ctypes.byref(isdescr))\n    return bool(isdescr.value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uddf(udfunc, x, dx):\n    x = ctypes.c_double(x)\n    dx = ctypes.c_double(dx)\n    deriv = ctypes.c_double()\n    libspice.uddf_c(udfunc, x, dx, ctypes.byref(deriv))\n    return deriv.value", "response": "This routine computes the first derivative of a caller - specified\n    function at x and dx."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unitim(epoch, insys, outsys):\n    epoch = ctypes.c_double(epoch)\n    insys = stypes.stringToCharP(insys)\n    outsys = stypes.stringToCharP(outsys)\n    return libspice.unitim_c(epoch, insys, outsys)", "response": "This routine transforms a time from one uniform scale to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunloads a SPICE kernel.", "response": "def unload(filename):\n    \"\"\"\n    Unload a SPICE kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/unload_c.html\n\n    :param filename: The name of a kernel to unload.\n    :type filename: str\n    \"\"\"\n    if isinstance(filename, list):\n        for f in filename:\n            libspice.unload_c(stypes.stringToCharP(f))\n        return\n    filename = stypes.stringToCharP(filename)\n    libspice.unload_c(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unorm(v1):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(3)\n    vmag = ctypes.c_double()\n    libspice.unorm_c(v1, vout, ctypes.byref(vmag))\n    return stypes.cVectorToPython(vout), vmag.value", "response": "This function normalizes a double precision 3 - vector and returns its magnitude."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unormg(v1, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(ndim)\n    vmag = ctypes.c_double()\n    ndim = ctypes.c_int(ndim)\n    libspice.unormg_c(v1, ndim, vout, ctypes.byref(vmag))\n    return stypes.cVectorToPython(vout), vmag.value", "response": "Normalizes a double precision vector of arbitrary dimension and\n    return its magnitude."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an input time from Calendar or Julian Date format UTC to ephemeris seconds past J2000.", "response": "def utc2et(utcstr):\n    \"\"\"\n    Convert an input time from Calendar or Julian Date format, UTC,\n    to ephemeris seconds past J2000.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/utc2et_c.html\n\n    :param utcstr: Input time string, UTC. \n    :type utcstr: str\n    :return: Output epoch, ephemeris seconds past J2000.\n    :rtype: float\n    \"\"\"\n    utcstr = stypes.stringToCharP(utcstr)\n    et = ctypes.c_double()\n    libspice.utc2et_c(utcstr, ctypes.byref(et))\n    return et.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vadd(v1, v2):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vadd_c(v1, v2, vout)\n    return stypes.cVectorToPython(vout)", "response": "Add two 3 - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd two n - dimensional vectors to a new n - dimensional vector.", "response": "def vaddg(v1, v2, ndim):\n    \"\"\" Add two n-dimensional vectors\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vaddg_c.html\n\n    :param v1: First vector to be added. \n    :type v1: list[ndim]\n    :param v2: Second vector to be added. \n    :type v2: list[ndim]\n    :param ndim: Dimension of v1 and v2. \n    :type ndim: int\n    :return: v1+v2\n    :rtype: list[ndim]\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vaddg_c(v1, v2, ndim, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a valid CSPICE set from a CSPICE Cell of any data type.", "response": "def valid(insize, n, inset):\n    \"\"\"\n    Create a valid CSPICE set from a CSPICE Cell of any data type.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/valid_c.html\n\n    :param insize: Size (maximum cardinality) of the set. \n    :type insize: int\n    :param n: Initial no. of (possibly non-distinct) elements. \n    :type n: int\n    :param inset: Set to be validated.\n    :return: validated set\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    insize = ctypes.c_int(insize)\n    n = ctypes.c_int(n)\n    libspice.valid_c(insize, n, inset)\n    return inset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the cross product of two 3 - dimensional vectors.", "response": "def vcrss(v1, v2):\n    \"\"\"\n    Compute the cross product of two 3-dimensional vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vcrss_c.html\n\n    :param v1: Left hand vector for cross product. \n    :type v1: 3-Element Array of floats\n    :param v2: Right hand vector for cross product. \n    :type v2: 3-Element Array of floats\n    :return: Cross product v1 x v2.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vcrss_c(v1, v2, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vdist(v1, v2):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    return libspice.vdist_c(v1, v2)", "response": "Return the distance between two three - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vdistg(v1, v2, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    ndim = ctypes.c_int(ndim)\n    return libspice.vdistg_c(v1, v2, ndim)", "response": "Return the distance between two vectors of arbitrary dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vdot(v1, v2):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    return libspice.vdot_c(v1, v2)", "response": "Compute the dot product of two double precision 3 - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the dot product of two double precision vectors of arbitrary dimension.", "response": "def vdotg(v1, v2, ndim):\n    \"\"\"\n    Compute the dot product of two double precision vectors of\n    arbitrary dimension.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vdotg_c.html\n\n    :param v1: First vector in the dot product. \n    :type v1: list[ndim]\n    :param v2: Second vector in the dot product. \n    :type v2: list[ndim]\n    :param ndim: Dimension of v1 and v2. \n    :type ndim: int\n    :return: dot product of v1 and v2.\n    :rtype: float\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    ndim = ctypes.c_int(ndim)\n    return libspice.vdotg_c(v1, v2, ndim)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vequ(v1):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vequ_c(v1, vout)\n    return stypes.cVectorToPython(vout)", "response": "Return a 3 - dimensional double precision vector set equal to v1."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vequg(v1, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vequg_c(v1, ndim, vout)\n    return stypes.cVectorToPython(vout)", "response": "Make one double precision vector of arbitrary dimension equal to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vhat(v1):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vhat_c(v1, vout)\n    return stypes.cVectorToPython(vout)", "response": "Find the unit vector along a double precision 3 - dimensional vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vhatg(v1, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vhatg_c(v1, ndim, vout)\n    return stypes.cVectorToPython(vout)", "response": "Find the unit vector along a double precision vector of arbitrary dimension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a vector linear combination of two double precision vectors.", "response": "def vlcom(a, v1, b, v2):\n    \"\"\"\n    Compute a vector linear combination of two double precision,\n    3-dimensional vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vlcom_c.html\n\n    :param a: Coefficient of v1 \n    :type a: float\n    :param v1: Vector in 3-space \n    :type v1: 3-Element Array of floats\n    :param b: Coefficient of v2 \n    :type b: float\n    :param v2: Vector in 3-space \n    :type v2: 3-Element Array of floats\n    :return: Linear Vector Combination a*v1 + b*v2.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    sumv = stypes.emptyDoubleVector(3)\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    libspice.vlcom_c(a, v1, b, v2, sumv)\n    return stypes.cVectorToPython(sumv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vminug(vin, ndim):\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vminug_c(vin, ndim, vout)\n    return stypes.cVectorToPython(vout)", "response": "Return a list of n - dimensional double precision vectors of arbitrary dimension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a vector that is negated by vin.", "response": "def vminus(vin):\n    \"\"\"\n    Negate a double precision 3-dimensional vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vminus_c.html\n\n    :param vin: Vector to be negated. \n    :type vin: 3-Element Array of floats\n    :return: Negated vector -v1.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vminus_c(vin, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the magnitude of a double precision vector of arbitrary dimension.", "response": "def vnormg(v, ndim):\n    \"\"\"\n    Compute the magnitude of a double precision vector of arbitrary dimension.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vnormg_c.html\n\n    :param v: Vector whose magnitude is to be found. \n    :type v: Array of floats\n    :param ndim: Dimension of v \n    :type ndim: int\n    :return: magnitude of v calculated in a numerically stable way\n    :rtype: float\n    \"\"\"\n    v = stypes.toDoubleVector(v)\n    ndim = ctypes.c_int(ndim)\n    return libspice.vnormg_c(v, ndim)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vpack(x, y, z):\n    x = ctypes.c_double(x)\n    y = ctypes.c_double(y)\n    z = ctypes.c_double(z)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vpack_c(x, y, z, vout)\n    return stypes.cVectorToPython(vout)", "response": "Pack three scalar components into a vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the component of a vector that is perpendicular to a second vector.", "response": "def vperp(a, b):\n    \"\"\"\n    Find the component of a vector that is perpendicular to a second\n    vector. All vectors are 3-dimensional.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vperp_c.html\n\n    :param a: The vector whose orthogonal component is sought. \n    :type a: 3-Element Array of floats\n    :param b: The vector used as the orthogonal reference. \n    :type b: 3-Element Array of floats\n    :return: The component of a orthogonal to b.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    a = stypes.toDoubleVector(a)\n    b = stypes.toDoubleVector(b)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vperp_c(a, b, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprojects a vector onto a specified plane orthogonally.", "response": "def vprjp(vin, plane):\n    \"\"\"\n    Project a vector onto a specified plane, orthogonally.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vprjp_c.html\n\n    :param vin: The projected vector. \n    :type vin: 3-Element Array of floats\n    :param plane: Plane containing vin. \n    :type plane: spiceypy.utils.support_types.Plane\n    :return: Vector resulting from projection.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vprjp_c(vin, ctypes.byref(plane), vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vprjpi(vin, projpl, invpl):\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(3)\n    found = ctypes.c_int()\n    libspice.vprjpi_c(vin, ctypes.byref(projpl), ctypes.byref(invpl), vout,\n                      ctypes.byref(found))\n    return stypes.cVectorToPython(vout), bool(found.value)", "response": "Find the vector in a specified plane that maps to a specified\n    vector in another plane under orthogonal projection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the projection of one vector onto another vector.", "response": "def vproj(a, b):\n    \"\"\"\n    Find the projection of one vector onto another vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vproj_c.html\n\n    :param a: The vector to be projected. \n    :type a: 3-Element Array of floats\n    :param b: The vector onto which a is to be projected. \n    :type b: 3-Element Array of floats\n    :return: The projection of a onto b.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    a = stypes.toDoubleVector(a)\n    b = stypes.toDoubleVector(b)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vproj_c(a, b, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vrel(v1, v2):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    return libspice.vrel_c(v1, v2)", "response": "Return the relative difference between two 3 - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vrelg(v1, v2, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    ndim = ctypes.c_int(ndim)\n    return libspice.vrelg_c(v1, v2, ndim)", "response": "Return the relative difference between two vectors of general dimension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrotate a vector about a specified axis vector by a specified angle and return the rotated vector.", "response": "def vrotv(v, axis, theta):\n    \"\"\"\n    Rotate a vector about a specified axis vector by a\n    specified angle and return the rotated vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vrotv_c.html\n\n    :param v: Vector to be rotated. \n    :type v: 3-Element Array of floats\n    :param axis: Axis of the rotation. \n    :type axis: 3-Element Array of floats\n    :param theta: Angle of rotation (radians). \n    :type theta: float\n    :return: Result of rotating v about axis by theta\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    v = stypes.toDoubleVector(v)\n    axis = stypes.toDoubleVector(axis)\n    theta = ctypes.c_double(theta)\n    r = stypes.emptyDoubleVector(3)\n    libspice.vrotv_c(v, axis, theta, r)\n    return stypes.cVectorToPython(r)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vscl(s, v1):\n    s = ctypes.c_double(s)\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vscl_c(s, v1, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply a scalar and a 3 - dimensional double precision vector."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vsclg(s, v1, ndim):\n    s = ctypes.c_double(s)\n    v1 = stypes.toDoubleVector(v1)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vsclg_c(s, v1, ndim, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply a scalar and a double precision vector of arbitrary dimension."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vsep(v1, v2):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    return libspice.vsep_c(v1, v2)", "response": "Find the separation angle in radians between two 3 - dimensional vectors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the separation angle in radians between two double precision vectors of arbitrary dimension.", "response": "def vsepg(v1, v2, ndim):\n    \"\"\"\n    Find the separation angle in radians between two double\n    precision vectors of arbitrary dimension. This angle is defined\n    as zero if either vector is zero.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vsepg_c.html\n\n    :param v1: First vector \n    :type v1: Array of floats\n    :param v2: Second vector \n    :type v2: Array of floats\n    :param ndim: The number of elements in v1 and v2. \n    :type ndim: int\n    :return: separation angle in radians\n    :rtype: float\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    ndim = ctypes.c_int(ndim)\n    return libspice.vsepg_c(v1, v2, ndim)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the difference between two 3 - dimensional double precision vectors.", "response": "def vsub(v1, v2):\n    \"\"\"\n    Compute the difference between two 3-dimensional,\n    double precision vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vsub_c.html\n\n    :param v1: First vector (minuend). \n    :type v1: 3-Element Array of floats\n    :param v2: Second vector (subtrahend). \n    :type v2: 3-Element Array of floats\n    :return: Difference vector, v1 - v2.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.vsub_c(v1, v2, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vsubg(v1, v2, ndim):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    vout = stypes.emptyDoubleVector(ndim)\n    ndim = ctypes.c_int(ndim)\n    libspice.vsubg_c(v1, v2, ndim, vout)\n    return stypes.cVectorToPython(vout)", "response": "Compute the difference between two double precision double precision vectors of arbitrary dimension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmultiplying the transpose of a 3 - dimensional column vector and a 3 - dimensional column vector.", "response": "def vtmv(v1, matrix, v2):\n    \"\"\"\n    Multiply the transpose of a 3-dimensional column vector\n    a 3x3 matrix, and a 3-dimensional column vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vtmv_c.html\n\n    :param v1: 3 dimensional double precision column vector. \n    :type v1: 3-Element Array of floats\n    :param matrix: 3x3 double precision matrix. \n    :type matrix: 3x3-Element Array of floats\n    :param v2: 3 dimensional double precision column vector. \n    :type v2: 3-Element Array of floats\n    :return: the result of (v1**t * matrix * v2 ).\n    :rtype: float\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    matrix = stypes.toDoubleMatrix(matrix)\n    v2 = stypes.toDoubleVector(v2)\n    return libspice.vtmv_c(v1, matrix, v2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmultiply the transpose of a n - dimensional double precision column vector a nxm matrix and a m - dimensional column vector.", "response": "def vtmvg(v1, matrix, v2, nrow, ncol):\n    \"\"\"\n    Multiply the transpose of a n-dimensional\n    column vector a nxm matrix,\n    and a m-dimensional column vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vtmvg_c.html\n\n    :param v1: n-dimensional double precision column vector. \n    :type v1: Array of floats\n    :param matrix: nxm double precision matrix. \n    :type matrix: NxM-Element Array of floats\n    :param v2: m-dimensional double porecision column vector. \n    :type v2: Array of floats\n    :param nrow: Number of rows in matrix (number of rows in v1.) \n    :type nrow: int\n    :param ncol: Number of columns in matrix (number of rows in v2.) \n    :type ncol: int\n    :return: the result of (v1**t * matrix * v2 )\n    :rtype: float\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    matrix = stypes.toDoubleMatrix(matrix)\n    v2 = stypes.toDoubleVector(v2)\n    nrow = ctypes.c_int(nrow)\n    ncol = ctypes.c_int(ncol)\n    return libspice.vtmvg_c(v1, matrix, v2, nrow, ncol)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vupack(v):\n    v1 = stypes.toDoubleVector(v)\n    x = ctypes.c_double()\n    y = ctypes.c_double()\n    z = ctypes.c_double()\n    libspice.vupack_c(v1, ctypes.byref(x), ctypes.byref(y), ctypes.byref(z))\n    return x.value, y.value, z.value", "response": "Unpack three scalar components from a vector."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vzero(v):\n    v = stypes.toDoubleVector(v)\n    return bool(libspice.vzero_c(v))", "response": "Indicate whether a 3 - vector is the zero vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nindicate whether a general - dimensional vector is the zero vector.", "response": "def vzerog(v, ndim):\n    \"\"\"\n    Indicate whether a general-dimensional vector is the zero vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/vzerog_c.html\n\n    :param v: Vector to be tested \n    :type v: Array of floats\n    :param ndim: Dimension of v \n    :type ndim: int\n    :return: true if and only if v is the zero vector\n    :rtype: bool\n    \"\"\"\n    v = stypes.toDoubleVector(v)\n    ndim = ctypes.c_int(ndim)\n    return bool(libspice.vzerog_c(v, ndim))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wncomd(left, right, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    left = ctypes.c_double(left)\n    right = ctypes.c_double(right)\n    result = stypes.SpiceCell.double(window.size)\n    libspice.wncomd_c(left, right, ctypes.byref(window), result)\n    return result", "response": "Determine the complement of a double precision window with respect to left and right endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncontracts each of the intervals of a double precision window.", "response": "def wncond(left, right, window):\n    \"\"\"\n    Contract each of the intervals of a double precision window.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/wncond_c.html\n\n    :param left: Amount added to each left endpoint. \n    :type left: float\n    :param right: Amount subtracted from each right endpoint. \n    :type right: float\n    :param window: Window to be contracted \n    :type window: spiceypy.utils.support_types.SpiceCell\n    :return: Contracted Window.\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    left = ctypes.c_double(left)\n    right = ctypes.c_double(right)\n    libspice.wncond_c(left, right, ctypes.byref(window))\n    return window"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wndifd(a, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == 1\n    assert b.dtype == 1\n    c = stypes.SpiceCell.double(a.size + b.size)\n    libspice.wndifd_c(ctypes.byref(a), ctypes.byref(b), ctypes.byref(c))\n    return c", "response": "Place the difference of two double precision windows into\n    a third window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining whether a point is an element of a double precision window.", "response": "def wnelmd(point, window):\n    \"\"\"\n    Determine whether a point is an element of a double precision\n    window.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/wnelmd_c.html\n\n    :param point: Input point. \n    :type point: float\n    :param window: Input window \n    :type window: spiceypy.utils.support_types.SpiceCell\n    :return: returns True if point is an element of window.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    point = ctypes.c_double(point)\n    return bool(libspice.wnelmd_c(point, ctypes.byref(window)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wnexpd(left, right, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    left = ctypes.c_double(left)\n    right = ctypes.c_double(right)\n    libspice.wnexpd_c(left, right, ctypes.byref(window))\n    return window", "response": "Expand each of the intervals of a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wnextd(side, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    assert side == 'L' or side == 'R'\n    side = ctypes.c_char(side.encode(encoding='UTF-8'))\n    libspice.wnextd_c(side, ctypes.byref(window))\n    return window", "response": "Extract the left or right endpoints from a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wnfetd(window, n):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    n = ctypes.c_int(n)\n    left = ctypes.c_double()\n    right = ctypes.c_double()\n    libspice.wnfetd_c(ctypes.byref(window), n, ctypes.byref(left),\n                      ctypes.byref(right))\n    return left.value, right.value", "response": "Fetch a particular interval from a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wnfild(small, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    small = ctypes.c_double(small)\n    libspice.wnfild_c(small, ctypes.byref(window))\n    return window", "response": "Fill small gaps between adjacent intervals of a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wnfltd(small, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    small = ctypes.c_double(small)\n    libspice.wnfltd_c(small, ctypes.byref(window))\n    return window", "response": "Filter small intervals from a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wnincd(left, right, window):\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    left = ctypes.c_double(left)\n    right = ctypes.c_double(right)\n    return bool(libspice.wnincd_c(left, right, ctypes.byref(window)))", "response": "Determines whether an interval is included in a double precision window."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts an interval into a double precision window.", "response": "def wninsd(left, right, window):\n    \"\"\"\n    Insert an interval into a double precision window.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/wninsd_c.html\n\n    :param left: Left endpoints of new interval. \n    :type left: float\n    :param right: Right endpoints of new interval. \n    :type right: float\n    :param window: Input window. \n    :type window: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    left = ctypes.c_double(left)\n    right = ctypes.c_double(right)\n    libspice.wninsd_c(left, right, ctypes.byref(window))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wnintd(a, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert b.dtype == 1\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == 1\n    c = stypes.SpiceCell.double(b.size + a.size)\n    libspice.wnintd_c(ctypes.byref(a), ctypes.byref(b), ctypes.byref(c))\n    return c", "response": "Place the intersection of two double precision windows into\n    a third window."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wnreld(a, op, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert b.dtype == 1\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == 1\n    assert isinstance(op, str)\n    op = stypes.stringToCharP(op.encode(encoding='UTF-8'))\n    return bool(libspice.wnreld_c(ctypes.byref(a), op, ctypes.byref(b)))", "response": "Compare two double precision windows."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsummarizing the contents of a double precision window.", "response": "def wnsumd(window):\n    \"\"\"\n    Summarize the contents of a double precision window.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/wnsumd_c.html\n\n    :param window: Window to be summarized. \n    :type window: spiceypy.utils.support_types.SpiceCell\n    :return:\n            Total measure of intervals in window,\n            Average measure, Standard deviation,\n            Location of shortest interval,\n            Location of longest interval.\n    :rtype: tuple\n    \"\"\"\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    meas = ctypes.c_double()\n    avg = ctypes.c_double()\n    stddev = ctypes.c_double()\n    shortest = ctypes.c_int()\n    longest = ctypes.c_int()\n    libspice.wnsumd_c(ctypes.byref(window), ctypes.byref(meas),\n                      ctypes.byref(avg), ctypes.byref(stddev),\n                      ctypes.byref(shortest), ctypes.byref(longest))\n    return meas.value, avg.value, stddev.value, shortest.value, longest.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wnunid(a, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert b.dtype == 1\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == 1\n    c = stypes.SpiceCell.double(b.size + a.size)\n    libspice.wnunid_c(ctypes.byref(a), ctypes.byref(b), ctypes.byref(c))\n    return c", "response": "Place the union of two double precision windows into a third window."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a valid double precision window from the contents of a window array.", "response": "def wnvald(insize, n, window):\n    \"\"\"\n    Form a valid double precision window from the contents\n    of a window array.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/wnvald_c.html\n\n    :param insize: Size of window. \n    :type insize: int\n    :param n: Original number of endpoints. \n    :type n: int\n    :param window: Input window. \n    :type window: spiceypy.utils.support_types.SpiceCell\n    :return: The union of the intervals in the input cell.\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(window, stypes.SpiceCell)\n    assert window.dtype == 1\n    insize = ctypes.c_int(insize)\n    n = ctypes.c_int(n)\n    libspice.wnvald_c(insize, n, ctypes.byref(window))\n    return window"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef writln(line, unit):\n    lineP    = stypes.stringToCharP(line)\n    unit     = ctypes.c_int(unit)\n    line_len = ctypes.c_int(len(line))\n    libspice.writln_(lineP, ctypes.byref(unit), line_len)", "response": "This function writes a line to a logical unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xf2rav(xform):\n    xform = stypes.toDoubleMatrix(xform)\n    rot = stypes.emptyDoubleMatrix()\n    av = stypes.emptyDoubleVector(3)\n    libspice.xf2rav_c(xform, rot, av)\n    return stypes.cMatrixToNumpy(rot), stypes.cVectorToPython(av)", "response": "This routine determines the rotation matrix and angular velocity of a state transformation matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform a state between coordinate systems.", "response": "def xfmsta(input_state, input_coord_sys, output_coord_sys, body):\n    \"\"\"\n    Transform a state between coordinate systems.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/xfmsta_c.html\n\n    :param input_state: Input state. \n    :type input_state: 6-Element Array of floats\n    :param input_coord_sys: Current (input) coordinate system. \n    :type input_coord_sys: str\n    :param output_coord_sys: Desired (output) coordinate system. \n    :type output_coord_sys: str\n    :param body:\n                Name or NAIF ID of body with which coordinates\n                are associated (if applicable).\n    :type body: str\n    :return: Converted output state\n    :rtype: 6-Element Array of floats\n    \"\"\"\n    input_state = stypes.toDoubleVector(input_state)\n    input_coord_sys = stypes.stringToCharP(input_coord_sys)\n    output_coord_sys = stypes.stringToCharP(output_coord_sys)\n    body = stypes.stringToCharP(body)\n    output_state = stypes.emptyDoubleVector(6)\n    libspice.xfmsta_c(input_state, input_coord_sys, output_coord_sys, body,\n                      output_state)\n    return stypes.cVectorToPython(output_state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranspose a 3x3 matrix.", "response": "def xpose(m):\n    \"\"\"\n    Transpose a 3x3 matrix\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/xpose_c.html\n\n    :param m: Matrix to be transposed \n    :type m: 3x3-Element Array of floats\n    :return: Transposed matrix\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    m = stypes.toDoubleMatrix(m)\n    mout = stypes.emptyDoubleMatrix(x=3, y=3)\n    libspice.xpose_c(m, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xpose6(m):\n    m = stypes.toDoubleMatrix(m)\n    mout = stypes.emptyDoubleMatrix(x=6, y=6)\n    libspice.xpose6_c(m, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Transpose a 6x6 matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xposeg(matrix, nrow, ncol):\n    matrix = stypes.toDoubleMatrix(matrix)\n    mout = stypes.emptyDoubleMatrix(x=ncol, y=nrow)\n    ncol = ctypes.c_int(ncol)\n    nrow = ctypes.c_int(nrow)\n    libspice.xposeg_c(matrix, nrow, ncol, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Transpose a matrix of arbitrary size\n    in place."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SpiceUDSTEP(f):\n\n    @functools.wraps(f)\n    def wrapping_udstep(x, value):\n        result = f(x)\n        value[0] = c_double(result)\n\n    return UDSTEP(wrapping_udstep)", "response": "Decorator for wrapping python functions in spice udstep callback type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CallUDFUNS(f, x):\n    value = c_double()\n    f(x, byref(value))\n    return value.value", "response": "This function is used to call a UDF function in SpiceUDFUNS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the c vector data into the correct python data type", "response": "def cVectorToPython(x):\n    \"\"\"\n    Convert the c vector data into the correct python data type\n    (numpy arrays or strings)\n    :param x:\n    :return:\n    \"\"\"\n    if isinstance(x[0], bool):\n        return numpy.frombuffer(x, dtype=numpy.bool).copy()\n    elif isinstance(x[0], int):\n        return numpy.frombuffer(x, dtype=numpy.int32).copy()\n    elif isinstance(x[0], float):\n        return numpy.frombuffer(x, dtype=numpy.float64).copy()\n    elif isinstance(x[0].value, bytes):\n        return [toPythonString(y) for y in x]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert input string to null string", "response": "def stringToCharP(inobject, inlen=None):\n\n    \"\"\"\n    :param inobject: input string, int for getting null string of length of int\n    :param inlen: optional parameter, length of a given string can be specified\n    :return:\n    \"\"\"\n    if inlen and isinstance(inobject, str):\n        return create_string_buffer(inobject.encode(encoding='UTF-8'), inlen)\n    if isinstance(inobject, bytes):\n        return inobject\n    if isinstance(inobject, c_int):\n        return stringToCharP(\" \" * inobject.value)\n    if isinstance(inobject, int):\n        return stringToCharP(\" \" * inobject)\n    return c_char_p(inobject.encode(encoding='UTF-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asalsan(X, rank, **kwargs):\n    # init options\n    ainit = kwargs.pop('init', _DEF_INIT)\n    proj = kwargs.pop('proj', _DEF_PROJ)\n    maxIter = kwargs.pop('maxIter', _DEF_MAXITER)\n    conv = kwargs.pop('conv', _DEF_CONV)\n    nne = kwargs.pop('nne', _DEF_NNE)\n    optfunc = kwargs.pop('optfunc', _DEF_OPTFUNC)\n    if not len(kwargs) == 0:\n        raise BaseException('Unknown keywords (%s)' % (kwargs.keys()))\n\n    # init starting points\n    D = ones((len(X), rank))\n    sz = X[0].shape\n    n = sz[0]\n    R = rand(rank, rank)\n    if ainit == 'random':\n        A = rand(n, rank)\n    elif ainit == 'nvecs':\n        S = zeros((n, n))\n        T = zeros((n, n))\n        for i in range(len(X)):\n            T = X[i]\n            S = S + T + T.T\n        evals, A = eigsh(S, rank)\n        if nne > 0:\n            A[A < 0] = 0\n        if proj:\n            Q, A2 = qr(A)\n            X2 = __projectSlices(X, Q)\n            R = __updateR(X2, A2, D, R, nne)\n        else:\n            R = __updateR(X, A, D, R, nne)\n    elif isinstance(ainit, np.ndarray):\n        A = ainit\n    else:\n        raise 'Unknown init option (\"%s\")' % ainit\n\n    # perform decomposition\n    if issparse(X[0]):\n        normX = [norm(M.data) ** 2 for M in X]\n        Xflat = [M.tolil().reshape((1, prod(M.shape))).tocsr() for M in X]\n    else:\n        normX = [norm(M) ** 2 for M in X]\n        Xflat = [M.flatten() for M in X]\n    M = zeros((n, n))\n    normXSum = sum(normX)\n    #normX = norm(X)**2\n    fit = fitold = f = fitchange = 0\n    exectimes = []\n    for iters in xrange(maxIter):\n        tic = time.clock()\n        fitold = fit\n        A = __updateA(X, A, D, R, nne)\n        if proj:\n            Q, A2 = qr(A)\n            X2 = __projectSlices(X, Q)\n            R = __updateR(X2, A2, D, R, nne)\n            D, f = __updateD(X2, A2, D, R, nne, optfunc)\n        else:\n            R = __updateR(X, A, D, R, nne)\n            D, f = __updateD(X, A, D, R, nne, optfunc)\n\n        # compute fit\n        f = 0\n        for i in xrange(len(X)):\n            AD = dot(A, diag(D[i, :]))\n            M = dot(dot(AD, R), AD.T)\n            f += normX[i] + norm(M) ** 2 - 2 * Xflat[i].dot(M.flatten())\n        f *= 0.5\n        fit = 1 - (f / normXSum)\n        fitchange = abs(fitold - fit)\n\n        exectimes.append(time.clock() - tic)\n\n        # print iter info when debugging is enabled\n        _log.debug('[%3d] fit: %.5f | delta: %7.1e | secs: %.5f' % (\n            iters, fit, fitchange, exectimes[-1]\n        ))\n\n        if iters > 1 and fitchange < conv:\n            break\n    return A, R, D, fit, iters, array(exectimes)", "response": "ASALSAN algorithm to compute the three - way DEDICOM decomposition of a tensor X."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing Gradient for update of D", "response": "def updateD_G(self, x):\n        \"\"\"\n        Compute Gradient for update of D\n\n        See [2] for derivation of Gradient\n        \"\"\"\n        self.precompute(x)\n        g = zeros(len(x))\n        Ai = zeros(self.A.shape[0])\n        for i in range(len(g)):\n            Ai = self.A[:, i]\n            g[i] = (self.E * (dot(self.AD, outer(self.R[:, i], Ai)) +\n                    dot(outer(Ai, self.R[i, :]), self.ADt))).sum()\n        return -2 * g"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes Hessian for update of D", "response": "def updateD_H(self, x):\n        \"\"\"\n        Compute Hessian for update of D\n\n        See [2] for derivation of Hessian\n        \"\"\"\n        self.precompute(x)\n        H = zeros((len(x), len(x)))\n        Ai = zeros(self.A.shape[0])\n        Aj = zeros(Ai.shape)\n        for i in range(len(x)):\n            Ai = self.A[:, i]\n            ti = dot(self.AD, outer(self.R[:, i], Ai)) + dot(outer(Ai, self.R[i, :]), self.ADt)\n\n            for j in range(i, len(x)):\n                Aj = self.A[:, j]\n                tj = outer(Ai, Aj)\n                H[i, j] = (\n                    self.E * (self.R[i, j] * tj + self.R[j, i] * tj.T) -\n                    ti * (\n                        dot(self.AD, outer(self.R[:, j], Aj)) +\n                        dot(outer(Aj, self.R[j, :]), self.ADt)\n                    )\n                ).sum()\n                H[j, i] = H[i, j]\n        H *= -2\n        e = eigvals(H).min()\n        H = H + (eye(H.shape[0]) * e)\n        return H"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_sequence(obj):\n    try:\n        from collections import Sequence\n    except ImportError:\n        from operator import isSequenceType\n        return isSequenceType(obj)\n    else:\n        return isinstance(obj, Sequence)", "response": "Helper function to determine if an object is a sequence"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the times vector product of the current and new values.", "response": "def _ttv_compute(self, v, dims, vidx, remdims):\n        \"\"\"\n        Tensor times vector product\n\n        Parameter\n        ---------\n        \"\"\"\n        if not isinstance(v, tuple):\n            raise ValueError('v must be a tuple of vectors')\n        ndim = self.ndim\n        order = list(remdims) + list(dims)\n        if ndim > 1:\n            T = self.transpose(order)\n        sz = array(self.shape)[order]\n        for i in np.arange(len(dims), 0, -1):\n            T = T.reshape((sz[:ndim - 1].prod(), sz[ndim - 1]))\n            T = T.dot(v[vidx[i - 1]])\n            ndim -= 1\n        if ndim > 0:\n            T = T.reshape(sz[:ndim])\n        return T"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unfold(self, mode):\n\n        sz = array(self.shape)\n        N = len(sz)\n        order = ([mode], from_to_without(N - 1, -1, mode, step=-1, skip=-1))\n        newsz = (sz[order[0]][0], prod(sz[order[1]]))\n        arr = self.transpose(axes=(order[0] + order[1]))\n        arr = arr.reshape(newsz)\n        return unfolded_dtensor(arr, mode, self.shape)", "response": "Unfolds a dense tensor in mode n."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hooi(X, rank, **kwargs):\n    # init options\n    ainit = kwargs.pop('init', __DEF_INIT)\n    maxIter = kwargs.pop('maxIter', __DEF_MAXITER)\n    conv = kwargs.pop('conv', __DEF_CONV)\n    dtype = kwargs.pop('dtype', X.dtype)\n    if not len(kwargs) == 0:\n        raise ValueError('Unknown keywords (%s)' % (kwargs.keys()))\n\n    ndims = X.ndim\n    if is_number(rank):\n        rank = rank * ones(ndims)\n\n    normX = norm(X)\n\n    U = __init(ainit, X, ndims, rank, dtype)\n    fit = 0\n    exectimes = []\n    for itr in range(maxIter):\n        tic = time.clock()\n        fitold = fit\n\n        for n in range(ndims):\n            Utilde = ttm(X, U, n, transp=True, without=True)\n            U[n] = nvecs(Utilde, n, rank[n])\n\n        # compute core tensor to get fit\n        core = ttm(Utilde, U, n, transp=True)\n\n        # since factors are orthonormal, compute fit on core tensor\n        normresidual = sqrt(normX ** 2 - norm(core) ** 2)\n\n        # fraction explained by model\n        fit = 1 - (normresidual / normX)\n        fitchange = abs(fitold - fit)\n        exectimes.append(time.clock() - tic)\n\n        _log.debug(\n            '[%3d] fit: %.5f | delta: %7.1e | secs: %.5f'\n            % (itr, fit, fitchange, exectimes[-1])\n        )\n        if itr > 1 and fitchange < conv:\n            break\n    return core, U", "response": "Hooi decomposition of a tensor X using Higher - Order Orthogonal Iterations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uttkrp(self, U, mode):\n\n        \"\"\"\n        Unfolded tensor times Khatri-Rao product for Kruskal tensors\n\n        Parameters\n        ----------\n        X : tensor_mixin\n            Tensor whose unfolding should be multiplied.\n        U : list of array_like\n            Matrices whose Khatri-Rao product should be multiplied.\n        mode : int\n            Mode in which X should be unfolded.\n\n        See also\n        --------\n        sktensor.sptensor.uttkrp : Efficient computation of uttkrp for sparse tensors\n        ttensor.uttkrp : Efficient computation of uttkrp for Tucker operators\n        \"\"\"\n        N = self.ndim\n        if mode == 1:\n            R = U[1].shape[1]\n        else:\n            R = U[0].shape[1]\n        W = np.tile(self.lmbda, 1, R)\n        for i in range(mode) + range(mode + 1, N):\n            W = W * dot(self.U[i].T, U[i])\n        return dot(self.U[mode], W)", "response": "Unfolded tensor times Khatri - Rao product for sparse and tucker operators."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef norm(self):\n        N = len(self.shape)\n        coef = outer(self.lmbda, self.lmbda)\n        for i in range(N):\n            coef = coef * dot(self.U[i].T, self.U[i])\n        return np.sqrt(coef.sum())", "response": "Efficient computation of the Frobenius norm for ktensors\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef innerprod(self, X):\n        N = len(self.shape)\n        R = len(self.lmbda)\n        res = 0\n        for r in range(R):\n            vecs = []\n            for n in range(N):\n                vecs.append(self.U[n][:, r])\n            res += self.lmbda[r] * X.ttv(tuple(vecs))\n        return res", "response": "Efficient computation of the inner product of a ktensor with another tensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a ktensor into a dense multidimensional array", "response": "def toarray(self):\n        \"\"\"\n        Converts a ktensor into a dense multidimensional ndarray\n\n        Returns\n        -------\n        arr : np.ndarray\n            Fully computed multidimensional array whose shape matches\n            the original ktensor.\n        \"\"\"\n        A = dot(self.lmbda, khatrirao(tuple(self.U)).T)\n        return A.reshape(self.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a sptensor from a dense numpy array", "response": "def fromarray(A):\n    \"\"\"Create a sptensor from a dense numpy array\"\"\"\n    subs = np.nonzero(A)\n    vals = A[subs]\n    return sptensor(subs, vals, shape=A.shape, dtype=A.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the T - time - domain table for each element of the set of edition vectors.", "response": "def _ttm_me_compute(self, V, edims, sdims, transp):\n        \"\"\"\n        Assume Y = T x_i V_i for i = 1...n can fit into memory\n        \"\"\"\n        shapeY = np.copy(self.shape)\n\n        # Determine size of Y\n        for n in np.union1d(edims, sdims):\n            shapeY[n] = V[n].shape[1] if transp else V[n].shape[0]\n\n        # Allocate Y (final result) and v (vectors for elementwise computations)\n        Y = zeros(shapeY)\n        shapeY = array(shapeY)\n        v = [None for _ in range(len(edims))]\n\n        for i in range(np.prod(shapeY[edims])):\n            rsubs = unravel_index(shapeY[edims], i)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transpose(self, axes=None):\n        if axes is None:\n            raise NotImplementedError(\n                'Sparse tensor transposition without axes argument is not supported'\n            )\n        nsubs = tuple([self.subs[idx] for idx in axes])\n        nshape = [self.shape[idx] for idx in axes]\n        return sptensor(nsubs, self.vals, nshape)", "response": "Returns a new instance of the sptensor with the same shape and subsformation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concatenate(self, tpl, axis=None):\n        if axis is None:\n            raise NotImplementedError(\n                'Sparse tensor concatenation without axis argument is not supported'\n            )\n        T = self\n        for i in range(1, len(tpl)):\n            T = _single_concatenate(T, tpl[i], axis=axis)\n        return T", "response": "Concatenates sparse tensors.\n\n        Parameters\n        ----------\n        tpl :  tuple of sparse tensors\n            Tensors to be concatenated.\n        axis :  int, optional\n            Axis along which concatenation should take place"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fold(self):\n        nsubs = zeros((len(self.data), len(self.ten_shape)), dtype=np.int)\n        if len(self.rdims) > 0:\n            nidx = unravel_index(self.row, self.ten_shape[self.rdims])\n            for i in range(len(self.rdims)):\n                nsubs[:, self.rdims[i]] = nidx[i]\n        if len(self.cdims) > 0:\n            nidx = unravel_index(self.col, self.ten_shape[self.cdims])\n            for i in range(len(self.cdims)):\n                nsubs[:, self.cdims[i]] = nidx[i]\n        nsubs = [z.flatten() for z in hsplit(nsubs, len(self.ten_shape))]\n        return sptensor(tuple(nsubs), self.data, self.ten_shape)", "response": "Recreate original tensor by folding unfolded_sptensor according to ten_shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates step for A", "response": "def _updateA(X, A, R, P, Z, lmbdaA, orthogonalize):\n    \"\"\"Update step for A\"\"\"\n    n, rank = A.shape\n    F = zeros((n, rank), dtype=A.dtype)\n    E = zeros((rank, rank), dtype=A.dtype)\n\n    AtA = dot(A.T, A)\n\n    for i in range(len(X)):\n        F += X[i].dot(dot(A, R[i].T)) + X[i].T.dot(dot(A, R[i]))\n        E += dot(R[i], dot(AtA, R[i].T)) + dot(R[i].T, dot(AtA, R[i]))\n\n    # regularization\n    I = lmbdaA * eye(rank, dtype=A.dtype)\n\n    # attributes\n    for i in range(len(Z)):\n        F += P[i].dot(Z[i].T)\n        E += dot(Z[i], Z[i].T)\n\n    # finally compute update for A\n    A = solve(I + E.T, F.T).T\n    return orth(A) if orthogonalize else A"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute fit for full slices", "response": "def _compute_fval(X, A, R, P, Z, lmbdaA, lmbdaR, lmbdaZ, normX):\n    \"\"\"Compute fit for full slices\"\"\"\n    f = lmbdaA * norm(A) ** 2\n    for i in range(len(X)):\n        ARAt = dot(A, dot(R[i], A.T))\n        f += (norm(X[i] - ARAt) ** 2) / normX[i] + lmbdaR * norm(R[i]) ** 2\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nalternate least-sqaures algorithm to compute the CP decomposition. Parameters ---------- X : tensor_mixin The tensor to be decomposed. rank : int Tensor rank of the decomposition. init : {'random', 'nvecs'}, optional The initialization method to use. - random : Factor matrices are initialized randomly. - nvecs : Factor matrices are initialzed via HOSVD. (default 'nvecs') max_iter : int, optional Maximium number of iterations of the ALS algorithm. (default 500) fit_method : {'full', None} The method to compute the fit of the factorization - 'full' : Compute least-squares fit of the dense approximation of. X and X. - None : Do not compute the fit of the factorization, but iterate until ``max_iter`` (Useful for large-scale tensors). (default 'full') conv : float Convergence tolerance on difference of fit between iterations (default 1e-5) Returns ------- P : ktensor Rank ``rank`` factorization of X. ``P.U[i]`` corresponds to the factor matrix for the i-th mode. ``P.lambda[i]`` corresponds to the weight of the i-th mode. fit : float Fit of the factorization compared to ``X`` itr : int Number of iterations that were needed until convergence exectimes : ndarray of floats Time needed for each single iteration Examples -------- Create random dense tensor >>> from sktensor import dtensor, ktensor >>> U = [np.random.rand(i,3) for i in (20, 10, 14)] >>> T = dtensor(ktensor(U).toarray()) Compute rank-3 CP decomposition of ``T`` with ALS >>> P, fit, itr, _ = als(T, 3) Result is a decomposed tensor stored as a Kruskal operator >>> type(P) <class 'sktensor.ktensor.ktensor'> Factorization should be close to original data >>> np.allclose(T, P.totensor()) True References ---------- .. [1] Kolda, T. G. & Bader, B. W. Tensor Decompositions and Applications. SIAM Rev. 51, 455\u2013500 (2009). .. [2] Harshman, R. A. Foundations of the PARAFAC procedure: models and conditions for an 'explanatory' multimodal factor analysis. UCLA Working Papers in Phonetics 16, (1970). .. [3] Carroll, J. D., Chang, J. J. Analysis of individual differences in multidimensional scaling via an N-way generalization of 'Eckart-Young' decomposition. Psychometrika 35, 283\u2013319 (1970).", "response": "def als(X, rank, **kwargs):\n    \"\"\"\n    Alternating least-sqaures algorithm to compute the CP decomposition.\n\n    Parameters\n    ----------\n    X : tensor_mixin\n        The tensor to be decomposed.\n    rank : int\n        Tensor rank of the decomposition.\n    init : {'random', 'nvecs'}, optional\n        The initialization method to use.\n            - random : Factor matrices are initialized randomly.\n            - nvecs : Factor matrices are initialzed via HOSVD.\n        (default 'nvecs')\n    max_iter : int, optional\n        Maximium number of iterations of the ALS algorithm.\n        (default 500)\n    fit_method : {'full', None}\n        The method to compute the fit of the factorization\n            - 'full' : Compute least-squares fit of the dense approximation of.\n                       X and X.\n            - None : Do not compute the fit of the factorization, but iterate\n                     until ``max_iter`` (Useful for large-scale tensors).\n        (default 'full')\n    conv : float\n        Convergence tolerance on difference of fit between iterations\n        (default 1e-5)\n\n    Returns\n    -------\n    P : ktensor\n        Rank ``rank`` factorization of X. ``P.U[i]`` corresponds to the factor\n        matrix for the i-th mode. ``P.lambda[i]`` corresponds to the weight\n        of the i-th mode.\n    fit : float\n        Fit of the factorization compared to ``X``\n    itr : int\n        Number of iterations that were needed until convergence\n    exectimes : ndarray of floats\n        Time needed for each single iteration\n\n    Examples\n    --------\n    Create random dense tensor\n\n    >>> from sktensor import dtensor, ktensor\n    >>> U = [np.random.rand(i,3) for i in (20, 10, 14)]\n    >>> T = dtensor(ktensor(U).toarray())\n\n    Compute rank-3 CP decomposition of ``T`` with ALS\n\n    >>> P, fit, itr, _ = als(T, 3)\n\n    Result is a decomposed tensor stored as a Kruskal operator\n\n    >>> type(P)\n    <class 'sktensor.ktensor.ktensor'>\n\n    Factorization should be close to original data\n\n    >>> np.allclose(T, P.totensor())\n    True\n\n    References\n    ----------\n    .. [1] Kolda, T. G. & Bader, B. W.\n           Tensor Decompositions and Applications.\n           SIAM Rev. 51, 455\u2013500 (2009).\n    .. [2] Harshman, R. A.\n           Foundations of the PARAFAC procedure: models and conditions for an 'explanatory' multimodal factor analysis.\n           UCLA Working Papers in Phonetics 16, (1970).\n    .. [3] Carroll, J. D.,  Chang, J. J.\n           Analysis of individual differences in multidimensional scaling via an N-way generalization of 'Eckart-Young' decomposition.\n           Psychometrika 35, 283\u2013319 (1970).\n    \"\"\"\n\n    # init options\n    ainit = kwargs.pop('init', _DEF_INIT)\n    maxiter = kwargs.pop('max_iter', _DEF_MAXITER)\n    fit_method = kwargs.pop('fit_method', _DEF_FIT_METHOD)\n    conv = kwargs.pop('conv', _DEF_CONV)\n    dtype = kwargs.pop('dtype', _DEF_TYPE)\n    if not len(kwargs) == 0:\n        raise ValueError('Unknown keywords (%s)' % (kwargs.keys()))\n\n    N = X.ndim\n    normX = norm(X)\n\n    U = _init(ainit, X, N, rank, dtype)\n    fit = 0\n    exectimes = []\n    for itr in range(maxiter):\n        tic = time.clock()\n        fitold = fit\n\n        for n in range(N):\n            Unew = X.uttkrp(U, n)\n            Y = ones((rank, rank), dtype=dtype)\n            for i in (list(range(n)) + list(range(n + 1, N))):\n                Y = Y * dot(U[i].T, U[i])\n            Unew = Unew.dot(pinv(Y))\n            # Normalize\n            if itr == 0:\n                lmbda = sqrt((Unew ** 2).sum(axis=0))\n            else:\n                lmbda = Unew.max(axis=0)\n                lmbda[lmbda < 1] = 1\n            U[n] = Unew / lmbda\n\n        P = ktensor(U, lmbda)\n        if fit_method == 'full':\n            normresidual = normX ** 2 + P.norm() ** 2 - 2 * P.innerprod(X)\n            fit = 1 - (normresidual / normX ** 2)\n        else:\n            fit = itr\n        fitchange = abs(fitold - fit)\n        exectimes.append(time.clock() - tic)\n        _log.debug(\n            '[%3d] fit: %.5f | delta: %7.1e | secs: %.5f' %\n            (itr, fit, fitchange, exectimes[-1])\n        )\n        if itr > 0 and fitchange < conv:\n            break\n\n    return P, fit, itr, array(exectimes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init(init, X, N, rank, dtype):\n    Uinit = [None for _ in range(N)]\n    if isinstance(init, list):\n        Uinit = init\n    elif init == 'random':\n        for n in range(1, N):\n            Uinit[n] = array(rand(X.shape[n], rank), dtype=dtype)\n    elif init == 'nvecs':\n        for n in range(1, N):\n            Uinit[n] = array(nvecs(X, n, rank), dtype=dtype)\n    else:\n        raise 'Unknown option (init=%s)' % str(init)\n    return Uinit", "response": "Initialization for CP models\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nvecs(X, n, rank, do_flipsign=True, dtype=np.float):\n    Xn = X.unfold(n)\n    if issparse_mat(Xn):\n        Xn = csr_matrix(Xn, dtype=dtype)\n        Y = Xn.dot(Xn.T)\n        _, U = eigsh(Y, rank, which='LM')\n    else:\n        Y = Xn.dot(Xn.T)\n        N = Y.shape[0]\n        _, U = eigh(Y, eigvals=(N - rank, N - 1))\n        #_, U = eigsh(Y, rank, which='LM')\n    # reverse order of eigenvectors such that eigenvalues are decreasing\n    U = array(U[:, ::-1])\n    # flip sign\n    if do_flipsign:\n        U = flipsign(U)\n    return U", "response": "Eigendecomposition of mode - n unfolding of a tensor X"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flipsign(U):\n    midx = abs(U).argmax(axis=0)\n    for i in range(U.shape[1]):\n        if U[midx[i], i] < 0:\n            U[:, i] = -U[:, i]\n    return U", "response": "Flip sign of factor matrices such that largest magnitude\n    element will be positive\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the columnwise Khatri - Rao product.", "response": "def khatrirao(A, reverse=False):\n    \"\"\"\n    Compute the columnwise Khatri-Rao product.\n\n    Parameters\n    ----------\n    A : tuple of ndarrays\n        Matrices for which the columnwise Khatri-Rao product should be computed\n\n    reverse : boolean\n        Compute Khatri-Rao product in reverse order\n\n    Examples\n    --------\n    >>> A = np.random.randn(5, 2)\n    >>> B = np.random.randn(4, 2)\n    >>> C = khatrirao((A, B))\n    >>> C.shape\n    (20, 2)\n    >>> (C[:, 0] == np.kron(A[:, 0], B[:, 0])).all()\n    true\n    >>> (C[:, 1] == np.kron(A[:, 1], B[:, 1])).all()\n    true\n    \"\"\"\n\n    if not isinstance(A, tuple):\n        raise ValueError('A must be a tuple of array likes')\n    N = A[0].shape[1]\n    M = 1\n    for i in range(len(A)):\n        if A[i].ndim != 2:\n            raise ValueError('A must be a tuple of matrices (A[%d].ndim = %d)' % (i, A[i].ndim))\n        elif N != A[i].shape[1]:\n            raise ValueError('All matrices must have same number of columns')\n        M *= A[i].shape[0]\n    matorder = arange(len(A))\n    if reverse:\n        matorder = matorder[::-1]\n    # preallocate\n    P = np.zeros((M, N), dtype=A[0].dtype)\n    for n in range(N):\n        ab = A[matorder[0]][:, n]\n        for j in range(1, len(matorder)):\n            ab = np.kron(ab, A[matorder[j]][:, n])\n        P[:, n] = ab\n    return P"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef teneye(dim, order):\n    I = zeros(dim ** order)\n    for f in range(dim):\n        idd = f\n        for i in range(1, order):\n            idd = idd + dim ** (i - 1) * (f - 1)\n        I[idd] = 1\n    return I.reshape(ones(order) * dim)", "response": "Create tensor with superdiagonal all one rest zeros\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ttm(self, V, mode=None, transp=False, without=False):\n        if mode is None:\n            mode = range(self.ndim)\n        if isinstance(V, np.ndarray):\n            Y = self._ttm_compute(V, mode, transp)\n        elif is_sequence(V):\n            dims, vidx = check_multiplication_dims(mode, self.ndim, len(V), vidx=True, without=without)\n            Y = self._ttm_compute(V[vidx[0]], dims[0], transp)\n            for i in xrange(1, len(dims)):\n                Y = Y._ttm_compute(V[vidx[i]], dims[i], transp)\n        return Y", "response": "Returns the tensor times matrix product of a set of elements in V."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ttv(self, v, modes=[], without=False):\n        if not isinstance(v, tuple):\n            v = (v, )\n        dims, vidx = check_multiplication_dims(modes, self.ndim, len(v), vidx=True, without=without)\n        for i in range(len(dims)):\n            if not len(v[vidx[i]]) == self.shape[dims[i]]:\n                raise ValueError('Multiplicant is wrong size')\n        remdims = np.setdiff1d(range(self.ndim), dims)\n        return self._ttv_compute(v, dims, vidx, remdims)", "response": "Computes the tensor times vector product of the given vector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(self, *args, **options):\n\n        from categories.migration import migrate_app\n        from categories.settings import MODEL_REGISTRY\n        if options['app_names']:\n            for app in options['app_names']:\n                migrate_app(None, app)\n        else:\n            for app in MODEL_REGISTRY:\n                migrate_app(None, app)", "response": "Handles the migration of the tables\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a dictionary and a registration function call_func on the model and the associated object.", "response": "def _process_registry(registry, call_func):\n    \"\"\"\n    Given a dictionary, and a registration function, process the registry\n    \"\"\"\n    from django.core.exceptions import ImproperlyConfigured\n    from django.apps import apps\n\n    for key, value in list(registry.items()):\n        model = apps.get_model(*key.split('.'))\n        if model is None:\n            raise ImproperlyConfigured(_('%(key)s is not a model') % {'key': key})\n        if isinstance(value, (tuple, list)):\n            for item in value:\n                if isinstance(item, str):\n                    call_func(model, item)\n                elif isinstance(item, dict):\n                    field_name = item.pop('name')\n                    call_func(model, field_name, extra_params=item)\n                else:\n                    raise ImproperlyConfigured(_(\"%(settings)s doesn't recognize the value of %(key)s\") %\n                                               {'settings': 'CATEGORY_SETTINGS', 'key': key})\n        elif isinstance(value, str):\n            call_func(model, value)\n        elif isinstance(value, dict):\n            field_name = value.pop('name')\n            call_func(model, field_name, extra_params=value)\n        else:\n            raise ImproperlyConfigured(_(\"%(settings)s doesn't recognize the value of %(key)s\") %\n                                       {'settings': 'CATEGORY_SETTINGS', 'key': key})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_model(self, app, model_name, field_type, field_definitions):\n        from django.apps import apps\n        import collections\n\n        app_label = app\n\n        if isinstance(field_definitions, str):\n            field_definitions = [field_definitions]\n        elif not isinstance(field_definitions, collections.Iterable):\n            raise ImproperlyConfigured(_('Field configuration for %(app)s should be a string or iterable') % {'app': app})\n\n        if field_type not in ('ForeignKey', 'ManyToManyField'):\n            raise ImproperlyConfigured(_('`field_type` must be either `\"ForeignKey\"` or `\"ManyToManyField\"`.'))\n\n        try:\n            if not hasattr(model_name, \"_meta\"):\n                app_config = apps.get_app_config(app)\n                app_label = app_config.label\n                model = app_config.get_model(model_name)\n            else:\n                model = model_name\n                model_name = model._meta.model_name\n            opts = model._meta\n            if app_label not in self._model_registry:\n                self._model_registry[app_label] = []\n            if model not in self._model_registry[app_label]:\n                self._model_registry[app_label].append(model)\n        except LookupError:\n            raise ImproperlyConfigured('Model \"%(model)s\" doesn\\'t exist in app \"%(app)s\".' % {'model': model_name, 'app': app})\n\n        if not isinstance(field_definitions, (tuple, list)):\n            field_definitions = [field_definitions]\n\n        for fld in field_definitions:\n            extra_params = {'to': 'categories.Category', 'blank': True}\n            if field_type != 'ManyToManyField':\n                extra_params['on_delete'] = CASCADE\n                extra_params['null'] = True\n            if isinstance(fld, str):\n                field_name = fld\n            elif isinstance(fld, dict):\n                if 'name' in fld:\n                    field_name = fld.pop('name')\n                else:\n                    continue\n                extra_params.update(fld)\n            else:\n                raise ImproperlyConfigured(\n                    _(\"%(settings)s doesn't recognize the value of %(app)s.%(model)s\") % {\n                        'settings': 'CATEGORY_SETTINGS',\n                        'app': app,\n                        'model': model_name})\n            registry_name = \".\".join([app_label, model_name.lower(), field_name])\n            if registry_name in self._field_registry:\n                continue\n\n            try:\n                opts.get_field(field_name)\n            except FieldDoesNotExist:\n                self._field_registry[registry_name] = FIELD_TYPES[field_type](**extra_params)\n                self._field_registry[registry_name].contribute_to_class(model, field_name)", "response": "Register a new model in the registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef field_exists(app_name, model_name, field_name):\n    model = apps.get_model(app_name, model_name)\n    table_name = model._meta.db_table\n    cursor = connection.cursor()\n    field_info = connection.introspection.get_table_description(cursor, table_name)\n    field_names = [f.name for f in field_info]\n    return field_name in field_names", "response": "Returns True if the FK or M2M table exists in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop the given field from the given app s model.", "response": "def drop_field(app_name, model_name, field_name):\n    \"\"\"\n    Drop the given field from the app's model\n    \"\"\"\n    app_config = apps.get_app_config(app_name)\n    model = app_config.get_model(model_name)\n    field = model._meta.get_field(field_name)\n    with connection.schema_editor() as schema_editor:\n        schema_editor.remove_field(model, field)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef migrate_app(sender, *args, **kwargs):\n    from .registration import registry\n    if 'app_config' not in kwargs:\n        return\n    app_config = kwargs['app_config']\n\n    app_name = app_config.label\n\n    fields = [fld for fld in list(registry._field_registry.keys()) if fld.startswith(app_name)]\n\n    sid = transaction.savepoint()\n    for fld in fields:\n        model_name, field_name = fld.split('.')[1:]\n        if field_exists(app_name, model_name, field_name):\n            continue\n        model = app_config.get_model(model_name)\n        try:\n            with connection.schema_editor() as schema_editor:\n                schema_editor.add_field(model, registry._field_registry[fld])\n                if sid:\n                    transaction.savepoint_commit(sid)\n        except ProgrammingError:\n            if sid:\n                transaction.savepoint_rollback(sid)\n            continue", "response": "Migrate all models of this app registered\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the list of items for the tree result.", "response": "def items_for_tree_result(cl, result, form):\n    \"\"\"\n    Generates the actual list of data.\n    \"\"\"\n    first = True\n    pk = cl.lookup_opts.pk.attname\n    for field_name in cl.list_display:\n        row_class = ''\n        try:\n            f, attr, value = lookup_field(field_name, result, cl.model_admin)\n        except (AttributeError, ObjectDoesNotExist):\n            result_repr = get_empty_value_display(cl)\n        else:\n            if f is None:\n                if django.VERSION[0] == 1 and django.VERSION[1] == 4:\n                    if field_name == 'action_checkbox':\n                        row_class = ' class=\"action-checkbox disclosure\"'\n                allow_tags = getattr(attr, 'allow_tags', False)\n                boolean = getattr(attr, 'boolean', False)\n                if boolean:\n                    allow_tags = True\n                    result_repr = _boolean_icon(value)\n                else:\n                    result_repr = smart_text(value)\n                # Strip HTML tags in the resulting text, except if the\n                # function has an \"allow_tags\" attribute set to True.\n                if not allow_tags:\n                    result_repr = escape(result_repr)\n                else:\n                    result_repr = mark_safe(result_repr)\n            else:\n                if value is None:\n                    result_repr = get_empty_value_display(cl)\n                if hasattr(f, 'rel') and isinstance(f.rel, models.ManyToOneRel):\n                    result_repr = escape(getattr(result, f.name))\n                else:\n                    result_repr = display_for_field(value, f, '')\n                if isinstance(f, models.DateField) or isinstance(f, models.TimeField):\n                    row_class = ' class=\"nowrap\"'\n            if first:\n                if django.VERSION[0] == 1 and django.VERSION[1] < 4:\n                    try:\n                        f, attr, checkbox_value = lookup_field('action_checkbox', result, cl.model_admin)\n                        if row_class:\n                            row_class = \"%s%s\" % (row_class[:-1], ' disclosure\"')\n                        else:\n                            row_class = ' class=\"disclosure\"'\n                    except (AttributeError, ObjectDoesNotExist):\n                        pass\n\n        if force_text(result_repr) == '':\n            result_repr = mark_safe('&nbsp;')\n        # If list_display_links not defined, add the link tag to the first field\n        if (first and not cl.list_display_links) or field_name in cl.list_display_links:\n            if django.VERSION[0] == 1 and django.VERSION[1] < 4:\n                table_tag = 'td'  # {True:'th', False:'td'}[first]\n            else:\n                table_tag = {True: 'th', False: 'td'}[first]\n\n            url = cl.url_for_result(result)\n            # Convert the pk to something that can be used in Javascript.\n            # Problem cases are long ints (23L) and non-ASCII strings.\n            if cl.to_field:\n                attr = str(cl.to_field)\n            else:\n                attr = pk\n            value = result.serializable_value(attr)\n            result_id = repr(force_text(value))[1:]\n            first = False\n            result_id = escapejs(value)\n            yield mark_safe(\n                format_html(\n                    smart_text('<{}{}><a href=\"{}\"{}>{}</a></{}>'),\n                    table_tag,\n                    row_class,\n                    url,\n                    format_html(\n                        ' onclick=\"opener.dismissRelatedLookupPopup(window, '\n                        '&#39;{}&#39;); return false;\"', result_id\n                    ) if cl.is_popup else '', result_repr, table_tag)\n            )\n\n        else:\n            # By default the fields come from ModelAdmin.list_editable, but if we pull\n            # the fields out of the form instead of list_editable custom admins\n            # can provide fields on a per request basis\n            if form and field_name in form.fields:\n                bf = form[field_name]\n                result_repr = mark_safe(force_text(bf.errors) + force_text(bf))\n            else:\n                result_repr = conditional_escape(result_repr)\n            yield mark_safe(smart_text('<td%s>%s</td>' % (row_class, result_repr)))\n    if form and not form[cl.model._meta.pk.name].is_hidden:\n        yield mark_safe(smart_text('<td>%s</td>' % force_text(form[cl.model._meta.pk.name])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary with the headers and data list together", "response": "def result_tree_list(cl):\n    \"\"\"\n    Displays the headers and data list together\n    \"\"\"\n    import django\n    result = {\n        'cl': cl,\n        'result_headers': list(result_headers(cl)),\n        'results': list(tree_results(cl))\n    }\n    if django.VERSION[0] == 1 and django.VERSION[1] > 2:\n        from django.contrib.admin.templatetags.admin_list import result_hidden_fields\n        result['result_hidden_fields'] = list(result_hidden_fields(cl))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_absolute_url(self):\n        from django.urls import NoReverseMatch\n\n        if self.alternate_url:\n            return self.alternate_url\n        try:\n            prefix = reverse('categories_tree_list')\n        except NoReverseMatch:\n            prefix = '/'\n        ancestors = list(self.get_ancestors()) + [self, ]\n        return prefix + '/'.join([force_text(i.slug) for i in ancestors]) + '/'", "response": "Return a path to the current instance s URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the items of the given content type related to this item.", "response": "def get_content_type(self, content_type):\n        \"\"\"\n        Get all the items of the given content type related to this item.\n        \"\"\"\n        qs = self.get_queryset()\n        return qs.filter(content_type__name=content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relation_type(self, relation_type):\n        qs = self.get_queryset()\n        return qs.filter(relation_type=relation_type)", "response": "Get all the items of the given relation type related to this item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_class_prepared(sender, **kwargs):\n    from .settings import M2M_REGISTRY, FK_REGISTRY\n    from .registration import registry\n    sender_app = sender._meta.app_label\n    sender_name = sender._meta.model_name\n\n    for key, val in list(FK_REGISTRY.items()):\n        app_name, model_name = key.split('.')\n        if app_name == sender_app and sender_name == model_name:\n            registry.register_model(app_name, sender, 'ForeignKey', val)\n\n    for key, val in list(M2M_REGISTRY.items()):\n        app_name, model_name = key.split('.')\n        if app_name == sender_app and sender_name == model_name:\n            registry.register_model(app_name, sender, 'ManyToManyField', val)", "response": "This function is called when the class is prepared and is ready to be used to register the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, *args, **kwargs):\n        return self.model._default_manager.get(*args, **kwargs)", "response": "This is a quick hack to fix change_view and delete_view and get the object they should work\n        with."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef old_changelist_view(self, request, extra_context=None):\n        \"The 'change list' admin view for this model.\"\n        from django.contrib.admin.views.main import ERROR_FLAG\n        from django.core.exceptions import PermissionDenied\n        from django.utils.encoding import force_text\n        from django.utils.translation import ungettext\n        opts = self.model._meta\n        app_label = opts.app_label\n        if not self.has_change_permission(request, None):\n            raise PermissionDenied\n\n        # Check actions to see if any are available on this changelist\n        actions = self.get_actions(request)\n\n        # Remove action checkboxes if there aren't any actions available.\n        list_display = list(self.list_display)\n        if not actions:\n            try:\n                list_display.remove('action_checkbox')\n            except ValueError:\n                pass\n\n        try:\n            if django.VERSION[0] == 1 and django.VERSION[1] < 4:\n                params = (\n                    request, self.model, list_display,\n                    self.list_display_links, self.list_filter, self.date_hierarchy,\n                    self.search_fields, self.list_select_related,\n                    self.list_per_page, self.list_editable, self)\n            elif django.VERSION[0] == 1 or (django.VERSION[0] == 2 and django.VERSION[1] < 1):\n                params = (\n                    request, self.model, list_display,\n                    self.list_display_links, self.list_filter, self.date_hierarchy,\n                    self.search_fields, self.list_select_related,\n                    self.list_per_page, self.list_max_show_all,\n                    self.list_editable, self)\n            else:\n                params = (\n                    request, self.model, list_display,\n                    self.list_display_links, self.list_filter, self.date_hierarchy,\n                    self.search_fields, self.list_select_related,\n                    self.list_per_page, self.list_max_show_all,\n                    self.list_editable, self, self.sortable_by)\n            cl = TreeChangeList(*params)\n        except IncorrectLookupParameters:\n            # Wacky lookup parameters were given, so redirect to the main\n            # changelist page, without parameters, and pass an 'invalid=1'\n            # parameter via the query string. If wacky parameters were given and\n            # the 'invalid=1' parameter was already in the query string, something\n            # is screwed up with the database, so display an error page.\n            if ERROR_FLAG in list(request.GET.keys()):\n                return render_to_response(\n                    'admin/invalid_setup.html', {'title': _('Database error')})\n            return HttpResponseRedirect(request.path + '?' + ERROR_FLAG + '=1')\n\n        # If the request was POSTed, this might be a bulk action or a bulk edit.\n        # Try to look up an action first, but if this isn't an action the POST\n        # will fall through to the bulk edit check, below.\n        if actions and request.method == 'POST':\n            response = self.response_action(request, queryset=cl.get_queryset())\n            if response:\n                return response\n\n        # If we're allowing changelist editing, we need to construct a formset\n        # for the changelist given all the fields to be edited. Then we'll\n        # use the formset to validate/process POSTed data.\n        formset = cl.formset = None\n\n        # Handle POSTed bulk-edit data.\n        if request.method == \"POST\" and self.list_editable:\n            FormSet = self.get_changelist_formset(request)\n            formset = cl.formset = FormSet(\n                request.POST, request.FILES, queryset=cl.result_list\n            )\n            if formset.is_valid():\n                changecount = 0\n                for form in formset.forms:\n                    if form.has_changed():\n                        obj = self.save_form(request, form, change=True)\n                        self.save_model(request, obj, form, change=True)\n                        form.save_m2m()\n                        change_msg = self.construct_change_message(request, form, None)\n                        self.log_change(request, obj, change_msg)\n                        changecount += 1\n\n                if changecount:\n                    if changecount == 1:\n                        name = force_text(opts.verbose_name)\n                    else:\n                        name = force_text(opts.verbose_name_plural)\n                    msg = ungettext(\n                        \"%(count)s %(name)s was changed successfully.\",\n                        \"%(count)s %(name)s were changed successfully.\",\n                        changecount) % {'count': changecount,\n                                        'name': name,\n                                        'obj': force_text(obj)}\n                    self.message_user(request, msg)\n\n                return HttpResponseRedirect(request.get_full_path())\n\n        # Handle GET -- construct a formset for display.\n        elif self.list_editable:\n            FormSet = self.get_changelist_formset(request)\n            formset = cl.formset = FormSet(queryset=cl.result_list)\n\n        # Build the list of media to be used by the formset.\n        if formset:\n            media = self.media + formset.media\n        else:\n            media = self.media\n\n        # Build the action form and populate it with available actions.\n        if actions:\n            action_form = self.action_form(auto_id=None)\n            action_form.fields['action'].choices = self.get_action_choices(request)\n        else:\n            action_form = None\n\n        context = {\n            'title': cl.title,\n            'is_popup': cl.is_popup,\n            'cl': cl,\n            'media': media,\n            'has_add_permission': self.has_add_permission(request),\n            'app_label': app_label,\n            'action_form': action_form,\n            'actions_on_top': self.actions_on_top,\n            'actions_on_bottom': self.actions_on_bottom,\n        }\n        if django.VERSION[0] == 1 and django.VERSION[1] < 4:\n            context['root_path'] = self.admin_site.root_path\n        elif django.VERSION[0] == 1 or (django.VERSION[0] == 2 and django.VERSION[1] < 1):\n            selection_note_all = ungettext('%(total_count)s selected', 'All %(total_count)s selected', cl.result_count)\n\n            context.update({\n                'module_name': force_text(opts.verbose_name_plural),\n                'selection_note': _('0 of %(cnt)s selected') % {'cnt': len(cl.result_list)},\n                'selection_note_all': selection_note_all % {'total_count': cl.result_count},\n            })\n        else:\n            context['opts'] = self.model._meta\n\n        context.update(extra_context or {})\n        return render_to_response(self.change_list_template or [\n            'admin/%s/%s/change_list.html' % (app_label, opts.object_name.lower()),\n            'admin/%s/change_list.html' % app_label,\n            'admin/change_list.html'\n        ], context=context)", "response": "The change list admin view for this model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the changelist view for the model instances", "response": "def changelist_view(self, request, extra_context=None, *args, **kwargs):\n        \"\"\"\n        Handle the changelist view, the django view for the model instances\n        change list/actions page.\n        \"\"\"\n        extra_context = extra_context or {}\n        extra_context['EDITOR_MEDIA_PATH'] = settings.MEDIA_PATH\n        extra_context['EDITOR_TREE_INITIAL_STATE'] = settings.TREE_INITIAL_STATE\n\n        # FIXME\n        return self.old_changelist_view(request, extra_context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_queryset(self, request):\n        qs = self.model._default_manager.get_queryset()\n        qs.__class__ = TreeEditorQuerySet\n        return qs", "response": "Returns a QuerySet of all model instances that can be edited by the TreeEditorAdmin site. This is used by changelist_view."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop the tables in the database.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Alter the tables\n        \"\"\"\n        from categories.migration import drop_field\n        if 'app_name' not in options or 'model_name' not in options or 'field_name' not in options:\n            raise CommandError(\"You must specify an Application name, a Model name and a Field name\")\n\n        drop_field(options['app_name'], options['model_name'], options['field_name'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deactivate(self, request, queryset):\n        selected_cats = self.model.objects.filter(\n            pk__in=[int(x) for x in request.POST.getlist('_selected_action')])\n\n        for item in selected_cats:\n            if item.active:\n                item.active = False\n                item.save()\n                item.children.all().update(active=False)", "response": "Deactivate items from selected items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the indentation of the string.", "response": "def get_indent(self, string):\n        \"\"\"\n        Look through the string and count the spaces\n        \"\"\"\n        indent_amt = 0\n\n        if string[0] == '\\t':\n            return '\\t'\n        for char in string:\n            if char == ' ':\n                indent_amt += 1\n            else:\n                return ' ' * indent_amt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking and save a category object from a string.", "response": "def make_category(self, string, parent=None, order=1):\n        \"\"\"\n        Make and save a category object from a string\n        \"\"\"\n        cat = Category(\n            name=string.strip(),\n            slug=slugify(SLUG_TRANSLITERATOR(string.strip()))[:49],\n            # arent=parent,\n            order=order\n        )\n        cat._tree_manager.insert_node(cat, parent, 'last-child', True)\n        cat.save()\n        if parent:\n            parent.rght = cat.rght + 1\n            parent.save()\n        return cat"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the lines of the log file.", "response": "def parse_lines(self, lines):\n        \"\"\"\n        Do the work of parsing each line\n        \"\"\"\n        indent = ''\n        level = 0\n\n        if lines[0][0] == ' ' or lines[0][0] == '\\t':\n            raise CommandError(\"The first line in the file cannot start with a space or tab.\")\n\n        # This keeps track of the current parents at a given level\n        current_parents = {0: None}\n\n        for line in lines:\n            if len(line) == 0:\n                continue\n            if line[0] == ' ' or line[0] == '\\t':\n                if indent == '':\n                    indent = self.get_indent(line)\n                elif not line[0] in indent:\n                    raise CommandError(\"You can't mix spaces and tabs for indents\")\n                level = line.count(indent)\n                current_parents[level] = self.make_category(line, parent=current_parents[level - 1])\n            else:\n                # We are back to a zero level, so reset the whole thing\n                current_parents = {0: self.make_category(line)}\n        current_parents[0]._tree_manager.rebuild()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the basic import", "response": "def handle(self, *file_paths, **options):\n        \"\"\"\n        Handle the basic import\n        \"\"\"\n        import os\n\n        for file_path in file_paths:\n            if not os.path.isfile(file_path):\n                print(\"File %s not found.\" % file_path)\n                continue\n            f = open(file_path, 'r')\n            data = f.readlines()\n            f.close()\n\n            self.parse_lines(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a label for the tree level of the given object.", "response": "def label_from_instance(self, obj):\n        \"\"\"\n        Creates labels which represent the tree level of each node when\n        generating option labels.\n        \"\"\"\n        return '%s %s' % (self.level_indicator * getattr(obj, obj._mptt_meta.level_attr), obj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a class from a string or class attery", "response": "def get_cat_model(model):\n    \"\"\"\n    Return a class from a string or class\n    \"\"\"\n    try:\n        if isinstance(model, string_types):\n            model_class = apps.get_model(*model.split(\".\"))\n        elif issubclass(model, CategoryBase):\n            model_class = model\n        if model_class is None:\n            raise TypeError\n    except TypeError:\n        raise TemplateSyntaxError(\"Unknown model submitted: %s\" % model)\n    return model_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_category(category_string, model=Category):\n    model_class = get_cat_model(model)\n    category = str(category_string).strip(\"'\\\"\")\n    category = category.strip('/')\n\n    cat_list = category.split('/')\n    if len(cat_list) == 0:\n        return None\n    try:\n        categories = model_class.objects.filter(name=cat_list[-1], level=len(cat_list) - 1)\n        if len(cat_list) == 1 and len(categories) > 1:\n            return None\n        # If there is only one, use it. If there is more than one, check\n        # if the parent matches the parent passed in the string\n        if len(categories) == 1:\n            return categories[0]\n        else:\n            for item in categories:\n                if item.parent.name == cat_list[-2]:\n                    return item\n    except model_class.DoesNotExist:\n        return None", "response": "Convert a string including a path and return the Category object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_category_drilldown(parser, token):\n    bits = token.split_contents()\n    error_str = '%(tagname)s tag should be in the format {%% %(tagname)s ' \\\n                '\"category name\" [using \"app.Model\"] as varname %%} or ' \\\n                '{%% %(tagname)s category_obj as varname %%}.'\n    if len(bits) == 4:\n        if bits[2] != 'as':\n            raise template.TemplateSyntaxError(error_str % {'tagname': bits[0]})\n        if bits[2] == 'as':\n            varname = bits[3].strip(\"'\\\"\")\n            model = \"categories.category\"\n    if len(bits) == 6:\n        if bits[2] not in ('using', 'as') or bits[4] not in ('using', 'as'):\n            raise template.TemplateSyntaxError(error_str % {'tagname': bits[0]})\n        if bits[2] == 'as':\n            varname = bits[3].strip(\"'\\\"\")\n            model = bits[5].strip(\"'\\\"\")\n        if bits[2] == 'using':\n            varname = bits[5].strip(\"'\\\"\")\n            model = bits[3].strip(\"'\\\"\")\n    category = FilterExpression(bits[1], parser)\n    return CategoryDrillDownNode(category, varname, model)", "response": "Returns the specified category drilldown."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders breadcrumbs using the categories. html template.", "response": "def breadcrumbs(category_string, separator=' > ', using='categories.category'):\n    \"\"\"\n    {% breadcrumbs category separator=\"::\" using=\"categories.category\" %}\n\n    Render breadcrumbs, using the ``categories/breadcrumbs.html`` template,\n    using the optional ``separator`` argument.\n    \"\"\"\n    cat = get_category(category_string, using)\n\n    return {'category': cat, 'separator': separator}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_drilldown_as_ul(category, using='categories.Category'):\n    cat = get_category(category, using)\n    if cat is None:\n        return {'category': cat, 'path': []}\n    else:\n        return {'category': cat, 'path': drilldown_tree_for_node(cat)}", "response": "Display the drilldown tree for a given category."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef display_path_as_ul(category, using='categories.Category'):\n    if isinstance(category, CategoryBase):\n        cat = category\n    else:\n        cat = get_category(category)\n\n    return {'category': cat, 'path': cat.get_ancestors() or []}", "response": "Render the category with ancestors but no children using the\n    template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an alphabetical list of all the categories that have no parents.", "response": "def get_top_level_categories(parser, token):\n    \"\"\"\n    Retrieves an alphabetical list of all the categories that have no parents.\n\n    Syntax::\n\n        {% get_top_level_categories [using \"app.Model\"] as categories %}\n\n    Returns an list of categories [<category>, <category>, <category, ...]\n    \"\"\"\n    bits = token.split_contents()\n    usage = 'Usage: {%% %s [using \"app.Model\"] as <variable> %%}' % bits[0]\n    if len(bits) == 3:\n        if bits[1] != 'as':\n            raise template.TemplateSyntaxError(usage)\n        varname = bits[2]\n        model = \"categories.category\"\n    elif len(bits) == 5:\n        if bits[1] not in ('as', 'using') and bits[3] not in ('as', 'using'):\n            raise template.TemplateSyntaxError(usage)\n        if bits[1] == 'using':\n            model = bits[2].strip(\"'\\\"\")\n            varname = bits[4].strip(\"'\\\"\")\n        else:\n            model = bits[4].strip(\"'\\\"\")\n            varname = bits[2].strip(\"'\\\"\")\n\n    return TopLevelCategoriesNode(varname, model)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tree_queryset(value):\n    from django.db.models.query import QuerySet\n    from copy import deepcopy\n    if not isinstance(value, QuerySet):\n        return value\n\n    qs = value\n    qs2 = deepcopy(qs)\n    # Reaching into the bowels of query sets to find out whether the qs is\n    # actually filtered and we need to do the INCLUDE_ANCESTORS dance at all.\n    # INCLUDE_ANCESTORS is quite expensive, so don't do it if not needed.\n    is_filtered = bool(qs.query.where.children)\n    if is_filtered:\n        include_pages = set()\n        # Order by 'rght' will return the tree deepest nodes first;\n        # this cuts down the number of queries considerably since all ancestors\n        # will already be in include_pages when they are checked, thus not\n        # trigger additional queries.\n        for p in qs2.order_by('rght').iterator():\n            if p.parent_id and p.parent_id not in include_pages and p.id not in include_pages:\n                ancestor_id_list = p.get_ancestors().values_list('id', flat=True)\n                include_pages.update(ancestor_id_list)\n\n        if include_pages:\n            qs = qs | qs.model._default_manager.filter(id__in=include_pages)\n\n        qs = qs.distinct()\n    return qs", "response": "Converts a normal queryset from an MPTT model to include all the ancestors\n    so a filtered subset of items can be formatted correctly"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the nodes in the tree, and renders the contained block for each node. This tag will recursively render children into the template variable {{ children }}. Only one database query is required (children are cached for the whole tree) Usage: <ul> {% recursetree nodes %} <li> {{ node.name }} {% if not node.is_leaf_node %} <ul> {{ children }} </ul> {% endif %} </li> {% endrecursetree %} </ul>", "response": "def recursetree(parser, token):\n    \"\"\"\n    Iterates over the nodes in the tree, and renders the contained block for each node.\n    This tag will recursively render children into the template variable {{ children }}.\n    Only one database query is required (children are cached for the whole tree)\n\n    Usage:\n            <ul>\n                {% recursetree nodes %}\n                    <li>\n                        {{ node.name }}\n                        {% if not node.is_leaf_node %}\n                            <ul>\n                                {{ children }}\n                            </ul>\n                        {% endif %}\n                    </li>\n                {% endrecursetree %}\n            </ul>\n    \"\"\"\n    bits = token.contents.split()\n    if len(bits) != 2:\n        raise template.TemplateSyntaxError('%s tag requires a queryset' % bits[0])\n    queryset_var = FilterExpression(bits[1], parser)\n\n    template_nodes = parser.parse(('endrecursetree',))\n    parser.delete_first_token()\n\n    return RecurseTreeNode(template_nodes, queryset_var)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gaussian_filter(data, sigma=4., truncate = 4., normalize=True, res_g=None):\n\n    if not len(data.shape) in [1, 2, 3]:\n        raise ValueError(\"dim = %s not supported\" % (len(data.shape)))\n\n    if np.isscalar(sigma):\n        sigma = [sigma] * data.ndim\n\n    if any(tuple(s <= 0 for s in sigma)):\n        raise ValueError(\"sigma = %s : all sigmas have to be positive!\" % str(sigma))\n\n    if isinstance(data, OCLArray):\n        return _gaussian_buf(data, sigma, res_g, normalize=normalize,truncate = truncate)\n    elif isinstance(data, np.ndarray):\n        return _gaussian_np(data, sigma,  normalize=normalize,truncate = truncate)\n\n    else:\n        raise TypeError(\"unknown type (%s)\" % (type(data)))", "response": "blurs data with a gaussian kernel of given sigmas"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _convolve_np(data, h):\n\n    data_g = OCLArray.from_array(np.require(data,np.float32,\"C\"))\n    h_g = OCLArray.from_array(np.require(h,np.float32,\"C\"))\n\n    return _convolve_buf(data_g, h_g).get()", "response": "convolves data and h into a numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convolve3_old(data, h, dev=None):\n\n    if dev is None:\n        dev = get_device()\n\n    if dev is None:\n        raise ValueError(\"no OpenCLDevice found...\")\n\n    dtype = data.dtype.type\n\n    dtypes_options = {np.float32: \"\",\n                      np.uint16: \"-D SHORTTYPE\"}\n\n    if not dtype in dtypes_options:\n        raise TypeError(\"data type %s not supported yet, please convert to:\" % dtype, list(dtypes_options.keys()))\n\n    prog = OCLProgram(abspath(\"kernels/convolve3.cl\"),\n                      build_options=dtypes_options[dtype])\n\n    hbuf = OCLArray.from_array(h.astype(np.float32))\n    img = OCLImage.from_array(data)\n    res = OCLArray.empty(data.shape, dtype=np.float32)\n\n    Ns = [np.int32(n) for n in data.shape + h.shape]\n\n    prog.run_kernel(\"convolve3d\", img.shape, None,\n                    img, hbuf.data, res.data,\n                    *Ns)\n\n    return res.get()", "response": "convolves 3d data with kernel h on the GPU Device dev\n    boundary conditions are clamping to edge"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the shape after scaling", "response": "def _scale_shape(dshape, scale = (1,1,1)):\n    \"\"\"returns the shape after scaling (should be the same as ndimage.zoom\"\"\"\n    nshape = np.round(np.array(dshape) * np.array(scale))\n    return tuple(nshape.astype(np.int))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scale(data, scale = (1.,1.,1.), interpolation = \"linear\"):\n\n\n    if not (isinstance(data, np.ndarray) and data.ndim == 3):\n        raise ValueError(\"input data has to be a 3d array!\")\n\n    interpolation_defines = {\"linear\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_LINEAR\"],\n                             \"nearest\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_NEAREST\"]}\n\n    if not interpolation in interpolation_defines:\n        raise KeyError(\n            \"interpolation = '%s' not defined ,valid: %s\" % (interpolation, list(interpolation_defines.keys())))\n\n\n    options_types = {np.uint8:[\"-D\",\"TYPENAME=uchar\",\"-D\",\"READ_IMAGE=read_imageui\"],\n                    np.uint16: [\"-D\",\"TYPENAME=short\",\"-D\", \"READ_IMAGE=read_imageui\"],\n                    np.float32: [\"-D\",\"TYPENAME=float\", \"-D\",\"READ_IMAGE=read_imagef\"],\n                    }\n\n    dtype = data.dtype.type\n\n    if not dtype in options_types:\n        raise ValueError(\"type %s not supported! Available: %s\"%(dtype ,str(list(options_types.keys()))))\n\n\n    if not isinstance(scale,(tuple, list, np.ndarray)):\n        scale = (scale,)*3\n\n    if len(scale) != 3:\n        raise ValueError(\"scale = %s misformed\"%scale)\n\n    d_im = OCLImage.from_array(data)\n\n    nshape = _scale_shape(data.shape,scale)\n\n    res_g = OCLArray.empty(nshape,dtype)\n\n\n    prog = OCLProgram(abspath(\"kernels/scale.cl\"),\n                      build_options=interpolation_defines[interpolation]+options_types[dtype ])\n\n\n    prog.run_kernel(\"scale\",\n                    res_g.shape[::-1],None,\n                    d_im,res_g.data)\n\n    return res_g.get()", "response": "Returns a scaled version of data in a new N - dimensional OCL image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abspath(myPath):\n    import sys, os\n    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n    try:\n        # PyInstaller creates a temp folder and stores path in _MEIPASS\n        base_path = sys._MEIPASS\n        return os.path.join(base_path, os.path.basename(myPath))\n    except Exception:\n        base_path = os.path.abspath(os.path.dirname(__file__))\n        return os.path.join(base_path, myPath)", "response": "Get absolute path to resource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perlin3(size, units=(1.,)*3, repeat=(10.,)*3, shift=0, scale=None, n_volumes=1):\n    if np.isscalar(shift):\n        shift = (shift,)*len(size)\n\n    if scale:\n        if np.isscalar(scale):\n            scale = (scale,)*3\n        repeat = scale\n        units = (1.,)*3\n\n    if n_volumes==1:\n        return _perlin3_single(size, units, repeat, shift=shift)\n    else:\n        Nx, Ny, Nz = size\n        Nz2 = Nz//n_volumes+1\n        res = np.empty((Nz, Ny, Nx), np.float32)\n        res_part = np.empty((Nz2, Ny, Nx), np.float32)\n        for i in range(n_volumes):\n            i1, i2 = i*Nz2, np.clip((i+1)*Nz2, 0, Nz)\n            if i<n_volumes-1:\n                res_part = _perlin3_single((Nx, Ny, i2-i1+1),\n                                           units,\n                                           shift=shift,\n                                           repeat=repeat,\n                                           offz=Nz2*i,\n                                           Nz0=Nz)\n\n                res[i1:i2, ...] = res_part[:-1, ...]\n            else:\n                res_part = _perlin3_single((Nx, Ny, i2-i1),\n                                           units,\n                                           shift=shift,\n                                           repeat=repeat,\n                                           offz=Nz2*i,\n                                           Nz0=Nz)\n\n                res[i1:i2, ...] = res_part\n        return res", "response": "perlin 3 - d noise array of given size and units"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nlm2(data,sigma, size_filter = 2, size_search = 3):\n\n    prog = OCLProgram(abspath(\"kernels/nlm2.cl\"),\n                      build_options=\"-D FS=%i -D BS=%i\"%(size_filter,size_search))\n\n    data = data.astype(np.float32)\n    img = OCLImage.from_array(data)\n\n    distImg = OCLImage.empty_like(data)\n\n    distImg = OCLImage.empty_like(data)\n    tmpImg = OCLImage.empty_like(data)\n    tmpImg2 = OCLImage.empty_like(data)\n\n    accBuf = OCLArray.zeros(data.shape,np.float32)    \n    weightBuf = OCLArray.zeros(data.shape,np.float32)\n\n    for dx in range(size_search+1):\n        for dy in range(-size_search,size_search+1):\n                prog.run_kernel(\"dist\",img.shape,None,\n                                img,tmpImg,np.int32(dx),np.int32(dy))\n                prog.run_kernel(\"convolve\",img.shape,None,\n                                tmpImg,tmpImg2,np.int32(1))\n                prog.run_kernel(\"convolve\",img.shape,None,\n                                tmpImg2,distImg,np.int32(2))\n\n                prog.run_kernel(\"computePlus\",img.shape,None,\n                                img,distImg,accBuf.data,weightBuf.data,\n                               np.int32(img.shape[0]),np.int32(img.shape[1]),\n                               np.int32(dx),np.int32(dy),np.float32(sigma))\n\n                if dx!=0:\n                #if any([dx,dy]):\n                    prog.run_kernel(\"computeMinus\",img.shape,None,\n                                    img,distImg,accBuf.data,weightBuf.data,\n                               np.int32(img.shape[0]),np.int32(img.shape[1]),\n                               np.int32(dx),np.int32(dy),np.float32(sigma))\n\n    accBuf /= weightBuf\n    return accBuf.get()", "response": "This function is used to run the NLM2 kernel on the data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_device(**kwargs):\n    new_device = OCLDevice(**kwargs)\n\n    # just change globals if new_device is different from old\n    if _ocl_globals.device.device != new_device.device:\n        _ocl_globals.device = new_device", "response": "init_device is a wrapper for OCLDevice."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing to sort devices", "response": "def device_priority(cls, device_with_type_tuple):\n        \"\"\"used to sort devices\n        device_with_type_tuple = (device, device_type)\n        \"\"\"\n        device, device_type = device_with_type_tuple\n        return (device_type is pyopencl.device_type.GPU,\n                device.get_info(pyopencl.device_info.GLOBAL_MEM_SIZE),\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fftshift(arr_obj, axes = None, res_g = None, return_buffer = False):\n\n    if axes is None:\n        axes = list(range(arr_obj.ndim))\n\n\n    if isinstance(arr_obj, OCLArray):\n        if not arr_obj.dtype.type in DTYPE_KERNEL_NAMES:\n            raise NotImplementedError(\"only works for float32 or complex64\")\n    elif isinstance(arr_obj, np.ndarray):\n        if np.iscomplexobj(arr_obj):\n            arr_obj = OCLArray.from_array(arr_obj.astype(np.complex64,copy = False))\n        else:\n            arr_obj = OCLArray.from_array(arr_obj.astype(np.float32,copy = False))\n    else:\n        raise ValueError(\"unknown type (%s)\"%(type(arr_obj)))\n\n    if not np.all([arr_obj.shape[a]%2==0 for a in axes]):\n        raise NotImplementedError(\"only works on axes of even dimensions\")\n\n    if res_g is None:\n        res_g = OCLArray.empty_like(arr_obj)\n\n\n    # iterate over all axes\n    # FIXME: this is still rather inefficient\n    in_g = arr_obj\n    for ax in axes:\n        _fftshift_single(in_g, res_g, ax)\n        in_g = res_g\n\n    if return_buffer:\n        return res_g\n    else:\n        return res_g.get()", "response": "fftshift for numpy arrays or OCLArrays"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fftshift_single(d_g, res_g, ax = 0):\n\n    dtype_kernel_name = {np.float32:\"fftshift_1_f\",\n                   np.complex64:\"fftshift_1_c\"\n                   }\n\n    N = d_g.shape[ax]\n    N1 = 1 if ax==0 else np.prod(d_g.shape[:ax])\n    N2 = 1 if ax == len(d_g.shape)-1 else np.prod(d_g.shape[ax+1:])\n\n    dtype = d_g.dtype.type\n\n    prog = OCLProgram(abspath(\"kernels/fftshift.cl\"))\n    prog.run_kernel(dtype_kernel_name[dtype],(N2,N//2,N1),None,\n                    d_g.data, res_g.data,\n                    np.int32(N),\n                    np.int32(N2))\n\n\n    return res_g", "response": "fftshift of a single array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convolve_sep2(data, hx, hy, res_g=None, sub_blocks=None):\n\n    if isinstance(data, np.ndarray):\n        data = np.ascontiguousarray(data)\n\n        if sub_blocks == (1, 1) or sub_blocks is None:\n            return _convolve_sep2_numpy(data, hx, hy)\n        else:\n            # cut the image into tile and operate on every of them\n            N_sub = [int(np.ceil(1. * n / s)) for n, s in zip(data.shape, sub_blocks)]\n            Npads = [int(len(_h) / 2) for _h in [hy, hx]]\n            res = np.empty(data.shape, np.float32)\n            for data_tile, data_s_src, data_s_dest \\\n                    in tile_iterator(data, blocksize=N_sub,\n                                     padsize=Npads,\n                                     mode=\"constant\"):\n                res_tile = _convolve_sep2_numpy(data_tile.copy(),\n                                                hx, hy)\n                res[data_s_src] = res_tile[data_s_dest]\n            return res\n    elif isinstance(data, OCLArray):\n        if not sub_blocks is None:\n            raise NotImplementedError()\n        return _convolve_sep2_gpu(data, hx, hy, res_g=res_g)\n    else:\n        raise TypeError(\"array argument (1) has bad type: %s\" % type(data))", "response": "convolves 2d data with kernel h = outer hx hy = outer hy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ssim(x, y, data_range=None, scaled = False, verbose = False):\n    if not x.shape == y.shape:\n        raise ValueError('Input images must have the same dimensions.')\n\n    K1 = 0.01\n    K2 = 0.03\n    sigma = 1.5\n    win_size = 7\n\n\n    if scaled:\n        x = x.astype(np.float32)\n        y = y.astype(np.float32)\n\n        # center it first for numerical stability...\n        my = np.mean(y)\n        mx = np.mean(x)\n        y = y - my\n        sxy = np.mean(x * y)  # mean(y)=0\n        sy = np.std(y)\n        a, b = sxy / (sy ** 2 + 1.e-30), mx\n        if verbose:\n            print(\"scaling in ssim: y2 = %.2g*y+%.2g\" % (a, b-my))\n        y = a * y + b\n\n        # my = np.mean(y)\n        # y = y - my\n        # sxy = np.mean(x * y)  # - np.mean(x) * np.mean(y)\n        # sy = np.std(y)\n        # sx = np.std(x)\n        # mx = np.mean(x)\n        # a, b = sx / sy, mx\n        # print(\"scaling in ssim: y2 = %.2g*y+%.2g\" % (a, b-my))\n        # y = a * y + b\n        #\n\n    if np.any((np.asarray(x.shape) - win_size) < 0):\n        raise ValueError(\"win_size exceeds image extent.\")\n\n    if data_range is None:\n        dmin, dmax = np.amin(x), np.amax(x)\n        data_range = dmax - dmin+1.e-10\n\n    x_g = OCLArray.from_array(x.astype(np.float32, copy=False))\n    y_g = OCLArray.from_array(y.astype(np.float32, copy=False))\n\n    ndim = x.ndim\n    NP = win_size ** ndim\n    cov_norm = 1. * NP / (NP - 1)  # sample covariance\n\n    filter_func = uniform_filter\n    filter_args = {'size': win_size}\n\n    ux = filter_func(x_g, **filter_args)\n    uy = filter_func(y_g, **filter_args)\n\n    # compute (weighted) variances and covariances\n    uxx = filter_func(x_g * x_g, **filter_args)\n    uyy = filter_func(y_g * y_g, **filter_args)\n    uxy = filter_func(x_g * y_g, **filter_args)\n    vx = cov_norm * (uxx - ux * ux)\n    vy = cov_norm * (uyy - uy * uy)\n    vxy = cov_norm * (uxy - ux * uy)\n\n\n    R = 1. * data_range\n    C1 = (K1 * R) ** 2\n    C2 = (K2 * R) ** 2\n\n    # save some gpu space by minimizing intermediate buffers\n\n    # A1 = 2. * ux * uy+C1\n    A1 = np.float32(2.) * ux\n    A1 *= uy\n    A1 += np.float32(C1)\n\n\n\n    # A2 =  2. * vxy + C2\n    # overwrite vxy to save space\n    A2 = vxy\n    A2 *= np.float32(2.)\n    A2 += np.float32(C2)\n\n\n    # B1 =  ux ** 2 + uy ** 2 + C1\n    # overwrite ux to save space\n    B1 = ux\n    B1 *= ux\n    uy *= uy\n    B1 += uy\n    B1 += np.float32(C1)\n\n    # B2 =  vx + vy + C2\n    # overwrite vx to save space\n    B2 = vx\n    B2 += vy\n    B2 += np.float32(C2)\n\n    D = B1\n    D *= B2\n    S = A1\n    S *= A2\n    S /= D\n\n\n    # import time\n    # time.sleep(2)\n    # return 1\n\n    # to avoid edge effects will ignore filter radius strip around edges\n    pad = (win_size - 1) // 2\n\n    ss = tuple(slice(pad, s - pad) for s in x.shape)\n    # compute (weighted) mean of ssim\n    mssim = S.get()[ss].mean()\n\n    return mssim", "response": "compute the ssim of the two images"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fft_convolve_gpu(data_g, h_g, res_g = None,\n                      plan = None, inplace = False,\n                      kernel_is_fft = False):\n    \"\"\" fft convolve for gpu buffer\n    \"\"\"\n\n\n\n\n    assert_bufs_type(np.complex64,data_g,h_g)\n\n    if data_g.shape != h_g.shape:\n        raise ValueError(\"data and kernel must have same size! %s vs %s \"%(str(data_g.shape),str(h_g.shape)))\n\n\n    if plan is None:\n        plan = fft_plan(data_g.shape)\n\n    if inplace:\n        res_g = data_g\n    else:\n        if res_g is None:\n            res_g = OCLArray.empty(data_g.shape,data_g.dtype)\n            \n        res_g.copy_buffer(data_g)\n        \n    if not kernel_is_fft:\n        kern_g = OCLArray.empty(h_g.shape,h_g.dtype)\n        kern_g.copy_buffer(h_g)\n        fft(kern_g,inplace=True, plan = plan)\n    else:\n        kern_g = h_g\n\n\n    fft(res_g,inplace=True, plan = plan)\n\n    #multiply in fourier domain\n    _complex_multiply_kernel(res_g,kern_g)\n\n    fft(res_g,inplace = True, inverse = True, plan = plan)\n\n    return res_g", "response": "convolves a gpu buffer with a kernel"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convolve_spatial2(im, hs,\n                      mode = \"constant\",\n                      grid_dim = None,\n                      pad_factor = 2,\n                      plan = None,\n                      return_plan = False):\n    \"\"\"\n    spatial varying convolution of an 2d image with a 2d grid of psfs\n\n    shape(im_ = (Ny,Nx)\n    shape(hs) = (Gy,Gx, Hy,Hx)\n\n    the input image im is subdivided into (Gy,Gx) blocks\n    hs[j,i] is the psf at the center of each block (i,j)\n\n    as of now each image dimension has to be divisible by the grid dim, i.e.\n    Nx % Gx == 0\n    Ny % Gy == 0\n\n\n    mode can be:\n    \"constant\" - assumed values to be zero\n    \"wrap\" - periodic boundary condition\n    \"\"\"\n\n    if grid_dim:\n        Gs = tuple(grid_dim)\n    else:\n        Gs = hs.shape[:2]\n\n\n    mode_str = {\"constant\":\"CLK_ADDRESS_CLAMP\",\n                \"wrap\":\"CLK_ADDRESS_REPEAT\"}\n\n    Ny, Nx = im.shape\n    Gy, Gx = Gs\n\n\n    # the size of each block within the grid\n    Nblock_y, Nblock_x = Ny // Gy, Nx // Gx\n\n\n    # the size of the overlapping patches with safety padding\n    Npatch_x, Npatch_y = _next_power_of_2(pad_factor*Nblock_x), _next_power_of_2(pad_factor*Nblock_y)\n\n\n    prog = OCLProgram(abspath(\"kernels/conv_spatial2.cl\"),\n                      build_options=[\"-D\",\"ADDRESSMODE=%s\"%mode_str[mode]])\n\n    if plan is None:\n        plan = fft_plan((Gy, Gx, Npatch_y,Npatch_x), axes = (-2,-1))\n\n    x0s = Nblock_x*np.arange(Gx)\n    y0s = Nblock_y*np.arange(Gy)\n\n\n    patches_g = OCLArray.empty((Gy,Gx,Npatch_y,Npatch_x),np.complex64)\n\n    #prepare psfs\n    if grid_dim:\n        h_g = OCLArray.zeros((Gy,Gx,Npatch_y,Npatch_x),np.complex64)\n        tmp_g = OCLArray.from_array(hs.astype(np.float32, copy = False))\n        for i,_x0 in enumerate(x0s):\n            for j,_y0 in enumerate(y0s):\n                prog.run_kernel(\"fill_psf_grid2\",\n                                (Nblock_x,Nblock_y),None,\n                        tmp_g.data,\n                        np.int32(Nx),\n                        np.int32(i*Nblock_x),\n                        np.int32(j*Nblock_y),\n                        h_g.data,\n                        np.int32(Npatch_x),\n                        np.int32(Npatch_y),\n                        np.int32(-Nblock_x//2+Npatch_x//2),\n                        np.int32(-Nblock_y//2+Npatch_y//2),\n                        np.int32(i*Npatch_x*Npatch_y+j*Gx*Npatch_x*Npatch_y)\n                            )\n    else:\n        hs = np.fft.fftshift(pad_to_shape(hs,(Gy,Gx,Npatch_y,Npatch_x)),axes=(2,3))\n        h_g = OCLArray.from_array(hs.astype(np.complex64))\n\n\n    #prepare image\n    im_g = OCLImage.from_array(im.astype(np.float32,copy=False))\n\n    for i,_x0 in enumerate(x0s):\n        for j,_y0 in enumerate(y0s):\n            prog.run_kernel(\"fill_patch2\",(Npatch_x,Npatch_y),None,\n                    im_g,\n                    np.int32(_x0+Nblock_x//2-Npatch_x//2),\n                    np.int32(_y0+Nblock_y//2-Npatch_y//2),\n                    patches_g.data,\n                    np.int32(i*Npatch_x*Npatch_y+j*Gx*Npatch_x*Npatch_y))\n\n\n    #return np.abs(patches_g.get())\n    # convolution\n    fft(patches_g,inplace=True,  plan = plan)\n    fft(h_g,inplace=True,  plan = plan)\n    prog.run_kernel(\"mult_inplace\",(Npatch_x*Npatch_y*Gx*Gy,),None,\n                    patches_g.data, h_g.data)\n    fft(patches_g,inplace=True, inverse = True, plan = plan)\n\n\n    logger.debug(\"Nblock_x: {}, Npatch_x: {}\".format(Nblock_x, Npatch_x))\n    #return np.abs(patches_g.get())\n    #accumulate\n    res_g = OCLArray.empty(im.shape,np.float32)\n\n    for j in range(Gy+1):\n        for i in range(Gx+1):\n            prog.run_kernel(\"interpolate2\",(Nblock_x,Nblock_y),None,\n                            patches_g.data,res_g.data,\n                            np.int32(i),np.int32(j),\n                            np.int32(Gx),np.int32(Gy),\n                            np.int32(Npatch_x),np.int32(Npatch_y))\n\n    res = res_g.get()\n\n    if return_plan:\n        return res, plan\n    else:\n        return res", "response": "convolve an image with a 2d grid of psfs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _tv2(data,weight,Niter=50):\n\n    if dev is None:\n        dev = imgtools.__DEFAULT_OPENCL_DEVICE__\n\n    if dev is None:\n        raise ValueError(\"no OpenCLDevice found...\")\n\n\n    proc = OCLProcessor(dev,utils.absPath(\"kernels/tv_chambolle.cl\"))\n\n    if Ncut ==1:\n        inImg = dev.createImage(data.shape[::-1],dtype = np.float32)\n\n        pImgs = [ dev.createImage(data.shape[::-1],\n                                  mem_flags = cl.mem_flags.READ_WRITE,\n                                  dtype= np.float32,\n                                  channel_order = cl.channel_order.RGBA)\n                                  for i in range(2)]\n\n        outImg = dev.createImage(data.shape[::-1],\n                                 dtype = np.float32,\n                                 mem_flags = cl.mem_flags.READ_WRITE)\n\n\n        dev.writeImage(inImg,data.astype(np.float32));\n        dev.writeImage(pImgs[0],np.zeros((4,)+data.shape,dtype=np.float32));\n        dev.writeImage(pImgs[1],np.zeros((4,)+data.shape,dtype=np.float32));\n\n\n        for i in range(Niter):\n            proc.runKernel(\"div_step\",inImg.shape,None,\n                           inImg,pImgs[i%2],outImg)\n            proc.runKernel(\"grad_step\",inImg.shape,None,\n                           outImg,pImgs[i%2],pImgs[1-i%2],\n                           np.float32(weight))\n        return dev.readImage(outImg,dtype=np.float32)\n\n    else:\n        res = np.empty_like(data,dtype=np.float32)\n        Nz,Ny,Nx = data.shape\n        # a heuristic guess: Npad = Niter means perfect\n        Npad = 1+Niter/2\n        for i0,(i,j,k) in enumerate(product(list(range(Ncut)),repeat=3)):\n            logger.info(\"calculating box  %i/%i\"%(i0+1,Ncut**3))\n            sx = slice(i*Nx/Ncut,(i+1)*Nx/Ncut)\n            sy = slice(j*Ny/Ncut,(j+1)*Ny/Ncut)\n            sz = slice(k*Nz/Ncut,(k+1)*Nz/Ncut)\n            sx1,sx2 = utils._extended_slice(sx,Nx,Npad)\n            sy1,sy2 = utils._extended_slice(sy,Ny,Npad)\n            sz1,sz2 = utils._extended_slice(sz,Nz,Npad)\n\n            data_sliced = data[sz1,sy1,sx1].copy()\n            _res = tv3_gpu(dev,data_sliced,weight,Niter,Ncut = 1)\n            res[sz,sy,sx] = _res[sz2,sy2,sx2]\n\n        return res", "response": "tv2 implementation of the tv2 algorithm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tv2(data,weight,Niter=50):\n\n    prog = OCLProgram(abspath(\"kernels/tv2.cl\"))\n\n    data_im = OCLImage.from_array(data.astype(np,float32,copy=False))\n\n    pImgs = [ dev.createImage(data.shape[::-1],\n                                  mem_flags = cl.mem_flags.READ_WRITE,\n                                  dtype= np.float32,\n                                  channel_order = cl.channel_order.RGBA)\n                                  for i in range(2)]\n\n    outImg = dev.createImage(data.shape[::-1],\n                             dtype = np.float32,\n                             mem_flags = cl.mem_flags.READ_WRITE)\n\n\n    dev.writeImage(inImg,data.astype(np.float32));\n    dev.writeImage(pImgs[0],np.zeros((4,)+data.shape,dtype=np.float32));\n    dev.writeImage(pImgs[1],np.zeros((4,)+data.shape,dtype=np.float32));\n\n\n    for i in range(Niter):\n        proc.runKernel(\"div_step\",inImg.shape,None,\n                           inImg,pImgs[i%2],outImg)\n        proc.runKernel(\"grad_step\",inImg.shape,None,\n                           outImg,pImgs[i%2],pImgs[1-i%2],\n                           np.float32(weight))\n    return dev.readImage(outImg,dtype=np.float32)", "response": "This function is used to generate tv regularized denoising and tv2 images."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef affine(data, mat=np.identity(4), mode=\"constant\", interpolation=\"linear\"):\n    warnings.warn(\n        \"gputools.transform.affine: API change as of gputools>= 0.2.8: the inverse of the matrix is now used as in scipy.ndimage.affine_transform\")\n\n    if not (isinstance(data, np.ndarray) and data.ndim == 3):\n        raise ValueError(\"input data has to be a 3d array!\")\n\n    interpolation_defines = {\"linear\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_LINEAR\"],\n                             \"nearest\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_NEAREST\"]}\n\n    mode_defines = {\"constant\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP\"],\n                    \"wrap\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_REPEAT\"],\n                    \"edge\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP_TO_EDGE\"]\n                    }\n\n    if not interpolation in interpolation_defines:\n        raise KeyError(\n            \"interpolation = '%s' not defined ,valid: %s\" % (interpolation, list(interpolation_defines.keys())))\n\n    if not mode in mode_defines:\n        raise KeyError(\"mode = '%s' not defined ,valid: %s\" % (mode, list(mode_defines.keys())))\n\n    # reorder matrix, such that x,y,z -> z,y,x (as the kernel is assuming that)\n\n    d_im = OCLImage.from_array(data.astype(np.float32, copy=False))\n    res_g = OCLArray.empty(data.shape, np.float32)\n    mat_inv_g = OCLArray.from_array(mat.astype(np.float32, copy=False))\n\n    prog = OCLProgram(abspath(\"kernels/affine.cl\")\n                      , build_options=interpolation_defines[interpolation] +\n                                      mode_defines[mode])\n\n    prog.run_kernel(\"affine3\",\n                    data.shape[::-1], None,\n                    d_im, res_g.data, mat_inv_g.data)\n\n    return res_g.get()", "response": "affine transform data with matrix mat"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shift(data, shift=(0, 0, 0), mode=\"constant\", interpolation=\"linear\"):\n    if np.isscalar(shift):\n        shift = (shift,) * 3\n\n    if len(shift) != 3:\n        raise ValueError(\"shift (%s) should be of length 3!\")\n\n    shift = -np.array(shift)\n    return affine(data, mat4_translate(*shift), mode=mode, interpolation=interpolation)", "response": "Translate 3d data by given amount."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrotate a 3d array around a given axis by a given angle.", "response": "def rotate(data, axis=(1., 0, 0), angle=0., center=None, mode=\"constant\", interpolation=\"linear\"):\n    \"\"\"\n    rotates data around axis by a given angle\n\n    Parameters\n    ----------\n    data: ndarray\n        3d array\n    axis: tuple\n        axis to rotate by angle about\n        axis = (x,y,z)\n    angle: float\n    center: tuple or None\n        origin of rotation (cz,cy,cx) in pixels\n        if None, center is the middle of data\n    \n    mode: string \n        boundary mode, one of the following:        \n        'constant'\n            pads with zeros \n        'edge'\n            pads with edge values\n        'wrap'\n            pads with the repeated version of the input \n    interpolation, string\n        interpolation mode, one of the following      \n        'linear'\n        'nearest'\n        \n    Returns\n    -------\n    res: ndarray\n        rotated array (same shape as input)\n\n    \"\"\"\n    if center is None:\n        center = tuple([s // 2 for s in data.shape])\n\n    cx, cy, cz = center\n    m = np.dot(mat4_translate(cx, cy, cz),\n               np.dot(mat4_rotate(angle, *axis),\n                      mat4_translate(-cx, -cy, -cz)))\n    m = np.linalg.inv(m)\n    return affine(data, m, mode=mode, interpolation=interpolation)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_coordinates(data, coordinates, interpolation=\"linear\",\n                    mode='constant'):\n    \"\"\"\n    Map data to new coordinates by interpolation.\n    The array of coordinates is used to find, for each point in the output,\n    the corresponding coordinates in the input.\n\n    should correspond to scipy.ndimage.map_coordinates\n    \n    Parameters\n    ----------\n    data\n    coordinates\n    output\n    interpolation\n    mode\n    cval\n    prefilter\n\n    Returns\n    -------\n    \"\"\"\n    if not (isinstance(data, np.ndarray) and data.ndim in (2, 3)):\n        raise ValueError(\"input data has to be a 2d or 3d array!\")\n\n    coordinates = np.asarray(coordinates, np.int32)\n    if not (coordinates.shape[0] == data.ndim):\n        raise ValueError(\"coordinate has to be of shape (data.ndim,m) \")\n\n    interpolation_defines = {\"linear\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_LINEAR\"],\n                             \"nearest\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_NEAREST\"]}\n\n    mode_defines = {\"constant\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP\"],\n                    \"wrap\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_REPEAT\"],\n                    \"edge\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP_TO_EDGE\"]\n                    }\n\n    if not interpolation in interpolation_defines:\n        raise KeyError(\n            \"interpolation = '%s' not defined ,valid: %s\" % (interpolation, list(interpolation_defines.keys())))\n\n    if not mode in mode_defines:\n        raise KeyError(\"mode = '%s' not defined ,valid: %s\" % (mode, list(mode_defines.keys())))\n\n    if not data.dtype.type in cl_buffer_datatype_dict:\n        raise KeyError(\"dtype %s not supported yet (%s)\" % (data.dtype.type, tuple(cl_buffer_datatype_dict.keys())))\n\n    dtype_defines = [\"-D\", \"DTYPE=%s\" % cl_buffer_datatype_dict[data.dtype.type]]\n\n    d_im = OCLImage.from_array(data)\n    coordinates_g = OCLArray.from_array(coordinates.astype(np.float32, copy=False))\n    res_g = OCLArray.empty(coordinates.shape[1], data.dtype)\n\n    prog = OCLProgram(abspath(\"kernels/map_coordinates.cl\")\n                      , build_options=interpolation_defines[interpolation] +\n                                      mode_defines[mode] + dtype_defines)\n\n    kernel = \"map_coordinates{ndim}\".format(ndim=data.ndim)\n\n    prog.run_kernel(kernel,\n                    (coordinates.shape[-1],), None,\n                    d_im, res_g.data, coordinates_g.data)\n\n    return res_g.get()", "response": "Maps data to new coordinates by interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef geometric_transform(data, mapping = \"c0,c1\", output_shape=None,\n                        mode='constant', interpolation=\"linear\"):\n    \"\"\"\n    Apply an arbitrary geometric transform.\n    The given mapping function is used to find, for each point in the\n    output, the corresponding coordinates in the input. The value of the\n    input at those coordinates is determined by spline interpolation of\n    the requested order.\n    Parameters\n    ----------\n    %(input)s\n    mapping : {callable, scipy.LowLevelCallable}\n        A callable object that accepts a tuple of length equal to the output\n        array rank, and returns the corresponding input coordinates as a tuple\n        of length equal to the input array rank.\n    \"\"\"\n\n    if not (isinstance(data, np.ndarray) and data.ndim in (2, 3)):\n        raise ValueError(\"input data has to be a 2d or 3d array!\")\n\n    interpolation_defines = {\"linear\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_LINEAR\"],\n                             \"nearest\": [\"-D\", \"SAMPLER_FILTER=CLK_FILTER_NEAREST\"]}\n\n    mode_defines = {\"constant\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP\"],\n                    \"wrap\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_REPEAT\"],\n                    \"edge\": [\"-D\", \"SAMPLER_ADDRESS=CLK_ADDRESS_CLAMP_TO_EDGE\"]\n                    }\n\n    if not interpolation in interpolation_defines:\n        raise KeyError(\n            \"interpolation = '%s' not defined ,valid: %s\" % (interpolation, list(interpolation_defines.keys())))\n\n    if not mode in mode_defines:\n        raise KeyError(\"mode = '%s' not defined ,valid: %s\" % (mode, list(mode_defines.keys())))\n\n    if not data.dtype.type in cl_buffer_datatype_dict:\n        raise KeyError(\"dtype %s not supported yet (%s)\" % (data.dtype.type, tuple(cl_buffer_datatype_dict.keys())))\n\n    dtype_defines = [\"-D\", \"DTYPE={type}\".format(type=cl_buffer_datatype_dict[data.dtype.type])]\n\n    image_functions = {np.float32:\"read_imagef\",\n                       np.uint8: \"read_imageui\",\n                       np.uint16: \"read_imageui\",\n                       np.int32: \"read_imagei\"}\n\n    image_read_defines = [\"-D\",\"READ_IMAGE=%s\"%image_functions[data.dtype.type]]\n\n    with open(abspath(\"kernels/geometric_transform.cl\"), \"r\") as f:\n        tpl = Template(f.read())\n\n    output_shape = tuple(output_shape)\n\n    mappings = {\"FUNC2\": \"c1,c0\",\n                \"FUNC3\": \"c2,c1,c0\"}\n\n    mappings[\"FUNC%d\" % data.ndim] = \",\".join(reversed(mapping.split(\",\")))\n\n    rendered = tpl.render(**mappings)\n\n    d_im = OCLImage.from_array(data)\n    res_g = OCLArray.empty(output_shape, data.dtype)\n\n    prog = OCLProgram(src_str=rendered,\n                      build_options=interpolation_defines[interpolation] +\n                                    mode_defines[mode] + dtype_defines+image_read_defines)\n\n    kernel = \"geometric_transform{ndim}\".format(ndim=data.ndim)\n\n    prog.run_kernel(kernel,\n                    output_shape[::-1], None,\n                    d_im, res_g.data)\n\n    return res_g.get()", "response": "Apply an arbitrary geometric transform to the base class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convolve_spatial2(im, hs,\n                      mode = \"constant\",\n                      plan = None,\n                      return_plan = False):\n    \"\"\"\n    spatial varying convolution of an 2d image with a 2d grid of psfs\n\n    shape(im_ = (Ny,Nx)\n    shape(hs) = (Gy,Gx, Hy,Hx)\n\n    the input image im is subdivided into (Gy,Gz) blocks\n    hs[j,i] is the psf at the center of each block (i,j)\n\n    as of now each image dimension has to be divisble by the grid dim, i.e.\n    Nx % Gx == 0\n    Ny % Gy == 0\n\n    mode can be:\n    \"constant\" - assumed values to be zero\n    \"wrap\" - periodic boundary condition\n    \"\"\"\n\n    if im.ndim !=2 or hs.ndim !=4:\n        raise ValueError(\"wrong dimensions of input!\")\n\n    if not np.all([n%g==0 for n,g in zip(im.shape,hs.shape[:2])]):\n        raise NotImplementedError(\"shape of image has to be divisible by Gx Gy  = %s shape mismatch\"%(str(hs.shape[:2])))\n\n\n    mode_str = {\"constant\":\"CLK_ADDRESS_CLAMP\",\n                \"wrap\":\"CLK_ADDRESS_REPEAT\"}\n\n    Ny, Nx = im.shape\n    Gy, Gx = hs.shape[:2]\n\n\n    # the size of each block within the grid\n    Nblock_y, Nblock_x = Ny/Gy, Nx/Gx\n\n\n    # the size of the overlapping patches with safety padding\n    Npatch_x, Npatch_y = _next_power_of_2(3*Nblock_x), _next_power_of_2(3*Nblock_y)\n    #Npatch_x, Npatch_y = _next_power_of_2(2*Nblock_x), _next_power_of_2(2*Nblock_y)\n\n    print(Nblock_x, Npatch_x)\n\n    hs = np.fft.fftshift(pad_to_shape(hs,(Gy,Gx,Npatch_y,Npatch_x)),axes=(2,3))\n\n\n    prog = OCLProgram(abspath(\"kernels/conv_spatial.cl\"),\n                      build_options=[\"-D\",\"ADDRESSMODE=%s\"%mode_str[mode]])\n\n    if plan is None:\n        plan = fft_plan((Npatch_y,Npatch_x))\n\n\n    patches_g = OCLArray.empty((Gy,Gx,Npatch_y,Npatch_x),np.complex64)\n\n    h_g = OCLArray.from_array(hs.astype(np.complex64))\n\n    im_g = OCLImage.from_array(im.astype(np.float32,copy=False))\n\n    x0s = Nblock_x*np.arange(Gx)\n    y0s = Nblock_y*np.arange(Gy)\n\n    print(x0s)\n\n    for i,_x0 in enumerate(x0s):\n        for j,_y0 in enumerate(y0s):\n            prog.run_kernel(\"fill_patch2\",(Npatch_x,Npatch_y),None,\n                    im_g,\n                    np.int32(_x0+Nblock_x/2-Npatch_x/2),\n                    np.int32(_y0+Nblock_y/2-Npatch_y/2),\n                    patches_g.data,\n                    np.int32(i*Npatch_x*Npatch_y+j*Gx*Npatch_x*Npatch_y))\n\n    # convolution\n    fft(patches_g,inplace=True, batch = Gx*Gy, plan = plan)\n    fft(h_g,inplace=True, batch = Gx*Gy, plan = plan)\n    prog.run_kernel(\"mult_inplace\",(Npatch_x*Npatch_y*Gx*Gy,),None,\n                    patches_g.data, h_g.data)\n\n    fft(patches_g,inplace=True, inverse = True, batch = Gx*Gy, plan = plan)\n\n    #return patches_g.get()\n\n    #accumulate\n    res_g = OCLArray.empty(im.shape,np.float32)\n\n    for i in range(Gx+1):\n        for j in range(Gy+1):\n            prog.run_kernel(\"interpolate2\",(Nblock_x,Nblock_y),None,\n                            patches_g.data,res_g.data,\n                            np.int32(i),np.int32(j),\n                            np.int32(Gx),np.int32(Gy),\n                            np.int32(Npatch_x),np.int32(Npatch_y))\n\n\n    res = res_g.get()\n\n    if return_plan:\n        return res, plan\n    else:\n        return res", "response": "convolve a 2d image with a 2d grid of psfs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts axes to absolute", "response": "def _convert_axes_to_absolute(dshape, axes):\n    \"\"\"axes = (-2,-1) does not work in reikna, so we have to convetr that\"\"\"\n\n    if axes is None:\n        return None\n    elif isinstance(axes, (tuple, list)):\n        return tuple(np.arange(len(dshape))[list(axes)])\n    else:\n        raise NotImplementedError(\"axes %s is of unsupported type %s \"%(str(axes), type(axes)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fft_plan(shape, dtype=np.complex64, axes=None, fast_math=True):\n    # if not axes is None and any([a<0 for a in axes]):\n    #     raise NotImplementedError(\"indices of axes have to be non negative, but are: %s\"%str(axes))\n\n    axes = _convert_axes_to_absolute(shape, axes)\n\n    mock_buffer = MockBuffer(dtype, shape)\n\n    fft_plan = FFT(mock_buffer, axes=axes).compile(cluda.ocl_api().Thread(get_device().queue),\n                                                   fast_math=fast_math)\n\n    return fft_plan", "response": "returns an FFT obj of shape dshape\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wrap_OCLArray(cls):\n\n    def prepare(arr):\n        return np.require(arr, None, \"C\")\n\n    @classmethod\n    def from_array(cls, arr, *args, **kwargs):\n        queue = get_device().queue\n        return cl_array.to_device(queue, prepare(arr), *args, **kwargs)\n\n    @classmethod\n    def empty(cls, shape, dtype=np.float32):\n        queue = get_device().queue\n        return cl_array.empty(queue, shape, dtype)\n\n    @classmethod\n    def empty_like(cls, arr):\n        return cls.empty(arr.shape, arr.dtype)\n\n    @classmethod\n    def zeros(cls, shape, dtype=np.float32):\n        queue = get_device().queue\n        return cl_array.zeros(queue, shape, dtype)\n\n    @classmethod\n    def zeros_like(cls, arr):\n        queue = get_device().queue\n        return cl_array.zeros_like(queue, arr)\n\n    def copy_buffer(self, buf, **kwargs):\n        queue = get_device().queue\n        return cl.enqueue_copy(queue, self.data, buf.data,\n                               **kwargs)\n\n    def write_array(self, data, **kwargs):\n        queue = get_device().queue\n        return cl.enqueue_copy(queue, self.data, prepare(data),\n                                       **kwargs)\n\n    def copy_image(self, img, **kwargs):\n        queue = get_device().queue\n        return cl.enqueue_copy(queue, self.data, img, offset=0,\n                               origin=(0,)*len(img.shape), region=img.shape,\n                               **kwargs)\n\n    def copy_image_resampled(self, img, **kwargs):\n        # if not self.dtype == img.dtype:\n        #     raise NotImplementedError(\"images have different dtype!\")\n\n\n        if self.dtype.type == np.float32:\n            type_str = \"float\"\n        elif self.dtype.type == np.complex64:\n            type_str = \"complex\"\n        else:\n            raise NotImplementedError(\"only resampling of float32 and complex64 arrays possible \")\n\n        kern_str = \"img%dd_to_buf_%s\" % (len(img.shape), type_str)\n\n        OCLArray._resample_prog.run_kernel(kern_str,\n                                           self.shape[::-1], None,\n                                           img, self.data)\n\n    def wrap_module_func(mod, f):\n        def func(self, *args, **kwargs):\n            return getattr(mod, f)(self, *args, **kwargs)\n\n        return func\n\n    cls.from_array = from_array\n    cls.empty = empty\n    cls.empty_like = empty_like\n    cls.zeros = zeros\n    cls.zeros_like = zeros_like\n\n    cls.copy_buffer = copy_buffer\n    cls.copy_image = copy_image\n    cls.copy_image_resampled = copy_image_resampled\n    cls.write_array = write_array\n\n    cls._resample_prog = OCLProgram(abspath(\"kernels/copy_resampled.cl\"))\n\n    for f in [\"sum\", \"max\", \"min\", \"dot\", \"vdot\"]:\n        setattr(cls, f, wrap_module_func(cl_array, f))\n\n    for f in dir(cl_math):\n        if isinstance(getattr(cl_math, f), collections.Callable):\n            setattr(cls, f, wrap_module_func(cl_math, f))\n\n    # cls.sum = sum\n    cls.__name__ = str(\"OCLArray\")\n    return cls", "response": "A wrapper for the OCLArray class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pad_to_shape(d, dshape, mode = \"constant\"):\n    if d.shape == dshape:\n        return d\n\n    diff = np.array(dshape)- np.array(d.shape)\n    #first shrink\n    slices  = tuple(slice(-x//2,x//2) if x<0 else slice(None,None) for x in diff)\n    res = d[slices]\n    #then pad\n    # return np.pad(res,[(n/2,n-n/2) if n>0 else (0,0) for n in diff],mode=mode)\n    return np.pad(res,[(int(np.ceil(d/2.)),d-int(np.ceil(d/2.))) if d>0 else (0,0) for d in diff],mode=mode)", "response": "pad array d to shape dshape"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pad_to_power2(data, axis = None, mode=\"constant\"):\n    if axis is None:\n        axis = list(range(data.ndim))\n\n    if np.all([_is_power2(n) for i, n in enumerate(data.shape) if i in axis]):\n        return data\n    else:\n        return pad_to_shape(data,[(_next_power_of_2(n) if i in axis else n) for i,n in enumerate(data.shape)], mode)", "response": "pad data to a shape of power 2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a minimum filter of given size", "response": "def min_filter(data, size=7, res_g=None, sub_blocks=(1, 1, 1)):\n    \"\"\"\n        minimum filter of given size\n\n    Parameters\n    ----------\n    data: 2 or 3 dimensional ndarray or OCLArray of type float32\n        input data\n    size: scalar, tuple\n        the size of the patch to consider\n    res_g: OCLArray\n        store result in buffer if given\n    sub_blocks:\n        perform over subblock tiling (only if data is ndarray)\n\n    Returns\n    -------\n        filtered image or None (if OCLArray)\n    \"\"\"\n    if data.ndim == 2:\n        _filt = make_filter(_generic_filter_gpu_2d(FUNC=\"(val<res?val:res)\", DEFAULT=\"INFINITY\"))\n    elif data.ndim == 3:\n        _filt = make_filter(_generic_filter_gpu_3d(FUNC=\"(val<res?val:res)\", DEFAULT=\"INFINITY\"))\n    else:\n        raise ValueError(\"currently only 2 or 3 dimensional data is supported\")\n    return _filt(data=data, size=size, res_g=res_g, sub_blocks=sub_blocks)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmeaning filter of given size Parameters ---------- data: 2 or 3 dimensional ndarray or OCLArray of type float32 input data size: scalar, tuple the size of the patch to consider res_g: OCLArray store result in buffer if given sub_blocks: perform over subblock tiling (only if data is ndarray) normalized: bool if True, the filter corresponds to mean if False, the filter corresponds to sum Returns ------- filtered image or None (if OCLArray)", "response": "def uniform_filter(data, size=7, res_g=None, sub_blocks=(1, 1, 1), normalized = True):\n    \"\"\"\n        mean filter of given size\n\n    Parameters\n    ----------\n    data: 2 or 3 dimensional ndarray or OCLArray of type float32\n        input data\n    size: scalar, tuple\n        the size of the patch to consider\n    res_g: OCLArray\n        store result in buffer if given\n    sub_blocks:\n        perform over subblock tiling (only if data is ndarray)\n    normalized: bool\n        if True, the filter corresponds to mean\n        if False, the filter corresponds to sum\n\n    Returns\n    -------\n        filtered image or None (if OCLArray)\n    \"\"\"\n\n    if normalized:\n        if np.isscalar(size):\n            norm = size\n        else:\n            norm = np.int32(np.prod(size))**(1./len(size))\n        FUNC = \"res+val/%s\"%norm\n    else:\n        FUNC = \"res+val\"\n\n    if data.ndim == 2:\n        _filt = make_filter(_generic_filter_gpu_2d(FUNC=FUNC, DEFAULT=\"0\"))\n    elif data.ndim == 3:\n        _filt = make_filter(_generic_filter_gpu_3d(FUNC=FUNC, DEFAULT=\"0\"))\n\n    res =  _filt(data=data, size=size, res_g=res_g, sub_blocks=sub_blocks)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gauss_filter(data, sigma=4, res_g=None, sub_blocks=(1, 1, 1)):\n    truncate = 4.\n    radius = tuple(int(truncate*s +0.5) for s in sigma)\n    size = tuple(2*r+1 for r in radius)\n\n    s = sigma[0]\n\n    if data.ndim == 2:\n        _filt = make_filter(_generic_filter_gpu_2d(FUNC=\"res+(val*native_exp((float)(-(ht-%s)*(ht-%s)/2/%s/%s)))\"%(size[0]//2,size[0]//2,s,s), DEFAULT=\"0.f\"))\n    elif data.ndim == 3:\n        _filt = make_filter(_generic_filter_gpu_3d(FUNC=\"res+(val*native_exp((float)(-(ht-%s)*(ht-%s)/2/%s/%s)))\"%(size[0]//2,size[0]//2,s,s), DEFAULT=\"0.f\"))\n\n    else:\n        raise ValueError(\"currently only 2 or 3 dimensional data is supported\")\n    return _filt(data=data, size=size, res_g=res_g, sub_blocks=sub_blocks)", "response": "Gaussian filter of given size"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deconv_rl(data, h, Niter=10, mode_conv=\"fft\", log_iter=False):\n\n    if isinstance(data, np.ndarray):\n        mode_data = \"np\"\n    elif isinstance(data, OCLArray):\n        mode_data = \"gpu\"\n    else:\n        raise TypeError(\"array argument (1) has bad type: %s\"%type(arr_obj))\n\n    if mode_conv==\"fft\":\n        res = _deconv_rl_np_fft(data, h, Niter) if mode_data==\"np\" else _deconv_rl_gpu_fft(data, h, Niter)\n        return res\n    elif mode_conv==\"spatial\":\n        res = _deconv_rl_np_conv(data, h, Niter) if mode_data==\"np\" else gpu_conv(data, h, Niter)\n        return res\n    else:\n        raise KeyError(\"mode_conv = %s not known, either 'fft' or 'spatial'\"%mode_conv)", "response": "Richardson lucy deconvolution of data with psf h using spatial convolutions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _deconv_rl_gpu_conv(data_g, h_g, Niter=10):\n\n    # set up some gpu buffers\n    u_g = OCLArray.empty(data_g.shape, np.float32)\n\n    u_g.copy_buffer(data_g)\n\n    tmp_g = OCLArray.empty(data_g.shape, np.float32)\n    tmp2_g = OCLArray.empty(data_g.shape, np.float32)\n\n\n    # fix this\n    hflip_g = OCLArray.from_array((h_g.get()[::-1, ::-1]).copy())\n\n\n\n    for i in range(Niter):\n        convolve(u_g, h_g,\n                 res_g=tmp_g)\n\n        _divide_inplace(data_g, tmp_g)\n\n        # return data_g, tmp_g\n\n        convolve(tmp_g, hflip_g,\n                 res_g=tmp2_g)\n\n\n\n        _multiply_inplace(u_g, tmp2_g)\n\n    return u_g", "response": "This function deconvolves the gpu data using convolve"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _deconv_rl_np_fft(data, h, Niter=10,\n                      h_is_fftshifted=False):\n    \"\"\" deconvolves data with given psf (kernel) h\n\n    data and h have to be same shape\n\n\n    via lucy richardson deconvolution\n    \"\"\"\n\n    if data.shape!=h.shape:\n        raise ValueError(\"data and h have to be same shape\")\n\n    if not h_is_fftshifted:\n        h = np.fft.fftshift(h)\n\n    hflip = h[::-1, ::-1]\n\n    # set up some gpu buffers\n    y_g = OCLArray.from_array(data.astype(np.complex64))\n    u_g = OCLArray.from_array(data.astype(np.complex64))\n\n    tmp_g = OCLArray.empty(data.shape, np.complex64)\n\n    hf_g = OCLArray.from_array(h.astype(np.complex64))\n    hflip_f_g = OCLArray.from_array(hflip.astype(np.complex64))\n\n    # hflipped_g = OCLArray.from_array(h.astype(np.complex64))\n\n    plan = fft_plan(data.shape)\n\n    # transform psf\n    fft(hf_g, inplace=True)\n    fft(hflip_f_g, inplace=True)\n\n    for i in range(Niter):\n        logger.info(\"Iteration: {}\".format(i))\n        fft_convolve(u_g, hf_g,\n                     res_g=tmp_g,\n                     kernel_is_fft=True)\n\n        _complex_divide_inplace(y_g, tmp_g)\n\n        fft_convolve(tmp_g, hflip_f_g,\n                     inplace=True,\n                     kernel_is_fft=True)\n\n        _complex_multiply_inplace(u_g, tmp_g)\n\n    return np.abs(u_g.get())", "response": "deconvolves data with given psf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _deconv_rl_gpu_fft(data_g, h_g, Niter=10):\n\n    if data_g.shape!=h_g.shape:\n        raise ValueError(\"data and h have to be same shape\")\n\n    # set up some gpu buffers\n    u_g = OCLArray.empty(data_g.shape, np.complex64)\n\n    u_g.copy_buffer(data_g)\n\n    tmp_g = OCLArray.empty(data_g.shape, np.complex64)\n\n    # fix this\n    hflip_g = OCLArray.from_array((h_g.get()[::-1, ::-1]).copy())\n\n    plan = fft_plan(data_g.shape)\n\n    # transform psf\n    fft(h_g, inplace=True)\n    fft(hflip_g, inplace=True)\n\n    for i in range(Niter):\n        logger.info(\"Iteration: {}\".format(i))\n        fft_convolve(u_g, h_g,\n                     res_g=tmp_g,\n                     kernel_is_fft=True)\n\n        _complex_divide_inplace(data_g, tmp_g)\n\n        fft_convolve(tmp_g, hflip_g,\n                     inplace=True,\n                     kernel_is_fft=True)\n\n        _complex_multiply_inplace(u_g, tmp_g)\n\n    return u_g", "response": "deconvolves the GPU data using the FFT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding separable approximations to the 2d function 2d h returns hx hy", "response": "def _separable_series2(h, N=1):\n    \"\"\" finds separable approximations to the 2d function 2d h\n\n    returns res = (hx, hy)[N]\n    s.t. h \\approx sum_i outer(res[i,0],res[i,1])\n    \"\"\"\n    if min(h.shape)<N:\n        raise ValueError(\"smallest dimension of h is smaller than approximation order! (%s < %s)\"%(min(h.shape),N))\n\n    U, S, V = linalg.svd(h)\n\n    hx = [-U[:, n] * np.sqrt(S[n]) for n in range(N)]\n    hy = [-V[n, :] * np.sqrt(S[n]) for n in range(N)]\n    return np.array(list(zip(hx, hy)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _separable_approx2(h, N=1):\n    return np.cumsum([np.outer(fy, fx) for fy, fx in _separable_series2(h, N)], 0)", "response": "returns the N first approximations to the 2d function h\n    whose sum should be h"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind separable approximations to the 3d kernel h returns h x hy z", "response": "def _separable_series3(h, N=1, verbose=False):\n    \"\"\" finds separable approximations to the 3d kernel h\n    returns res = (hx,hy,hz)[N]\n    s.t. h \\approx sum_i einsum(\"i,j,k\",res[i,0],res[i,1],res[i,2])\n\n    FIXME: This is just a naive and slow first try!\n    \"\"\"\n\n    hx, hy, hz = [], [], []\n    res = h.copy()\n    for i in range(N):\n        _hx, _hy, _hz, P = _splitrank3(res, verbose=verbose)\n        res -= P\n        hx.append(_hx)\n        hy.append(_hy)\n        hz.append(_hz)\n    return np.array(list(zip(hx, hy, hz)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _separable_approx3(h, N=1):\n    return np.cumsum([np.einsum(\"i,j,k\", fz, fy, fx) for fz, fy, fx in _separable_series3(h, N)], 0)", "response": "returns the N first approximations to the 3d function h\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a series of N rank 1 tensors that approximates the sum of the tensors h and returns the first N rank 1 tensors that approximates the sum of the tensors h", "response": "def separable_series(h, N=1):\n    \"\"\"\n    finds the first N rank 1 tensors such that their sum approximates\n    the tensor h (2d or 3d) best\n\n    returns (e.g. for 3d case) res = (hx,hy,hz)[i]\n\n    s.t.\n\n    h \\approx sum_i einsum(\"i,j,k\",res[i,0],res[i,1],res[i,2])\n\n    Parameters\n    ----------\n    h: ndarray\n        input array (2 or 2 dimensional)\n    N: int\n        order of approximation\n\n    Returns\n    -------\n        res, the series of tensors\n         res[i] = (hx,hy,hz)[i]\n\n    \"\"\"\n    if h.ndim == 2:\n        return _separable_series2(h, N)\n    elif h.ndim == 3:\n        return _separable_series3(h, N)\n    else:\n        raise ValueError(\"unsupported array dimension: %s (only 2d or 3d) \" % h.ndim)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef separable_approx(h, N=1):\n    if h.ndim == 2:\n        return _separable_approx2(h, N)\n    elif h.ndim == 3:\n        return _separable_approx3(h, N)\n    else:\n        raise ValueError(\"unsupported array dimension: %s (only 2d or 3d) \" % h.ndim)", "response": "Returns the k - th rank approximation to h where k = 1.. N"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a minutes offset into a pytz timezone", "response": "def offset_to_timezone(offset, now=None):\n    \"\"\"Convert a minutes offset (JavaScript-style) into a pytz timezone\n\n    The ``now`` parameter is generally used for testing only\n    \"\"\"\n    now = now or datetime.now()\n\n    # JS offsets are flipped, so unflip.\n    user_offset = -offset\n\n    # Helper: timezone offset in minutes\n    def get_tz_offset(tz):\n        try:\n            return tz.utcoffset(now).total_seconds() / 60\n        except (pytz.NonExistentTimeError, pytz.AmbiguousTimeError):\n            return tz.localize(now, is_dst=False).utcoffset().total_seconds() / 60\n\n    # Return the timezone with the minimum difference to the user's offset.\n    return min(\n        (pytz.timezone(tz_name) for tz_name in get_prioritized_timezones()),\n        key=lambda tz: abs(get_tz_offset(tz) - user_offset),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands pattern into an equivalent one but with single Either.", "response": "def transform(pattern):\n    \"\"\"Expand pattern into an (almost) equivalent one, but with single Either.\n\n    Example: ((-a | -b) (-c | -d)) => (-a -c | -a -d | -b -c | -b -d)\n    Quirks: [-a] => (-a), (-a...) => (-a -a)\n\n    \"\"\"\n    result = []\n    groups = [[pattern]]\n    while groups:\n        children = groups.pop(0)\n        parents = [Required, Optional, OptionsShortcut, Either, OneOrMore]\n        if any(t in map(type, children) for t in parents):\n            child = [c for c in children if type(c) in parents][0]\n            children.remove(child)\n            if type(child) is Either:\n                for c in child.children:\n                    groups.append([c] + children)\n            elif type(child) is OneOrMore:\n                groups.append(child.children * 2 + children)\n            else:\n                groups.append(child.children + children)\n        else:\n            result.append(children)\n    return Either(*[Required(*e) for e in result])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_long(tokens, options):\n    long, eq, value = tokens.move().partition('=')\n    assert long.startswith('--')\n    value = None if eq == value == '' else value\n    similar = [o for o in options if o.long == long]\n    if tokens.error is DocoptExit and similar == []:  # if no exact match\n        similar = [o for o in options if o.long and o.long.startswith(long)]\n    if len(similar) > 1:  # might be simply specified ambiguously 2+ times?\n        raise tokens.error('%s is not a unique prefix: %s?' %\n                           (long, ', '.join(o.long for o in similar)))\n    elif len(similar) < 1:\n        argcount = 1 if eq == '=' else 0\n        o = Option(None, long, argcount)\n        options.append(o)\n        if tokens.error is DocoptExit:\n            o = Option(None, long, argcount, value if argcount else True)\n    else:\n        o = Option(similar[0].short, similar[0].long,\n                   similar[0].argcount, similar[0].value)\n        if o.argcount == 0:\n            if value is not None:\n                raise tokens.error('%s must not have an argument' % o.long)\n        else:\n            if value is None:\n                if tokens.current() in [None, '--']:\n                    raise tokens.error('%s requires argument' % o.long)\n                value = tokens.move()\n        if tokens.error is DocoptExit:\n            o.value = value if value is not None else True\n    return [o]", "response": "Parse the long option."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a list of shorts from the tokens.", "response": "def parse_shorts(tokens, options):\n    \"\"\"shorts ::= '-' ( chars )* [ [ ' ' ] chars ] ;\"\"\"\n    token = tokens.move()\n    assert token.startswith('-') and not token.startswith('--')\n    left = token.lstrip('-')\n    parsed = []\n    while left != '':\n        short, left = '-' + left[0], left[1:]\n        similar = [o for o in options if o.short == short]\n        if len(similar) > 1:\n            raise tokens.error('%s is specified ambiguously %d times' %\n                               (short, len(similar)))\n        elif len(similar) < 1:\n            o = Option(short, None, 0)\n            options.append(o)\n            if tokens.error is DocoptExit:\n                o = Option(short, None, 0, True)\n        else:  # why copying is necessary here?\n            o = Option(short, similar[0].long,\n                       similar[0].argcount, similar[0].value)\n            value = None\n            if o.argcount != 0:\n                if left == '':\n                    if tokens.current() in [None, '--']:\n                        raise tokens.error('%s requires argument' % short)\n                    value = tokens.move()\n                else:\n                    value = left\n                    left = ''\n            if tokens.error is DocoptExit:\n                o.value = value if value is not None else True\n        parsed.append(o)\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the command - line interface described in doc and return a dictionary containing the parsed command - line arguments.", "response": "def docopt(doc, argv=None, help=True, version=None, options_first=False):\n    \"\"\"Parse `argv` based on command-line interface described in `doc`.\n\n    `docopt` creates your command-line interface based on its\n    description that you pass as `doc`. Such description can contain\n    --options, <positional-argument>, commands, which could be\n    [optional], (required), (mutually | exclusive) or repeated...\n\n    Parameters\n    ----------\n    doc : str\n        Description of your command-line interface.\n    argv : list of str, optional\n        Argument vector to be parsed. sys.argv[1:] is used if not\n        provided.\n    help : bool (default: True)\n        Set to False to disable automatic help on -h or --help\n        options.\n    version : any object\n        If passed, the object will be printed if --version is in\n        `argv`.\n    options_first : bool (default: False)\n        Set to True to require options precede positional arguments,\n        i.e. to forbid options and positional arguments intermix.\n\n    Returns\n    -------\n    args : dict\n        A dictionary, where keys are names of command-line elements\n        such as e.g. \"--verbose\" and \"<path>\", and values are the\n        parsed values of those elements.\n\n    Example\n    -------\n    >>> from docopt import docopt\n    >>> doc = '''\n    ... Usage:\n    ...     my_program tcp <host> <port> [--timeout=<seconds>]\n    ...     my_program serial <port> [--baud=<n>] [--timeout=<seconds>]\n    ...     my_program (-h | --help | --version)\n    ...\n    ... Options:\n    ...     -h, --help  Show this screen and exit.\n    ...     --baud=<n>  Baudrate [default: 9600]\n    ... '''\n    >>> argv = ['tcp', '127.0.0.1', '80', '--timeout', '30']\n    >>> docopt(doc, argv)\n    {'--baud': '9600',\n     '--help': False,\n     '--timeout': '30',\n     '--version': False,\n     '<host>': '127.0.0.1',\n     '<port>': '80',\n     'serial': False,\n     'tcp': True}\n\n    See also\n    --------\n    * For video introduction see http://docopt.org\n    * Full documentation is available in README.rst as well as online\n      at https://github.com/docopt/docopt#readme\n\n    \"\"\"\n    argv = sys.argv[1:] if argv is None else argv\n\n    usage_sections = parse_section('usage:', doc)\n    if len(usage_sections) == 0:\n        raise DocoptLanguageError('\"usage:\" (case-insensitive) not found.')\n    if len(usage_sections) > 1:\n        raise DocoptLanguageError('More than one \"usage:\" (case-insensitive).')\n    DocoptExit.usage = usage_sections[0]\n\n    options = parse_defaults(doc)\n    pattern = parse_pattern(formal_usage(DocoptExit.usage), options)\n    # [default] syntax for argument is disabled\n    #for a in pattern.flat(Argument):\n    #    same_name = [d for d in arguments if d.name == a.name]\n    #    if same_name:\n    #        a.value = same_name[0].value\n    argv = parse_argv(Tokens(argv), list(options), options_first)\n    pattern_options = set(pattern.flat(Option))\n    for options_shortcut in pattern.flat(OptionsShortcut):\n        doc_options = parse_defaults(doc)\n        options_shortcut.children = list(set(doc_options) - pattern_options)\n        #if any_options:\n        #    options_shortcut.children += [Option(o.short, o.long, o.argcount)\n        #                    for o in argv if type(o) is Option]\n    extras(help, version, argv, doc)\n    matched, left, collected = pattern.fix().match(argv)\n    if matched and left == []:  # better error message if left?\n        return Dict((a.name, a.value) for a in (pattern.flat() + collected))\n    raise DocoptExit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake pattern - tree tips point to same object if they are equal.", "response": "def fix_identities(self, uniq=None):\n        \"\"\"Make pattern-tree tips point to same object if they are equal.\"\"\"\n        if not hasattr(self, 'children'):\n            return self\n        uniq = list(set(self.flat())) if uniq is None else uniq\n        for i, child in enumerate(self.children):\n            if not hasattr(child, 'children'):\n                assert child in uniq\n                self.children[i] = uniq[uniq.index(child)]\n            else:\n                child.fix_identities(uniq)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_repeating_arguments(self):\n        either = [list(child.children) for child in transform(self).children]\n        for case in either:\n            for e in [child for child in case if case.count(child) > 1]:\n                if type(e) is Argument or type(e) is Option and e.argcount:\n                    if e.value is None:\n                        e.value = []\n                    elif type(e.value) is not list:\n                        e.value = e.value.split()\n                if type(e) is Command or type(e) is Option and e.argcount == 0:\n                    e.value = 0\n        return self", "response": "Fix elements that should accumulate or increment values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_version(fname):\n    version = \"\"\n    with open(fname, \"r\") as fp:\n        reg = re.compile(r'__version__ = [\\'\"]([^\\'\"]*)[\\'\"]')\n        for line in fp:\n            m = reg.match(line)\n            if m:\n                version = m.group(1)\n                break\n    if not version:\n        raise RuntimeError(\"Cannot find version information\")\n    return version", "response": "Attempts to find the version number in the file names fname. Raises RuntimeError if not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_context(\n    context: Context, formatter: typing.Union[str, Formatter] = \"full\"\n) -> str:\n    \"\"\"Output the a context dictionary as a string.\"\"\"\n    if not context:\n        return \"\"\n\n    if callable(formatter):\n        formatter_func = formatter\n    else:\n        if formatter in CONTEXT_FORMATTERS:\n            formatter_func = CONTEXT_FORMATTERS[formatter]\n        else:\n            raise ValueError(f'Invalid context format: \"{formatter}\"')\n    return formatter_func(context)", "response": "Output the a context dictionary as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_banner(\n    text: typing.Optional[str] = None,\n    context: typing.Optional[Context] = None,\n    banner_template: typing.Optional[str] = None,\n    context_format: ContextFormat = \"full\",\n) -> str:\n    \"\"\"Generates a full banner with version info, the given text, and a\n    formatted list of context variables.\n    \"\"\"\n    banner_text = text or speak()\n    banner_template = banner_template or BANNER_TEMPLATE\n    ctx = format_context(context or {}, formatter=context_format)\n    out = banner_template.format(version=sys.version, text=banner_text, context=ctx)\n    return out", "response": "Generates a full banner with version info the given text and a\n    formatted list of context variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef context_list2dict(context_list: typing.Sequence[typing.Any]) -> Context:\n    return {obj.__name__.split(\".\")[-1]: obj for obj in context_list}", "response": "Converts a list of objects to a dictionary mapping the object names to the objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(\n    context: typing.Optional[typing.Mapping] = None,\n    banner: typing.Optional[str] = None,\n    shell: typing.Type[Shell] = AutoShell,\n    prompt: typing.Optional[str] = None,\n    output: typing.Optional[str] = None,\n    context_format: str = \"full\",\n    **kwargs: typing.Any,\n) -> None:\n    \"\"\"Start up the konch shell. Takes the same parameters as Shell.__init__.\n    \"\"\"\n    logger.debug(f\"Using shell: {shell!r}\")\n    if banner is None:\n        banner = speak()\n    # Default to global config\n    context_ = context or _cfg[\"context\"]\n    banner_ = banner or _cfg[\"banner\"]\n    if isinstance(shell, type) and issubclass(shell, Shell):\n        shell_ = shell\n    else:\n        shell_ = SHELL_MAP.get(shell or _cfg[\"shell\"], _cfg[\"shell\"])\n    prompt_ = prompt or _cfg[\"prompt\"]\n    output_ = output or _cfg[\"output\"]\n    context_format_ = context_format or _cfg[\"context_format\"]\n    shell_(\n        context=context_,\n        banner=banner_,\n        prompt=prompt_,\n        output=output_,\n        context_format=context_format_,\n        **kwargs,\n    ).start()", "response": "Start the konch shell."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config(config_dict: typing.Mapping) -> Config:\n    logger.debug(f\"Updating with {config_dict}\")\n    _cfg.update(config_dict)\n    return _cfg", "response": "Configures the konch shell."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a named config to the config registry.", "response": "def named_config(name: str, config_dict: typing.Mapping) -> None:\n    \"\"\"Adds a named config to the config registry. The first argument\n    may either be a string or a collection of strings.\n\n    This function should be called in a .konchrc file.\n    \"\"\"\n    names = (\n        name\n        if isinstance(name, Iterable) and not isinstance(name, (str, bytes))\n        else [name]\n    )\n    for each in names:\n        _config_registry[each] = Config(**config_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __ensure_directory_in_path(filename: Path) -> None:\n    directory = Path(filename).parent.resolve()\n    if directory not in sys.path:\n        logger.debug(f\"Adding {directory} to sys.path\")\n        sys.path.insert(0, str(directory))", "response": "Ensures that a file s directory is in the Python path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying a confirmation prompt.", "response": "def confirm(text: str, default: bool = False) -> bool:\n    \"\"\"Display a confirmation prompt.\"\"\"\n    choices = \"Y/n\" if default else \"y/N\"\n    prompt = f\"{style(text, bold=True)} [{choices}]: \"\n    while 1:\n        try:\n            print(prompt, end=\"\")\n            value = input(\"\").lower().strip()\n        except (KeyboardInterrupt, EOFError):\n            sys.exit(1)\n        if value in (\"y\", \"yes\"):\n            rv = True\n        elif value in (\"n\", \"no\"):\n            rv = False\n        elif value == \"\":\n            rv = default\n        else:\n            print_error(\"Error: invalid input\")\n            continue\n        break\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads filename as a python file. Import filename and return it as a module.", "response": "def use_file(\n    filename: typing.Union[Path, str, None], trust: bool = False\n) -> typing.Union[types.ModuleType, None]:\n    \"\"\"Load filename as a python file. Import ``filename`` and return it\n    as a module.\n    \"\"\"\n    config_file = filename or resolve_path(CONFIG_FILE)\n\n    def preview_unauthorized() -> None:\n        if not config_file:\n            return None\n        print(SEPARATOR, file=sys.stderr)\n        with Path(config_file).open(\"r\", encoding=\"utf-8\") as fp:\n            for line in fp:\n                print(line, end=\"\", file=sys.stderr)\n        print(SEPARATOR, file=sys.stderr)\n\n    if config_file and not Path(config_file).exists():\n        print_error(f'\"{filename}\" not found.')\n        sys.exit(1)\n    if config_file and Path(config_file).exists():\n        if not trust:\n            with AuthFile.load() as authfile:\n                try:\n                    authfile.check(Path(config_file))\n                except KonchrcChangedError:\n                    print_error(f'\"{config_file}\" has changed since you last used it.')\n                    preview_unauthorized()\n                    if confirm(\"Would you like to authorize it?\"):\n                        authfile.allow(Path(config_file))\n                        print()\n                    else:\n                        sys.exit(1)\n                except KonchrcNotAuthorizedError:\n                    print_error(f'\"{config_file}\" is blocked.')\n                    preview_unauthorized()\n                    if confirm(\"Would you like to authorize it?\"):\n                        authfile.allow(Path(config_file))\n                        print()\n                    else:\n                        sys.exit(1)\n\n        logger.info(f\"Using {config_file}\")\n        # Ensure that relative imports are possible\n        __ensure_directory_in_path(Path(config_file))\n        mod = None\n        try:\n            mod = imp.load_source(\"konchrc\", str(config_file))\n        except UnboundLocalError:  # File not found\n            pass\n        else:\n            return mod\n    if not config_file:\n        print_warning(\"No konch config file found.\")\n    else:\n        print_warning(f'\"{config_file}\" not found.')\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a file by walking up parent directories until the file is found.", "response": "def resolve_path(filename: Path) -> typing.Union[Path, None]:\n    \"\"\"Find a file by walking up parent directories until the file is found.\n    Return the absolute path of the file.\n    \"\"\"\n    current = Path.cwd()\n    # Stop search at home directory\n    sentinel_dir = Path.home().parent.resolve()\n    while current != sentinel_dir:\n        target = Path(current) / Path(filename)\n        if target.exists():\n            return target.resolve()\n        else:\n            current = current.parent.resolve()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexposing the docopt command - line arguments parser. Return a dictionary of arguments and their values.", "response": "def parse_args(argv: typing.Optional[typing.Sequence] = None) -> typing.Dict[str, str]:\n    \"\"\"Exposes the docopt command-line arguments parser.\n    Return a dictionary of arguments.\n    \"\"\"\n    return docopt(__doc__, argv=argv, version=__version__)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_autoreload(mode: int) -> None:\n        from IPython.extensions import autoreload\n\n        ip = get_ipython()  # type: ignore # noqa: F821\n        autoreload.load_ipython_extension(ip)\n        ip.magics_manager.magics[\"line\"][\"autoreload\"](str(mode))", "response": "Load and initialize the IPython autoreload extension."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, text, element, context='eqn'):\n        \n        # Remove the inline comments from `text` before parsing the grammar\n        # http://docs.oasis-open.org/xmile/xmile/v1.0/csprd01/xmile-v1.0-csprd01.html#_Toc398039973\n        text = re.sub(r\"\\{[^}]*\\}\", \"\", text)\n        \n        self.ast = self.grammar.parse(text)\n        self.context = context\n        self.element = element\n        self.new_structure = []\n        \n        py_expr = self.visit(self.ast)\n        \n        return ({\n            'py_expr': py_expr\n        }, self.new_structure)", "response": "Parse the text and return a dictionary of the lone identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a vensim syntax model which has been formatted as a table.", "response": "def read_tabular(table_file, sheetname='Sheet1'):\n    \"\"\"\n    Reads a vensim syntax model which has been formatted as a table.\n\n    This is useful in contexts where model building is performed\n    without the aid of Vensim.\n\n    Parameters\n    ----------\n    table_file: .csv, .tab or .xls(x) file\n\n    Table should have columns titled as in the table below\n\n\n    | Variable | Equation | Units | Min | Max | Comment          |\n    | :------- | :------- | :---- | :-- | :-- | :--------------- |\n    | Age      | 5        | Yrs   | 0   | inf | How old are you? |\n    | ...      | ...      | ...   | ... | ... | ...              |\n\n    sheetname: basestring\n        if the model is specified in an excel file, what sheet?\n\n    Returns\n    -------\n    PySD Model Object\n\n    Notes\n    -----\n    Creates an intermediate file in vensim `.mdl` syntax, just so that\n    the existing vensim parsing machinery can be used.\n\n    \"\"\"\n\n    if isinstance(table_file, str):\n        extension = table_file.split('.')[-1]\n        if extension in ['xls', 'xlsx']:\n            table = pd.read_excel(table_file, sheetname=sheetname)\n        elif extension == 'csv':\n            table = pd.read_csv(table_file, encoding='UTF-8')\n        elif extension == 'tab':\n            table = pd.read_csv(table_file, sep='\\t', encoding='UTF-8')\n        else:\n            raise ValueError('Unknown file or table type')\n    else:\n        raise ValueError('Unknown file or table type')\n\n    if not set(table.columns).issuperset({'Variable', 'Equation'}):\n        raise ValueError('Table must contain at least columns \"Variable\" and \"Equation\"')\n\n    if \"Units\" not in set(table.columns):\n        warnings.warn('Column for \"Units\" not found', RuntimeWarning, stacklevel=2)\n        table['Units'] = ''\n\n    if \"Min\" not in set(table.columns):\n        warnings.warn('Column for \"Min\" not found', RuntimeWarning, stacklevel=2)\n        table['Min'] = ''\n\n    if \"Max\" not in set(table.columns):\n        warnings.warn('Column for \"Max\" not found', RuntimeWarning, stacklevel=2)\n        table['Max'] = ''\n\n    mdl_file = table_file.replace(extension, 'mdl')\n\n    with open(mdl_file, 'w', encoding='UTF-8') as outfile:\n        for element in table.to_dict(orient='records'):\n            outfile.write(\n                \"%(Variable)s = \\n\"\n                \"\\t %(Equation)s \\n\"\n                \"\\t~\\t %(Units)s [%(Min)s, %(Max)s] \\n\"\n                \"\\t~\\t %(Comment)s \\n\\t|\\n\\n\" % element\n            )\n\n        outfile.write(u'\\\\\\---/// Sketch information - this is where sketch stuff would go.')\n\n    return read_vensim(mdl_file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_xmile(xmile_file):\n    from . import py_backend\n    from .py_backend.xmile.xmile2py import translate_xmile\n    py_model_file = translate_xmile(xmile_file)\n    model = load(py_model_file)\n    model.xmile_file = xmile_file\n    return model", "response": "Construct a model object from a. xmile file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_vensim(mdl_file):\n\n    from .py_backend.vensim.vensim2py import translate_vensim\n    from .py_backend import functions\n    py_model_file = translate_vensim(mdl_file)\n    model = functions.Model(py_model_file)\n    model.mdl_file = mdl_file\n    return model", "response": "Read a Vensim model from a raw Vensim. mdl file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache(horizon):\n\n    def cache_step(func):\n        \"\"\" Decorator for caching at a step level\"\"\"\n\n        @wraps(func)\n        def cached(*args):\n            \"\"\"Step wise cache function\"\"\"\n            try:  # fails if cache is out of date or not instantiated\n                data = func.__globals__['__data']\n                assert cached.cache_t == data['time']()\n                assert hasattr(cached, 'cache_val')\n                assert cached.cache_val is not None\n            except (AssertionError, AttributeError):\n                cached.cache_val = func(*args)\n                data = func.__globals__['__data']\n                cached.cache_t = data['time']()\n            return cached.cache_val\n\n        return cached\n\n    def cache_run(func):\n        \"\"\" Decorator for caching at  the run level\"\"\"\n\n        @wraps(func)\n        def cached(*args):\n            \"\"\"Run wise cache function\"\"\"\n            try:  # fails if cache is not instantiated\n                return cached.cache_val\n            except AttributeError:\n                cached.cache_val = func(*args)\n                return cached.cache_val\n\n        return cached\n\n    if horizon == 'step':\n        return cache_step\n\n    elif horizon == 'run':\n        return cache_run\n\n    else:\n        raise (AttributeError('Bad horizon for cache decorator'))", "response": "Decorator for creating a new function that caches the current state of the current model at a specific horizon."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ramp(time, slope, start, finish=0):\n\n    t = time()\n    if t < start:\n        return 0\n    else:\n        if finish <= 0:\n            return slope * (t - start)\n        elif t > finish:\n            return slope * (finish - start)\n        else:\n            return slope * (t - start)", "response": "Returns the ramp of a vensim s venim s venim s ramp function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements vensim s PULSE function", "response": "def pulse(time, start, duration):\n    \"\"\" Implements vensim's PULSE function\n\n    In range [-inf, start) returns 0\n    In range [start, start + duration) returns 1\n    In range [start + duration, +inf] returns 0\n    \"\"\"\n    t = time()\n    return 1 if start <= t < start + duration else 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement vensim s PULSE TRAIN function", "response": "def pulse_train(time, start, duration, repeat_time, end):\n    \"\"\" Implements vensim's PULSE TRAIN function\n\n    In range [-inf, start) returns 0\n    In range [start + n * repeat_time, start + n * repeat_time + duration) return 1\n    In range [start + n * repeat_time + duration, start + (n+1) * repeat_time) return 0\n    \"\"\"\n    t = time()\n    if start <= t < end:\n        return 1 if (t - start) % repeat_time < duration else 0\n    else:\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement xmile's PULSE function PULSE: Generate a one-DT wide pulse at the given time Parameters: 2 or 3: (magnitude, first time[, interval]) Without interval or when interval = 0, the PULSE is generated only once Example: PULSE(20, 12, 5) generates a pulse value of 20/DT at time 12, 17, 22, etc. In rage [-inf, start) returns 0 In range [start + n * repeat_time, start + n * repeat_time + dt) return magnitude/dt In rage [start + n * repeat_time + dt, start + (n + 1) * repeat_time) return 0", "response": "def pulse_magnitude(time, magnitude, start, repeat_time=0):\n    \"\"\" Implements xmile's PULSE function\n    \n    PULSE:             Generate a one-DT wide pulse at the given time\n       Parameters:     2 or 3:  (magnitude, first time[, interval])\n                       Without interval or when interval = 0, the PULSE is generated only once\n       Example:        PULSE(20, 12, 5) generates a pulse value of 20/DT at time 12, 17, 22, etc.\n    \n    In rage [-inf, start) returns 0\n    In range [start + n * repeat_time, start + n * repeat_time + dt) return magnitude/dt\n    In rage [start + n * repeat_time + dt, start + (n + 1) * repeat_time) return 0\n    \"\"\"\n    t = time()\n    small = 1e-6  # What is considered zero according to Vensim Help\n    if repeat_time <= small:\n        if abs(t - start) < time.step():\n            return magnitude * time.step()\n        else:\n            return 0\n    else:\n        if abs((t - start) % repeat_time) < time.step():\n            return magnitude * time.step()\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nintermediate values are calculated with linear interpolation between the intermediate points. Out-of-range values are calculated with linear extrapolation from the last two values at either end.", "response": "def lookup_extrapolation(x, xs, ys):\n    \"\"\"\n    Intermediate values are calculated with linear interpolation between the intermediate points.\n    Out-of-range values are calculated with linear extrapolation from the last two values at either end.\n    \"\"\"\n    length = len(xs)\n    if x < xs[0]:\n        dx = xs[1] - xs[0]\n        dy = ys[1] - ys[0]\n        k = dy / dx\n        return ys[0] + (x - xs[0]) * k\n    if x > xs[length - 1]:\n        dx = xs[length - 1] - xs[length - 2]\n        dy = ys[length - 1] - ys[length - 2]\n        k = dy / dx\n        return ys[length - 1] + (x - xs[length - 1]) * k\n    return np.interp(x, xs, ys)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nintermediating values take on the value associated with the next lower x-coordinate (also called a step-wise function). The last two points of a discrete graphical function must have the same y value. Out-of-range values are the same as the closest endpoint (i.e, no extrapolation is performed).", "response": "def lookup_discrete(x, xs, ys):\n    \"\"\"\n    Intermediate values take on the value associated with the next lower x-coordinate (also called a step-wise function). The last two points of a discrete graphical function must have the same y value.\n    Out-of-range values are the same as the closest endpoint (i.e, no extrapolation is performed).\n    \"\"\"\n    for index in range(0, len(xs)):\n        if x < xs[index]:\n            return ys[index - 1] if index > 0 else ys[index]\n    return ys[len(ys) - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimplementing Vensim's XIDZ function. This function executes a division, robust to denominator being zero. In the case of zero denominator, the final argument is returned. Parameters ---------- numerator: float denominator: float Components of the division operation value_if_denom_is_zero: float The value to return if the denominator is zero Returns ------- numerator / denominator if denominator > 1e-6 otherwise, returns value_if_denom_is_zero", "response": "def xidz(numerator, denominator, value_if_denom_is_zero):\n    \"\"\"\n    Implements Vensim's XIDZ function.\n    This function executes a division, robust to denominator being zero.\n    In the case of zero denominator, the final argument is returned.\n\n    Parameters\n    ----------\n    numerator: float\n    denominator: float\n        Components of the division operation\n    value_if_denom_is_zero: float\n        The value to return if the denominator is zero\n\n    Returns\n    -------\n    numerator / denominator if denominator > 1e-6\n    otherwise, returns value_if_denom_is_zero\n    \"\"\"\n    small = 1e-6  # What is considered zero according to Vensim Help\n    if abs(denominator) < small:\n        return value_if_denom_is_zero\n    else:\n        return numerator * 1.0 / denominator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of exogenous model elements.", "response": "def set_components(self, params):\n        \"\"\" Set the value of exogenous model elements.\n        Element values can be passed as keyword=value pairs in the function call.\n        Values can be numeric type or pandas Series.\n        Series will be interpolated by integrator.\n\n        Examples\n        --------\n\n        >>> model.set_components({'birth_rate': 10})\n        >>> model.set_components({'Birth Rate': 10})\n\n        >>> br = pandas.Series(index=range(30), values=np.sin(range(30))\n        >>> model.set_components({'birth_rate': br})\n\n\n        \"\"\"\n        # It might make sense to allow the params argument to take a pandas series, where\n        # the indices of the series are variable names. This would make it easier to\n        # do a Pandas apply on a DataFrame of parameter values. However, this may conflict\n        # with a pandas series being passed in as a dictionary element.\n\n        for key, value in params.items():\n            if isinstance(value, pd.Series):\n                new_function = self._timeseries_component(value)\n            elif callable(value):\n                new_function = value\n            else:\n                new_function = self._constant_component(value)\n\n            func_name = utils.get_value_by_insensitive_key_or_value(key, self.components._namespace)\n\n            if func_name is None:\n                raise NameError('%s is not recognized as a model component' % key)\n\n            if '_integ_' + func_name in dir(self.components):  # this won't handle other statefuls...\n                warnings.warn(\"Replacing the equation of stock {} with params\".format(key),\n                              stacklevel=2)\n\n            setattr(self.components, func_name, new_function)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _timeseries_component(self, series):\n        # this is only called if the set_component function recognizes a pandas series\n        # Todo: raise a warning if extrapolating from the end of the series.\n        return lambda: np.interp(self.time(), series.index, series.values)", "response": "Internal function for creating a timeseries model element"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of the system.", "response": "def set_state(self, t, state):\n        \"\"\" Set the system state.\n\n        Parameters\n        ----------\n        t : numeric\n            The system time\n\n        state : dict\n            A (possibly partial) dictionary of the system state.\n            The keys to this dictionary may be either pysafe names or original model file names\n        \"\"\"\n        self.time.update(t)\n\n        for key, value in state.items():\n            # TODO Implement map with reference between component and stateful element?\n            component_name = utils.get_value_by_insensitive_key_or_value(key, self.components._namespace)\n            if component_name is not None:\n                stateful_name = '_integ_%s' % component_name\n            else:\n                component_name = key\n                stateful_name = key\n\n            # Try to update stateful component\n            if hasattr(self.components, stateful_name):\n                try:\n                    element = getattr(self.components, stateful_name)\n                    element.update(value)\n                except AttributeError:\n                    print(\"'%s' has no state elements, assignment failed\")\n                    raise\n            else:\n                # Try to override component\n                try:\n                    setattr(self.components, component_name, self._constant_component(value))\n                except AttributeError:\n                    print(\"'%s' has no component, assignment failed\")\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the Caches for all model elements.", "response": "def clear_caches(self):\n        \"\"\" Clears the Caches for all model elements \"\"\"\n        for element_name in dir(self.components):\n            element = getattr(self.components, element_name)\n            if hasattr(element, 'cache_val'):\n                delattr(element, 'cache_val')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doc(self):\n        collector = []\n        for name, varname in self.components._namespace.items():\n            try:\n                docstring = getattr(self.components, varname).__doc__\n                lines = docstring.split('\\n')\n                collector.append({'Real Name': name,\n                                  'Py Name': varname,\n                                  'Eqn': lines[2].replace(\"Original Eqn:\", \"\").strip(),\n                                  'Unit': lines[3].replace(\"Units:\", \"\").strip(),\n                                  'Lims': lines[4].replace(\"Limits:\", \"\").strip(),\n                                  'Type': lines[5].replace(\"Type:\", \"\").strip(),\n                                  'Comment': '\\n'.join(lines[7:]).strip()})\n            except:\n                pass\n\n        docs_df = _pd.DataFrame(collector)\n        docs_df.fillna('None', inplace=True)\n\n        order = ['Real Name', 'Py Name', 'Unit', 'Lims', 'Type', 'Eqn', 'Comment']\n        return docs_df[order].sort_values(by='Real Name').reset_index(drop=True)", "response": "Returns a pandas dataframe with the documentation strings for the model components and the variable names and their types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize(self):\n        self.time.update(self.components.initial_time())\n        self.time.stage = 'Initialization'\n        super(Model, self).initialize()", "response": "Initializes the simulation model"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the time series for the integration of the model.", "response": "def _build_euler_timeseries(self, return_timestamps=None):\n        \"\"\"\n        - The integration steps need to include the return values.\n        - There is no point running the model past the last return value.\n        - The last timestep will be the last in that requested for return\n        - Spacing should be at maximum what is specified by the integration time step.\n        - The initial time should be the one specified by the model file, OR\n          it should be the initial condition.\n        - This function needs to be called AFTER the model is set in its initial state\n        Parameters\n        ----------\n        return_timestamps: numpy array\n          Must be specified by user or built from model file before this function is called.\n\n        Returns\n        -------\n        ts: numpy array\n            The times that the integrator will use to compute time history\n        \"\"\"\n        t_0 = self.time()\n        t_f = return_timestamps[-1]\n        dt = self.components.time_step()\n        ts = np.arange(t_0, t_f, dt, dtype=np.float64)\n\n        # Add the returned time series into the integration array. Best we can do for now.\n        # This does change the integration ever so slightly, but for well-specified\n        # models there shouldn't be sensitivity to a finer integration time step.\n        ts = np.sort(np.unique(np.append(ts, return_timestamps)))\n        return ts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat the passed in return timestamps value as a numpy array.", "response": "def _format_return_timestamps(self, return_timestamps=None):\n        \"\"\"\n        Format the passed in return timestamps value as a numpy array.\n        If no value is passed, build up array of timestamps based upon\n        model start and end times, and the 'saveper' value.\n        \"\"\"\n        if return_timestamps is None:\n            # Build based upon model file Start, Stop times and Saveper\n            # Vensim's standard is to expect that the data set includes the `final time`,\n            # so we have to add an extra period to make sure we get that value in what\n            # numpy's `arange` gives us.\n            return_timestamps_array = np.arange(\n                self.components.initial_time(),\n                self.components.final_time() + self.components.saveper(),\n                self.components.saveper(), dtype=np.float64\n            )\n        elif inspect.isclass(range) and isinstance(return_timestamps, range):\n            return_timestamps_array = np.array(return_timestamps, ndmin=1)\n        elif isinstance(return_timestamps, (list, int, float, np.ndarray)):\n            return_timestamps_array = np.array(return_timestamps, ndmin=1)\n        elif isinstance(return_timestamps, _pd.Series):\n            return_timestamps_array = return_timestamps.as_matrix()\n        else:\n            raise TypeError('`return_timestamps` expects a list, array, pandas Series, '\n                            'or numeric value')\n        return return_timestamps_array"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates the model s behavior over time.", "response": "def run(self, params=None, return_columns=None, return_timestamps=None,\n            initial_condition='original', reload=False):\n        \"\"\" Simulate the model's behavior over time.\n        Return a pandas dataframe with timestamps as rows,\n        model elements as columns.\n\n        Parameters\n        ----------\n        params : dictionary\n            Keys are strings of model component names.\n            Values are numeric or pandas Series.\n            Numeric values represent constants over the model integration.\n            Timeseries will be interpolated to give time-varying input.\n\n        return_timestamps : list, numeric, numpy array(1-D)\n            Timestamps in model execution at which to return state information.\n            Defaults to model-file specified timesteps.\n\n        return_columns : list of string model component names\n            Returned dataframe will have corresponding columns.\n            Defaults to model stock values.\n\n        initial_condition : 'original'/'o', 'current'/'c', (t, {state})\n            The starting time, and the state of the system (the values of all the stocks)\n            at that starting time.\n\n            * 'original' (default) uses model-file specified initial condition\n            * 'current' uses the state of the model after the previous execution\n            * (t, {state}) lets the user specify a starting time and (possibly partial)\n              list of stock values.\n\n        reload : bool\n            If true, reloads the model from the translated model file before making changes\n\n        Examples\n        --------\n\n        >>> model.run(params={'exogenous_constant': 42})\n        >>> model.run(params={'exogenous_variable': timeseries_input})\n        >>> model.run(return_timestamps=[1, 2, 3.1415, 4, 10])\n        >>> model.run(return_timestamps=10)\n        >>> model.run(return_timestamps=np.linspace(1, 10, 20))\n\n        See Also\n        --------\n        pysd.set_components : handles setting model parameters\n        pysd.set_initial_condition : handles setting initial conditions\n\n        \"\"\"\n        if reload:\n            self.reload()\n\n        if params:\n            self.set_components(params)\n\n        self.set_initial_condition(initial_condition)\n\n        return_timestamps = self._format_return_timestamps(return_timestamps)\n\n        t_series = self._build_euler_timeseries(return_timestamps)\n\n        if return_columns is None:\n            return_columns = self._default_return_columns()\n\n        self.time.stage = 'Run'\n        self.clear_caches()\n\n        capture_elements, return_addresses = utils.get_return_elements(\n            return_columns, self.components._namespace, self.components._subscript_dict)\n\n        res = self._integrate(t_series, capture_elements, return_timestamps)\n\n        return_df = utils.make_flat_df(res, return_addresses)\n        return_df.index = return_timestamps\n\n        return return_df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of the model elements that do not include lookup functions or other functions that take parameters.", "response": "def _default_return_columns(self):\n        \"\"\"\n        Return a list of the model elements that does not include lookup functions\n        or other functions that take parameters.\n        \"\"\"\n        return_columns = []\n        parsed_expr = []\n\n        for key, value in self.components._namespace.items():\n            if hasattr(self.components, value):\n                sig = signature(getattr(self.components, value))\n                # The `*args` reference handles the py2.7 decorator.\n                if len(set(sig.parameters) - {'args'}) == 0:\n                    expr = self.components._namespace[key]\n                    if not expr in parsed_expr:\n                        return_columns.append(key)\n                        parsed_expr.append(expr)\n\n        return return_columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_initial_condition(self, initial_condition):\n\n        if isinstance(initial_condition, tuple):\n            # Todo: check the values more than just seeing if they are a tuple.\n            self.set_state(*initial_condition)\n        elif isinstance(initial_condition, str):\n            if initial_condition.lower() in ['original', 'o']:\n                self.initialize()\n            elif initial_condition.lower() in ['current', 'c']:\n                pass\n            else:\n                raise ValueError('Valid initial condition strings include:  \\n' +\n                                 '    \"original\"/\"o\",                       \\n' +\n                                 '    \"current\"/\"c\"')\n        else:\n            raise TypeError('Check documentation for valid entries')", "response": "Set the initial conditions of the system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a single step in the euler integration", "response": "def _euler_step(self, dt):\n        \"\"\" Performs a single step in the euler integration,\n        updating stateful components\n\n        Parameters\n        ----------\n        dt : float\n            This is the amount to increase time by this step\n        \"\"\"\n        self.state = self.state + self.ddt() * dt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nintegrating the model elements over a set of time steps.", "response": "def _integrate(self, time_steps, capture_elements, return_timestamps):\n        \"\"\"\n        Performs euler integration\n\n        Parameters\n        ----------\n        time_steps: iterable\n            the time steps that the integrator progresses over\n        capture_elements: list\n            which model elements to capture - uses pysafe names\n        return_timestamps:\n            which subset of 'timesteps' should be values be returned?\n\n        Returns\n        -------\n        outputs: list of dictionaries\n\n        \"\"\"\n        # Todo: consider adding the timestamp to the return elements, and using that as the index\n        outputs = []\n\n        for t2 in time_steps[1:]:\n            if self.time() in return_timestamps:\n                outputs.append({key: getattr(self.components, key)() for key in capture_elements})\n            self._euler_step(t2 - self.time())\n            self.time.update(t2)  # this will clear the stepwise caches\n\n        # need to add one more time step, because we run only the state updates in the previous\n        # loop and thus may be one short.\n        if self.time() in return_timestamps:\n            outputs.append({key: getattr(self.components, key)() for key in capture_elements})\n\n        return outputs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef translate_xmile(xmile_file):\n\n    # process xml file\n    xml_parser = etree.XMLParser(encoding=\"utf-8\", recover=True)\n    root = etree.parse(xmile_file, parser=xml_parser).getroot()\n    NS = root.nsmap[None]  # namespace of the xmile document\n\n    def get_xpath_text(node, path, ns=None, default=''):\n        \"\"\" Safe access of occassionally missing elements \"\"\"\n        # defined here to take advantage of NS in default\n        if ns is None:\n            ns = {'ns': NS}\n        try:\n            return node.xpath(path, namespaces=ns)[0].text\n        except:\n            return default\n\n    def get_xpath_attrib(node, path, attrib, ns=None, default=None):\n        \"\"\" Safe access of occassionally missing elements \"\"\"\n        # defined here to take advantage of NS in default\n        if ns is None:\n            ns = {'ns': NS}\n        try:\n            return node.xpath(path, namespaces=ns)[0].attrib[attrib]\n        except:\n            return default\n\n    def is_constant_expression(py_expr):\n        try:\n            val = float(py_expr)\n            return True\n        except ValueError:\n            return False\n\n    def parse_lookup_xml_node(node):\n        ys_node = node.xpath('ns:ypts', namespaces={'ns': NS})[0]\n        ys = np.fromstring(ys_node.text, dtype=np.float, sep=ys_node.attrib['sep'] if 'sep' in ys_node.attrib else ',')\n        xscale_node = node.xpath('ns:xscale', namespaces={'ns': NS})\n        if len(xscale_node) > 0:\n            xmin = xscale_node[0].attrib['min']\n            xmax = xscale_node[0].attrib['max']\n            xs = np.linspace(float(xmin), float(xmax), len(ys))\n        else:\n            xs_node = node.xpath('ns:xpts', namespaces={'ns': NS})[0]\n            xs = np.fromstring(xs_node.text, dtype=np.float, sep=xs_node.attrib['sep'] if 'sep' in xs_node.attrib else ',')\n\n        type = node.attrib['type'] if 'type' in node.attrib else 'continuous'\n        functions_map = {\n            'continuous': 'functions.lookup',\n            'extrapolation': 'functions.lookup_extrapolation',\n            'discrete': 'functions.lookup_discrete'\n        }\n        lookup_function = functions_map[type] if type in functions_map else functions_map['continuous']\n\n        return {\n            'name': node.attrib['name'] if 'name' in node.attrib else '',\n            'xs': xs,\n            'ys': ys,\n            'type': type,\n            'function': lookup_function\n        }\n\n    # build model namespace\n    namespace = {\n        'TIME': 'time',\n        'Time': 'time',\n        'time': 'time'\n    }  # namespace of the python model\n    names_xpath = '//ns:model/ns:variables/ns:aux|' \\\n                  '//ns:model/ns:variables/ns:flow|' \\\n                  '//ns:model/ns:variables/ns:stock|' \\\n                  '//ns:model/ns:variables/ns:gf'\n\n    for node in root.xpath(names_xpath, namespaces={'ns': NS}):\n        name = node.attrib['name']\n        _, namespace = utils.make_python_identifier(name, namespace)\n\n    model_elements = []\n    smile_parser = SMILEParser(namespace)\n\n    # add aux and flow elements\n    flaux_xpath = '//ns:model/ns:variables/ns:aux|//ns:model/ns:variables/ns:flow'\n    for node in root.xpath(flaux_xpath, namespaces={'ns': NS}):\n        name = node.attrib['name']\n        units = get_xpath_text(node, 'ns:units')\n        lims = (get_xpath_attrib(node, 'ns:range', 'min'), get_xpath_attrib(node, 'ns:range', 'max'))\n        lims = str(tuple(float(x) if x is not None else x for x in lims))\n        doc = get_xpath_text(node, 'ns:doc')\n        py_name = namespace[name]\n        eqn = get_xpath_text(node, 'ns:eqn')\n\n        element = {\n            'kind': 'component',\n            'real_name': name,\n            'unit': units,\n            'doc': doc,\n            'eqn': eqn,\n            'lims': lims,\n            'py_name': py_name,\n            'subs': [],  # Todo later\n            'arguments': '',\n        }\n\n        tranlation, new_structure = smile_parser.parse(eqn, element)\n        element.update(tranlation)\n        if is_constant_expression(element['py_expr']):\n            element['kind'] = 'constant'\n\n        model_elements += new_structure\n\n        gf_node = node.xpath(\"ns:gf\", namespaces={'ns': NS})\n        if len(gf_node) > 0:\n            gf_data = parse_lookup_xml_node(gf_node[0])\n\n            element.update({\n                'kind': 'lookup',\n                # This lookup declared as inline, so we should implement inline mode for flow and aux\n                'arguments': \"x = None\",\n                'py_expr': \"%(function)s(%(x)s, [%(xs)s], [%(ys)s]) if x is None else %(function)s(x, [%(xs)s], [%(ys)s])\" % {\n                    'function': gf_data['function'],\n                    'xs': ','.join(\"%10.3f\" % x for x in gf_data['xs']),\n                    'ys': ','.join(\"%10.3f\" % x for x in gf_data['ys']),\n                    'x': element['py_expr']\n                },\n            })\n\n        model_elements.append(element)\n\n    # add gf elements\n    gf_xpath = '//ns:model/ns:variables/ns:gf'\n    for node in root.xpath(gf_xpath, namespaces={'ns': NS}):\n        name = node.attrib['name']\n        py_name = namespace[name]\n\n        units = get_xpath_text(node, 'ns:units')\n        doc = get_xpath_text(node, 'ns:doc')\n\n        gf_data = parse_lookup_xml_node(node)\n\n        element = {\n            'kind': 'lookup',\n            'real_name': name,\n            'unit': units,\n            'lims': None,\n            'doc': doc,\n            'eqn': '',\n            'py_name': py_name,\n            'py_expr': \"%(function)s(x, [%(xs)s], [%(ys)s])\" % {\n                    'function': gf_data['function'],\n                    'xs': ','.join(\"%10.3f\" % x for x in gf_data['xs']),\n                    'ys': ','.join(\"%10.3f\" % x for x in gf_data['ys']),\n                },\n            'arguments': 'x',\n            'subs': [],  # Todo later\n        }\n        model_elements.append(element)\n\n    # add stock elements\n    stock_xpath = '//ns:model/ns:variables/ns:stock'\n    for node in root.xpath(stock_xpath, namespaces={'ns': NS}):\n        name = node.attrib['name']\n        units = get_xpath_text(node, 'ns:units')\n        lims = (get_xpath_attrib(node, 'ns:range', 'min'), get_xpath_attrib(node, 'ns:range', 'max'))\n        lims = str(tuple(float(x) if x is not None else x for x in lims))\n        doc = get_xpath_text(node, 'ns:doc')\n        py_name = namespace[name]\n\n        # Extract input and output flows equations\n        inflows = [n.text for n in node.xpath('ns:inflow', namespaces={'ns': NS})]\n        outflows = [n.text for n in node.xpath('ns:outflow', namespaces={'ns': NS})]\n\n        eqn = ' + '.join(inflows) if inflows else ''\n        eqn += (' - ' + ' - '.join(outflows)) if outflows else ''\n\n        element = {\n            'kind': 'component' if inflows or outflows else 'constant',\n            'real_name': name,\n            'unit': units,\n            'doc': doc,\n            'eqn': eqn,\n            'lims': lims,\n            'py_name': py_name,\n            'subs': [],  # Todo later\n            'arguments': ''\n        }\n\n        # Parse each flow equations\n        py_inflows = []\n        for inputFlow in inflows:\n            translation, new_structure = smile_parser.parse(inputFlow, element)\n            py_inflows.append(translation['py_expr'])\n            model_elements += new_structure\n\n        # Parse each flow equations\n        py_outflows = []\n        for outputFlow in outflows:\n            translation, new_structure = smile_parser.parse(outputFlow, element)\n            py_outflows.append(translation['py_expr'])\n            model_elements += new_structure\n\n        py_ddt = ' + '.join(py_inflows) if py_inflows else ''\n        py_ddt += (' - ' + ' - '.join(py_outflows)) if py_outflows else ''\n\n        # Read the initial value equation for stock element\n        initial_value_eqn = get_xpath_text(node, 'ns:eqn')\n        translation, new_structure = smile_parser.parse(initial_value_eqn, element)\n        py_initial_value = translation['py_expr']\n        model_elements += new_structure\n\n        py_expr, new_structure = builder.add_stock(identifier=py_name,\n                                                   subs=[],  # Todo later\n                                                   expression=py_ddt,\n                                                   initial_condition=py_initial_value,\n                                                   subscript_dict={},  # Todo later\n                                                   )\n        element['py_expr'] = py_expr\n        model_elements.append(element)\n        model_elements += new_structure\n\n    # remove timestamp pieces so as not to double-count\n    model_elements_parsed = []\n    for element in model_elements:\n        if element['real_name'].lower() not in ['initial time', 'final time', 'time step', 'saveper']:\n            model_elements_parsed.append(element)\n    model_elements = model_elements_parsed\n\n    # Add timeseries information\n\n    # Read the start time of simulation\n    sim_spec_node = root.xpath('//ns:sim_specs', namespaces={'ns': NS});\n    time_units = sim_spec_node[0].attrib['time_units'] if (len(sim_spec_node) > 0 and 'time_units' in sim_spec_node[0].attrib) else \"\"\n\n    tstart = root.xpath('//ns:sim_specs/ns:start', namespaces={'ns': NS})[0].text\n    element = {\n        'kind': 'constant',\n        'real_name': 'INITIAL TIME',\n        'unit': time_units,\n        'lims': None,\n        'doc': 'The initial time for the simulation.',\n        'eqn': tstart,\n        'py_name': 'initial_time',\n        'subs': None,\n        'arguments': '',\n    }\n    translation, new_structure = smile_parser.parse(tstart, element)\n    element.update(translation)\n    model_elements.append(element)\n    model_elements += new_structure\n\n    # Read the final time of simulation\n    tstop = root.xpath('//ns:sim_specs/ns:stop', namespaces={'ns': NS})[0].text\n    element = {\n        'kind': 'constant',\n        'real_name': 'FINAL TIME',\n        'unit': time_units,\n        'lims': None,\n        'doc': 'The final time for the simulation.',\n        'eqn': tstart,\n        'py_name': 'final_time',\n        'subs': None,\n        'arguments': '',\n    }\n\n    translation, new_structure = smile_parser.parse(tstop, element)\n    element.update(translation)\n    model_elements.append(element)\n    model_elements += new_structure\n\n    # Read the time step of simulation\n    dt_node = root.xpath('//ns:sim_specs/ns:dt', namespaces={'ns': NS})\n\n    # Use default value for time step if `dt` is not specified in model\n    dt_eqn = \"1.0\"\n    if len(dt_node) > 0:\n        dt_node = dt_node[0]\n        dt_eqn = dt_node.text\n        # If reciprocal mode are defined for `dt`, we should inverse value\n        if (\"reciprocal\" in dt_node.attrib and dt_node.attrib[\"reciprocal\"].lower() == \"true\"):\n            dt_eqn = \"1/\" + dt_eqn\n\n    element = {\n        'kind': 'constant',\n        'real_name': 'TIME STEP',\n        'unit': time_units,\n        'lims': None,\n        'doc': 'The time step for the simulation.',\n        'eqn': dt_eqn,\n        'py_name': 'time_step',\n        'subs': None,\n        'arguments': '',\n    }\n    translation, new_structure = smile_parser.parse(dt_eqn, element)\n    element.update(translation)\n    model_elements.append(element)\n    model_elements += new_structure\n\n    # Add the SAVEPER attribute to the model\n    model_elements.append({\n        'kind': 'constant',\n        'real_name': 'SAVEPER',\n        'unit': time_units,\n        'lims': None,\n        'doc': 'The time step for the simulation.',\n        'eqn': dt_eqn,\n        'py_name': 'saveper',\n        'py_expr': 'time_step()',\n        'subs': None,\n        'arguments': '',\n    })\n\n    outfile_name = xmile_file.replace('.xmile', '.py')\n\n    builder.build(elements=model_elements,\n                  subscript_dict={},\n                  namespace=namespace,\n                  outfile_name=outfile_name)\n\n    return outfile_name", "response": "Translate an xmile model file into a python class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(elements, subscript_dict, namespace, outfile_name):\n    # Todo: deal with model level documentation\n    # Todo: Make np, PySD.functions import conditional on usage in the file\n    # Todo: Make presence of subscript_dict instantiation conditional on usage\n    # Todo: Sort elements (alphabetically? group stock funcs?)\n    elements = merge_partial_elements(elements)\n    functions = [build_element(element, subscript_dict) for element in elements]\n\n    text = '''\n    \"\"\"\n    Python model \"%(outfile)s\"\n    Translated using PySD version %(version)s\n    \"\"\"\n    from __future__ import division\n    import numpy as np\n    from pysd import utils\n    import xarray as xr\n\n    from pysd.py_backend.functions import cache\n    from pysd.py_backend import functions\n\n    _subscript_dict = %(subscript_dict)s\n\n    _namespace = %(namespace)s\n\n    __pysd_version__ = \"%(version)s\"\n    \n    __data = {\n        'scope': None,\n        'time': lambda: 0\n    }\n\n    def _init_outer_references(data):\n        for key in data:\n            __data[key] = data[key]\n    \n    def time():\n        return __data['time']()\n    \n    %(functions)s\n\n    ''' % {'subscript_dict': repr(subscript_dict),\n           'functions': '\\n'.join(functions),\n           # 'namespace': '{\\n' + '\\n'.join(['%s: %s' % (key, namespace[key]) for key in\n           #                                namespace.keys()]) + '\\n}',\n           'namespace': repr(namespace),\n           'outfile': os.path.basename(outfile_name),\n           'version': __version__}\n\n    style_file = pkg_resources.resource_filename(\"pysd\", \"py_backend/output_style.yapf\")\n    text = text.replace('\\t', '    ')\n    text, changed = yapf.yapf_api.FormatCode(textwrap.dedent(text),\n                                             style_config=style_file)\n\n    # this is used for testing\n    if outfile_name == 'return':\n        return text\n\n    with open(outfile_name, 'w', encoding='UTF-8') as out:\n        out.write(text)", "response": "Builds a new model from a list of model elements and a dictionary containing the names of subscript families and the namespace of the model elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a single element dictionary from a dictionary containing at least one element and subscript_dict.", "response": "def build_element(element, subscript_dict):\n    \"\"\"\n    Returns a string that has processed a single element dictionary\n    Parameters\n    ----------\n    element: dictionary\n        dictionary containing at least the elements:\n        - kind: ['constant', 'setup', 'component', 'lookup']\n            Different types of elements will be built differently\n        - py_expr: string\n            An expression that has been converted already into python syntax\n        - subs: list of lists\n            Each sublist contains coordinates for initialization of a particular\n            part of a subscripted function, the list of subscripts vensim attaches to an equation\n\n    subscript_dict: dictionary\n\n    Returns\n    -------\n\n    \"\"\"\n    if element['kind'] == 'constant':\n        cache_type = \"@cache('run')\"\n    elif element['kind'] in ['setup', 'stateful']:  # setups only get called once, caching is wasted\n        cache_type = ''\n    elif element['kind'] == 'component':\n        cache_type = \"@cache('step')\"\n    elif element['kind'] == 'stateful':\n        cache_type = ''\n    elif element['kind'] == 'lookup':  # lookups may be called with different values in a round\n        cache_type = ''\n    else:\n        raise AttributeError(\"Bad value for 'kind'\")\n\n    if len(element['py_expr']) > 1:\n        contents = 'return utils.xrmerge([%(das)s,])' % {'das': ',\\n'.join(element['py_expr'])}\n    else:\n        contents = 'return %(py_expr)s' % {'py_expr': element['py_expr'][0]}\n\n    indent = 8\n    element.update({'cache': cache_type,\n                    'ulines': '-' * len(element['real_name']),\n                    'contents': contents.replace('\\n',\n                                                 '\\n' + ' ' * indent)})  # indent lines 2 onward\n    \n    element['doc'] = element['doc'].replace('\\\\', '\\n    ').encode('unicode-escape')\n\n    if 'unit' in element:\n        element['unit'] = element['unit'].encode('unicode-escape')\n    if 'real_name' in element:\n        element['real_name'] = element['real_name'].encode('unicode-escape')\n    if 'eqn' in element:\n        element['eqn'] = element['eqn'].encode('unicode-escape')\n    \n    if element['kind'] == 'stateful':\n        func = '''\n    %(py_name)s = %(py_expr)s\n            ''' % {'py_name': element['py_name'], 'py_expr': element['py_expr'][0]}\n\n    else:\n        func = '''\n    %(cache)s\n    def %(py_name)s(%(arguments)s):\n        \"\"\"\n        Real Name: %(real_name)s\n        Original Eqn: %(eqn)s\n        Units: %(unit)s\n        Limits: %(lims)s\n        Type: %(kind)s\n\n        %(doc)s\n        \"\"\"\n        %(contents)s\n        ''' % element\n\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging model elements which collectively all define the model component, mostly for multidimensional subscripts Parameters ---------- element_list Returns -------", "response": "def merge_partial_elements(element_list):\n    \"\"\"\n    merges model elements which collectively all define the model component,\n    mostly for multidimensional subscripts\n\n    Parameters\n    ----------\n    element_list\n\n    Returns\n    -------\n    \"\"\"\n    outs = dict()  # output data structure\n    for element in element_list:\n        if element['py_expr'] != \"None\":  # for\n            name = element['py_name']\n            if name not in outs:\n                # Use 'expr' for Vensim models, and 'eqn' for Xmile (This makes the Vensim equation prettier.)\n                eqn = element['expr'] if 'expr' in element else element['eqn']\n\n                outs[name] = {\n                    'py_name': element['py_name'],\n                    'real_name': element['real_name'],\n                    'doc': element['doc'],\n                    'py_expr': [element['py_expr']],  # in a list\n                    'unit': element['unit'],\n                    'subs': [element['subs']],\n                    'lims': element['lims'],\n                    'eqn': eqn,\n                    'kind': element['kind'],\n                    'arguments': element['arguments']\n                }\n\n            else:\n                outs[name]['doc'] = outs[name]['doc'] or element['doc']\n                outs[name]['unit'] = outs[name]['unit'] or element['unit']\n                outs[name]['lims'] = outs[name]['lims'] or element['lims']\n                outs[name]['eqn'] = outs[name]['eqn'] or element['eqn']\n                outs[name]['py_expr'] += [element['py_expr']]\n                outs[name]['subs'] += [element['subs']]\n                outs[name]['arguments'] = element['arguments']\n\n    return list(outs.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_stock(identifier, subs, expression, initial_condition, subscript_dict):\n    new_structure = []\n\n    if len(subs) == 0:\n        stateful_py_expr = 'functions.Integ(lambda: %s, lambda: %s)' % (expression,\n                                                                        initial_condition)\n    else:\n        stateful_py_expr = 'functions.Integ(lambda: _d%s_dt(), lambda: _init_%s())' % (identifier,\n                                                                                       identifier)\n\n        try:\n            decoded = initial_condition.decode('unicode-escape')\n            initial_condition_numeric = decoded.isnumeric()\n        except AttributeError:\n            # I believe this should be okay for Py3 but should be checked\n            initial_condition_numeric = initial_condition.isnumeric()\n\n        if subs and initial_condition_numeric:\n            coords = utils.make_coord_dict(subs, subscript_dict, terse=False)\n            dims = [utils.find_subscript_name(subscript_dict, sub) for sub in subs]\n            shape = [len(coords[dim]) for dim in dims]\n            initial_condition = textwrap.dedent(\"\"\"\\\n                xr.DataArray(data=np.ones(%(shape)s)*%(value)s,\n                             coords=%(coords)s,\n                             dims=%(dims)s )\"\"\" % {\n                'shape': shape,\n                'value': initial_condition,\n                'coords': repr(coords),\n                'dims': repr(dims)})\n\n        # create the stock initialization element\n        new_structure.append({\n            'py_name': '_init_%s' % identifier,\n            'real_name': 'Implicit',\n            'kind': 'setup',  # not explicitly specified in the model file, but must exist\n            'py_expr': initial_condition,\n            'subs': subs,\n            'doc': 'Provides initial conditions for %s function' % identifier,\n            'unit': 'See docs for %s' % identifier,\n            'lims': 'None',\n            'eqn': 'None',\n            'arguments': ''\n        })\n\n        new_structure.append({\n            'py_name': '_d%s_dt' % identifier,\n            'real_name': 'Implicit',\n            'kind': 'component',\n            'doc': 'Provides derivative for %s function' % identifier,\n            'subs': subs,\n            'unit': 'See docs for %s' % identifier,\n            'lims': 'None',\n            'eqn': 'None',\n            'py_expr': expression,\n            'arguments': ''\n        })\n\n    # describe the stateful object\n    stateful = {\n        'py_name': '_integ_%s' % identifier,\n        'real_name': 'Representation of  %s' % identifier,\n        'doc': 'Integrates Expression %s' % expression,\n        'py_expr': stateful_py_expr,\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    new_structure.append(stateful)\n    return \"%s()\" % stateful['py_name'], new_structure", "response": "Adds a stock to the list of model element dictionaries associated with a stateful object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_n_delay(delay_input, delay_time, initial_value, order, subs, subscript_dict):\n    # the py name has to be unique to all the passed parameters, or if there are two things\n    # that delay the output by different amounts, they'll overwrite the original function...\n\n    stateful = {\n        'py_name': utils.make_python_identifier('_delay_%s_%s_%s_%s' % (delay_input,\n                                                                       delay_time,\n                                                                       initial_value,\n                                                                       order))[0],\n        'real_name': 'Delay of %s' % delay_input,\n        'doc': 'Delay time: %s \\n Delay initial value %s \\n Delay order %s' % (\n            delay_time, initial_value, order),\n        'py_expr': 'functions.Delay(lambda: %s, lambda: %s, lambda: %s, lambda: %s)' % (\n            delay_input, delay_time, initial_value, order),\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    return \"%s()\" % stateful['py_name'], [stateful]", "response": "This function creates code to instantiate a stateful Delay object and adds it to the list of element construction dictionaries that can be used to build the stateful Delay object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a stateful copy of the base class that will be used to assemble the whole tree for the given model component.", "response": "def add_n_smooth(smooth_input, smooth_time, initial_value, order, subs, subscript_dict):\n    \"\"\"Constructs stock and flow chains that implement the calculation of\n        a smoothing function.\n\n        Parameters\n        ----------\n        smooth_input: <string>\n            Reference to the model component that is the input to the smoothing function\n\n        smooth_time: <string>\n            Can be a number (in string format) or a reference to another model element\n            which will calculate the delay. This is calculated throughout the simulation\n            at runtime.\n\n        initial_value: <string>\n            This is used to initialize the stocks that are present in the delay. We\n            initialize the stocks with equal values so that the outflow in the first\n            timestep is equal to this value.\n\n        order: string\n            The number of stocks in the delay pipeline. As we construct the delays at\n            build time, this must be an integer and cannot be calculated from other\n            model components. Anything else will yield a ValueError.\n\n        subs: list of strings\n            List of strings of subscript indices that correspond to the\n            list of expressions, and collectively define the shape of the output\n            See `builder.add_flaux` for more info\n\n        Returns\n        -------\n        reference: basestring\n            reference to the smooth object `__call__` method, which will return the output\n            of the smooth process\n\n        new_structure: list\n            list of element construction dictionaries for the builder to assemble\n        \"\"\"\n\n    stateful = {\n        'py_name': utils.make_python_identifier('_smooth_%s_%s_%s_%s' % (smooth_input,\n                                                                        smooth_time,\n                                                                        initial_value,\n                                                                        order))[0],\n        'real_name': 'Smooth of %s' % smooth_input,\n        'doc': 'Smooth time: %s \\n Smooth initial value %s \\n Smooth order %s' % (\n            smooth_time, initial_value, order),\n        'py_expr': 'functions.Smooth(lambda: %s, lambda: %s, lambda: %s, lambda: %s)' % (\n            smooth_input, smooth_time, initial_value, order),\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    return \"%s()\" % stateful['py_name'], [stateful]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrend Parameters ---------- trend_input: <string> average_time: <string> trend_initial: <string> subs: list of strings List of strings of subscript indices that correspond to the list of expressions, and collectively define the shape of the output See `builder.add_flaux` for more info Returns ------- reference: basestring reference to the trend object `__call__` method, which will return the output of the trend process new_structure: list list of element construction dictionaries for the builder to assemble", "response": "def add_n_trend(trend_input, average_time, initial_trend, subs, subscript_dict):\n    \"\"\"Trend.\n\n        Parameters\n        ----------\n        trend_input: <string>\n\n        average_time: <string>\n\n\n        trend_initial: <string>\n\n        subs: list of strings\n            List of strings of subscript indices that correspond to the\n            list of expressions, and collectively define the shape of the output\n            See `builder.add_flaux` for more info\n\n        Returns\n        -------\n        reference: basestring\n            reference to the trend object `__call__` method, which will return the output\n            of the trend process\n\n        new_structure: list\n            list of element construction dictionaries for the builder to assemble\n        \"\"\"\n\n    stateful = {\n        'py_name': utils.make_python_identifier('_trend_%s_%s_%s' % (trend_input,\n                                                                    average_time,\n                                                                    initial_trend))[0],\n        'real_name': 'trend of %s' % trend_input,\n        'doc': 'Trend average time: %s \\n Trend initial value %s' % (\n            average_time, initial_trend),\n        'py_expr': 'functions.Trend(lambda: %s, lambda: %s, lambda: %s)' % (\n            trend_input, average_time, initial_trend),\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    return \"%s()\" % stateful['py_name'], [stateful]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_initial(initial_input):\n    stateful = {\n        'py_name': utils.make_python_identifier('_initial_%s' % initial_input)[0],\n        'real_name': 'Smooth of %s' % initial_input,\n        'doc': 'Returns the value taken on during the initialization phase',\n        'py_expr': 'functions.Initial(lambda: %s)' % (\n            initial_input),\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    return \"%s()\" % stateful['py_name'], [stateful]", "response": "Constructs a stateful object for handling vensim s Initial functionality"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a stateful object instantiating a Macro", "response": "def add_macro(macro_name, filename, arg_names, arg_vals):\n    \"\"\"\n    Constructs a stateful object instantiating a 'Macro'\n\n    Parameters\n    ----------\n    macro_name: basestring\n        python safe name for macro\n    filename: basestring\n        filepath to macro definition\n    func_args: dict\n        dictionary of values to be passed to macro\n        {key: function}\n\n    Returns\n    -------\n    reference: basestring\n        reference to the Initial object `__call__` method,\n        which will return the first calculated value of `initial_input`\n\n    new_structure: list\n        list of element construction dictionaries for the builder to assemble\n\n    \"\"\"\n    func_args = '{ %s }' % ', '.join([\"'%s': lambda: %s\" % (key, val) for key, val in\n                                      zip(arg_names, arg_vals)])\n\n    stateful = {\n        'py_name': '_macro_' + macro_name + '_' + '_'.join(\n            [utils.make_python_identifier(f)[0] for f in arg_vals]),\n        'real_name': 'Macro Instantiation of ' + macro_name,\n        'doc': 'Instantiates the Macro',\n        'py_expr': \"functions.Macro('%s', %s, '%s', time_initialization=lambda: __data['time'])\" % (filename, func_args, macro_name),\n        'unit': 'None',\n        'lims': 'None',\n        'eqn': 'None',\n        'subs': '',\n        'kind': 'stateful',\n        'arguments': ''\n    }\n\n    return \"%s()\" % stateful['py_name'], [stateful]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_incomplete(var_name, dependencies):\n    warnings.warn('%s has no equation specified' % var_name,\n                  SyntaxWarning, stacklevel=2)\n\n    # first arg is `self` reference\n    return \"functions.incomplete(%s)\" % ', '.join(dependencies[1:]), []", "response": "Add an incomplete function to the list of functions that are not yet in the list of dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_sections(file_str):\n\n    # the leading 'r' for 'raw' in this string is important for handling backslashes properly\n    file_structure_grammar = _include_common_grammar(r\"\"\"\n    file = encoding? (macro / main)+\n    macro = \":MACRO:\" _ name _ \"(\" _ (name _ \",\"? _)+ _ \":\"? _ (name _ \",\"? _)* _ \")\" ~r\".+?(?=:END OF MACRO:)\" \":END OF MACRO:\"\n    main = !\":MACRO:\" ~r\".+(?!:MACRO:)\"\n    encoding = ~r\"\\{[^\\}]*\\}\"\n    \"\"\")\n\n    parser = parsimonious.Grammar(file_structure_grammar)\n    tree = parser.parse(file_str)\n\n    class FileParser(parsimonious.NodeVisitor):\n        def __init__(self, ast):\n            self.entries = []\n            self.visit(ast)\n\n        def visit_main(self, n, vc):\n            self.entries.append({'name': '_main_',\n                                 'params': [],\n                                 'returns': [],\n                                 'string': n.text.strip()})\n\n        def visit_macro(self, n, vc):\n            name = vc[2]\n            params = vc[6]\n            returns = vc[10]\n            text = vc[13]\n            self.entries.append({'name': name,\n                                 'params': [x.strip() for x in params.split(',')] if params else [],\n                                 'returns': [x.strip() for x in\n                                             returns.split(',')] if returns else [],\n                                 'string': text.strip()})\n\n        def generic_visit(self, n, vc):\n            return ''.join(filter(None, vc)) or n.text or ''\n\n    return FileParser(tree).entries", "response": "This function returns a list of dictionaries that represents the macros and main body of the model file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_model_elements(model_str):\n\n    model_structure_grammar = _include_common_grammar(r\"\"\"\n    model = (entry / section)+ sketch?\n    entry = element \"~\" element \"~\" element (\"~\" element)? \"|\"\n    section = element \"~\" element \"|\"\n    sketch = ~r\".*\"  #anything\n\n    # Either an escape group, or a character that is not tilde or pipe\n    element = (escape_group / ~r\"[^~|]\")*\n    \"\"\")\n\n    parser = parsimonious.Grammar(model_structure_grammar)\n    tree = parser.parse(model_str)\n\n    class ModelParser(parsimonious.NodeVisitor):\n        def __init__(self, ast):\n            self.entries = []\n            self.visit(ast)\n\n        def visit_entry(self, n, vc):\n            units, lims = parse_units(vc[2].strip())\n            self.entries.append({'eqn': vc[0].strip(),\n                                 'unit': units,\n                                 'lims': str(lims),\n                                 'doc': vc[4].strip(),\n                                 'kind': 'entry'})\n\n        def visit_section(self, n, vc):\n            if vc[2].strip() != \"Simulation Control Parameters\":\n                self.entries.append({'eqn': '',\n                                     'unit': '',\n                                     'lims': '',\n                                     'doc': vc[2].strip(),\n                                     'kind': 'section'})\n\n        def generic_visit(self, n, vc):\n            return ''.join(filter(None, vc)) or n.text or ''\n\n    return ModelParser(tree).entries", "response": "Takes in a string representing model text and splits it into elements"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_equation_components(equation_str):\n\n    component_structure_grammar = _include_common_grammar(r\"\"\"\n    entry = component / subscript_definition / lookup_definition\n    component = name _ subscriptlist? _ \"=\" _ expression\n    subscript_definition = name _ \":\" _ subscript _ (\",\" _ subscript)*\n    lookup_definition = name _ &\"(\" _ expression  # uses lookahead assertion to capture whole group\n\n    name = basic_id / escape_group\n    subscriptlist = '[' _ subscript _ (\",\" _ subscript)* _ ']'\n    expression = ~r\".*\"  # expression could be anything, at this point.\n\n    subscript = basic_id / escape_group\n    \"\"\")\n\n    # replace any amount of whitespace  with a single space\n    equation_str = equation_str.replace('\\\\t', ' ')\n    equation_str = re.sub(r\"\\s+\", ' ', equation_str)\n\n    parser = parsimonious.Grammar(component_structure_grammar)\n    tree = parser.parse(equation_str)\n\n    class ComponentParser(parsimonious.NodeVisitor):\n        def __init__(self, ast):\n            self.subscripts = []\n            self.real_name = None\n            self.expression = None\n            self.kind = None\n            self.visit(ast)\n\n        def visit_subscript_definition(self, n, vc):\n            self.kind = 'subdef'\n\n        def visit_lookup_definition(self, n, vc):\n            self.kind = 'lookup'\n\n        def visit_component(self, n, vc):\n            self.kind = 'component'\n\n        def visit_name(self, n, vc):\n            (name,) = vc\n            self.real_name = name.strip()\n\n        def visit_subscript(self, n, vc):\n            (subscript,) = vc\n            self.subscripts.append(subscript.strip())\n\n        def visit_expression(self, n, vc):\n            self.expression = n.text.strip()\n\n        def generic_visit(self, n, vc):\n            return ''.join(filter(None, vc)) or n.text\n\n        def visit__(self, n, vc):\n            return ' '\n\n    parse_object = ComponentParser(tree)\n\n    return {'real_name': parse_object.real_name,\n            'subs': parse_object.subscripts,\n            'expr': parse_object.expression,\n            'kind': parse_object.kind}", "response": "Returns a dictionary of all model elements that are part of a given model element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_units(units_str):\n    if not len(units_str):\n        return units_str, (None, None)\n\n    if units_str[-1] == ']':\n        units, lims = units_str.rsplit('[')  # type: str, str\n    else:\n        units = units_str\n        lims = '?, ?]'\n\n    lims = tuple([float(x) if x.strip() != '?' else None for x in lims.strip(']').split(',')])\n\n    return units.strip(), lims", "response": "Extract and parse the units from a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a general expression into a single tree structure.", "response": "def parse_general_expression(element, namespace=None, subscript_dict=None, macro_list=None):\n    \"\"\"\n    Parses a normal expression\n    # its annoying that we have to construct and compile the grammar every time...\n\n    Parameters\n    ----------\n    element: dictionary\n\n    namespace : dictionary\n\n    subscript_dict : dictionary\n\n    macro_list: list of dictionaries\n        [{'name': 'M', 'py_name':'m', 'filename':'path/to/file', 'args':['arg1', 'arg2']}]\n\n    Returns\n    -------\n    translation\n\n    new_elements: list of dictionaries\n        If the expression contains builder functions, those builders will create new elements\n        to add to our running list (that will eventually be output to a file) such as stock\n        initialization and derivative funcs, etc.\n\n\n    Examples\n    --------\n    >>> parse_general_expression({'expr': 'INTEG (FlowA, -10)',\n    ...                           'py_name':'test_stock',\n    ...                           'subs':None},\n    ...                          {'FlowA': 'flowa'}),\n    ({'kind': 'component', 'py_expr': \"_state['test_stock']\"},\n     [{'kind': 'implicit',\n       'subs': None,\n       'doc': 'Provides initial conditions for test_stock function',\n       'py_name': 'init_test_stock',\n       'real_name': None,\n       'unit': 'See docs for test_stock',\n       'py_expr': '-10'},\n      {'py_name': 'dtest_stock_dt',\n       'kind': 'implicit',\n       'py_expr': 'flowa',\n       'real_name': None}])\n\n    \"\"\"\n    if namespace is None:\n        namespace = {}\n    if subscript_dict is None:\n        subscript_dict = {}\n\n    in_ops = {\n        \"+\": \"+\", \"-\": \"-\", \"*\": \"*\", \"/\": \"/\", \"^\": \"**\", \"=\": \"==\", \"<=\": \"<=\", \"<>\": \"!=\",\n        \"<\": \"<\", \">=\": \">=\", \">\": \">\",\n        \":and:\": \" and \", \":or:\": \" or \"}  # spaces important for word-based operators\n\n    pre_ops = {\n        \"-\": \"-\", \":not:\": \" not \",  # spaces important for word-based operators\n        \"+\": \" \"  # space is important, so that and empty string doesn't slip through generic\n    }\n\n    # in the following, if lists are empty use non-printable character\n    # everything needs to be escaped before going into the grammar, in case it includes quotes\n    sub_names_list = [re.escape(x) for x in subscript_dict.keys()] or ['\\\\a']\n    sub_elems_list = [re.escape(y) for x in subscript_dict.values() for y in x] or ['\\\\a']\n    ids_list = [re.escape(x) for x in namespace.keys()] or ['\\\\a']\n    in_ops_list = [re.escape(x) for x in in_ops.keys()]\n    pre_ops_list = [re.escape(x) for x in pre_ops.keys()]\n    if macro_list is not None and len(macro_list) > 0:\n        macro_names_list = [re.escape(x['name']) for x in macro_list]\n    else:\n        macro_names_list = ['\\\\a']\n\n    expression_grammar = r\"\"\"\n    expr_type = array / expr / empty\n    expr = _ pre_oper? _ (lookup_def / build_call / macro_call / call / lookup_call / parens / number / reference) _ (in_oper _ expr)?\n\n    lookup_def = ~r\"(WITH\\ LOOKUP)\"I _ \"(\" _ expr _ \",\" _ \"(\" _  (\"[\" ~r\"[^\\]]*\" \"]\" _ \",\")?  ( \"(\" _ expr _ \",\" _ expr _ \")\" _ \",\"? _ )+ _ \")\" _ \")\"\n    lookup_call = id _ \"(\" _ (expr _ \",\"? _)* \")\"  # these don't need their args parsed...\n    call = func _ \"(\" _ (expr _ \",\"? _)* \")\"  # these don't need their args parsed...\n    build_call = builder _ \"(\" _ arguments _ \")\"\n    macro_call = macro _ \"(\" _ arguments _ \")\"\n    parens   = \"(\" _ expr _ \")\"\n\n    arguments = (expr _ \",\"? _)*\n\n    reference = id _ subscript_list?\n    subscript_list = \"[\" _ ((sub_name / sub_element) _ \",\"? _)+ \"]\"\n\n    array = (number _ (\",\" / \";\")? _)+ !~r\".\"  # negative lookahead for anything other than an array\n    number = ~r\"\\d+\\.?\\d*(e[+-]\\d+)?\"\n\n    id = ( basic_id / escape_group )\n    basic_id = ~r\"\\w[\\w\\d_\\s\\']*\"IU\n    escape_group = \"\\\"\" ( \"\\\\\\\"\" / ~r\"[^\\\"]\"IU )* \"\\\"\"\n    \n    sub_name = ~r\"(%(sub_names)s)\"IU  # subscript names (if none, use non-printable character)\n    sub_element = ~r\"(%(sub_elems)s)\"IU  # subscript elements (if none, use non-printable character)\n\n    func = ~r\"(%(funcs)s)\"IU  # functions (case insensitive)\n    in_oper = ~r\"(%(in_ops)s)\"IU  # infix operators (case insensitive)\n    pre_oper = ~r\"(%(pre_ops)s)\"IU  # prefix operators (case insensitive)\n    builder = ~r\"(%(builders)s)\"IU  # builder functions (case insensitive)\n    macro = ~r\"(%(macros)s)\"IU  # macros from model file (if none, use non-printable character)\n\n    _ = ~r\"[\\s\\\\]*\"  # whitespace character\n    empty = \"\" # empty string\n    \"\"\" % {\n        # In the following, we have to sort keywords in decreasing order of length so that the\n        # peg parser doesn't quit early when finding a partial keyword\n        'sub_names': '|'.join(reversed(sorted(sub_names_list, key=len))),\n        'sub_elems': '|'.join(reversed(sorted(sub_elems_list, key=len))),\n        'funcs': '|'.join(reversed(sorted(functions.keys(), key=len))),\n        'in_ops': '|'.join(reversed(sorted(in_ops_list, key=len))),\n        'pre_ops': '|'.join(reversed(sorted(pre_ops_list, key=len))),\n        'builders': '|'.join(reversed(sorted(builders.keys(), key=len))),\n        'macros': '|'.join(reversed(sorted(macro_names_list, key=len)))\n    }\n    \n    class ExpressionParser(parsimonious.NodeVisitor):\n        # Todo: at some point, we could make the 'kind' identification recursive on expression,\n        # so that if an expression is passed into a builder function, the information\n        # about whether it is a constant, or calls another function, goes with it.\n        def __init__(self, ast):\n            self.translation = \"\"\n            self.kind = 'constant'  # change if we reference anything else\n            self.new_structure = []\n            self.visit(ast)\n\n        def visit_expr_type(self, n, vc):\n            s = ''.join(filter(None, vc)).strip()\n            self.translation = s\n\n        def visit_expr(self, n, vc):\n            s = ''.join(filter(None, vc)).strip()\n            self.translation = s\n            return s\n\n        def visit_call(self, n, vc):\n            self.kind = 'component'\n            function_name = vc[0].lower()\n            arguments = [e.strip() for e in vc[4].split(\",\")]\n            return builder.build_function_call(functions[function_name], arguments)\n\n        def visit_in_oper(self, n, vc):\n            return in_ops[n.text.lower()]\n\n        def visit_pre_oper(self, n, vc):\n            return pre_ops[n.text.lower()]\n\n        def visit_reference(self, n, vc):\n            self.kind = 'component'\n            id_str = vc[0]\n            return id_str + '()'\n\n        def visit_id(self, n, vc):\n            return namespace[n.text.strip()]\n\n        def visit_lookup_def(self, n, vc):\n            \"\"\" This exists because vensim has multiple ways of doing lookups.\n            Which is frustrating.\"\"\"\n            x_val = vc[4]\n            pairs = vc[11]\n            mixed_list = pairs.replace('(', '').replace(')', '').split(',')\n            xs = mixed_list[::2]\n            ys = mixed_list[1::2]\n            string = \"functions.lookup(%(x)s, [%(xs)s], [%(ys)s])\" % {\n                'x': x_val,\n                'xs': ','.join(xs),\n                'ys': ','.join(ys)\n            }\n            return string\n\n        def visit_array(self, n, vc):\n            if 'subs' in element and element['subs']:  # first test handles when subs is not defined\n                coords = utils.make_coord_dict(element['subs'], subscript_dict, terse=False)\n                dims = [utils.find_subscript_name(subscript_dict, sub) for sub in element['subs']]\n                shape = [len(coords[dim]) for dim in dims]\n                if ';' in n.text or ',' in n.text:\n                    text = n.text.strip(';').replace(' ', '').replace(';', ',')\n                    data = np.array([float(s) for s in text.split(',')]).reshape(shape)\n                else:\n                    data = np.tile(float(n.text), shape)\n                datastr = np.array2string(data, separator=',').replace('\\n', '').replace(' ', '')\n                return textwrap.dedent(\"\"\"\\\n                    xr.DataArray(data=%(datastr)s,\n                                 coords=%(coords)s,\n                                 dims=%(dims)s )\"\"\" % {\n                    'datastr': datastr,\n                    'coords': repr(coords),\n                    'dims': repr(dims)})\n\n            else:\n                return n.text.replace(' ', '')\n\n        def visit_subscript_list(self, n, vc):\n            refs = vc[2]\n            subs = [x.strip() for x in refs.split(',')]\n            coordinates = utils.make_coord_dict(subs, subscript_dict)\n            if len(coordinates):\n                return '.loc[%s]' % repr(coordinates)\n            else:\n                return ' '\n\n        def visit_build_call(self, n, vc):\n            call = vc[0]\n            arglist = vc[4]\n            self.kind = 'component'\n\n            builder_name = call.strip().lower()\n            name, structure = builders[builder_name](element, subscript_dict, arglist)\n            self.new_structure += structure\n\n            if builder_name == 'delay fixed':\n                warnings.warn(\"Delay fixed only approximates solution, may not give the same \"\n                              \"result as vensim\")\n\n            return name\n\n        def visit_macro_call(self, n, vc):\n            call = vc[0]\n            arglist = vc[4]\n            self.kind = 'component'\n            py_name = utils.make_python_identifier(call)[0]\n            macro = [x for x in macro_list if x['py_name'] == py_name][0]  # should match once\n            name, structure = builder.add_macro(macro['py_name'], macro['file_name'],\n                                                macro['params'], arglist)\n            self.new_structure += structure\n            return name\n\n        def visit_arguments(self, n, vc):\n            arglist = [x.strip(',') for x in vc]\n            return arglist\n\n        def visit__(self, n, vc):\n            \"\"\" Handles whitespace characters\"\"\"\n            return ''\n\n        def visit_empty(self, n, vc):\n            return 'None'\n\n        def generic_visit(self, n, vc):\n            return ''.join(filter(None, vc)) or n.text\n\n    parser = parsimonious.Grammar(expression_grammar)\n    tree = parser.parse(element['expr'])\n    parse_object = ExpressionParser(tree)\n\n    return ({'py_expr': parse_object.translation,\n             'kind': parse_object.kind,\n             'arguments': ''},\n            parse_object.new_structure)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_lookup_expression(element):\n\n    lookup_grammar = r\"\"\"\n    lookup = _ \"(\" range? _ ( \"(\" _ number _ \",\" _ number _ \")\" _ \",\"? _ )+ \")\"\n    number = (\"+\"/\"-\")? ~r\"\\d+\\.?\\d*(e[+-]\\d+)?\"\n    _ = ~r\"[\\s\\\\]*\"  # whitespace character\n\trange = _ \"[\" ~r\"[^\\]]*\" \"]\" _ \",\"\n    \"\"\"\n    parser = parsimonious.Grammar(lookup_grammar)\n    tree = parser.parse(element['expr'])\n\n    class LookupParser(parsimonious.NodeVisitor):\n        def __init__(self, ast):\n            self.translation = \"\"\n            self.new_structure = []\n            self.visit(ast)\n\n        def visit__(self, n, vc):\n            # remove whitespace\n            return ''\n\n        def visit_lookup(self, n, vc):\n            pairs = max(vc, key=len)\n            mixed_list = pairs.replace('(', '').replace(')', '').split(',')\n            xs = mixed_list[::2]\n            ys = mixed_list[1::2]\n            string = \"functions.lookup(x, [%(xs)s], [%(ys)s])\" % {\n                'xs': ','.join(xs),\n                'ys': ','.join(ys)\n            }\n            self.translation = string\n\n        def generic_visit(self, n, vc):\n            return ''.join(filter(None, vc)) or n.text\n\n    parse_object = LookupParser(tree)\n    return {'py_expr': parse_object.translation,\n            'arguments': 'x'}", "response": "This syntax parses the expression of a lookup expression into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef xrmerge(das, accept_new=True):\n    da = das[0]\n    for new_da in das[1:]:\n        # Expand both to have same dimensions, padding with NaN\n        da, new_da = xr.align(da, new_da, join='outer')\n        # Fill NaNs one way or the other re. accept_new\n        da = new_da.fillna(da) if accept_new else da.fillna(new_da)\n    return da", "response": "Merge the data arrays of the same dimension sets into a single array of the same dimension sets."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_subscript_name(subscript_dict, element):\n    if element in subscript_dict.keys():\n        return element\n\n    for name, elements in subscript_dict.items():\n        if element in elements:\n            return name", "response": "Given a subscript dictionary and a member of a subscript family return the first key of which the member is within the value list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_coord_dict(subs, subscript_dict, terse=True):\n    sub_elems_list = [y for x in subscript_dict.values() for y in x]\n    coordinates = {}\n    for sub in subs:\n        if sub in sub_elems_list:\n            name = find_subscript_name(subscript_dict, sub)\n            coordinates[name] = [sub]\n        elif not terse:\n            coordinates[sub] = subscript_dict[sub]\n    return coordinates", "response": "This function creates a dictionary that contains the coordinates of the elements in subscript_dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes an arbitrary string and creates a valid python identifier based on the input string.", "response": "def make_python_identifier(string, namespace=None, reserved_words=None,\n                           convert='drop', handle='force'):\n    \"\"\"\n    Takes an arbitrary string and creates a valid Python identifier.\n\n    If the input string is in the namespace, return its value.\n\n    If the python identifier created is already in the namespace,\n    but the input string is not (ie, two similar strings resolve to\n    the same python identifier)\n\n    or if the identifier is a reserved word in the reserved_words\n    list, or is a python default reserved word,\n    adds _1, or if _1 is in the namespace, _2, etc.\n\n    Parameters\n    ----------\n    string : <basestring>\n        The text to be converted into a valid python identifier\n    namespace : <dictionary>\n        Map of existing translations into python safe identifiers.\n        This is to ensure that two strings are not translated into\n        the same python identifier\n    reserved_words : <list of strings>\n        List of words that are reserved (because they have other meanings\n        in this particular program, such as also being the names of\n        libraries, etc.\n    convert : <string>\n        Tells the function what to do with characters that are not\n        valid in python identifiers\n        - 'hex' implies that they will be converted to their hexidecimal\n                representation. This is handy if you have variables that\n                have a lot of reserved characters, or you don't want the\n                name to be dependent on when things were added to the\n                namespace\n        - 'drop' implies that they will just be dropped altogether\n    handle : <string>\n        Tells the function how to deal with namespace conflicts\n        - 'force' will create a representation which is not in conflict\n                  by appending _n to the resulting variable where n is\n                  the lowest number necessary to avoid a conflict\n        - 'throw' will raise an exception\n\n    Returns\n    -------\n    identifier : <string>\n        A vaild python identifier based on the input string\n    namespace : <dictionary>\n        An updated map of the translations of words to python identifiers,\n        including the passed in 'string'.\n\n    Examples\n    --------\n    >>> make_python_identifier('Capital')\n    ('capital', {'Capital': 'capital'})\n\n    >>> make_python_identifier('multiple words')\n    ('multiple_words', {'multiple words': 'multiple_words'})\n\n    >>> make_python_identifier('multiple     spaces')\n    ('multiple_spaces', {'multiple     spaces': 'multiple_spaces'})\n\n    When the name is a python keyword, add '_1' to differentiate it\n    >>> make_python_identifier('for')\n    ('for_1', {'for': 'for_1'})\n\n    Remove leading and trailing whitespace\n    >>> make_python_identifier('  whitespace  ')\n    ('whitespace', {'  whitespace  ': 'whitespace'})\n\n    Remove most special characters outright:\n    >>> make_python_identifier('H@t tr!ck')\n    ('ht_trck', {'H@t tr!ck': 'ht_trck'})\n\n    Replace special characters with their hex representations\n    >>> make_python_identifier('H@t tr!ck', convert='hex')\n    ('h40t_tr21ck', {'H@t tr!ck': 'h40t_tr21ck'})\n\n    remove leading digits\n    >>> make_python_identifier('123abc')\n    ('abc', {'123abc': 'abc'})\n\n    already in namespace\n    >>> make_python_identifier('Variable$', namespace={'Variable$': 'variable'})\n    ('variable', {'Variable$': 'variable'})\n\n    namespace conflicts\n    >>> make_python_identifier('Variable$', namespace={'Variable@': 'variable'})\n    ('variable_1', {'Variable@': 'variable', 'Variable$': 'variable_1'})\n\n    >>> make_python_identifier('Variable$', namespace={'Variable@': 'variable',\n    >>>                                                'Variable%': 'variable_1'})\n    ('variable_2', {'Variable@': 'variable', 'Variable%': 'variable_1', 'Variable$': 'variable_2'})\n\n    throw exception instead\n    >>> make_python_identifier('Variable$', namespace={'Variable@': 'variable'}, handle='throw')\n    Traceback (most recent call last):\n     ...\n    NameError: variable already exists in namespace or is a reserved word\n\n\n    References\n    ----------\n    Identifiers must follow the convention outlined here:\n        https://docs.python.org/2/reference/lexical_analysis.html#identifiers\n    \"\"\"\n\n    if namespace is None:\n        namespace = dict()\n\n    if reserved_words is None:\n        reserved_words = list()\n\n    if string in namespace:\n        return namespace[string], namespace\n\n    # create a working copy (and make it lowercase, while we're at it)\n    s = string.lower()\n\n    # remove leading and trailing whitespace\n    s = s.strip()\n\n    # Make spaces into underscores\n    s = re.sub('[\\\\s\\\\t\\\\n]+', '_', s)\n\n    if convert == 'hex':\n        # Convert invalid characters to hex. Note: \\p{l} designates all Unicode letter characters (any language),\n        # \\p{m} designates all mark symbols (e.g., vowel marks in Indian scrips, such as the final)\n        # and \\p{n} designates all numbers. We allow any of these to be present in the regex.\n        s = ''.join([c.encode(\"hex\") if re.findall('[^\\p{l}\\p{m}\\p{n}_]', c) else c for c in s])\n\n    elif convert == 'drop':\n        # Remove invalid characters\n        s = re.sub('[^\\p{l}\\p{m}\\p{n}_]', '', s)\n\n    # Remove leading characters until we find a letter or underscore. Only letters can be leading characters.\n    s = re.sub('^[^\\p{l}_]+', '', s)\n\n    # Check that the string is not a python identifier\n    while (s in keyword.kwlist or\n                   s in namespace.values() or\n                   s in reserved_words):\n        if handle == 'throw':\n            raise NameError(s + ' already exists in namespace or is a reserved word')\n        if handle == 'force':\n            if re.match(\".*?_\\d+$\", s):\n                i = re.match(\".*?_(\\d+)$\", s).groups()[0]\n                s = s.strip('_' + i) + '_' + str(int(i) + 1)\n            else:\n                s += '_1'\n\n    namespace[string] = s\n\n    return s, namespace"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes a list of dictionaries each representing what is returned from the model at a particular time and creates a dataframe whose columns correspond to the keys of return_addresses.", "response": "def make_flat_df(frames, return_addresses):\n    \"\"\"\n    Takes a list of dictionaries, each representing what is returned from the\n    model at a particular time, and creates a dataframe whose columns correspond\n    to the keys of `return addresses`\n\n    Parameters\n    ----------\n    frames: list of dictionaries\n        each dictionary represents the result of a prticular time in the model\n    return_addresses: a dictionary,\n        keys will be column names of the resulting dataframe, and are what the\n        user passed in as 'return_columns'. Values are a tuple:\n        (py_name, {coords dictionary}) which tells us where to look for the value\n        to put in that specific column.\n\n    Returns\n    -------\n\n    \"\"\"\n\n    # Todo: could also try a list comprehension here, or parallel apply\n    visited = list(map(lambda x: visit_addresses(x, return_addresses), frames))\n    return pd.DataFrame(visited)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvisit all of the addresses returns a dictionary containing only the addressed elements.", "response": "def visit_addresses(frame, return_addresses):\n    \"\"\"\n    Visits all of the addresses, returns a new dict\n    which contains just the addressed elements\n\n\n    Parameters\n    ----------\n    frame\n    return_addresses: a dictionary,\n        keys will be column names of the resulting dataframe, and are what the\n        user passed in as 'return_columns'. Values are a tuple:\n        (py_name, {coords dictionary}) which tells us where to look for the value\n        to put in that specific column.\n\n    Returns\n    -------\n    outdict: dictionary\n\n    \"\"\"\n    outdict = dict()\n    for real_name, (pyname, address) in return_addresses.items():\n        if address:\n            xrval = frame[pyname].loc[address]\n            if xrval.size > 1:\n                outdict[real_name] = xrval\n            else:\n                outdict[real_name] = float(np.squeeze(xrval.values))\n        else:\n            outdict[real_name] = frame[pyname]\n\n    return outdict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the request is valid.", "response": "def validate_request(request):\n    \"\"\"Check an incoming request.\n\n    Returns:\n        - True if authentication passed\n        - Adding request['REMOTE_USER'] as authenticated username.\n    \"\"\"\n    if getattr(settings, 'BASICAUTH_DISABLE', False):\n        # Not to use this env\n        return True\n\n    if 'HTTP_AUTHORIZATION' not in request.META:\n        return False\n\n    authorization_header = request.META['HTTP_AUTHORIZATION']\n    ret = extract_basicauth(authorization_header)\n    if not ret:\n        return False\n\n    username, password = ret\n\n    raw_pass = settings.BASICAUTH_USERS.get(username)\n    if raw_pass is None:\n        return False\n\n    # To avoid timing atacks\n    # https://security.stackexchange.com/questions/83660/simple-string-comparisons-not-secure-against-timing-attacks\n    if not constant_time_compare(raw_pass, password):\n        return False\n\n    request.META['REMOTE_USER'] = username\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a sequence of addresses.", "response": "def _find_address_range(addresses):\n    \"\"\"Find a sequence of addresses.\n\n    Args:\n        addresses: a list of IPv4 or IPv6 addresses.\n\n    Returns:\n        A tuple containing the first and last IP addresses in the sequence,\n        and the index of the last IP address in the sequence.\n\n    \"\"\"\n    first = last = addresses[0]\n    last_index = 0\n    for ip in addresses[1:]:\n        if ip._ip == last._ip + 1:\n            last = ip\n            last_index += 1\n        else:\n            break\n    return (first, last, last_index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prefix_from_prefix_int(self, prefixlen):\n        if not isinstance(prefixlen, (int, long)):\n            raise NetmaskValueError('%r is not an integer' % prefixlen)\n        prefixlen = int(prefixlen)\n        if not (0 <= prefixlen <= self._max_prefixlen):\n            raise NetmaskValueError('%d is not a valid prefix length' %\n                                    prefixlen)\n        return prefixlen", "response": "Validate and return a prefix length integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_colored(code, text, is_bold=False):\n    if is_bold:\n        code = '1;%s' % code\n\n    return '\\033[%sm%s\\033[0m' % (code, text)", "response": "Create function to output with color sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the application with the webpack stats.", "response": "def init_app(self, app):\n        \"\"\"\n        Mutate the application passed in as explained here:\n        http://flask.pocoo.org/docs/0.10/extensiondev/\n\n        :param app: Flask application\n        :return: None\n        \"\"\"\n\n        # Setup a few sane defaults.\n        app.config.setdefault('WEBPACK_MANIFEST_PATH',\n                              '/tmp/themostridiculousimpossiblepathtonotexist')\n        app.config.setdefault('WEBPACK_ASSETS_URL', None)\n\n        self._set_asset_paths(app)\n\n        # We only want to refresh the webpack stats in development mode,\n        # not everyone sets this setting, so let's assume it's production.\n        if app.config.get('DEBUG', False):\n            app.before_request(self._refresh_webpack_stats)\n\n        if hasattr(app, 'add_template_global'):\n            app.add_template_global(self.javascript_tag)\n            app.add_template_global(self.stylesheet_tag)\n            app.add_template_global(self.asset_url_for)\n        else:\n            # Flask < 0.10\n            ctx = {\n                'javascript_tag': self.javascript_tag,\n                'stylesheet_tag': self.stylesheet_tag,\n                'asset_url_for': self.asset_url_for\n            }\n            app.context_processor(lambda: ctx)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_asset_paths(self, app):\n        webpack_stats = app.config['WEBPACK_MANIFEST_PATH']\n\n        try:\n            with app.open_resource(webpack_stats, 'r') as stats_json:\n                stats = json.load(stats_json)\n\n                if app.config['WEBPACK_ASSETS_URL']:\n                    self.assets_url = app.config['WEBPACK_ASSETS_URL']\n                else:\n                    self.assets_url = stats['publicPath']\n\n                self.assets = stats['assets']\n        except IOError:\n            raise RuntimeError(\n                \"Flask-Webpack requires 'WEBPACK_MANIFEST_PATH' to be set and \"\n                \"it must point to a valid json file.\")", "response": "Read in the manifest json file which acts as a manifest for assets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asset_url_for(self, asset):\n        if '//' in asset:\n            return asset\n\n        if asset not in self.assets:\n            return None\n\n        return '{0}{1}'.format(self.assets_url, self.assets[asset])", "response": "Return the url of an asset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall before the instance is created or updated.", "response": "def pre_change_receiver(self, instance: Model, action: Action):\n        \"\"\"\n        Entry point for triggering the old_binding from save signals.\n        \"\"\"\n        if action == Action.CREATE:\n            group_names = set()\n        else:\n            group_names = set(self.group_names(instance))\n\n        # use a thread local dict to be safe...\n        if not hasattr(instance, '__instance_groups'):\n            instance.__instance_groups = threading.local()\n            instance.__instance_groups.observers = {}\n        if not hasattr(instance.__instance_groups, 'observers'):\n            instance.__instance_groups.observers = {}\n\n        instance.__instance_groups.observers[self] = group_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrigger the old binding to possibly send to its group.", "response": "def post_change_receiver(self, instance: Model, action: Action, **kwargs):\n        \"\"\"\n        Triggers the old_binding to possibly send to its group.\n        \"\"\"\n        try:\n            old_group_names = instance.__instance_groups.observers[self]\n        except (ValueError, KeyError):\n            old_group_names = set()\n\n        if action == Action.DELETE:\n            new_group_names = set()\n        else:\n            new_group_names = set(self.group_names(instance))\n\n        # if post delete, new_group_names should be []\n\n        # Django DDP had used the ordering of DELETE, UPDATE then CREATE for good reasons.\n        self.send_messages(\n            instance,\n            old_group_names - new_group_names,\n            Action.DELETE,\n            **kwargs\n        )\n        # the object has been updated so that its groups are not the same.\n        self.send_messages(\n            instance,\n            old_group_names & new_group_names,\n            Action.UPDATE,\n            **kwargs\n        )\n\n        #\n        self.send_messages(\n            instance,\n            new_group_names - old_group_names,\n            Action.CREATE,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_queryset(self, **kwargs) -> QuerySet:\n        assert self.queryset is not None, (\n            \"'%s' should either include a `queryset` attribute, \"\n            \"or override the `get_queryset()` method.\"\n            % self.__class__.__name__\n        )\n\n        queryset = self.queryset\n        if isinstance(queryset, QuerySet):\n            # Ensure queryset is re-evaluated on each request.\n            queryset = queryset.all()\n        return queryset", "response": "Returns the list of items for this view."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_object(self, **kwargs) ->Model:\n        queryset = self.filter_queryset(\n            queryset=self.get_queryset(**kwargs),\n            **kwargs\n        )\n\n        # Perform the lookup filtering.\n        lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field\n\n        assert lookup_url_kwarg in kwargs, (\n                'Expected view %s to be called with a URL keyword argument '\n                'named \"%s\". Fix your URL conf, or set the `.lookup_field` '\n                'attribute on the view correctly.' %\n                (self.__class__.__name__, lookup_url_kwarg)\n        )\n\n        filter_kwargs = {self.lookup_field: kwargs[lookup_url_kwarg]}\n\n        obj = get_object_or_404(queryset, **filter_kwargs)\n        # TODO check_object_permissions\n\n        return obj", "response": "Returns the object that is displaying."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_serializer(\n            self,\n            action_kwargs: Dict=None,\n            *args, **kwargs) -> Serializer:\n        \"\"\"\n        Return the serializer instance that should be used for validating and\n        deserializing input, and for serializing output.\n        \"\"\"\n        serializer_class = self.get_serializer_class(\n            **action_kwargs\n        )\n\n        kwargs['context'] = self.get_serializer_context(\n            **action_kwargs\n        )\n\n        return serializer_class(*args, **kwargs)", "response": "Returns the serializer instance that should be used for validating and\n            deserializing input and serializing output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the class to use for the serializer.", "response": "def get_serializer_class(self, **kwargs) -> Type[Serializer]:\n        \"\"\"\n        Return the class to use for the serializer.\n        Defaults to using `self.serializer_class`.\n\n        You may want to override this if you need to provide different\n        serializations depending on the incoming request.\n\n        (Eg. admins get full serialization, others get basic serialization)\n        \"\"\"\n        assert self.serializer_class is not None, (\n            \"'%s' should either include a `serializer_class` attribute, \"\n            \"or override the `get_serializer_class()` method.\"\n            % self.__class__.__name__\n        )\n\n        return self.serializer_class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view_as_consumer(\n        wrapped_view: typing.Callable[[HttpRequest], HttpResponse],\n        mapped_actions: typing.Optional[\n            typing.Dict[str, str]\n        ]=None) -> Type[AsyncConsumer]:\n    \"\"\"\n    Wrap a django View so that it will be triggered by actions over this json\n     websocket consumer.\n    \"\"\"\n    if mapped_actions is None:\n        mapped_actions = {\n            'create': 'PUT',\n            'update': 'PATCH',\n            'list': 'GET',\n            'retrieve': 'GET'\n        }\n\n    class DjangoViewWrapper(DjangoViewAsConsumer):\n        view = wrapped_view\n        actions = mapped_actions\n\n    return DjangoViewWrapper", "response": "Wrap a django View so that it will be triggered by actions over this json\n     websocket consumer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the action should be permitted. Raises an appropriate exception if the request is not permitted.", "response": "async def check_permissions(self, action: str, **kwargs):\n        \"\"\"\n        Check if the action should be permitted.\n        Raises an appropriate exception if the request is not permitted.\n        \"\"\"\n        for permission in await self.get_permissions(action=action, **kwargs):\n\n            if not await ensure_async(permission.has_permission)(\n                    scope=self.scope, consumer=self, action=action, **kwargs):\n                raise PermissionDenied()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle any exception that occurs by sending an appropriate message to the client.", "response": "async def handle_exception(self, exc: Exception, action: str, request_id):\n        \"\"\"\n        Handle any exception that occurs, by sending an appropriate message\n        \"\"\"\n        if isinstance(exc, APIException):\n            await self.reply(\n                action=action,\n                errors=self._format_errors(exc.detail),\n                status=exc.status_code,\n                request_id=request_id\n            )\n        elif exc == Http404 or isinstance(exc, Http404):\n            await self.reply(\n                action=action,\n                errors=self._format_errors('Not found'),\n                status=404,\n                request_id=request_id\n            )\n        else:\n            raise exc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def receive_json(self, content: typing.Dict, **kwargs):\n        # TODO assert format, if does not match return message.\n        request_id = content.pop('request_id')\n        action = content.pop('action')\n        await self.handle_action(action, request_id=request_id, **content)", "response": "Called with decoded JSON content."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks a method as an action.", "response": "def action(atomic=None, **kwargs):\n    \"\"\"\n    Mark a method as an action.\n    \"\"\"\n    def decorator(func):\n        if atomic is None:\n            _atomic = getattr(settings, 'ATOMIC_REQUESTS', False)\n        else:\n            _atomic = atomic\n\n        func.action = True\n        func.kwargs = kwargs\n        if asyncio.iscoroutinefunction(func):\n            if _atomic:\n                raise ValueError('Only synchronous actions can be atomic')\n            return func\n\n        if _atomic:\n            # wrap function in atomic wrapper\n            func = transaction.atomic(func)\n\n        @wraps(func)\n        async def async_f(self: AsyncAPIConsumer,\n                          *args, **_kwargs):\n\n            result, status = await database_sync_to_async(func)(\n                self, *args, **_kwargs\n            )\n\n            return result, status\n\n        async_f.action = True\n        async_f.kwargs = kwargs\n        async_f.__name__ = func.__name__\n\n        return async_f\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef datetime_parser(s):\n    try:\n        ts = arrow.get(s)\n        # Convert UTC to local, result of get is UTC unless it specifies timezone, bonfire assumes\n        # all time to be machine local\n        if ts.tzinfo == arrow.get().tzinfo:\n            ts = ts.replace(tzinfo='local')\n    except:\n        c = pdt.Calendar()\n        result, what = c.parse(s)\n\n        ts = None\n        if what in (1, 2, 3):\n            ts = datetime.datetime(*result[:6])\n\n            ts = arrow.get(ts)\n            ts = ts.replace(tzinfo='local')\n            return ts\n\n    if ts is None:\n        raise ValueError(\"Cannot parse timestamp '\" + s + \"'\")\n\n    return ts", "response": "Parse a timestamp s in local time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclosing the file if the file was opened by File.", "response": "def close(self, force=False) -> None:\n        \"\"\"\n        Closes the file if the file was opened by :class:`File`,\n        if not, this does nothing.\n\n        Parameters\n        ----------\n        force: bool\n            If set to :class:`True`, force close every file.\n\n        \"\"\"\n        self.fp.close = self._close\n        if self._manual_opened or force:\n            self.fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_title(self, title: str, url: str = None) -> None:\n        self.title = title\n        self.url = url", "response": "Sets the title of the embed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_timestamp(self, time: Union[str, datetime.datetime] = None,\n                      now: bool = False) -> None:\n        \"\"\"\n        Sets the timestamp of the embed.\n\n        Parameters\n        ----------\n        time: str or :class:`datetime.datetime`\n            The ``ISO 8601`` timestamp from the embed.\n\n        now: bool\n            Defaults to :class:`False`.\n            If set to :class:`True` the current time is used for the timestamp.\n\n        \"\"\"\n        if now:\n            self.timestamp = str(datetime.datetime.utcnow())\n        else:\n            self.timestamp = str(time)", "response": "Sets the timestamp of the embed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_field(self, name: str, value: str, inline: bool = True) -> None:\n        field = {\n            'name': name,\n            'value': value,\n            'inline': inline\n        }\n        self.fields.append(field)", "response": "Adds an embed field."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_author(self, name: str, icon_url: str = None, url: str = None) -> \\\n            None:\n        \"\"\"\n        Sets the author of the embed.\n\n        Parameters\n        ----------\n        name: str\n            The author's name.\n\n        icon_url: str, optional\n            URL for the author's icon.\n\n        url: str, optional\n            URL hyperlink for the author.\n\n        \"\"\"\n        self.author = {\n            'name': name,\n            'icon_url': icon_url,\n            'url': url\n        }", "response": "Sets the author of the embed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_footer(self, text: str, icon_url: str = None) -> None:\n        self.footer = {\n            'text': text,\n            'icon_url': icon_url\n        }", "response": "Sets the footer of the embed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self) -> dict:\n        return {\n            key: getattr(self, key)\n            for key in self.__slots__\n            if getattr(self, key) is not None\n        }", "response": "Turns the embed object into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the webhook channel when server starts.", "response": "async def init(app, loop):\n    \"\"\"Sends a message to the webhook channel when server starts.\"\"\"\n    app.session = aiohttp.ClientSession(loop=loop)  # to make web requests\n    app.webhook = Webhook.Async(webhook_url, session=app.session)\n\n    em = Embed(color=0x2ecc71)\n    em.set_author('[INFO] Starting Worker')\n    em.description = 'Host: {}'.format(socket.gethostname())\n\n    await app.webhook.send(embed=em)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def server_stop(app, loop):\n    em = Embed(color=0xe67e22)\n    em.set_footer('Host: {}'.format(socket.gethostname()))\n    em.description = '[INFO] Server Stopped'\n\n    await app.webhook.send(embed=em)\n    await app.session.close()", "response": "Sends a message to the webhook channel when server stops."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a message to the current user.", "response": "async def message(request):\n    \"\"\"\n    To send a message, go to 0.0.0.0:8000/message/?msg='insert message here'.\n    \"\"\"\n\n    msg = request.get('msg')\n    if msg is None:\n        return request.text(\"To send a message, go to 0.0.0.0:8000/\"\n                            \"message/?msg='insert message here'.\")\n    await app.webhook.send(msg)\n    return response.text(\"Send.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the deprecation warning message for the user.", "response": "def get_deprecated_msg(self, wrapped, instance):\n        \"\"\"\n        Get the deprecation warning message for the user.\n\n        :param wrapped: Wrapped class or function.\n\n        :param instance: The object to which the wrapped function was bound when it was called.\n\n        :return: The warning message.\n        \"\"\"\n        if instance is None:\n            if inspect.isclass(wrapped):\n                fmt = \"Call to deprecated class {name}.\"\n            else:\n                fmt = \"Call to deprecated function (or staticmethod) {name}.\"\n        else:\n            if inspect.isclass(instance):\n                fmt = \"Call to deprecated class method {name}.\"\n            else:\n                fmt = \"Call to deprecated method {name}.\"\n        if self.reason:\n            fmt += \" ({reason})\"\n        if self.version:\n            fmt += \" -- Deprecated since version {version}.\"\n        return fmt.format(name=wrapped.__name__,\n                          reason=self.reason or \"\",\n                          version=self.version or \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef better_print(self, printer=None):\n        printer = printer or pprint.pprint\n        printer(self.value)", "response": "Print the value using a printer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(varin, fname='MS2_L10.mat.txt'):\n    '''Read in dataset for variable var\n\n    :param varin: Variable for which to read in data.\n\n    '''\n\n    # # fname = 'MS09_L10.mat.txt'\n    # # fname = 'MS09_L05.mat.txt' # has PAR\n    # fname = 'MS2_L10.mat.txt' # empty PAR\n\n    d = np.loadtxt(fname, comments='*')\n\n    if fname == 'MS2_L10.mat.txt':\n        var = ['lat', 'lon', 'depth', 'temp', 'density', 'sigma', 'oxygen',\n               'voltage 2', 'voltage 3', 'fluorescence-CDOM', 'fluorescence-ECO',\n               'turbidity', 'pressure', 'salinity', 'RINKO temperature',\n               'RINKO DO - CTD temp', 'RINKO DO - RINKO temp', 'bottom', 'PAR']\n    elif (fname == 'MS09_L05.mat.txt') or (fname == 'MS09_L10.mat.txt') or (fname == 'MS08_L12.mat.txt'):\n        var = ['lat', 'lon', 'depth', 'temp', 'density', 'sigma', 'oxygen',\n               'voltage 2', 'voltage 3', 'voltage 4', 'fluorescence-CDOM', 'fluorescence-ECO',\n               'turbidity', 'pressure', 'salinity', 'RINKO temperature',\n               'RINKO DO - CTD temp', 'RINKO DO - RINKO temp', 'bottom', 'PAR']\n\n    # return data for variable varin\n    return d[:, 0], d[:, 1], d[:, 2], d[:, var.index(varin)]", "response": "Read in dataset for variable varin"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow a colormap for a chosen input variable var side by side with black and white and jet colormaps.", "response": "def show(cmap, var, vmin=None, vmax=None):\n    '''Show a colormap for a chosen input variable var side by side with\n    black and white and jet colormaps.\n\n    :param cmap: Colormap instance\n    :param var: Variable to plot.\n    :param vmin=None: Min plot value.\n    :param vmax=None: Max plot value.\n\n    '''\n\n    # get variable data\n    lat, lon, z, data = read(var)\n\n    fig = plt.figure(figsize=(16, 12))\n\n    # Plot with grayscale\n    ax = fig.add_subplot(3, 1, 1)\n    map1 = ax.scatter(lon, -z, c=data, cmap='gray', s=10, linewidths=0., vmin=vmin, vmax=vmax)\n    plt.colorbar(map1, ax=ax)\n\n    # Plot with jet\n    ax = fig.add_subplot(3, 1, 2)\n    map1 = ax.scatter(lon, -z, c=data, cmap='jet', s=10, linewidths=0., vmin=vmin, vmax=vmax)\n    plt.colorbar(map1, ax=ax)\n\n    # Plot with cmap\n    ax = fig.add_subplot(3, 1, 3)\n    map1 = ax.scatter(lon, -z, c=data, cmap=cmap, s=10, linewidths=0., vmin=vmin, vmax=vmax)\n    ax.set_xlabel('Longitude [degrees]')\n    ax.set_ylabel('Depth [m]')\n    plt.colorbar(map1, ax=ax)\n\n    plt.suptitle(var)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_data():\n    '''Plot sample data up with the fancy colormaps.\n\n    '''\n\n    var = ['temp', 'oxygen', 'salinity', 'fluorescence-ECO', 'density', 'PAR', 'turbidity', 'fluorescence-CDOM']\n    # colorbar limits for each property\n    lims = np.array([[26, 33], [0, 10], [0, 36], [0, 6], [1005, 1025], [0, 0.6], [0, 2], [0, 9]])  # reasonable values\n    # lims = np.array([[20,36], [26,33], [1.5,5.6], [0,4], [0,9], [0,1.5]]) # values to show colormaps\n\n    for fname in fnames:\n        fig, axes = plt.subplots(nrows=4, ncols=2)\n        fig.set_size_inches(20, 10)\n        fig.subplots_adjust(top=0.95, bottom=0.01, left=0.2, right=0.99, wspace=0.0, hspace=0.07)\n        i = 0\n        for ax, Var, cmap in zip(axes.flat, var, cmaps):  # loop through data to plot up\n\n            # get variable data\n            lat, lon, z, data = test.read(Var, fname)\n\n            map1 = ax.scatter(lat, -z, c=data, cmap=cmap, s=10, linewidths=0., vmin=lims[i, 0], vmax=lims[i, 1])\n            # no stupid offset\n            y_formatter = mpl.ticker.ScalarFormatter(useOffset=False)\n            ax.xaxis.set_major_formatter(y_formatter)\n            if i == 6:\n                ax.set_xlabel('Latitude [degrees]')\n                ax.set_ylabel('Depth [m]')\n            else:\n                ax.set_xticklabels([])\n                ax.set_yticklabels([])\n            ax.set_ylim(-z.max(), 0)\n            ax.set_xlim(lat.min(), lat.max())\n            cb = plt.colorbar(map1, ax=ax, pad=0.02)\n            cb.set_label(cmap.name + ' [' + '$' + cmap.units + '$]')\n            i += 1\n\n        fig.savefig('figures/' + fname.split('.')[0] + '.png', bbox_inches='tight')", "response": "Plot sample data up with the fancy colormaps.\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_lightness(saveplot=False):\n    '''Plot lightness of colormaps together.\n\n    '''\n\n    from colorspacious import cspace_converter\n\n    dc = 1.\n    x = np.linspace(0.0, 1.0, 256)\n    locs = []  # locations for text labels\n\n    fig = plt.figure(figsize=(16, 5))\n    ax = fig.add_subplot(111)\n    fig.subplots_adjust(left=0.03, right=0.97)\n    ax.set_xlim(-0.1, len(cm.cmap_d)/2. + 0.1)\n    ax.set_ylim(0, 100)\n    ax.set_xlabel('Lightness for each colormap', fontsize=14)\n\n    for j, cmapname in enumerate(cm.cmapnames):\n\n        if '_r' in cmapname:  # skip reversed versions for plot\n            continue\n\n        cmap = cm.cmap_d[cmapname]  # get the colormap instance\n        rgb = cmap(x)[np.newaxis, :, :3]\n        lab = cspace_converter(\"sRGB1\", \"CAM02-UCS\")(rgb)\n        L = lab[0, :, 0]\n        if L[-1] > L[0]:\n            ax.scatter(x+j*dc, L, c=x, cmap=cmap, s=200, linewidths=0.)\n        else:\n            ax.scatter(x+j*dc, L[::-1], c=x[::-1], cmap=cmap, s=200, linewidths=0.)\n        locs.append(x[-1]+j*dc)  # store locations for colormap labels\n\n    # Set up labels for colormaps\n    ax.xaxis.set_ticks_position('top')\n    ticker = mpl.ticker.FixedLocator(locs)\n    ax.xaxis.set_major_locator(ticker)\n    formatter = mpl.ticker.FixedFormatter([cmapname for cmapname in cm.cmapnames])\n    ax.xaxis.set_major_formatter(formatter)\n    labels = ax.get_xticklabels()\n    for label in labels:\n        label.set_rotation(60)\n\n    if saveplot:\n        fig.savefig('figures/lightness.png', bbox_inches='tight')\n        fig.savefig('figures/lightness.pdf', bbox_inches='tight')\n\n    plt.show()", "response": "Plot lightness of colormaps together."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a plot of colormaps and labels like in the matplotlib gallery.", "response": "def plot_gallery(saveplot=False):\n    '''Make plot of colormaps and labels, like in the matplotlib\n    gallery.\n\n    :param saveplot=False: Whether to save the plot or not.\n\n    '''\n\n    from colorspacious import cspace_converter\n\n    gradient = np.linspace(0, 1, 256)\n    gradient = np.vstack((gradient, gradient))\n    x = np.linspace(0.0, 1.0, 256)\n\n    fig, axes = plt.subplots(nrows=int(len(cm.cmap_d)/2), ncols=1, figsize=(6, 12))\n    fig.subplots_adjust(top=0.99, bottom=0.01, left=0.2, right=0.99, wspace=0.05)\n\n    for ax, cmapname in zip(axes, cm.cmapnames):\n\n        if '_r' in cmapname:  # skip reversed versions for plot\n            continue\n\n        cmap = cm.cmap_d[cmapname]  # get the colormap instance\n\n        rgb = cmap(x)[np.newaxis, :, :3]\n\n        # Find a good conversion to grayscale\n        jch = cspace_converter(\"sRGB1\", \"CAM02-UCS\")(rgb)  # Not sure why to use JCh instead so using this.\n        L = jch[0, :, 0]\n        L = np.float32(np.vstack((L, L, L)))\n\n        ax.imshow(gradient, aspect='auto', cmap=cmap)\n\n        pos1 = ax.get_position()  # get the original position\n        pos2 = [pos1.x0, pos1.y0,  pos1.width, pos1.height / 3.0]\n        axbw = fig.add_axes(pos2)  # colorbar axes\n        axbw.set_axis_off()\n        axbw.imshow(L, aspect='auto', cmap=cm.gray, vmin=0, vmax=100.)\n        pos = list(ax.get_position().bounds)\n        x_text = pos[0] - 0.01\n        y_text = pos[1] + pos[3]/2.\n        fig.text(x_text, y_text, cmap.name, va='center', ha='right')\n\n    # Turn off *all* ticks & spines, not just the ones with colormaps.\n    for ax in axes:\n        ax.set_axis_off()\n\n    if saveplot:\n        fig.savefig('figures/gallery.pdf', bbox_inches='tight')\n        fig.savefig('figures/gallery.png', bbox_inches='tight')\n\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate goodness of colormap using perceptual deltas.", "response": "def wrap_viscm(cmap, dpi=100, saveplot=False):\n    '''Evaluate goodness of colormap using perceptual deltas.\n\n    :param cmap: Colormap instance.\n    :param dpi=100: dpi for saved image.\n    :param saveplot=False: Whether to save the plot or not.\n\n    '''\n\n    from viscm import viscm\n\n    viscm(cmap)\n    fig = plt.gcf()\n    fig.set_size_inches(22, 10)\n    plt.show()\n\n    if saveplot:\n        fig.savefig('figures/eval_' + cmap.name + '.png', bbox_inches='tight', dpi=dpi)\n        fig.savefig('figures/eval_' + cmap.name + '.pdf', bbox_inches='tight', dpi=dpi)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef quick_plot(cmap, fname=None, fig=None, ax=None, N=10):\n    '''Show quick test of a colormap.\n\n    '''\n\n    x = np.linspace(0, 10, N)\n    X, _ = np.meshgrid(x, x)\n\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n    mappable = ax.pcolor(X, cmap=cmap)\n    ax.set_title(cmap.name, fontsize=14)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.colorbar(mappable)\n    plt.show()\n\n    if fname is not None:\n        plt.savefig(fname + '.png', bbox_inches='tight')", "response": "Show quick test of a colormap."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting colormaps in 256 RGB colors to text files.", "response": "def print_colormaps(cmaps, N=256, returnrgb=True, savefiles=False):\n    '''Print colormaps in 256 RGB colors to text files.\n\n    :param returnrgb=False: Whether or not to return the rgb array. Only makes sense to do if print one colormaps' rgb.\n\n    '''\n\n    rgb = []\n\n    for cmap in cmaps:\n\n        rgbtemp = cmap(np.linspace(0, 1, N))[np.newaxis, :, :3][0]\n        if savefiles:\n            np.savetxt(cmap.name + '-rgb.txt', rgbtemp)\n        rgb.append(rgbtemp)\n\n    if returnrgb:\n        return rgb"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dict(cmap, N=256):\n    '''Change from rgb to dictionary that LinearSegmentedColormap expects.\n    Code from https://mycarta.wordpress.com/2014/04/25/convert-color-palettes-to-python-matplotlib-colormaps/\n    and http://nbviewer.ipython.org/github/kwinkunks/notebooks/blob/master/Matteo_colourmaps.ipynb\n    '''\n\n    x = np.linspace(0, 1, N)  # position of sample n - ranges from 0 to 1\n\n    rgb = cmap(x)\n\n    # flip colormap to follow matplotlib standard\n    if rgb[0, :].sum() < rgb[-1, :].sum():\n        rgb = np.flipud(rgb)\n\n    b3 = rgb[:, 2]  # value of blue at sample n\n    b2 = rgb[:, 2]  # value of blue at sample n\n\n    # Setting up columns for tuples\n    g3 = rgb[:, 1]\n    g2 = rgb[:, 1]\n\n    r3 = rgb[:, 0]\n    r2 = rgb[:, 0]\n\n    # Creating tuples\n    R = list(zip(x, r2, r3))\n    G = list(zip(x, g2, g3))\n    B = list(zip(x, b2, b3))\n\n    # Creating dictionary\n    k = ['red', 'green', 'blue']\n    LinearL = dict(zip(k, [R, G, B]))\n\n    return LinearL", "response": "Change from rgb to dictionary that LinearSegmentedColormap expects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a colormap from an array of rgb values.", "response": "def cmap(rgbin, N=256):\n    '''Input an array of rgb values to generate a colormap.\n\n    :param rgbin: An [mx3] array, where m is the number of input color triplets which\n         are interpolated between to make the colormap that is returned. hex values\n         can be input instead, as [mx1] in single quotes with a #.\n    :param N=10: The number of levels to be interpolated to.\n\n    '''\n\n    # rgb inputs here\n    if not isinstance(rgbin[0], _string_types):\n        # normalize to be out of 1 if out of 256 instead\n        if rgbin.max() > 1:\n            rgbin = rgbin/256.\n\n    cmap = mpl.colors.LinearSegmentedColormap.from_list('mycmap', rgbin, N=N)\n\n    return cmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlightens a colormap by adding alpha < 1.", "response": "def lighten(cmapin, alpha):\n    '''Lighten a colormap by adding alpha < 1.\n\n    :param cmap: A colormap object, like cmocean.cm.matter.\n    :param alpha: An alpha or transparency value to assign the colormap. Alpha\n        of 1 is opaque and of 1 is fully transparent.\n\n    Outputs resultant colormap object.\n\n    This will lighten the appearance of a plot you make using the output\n        colormap object. It is also possible to lighten many plots in the\n        plotting function itself (e.g. pcolormesh or contourf).\n    '''\n\n    # set the alpha value while retaining the number of rows in original cmap\n    return cmap(cmapin(np.linspace(0,1,cmapin.N), alpha))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncrop end or end of a diverging colormap by vmin vmax pivot.", "response": "def crop(cmapin, vmin, vmax, pivot, N=None, dmax=None):\n    '''Crop end or ends of a diverging colormap by vmin/vmax values.\n\n    :param cmap: A colormap object, like cmocean.cm.matter.\n    :param vmin/vmax: vmin/vmax for use in plot with colormap.\n    :param pivot: center point to be used in plot with diverging colormap.\n    :param N=None: User can specify the number of rows for the outgoing colormap.\n        If unspecified, N from incoming colormap will be used and values will\n        be interpolated as needed to fill in rows.\n    :param dmax=None: dmax is the highest number to be included in a plot with\n        the colormap; values higher in magnitude than dmax are removed from both\n        ends of colormap. It should be less than abs(vmin) and abs(vmax), which\n        should be equal for this parameter to be used.\n\n    Outputs resultant colormap object.\n\n    This function can be used for sequential and other non-diverging colormaps\n        but it is easier to use that way through crop_by_percent().\n    This should be useful for plotting bathymetry and topography data with the\n        topo colormap when max bathymetry value is different from max topography.\n\n    Example usage:\n        # example for crop on min end of diverging colormap\n        vmin = -2; vmax = 5; pivot = 0\n        newcmap = crop(cmocean.cm.curl, vmin, vmax, pivot)\n        A = np.random.randint(vmin, vmax, (5,5))\n        plt.pcolormesh(A, vmin=vmin, vmax=vmax, cmap=newcmap)\n        plt.colorbar()\n\n        # example for crop on max end of diverging colormap\n        vmin = -10; vmax = 8; pivot = 0\n        newcmap = crop(cmocean.cm.delta, vmin, vmax, pivot)\n        A = np.random.randint(vmin, vmax, (5,5))\n        plt.pcolormesh(A, vmin=vmin, vmax=vmax, cmap=newcmap)\n        plt.colorbar()\n\n    '''\n\n    assert pivot >= vmin and pivot <= vmax\n\n    # dmax used if and only if ends are equal\n    if vmax-pivot == pivot-vmin:\n        assert dmax is not None\n\n    # allow user to input N, but otherwise use N for incoming colormap\n    if N is None:\n        N = cmapin.N\n    else:\n        N = N\n\n    # ratio of the colormap to remove\n    below = pivot - vmin  # below pivot\n    above = vmax - pivot  # above pivot\n\n    ranges = (above, below)\n    half_range = max(ranges)\n    full_range = half_range*2\n    reduced_range = min(ranges)\n    range_to_keep = half_range + reduced_range\n\n    ratio = (full_range-range_to_keep)/full_range\n\n\n    if below < above:  # reducing colormap on side below pivot\n        # start colormap partway through\n        shortcmap = cmapin(np.linspace(0,1,N))[int(np.ceil(N*ratio)):]\n\n    elif above < below:  # reducing colormap on side above pivot\n        # end colormap early\n        shortcmap = cmapin(np.linspace(0,1,N))[:-int(np.ceil(N*ratio))]\n\n    elif (below == above) and (dmax is not None):  # equal\n        ratio = dmax/full_range\n        shortcmap = cmapin(np.linspace(0,1,N))[int(np.ceil(N*ratio)):-int(np.ceil(N*ratio))]\n\n    # interpolate to original number of rows in colormap\n    newrgb = np.zeros((N, 4))\n    shnum = shortcmap.shape[0]\n    for i in range(4):  # loop through each column of cmap\n        newrgb[:,i] = np.interp(np.linspace(0,shnum,N), np.arange(0,shnum), shortcmap[:,i])\n\n    newcmap = cmap(newrgb)\n\n    return newcmap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef crop_by_percent(cmap, per, which='both', N=None):\n    '''Crop end or ends of a colormap by per percent.\n\n    :param cmap: A colormap object, like cmocean.cm.matter.\n    :param per: Percent of colormap to remove. If which=='both', take this\n        percent off both ends of colormap. If which=='min' or which=='max',\n        take percent only off the specified end of colormap.\n    :param which='both': which end or ends of colormap to cut off. which='both'\n        removes from both ends, which='min' from bottom end, and which='max'\n        from top end.\n    :param N=None: User can specify the number of rows for the outgoing colormap.\n        If unspecified, N from incoming colormap will be used and values will\n        be interpolated as needed to fill in rows.\n\n    Outputs resultant colormap object.\n\n    This is a wrapper around crop() to make it easier to use for cropping\n        based on percent.\n\n    Examples:\n        # example with oxy map: cut off yellow part which is top 20%\n        # compare with full colormap\n        vmin = 0; vmax = 10; pivot = 5\n        A = np.random.randint(vmin, vmax, (5,5))\n        fig, axes = plt.subplots(1, 2)\n        mappable = axes[0].pcolormesh(A, vmin=vmin, vmax=vmax, cmap=cmocean.cm.oxy)\n        fig.colorbar(mappable, ax=axes[0])\n        vmin = 0; vmax = 8; pivot = 5\n        newcmap = crop_by_percent(cmocean.cm.oxy, 20, which='max', N=None)\n        plt.figure()\n        plt.pcolormesh(A, vmin=vmin, vmax=vmax, cmap=newcmap)\n        plt.colorbar()\n\n        # example with oxy map: cut off red part which is bottom 20%\n        # compare with full colormap\n        vmin = 0; vmax = 10; pivot = 5\n        A = np.random.randint(vmin, vmax, (5,5))\n        fig, axes = plt.subplots(1, 2)\n        mappable = axes[0].pcolormesh(A, vmin=vmin, vmax=vmax, cmap=cmocean.cm.oxy)\n        fig.colorbar(mappable, ax=axes[0])\n        vmin = 2; vmax = 10; pivot = 5\n        A = np.random.randint(vmin, vmax, (5,5))\n        newcmap = crop_by_percent(cmocean.cm.oxy, 20, which='min', N=None)\n        plt.figure()\n        plt.pcolormesh(A, vmin=vmin, vmax=vmax, cmap=newcmap)\n        plt.colorbar()\n\n        # crop both dark ends off colormap to reduce range\n        newcmap = crop_by_percent(cmocean.cm.balance, 10, which='both', N=None)\n        plt.figure()\n        A = np.random.randint(-5, 5, (5,5))\n        plt.pcolormesh(A, vmin=vmin, vmax=vmax, cmap=newcmap)\n        plt.colorbar()\n\n    '''\n\n    if which == 'both':  # take percent off both ends of cmap\n        vmin = -100; vmax = 100; pivot = 0\n        dmax = per\n\n    elif which == 'min':  # take percent off bottom of cmap\n        vmax = 10; pivot = 5\n        vmin = (0 + per/100)*2*pivot\n        dmax = None\n\n    elif which == 'max':  # take percent off top of cmap\n        vmin = 0; pivot = 5\n        vmax = (1 - per/100)*2*pivot\n        dmax = None\n\n    newcmap = crop(cmap, vmin, vmax, pivot, dmax=dmax, N=N)\n\n    return newcmap", "response": "Crop end or ends of a colormap by percent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _premium(fn):\n        @_functools.wraps(fn)\n        def _fn(self, *args, **kwargs):\n            if self._lite:\n                raise RuntimeError('Premium API not available in lite access.')\n            return fn(self, *args, **kwargs)\n        return _fn", "response": "Decorator for APIs that require premium access level."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate retrieve parameters dictionary to be used with API Gateway.", "response": "def make_retrieveParameters(offset=1, count=100, name='RS', sort='D'):\n        \"\"\"Create retrieve parameters dictionary to be used with APIs.\n\n        :count: Number of records to display in the result. Cannot be less than\n                0 and cannot be greater than 100. If count is 0 then only the\n                summary information will be returned.\n\n        :offset: First record in results to return. Must be greater than zero\n\n        :name: Name of the field to order by. Use a two-character abbreviation\n               to specify the field ('AU': Author, 'CF': Conference Title,\n               'CG': Page, 'CW': Source, 'CV': Volume, 'LC': Local Times Cited,\n               'LD': Load Date, 'PG': Page, 'PY': Publication Year, 'RS':\n               Relevance, 'SO': Source, 'TC': Times Cited, 'VL': Volume)\n\n        :sort: Must be A (ascending) or D (descending). The sort parameter can\n               only be D for Relevance and TimesCited.\n        \"\"\"\n        return _OrderedDict([\n            ('firstRecord', offset),\n            ('count', count),\n            ('sortField', _OrderedDict([('name', name), ('sort', sort)]))\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nauthenticate to WOS and set the SID cookie.", "response": "def connect(self):\n        \"\"\"Authenticate to WOS and set the SID cookie.\"\"\"\n        if not self._SID:\n            self._SID = self._auth.service.authenticate()\n            print('Authenticated (SID: %s)' % self._SID)\n\n        self._search.set_options(headers={'Cookie': 'SID=\"%s\"' % self._SID})\n        self._auth.options.headers.update({'Cookie': 'SID=\"%s\"' % self._SID})\n        return self._SID"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if self._SID:\n            self._auth.service.closeSession()\n            self._SID = None", "response": "The close operation loads the session if it is valid and releases the session seat."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, query, count=5, offset=1, editions=None,\n               symbolicTimeSpan=None, timeSpan=None, retrieveParameters=None):\n        \"\"\"The search operation submits a search query to the specified\n        database edition and retrieves data. This operation returns a query ID\n        that can be used in subsequent operations to retrieve more records.\n\n        :query: User query for requesting data. The query parser will return\n                errors for invalid queries\n\n        :count: Number of records to display in the result. Cannot be less than\n                0 and cannot be greater than 100. If count is 0 then only the\n                summary information will be returned.\n\n        :offset: First record in results to return. Must be greater than zero\n\n        :editions: List of editions to be searched. If None, user permissions\n                   will be substituted.\n\n                   Fields:\n                   collection - Name of the collection\n                   edition - Name of the edition\n\n        :symbolicTimeSpan: This element defines a range of load dates. The load\n                           date is the date when a record was added to a\n                           database. If symbolicTimeSpan is specified, the\n                           timeSpan parameter must be omitted.  If timeSpan and\n                           symbolicTimeSpan are both omitted, then the maximum\n                           publication date time span will be inferred from the\n                           editions data.\n\n                           Valid values:\n                           '1week' - Specifies to use the end date as today and\n                                     the begin date as 1 week prior to today.\n                           '2week' - Specifies to use the end date as today and\n                                     the begin date as 2 week prior to today.\n                           '4week' - Specifies to use the end date as today and\n                                     the begin date as 4 week prior to today.\n\n        :timeSpan: This element defines specifies a range of publication dates.\n                   If timeSpan is used, the symbolicTimeSpan parameter must be\n                   omitted. If timeSpan and symbolicTimeSpan are both omitted,\n                   then the maximum time span will be inferred from the\n                   editions data.\n\n                   Fields:\n                   begin - Beginning date for this search. Format: YYYY-MM-DD\n                   end - Ending date for this search. Format: YYYY-MM-DD\n\n        :retrieveParameters: Retrieve parameters. If omitted the result of\n                             make_retrieveParameters(offset, count, 'RS', 'D')\n                             is used.\n        \"\"\"\n        return self._search.service.search(\n            queryParameters=_OrderedDict([\n                ('databaseId', 'WOS'),\n                ('userQuery', query),\n                ('editions', editions),\n                ('symbolicTimeSpan', symbolicTimeSpan),\n                ('timeSpan', timeSpan),\n                ('queryLanguage', 'en')\n            ]),\n            retrieveParameters=(retrieveParameters or\n                                self.make_retrieveParameters(offset, count))\n        )", "response": "This method submits a search query to the specified ID\n        database edition and retrieves more records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef citingArticles(self, uid, count=100, offset=1, editions=None,\n                       timeSpan=None, retrieveParameters=None):\n        \"\"\"The citingArticles operation finds citing articles for the article\n        specified by unique identifier. You may specify only one identifier per\n        request. Web of Science Core Collection (WOS) is the only valid\n        database for this operation.\n\n        :uid: A unique item identifier. It cannot be None or empty string.\n\n        :count: Number of records to display in the result. Cannot be less than\n                0 and cannot be greater than 100. If count is 0 then only the\n                summary information will be returned.\n\n        :offset: First record in results to return. Must be greater than zero\n\n        :editions: List of editions to be searched. If None, user permissions\n                   will be substituted.\n\n                   Fields:\n                   collection - Name of the collection\n                   edition - Name of the edition\n\n        :timeSpan: This element defines specifies a range of publication dates.\n                   If timeSpan is null, then the maximum time span will be\n                   inferred from the editions data.\n\n                   Fields:\n                   begin - Beginning date for this search. Format: YYYY-MM-DD\n                   end - Ending date for this search. Format: YYYY-MM-DD\n\n        :retrieveParameters: Retrieve parameters. If omitted the result of\n                             make_retrieveParameters(offset, count, 'RS', 'D')\n                             is used.\n        \"\"\"\n        return self._search.service.citingArticles(\n            databaseId='WOS',\n            uid=uid,\n            editions=editions,\n            timeSpan=timeSpan,\n            queryLanguage='en',\n            retrieveParameters=(retrieveParameters or\n                                self.make_retrieveParameters(offset, count))\n        )", "response": "The citingArticles operation returns a list of citing articles for the article with the specified unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform a single Web of Science query and then XML query the results.", "response": "def single(wosclient, wos_query, xml_query=None, count=5, offset=1):\n    \"\"\"Perform a single Web of Science query and then XML query the results.\"\"\"\n    result = wosclient.search(wos_query, count, offset)\n    xml = _re.sub(' xmlns=\"[^\"]+\"', '', result.records, count=1).encode('utf-8')\n    if xml_query:\n        xml = _ET.fromstring(xml)\n        return [el.text for el in xml.findall(xml_query)]\n    else:\n        return _minidom.parseString(xml).toprettyxml()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query(wosclient, wos_query, xml_query=None, count=5, offset=1, limit=100):\n    results = [single(wosclient, wos_query, xml_query, min(limit, count-x+1), x)\n               for x in range(offset, count+1, limit)]\n    if xml_query:\n        return [el for res in results for el in res]\n    else:\n        pattern = _re.compile(r'^<\\?xml.*?\\n<records>\\n|\\n</records>$.*')\n        return ('<?xml version=\"1.0\" ?>\\n<records>' +\n                '\\n'.join(pattern.sub('', res) for res in results) +\n                '</records>')", "response": "Query Web of Science and XML query results with multiple requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doi_to_wos(wosclient, doi):\n    results = query(wosclient, 'DO=\"%s\"' % doi, './REC/UID', count=1)\n    return results[0].lstrip('WOS:') if results else None", "response": "Convert DOI to WOS identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimplifying a query taking away exact values and fields selected.", "response": "def sql_fingerprint(query, hide_columns=True):\n    \"\"\"\n    Simplify a query, taking away exact values and fields selected.\n\n    Imperfect but better than super explicit, value-dependent queries.\n    \"\"\"\n    parsed_query = parse(query)[0]\n    sql_recursively_simplify(parsed_query, hide_columns=hide_columns)\n    return str(parsed_query)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_keyword(token, keywords):\n    if not token:\n        return False\n    if not token.is_keyword:\n        return False\n\n    return token.value.upper() in keywords", "response": "Checks if the given token represents one of the given keywords"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_group(token):\n    is_group = token.is_group\n    if isinstance(is_group, bool):\n        return is_group\n    else:\n        return is_group()", "response": "Returns a bool property if the token is a group"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning up a key so that tests aren t affected by random variables.", "response": "def clean_key(cls, key):\n        \"\"\"\n        Replace things that look like variables with a '#' so tests aren't affected by random variables\n        \"\"\"\n        for var_re in cls.VARIABLE_RES:\n            key = var_re.sub('#', key)\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sorted_names(names):\n    names = list(names)\n\n    have_default = False\n    if 'default' in names:\n        names.remove('default')\n        have_default = True\n\n    sorted_names = sorted(names)\n\n    if have_default:\n        sorted_names = ['default'] + sorted_names\n\n    return sorted_names", "response": "Sort a list of names but keep the word default first if it s there."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a human - readable diff of two performance records.", "response": "def record_diff(old, new):\n    \"\"\"\n    Generate a human-readable diff of two performance records.\n    \"\"\"\n    return '\\n'.join(difflib.ndiff(\n        ['%s: %s' % (k, v) for op in old for k, v in op.items()],\n        ['%s: %s' % (k, v) for op in new for k, v in op.items()],\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dequeue(self, block=True):\n        return self.queue.get(block, self.queue_get_timeout)", "response": "Dequeue a record and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the listener. This starts up a background thread to monitor the queue for items to process.", "response": "def start(self):\n        \"\"\"Start the listener.\n\n        This starts up a background thread to monitor the queue for\n        items to process.\n        \"\"\"\n        self._thread = t = threading.Thread(target=self._monitor)\n        t.setDaemon(True)\n        t.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(self, record):\n        record = self.prepare(record)\n        for handler in self.handlers:\n            handler(record)", "response": "Handle an item.\n\n        This just loops through the handlers offering them the record\n        to handle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _monitor(self):\n        err_msg = (\"invalid internal state:\"\n                   \" _stop_nowait can not be set if _stop is not set\")\n        assert self._stop.isSet() or not self._stop_nowait.isSet(), err_msg\n\n        q = self.queue\n        has_task_done = hasattr(q, 'task_done')\n        while not self._stop.isSet():\n            try:\n                record = self.dequeue(True)\n                if record is self._sentinel_item:\n                    break\n                self.handle(record)\n                if has_task_done:\n                    q.task_done()\n            except queue.Empty:\n                pass\n\n        # There might still be records in the queue,\n        # handle then unless _stop_nowait is set.\n        while not self._stop_nowait.isSet():\n            try:\n                record = self.dequeue(False)\n                if record is self._sentinel_item:\n                    break\n                self.handle(record)\n                if has_task_done:\n                    q.task_done()\n            except queue.Empty:\n                break", "response": "Monitor the queue for items and ask the handler to deal with them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self, nowait=False):\n        self._stop.set()\n        if nowait:\n            self._stop_nowait.set()\n        self.queue.put_nowait(self._sentinel_item)\n        if (self._thread.isAlive() and\n                self._thread is not threading.currentThread()):\n            self._thread.join()\n        self._thread = None", "response": "Stop the listener.\n\n        This asks the thread to terminate, and then waits for it to do so.\n        Note that if you don't call this before your application exits, there\n        may be some records still left on the queue, which won't be processed.\n        If nowait is False then thread will handle remaining items in queue and\n        stop.\n        If nowait is True then thread will be stopped even if the queue still\n        contains items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef terminate(self, nowait=False):\n        logger.debug(\"Acquiring lock for service termination\")\n        with self.lock:\n            logger.debug(\"Terminating service\")\n\n            if not self.listener:\n                logger.warning(\"Service already stopped.\")\n                return\n\n            self.listener.stop(nowait)\n\n            try:\n                if not nowait:\n                    self._post_log_batch()\n            except Exception:\n                if self.error_handler:\n                    self.error_handler(sys.exc_info())\n                else:\n                    raise\n            finally:\n                self.queue = None\n                self.listener = None", "response": "Finalize and stop the service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_log(self, **log_item):\n        logger.debug(\"Processing log item: %s\", log_item)\n        self.log_batch.append(log_item)\n        if len(self.log_batch) >= self.log_batch_size:\n            self._post_log_batch()", "response": "Process incoming log messages and post them in batch."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by queue listener.", "response": "def process_item(self, item):\n        \"\"\"Main item handler.\n\n        Called by queue listener.\n        \"\"\"\n        logger.debug(\"Processing item: %s (queue size: %s)\", item,\n                     self.queue.qsize())\n        method, kwargs = item\n\n        if method not in self.supported_methods:\n            raise Error(\"Not expected service method: {}\".format(method))\n\n        try:\n            if method == \"log\":\n                self.process_log(**kwargs)\n            else:\n                self._post_log_batch()\n                getattr(self.rp_client, method)(**kwargs)\n        except Exception:\n            if self.error_handler:\n                self.error_handler(sys.exc_info())\n            else:\n                self.terminate(nowait=True)\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a message with attachment.", "response": "def log(self, time, message, level=None, attachment=None):\n        \"\"\"Logs a message with attachment.\n\n        The attachment is a dict of:\n            name: name of attachment\n            data: file content\n            mime: content type for attachment\n        \"\"\"\n        logger.debug(\"log queued\")\n\n        args = {\n            \"time\": time,\n            \"message\": message,\n            \"level\": level,\n            \"attachment\": attachment,\n        }\n        self.queue.put_nowait((\"log\", args))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_batch(self, log_data):\n\n        url = uri_join(self.base_url, \"log\")\n\n        attachments = []\n        for log_item in log_data:\n            log_item[\"item_id\"] = self.stack[-1]\n            attachment = log_item.get(\"attachment\", None)\n\n            if \"attachment\" in log_item:\n                del log_item[\"attachment\"]\n\n            if attachment:\n                if not isinstance(attachment, collections.Mapping):\n                    attachment = {\"data\": attachment}\n\n                name = attachment.get(\"name\", str(uuid.uuid4()))\n                log_item[\"file\"] = {\"name\": name}\n                attachments.append((\"file\", (\n                    name,\n                    attachment[\"data\"],\n                    attachment.get(\"mime\", \"application/octet-stream\")\n                )))\n\n        files = [(\n            \"json_request_part\", (\n                None,\n                json.dumps(log_data),\n                \"application/json\"\n            )\n        )]\n        files.extend(attachments)\n        from reportportal_client import POST_LOGBATCH_RETRY_COUNT\n        for i in range(POST_LOGBATCH_RETRY_COUNT):\n            try:\n                r = self.session.post(\n                    url=url,\n                    files=files,\n                    verify=self.verify_ssl\n                )\n            except KeyError:\n                if i < POST_LOGBATCH_RETRY_COUNT - 1:\n                    continue\n                else:\n                    raise\n            break\n\n        logger.debug(\"log_batch - Stack: %s\", self.stack)\n        logger.debug(\"log_batch response: %s\", r.text)\n\n        return _get_data(r)", "response": "Logs batch of messages with attachment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting version information from git keywords.", "response": "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = set([r for r in refs if re.search(r'\\d', r)])\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None,\n                    \"date\": date, \"branch\": None}\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\", \"date\": None,\n            \"branch\": None}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a branch based version of the current project.", "response": "def render_pep440_branch_based(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.BRANCH_gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.BRANCH_gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.BRANCH_gHEX[.dirty]\n    \"\"\"\n    replacements = ([' ', '.'], ['(', ''], [')', ''], ['\\\\', '.'], ['/', '.'])\n    branch_name = pieces.get('branch') or ''\n    if branch_name:\n        for old, new in replacements:\n            branch_name = branch_name.replace(old, new)\n    else:\n        branch_name = 'unknown_branch'\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += '.dev0' + plus_or_dot(pieces)\n            rendered += \"%d.%s.g%s\" % (\n                pieces[\"distance\"],\n                branch_name,\n                pieces['short']\n            )\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.%s.g%s\" % (\n            pieces[\"distance\"],\n            branch_name,\n            pieces['short']\n        )\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"pep440-branch-based\":\n        rendered = render_pep440_branch_based(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None,\n            \"date\": pieces.get(\"date\")}", "response": "Render the given version pieces into the requested style."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes main VCS - independent setup function for installing Versioneer.", "response": "def do_setup():\n    \"\"\"Do main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\",\n                  file=sys.stderr)\n            with open(os.path.join(root, \"setup.cfg\"), \"a\") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print(\" creating %s\" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, \"w\") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {\"DOLLAR\": \"$\",\n                        \"STYLE\": cfg.style,\n                        \"TAG_PREFIX\": cfg.tag_prefix,\n                        \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                        \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       \"__init__.py\")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, \"r\") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = \"\"\n        if INIT_PY_SNIPPET_RE.search(old) is None:\n            print(\" appending to %s\" % ipy)\n            with open(ipy, \"a\") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print(\" %s unmodified\" % ipy)\n    else:\n        print(\" %s doesn't exist, ok\" % ipy)\n        ipy = None\n\n    # Make sure both the top-level \"versioneer.py\" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they'll be copied into source distributions. Pip won't be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, \"MANIFEST.in\")\n    simple_includes = set()\n    try:\n        with open(manifest_in, \"r\") as f:\n            for line in f:\n                if line.startswith(\"include \"):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn't cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant 'include'\n    # lines is safe, though.\n    if \"versioneer.py\" not in simple_includes:\n        print(\" appending 'versioneer.py' to MANIFEST.in\")\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include versioneer.py\\n\")\n    else:\n        print(\" 'versioneer.py' already in MANIFEST.in\")\n    if cfg.versionfile_source not in simple_includes:\n        print(\" appending versionfile_source ('%s') to MANIFEST.in\" %\n              cfg.versionfile_source)\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include %s\\n\" % cfg.versionfile_source)\n    else:\n        print(\" versionfile_source already in MANIFEST.in\")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the contents of setup. py against Versioneer s expectations.", "response": "def scan_setup_py():\n    \"\"\"Validate the contents of setup.py against Versioneer's expectations.\"\"\"\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass(\" in line:\n                found.add(\"cmdclass\")\n            if \"versioneer.get_version()\" in line:\n                found.add(\"get_version\")\n            if \"versioneer.VCS\" in line:\n                setters = True\n            if \"versioneer.versionfile_source\" in line:\n                setters = True\n    if len(found) != 3:\n        print(\"\")\n        print(\"Your setup.py appears to be missing some important items\")\n        print(\"(but I might be wrong). Please make sure it has something\")\n        print(\"roughly like the following:\")\n        print(\"\")\n        print(\" import versioneer\")\n        print(\" setup( version=versioneer.get_version(),\")\n        print(\"        cmdclass=versioneer.get_cmdclass(),  ...)\")\n        print(\"\")\n        errors += 1\n    if setters:\n        print(\"You should remove lines like 'versioneer.VCS = ' and\")\n        print(\"'versioneer.versionfile_source = ' . This configuration\")\n        print(\"now lives in setup.cfg, and should be removed from setup.py\")\n        print(\"\")\n        errors += 1\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(fname):\n    '''\n    Read a file from the directory where setup.py resides\n    '''\n    file_path = os.path.join(SETUP_DIRNAME, fname)\n    with codecs.open(file_path, encoding='utf-8') as rfh:\n        return rfh.read()", "response": "Read a file from the directory where setup. py resides\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, X, y, X_val=None, y_val=None):\n        y = y.reshape((len(y), 1))\n\n        if sparse.issparse(X):\n            X = X.tocsr()\n\n        if X_val is not None:\n            n_val = len(y_val)\n            y_val = y_val.reshape((n_val, 1))\n\n        # Set initial weights randomly.\n        self.i = X.shape[1]\n        self.l1 = self.l1 / self.i\n        self.w = (np.random.rand((self.i + 2) * self.h + 1) - .5) * 1e-6\n        self.w_opt = self.w\n        self.n_opt = 0\n\n        logger.info('training ...')\n        n_obs = X.shape[0]\n        batch = self.b\n        n_epoch = self.n\n        idx = range(n_obs)\n        self.auc_opt = .5\n\n        start = time.time()\n        print('\\tEPOCH TRAIN     VALID     BEST      TIME (m)')\n        print('\\t--------------------------------------------')\n\n        # Before training\n        p = self.predict_raw(X)\n        auc = roc_auc_score(y, p)\n        auc_val = auc\n        if X_val is not None:\n            p_val = self.predict_raw(X_val)\n            auc_val = roc_auc_score(y_val, p_val)\n\n        print('\\t{:3d}:  {:.6f}  {:.6f}  {:.6f}  {:.2f}'.format(\n              0, auc, auc_val, self.auc_opt,\n              (time.time() - start) / SEC_PER_MIN))\n     \n        # Use 'while' instead of 'for' to increase n_epoch if the validation\n        # error keeps improving at the end of n_epoch \n        epoch = 1\n        while epoch <= n_epoch:\n            # Shuffle inputs every epoch - it helps avoiding the local optimum\n            # when batch < n_obs.\n            np.random.shuffle(idx)\n\n            # Find the optimal weights for batch input examples.\n            # If batch == 1, it's the stochastic optimization, which is slow\n            # but uses minimal memory.  If batch == n_obs, it's the batch\n            # optimization, which is fast but uses maximum memory.\n            # Otherwise, it's the mini-batch optimization, which balances the\n            # speed and space trade-offs.\n            for i in range(int(n_obs / batch) + 1):\n                if (i + 1) * batch > n_obs:\n                    sub_idx = idx[batch * i:n_obs]\n                else:\n                    sub_idx = idx[batch * i:batch * (i + 1)]\n\n                x = X[sub_idx]\n                neg_idx = [n_idx for n_idx, n_y in enumerate(y[sub_idx]) if n_y == 0.]\n                pos_idx = [p_idx for p_idx, p_y in enumerate(y[sub_idx]) if p_y == 1.]\n                x0 = x[neg_idx]\n                x1 = x[pos_idx]\n                # Update weights to minimize the cost function using the\n                # quasi-Newton method (L-BFGS-B), where:\n                #   func -- cost function\n                #   jac -- jacobian (derivative of the cost function)\n                #   maxiter -- number of iterations for L-BFGS-B\n                ret = minimize(self.func,\n                               self.w,\n                               args=(x0, x1),\n                               method='L-BFGS-B',\n                               jac=self.fprime,\n                               options={'maxiter': 5})\n                self.w = ret.x\n\n            p = self.predict_raw(X)\n            auc = roc_auc_score(y, p)\n            auc_val = auc\n\n            if X_val is not None:\n                p_val = self.predict_raw(X_val)\n                auc_val = roc_auc_score(y_val, p_val)\n\n                if auc_val > self.auc_opt:\n                    self.auc_opt = auc_val\n                    self.w_opt = self.w\n                    self.n_opt = epoch\n\n                    # If validation auc is still improving after n_epoch,\n                    # try 10 more epochs\n                    if epoch == n_epoch:\n                        n_epoch += 5\n\n            print('\\t{:3d}:  {:.6f}  {:.6f}  {:.6f}  {:.2f}'.format(\n                  epoch, auc, auc_val, self.auc_opt,\n                  (time.time() - start) / SEC_PER_MIN))\n\n            epoch += 1\n\n        if X_val is not None:\n            print('Optimal epoch is {0} ({1:.6f})'.format(self.n_opt,\n                                                          self.auc_opt))\n            self.w = self.w_opt\n\n        logger.info('done training')", "response": "Train a model with the quasi - Newton method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict(self, X):\n        logger.info('predicting ...')\n        ps = self.predict_raw(X)\n\n        return sigm(ps[:, 0])", "response": "Predict targets for a feature matrix X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npredicting targets for a feature matrix X.", "response": "def predict_raw(self, X):\n        \"\"\"Predict targets for a feature matrix.\n\n        Args:\n            X (np.array of float): feature matrix for prediction\n        \"\"\"\n        # b -- bias for the input and h layers\n        b = np.ones((X.shape[0], 1))\n        w2 = self.w[-(self.h + 1):].reshape(self.h + 1, 1)\n        w1 = self.w[:-(self.h + 1)].reshape(self.i + 1, self.h)\n\n        # Make X to have the same number of columns as self.i.\n        # Because of the sparse matrix representation, X for prediction can\n        # have a different number of columns.\n        if X.shape[1] > self.i:\n            # If X has more columns, cut extra columns.\n            X = X[:, :self.i]\n        elif X.shape[1] < self.i:\n            # If X has less columns, cut the rows of the weight matrix between\n            # the input and h layers instead of X itself because the SciPy\n            # sparse matrix does not support .set_shape() yet.\n            idx = range(X.shape[1])\n            idx.append(self.i)        # Include the last row for the bias\n            w1 = w1[idx, :]\n\n        if sparse.issparse(X):\n            return np.hstack((sigm(sparse.hstack((X, b)).dot(w1)), b)).dot(w2)\n        else:\n            return np.hstack((sigm(np.hstack((X, b)).dot(w1)), b)).dot(w2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef func(self, w, *args):\n        x0 = args[0]\n        x1 = args[1]\n\n        n0 = x0.shape[0]\n        n1 = x1.shape[0]\n\n        # n -- number of pairs to evaluate\n        n = max(n0, n1) * 10\n        idx0 = np.random.choice(range(n0), size=n)\n        idx1 = np.random.choice(range(n1), size=n)\n\n        # b -- bias for the input and h layers\n        b0 = np.ones((n0, 1))\n        b1 = np.ones((n1, 1))\n        i1 = self.i + 1\n        h = self.h\n        h1 = h + 1\n\n        # Predict for features -- cannot use predict_raw() because here\n        # different weights can be used.\n        if sparse.issparse(x0):\n            p0 = np.hstack((sigm(sparse.hstack((x0, b0)).dot(w[:-h1].reshape(\n                               i1, h))), b0)).dot(w[-h1:].reshape(h1, 1))\n            p1 = np.hstack((sigm(sparse.hstack((x1, b1)).dot(w[:-h1].reshape(\n                               i1, h))), b1)).dot(w[-h1:].reshape(h1, 1))\n        else:\n            p0 = np.hstack((sigm(np.hstack((x0, b0)).dot(w[:-h1].reshape(\n                               i1, h))), b0)).dot(w[-h1:].reshape(h1, 1))\n            p1 = np.hstack((sigm(np.hstack((x1, b1)).dot(w[:-h1].reshape(\n                               i1, h))), b1)).dot(w[-h1:].reshape(h1, 1))\n\n        p0 = p0[idx0]\n        p1 = p1[idx1]\n\n        # Return the cost that consists of the sum of squared error +\n        # L2-regularization for weights between the input and h layers +\n        # L2-regularization for weights between the h and output layers.\n        #return .5 * (sum((1 - sigm(p1 - p0)) ** 2) + self.l1 * sum(w[:-h1] ** 2) +\n        return .5 * (sum((1 - p1 + p0) ** 2) / n +\n                     self.l1 * sum(w[:-h1] ** 2) / (i1 * h) +\n                     self.l2 * sum(w[-h1:] ** 2) / h1)", "response": "Function to compute the cost of the neural network for predictions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fprime(self, w, *args):\n\n        x0 = args[0]\n        x1 = args[1]\n\n        n0 = x0.shape[0]\n        n1 = x1.shape[0]\n\n        # n -- number of pairs to evaluate\n        n = max(n0, n1) * 10\n        idx0 = np.random.choice(range(n0), size=n)\n        idx1 = np.random.choice(range(n1), size=n)\n\n        # b -- bias for the input and h layers\n        b = np.ones((n, 1))\n        i1 = self.i + 1\n        h = self.h\n        h1 = h + 1\n\n        w2 = w[-h1:].reshape(h1, 1)\n        w1 = w[:-h1].reshape(i1, h)\n\n        if sparse.issparse(x0):\n            x0 = x0.tocsr()[idx0]\n            x1 = x1.tocsr()[idx1]\n            xb0 = sparse.hstack((x0, b))\n            xb1 = sparse.hstack((x1, b))\n        else:\n            x0 = x0[idx0]\n            x1 = x1[idx1]\n            xb0 = np.hstack((x0, b))\n            xb1 = np.hstack((x1, b))\n\n        z0 = np.hstack((sigm(xb0.dot(w1)), b))\n        z1 = np.hstack((sigm(xb1.dot(w1)), b))\n        y0 = z0.dot(w2)\n        y1 = z1.dot(w2)\n\n        #e = 1 - sigm(y1 - y0)\n        #dy = e * dsigm(y1 - y0)\n        e = 1 - (y1 - y0)\n        dy = e / n\n\n        # Calculate the derivative of the cost function w.r.t. F and w2 where:\n        # F -- weights between the input and h layers\n        # w2 -- weights between the h and output layers\n        dw1 = -(xb1.T.dot(dy.dot(w2[:-1].reshape(1, h)) * dsigm(xb1.dot(w1))) -\n               xb0.T.dot(dy.dot(w2[:-1].reshape(1, h)) * dsigm(xb0.dot(w1)))\n                       ).reshape(i1 * h) + self.l1 * w[:-h1] / (i1 * h)\n        dw2 = -(z1 - z0).T.dot(dy).reshape(h1) + self.l2 * w[-h1:] / h1\n\n        return np.append(dw1, dw2)", "response": "Returns the derivatives of the cost function for predictions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(self, X):\n\n        for col in range(X.shape[1]):\n            X[:, col] = self._transform_col(X[:, col], col)\n\n        return X", "response": "Normalize numerical columns.\n\n        Args:\n            X (numpy.array) : numerical columns to normalize\n\n        Returns:\n            X (numpy.array): normalized numerical columns"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_transform(self, X, y=None):\n\n        self.ecdfs = [None] * X.shape[1]\n\n        for col in range(X.shape[1]):\n            self.ecdfs[col] = ECDF(X[:, col])\n            X[:, col] = self._transform_col(X[:, col], col)\n\n        return X", "response": "Fit the ECDF to the data and transform the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes one numerical column.", "response": "def _transform_col(self, x, col):\n        \"\"\"Normalize one numerical column.\n\n        Args:\n            x (numpy.array): a numerical column to normalize\n            col (int): column index\n\n        Returns:\n            A normalized feature vector.\n        \"\"\"\n\n        return norm.ppf(self.ecdfs[col](x) * .998 + .001)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_label_encoder_and_max(self, x):\n\n        # NaN cannot be used as a key for dict. So replace it with a random integer.\n        label_count = x.fillna(NAN_INT).value_counts()\n        n_uniq = label_count.shape[0]\n\n        label_count = label_count[label_count >= self.min_obs]\n        n_uniq_new = label_count.shape[0]\n\n        # If every label appears more than min_obs, new label starts from 0.\n        # Otherwise, new label starts from 1 and 0 is used for all old labels\n        # that appear less than min_obs.\n        offset = 0 if n_uniq == n_uniq_new else 1\n\n        label_encoder = pd.Series(np.arange(n_uniq_new) + offset, index=label_count.index)\n        max_label = label_encoder.max()\n        label_encoder = label_encoder.to_dict()\n\n        return label_encoder, max_label", "response": "Return a mapping from values and its maximum of a column to integer labels."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode one categorical column into labels.", "response": "def _transform_col(self, x, i):\n        \"\"\"Encode one categorical column into labels.\n\n        Args:\n            x (pandas.Series): a categorical column to encode\n            i (int): column index\n\n        Returns:\n            x (pandas.Series): a column with labels.\n        \"\"\"\n        return x.fillna(NAN_INT).map(self.label_encoders[i]).fillna(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, X):\n\n        for i, col in enumerate(X.columns):\n            X.loc[:, col] = self._transform_col(X[col], i)\n\n        return X", "response": "Encode categorical columns into label encoded columns"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_transform(self, X, y=None):\n\n        self.label_encoders = [None] * X.shape[1]\n        self.label_maxes = [None] * X.shape[1]\n\n        for i, col in enumerate(X.columns):\n            self.label_encoders[i], self.label_maxes[i] = \\\n                self._get_label_encoder_and_max(X[col])\n\n            X.loc[:, col] = X[col].fillna(NAN_INT).map(self.label_encoders[i]).fillna(0)\n\n        return X", "response": "Encode categorical columns into label encoded columns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _transform_col(self, x, i):\n\n        labels = self.label_encoder._transform_col(x, i)\n        label_max = self.label_encoder.label_maxes[i]\n\n        # build row and column index for non-zero values of a sparse matrix\n        index = np.array(range(len(labels)))\n        i = index[labels > 0]\n        j = labels[labels > 0] - 1  # column index starts from 0\n\n        if len(i) > 0:\n            return sparse.coo_matrix((np.ones_like(i), (i, j)),\n                                     shape=(x.shape[0], label_max))\n        else:\n            # if there is no non-zero value, return no matrix\n            return None", "response": "Encode one categorical column into sparse matrix with one - hot - encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode categorical columns into sparse matrix with one - hot - encoding.", "response": "def transform(self, X):\n        \"\"\"Encode categorical columns into sparse matrix with one-hot-encoding.\n\n        Args:\n            X (pandas.DataFrame): categorical columns to encode\n\n        Returns:\n            X_new (scipy.sparse.coo_matrix): sparse matrix encoding categorical\n                                             variables into dummy variables\n        \"\"\"\n\n        for i, col in enumerate(X.columns):\n            X_col = self._transform_col(X[col], i)\n            if X_col is not None:\n                if i == 0:\n                    X_new = X_col\n                else:\n                    X_new = sparse.hstack((X_new, X_col))\n\n            logger.debug('{} --> {} features'.format(\n                col, self.label_encoder.label_maxes[i])\n            )\n\n        return X_new"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_target_encoder(self, x, y):\n\n        assert len(x) == len(y)\n\n        # NaN cannot be used as a key for dict. So replace it with a random integer\n        df = pd.DataFrame({y.name: y, x.name: x.fillna(NAN_INT)})\n        return df.groupby(x.name)[y.name].mean().to_dict()", "response": "Return a dict mapping from categories to average target values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencodes one categorical column into average target values.", "response": "def _transform_col(self, x, i):\n        \"\"\"Encode one categorical column into average target values.\n        Args:\n            x (pandas.Series): a categorical column to encode\n            i (int): column index\n        Returns:\n            x (pandas.Series): a column with labels.\n        \"\"\"\n        return x.fillna(NAN_INT).map(self.target_encoders[i]).fillna(self.target_mean)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding categorical columns into average target values.", "response": "def fit(self, X, y):\n        \"\"\"Encode categorical columns into average target values.\n        Args:\n            X (pandas.DataFrame): categorical columns to encode\n            y (pandas.Series): the target column\n        Returns:\n            X (pandas.DataFrame): encoded columns\n        \"\"\"\n        self.target_encoders = [None] * X.shape[1]\n        self.target_mean = y.mean()\n\n        for i, col in enumerate(X.columns):\n            self.target_encoders[i] = self._get_target_encoder(X[col], y)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_transform(self, X, y):\n        self.target_encoders = [None] * X.shape[1]\n        self.target_mean = y.mean()\n\n        for i, col in enumerate(X.columns):\n            self.target_encoders[i] = self._get_target_encoder(X[col], y)\n\n            X.loc[:, col] = X[col].fillna(NAN_INT).map(self.target_encoders[i]).fillna(self.target_mean)\n\n        return X", "response": "Encode categorical columns into average target values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the score of the split", "response": "def _calculate_split_score(self, split):\n        \"\"\"\n        calculate the score of the split:\n        score = current_error - after_split_error\n        \"\"\"\n        left_error = gini(split['left'])\n        right_error = gini(split['right'])\n        error = gini(self.Y)\n        # if the split is any good, the score should be greater than 0\n        total = float(len(self.Y))\n        score = error - 1 / total * (len(split['left']) * left_error\\\n                                     + len(split['right']) * right_error)\n        return score"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, x):\n        if self._is_leaf():\n            d1 = self.predict_initialize['count_dict']\n            d2 = count_dict(self.Y)\n            for key, value in d1.iteritems():\n                if key in d2:\n                    d2[key] += value\n                else:\n                    d2[key] = value\n            return argmax(d2)\n        else:\n            if self.criterion(x):\n                return self.right.predict(x)\n            else:\n                return self.left.predict(x)", "response": "Make prediction recursively. Use both the samples inside the current node and the statistics inherited from parent node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef netflix(es, ps, e0, l=.0001):\n    m = len(es)\n    n = len(ps[0])\n\n    X = np.stack(ps).T\n    pTy = .5 * (n * e0**2 + (X**2).sum(axis=0) - n * np.array(es)**2)\n\n    w = np.linalg.pinv(X.T.dot(X) + l * n * np.eye(m)).dot(pTy)\n\n    return X.dot(w), w", "response": "Combine predictions with the optimal weights to minimize RMSE."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_data(X, y, path):\n    catalog = {'.csv': save_csv, '.sps': save_libsvm, '.h5': save_hdf5}\n\n    ext = os.path.splitext(path)[1]\n    func = catalog[ext]\n\n    if y is None:\n        y = np.zeros((X.shape[0], ))\n\n    func(X, y, path)", "response": "Save data to a CSV LibSVM or HDF5 file based on the file extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves data as a CSV file.", "response": "def save_csv(X, y, path):\n    \"\"\"Save data as a CSV file.\n\n    Args:\n        X (numpy or scipy sparse matrix): Data matrix\n        y (numpy array): Target vector.\n        path (str): Path to the CSV file to save data.\n    \"\"\"\n\n    if sparse.issparse(X):\n        X = X.todense()\n\n    np.savetxt(path, np.hstack((y.reshape((-1, 1)), X)), delimiter=',')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_libsvm(X, y, path):\n\n    dump_svmlight_file(X, y, path, zero_based=False)", "response": "Save data as a LibSVM file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave data as a HDF5 file.", "response": "def save_hdf5(X, y, path):\n    \"\"\"Save data as a HDF5 file.\n\n    Args:\n        X (numpy or scipy sparse matrix): Data matrix\n        y (numpy array): Target vector.\n        path (str): Path to the HDF5 file to save data.\n    \"\"\"\n\n    with h5py.File(path, 'w') as f:\n        is_sparse = 1 if sparse.issparse(X) else 0\n        f['issparse'] = is_sparse\n        f['target'] = y\n\n        if is_sparse:\n            if not sparse.isspmatrix_csr(X):\n                X = X.tocsr()\n\n            f['shape'] = np.array(X.shape)\n            f['data'] = X.data\n            f['indices'] = X.indices\n            f['indptr'] = X.indptr\n        else:\n            f['data'] = X"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_data(path, dense=False):\n\n    catalog = {'.csv': load_csv, '.sps': load_svmlight_file, '.h5': load_hdf5}\n\n    ext = os.path.splitext(path)[1]\n    func = catalog[ext]\n    X, y = func(path)\n\n    if dense and sparse.issparse(X):\n        X = X.todense()\n\n    return X, y", "response": "Load data from a CSV LibSVM or HDF5 file based on the file extension."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload data from a CSV file.", "response": "def load_csv(path):\n    \"\"\"Load data from a CSV file.\n\n    Args:\n        path (str): A path to the CSV format file containing data.\n        dense (boolean): An optional variable indicating if the return matrix\n                         should be dense.  By default, it is false.\n\n    Returns:\n        Data matrix X and target vector y\n    \"\"\"\n\n    with open(path) as f:\n        line = f.readline().strip()\n\n    X = np.loadtxt(path, delimiter=',',\n                   skiprows=0 if is_number(line.split(',')[0]) else 1)\n\n    y = np.array(X[:, 0]).flatten()\n    X = X[:, 1:]\n\n    return X, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_hdf5(path):\n\n    with h5py.File(path, 'r') as f:\n        is_sparse = f['issparse'][...]\n        if is_sparse:\n            shape = tuple(f['shape'][...])\n            data = f['data'][...]\n            indices = f['indices'][...]\n            indptr = f['indptr'][...]\n            X = sparse.csr_matrix((data, indices, indptr), shape=shape)\n        else:\n            X = f['data'][...]\n\n        y = f['target'][...]\n\n    return X, y", "response": "Load data from a HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a LibSVM file line - by - line.", "response": "def read_sps(path):\n    \"\"\"Read a LibSVM file line-by-line.\n\n    Args:\n        path (str): A path to the LibSVM file to read.\n\n    Yields:\n        data (list) and target (int).\n    \"\"\"\n\n    for line in open(path):\n        # parse x\n        xs = line.rstrip().split(' ')\n\n        yield xs[1:], int(xs[0])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mape(y, p):\n\n    filt = np.abs(y) > EPS\n    return np.mean(np.abs(1 - p[filt] / y[filt]))", "response": "Mean Absolute Percentage Error ( MAPE )."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nroots Mean Squared Error ( RMSE ).", "response": "def rmse(y, p):\n    \"\"\"Root Mean Squared Error (RMSE).\n\n    Args:\n        y (numpy.array): target\n        p (numpy.array): prediction\n\n    Returns:\n        e (numpy.float64): RMSE\n    \"\"\"\n\n    # check and get number of samples\n    assert y.shape == p.shape\n\n    return np.sqrt(mse(y, p))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes Gini Coefficient. Args: y (numpy.array): target p (numpy.array): prediction Returns: e (numpy.float64): normalized Gini coefficient", "response": "def gini(y, p):\n    \"\"\"Normalized Gini Coefficient.\n\n    Args:\n        y (numpy.array): target\n        p (numpy.array): prediction\n\n    Returns:\n        e (numpy.float64): normalized Gini coefficient\n    \"\"\"\n\n    # check and get number of samples\n    assert y.shape == p.shape\n\n    n_samples = y.shape[0]\n\n    # sort rows on prediction column\n    # (from largest to smallest)\n    arr = np.array([y, p]).transpose()\n    true_order = arr[arr[:,0].argsort()][::-1,0]\n    pred_order = arr[arr[:,1].argsort()][::-1,0]\n\n    # get Lorenz curves\n    l_true = np.cumsum(true_order) / np.sum(true_order)\n    l_pred = np.cumsum(pred_order) / np.sum(pred_order)\n    l_ones = np.linspace(1/n_samples, 1, n_samples)\n\n    # get Gini coefficients (area between curves)\n    g_true = np.sum(l_ones - l_true)\n    g_pred = np.sum(l_ones - l_pred)\n\n    # normalize to true Gini coefficient\n    return g_pred / g_true"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbound log loss error.", "response": "def logloss(y, p):\n    \"\"\"Bounded log loss error.\n\n    Args:\n        y (numpy.array): target\n        p (numpy.array): prediction\n\n    Returns:\n        bounded log loss error\n    \"\"\"\n\n    p[p < EPS] = EPS\n    p[p > 1 - EPS] = 1 - EPS\n    return log_loss(y, p)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert CSV file to HTML table", "response": "def convert(input_file_name, **kwargs):\n    \"\"\"Convert CSV file to HTML table\"\"\"\n    delimiter = kwargs[\"delimiter\"] or \",\"\n    quotechar = kwargs[\"quotechar\"] or \"|\"\n\n    if six.PY2:\n        delimiter = delimiter.encode(\"utf-8\")\n        quotechar = quotechar.encode(\"utf-8\")\n\n    # Read CSV and form a header and rows list\n    with open(input_file_name, \"rb\") as input_file:\n        reader = csv.reader(input_file,\n                            encoding=\"utf-8\",\n                            delimiter=delimiter,\n                            quotechar=quotechar)\n\n        csv_headers = []\n        if not kwargs.get(\"no_header\"):\n            # Read header from first line\n            csv_headers = next(reader)\n\n        csv_rows = [row for row in reader if row]\n\n        # Set default column name if header is not present\n        if not csv_headers and len(csv_rows) > 0:\n            end = len(csv_rows[0]) + 1\n            csv_headers = [\"Column {}\".format(n) for n in range(1, end)]\n\n    # Render csv to HTML\n    html = render_template(csv_headers, csv_rows, **kwargs)\n\n    # Freeze all JS files in template\n    return freeze_js(html)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving content to a file", "response": "def save(file_name, content):\n    \"\"\"Save content to a file\"\"\"\n    with open(file_name, \"w\", encoding=\"utf-8\") as output_file:\n        output_file.write(content)\n        return output_file.name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite content to a temp file and serve it in browser", "response": "def serve(content):\n    \"\"\"Write content to a temp file and serve it in browser\"\"\"\n    temp_folder = tempfile.gettempdir()\n    temp_file_name = tempfile.gettempprefix() + str(uuid.uuid4()) + \".html\"\n    # Generate a file path with a random name in temporary dir\n    temp_file_path = os.path.join(temp_folder, temp_file_name)\n\n    # save content to temp file\n    save(temp_file_path, content)\n\n    # Open templfile in a browser\n    webbrowser.open(\"file://{}\".format(temp_file_path))\n\n    # Block the thread while content is served\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        # cleanup the temp file\n        os.remove(temp_file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_template(table_headers, table_items, **options):\n    caption = options.get(\"caption\") or \"Table\"\n    display_length = options.get(\"display_length\") or -1\n    height = options.get(\"height\") or \"70vh\"\n    default_length_menu = [-1, 10, 25, 50]\n    pagination = options.get(\"pagination\")\n    virtual_scroll_limit = options.get(\"virtual_scroll\")\n\n    # Change % to vh\n    height = height.replace(\"%\", \"vh\")\n\n    # Header columns\n    columns = []\n    for header in table_headers:\n        columns.append({\"title\": header})\n\n    # Data table options\n    datatable_options = {\n        \"columns\": columns,\n        \"data\": table_items,\n        \"iDisplayLength\": display_length,\n        \"sScrollX\": \"100%\",\n        \"sScrollXInner\": \"100%\"\n    }\n\n    # Enable virtual scroll for rows bigger than 1000 rows\n    is_paging = pagination\n    virtual_scroll = False\n    scroll_y = height\n\n    if virtual_scroll_limit:\n        if virtual_scroll_limit != -1 and len(table_items) > virtual_scroll_limit:\n            virtual_scroll = True\n            display_length = -1\n\n        fmt = (\"\\nVirtual scroll is enabled since number of rows exceeds {limit}.\"\n               \" You can set custom row limit by setting flag -vs, --virtual-scroll.\"\n               \" Virtual scroll can be disabled by setting the value to -1 and set it to 0 to always enable.\")\n        logger.warn(fmt.format(limit=virtual_scroll_limit))\n\n        if not is_paging:\n            fmt = \"\\nPagination can not be disabled in virtual scroll mode.\"\n            logger.warn(fmt)\n\n        is_paging = True\n\n    if is_paging and not virtual_scroll:\n        # Add display length to the default display length menu\n        length_menu = []\n        if display_length != -1:\n            length_menu = sorted(default_length_menu + [display_length])\n        else:\n            length_menu = default_length_menu\n\n        # Set label as \"All\" it display length is -1\n        length_menu_label = [str(\"All\") if i == -1 else i for i in length_menu]\n        datatable_options[\"lengthMenu\"] = [length_menu, length_menu_label]\n        datatable_options[\"iDisplayLength\"] = display_length\n\n    if is_paging:\n        datatable_options[\"paging\"] = True\n    else:\n        datatable_options[\"paging\"] = False\n\n    if scroll_y:\n        datatable_options[\"scrollY\"] = scroll_y\n\n    if virtual_scroll:\n        datatable_options[\"scroller\"] = True\n        datatable_options[\"bPaginate\"] = False\n        datatable_options[\"deferRender\"] = True\n        datatable_options[\"bLengthChange\"] = False\n\n    enable_export = options.get(\"export\")\n    if enable_export:\n        if options[\"export_options\"]:\n            allowed = list(options[\"export_options\"])\n        else:\n            allowed = [\"copy\", \"csv\", \"json\", \"print\"]\n\n        datatable_options[\"dom\"] = \"Bfrtip\"\n        datatable_options[\"buttons\"] = allowed\n\n    datatable_options_json = json.dumps(datatable_options,\n                                        separators=(\",\", \":\"))\n\n    return template.render(title=caption or \"Table\",\n                           caption=caption,\n                           datatable_options=datatable_options_json,\n                           virtual_scroll=virtual_scroll,\n                           enable_export=enable_export)", "response": "Render Jinja2 template for table items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef freeze_js(html):\n    matches = js_src_pattern.finditer(html)\n\n    if not matches:\n        return html\n\n    # Reverse regex matches to replace match string with respective JS content\n    for match in reversed(tuple(matches)):\n        # JS file name\n        file_name = match.group(1)\n        file_path = os.path.join(js_files_path, file_name)\n\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            file_content = f.read()\n        # Replace matched string with inline JS\n        fmt = '<script type=\"text/javascript\">{}</script>'\n        js_content = fmt.format(file_content)\n        html = html[:match.start()] + js_content + html[match.end():]\n\n    return html", "response": "Freeze all JS assets to the rendered html itself."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef activate(request, activation_key,\n             template_name='userena/activate_fail.html',\n             retry_template_name='userena/activate_retry.html',\n             success_url=None, extra_context=None):\n    \"\"\"\n    Activate a user with an activation key.\n\n    The key is a SHA1 string. When the SHA1 is found with an\n    :class:`UserenaSignup`, the :class:`User` of that account will be\n    activated.  After a successful activation the view will redirect to\n    ``success_url``.  If the SHA1 is not found, the user will be shown the\n    ``template_name`` template displaying a fail message.\n    If the SHA1 is found but expired, ``retry_template_name`` is used instead,\n    so the user can proceed to :func:`activate_retry` to get a new activation key.\n\n    :param activation_key:\n        String of a SHA1 string of 40 characters long. A SHA1 is always 160bit\n        long, with 4 bits per character this makes it --160/4-- 40 characters\n        long.\n\n    :param template_name:\n        String containing the template name that is used when the\n        ``activation_key`` is invalid and the activation fails. Defaults to\n        ``userena/activate_fail.html``.\n\n    :param retry_template_name:\n        String containing the template name that is used when the\n        ``activation_key`` is expired. Defaults to\n        ``userena/activate_retry.html``.\n\n    :param success_url:\n        String containing the URL where the user should be redirected to after\n        a successful activation. Will replace ``%(username)s`` with string\n        formatting if supplied. If ``success_url`` is left empty, will direct\n        to ``userena_profile_detail`` view.\n\n    :param extra_context:\n        Dictionary containing variables which could be added to the template\n        context. Default to an empty dictionary.\n\n    \"\"\"\n    try:\n        if (not UserenaSignup.objects.check_expired_activation(activation_key)\n            or not userena_settings.USERENA_ACTIVATION_RETRY):\n            user = UserenaSignup.objects.activate_user(activation_key)\n            if user:\n                # Sign the user in.\n                auth_user = authenticate(identification=user.email,\n                                         check_password=False)\n                login(request, auth_user)\n\n                if userena_settings.USERENA_USE_MESSAGES:\n                    messages.success(request, _('Your account has been activated and you have been signed in.'),\n                                     fail_silently=True)\n\n                if success_url: redirect_to = success_url % {'username': user.username }\n                else: redirect_to = reverse('userena_profile_detail',\n                                            kwargs={'username': user.username})\n                return redirect(redirect_to)\n            else:\n                if not extra_context: extra_context = dict()\n                return ExtraContextTemplateView.as_view(template_name=template_name,\n                                                        extra_context=extra_context)(\n                                        request)\n        else:\n            if not extra_context: extra_context = dict()\n            extra_context['activation_key'] = activation_key\n            return ExtraContextTemplateView.as_view(template_name=retry_template_name,\n                                                extra_context=extra_context)(request)\n    except UserenaSignup.DoesNotExist:\n        if not extra_context: extra_context = dict()\n        return ExtraContextTemplateView.as_view(template_name=template_name,\n                                                extra_context=extra_context)(request)", "response": "Activates a user with a new activation key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreissues a new activation key for the user with the expired ones.", "response": "def activate_retry(request, activation_key,\n                   template_name='userena/activate_retry_success.html',\n                   extra_context=None):\n    \"\"\"\n    Reissue a new ``activation_key`` for the user with the expired\n    ``activation_key``.\n\n    If ``activation_key`` does not exists, or ``USERENA_ACTIVATION_RETRY`` is\n    set to False and for any other error condition user is redirected to\n    :func:`activate` for error message display.\n\n    :param activation_key:\n        String of a SHA1 string of 40 characters long. A SHA1 is always 160bit\n        long, with 4 bits per character this makes it --160/4-- 40 characters\n        long.\n\n    :param template_name:\n        String containing the template name that is used when new\n        ``activation_key`` has been created. Defaults to\n        ``userena/activate_retry_success.html``.\n\n    :param extra_context:\n        Dictionary containing variables which could be added to the template\n        context. Default to an empty dictionary.\n\n    \"\"\"\n    if not userena_settings.USERENA_ACTIVATION_RETRY:\n        return redirect(reverse('userena_activate', args=(activation_key,)))\n    try:\n        if UserenaSignup.objects.check_expired_activation(activation_key):\n            new_key = UserenaSignup.objects.reissue_activation(activation_key)\n            if new_key:\n                if not extra_context: extra_context = dict()\n                return ExtraContextTemplateView.as_view(template_name=template_name,\n                                                    extra_context=extra_context)(request)\n            else:\n                return redirect(reverse('userena_activate',args=(activation_key,)))\n        else:\n            return redirect(reverse('userena_activate',args=(activation_key,)))\n    except UserenaSignup.DoesNotExist:\n        return redirect(reverse('userena_activate',args=(activation_key,)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_confirm(request, confirmation_key,\n                  template_name='userena/email_confirm_fail.html',\n                  success_url=None, extra_context=None):\n    \"\"\"\n    Confirms an email address with a confirmation key.\n\n    Confirms a new email address by running :func:`User.objects.confirm_email`\n    method. If the method returns an :class:`User` the user will have his new\n    e-mail address set and redirected to ``success_url``. If no ``User`` is\n    returned the user will be represented with a fail message from\n    ``template_name``.\n\n    :param confirmation_key:\n        String with a SHA1 representing the confirmation key used to verify a\n        new email address.\n\n    :param template_name:\n        String containing the template name which should be rendered when\n        confirmation fails. When confirmation is successful, no template is\n        needed because the user will be redirected to ``success_url``.\n\n    :param success_url:\n        String containing the URL which is redirected to after a successful\n        confirmation.  Supplied argument must be able to be rendered by\n        ``reverse`` function.\n\n    :param extra_context:\n        Dictionary of variables that are passed on to the template supplied by\n        ``template_name``.\n\n    \"\"\"\n    user = UserenaSignup.objects.confirm_email(confirmation_key)\n    if user:\n        if userena_settings.USERENA_USE_MESSAGES:\n            messages.success(request, _('Your email address has been changed.'),\n                             fail_silently=True)\n\n        if success_url: redirect_to = success_url\n        else: redirect_to = reverse('userena_email_confirm_complete',\n                                    kwargs={'username': user.username})\n        return redirect(redirect_to)\n    else:\n        if not extra_context: extra_context = dict()\n        return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)", "response": "This function is used to confirm an email address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the account is disabled returns the disabled account template.", "response": "def disabled_account(request, username, template_name, extra_context=None):\n    \"\"\"\n    Checks if the account is disabled, if so, returns the disabled account template.\n\n    :param username:\n        String defining the username of the user that made the action.\n\n    :param template_name:\n        String defining the name of the template to use. Defaults to\n        ``userena/signup_complete.html``.\n\n    **Keyword arguments**\n\n    ``extra_context``\n        A dictionary containing extra variables that should be passed to the\n        rendered template. The ``account`` key is always the ``User``\n        that completed the action.\n\n    **Extra context**\n\n    ``viewed_user``\n        The currently :class:`User` that is viewed.\n\n    ``profile``\n        Profile of the viewed user.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n\n    if user.is_active:\n        raise Http404\n\n    if not extra_context: extra_context = dict()\n    extra_context['viewed_user'] = user\n    extra_context['profile'] = get_user_profile(user=user)\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signin(request, auth_form=AuthenticationForm,\n           template_name='userena/signin_form.html',\n           redirect_field_name=REDIRECT_FIELD_NAME,\n           redirect_signin_function=signin_redirect, extra_context=None):\n    \"\"\"\n    Signin using email or username with password.\n\n    Signs a user in by combining email/username with password. If the\n    combination is correct and the user :func:`is_active` the\n    :func:`redirect_signin_function` is called with the arguments\n    ``REDIRECT_FIELD_NAME`` and an instance of the :class:`User` who is is\n    trying the login. The returned value of the function will be the URL that\n    is redirected to.\n\n    A user can also select to be remembered for ``USERENA_REMEMBER_DAYS``.\n\n    :param auth_form:\n        Form to use for signing the user in. Defaults to the\n        :class:`AuthenticationForm` supplied by userena.\n\n    :param template_name:\n        String defining the name of the template to use. Defaults to\n        ``userena/signin_form.html``.\n\n    :param redirect_field_name:\n        Form field name which contains the value for a redirect to the\n        succeeding page. Defaults to ``next`` and is set in\n        ``REDIRECT_FIELD_NAME`` setting.\n\n    :param redirect_signin_function:\n        Function which handles the redirect. This functions gets the value of\n        ``REDIRECT_FIELD_NAME`` and the :class:`User` who has logged in. It\n        must return a string which specifies the URI to redirect to.\n\n    :param extra_context:\n        A dictionary containing extra variables that should be passed to the\n        rendered template. The ``form`` key is always the ``auth_form``.\n\n    **Context**\n\n    ``form``\n        Form used for authentication supplied by ``auth_form``.\n\n    \"\"\"\n    form = auth_form()\n\n    if request.method == 'POST':\n        form = auth_form(request.POST, request.FILES)\n        if form.is_valid():\n            identification, password, remember_me = (form.cleaned_data['identification'],\n                                                     form.cleaned_data['password'],\n                                                     form.cleaned_data['remember_me'])\n            user = authenticate(identification=identification,\n                                password=password)\n            if user.is_active:\n                login(request, user)\n                if remember_me:\n                    request.session.set_expiry(userena_settings.USERENA_REMEMBER_ME_DAYS[1] * 86400)\n                else: request.session.set_expiry(0)\n\n                if userena_settings.USERENA_USE_MESSAGES:\n                    messages.success(request, _('You have been signed in.'),\n                                     fail_silently=True)\n\n                #send a signal that a user has signed in\n                userena_signals.account_signin.send(sender=None, user=user)\n                # Whereto now?\n                redirect_to = redirect_signin_function(\n                    request.GET.get(redirect_field_name,\n                                    request.POST.get(redirect_field_name)), user)\n                return HttpResponseRedirect(redirect_to)\n            else:\n                return redirect(reverse('userena_disabled',\n                                        kwargs={'username': user.username}))\n\n    if not extra_context: extra_context = dict()\n    extra_context.update({\n        'form': form,\n        'next': request.GET.get(redirect_field_name,\n                                request.POST.get(redirect_field_name)),\n    })\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)", "response": "Signin the user with the given email or username with password."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef email_change(request, username, email_form=ChangeEmailForm,\n                 template_name='userena/email_form.html', success_url=None,\n                 extra_context=None):\n    \"\"\"\n    Change email address\n\n    :param username:\n        String of the username which specifies the current account.\n\n    :param email_form:\n        Form that will be used to change the email address. Defaults to\n        :class:`ChangeEmailForm` supplied by userena.\n\n    :param template_name:\n        String containing the template to be used to display the email form.\n        Defaults to ``userena/email_form.html``.\n\n    :param success_url:\n        Named URL where the user will get redirected to when successfully\n        changing their email address.  When not supplied will redirect to\n        ``userena_email_complete`` URL.\n\n    :param extra_context:\n        Dictionary containing extra variables that can be used to render the\n        template. The ``form`` key is always the form supplied by the keyword\n        argument ``form`` and the ``user`` key by the user whose email address\n        is being changed.\n\n    **Context**\n\n    ``form``\n        Form that is used to change the email address supplied by ``form``.\n\n    ``account``\n        Instance of the ``Account`` whose email address is about to be changed.\n\n    **Todo**\n\n    Need to have per-object permissions, which enables users with the correct\n    permissions to alter the email address of others.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n    prev_email = user.email\n    form = email_form(user)\n\n    if request.method == 'POST':\n        form = email_form(user, request.POST, request.FILES)\n\n        if form.is_valid():\n            form.save()\n\n            if success_url:\n                # Send a signal that the email has changed\n                userena_signals.email_change.send(sender=None,\n                                                  user=user,\n                                                  prev_email=prev_email,\n                                                  new_email=user.email)\n                redirect_to = success_url\n            else: redirect_to = reverse('userena_email_change_complete',\n                                        kwargs={'username': user.username})\n            return redirect(redirect_to)\n\n    if not extra_context: extra_context = dict()\n    extra_context['form'] = form\n    extra_context['profile'] = get_user_profile(user=user)\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)", "response": "Change the email address of the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef profile_edit(request, username, edit_profile_form=EditProfileForm,\n                 template_name='userena/profile_form.html', success_url=None,\n                 extra_context=None, **kwargs):\n    \"\"\"\n    Edit profile.\n\n    Edits a profile selected by the supplied username. First checks\n    permissions if the user is allowed to edit this profile, if denied will\n    show a 404. When the profile is successfully edited will redirect to\n    ``success_url``.\n\n    :param username:\n        Username of the user which profile should be edited.\n\n    :param edit_profile_form:\n\n        Form that is used to edit the profile. The :func:`EditProfileForm.save`\n        method of this form will be called when the form\n        :func:`EditProfileForm.is_valid`.  Defaults to :class:`EditProfileForm`\n        from userena.\n\n    :param template_name:\n        String of the template that is used to render this view. Defaults to\n        ``userena/edit_profile_form.html``.\n\n    :param success_url:\n        Named URL which will be passed on to a django ``reverse`` function after\n        the form is successfully saved. Defaults to the ``userena_detail`` url.\n\n    :param extra_context:\n        Dictionary containing variables that are passed on to the\n        ``template_name`` template.  ``form`` key will always be the form used\n        to edit the profile, and the ``profile`` key is always the edited\n        profile.\n\n    **Context**\n\n    ``form``\n        Form that is used to alter the profile.\n\n    ``profile``\n        Instance of the ``Profile`` that is edited.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n\n    profile = get_user_profile(user=user)\n\n    user_initial = {'first_name': user.first_name,\n                    'last_name': user.last_name}\n\n    form = edit_profile_form(instance=profile, initial=user_initial)\n\n    if request.method == 'POST':\n        form = edit_profile_form(request.POST, request.FILES, instance=profile,\n                                 initial=user_initial)\n\n        if form.is_valid():\n            profile = form.save()\n\n            if userena_settings.USERENA_USE_MESSAGES:\n                messages.success(request, _('Your profile has been updated.'),\n                                 fail_silently=True)\n\n            if success_url:\n                # Send a signal that the profile has changed\n                userena_signals.profile_change.send(sender=None,\n                                                    user=user)\n                redirect_to = success_url\n            else: redirect_to = reverse('userena_profile_detail', kwargs={'username': username})\n            return redirect(redirect_to)\n\n    if not extra_context: extra_context = dict()\n    extra_context['form'] = form\n    extra_context['profile'] = profile\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)", "response": "Edit profile.\n\n    Edits a profile selected by the supplied username. First checks\n    permissions if the user is allowed to edit this profile, if denied will\n    show a 404. When the profile is successfully edited will redirect to\n    ``success_url``.\n\n    :param username:\n        Username of the user which profile should be edited.\n\n    :param edit_profile_form:\n\n        Form that is used to edit the profile. The :func:`EditProfileForm.save`\n        method of this form will be called when the form\n        :func:`EditProfileForm.is_valid`.  Defaults to :class:`EditProfileForm`\n        from userena.\n\n    :param template_name:\n        String of the template that is used to render this view. Defaults to\n        ``userena/edit_profile_form.html``.\n\n    :param success_url:\n        Named URL which will be passed on to a django ``reverse`` function after\n        the form is successfully saved. Defaults to the ``userena_detail`` url.\n\n    :param extra_context:\n        Dictionary containing variables that are passed on to the\n        ``template_name`` template.  ``form`` key will always be the form used\n        to edit the profile, and the ``profile`` key is always the edited\n        profile.\n\n    **Context**\n\n    ``form``\n        Form that is used to alter the profile.\n\n    ``profile``\n        Instance of the ``Profile`` that is edited."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetail view of an user. :param username: String of the username of which the profile should be viewed. :param template_name: String representing the template name that should be used to display the profile. :param extra_context: Dictionary of variables which should be supplied to the template. The ``profile`` key is always the current profile. **Context** ``profile`` Instance of the currently viewed ``Profile``.", "response": "def profile_detail(request, username,\n    template_name=userena_settings.USERENA_PROFILE_DETAIL_TEMPLATE,\n    extra_context=None, **kwargs):\n    \"\"\"\n    Detailed view of an user.\n\n    :param username:\n        String of the username of which the profile should be viewed.\n\n    :param template_name:\n        String representing the template name that should be used to display\n        the profile.\n\n    :param extra_context:\n        Dictionary of variables which should be supplied to the template. The\n        ``profile`` key is always the current profile.\n\n    **Context**\n\n    ``profile``\n        Instance of the currently viewed ``Profile``.\n\n    \"\"\"\n    user = get_object_or_404(get_user_model(), username__iexact=username)\n    profile = get_user_profile(user=user)\n    if not profile.can_view_profile(request.user):\n        raise PermissionDenied\n    if not extra_context: extra_context = dict()\n    extra_context['profile'] = profile\n    extra_context['hide_email'] = userena_settings.USERENA_HIDE_EMAIL\n    return ExtraContextTemplateView.as_view(template_name=template_name,\n                                            extra_context=extra_context)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all profiles that are public.", "response": "def profile_list(request, page=1, template_name='userena/profile_list.html',\n                 paginate_by=50, extra_context=None, **kwargs): # pragma: no cover\n    \"\"\"\n    Returns a list of all profiles that are public.\n\n    It's possible to disable this by changing ``USERENA_DISABLE_PROFILE_LIST``\n    to ``True`` in your settings.\n\n    :param page:\n        Integer of the active page used for pagination. Defaults to the first\n        page.\n\n    :param template_name:\n        String defining the name of the template that is used to render the\n        list of all users. Defaults to ``userena/list.html``.\n\n    :param paginate_by:\n        Integer defining the amount of displayed profiles per page. Defaults to\n        50 profiles per page.\n\n    :param extra_context:\n        Dictionary of variables that are passed on to the ``template_name``\n        template.\n\n    **Context**\n\n    ``profile_list``\n        A list of profiles.\n\n    ``is_paginated``\n        A boolean representing whether the results are paginated.\n\n    If the result is paginated. It will also contain the following variables.\n\n    ``paginator``\n        An instance of ``django.core.paginator.Paginator``.\n\n    ``page_obj``\n        An instance of ``django.core.paginator.Page``.\n\n    \"\"\"\n    warnings.warn(\"views.profile_list is deprecated. Use ProfileListView instead\", DeprecationWarning, stacklevel=2)\n\n    try:\n        page = int(request.GET.get('page', None))\n    except (TypeError, ValueError):\n        page = page\n\n    if userena_settings.USERENA_DISABLE_PROFILE_LIST \\\n       and not request.user.is_staff:\n        raise Http404\n\n    profile_model = get_profile_model()\n    queryset = profile_model.objects.get_visible_profiles(request.user)\n\n    if not extra_context: extra_context = dict()\n    return ProfileListView.as_view(queryset=queryset,\n                                   paginate_by=paginate_by,\n                                   page=page,\n                                   template_name=template_name,\n                                   extra_context=extra_context,\n                                   **kwargs)(request)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an email using the given message.", "response": "def send_mail(subject, message_plain, message_html, email_from, email_to,\n              custom_headers={}, attachments=()):\n    \"\"\"\n    Build the email as a multipart message containing\n    a multipart alternative for text (plain, HTML) plus\n    all the attached files.\n    \"\"\"\n    if not message_plain and not message_html:\n        raise ValueError(_(\"Either message_plain or message_html should be not None\"))\n\n    if not message_plain:\n        message_plain = html2text(message_html)\n\n    message = {}\n\n    message['subject'] = subject\n    message['body'] = message_plain\n    message['from_email'] = email_from\n    message['to'] = email_to\n    if attachments:\n        message['attachments'] = attachments\n    if custom_headers:\n        message['headers'] = custom_headers\n\n    msg = EmailMultiAlternatives(**message)\n    if message_html:\n        msg.attach_alternative(message_html, \"text/html\")\n    msg.send()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_or_create(self, um_from_user, um_to_user, message):\n        created = False\n        try:\n            contact = self.get(Q(um_from_user=um_from_user, um_to_user=um_to_user) |\n                               Q(um_from_user=um_to_user, um_to_user=um_from_user))\n\n        except self.model.DoesNotExist:\n            created = True\n            contact = self.create(um_from_user=um_from_user,\n                                  um_to_user=um_to_user,\n                                  latest_message=message)\n\n        return (contact, created)", "response": "Get or create a Contact object for the given user and message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_contact(self, um_from_user, um_to_user, message):\n        contact, created = self.get_or_create(um_from_user,\n                                              um_to_user,\n                                              message)\n\n        # If the contact already existed, update the message\n        if not created:\n            contact.latest_message = message\n            contact.save()\n        return contact", "response": "Get or create a contact information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the contacts for this user.", "response": "def get_contacts_for(self, user):\n        \"\"\"\n        Returns the contacts for this user.\n\n        Contacts are other users that this user has received messages\n        from or send messages to.\n\n        :param user:\n            The :class:`User` which to get the contacts for.\n\n        \"\"\"\n        contacts = self.filter(Q(um_from_user=user) | Q(um_to_user=user))\n        return contacts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(self, sender, um_to_user_list, body):\n        msg = self.model(sender=sender,\n                         body=body)\n        msg.save()\n\n        # Save the recipients\n        msg.save_recipients(um_to_user_list)\n        msg.update_contacts(um_to_user_list)\n        signals.email_sent.send(sender=None,msg=msg)\n\n        return msg", "response": "Send a message from a user to a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a conversation between two users", "response": "def get_conversation_between(self, um_from_user, um_to_user):\n        \"\"\" Returns a conversation between two users \"\"\"\n        messages = self.filter(Q(sender=um_from_user, recipients=um_to_user,\n                                 sender_deleted_at__isnull=True) |\n                               Q(sender=um_to_user, recipients=um_from_user,\n                                 messagerecipient__deleted_at__isnull=True))\n        return messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_unread_messages_for(self, user):\n        unread_total = self.filter(user=user,\n                                   read_at__isnull=True,\n                                   deleted_at__isnull=True).count()\n\n        return unread_total", "response": "Returns the amount of unread messages for this user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_unread_messages_between(self, um_to_user, um_from_user):\n        unread_total = self.filter(message__sender=um_from_user,\n                                   user=um_to_user,\n                                   read_at__isnull=True,\n                                   deleted_at__isnull=True).count()\n\n        return unread_total", "response": "Returns the amount of unread messages between two users\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new user in the database.", "response": "def create_user(self, username, email, password, active=False,\n                    send_email=True):\n        \"\"\"\n        A simple wrapper that creates a new :class:`User`.\n\n        :param username:\n            String containing the username of the new user.\n\n        :param email:\n            String containing the email address of the new user.\n\n        :param password:\n            String containing the password for the new user.\n\n        :param active:\n            Boolean that defines if the user requires activation by clicking\n            on a link in an e-mail. Defaults to ``False``.\n\n        :param send_email:\n            Boolean that defines if the user should be sent an email. You could\n            set this to ``False`` when you want to create a user in your own\n            code, but don't want the user to activate through email.\n\n        :return: :class:`User` instance representing the new user.\n\n        \"\"\"\n\n        new_user = get_user_model().objects.create_user(\n            username, email, password)\n        new_user.is_active = active\n        new_user.save()\n\n        # Give permissions to view and change profile\n        for perm in ASSIGNED_PERMISSIONS['profile']:\n            assign_perm(perm[0], new_user, get_user_profile(user=new_user))\n\n        # Give permissions to view and change itself\n        for perm in ASSIGNED_PERMISSIONS['user']:\n            assign_perm(perm[0], new_user, new_user)\n\n        userena_profile = self.create_userena_profile(new_user)\n\n        if send_email:\n            userena_profile.send_activation_email()\n\n        return new_user"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an instance of UserenaSignup for the given user.", "response": "def create_userena_profile(self, user):\n        \"\"\"\n        Creates an :class:`UserenaSignup` instance for this user.\n\n        :param user:\n            Django :class:`User` instance.\n\n        :return: The newly created :class:`UserenaSignup` instance.\n\n        \"\"\"\n        if isinstance(user.username, text_type):\n            user.username = smart_text(user.username)\n        salt, activation_key = generate_sha1(user.username)\n\n        try:\n            profile = self.get(user=user)\n        except self.model.DoesNotExist:\n            profile = self.create(user=user,\n                           activation_key=activation_key)\n        return profile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreissuing an activation key when the previous key expire.", "response": "def reissue_activation(self, activation_key):\n        \"\"\"\n        Creates a new ``activation_key`` resetting activation timeframe when\n        users let the previous key expire.\n\n        :param activation_key:\n            String containing the secret SHA1 activation key.\n\n        \"\"\"\n        try:\n            userena = self.get(activation_key=activation_key)\n        except self.model.DoesNotExist:\n            return False\n        try:\n            salt, new_activation_key = generate_sha1(userena.user.username)\n            userena.activation_key = new_activation_key\n            userena.save(using=self._db)\n            userena.user.date_joined = get_datetime_now()\n            userena.user.save(using=self._db)\n            userena.send_activation_email()\n            return True\n        except Exception:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nactivate a user by supplying a valid activation key.", "response": "def activate_user(self, activation_key):\n        \"\"\"\n        Activate an :class:`User` by supplying a valid ``activation_key``.\n\n        If the key is valid and an user is found, activates the user and\n        return it. Also sends the ``activation_complete`` signal.\n\n        :param activation_key:\n            String containing the secret SHA1 for a valid activation.\n\n        :return:\n            The newly activated :class:`User` or ``False`` if not successful.\n\n        \"\"\"\n        if SHA1_RE.search(activation_key):\n            try:\n                userena = self.get(activation_key=activation_key)\n            except self.model.DoesNotExist:\n                return False\n            if not userena.activation_key_expired():\n                userena.activation_key = userena_settings.USERENA_ACTIVATED\n                user = userena.user\n                user.is_active = True\n                userena.save(using=self._db)\n                user.save(using=self._db)\n\n                # Send the activation_complete signal\n                userena_signals.activation_complete.send(sender=None,\n                                                         user=user)\n\n                return user\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if activation_key is still valid.", "response": "def check_expired_activation(self, activation_key):\n        \"\"\"\n        Check if ``activation_key`` is still valid.\n\n        Raises a ``self.model.DoesNotExist`` exception if key is not present or\n         ``activation_key`` is not a valid string\n\n        :param activation_key:\n            String containing the secret SHA1 for a valid activation.\n\n        :return:\n            True if the ket has expired, False if still valid.\n\n        \"\"\"\n        if SHA1_RE.search(activation_key):\n            userena = self.get(activation_key=activation_key)\n            return userena.activation_key_expired()\n        raise self.model.DoesNotExist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef confirm_email(self, confirmation_key):\n        if SHA1_RE.search(confirmation_key):\n            try:\n                userena = self.get(email_confirmation_key=confirmation_key,\n                                   email_unconfirmed__isnull=False)\n            except self.model.DoesNotExist:\n                return False\n            else:\n                user = userena.user\n                old_email = user.email\n                user.email = userena.email_unconfirmed\n                userena.email_unconfirmed, userena.email_confirmation_key = '',''\n                userena.save(using=self._db)\n                user.save(using=self._db)\n\n                # Send the confirmation_complete signal\n                userena_signals.confirmation_complete.send(sender=None,\n                                                           user=user,\n                                                           old_email=old_email)\n\n                return user\n        return False", "response": "Confirm an e - mail address by checking a confirmation key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_expired_users(self):\n        deleted_users = []\n        for user in get_user_model().objects.filter(is_staff=False,\n                                                    is_active=False):\n            if user.userena_signup.activation_key_expired():\n                deleted_users.append(user)\n                user.delete()\n        return deleted_users", "response": "Checks for expired users and delete s the User associated with\n        it. Skips the user is_staff"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_permissions(self):\n        # Variable to supply some feedback\n        changed_permissions = []\n        changed_users = []\n        warnings = []\n\n        # Check that all the permissions are available.\n        for model, perms in ASSIGNED_PERMISSIONS.items():\n            if model == 'profile':\n                model_obj = get_profile_model()\n            else: model_obj = get_user_model()\n\n            model_content_type = ContentType.objects.get_for_model(model_obj)\n\n            for perm in perms:\n                try:\n                    Permission.objects.get(codename=perm[0],\n                                           content_type=model_content_type)\n                except Permission.DoesNotExist:\n                    changed_permissions.append(perm[1])\n                    Permission.objects.create(name=perm[1],\n                                              codename=perm[0],\n                                              content_type=model_content_type)\n\n        # it is safe to rely on settings.ANONYMOUS_USER_NAME since it is a\n        # requirement of django-guardian\n        for user in get_user_model().objects.exclude(username=settings.ANONYMOUS_USER_NAME):\n            try:\n                user_profile = get_user_profile(user=user)\n            except ObjectDoesNotExist:\n                warnings.append(_(\"No profile found for %(username)s\") \\\n                                    % {'username': user.username})\n            else:\n                all_permissions = get_perms(user, user_profile) + get_perms(user, user)\n\n                for model, perms in ASSIGNED_PERMISSIONS.items():\n                    if model == 'profile':\n                        perm_object = get_user_profile(user=user)\n                    else: perm_object = user\n\n                    for perm in perms:\n                        if perm[0] not in all_permissions:\n                            assign_perm(perm[0], user, perm_object)\n                            changed_users.append(user)\n\n        return (changed_permissions, changed_users, warnings)", "response": "Checks that all permissions are set correctly for the users."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all the visible profiles for this user.", "response": "def get_visible_profiles(self, user=None):\n        \"\"\"\n        Returns all the visible profiles available to this user.\n\n        For now keeps it simple by just applying the cases when a user is not\n        active, a user has it's profile closed to everyone or a user only\n        allows registered users to view their profile.\n\n        :param user:\n            A Django :class:`User` instance.\n\n        :return:\n            All profiles that are visible to this user.\n\n        \"\"\"\n        profiles = self.all()\n\n        filter_kwargs = {'user__is_active': True}\n\n        profiles = profiles.filter(**filter_kwargs)\n        if user and isinstance(user, AnonymousUser):\n            profiles = profiles.exclude(Q(privacy='closed') | Q(privacy='registered'))\n        else: profiles = profiles.exclude(Q(privacy='closed'))\n        return profiles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate(self, request, identification, password=None, check_password=True):\n        User = get_user_model()\n        try:\n            django.core.validators.validate_email(identification)\n            try: user = User.objects.get(email__iexact=identification)\n            except User.DoesNotExist: return None\n        except django.core.validators.ValidationError:\n            try: user = User.objects.get(username__iexact=identification)\n            except User.DoesNotExist: return None\n        if check_password:\n            if user.check_password(password):\n                return user\n            return None\n        else: return user", "response": "Authenticates a user through the combination email and username with the password."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unread_message_count_for(parser, token):\n    try:\n        tag_name, arg = token.contents.split(None, 1)\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%s tag requires arguments\" % token.contents.split()[0])\n    m = re.search(r'(.*?) as (\\w+)', arg)\n    if not m:\n        raise template.TemplateSyntaxError(\"%s tag had invalid arguments\" % tag_name)\n    user, var_name = m.groups()\n    return MessageCount(user, var_name)", "response": "Returns the unread message count for a user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unread_message_count_between(parser, token):\n    try:\n        tag_name, arg = token.contents.split(None, 1)\n    except ValueError:\n        raise template.TemplateSyntaxError(\"%s tag requires arguments\" % token.contents.split()[0])\n    m = re.search(r'(.*?) and (.*?) as (\\w+)', arg)\n    if not m:\n        raise template.TemplateSyntaxError(\"%s tag had invalid arguments\" % tag_name)\n    um_from_user, um_to_user, var_name = m.groups()\n    return MessageCount(um_from_user, var_name, um_to_user)", "response": "Returns the unread message count between two users."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a mugshot for a user to the mugshot directory and saves it under unique hash for the image.", "response": "def upload_to_mugshot(instance, filename):\n    \"\"\"\n    Uploads a mugshot for a user to the ``USERENA_MUGSHOT_PATH`` and saving it\n    under unique hash for the image. This is for privacy reasons so others\n    can't just browse through the mugshot directory.\n\n    \"\"\"\n    extension = filename.split('.')[-1].lower()\n    salt, hash = generate_sha1(instance.pk)\n    path = userena_settings.USERENA_MUGSHOT_PATH % {'username': instance.user.username,\n                                                    'id': instance.user.id,\n                                                    'date': instance.user.date_joined,\n                                                    'date_now': get_datetime_now().date()}\n    return '%(path)s%(hash)s.%(extension)s' % {'path': path,\n                                               'hash': hash[:10],\n                                               'extension': extension}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new message in the message queue.", "response": "def message_compose(request, recipients=None, compose_form=ComposeForm,\n                    success_url=None, template_name=\"umessages/message_form.html\",\n                    recipient_filter=None, extra_context=None):\n    \"\"\"\n    Compose a new message\n\n    :recipients:\n        String containing the usernames to whom the message is send to. Can be\n        multiple username by seperating them with a ``+`` sign.\n\n    :param compose_form:\n        The form that is used for getting neccesary information. Defaults to\n        :class:`ComposeForm`.\n\n    :param success_url:\n        String containing the named url which to redirect to after successfull\n        sending a message. Defaults to ``userena_umessages_list`` if there are\n        multiple recipients. If there is only one recipient, will redirect to\n        ``userena_umessages_detail`` page, showing the conversation.\n\n    :param template_name:\n        String containing the name of the template that is used.\n\n    :param recipient_filter:\n        A list of :class:`User` that don\"t want to receive any messages.\n\n    :param extra_context:\n        Dictionary with extra variables supplied to the template.\n\n    **Context**\n\n    ``form``\n        The form that is used.\n\n    \"\"\"\n    initial_data = dict()\n\n    if recipients:\n        username_list = [r.strip() for r in recipients.split(\"+\")]\n        recipients = [u for u in get_user_model().objects.filter(username__in=username_list)]\n        initial_data[\"to\"] = recipients\n\n    form = compose_form(initial=initial_data)\n    if request.method == \"POST\":\n        form = compose_form(request.POST)\n        if form.is_valid():\n            requested_redirect = request.GET.get(REDIRECT_FIELD_NAME,\n                                                 request.POST.get(REDIRECT_FIELD_NAME, False))\n\n            message = form.save(request.user)\n            recipients = form.cleaned_data['to']\n\n            if userena_settings.USERENA_USE_MESSAGES:\n                messages.success(request, _('Message is sent.'),\n                                 fail_silently=True)\n\n            # Redirect mechanism\n            redirect_to = reverse('userena_umessages_list')\n            if requested_redirect: redirect_to = requested_redirect\n            elif success_url: redirect_to = success_url\n            elif len(recipients) == 1:\n                redirect_to = reverse('userena_umessages_detail',\n                                      kwargs={'username': recipients[0].username})\n            return redirect(redirect_to)\n\n    if not extra_context: extra_context = dict()\n    extra_context[\"form\"] = form\n    extra_context[\"recipients\"] = recipients\n    return render(request, template_name, extra_context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef message_remove(request, undo=False):\n    message_pks = request.POST.getlist('message_pks')\n    redirect_to = request.GET.get(REDIRECT_FIELD_NAME,\n                                  request.POST.get(REDIRECT_FIELD_NAME, False))\n\n    if message_pks:\n        # Check that all values are integers.\n        valid_message_pk_list = set()\n        for pk in message_pks:\n            try: valid_pk = int(pk)\n            except (TypeError, ValueError): pass\n            else:\n                valid_message_pk_list.add(valid_pk)\n\n        # Delete all the messages, if they belong to the user.\n        now = get_datetime_now()\n        changed_message_list = set()\n        for pk in valid_message_pk_list:\n            message = get_object_or_404(Message, pk=pk)\n\n            # Check if the user is the owner\n            if message.sender == request.user:\n                if undo:\n                    message.sender_deleted_at = None\n                else:\n                    message.sender_deleted_at = now\n                message.save()\n                changed_message_list.add(message.pk)\n\n            # Check if the user is a recipient of the message\n            if request.user in message.recipients.all():\n                mr = message.messagerecipient_set.get(user=request.user,\n                                                      message=message)\n                if undo:\n                    mr.deleted_at = None\n                else:\n                    mr.deleted_at = now\n                mr.save()\n                changed_message_list.add(message.pk)\n\n        # Send messages\n        if (len(changed_message_list) > 0) and userena_settings.USERENA_USE_MESSAGES:\n            if undo:\n                message = ungettext('Message is succesfully restored.',\n                                    'Messages are succesfully restored.',\n                                    len(changed_message_list))\n            else:\n                message = ungettext('Message is successfully removed.',\n                                    'Messages are successfully removed.',\n                                    len(changed_message_list))\n\n            messages.success(request, message, fail_silently=True)\n\n    if redirect_to: return redirect(redirect_to)\n    else: return redirect(reverse('userena_umessages_list'))", "response": "Removes messages from the tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef secure_required(view_func):\n    def _wrapped_view(request, *args, **kwargs):\n        if not request.is_secure():\n            if getattr(settings, 'USERENA_USE_HTTPS', userena_settings.DEFAULT_USERENA_USE_HTTPS):\n                request_url = request.build_absolute_uri(request.get_full_path())\n                secure_url = request_url.replace('http://', 'https://')\n                return HttpResponsePermanentRedirect(secure_url)\n        return view_func(request, *args, **kwargs)\n    return wraps(view_func, assigned=available_attrs(view_func))(_wrapped_view)", "response": "Decorator to switch an url from http to https."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the user s first and last name to the user field.", "response": "def save(self):\n        \"\"\" \n        Override the save method to save the first and last name to the user\n        field.\n\n        \"\"\"\n        # First save the parent form and get the user.\n        new_user = super(SignupFormExtra, self).save()\n\n        new_user.first_name = self.cleaned_data['first_name']\n        new_user.last_name = self.cleaned_data['last_name']\n        new_user.save()\n\n        # Userena expects to get the new user from this form, so return the new\n        # user.\n        return new_user"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting s a Gravatar for a given email address.", "response": "def get_gravatar(email, size=80, default='identicon'):\n    \"\"\" Get's a Gravatar for a email address.\n\n    :param size:\n        The size in pixels of one side of the Gravatar's square image.\n        Optional, if not supplied will default to ``80``.\n\n    :param default:\n        Defines what should be displayed if no image is found for this user.\n        Optional argument which defaults to ``identicon``. The argument can be\n        a URI to an image or one of the following options:\n\n            ``404``\n                Do not load any image if none is associated with the email\n                hash, instead return an HTTP 404 (File Not Found) response.\n\n            ``mm``\n                Mystery-man, a simple, cartoon-style silhouetted outline of a\n                person (does not vary by email hash).\n\n            ``identicon``\n                A geometric pattern based on an email hash.\n\n            ``monsterid``\n                A generated 'monster' with different colors, faces, etc.\n\n            ``wavatar``\n                Generated faces with differing features and backgrounds\n\n    :return: The URI pointing to the Gravatar.\n\n    \"\"\"\n    if userena_settings.USERENA_MUGSHOT_GRAVATAR_SECURE:\n        base_url = 'https://secure.gravatar.com/avatar/'\n    else: base_url = '//www.gravatar.com/avatar/'\n\n    gravatar_url = '%(base_url)s%(gravatar_id)s?' % \\\n            {'base_url': base_url,\n             'gravatar_id': md5(email.lower().encode('utf-8')).hexdigest()}\n\n    gravatar_url += urlencode({\n        's': str(size),\n        'd': default\n    })\n    return gravatar_url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef signin_redirect(redirect=None, user=None):\n    if redirect: return redirect\n    elif user is not None:\n        return userena_settings.USERENA_SIGNIN_REDIRECT_URL % \\\n                {'username': user.username}\n    else: return settings.LOGIN_REDIRECT_URL", "response": "Returns the URI to redirect to after successful sign in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_sha1(string, salt=None):\n    if not isinstance(string, (str, text_type)):\n        string = str(string)\n\n    if not salt:\n        salt = sha1(str(random.random()).encode('utf-8')).hexdigest()[:5]\n\n    salted_bytes = (smart_bytes(salt) + smart_bytes(string))\n    hash_ = sha1(salted_bytes).hexdigest()\n\n    return salt, hash_", "response": "Generates a sha1 hash for the supplied string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_profile_model():\n    if (not hasattr(settings, 'AUTH_PROFILE_MODULE')) or \\\n           (not settings.AUTH_PROFILE_MODULE):\n        raise SiteProfileNotAvailable\n\n    try:\n        profile_mod = apps.get_model(*settings.AUTH_PROFILE_MODULE.rsplit('.', 1))\n    except LookupError:\n        profile_mod = None\n\n    if profile_mod is None:\n        raise SiteProfileNotAvailable\n    return profile_mod", "response": "Returns the model class that is used as profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the message and send it out into the wide world.", "response": "def save(self, sender):\n        \"\"\"\n        Save the message and send it out into the wide world.\n\n        :param sender:\n            The :class:`User` that sends the message.\n\n        :param parent_msg:\n            The :class:`Message` that preceded this message in the thread.\n\n        :return: The saved :class:`Message`.\n\n        \"\"\"\n        um_to_user_list = self.cleaned_data['to']\n        body = self.cleaned_data['body']\n\n        msg = Message.objects.send_message(sender,\n                                           um_to_user_list,\n                                           body)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the username is alphanumeric and is not already in use.", "response": "def clean_username(self):\n        \"\"\"\n        Validate that the username is alphanumeric and is not already in use.\n        Also validates that the username is not listed in\n        ``USERENA_FORBIDDEN_USERNAMES`` list.\n\n        \"\"\"\n        try:\n            user = get_user_model().objects.get(username__iexact=self.cleaned_data['username'])\n        except get_user_model().DoesNotExist:\n            pass\n        else:\n            if userena_settings.USERENA_ACTIVATION_REQUIRED and UserenaSignup.objects.filter(user__username__iexact=self.cleaned_data['username']).exclude(activation_key=userena_settings.USERENA_ACTIVATED):\n                raise forms.ValidationError(_('This username is already taken but not confirmed. Please check your email for verification steps.'))\n            raise forms.ValidationError(_('This username is already taken.'))\n        if self.cleaned_data['username'].lower() in userena_settings.USERENA_FORBIDDEN_USERNAMES:\n            raise forms.ValidationError(_('This username is not allowed.'))\n        return self.cleaned_data['username']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the e - mail address is unique.", "response": "def clean_email(self):\n        \"\"\" Validate that the e-mail address is unique. \"\"\"\n        if get_user_model().objects.filter(email__iexact=self.cleaned_data['email']):\n            if userena_settings.USERENA_ACTIVATION_REQUIRED and UserenaSignup.objects.filter(user__email__iexact=self.cleaned_data['email']).exclude(activation_key=userena_settings.USERENA_ACTIVATED):\n                raise forms.ValidationError(_('This email is already in use but not confirmed. Please check your email for verification steps.'))\n            raise forms.ValidationError(_('This email is already in use. Please supply a different email.'))\n        return self.cleaned_data['email']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n        if 'password1' in self.cleaned_data and 'password2' in self.cleaned_data:\n            if self.cleaned_data['password1'] != self.cleaned_data['password2']:\n                raise forms.ValidationError(_('The two password fields didn\\'t match.'))\n        return self.cleaned_data", "response": "Validates that the values entered into the two password fields match."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new user and returns the newly created user.", "response": "def save(self):\n        \"\"\" Creates a new user and account. Returns the newly created user. \"\"\"\n        username, email, password = (self.cleaned_data['username'],\n                                     self.cleaned_data['email'],\n                                     self.cleaned_data['password1'])\n\n        new_user = UserenaSignup.objects.create_user(username,\n                                                     email,\n                                                     password,\n                                                     not userena_settings.USERENA_ACTIVATION_REQUIRED,\n                                                     userena_settings.USERENA_ACTIVATION_REQUIRED)\n        return new_user"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a random username before falling back to parent signup form", "response": "def save(self):\n        \"\"\" Generate a random username before falling back to parent signup form \"\"\"\n        while True:\n            username = sha1(str(random.random()).encode('utf-8')).hexdigest()[:5]\n            try:\n                get_user_model().objects.get(username__iexact=username)\n            except get_user_model().DoesNotExist: break\n\n        self.cleaned_data['username'] = username\n        return super(SignupFormOnlyEmail, self).save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks for the combination of the identification and password and returns a dict of the user s attributes.", "response": "def clean(self):\n        \"\"\"\n        Checks for the identification and password.\n\n        If the combination can't be found will raise an invalid sign in error.\n\n        \"\"\"\n        identification = self.cleaned_data.get('identification')\n        password = self.cleaned_data.get('password')\n\n        if identification and password:\n            user = authenticate(identification=identification, password=password)\n            if user is None:\n                raise forms.ValidationError(_(\"Please enter a correct username or email and password. Note that both fields are case-sensitive.\"))\n        return self.cleaned_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an object - per - line JSON file into a log data dict", "response": "def parse_file(self, sourcepath):\n        \"\"\"Parse an object-per-line JSON file into a log data dict\"\"\"\n\n        # Open input file and read JSON array:\n        with open(sourcepath, 'r') as logfile:\n            jsonlist = logfile.readlines()\n\n        # Set our attributes for this entry and add it to data.entries:\n        data = {}\n        data['entries'] = []\n        for line in jsonlist:\n            entry = self.parse_line(line)\n            data['entries'].append(entry)\n        if self.tzone:\n            for e in data['entries']:\n                e['tzone'] = self.tzone\n\n        # Return the parsed data\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering log data by preceeding time period.", "response": "def filter_data(self, data, value=None, args=None):\n        \"\"\"Morph log data by preceeding time period (single log)\"\"\"\n        if args:\n            if not args.last:\n                return data\n        if not value: value = args.last\n        # Set the units and number from the option:\n        lastunit = value[-1]\n        lastnum = value[:-1]\n        \n        # Set the start time:\n        if lastunit == 's':\n            starttime = datetime.utcnow() - \\\n                    timedelta(seconds=int(lastnum))\n        if lastunit == 'm':\n            starttime = datetime.utcnow() - \\\n                    timedelta(minutes=int(lastnum))\n        if lastunit == 'h':\n            starttime = datetime.utcnow() - \\\n                    timedelta(hours=int(lastnum))\n        if lastunit == 'd':\n            starttime = datetime.utcnow() - \\\n                    timedelta(days=int(lastnum))\n        ourstart = int(starttime.strftime('%Y%m%d%H%M%S'))\n        \n        # Pull out the specified time period:\n        newdata = {}\n        if 'parser' in data.keys():\n            newdata['parser'] = data['parser']\n            newdata['source_path'] = data['source_path']\n            newdata['source_file'] = data['source_file']\n            newdata['source_file_mtime'] = data['source_file_mtime']\n            newdata['source_file_year'] = data['source_file_year']\n        newdata['entries'] = []\n\n        for entry in data['entries']:\n            if 'numeric_date_stamp_utc' in entry.keys():\n                if '.' in entry['numeric_date_stamp_utc']:\n                    dstamp = int(entry['numeric_date_stamp_utc'].split('.')[0])\n                else:\n                    dstamp = int(entry['numeric_date_stamp_utc'])\n                if dstamp >= ourstart: \n                    newdata['entries'].append(entry)\n\n        return newdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a single JSON object into a LogData object", "response": "def parse_file(self, sourcepath):\n        \"\"\"Parse single JSON object into a LogData object\"\"\"\n\n        # Open input file and read JSON array:\n        with open(sourcepath, 'r') as logfile:\n            jsonstr = logfile.read()\n\n        # Set our attributes for this entry and add it to data.entries:\n        data = {}\n        data['entries'] = json.loads(jsonstr)\n        if self.tzone:\n            for e in data['entries']:\n                e['tzone'] = self.tzone\n\n        # Return the parsed data\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_data(self, data, values=None, args=None):\n        if args:\n            if not args.rpattern:\n                return data\n        if not values: values = args.rpattern\n        newdata = {}\n        if 'parser' in data.keys():\n            newdata['parser'] = data['parser']\n            newdata['source_path'] = data['source_path']\n            newdata['source_file'] = data['source_file']\n            newdata['source_file_mtime'] = data['source_file_mtime']\n            newdata['source_file_year'] = data['source_file_year']\n        newdata['entries'] = []\n\n        repatterns = {}\n        for rpat in values:\n            repatterns[rpat] = re.compile(r\".*({}).*\".format(args.rpattern))\n\n        for entry in data['entries']:\n            match = False\n            for r in args.rgrep:\n                if re.match(repatterns[r], entry['raw_text']):\n                    match = True\n\n            if not match:\n                newdata['entries'].append(entry)\n\n        return newdata", "response": "Filter data by pattern"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a logdissect job", "response": "def run_job(self):\n        \"\"\"Execute a logdissect job\"\"\"\n        try:\n            self.load_parsers()\n            self.load_filters()\n            self.load_outputs()\n            self.config_args()\n            if self.args.list_parsers:\n                self.list_parsers()\n            if self.args.verbosemode: print('Loading input files')\n            self.load_inputs()\n            if self.args.verbosemode: print('Running parsers')\n            self.run_parse()\n            if self.args.verbosemode: print('Merging data')\n            self.data_set['finalized_data'] = \\\n                    logdissect.utils.merge_logs(\n                            self.data_set['data_set'], sort=True)\n            if self.args.verbosemode: print('Running filters')\n            self.run_filters()\n            if self.args.verbosemode: print('Running output')\n            self.run_output()\n        except KeyboardInterrupt:\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing one or more log files", "response": "def run_parse(self):\n        \"\"\"Parse one or more log files\"\"\"\n        # Data set already has source file names from load_inputs\n        parsedset = {}\n        parsedset['data_set'] = []\n        for log in self.input_files:\n            parsemodule = self.parse_modules[self.args.parser]\n            try:\n                if self.args.tzone:\n                    parsemodule.tzone = self.args.tzone\n            except NameError: pass\n            parsedset['data_set'].append(parsemodule.parse_file(log))\n        self.data_set = parsedset\n        del(parsedset)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_output(self):\n        for f in logdissect.output.__formats__:\n            ouroutput = self.output_modules[f]\n            ouroutput.write_output(self.data_set['finalized_data'],\n                    args=self.args)\n            del(ouroutput)\n\n        # Output to terminal if silent mode is not set:\n        if not self.args.silentmode:\n            if self.args.verbosemode:\n                print('\\n==== ++++ ==== Output: ==== ++++ ====\\n')\n            for line in self.data_set['finalized_data']['entries']:\n                print(line['raw_text'])", "response": "Output finalized data to terminal"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_inputs(self):\n        for f in self.args.files:\n            if os.path.isfile(f):\n                fparts = str(f).split('.')\n                if fparts[-1] == 'gz':\n                    if self.args.unzip:\n                        fullpath = os.path.abspath(str(f))\n                        self.input_files.append(fullpath)\n                    else:\n                        return 0\n                elif fparts[-1] == 'bz2' or fparts[-1] == 'zip':\n                    return 0\n                else:\n                    fullpath = os.path.abspath(str(f))\n                    self.input_files.append(fullpath)\n            else:\n                print('File '+ f + ' not found')\n                return 1", "response": "Load the specified inputs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_parsers(self, *args):\n        print('==== Available parsing modules: ====\\n')\n        for parser in sorted(self.parse_modules):\n            print(self.parse_modules[parser].name.ljust(16) + \\\n                ': ' + self.parse_modules[parser].desc)\n        sys.exit(0)", "response": "Return a list of available parsing modules"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the parser modules.", "response": "def load_parsers(self):\n        \"\"\"Load parsing module(s)\"\"\"\n        for parser in sorted(logdissect.parsers.__all__):\n            self.parse_modules[parser] = \\\n                __import__('logdissect.parsers.' + parser, globals(), \\\n                locals(), [logdissect]).ParseModule()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning datestamp converted to UTC", "response": "def get_utc_date(entry):\n    \"\"\"Return datestamp converted to UTC\"\"\"\n    if entry['numeric_date_stamp'] == '0':\n        entry['numeric_date_stamp_utc'] = '0'\n        return entry\n\n    else:\n        if '.' in entry['numeric_date_stamp']:\n            t = datetime.strptime(entry['numeric_date_stamp'],\n                    '%Y%m%d%H%M%S.%f')\n        else:\n            t = datetime.strptime(entry['numeric_date_stamp'],\n                    '%Y%m%d%H%M%S')\n        tdelta = timedelta(hours = int(entry['tzone'][1:3]),\n                minutes = int(entry['tzone'][3:5]))\n\n        if entry['tzone'][0] == '-':\n            ut = t + tdelta\n        else:\n            ut = t - tdelta\n\n        entry['numeric_date_stamp_utc'] = ut.strftime('%Y%m%d%H%M%S.%f')\n\n        return entry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the current time zone on the local host", "response": "def get_local_tzone():\n    \"\"\"Get the current time zone on the local host\"\"\"\n    if localtime().tm_isdst:\n        if altzone < 0:\n            tzone = '+' + \\\n                    str(int(float(altzone) / 60 // 60)).rjust(2,\n                            '0') + \\\n                            str(int(float(\n                                altzone) / 60 % 60)).ljust(2, '0')\n        else:\n            tzone = '-' + \\\n                    str(int(float(altzone) / 60 // 60)).rjust(2,\n                            '0') + \\\n                            str(int(float(\n                                altzone) / 60 % 60)).ljust(2, '0')\n    else:\n        if altzone < 0:\n            tzone = \\\n                    '+' + str(int(float(timezone) / 60 // 60)).rjust(2,\n                            '0') + \\\n                            str(int(float(\n                                timezone) / 60 % 60)).ljust(2, '0')\n        else:\n            tzone = \\\n                    '-' + str(int(float(timezone) / 60 // 60)).rjust(2,\n                            '0') + \\\n                            str(int(float(\n                                timezone) / 60 % 60)).ljust(2, '0')\n\n    return tzone"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging log dictionaries together into one log dictionary", "response": "def merge_logs(dataset, sort=True):\n    \"\"\"Merge log dictionaries together into one log dictionary\"\"\"\n    ourlog = {}\n    ourlog['entries'] = []\n    for d in dataset:\n        ourlog['entries'] = ourlog['entries'] + d['entries']\n    if sort:\n        ourlog['entries'].sort(key= lambda x: x['numeric_date_stamp_utc'])\n\n    return ourlog"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering data by pattern", "response": "def filter_data(self, data, values=None, args=None):\n        \"\"\"Return entries containing specified patterns (single log)\"\"\"\n        if args:\n            if not args.pattern:\n                return data\n        if not values: values = args.pattern\n        newdata = {}\n        if 'parser' in data.keys():\n            newdata['parser'] = data['parser']\n            newdata['source_path'] = data['source_path']\n            newdata['source_file'] = data['source_file']\n            newdata['source_file_mtime'] = data['source_file_mtime']\n            newdata['source_file_year'] = data['source_file_year']\n        newdata['entries'] = []\n\n        repatterns = {}\n        for pat in values:\n            repatterns[pat] = re.compile(r\".*({}).*\".format(pat))\n\n        for entry in data['entries']:\n            for repat in repatterns:\n                if re.match(repatterns[repat], entry['raw_text']):\n                    newdata['entries'].append(entry)\n                    break\n\n        return newdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_output(self, data, args=None, filename=None, label=None):\n        if args:\n            if not args.outlog:\n                return 0\n        if not filename: filename=args.outlog\n        lastpath = ''\n        with open(str(filename), 'w') as output_file:\n            for entry in data['entries']:\n                if args.label:\n                    if entry['source_path'] == lastpath:\n                        output_file.write(entry['raw_text'] + '\\n')\n                    elif args.label == 'fname':\n                        output_file.write('======== ' + \\\n                                entry['source_path'].split('/')[-1] + \\\n                                ' >>>>\\n' + entry['raw_text'] + '\\n')\n                    elif args.label == 'fpath':\n                        output_file.write('======== ' + \\\n                                entry['source_path']  + \\\n                                ' >>>>\\n' + entry['raw_text'] + '\\n')\n                else: output_file.write(entry['raw_text'] + '\\n')\n                lastpath = entry['source_path']", "response": "Write log data to a log file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite log data to a single JSON object", "response": "def write_output(self, data, args=None, filename=None, pretty=False):\n        \"\"\"Write log data to a single JSON object\"\"\"\n        if args:\n            if not args.sojson:\n                return 0\n            pretty = args.pretty\n        if not filename: filename = args.sojson\n        if pretty:\n            logstring = json.dumps(\n                    data['entries'], indent=2, sort_keys=True,\n                    separators=(',', ': '))\n        else:\n            logstring = json.dumps(data['entries'], sort_keys=True)\n        \n        with open(str(filename), 'w') as output_file:\n            output_file.write(logstring)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_output(self, data, filename=None, args=None):\n        if args:\n            if not args.linejson:\n                return 0\n        if not filename: filename = args.linejson\n        entrylist = []\n        for entry in data['entries']:\n            entrystring = json.dumps(entry, sort_keys=True)\n            entrylist.append(entrystring)\n        \n        with open(str(filename), 'w') as output_file:\n            output_file.write('\\n'.join(entrylist))", "response": "Write log data to a file with one JSON object per line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a file into a LogData object", "response": "def parse_file(self, sourcepath):\n        \"\"\"Parse a file into a LogData object\"\"\"\n        # Get regex objects:\n        self.date_regex = re.compile(\n                r'{}'.format(self.format_regex))\n        if self.backup_format_regex:\n            self.backup_date_regex = re.compile(\n                    r'{}'.format(self.backup_format_regex))\n        data = {}\n        data['entries'] = []\n        data['parser'] = self.name\n        data['source_path'] = sourcepath\n        data['source_file'] = sourcepath.split('/')[-1]\n\n        # Set our start year:\n        data['source_file_mtime'] = os.path.getmtime(data['source_path'])\n        timestamp = datetime.fromtimestamp(data['source_file_mtime'])\n        data['source_file_year'] = timestamp.year\n        entryyear = timestamp.year\n        currentmonth = '99'\n        if self.datestamp_type == 'nodate':\n            self.datedata = {}\n            self.datedata['timestamp'] = timestamp\n            self.datedata['entry_time'] = int(timestamp.strftime('%H%M%S'))\n\n        # Set our timezone\n        if not self.tzone:\n            self.backuptzone = logdissect.utils.get_local_tzone()\n\n        # Parsing works in reverse. This helps with multi-line entries,\n        # and logs that span multiple years (December to January shift).\n\n        # Get our lines:\n        fparts = sourcepath.split('.')\n        if fparts[-1] == 'gz':\n            with gzip.open(sourcepath, 'r') as logfile:\n                loglines = reversed(logfile.readlines())\n        else:\n            with open(str(sourcepath), 'r') as logfile:\n                loglines = reversed(logfile.readlines())\n\n        # Parse our lines:\n        for line in loglines:\n            ourline = line.rstrip()\n\n            # Send the line to self.parse_line\n            entry = self.parse_line(ourline)\n\n            if entry:\n                if 'date_stamp' in self.fields:\n                    # Check for Dec-Jan jump and set the year:\n                    if self.datestamp_type == 'standard':\n                        if int(entry['month']) > int(currentmonth):\n                            entryyear = entryyear - 1\n                        currentmonth = entry['month']\n                    \n                        entry['numeric_date_stamp'] = str(entryyear) \\\n                                + entry['month'] + entry['day'] + \\\n                                entry['tstamp']\n                        entry['year'] = str(entryyear)\n                    if self.tzone:\n                        entry['tzone'] = self.tzone\n                    else:\n                        entry['tzone'] = self.backuptzone\n                    entry = logdissect.utils.get_utc_date(entry)\n                entry['raw_text'] = ourline\n                entry['source_path'] = data['source_path']\n\n                # Append current entry\n                data['entries'].append(entry)\n\n            else:\n                continue\n\n        # Write the entries to the log object\n        data['entries'].reverse()\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_line(self, line):\n        match = re.findall(self.date_regex, line)\n        if match:\n            fields = self.fields\n        elif self.backup_format_regex and not match:\n            match = re.findall(self.backup_date_regex, line)\n            fields = self.backup_fields\n\n        if match:\n            entry = {}\n            entry['raw_text'] = line\n            entry['parser'] = self.name\n\n            matchlist = list(zip(fields, match[0]))\n            for f, v in matchlist:\n                entry[f] = v\n\n            if 'date_stamp' in entry.keys():\n                if self.datestamp_type == 'standard':\n                    entry = logdissect.utils.convert_standard_datestamp(entry)\n                elif self.datestamp_type == 'iso':\n                    entry = logdissect.utils.convert_iso_datestamp(\n                            entry)\n                elif self.datestamp_type == 'webaccess':\n                    entry = logdissect.utils.convert_webaccess_datestamp(\n                            entry)\n                elif self.datestamp_type == 'nodate':\n                    entry, self.datedata = \\\n                            logdissect.utils.convert_nodate_datestamp(\n                            entry, self.datedata)\n                elif self.datestamp_type == 'unix':\n                    entry = logdissect.utils.convert_unix_datestamp(\n                            entry)\n            if self.datestamp_type == 'now':\n                entry = logdissect.utils.convert_now_datestamp(\n                        entry)\n\n            entry = self.post_parse_action(entry)\n            return entry\n\n        else:\n            return None", "response": "Parse a line into a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_parse_action(self, entry):\n        if 'source_host' in entry.keys():\n            host = self.ip_port_regex.findall(entry['source_host'])\n            if host:\n                hlist = host[0].split('.')\n                entry['source_host'] = '.'.join(hlist[:4])\n                entry['source_port'] = hlist[-1]\n        if 'dest_host' in entry.keys():\n            host = self.ip_port_regex.findall(entry['dest_host'])\n            if host:\n                hlist = host[0].split('.')\n                entry['dest_host'] = '.'.join(hlist[:4])\n                entry['dest_port'] = hlist[-1]\n\n        return entry", "response": "separate hosts and ports after entry is parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters log data by timestamp range", "response": "def filter_data(self, data, value=None, utc=False, args=None):\n        \"\"\"Morph log data by timestamp range (single log)\"\"\"\n        if args:\n            if not args.range:\n                return data\n        if not value:\n            value = args.range\n            utc = args.utc\n        ourlimits = value.split('-')\n\n        newdata = {}\n        if 'parser' in data.keys():\n            newdata['parser'] = data['parser']\n            newdata['source_path'] = data['source_path']\n            newdata['source_file'] = data['source_file']\n            newdata['source_file_mtime'] = data['source_file_mtime']\n            newdata['source_file_year'] = data['source_file_year']\n        newdata['entries'] = []\n\n        firstdate = int(ourlimits[0].ljust(14, '0'))\n        lastdate = int(ourlimits[1].ljust(14, '0'))\n        for entry in data['entries']:\n            if utc:\n                if 'numeric_date_stamp_utc' in entry:\n                    if 'numeric_date_stamp_utc' in entry:\n                        if '.' in entry['numeric_date_stamp_utc']:\n                            dstamp = int(\n                                    entry['numeric_date_stamp_utc'].split(\n                                        '.')[0])\n                        else:\n                            dstamp = int(entry['numeric_date_stamp_utc'])\n                        if dstamp >= firstdate:\n                            if dstamp <= lastdate:\n                                newdata['entries'].append(entry)\n            else:\n                if 'numeric_date_stamp' in entry:\n                    if '.' in entry['numeric_date_stamp']:\n                        dstamp = int(\n                                entry['numeric_date_stamp'].split('.')[0])\n                    else:\n                        dstamp = int(entry['numeric_date_stamp'])\n                    if dstamp >= firstdate:\n                        if dstamp <= lastdate:\n                            newdata['entries'].append(entry)\n\n        return newdata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter data to only return entries with specified protocol", "response": "def filter_data(self, data, values=None, args=None):\n        \"\"\"Return entries without specified protocol (single log)\"\"\"\n        if args:\n            if not args.rprotocol:\n                return data\n        if not values: values = args.rprotocol\n        newdata = {}\n        if 'parser' in data.keys():\n            newdata['parser'] = data['parser']\n            newdata['source_path'] = data['source_path']\n            newdata['source_file'] = data['source_file']\n            newdata['source_file_mtime'] = data['source_file_mtime']\n            newdata['source_file_year'] = data['source_file_year']\n        newdata['entries'] = []\n\n        for entry in data['entries']:\n            if 'protocol' in entry.keys():\n                if entry['protocol'] not in values:\n                    newdata['entries'].append(entry)\n            else:\n                newdata['entries'].append(entry)\n\n        return newdata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimise_partition(self, partition):\n    # Perhaps we\n    diff = _c_louvain._Optimiser_optimise_partition(self._optimiser, partition._partition)\n    partition._update_internal_membership()\n    return diff", "response": "Optimise the given partition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef optimise_partition_multiplex(self, partitions, layer_weights=None):\n    if not layer_weights:\n      layer_weights = [1]*len(partitions)\n    diff = _c_louvain._Optimiser_optimise_partition_multiplex(\n      self._optimiser,\n      [partition._partition for partition in partitions],\n      layer_weights)\n    for partition in partitions:\n      partition._update_internal_membership()\n    return diff", "response": "This method optimises the given partitions simultaneously."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):\n  if not weights is None:\n    kwargs['weights'] = weights\n  partition = partition_type(graph,\n                             initial_membership=initial_membership,\n                             **kwargs)\n  optimiser = Optimiser()\n  optimiser.optimise_partition(partition)\n  return partition", "response": "This function finds a partition in the given graph using the specified method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_partition_multiplex(graphs, partition_type, **kwargs):\n  n_layers = len(graphs)\n  partitions = []\n  layer_weights = [1]*n_layers\n  for graph in graphs:\n    partitions.append(partition_type(graph, **kwargs))\n  optimiser = Optimiser()\n  improvement = optimiser.optimise_partition_multiplex(partitions, layer_weights)\n  return partitions[0].membership, improvement", "response": "Finds the partition of a list of multiplex graphs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect communities for temporal graphs. Each graph is considered to represent a time slice and does not necessarily need to be defined on the same set of vertices. Nodes in two consecutive slices are identified on the basis of the ``vertex_id_attr``, i.e. if two nodes in two consecutive slices have an identical value of the ``vertex_id_attr`` they are coupled. The ``vertex_id_attr`` should hence be unique in each slice. The nodes are then coupled with a weight of ``interslice_weight`` which is set in the edge attribute ``weight_attr``. No weight is set if the ``interslice_weight`` is None (i.e. corresponding in practice with a weight of 1). See :func:`time_slices_to_layers` for a more detailed explanation. Parameters ---------- graphs : list of :class:`ig.Graph` List of :class:`louvain.VertexPartition` layers to optimise. partition_type : type of :class:`VertexPartition.MutableVertexPartition` The type of partition to use for optimisation (identical for all graphs). interslice_weight : float The weight of the coupling between two consecutive time slices. slice_attr : string The vertex attribute to use for indicating the slice of a node. vertex_id_attr : string The vertex to use to identify nodes. edge_type_attr : string The edge attribute to use for indicating the type of link (`interslice` or `intraslice`). weight_attr : string The edge attribute used to indicate the weight. **kwargs Remaining keyword arguments, passed on to constructor of ``partition_type``. Returns ------- list of membership list containing for each slice the membership vector. float Improvement in quality of combined partitions, see :func:`Optimiser.optimise_partition_multiplex`. See Also -------- :func:`time_slices_to_layers` :func:`slices_to_layers` Examples -------- >>> n = 100 >>> G_1 = ig.Graph.Lattice([n], 1) >>> G_1.vs['id'] = range(n) >>> G_2 = ig.Graph.Lattice([n], 1) >>> G_2.vs['id'] = range(n) >>> membership, improvement = louvain.find_partition_temporal([G_1, G_2], ... louvain.ModularityVertexPartition, ... interslice_weight=1)", "response": "def find_partition_temporal(graphs, partition_type,\n                            interslice_weight=1,\n                            slice_attr='slice', vertex_id_attr='id',\n                            edge_type_attr='type', weight_attr='weight',\n                            **kwargs):\n  \"\"\" Detect communities for temporal graphs.\n\n  Each graph is considered to represent a time slice and does not necessarily\n  need to be defined on the same set of vertices. Nodes in two consecutive\n  slices are identified on the basis of the ``vertex_id_attr``, i.e. if two\n  nodes in two consecutive slices have an identical value of the\n  ``vertex_id_attr`` they are coupled.  The ``vertex_id_attr`` should hence be\n  unique in each slice. The nodes are then coupled with a weight of\n  ``interslice_weight`` which is set in the edge attribute ``weight_attr``. No\n  weight is set if the ``interslice_weight`` is None (i.e.  corresponding in\n  practice with a weight of 1). See :func:`time_slices_to_layers` for\n  a more detailed explanation.\n\n  Parameters\n  ----------\n  graphs : list of :class:`ig.Graph`\n    List of :class:`louvain.VertexPartition` layers to optimise.\n\n  partition_type : type of :class:`VertexPartition.MutableVertexPartition`\n    The type of partition to use for optimisation (identical for all graphs).\n\n  interslice_weight : float\n    The weight of the coupling between two consecutive time slices.\n\n  slice_attr : string\n    The vertex attribute to use for indicating the slice of a node.\n\n  vertex_id_attr : string\n    The vertex to use to identify nodes.\n\n  edge_type_attr : string\n    The edge attribute to use for indicating the type of link (`interslice` or\n    `intraslice`).\n\n  weight_attr : string\n    The edge attribute used to indicate the weight.\n\n  **kwargs\n    Remaining keyword arguments, passed on to constructor of\n    ``partition_type``.\n\n  Returns\n  -------\n  list of membership\n    list containing for each slice the membership vector.\n\n  float\n    Improvement in quality of combined partitions, see\n    :func:`Optimiser.optimise_partition_multiplex`.\n\n  See Also\n  --------\n  :func:`time_slices_to_layers`\n\n  :func:`slices_to_layers`\n\n  Examples\n  --------\n  >>> n = 100\n  >>> G_1 = ig.Graph.Lattice([n], 1)\n  >>> G_1.vs['id'] = range(n)\n  >>> G_2 = ig.Graph.Lattice([n], 1)\n  >>> G_2.vs['id'] = range(n)\n  >>> membership, improvement = louvain.find_partition_temporal([G_1, G_2], \n  ...                                                           louvain.ModularityVertexPartition, \n  ...                                                           interslice_weight=1)\n  \"\"\"\n  # Create layers\n  G_layers, G_interslice, G = time_slices_to_layers(graphs,\n                                                    interslice_weight,\n                                                    slice_attr=slice_attr,\n                                                    vertex_id_attr=vertex_id_attr,\n                                                    edge_type_attr=edge_type_attr,\n                                                    weight_attr=weight_attr)\n  # Optimise partitions\n  arg_dict = {}\n  if 'node_sizes' in partition_type.__init__.__code__.co_varnames:\n    arg_dict['node_sizes'] = 'node_size'\n\n  if 'weights' in partition_type.__init__.__code__.co_varnames:\n    arg_dict['weights'] = 'weight'\n\n  arg_dict.update(kwargs)\n\n  partitions = []\n  for H in G_layers:\n    arg_dict['graph'] = H\n    partitions.append(partition_type(**arg_dict))\n\n  # We can always take the same interslice partition, as this should have no\n  # cost in the optimisation.\n  partition_interslice = CPMVertexPartition(G_interslice, resolution_parameter=0,\n                                            node_sizes='node_size', weights=weight_attr)\n  optimiser = Optimiser()\n  improvement = optimiser.optimise_partition_multiplex(partitions + [partition_interslice])\n  # Transform results back into original form.\n  membership = {(v[slice_attr], v[vertex_id_attr]): m for v, m in zip(G.vs, partitions[0].membership)}\n\n  membership_time_slices = []\n  for slice_idx, H in enumerate(graphs):\n    membership_slice = [membership[(slice_idx, v[vertex_id_attr])] for v in H.vs]\n    membership_time_slices.append(list(membership_slice))\n  return membership_time_slices, improvement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a class that can be used as a replacement for the the build_ext command in distutils and that will download and compile the C core of igraph if needed.", "response": "def build_ext(self):\n        \"\"\"Returns a class that can be used as a replacement for the\n        ``build_ext`` command in ``distutils`` and that will download and\n        compile the C core of igraph if needed.\"\"\"\n        try:\n            from setuptools.command.build_ext import build_ext\n        except ImportError:\n            from distutils.command.build_ext import build_ext\n\n        buildcfg = self\n        class custom_build_ext(build_ext):\n            def run(self):\n                # Print a warning if pkg-config is not available or does not know about igraph\n                if buildcfg.use_pkgconfig:\n                    detected = buildcfg.detect_from_pkgconfig()\n                else:\n                    detected = False\n\n                # Check whether we have already compiled igraph in a previous run.\n                # If so, it should be found in igraphcore/include and\n                # igraphcore/lib\n                if os.path.exists(\"igraphcore\"):\n                    buildcfg.use_built_igraph()\n                    detected = True\n\n                # Download and compile igraph if the user did not disable it and\n                # we do not know the libraries from pkg-config yet\n                if not detected:\n                    if buildcfg.download_igraph_if_needed and is_unix_like():\n                        detected = buildcfg.download_and_compile_igraph()\n                        if detected:\n                            buildcfg.use_built_igraph()\n\n                # Fall back to an educated guess if everything else failed\n                if not detected:\n                    buildcfg.use_educated_guess()\n\n                # Replaces library names with full paths to static libraries\n                # where possible\n                if buildcfg.static_extension:\n                    buildcfg.replace_static_libraries(exclusions=[\"m\"])\n\n                # Prints basic build information\n                buildcfg.print_build_info()\n\n                ext = first(extension for extension in self.extensions\n                        if extension.name == \"louvain._c_louvain\")\n                buildcfg.configure(ext)\n\n                # Run the original build_ext command\n                build_ext.run(self)\n\n        return custom_build_ext"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_membership(self, membership):\n    _c_louvain._MutableVertexPartition_set_membership(self._partition, list(membership))\n    self._update_internal_membership()", "response": "Set the membership of the partition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the difference in the quality function if node v is moved to community new_comm.", "response": "def diff_move(self,v,new_comm):\n    \"\"\" Calculate the difference in the quality function if node ``v`` is\n    moved to community ``new_comm``.\n\n    Parameters\n    ----------\n    v\n      The node to move.\n\n    new_comm\n      The community to move to.\n\n    Returns\n    -------\n    float\n      Difference in quality function.\n\n    Notes\n    -----\n    The difference returned by diff_move should be equivalent to first\n    determining the quality of the partition, then calling move_node, and then\n    determining again the quality of the partition and looking at the\n    difference. In other words\n\n    >>> partition = louvain.find_partition(ig.Graph.Famous('Zachary'),\n    ...                            louvain.ModularityVertexPartition)\n    >>> diff = partition.diff_move(v=0, new_comm=0)\n    >>> q1 = partition.quality()\n    >>> partition.move_node(v=0, new_comm=0)\n    >>> q2 = partition.quality()\n    >>> round(diff, 10) == round(q2 - q1, 10)\n    True\n\n    .. warning:: Only derived classes provide actual implementations, the base\n                 class provides no implementation for this function.\n\n    \"\"\"\n    return _c_louvain._MutableVertexPartition_diff_move(self._partition, v, new_comm)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the total number of edges or sum of weights from node v to community comm.", "response": "def weight_to_comm(self, v, comm):\n    \"\"\" The total number of edges (or sum of weights) from node ``v`` to\n    community ``comm``.\n\n    See Also\n    --------\n    :func:`~VertexPartition.MutableVertexPartition.weight_from_comm`\n    \"\"\"\n    return _c_louvain._MutableVertexPartition_weight_to_comm(self._partition, v, comm)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the total number of edges or sum of weights to node v from community comm.", "response": "def weight_from_comm(self, v, comm):\n    \"\"\" The total number of edges (or sum of weights) to node ``v`` from\n    community ``comm``.\n\n    See Also\n    --------\n    :func:`~VertexPartition.MutableVertexPartition.weight_to_comm`\n    \"\"\"\n    return _c_louvain._MutableVertexPartition_weight_from_comm(self._partition, v, comm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Bipartite(graph, resolution_parameter_01,\n                resolution_parameter_0 = 0, resolution_parameter_1 = 0,\n                degree_as_node_size=False, types='type', **kwargs):\n    \"\"\" Create three layers for bipartite partitions.\n\n    This creates three layers for bipartite partition necessary for detecting\n    communities in bipartite networks. These three layers should be passed to\n    :func:`Optimiser.optimise_partition_multiplex` with\n    ``layer_weights=[1,-1,-1]``.\n\n    Parameters\n    ----------\n    graph : :class:`ig.Graph`\n      Graph to define the bipartite partitions on.\n\n    resolution_parameter_01 : double\n      Resolution parameter for in between two classes.\n\n    resolution_parameter_0 : double\n      Resolution parameter for class 0.\n\n    resolution_parameter_1 : double\n      Resolution parameter for class 1.\n\n    degree_as_node_size : boolean\n      If ``True`` use degree as node size instead of 1, to mimic modularity,\n      see `Notes <#notes-bipartite>`_.\n\n    types : vertex attribute or list\n      Indicator of the class for each vertex. If not 0, 1, it is automatically\n      converted.\n\n    **kwargs\n      Additional arguments passed on to default constructor of\n      :class:`CPMVertexPartition`.\n\n    .. _notes-bipartite:\n\n    Notes\n    -----\n\n    For bipartite networks, we would like to be able to set three different\n    resolution parameters: one for within each class :math:`\\\\gamma_0,\n    \\\\gamma_1`, and one for the links between classes, :math:`\\\\gamma_{01}`.\n    Then the formulation would be\n\n    .. math:: Q = \\\\sum_{ij}\n       [A_{ij}\n        - (\\\\gamma_0\\\\delta(s_i,0) + \\\\gamma_1\\\\delta(s_i,1)) \\\\delta(s_i,s_j)\n        - \\\\gamma_{01}(1 - \\\\delta(s_i, s_j))\n       ]\\\\delta(\\\\sigma_i, \\\\sigma_j)\n\n    In terms of communities this is\n\n    .. math:: Q = \\\\sum_c (e_c\n                          - \\\\gamma_{01} 2 n_c(0) n_c(1)\n                          - \\\\gamma_0 n^2_c(0)\n                          - \\\\gamma_1 n^2_c(1))\n\n    where :math:`n_c(0)` is the number of nodes in community :math:`c` of class 0\n    (and similarly for 1) and :math:`e_c` is the number of edges within community\n    :math:`c`. We denote by :math:`n_c = n_c(0) + n_c(1)` the total number of nodes\n    in community :math:`c`.\n\n    We achieve this by creating three layers : (1) all nodes have ``node_size =\n    1`` and all relevant links; (2) only nodes of class 0 have ``node_size =\n    1`` and no links; (3) only nodes of class 1 have ``node_size = 1`` and no\n    links. If we add the first with resolution parameter :math:`\\\\gamma_{01}`,\n    and the others with resolution parameters :math:`\\\\gamma_{01} - \\\\gamma_0`\n    and :math:`\\\\gamma_{01} - \\\\gamma_1`, but the latter two with a layer\n    weight of -1 while the first layer has layer weight 1, we obtain the\n    following:\n\n    .. math:: Q &=  \\\\sum_c (e_c - \\\\gamma_{01} n_c^2)\n                   -\\\\sum_c (- (\\\\gamma_{01} - \\\\gamma_0) n_c(0)^2)\n                   -\\\\sum_c (- (\\\\gamma_{01} - \\\\gamma_1) n_c(1)^2) \\\\\\\\\n                &=  \\\\sum_c [e_c - \\\\gamma_{01} 2 n_c(0) n_c(1)\n                                 - \\\\gamma_{01} n_c(0)^2\n                                 - \\\\gamma_{01} n_c(1)^2)\n                                 + ( \\\\gamma_{01} - \\\\gamma_0) n_c(0)^2\n                                 + ( \\\\gamma_{01} - \\\\gamma_1) n_c(1)^2\n                           ] \\\\\\\\\n                &=  \\\\sum_c [e_c - \\\\gamma_{01} 2 n_c(0) n_c(1)\n                                 - \\\\gamma_{0} n_c(0)^2\n                                 - \\\\gamma_{1} n_c(1)^2]\n\n    Although the derivation above is using :math:`n_c^2`, implicitly assuming a\n    direct graph with self-loops, similar derivations can be made for\n    undirected graphs using :math:`\\\\binom{n_c}{2}`, but the notation is then\n    somewhat more convoluted.\n\n    If we set node sizes equal to the degree, we get something similar to\n    modularity, except that the resolution parameter should still be divided by\n    :math:`2m`. In particular, in general (i.e. not specifically for bipartite\n    graph) if ``node_sizes=G.degree()`` we then obtain\n\n    .. math:: Q = \\\\sum_{ij} A_{ij} - \\\\gamma k_i k_j\n\n    In the case of bipartite graphs something similar is obtained, but then\n    correctly adapted (as long as the resolution parameter is also\n    appropriately rescaled).\n\n    .. note:: This function is not suited for directed graphs in the case of\n              using the degree as node sizes.\n    \"\"\"\n\n    if types is not None:\n      if isinstance(types, str):\n        types = graph.vs[types]\n      else:\n        # Make sure it is a list\n        types = list(types)\n\n    if set(types) != set([0, 1]):\n      new_type = _ig.UniqueIdGenerator()\n      types = [new_type[t] for t in types]\n\n    if set(types) != set([0, 1]):\n      raise ValueError(\"More than one type specified.\")\n\n    if degree_as_node_size:\n      if (graph.is_directed()):\n        raise ValueError(\"This method is not suitable for directed graphs \" +\n                         \"when using degree as node sizes.\")\n      node_sizes = graph.degree()\n    else:\n      node_sizes = [1]*graph.vcount()\n\n    partition_01 = CPMVertexPartition(graph,\n                     node_sizes=node_sizes,\n                     resolution_parameter=resolution_parameter_01,\n                     **kwargs)\n    H_0 = graph.subgraph_edges([], delete_vertices=False)\n    partition_0 = CPMVertexPartition(H_0, weights=None,\n                     node_sizes=[s if t == 0 else 0\n                                 for v, s, t in zip(graph.vs,node_sizes,types)],\n                     resolution_parameter=resolution_parameter_01 - resolution_parameter_0,\n                     **kwargs)\n    H_1 = graph.subgraph_edges([], delete_vertices=False)\n    partition_1 = CPMVertexPartition(H_1, weights=None,\n                     node_sizes=[s if t == 1 else 0\n                                 for v, s, t in zip(graph.vs,node_sizes,types)],\n                     resolution_parameter=resolution_parameter_01 - resolution_parameter_1,\n                     **kwargs)\n    return partition_01, partition_0, partition_1", "response": "This function creates a bipartite partition for a given set of edges."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spacing(text):\n    if len(text) <= 1 or not ANY_CJK.search(text):\n        return text\n\n    new_text = text\n\n    # TODO: refactoring\n    matched = CONVERT_TO_FULLWIDTH_CJK_SYMBOLS_CJK.search(new_text)\n    while matched:\n        start, end = matched.span()\n        new_text = ''.join((new_text[:start + 1], convert_to_fullwidth(new_text[start + 1:end - 1]), new_text[end - 1:]))\n        matched = CONVERT_TO_FULLWIDTH_CJK_SYMBOLS_CJK.search(new_text)\n\n    matched = CONVERT_TO_FULLWIDTH_CJK_SYMBOLS.search(new_text)\n    while matched:\n        start, end = matched.span()\n        new_text = ''.join((new_text[:start + 1].strip(), convert_to_fullwidth(new_text[start + 1:end]), new_text[end:].strip()))\n        matched = CONVERT_TO_FULLWIDTH_CJK_SYMBOLS.search(new_text)\n\n    new_text = DOTS_CJK.sub(r'\\1 \\2', new_text)\n    new_text = FIX_CJK_COLON_ANS.sub(r'\\1\uff1a\\2', new_text)\n\n    new_text = CJK_QUOTE.sub(r'\\1 \\2', new_text)\n    new_text = QUOTE_CJK.sub(r'\\1 \\2', new_text)\n    new_text = FIX_QUOTE_ANY_QUOTE.sub(r'\\1\\3\\5', new_text)\n\n    new_text = CJK_SINGLE_QUOTE_BUT_POSSESSIVE.sub(r'\\1 \\2', new_text)\n    new_text = SINGLE_QUOTE_CJK.sub(r'\\1 \\2', new_text)\n    new_text = FIX_POSSESSIVE_SINGLE_QUOTE.sub(r\"\\1's\", new_text)\n\n    new_text = HASH_ANS_CJK_HASH.sub(r'\\1 \\2\\3\\4 \\5', new_text)\n    new_text = CJK_HASH.sub(r'\\1 \\2', new_text)\n    new_text = HASH_CJK.sub(r'\\1 \\3', new_text)\n\n    new_text = CJK_OPERATOR_ANS.sub(r'\\1 \\2 \\3', new_text)\n    new_text = ANS_OPERATOR_CJK.sub(r'\\1 \\2 \\3', new_text)\n\n    new_text = FIX_SLASH_AS.sub(r'\\1\\2', new_text)\n    new_text = FIX_SLASH_AS_SLASH.sub(r'\\1\\2\\3', new_text)\n\n    new_text = CJK_LEFT_BRACKET.sub(r'\\1 \\2', new_text)\n    new_text = RIGHT_BRACKET_CJK.sub(r'\\1 \\2', new_text)\n    new_text = FIX_LEFT_BRACKET_ANY_RIGHT_BRACKET.sub(r'\\1\\3\\5', new_text)\n    new_text = ANS_CJK_LEFT_BRACKET_ANY_RIGHT_BRACKET.sub(r'\\1 \\2\\3\\4', new_text)\n    new_text = LEFT_BRACKET_ANY_RIGHT_BRACKET_ANS_CJK.sub(r'\\1\\2\\3 \\4', new_text)\n\n    new_text = AN_LEFT_BRACKET.sub(r'\\1 \\2', new_text)\n    new_text = RIGHT_BRACKET_AN.sub(r'\\1 \\2', new_text)\n\n    new_text = CJK_ANS.sub(r'\\1 \\2', new_text)\n    new_text = ANS_CJK.sub(r'\\1 \\2', new_text)\n\n    new_text = S_A.sub(r'\\1 \\2', new_text)\n\n    new_text = MIDDLE_DOT.sub('\u30fb', new_text)\n\n    return new_text.strip()", "response": "Perform paranoid text spacing on text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spacing_file(path):\n    # TODO: read line by line\n    with open(os.path.abspath(path)) as f:\n        return spacing_text(f.read())", "response": "Perform paranoid text spacing from file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute(self,\n                text,           # text for which to find the most similar event\n                lang = \"eng\"):  # language in which the text is written\n        \"\"\"\n        compute the list of most similar events for the given text\n        \"\"\"\n        params = { \"lang\": lang, \"text\": text, \"topClustersCount\": self._nrOfEventsToReturn }\n        res = self._er.jsonRequest(\"/json/getEventForText/enqueueRequest\", params)\n\n        requestId = res[\"requestId\"]\n        for i in range(10):\n            time.sleep(1)   # sleep for 1 second to wait for the clustering to perform computation\n            res = self._er.jsonRequest(\"/json/getEventForText/testRequest\", { \"requestId\": requestId })\n            if isinstance(res, list) and len(res) > 0:\n                return res\n        return None", "response": "compute the most similar event for the given text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getUpdates(self):\n        # execute the query\n        ret = self._er.execQuery(self)\n\n        if ret and \"recentActivityEvents\" in ret:\n            # return the updated information\n            return ret[\"recentActivityEvents\"]\n        # or empty\n        return {}", "response": "Get the latest new or updated events from Event Registry"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef annotate(self, text, lang = None, customParams = None):\n        params = {\"lang\": lang, \"text\": text}\n        if customParams:\n            params.update(customParams)\n        return self._er.jsonRequestAnalytics(\"/api/v1/annotate\", params)", "response": "annotate the list of entities and nonentities mentioned in the input text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sentiment(self, text, method = \"vocabulary\"):\n        assert method == \"vocabulary\" or method == \"rnn\"\n        endpoint = method == \"vocabulary\" and \"sentiment\" or \"sentimentRNN\"\n        return self._er.jsonRequestAnalytics(\"/api/v1/\" + endpoint, { \"text\": text })", "response": "returns the sentiment of the provided text in English language"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the semantic similarity of the two provided documents @param text1: first document to analyze @param text2: second document to analyze @param distanceMeasure: distance measure to use for comparing two documents. Possible values are \"cosine\" (default) or \"jaccard\" @returns: dict", "response": "def semanticSimilarity(self, text1, text2, distanceMeasure = \"cosine\"):\n        \"\"\"\n        determine the semantic similarity of the two provided documents\n        @param text1: first document to analyze\n        @param text2: second document to analyze\n        @param distanceMeasure: distance measure to use for comparing two documents. Possible values are \"cosine\" (default) or \"jaccard\"\n        @returns: dict\n        \"\"\"\n        return self._er.jsonRequestAnalytics(\"/api/v1/semanticSimilarity\", { \"text1\": text1, \"text2\": text2, \"distanceMeasure\": distanceMeasure })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract all available information about an article at url", "response": "def extractArticleInfo(self, url, proxyUrl = None, headers = None, cookies = None):\n        \"\"\"\n        extract all available information about an article available at url `url`. Returned information will include\n        article title, body, authors, links in the articles, ...\n        @param url: article url to extract article information from\n        @param proxyUrl: proxy that should be used for downloading article information. format: {schema}://{username}:{pass}@{proxy url/ip}\n        @param headers: dict with headers to set in the request (optional)\n        @param cookies: dict with cookies to set in the request (optional)\n        @returns: dict\n        \"\"\"\n        params = { \"url\": url }\n        if proxyUrl:\n            params[\"proxyUrl\"] = proxyUrl\n        if headers:\n            if isinstance(headers, dict):\n                headers = json.dumps(headers)\n            params[\"headers\"] = headers\n        if cookies:\n            if isinstance(cookies, dict):\n                cookies = json.dumps(cookies)\n            params[\"cookies\"] = cookies\n        return self._er.jsonRequestAnalytics(\"/api/v1/extractArticleInfo\", params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain a topic on tweets", "response": "def trainTopicOnTweets(self, twitterQuery, useTweetText=True, useIdfNormalization=True,\n            normalization=\"linear\", maxTweets=2000, maxUsedLinks=500, ignoreConceptTypes=[],\n            maxConcepts = 20, maxCategories = 10, notifyEmailAddress = None):\n        \"\"\"\n        create a new topic and train it using the tweets that match the twitterQuery\n        @param twitterQuery: string containing the content to search for. It can be a Twitter user account (using \"@\" prefix or user's Twitter url),\n                a hash tag (using \"#\" prefix) or a regular keyword.\n        @param useTweetText: do you want to analyze the content of the tweets and extract the concepts mentioned in them? If False, only content shared\n            in the articles in the user's tweets will be analyzed\n        @param useIdfNormalization: normalize identified concepts by their IDF in the news (punish very common concepts)\n        @param normalization: way to normalize the concept weights (\"none\", \"linear\")\n        @param maxTweets: maximum number of tweets to collect (default 2000, max 5000)\n        @param maxUsedLinks: maximum number of article links in the tweets to analyze (default 500, max 2000)\n        @param ignoreConceptTypes: what types of concepts you would like to ignore in the profile. options: person, org, loc, wiki or an array with those\n        @param maxConcepts: the number of concepts to save in the final topic\n        @param maxCategories: the number of categories to save in the final topic\n        @param maxTweets: the maximum number of tweets to collect for the user to analyze\n        @param notifyEmailAddress: when finished, should we send a notification email to this address?\n        \"\"\"\n        assert maxTweets < 5000, \"we can analyze at most 5000 tweets\"\n        params = {\"twitterQuery\": twitterQuery, \"useTweetText\": useTweetText,\n            \"useIdfNormalization\": useIdfNormalization, \"normalization\": normalization,\n            \"maxTweets\": maxTweets, \"maxUsedLinks\": maxUsedLinks,\n            \"maxConcepts\": maxConcepts, \"maxCategories\": maxCategories }\n        if notifyEmailAddress:\n            params[\"notifyEmailAddress\"] = notifyEmailAddress\n        if len(ignoreConceptTypes) > 0:\n            params[\"ignoreConceptTypes\"] = ignoreConceptTypes\n        return self._er.jsonRequestAnalytics(\"/api/v1/trainTopicOnTwitter\", params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the trained topic for the topic for which you have already finished training", "response": "def trainTopicGetTrainedTopic(self, uri, maxConcepts = 20, maxCategories = 10,\n            ignoreConceptTypes=[], idfNormalization = True):\n        \"\"\"\n        retrieve topic for the topic for which you have already finished training\n        @param uri: uri of the topic (obtained by calling trainTopicCreateTopic method)\n        @param maxConcepts: number of top concepts to retrieve in the topic\n        @param maxCategories: number of top categories to retrieve in the topic\n        @param ignoreConceptTypes: what types of concepts you would like to ignore in the profile. options: person, org, loc, wiki or an array with those\n        @param idfNormalization: should the concepts be normalized by punishing the commonly mentioned concepts\n        @param returns: returns the trained topic: { concepts: [], categories: [] }\n        \"\"\"\n        return self._er.jsonRequestAnalytics(\"/api/v1/trainTopic\", { \"action\": \"getTrainedTopic\", \"uri\": uri, \"maxConcepts\": maxConcepts, \"maxCategories\": maxCategories, \"idfNormalization\": idfNormalization })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createTopicPage1():\n    topic = TopicPage(er)\n    topic.addKeyword(\"renewable energy\", 30)\n    topic.addConcept(er.getConceptUri(\"biofuel\"), 50)\n    topic.addConcept(er.getConceptUri(\"solar energy\"), 50)\n    topic.addCategory(er.getCategoryUri(\"renewable\"), 50)\n\n    # skip articles that are duplicates of other articles\n    topic.articleHasDuplicateFilter(\"skipHasDuplicates\")\n    # return only articles that are about some event that we have detected\n    topic.articleHasEventFilter(\"skipArticlesWithoutEvent\")\n\n    # get first 2 pages of articles sorted by relevance to the topic page\n    arts1 = topic.getArticles(page=1, sortBy=\"rel\")\n    arts2 = topic.getArticles(page=2, sortBy=\"rel\")\n\n    # get first page of events\n    events1 = topic.getEvents(page=1)", "response": "create a topic page directly"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createTopicPage2():\n    topic = TopicPage(er)\n\n    topic.addCategory(er.getCategoryUri(\"renewable\"), 50)\n\n    topic.addKeyword(\"renewable energy\", 30)\n    topic.addConcept(er.getConceptUri(\"biofuel\"), 50)\n    topic.addConcept(er.getConceptUri(\"solar energy\"), 50)\n    # require that the results will mention at least one of the concepts and keywords specified\n    # (even though they might have the category about renewable energy, that will not be enough\n    # for an article to be among the results)\n    topic.restrictToSetConceptsAndKeywords(True)\n\n    # limit results to English, German and Spanish results\n    topic.setLanguages([\"eng\", \"deu\", \"spa\"])\n\n    # get results that are at most 3 days old\n    topic.setMaxDaysBack(3)\n\n    # require that the articles that will be returned should get at least a total score of 30 points or more\n    # based on the specified list of conditions\n    topic.setArticleThreshold(30)\n\n    # get first page of articles sorted by date (from most recent backward) to the topic page\n    arts1 = topic.getArticles(page=1,\n        sortBy=\"date\",\n        returnInfo=ReturnInfo(\n            articleInfo = ArticleInfoFlags(concepts=True, categories=True)\n        ))\n    for art in arts1.get(\"articles\", {}).get(\"results\", []):\n        print(art)", "response": "create a topic page directly"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count(self, eventRegistry):\n        self.setRequestedResult(RequestEventArticles(**self.queryParams))\n        res = eventRegistry.execQuery(self)\n        if \"error\" in res:\n            print(res[\"error\"])\n        count = res.get(self.queryParams[\"eventUri\"], {}).get(\"articles\", {}).get(\"totalResults\", 0)\n        return count", "response": "returns the number of articles that match the criteria\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the query and return the results.", "response": "def execQuery(self, eventRegistry,\n            sortBy = \"cosSim\", sortByAsc = False,\n            returnInfo = None,\n            maxItems = -1):\n        \"\"\"\n        @param eventRegistry: instance of EventRegistry class. used to obtain the necessary data\n\n        @param sortBy: order in which event articles are sorted. Options: none (no specific sorting), id (internal id), date (published date), cosSim (closeness to event centroid), sourceImportance (manually curated score of source importance - high value, high importance), sourceImportanceRank (reverse of sourceImportance), sourceAlexaGlobalRank (global rank of the news source), sourceAlexaCountryRank (country rank of the news source), socialScore (total shares on social media), facebookShares (shares on Facebook only)\n        @param sortByAsc: should the results be sorted in ascending order (True) or descending (False)\n        @param returnInfo: what details should be included in the returned information\n        @param maxItems: maximum number of items to be returned. Used to stop iteration sooner than results run out\n        \"\"\"\n        self._er = eventRegistry\n        self._articlePage = 0\n        self._totalPages = None\n        # if we want to return only a subset of items:\n        self._maxItems = maxItems\n        self._currItem = 0\n\n        self._articlesSortBy = sortBy\n        self._articlesSortByAsc = sortByAsc\n        self._returnInfo = returnInfo\n\n        # download the list of article uris\n        self._articleList = []\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads next batch of events based on the event uris in the uri list", "response": "def _getNextArticleBatch(self):\n        \"\"\"download next batch of events based on the event uris in the uri list\"\"\"\n        eventUri = self.queryParams[\"eventUri\"]\n        # move to the next page to download\n        self._articlePage += 1\n        # if we have already obtained all pages, then exit\n        if self._totalPages != None and self._articlePage > self._totalPages:\n            return\n        if self._er._verboseOutput:\n            print(\"Downloading article page %d from event %s\" % (self._articlePage, eventUri))\n\n        self.setRequestedResult(RequestEventArticles(\n            page = self._articlePage,\n            sortBy = self._articlesSortBy, sortByAsc = self._articlesSortByAsc,\n            returnInfo = self._returnInfo,\n            **self.queryParams))\n        res = self._er.execQuery(self)\n        if \"error\" in res:\n            print(res[\"error\"])\n        else:\n            self._totalPages = res.get(eventUri, {}).get(\"articles\", {}).get(\"pages\", 0)\n        arts = res.get(eventUri, {}).get(\"articles\", {}).get(\"results\", [])\n        self._articleList.extend(arts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initWithArticleUriList(uriList):\n        q = QueryArticles()\n        assert isinstance(uriList, list), \"uriList has to be a list of strings that represent article uris\"\n        q.queryParams = { \"action\": \"getArticles\", \"articleUri\": uriList }\n        return q", "response": "initWithArticleUriList - Create a QueryArticles object and return it"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initWithComplexQuery(query):\n        q = QueryArticles()\n        # provided an instance of ComplexArticleQuery\n        if isinstance(query, ComplexArticleQuery):\n            q._setVal(\"query\", json.dumps(query.getQuery()))\n        # provided query as a string containing the json object\n        elif isinstance(query, six.string_types):\n            foo = json.loads(query)\n            q._setVal(\"query\", query)\n        # provided query as a python dict\n        elif isinstance(query, dict):\n            q._setVal(\"query\", json.dumps(query))\n        else:\n            assert False, \"The instance of query parameter was not a ComplexArticleQuery, a string or a python dict\"\n        return q", "response": "create a query using a complex article query"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initWithArticleUriList(uriList):\n        q = QueryArticlesIter()\n        assert isinstance(uriList, list), \"uriList has to be a list of strings that represent article uris\"\n        q.queryParams = { \"action\": \"getArticles\", \"articleUri\": uriList }\n        return q", "response": "initWithArticleUriList - Create a QueryArticlesIter object that will return the desired results on top of them"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getNextArticleBatch(self):\n        # try to get more uris, if none\n        self._articlePage += 1\n        # if we have already obtained all pages, then exit\n        if self._totalPages != None and self._articlePage > self._totalPages:\n            return\n        self.setRequestedResult(RequestArticlesInfo(page=self._articlePage,\n            sortBy=self._sortBy, sortByAsc=self._sortByAsc,\n            returnInfo = self._returnInfo))\n        if self._er._verboseOutput:\n            print(\"Downloading article page %d...\" % (self._articlePage))\n        res = self._er.execQuery(self)\n        if \"error\" in res:\n            print(\"Error while obtaining a list of articles: \" + res[\"error\"])\n        else:\n            self._totalPages = res.get(\"articles\", {}).get(\"pages\", 0)\n        results = res.get(\"articles\", {}).get(\"results\", [])\n        self._articleList.extend(results)", "response": "download next batch of articles based on the uris in the uri list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initWithEventUriList(uriList):\n        q = QueryEvents()\n        assert isinstance(uriList, list), \"uriList has to be a list of strings that represent event uris\"\n        q.queryParams = { \"action\": \"getEvents\", \"eventUriList\": \",\".join(uriList) }\n        return q", "response": "Initialize a QueryEvents object with a custom list of event uris."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initWithEventUriWgtList(uriWgtList):\n        q = QueryEvents()\n        assert isinstance(uriWgtList, list), \"uriWgtList has to be a list of strings that represent event uris with their weights\"\n        q.queryParams = { \"action\": \"getEvents\", \"eventUriWgtList\": \",\".join(uriWgtList) }\n        return q", "response": "Initialize a QueryEvents object with a custom list of event uris with their weights."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initWithComplexQuery(query):\n        q = QueryEvents()\n        # provided an instance of ComplexEventQuery\n        if isinstance(query, ComplexEventQuery):\n            q._setVal(\"query\", json.dumps(query.getQuery()))\n        # provided query as a string containing the json object\n        elif isinstance(query, six.string_types):\n            foo = json.loads(query)\n            q._setVal(\"query\", query)\n        # provided query as a python dict\n        elif isinstance(query, dict):\n            q._setVal(\"query\", json.dumps(query))\n        # unrecognized value provided\n        else:\n            assert False, \"The instance of query parameter was not a ComplexEventQuery, a string or a python dict\"\n        return q", "response": "create a query using a complex event query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count(self, eventRegistry):\n        self.setRequestedResult(RequestEventsInfo())\n        res = eventRegistry.execQuery(self)\n        if \"error\" in res:\n            print(res[\"error\"])\n        count = res.get(\"events\", {}).get(\"totalResults\", 0)\n        return count", "response": "count the number of events that match the criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads next batch of events based on the event uris in the uriList", "response": "def _getNextEventBatch(self):\n        \"\"\"download next batch of events based on the event uris in the uri list\"\"\"\n        self._eventPage += 1\n        # if we have already obtained all pages, then exit\n        if self._totalPages != None and self._eventPage > self._totalPages:\n            return\n        self.setRequestedResult(RequestEventsInfo(page=self._eventPage, count=self._eventBatchSize,\n            sortBy= self._sortBy, sortByAsc=self._sortByAsc,\n            returnInfo = self._returnInfo))\n        # download articles and make sure that we set the same archive flag as it was returned when we were processing the uriList request\n        if self._er._verboseOutput:\n            print(\"Downloading event page %d...\" % (self._eventPage))\n        res = self._er.execQuery(self)\n        if \"error\" in res:\n            print(\"Error while obtaining a list of events: \" + res[\"error\"])\n        else:\n            self._totalPages = res.get(\"events\", {}).get(\"pages\", 0)\n        results = res.get(\"events\", {}).get(\"results\", [])\n        self._eventList.extend(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setFlag(self, name, val, defVal):\n        if not hasattr(self, \"flags\"):\n            self.flags = {}\n        if val != defVal:\n            self.flags[name] = val", "response": "set the objects property propName if the dictKey key exists in dict and it is not the same as default value defVal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting value of name to val in case the val!= defVal", "response": "def _setVal(self, name, val, defVal = None):\n        \"\"\"set value of name to val in case the val != defVal\"\"\"\n        if val == defVal:\n            return\n        if not hasattr(self, \"vals\"):\n            self.vals = {}\n        self.vals[name] = val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _getVals(self, prefix = \"\"):\n        if not hasattr(self, \"vals\"):\n            self.vals = {}\n        dict = {}\n        for key in list(self.vals.keys()):\n            # if no prefix then lower the first letter\n            if prefix == \"\":\n                newkey = key[:1].lower() + key[1:] if key else \"\"\n                dict[newkey] = self.vals[key]\n            else:\n                newkey = key[:1].upper() + key[1:] if key else \"\"\n                dict[prefix + newkey] = self.vals[key]\n        return dict", "response": "get the values in the vals dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the configuration for the ReturnInfo from a file", "response": "def loadFromFile(fileName):\n        \"\"\"\n        load the configuration for the ReturnInfo from a fileName\n        @param fileName: filename that contains the json configuration to use in the ReturnInfo\n        \"\"\"\n        assert os.path.exists(fileName), \"File \" + fileName + \" does not exist\"\n        conf = json.load(open(fileName))\n        return ReturnInfo(\n            articleInfo=ArticleInfoFlags(**conf.get(\"articleInfo\", {})),\n            eventInfo=EventInfoFlags(**conf.get(\"eventInfo\", {})),\n            sourceInfo=SourceInfoFlags(**conf.get(\"sourceInfo\", {})),\n            categoryInfo=CategoryInfoFlags(**conf.get(\"categoryInfo\", {})),\n            conceptInfo=ConceptInfoFlags(**conf.get(\"conceptInfo\", {})),\n            locationInfo=LocationInfoFlags(**conf.get(\"locationInfo\", {})),\n            storyInfo=StoryInfoFlags(**conf.get(\"storyInfo\", {})),\n            conceptClassInfo=ConceptClassInfoFlags(**conf.get(\"conceptClassInfo\", {})),\n            conceptFolderInfo=ConceptFolderInfoFlags(**conf.get(\"conceptFolderInfo\", {}))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getConf(self):\n        conf = {\n            \"articleInfo\": self.articleInfo._getFlags().copy(),\n            \"eventInfo\": self.eventInfo._getFlags().copy(),\n            \"sourceInfo\": self.sourceInfo._getFlags().copy(),\n            \"categoryInfo\":  self.categoryInfo._getFlags().copy(),\n            \"conceptInfo\": self.conceptInfo._getFlags().copy(),\n            \"locationInfo\": self.locationInfo._getFlags().copy(),\n            \"storyInfo\": self.storyInfo._getFlags().copy(),\n            \"conceptClassInfo\": self.articleInfo._getFlags().copy(),\n            \"conceptFolderInfo\": self.articleInfo._getFlags().copy()\n        }\n        conf[\"articleInfo\"].update(self.articleInfo._getVals())\n        conf[\"eventInfo\"].update(self.eventInfo._getVals())\n        conf[\"sourceInfo\"].update(self.sourceInfo._getVals())\n        conf[\"categoryInfo\"].update(self.categoryInfo._getVals())\n        conf[\"conceptInfo\"].update(self.conceptInfo._getVals())\n        conf[\"locationInfo\"].update(self.locationInfo._getVals())\n        conf[\"storyInfo\"].update(self.storyInfo._getVals())\n        conf[\"conceptClassInfo\"].update(self.conceptClassInfo._getVals())\n        conf[\"conceptFolderInfo\"].update(self.conceptFolderInfo._getVals())\n        return conf", "response": "getConf - returns a json object that stores properties set by each InfoFlags class\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload an existing topic page from Event Registry based on the topic page URI", "response": "def loadTopicPageFromER(self, uri):\n        \"\"\"\n        load an existing topic page from Event Registry based on the topic page URI\n        @param uri: uri of the topic page saved in your Event Registry account\n        \"\"\"\n        params = {\n            \"action\": \"getTopicPageJson\",\n            \"includeConceptDescription\": True,\n            \"includeTopicPageDefinition\": True,\n            \"includeTopicPageOwner\": True,\n            \"uri\": uri\n        }\n        self.topicPage = self._createEmptyTopicPage()\n        self.concept = self.eventRegistry.jsonRequest(\"/json/topicPage\", params)\n        self.topicPage.update(self.concept.get(\"topicPage\", {}))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload topic page from an existing file", "response": "def loadTopicPageFromFile(self, fname):\n        \"\"\"\n        load topic page from an existing file\n        \"\"\"\n        assert os.path.exists(fname)\n        f = open(fname, \"r\", encoding=\"utf-8\")\n        self.topicPage = json.load(f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef saveTopicPageDefinitionToFile(self, fname):\n        open(fname, \"w\", encoding=\"utf-8\").write(json.dumps(self.topicPage, indent = 4, sort_keys = True))", "response": "save the topic page definition to a file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setArticleThreshold(self, value):\n        assert isinstance(value, int)\n        assert value >= 0\n        self.topicPage[\"articleTreshWgt\"] = value", "response": "set the article threshold"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the event threshold", "response": "def setEventThreshold(self, value):\n        \"\"\"\n        what is the minimum total weight that an event has to have in order to get it among the results?\n        @param value: threshold to use\n        \"\"\"\n        assert isinstance(value, int)\n        assert value >= 0\n        self.topicPage[\"eventTreshWgt\"] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setMaxDaysBack(self, maxDaysBack):\n        assert isinstance(maxDaysBack, int), \"maxDaysBack value has to be a positive integer\"\n        assert maxDaysBack >= 1\n        self.topicPage[\"maxDaysBack\"] = maxDaysBack", "response": "set the maximum number of days to back for this topic page"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addConcept(self, conceptUri, weight, label = None, conceptType = None):\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        concept = {\"uri\": conceptUri, \"wgt\": weight}\n        if label != None: concept[\"label\"] = label\n        if conceptType != None: concept[\"type\"] = conceptType\n        self.topicPage[\"concepts\"].append(concept)", "response": "add a relevant concept to the topic page\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a relevant keyword to the topic page", "response": "def addKeyword(self, keyword, weight):\n        \"\"\"\n        add a relevant keyword to the topic page\n        @param keyword: keyword or phrase to be added\n        @param weight: importance of the provided keyword (typically in range 1 - 50)\n        \"\"\"\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"keywords\"].append({\"keyword\": keyword, \"wgt\": weight})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a relevant category to the topic page", "response": "def addCategory(self, categoryUri, weight):\n        \"\"\"\n        add a relevant category to the topic page\n        @param categoryUri: uri of the category to be added\n        @param weight: importance of the provided category (typically in range 1 - 50)\n        \"\"\"\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"categories\"].append({\"uri\": categoryUri, \"wgt\": weight})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addSource(self, sourceUri, weight):\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"sources\"].append({\"uri\": sourceUri, \"wgt\": weight})", "response": "add a news source to the topic page\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addSourceLocation(self, sourceLocationUri, weight):\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"sourceLocations\"].append({\"uri\": sourceLocationUri, \"wgt\": weight})", "response": "add a list of relevant sources by identifying them by their geographic location\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a list of relevant sources by specifying a whole source group to the topic page", "response": "def addSourceGroup(self, sourceGroupUri, weight):\n        \"\"\"\n        add a list of relevant sources by specifying a whole source group to the topic page\n        @param sourceGroupUri: uri of the source group to add\n        @param weight: importance of the provided list of sources (typically in range 1 - 50)\n        \"\"\"\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"sourceGroups\"].append({\"uri\": sourceGroupUri, \"wgt\": weight})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addLocation(self, locationUri, weight):\n        assert isinstance(weight, (float, int)), \"weight value has to be a positive or negative integer\"\n        self.topicPage[\"locations\"].append({\"uri\": locationUri, \"wgt\": weight})", "response": "add relevant location to the topic page\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestricts the results to the list of specified languages", "response": "def setLanguages(self, languages):\n        \"\"\"\n        restrict the results to the list of specified languages\n        \"\"\"\n        if isinstance(languages, six.string_types):\n            languages = [languages]\n        for lang in languages:\n            assert len(lang) == 3, \"Expected to get language in ISO3 code\"\n        self.topicPage[\"langs\"] = languages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getArticles(self,\n                page=1,\n                count=100,\n                sortBy = \"rel\",\n                sortByAsc = False,\n                returnInfo=ReturnInfo()):\n        \"\"\"\n        return a list of articles that match the topic page\n        @param page: which page of the results to return (default: 1)\n        @param count: number of articles to return (default: 100)\n        @param sortBy: how are articles sorted. Options: id (internal id), date (publishing date), cosSim (closeness to the event centroid), rel (relevance to the query), sourceImportance (manually curated score of source importance - high value, high importance), sourceImportanceRank (reverse of sourceImportance), sourceAlexaGlobalRank (global rank of the news source), sourceAlexaCountryRank (country rank of the news source), socialScore (total shares on social media), facebookShares (shares on Facebook only)\n        @param sortByAsc: should the results be sorted in ascending order (True) or descending (False)\n        @param returnInfo: what details should be included in the returned information\n        \"\"\"\n        assert page >= 1\n        assert count <= 100\n        params = {\n            \"action\": \"getArticlesForTopicPage\",\n            \"resultType\": \"articles\",\n            \"dataType\": self.topicPage[\"dataType\"],\n            \"articlesCount\": count,\n            \"articlesSortBy\": sortBy,\n            \"articlesSortByAsc\": sortByAsc,\n            \"page\": page,\n            \"topicPage\": json.dumps(self.topicPage)\n        }\n        params.update(returnInfo.getParams(\"articles\"))\n        return self.eventRegistry.jsonRequest(\"/json/article\", params)", "response": "getArticles for a topic page"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AND(queryArr,\n            exclude = None):\n        \"\"\"\n        create a combined query with multiple items on which to perform an AND operation\n        @param queryArr: a list of items on which to perform an AND operation. Items can be either a CombinedQuery or BaseQuery instances.\n        @param exclude: a instance of BaseQuery, CombinedQuery or None. Used to filter out results matching the other criteria specified in this query\n        \"\"\"\n        assert isinstance(queryArr, list), \"provided argument as not a list\"\n        assert len(queryArr) > 0, \"queryArr had an empty list\"\n        q = CombinedQuery()\n        q.setQueryParam(\"$and\", [])\n        for item in queryArr:\n            assert isinstance(item, (CombinedQuery, BaseQuery)), \"item in the list was not a CombinedQuery or BaseQuery instance\"\n            q.getQuery()[\"$and\"].append(item.getQuery())\n        if exclude != None:\n            assert isinstance(exclude, (CombinedQuery, BaseQuery)), \"exclude parameter was not a CombinedQuery or BaseQuery instance\"\n            q.setQueryParam(\"$not\", exclude.getQuery())\n        return q", "response": "create a combined query with multiple items on which to perform an AND operation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def verify_credentials(self):\n        _, public_key = self.srp.initialize()\n\n        msg = messages.crypto_pairing({\n            tlv8.TLV_SEQ_NO: b'\\x01',\n            tlv8.TLV_PUBLIC_KEY: public_key})\n        resp = await self.protocol.send_and_receive(\n            msg, generate_identifier=False)\n\n        resp = _get_pairing_data(resp)\n        session_pub_key = resp[tlv8.TLV_PUBLIC_KEY]\n        encrypted = resp[tlv8.TLV_ENCRYPTED_DATA]\n        log_binary(_LOGGER,\n                   'Device',\n                   Public=self.credentials.ltpk,\n                   Encrypted=encrypted)\n\n        encrypted_data = self.srp.verify1(\n            self.credentials, session_pub_key, encrypted)\n        msg = messages.crypto_pairing({\n            tlv8.TLV_SEQ_NO: b'\\x03',\n            tlv8.TLV_ENCRYPTED_DATA: encrypted_data})\n        resp = await self.protocol.send_and_receive(\n            msg, generate_identifier=False)\n\n        # TODO: check status code\n\n        self._output_key, self._input_key = self.srp.verify2()", "response": "Verify credentials with device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up a tag based on its key. Returns a DmapTag.", "response": "def lookup_tag(name):\n    \"\"\"Look up a tag based on its key. Returns a DmapTag.\"\"\"\n    return next((_TAGS[t] for t in _TAGS if t == name),\n                DmapTag(_read_unknown, 'unknown tag'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscanning for Apple TVs using zeroconf and return them.", "response": "async def scan_for_apple_tvs(loop, timeout=5, abort_on_found=False,\n                             device_ip=None, only_usable=True,\n                             protocol=None):\n    \"\"\"Scan for Apple TVs using zeroconf (bonjour) and returns them.\"\"\"\n    semaphore = asyncio.Semaphore(value=0, loop=loop)\n    listener = _ServiceListener(\n        loop, abort_on_found, device_ip, protocol, semaphore)\n    zeroconf = Zeroconf()\n    try:\n        ServiceBrowser(zeroconf, HOMESHARING_SERVICE, listener)\n        ServiceBrowser(zeroconf, DEVICE_SERVICE, listener)\n        ServiceBrowser(zeroconf, MEDIAREMOTE_SERVICE, listener)\n        ServiceBrowser(zeroconf, AIRPLAY_SERVICE, listener)\n        _LOGGER.debug('Discovering devices for %d seconds', timeout)\n        await asyncio.wait_for(semaphore.acquire(), timeout, loop=loop)\n    except concurrent.futures.TimeoutError:\n        pass  # Will happen when timeout occurs (totally normal)\n    finally:\n        zeroconf.close()\n\n    def _should_include(atv):\n        if not only_usable:\n            return True\n\n        return atv.is_usable()\n\n    return list(filter(_should_include, listener.found_devices.values()))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect_to_apple_tv(details, loop, protocol=None, session=None):\n    service = _get_service_used_to_connect(details, protocol)\n\n    # If no session is given, create a default one\n    if session is None:\n        session = ClientSession(loop=loop)\n\n    # AirPlay service is the same for both DMAP and MRP\n    airplay = _setup_airplay(loop, session, details)\n\n    # Create correct implementation depending on protocol\n    if service.protocol == PROTOCOL_DMAP:\n        return DmapAppleTV(loop, session, details, airplay)\n\n    return MrpAppleTV(loop, session, details, airplay)", "response": "Connect and logins to an Apple TV."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_service(self, zeroconf, service_type, name):\n        self.lock.acquire()\n        try:\n            self._internal_add(zeroconf, service_type, name)\n        finally:\n            self.lock.release()", "response": "Handle callback from zeroconf when a service has been discovered."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new HS service to the discovered list.", "response": "def add_hs_service(self, info, address):\n        \"\"\"Add a new device to discovered list.\"\"\"\n        if self.protocol and self.protocol != PROTOCOL_DMAP:\n            return\n\n        name = info.properties[b'Name'].decode('utf-8')\n        hsgid = info.properties[b'hG'].decode('utf-8')\n        self._handle_service(\n            address, name, conf.DmapService(hsgid, port=info.port))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_non_hs_service(self, info, address):\n        if self.protocol and self.protocol != PROTOCOL_DMAP:\n            return\n\n        name = info.properties[b'CtlN'].decode('utf-8')\n        self._handle_service(\n            address, name, conf.DmapService(None, port=info.port))", "response": "Add a new device without Home Sharing to discovered list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_mrp_service(self, info, address):\n        if self.protocol and self.protocol != PROTOCOL_MRP:\n            return\n\n        name = info.properties[b'Name'].decode('utf-8')\n        self._handle_service(address, name, conf.MrpService(info.port))", "response": "Add a new MediaRemoteProtocol device to discovered list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new AirPlay service to discovered list.", "response": "def add_airplay_service(self, info, address):\n        \"\"\"Add a new AirPlay device to discovered list.\"\"\"\n        name = info.name.replace('._airplay._tcp.local.', '')\n        self._handle_service(address, name, conf.AirPlayService(info.port))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_service(self, service):\n        if service.protocol in self._services:\n            existing = self._services[service.protocol]\n            if not existing.superseeded_by(service):\n                return\n\n        self._services[service.protocol] = service", "response": "Add a new service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a usable service or None if there is none.", "response": "def usable_service(self):\n        \"\"\"Return a usable service or None if there is none.\n\n        A service is usable if enough configuration to be able to make a\n        connection is available. If several protocols are usable, MRP will be\n        preferred over DMAP.\n        \"\"\"\n        services = self._services\n        for protocol in self._supported_protocols:\n            if protocol in services and services[protocol].is_usable():\n                return services[protocol]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef superseeded_by(self, other_service):\n        if not other_service or \\\n                other_service.__class__ != self.__class__ or \\\n                other_service.protocol != self.protocol or \\\n                other_service.port != self.port:\n            return False\n\n        # If this service does not have a login id but the other one does, then\n        # we should return True here\n        return not self.device_credentials and other_service.device_credentials", "response": "Return True if input service has login id and this has not."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def print_what_is_playing(loop):\n    print('Discovering devices on network...')\n    atvs = await pyatv.scan_for_apple_tvs(loop, timeout=5)\n\n    if not atvs:\n        print('no device found', file=sys.stderr)\n        return\n\n    print('Connecting to {0}'.format(atvs[0].address))\n    atv = pyatv.connect_to_apple_tv(atvs[0], loop)\n\n    try:\n        playing = await atv.metadata.playing()\n        print('Currently playing:')\n        print(playing)\n    finally:\n        # Do not forget to logout\n        await atv.logout()", "response": "Find a device and print what is playing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def start(self, **kwargs):\n        zeroconf = kwargs['zeroconf']\n        self._name = kwargs['name']\n        self._pairing_guid = kwargs.get('pairing_guid', None) or \\\n            self._generate_random_guid()\n\n        self._web_server = web.Server(self.handle_request, loop=self._loop)\n        self._server = await self._loop.create_server(\n            self._web_server, '0.0.0.0')\n\n        # Get the allocated (random port) and include it in zeroconf service\n        allocated_port = self._server.sockets[0].getsockname()[1]\n        _LOGGER.debug('Started pairing web server at port %d', allocated_port)\n\n        self._setup_zeroconf(zeroconf, allocated_port)", "response": "Start the pairing server and publish service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def stop(self, **kwargs):\n        _LOGGER.debug('Shutting down pairing server')\n        if self._web_server is not None:\n            await self._web_server.shutdown()\n            self._server.close()\n\n        if self._server is not None:\n            await self._server.wait_closed()", "response": "Stop pairing server and unpublish service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrespond to request if PIN is correct.", "response": "async def handle_request(self, request):\n        \"\"\"Respond to request if PIN is correct.\"\"\"\n        service_name = request.rel_url.query['servicename']\n        received_code = request.rel_url.query['pairingcode'].lower()\n        _LOGGER.info('Got pairing request from %s with code %s',\n                     service_name, received_code)\n\n        if self._verify_pin(received_code):\n            cmpg = tags.uint64_tag('cmpg', int(self._pairing_guid, 16))\n            cmnm = tags.string_tag('cmnm', self._name)\n            cmty = tags.string_tag('cmty', 'iPhone')\n            response = tags.container_tag('cmpa', cmpg + cmnm + cmty)\n            self._has_paired = True\n            return web.Response(body=response)\n\n        # Code did not match, generate an error\n        return web.Response(status=500)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging binary data if debug is enabled.", "response": "def log_binary(logger, message, **kwargs):\n    \"\"\"Log binary data if debug is enabled.\"\"\"\n    if logger.isEnabledFor(logging.DEBUG):\n        output = ('{0}={1}'.format(k, binascii.hexlify(\n            bytearray(v)).decode()) for k, v in sorted(kwargs.items()))\n        logger.debug('%s (%s)', message, ', '.join(output))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def cli_handler(loop):\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('command', nargs='+',\n                        help='commands, help, ...')\n    parser.add_argument('--name', help='apple tv name',\n                        dest='name', default='Apple TV')\n    parser.add_argument('--address', help='device ip address or hostname',\n                        dest='address', default=None)\n    parser.add_argument('--protocol', action=TransformProtocol,\n                        help='protocol to use (values: dmap, mrp)',\n                        dest='protocol', default=None)\n    parser.add_argument('--port', help='port when connecting',\n                        dest='port', type=_in_range(0, 65535),\n                        default=0)\n    parser.add_argument('-t', '--scan-timeout', help='timeout when scanning',\n                        dest='scan_timeout', type=_in_range(1, 100),\n                        metavar='TIMEOUT', default=3)\n    parser.add_argument('--version', action='version',\n                        help='version of atvremote and pyatv',\n                        version='%(prog)s {0}'.format(const.__version__))\n\n    pairing = parser.add_argument_group('pairing')\n    pairing.add_argument('--remote-name', help='remote pairing name',\n                         dest='remote_name', default='pyatv')\n    pairing.add_argument('-p', '--pin', help='pairing pin code',\n                         dest='pin_code', metavar='PIN', default=1234,\n                         type=_in_range(0, 9999, allow_none=True))\n    pairing.add_argument('--pairing-guid',\n                         help='pairing guid (16 chars hex)',\n                         dest='pairing_guid', default=None)\n\n    parser.add_argument('-a', '--autodiscover', action='store_true',\n                        help='automatically find a device',\n                        dest='autodiscover', default=False)\n    parser.add_argument('--device_credentials', help='credentials to device',\n                        dest='device_credentials', default=None)\n\n    airplay = parser.add_argument_group('airplay')\n    airplay.add_argument('--airplay_credentials',\n                         help='credentials for airplay',\n                         dest='airplay_credentials', default=None)\n\n    debug = parser.add_argument_group('debugging')\n    debug.add_argument('-v', '--verbose', help='increase output verbosity',\n                       action='store_true', dest='verbose')\n    debug.add_argument('--debug', help='print debug information',\n                       action='store_true', dest='debug')\n\n    args = parser.parse_args()\n    loglevel = logging.WARNING\n    if args.verbose:\n        loglevel = logging.INFO\n    if args.debug:\n        loglevel = logging.DEBUG\n\n    logging.basicConfig(level=loglevel,\n                        format='%(levelname)s: %(message)s')\n    logging.getLogger('requests').setLevel(logging.WARNING)\n\n    cmds = retrieve_commands(GlobalCommands)\n\n    if args.command[0] in cmds:\n        glob_cmds = GlobalCommands(args, loop)\n        return (await _exec_command(\n            glob_cmds, args.command[0], print_result=False))\n    if args.autodiscover:\n        if not await _autodiscover_device(args, loop):\n            return 1\n\n        return await _handle_commands(args, loop)\n    if args.address:\n        return await _handle_commands(args, loop)\n\n    logging.error('To autodiscover an Apple TV, add -a')\n\n    return 1", "response": "The main entry point for the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the input command with arguments.", "response": "def _extract_command_with_args(cmd):\n    \"\"\"Parse input command with arguments.\n\n    Parses the input command in such a way that the user may\n    provide additional argument to the command. The format used is this:\n      command=arg1,arg2,arg3,...\n    all the additional arguments are passed as arguments to the target\n    method.\n    \"\"\"\n    def _isint(value):\n        try:\n            int(value)\n            return True\n        except ValueError:\n            return False\n\n    equal_sign = cmd.find('=')\n    if equal_sign == -1:\n        return cmd, []\n\n    command = cmd[0:equal_sign]\n    args = cmd[equal_sign+1:].split(',')\n    converted = [x if not _isint(x) else int(x) for x in args]\n    return command, converted"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the asyncio event loop and runs the application.", "response": "def main():\n    \"\"\"Start the asyncio event loop and runs the application.\"\"\"\n    # Helper method so that the coroutine exits cleanly if an exception\n    # happens (which would leave resources dangling)\n    async def _run_application(loop):\n        try:\n            return await cli_handler(loop)\n\n        except KeyboardInterrupt:\n            pass  # User pressed Ctrl+C, just ignore it\n\n        except SystemExit:\n            pass  # sys.exit() was used - do nothing\n\n        except:  # pylint: disable=bare-except  # noqa\n            import traceback\n\n            traceback.print_exc(file=sys.stderr)\n            sys.stderr.writelines(\n                '\\n>>> An error occurred, full stack trace above\\n')\n\n        return 1\n\n    try:\n        loop = asyncio.get_event_loop()\n        return loop.run_until_complete(_run_application(loop))\n    except KeyboardInterrupt:\n        pass\n\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a list with available commands.", "response": "async def commands(self):\n        \"\"\"Print a list with available commands.\"\"\"\n        _print_commands('Remote control', interface.RemoteControl)\n        _print_commands('Metadata', interface.Metadata)\n        _print_commands('Playing', interface.Playing)\n        _print_commands('AirPlay', interface.AirPlay)\n        _print_commands('Device', DeviceCommands)\n        _print_commands('Global', self.__class__)\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def help(self):\n        if len(self.args.command) != 2:\n            print('Which command do you want help with?', file=sys.stderr)\n            return 1\n\n        iface = [interface.RemoteControl,\n                 interface.Metadata,\n                 interface.Playing,\n                 interface.AirPlay,\n                 self.__class__,\n                 DeviceCommands]\n        for cmd in iface:\n            for key, value in cmd.__dict__.items():\n                if key.startswith('_') or key != self.args.command[1]:\n                    continue\n\n                if inspect.isfunction(value):\n                    signature = inspect.signature(value)\n                else:\n                    signature = ' (property)'\n\n                print('COMMAND:\\n>> {0}{1}\\n\\nHELP:\\n{2}'.format(\n                    key, signature, inspect.getdoc(value)))\n        return 0", "response": "Print help text for a command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscanning for Apple TVs on the network.", "response": "async def scan(self):\n        \"\"\"Scan for Apple TVs on the network.\"\"\"\n        atvs = await pyatv.scan_for_apple_tvs(\n            self.loop, timeout=self.args.scan_timeout, only_usable=False)\n        _print_found_apple_tvs(atvs)\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def cli(self):\n        print('Enter commands and press enter')\n        print('Type help for help and exit to quit')\n\n        while True:\n            command = await _read_input(self.loop, 'pyatv> ')\n            if command.lower() == 'exit':\n                break\n            elif command == 'cli':\n                print('Command not availble here')\n                continue\n\n            await _handle_device_command(\n                self.args, command, self.atv, self.loop)", "response": "Enter commands in a simple CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads artwork and save it to artwork. png.", "response": "async def artwork_save(self):\n        \"\"\"Download artwork and save it to artwork.png.\"\"\"\n        artwork = await self.atv.metadata.artwork()\n        if artwork is not None:\n            with open('artwork.png', 'wb') as file:\n                file.write(artwork)\n        else:\n            print('No artwork is currently available.')\n            return 1\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlistens for push updates.", "response": "async def push_updates(self):\n        \"\"\"Listen for push updates.\"\"\"\n        print('Press ENTER to stop')\n\n        self.atv.push_updater.start()\n        await self.atv.login()\n        await self.loop.run_in_executor(None, sys.stdin.readline)\n        self.atv.push_updater.stop()\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms AirPlay device authentication.", "response": "async def auth(self):\n        \"\"\"Perform AirPlay device authentication.\"\"\"\n        credentials = await self.atv.airplay.generate_credentials()\n        await self.atv.airplay.load_credentials(credentials)\n\n        try:\n            await self.atv.airplay.start_authentication()\n            pin = await _read_input(self.loop, 'Enter PIN on screen: ')\n\n            await self.atv.airplay.finish_authentication(pin)\n            print('You may now use these credentials:')\n            print(credentials)\n            return 0\n\n        except exceptions.DeviceAuthenticationError:\n            logging.exception('Failed to authenticate - invalid PIN?')\n            return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def pair(self):\n        # Connect using the specified protocol\n        # TODO: config should be stored elsewhere so that API is same for both\n        protocol = self.atv.service.protocol\n        if protocol == const.PROTOCOL_DMAP:\n            await self.atv.pairing.start(zeroconf=Zeroconf(),\n                                         name=self.args.remote_name,\n                                         pairing_guid=self.args.pairing_guid)\n        elif protocol == const.PROTOCOL_MRP:\n            await self.atv.pairing.start()\n\n        # Ask for PIN if present or just wait for pairing to end\n        if self.atv.pairing.device_provides_pin:\n            pin = await _read_input(self.loop, 'Enter PIN on screen: ')\n            self.atv.pairing.pin(pin)\n        else:\n            self.atv.pairing.pin(self.args.pin_code)\n\n            print('Use {0} to pair with \"{1}\" (press ENTER to stop)'.format(\n                self.args.pin_code, self.args.remote_name))\n\n        if self.args.pin_code is None:\n            print('Use any pin to pair with \"{}\" (press ENTER to stop)'.format(\n                self.args.remote_name))\n        else:\n            print('Use pin {} to pair with \"{}\" (press ENTER to stop)'.format(\n                self.args.pin_code, self.args.remote_name))\n\n        await self.loop.run_in_executor(None, sys.stdin.readline)\n\n        await self.atv.pairing.stop()\n\n        # Give some feedback to the user\n        if self.atv.pairing.has_paired:\n            print('Pairing seems to have succeeded, yey!')\n            print('You may now use these credentials: {0}'.format(\n                self.atv.pairing.credentials))\n        else:\n            print('Pairing failed!')\n            return 1\n\n        return 0", "response": "Pair pyatv with an Apple TV."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting iTunes media kind to API representation.", "response": "def media_kind(kind):\n    \"\"\"Convert iTunes media kind to API representation.\"\"\"\n    if kind in [1]:\n        return const.MEDIA_TYPE_UNKNOWN\n    if kind in [3, 7, 11, 12, 13, 18, 32]:\n        return const.MEDIA_TYPE_VIDEO\n    if kind in [2, 4, 10, 14, 17, 21, 36]:\n        return const.MEDIA_TYPE_MUSIC\n    if kind in [8, 64]:\n        return const.MEDIA_TYPE_TV\n\n    raise exceptions.UnknownMediaKind('Unknown media kind: ' + str(kind))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert internal API media type to string.", "response": "def media_type_str(mediatype):\n    \"\"\"Convert internal API media type to string.\"\"\"\n    if mediatype == const.MEDIA_TYPE_UNKNOWN:\n        return 'Unknown'\n    if mediatype == const.MEDIA_TYPE_VIDEO:\n        return 'Video'\n    if mediatype == const.MEDIA_TYPE_MUSIC:\n        return 'Music'\n    if mediatype == const.MEDIA_TYPE_TV:\n        return 'TV'\n    return 'Unsupported'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert iTunes playstate to API representation.", "response": "def playstate(state):\n    \"\"\"Convert iTunes playstate to API representation.\"\"\"\n    # pylint: disable=too-many-return-statements\n    if state is None:\n        return const.PLAY_STATE_NO_MEDIA\n    if state == 0:\n        return const.PLAY_STATE_IDLE\n    if state == 1:\n        return const.PLAY_STATE_LOADING\n    if state == 3:\n        return const.PLAY_STATE_PAUSED\n    if state == 4:\n        return const.PLAY_STATE_PLAYING\n    if state == 5:\n        return const.PLAY_STATE_FAST_FORWARD\n    if state == 6:\n        return const.PLAY_STATE_FAST_BACKWARD\n\n    raise exceptions.UnknownPlayState('Unknown playstate: ' + str(state))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert internal API playstate to string.", "response": "def playstate_str(state):\n    \"\"\"Convert internal API playstate to string.\"\"\"\n    if state == const.PLAY_STATE_NO_MEDIA:\n        return 'No media'\n    if state == const.PLAY_STATE_IDLE:\n        return 'Idle'\n    if state == const.PLAY_STATE_LOADING:\n        return 'Loading'\n    if state == const.PLAY_STATE_PAUSED:\n        return 'Paused'\n    if state == const.PLAY_STATE_PLAYING:\n        return 'Playing'\n    if state == const.PLAY_STATE_FAST_FORWARD:\n        return 'Fast forward'\n    if state == const.PLAY_STATE_FAST_BACKWARD:\n        return 'Fast backward'\n    return 'Unsupported'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts internal API repeat state to string.", "response": "def repeat_str(state):\n    \"\"\"Convert internal API repeat state to string.\"\"\"\n    if state == const.REPEAT_STATE_OFF:\n        return 'Off'\n    if state == const.REPEAT_STATE_TRACK:\n        return 'Track'\n    if state == const.REPEAT_STATE_ALL:\n        return 'All'\n    return 'Unsupported'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef protocol_str(protocol):\n    if protocol == const.PROTOCOL_MRP:\n        return 'MRP'\n    if protocol == const.PROTOCOL_DMAP:\n        return 'DMAP'\n    if protocol == const.PROTOCOL_AIRPLAY:\n        return 'AirPlay'\n    return 'Unknown'", "response": "Convert internal API protocol to string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef first(dmap_data, *path):\n    if not (path and isinstance(dmap_data, list)):\n        return dmap_data\n\n    for key in dmap_data:\n        if path[0] in key:\n            return first(key[path[0]], *path[1:])\n\n    return None", "response": "Look up a value given a path in some parsed DMAP data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pprint(data, tag_lookup, indent=0):\n    output = ''\n    if isinstance(data, dict):\n        for key, value in data.items():\n            tag = tag_lookup(key)\n            if isinstance(value, (dict, list)) and tag.type is not read_bplist:\n                output += '{0}{1}: {2}\\n'.format(indent*' ', key, tag)\n                output += pprint(value, tag_lookup, indent+2)\n            else:\n                output += '{0}{1}: {2} {3}\\n'.format(\n                    indent*' ', key, str(value), tag)\n    elif isinstance(data, list):\n        for elem in data:\n            output += pprint(elem, tag_lookup, indent)\n    else:\n        raise exceptions.InvalidDmapDataError(\n            'invalid dmap data: ' + str(data))\n    return output", "response": "Return a pretty formatted string of parsed DMAP data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve all commands and help texts from an API object.", "response": "def retrieve_commands(obj):\n    \"\"\"Retrieve all commands and help texts from an API object.\"\"\"\n    commands = {}  # Name and help\n    for func in obj.__dict__:\n        if not inspect.isfunction(obj.__dict__[func]) and \\\n           not isinstance(obj.__dict__[func], property):\n            continue\n        if func.startswith('_'):\n            continue\n        commands[func] = _get_first_sentence_in_pydoc(\n            obj.__dict__[func])\n    return commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hash(self):\n        base = '{0}{1}{2}{3}'.format(\n            self.title, self.artist, self.album, self.total_time)\n        return hashlib.sha256(base.encode('utf-8')).hexdigest()", "response": "Create a unique hash for what is currently playing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplay media from an URL on the device.", "response": "async def play_url(self, url, position=0):\n        \"\"\"Play media from an URL on the device.\"\"\"\n        headers = {'User-Agent': 'MediaControl/1.0',\n                   'Content-Type': 'application/x-apple-binary-plist'}\n        body = {'Content-Location': url, 'Start-Position': position}\n\n        address = self._url(self.port, 'play')\n        _LOGGER.debug('AirPlay %s to %s', url, address)\n\n        resp = None\n        try:\n            # pylint: disable=no-member\n            resp = await self.session.post(\n                address, headers=headers,\n                data=plistlib.dumps(body, fmt=plistlib.FMT_BINARY),\n                timeout=TIMEOUT)\n            await self._wait_for_media_to_end()\n        finally:\n            if resp is not None:\n                resp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_message_info():\n    base_path = BASE_PACKAGE.replace('.', '/')\n    filename = os.path.join(base_path, 'ProtocolMessage.proto')\n\n    with open(filename, 'r') as file:\n        types_found = False\n\n        for line in file:\n            stripped = line.lstrip().rstrip()\n\n            # Look for the Type enum\n            if stripped == 'enum Type {':\n                types_found = True\n                continue\n            elif types_found and stripped == '}':\n                break\n            elif not types_found:\n                continue\n\n            constant = stripped.split(' ')[0]\n            title = constant.title().replace(\n                '_', '').replace('Hid', 'HID')  # Hack...\n            accessor = title[0].lower() + title[1:]\n\n            if not os.path.exists(os.path.join(base_path, title + '.proto')):\n                continue\n\n            yield MessageInfo(\n                title + '_pb2', title, accessor, constant)", "response": "Get information about all messages of interest."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscripting starts somewhere around here.", "response": "def main():\n    \"\"\"Script starts somewhere around here.\"\"\"\n    message_names = set()\n    packages = []\n    messages = []\n    extensions = []\n    constants = []\n\n    # Extract everything needed to generate output file\n    for info in extract_message_info():\n        message_names.add(info.title)\n        packages.append(\n            'from {0} import {1}'.format(\n                BASE_PACKAGE, info.module))\n        messages.append(\n            'from {0}.{1} import {2}'.format(\n                BASE_PACKAGE, info.module, info.title))\n        extensions.append(\n            'ProtocolMessage.{0}: {1}.{2},'.format(\n                info.const, info.module, info.accessor))\n        constants.append(\n            '{0} = ProtocolMessage.{0}'.format(\n                info.const))\n\n\n    # Look for remaining messages\n    for module_name, message_name in extract_unreferenced_messages():\n        if message_name not in message_names:\n            message_names.add(message_name)\n            messages.append('from {0}.{1} import {2}'.format(\n                    BASE_PACKAGE, module_name, message_name))\n\n    # Print file output with values inserted\n    print(OUTPUT_TEMPLATE.format(\n        packages='\\n'.join(sorted(packages)),\n        messages='\\n'.join(sorted(messages)),\n        extensions='\\n    '.join(sorted(extensions)),\n        constants='\\n'.join(sorted(constants))))\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hkdf_expand(salt, info, shared_secret):\n    from cryptography.hazmat.primitives import hashes\n    from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n    from cryptography.hazmat.backends import default_backend\n    hkdf = HKDF(\n        algorithm=hashes.SHA512(),\n        length=32,\n        salt=salt.encode(),\n        info=info.encode(),\n        backend=default_backend()\n    )\n    return hkdf.derive(shared_secret)", "response": "Derive encryption keys from shared secret."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a string represention of Credentials.", "response": "def parse(cls, detail_string):\n        \"\"\"Parse a string represention of Credentials.\"\"\"\n        split = detail_string.split(':')\n        if len(split) != 4:\n            raise Exception('invalid credentials')  # TODO: other exception\n\n        ltpk = binascii.unhexlify(split[0])\n        ltsk = binascii.unhexlify(split[1])\n        atv_id = binascii.unhexlify(split[2])\n        client_id = binascii.unhexlify(split[3])\n        return Credentials(ltpk, ltsk, atv_id, client_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes operation by generating new keys.", "response": "def initialize(self):\n        \"\"\"Initialize operation by generating new keys.\"\"\"\n        self._signing_key = SigningKey(os.urandom(32))\n        self._auth_private = self._signing_key.to_seed()\n        self._auth_public = self._signing_key.get_verifying_key().to_bytes()\n        self._verify_private = curve25519.Private(secret=os.urandom(32))\n        self._verify_public = self._verify_private.get_public()\n        return self._auth_public, self._verify_public.serialize()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlast verification step. The derived keys (output, input) are returned here.", "response": "def verify2(self):\n        \"\"\"Last verification step.\n\n        The derived keys (output, input) are returned here.\n        \"\"\"\n        output_key = hkdf_expand('MediaRemote-Salt',\n                                 'MediaRemote-Write-Encryption-Key',\n                                 self._shared)\n\n        input_key = hkdf_expand('MediaRemote-Salt',\n                                'MediaRemote-Read-Encryption-Key',\n                                self._shared)\n\n        log_binary(_LOGGER, 'Keys', Output=output_key, Input=input_key)\n        return output_key, input_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hash_sha512(*indata):\n    hasher = hashlib.sha512()\n    for data in indata:\n        if isinstance(data, str):\n            hasher.update(data.encode('utf-8'))\n        elif isinstance(data, bytes):\n            hasher.update(data)\n        else:\n            raise Exception('invalid input data: ' + str(data))\n    return hasher.digest()", "response": "Create SHA512 hash for input arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencrypt data with AES in specified mode.", "response": "def aes_encrypt(mode, aes_key, aes_iv, *data):\n    \"\"\"Encrypt data with AES in specified mode.\"\"\"\n    encryptor = Cipher(\n        algorithms.AES(aes_key),\n        mode(aes_iv),\n        backend=default_backend()).encryptor()\n\n    result = None\n    for value in data:\n        result = encryptor.update(value)\n    encryptor.finalize()\n\n    return result, None if not hasattr(encryptor, 'tag') else encryptor.tag"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a new identifier and seed for authentication.", "response": "def new_credentials():\n    \"\"\"Generate a new identifier and seed for authentication.\n\n    Use the returned values in the following way:\n    * The identifier shall be passed as username to SRPAuthHandler.step1\n    * Seed shall be passed to SRPAuthHandler constructor\n    \"\"\"\n    identifier = binascii.b2a_hex(os.urandom(8)).decode().upper()\n    seed = binascii.b2a_hex(os.urandom(32))  # Corresponds to private key\n    return identifier, seed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_common_session_key(self, premaster_secret):\n        k_1 = self.hash(premaster_secret, b'\\x00\\x00\\x00\\x00', as_bytes=True)\n        k_2 = self.hash(premaster_secret, b'\\x00\\x00\\x00\\x01', as_bytes=True)\n        return k_1 + k_2", "response": "Get the common session key for the current session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing handler operation. This method will generate new encryption keys and must be called prior to doing authentication or verification.", "response": "def initialize(self, seed=None):\n        \"\"\"Initialize handler operation.\n\n        This method will generate new encryption keys and must be called prior\n        to doing authentication or verification.\n        \"\"\"\n        self.seed = seed or os.urandom(32)  # Generate new seed if not provided\n        signing_key = SigningKey(self.seed)\n        verifying_key = signing_key.get_verifying_key()\n        self._auth_private = signing_key.to_seed()\n        self._auth_public = verifying_key.to_bytes()\n        log_binary(_LOGGER,\n                   'Authentication keys',\n                   Private=self._auth_private,\n                   Public=self._auth_public)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify2(self, atv_public_key, data):\n        self._check_initialized()\n        log_binary(_LOGGER, 'Verify', PublicSecret=atv_public_key, Data=data)\n\n        # Generate a shared secret key\n        public = curve25519.Public(atv_public_key)\n        shared = self._verify_private.get_shared_key(\n            public, hashfunc=lambda x: x)  # No additional hashing used\n        log_binary(_LOGGER, 'Shared secret', Secret=shared)\n\n        # Derive new AES key and IV from shared key\n        aes_key = hash_sha512('Pair-Verify-AES-Key', shared)[0:16]\n        aes_iv = hash_sha512('Pair-Verify-AES-IV', shared)[0:16]\n        log_binary(_LOGGER, 'Pair-Verify-AES', Key=aes_key, IV=aes_iv)\n\n        # Sign public keys and encrypt with AES\n        signer = SigningKey(self._auth_private)\n        signed = signer.sign(self._verify_public.serialize() + atv_public_key)\n        signature, _ = aes_encrypt(modes.CTR, aes_key, aes_iv, data, signed)\n        log_binary(_LOGGER, 'Signature', Signature=signature)\n\n        # Signature is prepended with 0x00000000 (alignment?)\n        return b'\\x00\\x00\\x00\\x00' + signature", "response": "Last device verification step."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the authentication process.", "response": "async def start_authentication(self):\n        \"\"\"Start the authentication process.\n\n        This method will show the expected PIN on screen.\n        \"\"\"\n        _, code = await self.http.post_data(\n            'pair-pin-start', headers=_AIRPLAY_HEADERS)\n        if code != 200:\n            raise DeviceAuthenticationError('pair start failed')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def finish_authentication(self, username, password):\n        # Step 1\n        self.srp.step1(username, password)\n        data = await self._send_plist(\n            'step1', method='pin', user=username)\n        resp = plistlib.loads(data)\n\n        # Step 2\n        pub_key, key_proof = self.srp.step2(resp['pk'], resp['salt'])\n        await self._send_plist(\n            'step2',\n            pk=binascii.unhexlify(pub_key),\n            proof=binascii.unhexlify(key_proof))\n\n        # Step 3\n        epk, tag = self.srp.step3()\n        await self._send_plist('step3', epk=epk, authTag=tag)\n        return True", "response": "Finish authentication process.\n\n        A username (generated by new_credentials) and the PIN code shown on\n        screen must be provided."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify if device is allowed to use AirPlau.", "response": "async def verify_authed(self):\n        \"\"\"Verify if device is allowed to use AirPlau.\"\"\"\n        resp = await self._send(self.srp.verify1(), 'verify1')\n\n        atv_public_secret = resp[0:32]\n        data = resp[32:]  # TODO: what is this?\n        await self._send(\n            self.srp.verify2(atv_public_secret, data), 'verify2')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def generate_credentials(self):\n        identifier, seed = new_credentials()\n        return '{0}:{1}'.format(identifier, seed.decode().upper())", "response": "Generate new credentials for authentication."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def play_url(self, url, **kwargs):\n        # If credentials have been loaded, do device verification first\n        if self.identifier:\n            await self.verify_authenticated()\n\n        position = 0 if 'position' not in kwargs else int(kwargs['position'])\n        return await self.player.play_url(url, position)", "response": "Play a media from an URL on the device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_encryption(self, output_key, input_key):\n        self._chacha = chacha20.Chacha20Cipher(output_key, input_key)", "response": "Enable encryption with the specified keys."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        if self._transport:\n            self._transport.close()\n        self._transport = None\n        self._chacha = None", "response": "Close connection to device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a message to the device.", "response": "def send(self, message):\n        \"\"\"Send message to device.\"\"\"\n        serialized = message.SerializeToString()\n\n        log_binary(_LOGGER, '>> Send', Data=serialized)\n        if self._chacha:\n            serialized = self._chacha.encrypt(serialized)\n            log_binary(_LOGGER, '>> Send', Encrypted=serialized)\n\n        data = write_variant(len(serialized)) + serialized\n        self._transport.write(data)\n        _LOGGER.debug('>> Send: Protobuf=%s', message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle incoming data from the device.", "response": "def data_received(self, data):\n        \"\"\"Message was received from device.\"\"\"\n        # A message might be split over several reads, so we store a buffer and\n        # try to decode messages from that buffer\n        self._buffer += data\n        log_binary(_LOGGER, '<< Receive', Data=data)\n\n        while self._buffer:\n            # The variant tells us how much data must follow\n            length, raw = read_variant(self._buffer)\n            if len(raw) < length:\n                _LOGGER.debug(\n                    'Require %d bytes but only %d in buffer', length, len(raw))\n                break\n\n            data = raw[:length]  # Incoming message (might be encrypted)\n            self._buffer = raw[length:]  # Buffer, might contain more messages\n\n            try:\n                self._handle_message(data)\n            except Exception:  # pylint: disable=broad-except\n                _LOGGER.error('Failed to handle message')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_data(self, path, headers=None, timeout=None):\n        url = self.base_url + path\n        _LOGGER.debug('GET URL: %s', url)\n        resp = None\n        try:\n            resp = await self._session.get(\n                url, headers=headers,\n                timeout=DEFAULT_TIMEOUT if timeout is None else timeout)\n            if resp.content_length is not None:\n                resp_data = await resp.read()\n            else:\n                resp_data = None\n            return resp_data, resp.status\n        except Exception as ex:\n            if resp is not None:\n                resp.close()\n            raise ex\n        finally:\n            if resp is not None:\n                await resp.release()", "response": "Perform a GET request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def post_data(self, path, data=None, headers=None, timeout=None):\n        url = self.base_url + path\n        _LOGGER.debug('POST URL: %s', url)\n        self._log_data(data, False)\n\n        resp = None\n        try:\n            resp = await self._session.post(\n                url, headers=headers, data=data,\n                timeout=DEFAULT_TIMEOUT if timeout is None else timeout)\n            if resp.content_length is not None:\n                resp_data = await resp.read()\n            else:\n                resp_data = None\n            self._log_data(resp_data, True)\n            return resp_data, resp.status\n        except Exception as ex:\n            if resp is not None:\n                resp.close()\n            raise ex\n        finally:\n            if resp is not None:\n                await resp.release()", "response": "Perform a POST request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a uint from a position in a sequence.", "response": "def read_uint(data, start, length):\n    \"\"\"Extract a uint from a position in a sequence.\"\"\"\n    return int.from_bytes(data[start:start+length], byteorder='big')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract a binary plist from a position in a sequence.", "response": "def read_bplist(data, start, length):\n    \"\"\"Extract a binary plist from a position in a sequence.\"\"\"\n    # TODO: pylint doesn't find FMT_BINARY, why?\n    # pylint: disable=no-member\n    return plistlib.loads(data[start:start+length],\n                          fmt=plistlib.FMT_BINARY)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a DMAP tag with raw data.", "response": "def raw_tag(name, value):\n    \"\"\"Create a DMAP tag with raw data.\"\"\"\n    return name.encode('utf-8') + \\\n        len(value).to_bytes(4, byteorder='big') + \\\n        value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef string_tag(name, value):\n    return name.encode('utf-8') + \\\n        len(value).to_bytes(4, byteorder='big') + \\\n        value.encode('utf-8')", "response": "Create a DMAP tag with string data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new DEVICE_INFO_MESSAGE.", "response": "def device_information(name, identifier):\n    \"\"\"Create a new DEVICE_INFO_MESSAGE.\"\"\"\n    # pylint: disable=no-member\n    message = create(protobuf.DEVICE_INFO_MESSAGE)\n    info = message.inner()\n    info.uniqueIdentifier = identifier\n    info.name = name\n    info.localizedModelName = 'iPhone'\n    info.systemBuildVersion = '14G60'\n    info.applicationBundleIdentifier = 'com.apple.TVRemote'\n    info.applicationBundleVersion = '273.12'\n    info.protocolVersion = 1\n    info.lastSupportedMessageType = 58\n    info.supportsExtendedMotion = True\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new SET_CONNECTION_STATE message.", "response": "def set_connection_state():\n    \"\"\"Create a new SET_CONNECTION_STATE.\"\"\"\n    message = create(protobuf.ProtocolMessage.SET_CONNECTION_STATE_MESSAGE)\n    message.inner().state = protobuf.SetConnectionStateMessage.Connected\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef crypto_pairing(pairing_data):\n    message = create(protobuf.CRYPTO_PAIRING_MESSAGE)\n    crypto = message.inner()\n    crypto.status = 0\n    crypto.pairingData = tlv8.write_tlv(pairing_data)\n    return message", "response": "Create a new CRYPTO_PAIRING_MESSAGE."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef client_updates_config(artwork=True, now_playing=True,\n                          volume=True, keyboard=True):\n    \"\"\"Create a new CLIENT_UPDATES_CONFIG_MESSAGE.\"\"\"\n    message = create(protobuf.CLIENT_UPDATES_CONFIG_MESSAGE)\n    config = message.inner()\n    config.artworkUpdates = artwork\n    config.nowPlayingUpdates = now_playing\n    config.volumeUpdates = volume\n    config.keyboardUpdates = keyboard\n    return message", "response": "Create a new CLIENT_UPDATES_CONFIG_MESSAGE."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new REGISTER_HID_DEVICE_MESSAGE.", "response": "def register_hid_device(screen_width, screen_height,\n                        absolute=False, integrated_display=False):\n    \"\"\"Create a new REGISTER_HID_DEVICE_MESSAGE.\"\"\"\n    message = create(protobuf.REGISTER_HID_DEVICE_MESSAGE)\n    descriptor = message.inner().deviceDescriptor\n    descriptor.absolute = 1 if absolute else 0\n    descriptor.integratedDisplay = 1 if integrated_display else 0\n    descriptor.screenSizeWidth = screen_width\n    descriptor.screenSizeHeight = screen_height\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_packed_virtual_touch_event(xpos, ypos, phase, device_id, finger):\n    message = create(protobuf.SEND_PACKED_VIRTUAL_TOUCH_EVENT_MESSAGE)\n    event = message.inner()\n\n    # The packed version of VirtualTouchEvent contains X, Y, phase, deviceID\n    # and finger stored as a byte array. Each value is written as 16bit little\n    # endian integers.\n    event.data = xpos.to_bytes(2, byteorder='little')\n    event.data += ypos.to_bytes(2, byteorder='little')\n    event.data += phase.to_bytes(2, byteorder='little')\n    event.data += device_id.to_bytes(2, byteorder='little')\n    event.data += finger.to_bytes(2, byteorder='little')\n\n    return message", "response": "Create a new WAKE_DEVICE_MESSAGE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_hid_event(use_page, usage, down):\n    message = create(protobuf.SEND_HID_EVENT_MESSAGE)\n    event = message.inner()\n\n    # TODO: This should be generated somehow. I guess it's mach AbsoluteTime\n    # which is tricky to generate. The device does not seem to care much about\n    # the value though, so hardcode something here.\n    abstime = binascii.unhexlify(b'438922cf08020000')\n\n    data = use_page.to_bytes(2, byteorder='big')\n    data += usage.to_bytes(2, byteorder='big')\n    data += (1 if down else 0).to_bytes(2, byteorder='big')\n\n    # This is the format that the device expects. Some day I might take some\n    # time to decode it for real, but this is fine for now.\n    event.hidEventData = abstime + \\\n        binascii.unhexlify(b'00000000000000000100000000000000020' +\n                           b'00000200000000300000001000000000000') + \\\n        data + \\\n        binascii.unhexlify(b'0000000000000001000000')\n\n    return message", "response": "Create a new SEND_HID_EVENT_MESSAGE."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchanges repeat mode of current player.", "response": "def repeat(mode):\n    \"\"\"Change repeat mode of current player.\"\"\"\n    message = command(protobuf.CommandInfo_pb2.ChangeShuffleMode)\n    send_command = message.inner()\n    send_command.options.externalPlayerCommand = True\n    send_command.options.repeatMode = mode\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges shuffle mode of current player.", "response": "def shuffle(enable):\n    \"\"\"Change shuffle mode of current player.\"\"\"\n    message = command(protobuf.CommandInfo_pb2.ChangeShuffleMode)\n    send_command = message.inner()\n    send_command.options.shuffleMode = 3 if enable else 1\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nseeking to an absolute position in stream.", "response": "def seek_to_position(position):\n    \"\"\"Seek to an absolute position in stream.\"\"\"\n    message = command(protobuf.CommandInfo_pb2.SeekToPlaybackPosition)\n    send_command = message.inner()\n    send_command.options.playbackPosition = position\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake it possible to pair with device.", "response": "async def pair_with_device(loop):\n    \"\"\"Make it possible to pair with device.\"\"\"\n    my_zeroconf = Zeroconf()\n    details = conf.AppleTV('127.0.0.1', 'Apple TV')\n    details.add_service(conf.DmapService('login_id'))\n    atv = pyatv.connect_to_apple_tv(details, loop)\n\n    atv.pairing.pin(PIN_CODE)\n    await atv.pairing.start(zeroconf=my_zeroconf, name=REMOTE_NAME)\n    print('You can now pair with pyatv')\n\n    # Wait for a minute to allow pairing\n    await asyncio.sleep(60, loop=loop)\n\n    await atv.pairing.stop()\n\n    # Give some feedback about the process\n    if atv.pairing.has_paired:\n        print('Paired with device!')\n        print('Credentials:', atv.pairing.credentials)\n    else:\n        print('Did not pair with device!')\n\n    my_zeroconf.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_variant(variant):\n    result = 0\n    cnt = 0\n    for data in variant:\n        result |= (data & 0x7f) << (7 * cnt)\n        cnt += 1\n        if not data & 0x80:\n            return result, variant[cnt:]\n    raise Exception('invalid variant')", "response": "Read and parse a binary protobuf variant value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to device and print what is playing.", "response": "async def print_what_is_playing(loop):\n    \"\"\"Connect to device and print what is playing.\"\"\"\n    details = conf.AppleTV(ADDRESS, NAME)\n    details.add_service(conf.DmapService(HSGID))\n\n    print('Connecting to {}'.format(details.address))\n    atv = pyatv.connect_to_apple_tv(details, loop)\n\n    try:\n        print((await atv.metadata.playing()))\n    finally:\n        # Do not forget to logout\n        await atv.logout()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a listener that will receice incoming messages.", "response": "def add_listener(self, listener, message_type, data=None, one_shot=False):\n        \"\"\"Add a listener that will receice incoming messages.\"\"\"\n        lst = self._one_shots if one_shot else self._listeners\n\n        if message_type not in lst:\n            lst[message_type] = []\n\n        lst[message_type].append(Listener(listener, data))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def start(self):\n        if self.connection.connected:\n            return\n\n        await self.connection.connect()\n\n        # In case credentials have been given externally (i.e. not by pairing\n        # with a device), then use that client id\n        if self.service.device_credentials:\n            self.srp.pairing_id = Credentials.parse(\n                self.service.device_credentials).client_id\n\n        # The first message must always be DEVICE_INFORMATION, otherwise the\n        # device will not respond with anything\n        msg = messages.device_information(\n            'pyatv', self.srp.pairing_id.decode())\n        await self.send_and_receive(msg)\n        self._initial_message_sent = True\n\n        # This should be the first message sent after encryption has\n        # been enabled\n        await self.send(messages.set_ready_state())\n\n        async def _wait_for_updates(_, semaphore):\n            # Use a counter here whenever more than one message is expected\n            semaphore.release()\n\n        # Wait for some stuff to arrive before returning\n        semaphore = asyncio.Semaphore(value=0, loop=self.loop)\n        self.add_listener(_wait_for_updates,\n                          protobuf.SET_STATE_MESSAGE,\n                          data=semaphore,\n                          one_shot=True)\n\n        # Subscribe to updates at this stage\n        await self.send(messages.client_updates_config())\n        await self.send(messages.wake_device())\n\n        try:\n            await asyncio.wait_for(\n                semaphore.acquire(), 1, loop=self.loop)\n        except asyncio.TimeoutError:\n            # This is not an issue itself, but I should do something better.\n            # Basically this gives the device about one second to respond with\n            # some metadata before continuing.\n            pass", "response": "Connect to device and listen to incoming messages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a message and wait for a response.", "response": "async def send_and_receive(self, message,\n                               generate_identifier=True, timeout=5):\n        \"\"\"Send a message and wait for a response.\"\"\"\n        await self._connect_and_encrypt()\n\n        # Some messages will respond with the same identifier as used in the\n        # corresponding request. Others will not and one example is the crypto\n        # message (for pairing). They will never include an identifer, but it\n        # it is in turn only possible to have one of those message outstanding\n        # at one time (i.e. it's not possible to mix up the responses). In\n        # those cases, a \"fake\" identifier is used that includes the message\n        # type instead.\n        if generate_identifier:\n            identifier = str(uuid.uuid4())\n            message.identifier = identifier\n        else:\n            identifier = 'type_' + str(message.type)\n\n        self.connection.send(message)\n        return await self._receive(identifier, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a message received from the device.", "response": "def message_received(self, message):\n        \"\"\"Message was received from device.\"\"\"\n        # If the message identifer is outstanding, then someone is\n        # waiting for the respone so we save it here\n        identifier = message.identifier or 'type_' + str(message.type)\n        if identifier in self._outstanding:\n            outstanding = OutstandingMessage(\n                self._outstanding[identifier].semaphore, message)\n            self._outstanding[identifier] = outstanding\n            self._outstanding[identifier].semaphore.release()\n        else:\n            asyncio.ensure_future(self._dispatch(message), loop=self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def playstatus(self, use_revision=False, timeout=None):\n        cmd_url = _PSU_CMD.format(\n            self.playstatus_revision if use_revision else 0)\n        resp = await self.daap.get(cmd_url, timeout=timeout)\n        self.playstatus_revision = parser.first(resp, 'cmst', 'cmsr')\n        return resp", "response": "Request raw data about what is currently playing on the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an image file for what is currently playing.", "response": "async def artwork(self):\n        \"\"\"Return an image file (png) for what is currently playing.\n\n        None is returned if no artwork is available. Must be logged in.\n        \"\"\"\n        art = await self.daap.get(_ARTWORK_CMD, daap_data=False)\n        return art if art != b'' else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a ctrl - int command.", "response": "def ctrl_int_cmd(self, cmd):\n        \"\"\"Perform a \"ctrl-int\" command.\"\"\"\n        cmd_url = 'ctrl-int/1/{}?[AUTH]&prompt-id=0'.format(cmd)\n        return self.daap.post(cmd_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a controlpromptentry command.", "response": "def controlprompt_cmd(self, cmd):\n        \"\"\"Perform a \"controlpromptentry\" command.\"\"\"\n        data = tags.string_tag('cmbe', cmd) + tags.uint8_tag('cmcc', 0)\n        return self.daap.post(_CTRL_PROMPT_CMD, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_property(self, prop, value):\n        cmd_url = 'ctrl-int/1/setproperty?{}={}&[AUTH]'.format(\n            prop, value)\n        return self.daap.post(cmd_url)", "response": "Change value of a DAAP property e. g. volume or media position."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_position(self, pos):\n        time_in_ms = int(pos)*1000\n        return self.apple_tv.set_property('dacp.playingtime', time_in_ms)", "response": "Seek in the current playing media."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef media_type(self):\n        state = parser.first(self.playstatus, 'cmst', 'caps')\n        if not state:\n            return const.MEDIA_TYPE_UNKNOWN\n\n        mediakind = parser.first(self.playstatus, 'cmst', 'cmmk')\n        if mediakind is not None:\n            return convert.media_kind(mediakind)\n\n        # Fallback: if artist or album exists we assume music (not present\n        # for video)\n        if self.artist or self.album:\n            return const.MEDIA_TYPE_MUSIC\n\n        return const.MEDIA_TYPE_VIDEO", "response": "Type of media currently playing e. g. video music or unknown."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current play state.", "response": "def play_state(self):\n        \"\"\"Play state, e.g. playing or paused.\"\"\"\n        state = parser.first(self.playstatus, 'cmst', 'caps')\n        return convert.playstate(state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the push update polling.", "response": "def start(self, initial_delay=0):\n        \"\"\"Wait for push updates from device.\n\n        Will throw NoAsyncListenerError if no listner has been set.\n        \"\"\"\n        if self.listener is None:\n            raise exceptions.NoAsyncListenerError\n        elif self._future is not None:\n            return None\n\n        # Always start with 0 to trigger an immediate response for the\n        # first request\n        self._atv.playstatus_revision = 0\n\n        # This for some reason fails on travis but not in other places.\n        # Why is that (same python version)?\n        # pylint: disable=deprecated-method\n        self._future = asyncio.ensure_future(\n            self._poller(initial_delay), loop=self._loop)\n        return self._future"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def authenticate_with_device(atv):\n    credentials = await atv.airplay.generate_credentials()\n    await atv.airplay.load_credentials(credentials)\n\n    try:\n        await atv.airplay.start_authentication()\n        pin = input('PIN Code: ')\n        await atv.airplay.finish_authentication(pin)\n        print('Credentials: {0}'.format(credentials))\n\n    except exceptions.DeviceAuthenticationError:\n        print('Failed to authenticate', file=sys.stderr)", "response": "Perform device authentication and print credentials."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts data with counter or specified nounce.", "response": "def encrypt(self, data, nounce=None):\n        \"\"\"Encrypt data with counter or specified nounce.\"\"\"\n        if nounce is None:\n            nounce = self._out_counter.to_bytes(length=8, byteorder='little')\n            self._out_counter += 1\n\n        return self._enc_out.seal(b'\\x00\\x00\\x00\\x00' + nounce, data, bytes())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decrypt(self, data, nounce=None):\n        if nounce is None:\n            nounce = self._in_counter.to_bytes(length=8, byteorder='little')\n            self._in_counter += 1\n\n        decrypted = self._enc_in.open(\n            b'\\x00\\x00\\x00\\x00' + nounce, data, bytes())\n\n        if not decrypted:\n            raise Exception('data decrypt failed')  # TODO: new exception\n\n        return bytes(decrypted)", "response": "Decrypt data with counter or specified nounce."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshorting method for connecting to a device. This is a convenience method that create an event loop, auto discovers devices, picks the first device found, connects to it and passes it to a user provided handler. An optional error handler can be provided that is called when no device was found. Very inflexible in many cases, but can be handys sometimes when trying things. Note 1: both handler and not_found must be coroutines Note 2: An optional loop can be passed if needed (mainly for testing)", "response": "def auto_connect(handler, timeout=5, not_found=None, event_loop=None):\n    \"\"\"Short method for connecting to a device.\n\n    This is a convenience method that create an event loop, auto discovers\n    devices, picks the first device found, connects to it and passes it to a\n    user provided handler. An optional error handler can be provided that is\n    called when no device was found. Very inflexible in many cases, but can be\n    handys sometimes when trying things.\n\n    Note 1: both handler and not_found must be coroutines\n    Note 2: An optional loop can be passed if needed (mainly for testing)\n    \"\"\"\n    # A coroutine is used so we can connect to the device while being inside\n    # the event loop\n    async def _handle(loop):\n        atvs = await pyatv.scan_for_apple_tvs(\n            loop, timeout=timeout, abort_on_found=True)\n\n        # Take the first device found\n        if atvs:\n            atv = pyatv.connect_to_apple_tv(atvs[0], loop)\n            try:\n                await handler(atv)\n            finally:\n                await atv.logout()\n        else:\n            if not_found is not None:\n                await not_found()\n\n    loop = event_loop if event_loop else asyncio.get_event_loop()\n    loop.run_until_complete(_handle(loop))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlogin to Apple TV using specified login id.", "response": "async def login(self):\n        \"\"\"Login to Apple TV using specified login id.\"\"\"\n        # Do not use session.get_data(...) in login as that would end up in\n        # an infinte loop.\n        def _login_request():\n            return self.http.get_data(\n                self._mkurl('login?[AUTH]&hasFP=1',\n                            session=False, login_id=True),\n                headers=_DMAP_HEADERS)\n\n        resp = await self._do(_login_request, is_login=True)\n        self._session_id = parser.first(resp, 'mlog', 'mlid')\n\n        _LOGGER.info('Logged in and got session id %s', self._session_id)\n        return self._session_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get(self, cmd, daap_data=True, timeout=None, **args):\n        def _get_request():\n            return self.http.get_data(\n                self._mkurl(cmd, *args),\n                headers=_DMAP_HEADERS,\n                timeout=timeout)\n\n        await self._assure_logged_in()\n        return await self._do(_get_request, is_daap=daap_data)", "response": "Perform a DAAP GET command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexpand the request URL for a request.", "response": "def get_url(self, cmd, **args):\n        \"\"\"Expand the request URL for a request.\"\"\"\n        return self.http.base_url + self._mkurl(cmd, *args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def post(self, cmd, data=None, timeout=None, **args):\n        def _post_request():\n            headers = copy(_DMAP_HEADERS)\n            headers['Content-Type'] = 'application/x-www-form-urlencoded'\n            return self.http.post_data(\n                self._mkurl(cmd, *args),\n                data=data,\n                headers=headers,\n                timeout=timeout)\n\n        await self._assure_logged_in()\n        return await self._do(_post_request)", "response": "Perform DAAP POST command with optional data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play_state(self):\n        # TODO: extract to a convert module\n        state = self._setstate.playbackState\n        if state == 1:\n            return const.PLAY_STATE_PLAYING\n        if state == 2:\n            return const.PLAY_STATE_PAUSED\n\n        return const.PLAY_STATE_PAUSED", "response": "Return the state of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef genre(self):\n        if self._metadata:\n            from pyatv.mrp.protobuf import ContentItem_pb2\n            transaction = ContentItem_pb2.ContentItem()\n            transaction.ParseFromString(self._metadata)", "response": "Returns the current genre of the currently playing song."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_time(self):\n        now_playing = self._setstate.nowPlayingInfo\n        if now_playing.HasField('duration'):\n            return int(now_playing.duration)\n\n        return None", "response": "Returns the total play time in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef position(self):\n        now_playing = self._setstate.nowPlayingInfo\n        if now_playing.HasField('elapsedTime'):\n            return int(now_playing.elapsedTime)\n\n        return None", "response": "Returns the current position in the playing media."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn whether shuffle is enabled or not.", "response": "def shuffle(self):\n        \"\"\"If shuffle is enabled or not.\"\"\"\n        info = self._get_command_info(CommandInfo_pb2.ChangeShuffleMode)\n        return None if info is None else info.shuffleMode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def playing(self):\n        # TODO: This is hack-ish\n        if self._setstate is None:\n            await self.protocol.start()\n\n        # No SET_STATE_MESSAGE received yet, use default\n        if self._setstate is None:\n            return MrpPlaying(protobuf.SetStateMessage(), None)\n\n        return MrpPlaying(self._setstate, self._nowplaying)", "response": "Return what is currently playing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the async listener.", "response": "def start(self, initial_delay=0):\n        \"\"\"Wait for push updates from device.\n\n        Will throw NoAsyncListenerError if no listner has been set.\n        \"\"\"\n        if self.listener is None:\n            raise exceptions.NoAsyncListenerError\n        elif self._enabled:\n            return\n\n        self._enabled = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_tlv(data):\n    def _parse(data, pos, size, result=None):\n        if result is None:\n            result = {}\n        if pos >= size:\n            return result\n\n        tag = str(data[pos])\n        length = data[pos+1]\n        value = data[pos+2:pos+2+length]\n\n        if tag in result:\n            result[tag] += value  # value > 255 is split up\n        else:\n            result[tag] = value\n        return _parse(data, pos+2+length, size, result)\n\n    return _parse(data, 0, len(data))", "response": "Parse TLV8 bytes into a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_tlv(data):\n    tlv = b''\n    for key, value in data.items():\n        tag = bytes([int(key)])\n        length = len(value)\n        pos = 0\n\n        # A tag with length > 255 is added multiple times and concatenated into\n        # one buffer when reading the TLV again.\n        while pos < len(value):\n            size = min(length, 255)\n            tlv += tag\n            tlv += bytes([size])\n            tlv += value[pos:pos+size]\n            pos += size\n            length -= size\n    return tlv", "response": "Convert a dict to TLV8 bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nannotates a value or Doc with a comment.", "response": "def comment(value, comment_text):\n    \"\"\"Annotates a value or a Doc with a comment.\n\n    When printed by prettyprinter, the comment will be\n    rendered next to the value or Doc.\n    \"\"\"\n    if isinstance(value, Doc):\n        return comment_doc(value, comment_text)\n    return comment_value(value, comment_text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_pretty(type=None, predicate=None):\n\n    if type is None and predicate is None:\n        raise ValueError(\n            \"You must provide either the 'type' or 'predicate' argument.\"\n        )\n\n    if type is not None and predicate is not None:\n        raise ValueError(\n            \"You must provide either the 'type' or 'predicate' argument,\"\n            \"but not both\"\n        )\n\n    if predicate is not None:\n        if not callable(predicate):\n            raise ValueError(\n                \"Expected a callable for 'predicate', got {}\".format(\n                    repr(predicate)\n                )\n            )\n\n    def decorator(fn):\n        sig = inspect.signature(fn)\n\n        value = None\n        ctx = None\n\n        try:\n            sig.bind(value, ctx)\n        except TypeError:\n            fnname = '{}.{}'.format(\n                fn.__module__,\n                fn.__qualname__\n            )\n            raise ValueError(\n                \"Functions decorated with register_pretty must accept \"\n                \"exactly two positional parameters: 'value' and 'ctx'. \"\n                \"The function signature for {} was not compatible.\".format(\n                    fnname\n                )\n            )\n\n        if type:\n            if isinstance(type, str):\n                # We don't wrap this with _run_pretty,\n                # so that when we register this printer with an actual\n                # class, we can call register_pretty(cls)(fn)\n                _DEFERRED_DISPATCH_BY_NAME[type] = fn\n            else:\n                pretty_dispatch.register(type, partial(_run_pretty, fn))\n        else:\n            assert callable(predicate)\n            _PREDICATE_REGISTRY.append((predicate, fn))\n        return fn\n    return decorator", "response": "Returns a decorator that registers the decorated function as the pretty printer for instances of type or a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commentdoc(text):\n    if not text:\n        raise ValueError(\n            'Expected non-empty comment str, got {}'.format(repr(text))\n        )\n\n    commentlines = []\n    for line in text.splitlines():\n        alternating_words_ws = list(filter(None, WHITESPACE_PATTERN_TEXT.split(line)))\n        starts_with_whitespace = bool(\n            WHITESPACE_PATTERN_TEXT.match(alternating_words_ws[0])\n        )\n\n        if starts_with_whitespace:\n            prefix = alternating_words_ws[0]\n            alternating_words_ws = alternating_words_ws[1:]\n        else:\n            prefix = NIL\n\n        if len(alternating_words_ws) % 2 == 0:\n            # The last part must be whitespace.\n            alternating_words_ws = alternating_words_ws[:-1]\n\n        for idx, tup in enumerate(zip(alternating_words_ws, cycle([False, True]))):\n            part, is_ws = tup\n            if is_ws:\n                alternating_words_ws[idx] = flat_choice(\n                    when_flat=part,\n                    when_broken=always_break(\n                        concat([\n                            HARDLINE,\n                            '# ',\n                        ])\n                    )\n                )\n\n        commentlines.append(\n            concat([\n                '# ',\n                prefix,\n                fill(alternating_words_ws)\n            ])\n        )\n\n    outer = identity\n\n    if len(commentlines) > 1:\n        outer = always_break\n\n    return annotate(\n        Token.COMMENT_SINGLE,\n        outer(concat(intersperse(HARDLINE, commentlines)))\n    )", "response": "Returns a Doc representing a comment text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Doc that represents a function call to the given context with the remaining positional and keyword arguments.", "response": "def pretty_call(ctx, fn, *args, **kwargs):\n    \"\"\"Returns a Doc that represents a function call to :keyword:`fn` with\n    the remaining positional and keyword arguments.\n\n    You can only use this function on Python 3.6+. On Python 3.5, the order\n    of keyword arguments is not maintained, and you have to use\n    :func:`~prettyprinter.pretty_call_alt`.\n\n    Given an arbitrary context ``ctx``,::\n\n        pretty_call(ctx, sorted, [7, 4, 5], reverse=True)\n\n    Will result in output::\n\n        sorted([7, 4, 5], reverse=True)\n\n    The layout algorithm will automatically break the call to multiple\n    lines if needed::\n\n        sorted(\n            [7, 4, 5],\n            reverse=True\n        )\n\n    ``pretty_call`` automatically handles syntax highlighting.\n\n    :param ctx: a context value\n    :type ctx: prettyprinter.prettyprinter.PrettyContext\n    :param fn: a callable\n    :param args: positional arguments to render to the call\n    :param kwargs: keyword arguments to render to the call\n    :returns: :class:`~prettyprinter.doc.Doc`\n    \"\"\"\n    return pretty_call_alt(ctx, fn, args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Doc that represents a function call to the specified function with the given arguments and keyword arguments.", "response": "def pretty_call_alt(ctx, fn, args=(), kwargs=()):\n    \"\"\"Returns a Doc that represents a function call to :keyword:`fn` with\n    the ``args`` and ``kwargs``.\n\n    Given an arbitrary context ``ctx``,::\n\n        pretty_call_alt(ctx, sorted, args=([7, 4, 5], ), kwargs=[('reverse', True)])\n\n    Will result in output::\n\n        sorted([7, 4, 5], reverse=True)\n\n    The layout algorithm will automatically break the call to multiple\n    lines if needed::\n\n        sorted(\n            [7, 4, 5],\n            reverse=True\n        )\n\n    ``pretty_call_alt`` automatically handles syntax highlighting.\n\n    :param ctx: a context value\n    :type ctx: prettyprinter.prettyprinter.PrettyContext\n    :param fn: a callable\n    :param args: a ``tuple`` of positional arguments to render to the call\n    :param kwargs: keyword arguments to render to the call. Either an instance\n                   of ``OrderedDict``, or an iterable of two-tuples, where the\n                   first element is a `str` (key), and the second is the Python\n                   value for that keyword argument.\n    :returns: :class:`~prettyprinter.doc.Doc`\n    \"\"\"\n\n    fndoc = general_identifier(fn)\n\n    if ctx.depth_left <= 0:\n        return concat([fndoc, LPAREN, ELLIPSIS, RPAREN])\n\n    if not kwargs and len(args) == 1:\n        sole_arg = args[0]\n        unwrapped_sole_arg, _comment, _trailing_comment = unwrap_comments(args[0])\n        if type(unwrapped_sole_arg) in (list, dict, tuple):\n            return build_fncall(\n                ctx,\n                fndoc,\n                argdocs=[pretty_python_value(sole_arg, ctx)],\n                hug_sole_arg=True,\n            )\n\n    nested_ctx = (\n        ctx\n        .nested_call()\n        .use_multiline_strategy(MULTILINE_STRATEGY_HANG)\n    )\n\n    if not DICT_KEY_ORDER_SUPPORTED and isinstance(kwargs, dict):\n        warnings.warn(\n            \"A dict was passed to pretty_call_alt to represent kwargs, \"\n            \"but Python 3.5 doesn't maintain key order for dicts. The order \"\n            \"of keyword arguments will be undefined in the output. \"\n            \"To fix this, pass a list of two-tuples or an instance of \"\n            \"OrderedDict instead.\",\n            UserWarning\n        )\n\n    kwargitems = (\n        kwargs.items()\n        if isinstance(kwargs, (OrderedDict, dict))\n        else kwargs\n    )\n\n    return build_fncall(\n        ctx,\n        fndoc,\n        argdocs=(\n            pretty_python_value(arg, nested_ctx)\n            for arg in args\n        ),\n        kwargdocs=(\n            (kwarg, pretty_python_value(v, nested_ctx))\n            for kwarg, v in kwargitems\n        ),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a function call doc that looks like a function call.", "response": "def build_fncall(\n    ctx,\n    fndoc,\n    argdocs=(),\n    kwargdocs=(),\n    hug_sole_arg=False,\n    trailing_comment=None,\n):\n    \"\"\"Builds a doc that looks like a function call,\n    from docs that represent the function, arguments\n    and keyword arguments.\n\n    If ``hug_sole_arg`` is True, and the represented\n    functional call is done with a single non-keyword\n    argument, the function call parentheses will hug\n    the sole argument doc without newlines and indentation\n    in break mode. This makes a difference in calls\n    like this::\n\n        > hug_sole_arg = False\n        frozenset(\n            [\n                1,\n                2,\n                3,\n                4,\n                5\n            ]\n        )\n        > hug_sole_arg = True\n        frozenset([\n            1,\n            2,\n            3,\n            4,\n            5,\n        ])\n\n    If ``trailing_comment`` is provided, the text is\n    rendered as a comment after the last argument and\n    before the closing parenthesis. This will force\n    the function call to be broken to multiple lines.\n    \"\"\"\n    if callable(fndoc):\n        fndoc = general_identifier(fndoc)\n\n    has_comment = bool(trailing_comment)\n\n    argdocs = list(argdocs)\n    kwargdocs = list(kwargdocs)\n\n    kwargdocs = [\n        # Propagate any comments to the kwarg doc.\n        (\n            comment_doc(\n                concat([\n                    keyword_arg(binding),\n                    ASSIGN_OP,\n                    doc.doc\n                ]),\n                doc.annotation.value\n            )\n            if is_commented(doc)\n            else concat([\n                keyword_arg(binding),\n                ASSIGN_OP,\n                doc\n            ])\n        )\n        for binding, doc in kwargdocs\n    ]\n\n    if not (argdocs or kwargdocs):\n        return concat([\n            fndoc,\n            LPAREN,\n            RPAREN,\n        ])\n\n    if (\n        hug_sole_arg and\n        not kwargdocs and\n        len(argdocs) == 1 and\n        not is_commented(argdocs[0])\n    ):\n        return group(\n            concat([\n                fndoc,\n                LPAREN,\n                argdocs[0],\n                RPAREN\n            ])\n        )\n\n    allarg_docs = [*argdocs, *kwargdocs]\n\n    if trailing_comment:\n        allarg_docs.append(commentdoc(trailing_comment))\n\n    parts = []\n\n    for idx, doc in enumerate(allarg_docs):\n        last = idx == len(allarg_docs) - 1\n\n        if is_commented(doc):\n            has_comment = True\n            comment_str = doc.annotation.value\n            doc = doc.doc\n        else:\n            comment_str = None\n\n        part = concat([doc, NIL if last else COMMA])\n\n        if comment_str:\n            part = group(\n                flat_choice(\n                    when_flat=concat([\n                        part,\n                        '  ',\n                        commentdoc(comment_str)\n                    ]),\n                    when_broken=concat([\n                        commentdoc(comment_str),\n                        HARDLINE,\n                        part,\n                    ]),\n                )\n            )\n\n        if not last:\n            part = concat([part, HARDLINE if has_comment else LINE])\n\n        parts.append(part)\n\n    outer = (\n        always_break\n        if has_comment\n        else group\n    )\n\n    return outer(\n        concat([\n            fndoc,\n            LPAREN,\n            nest(\n                ctx.indent,\n                concat([\n                    SOFTLINE,\n                    concat(parts),\n                ])\n            ),\n            SOFTLINE,\n            RPAREN\n        ])\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a modified PrettyContext with key set to value", "response": "def assoc(self, key, value):\n        \"\"\"\n        Return a modified PrettyContext with ``key`` set to ``value``\n        \"\"\"\n        return self._replace(user_ctx={\n            **self.user_ctx,\n            key: value,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nalign each new line in doc with the first new line.", "response": "def align(doc):\n    \"\"\"Aligns each new line in ``doc`` with the first new line.\n    \"\"\"\n    validate_doc(doc)\n\n    def evaluator(indent, column, page_width, ribbon_width):\n        return Nest(column - indent, doc)\n    return contextual(evaluator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting default global style to be used by prettyprinter. cpprint.", "response": "def set_default_style(style):\n    \"\"\"Sets default global style to be used by ``prettyprinter.cpprint``.\n\n    :param style: the style to set, either subclass of\n                  ``pygments.styles.Style`` or one of ``'dark'``, ``'light'``\n    \"\"\"\n    global default_style\n    if style == 'dark':\n        style = default_dark_style\n    elif style == 'light':\n        style = default_light_style\n\n    if not issubclass(style, Style):\n        raise TypeError(\n            \"style must be a subclass of pygments.styles.Style or \"\n            \"one of 'dark', 'light'. Got {}\".format(repr(style))\n        )\n    default_style = style"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nindents the docstrings of the current object.", "response": "def indent(self, indent):\n        \"\"\"with statement support for indenting/dedenting.\"\"\"\n        curr_docparts = self._docparts\n        self._docparts = []\n        self.indentation += indent\n        try:\n            yield\n        finally:\n            self.indentation -= indent\n            indented_docparts = self._docparts\n            self._docparts = curr_docparts\n            self._docparts.append(nest(indent, concat(indented_docparts)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield the elements of x between each element of ys.", "response": "def intersperse(x, ys):\n    \"\"\"\n    Returns an iterable where ``x`` is inserted between\n    each element of ``ys``\n\n    :type ys: Iterable\n    \"\"\"\n    it = iter(ys)\n\n    try:\n        y = next(it)\n    except StopIteration:\n        return\n\n    yield y\n\n    for y in it:\n        yield x\n        yield y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pformat(\n    object,\n    indent=_UNSET_SENTINEL,\n    width=_UNSET_SENTINEL,\n    depth=_UNSET_SENTINEL,\n    *,\n    ribbon_width=_UNSET_SENTINEL,\n    max_seq_len=_UNSET_SENTINEL,\n    compact=_UNSET_SENTINEL,\n    sort_dict_keys=_UNSET_SENTINEL\n):\n    \"\"\"\n    Returns a pretty printed representation of the object as a ``str``.\n    Accepts the same parameters as :func:`~prettyprinter.pprint`.\n    The output is not colored.\n    \"\"\"\n    sdocs = python_to_sdocs(\n        object,\n        **_merge_defaults(\n            indent=indent,\n            width=width,\n            depth=depth,\n            ribbon_width=ribbon_width,\n            max_seq_len=max_seq_len,\n            sort_dict_keys=sort_dict_keys,\n        )\n    )\n    stream = StringIO()\n    default_render_to_stream(stream, sdocs)\n    return stream.getvalue()", "response": "Pretty print a single object as a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pprint(\n    object,\n    stream=_UNSET_SENTINEL,\n    indent=_UNSET_SENTINEL,\n    width=_UNSET_SENTINEL,\n    depth=_UNSET_SENTINEL,\n    *,\n    compact=False,\n    ribbon_width=_UNSET_SENTINEL,\n    max_seq_len=_UNSET_SENTINEL,\n    sort_dict_keys=_UNSET_SENTINEL,\n    end='\\n'\n):\n    \"\"\"Pretty print a Python value ``object`` to ``stream``,\n    which defaults to ``sys.stdout``. The output will not be colored.\n\n    :param indent: number of spaces to add for each level of nesting.\n    :param stream: the output stream, defaults to ``sys.stdout``\n    :param width: a soft maximum allowed number of columns in the output,\n                  which the layout algorithm attempts to stay under.\n    :param depth: maximum depth to print nested structures\n    :param ribbon_width: a soft maximum allowed number of columns in the output,\n                         after indenting the line\n    :param max_seq_len: a maximum sequence length that applies to subclasses of\n                        lists, sets, frozensets, tuples and dicts. A trailing\n                        comment that indicates the number of truncated elements.\n                        Setting max_seq_len to ``None`` disables truncation.\n    :param sort_dict_keys: a ``bool`` value indicating if dict keys should be\n                           sorted in the output. Defaults to ``False``, in\n                           which case the default order is used, which is the\n                           insertion order in CPython 3.6+.\n    \"\"\"\n    sdocs = python_to_sdocs(\n        object,\n        **_merge_defaults(\n            indent=indent,\n            width=width,\n            depth=depth,\n            ribbon_width=ribbon_width,\n            max_seq_len=max_seq_len,\n            sort_dict_keys=sort_dict_keys,\n        )\n    )\n    stream = (\n        # This is not in _default_config in case\n        # sys.stdout changes.\n        sys.stdout\n        if stream is _UNSET_SENTINEL\n        else stream\n    )\n\n    default_render_to_stream(stream, sdocs)\n    if end:\n        stream.write(end)", "response": "Pretty print a Python object to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cpprint(\n    object,\n    stream=_UNSET_SENTINEL,\n    indent=_UNSET_SENTINEL,\n    width=_UNSET_SENTINEL,\n    depth=_UNSET_SENTINEL,\n    *,\n    compact=False,\n    ribbon_width=_UNSET_SENTINEL,\n    max_seq_len=_UNSET_SENTINEL,\n    sort_dict_keys=_UNSET_SENTINEL,\n    style=None,\n    end='\\n'\n):\n    \"\"\"Pretty print a Python value ``object`` to ``stream``,\n    which defaults to sys.stdout. The output will be colored and\n    syntax highlighted.\n\n    :param indent: number of spaces to add for each level of nesting.\n    :param stream: the output stream, defaults to sys.stdout\n    :param width: a soft maximum allowed number of columns in the output,\n                  which the layout algorithm attempts to stay under.\n    :param depth: maximum depth to print nested structures\n    :param ribbon_width: a soft maximum allowed number of columns in the output,\n                         after indenting the line\n    :param max_seq_len: a maximum sequence length that applies to subclasses of\n                        lists, sets, frozensets, tuples and dicts. A trailing\n                        comment that indicates the number of truncated elements.\n                        Setting max_seq_len to ``None`` disables truncation.\n    :param sort_dict_keys: a ``bool`` value indicating if dict keys should be\n                           sorted in the output. Defaults to ``False``, in\n                           which case the default order is used, which is the\n                           insertion order in CPython 3.6+.\n    :param style: one of ``'light'``, ``'dark'`` or a subclass\n                  of ``pygments.styles.Style``. If omitted,\n                  will use the default style. If the default style\n                  is not changed by the user with :func:`~prettyprinter.set_default_style`,\n                  the default is ``'dark'``.\n    \"\"\"\n    sdocs = python_to_sdocs(\n        object,\n        **_merge_defaults(\n            indent=indent,\n            width=width,\n            depth=depth,\n            ribbon_width=ribbon_width,\n            max_seq_len=max_seq_len,\n            sort_dict_keys=sort_dict_keys,\n        )\n    )\n    stream = (\n        # This is not in _default_config in case\n        # sys.stdout changes.\n        sys.stdout\n        if stream is _UNSET_SENTINEL\n        else stream\n    )\n    colored_render_to_stream(stream, sdocs, style=style)\n    if end:\n        stream.write(end)", "response": "Pretty print a Python object to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling extras for objects from third - party libraries and or enabling integrations with other python programs.", "response": "def install_extras(\n    include=ALL_EXTRAS,\n    *,\n    exclude=EMPTY_SET,\n    raise_on_error=False,\n    warn_on_error=True\n):\n    \"\"\"Installs extras.\n\n    Installing an extra means registering pretty printers for objects from third\n    party libraries and/or enabling integrations with other python programs.\n\n    - ``'attrs'`` - automatically pretty prints classes created using the ``attrs`` package.\n    - ``'dataclasses'`` - automatically pretty prints classes created using the ``dataclasses``\n      module.\n    - ``'django'`` - automatically pretty prints Model and QuerySet subclasses defined in your\n        Django apps.\n    - ``numpy`` - automatically pretty prints numpy scalars with explicit types, and,\n      for numpy>=1.14, numpy arrays.\n    - ``'requests'`` - automatically pretty prints Requests, Responses, Sessions, etc.\n    - ``'ipython'`` - makes prettyprinter the default printer in the IPython shell.\n    - ``'python'`` - makes prettyprinter the default printer in the default Python shell.\n    - ``'ipython_repr_pretty'`` - automatically prints objects that define a ``_repr_pretty_``\n      method to integrate with `IPython.lib.pretty\n      <http://ipython.readthedocs.io/en/stable/api/generated/IPython.lib.pretty.html#extending>`_.\n\n    :param include: an iterable of strs representing the extras to include.\n        All extras are included by default.\n    :param exclude: an iterable of strs representing the extras to exclude.\n    \"\"\"  # noqa\n    include = set(include)\n    exclude = set(exclude)\n\n    unexisting_extras = (include | exclude) - ALL_EXTRAS\n\n    if unexisting_extras:\n        raise ValueError(\n            \"The following extras don't exist: {}\".format(\n                ', '.join(unexisting_extras)\n            )\n        )\n\n    extras_to_install = (ALL_EXTRAS & include) - exclude\n\n    for extra in extras_to_install:\n        module_name = 'prettyprinter.extras.' + extra\n        try:\n            extra_module = import_module(module_name)\n        except ImportError as e:\n            if raise_on_error:\n                raise e\n            if warn_on_error:\n                warnings.warn(\n                    \"Failed to import '{0}' PrettyPrinter extra. \"\n                    \"If you don't need it, call install_extras with \"\n                    \"exclude=['{0}']\".format(extra)\n                )\n        else:\n            try:\n                extra_module.install()\n            except Exception as exc:\n                if raise_on_error:\n                    raise exc\n                elif warn_on_error:\n                    warnings.warn(\n                        \"Failed to install '{0}' PrettyPrinter extra. \"\n                        \"If you don't need it, call install_extras with \"\n                        \"exclude=['{0}']\".format(extra)\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the default configuration values used when calling a base class.", "response": "def set_default_config(\n    *,\n    style=_UNSET_SENTINEL,\n    max_seq_len=_UNSET_SENTINEL,\n    width=_UNSET_SENTINEL,\n    ribbon_width=_UNSET_SENTINEL,\n    depth=_UNSET_SENTINEL,\n    sort_dict_keys=_UNSET_SENTINEL\n):\n    \"\"\"\n    Sets the default configuration values used when calling\n    `pprint`, `cpprint`, or `pformat`, if those values weren't\n    explicitly provided. Only overrides the values provided in\n    the keyword arguments.\n    \"\"\"\n    global _default_config\n\n    if style is not _UNSET_SENTINEL:\n        set_default_style(style)\n\n    new_defaults = {**_default_config}\n\n    if max_seq_len is not _UNSET_SENTINEL:\n        new_defaults['max_seq_len'] = max_seq_len\n\n    if width is not _UNSET_SENTINEL:\n        new_defaults['width'] = width\n\n    if ribbon_width is not _UNSET_SENTINEL:\n        new_defaults['ribbon_width'] = ribbon_width\n\n    if depth is not _UNSET_SENTINEL:\n        new_defaults['depth'] = depth\n\n    if sort_dict_keys is not _UNSET_SENTINEL:\n        new_defaults['sort_dict_keys'] = sort_dict_keys\n\n    _default_config = new_defaults\n    return new_defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pretty_repr(instance):\n\n    instance_type = type(instance)\n    if not is_registered(\n        instance_type,\n        check_superclasses=True,\n        check_deferred=True,\n        register_deferred=True\n    ):\n        warnings.warn(\n            \"pretty_repr is assigned as the __repr__ method of \"\n            \"'{}'. However, no pretty printer is registered for that type, \"\n            \"its superclasses or its subclasses. Falling back to the default \"\n            \"repr implementation. To fix this warning, register a pretty \"\n            \"printer using prettyprinter.register_pretty.\".format(\n                instance_type.__qualname__\n            ),\n            UserWarning\n        )\n        return object.__repr__(instance)\n\n    return pformat(instance)", "response": "A function assignable to the pretty_repr method so that the pretty printer definition for the type of the object is used to provide the pretty representation output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns Maven package lifecycle", "response": "def package_maven():\n    \"\"\" Run maven package lifecycle \"\"\"\n    if not os.getenv('JAVA_HOME'):\n        # make sure Maven uses the same JDK which we have used to compile\n        # and link the C-code\n        os.environ['JAVA_HOME'] = jdk_home_dir\n\n    mvn_goal = 'package'\n    log.info(\"Executing Maven goal '\" + mvn_goal + \"'\")\n    code = subprocess.call(['mvn', 'clean', mvn_goal, '-DskipTests'],\n                           shell=platform.system() == 'Windows')\n    if code:\n        exit(code)\n\n    #\n    # Copy JAR results to lib/*.jar\n    #\n\n    if not os.path.exists(lib_dir):\n        os.mkdir(lib_dir)\n    target_dir = os.path.join(base_dir, 'target')\n    jar_files = glob.glob(os.path.join(target_dir, '*.jar'))\n    jar_files = [f for f in jar_files\n                 if not (f.endswith('-sources.jar')\n                         or f.endswith('-javadoc.jar'))]\n    if not jar_files:\n        log.error('Maven did not generate any JAR artifacts')\n        exit(1)\n    for jar_file in jar_files:\n        build_dir = _build_dir()\n        log.info(\"Copying \" + jar_file + \" -> \" + build_dir + \"\")\n        shutil.copy(jar_file, build_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _write_jpy_config(target_dir=None, install_dir=None):\n    if not target_dir:\n        target_dir = _build_dir()\n    \n    args = [sys.executable,\n            os.path.join(target_dir, 'jpyutil.py'),\n            '--jvm_dll', jvm_dll_file,\n            '--java_home', jdk_home_dir,\n            '--log_level', 'DEBUG',\n            '--req_java',\n            '--req_py']\n    if install_dir:\n        args.append('--install_dir')\n        args.append(install_dir)\n\n    log.info('Writing jpy configuration to %s using install_dir %s' % (target_dir, install_dir))\n    return subprocess.call(args)", "response": "Write out a well - formed jpyconfig. properties file for easier Java\n    integration in a given location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_module_path(name, fail=False, install_path=None):\n    import imp\n\n    module = imp.find_module(name)\n    if not module and fail:\n        raise RuntimeError(\"can't find module '\" + name + \"'\")\n    path = module[1]\n    if not path and fail:\n        raise RuntimeError(\"module '\" + name + \"' is missing a file path\")\n    \n    if install_path:\n        return os.path.join(install_path, os.path.split(path)[1])\n\n    return path", "response": "Find the path to the jpy jni modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to detect JDK home directory from Maven if available.", "response": "def find_jdk_home_dir():\n    \"\"\"\n    Try to detect the JDK home directory from Maven, if available, or use\n    dedicated environment variables.\n    :return: pathname if found, else None\n    \"\"\"\n    for name in JDK_HOME_VARS:\n        jdk_home_dir = os.environ.get(name, None)\n        if jdk_home_dir \\\n                and os.path.exists(os.path.join(jdk_home_dir, 'include')) \\\n                and os.path.exists(os.path.join(jdk_home_dir, 'lib')):\n            return jdk_home_dir\n    logger.debug('Checking Maven for JAVA_HOME...')\n    try:\n        output = subprocess.check_output(['mvn', '-v'])\n        if isinstance(output, bytes) and not isinstance(output, str):\n            #PY3 related\n            output = output.decode('utf-8')\n        for part in output.split('\\n'):\n            if part.startswith('Java home:'):\n                path = part.split(':')[1].strip()\n                if path.endswith('jre'):\n                    return path[0:-3]\n                \n    except Exception:\n        # maven probably isn't installed or not on PATH\n        logger.debug('Maven not found on PATH. No JAVA_HOME found.')\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to detect the JVM s shared library file.", "response": "def find_jvm_dll_file(java_home_dir=None, fail=False):\n    \"\"\"\n    Try to detect the JVM's shared library file.\n    :param java_home_dir: The Java JRE or JDK installation directory to be used for searching.\n    :return: pathname if found, else None\n    \"\"\"\n\n    logger.debug(\"Searching for JVM shared library file\")\n\n    if java_home_dir:\n        jvm_dll_path = _find_jvm_dll_file(java_home_dir)\n        if jvm_dll_path:\n            return jvm_dll_path\n\n    jvm_dll_path = os.environ.get('JPY_JVM_DLL', None)\n    if jvm_dll_path:\n        return jvm_dll_path\n\n    for name in JRE_HOME_VARS:\n        java_home_dir = os.environ.get(name, None)\n        if java_home_dir:\n            jvm_dll_path = _find_jvm_dll_file(java_home_dir)\n            if jvm_dll_path:\n                return jvm_dll_path\n\n    jvm_dll_path = ctypes.util.find_library(JVM_LIB_NAME)\n    if jvm_dll_path:\n        logger.debug(\"No JVM shared library file found in all search paths. Using fallback %s\" % repr(jvm_dll_path))\n    elif fail:\n        raise RuntimeError(\"can't find any JVM shared library\")\n\n    return jvm_dll_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing a new JVM virtual machine.", "response": "def init_jvm(java_home=None,\n             jvm_dll=None,\n             jvm_maxmem=None,\n             jvm_classpath=None,\n             jvm_properties=None,\n             jvm_options=None,\n             config_file=None,\n             config=None):\n    \"\"\"\n    Creates a configured Java virtual machine which will be used by jpy.\n\n    :param java_home: The Java JRE or JDK home directory used to search JVM shared library, if 'jvm_dll' is omitted.\n    :param jvm_dll: The JVM shared library file. My be inferred from 'java_home'.\n    :param jvm_maxmem: The JVM maximum heap space, e.g. '400M', '8G'. Refer to the java executable '-Xmx' option.\n    :param jvm_classpath: The JVM search paths for Java class files. Separated by colons (Unix) or semicolons\n                          (Windows). Refer to the java executable '-cp' option.\n    :param jvm_properties: A dictionary of key -> value pairs passed to the JVM as Java system properties.\n                        Refer to the java executable '-D' option.\n    :param jvm_options: A list of extra options for the JVM. Refer to the java executable options.\n    :param config_file: Extra configuration file (e.g. 'jpyconfig.py') to be loaded if 'config' parameter is omitted.\n    :param config: An optional default configuration object providing default attributes\n                   for the 'jvm_maxmem', 'jvm_classpath', 'jvm_properties', 'jvm_options' parameters.\n    :return: a tuple (cdll, actual_jvm_options) on success, None otherwise.\n    \"\"\"\n    if not config:\n        config = _get_python_api_config(config_file=config_file)\n\n    cdll = preload_jvm_dll(jvm_dll_file=jvm_dll,\n                           java_home_dir=java_home,\n                           config_file=config_file,\n                           config=config,\n                           fail=False)\n\n    import jpy\n\n    if not jpy.has_jvm():\n        jvm_options = get_jvm_options(jvm_maxmem=jvm_maxmem,\n                                      jvm_classpath=jvm_classpath,\n                                      jvm_properties=jvm_properties,\n                                      jvm_options=jvm_options,\n                                      config=config)\n        logger.debug('Creating JVM with options %s' % repr(jvm_options))\n        jpy.create_jvm(options=jvm_options)\n    else:\n        jvm_options = None\n\n    # print('jvm_dll =', jvm_dll)\n    # print('jvm_options =', jvm_options)\n    return cdll, jvm_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_config_files(out_dir='.',\n                       java_home_dir=None,\n                       jvm_dll_file=None,\n                       install_dir=None,\n                       req_java_api_conf=True,\n                       req_py_api_conf=True):\n    \"\"\"\n    Writes the jpy configuration files for Java and/or Python.\n\n    :param out_dir: output directory, must exist\n    :param java_home_dir: optional home directory of the Java JRE or JDK installation\n    :param jvm_dll_file: optional file to JVM shared library file\n    :param install_dir: optional path to where to searfh for modules\n    :param req_java_api_conf: whether to write the jpy configuration file 'jpyconfig.properties' for Java\n    :param req_py_api_conf: whether to write the jpy configuration file 'jpyconfig.py' for Python\n    :return: zero on success, otherwise an error code\n    \"\"\"\n    import datetime\n\n    retcode = 0\n\n    tool_name = os.path.basename(__file__)\n\n    py_api_config_basename = 'jpyconfig.py'\n    java_api_config_basename = 'jpyconfig.properties'\n\n    if not jvm_dll_file:\n        jvm_dll_file = find_jvm_dll_file(java_home_dir=java_home_dir)\n    if jvm_dll_file:\n        py_api_config_file = os.path.join(out_dir, py_api_config_basename)\n        try:\n            with open(py_api_config_file, 'w') as f:\n                f.write(\"# Created by '%s' tool on %s\\n\" % (tool_name, str(datetime.datetime.now())))\n                f.write(\n                    \"# This file is read by the 'jpyutil' module in order to load and configure the JVM from Python\\n\")\n                if java_home_dir:\n                    f.write('java_home = %s\\n' % repr(java_home_dir))\n                f.write('jvm_dll = %s\\n' % repr(jvm_dll_file))\n                f.write('jvm_maxmem = None\\n')\n                f.write('jvm_classpath = []\\n')\n                f.write('jvm_properties = {}\\n')\n                f.write('jvm_options = []\\n')\n            logger.info(\"jpy Python API configuration written to '%s'\" % py_api_config_file)\n        except Exception:\n            logger.exception(\"Error while writing Python API configuration\")\n            if req_py_api_conf:\n                retcode = 1\n    else:\n        logger.error(\"Can't determine any JVM shared library\")\n        if req_py_api_conf:\n            retcode = 2\n\n    try:\n        java_api_config_file = os.path.join(out_dir, java_api_config_basename)\n        java_api_properties = _get_java_api_properties(fail=req_java_api_conf, path=install_dir)\n        java_api_properties.store(java_api_config_file, comments=[\n            \"Created by '%s' tool on %s\" % (tool_name, str(datetime.datetime.now())),\n            \"This file is read by the jpy Java API (org.jpy.PyLib class) in order to find shared libraries\"])\n        logger.info(\"jpy Java API configuration written to '%s'\" % java_api_config_file)\n    except Exception:\n        logger.exception(\"Error while writing Java API configuration\")\n        if req_java_api_conf:\n            retcode = 3\n\n    return retcode", "response": "Writes the jpyconfig. py file for the Java and Python modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, path):\n        with open(path) as f:\n            code = f.read()\n            exec(code, {}, self.__dict__)", "response": "Read the the\n            Python file from path and return the object that stores all variables of the\n            Python code as attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--lint',\n                        help='Path to the ADT lint tool. If not specified it assumes lint tool is in your path',\n                        default='lint')\n    parser.add_argument('--app',\n                        help='Path to the Android app. If not specifies it assumes current directory is your Android '\n                             'app directory',\n                        default='.')\n    parser.add_argument('--xml',\n                        help='Path to the lint result. If not specifies linting will be done by the script',\n                        default=None)\n    parser.add_argument('--ignore-layouts',\n                        help='Should ignore layouts',\n                        action='store_true')\n    args = parser.parse_args()\n    return args.lint, args.app, args.xml, args.ignore_layouts", "response": "Parse command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the lint command in the shell and save results to lint - result. xml racket", "response": "def run_lint_command():\n    \"\"\"\n    Run lint command in the shell and save results to lint-result.xml\n    \"\"\"\n    lint, app_dir, lint_result, ignore_layouts = parse_args()\n    if not lint_result:\n        if not distutils.spawn.find_executable(lint):\n            raise Exception(\n                '`%s` executable could not be found and path to lint result not specified. See --help' % lint)\n        lint_result = os.path.join(app_dir, 'lint-result.xml')\n        call_result = subprocess.call([lint, app_dir, '--xml', lint_result])\n        if call_result > 0:\n            print('Running the command failed with result %s. Try running it from the console.'\n                  ' Arguments for subprocess.call: %s' % (call_result, [lint, app_dir, '--xml', lint_result]))\n    else:\n        if not os.path.isabs(lint_result):\n            lint_result = os.path.join(app_dir, lint_result)\n    lint_result = os.path.abspath(lint_result)\n    return lint_result, app_dir, ignore_layouts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_lint_result(lint_result_path, manifest_path):\n    unused_string_pattern = re.compile('The resource `R\\.string\\.([^`]+)` appears to be unused')\n    mainfest_string_refs = get_manifest_string_refs(manifest_path)\n    root = etree.parse(lint_result_path).getroot()\n    issues = []\n\n    for issue_xml in root.findall('.//issue[@id=\"UnusedResources\"]'):\n        message = issue_xml.get('message')\n        unused_string = re.match(unused_string_pattern, issue_xml.get('message'))\n        has_string_in_manifest = unused_string and unused_string.group(1) in mainfest_string_refs\n        if not has_string_in_manifest:\n            issues.extend(_get_issues_from_location(UnusedResourceIssue,\n                                                    issue_xml.findall('location'),\n                                                    message))\n\n    for issue_xml in root.findall('.//issue[@id=\"ExtraTranslation\"]'):\n        message = issue_xml.get('message')\n        if re.findall(ExtraTranslationIssue.pattern, message):\n            issues.extend(_get_issues_from_location(ExtraTranslationIssue,\n                                                    issue_xml.findall('location'),\n                                                    message))\n\n    return issues", "response": "Parse lint - result. xml and create issues for every problem found except unused strings referenced in AndroidManifest\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a file from the filesystem", "response": "def remove_resource_file(issue, filepath, ignore_layouts):\n    \"\"\"\n    Delete a file from the filesystem\n    \"\"\"\n    if os.path.exists(filepath) and (ignore_layouts is False or issue.elements[0][0] != 'layout'):\n        print('removing resource: {0}'.format(filepath))\n        os.remove(os.path.abspath(filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading an xml file and remove an element which is unused from the resource", "response": "def remove_resource_value(issue, filepath):\n    \"\"\"\n    Read an xml file and remove an element which is unused, then save the file back to the filesystem\n    \"\"\"\n    if os.path.exists(filepath):\n        for element in issue.elements:\n            print('removing {0} from resource {1}'.format(element, filepath))\n            parser = etree.XMLParser(remove_blank_text=False, remove_comments=False,\n                                     remove_pis=False, strip_cdata=False, resolve_entities=False)\n            tree = etree.parse(filepath, parser)\n            root = tree.getroot()\n            for unused_value in root.findall('.//{0}[@name=\"{1}\"]'.format(element[0], element[1])):\n                root.remove(unused_value)\n            with open(filepath, 'wb') as resource:\n                tree.write(resource, encoding='utf-8', xml_declaration=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving unused resources from the given issue.", "response": "def remove_unused_resources(issues, app_dir, ignore_layouts):\n    \"\"\"\n    Remove the file or the value inside the file depending if the whole file is unused or not.\n    \"\"\"\n    for issue in issues:\n        filepath = os.path.join(app_dir, issue.filepath)\n        if issue.remove_file:\n            remove_resource_file(issue, filepath, ignore_layouts)\n        else:\n            remove_resource_value(issue, filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _encryption_context_hash(hasher, encryption_context):\n    serialized_encryption_context = serialize_encryption_context(encryption_context)\n    hasher.update(serialized_encryption_context)\n    return hasher.finalize()", "response": "Generates the expected hash for the provided encryption context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_encryption_materials_cache_key(partition, request):\n    if request.algorithm is None:\n        _algorithm_info = b\"\\x00\"\n    else:\n        _algorithm_info = b\"\\x01\" + request.algorithm.id_as_bytes()\n\n    hasher = _new_cache_key_hasher()\n    _partition_hash = _partition_name_hash(hasher=hasher.copy(), partition_name=partition)\n    _ec_hash = _encryption_context_hash(hasher=hasher.copy(), encryption_context=request.encryption_context)\n\n    hasher.update(_partition_hash)\n    hasher.update(_algorithm_info)\n    hasher.update(_ec_hash)\n    return hasher.finalize()", "response": "Generates a cache key for an encrypt request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the expected hash for the provided encrypted data keys.", "response": "def _encrypted_data_keys_hash(hasher, encrypted_data_keys):\n    \"\"\"Generates the expected hash for the provided encrypted data keys.\n\n    :param hasher: Existing hasher to use\n    :type hasher: cryptography.hazmat.primitives.hashes.Hash\n    :param iterable encrypted_data_keys: Encrypted data keys to hash\n    :returns: Concatenated, sorted, list of all hashes\n    :rtype: bytes\n    \"\"\"\n    hashed_keys = []\n    for edk in encrypted_data_keys:\n        serialized_edk = serialize_encrypted_data_key(edk)\n        _hasher = hasher.copy()\n        _hasher.update(serialized_edk)\n        hashed_keys.append(_hasher.finalize())\n    return b\"\".join(sorted(hashed_keys))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a cache key for a decrypt request.", "response": "def build_decryption_materials_cache_key(partition, request):\n    \"\"\"Generates a cache key for a decrypt request.\n\n    :param bytes partition: Partition name for which to generate key\n    :param request: Request for which to generate key\n    :type request: aws_encryption_sdk.materials_managers.DecryptionMaterialsRequest\n    :returns: cache key\n    :rtype: bytes\n    \"\"\"\n    hasher = _new_cache_key_hasher()\n    _partition_hash = _partition_name_hash(hasher=hasher.copy(), partition_name=partition)\n    _algorithm_info = request.algorithm.id_as_bytes()\n    _edks_hash = _encrypted_data_keys_hash(hasher=hasher.copy(), encrypted_data_keys=request.encrypted_data_keys)\n    _ec_hash = _encryption_context_hash(hasher=hasher.copy(), encryption_context=request.encryption_context)\n\n    hasher.update(_partition_hash)\n    hasher.update(_algorithm_info)\n    hasher.update(_edks_hash)\n    hasher.update(_512_BIT_PAD)\n    hasher.update(_ec_hash)\n    return hasher.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencrypting and then decrypts a string under a KMS customer master key.", "response": "def cycle_string(key_arn, source_plaintext, botocore_session=None):\n    \"\"\"Encrypts and then decrypts a string under a KMS customer master key (CMK).\n\n    :param str key_arn: Amazon Resource Name (ARN) of the KMS CMK\n    :param bytes source_plaintext: Data to encrypt\n    :param botocore_session: existing botocore session instance\n    :type botocore_session: botocore.session.Session\n    \"\"\"\n    # Create a KMS master key provider\n    kms_kwargs = dict(key_ids=[key_arn])\n    if botocore_session is not None:\n        kms_kwargs[\"botocore_session\"] = botocore_session\n    master_key_provider = aws_encryption_sdk.KMSMasterKeyProvider(**kms_kwargs)\n\n    # Encrypt the plaintext source data\n    ciphertext, encryptor_header = aws_encryption_sdk.encrypt(source=source_plaintext, key_provider=master_key_provider)\n\n    # Decrypt the ciphertext\n    cycled_plaintext, decrypted_header = aws_encryption_sdk.decrypt(source=ciphertext, key_provider=master_key_provider)\n\n    # Verify that the \"cycled\" (encrypted, then decrypted) plaintext is identical to the source plaintext\n    assert cycled_plaintext == source_plaintext\n\n    # Verify that the encryption context used in the decrypt operation includes all key pairs from\n    # the encrypt operation. (The SDK can add pairs, so don't require an exact match.)\n    #\n    # In production, always use a meaningful encryption context. In this sample, we omit the\n    # encryption context (no key pairs).\n    assert all(\n        pair in decrypted_header.encryption_context.items() for pair in encryptor_header.encryption_context.items()\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencrypt and then decrypts a file under a custom static master key provider.", "response": "def cycle_file(source_plaintext_filename):\n    \"\"\"Encrypts and then decrypts a file under a custom static master key provider.\n\n    :param str source_plaintext_filename: Filename of file to encrypt\n    \"\"\"\n    # Create a static random master key provider\n    key_id = os.urandom(8)\n    master_key_provider = StaticRandomMasterKeyProvider()\n    master_key_provider.add_master_key(key_id)\n\n    ciphertext_filename = source_plaintext_filename + \".encrypted\"\n    cycled_plaintext_filename = source_plaintext_filename + \".decrypted\"\n\n    # Encrypt the plaintext source data\n    with open(source_plaintext_filename, \"rb\") as plaintext, open(ciphertext_filename, \"wb\") as ciphertext:\n        with aws_encryption_sdk.stream(mode=\"e\", source=plaintext, key_provider=master_key_provider) as encryptor:\n            for chunk in encryptor:\n                ciphertext.write(chunk)\n\n    # Decrypt the ciphertext\n    with open(ciphertext_filename, \"rb\") as ciphertext, open(cycled_plaintext_filename, \"wb\") as plaintext:\n        with aws_encryption_sdk.stream(mode=\"d\", source=ciphertext, key_provider=master_key_provider) as decryptor:\n            for chunk in decryptor:\n                plaintext.write(chunk)\n\n    # Verify that the \"cycled\" (encrypted, then decrypted) plaintext is identical to the source\n    # plaintext\n    assert filecmp.cmp(source_plaintext_filename, cycled_plaintext_filename)\n\n    # Verify that the encryption context used in the decrypt operation includes all key pairs from\n    # the encrypt operation\n    #\n    # In production, always use a meaningful encryption context. In this sample, we omit the\n    # encryption context (no key pairs).\n    assert all(\n        pair in decryptor.header.encryption_context.items() for pair in encryptor.header.encryption_context.items()\n    )\n    return ciphertext_filename, cycled_plaintext_filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_raw_key(self, key_id):\n        try:\n            static_key = self._static_keys[key_id]\n        except KeyError:\n            static_key = os.urandom(32)\n            self._static_keys[key_id] = static_key\n        return WrappingKey(\n            wrapping_algorithm=WrappingAlgorithm.AES_256_GCM_IV12_TAG16_NO_PADDING,\n            wrapping_key=static_key,\n            wrapping_key_type=EncryptionKeyType.SYMMETRIC,\n        )", "response": "Returns a static randomly - generated symmetric key for the specified key ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_length(self):\n        if self._stream_length is None:\n            try:\n                current_position = self.source_stream.tell()\n                self.source_stream.seek(0, 2)\n                self._stream_length = self.source_stream.tell()\n                self.source_stream.seek(current_position, 0)\n            except Exception as error:\n                # Catch-all for unknown issues encountered trying to seek for stream length\n                raise NotSupportedError(error)\n        return self._stream_length", "response": "Returns the length of the source stream if not already known."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, b=-1):\n        # Any negative value for b is interpreted as a full read\n        # None is also accepted for legacy compatibility\n        if b is None or b < 0:\n            b = -1\n\n        _LOGGER.debug(\"Stream read called, requesting %d bytes\", b)\n        output = io.BytesIO()\n\n        if not self._message_prepped:\n            self._prep_message()\n\n        if self.closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        if b >= 0:\n            self._read_bytes(b)\n            output.write(self.output_buffer[:b])\n            self.output_buffer = self.output_buffer[b:]\n        else:\n            while True:\n                line = self.readline()\n                if not line:\n                    break\n                output.write(line)\n\n        self.bytes_read += output.tell()\n        _LOGGER.debug(\"Returning %d bytes of %d bytes requested\", output.tell(), b)\n        return output.getvalue()", "response": "Reads the requested number of bytes from the source stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a line of data from the output.", "response": "def readline(self):\n        \"\"\"Read a chunk of the output\"\"\"\n        _LOGGER.info(\"reading line\")\n        line = self.read(self.line_length)\n        if len(line) < self.line_length:\n            _LOGGER.info(\"all lines read\")\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprovide hook for Python2 iterator functionality.", "response": "def next(self):\n        \"\"\"Provides hook for Python2 iterator functionality.\"\"\"\n        _LOGGER.debug(\"reading next\")\n        if self.closed:\n            _LOGGER.debug(\"stream is closed\")\n            raise StopIteration()\n\n        line = self.readline()\n        if not line:\n            _LOGGER.debug(\"nothing more to read\")\n            raise StopIteration()\n\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the length of the resulting ciphertext message in bytes.", "response": "def ciphertext_length(self):\n        \"\"\"Returns the length of the resulting ciphertext message in bytes.\n\n        :rtype: int\n        \"\"\"\n        return aws_encryption_sdk.internal.formatting.ciphertext_length(\n            header=self.header, plaintext_length=self.stream_length\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prep_message(self):\n        message_id = aws_encryption_sdk.internal.utils.message_id()\n\n        try:\n            plaintext_length = self.stream_length\n        except NotSupportedError:\n            plaintext_length = None\n        encryption_materials_request = EncryptionMaterialsRequest(\n            algorithm=self.config.algorithm,\n            encryption_context=self.config.encryption_context.copy(),\n            frame_length=self.config.frame_length,\n            plaintext_rostream=aws_encryption_sdk.internal.utils.streams.ROStream(self.source_stream),\n            plaintext_length=plaintext_length,\n        )\n        self._encryption_materials = self.config.materials_manager.get_encryption_materials(\n            request=encryption_materials_request\n        )\n\n        if self.config.algorithm is not None and self._encryption_materials.algorithm != self.config.algorithm:\n            raise ActionNotAllowedError(\n                (\n                    \"Cryptographic materials manager provided algorithm suite\"\n                    \" differs from algorithm suite in request.\\n\"\n                    \"Required: {requested}\\n\"\n                    \"Provided: {provided}\"\n                ).format(requested=self.config.algorithm, provided=self._encryption_materials.algorithm)\n            )\n\n        if self._encryption_materials.signing_key is None:\n            self.signer = None\n        else:\n            self.signer = Signer.from_key_bytes(\n                algorithm=self._encryption_materials.algorithm, key_bytes=self._encryption_materials.signing_key\n            )\n        aws_encryption_sdk.internal.utils.validate_frame_length(\n            frame_length=self.config.frame_length, algorithm=self._encryption_materials.algorithm\n        )\n\n        self._derived_data_key = derive_data_encryption_key(\n            source_key=self._encryption_materials.data_encryption_key.data_key,\n            algorithm=self._encryption_materials.algorithm,\n            message_id=message_id,\n        )\n\n        self._header = MessageHeader(\n            version=VERSION,\n            type=TYPE,\n            algorithm=self._encryption_materials.algorithm,\n            message_id=message_id,\n            encryption_context=self._encryption_materials.encryption_context,\n            encrypted_data_keys=self._encryption_materials.encrypted_data_keys,\n            content_type=self.content_type,\n            content_aad_length=0,\n            header_iv_length=self._encryption_materials.algorithm.iv_len,\n            frame_length=self.config.frame_length,\n        )\n        self._write_header()\n        if self.content_type == ContentType.NO_FRAMING:\n            self._prep_non_framed()\n        self._message_prepped = True", "response": "Prepares the message for the master key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the message header and writes it to the output stream.", "response": "def _write_header(self):\n        \"\"\"Builds the message header and writes it to the output stream.\"\"\"\n        self.output_buffer += serialize_header(header=self._header, signer=self.signer)\n        self.output_buffer += serialize_header_auth(\n            algorithm=self._encryption_materials.algorithm,\n            header=self.output_buffer,\n            data_encryption_key=self._derived_data_key,\n            signer=self.signer,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare the opening data for a non - framed message.", "response": "def _prep_non_framed(self):\n        \"\"\"Prepare the opening data for a non-framed message.\"\"\"\n        try:\n            plaintext_length = self.stream_length\n            self.__unframed_plaintext_cache = self.source_stream\n        except NotSupportedError:\n            # We need to know the plaintext length before we can start processing the data.\n            # If we cannot seek on the source then we need to read the entire source into memory.\n            self.__unframed_plaintext_cache = io.BytesIO()\n            self.__unframed_plaintext_cache.write(self.source_stream.read())\n            plaintext_length = self.__unframed_plaintext_cache.tell()\n            self.__unframed_plaintext_cache.seek(0)\n\n        aad_content_string = aws_encryption_sdk.internal.utils.get_aad_content_string(\n            content_type=self.content_type, is_final_frame=True\n        )\n        associated_data = assemble_content_aad(\n            message_id=self._header.message_id,\n            aad_content_string=aad_content_string,\n            seq_num=1,\n            length=plaintext_length,\n        )\n        self.encryptor = Encryptor(\n            algorithm=self._encryption_materials.algorithm,\n            key=self._derived_data_key,\n            associated_data=associated_data,\n            iv=non_framed_body_iv(self._encryption_materials.algorithm),\n        )\n        self.output_buffer += serialize_non_framed_open(\n            algorithm=self._encryption_materials.algorithm,\n            iv=self.encryptor.iv,\n            plaintext_length=plaintext_length,\n            signer=self.signer,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_bytes_to_non_framed_body(self, b):\n        _LOGGER.debug(\"Reading %d bytes\", b)\n        plaintext = self.__unframed_plaintext_cache.read(b)\n        plaintext_length = len(plaintext)\n        if self.tell() + len(plaintext) > MAX_NON_FRAMED_SIZE:\n            raise SerializationError(\"Source too large for non-framed message\")\n\n        ciphertext = self.encryptor.update(plaintext)\n        self._bytes_encrypted += plaintext_length\n        if self.signer is not None:\n            self.signer.update(ciphertext)\n\n        if len(plaintext) < b:\n            _LOGGER.debug(\"Closing encryptor after receiving only %d bytes of %d bytes requested\", plaintext_length, b)\n\n            closing = self.encryptor.finalize()\n\n            if self.signer is not None:\n                self.signer.update(closing)\n\n            closing += serialize_non_framed_close(tag=self.encryptor.tag, signer=self.signer)\n\n            if self.signer is not None:\n                closing += serialize_footer(self.signer)\n            self.__message_complete = True\n            return ciphertext + closing\n\n        return ciphertext", "response": "Reads the requested number of bytes from source to a streaming non - framed message body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the requested number of bytes from source stream to a streaming framed message body.", "response": "def _read_bytes_to_framed_body(self, b):\n        \"\"\"Reads the requested number of bytes from source to a streaming framed message body.\n\n        :param int b: Number of bytes to read\n        :returns: Bytes read from source stream, encrypted, and serialized\n        :rtype: bytes\n        \"\"\"\n        _LOGGER.debug(\"collecting %d bytes\", b)\n        _b = b\n\n        if b > 0:\n            _frames_to_read = math.ceil(b / float(self.config.frame_length))\n            b = int(_frames_to_read * self.config.frame_length)\n        _LOGGER.debug(\"%d bytes requested; reading %d bytes after normalizing to frame length\", _b, b)\n\n        plaintext = self.source_stream.read(b)\n        plaintext_length = len(plaintext)\n        _LOGGER.debug(\"%d bytes read from source\", plaintext_length)\n\n        finalize = False\n\n        if b < 0 or plaintext_length < b:\n            _LOGGER.debug(\"Final plaintext read from source\")\n            finalize = True\n\n        output = b\"\"\n        final_frame_written = False\n\n        while (\n            # If not finalizing on this pass, exit when plaintext is exhausted\n            (not finalize and plaintext)\n            # If finalizing on this pass, wait until final frame is written\n            or (finalize and not final_frame_written)\n        ):\n            current_plaintext_length = len(plaintext)\n            is_final_frame = finalize and current_plaintext_length < self.config.frame_length\n            bytes_in_frame = min(current_plaintext_length, self.config.frame_length)\n            _LOGGER.debug(\n                \"Writing %d bytes into%s frame %d\",\n                bytes_in_frame,\n                \" final\" if is_final_frame else \"\",\n                self.sequence_number,\n            )\n            self._bytes_encrypted += bytes_in_frame\n            ciphertext, plaintext = serialize_frame(\n                algorithm=self._encryption_materials.algorithm,\n                plaintext=plaintext,\n                message_id=self._header.message_id,\n                data_encryption_key=self._derived_data_key,\n                frame_length=self.config.frame_length,\n                sequence_number=self.sequence_number,\n                is_final_frame=is_final_frame,\n                signer=self.signer,\n            )\n            final_frame_written = is_final_frame\n            output += ciphertext\n            self.sequence_number += 1\n\n        if finalize:\n            _LOGGER.debug(\"Writing footer\")\n            if self.signer is not None:\n                output += serialize_footer(self.signer)\n            self.__message_complete = True\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the requested number of bytes from a streaming message body.", "response": "def _read_bytes(self, b):\n        \"\"\"Reads the requested number of bytes from a streaming message body.\n\n        :param int b: Number of bytes to read\n        :raises NotSupportedError: if content type is not supported\n        \"\"\"\n        _LOGGER.debug(\"%d bytes requested from stream with content type: %s\", b, self.content_type)\n        if 0 <= b <= len(self.output_buffer) or self.__message_complete:\n            _LOGGER.debug(\"No need to read from source stream or source stream closed\")\n            return\n\n        if self.content_type == ContentType.FRAMED_DATA:\n            _LOGGER.debug(\"Reading to framed body\")\n            self.output_buffer += self._read_bytes_to_framed_body(b)\n        elif self.content_type == ContentType.NO_FRAMING:\n            _LOGGER.debug(\"Reading to non-framed body\")\n            self.output_buffer += self._read_bytes_to_non_framed_body(b)\n        else:\n            raise NotSupportedError(\"Unsupported content type\")\n\n        # To maintain backwards compatibility, only enforce this if a CMM is provided by the caller.\n        if self.config.key_provider is None and self.config.source_length is not None:\n            # Enforce that if the caller provided a source length value, the total bytes encrypted\n            # must not exceed that value.\n            if self._bytes_encrypted > self.config.source_length:\n                raise CustomMaximumValueExceeded(\n                    \"Bytes encrypted has exceeded stated source length estimate:\\n{actual:d} > {estimated:d}\".format(\n                        actual=self._bytes_encrypted, estimated=self.config.source_length\n                    )\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms initial message setup.", "response": "def _prep_message(self):\n        \"\"\"Performs initial message setup.\"\"\"\n        self._header, self.header_auth = self._read_header()\n        if self._header.content_type == ContentType.NO_FRAMING:\n            self._prep_non_framed()\n        self._message_prepped = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the message header from the input stream.", "response": "def _read_header(self):\n        \"\"\"Reads the message header from the input stream.\n\n        :returns: tuple containing deserialized header and header_auth objects\n        :rtype: tuple of aws_encryption_sdk.structures.MessageHeader\n            and aws_encryption_sdk.internal.structures.MessageHeaderAuthentication\n        :raises CustomMaximumValueExceeded: if frame length is greater than the custom max value\n        \"\"\"\n        header, raw_header = deserialize_header(self.source_stream)\n        self.__unframed_bytes_read += len(raw_header)\n\n        if (\n            self.config.max_body_length is not None\n            and header.content_type == ContentType.FRAMED_DATA\n            and header.frame_length > self.config.max_body_length\n        ):\n            raise CustomMaximumValueExceeded(\n                \"Frame Size in header found larger than custom value: {found:d} > {custom:d}\".format(\n                    found=header.frame_length, custom=self.config.max_body_length\n                )\n            )\n\n        decrypt_materials_request = DecryptionMaterialsRequest(\n            encrypted_data_keys=header.encrypted_data_keys,\n            algorithm=header.algorithm,\n            encryption_context=header.encryption_context,\n        )\n        decryption_materials = self.config.materials_manager.decrypt_materials(request=decrypt_materials_request)\n        if decryption_materials.verification_key is None:\n            self.verifier = None\n        else:\n            self.verifier = Verifier.from_key_bytes(\n                algorithm=header.algorithm, key_bytes=decryption_materials.verification_key\n            )\n        if self.verifier is not None:\n            self.verifier.update(raw_header)\n\n        header_auth = deserialize_header_auth(\n            stream=self.source_stream, algorithm=header.algorithm, verifier=self.verifier\n        )\n        self._derived_data_key = derive_data_encryption_key(\n            source_key=decryption_materials.data_key.data_key, algorithm=header.algorithm, message_id=header.message_id\n        )\n        validate_header(header=header, header_auth=header_auth, raw_header=raw_header, data_key=self._derived_data_key)\n        return header, header_auth"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare the opening data for a non - framed message.", "response": "def _prep_non_framed(self):\n        \"\"\"Prepare the opening data for a non-framed message.\"\"\"\n        self._unframed_body_iv, self.body_length = deserialize_non_framed_values(\n            stream=self.source_stream, header=self._header, verifier=self.verifier\n        )\n\n        if self.config.max_body_length is not None and self.body_length > self.config.max_body_length:\n            raise CustomMaximumValueExceeded(\n                \"Non-framed message content length found larger than custom value: {found:d} > {custom:d}\".format(\n                    found=self.body_length, custom=self.config.max_body_length\n                )\n            )\n\n        self.__unframed_bytes_read += self._header.algorithm.iv_len\n        self.__unframed_bytes_read += 8  # encrypted content length field\n        self._body_start = self.__unframed_bytes_read\n        self._body_end = self._body_start + self.body_length"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_bytes_from_non_framed_body(self, b):\n        _LOGGER.debug(\"starting non-framed body read\")\n        # Always read the entire message for non-framed message bodies.\n        bytes_to_read = self.body_length\n\n        _LOGGER.debug(\"%d bytes requested; reading %d bytes\", b, bytes_to_read)\n        ciphertext = self.source_stream.read(bytes_to_read)\n\n        if len(self.output_buffer) + len(ciphertext) < self.body_length:\n            raise SerializationError(\"Total message body contents less than specified in body description\")\n\n        if self.verifier is not None:\n            self.verifier.update(ciphertext)\n\n        tag = deserialize_tag(stream=self.source_stream, header=self._header, verifier=self.verifier)\n\n        aad_content_string = aws_encryption_sdk.internal.utils.get_aad_content_string(\n            content_type=self._header.content_type, is_final_frame=True\n        )\n        associated_data = assemble_content_aad(\n            message_id=self._header.message_id,\n            aad_content_string=aad_content_string,\n            seq_num=1,\n            length=self.body_length,\n        )\n        self.decryptor = Decryptor(\n            algorithm=self._header.algorithm,\n            key=self._derived_data_key,\n            associated_data=associated_data,\n            iv=self._unframed_body_iv,\n            tag=tag,\n        )\n\n        plaintext = self.decryptor.update(ciphertext)\n        plaintext += self.decryptor.finalize()\n\n        self.footer = deserialize_footer(stream=self.source_stream, verifier=self.verifier)\n        return plaintext", "response": "Reads the requested number of bytes from a streaming non - framed message body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the requested number of bytes from a streaming framed message body.", "response": "def _read_bytes_from_framed_body(self, b):\n        \"\"\"Reads the requested number of bytes from a streaming framed message body.\n\n        :param int b: Number of bytes to read\n        :returns: Bytes read from source stream and decrypted\n        :rtype: bytes\n        \"\"\"\n        plaintext = b\"\"\n        final_frame = False\n        _LOGGER.debug(\"collecting %d bytes\", b)\n        while len(plaintext) < b and not final_frame:\n            _LOGGER.debug(\"Reading frame\")\n            frame_data, final_frame = deserialize_frame(\n                stream=self.source_stream, header=self._header, verifier=self.verifier\n            )\n            _LOGGER.debug(\"Read complete for frame %d\", frame_data.sequence_number)\n            if frame_data.sequence_number != self.last_sequence_number + 1:\n                raise SerializationError(\"Malformed message: frames out of order\")\n            self.last_sequence_number += 1\n            aad_content_string = aws_encryption_sdk.internal.utils.get_aad_content_string(\n                content_type=self._header.content_type, is_final_frame=frame_data.final_frame\n            )\n            associated_data = assemble_content_aad(\n                message_id=self._header.message_id,\n                aad_content_string=aad_content_string,\n                seq_num=frame_data.sequence_number,\n                length=len(frame_data.ciphertext),\n            )\n            plaintext += decrypt(\n                algorithm=self._header.algorithm,\n                key=self._derived_data_key,\n                encrypted_data=frame_data,\n                associated_data=associated_data,\n            )\n            plaintext_length = len(plaintext)\n            _LOGGER.debug(\"bytes collected: %d\", plaintext_length)\n        if final_frame:\n            _LOGGER.debug(\"Reading footer\")\n            self.footer = deserialize_footer(stream=self.source_stream, verifier=self.verifier)\n\n        return plaintext"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the requested number of bytes from a streaming message body.", "response": "def _read_bytes(self, b):\n        \"\"\"Reads the requested number of bytes from a streaming message body.\n\n        :param int b: Number of bytes to read\n        :raises NotSupportedError: if content type is not supported\n        \"\"\"\n        if hasattr(self, \"footer\"):\n            _LOGGER.debug(\"Source stream processing complete\")\n            return\n\n        buffer_length = len(self.output_buffer)\n        if 0 <= b <= buffer_length:\n            _LOGGER.debug(\"%d bytes requested less than or equal to current output buffer size %d\", b, buffer_length)\n            return\n\n        if self._header.content_type == ContentType.FRAMED_DATA:\n            self.output_buffer += self._read_bytes_from_framed_body(b)\n        elif self._header.content_type == ContentType.NO_FRAMING:\n            self.output_buffer += self._read_bytes_from_non_framed_body(b)\n        else:\n            raise NotSupportedError(\"Unsupported content type\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose out the stream.", "response": "def close(self):\n        \"\"\"Closes out the stream.\"\"\"\n        _LOGGER.debug(\"Closing stream\")\n        if not hasattr(self, \"footer\"):\n            raise SerializationError(\"Footer not read\")\n        super(StreamDecryptor, self).close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines the target region from a key ID.", "response": "def _region_from_key_id(key_id, default_region=None):\n    \"\"\"Determine the target region from a key ID, falling back to a default region if provided.\n\n    :param str key_id: AWS KMS key ID\n    :param str default_region: Region to use if no region found in key_id\n    :returns: region name\n    :rtype: str\n    :raises UnknownRegionError: if no region found in key_id and no default_region provided\n    \"\"\"\n    try:\n        region_name = key_id.split(\":\", 4)[3]\n    except IndexError:\n        if default_region is None:\n            raise UnknownRegionError(\n                \"No default region found and no region determinable from key id: {}\".format(key_id)\n            )\n        region_name = default_region\n    return region_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_config(self):\n        self._user_agent_adding_config = botocore.config.Config(user_agent_extra=USER_AGENT_SUFFIX)\n\n        if self.config.region_names:\n            self.add_regional_clients_from_list(self.config.region_names)\n            self.default_region = self.config.region_names[0]\n        else:\n            self.default_region = self.config.botocore_session.get_config_variable(\"region\")\n            if self.default_region is not None:\n                self.add_regional_client(self.default_region)\n\n        if self.config.key_ids:\n            self.add_master_keys_from_list(self.config.key_ids)", "response": "Traverses the config and adds master keys and regional clients as needed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _wrap_client(self, region_name, method, *args, **kwargs):\n        try:\n            return method(*args, **kwargs)\n        except botocore.exceptions.BotoCoreError:\n            self._regional_clients.pop(region_name)\n            _LOGGER.error(\n                'Removing regional client \"%s\" from cache due to BotoCoreError on %s call', region_name, method.__name__\n            )\n            raise", "response": "Wrap a client method to a KMS client and remove any exceptions raised by it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps all methods on a client with a functools. partial to wrap all methods on a client with the self. _wrap_client method", "response": "def _register_client(self, client, region_name):\n        \"\"\"Uses functools.partial to wrap all methods on a client with the self._wrap_client method\n\n        :param botocore.client.BaseClient client: the client to proxy\n        :param str region_name: AWS Region ID (ex: us-east-1)\n        \"\"\"\n        for item in client.meta.method_to_api_mapping:\n            method = getattr(client, item)\n            wrapped_method = functools.partial(self._wrap_client, region_name, method)\n            setattr(client, item, wrapped_method)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a regional client for the specified region if it does not already exist.", "response": "def add_regional_client(self, region_name):\n        \"\"\"Adds a regional client for the specified region if it does not already exist.\n\n        :param str region_name: AWS Region ID (ex: us-east-1)\n        \"\"\"\n        if region_name not in self._regional_clients:\n            session = boto3.session.Session(region_name=region_name, botocore_session=self.config.botocore_session)\n            client = session.client(\"kms\", config=self._user_agent_adding_config)\n            self._register_client(client, region_name)\n            self._regional_clients[region_name] = client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Boto3 KMS client for the appropriate region.", "response": "def _client(self, key_id):\n        \"\"\"Returns a Boto3 KMS client for the appropriate region.\n\n        :param str key_id: KMS CMK ID\n        \"\"\"\n        region_name = _region_from_key_id(key_id, self.default_region)\n        self.add_regional_client(region_name)\n        return self._regional_clients[region_name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a KMSMasterKey based on the specified key_id.", "response": "def _new_master_key(self, key_id):\n        \"\"\"Returns a KMSMasterKey for the specified key_id.\n\n        :param bytes key_id: KMS CMK ID\n        :returns: KMS Master Key based on key_id\n        :rtype: aws_encryption_sdk.key_providers.kms.KMSMasterKey\n        :raises InvalidKeyIdError: if key_id is not a valid KMS CMK ID to which this key provider has access\n        \"\"\"\n        _key_id = to_str(key_id)  # KMS client requires str, not bytes\n        return KMSMasterKey(config=KMSMasterKeyConfig(key_id=key_id, client=self._client(_key_id)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _generate_data_key(self, algorithm, encryption_context=None):\n        kms_params = {\"KeyId\": self._key_id, \"NumberOfBytes\": algorithm.kdf_input_len}\n        if encryption_context is not None:\n            kms_params[\"EncryptionContext\"] = encryption_context\n        if self.config.grant_tokens:\n            kms_params[\"GrantTokens\"] = self.config.grant_tokens\n        # Catch any boto3 errors and normalize to expected EncryptKeyError\n        try:\n            response = self.config.client.generate_data_key(**kms_params)\n            plaintext = response[\"Plaintext\"]\n            ciphertext = response[\"CiphertextBlob\"]\n            key_id = response[\"KeyId\"]\n        except (ClientError, KeyError):\n            error_message = \"Master Key {key_id} unable to generate data key\".format(key_id=self._key_id)\n            _LOGGER.exception(error_message)\n            raise GenerateKeyError(error_message)\n        return DataKey(\n            key_provider=MasterKeyInfo(provider_id=self.provider_id, key_info=key_id),\n            data_key=plaintext,\n            encrypted_data_key=ciphertext,\n        )", "response": "Generates a data key and returns plaintext and ciphertext of key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _encrypt_data_key(self, data_key, algorithm, encryption_context=None):\n        kms_params = {\"KeyId\": self._key_id, \"Plaintext\": data_key.data_key}\n        if encryption_context:\n            kms_params[\"EncryptionContext\"] = encryption_context\n        if self.config.grant_tokens:\n            kms_params[\"GrantTokens\"] = self.config.grant_tokens\n        # Catch any boto3 errors and normalize to expected EncryptKeyError\n        try:\n            response = self.config.client.encrypt(**kms_params)\n            ciphertext = response[\"CiphertextBlob\"]\n            key_id = response[\"KeyId\"]\n        except (ClientError, KeyError):\n            error_message = \"Master Key {key_id} unable to encrypt data key\".format(key_id=self._key_id)\n            _LOGGER.exception(error_message)\n            raise EncryptKeyError(error_message)\n        return EncryptedDataKey(\n            key_provider=MasterKeyInfo(provider_id=self.provider_id, key_info=key_id), encrypted_data_key=ciphertext\n        )", "response": "Encrypts a data key and returns the ciphertext."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_encrypted_data_key(encrypted_data_key):\n    encrypted_data_key_format = (\n        \">\"  # big endian\n        \"H\"  # key provider ID length\n        \"{provider_id_len}s\"  # key provider ID\n        \"H\"  # key info length\n        \"{provider_info_len}s\"  # key info\n        \"H\"  # encrypted data key length\n        \"{enc_data_key_len}s\"  # encrypted data key\n    )\n    return struct.pack(\n        encrypted_data_key_format.format(\n            provider_id_len=len(encrypted_data_key.key_provider.provider_id),\n            provider_info_len=len(encrypted_data_key.key_provider.key_info),\n            enc_data_key_len=len(encrypted_data_key.encrypted_data_key),\n        ),\n        len(encrypted_data_key.key_provider.provider_id),\n        to_bytes(encrypted_data_key.key_provider.provider_id),\n        len(encrypted_data_key.key_provider.key_info),\n        to_bytes(encrypted_data_key.key_provider.key_info),\n        len(encrypted_data_key.encrypted_data_key),\n        encrypted_data_key.encrypted_data_key,\n    )", "response": "Serializes an encrypted data key into a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_header(header, signer=None):\n    ec_serialized = aws_encryption_sdk.internal.formatting.encryption_context.serialize_encryption_context(\n        header.encryption_context\n    )\n    header_start_format = (\n        \">\"  # big endian\n        \"B\"  # version\n        \"B\"  # type\n        \"H\"  # algorithm ID\n        \"16s\"  # message ID\n        \"H\"  # encryption context length\n        \"{}s\"  # serialized encryption context\n    ).format(len(ec_serialized))\n    header_bytes = bytearray()\n    header_bytes.extend(\n        struct.pack(\n            header_start_format,\n            header.version.value,\n            header.type.value,\n            header.algorithm.algorithm_id,\n            header.message_id,\n            len(ec_serialized),\n            ec_serialized,\n        )\n    )\n\n    serialized_data_keys = bytearray()\n    for data_key in header.encrypted_data_keys:\n        serialized_data_keys.extend(serialize_encrypted_data_key(data_key))\n\n    header_bytes.extend(struct.pack(\">H\", len(header.encrypted_data_keys)))\n    header_bytes.extend(serialized_data_keys)\n\n    header_close_format = (\n        \">\"  # big endian\n        \"B\"  # content type (no framing vs framing)\n        \"4x\"  # reserved (formerly content AAD length)\n        \"B\"  # nonce/IV length, this applies to all IVs in this message\n        \"I\"  # frame length\n    )\n    header_bytes.extend(\n        struct.pack(header_close_format, header.content_type.value, header.algorithm.iv_len, header.frame_length)\n    )\n    output = bytes(header_bytes)\n    if signer is not None:\n        signer.update(output)\n    return output", "response": "Serializes a message header object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize_header_auth(algorithm, header, data_encryption_key, signer=None):\n    header_auth = encrypt(\n        algorithm=algorithm,\n        key=data_encryption_key,\n        plaintext=b\"\",\n        associated_data=header,\n        iv=header_auth_iv(algorithm),\n    )\n    output = struct.pack(\n        \">{iv_len}s{tag_len}s\".format(iv_len=algorithm.iv_len, tag_len=algorithm.tag_len),\n        header_auth.iv,\n        header_auth.tag,\n    )\n    if signer is not None:\n        signer.update(output)\n    return output", "response": "Creates serialized header authentication data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_non_framed_open(algorithm, iv, plaintext_length, signer=None):\n    body_start_format = (\">\" \"{iv_length}s\" \"Q\").format(iv_length=algorithm.iv_len)  # nonce (IV)  # content length\n    body_start = struct.pack(body_start_format, iv, plaintext_length)\n    if signer:\n        signer.update(body_start)\n    return body_start", "response": "Serializes the opening block for a non - framed message body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_non_framed_close(tag, signer=None):\n    body_close = struct.pack(\"{auth_len}s\".format(auth_len=len(tag)), tag)\n    if signer:\n        signer.update(body_close)\n    return body_close", "response": "Serializes the closing block for a non - framed message body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_frame(\n    algorithm, plaintext, message_id, data_encryption_key, frame_length, sequence_number, is_final_frame, signer=None\n):\n    \"\"\"Receives a message plaintext, breaks off a frame, encrypts and serializes\n    the frame, and returns the encrypted frame and the remaining plaintext.\n\n    :param algorithm: Algorithm to use for encryption\n    :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n    :param bytes plaintext: Source plaintext to encrypt and serialize\n    :param bytes message_id: Message ID\n    :param bytes data_encryption_key: Data key with which to encrypt message\n    :param int frame_length: Length of the framed data\n    :param int sequence_number: Sequence number for frame to be generated\n    :param bool is_final_frame: Boolean stating whether or not this frame is a final frame\n    :param signer: Cryptographic signer object (optional)\n    :type signer: aws_encryption_sdk.Signer\n    :returns: Serialized frame and remaining plaintext\n    :rtype: tuple of bytes\n    :raises SerializationError: if number of frames is too large\n    \"\"\"\n    if sequence_number < 1:\n        raise SerializationError(\"Frame sequence number must be greater than 0\")\n    if sequence_number > aws_encryption_sdk.internal.defaults.MAX_FRAME_COUNT:\n        raise SerializationError(\"Max frame count exceeded\")\n    if is_final_frame:\n        content_string = ContentAADString.FINAL_FRAME_STRING_ID\n    else:\n        content_string = ContentAADString.FRAME_STRING_ID\n    frame_plaintext = plaintext[:frame_length]\n    frame_ciphertext = encrypt(\n        algorithm=algorithm,\n        key=data_encryption_key,\n        plaintext=frame_plaintext,\n        associated_data=aws_encryption_sdk.internal.formatting.encryption_context.assemble_content_aad(\n            message_id=message_id,\n            aad_content_string=content_string,\n            seq_num=sequence_number,\n            length=len(frame_plaintext),\n        ),\n        iv=frame_iv(algorithm, sequence_number),\n    )\n    plaintext = plaintext[frame_length:]\n    if is_final_frame:\n        _LOGGER.debug(\"Serializing final frame\")\n        packed_frame = struct.pack(\n            \">II{iv_len}sI{content_len}s{auth_len}s\".format(\n                iv_len=algorithm.iv_len, content_len=len(frame_ciphertext.ciphertext), auth_len=algorithm.auth_len\n            ),\n            SequenceIdentifier.SEQUENCE_NUMBER_END.value,\n            sequence_number,\n            frame_ciphertext.iv,\n            len(frame_ciphertext.ciphertext),\n            frame_ciphertext.ciphertext,\n            frame_ciphertext.tag,\n        )\n    else:\n        _LOGGER.debug(\"Serializing frame\")\n        packed_frame = struct.pack(\n            \">I{iv_len}s{content_len}s{auth_len}s\".format(\n                iv_len=algorithm.iv_len, content_len=frame_length, auth_len=algorithm.auth_len\n            ),\n            sequence_number,\n            frame_ciphertext.iv,\n            frame_ciphertext.ciphertext,\n            frame_ciphertext.tag,\n        )\n    if signer is not None:\n        signer.update(packed_frame)\n    return packed_frame, plaintext", "response": "Takes a message plaintext and encrypts and serializes the frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes the footer of a .", "response": "def serialize_footer(signer):\n    \"\"\"Uses the signer object which has been used to sign the message to generate\n    the signature, then serializes that signature.\n\n    :param signer: Cryptographic signer object\n    :type signer: aws_encryption_sdk.internal.crypto.Signer\n    :returns: Serialized footer\n    :rtype: bytes\n    \"\"\"\n    footer = b\"\"\n    if signer is not None:\n        signature = signer.finalize()\n        footer = struct.pack(\">H{sig_len}s\".format(sig_len=len(signature)), len(signature), signature)\n    return footer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_raw_master_key_prefix(raw_master_key):\n    if raw_master_key.config.wrapping_key.wrapping_algorithm.encryption_type is EncryptionType.ASYMMETRIC:\n        return to_bytes(raw_master_key.key_id)\n    return struct.pack(\n        \">{}sII\".format(len(raw_master_key.key_id)),\n        to_bytes(raw_master_key.key_id),\n        # Tag Length is stored in bits, not bytes\n        raw_master_key.config.wrapping_key.wrapping_algorithm.algorithm.tag_len * 8,\n        raw_master_key.config.wrapping_key.wrapping_algorithm.algorithm.iv_len,\n    )", "response": "Serializes a RawMasterKey into a prefix that a RawMasterKey will always use for the the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes EncryptedData into a Wrapped EncryptedDataKey.", "response": "def serialize_wrapped_key(key_provider, wrapping_algorithm, wrapping_key_id, encrypted_wrapped_key):\n    \"\"\"Serializes EncryptedData into a Wrapped EncryptedDataKey.\n\n    :param key_provider: Info for Wrapping MasterKey\n    :type key_provider: aws_encryption_sdk.structures.MasterKeyInfo\n    :param wrapping_algorithm: Wrapping Algorithm with which to wrap plaintext_data_key\n    :type wrapping_algorithm: aws_encryption_sdk.identifiers.WrappingAlgorithm\n    :param bytes wrapping_key_id: Key ID of wrapping MasterKey\n    :param encrypted_wrapped_key: Encrypted data key\n    :type encrypted_wrapped_key: aws_encryption_sdk.internal.structures.EncryptedData\n    :returns: Wrapped EncryptedDataKey\n    :rtype: aws_encryption_sdk.structures.EncryptedDataKey\n    \"\"\"\n    if encrypted_wrapped_key.iv is None:\n        key_info = wrapping_key_id\n        key_ciphertext = encrypted_wrapped_key.ciphertext\n    else:\n        key_info = struct.pack(\n            \">{key_id_len}sII{iv_len}s\".format(\n                key_id_len=len(wrapping_key_id), iv_len=wrapping_algorithm.algorithm.iv_len\n            ),\n            to_bytes(wrapping_key_id),\n            len(encrypted_wrapped_key.tag) * 8,  # Tag Length is stored in bits, not bytes\n            wrapping_algorithm.algorithm.iv_len,\n            encrypted_wrapped_key.iv,\n        )\n        key_ciphertext = encrypted_wrapped_key.ciphertext + encrypted_wrapped_key.tag\n    return EncryptedDataKey(\n        key_provider=MasterKeyInfo(provider_id=key_provider.provider_id, key_info=key_info),\n        encrypted_data_key=key_ciphertext,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assemble_content_aad(message_id, aad_content_string, seq_num, length):\n    if not isinstance(aad_content_string, aws_encryption_sdk.identifiers.ContentAADString):\n        raise SerializationError(\"Unknown aad_content_string\")\n    fmt = \">16s{}sIQ\".format(len(aad_content_string.value))\n    return struct.pack(fmt, message_id, aad_content_string.value, seq_num, length)", "response": "Assemble the Body AAD string for a message body structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize the contents of a dictionary into a byte string.", "response": "def serialize_encryption_context(encryption_context):\n    \"\"\"Serializes the contents of a dictionary into a byte string.\n\n    :param dict encryption_context: Dictionary of encrytion context keys/values.\n    :returns: Serialized encryption context\n    :rtype: bytes\n    \"\"\"\n    if not encryption_context:\n        return bytes()\n\n    serialized_context = bytearray()\n    dict_size = len(encryption_context)\n\n    if dict_size > aws_encryption_sdk.internal.defaults.MAX_BYTE_ARRAY_SIZE:\n        raise SerializationError(\"The encryption context contains too many elements.\")\n\n    serialized_context.extend(struct.pack(\">H\", dict_size))\n\n    # Encode strings first to catch bad values.\n    encryption_context_list = []\n    for key, value in encryption_context.items():\n        try:\n            if isinstance(key, bytes):\n                key = codecs.decode(key)\n            if isinstance(value, bytes):\n                value = codecs.decode(value)\n            encryption_context_list.append(\n                (aws_encryption_sdk.internal.str_ops.to_bytes(key), aws_encryption_sdk.internal.str_ops.to_bytes(value))\n            )\n        except Exception:\n            raise SerializationError(\n                \"Cannot encode dictionary key or value using {}.\".format(aws_encryption_sdk.internal.defaults.ENCODING)\n            )\n\n    for key, value in sorted(encryption_context_list, key=lambda x: x[0]):\n        serialized_context.extend(\n            struct.pack(\n                \">H{key_size}sH{value_size}s\".format(key_size=len(key), value_size=len(value)),\n                len(key),\n                key,\n                len(value),\n                value,\n            )\n        )\n        if len(serialized_context) > aws_encryption_sdk.internal.defaults.MAX_BYTE_ARRAY_SIZE:\n            raise SerializationError(\"The serialized context is too large.\")\n    return bytes(serialized_context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_short(source, offset):\n    try:\n        (short,) = struct.unpack_from(\">H\", source, offset)\n        return short, offset + struct.calcsize(\">H\")\n    except struct.error:\n        raise SerializationError(\"Bad format of serialized context.\")", "response": "Reads a number from a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a string from a byte string.", "response": "def read_string(source, offset, length):\n    \"\"\"Reads a string from a byte string.\n\n    :param bytes source: Source byte string\n    :param int offset: Point in byte string to start reading\n    :param int length: Length of string to read\n    :returns: Read string and offset at point after read data\n    :rtype: tuple of str and int\n    :raises SerializationError: if unable to unpack\n    \"\"\"\n    end = offset + length\n    try:\n        return (codecs.decode(source[offset:end], aws_encryption_sdk.internal.defaults.ENCODING), end)\n    except Exception:\n        raise SerializationError(\"Bad format of serialized context.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize_encryption_context(serialized_encryption_context):\n    if len(serialized_encryption_context) > aws_encryption_sdk.internal.defaults.MAX_BYTE_ARRAY_SIZE:\n        raise SerializationError(\"Serialized context is too long.\")\n\n    if serialized_encryption_context == b\"\":\n        _LOGGER.debug(\"No encryption context data found\")\n        return {}\n\n    deserialized_size = 0\n    encryption_context = {}\n\n    dict_size, deserialized_size = read_short(source=serialized_encryption_context, offset=deserialized_size)\n    _LOGGER.debug(\"Found %d keys\", dict_size)\n    for _ in range(dict_size):\n        key_size, deserialized_size = read_short(source=serialized_encryption_context, offset=deserialized_size)\n        key, deserialized_size = read_string(\n            source=serialized_encryption_context, offset=deserialized_size, length=key_size\n        )\n        value_size, deserialized_size = read_short(source=serialized_encryption_context, offset=deserialized_size)\n        value, deserialized_size = read_string(\n            source=serialized_encryption_context, offset=deserialized_size, length=value_size\n        )\n        if key in encryption_context:\n            raise SerializationError(\"Duplicate key in serialized context.\")\n        encryption_context[key] = value\n\n    if deserialized_size != len(serialized_encryption_context):\n        raise SerializationError(\"Formatting error: Extra data in serialized context.\")\n\n    return encryption_context", "response": "Deserializes the contents of a byte string into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines whether the data key is owned by a null or zero provider.", "response": "def owns_data_key(self, data_key: DataKey) -> bool:\n        \"\"\"Determine whether the data key is owned by a ``null`` or ``zero`` provider.\n\n        :param data_key: Data key to evaluate\n        :type data_key: :class:`aws_encryption_sdk.structures.DataKey`,\n            :class:`aws_encryption_sdk.structures.RawDataKey`,\n            or :class:`aws_encryption_sdk.structures.EncryptedDataKey`\n        :returns: Boolean statement of ownership\n        :rtype: bool\n        \"\"\"\n        return data_key.key_provider.provider_id in self._allowed_provider_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a null master key for the given algorithm.", "response": "def _generate_data_key(self, algorithm: AlgorithmSuite, encryption_context: Dict[Text, Text]) -> DataKey:\n        \"\"\":class:`NullMasterKey` does not support generate_data_key\n\n        :param algorithm: Algorithm on which to base data key\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param dict encryption_context: Encryption context to use in encryption\n        :raises NotImplementedError: when called\n        \"\"\"\n        return DataKey(\n            key_provider=self.key_provider, data_key=self._null_plaintext_data_key(algorithm), encrypted_data_key=b\"\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _decrypt_data_key(\n        self, encrypted_data_key: EncryptedDataKey, algorithm: AlgorithmSuite, encryption_context: Dict[Text, Text]\n    ) -> DataKey:\n        \"\"\"Decrypt an encrypted data key and return the plaintext.\n\n        :param data_key: Encrypted data key\n        :type data_key: aws_encryption_sdk.structures.EncryptedDataKey\n        :param algorithm: Algorithm object which directs how this Master Key will encrypt the data key\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param dict encryption_context: Encryption context to use in decryption\n        :returns: Data key containing decrypted data key\n        :rtype: aws_encryption_sdk.structures.DataKey\n        \"\"\"\n        return DataKey(\n            key_provider=self.key_provider,\n            data_key=self._null_plaintext_data_key(algorithm),\n            encrypted_data_key=encrypted_data_key.encrypted_data_key,\n        )", "response": "Decrypt an encrypted data key and return the plaintext."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the deterministic IV for a body frame.", "response": "def frame_iv(algorithm, sequence_number):\n    \"\"\"Builds the deterministic IV for a body frame.\n\n    :param algorithm: Algorithm for which to build IV\n    :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n    :param int sequence_number: Frame sequence number\n    :returns: Generated IV\n    :rtype: bytes\n    :raises ActionNotAllowedError: if sequence number of out bounds\n    \"\"\"\n    if sequence_number < 1 or sequence_number > MAX_FRAME_COUNT:\n        raise ActionNotAllowedError(\n            \"Invalid frame sequence number: {actual}\\nMust be between 1 and {max}\".format(\n                actual=sequence_number, max=MAX_FRAME_COUNT\n            )\n        )\n    prefix_len = algorithm.iv_len - 4\n    prefix = b\"\\x00\" * prefix_len\n    return prefix + struct.pack(\">I\", sequence_number)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef valid_kdf(self, kdf):\n        if kdf.input_length is None:\n            return True\n\n        if self.data_key_length > kdf.input_length(self):\n            raise InvalidAlgorithmError(\n                \"Invalid Algorithm definition: data_key_len must not be greater than kdf_input_len\"\n            )\n\n        return True", "response": "Determines whether a KDFSuite can be used with this EncryptionSuite."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the ciphertext message header length given a complete message header.", "response": "def header_length(header):\n    \"\"\"Calculates the ciphertext message header length, given a complete header.\n\n    :param header: Complete message header object\n    :type header: aws_encryption_sdk.structures.MessageHeader\n    :rtype: int\n    \"\"\"\n    # Because encrypted data key lengths may not be knowable until the ciphertext\n    #  is received from the providers, just serialize the header directly.\n    header_length = len(serialize_header(header))\n    header_length += header.algorithm.iv_len  # Header Authentication IV\n    header_length += header.algorithm.auth_len  # Header Authentication Tag\n    return header_length"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the length of a non - framed message body given a complete header.", "response": "def _non_framed_body_length(header, plaintext_length):\n    \"\"\"Calculates the length of a non-framed message body, given a complete header.\n\n    :param header: Complete message header object\n    :type header: aws_encryption_sdk.structures.MessageHeader\n    :param int plaintext_length: Length of plaintext in bytes\n    :rtype: int\n    \"\"\"\n    body_length = header.algorithm.iv_len  # IV\n    body_length += 8  # Encrypted Content Length\n    body_length += plaintext_length  # Encrypted Content\n    body_length += header.algorithm.auth_len  # Authentication Tag\n    return body_length"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the length of a standard ciphertext frame given a complete message header object.", "response": "def _standard_frame_length(header):\n    \"\"\"Calculates the length of a standard ciphertext frame, given a complete header.\n\n    :param header: Complete message header object\n    :type header: aws_encryption_sdk.structures.MessageHeader\n    :rtype: int\n    \"\"\"\n    frame_length = 4  # Sequence Number\n    frame_length += header.algorithm.iv_len  # IV\n    frame_length += header.frame_length  # Encrypted Content\n    frame_length += header.algorithm.auth_len  # Authentication Tag\n    return frame_length"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _final_frame_length(header, final_frame_bytes):\n    final_frame_length = 4  # Sequence Number End\n    final_frame_length += 4  # Sequence Number\n    final_frame_length += header.algorithm.iv_len  # IV\n    final_frame_length += 4  # Encrypted Content Length\n    final_frame_length += final_frame_bytes  # Encrypted Content\n    final_frame_length += header.algorithm.auth_len  # Authentication Tag\n    return final_frame_length", "response": "Calculates the length of a final ciphertext frame given a complete message header and the number of bytes of ciphertext in the final frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the ciphertext message body length given a complete message header object.", "response": "def body_length(header, plaintext_length):\n    \"\"\"Calculates the ciphertext message body length, given a complete header.\n\n    :param header: Complete message header object\n    :type header: aws_encryption_sdk.structures.MessageHeader\n    :param int plaintext_length: Length of plaintext in bytes\n    :rtype: int\n    \"\"\"\n    body_length = 0\n    if header.frame_length == 0:  # Non-framed\n        body_length += _non_framed_body_length(header, plaintext_length)\n    else:  # Framed\n        frames, final_frame_bytes = divmod(plaintext_length, header.frame_length)\n        body_length += frames * _standard_frame_length(header)\n        body_length += _final_frame_length(header, final_frame_bytes)  # Final frame is always written\n    return body_length"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef footer_length(header):\n    footer_length = 0\n    if header.algorithm.signing_algorithm_info is not None:\n        footer_length += 2  # Signature Length\n        footer_length += header.algorithm.signature_len  # Signature\n    return footer_length", "response": "Calculates the ciphertext message footer length given a complete header."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ciphertext_length(header, plaintext_length):\n    ciphertext_length = header_length(header)\n    ciphertext_length += body_length(header, plaintext_length)\n    ciphertext_length += footer_length(header)\n    return ciphertext_length", "response": "Calculates the complete ciphertext message length given a complete message header and plaintext length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef owns_data_key(self, data_key):\n        expected_key_info_len = -1\n        if (\n            self.config.wrapping_key.wrapping_algorithm.encryption_type is EncryptionType.ASYMMETRIC\n            and data_key.key_provider == self.key_provider\n        ):\n            return True\n        elif self.config.wrapping_key.wrapping_algorithm.encryption_type is EncryptionType.SYMMETRIC:\n            expected_key_info_len = (\n                len(self._key_info_prefix) + self.config.wrapping_key.wrapping_algorithm.algorithm.iv_len\n            )\n            if (\n                data_key.key_provider.provider_id == self.provider_id\n                and len(data_key.key_provider.key_info) == expected_key_info_len\n                and data_key.key_provider.key_info.startswith(self._key_info_prefix)\n            ):\n                return True\n        _LOGGER.debug(\n            (\n                \"RawMasterKey does not own data_key: %s\\n\"\n                \"Expected provider_id: %s\\n\"\n                \"Expected key_info len: %s\\n\"\n                \"Expected key_info prefix: %s\"\n            ),\n            data_key,\n            self.provider_id,\n            expected_key_info_len,\n            self._key_info_prefix,\n        )\n        return False", "response": "Determines if the given data key object is owned by this RawMasterKey."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_data_key(self, algorithm, encryption_context):\n        plaintext_data_key = os.urandom(algorithm.kdf_input_len)\n        encrypted_data_key = self._encrypt_data_key(\n            data_key=RawDataKey(key_provider=self.key_provider, data_key=plaintext_data_key),\n            algorithm=algorithm,\n            encryption_context=encryption_context,\n        )\n        return DataKey(\n            key_provider=encrypted_data_key.key_provider,\n            data_key=plaintext_data_key,\n            encrypted_data_key=encrypted_data_key.encrypted_data_key,\n        )", "response": "Generates a data key and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform the provider - specific key encryption actions.", "response": "def _encrypt_data_key(self, data_key, algorithm, encryption_context):\n        \"\"\"Performs the provider-specific key encryption actions.\n\n        :param data_key: Unencrypted data key\n        :type data_key: :class:`aws_encryption_sdk.structures.RawDataKey`\n            or :class:`aws_encryption_sdk.structures.DataKey`\n        :param algorithm: Algorithm object which directs how this Master Key will encrypt the data key\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param dict encryption_context: Encryption context to use in encryption\n        :returns: Decrypted data key\n        :rtype: aws_encryption_sdk.structures.EncryptedDataKey\n        :raises EncryptKeyError: if Master Key is unable to encrypt data key\n        \"\"\"\n        # Raw key string to EncryptedData\n        encrypted_wrapped_key = self.config.wrapping_key.encrypt(\n            plaintext_data_key=data_key.data_key, encryption_context=encryption_context\n        )\n        # EncryptedData to EncryptedDataKey\n        return aws_encryption_sdk.internal.formatting.serialize.serialize_wrapped_key(\n            key_provider=self.key_provider,\n            wrapping_algorithm=self.config.wrapping_key.wrapping_algorithm,\n            wrapping_key_id=self.key_id,\n            encrypted_wrapped_key=encrypted_wrapped_key,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _decrypt_data_key(self, encrypted_data_key, algorithm, encryption_context):\n        # Wrapped EncryptedDataKey to deserialized EncryptedData\n        encrypted_wrapped_key = aws_encryption_sdk.internal.formatting.deserialize.deserialize_wrapped_key(\n            wrapping_algorithm=self.config.wrapping_key.wrapping_algorithm,\n            wrapping_key_id=self.key_id,\n            wrapped_encrypted_key=encrypted_data_key,\n        )\n        # EncryptedData to raw key string\n        plaintext_data_key = self.config.wrapping_key.decrypt(\n            encrypted_wrapped_data_key=encrypted_wrapped_key, encryption_context=encryption_context\n        )\n        # Raw key string to DataKey\n        return DataKey(\n            key_provider=encrypted_data_key.key_provider,\n            data_key=plaintext_data_key,\n            encrypted_data_key=encrypted_data_key.encrypted_data_key,\n        )", "response": "Decrypts an encrypted data key and returns the plaintext."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts a string using an AWS KMS customer master key and data key caching.", "response": "def encrypt_with_caching(kms_cmk_arn, max_age_in_cache, cache_capacity):\n    \"\"\"Encrypts a string using an AWS KMS customer master key (CMK) and data key caching.\n\n    :param str kms_cmk_arn: Amazon Resource Name (ARN) of the KMS customer master key\n    :param float max_age_in_cache: Maximum time in seconds that a cached entry can be used\n    :param int cache_capacity: Maximum number of entries to retain in cache at once\n    \"\"\"\n    # Data to be encrypted\n    my_data = \"My plaintext data\"\n\n    # Security thresholds\n    #   Max messages (or max bytes per) data key are optional\n    MAX_ENTRY_MESSAGES = 100\n\n    # Create an encryption context\n    encryption_context = {\"purpose\": \"test\"}\n\n    # Create a master key provider for the KMS customer master key (CMK)\n    key_provider = aws_encryption_sdk.KMSMasterKeyProvider(key_ids=[kms_cmk_arn])\n\n    # Create a local cache\n    cache = aws_encryption_sdk.LocalCryptoMaterialsCache(cache_capacity)\n\n    # Create a caching CMM\n    caching_cmm = aws_encryption_sdk.CachingCryptoMaterialsManager(\n        master_key_provider=key_provider,\n        cache=cache,\n        max_age=max_age_in_cache,\n        max_messages_encrypted=MAX_ENTRY_MESSAGES,\n    )\n\n    # When the call to encrypt data specifies a caching CMM,\n    # the encryption operation uses the data key cache specified\n    # in the caching CMM\n    encrypted_message, _header = aws_encryption_sdk.encrypt(\n        source=my_data, materials_manager=caching_cmm, encryption_context=encryption_context\n    )\n\n    return encrypted_message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put_encryption_materials(self, cache_key, encryption_materials, plaintext_length, entry_hints=None):\n        return CryptoMaterialsCacheEntry(cache_key=cache_key, value=encryption_materials)", "response": "Adds the given encryption materials to the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the version from this module.", "response": "def get_version():\n    \"\"\"Reads the version (MAJOR.MINOR) from this module.\"\"\"\n    release = get_release()\n    split_version = release.split(\".\")\n    if len(split_version) == 3:\n        return \".\".join(split_version[:2])\n    return release"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_signature_type(self):\n        try:\n            verify_interface(ec.EllipticCurve, self.algorithm.signing_algorithm_info)\n            return ec.EllipticCurve\n        except InterfaceNotImplemented:\n            raise NotSupportedError(\"Unsupported signing algorithm info\")", "response": "Ensures that the algorithm signature type is a known type and sets a reference value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_key_bytes(cls, algorithm, key_bytes):\n        key = serialization.load_der_private_key(data=key_bytes, password=None, backend=default_backend())\n        return cls(algorithm, key)", "response": "Builds a Signer from an algorithm suite and a raw signing key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_bytes(self):\n        return self.key.private_bytes(\n            encoding=serialization.Encoding.DER,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption(),\n        )", "response": "Returns the raw signing key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef finalize(self):\n        prehashed_digest = self._hasher.finalize()\n        return _ecc_static_length_signature(key=self.key, algorithm=self.algorithm, digest=prehashed_digest)", "response": "Finalizes the signer and returns the signature."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Verifier object based on the supplied algorithm and encoded compressed ECC curve point.", "response": "def from_encoded_point(cls, algorithm, encoded_point):\n        \"\"\"Creates a Verifier object based on the supplied algorithm and encoded compressed ECC curve point.\n\n        :param algorithm: Algorithm on which to base verifier\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param bytes encoded_point: ECC public point compressed and encoded with _ecc_encode_compressed_point\n        :returns: Instance of Verifier generated from encoded point\n        :rtype: aws_encryption_sdk.internal.crypto.Verifier\n        \"\"\"\n        return cls(\n            algorithm=algorithm,\n            key=_ecc_public_numbers_from_compressed_point(\n                curve=algorithm.signing_algorithm_info(), compressed_point=base64.b64decode(encoded_point)\n            ).public_key(default_backend()),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Verifier object based on the supplied algorithm and raw verification key.", "response": "def from_key_bytes(cls, algorithm, key_bytes):\n        \"\"\"Creates a `Verifier` object based on the supplied algorithm and raw verification key.\n\n        :param algorithm: Algorithm on which to base verifier\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param bytes encoded_point: Raw verification key\n        :returns: Instance of Verifier generated from encoded point\n        :rtype: aws_encryption_sdk.internal.crypto.Verifier\n        \"\"\"\n        return cls(\n            algorithm=algorithm, key=serialization.load_der_public_key(data=key_bytes, backend=default_backend())\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef key_bytes(self):\n        return self.key.public_bytes(\n            encoding=serialization.Encoding.DER, format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )", "response": "Returns the raw verification key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying the signature against the current cryptographic verifier state.", "response": "def verify(self, signature):\n        \"\"\"Verifies the signature against the current cryptographic verifier state.\n\n        :param bytes signature: The signature to verify\n        \"\"\"\n        prehashed_digest = self._hasher.finalize()\n        self.key.verify(\n            signature=signature,\n            data=prehashed_digest,\n            signature_algorithm=ec.ECDSA(Prehashed(self.algorithm.signing_hash_type())),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encrypt(self, plaintext_data_key, encryption_context):\n        if self.wrapping_algorithm.encryption_type is EncryptionType.ASYMMETRIC:\n            if self.wrapping_key_type is EncryptionKeyType.PRIVATE:\n                encrypted_key = self._wrapping_key.public_key().encrypt(\n                    plaintext=plaintext_data_key, padding=self.wrapping_algorithm.padding\n                )\n            else:\n                encrypted_key = self._wrapping_key.encrypt(\n                    plaintext=plaintext_data_key, padding=self.wrapping_algorithm.padding\n                )\n            return EncryptedData(iv=None, ciphertext=encrypted_key, tag=None)\n        serialized_encryption_context = serialize_encryption_context(encryption_context=encryption_context)\n        iv = os.urandom(self.wrapping_algorithm.algorithm.iv_len)\n        return encrypt(\n            algorithm=self.wrapping_algorithm.algorithm,\n            key=self._derived_wrapping_key,\n            plaintext=plaintext_data_key,\n            associated_data=serialized_encryption_context,\n            iv=iv,\n        )", "response": "Encrypts a data key using a direct wrapping key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the provider - specific data key generation task.", "response": "def _generate_data_key(self, algorithm: AlgorithmSuite, encryption_context: Dict[Text, Text]) -> DataKey:\n        \"\"\"Perform the provider-specific data key generation task.\n\n        :param algorithm: Algorithm on which to base data key\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param dict encryption_context: Encryption context to use in encryption\n        :returns: Generated data key\n        :rtype: aws_encryption_sdk.structures.DataKey\n        \"\"\"\n        data_key = b\"\".join([chr(i).encode(\"utf-8\") for i in range(1, algorithm.data_key_len + 1)])\n        return DataKey(key_provider=self.key_provider, data_key=data_key, encrypted_data_key=self._encrypted_data_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencrypt a data key and return the ciphertext.", "response": "def _encrypt_data_key(\n        self, data_key: DataKey, algorithm: AlgorithmSuite, encryption_context: Dict[Text, Text]\n    ) -> NoReturn:\n        \"\"\"Encrypt a data key and return the ciphertext.\n\n        :param data_key: Unencrypted data key\n        :type data_key: :class:`aws_encryption_sdk.structures.RawDataKey`\n            or :class:`aws_encryption_sdk.structures.DataKey`\n        :param algorithm: Algorithm object which directs how this Master Key will encrypt the data key\n        :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n        :param dict encryption_context: Encryption context to use in encryption\n        :raises NotImplementedError: when called\n        \"\"\"\n        raise NotImplementedError(\"CountingMasterKey does not support encrypt_data_key\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the header using the header authentication data.", "response": "def validate_header(header, header_auth, raw_header, data_key):\n    \"\"\"Validates the header using the header authentication data.\n\n    :param header: Deserialized header\n    :type header: aws_encryption_sdk.structures.MessageHeader\n    :param header_auth: Deserialized header auth\n    :type header_auth: aws_encryption_sdk.internal.structures.MessageHeaderAuthentication\n    :type stream: io.BytesIO\n    :param bytes raw_header: Raw header bytes\n    :param bytes data_key: Data key with which to perform validation\n    :raises SerializationError: if header authorization fails\n    \"\"\"\n    _LOGGER.debug(\"Starting header validation\")\n    try:\n        decrypt(\n            algorithm=header.algorithm,\n            key=data_key,\n            encrypted_data=EncryptedData(header_auth.iv, b\"\", header_auth.tag),\n            associated_data=raw_header,\n        )\n    except InvalidTag:\n        raise SerializationError(\"Header authorization failed\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a message object from the specified version ID.", "response": "def _verified_version_from_id(version_id):\n    # type: (int) -> SerializationVersion\n    \"\"\"Load a message :class:`SerializationVersion` for the specified version ID.\n\n    :param int version_id: Message format version ID\n    :return: Message format version\n    :rtype: SerializationVersion\n    :raises NotSupportedError: if unsupported version ID is received\n    \"\"\"\n    try:\n        return SerializationVersion(version_id)\n    except ValueError as error:\n        raise NotSupportedError(\"Unsupported version {}\".format(version_id), error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _verified_message_type_from_id(message_type_id):\n    # type: (int) -> ObjectType\n    \"\"\"Load a message :class:`ObjectType` for the specified message type ID.\n\n    :param int message_type_id: Message type ID\n    :return: Message type\n    :rtype: ObjectType\n    :raises NotSupportedError: if unsupported message type ID is received\n    \"\"\"\n    try:\n        return ObjectType(message_type_id)\n    except ValueError as error:\n        raise NotSupportedError(\"Unsupported type {} discovered in data stream\".format(message_type_id), error)", "response": "Load a message object type from the specified message type ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a message : class : AlgorithmSuite object for the specified algorithm ID.", "response": "def _verified_algorithm_from_id(algorithm_id):\n    # type: (int) -> AlgorithmSuite\n    \"\"\"Load a message :class:`AlgorithmSuite` for the specified algorithm suite ID.\n\n    :param int algorithm_id: Algorithm suite ID\n    :return: Algorithm suite\n    :rtype: AlgorithmSuite\n    :raises UnknownIdentityError: if unknown algorithm ID is received\n    :raises NotSupportedError: if unsupported algorithm ID is received\n    \"\"\"\n    try:\n        algorithm_suite = AlgorithmSuite.get_by_id(algorithm_id)\n    except KeyError as error:\n        raise UnknownIdentityError(\"Unknown algorithm {}\".format(algorithm_id), error)\n\n    if not algorithm_suite.allowed:\n        raise NotSupportedError(\"Unsupported algorithm: {}\".format(algorithm_suite))\n\n    return algorithm_suite"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verified_content_type_from_id(content_type_id):\n    # type: (int) -> ContentType\n    \"\"\"Load a message :class:`ContentType` for the specified content type ID.\n\n    :param int content_type_id: Content type ID\n    :return: Message content type\n    :rtype: ContentType\n    :raises UnknownIdentityError: if unknown content type ID is received\n    \"\"\"\n    try:\n        return ContentType(content_type_id)\n    except ValueError as error:\n        raise UnknownIdentityError(\"Unknown content type {}\".format(content_type_id), error)", "response": "Load a message content type from the specified content type ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies an IV length for an algorithm suite.", "response": "def _verified_iv_length(iv_length, algorithm_suite):\n    # type: (int, AlgorithmSuite) -> int\n    \"\"\"Verify an IV length for an algorithm suite.\n\n    :param int iv_length: IV length to verify\n    :param AlgorithmSuite algorithm_suite: Algorithm suite to verify against\n    :return: IV length\n    :rtype: int\n    :raises SerializationError: if IV length does not match algorithm suite\n    \"\"\"\n    if iv_length != algorithm_suite.iv_len:\n        raise SerializationError(\n            \"Specified IV length ({length}) does not match algorithm IV length ({algorithm})\".format(\n                length=iv_length, algorithm=algorithm_suite\n            )\n        )\n\n    return iv_length"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify a frame length value for a message content type.", "response": "def _verified_frame_length(frame_length, content_type):\n    # type: (int, ContentType) -> int\n    \"\"\"Verify a frame length value for a message content type.\n\n    :param int frame_length: Frame length to verify\n    :param ContentType content_type: Message content type to verify against\n    :return: frame length\n    :rtype: int\n    :raises SerializationError: if frame length is too large\n    :raises SerializationError: if frame length is not zero for unframed content type\n    \"\"\"\n    if content_type == ContentType.FRAMED_DATA and frame_length > MAX_FRAME_SIZE:\n        raise SerializationError(\n            \"Specified frame length larger than allowed maximum: {found} > {max}\".format(\n                found=frame_length, max=MAX_FRAME_SIZE\n            )\n        )\n\n    if content_type == ContentType.NO_FRAMING and frame_length != 0:\n        raise SerializationError(\"Non-zero frame length found for non-framed message\")\n\n    return frame_length"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize_header(stream):\n    # type: (IO) -> MessageHeader\n    \"\"\"Deserializes the header from a source stream\n\n    :param stream: Source data stream\n    :type stream: io.BytesIO\n    :returns: Deserialized MessageHeader object\n    :rtype: :class:`aws_encryption_sdk.structures.MessageHeader` and bytes\n    :raises NotSupportedError: if unsupported data types are found\n    :raises UnknownIdentityError: if unknown data types are found\n    :raises SerializationError: if IV length does not match algorithm\n    \"\"\"\n    _LOGGER.debug(\"Starting header deserialization\")\n    tee = io.BytesIO()\n    tee_stream = TeeStream(stream, tee)\n    version_id, message_type_id = unpack_values(\">BB\", tee_stream)\n    header = dict()\n    header[\"version\"] = _verified_version_from_id(version_id)\n    header[\"type\"] = _verified_message_type_from_id(message_type_id)\n\n    algorithm_id, message_id, ser_encryption_context_length = unpack_values(\">H16sH\", tee_stream)\n\n    header[\"algorithm\"] = _verified_algorithm_from_id(algorithm_id)\n    header[\"message_id\"] = message_id\n\n    header[\"encryption_context\"] = deserialize_encryption_context(tee_stream.read(ser_encryption_context_length))\n\n    header[\"encrypted_data_keys\"] = _deserialize_encrypted_data_keys(tee_stream)\n\n    (content_type_id,) = unpack_values(\">B\", tee_stream)\n    header[\"content_type\"] = _verified_content_type_from_id(content_type_id)\n\n    (content_aad_length,) = unpack_values(\">I\", tee_stream)\n    header[\"content_aad_length\"] = _verified_content_aad_length(content_aad_length)\n\n    (iv_length,) = unpack_values(\">B\", tee_stream)\n    header[\"header_iv_length\"] = _verified_iv_length(iv_length, header[\"algorithm\"])\n\n    (frame_length,) = unpack_values(\">I\", tee_stream)\n    header[\"frame_length\"] = _verified_frame_length(frame_length, header[\"content_type\"])\n\n    return MessageHeader(**header), tee.getvalue()", "response": "Deserializes the header from a source stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize_frame(stream, header, verifier=None):\n    _LOGGER.debug(\"Starting frame deserialization\")\n    frame_data = {}\n    final_frame = False\n    (sequence_number,) = unpack_values(\">I\", stream, verifier)\n    if sequence_number == SequenceIdentifier.SEQUENCE_NUMBER_END.value:\n        _LOGGER.debug(\"Deserializing final frame\")\n        (sequence_number,) = unpack_values(\">I\", stream, verifier)\n        final_frame = True\n    else:\n        _LOGGER.debug(\"Deserializing frame sequence number %d\", int(sequence_number))\n    frame_data[\"final_frame\"] = final_frame\n    frame_data[\"sequence_number\"] = sequence_number\n    (frame_iv,) = unpack_values(\">{iv_len}s\".format(iv_len=header.algorithm.iv_len), stream, verifier)\n    frame_data[\"iv\"] = frame_iv\n    if final_frame is True:\n        (content_length,) = unpack_values(\">I\", stream, verifier)\n        if content_length >= header.frame_length:\n            raise SerializationError(\n                \"Invalid final frame length: {final} >= {normal}\".format(\n                    final=content_length, normal=header.frame_length\n                )\n            )\n    else:\n        content_length = header.frame_length\n    (frame_content, frame_tag) = unpack_values(\n        \">{content_len}s{auth_len}s\".format(content_len=content_length, auth_len=header.algorithm.auth_len),\n        stream,\n        verifier,\n    )\n    frame_data[\"ciphertext\"] = frame_content\n    frame_data[\"tag\"] = frame_tag\n    return MessageFrameBody(**frame_data), final_frame", "response": "Deserializes a message frame from a stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_values(format_string, stream, verifier=None):\n    try:\n        message_bytes = stream.read(struct.calcsize(format_string))\n        if verifier:\n            verifier.update(message_bytes)\n        values = struct.unpack(format_string, message_bytes)\n    except struct.error as error:\n        raise SerializationError(\"Unexpected deserialization error\", type(error), error.args)\n    return values", "response": "Helper function to unpack the values from a stream and update the signature verifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserialize_wrapped_key(wrapping_algorithm, wrapping_key_id, wrapped_encrypted_key):\n    if wrapping_key_id == wrapped_encrypted_key.key_provider.key_info:\n        encrypted_wrapped_key = EncryptedData(iv=None, ciphertext=wrapped_encrypted_key.encrypted_data_key, tag=None)\n    else:\n        if not wrapped_encrypted_key.key_provider.key_info.startswith(wrapping_key_id):\n            raise SerializationError(\"Master Key mismatch for wrapped data key\")\n        _key_info = wrapped_encrypted_key.key_provider.key_info[len(wrapping_key_id) :]\n        try:\n            tag_len, iv_len = struct.unpack(\">II\", _key_info[:8])\n        except struct.error:\n            raise SerializationError(\"Malformed key info: key info missing data\")\n        tag_len //= 8  # Tag Length is stored in bits, not bytes\n        if iv_len != wrapping_algorithm.algorithm.iv_len:\n            raise SerializationError(\"Wrapping AlgorithmSuite mismatch for wrapped data key\")\n        iv = _key_info[8:]\n        if len(iv) != iv_len:\n            raise SerializationError(\"Malformed key info: incomplete iv\")\n        ciphertext = wrapped_encrypted_key.encrypted_data_key[: -1 * tag_len]\n        tag = wrapped_encrypted_key.encrypted_data_key[-1 * tag_len :]\n        if not ciphertext or len(tag) != tag_len:\n            raise SerializationError(\"Malformed key info: incomplete ciphertext or tag\")\n        encrypted_wrapped_key = EncryptedData(iv=iv, ciphertext=ciphertext, tag=tag)\n    return encrypted_wrapped_key", "response": "Extracts and deserializes EncryptedData from a Wrapped EncryptedDataKey."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_frame_length(frame_length, algorithm):\n    if frame_length < 0 or frame_length % algorithm.encryption_algorithm.block_size != 0:\n        raise SerializationError(\n            \"Frame size must be a non-negative multiple of the block size of the crypto algorithm: {block_size}\".format(\n                block_size=algorithm.encryption_algorithm.block_size\n            )\n        )\n    if frame_length > aws_encryption_sdk.internal.defaults.MAX_FRAME_SIZE:\n        raise SerializationError(\n            \"Frame size too large: {frame} > {max}\".format(\n                frame=frame_length, max=aws_encryption_sdk.internal.defaults.MAX_FRAME_SIZE\n            )\n        )", "response": "Validates that the frame length is within the defined limits and is compatible with the selected algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_aad_content_string(content_type, is_final_frame):\n    if content_type == ContentType.NO_FRAMING:\n        aad_content_string = ContentAADString.NON_FRAMED_STRING_ID\n    elif content_type == ContentType.FRAMED_DATA:\n        if is_final_frame:\n            aad_content_string = ContentAADString.FINAL_FRAME_STRING_ID\n        else:\n            aad_content_string = ContentAADString.FRAME_STRING_ID\n    else:\n        raise UnknownIdentityError(\"Unhandled content type\")\n    return aad_content_string", "response": "Prepares the appropriate Body AAD Value for a message body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_data_keys(primary_master_key, master_keys, algorithm, encryption_context):\n    encrypted_data_keys = set()\n    encrypted_data_encryption_key = None\n    data_encryption_key = primary_master_key.generate_data_key(algorithm, encryption_context)\n    _LOGGER.debug(\"encryption data generated with master key: %s\", data_encryption_key.key_provider)\n    for master_key in master_keys:\n        # Don't re-encrypt the encryption data key; we already have the ciphertext\n        if master_key is primary_master_key:\n            encrypted_data_encryption_key = EncryptedDataKey(\n                key_provider=data_encryption_key.key_provider, encrypted_data_key=data_encryption_key.encrypted_data_key\n            )\n            encrypted_data_keys.add(encrypted_data_encryption_key)\n            continue\n        encrypted_key = master_key.encrypt_data_key(\n            data_key=data_encryption_key, algorithm=algorithm, encryption_context=encryption_context\n        )\n        encrypted_data_keys.add(encrypted_key)\n        _LOGGER.debug(\"encryption key encrypted with master key: %s\", master_key.key_provider)\n    return data_encryption_key, encrypted_data_keys", "response": "Prepares a DataKey to be used for encrypting message and list\n    of EncryptedDataKey objects to be serialized into header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prep_stream_data(data):\n    if isinstance(data, (six.string_types, six.binary_type)):\n        stream = io.BytesIO(to_bytes(data))\n    else:\n        stream = data\n\n    return InsistentReaderBytesIO(stream)", "response": "Take an input and prepare it for use as a stream."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef source_data_key_length_check(source_data_key, algorithm):\n    if len(source_data_key.data_key) != algorithm.kdf_input_len:\n        raise InvalidDataKeyError(\n            \"Invalid Source Data Key length {actual} for algorithm required: {required}\".format(\n                actual=len(source_data_key.data_key), required=algorithm.kdf_input_len\n            )\n        )", "response": "Validates that the supplied source_data_key s data_key is the correct length for the supplied algorithm s kdf_input_len value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encrypt(algorithm, key, plaintext, associated_data, iv):\n    encryptor = Encryptor(algorithm, key, associated_data, iv)\n    ciphertext = encryptor.update(plaintext) + encryptor.finalize()\n    return EncryptedData(encryptor.iv, ciphertext, encryptor.tag)", "response": "Encrypts a frame body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt(algorithm, key, encrypted_data, associated_data):\n    decryptor = Decryptor(algorithm, key, associated_data, encrypted_data.iv, encrypted_data.tag)\n    return decryptor.update(encrypted_data.ciphertext) + decryptor.finalize()", "response": "Decrypts a frame body."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_str(data):\n    if isinstance(data, bytes):\n        return codecs.decode(data, aws_encryption_sdk.internal.defaults.ENCODING)\n    return data", "response": "Takes an input str or bytes object and returns an equivalent str object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake an input str or bytes object and returns an equivalent bytes object.", "response": "def to_bytes(data):\n    \"\"\"Takes an input str or bytes object and returns an equivalent bytes object.\n\n    :param data: Input data\n    :type data: str or bytes\n    :returns: Data normalized to bytes\n    :rtype: bytes\n    \"\"\"\n    if isinstance(data, six.string_types) and not isinstance(data, bytes):\n        return codecs.encode(data, aws_encryption_sdk.internal.defaults.ENCODING)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _master_key_provider() -> KMSMasterKeyProvider:\n    master_key_provider = KMSMasterKeyProvider()\n    master_key_provider.add_master_key_provider(NullMasterKey())\n    master_key_provider.add_master_key_provider(CountingMasterKey())\n    return master_key_provider", "response": "Build the V0 master key provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads data from source copying it into tee before returning.", "response": "def read(self, b=None):\n        \"\"\"Reads data from source, copying it into ``tee`` before returning.\n\n        :param int b: number of bytes to read\n        \"\"\"\n        data = self.__wrapped__.read(b)\n        self.__tee.write(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nkeeps reading from source stream until either the source stream is done or the requested number of bytes have been obtained.", "response": "def read(self, b=-1):\n        \"\"\"Keep reading from source stream until either the source stream is done\n        or the requested number of bytes have been obtained.\n\n        :param int b: number of bytes to read\n        :return: All bytes read from wrapped stream\n        :rtype: bytes\n        \"\"\"\n        remaining_bytes = b\n        data = io.BytesIO()\n        while True:\n            try:\n                chunk = to_bytes(self.__wrapped__.read(remaining_bytes))\n            except ValueError:\n                if self.__wrapped__.closed:\n                    break\n                raise\n\n            if not chunk:\n                break\n\n            data.write(chunk)\n            remaining_bytes -= len(chunk)\n\n            if remaining_bytes <= 0:\n                break\n        return data.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ecc_static_length_signature(key, algorithm, digest):\n    pre_hashed_algorithm = ec.ECDSA(Prehashed(algorithm.signing_hash_type()))\n    signature = b\"\"\n    while len(signature) != algorithm.signature_len:\n        _LOGGER.debug(\n            \"Signature length %d is not desired length %d.  Recalculating.\", len(signature), algorithm.signature_len\n        )\n        signature = key.sign(digest, pre_hashed_algorithm)\n        if len(signature) != algorithm.signature_len:\n            # Most of the time, a signature of the wrong length can be fixed\n            # by negating s in the signature relative to the group order.\n            _LOGGER.debug(\n                \"Signature length %d is not desired length %d.  Negating s.\", len(signature), algorithm.signature_len\n            )\n            r, s = decode_dss_signature(signature)\n            s = _ECC_CURVE_PARAMETERS[algorithm.signing_algorithm_info.name].order - s\n            signature = encode_dss_signature(r, s)\n    return signature", "response": "Calculates an elliptic curve signature with a static length using pre - calculated hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes a compressed elliptic curve point by using the ECC algorithm.", "response": "def _ecc_encode_compressed_point(private_key):\n    \"\"\"Encodes a compressed elliptic curve point\n        as described in SEC-1 v2 section 2.3.3\n        http://www.secg.org/sec1-v2.pdf\n\n    :param private_key: Private key from which to extract point data\n    :type private_key: cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePrivateKey\n    :returns: Encoded compressed elliptic curve point\n    :rtype: bytes\n    :raises NotSupportedError: for non-prime curves\n    \"\"\"\n    # key_size is in bits. Convert to bytes and round up\n    byte_length = (private_key.curve.key_size + 7) // 8\n    public_numbers = private_key.public_key().public_numbers()\n    y_map = [b\"\\x02\", b\"\\x03\"]\n    # If curve in prime field.\n    if private_key.curve.name.startswith(\"secp\"):\n        y_order = public_numbers.y % 2\n        y = y_map[y_order]\n    else:\n        raise NotSupportedError(\"Non-prime curves are not supported at this time\")\n    return y + int_to_bytes(public_numbers.x, byte_length)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes a compressed elliptic curve point into a set of longs and x coordinates.", "response": "def _ecc_decode_compressed_point(curve, compressed_point):\n    \"\"\"Decodes a compressed elliptic curve point\n        as described in SEC-1 v2 section 2.3.4\n        http://www.secg.org/sec1-v2.pdf\n\n    :param curve: Elliptic curve type to generate\n    :type curve: cryptography.hazmat.primitives.asymmetric.ec.EllipticCurve\n    :param bytes compressed_point: Encoded compressed elliptic curve point\n    :returns: X and Y coordinates from compressed point\n    :rtype: tuple of longs\n    :raises NotSupportedError: for non-prime curves, unsupported prime curves, and points at infinity\n    \"\"\"\n    if not compressed_point:\n        raise NotSupportedError(\"Points at infinity are not allowed\")\n    y_order_map = {b\"\\x02\": 0, b\"\\x03\": 1}\n    raw_x = compressed_point[1:]\n    raw_x = to_bytes(raw_x)\n    x = int_from_bytes(raw_x, \"big\")\n    raw_y = compressed_point[0]\n    # In Python3, bytes index calls return int values rather than strings\n    if isinstance(raw_y, six.integer_types):\n        raw_y = six.b(chr(raw_y))\n    elif isinstance(raw_y, six.string_types):\n        raw_y = six.b(raw_y)\n    y_order = y_order_map[raw_y]\n    # If curve in prime field.\n    if curve.name.startswith(\"secp\"):\n        try:\n            params = _ECC_CURVE_PARAMETERS[curve.name]\n        except KeyError:\n            raise NotSupportedError(\"Curve {name} is not supported at this time\".format(name=curve.name))\n        alpha = (pow(x, 3, params.p) + (params.a * x % params.p) + params.b) % params.p\n        # Only works for p % 4 == 3 at this time.\n        # This is the case for all currently supported algorithms.\n        # This will need to be expanded if curves which do not match this are added.\n        #  Python-ecdsa has these algorithms implemented.  Copy or reference?\n        #  https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm\n        #  Handbook of Applied Cryptography, algorithms 3.34 - 3.39\n        if params.p % 4 == 3:\n            beta = pow(alpha, (params.p + 1) // 4, params.p)\n        else:\n            raise NotSupportedError(\"S not 1 :: Curve not supported at this time\")\n        if beta % 2 == y_order:\n            y = beta\n        else:\n            y = params.p - beta\n    else:\n        raise NotSupportedError(\"Non-prime curves are not supported at this time\")\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ecc_public_numbers_from_compressed_point(curve, compressed_point):\n    x, y = _ecc_decode_compressed_point(curve, compressed_point)\n    return ec.EllipticCurvePublicNumbers(x=x, y=y, curve=curve)", "response": "Decodes a compressed elliptic curve point and returns a EllipticCurvePublicNumbers instance based on the decoded point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_ecc_signing_key(algorithm):\n    try:\n        verify_interface(ec.EllipticCurve, algorithm.signing_algorithm_info)\n        return ec.generate_private_key(curve=algorithm.signing_algorithm_info(), backend=default_backend())\n    except InterfaceNotImplemented:\n        raise NotSupportedError(\"Unsupported signing algorithm info\")", "response": "Generates an ECC signing key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nderives the data encryption key using the defined algorithm.", "response": "def derive_data_encryption_key(source_key, algorithm, message_id):\n    \"\"\"Derives the data encryption key using the defined algorithm.\n\n    :param bytes source_key: Raw source key\n    :param algorithm: Algorithm used to encrypt this body\n    :type algorithm: aws_encryption_sdk.identifiers.Algorithm\n    :param bytes message_id: Message ID\n    :returns: Derived data encryption key\n    :rtype: bytes\n    \"\"\"\n    key = source_key\n    if algorithm.kdf_type is not None:\n        key = algorithm.kdf_type(\n            algorithm=algorithm.kdf_hash_type(),\n            length=algorithm.data_key_len,\n            salt=None,\n            info=struct.pack(\">H16s\", algorithm.algorithm_id, message_id),\n            backend=default_backend(),\n        ).derive(source_key)\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt(**kwargs):\n    with StreamEncryptor(**kwargs) as encryptor:\n        ciphertext = encryptor.read()\n    return ciphertext, encryptor.header", "response": "Encrypts and serializes the provided plaintext message into memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream(**kwargs):\n    mode = kwargs.pop(\"mode\")\n    _stream_map = {\"e\": StreamEncryptor, \"encrypt\": StreamEncryptor, \"d\": StreamDecryptor, \"decrypt\": StreamDecryptor}\n    try:\n        return _stream_map[mode.lower()](**kwargs)\n    except KeyError:\n        raise ValueError(\"Unsupported mode: {}\".format(mode))", "response": "Returns a stream of encrypted and non - framed messages from the encrypted data file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencrypting and then decrypts a file using a KMS master key provider and a custom static master key provider.", "response": "def cycle_file(key_arn, source_plaintext_filename, botocore_session=None):\n    \"\"\"Encrypts and then decrypts a file using a KMS master key provider and a custom static master\n    key provider. Both master key providers are used to encrypt the plaintext file, so either one alone\n    can decrypt it.\n\n    :param str key_arn: Amazon Resource Name (ARN) of the KMS Customer Master Key (CMK)\n    (http://docs.aws.amazon.com/kms/latest/developerguide/viewing-keys.html)\n    :param str source_plaintext_filename: Filename of file to encrypt\n    :param botocore_session: existing botocore session instance\n    :type botocore_session: botocore.session.Session\n    \"\"\"\n    # \"Cycled\" means encrypted and then decrypted\n    ciphertext_filename = source_plaintext_filename + \".encrypted\"\n    cycled_kms_plaintext_filename = source_plaintext_filename + \".kms.decrypted\"\n    cycled_static_plaintext_filename = source_plaintext_filename + \".static.decrypted\"\n\n    # Create a KMS master key provider\n    kms_kwargs = dict(key_ids=[key_arn])\n    if botocore_session is not None:\n        kms_kwargs[\"botocore_session\"] = botocore_session\n    kms_master_key_provider = aws_encryption_sdk.KMSMasterKeyProvider(**kms_kwargs)\n\n    # Create a static master key provider and add a master key to it\n    static_key_id = os.urandom(8)\n    static_master_key_provider = StaticRandomMasterKeyProvider()\n    static_master_key_provider.add_master_key(static_key_id)\n\n    # Add the static master key provider to the KMS master key provider\n    #   The resulting master key provider uses KMS master keys to generate (and encrypt)\n    #   data keys and static master keys to create an additional encrypted copy of each data key.\n    kms_master_key_provider.add_master_key_provider(static_master_key_provider)\n\n    # Encrypt plaintext with both KMS and static master keys\n    with open(source_plaintext_filename, \"rb\") as plaintext, open(ciphertext_filename, \"wb\") as ciphertext:\n        with aws_encryption_sdk.stream(source=plaintext, mode=\"e\", key_provider=kms_master_key_provider) as encryptor:\n            for chunk in encryptor:\n                ciphertext.write(chunk)\n\n    # Decrypt the ciphertext with only the KMS master key\n    with open(ciphertext_filename, \"rb\") as ciphertext, open(cycled_kms_plaintext_filename, \"wb\") as plaintext:\n        with aws_encryption_sdk.stream(\n            source=ciphertext, mode=\"d\", key_provider=aws_encryption_sdk.KMSMasterKeyProvider(**kms_kwargs)\n        ) as kms_decryptor:\n            for chunk in kms_decryptor:\n                plaintext.write(chunk)\n\n    # Decrypt the ciphertext with only the static master key\n    with open(ciphertext_filename, \"rb\") as ciphertext, open(cycled_static_plaintext_filename, \"wb\") as plaintext:\n        with aws_encryption_sdk.stream(\n            source=ciphertext, mode=\"d\", key_provider=static_master_key_provider\n        ) as static_decryptor:\n            for chunk in static_decryptor:\n                plaintext.write(chunk)\n\n    # Verify that the \"cycled\" (encrypted, then decrypted) plaintext is identical to the source plaintext\n    assert filecmp.cmp(source_plaintext_filename, cycled_kms_plaintext_filename)\n    assert filecmp.cmp(source_plaintext_filename, cycled_static_plaintext_filename)\n\n    # Verify that the encryption context in the decrypt operation includes all key pairs from the\n    # encrypt operation.\n    #\n    # In production, always use a meaningful encryption context. In this sample, we omit the\n    # encryption context (no key pairs).\n    assert all(\n        pair in kms_decryptor.header.encryption_context.items() for pair in encryptor.header.encryption_context.items()\n    )\n    assert all(\n        pair in static_decryptor.header.encryption_context.items()\n        for pair in encryptor.header.encryption_context.items()\n    )\n    return ciphertext_filename, cycled_kms_plaintext_filename, cycled_static_plaintext_filename"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_raw_key(self, key_id):\n        try:\n            static_key = self._static_keys[key_id]\n        except KeyError:\n            private_key = rsa.generate_private_key(public_exponent=65537, key_size=4096, backend=default_backend())\n            static_key = private_key.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.PKCS8,\n                encryption_algorithm=serialization.NoEncryption(),\n            )\n            self._static_keys[key_id] = static_key\n        return WrappingKey(\n            wrapping_algorithm=WrappingAlgorithm.RSA_OAEP_SHA1_MGF1,\n            wrapping_key=static_key,\n            wrapping_key_type=EncryptionKeyType.PRIVATE,\n        )", "response": "Retrieves a static randomly generated RSA key for the specified key id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of time slot options for use in swingtime forms.", "response": "def timeslot_options(\n    interval=swingtime_settings.TIMESLOT_INTERVAL,\n    start_time=swingtime_settings.TIMESLOT_START_TIME,\n    end_delta=swingtime_settings.TIMESLOT_END_TIME_DURATION,\n    fmt=swingtime_settings.TIMESLOT_TIME_FORMAT\n):\n    '''\n    Create a list of time slot options for use in swingtime forms.\n\n    The list is comprised of 2-tuples containing a 24-hour time value and a\n    12-hour temporal representation of that offset.\n\n    '''\n    dt = datetime.combine(date.today(), time(0))\n    dtstart = datetime.combine(dt.date(), start_time)\n    dtend = dtstart + end_delta\n    options = []\n\n    while dtstart <= dtend:\n        options.append((str(dtstart.time()), dtstart.strftime(fmt)))\n        dtstart += interval\n\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef timeslot_offset_options(\n    interval=swingtime_settings.TIMESLOT_INTERVAL,\n    start_time=swingtime_settings.TIMESLOT_START_TIME,\n    end_delta=swingtime_settings.TIMESLOT_END_TIME_DURATION,\n    fmt=swingtime_settings.TIMESLOT_TIME_FORMAT\n):\n    '''\n    Create a list of time slot options for use in swingtime forms.\n\n    The list is comprised of 2-tuples containing the number of seconds since the\n    start of the day and a 12-hour temporal representation of that offset.\n\n    '''\n    dt = datetime.combine(date.today(), time(0))\n    dtstart = datetime.combine(dt.date(), start_time)\n    dtend = dtstart + end_delta\n    options = []\n\n    delta = utils.time_delta_total_seconds(dtstart - dt)\n    seconds = utils.time_delta_total_seconds(interval)\n    while dtstart <= dtend:\n        options.append((delta, dtstart.strftime(fmt)))\n        dtstart += interval\n        delta += seconds\n\n    return options", "response": "Create a list of time slot options for use in swingtime forms."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a 2 - tuple containing the first and last date of the current month.", "response": "def month_boundaries(dt=None):\n    '''\n    Return a 2-tuple containing the datetime instances for the first and last\n    dates of the current month or using ``dt`` as a reference.\n\n    '''\n    dt = dt or date.today()\n    wkday, ndays = calendar.monthrange(dt.year, dt.month)\n    start = datetime(dt.year, dt.month, 1)\n    return (start, start + timedelta(ndays - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef css_class_cycler():\n    '''\n    Return a dictionary keyed by ``EventType`` abbreviations, whose values are an\n    iterable or cycle of CSS class names.\n\n    '''\n    FMT = 'evt-{0}-{1}'.format\n    return defaultdict(default_css_class_cycler, (\n        (e.abbr, itertools.cycle((FMT(e.abbr, 'even'), FMT(e.abbr, 'odd'))))\n        for e in EventType.objects.all()\n    ))", "response": "Return a dictionary keyed by EventType abbreviations whose values are an iterable or cycle of CSS class names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_timeslot_table(\n    dt=None,\n    items=None,\n    start_time=swingtime_settings.TIMESLOT_START_TIME,\n    end_time_delta=swingtime_settings.TIMESLOT_END_TIME_DURATION,\n    time_delta=swingtime_settings.TIMESLOT_INTERVAL,\n    min_columns=swingtime_settings.TIMESLOT_MIN_COLUMNS,\n    css_class_cycles=css_class_cycler,\n    proxy_class=DefaultOccurrenceProxy\n):\n    '''\n    Create a grid-like object representing a sequence of times (rows) and\n    columns where cells are either empty or reference a wrapper object for\n    event occasions that overlap a specific time slot.\n\n    Currently, there is an assumption that if an occurrence has a ``start_time``\n    that falls with the temporal scope of the grid, then that ``start_time`` will\n    also match an interval in the sequence of the computed row entries.\n\n    * ``dt`` - a ``datetime.datetime`` instance or ``None`` to default to now\n    * ``items`` - a queryset or sequence of ``Occurrence`` instances. If\n      ``None``, default to the daily occurrences for ``dt``\n    * ``start_time`` - a ``datetime.time`` instance\n    * ``end_time_delta`` - a ``datetime.timedelta`` instance\n    * ``time_delta`` - a ``datetime.timedelta`` instance\n    * ``min_column`` - the minimum number of columns to show in the table\n    * ``css_class_cycles`` - if not ``None``, a callable returning a dictionary\n      keyed by desired ``EventType`` abbreviations with values that iterate over\n      progressive CSS class names for the particular abbreviation.\n    * ``proxy_class`` - a wrapper class for accessing an ``Occurrence`` object.\n      This class should also expose ``event_type`` and ``event_type`` attrs, and\n      handle the custom output via its __unicode__ method.\n\n    '''\n    dt = dt or datetime.now()\n    start_time = start_time.replace(tzinfo=dt.tzinfo) if not start_time.tzinfo else start_time\n    dtstart = datetime.combine(dt.date(), start_time)\n    dtend = dtstart + end_time_delta\n\n    if isinstance(items, QuerySet):\n        items = items._clone()\n    elif not items:\n        items = Occurrence.objects.daily_occurrences(dt).select_related('event')\n\n    # build a mapping of timeslot \"buckets\"\n    timeslots = {}\n    n = dtstart\n    while n <= dtend:\n        timeslots[n] = {}\n        n += time_delta\n\n    # fill the timeslot buckets with occurrence proxies\n    for item in sorted(items):\n        if item.end_time <= dtstart:\n            # this item began before the start of our schedle constraints\n            continue\n\n        if item.start_time > dtstart:\n            rowkey = current = item.start_time\n        else:\n            rowkey = current = dtstart\n\n        timeslot = timeslots.get(rowkey, None)\n        if timeslot is None:\n            # TODO fix atypical interval boundry spans\n            # This is rather draconian, we should probably try to find a better\n            # way to indicate that this item actually occurred between 2 intervals\n            # and to account for the fact that this item may be spanning cells\n            # but on weird intervals\n            continue\n\n        colkey = 0\n        while 1:\n            # keep searching for an open column to place this occurrence\n            if colkey not in timeslot:\n                proxy = proxy_class(item, colkey)\n                timeslot[colkey] = proxy\n\n                while current < item.end_time:\n                    rowkey = current\n                    row = timeslots.get(rowkey, None)\n                    if row is None:\n                        break\n\n                    # we might want to put a sanity check in here to ensure that\n                    # we aren't trampling some other entry, but by virtue of\n                    # sorting all occurrence that shouldn't happen\n                    row[colkey] = proxy\n                    current += time_delta\n                break\n\n            colkey += 1\n\n    # determine the number of timeslot columns we should show\n    column_lens = [len(x) for x in timeslots.values()]\n    column_count = max((min_columns, max(column_lens) if column_lens else 0))\n    column_range = range(column_count)\n    empty_columns = ['' for x in column_range]\n\n    if css_class_cycles:\n        column_classes = dict([(i, css_class_cycles()) for i in column_range])\n    else:\n        column_classes = None\n\n    # create the chronological grid layout\n    table = []\n    for rowkey in sorted(timeslots.keys()):\n        cols = empty_columns[:]\n        for colkey in timeslots[rowkey]:\n            proxy = timeslots[rowkey][colkey]\n            cols[colkey] = proxy\n            if not proxy.event_class and column_classes:\n                proxy.event_class = next(column_classes[colkey][proxy.event_type.abbr])\n\n        table.append((rowkey, cols))\n\n    return table", "response": "Creates a time slot table for the given date range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_occurrences(self, start_time, end_time, **rrule_params):\n        '''\n        Add one or more occurences to the event using a comparable API to\n        ``dateutil.rrule``.\n\n        If ``rrule_params`` does not contain a ``freq``, one will be defaulted\n        to ``rrule.DAILY``.\n\n        Because ``rrule.rrule`` returns an iterator that can essentially be\n        unbounded, we need to slightly alter the expected behavior here in order\n        to enforce a finite number of occurrence creation.\n\n        If both ``count`` and ``until`` entries are missing from ``rrule_params``,\n        only a single ``Occurrence`` instance will be created using the exact\n        ``start_time`` and ``end_time`` values.\n        '''\n        count = rrule_params.get('count')\n        until = rrule_params.get('until')\n        if not (count or until):\n            self.occurrence_set.create(start_time=start_time, end_time=end_time)\n        else:\n            rrule_params.setdefault('freq', rrule.DAILY)\n            delta = end_time - start_time\n            occurrences = []\n            for ev in rrule.rrule(dtstart=start_time, **rrule_params):\n                occurrences.append(Occurrence(start_time=ev, end_time=ev + delta, event=self))\n            self.occurrence_set.bulk_create(occurrences)", "response": "Add one or more occurences to the event using a comparable API to_rrule."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef daily_occurrences(self, dt=None):\n        '''\n        Convenience method wrapping ``Occurrence.objects.daily_occurrences``.\n        '''\n        return Occurrence.objects.daily_occurrences(dt=dt, event=self)", "response": "Returns a list of daily Occurrence objects for this event."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef daily_occurrences(self, dt=None, event=None):\n        '''\n        Returns a queryset of for instances that have any overlap with a\n        particular day.\n\n        * ``dt`` may be either a datetime.datetime, datetime.date object, or\n          ``None``. If ``None``, default to the current day.\n\n        * ``event`` can be an ``Event`` instance for further filtering.\n        '''\n        dt = dt or datetime.now()\n        start = datetime(dt.year, dt.month, dt.day)\n        end = start.replace(hour=23, minute=59, second=59)\n        qs = self.filter(\n            models.Q(\n                start_time__gte=start,\n                start_time__lte=end,\n            ) |\n            models.Q(\n                end_time__gte=start,\n                end_time__lte=end,\n            ) |\n            models.Q(\n                start_time__lt=start,\n                end_time__gt=end\n            )\n        )\n\n        return qs.filter(event=event) if event else qs", "response": "Returns a queryset of daily occurrences for the specified date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nviews all ``events``. If ``events`` is a queryset, clone it. If ``None`` default to all ``Event``s. Context parameters: ``events`` an iterable of ``Event`` objects ... plus all values passed in via **extra_context", "response": "def event_listing(\n    request,\n    template='swingtime/event_list.html',\n    events=None,\n    **extra_context\n):\n    '''\n    View all ``events``.\n\n    If ``events`` is a queryset, clone it. If ``None`` default to all ``Event``s.\n\n    Context parameters:\n\n    ``events``\n        an iterable of ``Event`` objects\n\n    ... plus all values passed in via **extra_context\n    '''\n    events = events or Event.objects.all()\n    extra_context['events'] = events\n    return render(request, template, extra_context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nview an Event instance and optionally update either the event or its occurrences.", "response": "def event_view(\n    request,\n    pk,\n    template='swingtime/event_detail.html',\n    event_form_class=forms.EventForm,\n    recurrence_form_class=forms.MultipleOccurrenceForm\n):\n    '''\n    View an ``Event`` instance and optionally update either the event or its\n    occurrences.\n\n    Context parameters:\n\n    ``event``\n        the event keyed by ``pk``\n\n    ``event_form``\n        a form object for updating the event\n\n    ``recurrence_form``\n        a form object for adding occurrences\n    '''\n    event = get_object_or_404(Event, pk=pk)\n    event_form = recurrence_form = None\n    if request.method == 'POST':\n        if '_update' in request.POST:\n            event_form = event_form_class(request.POST, instance=event)\n            if event_form.is_valid():\n                event_form.save(event)\n                return http.HttpResponseRedirect(request.path)\n        elif '_add' in request.POST:\n            recurrence_form = recurrence_form_class(request.POST)\n            if recurrence_form.is_valid():\n                recurrence_form.save(event)\n                return http.HttpResponseRedirect(request.path)\n        else:\n            return http.HttpResponseBadRequest('Bad Request')\n\n    data = {\n        'event': event,\n        'event_form': event_form or event_form_class(instance=event),\n        'recurrence_form': recurrence_form or recurrence_form_class(\n            initial={'dtstart': datetime.now()}\n        )\n    }\n    return render(request, template, data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nviews a specific occurrence and optionally handle any updates.", "response": "def occurrence_view(\n    request,\n    event_pk,\n    pk,\n    template='swingtime/occurrence_detail.html',\n    form_class=forms.SingleOccurrenceForm\n):\n    '''\n    View a specific occurrence and optionally handle any updates.\n\n    Context parameters:\n\n    ``occurrence``\n        the occurrence object keyed by ``pk``\n\n    ``form``\n        a form object for updating the occurrence\n    '''\n    occurrence = get_object_or_404(Occurrence, pk=pk, event__pk=event_pk)\n    if request.method == 'POST':\n        form = form_class(request.POST, instance=occurrence)\n        if form.is_valid():\n            form.save()\n            return http.HttpResponseRedirect(request.path)\n    else:\n        form = form_class(instance=occurrence)\n\n    return render(request, template, {'occurrence': occurrence, 'form': form})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_event(\n    request,\n    template='swingtime/add_event.html',\n    event_form_class=forms.EventForm,\n    recurrence_form_class=forms.MultipleOccurrenceForm\n):\n    '''\n    Add a new ``Event`` instance and 1 or more associated ``Occurrence``s.\n\n    Context parameters:\n\n    ``dtstart``\n        a datetime.datetime object representing the GET request value if present,\n        otherwise None\n\n    ``event_form``\n        a form object for updating the event\n\n    ``recurrence_form``\n        a form object for adding occurrences\n\n    '''\n    dtstart = None\n    if request.method == 'POST':\n        event_form = event_form_class(request.POST)\n        recurrence_form = recurrence_form_class(request.POST)\n        if event_form.is_valid() and recurrence_form.is_valid():\n            event = event_form.save()\n            recurrence_form.save(event)\n            return http.HttpResponseRedirect(event.get_absolute_url())\n\n    else:\n        if 'dtstart' in request.GET:\n            try:\n                dtstart = parser.parse(request.GET['dtstart'])\n            except(TypeError, ValueError) as exc:\n                # TODO: A badly formatted date is passed to add_event\n                logging.warning(exc)\n\n        dtstart = dtstart or datetime.now()\n        event_form = event_form_class()\n        recurrence_form = recurrence_form_class(initial={'dtstart': dtstart})\n\n    return render(\n        request,\n        template,\n        {'dtstart': dtstart, 'event_form': event_form, 'recurrence_form': recurrence_form}\n    )", "response": "Adds an event to the internal list of occurrences."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a time slot grid representation for the given datetime dt.", "response": "def _datetime_view(\n    request,\n    template,\n    dt,\n    timeslot_factory=None,\n    items=None,\n    params=None\n):\n    '''\n    Build a time slot grid representation for the given datetime ``dt``. See\n    utils.create_timeslot_table documentation for items and params.\n\n    Context parameters:\n\n    ``day``\n        the specified datetime value (dt)\n\n    ``next_day``\n        day + 1 day\n\n    ``prev_day``\n        day - 1 day\n\n    ``timeslots``\n        time slot grid of (time, cells) rows\n\n    '''\n    timeslot_factory = timeslot_factory or utils.create_timeslot_table\n    params = params or {}\n\n    return render(request, template, {\n        'day':       dt,\n        'next_day':  dt + timedelta(days=+1),\n        'prev_day':  dt + timedelta(days=-1),\n        'timeslots': timeslot_factory(dt, items, **params)\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef day_view(request, year, month, day, template='swingtime/daily_view.html', **params):\n    '''\n    See documentation for function``_datetime_view``.\n\n    '''\n    dt = datetime(int(year), int(month), int(day))\n    return _datetime_view(request, template, dt, **params)", "response": "A daily view of a date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef today_view(request, template='swingtime/daily_view.html', **params):\n    '''\n    See documentation for function``_datetime_view``.\n\n    '''\n    return _datetime_view(request, template, datetime.now(), **params)", "response": "See documentation for function _datetime_view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef month_view(\n    request,\n    year,\n    month,\n    template='swingtime/monthly_view.html',\n    queryset=None\n):\n    '''\n    Render a tradional calendar grid view with temporal navigation variables.\n\n    Context parameters:\n\n    ``today``\n        the current datetime.datetime value\n\n    ``calendar``\n        a list of rows containing (day, items) cells, where day is the day of\n        the month integer and items is a (potentially empty) list of occurrence\n        for the day\n\n    ``this_month``\n        a datetime.datetime representing the first day of the month\n\n    ``next_month``\n        this_month + 1 month\n\n    ``last_month``\n        this_month - 1 month\n\n    '''\n    year, month = int(year), int(month)\n    cal = calendar.monthcalendar(year, month)\n    dtstart = datetime(year, month, 1)\n    last_day = max(cal[-1])\n    dtend = datetime(year, month, last_day)\n\n    # TODO Whether to include those occurrences that started in the previous\n    # month but end in this month?\n    queryset = queryset._clone() if queryset is not None else Occurrence.objects.select_related()\n    occurrences = queryset.filter(start_time__year=year, start_time__month=month)\n\n    def start_day(o):\n        return o.start_time.day\n\n    by_day = dict([(dt, list(o)) for dt, o in itertools.groupby(occurrences, start_day)])\n    data = {\n        'today':      datetime.now(),\n        'calendar':   [[(d, by_day.get(d, [])) for d in row] for row in cal],\n        'this_month': dtstart,\n        'next_month': dtstart + timedelta(days=+last_day),\n        'last_month': dtstart + timedelta(days=-1),\n    }\n\n    return render(request, template, data)", "response": "Render a tradional calendar grid view with temporal navigation variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cast(self, value, custom_formatters=None, strict=True):\n        if value is None:\n            if not self.nullable:\n                raise InvalidSchemaValue(\"Null value for non-nullable schema\", value, self.type)\n            return self.default\n\n        cast_mapping = self.get_cast_mapping(\n            custom_formatters=custom_formatters, strict=strict)\n\n        if self.type is not SchemaType.STRING and value == '':\n            return None\n\n        cast_callable = cast_mapping[self.type]\n        try:\n            return cast_callable(value)\n        except ValueError:\n            raise InvalidSchemaValue(\n                \"Failed to cast value {value} to type {type}\", value, self.type)", "response": "Cast value to schema type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_operation_pattern(server_url, request_url_pattern):\n    if server_url[-1] == \"/\":\n        # operations have to start with a slash, so do not remove it\n        server_url = server_url[:-1]\n    if is_absolute(server_url):\n        return request_url_pattern.replace(server_url, \"\", 1)\n    return path_qs(request_url_pattern).replace(server_url, \"\", 1)", "response": "Return an updated request URL pattern with the server URL removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef valid_sequences(self):\n        valid_sets = [[x] for x in self.possible_items if x['left'] == 0]\n        change = True\n        niter = 200\n        while change and niter > 0:\n            change = False\n            niter -=1\n            for possible in sorted(self.possible_items, key=lambda x:x['left']):\n                for current_valid in valid_sets[:]:\n                    if possible['left'] == current_valid[-1]['right']:\n                        if current_valid + [possible] not in valid_sets:\n                            if current_valid[-1]['left'] != current_valid[-1]['right'] or possible['left'] != possible['right']: #avoids Null insertion twice\n                                valid_sets.append(current_valid + [possible])\n                                change = True\n        if not niter:\n            raise Exception('too many iterations')\n        return valid_sets", "response": "Returns a list of all valid sequences in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(definition, data, *args, **kwargs):\n    checker = checker_factory(definition)\n    return checker(data, *args, **kwargs)", "response": "Checks if the input follows the definition"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a dictionary of strings : checkers into a formatchecker object", "response": "def formatchecker_factory(**checkerdict):\n    \"\"\"Converts a dictionary of strings:checkers into a formatchecker object\"\"\"\n    fc = FormatChecker()\n    for format_name, checker in checkerdict.items():\n        fc.checks(format_name)(checker)\n    return fc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self, data):\n        if isinstance(data, Iterable):\n            data = \"\".join(str(x) for x in data)\n        try:\n            data = str(data)\n        except UnicodeDecodeError:\n            return False\n        return bool(data and self.__regexp.match(data))", "response": "returns True if any match any regexp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _build_item_closure(itemset, productionset):\n    #For every item inside current itemset, if we have the following rule:\n    #  xxx <cursor><nonterminalSymbol> xxx  append every rule from self._productionruleset that begins with that NonTerminalSymbol\n    if not isinstance(itemset, LR0ItemSet):\n        raise TypeError\n    import copy\n    resultset = copy.copy(itemset)\n    changed = True\n    while changed:\n        changed = False\n        for currentitem in resultset.itemlist:\n            nextsymbol = currentitem.next_symbol()\n            if nextsymbol is None:\n                break\n            for rule in productionset.productions:\n                newitem = LR0Item(rule)\n                if rule.leftside[0] == nextsymbol and newitem not in resultset.itemlist:\n                    resultset.append_item(newitem)\n                    changed = True\n    return resultset", "response": "Build the itemset closure for the given itemset and productionset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef item_set_goto(itemset, inputsymbol, productionset):\n    resultset = LR0ItemSet()\n    for item in itemset.itemlist:\n        if item.next_symbol() == inputsymbol:\n            newitem = LR0Item(item.rule, item.position + 1)\n            resultset.append_item(newitem)\n    return _build_item_closure(resultset, productionset)", "response": "returns an itemset where every element with inputsymbol following cursor\n    appends its itemclosure"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _slr_build_parser_table(productionset):\n    result = ParserTable()\n    statesset = build_states_sets(productionset)\n    for itemindex, itemset in enumerate(statesset):\n        LOG.debug(\"_slr_build_parser_table: Evaluating itemset:\" + str(itemset))\n        for symbol in productionset.getSymbols() + [EndSymbol()]:\n            numberoptions = 0\n            for lritem in itemset.itemlist:\n                #if cursor is before a terminal, and there is a transition to another itemset with the following terminal, append shift rule\n                if isinstance(symbol, TerminalSymbol) and lritem.next_symbol() == symbol and itemset.has_transition(symbol):\n                    destinationstate = statesset.index(itemset.get_transition(symbol))\n                    result.append(itemindex, symbol, \"Shift\", destinationstate)\n                    numberoptions += 1\n                if isinstance(symbol, NonTerminalSymbol) and lritem.next_symbol() == symbol and itemset.has_transition(symbol):\n                    destinationstate = statesset.index(itemset.get_transition(symbol))\n                    result.append_goto(itemindex, symbol, destinationstate)\n                #if cursor is at the end of the rule, then append reduce rule and go transition\n                if lritem.previous_symbol() == symbol and lritem.is_last_position() and symbol != Extended_S:\n                    for x in productionset.next_lookup(symbol):\n                        if isinstance(x, Grammar):\n                            result.append(itemindex, TerminalSymbol(x), \"Reduce\", None, lritem.rule)\n                        elif isinstance(x, Symbol):\n                            result.append(itemindex, x, \"Reduce\", None, lritem.rule)\n                        else:\n                            raise TypeError(x)\n                    numberoptions += 1\n                #if cursor is at the end of main rule, and current symbol is end, then append accept rule\n                if symbol == EndSymbol() and lritem.previous_symbol() == productionset.initialsymbol and lritem.next_symbol() == EndSymbol():\n                    result.append(itemindex, symbol, \"Accept\", None)\n                    numberoptions += 1\n            if not numberoptions:\n                LOG.info(\"No rule found to generate a new parsertable entry \")\n                LOG.debug(\"symbol: \" + str(symbol))\n                LOG.debug(\"itemset: \" + str(itemset))\n            elif numberoptions > 1: #FIXME can it count duplicated entries?\n                raise Exception(\"LR Conflict %s\" % symbol)\n    return result", "response": "This method builds the parser table for a single grammar."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, state, symbol, action, destinationstate, production = None):\n        if action not in (None, \"Accept\", \"Shift\", \"Reduce\"):\n            raise TypeError\n        rule = {\"action\":action, \"dest\":destinationstate}\n        if action == \"Reduce\":\n            if rule is None:\n                raise TypeError(\"Expected production parameter\")\n            rule[\"rule\"] = production\n        while isinstance(symbol, TerminalSymbol) and isinstance(symbol.gd, Iterable) and len(symbol.gd) == 1 and isinstance(list(symbol.gd)[0], Grammar):\n            symbol = TerminalSymbol(list(symbol.gd)[0]) #Reduces symbol if its gd is a Sequence/Choice of 1 element\n        if not isinstance(symbol, Symbol):\n            raise TypeError(\"Expected symbol, got %s\" % symbol)\n        self[state][symbol] = rule", "response": "Appends a new rule to the state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a new entry into the internal state", "response": "def insert(self, state, token):\n        \"\"\"change internal state, return action\"\"\"\n        if token == EndSymbol():\n            return self[state][EndSymbol()]\n        from pydsl.check import check\n        symbol_list = [x for x in self[state] if isinstance(x, TerminalSymbol) and check(x.gd, [token])]\n        if not symbol_list:\n            return {\"action\":\"Fail\"}\n        if len(symbol_list) > 1:\n            raise Exception(\"Multiple symbols matches input\")\n        symbol = symbol_list[0]\n        return self[state][symbol]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append_item(self, item):\n        if not isinstance(item, LR0Item):\n            raise TypeError\n        self.itemlist.append(item)", "response": "Append new item to set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend a transition to the set", "response": "def append_transition(self, symbol, targetset):\n        \"\"\"Appends a transition\"\"\"\n        if symbol in self.transitions:\n            return\n        self.transitions[symbol] = targetset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __parse(self, tokenlist):\n        #empty stack\n        #iterate over symbollist\n        tokenlist = [x for x in tokenlist]\n        if not isinstance(tokenlist, list):\n            raise TypeError(\"Expected list, got %s\" % tokenlist.__class__.__name__)\n        LOG.debug(\"get_trees: checking list: \" + str(tokenlist))\n        stack = [(0, Extended_S)]\n        while True:\n            state = stack[-1][0]\n            if len(tokenlist):#FIXME: tokenlist with one element is reported as false\n                token = tokenlist[0]\n            else:\n                token = EndSymbol()\n            newdic = self.__parsertable.insert(state, token)\n            action = newdic[\"action\"]\n            if action == \"Fail\":\n                return False\n            elif action == \"Accept\":\n                return True\n            if action == \"Reduce\":\n                reductionrule = newdic[\"rule\"]\n                #TODO extract len(right side) of the rule and insert left side\n                for rsymbol in reversed(reductionrule.rightside):\n                    state, symbol = stack.pop() # TODO: check\n                state = stack[-1][0]\n                state = self.__parsertable.goto(state,reductionrule.leftside[0])\n                stack.append((state, reductionrule.leftside[0]))\n            elif action == \"Shift\":\n                stack.append((newdic['dest'], tokenlist.pop(0)))\n            else:\n                raise ValueError(\"Unknown action\")\n        return False", "response": "Parse a list of tokens into a list of states and states."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef graph_from_alphabet(alphabet, base):\n    if not isinstance(alphabet, Choice):\n        raise TypeError(alphabet.__class__.__name__)\n    if not isinstance(base, Choice):\n        raise TypeError(base.__class__.__name__)\n            \n    import networkx\n    result = networkx.DiGraph()\n    current_alphabet = alphabet\n    pending_stack = set(current_alphabet)\n    while pending_stack:\n        current_alphabet = pending_stack.pop()\n        if current_alphabet == base:\n            continue\n        if current_alphabet in base:\n            result.add_edge(current_alphabet, base)\n        elif isinstance(current_alphabet, Choice):\n            for element in current_alphabet:\n                if element in base:\n                    result.add_edge(current_alphabet, base)\n                else:\n                    result.add_edge(current_alphabet, element)\n                    pending_stack.add(element)\n        elif current_alphabet.alphabet:\n            result.add_edge(current_alphabet, current_alphabet.alphabet)\n            pending_stack.add(current_alphabet.alphabet)\n    return result", "response": "Creates a graph that connects the base with the target through alphabets\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_subset(a, b):\n    return b.left <= a.left and b.right > a.right or b.left < a.left and b.right >= a.right", "response": "Returns True if a is a subset of b."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef digraph_walker_backwards(graph, element, call_back):\n    call_back(graph, element)\n    for predecessor in graph.predecessors(element):\n        call_back(graph, predecessor)\n    for predecessor in graph.predecessors(element):\n        digraph_walker_backwards(graph, predecessor, call_back)", "response": "This function walks the graph in - place and then calls the call_back function for each element in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef first_lookup(self, symbol, size=1):\n        if isinstance(symbol, (TerminalSymbol, NullSymbol)):\n            return [symbol.gd]\n        result = []\n        for production in self.productions:\n            if production.leftside[0] != symbol:\n                continue\n            for right_symbol in production.rightside:\n                if right_symbol == symbol: #Avoids infinite recursion\n                    break\n                current_symbol_first = self.first_lookup(right_symbol, size)\n                import collections\n                from pydsl.grammar.definition import String\n                if isinstance(current_symbol_first, collections.Iterable) and not isinstance(current_symbol_first, String):\n                    result += current_symbol_first\n                else:\n                    result.append(current_symbol_first)\n                if isinstance(current_symbol_first, String) or \\\n                        not isinstance(current_symbol_first, collections.Iterable) or \\\n                        (NullSymbol not in current_symbol_first):\n                    break # This element doesn't have Null in its first set so there is no need to continue\n        if not result:\n            raise KeyError(\"Symbol doesn't exist in this grammar\")\n        return Choice(result)", "response": "Returns a Grammar Definition with the first n terminal symbols produced by the input symbol"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the next TerminalSymbols produced by the input symbol within this grammar definition.", "response": "def next_lookup(self, symbol):\n        \"\"\"Returns the next TerminalSymbols produced by the input symbol within this grammar definition\"\"\"\n        result = []\n        if symbol == self.initialsymbol:\n            result.append(EndSymbol())\n        for production in self.productions:\n            if symbol in production.rightside:\n                nextindex = production.rightside.index(symbol) + 1\n                while nextindex < len(production.rightside):\n                    nextsymbol = production.rightside[nextindex]\n                    firstlist = self.first_lookup(nextsymbol)\n                    cleanfirstlist = Choice([x for x in firstlist if x != NullSymbol()])\n                    result.append(cleanfirstlist)\n                    if NullSymbol() not in firstlist:\n                        break\n                else:\n                    result += self.next_lookup(production.leftside[0]) #reached the end of the rightside\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn every symbol in the terminal", "response": "def getSymbols(self):\n        \"\"\"Returns every symbol\"\"\"\n        symbollist = []\n        for rule in self.productions:\n            for symbol in rule.leftside + rule.rightside:\n                if symbol not in symbollist:\n                    symbollist.append(symbol)\n        symbollist += self.terminal_symbols\n        return symbollist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef t_NUMBER(t):\n    r'\\d+'\n    try:\n        t.value = int(t.value)\n    except ValueError:\n        print(\"Integer value too large %d\", t.value)\n        t.value = 0\n    return t", "response": "r \\ d + t. value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expression_binop(t):\n    '''expression : expression PLUS expression\n                  | expression MINUS expression\n                  | expression TIMES expression\n                  | expression DIVIDE expression'''\n    if t[2] == '+'  : t[0] = t[1] + t[3]\n    elif t[2] == '-': t[0] = t[1] - t[3]\n    elif t[2] == '*': t[0] = t[1] * t[3]\n    elif t[2] == '/': t[0] = t[1] / t[3]", "response": "expression : expression PLUS expression\n                  | expression MINUS expression\n                  | expression TIMES expression\n                  | expression DIVIDE expression"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_alphabet(alphabet, inputdata, fixed_start = False):\n    if not inputdata:\n        return []\n    base_alphabet = alphabet.alphabet\n\n    lexer = lexer_factory(alphabet, base_alphabet)\n    totallen = len(inputdata)\n    maxl = totallen\n    minl = 1\n    if fixed_start:\n        max_start = 1\n    else:\n        max_start = totallen\n    result = []\n    for i in range(max_start):\n        for j in range(i+minl, min(i+maxl, totallen) + 1):\n            try:\n                lexed = lexer(inputdata[i:j])\n                if lexed and len(lexed) == 1:\n                    result.append((i,j, inputdata[i:j], lexed[0].gd))\n                elif lexed:\n                    raise Exception\n            except:\n                continue\n    result = filter_subsets(result)\n    return [PositionToken(content, gd, left, right) for (left, right, content, gd) in result]", "response": "Extracts all of the parts of a sequence and an alphabet and returns a list of PositionTokens with all of the parts of the sequence that are a subset of the alphabet."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting a sequence of PositionTokens from inputdata that are recognized by the grammar. Returns a list of PositionTokens with all of the parts of the inputdata that are recognized by the grammar.", "response": "def extract(grammar, inputdata, fixed_start = False, return_first=False):\n    \"\"\"\n    Receives a sequence and a grammar, \n    returns a list of PositionTokens with all of the parts of the sequence that \n    are recognized by the grammar\n    \"\"\"\n    if not inputdata:\n        return []\n    checker = checker_factory(grammar)\n\n    totallen = len(inputdata)\n    from pydsl.grammar.PEG import Choice\n    try:\n        maxl = grammar.maxsize or totallen\n    except NotImplementedError:\n        maxl = totallen\n    try:\n        #minl = grammar.minsize #FIXME: It won't work with incompatible alphabets\n        minl = 1\n    except NotImplementedError:\n        minl = 1\n    if fixed_start:\n        max_start = 1\n    else:\n        max_start = totallen\n    result = []\n    for i in range(max_start):\n        for j in range(i+minl, min(i+maxl, totallen) + 1):\n            slice = inputdata[i:j]\n            check = checker.check(slice)\n            if check:\n                this_pt = PositionToken(slice, grammar, i, j)\n                if return_first:\n                    return this_pt\n                result.append(this_pt)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_trees(self, data, showerrors = False): # -> list:\n        if showerrors:\n            raise NotImplementedError(\"This parser doesn't implement errors\")\n        self.data = data\n        self.index = 0\n        try:\n            return [self.__aux_parser(self._productionset.initialsymbol)]\n        except (IndexError, ParseError):\n            return []", "response": "returns a list of trees with valid guesses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append_position_to_token_list(token_list):\n    return [PositionToken(value.content, value.gd, index, index+1) for (index, value) in enumerate(token_list)]", "response": "Converts a list of Token into a list of Token s."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_python_file(moduleobject):\n    if isinstance(moduleobject, str):\n        moduleobject = load_module(moduleobject)\n    if not hasattr(moduleobject, \"iclass\"):\n        raise KeyError(\"Element\" + str(moduleobject))\n    iclass = getattr(moduleobject, \"iclass\")\n    mylist = getattr(moduleobject, \"__all__\", None) or list(filter(lambda x:x[:1] != \"_\", (dir(moduleobject))))\n    mylist.remove('iclass')\n    resultdic = {}\n    for x in mylist:\n        resultdic[x] = getattr(moduleobject, x)\n    if iclass == \"SymbolGrammar\":\n        from pydsl.grammar.BNF import BNFGrammar\n        return BNFGrammar(**resultdic)\n    elif iclass == \"PLY\":\n        from pydsl.grammar.definition import PLYGrammar\n        return PLYGrammar(moduleobject)\n    elif iclass in [\"PythonGrammar\"]:\n        from pydsl.grammar.definition import PythonGrammar\n        return PythonGrammar(resultdic)\n    elif iclass == \"PythonTranslator\":\n        return resultdic\n    elif iclass == \"parsley\":\n        from pydsl.grammar.parsley import ParsleyGrammar\n        return ParsleyGrammar(**resultdic)\n    elif iclass == \"pyparsing\":\n        return resultdic['root_symbol']\n    else:\n        raise ValueError(str(moduleobject))", "response": "Try to create an indexable instance from a Python module object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a bnf file into a production set", "response": "def load_bnf_file(filepath, repository = None):\n    \"\"\"Converts a bnf file into a BNFGrammar instance\"\"\"\n    linelist = []\n    with open(filepath,'r') as mlfile:\n        for line in mlfile:\n            linelist.append(line)\n    return strlist_to_production_set(linelist, repository)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of trees with valid guesses", "response": "def get_trees(self, data, showerrors = False): # -> list:\n        \"\"\" returns a list of trees with valid guesses \"\"\"\n        if not all(check(self._productionset.alphabet, [x]) for x in data):\n            raise ValueError(\"Unknown element in {}, alphabet:{}\".format(str(data), self.productionset.alphabet))\n        result = self.__recursive_parser(self._productionset.initialsymbol, data, self._productionset.main_production, showerrors)\n        finalresult = []\n        for eresult in result:\n            if eresult.left == 0 and eresult.right == len(data) and eresult not in finalresult:\n                finalresult.append(eresult)        \n        return finalresult"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_re_from_file(filepath):\n    regexp = None\n    with open(filepath,'r') as mlfile:\n        flagstr = \"\"\n        for line in mlfile:\n            cleanline = re.sub(\"//.*$\", \"\", line)\n            if re.search(\"^\\s*$\", cleanline):\n                continue\n            if re.search (\"^#.*$\", cleanline):\n                flagstr = cleanline[1:]\n                continue\n            if regexp is not None:\n                raise Exception(\"Regular expression file format error\")\n            else:\n                regexp = cleanline.rstrip('\\n')\n    flags = 0\n    if \"i\" in flagstr:\n        flags |= re.I\n    from pydsl.grammar.definition import RegularExpression\n    return RegularExpression(regexp, flags)", "response": "Converts a re file to a Regular Grammar instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url_for(context, __route_name, **parts):\n    app = context['app']\n\n    query = None\n    if 'query_' in parts:\n        query = parts.pop('query_')\n\n    for key in parts:\n        val = parts[key]\n        if isinstance(val, str):\n            # if type is inherited from str expilict cast to str makes sense\n            # if type is exactly str the operation is very fast\n            val = str(val)\n        elif type(val) is int:\n            # int inherited classes like bool are forbidden\n            val = str(val)\n        else:\n            raise TypeError(\"argument value should be str or int, \"\n                            \"got {} -> [{}] {!r}\".format(key, type(val), val))\n        parts[key] = val\n\n    url = app.router[__route_name].url_for(**parts)\n    if query:\n        url = url.with_query(query)\n    return url", "response": "Filter for generating urls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a static url for a given static file path.", "response": "def static_url(context, static_file_path):\n    \"\"\"Filter for generating urls for static files.\n\n    NOTE: you'll need\n    to set app['static_root_url'] to be used as the root for the urls returned.\n\n    Usage: {{ static('styles.css') }} might become\n    \"/static/styles.css\" or \"http://mycdn.example.com/styles.css\"\n    \"\"\"\n    app = context['app']\n    try:\n        static_url = app['static_root_url']\n    except KeyError:\n        raise RuntimeError(\n            \"app does not define a static root url \"\n            \"'static_root_url', you need to set the url root \"\n            \"with app['static_root_url'] = '<static root>'.\") from None\n    return '{}/{}'.format(static_url.rstrip('/'), static_file_path.lstrip('/'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_message(self, *args, **kwargs):\n\t\t'''Wrapped method would accept new `queued` and `isgroup`\n\t\tOPTIONAL arguments'''\n\t\treturn super(MQBot, self).send_message(*args, **kwargs)", "response": "Wrapper method for sending a message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap method for edit_message_text.", "response": "def edit_message_text(self, *args, **kwargs):\n\n\t\t'''Wrapped method would accept new `queued` and `isgroup`\n\t\tOPTIONAL arguments'''\n\t\treturn super(MQBot, self).edit_message_text(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef display(self):\r\n        \"Renders the scene once every refresh\"\r\n        self.compositor.waitGetPoses(self.poses, openvr.k_unMaxTrackedDeviceCount, None, 0)\r\n        hmd_pose0 = self.poses[openvr.k_unTrackedDeviceIndex_Hmd]\r\n        if not hmd_pose0.bPoseIsValid:\r\n            return\r\n        # hmd_pose = hmd_pose0.mDeviceToAbsoluteTracking\r\n        # 1) On-screen render:\r\n        if True:\r\n            glClearColor(0.8, 0.4, 0.4, 0) # Pink background\r\n            glClear(GL_COLOR_BUFFER_BIT)\r\n            # glutSwapBuffers()\r\n            glFlush() # Single buffer\r\n        # 2) VR render\r\n        # TODO: render different things to each eye\r\n        glBindFramebuffer(GL_FRAMEBUFFER, self.fb)\r\n        glClearColor(0.8, 0.4, 0.4, 0) # Pink background\r\n        glClear(GL_COLOR_BUFFER_BIT)\r\n        glBindFramebuffer(GL_FRAMEBUFFER, 0)\r\n        #\r\n        # TODO: use different textures for each eye\r\n        self.compositor.submit(openvr.Eye_Left, self.texture)\r\n        self.compositor.submit(openvr.Eye_Right, self.texture)\r\n        glBindFramebuffer(GL_FRAMEBUFFER, 0)", "response": "Renders the scene once every refresh"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef key_press(self, key, x, y):\r\n        \"Close the application when the player presses ESCAPE\"\r\n        if ord(key) == 27:\r\n            # print \"Escape!\"\r\n            if bool(glutLeaveMainLoop):\r\n                glutLeaveMainLoop()\r\n            else:\r\n                raise Exception(\"Application quit\")", "response": "Close the application when the player presses ESCAPE"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_scene(self):\n        \"render scene one time\"\n        self.init_gl()\n        glfw.MakeContextCurrent(self.window)\n        self.renderer.render_scene()\n        glfw.SwapBuffers(self.window)\n        glfw.PollEvents()", "response": "render scene one time"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npress ESCAPE to quite the application", "response": "def key_callback(self, window, key, scancode, action, mods):\n        \"\"\"press ESCAPE to quite the application\"\"\"\n        if key == glfw.KEY_ESCAPE and action == glfw.PRESS:\n            glfw.SetWindowShouldClose(self.window, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_scene(self):\r\n\t\t\"render scene one time\"\r\n\t\tself.init_gl() # should be a no-op after the first frame is rendered\r\n\t\tSDL_GL_MakeCurrent ( self.window, self.context )\r\n\t\tself.renderer.render_scene()\r\n\t\t# Done rendering\r\n\t\t# SDL_GL_SwapWindow(self.window)\r\n\t\tglFlush()", "response": "render scene one time"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npress ESCAPE to quit the application", "response": "def on_sdl_keydown ( self, event ):\r\n\t\t\"press ESCAPE to quit the application\"\r\n\t\tkey = event.key.keysym.sym\r\n\t\tif key == SDLK_ESCAPE:\r\n\t\t\tself.running = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_loop(self):\r\n\t\t\"keep rendering until the user says quit\"\r\n\t\tself.running = True\r\n\t\tevent = SDL_Event()\r\n\t\ttry:\r\n\t\t\twhile self.running:\r\n\t\t\t\twhile SDL_PollEvent(ctypes.byref(event)) != 0:\r\n\t\t\t\t\tf = self._sdl_event_handlers.get(event.type)\r\n\t\t\t\t\tif f is not None:\r\n\t\t\t\t\t\tf ( event )\r\n\t\t\t\tself.render_scene()\r\n\t\texcept SdlAppQuit as e:\r\n\t\t\tpass", "response": "keep rendering until the user says quit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuniforming scale if only sx argument is specified", "response": "def scale(self, x, y=None, z=None):\r\n        \"Uniform scale, if only sx argument is specified\"\r\n        if y is None:\r\n            y = x\r\n        if z is None:\r\n            z = x\r\n        m = self\r\n        for col in range(4):\r\n            # Only the top three rows\r\n            m[0,col] *= x\r\n            m[1,col] *= y\r\n            m[2,col] *= z\r\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bInit( self, vrModel, vrDiffuseTexture ):\r\n        \"Purpose: Allocates and populates the GL resources for a render model\"\r\n        # create and bind a VAO to hold state for this model\r\n        self.m_glVertArray = glGenVertexArrays(1)\r\n        glBindVertexArray( self.m_glVertArray )\r\n        # Populate a vertex buffer\r\n        self.m_glVertBuffer = glGenBuffers(1)\r\n        glBindBuffer( GL_ARRAY_BUFFER, self.m_glVertBuffer )\r\n        glBufferData( GL_ARRAY_BUFFER, sizeof( openvr.RenderModel_Vertex_t ) * vrModel.unVertexCount, vrModel.rVertexData, GL_STATIC_DRAW )\r\n        # Identify the components in the vertex buffer\r\n        glEnableVertexAttribArray( 0 )\r\n        glVertexAttribPointer( 0, 3, GL_FLOAT, False, sizeof( openvr.RenderModel_Vertex_t ), openvr.RenderModel_Vertex_t.vPosition.offset )\r\n        glEnableVertexAttribArray( 1 )\r\n        glVertexAttribPointer( 1, 3, GL_FLOAT, False, sizeof( openvr.RenderModel_Vertex_t ), openvr.RenderModel_Vertex_t.vNormal.offset )\r\n        glEnableVertexAttribArray( 2 )\r\n        glVertexAttribPointer( 2, 2, GL_FLOAT, False, sizeof( openvr.RenderModel_Vertex_t ), openvr.RenderModel_Vertex_t.rfTextureCoord.offset )\r\n        # Create and populate the index buffer\r\n        self.m_glIndexBuffer = glGenBuffers(1)\r\n        glBindBuffer( GL_ELEMENT_ARRAY_BUFFER, self.m_glIndexBuffer )\r\n        glBufferData( GL_ELEMENT_ARRAY_BUFFER, sizeof( ctypes.c_uint16 ) * vrModel.unTriangleCount * 3, vrModel.rIndexData, GL_STATIC_DRAW )\r\n        glBindVertexArray( 0 )\r\n        # create and populate the texture\r\n        self.m_glTexture = glGenTextures(1)\r\n        glBindTexture( GL_TEXTURE_2D, self.m_glTexture )\r\n        glTexImage2D( GL_TEXTURE_2D, 0, GL_RGBA, vrDiffuseTexture.unWidth, vrDiffuseTexture.unHeight,\r\n            0, GL_RGBA, GL_UNSIGNED_BYTE, vrDiffuseTexture.rubTextureMapData )\r\n        # If this renders black ask McJohn what's wrong.\r\n        glGenerateMipmap(GL_TEXTURE_2D)\r\n        glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE )\r\n        glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE )\r\n        glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR )\r\n        glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR )\r\n        fLargest = glGetFloatv( GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT )\r\n        glTexParameterf( GL_TEXTURE_2D, GL_TEXTURE_MAX_ANISOTROPY_EXT, fLargest )\r\n        glBindTexture( GL_TEXTURE_2D, 0 )\r\n        self.m_unVertexCount = vrModel.unTriangleCount * 3\r\n        return True", "response": "Purpose : Allocates and populates the GL resources for a render model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup(self):\r\n        \"Purpose: Frees the GL resources for a render model\"\r\n        if self.m_glVertBuffer != 0:\r\n            glDeleteBuffers(1, (self.m_glIndexBuffer,))\r\n            glDeleteVertexArrays( 1, (self.m_glVertArray,) )\r\n            glDeleteBuffers(1, (self.m_glVertBuffer,))\r\n            self.m_glIndexBuffer = 0\r\n            self.m_glVertArray = 0\r\n            self.m_glVertBuffer = 0", "response": "Purpose : Frees the GL resources for a render model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw(self):\r\n        \"Purpose: Draws the render model\"\r\n        glBindVertexArray( self.m_glVertArray )\r\n        glActiveTexture( GL_TEXTURE0 )\r\n        glBindTexture( GL_TEXTURE_2D, self.m_glTexture )\r\n        glDrawElements( GL_TRIANGLES, self.m_unVertexCount, GL_UNSIGNED_SHORT, 0 )\r\n        glBindVertexArray( 0 )", "response": "Purpose : Draws the render model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npurpose : Create / destroy GL Render Models", "response": "def setupRenderModels(self):\r\n        \"Purpose: Create/destroy GL Render Models\"\r\n        self.m_rTrackedDeviceToRenderModel = [None] * openvr.k_unMaxTrackedDeviceCount\r\n        if self.m_pHMD is None:\r\n            return\r\n        for unTrackedDevice in range(openvr.k_unTrackedDeviceIndex_Hmd + 1, openvr.k_unMaxTrackedDeviceCount):\r\n            if not self.m_pHMD.isTrackedDeviceConnected( unTrackedDevice ):\r\n                continue\r\n            self.setupRenderModelForTrackedDevice( unTrackedDevice )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef processVREvent(self, event):\r\n        \"Purpose: Processes a single VR event\"\r\n        et = event.eventType\r\n        if et == openvr.VREvent_TrackedDeviceActivated:\r\n            self.setupRenderModelForTrackedDevice( event.trackedDeviceIndex )\r\n            dprintf( \"Device %u attached. Setting up render model.\\n\" % event.trackedDeviceIndex )\r\n        elif et == openvr.VREvent_TrackedDeviceDeactivated:\r\n            dprintf( \"Device %u detached.\\n\" % event.trackedDeviceIndex )\r\n        elif et == openvr.VREvent_TrackedDeviceUpdated:\r\n            dprintf( \"Device %u updated.\\n\" % event.trackedDeviceIndex )", "response": "Purpose : Processes a single VR event"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setupScene(self):\r\n        \"Purpose: create a sea of cubes\"\r\n        if self.m_pHMD is None:\r\n            return\r\n        vertdataarray = list()\r\n        matScale = Matrix4()\r\n        matScale.scale( self.m_fScale, self.m_fScale, self.m_fScale )\r\n        matTransform = Matrix4()\r\n        matTransform.translate([\r\n            -( float(self.m_iSceneVolumeWidth) * self.m_fScaleSpacing ) / 2.0,\r\n            -( float(self.m_iSceneVolumeHeight) * self.m_fScaleSpacing ) / 2.0,\r\n            -( float(self.m_iSceneVolumeDepth) * self.m_fScaleSpacing ) / 2.0 ])\r\n        mat = matScale * matTransform\r\n        for z in range(self.m_iSceneVolumeDepth):  # @UnusedVariable\r\n            for y in range(self.m_iSceneVolumeHeight):  # @UnusedVariable\r\n                for x in range(self.m_iSceneVolumeWidth):  # @UnusedVariable\r\n                    self.addCubeToScene( mat, vertdataarray )\r\n                    mat = mat * Matrix4().translate( [self.m_fScaleSpacing, 0, 0] )\r\n                mat = mat * Matrix4().translate( [-(float(self.m_iSceneVolumeWidth)) * self.m_fScaleSpacing, self.m_fScaleSpacing, 0] )\r\n            mat = mat * Matrix4().translate( [0, -(float(self.m_iSceneVolumeHeight)) * self.m_fScaleSpacing, self.m_fScaleSpacing] )\r\n        self.m_uiVertcount = len(vertdataarray)/5\r\n        self.m_unSceneVAO = glGenVertexArrays(1)\r\n        glBindVertexArray( self.m_unSceneVAO )\r\n        self.m_glSceneVertBuffer = glGenBuffers(1)\r\n        glBindBuffer( GL_ARRAY_BUFFER, self.m_glSceneVertBuffer )\r\n        vertdataarray = numpy.array(vertdataarray, numpy.float32) # convert to numpy array at last possible moment\r\n        glBufferData( GL_ARRAY_BUFFER, sizeof(ctypes.c_float) * len(vertdataarray), vertdataarray, GL_STATIC_DRAW)\r\n        glBindBuffer( GL_ARRAY_BUFFER, self.m_glSceneVertBuffer )\r\n        stride = sizeof(VertexDataScene)\r\n        offset = 0\r\n        glEnableVertexAttribArray( 0 )\r\n        glVertexAttribPointer( 0, 3, GL_FLOAT, False, stride , offset)\r\n        offset += sizeof(Vector3)\r\n        glEnableVertexAttribArray( 1 )\r\n        glVertexAttribPointer( 1, 2, GL_FLOAT, False, stride, offset)\r\n        glBindVertexArray( 0 )\r\n        glDisableVertexAttribArray(0)\r\n        glDisableVertexAttribArray(1)", "response": "Purpose : create a sea of cubes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drawControllers(self):\r\n        \"Purpose: Draw all of the controllers as X/Y/Z lines\"\r\n        # don't draw controllers if somebody else has input focus\r\n        if self.m_pHMD.isInputFocusCapturedByAnotherProcess():\r\n            return\r\n        vertdataarray = list()\r\n        self.m_uiControllerVertcount = 0\r\n        self.m_iTrackedControllerCount = 0\r\n    \r\n        for unTrackedDevice in range(openvr.k_unTrackedDeviceIndex_Hmd + 1, openvr.k_unMaxTrackedDeviceCount):\r\n            if not self.m_pHMD.isTrackedDeviceConnected( unTrackedDevice ):\r\n                continue\r\n            if self.m_pHMD.getTrackedDeviceClass( unTrackedDevice ) != openvr.TrackedDeviceClass_Controller:\r\n                continue\r\n            self.m_iTrackedControllerCount += 1\r\n            if not self.m_rTrackedDevicePose[ unTrackedDevice ].bPoseIsValid:\r\n                continue\r\n            mat = self.m_rmat4DevicePose[unTrackedDevice]\r\n            center = mat * Vector4( 0, 0, 0, 1 )\r\n            for i in range(3):\r\n                color = Vector4( 0, 0, 0 )\r\n                point = Vector4( 0, 0, 0, 1 )\r\n                point[i] += 0.05  # offset in X, Y, Z\r\n                color[i] = 1.0  # R, G, B\r\n                point = mat * point\r\n                vertdataarray.append( center.x )\r\n                vertdataarray.append( center.y )\r\n                vertdataarray.append( center.z )\r\n                vertdataarray.append( color.x )\r\n                vertdataarray.append( color.y )\r\n                vertdataarray.append( color.z )\r\n                vertdataarray.append( point.x )\r\n                vertdataarray.append( point.y )\r\n                vertdataarray.append( point.z )\r\n                vertdataarray.append( color.x )\r\n                vertdataarray.append( color.y )\r\n                vertdataarray.append( color.z )\r\n                self.m_uiControllerVertcount += 2\r\n            start = mat * Vector4( 0, 0, -0.02, 1 )\r\n            end = mat * Vector4( 0, 0, -39., 1 )\r\n            color = Vector3( .92, .92, .71 )\r\n            vertdataarray.append( start.x )\r\n            vertdataarray.append( start.y )\r\n            vertdataarray.append( start.z )\r\n            vertdataarray.append( color.x )\r\n            vertdataarray.append( color.y )\r\n            vertdataarray.append( color.z )\r\n            vertdataarray.append( end.x )\r\n            vertdataarray.append( end.y )\r\n            vertdataarray.append( end.z )\r\n            vertdataarray.append( color.x )\r\n            vertdataarray.append( color.y )\r\n            vertdataarray.append( color.z )\r\n            self.m_uiControllerVertcount += 2\r\n        # Setup the VAO the first time through.\r\n        if self.m_unControllerVAO == 0:        \r\n            self.m_unControllerVAO = glGenVertexArrays(1)\r\n            glBindVertexArray( self.m_unControllerVAO )\r\n            self.m_glControllerVertBuffer = glGenBuffers(1)\r\n            glBindBuffer( GL_ARRAY_BUFFER, self.m_glControllerVertBuffer )\r\n            stride = 2 * 3 * sizeof( ctypes.c_float )\r\n            offset = 0\r\n            glEnableVertexAttribArray( 0 )\r\n            glVertexAttribPointer( 0, 3, GL_FLOAT, False, stride, offset)\r\n            offset += sizeof( Vector3 )\r\n            glEnableVertexAttribArray( 1 )\r\n            glVertexAttribPointer( 1, 3, GL_FLOAT, False, stride, offset)\r\n            glBindVertexArray( 0 )\r\n        glBindBuffer( GL_ARRAY_BUFFER, self.m_glControllerVertBuffer )\r\n        # set vertex data if we have some\r\n        if len(vertdataarray) > 0:\r\n            #$ TODO: Use glBufferSubData for this...\r\n            glBufferData( GL_ARRAY_BUFFER, sizeof(float) * vertdataarray.size(), vertdataarray[0], GL_STREAM_DRAW )", "response": "Purpose : Draw all of the controllers as X / Y / Z lines"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convertSteamVRMatrixToMatrix4(self, matPose):\r\n        \"Purpose: Converts a SteamVR matrix to our local matrix class\"\r\n        matrixObj = Matrix4( [\r\n        [matPose.m[0][0], matPose.m[1][0], matPose.m[2][0], 0.0],\r\n        [matPose.m[0][1], matPose.m[1][1], matPose.m[2][1], 0.0],\r\n        [matPose.m[0][2], matPose.m[1][2], matPose.m[2][2], 0.0],\r\n        [matPose.m[0][3], matPose.m[1][3], matPose.m[2][3], 1.0] ] ) \r\n        return matrixObj", "response": "Purpose : Converts a SteamVR matrix to our local matrix class"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compileGLShader(self, pchShaderName, pchVertexShader, pchFragmentShader):\r\n        unProgramID = glCreateProgram()\r\n        nSceneVertexShader = glCreateShader(GL_VERTEX_SHADER)\r\n        glShaderSource( nSceneVertexShader, pchVertexShader)\r\n        glCompileShader( nSceneVertexShader )\r\n        vShaderCompiled = glGetShaderiv( nSceneVertexShader, GL_COMPILE_STATUS)\r\n        if not vShaderCompiled:\r\n            dprintf(\"%s - Unable to compile vertex shader %d!\\n\" % (pchShaderName, nSceneVertexShader) )\r\n            glDeleteProgram( unProgramID )\r\n            glDeleteShader( nSceneVertexShader )\r\n            return 0\r\n        glAttachShader( unProgramID, nSceneVertexShader)\r\n        glDeleteShader( nSceneVertexShader ) # the program hangs onto this once it's attached\r\n        nSceneFragmentShader = glCreateShader(GL_FRAGMENT_SHADER)\r\n        glShaderSource( nSceneFragmentShader, pchFragmentShader)\r\n        glCompileShader( nSceneFragmentShader )\r\n        fShaderCompiled = glGetShaderiv( nSceneFragmentShader, GL_COMPILE_STATUS)\r\n        if not fShaderCompiled:\r\n            dprintf(\"%s - Unable to compile fragment shader %d!\\n\" % ( pchShaderName, nSceneFragmentShader) )\r\n            glDeleteProgram( unProgramID )\r\n            glDeleteShader( nSceneFragmentShader )\r\n            return 0\r\n        glAttachShader( unProgramID, nSceneFragmentShader )\r\n        glDeleteShader( nSceneFragmentShader ) # the program hangs onto this once it's attached\r\n        glLinkProgram( unProgramID )\r\n        programSuccess = glGetProgramiv( unProgramID, GL_LINK_STATUS)\r\n        if not programSuccess:\r\n            dprintf(\"%s - Error linking program %d!\\n\" % (pchShaderName, unProgramID) )\r\n            glDeleteProgram( unProgramID )\r\n            return 0\r\n        glUseProgram( unProgramID )\r\n        glUseProgram( 0 )\r\n        return unProgramID", "response": "Function to compile a GL shader and return the handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npurposes : Creates all the shaders used by HelloVR SDL", "response": "def createAllShaders(self):\r\n        \"Purpose: Creates all the shaders used by HelloVR SDL\"\r\n        self.m_unSceneProgramID = self.compileGLShader( \r\n            \"Scene\",\r\n            # Vertex Shader\r\n            dedent(\"\"\"\\\r\n            #version 410\r\n            uniform mat4 matrix;\r\n            layout(location = 0) in vec4 position;\r\n            layout(location = 1) in vec2 v2UVcoordsIn;\r\n            layout(location = 2) in vec3 v3NormalIn;\r\n            out vec2 v2UVcoords;\r\n            void main()\r\n            {\r\n                v2UVcoords = v2UVcoordsIn;\r\n                gl_Position = matrix * position;\r\n            }\r\n            \"\"\"),\r\n            # Fragment Shader\r\n            dedent(\"\"\"\\\r\n            #version 410 core\r\n            uniform sampler2D mytexture;\r\n            in vec2 v2UVcoords;\r\n            out vec4 outputColor;\r\n            void main()\r\n            {\r\n               outputColor = texture(mytexture, v2UVcoords);\r\n            }\r\n            \"\"\")\r\n            )\r\n        self.m_nSceneMatrixLocation = glGetUniformLocation( self.m_unSceneProgramID, \"matrix\" )\r\n        if self.m_nSceneMatrixLocation == -1:\r\n            dprintf( \"Unable to find matrix uniform in scene shader\\n\" )\r\n            return False\r\n        self.m_unControllerTransformProgramID = self.compileGLShader(\r\n            \"Controller\",\r\n            # vertex shader\r\n            dedent(\"\"\"\\\r\n            #version 410\r\n            uniform mat4 matrix;\r\n            layout(location = 0) in vec4 position;\r\n            layout(location = 1) in vec3 v3ColorIn;\r\n            out vec4 v4Color;\r\n            void main()\r\n            {\r\n                v4Color.xyz = v3ColorIn;\r\n                v4Color.a = 1.0;\r\n                gl_Position = matrix * position;\r\n            }\r\n            \"\"\"),\r\n            # fragment shader\r\n            dedent(\"\"\"\\\r\n            #version 410\r\n            in vec4 v4Color;\r\n            out vec4 outputColor;\r\n            void main()\r\n            {\r\n               outputColor = v4Color;\r\n            }\r\n            \"\"\") )\r\n        self.m_nControllerMatrixLocation = glGetUniformLocation( self.m_unControllerTransformProgramID, \"matrix\" )\r\n        if self.m_nControllerMatrixLocation == -1:\r\n            dprintf( \"Unable to find matrix uniform in controller shader\\n\" )\r\n            return False\r\n        self.m_unRenderModelProgramID = self.compileGLShader( \r\n            \"render model\",\r\n            # vertex shader\r\n            dedent(\"\"\"\\\r\n            #version 410\r\n            uniform mat4 matrix;\r\n            layout(location = 0) in vec4 position;\r\n            layout(location = 1) in vec3 v3NormalIn;\r\n            layout(location = 2) in vec2 v2TexCoordsIn;\r\n            out vec2 v2TexCoord;\r\n            void main()\r\n            {\r\n                v2TexCoord = v2TexCoordsIn;\r\n                gl_Position = matrix * vec4(position.xyz, 1);\r\n            }\r\n            \"\"\"),\r\n            #fragment shader\r\n            dedent(\"\"\"\\\r\n            #version 410 core\r\n            uniform sampler2D diffuse;\r\n            in vec2 v2TexCoord;\r\n            out vec4 outputColor;\r\n            void main()\r\n            {\r\n               outputColor = texture( diffuse, v2TexCoord);\r\n            }\r\n            \"\"\") )\r\n        self.m_nRenderModelMatrixLocation = glGetUniformLocation( self.m_unRenderModelProgramID, \"matrix\" )\r\n        if self.m_nRenderModelMatrixLocation == -1:\r\n            dprintf( \"Unable to find matrix uniform in render model shader\\n\" )\r\n            return False\r\n        self.m_unLensProgramID = self.compileGLShader(\r\n            \"Distortion\",\r\n            # vertex shader\r\n            dedent(\"\"\"\\\r\n            #version 410 core\r\n            layout(location = 0) in vec4 position;\r\n            layout(location = 1) in vec2 v2UVredIn;\r\n            layout(location = 2) in vec2 v2UVGreenIn;\r\n            layout(location = 3) in vec2 v2UVblueIn;\r\n            noperspective  out vec2 v2UVred;\r\n            noperspective  out vec2 v2UVgreen;\r\n            noperspective  out vec2 v2UVblue;\r\n            void main()\r\n            {\r\n                v2UVred = v2UVredIn;\r\n                v2UVgreen = v2UVGreenIn;\r\n                v2UVblue = v2UVblueIn;\r\n                gl_Position = position;\r\n            }\r\n            \"\"\"),\r\n            # fragment shader\r\n            dedent(\"\"\"\\\r\n            #version 410 core\r\n            uniform sampler2D mytexture;\r\n    \r\n            noperspective  in vec2 v2UVred;\r\n            noperspective  in vec2 v2UVgreen;\r\n            noperspective  in vec2 v2UVblue;\r\n    \r\n            out vec4 outputColor;\r\n    \r\n            void main()\r\n            {\r\n                float fBoundsCheck = ( \r\n                    (dot( vec2( lessThan( v2UVgreen.xy, vec2(0.05, 0.05)) ), vec2(1.0, 1.0))\r\n                    + dot( vec2( greaterThan( v2UVgreen.xy, vec2( 0.95, 0.95)) ), vec2(1.0, 1.0))) \r\n                    );\r\n                if( fBoundsCheck > 1.0 ) {\r\n                    outputColor = vec4( 0, 0, 0, 1.0 ); \r\n                } \r\n                else {\r\n                    float red = texture(mytexture, v2UVred).x;\r\n                    float green = texture(mytexture, v2UVgreen).y;\r\n                    float blue = texture(mytexture, v2UVblue).z;\r\n                    outputColor = vec4( red, green, blue, 1.0  ); \r\n                }\r\n            }\r\n            \"\"\") )\r\n        return self.m_unSceneProgramID != 0 and self.m_unControllerTransformProgramID != 0 and self.m_unRenderModelProgramID != 0 and self.m_unLensProgramID != 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npurposes : Create / destroy GL a Render Model for a single tracked device", "response": "def setupRenderModelForTrackedDevice(self, unTrackedDeviceIndex):\r\n        \"Purpose: Create/destroy GL a Render Model for a single tracked device\"\r\n        if unTrackedDeviceIndex >= openvr.k_unMaxTrackedDeviceCount:\r\n            return\r\n        # try to find a model we've already set up\r\n        sRenderModelName = getTrackedDeviceString( self.m_pHMD, unTrackedDeviceIndex, openvr.Prop_RenderModelName_String )\r\n        pRenderModel = self.findOrLoadRenderModel( sRenderModelName )\r\n        if pRenderModel is None:        \r\n            sTrackingSystemName = getTrackedDeviceString( self.m_pHMD, unTrackedDeviceIndex, openvr.Prop_TrackingSystemName_String )\r\n            dprintf( \"Unable to load render model for tracked device %d (%s.%s)\" % (\r\n                    unTrackedDeviceIndex, sTrackingSystemName, sRenderModelName) )\r\n        else:\r\n            self.m_rTrackedDeviceToRenderModel[ unTrackedDeviceIndex ] = pRenderModel\r\n            self.m_rbShowTrackedDevice[ unTrackedDeviceIndex ] = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef findOrLoadRenderModel(self, pchRenderModelName):\r\n        \"Purpose: Finds a render model we've already loaded or loads a new one\"\r\n        pRenderModel = None\r\n        for model in self.m_vecRenderModels:\r\n            if model.getName() == pchRenderModelName:\r\n                pRenderModel = model\r\n                break\r\n        # load the model if we didn't find one\r\n        if pRenderModel is None:\r\n            error = openvr.EVRRenderModelError()\r\n            while True:\r\n                error, pModel = openvr.VRRenderModels().loadRenderModel_Async( pchRenderModelName )\r\n                if error != openvr.VRRenderModelError_Loading:\r\n                    break\r\n                threadSleep( 1 )\r\n            if error != openvr.VRRenderModelError_None:\r\n                dprintf( \"Unable to load render model %s - %s\\n\" % (\r\n                        pchRenderModelName, \r\n                        openvr.VRRenderModels().getRenderModelErrorNameFromEnum( error )) )\r\n                return None # move on to the next tracked device\r\n            while True:\r\n                error, pTexture = openvr.VRRenderModels().loadTexture_Async( pModel.contents.diffuseTextureId )\r\n                if error != openvr.VRRenderModelError_Loading:\r\n                    break\r\n                threadSleep( 1 )\r\n            if error != openvr.VRRenderModelError_None:\r\n                dprintf( \"Unable to load render texture id:%d for render model %s\\n\" % (\r\n                        pModel.contents.diffuseTextureId, pchRenderModelName) )\r\n                openvr.VRRenderModels().FreeRenderModel( pModel )\r\n                return None # move on to the next tracked device\r\n            pRenderModel = CGLRenderModel( pchRenderModelName )\r\n            if not pRenderModel.bInit( pModel.contents, pTexture.contents ):\r\n                dprintf( \"Unable to create GL model from render model %s\\n\" % pchRenderModelName )\r\n                # delete pRenderModel\r\n                pRenderModel = None\r\n            else:\r\n                self.m_vecRenderModels.append( pRenderModel )\r\n            openvr.VRRenderModels().freeRenderModel( pModel )\r\n            openvr.VRRenderModels().freeTexture( pTexture )\r\n        return pRenderModel", "response": "Purpose : Finds a render model we've already loaded or loads a new one"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering scene one time", "response": "def render_scene(self):\n        \"render scene one time\"\n        self.init_gl() # should be a no-op after the first frame is rendered\n        glfw.make_context_current(self.window)\n        self.renderer.render_scene()\n        # Done rendering\n        # glfw.swap_buffers(self.window) # avoid double buffering to avoid stalling\n        glFlush() # single buffering\n        glfw.poll_events()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shader_string(body, glsl_version='450 core'):\r\n    line_count = len(body.split('\\n'))\r\n    line_number = inspect.currentframe().f_back.f_lineno + 1 - line_count\r\n    return \"\"\"\\\r\n#version %s\r\n%s\r\n\"\"\" % (glsl_version, shader_substring(body, stack_frame=2))", "response": "Returns a string that represents a GLSL shader string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shader_substring(body, stack_frame=1):\r\n    line_count = len(body.splitlines(True))\r\n    line_number = inspect.stack()[stack_frame][2] + 1 - line_count\r\n    return \"\"\"\\\r\n#line %d\r\n%s\r\n\"\"\" % (line_number, textwrap.dedent(body))", "response": "Returns a string that contains the first line of the shader string that is the string body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_devices(self):\n        \"Enumerate OpenVR tracked devices and check whether any need to be initialized\"\n        for i in range(1, len(self.poses)):\n            pose = self.poses[i]\n            if not pose.bDeviceIsConnected:\n                continue\n            if not pose.bPoseIsValid:\n                continue\n            if self.show_controllers_only:\n                device_class = openvr.VRSystem().getTrackedDeviceClass(i)\n                if not device_class == openvr.TrackedDeviceClass_Controller:\n                    continue\n            model_name = openvr.VRSystem().getStringTrackedDeviceProperty(i, openvr.Prop_RenderModelName_String)\n            # Create a new mesh object, if necessary\n            if model_name not in self.meshes:\n                self.meshes[model_name] = TrackedDeviceMesh(model_name)", "response": "Enumerate OpenVR tracked devices and check whether any need to be initialized"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keyPressEvent(self, event):\n        \"press ESCAPE to quit the application\"\n        key = event.key()\n        if key == Qt.Key_Escape:\n            self.app.quit()", "response": "press ESCAPE to quit the application"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the generic interface of the specified version.", "response": "def getGenericInterface(interfaceVersion):\n    \"\"\"\n    Returns the interface of the specified version. This method must be called after VR_Init. The\r\n    pointer returned is valid until VR_Shutdown is called.\n    \"\"\"\n    error = EVRInitError()\n    result =     _openvr.VR_GetGenericInterface(interfaceVersion, byref(error))\n    _checkInitError(error.value)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getRecommendedRenderTargetSize(self):\n\n        fn = self.function_table.getRecommendedRenderTargetSize\n        pnWidth = c_uint32()\n        pnHeight = c_uint32()\n        fn(byref(pnWidth), byref(pnHeight))\n        return pnWidth.value, pnHeight.value", "response": "Suggested size for the intermediate render target that the distortion pulls from."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getProjectionMatrix(self, eEye, fNearZ, fFarZ):\n\n        fn = self.function_table.getProjectionMatrix\n        result = fn(eEye, fNearZ, fFarZ)\n        return result", "response": "Returns the projection matrix for the specified eye."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getProjectionRaw(self, eEye):\n\n        fn = self.function_table.getProjectionRaw\n        pfLeft = c_float()\n        pfRight = c_float()\n        pfTop = c_float()\n        pfBottom = c_float()\n        fn(eEye, byref(pfLeft), byref(pfRight), byref(pfTop), byref(pfBottom))\n        return pfLeft.value, pfRight.value, pfTop.value, pfBottom.value", "response": "Returns the projection matrix for the specified eye."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef computeDistortion(self, eEye, fU, fV):\n\n        fn = self.function_table.computeDistortion\n        pDistortionCoordinates = DistortionCoordinates_t()\n        result = fn(eEye, fU, fV, byref(pDistortionCoordinates))\n        return result, pDistortionCoordinates", "response": "Computes the distortion function for the specified eye and input UVs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the transform from eye space to head space.", "response": "def getEyeToHeadTransform(self, eEye):\n        \"\"\"\n        Returns the transform from eye space to the head space. Eye space is the per-eye flavor of head\n        space that provides stereo disparity. Instead of Model * View * Projection the sequence is Model * View * Eye^-1 * Projection. \n        Normally View and Eye^-1 will be multiplied together and treated as View in your application.\n        \"\"\"\n\n        fn = self.function_table.getEyeToHeadTransform\n        result = fn(eEye)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTimeSinceLastVsync(self):\n\n        fn = self.function_table.getTimeSinceLastVsync\n        pfSecondsSinceLastVsync = c_float()\n        pulFrameCounter = c_uint64()\n        result = fn(byref(pfSecondsSinceLastVsync), byref(pulFrameCounter))\n        return result, pfSecondsSinceLastVsync.value, pulFrameCounter.value", "response": "Returns the number of elapsed seconds since the last vsync event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getDXGIOutputInfo(self):\n\n        fn = self.function_table.getDXGIOutputInfo\n        pnAdapterIndex = c_int32()\n        fn(byref(pnAdapterIndex))\n        return pnAdapterIndex.value", "response": "Returns the adapter index and output index that the user should pass into EnumAdapters and EnumOutputs\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getOutputDevice(self, textureType):\n\n        fn = self.function_table.getOutputDevice\n        pnDevice = c_uint64()\n        pInstance = VkInstance_T()\n        fn(byref(pnDevice), textureType, byref(pInstance))\n        return pnDevice.value, pInstance", "response": "This function returns the platform - specific IDXGIAdapter that is used to create the output device for the specified texture type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the display visibility of the specified resource. Returns value of true indicates that the change was successful.", "response": "def setDisplayVisibility(self, bIsVisibleOnDesktop):\n        \"\"\"Set the display visibility (true = extended, false = direct mode).  Return value of true indicates that the change was successful.\"\"\"\n\n        fn = self.function_table.setDisplayVisibility\n        result = fn(bIsVisibleOnDesktop)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a sorted array of device indices of a given class of tracked devices.", "response": "def getSortedTrackedDeviceIndicesOfClass(self, eTrackedDeviceClass, unTrackedDeviceIndexArrayCount, unRelativeToTrackedDeviceIndex):\n        \"\"\"\n        Get a sorted array of device indices of a given class of tracked devices (e.g. controllers).  Devices are sorted right to left\n        relative to the specified tracked device (default: hmd -- pass in -1 for absolute tracking space).  Returns the number of devices\n        in the list, or the size of the array needed if not large enough.\n        \"\"\"\n\n        fn = self.function_table.getSortedTrackedDeviceIndicesOfClass\n        punTrackedDeviceIndexArray = TrackedDeviceIndex_t()\n        result = fn(eTrackedDeviceClass, byref(punTrackedDeviceIndexArray), unTrackedDeviceIndexArrayCount, unRelativeToTrackedDeviceIndex)\n        return result, punTrackedDeviceIndexArray"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the level of activity on the device.", "response": "def getTrackedDeviceActivityLevel(self, unDeviceId):\n        \"\"\"Returns the level of activity on the device.\"\"\"\n\n        fn = self.function_table.getTrackedDeviceActivityLevel\n        result = fn(unDeviceId)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef applyTransform(self):\n\n        fn = self.function_table.applyTransform\n        pOutputPose = TrackedDevicePose_t()\n        pTrackedDevicePose = TrackedDevicePose_t()\n        pTransform = HmdMatrix34_t()\n        fn(byref(pOutputPose), byref(pTrackedDevicePose), byref(pTransform))\n        return pOutputPose, pTrackedDevicePose, pTransform", "response": "This utility is used to apply the specified transform to the specified pose. This utility is used to apply the specified transform to the specified pose."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the index associated with a specific controller role. This function is deprecated in favor of the new IVRInput system.", "response": "def getTrackedDeviceIndexForControllerRole(self, unDeviceType):\n        \"\"\"Returns the device index associated with a specific role, for example the left hand or the right hand. This function is deprecated in favor of the new IVRInput system.\"\"\"\n\n        fn = self.function_table.getTrackedDeviceIndexForControllerRole\n        result = fn(unDeviceType)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getControllerRoleForTrackedDeviceIndex(self, unDeviceIndex):\n\n        fn = self.function_table.getControllerRoleForTrackedDeviceIndex\n        result = fn(unDeviceIndex)\n        return result", "response": "Returns the controller type associated with a device index. This function is deprecated in favor of the new IVRInput system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getTrackedDeviceClass(self, unDeviceIndex):\n\n        fn = self.function_table.getTrackedDeviceClass\n        result = fn(unDeviceIndex)\n        return result", "response": "Returns the class of a tracked device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isTrackedDeviceConnected(self, unDeviceIndex):\n\n        fn = self.function_table.isTrackedDeviceConnected\n        result = fn(unDeviceIndex)\n        return result", "response": "Returns true if there is a device connected in this slot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getBoolTrackedDeviceProperty(self, unDeviceIndex, prop):\n\n        fn = self.function_table.getBoolTrackedDeviceProperty\n        pError = ETrackedPropertyError()\n        result = fn(unDeviceIndex, prop, byref(pError))\n        return result, pError", "response": "Returns a bool property."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getArrayTrackedDeviceProperty(self, unDeviceIndex, prop, propType, pBuffer, unBufferSize):\n\n        fn = self.function_table.getArrayTrackedDeviceProperty\n        pError = ETrackedPropertyError()\n        result = fn(unDeviceIndex, prop, propType, pBuffer, unBufferSize, byref(pError))\n        return result, pError", "response": "Returns an array of one type of property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string property.", "response": "def getStringTrackedDeviceProperty(self, unDeviceIndex, prop):\n        \"\"\"\n        Returns a string property. If the device index is not valid or the property is not a string type this function will \n        return 0. Otherwise it returns the length of the number of bytes necessary to hold this string including the trailing\n        null. Strings will always fit in buffers of k_unMaxPropertyStringSize characters.\n        \"\"\"\n\n        fn = self.function_table.getStringTrackedDeviceProperty\n        pError = ETrackedPropertyError()\n        # TODO: automate this string argument manipulation ****\n        unRequiredBufferLen = fn( unDeviceIndex, prop, None, 0, byref(pError) )\n        if unRequiredBufferLen == 0:\n            return b\"\"\n        pchBuffer = ctypes.create_string_buffer(unRequiredBufferLen)\n        fn( unDeviceIndex, prop, pchBuffer, unRequiredBufferLen, byref(pError) )\n        if pError.value != TrackedProp_Success:\n            raise OpenVRError(str(pError))\n        sResult = bytes(pchBuffer.value)\n        return sResult"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string that corresponds with the specified error enum value", "response": "def getPropErrorNameFromEnum(self, error):\n        \"\"\"\n        returns a string that corresponds with the specified property error. The string will be the name \n        of the error enum value for all valid error codes\n        \"\"\"\n\n        fn = self.function_table.getPropErrorNameFromEnum\n        result = fn(error)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pollNextEvent(self, pEvent):\n\n        fn = self.function_table.pollNextEvent\n        result = fn(byref(pEvent), sizeof(VREvent_t))\n        return result != 0", "response": "Returns true and fills the event with the next event on the queue. Returns false if there is no next event on the queue. Returns false if there is no next event on the queue. Returns true and fills the event with the next event on the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pollNextEventWithPose(self, eOrigin, uncbVREvent):\n\n        fn = self.function_table.pollNextEventWithPose\n        pEvent = VREvent_t()\n        pTrackedDevicePose = TrackedDevicePose_t()\n        result = fn(eOrigin, byref(pEvent), uncbVREvent, byref(pTrackedDevicePose))\n        return result, pEvent, pTrackedDevicePose", "response": "Returns true and fills the event with the next event on the queue if there is one. Returns false otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of an EVREvent enum value", "response": "def getEventTypeNameFromEnum(self, eType):\n        \"\"\"returns the name of an EVREvent enum value\"\"\"\n\n        fn = self.function_table.getEventTypeNameFromEnum\n        result = fn(eType)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getHiddenAreaMesh(self, eEye, type_):\n\n        fn = self.function_table.getHiddenAreaMesh\n        result = fn(eEye, type_)\n        return result", "response": "Returns the hidden area mesh for the current HMD."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getControllerState(self, unControllerDeviceIndex, unControllerStateSize=sizeof(VRControllerState_t)):\n\n        fn = self.function_table.getControllerState\n        pControllerState = VRControllerState_t()\n        result = fn(unControllerDeviceIndex, byref(pControllerState), unControllerStateSize)\n        return result, pControllerState", "response": "Returns true if the controller index is valid otherwise returns false."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the current state of the controller and the pose of .", "response": "def getControllerStateWithPose(self, eOrigin, unControllerDeviceIndex, unControllerStateSize=sizeof(VRControllerState_t)):\n        \"\"\"\n        fills the supplied struct with the current state of the controller and the provided pose with the pose of \n        the controller when the controller state was updated most recently. Use this form if you need a precise controller\n        pose as input to your application when the user presses or releases a button. This function is deprecated in favor of the new IVRInput system.\n        \"\"\"\n\n        fn = self.function_table.getControllerStateWithPose\n        pControllerState = VRControllerState_t()\n        pTrackedDevicePose = TrackedDevicePose_t()\n        result = fn(eOrigin, unControllerDeviceIndex, byref(pControllerState), unControllerStateSize, byref(pTrackedDevicePose))\n        return result, pControllerState, pTrackedDevicePose"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrigger a single haptic pulse on a controller.", "response": "def triggerHapticPulse(self, unControllerDeviceIndex, unAxisId, usDurationMicroSec):\n        \"\"\"\n        Trigger a single haptic pulse on a controller. After this call the application may not trigger another haptic pulse on this controller\n        and axis combination for 5ms. This function is deprecated in favor of the new IVRInput system.\n        \"\"\"\n\n        fn = self.function_table.triggerHapticPulse\n        fn(unControllerDeviceIndex, unAxisId, usDurationMicroSec)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getButtonIdNameFromEnum(self, eButtonId):\n\n        fn = self.function_table.getButtonIdNameFromEnum\n        result = fn(eButtonId)\n        return result", "response": "returns the name of an EVRButtonId enum value. This function is deprecated in favor of the new IVRInput system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name of an EVRControllerAxisType enum value. This function is deprecated in favor of the new IVRInput system.", "response": "def getControllerAxisTypeNameFromEnum(self, eAxisType):\n        \"\"\"returns the name of an EVRControllerAxisType enum value. This function is deprecated in favor of the new IVRInput system.\"\"\"\n\n        fn = self.function_table.getControllerAxisTypeNameFromEnum\n        result = fn(eAxisType)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a request to the driver and returns the response.", "response": "def driverDebugRequest(self, unDeviceIndex, pchRequest, pchResponseBuffer, unResponseBufferSize):\n        \"\"\"\n        Sends a request to the driver for the specified device and returns the response. The maximum response size is 32k,\n        but this method can be called with a smaller buffer. If the response exceeds the size of the buffer, it is truncated. \n        The size of the response including its terminating null is returned.\n        \"\"\"\n\n        fn = self.function_table.driverDebugRequest\n        result = fn(unDeviceIndex, pchRequest, pchResponseBuffer, unResponseBufferSize)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef performFirmwareUpdate(self, unDeviceIndex):\n\n        fn = self.function_table.performFirmwareUpdate\n        result = fn(unDeviceIndex)\n        return result", "response": "Performs the firmware update of the specified entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getWindowBounds(self):\n\n        fn = self.function_table.getWindowBounds\n        pnX = c_int32()\n        pnY = c_int32()\n        pnWidth = c_uint32()\n        pnHeight = c_uint32()\n        fn(byref(pnX), byref(pnY), byref(pnWidth), byref(pnHeight))\n        return pnX.value, pnY.value, pnWidth.value, pnHeight.value", "response": "Size and position that the window needs to be on the VR display."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the viewport in the frame buffer to draw the output of the distortion into", "response": "def getEyeOutputViewport(self, eEye):\n        \"\"\"Gets the viewport in the frame buffer to draw the output of the distortion into\"\"\"\n\n        fn = self.function_table.getEyeOutputViewport\n        pnX = c_uint32()\n        pnY = c_uint32()\n        pnWidth = c_uint32()\n        pnHeight = c_uint32()\n        fn(eEye, byref(pnX), byref(pnY), byref(pnWidth), byref(pnHeight))\n        return pnX.value, pnY.value, pnWidth.value, pnHeight.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the adapter index and output index that the user should pass into EnumAdapters and EnumOutputs .", "response": "def getDXGIOutputInfo(self):\n        \"\"\"\n        [D3D10/11 Only]\n        Returns the adapter index and output index that the user should pass into EnumAdapters and EnumOutputs\n        to create the device and swap chain in DX10 and DX11. If an error occurs both indices will be set to -1.\n        \"\"\"\n\n        fn = self.function_table.getDXGIOutputInfo\n        pnAdapterIndex = c_int32()\n        pnAdapterOutputIndex = c_int32()\n        fn(byref(pnAdapterIndex), byref(pnAdapterOutputIndex))\n        return pnAdapterIndex.value, pnAdapterOutputIndex.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string for an error", "response": "def getCameraErrorNameFromEnum(self, eCameraError):\n        \"\"\"Returns a string for an error\"\"\"\n\n        fn = self.function_table.getCameraErrorNameFromEnum\n        result = fn(eCameraError)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getCameraFrameSize(self, nDeviceIndex, eFrameType):\n\n        fn = self.function_table.getCameraFrameSize\n        pnWidth = c_uint32()\n        pnHeight = c_uint32()\n        pnFrameBufferSize = c_uint32()\n        result = fn(nDeviceIndex, eFrameType, byref(pnWidth), byref(pnHeight), byref(pnFrameBufferSize))\n        return result, pnWidth.value, pnHeight.value, pnFrameBufferSize.value", "response": "Gets the size of the image frame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nacquire a video streaming service for the caller.", "response": "def acquireVideoStreamingService(self, nDeviceIndex):\n        \"\"\"\n        Acquiring streaming service permits video streaming for the caller. Releasing hints the system that video services do not need to be maintained for this client.\n        If the camera has not already been activated, a one time spin up may incur some auto exposure as well as initial streaming frame delays.\n        The camera should be considered a global resource accessible for shared consumption but not exclusive to any caller.\n        The camera may go inactive due to lack of active consumers or headset idleness.\n        \"\"\"\n\n        fn = self.function_table.acquireVideoStreamingService\n        pHandle = TrackedCameraHandle_t()\n        result = fn(nDeviceIndex, byref(pHandle))\n        return result, pHandle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getVideoStreamFrameBuffer(self, hTrackedCamera, eFrameType, pFrameBuffer, nFrameBufferSize, nFrameHeaderSize):\n\n        fn = self.function_table.getVideoStreamFrameBuffer\n        pFrameHeader = CameraVideoStreamFrameHeader_t()\n        result = fn(hTrackedCamera, eFrameType, pFrameBuffer, nFrameBufferSize, byref(pFrameHeader), nFrameHeaderSize)\n        return result, pFrameHeader", "response": "Returns the image data for the given frame type into a caller s provided buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the size of the image frame.", "response": "def getVideoStreamTextureSize(self, nDeviceIndex, eFrameType):\n        \"\"\"Gets size of the image frame.\"\"\"\n\n        fn = self.function_table.getVideoStreamTextureSize\n        pTextureBounds = VRTextureBounds_t()\n        pnWidth = c_uint32()\n        pnHeight = c_uint32()\n        result = fn(nDeviceIndex, eFrameType, byref(pTextureBounds), byref(pnWidth), byref(pnHeight))\n        return result, pTextureBounds, pnWidth.value, pnHeight.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getVideoStreamTextureGL(self, hTrackedCamera, eFrameType, nFrameHeaderSize):\n\n        fn = self.function_table.getVideoStreamTextureGL\n        pglTextureId = glUInt_t()\n        pFrameHeader = CameraVideoStreamFrameHeader_t()\n        result = fn(hTrackedCamera, eFrameType, byref(pglTextureId), byref(pFrameHeader), nFrameHeaderSize)\n        return result, pglTextureId, pFrameHeader", "response": "Access a shared GL texture for the specified tracked camera stream"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an application manifest to the list of installed applications.", "response": "def addApplicationManifest(self, pchApplicationManifestFullPath, bTemporary):\n        \"\"\"\n        Adds an application manifest to the list to load when building the list of installed applications. \n        Temporary manifests are not automatically loaded\n        \"\"\"\n\n        fn = self.function_table.addApplicationManifest\n        result = fn(pchApplicationManifestFullPath, bTemporary)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef removeApplicationManifest(self, pchApplicationManifestFullPath):\n\n        fn = self.function_table.removeApplicationManifest\n        result = fn(pchApplicationManifestFullPath)\n        return result", "response": "Removes an application manifest from the list to load when building the list of installed applications."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true if an application is installed.", "response": "def isApplicationInstalled(self, pchAppKey):\n        \"\"\"Returns true if an application is installed\"\"\"\n\n        fn = self.function_table.isApplicationInstalled\n        result = fn(pchAppKey)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef launchApplication(self, pchAppKey):\n\n        fn = self.function_table.launchApplication\n        result = fn(pchAppKey)\n        return result", "response": "Launches the application with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlaunches an application of type template with the given app key pchTemplateAppKey and optionally overrides sections from the manifest file.", "response": "def launchTemplateApplication(self, pchTemplateAppKey, pchNewAppKey, unKeys):\n        \"\"\"\n        Launches an instance of an application of type template, with its app key being pchNewAppKey (which must be unique) and optionally override sections\n        from the manifest file via AppOverrideKeys_t\n        \"\"\"\n\n        fn = self.function_table.launchTemplateApplication\n        pKeys = AppOverrideKeys_t()\n        result = fn(pchTemplateAppKey, pchNewAppKey, byref(pKeys), unKeys)\n        return result, pKeys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlaunching the application currently associated with this mime type and passes it the option args typically the filename or object name of the item being launched", "response": "def launchApplicationFromMimeType(self, pchMimeType, pchArgs):\n        \"\"\"launches the application currently associated with this mime type and passes it the option args, typically the filename or object name of the item being launched\"\"\"\n\n        fn = self.function_table.launchApplicationFromMimeType\n        result = fn(pchMimeType, pchArgs)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlaunch the dashboard overlay application if it is not already running. This is only valid for .", "response": "def launchDashboardOverlay(self, pchAppKey):\n        \"\"\"\n        Launches the dashboard overlay application if it is not already running. This call is only valid for \n        dashboard overlay applications.\n        \"\"\"\n\n        fn = self.function_table.launchDashboardOverlay\n        result = fn(pchAppKey)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncancels a pending launch for an application.", "response": "def cancelApplicationLaunch(self, pchAppKey):\n        \"\"\"Cancel a pending launch for an application\"\"\"\n\n        fn = self.function_table.cancelApplicationLaunch\n        result = fn(pchAppKey)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identifyApplication(self, unProcessId, pchAppKey):\n\n        fn = self.function_table.identifyApplication\n        result = fn(unProcessId, pchAppKey)\n        return result", "response": "Identify an application by process ID and application key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getApplicationsErrorNameFromEnum(self, error):\n\n        fn = self.function_table.getApplicationsErrorNameFromEnum\n        result = fn(error)\n        return result", "response": "Returns a string for an applications error"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getApplicationPropertyString(self, pchAppKey, eProperty, pchPropertyValueBuffer, unPropertyValueBufferLen):\n\n        fn = self.function_table.getApplicationPropertyString\n        peError = EVRApplicationError()\n        result = fn(pchAppKey, eProperty, pchPropertyValueBuffer, unPropertyValueBufferLen, byref(peError))\n        return result, peError", "response": "Returns a value for an application property. The required buffer size is fit this value will be returned."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getApplicationPropertyBool(self, pchAppKey, eProperty):\n\n        fn = self.function_table.getApplicationPropertyBool\n        peError = EVRApplicationError()\n        result = fn(pchAppKey, eProperty, byref(peError))\n        return result, peError", "response": "Returns a bool value for an application property. Returns false in all error cases. Returns true in all error cases. Returns false in all error cases. Returns false in all error cases. Returns false in all error cases. Returns false in all error cases. Returns false in all error cases. Returns false in all error cases."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the application auto - launch flag. This is only valid for applications which return true for DashboardOverlays. This is only valid for applications which return true for DashboardOverlays.", "response": "def setApplicationAutoLaunch(self, pchAppKey, bAutoLaunch):\n        \"\"\"Sets the application auto-launch flag. This is only valid for applications which return true for VRApplicationProperty_IsDashboardOverlay_Bool.\"\"\"\n\n        fn = self.function_table.setApplicationAutoLaunch\n        result = fn(pchAppKey, bAutoLaunch)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the application auto - launch flag. This is only valid for applications which return true for DashboardOverlay_Bool.", "response": "def getApplicationAutoLaunch(self, pchAppKey):\n        \"\"\"Gets the application auto-launch flag. This is only valid for applications which return true for VRApplicationProperty_IsDashboardOverlay_Bool.\"\"\"\n\n        fn = self.function_table.getApplicationAutoLaunch\n        result = fn(pchAppKey)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setDefaultApplicationForMimeType(self, pchAppKey, pchMimeType):\n\n        fn = self.function_table.setDefaultApplicationForMimeType\n        result = fn(pchAppKey, pchMimeType)\n        return result", "response": "Sets the default application for this mime - type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the app key that will open this mime type", "response": "def getDefaultApplicationForMimeType(self, pchMimeType, pchAppKeyBuffer, unAppKeyBufferLen):\n        \"\"\"return the app key that will open this mime type\"\"\"\n\n        fn = self.function_table.getDefaultApplicationForMimeType\n        result = fn(pchMimeType, pchAppKeyBuffer, unAppKeyBufferLen)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of supported mime types for this application comma - delimited", "response": "def getApplicationSupportedMimeTypes(self, pchAppKey, pchMimeTypesBuffer, unMimeTypesBuffer):\n        \"\"\"Get the list of supported mime types for this application, comma-delimited\"\"\"\n\n        fn = self.function_table.getApplicationSupportedMimeTypes\n        result = fn(pchAppKey, pchMimeTypesBuffer, unMimeTypesBuffer)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of app - keys that support this mime type comma - delimited and the return value is number of bytes you need to return the full string", "response": "def getApplicationsThatSupportMimeType(self, pchMimeType, pchAppKeysThatSupportBuffer, unAppKeysThatSupportBuffer):\n        \"\"\"Get the list of app-keys that support this mime type, comma-delimited, the return value is number of bytes you need to return the full string\"\"\"\n\n        fn = self.function_table.getApplicationsThatSupportMimeType\n        result = fn(pchMimeType, pchAppKeysThatSupportBuffer, unAppKeysThatSupportBuffer)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the args list from an app launch that had the process already running", "response": "def getApplicationLaunchArguments(self, unHandle, pchArgs, unArgs):\n        \"\"\"Get the args list from an app launch that had the process already running, you call this when you get a VREvent_ApplicationMimeTypeLoad\"\"\"\n\n        fn = self.function_table.getApplicationLaunchArguments\n        result = fn(unHandle, pchArgs, unArgs)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getStartingApplication(self, pchAppKeyBuffer, unAppKeyBufferLen):\n\n        fn = self.function_table.getStartingApplication\n        result = fn(pchAppKeyBuffer, unAppKeyBufferLen)\n        return result", "response": "Returns the app key for the application that is starting up"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef performApplicationPrelaunchCheck(self, pchAppKey):\n\n        fn = self.function_table.performApplicationPrelaunchCheck\n        result = fn(pchAppKey)\n        return result", "response": "This function checks if the specified application is not already launching immediately."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string for an application transition state", "response": "def getApplicationsTransitionStateNameFromEnum(self, state):\n        \"\"\"Returns a string for an application transition state\"\"\"\n\n        fn = self.function_table.getApplicationsTransitionStateNameFromEnum\n        result = fn(state)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a subprocess within the calling application. This method is called by the application s main application to launch a new process.", "response": "def launchInternalProcess(self, pchBinaryPath, pchArguments, pchWorkingDirectory):\n        \"\"\"\n        Starts a subprocess within the calling application. This\n        suppresses all application transition UI and automatically identifies the new executable \n        as part of the same application. On success the calling process should exit immediately. \n        If working directory is NULL or \"\" the directory portion of the binary path will be \n        the working directory.\n        \"\"\"\n\n        fn = self.function_table.launchInternalProcess\n        result = fn(pchBinaryPath, pchArguments, pchWorkingDirectory)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the width and depth of the Play Area in X and Z.", "response": "def getPlayAreaSize(self):\n        \"\"\"\n        Returns the width and depth of the Play Area (formerly named Soft Bounds) in X and Z. \n        Tracking space center (0,0,0) is the center of the Play Area.\n        \"\"\"\n\n        fn = self.function_table.getPlayAreaSize\n        pSizeX = c_float()\n        pSizeZ = c_float()\n        result = fn(byref(pSizeX), byref(pSizeZ))\n        return result, pSizeX.value, pSizeZ.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the 4 corner positions of the Play Area and the rectangle that is parallel to the X axis.", "response": "def getPlayAreaRect(self):\n        \"\"\"\n        Returns the 4 corner positions of the Play Area (formerly named Soft Bounds).\n        Corners are in counter-clockwise order.\n        Standing center (0,0,0) is the center of the Play Area.\n        It's a rectangle.\n        2 sides are parallel to the X axis and 2 sides are parallel to the Z axis.\n        Height of every corner is 0Y (on the floor).\n        \"\"\"\n\n        fn = self.function_table.getPlayAreaRect\n        rect = HmdQuad_t()\n        result = fn(byref(rect))\n        return result, rect"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getBoundsColor(self, nNumOutputColors, flCollisionBoundsFadeDistance):\n\n        fn = self.function_table.getBoundsColor\n        pOutputColorArray = HmdColor_t()\n        pOutputCameraColor = HmdColor_t()\n        fn(byref(pOutputColorArray), nNumOutputColors, flCollisionBoundsFadeDistance, byref(pOutputCameraColor))\n        return pOutputColorArray, pOutputCameraColor", "response": "Get the current chaperone bounds draw color and brightness"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commitWorkingCopy(self, configFile):\n\n        fn = self.function_table.commitWorkingCopy\n        result = fn(configFile)\n        return result", "response": "Saves the current working copy to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getWorkingPlayAreaRect(self):\n\n        fn = self.function_table.getWorkingPlayAreaRect\n        rect = HmdQuad_t()\n        result = fn(byref(rect))\n        return result, rect", "response": "Returns the rectangle of the working copy of the Play Area."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the number of Quads that are in the working copy or null if the buffer points to null. Otherwise it returns Quads into the working copy and the buffer up to the max specified from the working copy.", "response": "def getWorkingCollisionBoundsInfo(self):\n        \"\"\"\n        Returns the number of Quads if the buffer points to null. Otherwise it returns Quads \n        into the buffer up to the max specified from the working copy.\n        \"\"\"\n\n        fn = self.function_table.getWorkingCollisionBoundsInfo\n        pQuadsBuffer = HmdQuad_t()\n        punQuadsCount = c_uint32()\n        result = fn(byref(pQuadsBuffer), byref(punQuadsCount))\n        return result, pQuadsBuffer, punQuadsCount.value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the preferred seated position from the working copy. Returns 0 if the working copy is empty and 1 if the working copy is not empty.", "response": "def getWorkingSeatedZeroPoseToRawTrackingPose(self):\n        \"\"\"Returns the preferred seated position from the working copy.\"\"\"\n\n        fn = self.function_table.getWorkingSeatedZeroPoseToRawTrackingPose\n        pmatSeatedZeroPoseToRawTrackingPose = HmdMatrix34_t()\n        result = fn(byref(pmatSeatedZeroPoseToRawTrackingPose))\n        return result, pmatSeatedZeroPoseToRawTrackingPose"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the standing origin from the working copy. Returns None if the working copy is empty.", "response": "def getWorkingStandingZeroPoseToRawTrackingPose(self):\n        \"\"\"Returns the standing origin from the working copy.\"\"\"\n\n        fn = self.function_table.getWorkingStandingZeroPoseToRawTrackingPose\n        pmatStandingZeroPoseToRawTrackingPose = HmdMatrix34_t()\n        result = fn(byref(pmatStandingZeroPoseToRawTrackingPose))\n        return result, pmatStandingZeroPoseToRawTrackingPose"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setWorkingPlayAreaSize(self, sizeX, sizeZ):\n\n        fn = self.function_table.setWorkingPlayAreaSize\n        fn(sizeX, sizeZ)", "response": "Sets the Play Area in the working copy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the Collision Bounds in the working copy. Returns the HmdQuad_t object.", "response": "def setWorkingCollisionBoundsInfo(self, unQuadsCount):\n        \"\"\"Sets the Collision Bounds in the working copy.\"\"\"\n\n        fn = self.function_table.setWorkingCollisionBoundsInfo\n        pQuadsBuffer = HmdQuad_t()\n        fn(byref(pQuadsBuffer), unQuadsCount)\n        return pQuadsBuffer"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setWorkingPerimeter(self, unPointCount):\n\n        fn = self.function_table.setWorkingPerimeter\n        pPointBuffer = HmdVector2_t()\n        fn(byref(pPointBuffer), unPointCount)\n        return pPointBuffer", "response": "Sets the Collision Bounds in the working copy. Returns the HmdVector2_t object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setWorkingSeatedZeroPoseToRawTrackingPose(self):\n\n        fn = self.function_table.setWorkingSeatedZeroPoseToRawTrackingPose\n        pMatSeatedZeroPoseToRawTrackingPose = HmdMatrix34_t()\n        fn(byref(pMatSeatedZeroPoseToRawTrackingPose))\n        return pMatSeatedZeroPoseToRawTrackingPose", "response": "Sets the preferred seated position in the working copy. Returns the new one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setWorkingStandingZeroPoseToRawTrackingPose(self):\n\n        fn = self.function_table.setWorkingStandingZeroPoseToRawTrackingPose\n        pMatStandingZeroPoseToRawTrackingPose = HmdMatrix34_t()\n        fn(byref(pMatStandingZeroPoseToRawTrackingPose))\n        return pMatStandingZeroPoseToRawTrackingPose", "response": "Sets the preferred standing position in the working copy. Returns the new one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the preferred seated position.", "response": "def getLiveSeatedZeroPoseToRawTrackingPose(self):\n        \"\"\"Returns the preferred seated position.\"\"\"\n\n        fn = self.function_table.getLiveSeatedZeroPoseToRawTrackingPose\n        pmatSeatedZeroPoseToRawTrackingPose = HmdMatrix34_t()\n        result = fn(byref(pmatSeatedZeroPoseToRawTrackingPose))\n        return result, pmatSeatedZeroPoseToRawTrackingPose"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef waitGetPoses(self, pRenderPoseArray, unRenderPoseArrayCount, pGamePoseArray, unGamePoseArrayCount):\n\n        fn = self.function_table.waitGetPoses\n        # TODO: Automate this manual translation\n        # Convert non-pointer python arguments to pointers\n        if pRenderPoseArray is not None:\n            pRenderPoseArray = byref(pRenderPoseArray[0])\n        if pGamePoseArray is not None:\n            pGamePoseArray = byref(pGamePoseArray[0])\n        result = fn(pRenderPoseArray, unRenderPoseArrayCount, pGamePoseArray, unGamePoseArrayCount)\n        return result", "response": "This function is called by the VR_GetPoses function to wait for poses to render with the gameplay."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the last set of poses returned by WaitGetPoses.", "response": "def getLastPoses(self, unRenderPoseArrayCount, unGamePoseArrayCount):\n        \"\"\"Get the last set of poses returned by WaitGetPoses.\"\"\"\n\n        fn = self.function_table.getLastPoses\n        pRenderPoseArray = TrackedDevicePose_t()\n        pGamePoseArray = TrackedDevicePose_t()\n        result = fn(byref(pRenderPoseArray), unRenderPoseArrayCount, byref(pGamePoseArray), unGamePoseArrayCount)\n        return result, pRenderPoseArray, pGamePoseArray"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getLastPoseForTrackedDeviceIndex(self, unDeviceIndex):\n\n        fn = self.function_table.getLastPoseForTrackedDeviceIndex\n        pOutputPose = TrackedDevicePose_t()\n        pOutputGamePose = TrackedDevicePose_t()\n        result = fn(unDeviceIndex, byref(pOutputPose), byref(pOutputGamePose))\n        return result, pOutputPose, pOutputGamePose", "response": "This function returns the last pose for a given unDeviceIndex."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubmits a new texture to display.", "response": "def submit(self, eEye, pTexture, pBounds=None, nSubmitFlags=Submit_Default):\n        \"\"\"\n        Updated scene texture to display. If pBounds is NULL the entire texture will be used.  If called from an OpenGL app, consider adding a glFlush after\n        Submitting both frames to signal the driver to start processing, otherwise it may wait until the command buffer fills up, causing the app to miss frames.\n        * OpenGL dirty state:\n        glBindTexture\n        * Return codes:\n        - IsNotSceneApplication (make sure to call VR_Init with VRApplicaiton_Scene)\n        - DoNotHaveFocus (some other app has taken focus)\n        - TextureIsOnWrongDevice (application did not use proper AdapterIndex - see IVRSystem.GetDXGIOutputInfo)\n        - SharedTexturesNotSupported (application needs to call CreateDXGIFactory1 or later before creating DX device)\n        - TextureUsesUnsupportedFormat (scene textures must be compatible with DXGI sharing rules - e.g. uncompressed, no mips, etc.)\n        - InvalidTexture (usually means bad arguments passed in)\n        - AlreadySubmitted (app has submitted two left textures or two right textures in a single frame - i.e. before calling WaitGetPoses again)\n        \"\"\"\n\n        fn = self.function_table.submit\n        result = fn(eEye, byref(pTexture), pBounds, nSubmitFlags)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getFrameTiming(self, unFramesAgo):\n\n        fn = self.function_table.getFrameTiming\n        pTiming = Compositor_FrameTiming()\n        result = fn(byref(pTiming), unFramesAgo)\n        return result, pTiming", "response": "Returns true if timing data is filled it sets oldest timing info if unFramesAgo is larger than the stored history. Returns false otherwise. Returns false otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a range of frames from the current timing data.", "response": "def getFrameTimings(self, nFrames):\n        \"\"\"\n        Interface for copying a range of timing data.  Frames are returned in ascending order (oldest to newest) with the last being the most recent frame.\n        Only the first entry's m_nSize needs to be set, as the rest will be inferred from that.  Returns total number of entries filled out.\n        \"\"\"\n\n        fn = self.function_table.getFrameTimings\n        pTiming = Compositor_FrameTiming()\n        result = fn(byref(pTiming), nFrames)\n        return result, pTiming"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getCumulativeStats(self, nStatsSizeInBytes):\n\n        fn = self.function_table.getCumulativeStats\n        pStats = Compositor_CumulativeStats()\n        fn(byref(pStats), nStatsSizeInBytes)\n        return pStats", "response": "Fills out stats accumulated for the last connected application. Pass in sizeof ( Compositor_CumulativeStats ) as first parameter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfade the view on the HMD to the specified color.", "response": "def fadeToColor(self, fSeconds, fRed, fGreen, fBlue, fAlpha, bBackground):\n        \"\"\"\n        Fades the view on the HMD to the specified color. The fade will take fSeconds, and the color values are between\n        0.0 and 1.0. This color is faded on top of the scene based on the alpha parameter. Removing the fade color instantly \n        would be FadeToColor( 0.0, 0.0, 0.0, 0.0, 0.0 ).  Values are in un-premultiplied alpha space.\n        \"\"\"\n\n        fn = self.function_table.fadeToColor\n        fn(fSeconds, fRed, fGreen, fBlue, fAlpha, bBackground)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getCurrentFadeColor(self, bBackground):\n\n        fn = self.function_table.getCurrentFadeColor\n        result = fn(bBackground)\n        return result", "response": "Get current fade color value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfades the Grid in or out in fSeconds", "response": "def fadeGrid(self, fSeconds, bFadeIn):\n        \"\"\"Fading the Grid in or out in fSeconds\"\"\"\n\n        fn = self.function_table.fadeGrid\n        fn(fSeconds, bFadeIn)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setSkyboxOverride(self, unTextureCount):\n\n        fn = self.function_table.setSkyboxOverride\n        pTextures = Texture_t()\n        result = fn(byref(pTextures), unTextureCount)\n        return result, pTextures", "response": "Override the skybox used in the compositor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getMirrorTextureD3D11(self, eEye, pD3D11DeviceOrResource):\n\n        fn = self.function_table.getMirrorTextureD3D11\n        ppD3D11ShaderResourceView = c_void_p()\n        result = fn(eEye, pD3D11DeviceOrResource, byref(ppD3D11ShaderResourceView))\n        return result, ppD3D11ShaderResourceView.value", "response": "Opens a shared D3D11 texture with the undistorted composited image for each eye."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\naccess to mirror textures from OpenGL.", "response": "def getMirrorTextureGL(self, eEye):\n        \"\"\"Access to mirror textures from OpenGL.\"\"\"\n\n        fn = self.function_table.getMirrorTextureGL\n        pglTextureId = glUInt_t()\n        pglSharedTextureHandle = glSharedTextureHandle_t()\n        result = fn(eEye, byref(pglTextureId), byref(pglSharedTextureHandle))\n        return result, pglTextureId, pglSharedTextureHandle"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findOverlay(self, pchOverlayKey):\n\n        fn = self.function_table.findOverlay\n        pOverlayHandle = VROverlayHandle_t()\n        result = fn(pchOverlayKey, byref(pOverlayHandle))\n        return result, pOverlayHandle", "response": "Finds an existing overlay with the specified key. Returns 0 if no overlay exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new named overlay. All overlays start hidden and with default settings.", "response": "def createOverlay(self, pchOverlayKey, pchOverlayName):\n        \"\"\"Creates a new named overlay. All overlays start hidden and with default settings.\"\"\"\n\n        fn = self.function_table.createOverlay\n        pOverlayHandle = VROverlayHandle_t()\n        result = fn(pchOverlayKey, pchOverlayName, byref(pOverlayHandle))\n        return result, pOverlayHandle"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndestroys the specified overlay.", "response": "def destroyOverlay(self, ulOverlayHandle):\n        \"\"\"\n        Destroys the specified overlay. When an application calls VR_Shutdown all overlays created by that app are\n        automatically destroyed.\n        \"\"\"\n\n        fn = self.function_table.destroyOverlay\n        result = fn(ulOverlayHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setHighQualityOverlay(self, ulOverlayHandle):\n\n        fn = self.function_table.setHighQualityOverlay\n        result = fn(ulOverlayHandle)\n        return result", "response": "Sets the high quality overlay to use the high quality render path. This is only applicable to overlays that are not currently supported by the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setOverlayName(self, ulOverlayHandle, pchName):\n\n        fn = self.function_table.setOverlayName\n        result = fn(ulOverlayHandle, pchName)\n        return result", "response": "set the name to use for this overlay"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the raw image data from an overlay.", "response": "def getOverlayImageData(self, ulOverlayHandle, pvBuffer, unBufferSize):\n        \"\"\"\n        Gets the raw image data from an overlay. Overlay image data is always returned as RGBA data, 4 bytes per pixel. If the buffer is not large enough, width and height \n        will be set and VROverlayError_ArrayTooSmall is returned.\n        \"\"\"\n\n        fn = self.function_table.getOverlayImageData\n        punWidth = c_uint32()\n        punHeight = c_uint32()\n        result = fn(ulOverlayHandle, pvBuffer, unBufferSize, byref(punWidth), byref(punHeight))\n        return result, punWidth.value, punHeight.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getOverlayErrorNameFromEnum(self, error):\n\n        fn = self.function_table.getOverlayErrorNameFromEnum\n        result = fn(error)\n        return result", "response": "returns the name of the error enum value that corresponds with the specified overlay error"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setOverlayRenderingPid(self, ulOverlayHandle, unPID):\n\n        fn = self.function_table.setOverlayRenderingPid\n        result = fn(ulOverlayHandle, unPID)\n        return result", "response": "Sets the pid that is allowed to render to this overlay"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getOverlayRenderingPid(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayRenderingPid\n        result = fn(ulOverlayHandle)\n        return result", "response": "Gets the pid that is allowed to render to this overlay"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the flag setting for a given overlay", "response": "def setOverlayFlag(self, ulOverlayHandle, eOverlayFlag, bEnabled):\n        \"\"\"Specify flag setting for a given overlay\"\"\"\n\n        fn = self.function_table.setOverlayFlag\n        result = fn(ulOverlayHandle, eOverlayFlag, bEnabled)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset flag setting for a given overlay", "response": "def getOverlayFlag(self, ulOverlayHandle, eOverlayFlag):\n        \"\"\"Sets flag setting for a given overlay\"\"\"\n\n        fn = self.function_table.getOverlayFlag\n        pbEnabled = openvr_bool()\n        result = fn(ulOverlayHandle, eOverlayFlag, byref(pbEnabled))\n        return result, pbEnabled"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayColor(self, ulOverlayHandle, fRed, fGreen, fBlue):\n\n        fn = self.function_table.setOverlayColor\n        result = fn(ulOverlayHandle, fRed, fGreen, fBlue)\n        return result", "response": "Sets the color tint of the overlay quad. Use 0. 0 to 1. 0 per channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getOverlayColor(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayColor\n        pfRed = c_float()\n        pfGreen = c_float()\n        pfBlue = c_float()\n        result = fn(ulOverlayHandle, byref(pfRed), byref(pfGreen), byref(pfBlue))\n        return result, pfRed.value, pfGreen.value, pfBlue.value", "response": "Gets the color tint of the overlay quad."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayAlpha(self, ulOverlayHandle, fAlpha):\n\n        fn = self.function_table.setOverlayAlpha\n        result = fn(ulOverlayHandle, fAlpha)\n        return result", "response": "Sets the alpha of the overlay quad. Use 1. 0 for 100 percent opacity to 0. 0 for 0 percent opacity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the alpha of the overlay quad. By default overlays are rendering at 100 percent alpha.", "response": "def getOverlayAlpha(self, ulOverlayHandle):\n        \"\"\"Gets the alpha of the overlay quad. By default overlays are rendering at 100 percent alpha (1.0).\"\"\"\n\n        fn = self.function_table.getOverlayAlpha\n        pfAlpha = c_float()\n        result = fn(ulOverlayHandle, byref(pfAlpha))\n        return result, pfAlpha.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setOverlayTexelAspect(self, ulOverlayHandle, fTexelAspect):\n\n        fn = self.function_table.setOverlayTexelAspect\n        result = fn(ulOverlayHandle, fTexelAspect)\n        return result", "response": "Sets the aspect ratio of the texels in the overlay."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getOverlayTexelAspect(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayTexelAspect\n        pfTexelAspect = c_float()\n        result = fn(ulOverlayHandle, byref(pfTexelAspect))\n        return result, pfTexelAspect.value", "response": "Gets the aspect ratio of the texels in the overlay. Defaults to 1. 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlaySortOrder(self, ulOverlayHandle, unSortOrder):\n\n        fn = self.function_table.setOverlaySortOrder\n        result = fn(ulOverlayHandle, unSortOrder)\n        return result", "response": "Sets the rendering sort order for the overlay."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the sort order of the overlay. See SetOverlaySortOrder for how this works.", "response": "def getOverlaySortOrder(self, ulOverlayHandle):\n        \"\"\"Gets the sort order of the overlay. See SetOverlaySortOrder for how this works.\"\"\"\n\n        fn = self.function_table.getOverlaySortOrder\n        punSortOrder = c_uint32()\n        result = fn(ulOverlayHandle, byref(punSortOrder))\n        return result, punSortOrder.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setOverlayWidthInMeters(self, ulOverlayHandle, fWidthInMeters):\n\n        fn = self.function_table.setOverlayWidthInMeters\n        result = fn(ulOverlayHandle, fWidthInMeters)\n        return result", "response": "Sets the width of the overlay quad in meters. By default overlays are rendered on a quad that is 1 meter across. By default overlays are rendered on a quad that is 1 meter across. By default overlays are rendered on a quad that is 1 meter across."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getOverlayWidthInMeters(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayWidthInMeters\n        pfWidthInMeters = c_float()\n        result = fn(ulOverlayHandle, byref(pfWidthInMeters))\n        return result, pfWidthInMeters.value", "response": "Returns the width of the overlay quad in meters. By default overlays are rendered on a quad that is 1 meter across. By default overlays are rendered on a quad that is 1 meter across."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setOverlayAutoCurveDistanceRangeInMeters(self, ulOverlayHandle, fMinDistanceInMeters, fMaxDistanceInMeters):\n\n        fn = self.function_table.setOverlayAutoCurveDistanceRangeInMeters\n        result = fn(ulOverlayHandle, fMinDistanceInMeters, fMaxDistanceInMeters)\n        return result", "response": "Sets the distance range in meters from the overlay used to automatically curve the surface around the viewer. This is only applicable to high - quality curved overlays."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setOverlayTextureColorSpace(self, ulOverlayHandle, eTextureColorSpace):\n\n        fn = self.function_table.setOverlayTextureColorSpace\n        result = fn(ulOverlayHandle, eTextureColorSpace)\n        return result", "response": "Sets the colorspace the overlay s data is in. Defaults to auto."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getOverlayTextureColorSpace(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayTextureColorSpace\n        peTextureColorSpace = EColorSpace()\n        result = fn(ulOverlayHandle, byref(peTextureColorSpace))\n        return result, peTextureColorSpace", "response": "Gets the current colorspace setting for the overlay."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getOverlayRenderModel(self, ulOverlayHandle, pchValue, unBufferSize):\n\n        fn = self.function_table.getOverlayRenderModel\n        pColor = HmdColor_t()\n        pError = EVROverlayError()\n        result = fn(ulOverlayHandle, pchValue, unBufferSize, byref(pColor), byref(pError))\n        return result, pColor, pError", "response": "Gets the render model that is used to draw this overlay"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the render model for this overlay and the vertex color to use. If pColor is not set the overlay s vertex color is used.", "response": "def setOverlayRenderModel(self, ulOverlayHandle, pchRenderModel):\n        \"\"\"\n        Sets render model to draw behind this overlay and the vertex color to use, pass null for pColor to match the overlays vertex color. \n        The model is scaled by the same amount as the overlay, with a default of 1m.\n        \"\"\"\n\n        fn = self.function_table.setOverlayRenderModel\n        pColor = HmdColor_t()\n        result = fn(ulOverlayHandle, pchRenderModel, byref(pColor))\n        return result, pColor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getOverlayTransformType(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayTransformType\n        peTransformType = VROverlayTransformType()\n        result = fn(ulOverlayHandle, byref(peTransformType))\n        return result, peTransformType", "response": "Returns the transform type of this overlay."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayTransformAbsolute(self, ulOverlayHandle, eTrackingOrigin):\n\n        fn = self.function_table.setOverlayTransformAbsolute\n        pmatTrackingOriginToOverlayTransform = HmdMatrix34_t()\n        result = fn(ulOverlayHandle, eTrackingOrigin, byref(pmatTrackingOriginToOverlayTransform))\n        return result, pmatTrackingOriginToOverlayTransform", "response": "Sets the transform to absolute tracking origin."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the transform to relative to the transform of the specified tracked device.", "response": "def setOverlayTransformTrackedDeviceRelative(self, ulOverlayHandle, unTrackedDevice):\n        \"\"\"Sets the transform to relative to the transform of the specified tracked device.\"\"\"\n\n        fn = self.function_table.setOverlayTransformTrackedDeviceRelative\n        pmatTrackedDeviceToOverlayTransform = HmdMatrix34_t()\n        result = fn(ulOverlayHandle, unTrackedDevice, byref(pmatTrackedDeviceToOverlayTransform))\n        return result, pmatTrackedDeviceToOverlayTransform"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayTransformTrackedDeviceComponent(self, ulOverlayHandle, unDeviceIndex, pchComponentName):\n\n        fn = self.function_table.setOverlayTransformTrackedDeviceComponent\n        result = fn(ulOverlayHandle, unDeviceIndex, pchComponentName)\n        return result", "response": "Sets the transform to draw the overlay on a rendermodel component mesh instead of a quad."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getOverlayTransformTrackedDeviceComponent(self, ulOverlayHandle, pchComponentName, unComponentNameSize):\n\n        fn = self.function_table.getOverlayTransformTrackedDeviceComponent\n        punDeviceIndex = TrackedDeviceIndex_t()\n        result = fn(ulOverlayHandle, byref(punDeviceIndex), pchComponentName, unComponentNameSize)\n        return result, punDeviceIndex", "response": "Gets the transform information when the overlay is rendering on a component."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayTransformOverlayRelative(self, ulOverlayHandle, ulOverlayHandleParent):\n\n        fn = self.function_table.setOverlayTransformOverlayRelative\n        pmatParentOverlayToOverlayTransform = HmdMatrix34_t()\n        result = fn(ulOverlayHandle, ulOverlayHandleParent, byref(pmatParentOverlayToOverlayTransform))\n        return result, pmatParentOverlayToOverlayTransform", "response": "Sets the transform to relative to the transform of the specified overlay."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow the VR overlay.", "response": "def showOverlay(self, ulOverlayHandle):\n        \"\"\"Shows the VR overlay.  For dashboard overlays, only the Dashboard Manager is allowed to call this.\"\"\"\n\n        fn = self.function_table.showOverlay\n        result = fn(ulOverlayHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hideOverlay(self, ulOverlayHandle):\n\n        fn = self.function_table.hideOverlay\n        result = fn(ulOverlayHandle)\n        return result", "response": "Hides the VR overlay."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if the overlay is visible.", "response": "def isOverlayVisible(self, ulOverlayHandle):\n        \"\"\"Returns true if the overlay is visible.\"\"\"\n\n        fn = self.function_table.isOverlayVisible\n        result = fn(ulOverlayHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the transform in 3d space associated with a specific 2d point in the overlay s coordinate space.", "response": "def getTransformForOverlayCoordinates(self, ulOverlayHandle, eTrackingOrigin, coordinatesInOverlay):\n        \"\"\"Get the transform in 3d space associated with a specific 2d point in the overlay's coordinate space (where 0,0 is the lower left). -Z points out of the overlay\"\"\"\n\n        fn = self.function_table.getTransformForOverlayCoordinates\n        pmatTransform = HmdMatrix34_t()\n        result = fn(ulOverlayHandle, eTrackingOrigin, coordinatesInOverlay, byref(pmatTransform))\n        return result, pmatTransform"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns true and fills the event with the next event on the overlay s event queue. uncbVREvent should be the size in bytes of the event queue. Returns false and the event is not set. Returns false and the event is not set.", "response": "def pollNextOverlayEvent(self, ulOverlayHandle, uncbVREvent):\n        \"\"\"\n        Returns true and fills the event with the next event on the overlay's event queue, if there is one. \n        If there are no events this method returns false. uncbVREvent should be the size in bytes of the VREvent_t struct\n        \"\"\"\n\n        fn = self.function_table.pollNextOverlayEvent\n        pEvent = VREvent_t()\n        result = fn(ulOverlayHandle, byref(pEvent), uncbVREvent)\n        return result, pEvent"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getOverlayInputMethod(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayInputMethod\n        peInputMethod = VROverlayInputMethod()\n        result = fn(ulOverlayHandle, byref(peInputMethod))\n        return result, peInputMethod", "response": "Returns the current input settings for the specified overlay."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setOverlayInputMethod(self, ulOverlayHandle, eInputMethod):\n\n        fn = self.function_table.setOverlayInputMethod\n        result = fn(ulOverlayHandle, eInputMethod)\n        return result", "response": "Sets the input settings for the specified overlay."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getOverlayMouseScale(self, ulOverlayHandle):\n\n        fn = self.function_table.getOverlayMouseScale\n        pvecMouseScale = HmdVector2_t()\n        result = fn(ulOverlayHandle, byref(pvecMouseScale))\n        return result, pvecMouseScale", "response": "Gets the mouse scaling factor that is used for mouse events. This is the size of the actual texture that is used for mouse events."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef computeOverlayIntersection(self, ulOverlayHandle):\n\n        fn = self.function_table.computeOverlayIntersection\n        pParams = VROverlayIntersectionParams_t()\n        pResults = VROverlayIntersectionResults_t()\n        result = fn(ulOverlayHandle, byref(pParams), byref(pResults))\n        return result, pParams, pResults", "response": "Computes the intersection of the ray with the base overlay. Returns false if there is no intersection. Returns true if there is no intersection. Returns false if there is no intersection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setGamepadFocusOverlay(self, ulNewFocusOverlay):\n\n        fn = self.function_table.setGamepadFocusOverlay\n        result = fn(ulNewFocusOverlay)\n        return result", "response": "Sets the current Gamepad focus overlay"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setOverlayNeighbor(self, eDirection, ulFrom, ulTo):\n\n        fn = self.function_table.setOverlayNeighbor\n        result = fn(eDirection, ulFrom, ulTo)\n        return result", "response": "Sets an overlay s neighbor. This will set the neighbor of the from overlay to the to overlay."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves the Gamepad focus from one overlay to one of its neighbors. Returns VROverlayError_NoNeighbor if there is no neighbor in that direction.", "response": "def moveGamepadFocusToNeighbor(self, eDirection, ulFrom):\n        \"\"\"\n        Changes the Gamepad focus from one overlay to one of its neighbors. Returns VROverlayError_NoNeighbor if there is no\n        neighbor in that direction\n        \"\"\"\n\n        fn = self.function_table.moveGamepadFocusToNeighbor\n        result = fn(eDirection, ulFrom)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayDualAnalogTransform(self, ulOverlay, eWhich, fRadius):\n\n        fn = self.function_table.setOverlayDualAnalogTransform\n        pvCenter = HmdVector2_t()\n        result = fn(ulOverlay, eWhich, byref(pvCenter), fRadius)\n        return result, pvCenter", "response": "Sets the analog input to Dual Analog coordinate scale for the specified overlay."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the analog input to Dual Analog coordinate scale for the specified overlay.", "response": "def getOverlayDualAnalogTransform(self, ulOverlay, eWhich):\n        \"\"\"Gets the analog input to Dual Analog coordinate scale for the specified overlay.\"\"\"\n\n        fn = self.function_table.getOverlayDualAnalogTransform\n        pvCenter = HmdVector2_t()\n        pfRadius = c_float()\n        result = fn(ulOverlay, eWhich, byref(pvCenter), byref(pfRadius))\n        return result, pvCenter, pfRadius.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setOverlayTexture(self, ulOverlayHandle):\n\n        fn = self.function_table.setOverlayTexture\n        pTexture = Texture_t()\n        result = fn(ulOverlayHandle, byref(pTexture))\n        return result, pTexture", "response": "Sets the current texture for the overlay. This is only called by the overlay s creator or renderer process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses this to release the texture set for this overlay.", "response": "def clearOverlayTexture(self, ulOverlayHandle):\n        \"\"\"Use this to tell the overlay system to release the texture set for this overlay.\"\"\"\n\n        fn = self.function_table.clearOverlayTexture\n        result = fn(ulOverlayHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nseparating interface for providing the data as a stream of bytes, but there is an upper bound on data that can be sent. This function can only be called by the overlay's renderer process.", "response": "def setOverlayRaw(self, ulOverlayHandle, pvBuffer, unWidth, unHeight, unDepth):\n        \"\"\"\n        Separate interface for providing the data as a stream of bytes, but there is an upper bound on data \n        that can be sent. This function can only be called by the overlay's renderer process.\n        \"\"\"\n\n        fn = self.function_table.setOverlayRaw\n        result = fn(ulOverlayHandle, pvBuffer, unWidth, unHeight, unDepth)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setOverlayFromFile(self, ulOverlayHandle, pchFilePath):\n\n        fn = self.function_table.setOverlayFromFile\n        result = fn(ulOverlayHandle, pchFilePath)\n        return result", "response": "This function is used to set the overlay image through a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getOverlayTexture(self, ulOverlayHandle, pNativeTextureRef):\n\n        fn = self.function_table.getOverlayTexture\n        pNativeTextureHandle = c_void_p()\n        pWidth = c_uint32()\n        pHeight = c_uint32()\n        pNativeFormat = c_uint32()\n        pAPIType = ETextureType()\n        pColorSpace = EColorSpace()\n        pTextureBounds = VRTextureBounds_t()\n        result = fn(ulOverlayHandle, byref(pNativeTextureHandle), pNativeTextureRef, byref(pWidth), byref(pHeight), byref(pNativeFormat), byref(pAPIType), byref(pColorSpace), byref(pTextureBounds))\n        return result, pNativeTextureHandle.value, pWidth.value, pHeight.value, pNativeFormat.value, pAPIType, pColorSpace, pTextureBounds", "response": "Get the native texture for an overlay. This is a convenience method that is used by the overlays that are not yet supported by the Windows system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrelease the native texture handle provided by the GetOverlayTexture call. This is only needed if the GetOverlayTexture call is called on the object itself.", "response": "def releaseNativeOverlayHandle(self, ulOverlayHandle, pNativeTextureHandle):\n        \"\"\"\n        Release the pNativeTextureHandle provided from the GetOverlayTexture call, this allows the system to free the underlying GPU resources for this object,\n        so only do it once you stop rendering this texture.\n        \"\"\"\n\n        fn = self.function_table.releaseNativeOverlayHandle\n        result = fn(ulOverlayHandle, pNativeTextureHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the size of the overlay texture", "response": "def getOverlayTextureSize(self, ulOverlayHandle):\n        \"\"\"Get the size of the overlay texture\"\"\"\n\n        fn = self.function_table.getOverlayTextureSize\n        pWidth = c_uint32()\n        pHeight = c_uint32()\n        result = fn(ulOverlayHandle, byref(pWidth), byref(pHeight))\n        return result, pWidth.value, pHeight.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a dashboard overlay and returns its handle", "response": "def createDashboardOverlay(self, pchOverlayKey, pchOverlayFriendlyName):\n        \"\"\"Creates a dashboard overlay and returns its handle\"\"\"\n\n        fn = self.function_table.createDashboardOverlay\n        pMainHandle = VROverlayHandle_t()\n        pThumbnailHandle = VROverlayHandle_t()\n        result = fn(pchOverlayKey, pchOverlayFriendlyName, byref(pMainHandle), byref(pThumbnailHandle))\n        return result, pMainHandle, pThumbnailHandle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if the dashboard is visible and the specified overlay is the active system Overlay", "response": "def isActiveDashboardOverlay(self, ulOverlayHandle):\n        \"\"\"returns true if the dashboard is visible and the specified overlay is the active system Overlay\"\"\"\n\n        fn = self.function_table.isActiveDashboardOverlay\n        result = fn(ulOverlayHandle)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setDashboardOverlaySceneProcess(self, ulOverlayHandle, unProcessId):\n\n        fn = self.function_table.setDashboardOverlaySceneProcess\n        result = fn(ulOverlayHandle, unProcessId)\n        return result", "response": "Sets the dashboard overlay to only appear when the specified process ID has scene focus"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDashboardOverlaySceneProcess(self, ulOverlayHandle):\n\n        fn = self.function_table.getDashboardOverlaySceneProcess\n        punProcessId = c_uint32()\n        result = fn(ulOverlayHandle, byref(punProcessId))\n        return result, punProcessId.value", "response": "Gets the process ID that this dashboard overlay requires to have scene focus"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef showKeyboard(self, eInputMode, eLineInputMode, pchDescription, unCharMax, pchExistingText, bUseMinimalMode, uUserValue):\n\n        fn = self.function_table.showKeyboard\n        result = fn(eInputMode, eLineInputMode, pchDescription, unCharMax, pchExistingText, bUseMinimalMode, uUserValue)\n        return result", "response": "Show the virtual keyboard to accept input"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the text that was entered into the text input", "response": "def getKeyboardText(self, pchText, cchText):\n        \"\"\"Get the text that was entered into the text input\"\"\"\n\n        fn = self.function_table.getKeyboardText\n        result = fn(pchText, cchText)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the position of the keyboard in world space. Returns the matrix that maps the origin of the keyboard in world space to the transform of the keyboard in world space.", "response": "def setKeyboardTransformAbsolute(self, eTrackingOrigin):\n        \"\"\"Set the position of the keyboard in world space\"\"\"\n\n        fn = self.function_table.setKeyboardTransformAbsolute\n        pmatTrackingOriginToKeyboardTransform = HmdMatrix34_t()\n        fn(eTrackingOrigin, byref(pmatTrackingOriginToKeyboardTransform))\n        return pmatTrackingOriginToKeyboardTransform"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setKeyboardPositionForOverlay(self, ulOverlayHandle, avoidRect):\n\n        fn = self.function_table.setKeyboardPositionForOverlay\n        fn(ulOverlayHandle, avoidRect)", "response": "Set the position of the keyboard in the overlay space by telling it to avoid a rectangle in the overlay."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOverlayIntersectionMask(self, ulOverlayHandle, unNumMaskPrimitives, unPrimitiveSize):\n\n        fn = self.function_table.setOverlayIntersectionMask\n        pMaskPrimitives = VROverlayIntersectionMaskPrimitive_t()\n        result = fn(ulOverlayHandle, byref(pMaskPrimitives), unNumMaskPrimitives, unPrimitiveSize)\n        return result, pMaskPrimitives", "response": "Sets the mask of the controller rays that are used for intersection with the overlay."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef showMessageOverlay(self, pchText, pchCaption, pchButton0Text, pchButton1Text, pchButton2Text, pchButton3Text):\n\n        fn = self.function_table.showMessageOverlay\n        result = fn(pchText, pchCaption, pchButton0Text, pchButton1Text, pchButton2Text, pchButton3Text)\n        return result", "response": "Show the message overlay. This will block and return you a result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload and returns a render model for use in the application.", "response": "def loadRenderModel_Async(self, pchRenderModelName):\n        \"\"\"\n        Loads and returns a render model for use in the application. pchRenderModelName should be a render model name\n        from the Prop_RenderModelName_String property or an absolute path name to a render model on disk. \n        * The resulting render model is valid until VR_Shutdown() is called or until FreeRenderModel() is called. When the \n        application is finished with the render model it should call FreeRenderModel() to free the memory associated\n        with the model.\n        * The method returns VRRenderModelError_Loading while the render model is still being loaded.\n        The method returns VRRenderModelError_None once loaded successfully, otherwise will return an error.\n        \"\"\"\n\n        fn = self.function_table.loadRenderModel_Async\n        ppRenderModel = POINTER(RenderModel_t)()\n        result = fn(pchRenderModelName, byref(ppRenderModel))\n        if ppRenderModel:\n            ppRenderModel = ppRenderModel.contents\n        else:\n            ppRenderModel = None\n        return result, ppRenderModel"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef freeRenderModel(self):\n\n        fn = self.function_table.freeRenderModel\n        pRenderModel = RenderModel_t()\n        fn(byref(pRenderModel))\n        return pRenderModel", "response": "Frees a previously returned render model and returns a null ptr."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads and returns a texture for use in the application.", "response": "def loadTexture_Async(self, textureId):\n        \"\"\"Loads and returns a texture for use in the application.\"\"\"\n\n        fn = self.function_table.loadTexture_Async\n        ppTexture = POINTER(RenderModel_TextureMap_t)()\n        result = fn(textureId, byref(ppTexture))\n        return result, ppTexture"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfreeing a previously returned texture It returns a null ptr.", "response": "def freeTexture(self):\n        \"\"\"\n        Frees a previously returned texture\n          It is safe to call this on a null ptr.\n        \"\"\"\n\n        fn = self.function_table.freeTexture\n        pTexture = RenderModel_TextureMap_t()\n        fn(byref(pTexture))\n        return pTexture"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadTextureD3D11_Async(self, textureId, pD3D11Device):\n\n        fn = self.function_table.loadTextureD3D11_Async\n        ppD3D11Texture2D = c_void_p()\n        result = fn(textureId, pD3D11Device, byref(ppD3D11Texture2D))\n        return result, ppD3D11Texture2D.value", "response": "Creates a D3D11 texture and loads data into it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getRenderModelName(self, unRenderModelIndex, pchRenderModelName, unRenderModelNameLen):\n\n        fn = self.function_table.getRenderModelName\n        result = fn(unRenderModelIndex, pchRenderModelName, unRenderModelNameLen)\n        return result", "response": "This function returns the name of the available render models."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of components of the specified render model.", "response": "def getComponentCount(self, pchRenderModelName):\n        \"\"\"\n        Returns the number of components of the specified render model.\n         Components are useful when client application wish to draw, label, or otherwise interact with components of tracked objects.\n         Examples controller components:\n          renderable things such as triggers, buttons\n          non-renderable things which include coordinate systems such as 'tip', 'base', a neutral controller agnostic hand-pose\n          If all controller components are enumerated and rendered, it will be equivalent to drawing the traditional render model\n          Returns 0 if components not supported, >0 otherwise\n        \"\"\"\n\n        fn = self.function_table.getComponentCount\n        result = fn(pchRenderModelName)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getComponentName(self, pchRenderModelName, unComponentIndex, pchComponentName, unComponentNameLen):\n\n        fn = self.function_table.getComponentName\n        result = fn(pchRenderModelName, unComponentIndex, pchComponentName, unComponentNameLen)\n        return result", "response": "This function returns the name of the available components."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the render model name for the specified rendermode and component combination.", "response": "def getComponentRenderModelName(self, pchRenderModelName, pchComponentName, pchComponentRenderModelName, unComponentRenderModelNameLen):\n        \"\"\"\n        Use this to get the render model name for the specified rendermode/component combination, to be passed to LoadRenderModel.\n        If the component name is out of range, this function will return 0.\n        Otherwise, it will return the size of the buffer required for the name.\n        \"\"\"\n\n        fn = self.function_table.getComponentRenderModelName\n        result = fn(pchRenderModelName, pchComponentName, pchComponentRenderModelName, unComponentRenderModelNameLen)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getComponentStateForDevicePath(self, pchRenderModelName, pchComponentName, devicePath):\n\n        fn = self.function_table.getComponentStateForDevicePath\n        pState = RenderModel_ControllerMode_State_t()\n        pComponentState = RenderModel_ComponentState_t()\n        result = fn(pchRenderModelName, pchComponentName, devicePath, byref(pState), byref(pComponentState))\n        return result, pState, pComponentState", "response": "Returns the state of the component for a given device path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getComponentState(self, pchRenderModelName, pchComponentName):\n\n        fn = self.function_table.getComponentState\n        pControllerState = VRControllerState_t()\n        pState = RenderModel_ControllerMode_State_t()\n        pComponentState = RenderModel_ComponentState_t()\n        result = fn(pchRenderModelName, pchComponentName, byref(pControllerState), byref(pState), byref(pComponentState))\n        return result, pControllerState, pState, pComponentState", "response": "This version of GetComponentState takes a controller state block instead of an action origin. This function is deprecated. You should use GetComponentStateForDevicePath instead."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning true if the render model has a component with the specified name", "response": "def renderModelHasComponent(self, pchRenderModelName, pchComponentName):\n        \"\"\"Returns true if the render model has a component with the specified name\"\"\"\n\n        fn = self.function_table.renderModelHasComponent\n        result = fn(pchRenderModelName, pchComponentName)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getRenderModelThumbnailURL(self, pchRenderModelName, pchThumbnailURL, unThumbnailURLLen):\n\n        fn = self.function_table.getRenderModelThumbnailURL\n        peError = EVRRenderModelError()\n        result = fn(pchRenderModelName, pchThumbnailURL, unThumbnailURLLen, byref(peError))\n        return result, peError", "response": "Returns the URL of the thumbnail image for this rendermodel. Returns an error if the thumbnail image is not available."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the path that the render model was loaded from.", "response": "def getRenderModelOriginalPath(self, pchRenderModelName, pchOriginalPath, unOriginalPathLen):\n        \"\"\"\n        Provides a render model path that will load the unskinned model if the model name provided has been replace by the user. If the model\n        hasn't been replaced the path value will still be a valid path to load the model. Pass this to LoadRenderModel_Async, etc. to load the\n        model.\n        \"\"\"\n\n        fn = self.function_table.getRenderModelOriginalPath\n        peError = EVRRenderModelError()\n        result = fn(pchRenderModelName, pchOriginalPath, unOriginalPathLen, byref(peError))\n        return result, peError"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getRenderModelErrorNameFromEnum(self, error):\n\n        fn = self.function_table.getRenderModelErrorNameFromEnum\n        result = fn(error)\n        return result", "response": "Returns a string for a render model error"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createNotification(self, ulOverlayHandle, ulUserValue, type_, pchText, style):\n\n        fn = self.function_table.createNotification\n        pImage = NotificationBitmap_t()\n        pNotificationId = VRNotificationId()\n        result = fn(ulOverlayHandle, ulUserValue, type_, pchText, style, byref(pImage), byref(pNotificationId))\n        return result, pImage, pNotificationId", "response": "Creates a new notification for the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndestroy a notification, hiding it first if it currently shown to the user.", "response": "def removeNotification(self, notificationId):\n        \"\"\"Destroy a notification, hiding it first if it currently shown to the user.\"\"\"\n\n        fn = self.function_table.removeNotification\n        result = fn(notificationId)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync(self, bForce):\n\n        fn = self.function_table.sync\n        peError = EVRSettingsError()\n        result = fn(bForce, byref(peError))\n        return result, peError", "response": "Returns true if file sync occurred ( force or settings dirty"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a boolean value for the specified key in the specified section.", "response": "def getBool(self, pchSection, pchSettingsKey):\n        \"\"\"\n        Users of the system need to provide a proper default in default.vrsettings in the resources/settings/ directory\n        of either the runtime or the driver_xxx directory. Otherwise the default will be false, 0, 0.0 or \"\"\n        \"\"\"\n\n        fn = self.function_table.getBool\n        peError = EVRSettingsError()\n        result = fn(pchSection, pchSettingsKey, byref(peError))\n        return result, peError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequest a screenshot of the requested type.", "response": "def requestScreenshot(self, type_, pchPreviewFilename, pchVRFilename):\n        \"\"\"\n        Request a screenshot of the requested type.\n         A request of the VRScreenshotType_Stereo type will always\n         work. Other types will depend on the underlying application\n         support.\n         The first file name is for the preview image and should be a\n         regular screenshot (ideally from the left eye). The second\n         is the VR screenshot in the correct format. They should be\n         in the same aspect ratio.  Formats per type:\n         VRScreenshotType_Mono: the VR filename is ignored (can be\n         nullptr), this is a normal flat single shot.\n         VRScreenshotType_Stereo:  The VR image should be a\n         side-by-side with the left eye image on the left.\n         VRScreenshotType_Cubemap: The VR image should be six square\n         images composited horizontally.\n         VRScreenshotType_StereoPanorama: above/below with left eye\n         panorama being the above image.  Image is typically square\n         with the panorama being 2x horizontal.\n         \n         Note that the VR dashboard will call this function when\n         the user presses the screenshot binding (currently System\n         Button + Trigger).  If Steam is running, the destination\n         file names will be in %TEMP% and will be copied into\n         Steam's screenshot library for the running application\n         once SubmitScreenshot() is called.\n         If Steam is not running, the paths will be in the user's\n         documents folder under Documents\\SteamVR\\Screenshots.\n         Other VR applications can call this to initiate a\n         screenshot outside of user control.\n         The destination file names do not need an extension,\n         will be replaced with the correct one for the format\n         which is currently .png.\n        \"\"\"\n\n        fn = self.function_table.requestScreenshot\n        pOutScreenshotHandle = ScreenshotHandle_t()\n        result = fn(byref(pOutScreenshotHandle), type_, pchPreviewFilename, pchVRFilename)\n        return result, pOutScreenshotHandle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hookScreenshot(self, numTypes):\n\n        fn = self.function_table.hookScreenshot\n        pSupportedTypes = EVRScreenshotType()\n        result = fn(byref(pSupportedTypes), numTypes)\n        return result, pSupportedTypes", "response": "Hook screenshots that are being used by the running application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getScreenshotPropertyType(self, screenshotHandle):\n\n        fn = self.function_table.getScreenshotPropertyType\n        pError = EVRScreenshotError()\n        result = fn(screenshotHandle, byref(pError))\n        return result, pError", "response": "Returns the type of screenshot that is specified by the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the filename for the preview or vr image.", "response": "def getScreenshotPropertyFilename(self, screenshotHandle, filenameType, pchFilename, cchFilename):\n        \"\"\"\n        Get the filename for the preview or vr image (see\n         vr::EScreenshotPropertyFilenames).  The return value is\n         the size of the string.\n        \"\"\"\n\n        fn = self.function_table.getScreenshotPropertyFilename\n        pError = EVRScreenshotError()\n        result = fn(screenshotHandle, filenameType, pchFilename, cchFilename, byref(pError))\n        return result, pError"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the progress of a screenshot.", "response": "def updateScreenshotProgress(self, screenshotHandle, flProgress):\n        \"\"\"\n        Call this if the application is taking the screen shot\n         will take more than a few ms processing. This will result\n         in an overlay being presented that shows a completion\n         bar.\n        \"\"\"\n\n        fn = self.function_table.updateScreenshotProgress\n        result = fn(screenshotHandle, flProgress)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntell the compositor to take an internal screenshot of type VRScreenshotType_Stereo. It will take the current submitted scene textures of the running application and write them into the preview image and a side-by-side file for the VR image. This is similar to request screenshot, but doesn't ever talk to the application, just takes the shot and submits.", "response": "def takeStereoScreenshot(self, pchPreviewFilename, pchVRFilename):\n        \"\"\"\n        Tells the compositor to take an internal screenshot of\n         type VRScreenshotType_Stereo. It will take the current\n         submitted scene textures of the running application and\n         write them into the preview image and a side-by-side file\n         for the VR image.\n         This is similar to request screenshot, but doesn't ever\n         talk to the application, just takes the shot and submits.\n        \"\"\"\n\n        fn = self.function_table.takeStereoScreenshot\n        pOutScreenshotHandle = ScreenshotHandle_t()\n        result = fn(byref(pOutScreenshotHandle), pchPreviewFilename, pchVRFilename)\n        return result, pOutScreenshotHandle"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submitScreenshot(self, screenshotHandle, type_, pchSourcePreviewFilename, pchSourceVRFilename):\n\n        fn = self.function_table.submitScreenshot\n        result = fn(screenshotHandle, type_, pchSourcePreviewFilename, pchSourceVRFilename)\n        return result", "response": "Submit the completed screenshot.  If Steam is running\n         this will call into the Steam client and upload the\n         screenshot to the screenshots section of the library for\n         the running application.  If Steam is not running, this\n         function will display a notification to the user that the\n         screenshot was taken. The paths should be full paths with\n         extensions.\n         File paths should be absolute including extensions.\n         screenshotHandle can be k_unScreenshotHandleInvalid if this\n         was a new shot taking by the app to be saved and not\n         initiated by a user (achievement earned or something)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadSharedResource(self, pchResourceName, pchBuffer, unBufferLen):\n\n        fn = self.function_table.loadSharedResource\n        result = fn(pchResourceName, pchBuffer, unBufferLen)\n        return result", "response": "Loads the specified resource into the provided buffer if large enough. Returns the size in bytes of the buffer required to hold the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getResourceFullPath(self, pchResourceName, pchResourceTypeDirectory, pchPathBuffer, unBufferLen):\n\n        fn = self.function_table.getResourceFullPath\n        result = fn(pchResourceName, pchResourceTypeDirectory, pchPathBuffer, unBufferLen)\n        return result", "response": "Provides the full path to the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getDriverName(self, nDriver, pchValue, unBufferSize):\n\n        fn = self.function_table.getDriverName\n        result = fn(nDriver, pchValue, unBufferSize)\n        return result", "response": "Returns the length of the string required to hold this string including the trailing null."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the path to the action manifest JSON file that is used by this application. This is only used for the Steam partner site.", "response": "def setActionManifestPath(self, pchActionManifestPath):\n        \"\"\"\n        Sets the path to the action manifest JSON file that is used by this application. If this information\n        was set on the Steam partner site, calls to this function are ignored. If the Steam partner site\n        setting and the path provided by this call are different, VRInputError_MismatchedActionManifest is returned. \n        This call must be made before the first call to UpdateActionState or IVRSystem::PollNextEvent.\n        \"\"\"\n\n        fn = self.function_table.setActionManifestPath\n        result = fn(pchActionManifestPath)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a handle for an action set. This handle is used for all performance - sensitive calls. This handle is used for all performance - sensitive calls.", "response": "def getActionSetHandle(self, pchActionSetName):\n        \"\"\"Returns a handle for an action set. This handle is used for all performance-sensitive calls.\"\"\"\n\n        fn = self.function_table.getActionSetHandle\n        pHandle = VRActionSetHandle_t()\n        result = fn(pchActionSetName, byref(pHandle))\n        return result, pHandle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a handle for an action. This handle is used for all performance - sensitive calls.", "response": "def getActionHandle(self, pchActionName):\n        \"\"\"Returns a handle for an action. This handle is used for all performance-sensitive calls.\"\"\"\n\n        fn = self.function_table.getActionHandle\n        pHandle = VRActionHandle_t()\n        result = fn(pchActionName, byref(pHandle))\n        return result, pHandle"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getInputSourceHandle(self, pchInputSourcePath):\n\n        fn = self.function_table.getInputSourceHandle\n        pHandle = VRInputValueHandle_t()\n        result = fn(pchInputSourcePath, byref(pHandle))\n        return result, pHandle", "response": "Returns a handle for any path in the input system. Eg. / user. hand. right"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the current state of all action sets and updates the state of all the action sets in the action set to unSetCount. Returns a tuple of the result and the action sets in the action set.", "response": "def updateActionState(self, unSizeOfVRSelectedActionSet_t, unSetCount):\n        \"\"\"\n        Reads the current state into all actions. After this call, the results of Get*Action calls \n        will be the same until the next call to UpdateActionState.\n        \"\"\"\n\n        fn = self.function_table.updateActionState\n        pSets = VRActiveActionSet_t()\n        result = fn(byref(pSets), unSizeOfVRSelectedActionSet_t, unSetCount)\n        return result, pSets"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDigitalActionData(self, action, unActionDataSize, ulRestrictToDevice):\n\n        fn = self.function_table.getDigitalActionData\n        pActionData = InputDigitalActionData_t()\n        result = fn(action, byref(pActionData), unActionDataSize, ulRestrictToDevice)\n        return result, pActionData", "response": "Reads the state of a digital action given its handle. This will return VRInputError_WrongType if the type of action is not a digital action. This will return VRInputError_WrongType if the type of action is not a digital action."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the state of an analog action given its handle. This will return VRInputError_WrongType if the type of action is not an analog action. This will return VRInputError_WrongType if the type of action is not an analog action.", "response": "def getAnalogActionData(self, action, unActionDataSize, ulRestrictToDevice):\n        \"\"\"\n        Reads the state of an analog action given its handle. This will return VRInputError_WrongType if the type of\n        action is something other than analog\n        \"\"\"\n\n        fn = self.function_table.getAnalogActionData\n        pActionData = InputAnalogActionData_t()\n        result = fn(action, byref(pActionData), unActionDataSize, ulRestrictToDevice)\n        return result, pActionData"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the state of a pose action given its handle.", "response": "def getPoseActionData(self, action, eOrigin, fPredictedSecondsFromNow, unActionDataSize, ulRestrictToDevice):\n        \"\"\"Reads the state of a pose action given its handle.\"\"\"\n\n        fn = self.function_table.getPoseActionData\n        pActionData = InputPoseActionData_t()\n        result = fn(action, eOrigin, fPredictedSecondsFromNow, byref(pActionData), unActionDataSize, ulRestrictToDevice)\n        return result, pActionData"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the state of a skeletal action given its handle. Returns 0 if the action is not in the skeletal state and unActionDataSize otherwise.", "response": "def getSkeletalActionData(self, action, unActionDataSize):\n        \"\"\"Reads the state of a skeletal action given its handle.\"\"\"\n\n        fn = self.function_table.getSkeletalActionData\n        pActionData = InputSkeletalActionData_t()\n        result = fn(action, byref(pActionData), unActionDataSize)\n        return result, pActionData"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the number of bones in skeleton associated with the given action", "response": "def getBoneCount(self, action):\n        \"\"\"Reads the number of bones in skeleton associated with the given action\"\"\"\n\n        fn = self.function_table.getBoneCount\n        pBoneCount = c_uint32()\n        result = fn(action, byref(pBoneCount))\n        return result, pBoneCount.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getBoneHierarchy(self, action, unIndexArayCount):\n\n        fn = self.function_table.getBoneHierarchy\n        pParentIndices = BoneIndex_t()\n        result = fn(action, byref(pParentIndices), unIndexArayCount)\n        return result, pParentIndices", "response": "Fills the given array with the index of each bone s parent in the skeleton associated with the given action"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getBoneName(self, action, nBoneIndex, pchBoneName, unNameBufferSize):\n\n        fn = self.function_table.getBoneName\n        result = fn(action, nBoneIndex, pchBoneName, unNameBufferSize)\n        return result", "response": "Fills the given buffer with the name of the bone at the given index in the skeleton associated with the given action. The buffer is unNameBufferSize bytes that can be used to fill up the buffer with the name of the bone at the given index in the skeleton associated with the given action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfill the given buffer with the transforms for a specific static skeletal reference pose", "response": "def getSkeletalReferenceTransforms(self, action, eTransformSpace, eReferencePose, unTransformArrayCount):\n        \"\"\"Fills the given buffer with the transforms for a specific static skeletal reference pose\"\"\"\n\n        fn = self.function_table.getSkeletalReferenceTransforms\n        pTransformArray = VRBoneTransform_t()\n        result = fn(action, eTransformSpace, eReferencePose, byref(pTransformArray), unTransformArrayCount)\n        return result, pTransformArray"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSkeletalTrackingLevel(self, action):\n\n        fn = self.function_table.getSkeletalTrackingLevel\n        pSkeletalTrackingLevel = EVRSkeletalTrackingLevel()\n        result = fn(action, byref(pSkeletalTrackingLevel))\n        return result, pSkeletalTrackingLevel", "response": "Reads the level of accuracy to which the controller is able to recreate a skeletal pose"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSkeletalBoneData(self, action, eTransformSpace, eMotionRange, unTransformArrayCount):\n\n        fn = self.function_table.getSkeletalBoneData\n        pTransformArray = VRBoneTransform_t()\n        result = fn(action, eTransformSpace, eMotionRange, byref(pTransformArray), unTransformArrayCount)\n        return result, pTransformArray", "response": "Reads the state of the skeletal bone data associated with this action and copies it into the given buffer. Returns 0 if the action is not a skeletal bone and untransformArrayCount if the action is not a skeletal bone."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getSkeletalSummaryData(self, action):\n\n        fn = self.function_table.getSkeletalSummaryData\n        pSkeletalSummaryData = VRSkeletalSummaryData_t()\n        result = fn(action, byref(pSkeletalSummaryData))\n        return result, pSkeletalSummaryData", "response": "Reads summary information about the current pose of the skeleton associated with the given action. Returns false if the action is not a skeleton."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSkeletalBoneDataCompressed(self, action, eMotionRange, pvCompressedData, unCompressedSize):\n\n        fn = self.function_table.getSkeletalBoneDataCompressed\n        punRequiredCompressedSize = c_uint32()\n        result = fn(action, eMotionRange, pvCompressedData, unCompressedSize, byref(punRequiredCompressedSize))\n        return result, punRequiredCompressedSize.value", "response": "Reads the state of the skeletal bone data in a compressed form that can be sent over the network."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decompressSkeletalBoneData(self, pvCompressedBuffer, unCompressedBufferSize, eTransformSpace, unTransformArrayCount):\n\n        fn = self.function_table.decompressSkeletalBoneData\n        pTransformArray = VRBoneTransform_t()\n        result = fn(pvCompressedBuffer, unCompressedBufferSize, eTransformSpace, byref(pTransformArray), unTransformArrayCount)\n        return result, pTransformArray", "response": "Turns a compressed buffer from GetSkeletalBoneDataCompressed and turns it back into a bone transform array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrigger a haptic vibration action as described by the specified action.", "response": "def triggerHapticVibrationAction(self, action, fStartSecondsFromNow, fDurationSeconds, fFrequency, fAmplitude, ulRestrictToDevice):\n        \"\"\"Triggers a haptic event as described by the specified action\"\"\"\n\n        fn = self.function_table.triggerHapticVibrationAction\n        result = fn(action, fStartSecondsFromNow, fDurationSeconds, fFrequency, fAmplitude, ulRestrictToDevice)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getActionOrigins(self, actionSetHandle, digitalActionHandle, originOutCount):\n\n        fn = self.function_table.getActionOrigins\n        originsOut = VRInputValueHandle_t()\n        result = fn(actionSetHandle, digitalActionHandle, byref(originsOut), originOutCount)\n        return result, originsOut", "response": "Retrieve the origin handles for an action set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the origin in the current language.", "response": "def getOriginLocalizedName(self, origin, pchNameArray, unNameArraySize, unStringSectionsToInclude):\n        \"\"\"\n        Retrieves the name of the origin in the current language. unStringSectionsToInclude is a bitfield of values in EVRInputStringBits that allows the \n        application to specify which parts of the origin's information it wants a string for.\n        \"\"\"\n\n        fn = self.function_table.getOriginLocalizedName\n        result = fn(origin, pchNameArray, unNameArraySize, unStringSectionsToInclude)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getOriginTrackedDeviceInfo(self, origin, unOriginInfoSize):\n\n        fn = self.function_table.getOriginTrackedDeviceInfo\n        pOriginInfo = InputOriginInfo_t()\n        result = fn(origin, byref(pOriginInfo), unOriginInfoSize)\n        return result, pOriginInfo", "response": "Retrieves useful information for the origin of this action"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef showActionOrigins(self, actionSetHandle, ulActionHandle):\n\n        fn = self.function_table.showActionOrigins\n        result = fn(actionSetHandle, ulActionHandle)\n        return result", "response": "Shows the current binding for the action in - headset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the current binding all the actions in the specified action sets.", "response": "def showBindingsForActionSet(self, unSizeOfVRSelectedActionSet_t, unSetCount, originToHighlight):\n        \"\"\"Shows the current binding all the actions in the specified action sets\"\"\"\n\n        fn = self.function_table.showBindingsForActionSet\n        pSets = VRActiveActionSet_t()\n        result = fn(byref(pSets), unSizeOfVRSelectedActionSet_t, unSetCount, originToHighlight)\n        return result, pSets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening an existing IOBuffer of unSize bytes", "response": "def open(self, pchPath, mode, unElementSize, unElements):\n        \"\"\"opens an existing or creates a new IOBuffer of unSize bytes\"\"\"\n\n        fn = self.function_table.open\n        pulBuffer = IOBufferHandle_t()\n        result = fn(pchPath, mode, unElementSize, unElements, byref(pulBuffer))\n        return result, pulBuffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self, ulBuffer):\n\n        fn = self.function_table.close\n        result = fn(ulBuffer)\n        return result", "response": "closes a previously opened or created buffer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, ulBuffer, pDst, unBytes):\n\n        fn = self.function_table.read\n        punRead = c_uint32()\n        result = fn(ulBuffer, pDst, unBytes, byref(punRead))\n        return result, punRead.value", "response": "reads up to unBytes from buffer into pDst returning the number of bytes read in punRead"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites unBytes of data from * pSrc into a buffer. Returns 0 if success.", "response": "def write(self, ulBuffer, pSrc, unBytes):\n        \"\"\"writes unBytes of data from *pSrc into a buffer.\"\"\"\n\n        fn = self.function_table.write\n        result = fn(ulBuffer, pSrc, unBytes)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef propertyContainer(self, ulBuffer):\n\n        fn = self.function_table.propertyContainer\n        result = fn(ulBuffer)\n        return result", "response": "retrieves the property container of an buffer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hasReaders(self, ulBuffer):\n\n        fn = self.function_table.hasReaders\n        result = fn(ulBuffer)\n        return result", "response": "inexpensively checks for readers to allow fast - fail potentially expensive copies and writes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new spatial anchor from the given descriptor.", "response": "def createSpatialAnchorFromDescriptor(self, pchDescriptor):\n        \"\"\"\n        Returns a handle for an spatial anchor described by \"descriptor\".  On success, pHandle\n        will contain a handle valid for this session.  Caller can wait for an event or occasionally\n        poll GetSpatialAnchorPose() to find the virtual coordinate associated with this anchor.\n        \"\"\"\n\n        fn = self.function_table.createSpatialAnchorFromDescriptor\n        pHandleOut = SpatialAnchorHandle_t()\n        result = fn(pchDescriptor, byref(pHandleOut))\n        return result, pHandleOut"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new spatial anchor at the specified position.", "response": "def createSpatialAnchorFromPose(self, unDeviceIndex, eOrigin):\n        \"\"\"\n        Returns a handle for an new spatial anchor at pPose.  On success, pHandle\n        will contain a handle valid for this session.  Caller can wait for an event or occasionally\n        poll GetSpatialAnchorDescriptor() to find the permanent descriptor for this pose.\n        The result of GetSpatialAnchorPose() may evolve from this initial position if the driver chooses\n        to update it.\n        The anchor will be associated with the driver that provides unDeviceIndex, and the driver may use that specific\n        device as a hint for how to best create the anchor.\n        The eOrigin must match whatever tracking origin you are working in (seated/standing/raw).\n        This should be called when the user is close to (and ideally looking at/interacting with) the target physical\n        location.  At that moment, the driver will have the most information about how to recover that physical point\n        in the future, and the quality of the anchor (when the descriptor is re-used) will be highest.\n        The caller may decide to apply offsets from this initial pose, but is advised to stay relatively close to the \n        original pose location for highest fidelity.\n        \"\"\"\n\n        fn = self.function_table.createSpatialAnchorFromPose\n        pPose = SpatialAnchorPose_t()\n        pHandleOut = SpatialAnchorHandle_t()\n        result = fn(unDeviceIndex, eOrigin, byref(pPose), byref(pHandleOut))\n        return result, pPose, pHandleOut"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the pose for a given handle.", "response": "def getSpatialAnchorPose(self, unHandle, eOrigin):\n        \"\"\"\n        Get the pose for a given handle.  This is intended to be cheap enough to call every frame (or fairly often)\n        so that the driver can refine this position when it has more information available.\n        \"\"\"\n\n        fn = self.function_table.getSpatialAnchorPose\n        pPoseOut = SpatialAnchorPose_t()\n        result = fn(unHandle, eOrigin, byref(pPoseOut))\n        return result, pPoseOut"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the descriptor for a given handle. This descriptor will be empty for handles where the driver has not yet built a descriptor for previously saved anchors .", "response": "def getSpatialAnchorDescriptor(self, unHandle, pchDescriptorOut):\n        \"\"\"\n        Get the descriptor for a given handle.  This will be empty for handles where the driver has not\n        yet built a descriptor.  It will be the application-supplied descriptor for previously saved anchors\n        that the application is requesting poses for.  If the driver has called UpdateSpatialAnchorDescriptor()\n        already in this session, it will be the descriptor provided by the driver.\n        Returns true if the descriptor fits into the buffer, else false.  Buffer size should be at least\n        k_unMaxSpatialAnchorDescriptorSize.\n        \"\"\"\n\n        fn = self.function_table.getSpatialAnchorDescriptor\n        punDescriptorBufferLenInOut = c_uint32()\n        result = fn(unHandle, pchDescriptorOut, byref(punDescriptorBufferLenInOut))\n        return result, punDescriptorBufferLenInOut.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering scene one time", "response": "def render_scene(self):\r\n\t\t\"render scene one time\"\r\n\t\tself.canvas.SetCurrent ( self.context )\r\n\t\tself.renderer.render_scene()\r\n\t\t# Done rendering\r\n\t\t# self.canvas.SwapBuffers()\r\n\t\tif self.canvas.IsDoubleBuffered():\r\n\t\t\tself.canvas.SwapBuffers()\r\n\t\t\tprint (\"double buffered\") # Do not want\r\n\t\telse:\r\n\t\t\tpass\r\n\t\t\t# TODO: SwapBuffers() seems required to show on desktop monitor,\r\n\t\t\t# but causes stalling when monitor is slower than VR headset\r\n\t\t\tself.canvas.SwapBuffers()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def close(self):\n        if self._conn is None:\n            return\n        await self._run_operation(self._impl.close)\n        self._conn = None", "response": "Close the cursor now."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def execute(self, sql, *params):\n        if self._echo:\n            logger.info(sql)\n            logger.info(\"%r\", sql)\n        await self._run_operation(self._impl.execute, sql, *params)\n        return self", "response": "Executes the given SQL statement substituting any markers with\n            the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a database query or command against all the parameter sequences in the sequence seq_of_params. Returns a Future that will be completed with the result.", "response": "def executemany(self, sql, *params):\n        \"\"\"Prepare a database query or command and then execute it against\n        all parameter sequences  found in the sequence seq_of_params.\n\n        :param sql: the SQL statement to execute with optional ? parameters\n        :param params: sequence parameters for the markers in the SQL.\n        \"\"\"\n        fut = self._run_operation(self._impl.executemany, sql, *params)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of rows containing no more than size rows used to process results in chunks.", "response": "def fetchmany(self, size):\n        \"\"\"Returns a list of remaining rows, containing no more than size\n        rows, used to process results in chunks. The list will be empty when\n        there are no more rows.\n\n        The default for cursor.arraysize is 1 which is no different than\n        calling fetchone().\n\n        A ProgrammingError exception is raised if no SQL has been executed\n        or if it did not return a result set (e.g. was not a SELECT\n        statement).\n\n        :param size: int, max number of rows to return\n        \"\"\"\n        fut = self._run_operation(self._impl.fetchmany, size)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a result set of tables in the database that match the passed criteria.", "response": "def tables(self, **kw):\n        \"\"\"Creates a result set of tables in the database that match the\n        given criteria.\n\n        :param table: the table tname\n        :param catalog: the catalog name\n        :param schema: the schmea name\n        :param tableType: one of TABLE, VIEW, SYSTEM TABLE ...\n        \"\"\"\n        fut = self._run_operation(self._impl.tables, **kw)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef columns(self, **kw):\n        fut = self._run_operation(self._impl.columns, **kw)\n        return fut", "response": "Returns a result set of column names in specified tables by executing the SQLColumns function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef statistics(self, catalog=None, schema=None, unique=False, quick=True):\n        fut = self._run_operation(self._impl.statistics, catalog=catalog,\n                                  schema=schema, unique=unique, quick=quick)\n        return fut", "response": "Returns a results set of statistics about a single table and the indexes associated with the table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rowIdColumns(self, table, catalog=None, schema=None,  # nopep8\n                     nullable=True):\n        \"\"\"Executes SQLSpecialColumns with SQL_BEST_ROWID which creates a\n        result set of columns that uniquely identify a row\n        \"\"\"\n        fut = self._run_operation(self._impl.rowIdColumns, table,\n                                  catalog=catalog, schema=schema,\n                                  nullable=nullable)\n        return fut", "response": "Executes SQLSpecialColumns with SQL_BEST_ROWID which creates a\n        result set of columns that uniquely identify a row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a result set of column names that make up the primary key for a table by executing the SQLPrimaryKeys function.", "response": "def primaryKeys(self, table, catalog=None, schema=None):  # nopep8\n        \"\"\"Creates a result set of column names that make up the primary key\n        for a table by executing the SQLPrimaryKeys function.\"\"\"\n        fut = self._run_operation(self._impl.primaryKeys, table,\n                                  catalog=catalog, schema=schema)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef foreignKeys(self, *a, **kw):  # nopep8\n        fut = self._run_operation(self._impl.foreignKeys, *a, **kw)\n        return fut", "response": "Executes the SQLForeignKeys function and creates a result set\n        that contains the column names that are foreign keys in the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTypeInfo(self, sql_type):  # nopep8\n        fut = self._run_operation(self._impl.getTypeInfo, sql_type)\n        return fut", "response": "Executes SQLGetTypeInfo a creates a result set with information\n        about the specified data type or all data types supported by the ODBC driver."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef procedures(self, *a, **kw):\n        fut = self._run_operation(self._impl.procedures, *a, **kw)\n        return fut", "response": "Executes SQLProcedures and creates a result set of information\n        about the procedures in the data source."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def dataSources(loop=None, executor=None):\n    loop = loop or asyncio.get_event_loop()\n    sources = await loop.run_in_executor(executor, _dataSources)\n    return sources", "response": "Returns a dictionary mapping available DSNs to their descriptions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose all free connections in pool.", "response": "async def clear(self):\n        \"\"\"Close all free connections in pool.\"\"\"\n        with (await self._cond):\n            while self._free:\n                conn = self._free.popleft()\n                await conn.close()\n            self._cond.notify()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def release(self, conn):\n        assert conn in self._used, (conn, self._used)\n        self._used.remove(conn)\n        if not conn.closed:\n            if self._closing:\n                await conn.close()\n            else:\n                self._free.append(conn)\n            await self._wakeup()", "response": "Release a free connection back to the connection pool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to an ODBC database and return a new Connection object.", "response": "def connect(*, dsn, autocommit=False, ansi=False, timeout=0, loop=None,\n            executor=None, echo=False, after_created=None, **kwargs):\n    \"\"\"Accepts an ODBC connection string and returns a new Connection object.\n\n    The connection string can be passed as the string `str`, as a list of\n    keywords,or a combination of the two.  Any keywords except autocommit,\n    ansi, and timeout are simply added to the connection string.\n\n    :param autocommit bool: False or zero, the default, if True or non-zero,\n        the connection is put into ODBC autocommit mode and statements are\n        committed automatically.\n    :param ansi bool: By default, pyodbc first attempts to connect using\n        the Unicode version of SQLDriverConnectW. If the driver returns IM001\n        indicating it does not support the Unicode version, the ANSI version\n        is tried.\n    :param timeout int: An integer login timeout in seconds, used to set\n        the SQL_ATTR_LOGIN_TIMEOUT attribute of the connection. The default is\n         0  which means the database's default timeout, if any, is use\n    :param after_created callable: support customize configuration after\n        connection is connected.  Must be an async unary function, or leave it\n        as None.\n    \"\"\"\n    return _ContextManager(_connect(dsn=dsn, autocommit=autocommit,\n                           ansi=ansi, timeout=timeout, loop=loop,\n                           executor=executor, echo=echo,\n                           after_created=after_created, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def execute(self, sql, *args):\n        _cursor = await self._execute(self._conn.execute, sql, *args)\n        connection = self\n        cursor = Cursor(_cursor, connection, echo=self._echo)\n        return cursor", "response": "Create a new Cursor object and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning general information about the driver and data source with the given type.", "response": "def getinfo(self, type_):\n        \"\"\"Returns general information about the driver and data source\n        associated with a connection by calling SQLGetInfo and returning its\n        results. See Microsoft's SQLGetInfo documentation for the types of\n        information available.\n\n        :param type_: int, pyodbc.SQL_* constant\n        \"\"\"\n        fut = self._execute(self._conn.getinfo, type_)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister an output converter function that will be called whenever a value with the given SQL type is read from the database.", "response": "def add_output_converter(self, sqltype, func):\n        \"\"\"Register an output converter function that will be called whenever\n        a value with the given SQL type is read from the database.\n\n        :param sqltype: the integer SQL type value to convert, which can\n            be one of the defined standard constants (pyodbc.SQL_VARCHAR)\n            or a database-specific value (e.g. -151 for the SQL Server 2008\n            geometry data type).\n        :param func: the converter function which will be called with a\n            single parameter, the value, and should return the converted\n            value. If the value is NULL, the parameter will be None.\n            Otherwise it will be a Python string.\n        \"\"\"\n        fut = self._execute(self._conn.add_output_converter, sqltype, func)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall SQLSetConnectAttr with the given values.", "response": "def set_attr(self, attr_id, value):\n        \"\"\"Calls SQLSetConnectAttr with the given values.\n\n        :param attr_id: the attribute ID (integer) to set. These are ODBC or\n            driver constants.\n        :parm value: the connection attribute value to set. At this time\n            only integer values are supported.\n        \"\"\"\n        fut = self._execute(self._conn.set_attr, attr_id, value)\n        return fut"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a HTTP GET request.", "response": "def _request_get(self, path, params=None, json=True, url=BASE_URL):\n        \"\"\"Perform a HTTP GET request.\"\"\"\n        url = urljoin(url, path)\n        headers = self._get_request_headers()\n\n        response = requests.get(url, params=params, headers=headers)\n        if response.status_code >= 500:\n\n            backoff = self._initial_backoff\n            for _ in range(self._max_retries):\n                time.sleep(backoff)\n                backoff_response = requests.get(\n                    url, params=params, headers=headers,\n                    timeout=DEFAULT_TIMEOUT)\n                if backoff_response.status_code < 500:\n                    response = backoff_response\n                    break\n                backoff *= 2\n\n        response.raise_for_status()\n        if json:\n            return response.json()\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a HTTP POST request..", "response": "def _request_post(self, path, data=None, params=None, url=BASE_URL):\n        \"\"\"Perform a HTTP POST request..\"\"\"\n        url = urljoin(url, path)\n\n        headers = self._get_request_headers()\n\n        response = requests.post(\n            url, json=data, params=params, headers=headers,\n            timeout=DEFAULT_TIMEOUT)\n        response.raise_for_status()\n        if response.status_code == 200:\n            return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _request_delete(self, path, params=None, url=BASE_URL):\n        url = urljoin(url, path)\n\n        headers = self._get_request_headers()\n\n        response = requests.delete(\n            url, params=params, headers=headers, timeout=DEFAULT_TIMEOUT)\n        response.raise_for_status()\n        if response.status_code == 200:\n            return response.json()", "response": "Perform a HTTP DELETE request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(cls, signed_request, application_secret_key):\n        def decode(encoded):\n            padding = '=' * (len(encoded) % 4)\n            return base64.urlsafe_b64decode(encoded + padding)\n\n        try:\n            encoded_signature, encoded_payload = (str(string) for string in signed_request.split('.', 2))\n            signature = decode(encoded_signature)\n            signed_request_data = json.loads(decode(encoded_payload).decode('utf-8'))\n        except (TypeError, ValueError):\n            raise SignedRequestError(\"Signed request had a corrupt payload\")\n\n        if signed_request_data.get('algorithm', '').upper() != 'HMAC-SHA256':\n            raise SignedRequestError(\"Signed request is using an unknown algorithm\")\n\n        expected_signature = hmac.new(application_secret_key.encode('utf-8'), msg=encoded_payload.encode('utf-8'),\n                                      digestmod=hashlib.sha256).digest()\n        if signature != expected_signature:\n            raise SignedRequestError(\"Signed request signature mismatch\")\n\n        return signed_request_data", "response": "Parse a signed request returning a dictionary describing its payload."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(self):\n        payload = {\n            'algorithm': 'HMAC-SHA256'\n        }\n\n        if self.data:\n            payload['app_data'] = self.data\n\n        if self.page:\n            payload['page'] = {}\n\n            if self.page.id:\n                payload['page']['id'] = self.page.id\n\n            if self.page.is_liked:\n                payload['page']['liked'] = self.page.is_liked\n\n            if self.page.is_admin:\n                payload['page']['admin'] = self.page.is_admin\n\n        if self.user:\n            payload['user'] = {}\n\n            if self.user.country:\n                payload['user']['country'] = self.user.country\n\n            if self.user.locale:\n                payload['user']['locale'] = self.user.locale\n\n            if self.user.age:\n                payload['user']['age'] = {\n                    'min': self.user.age[0],\n                    'max': self.user.age[-1]\n                }\n\n            if self.user.oauth_token:\n\n                if self.user.oauth_token.token:\n                    payload['oauth_token'] = self.user.oauth_token.token\n\n                if self.user.oauth_token.expires_at is None:\n                    payload['expires_in'] = 0\n                else:\n                    payload['expires_in'] = int(time.mktime(self.user.oauth_token.expires_at.timetuple()))\n\n                if self.user.oauth_token.issued_at:\n                    payload['issued_at'] = int(time.mktime(self.user.oauth_token.issued_at.timetuple()))\n\n        if self.user.id:\n            payload['user_id'] = self.user.id\n\n        encoded_payload = base64.urlsafe_b64encode(\n            json.dumps(payload, separators=(',', ':')).encode('utf-8')\n        )\n\n        encoded_signature = base64.urlsafe_b64encode(hmac.new(\n            self.application_secret_key.encode('utf-8'),\n            encoded_payload,\n            hashlib.sha256\n        ).digest())\n\n        return '%(signature)s.%(payload)s' % {\n            'signature': encoded_signature,\n            'payload': encoded_payload\n        }", "response": "Generate a signed request from this instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef for_application(self, id, secret_key, api_version=None):\n        from facepy.utils import get_application_access_token\n\n        access_token = get_application_access_token(id, secret_key, api_version=api_version)\n        return GraphAPI(access_token, version=api_version)", "response": "Initialize GraphAPI with an OAuth access token for an application."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an item from the Graph API.", "response": "def get(self, path='', page=False, retry=3, **options):\n        \"\"\"\n        Get an item from the Graph API.\n\n        :param path: A string describing the path to the item.\n        :param page: A boolean describing whether to return a generator that\n                     iterates over each page of results.\n        :param retry: An integer describing how many times the request may be retried.\n        :param options: Graph API parameters such as 'limit', 'offset' or 'since'.\n\n        Floating-point numbers will be returned as :class:`decimal.Decimal`\n        instances.\n\n        See `Facebook's Graph API documentation <http://developers.facebook.com/docs/reference/api/>`_\n        for an exhaustive list of parameters.\n        \"\"\"\n        response = self._query(\n            method='GET',\n            path=path,\n            data=options,\n            page=page,\n            retry=retry\n        )\n\n        if response is False:\n            raise FacebookError('Could not get \"%s\".' % path)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nposts an item to the Graph API.", "response": "def post(self, path='', retry=0, **data):\n        \"\"\"\n        Post an item to the Graph API.\n\n        :param path: A string describing the path to the item.\n        :param retry: An integer describing how many times the request may be retried.\n        :param data: Graph API parameters such as 'message' or 'source'.\n\n        See `Facebook's Graph API documentation <http://developers.facebook.com/docs/reference/api/>`_\n        for an exhaustive list of options.\n        \"\"\"\n        response = self._query(\n            method='POST',\n            path=path,\n            data=data,\n            retry=retry\n        )\n\n        if response is False:\n            raise FacebookError('Could not post to \"%s\"' % path)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for an item in the Graph API.", "response": "def search(self, term, type='place', page=False, retry=3, **options):\n        \"\"\"\n        Search for an item in the Graph API.\n\n        :param term: A string describing the search term.\n        :param type: A string describing the type of items to search for.\n        :param page: A boolean describing whether to return a generator that\n                     iterates over each page of results.\n        :param retry: An integer describing how many times the request may be retried.\n        :param options: Graph API parameters, such as 'center' and 'distance'.\n\n        Supported types are only ``place`` since Graph API 2.0.\n\n        See `Facebook's Graph API documentation <http://developers.facebook.com/docs/reference/api/>`_\n        for an exhaustive list of options.\n        \"\"\"\n\n        if type != 'place':\n            raise ValueError('Unsupported type \"%s\". The only supported type is \"place\" since Graph API 2.0.' % type)\n\n        options = dict({\n            'q': term,\n            'type': type,\n        }, **options)\n\n        response = self._query('GET', 'search', options, page, retry)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a list of requests and yields a list of responses and exceptions.", "response": "def batch(self, requests):\n        \"\"\"\n        Make a batch request.\n\n        :param requests: A list of dictionaries with keys 'method', 'relative_url' and optionally 'body'.\n\n        Yields a list of responses and/or exceptions.\n        \"\"\"\n\n        for request in requests:\n            if 'body' in request:\n                request['body'] = urlencode(request['body'])\n\n        def _grouper(complete_list, n=1):\n            \"\"\"\n            Batches a list into constant size chunks.\n\n            :param complete_list: A input list (not a generator).\n            :param n: The size of the chunk.\n\n            Adapted from <http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python>\n            \"\"\"\n\n            for i in range(0, len(complete_list), n):\n                yield complete_list[i:i + n]\n\n        responses = []\n\n        # Maximum batch size for Facebook is 50 so split up requests\n        # https://developers.facebook.com/docs/graph-api/making-multiple-requests/#limits\n        for group in _grouper(requests, 50):\n            responses += self.post(\n                batch=json.dumps(group)\n            )\n\n        for response, request in zip(responses, requests):\n\n            # Facilitate for empty Graph API responses.\n            #\n            # https://github.com/jgorset/facepy/pull/30\n            if not response:\n                yield None\n                continue\n\n            try:\n                yield self._parse(response['body'])\n            except FacepyError as exception:\n                exception.request = request\n                yield exception"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _query(self, method, path, data=None, page=False, retry=0):\n\n        if(data):\n            data = dict(\n                (k.replace('_sqbro_', '['), v) for k, v in data.items())\n            data = dict(\n                (k.replace('_sqbrc_', ']'), v) for k, v in data.items())\n            data = dict(\n                (k.replace('__', ':'), v) for k, v in data.items())\n        data = data or {}\n\n        def load(method, url, data):\n            for key in data:\n                value = data[key]\n\n                if isinstance(value, (list, dict, set)):\n                    data[key] = json.dumps(value)\n\n            try:\n                if method in ['GET', 'DELETE']:\n                    response = self.session.request(\n                        method, url, params=data, allow_redirects=True,\n                        verify=self.verify_ssl_certificate, timeout=self.timeout\n                    )\n\n                if method in ['POST', 'PUT']:\n                    files = {}\n\n                    for key in data:\n                        if hasattr(data[key], 'read'):\n                            files[key] = data[key]\n\n                    for key in files:\n                        data.pop(key)\n\n                    response = self.session.request(\n                        method, url, data=data, files=files,\n                        verify=self.verify_ssl_certificate, timeout=self.timeout\n                    )\n\n                if 500 <= response.status_code < 600:\n                    # Facebook 5XX errors usually come with helpful messages\n                    # as a JSON object describing the problem with the request.\n                    # If this is the case, an error will be raised and we just\n                    # need to re-raise it. This is most likely to happen\n                    # with the Ads API.\n                    # This will raise an exception if a JSON-like error object\n                    # comes in the response.\n                    self._parse(response.content)\n                    # If Facebook does not provide any JSON-formatted error\n                    # but just a plain-text, useless error, we'll just inform\n                    # about a Facebook Internal errror occurred.\n                    raise FacebookError(\n                        'Internal Facebook error occurred',\n                        response.status_code\n                    )\n\n            except requests.RequestException as exception:\n                raise HTTPError(exception)\n\n            result = self._parse(response.content)\n            if isinstance(result, dict):\n                result['headers'] = response.headers\n\n            try:\n                next_url = result['paging']['next']\n            except (KeyError, TypeError):\n                next_url = None\n\n            return result, next_url\n\n        def load_with_retry(method, url, data):\n            remaining_retries = retry\n            while True:\n                try:\n                    return load(method, url, data)\n                except FacepyError as e:\n                    log.warn(\"Exception on %s: %s, retries remaining: %s\",\n                             url,\n                             e,\n                             remaining_retries,\n                             )\n                    if remaining_retries > 0:\n                        remaining_retries -= 1\n                    else:\n                        raise\n\n        def paginate(method, url, data):\n            while url:\n                result, url = load_with_retry(method, url, data)\n\n                # Reset pagination parameters.\n                for key in ['offset', 'until', 'since']:\n                    if key in data:\n                        del data[key]\n\n                yield result\n\n        # Convert option lists to comma-separated values.\n        for key in data:\n            if isinstance(data[key], (list, set, tuple)) and all([isinstance(item, six.string_types) for item in data[key]]):\n                data[key] = ','.join(data[key])\n\n        # Support absolute paths too\n        if not path.startswith('/'):\n            if six.PY2:\n                path = '/' + six.text_type(path.decode('utf-8'))\n            else:\n                path = '/' + path\n\n        url = self._get_url(path)\n\n        if self.oauth_token:\n            data['access_token'] = self.oauth_token\n\n        if self.appsecret and self.oauth_token:\n            data['appsecret_proof'] = self._generate_appsecret_proof()\n\n        if page:\n            return paginate(method, url, data)\n        else:\n            return load_with_retry(method, url, data)[0]", "response": "Fetch an object from the Graph API and parse the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse(self, data):\n        if type(data) == type(bytes()):\n            try:\n                data = data.decode('utf-8')\n            except UnicodeDecodeError:\n                return data\n\n        try:\n            data = json.loads(data, parse_float=Decimal)\n        except ValueError:\n            return data\n\n        # Facebook's Graph API sometimes responds with 'true' or 'false'. Facebook offers no documentation\n        # as to the prerequisites for this type of response, though it seems that it responds with 'true'\n        # when objects are successfully deleted and 'false' upon attempting to delete or access an item that\n        # one does not have access to.\n        #\n        # For example, the API would respond with 'false' upon attempting to query a feed item without having\n        # the 'read_stream' extended permission. If you were to query the entire feed, however, it would respond\n        # with an empty list instead.\n        #\n        # Genius.\n        #\n        # We'll handle this discrepancy as gracefully as we can by implementing logic to deal with this behavior\n        # in the high-level access functions (get, post, delete etc.).\n        if type(data) is dict:\n            if 'error' in data:\n                error = data['error']\n\n                if error.get('type') == \"OAuthException\":\n                    exception = OAuthError\n                else:\n                    exception = FacebookError\n\n                raise exception(**self._get_error_params(data))\n\n            # Facebook occasionally reports errors in its legacy error format.\n            if 'error_msg' in data:\n                raise FacebookError(**self._get_error_params(data))\n\n        return data", "response": "Parse the response from Facebook s Graph API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the appsecret proof of the user s access token.", "response": "def _generate_appsecret_proof(self):\n        \"\"\"\n        Returns a SHA256 of the oauth_token signed by appsecret.\n        https://developers.facebook.com/docs/graph-api/securing-requests/\n        \"\"\"\n        if six.PY2:\n            key = self.appsecret\n            message = self.oauth_token\n        else:\n            key = bytes(self.appsecret, 'utf-8')\n            message = bytes(self.oauth_token, 'utf-8')\n\n        return hmac.new(key, message, hashlib.sha256).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_extended_access_token(access_token, application_id, application_secret_key, api_version=None):\n    graph = GraphAPI(version=api_version)\n\n    response = graph.get(\n        path='oauth/access_token',\n        client_id=application_id,\n        client_secret=application_secret_key,\n        grant_type='fb_exchange_token',\n        fb_exchange_token=access_token\n    )\n\n    try:\n        components = parse_qs(response)\n    except AttributeError:  # api_version >= 2.3 returns a dict\n        return response['access_token'], None\n\n    token = components['access_token'][0]\n\n    try:\n        expires_at = datetime.now() + timedelta(seconds=int(components['expires'][0]))\n    except KeyError:  # there is no expiration\n        expires_at = None\n\n    return token, expires_at", "response": "Get an extended OAuth access token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_application_access_token(application_id, application_secret_key, api_version=None):\n    graph = GraphAPI(version=api_version)\n\n    response = graph.get(\n        path='oauth/access_token',\n        client_id=application_id,\n        client_secret=application_secret_key,\n        grant_type='client_credentials'\n    )\n\n    try:\n        data = parse_qs(response)\n\n        try:\n            return data['access_token'][0]\n        except KeyError:\n            raise GraphAPI.FacebookError('No access token given')\n    except AttributeError:  # api_version >= 2.3 returns a dict\n        return response['access_token'], None", "response": "Get an OAuth access token for the given application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a given key from the cache or set it to the given value.", "response": "def locked_get_or_set(self, key, value_creator, version=None,\n                          expire=None, id=None, lock_key=None,\n                          timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        Fetch a given key from the cache. If the key does not exist, the key is added and\n        set to the value returned when calling `value_creator`. The creator function\n        is invoked inside of a lock.\n        \"\"\"\n        if lock_key is None:\n            lock_key = 'get_or_set:' + key\n\n        val = self.get(key, version=version)\n        if val is not None:\n            return val\n\n        with self.lock(lock_key, expire=expire, id=id):\n            # Was the value set while we were trying to acquire the lock?\n            val = self.get(key, version=version)\n            if val is not None:\n                return val\n\n            # Nope, create value now.\n            val = value_creator()\n\n            if val is None:\n                raise ValueError('`value_creator` must return a value')\n\n            self.set(key, val, timeout=timeout, version=version)\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _eval_script(redis, script_id, *keys, **kwargs):\n    args = kwargs.pop('args', ())\n    if kwargs:\n        raise TypeError(\"Unexpected keyword arguments %s\" % kwargs.keys())\n    try:\n        return redis.evalsha(SCRIPTS[script_id], len(keys), *keys + args)\n    except NoScriptError:\n        logger.info(\"%s not cached.\", SCRIPTS[script_id + 2])\n        return redis.eval(SCRIPTS[script_id + 1], len(keys), *keys + args)", "response": "Tries to call EVALSHA with the script and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nacquire a lock from the cache.", "response": "def acquire(self, blocking=True, timeout=None):\n        \"\"\"\n        :param blocking:\n            Boolean value specifying whether lock should be blocking or not.\n        :param timeout:\n            An integer value specifying the maximum number of seconds to block.\n        \"\"\"\n        logger.debug(\"Getting %r ...\", self._name)\n\n        if self._held:\n            raise AlreadyAcquired(\"Already acquired from this Lock instance.\")\n\n        if not blocking and timeout is not None:\n            raise TimeoutNotUsable(\"Timeout cannot be used if blocking=False\")\n\n        timeout = timeout if timeout is None else int(timeout)\n        if timeout is not None and timeout <= 0:\n            raise InvalidTimeout(\"Timeout (%d) cannot be less than or equal to 0\" % timeout)\n\n        if timeout and self._expire and timeout > self._expire:\n            raise TimeoutTooLarge(\"Timeout (%d) cannot be greater than expire (%d)\" % (timeout, self._expire))\n\n        busy = True\n        blpop_timeout = timeout or self._expire or 0\n        timed_out = False\n        while busy:\n            busy = not self._client.set(self._name, self._id, nx=True, ex=self._expire)\n            if busy:\n                if timed_out:\n                    return False\n                elif blocking:\n                    timed_out = not self._client.blpop(self._signal, blpop_timeout) and timeout\n                else:\n                    logger.debug(\"Failed to get %r.\", self._name)\n                    return False\n\n        logger.debug(\"Got lock for %r.\", self._name)\n        if self._lock_renewal_interval is not None:\n            self._start_lock_renewer()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends the expiration time of the lock.", "response": "def extend(self, expire=None):\n        \"\"\"Extends expiration time of the lock.\n\n        :param expire:\n            New expiration time. If ``None`` - `expire` provided during\n            lock initialization will be taken.\n        \"\"\"\n        if expire is None:\n            if self._expire is not None:\n                expire = self._expire\n            else:\n                raise TypeError(\n                    \"To extend a lock 'expire' must be provided as an \"\n                    \"argument to extend() method or at initialization time.\"\n                )\n        error = _eval_script(self._client, EXTEND, self._name, args=(expire, self._id))\n        if error == 1:\n            raise NotAcquired(\"Lock %s is not acquired or it already expired.\" % self._name)\n        elif error == 2:\n            raise NotExpirable(\"Lock %s has no assigned expiration time\" %\n                               self._name)\n        elif error:\n            raise RuntimeError(\"Unsupported error code %s from EXTEND script\" % error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _lock_renewer(lockref, interval, stop):\n        log = getLogger(\"%s.lock_refresher\" % __name__)\n        while not stop.wait(timeout=interval):\n            log.debug(\"Refreshing lock\")\n            lock = lockref()\n            if lock is None:\n                log.debug(\"The lock no longer exists, \"\n                          \"stopping lock refreshing\")\n                break\n            lock.extend(expire=lock._expire)\n            del lock\n        log.debug(\"Exit requested, stopping lock refreshing\")", "response": "Renew the lock in redis every interval seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the lock refresher thread.", "response": "def _start_lock_renewer(self):\n        \"\"\"\n        Starts the lock refresher thread.\n        \"\"\"\n        if self._lock_renewal_thread is not None:\n            raise AlreadyStarted(\"Lock refresh thread already started\")\n\n        logger.debug(\n            \"Starting thread to refresh lock every %s seconds\",\n            self._lock_renewal_interval\n        )\n        self._lock_renewal_stop = threading.Event()\n        self._lock_renewal_thread = threading.Thread(\n            group=None,\n            target=self._lock_renewer,\n            kwargs={'lockref': weakref.ref(self),\n                    'interval': self._lock_renewal_interval,\n                    'stop': self._lock_renewal_stop}\n        )\n        self._lock_renewal_thread.setDaemon(True)\n        self._lock_renewal_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _stop_lock_renewer(self):\n        if self._lock_renewal_thread is None or not self._lock_renewal_thread.is_alive():\n            return\n        logger.debug(\"Signalling the lock refresher to stop\")\n        self._lock_renewal_stop.set()\n        self._lock_renewal_thread.join()\n        self._lock_renewal_thread = None\n        logger.debug(\"Lock refresher has stopped\")", "response": "Stop the lock renewer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing the lock that was acquired with the same object.", "response": "def release(self):\n        \"\"\"Releases the lock, that was acquired with the same object.\n\n        .. note::\n\n            If you want to release a lock that you acquired in a different place you have two choices:\n\n            * Use ``Lock(\"name\", id=id_from_other_place).release()``\n            * Use ``Lock(\"name\").reset()``\n        \"\"\"\n        if self._lock_renewal_thread is not None:\n            self._stop_lock_renewer()\n        logger.debug(\"Releasing %r.\", self._name)\n        error = _eval_script(self._client, UNLOCK, self._name, self._signal, args=(self._id,))\n        if error == 1:\n            raise NotAcquired(\"Lock %s is not acquired or it already expired.\" % self._name)\n        elif error:\n            raise RuntimeError(\"Unsupported error code %s from EXTEND script.\" % error)\n        else:\n            self._delete_signal()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bunchify(x):\n    if isinstance(x, dict):\n        return Bunch( (k, bunchify(v)) for k,v in iteritems(x) )\n    elif isinstance(x, (list, tuple)):\n        return type(x)( bunchify(v) for v in x )\n    else:\n        return x", "response": "Recursively transforms a dictionary into a Bunch."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unbunchify(x):\n    if isinstance(x, dict):\n        return dict( (k, unbunchify(v)) for k,v in iteritems(x) )\n    elif isinstance(x, (list, tuple)):\n        return type(x)( unbunchify(v) for v in x )\n    else:\n        return x", "response": "Recursively converts a Bunch into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_detail(self, course_id):\n        # the request is done in behalf of the current logged in user\n        resp = self._requester.get(\n            urljoin(\n                self._base_url,\n                '/api/courses/v1/courses/{course_key}/'.format(course_key=course_id)\n            )\n        )\n\n        resp.raise_for_status()\n\n        return CourseDetail(resp.json())", "response": "Fetches course details.\n\n        Args:\n            course_id (str): An edx course id.\n\n        Returns:\n            CourseDetail"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_user_info(self):\n        # the request is done in behalf of the current logged in user\n        resp = self.requester.get(\n            urljoin(\n                self.base_url,\n                '/api/mobile/v0.5/my_user_info'\n            )\n        )\n\n        resp.raise_for_status()\n\n        return Info(resp.json())", "response": "Returns a UserInfo object representing the student current grades and the current logged in user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the course blocks for a user.", "response": "def course_blocks(self, course_id, username):\n        \"\"\"\n        Fetches course blocks.\n\n        Args:\n            course_id (str): An edx course id.\n            username (str): username of the user to query for (can reveal hidden\n                            modules)\n\n        Returns:\n            Structure\n        \"\"\"\n        resp = self.requester.get(\n            urljoin(self.base_url, '/api/courses/v1/blocks/'),\n            params={\n                \"depth\": \"all\",\n                \"username\": username,\n                \"course_id\": course_id,\n                \"requested_fields\": \"children,display_name,id,type,visible_to_staff_only\",\n            })\n\n        resp.raise_for_status()\n\n        return Structure(resp.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an CurrentGrade object representing the student current grade for the user in a course.", "response": "def get_student_current_grade(self, username, course_id):\n        \"\"\"\n        Returns an CurrentGrade object for the user in a course\n\n        Args:\n            username (str): an edx user's username\n            course_id (str): an edX course id.\n\n        Returns:\n            CurrentGrade: object representing the student current grade for a course\n        \"\"\"\n        # the request is done in behalf of the current logged in user\n        resp = self.requester.get(\n            urljoin(\n                self.base_url,\n                '/api/grades/v1/courses/{course_key}/?username={username}'.format(\n                    username=username,\n                    course_key=course_id\n                )\n            )\n        )\n\n        resp.raise_for_status()\n\n        return CurrentGrade(resp.json()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_student_current_grades(self, username, course_ids=None):\n        # if no course ids are provided, let's get the user enrollments\n        if course_ids is None:\n            enrollments_client = CourseEnrollments(self.requester, self.base_url)\n            enrollments = enrollments_client.get_student_enrollments()\n            course_ids = list(enrollments.get_enrolled_course_ids())\n\n        all_current_grades = []\n        for course_id in course_ids:\n            try:\n                all_current_grades.append(self.get_student_current_grade(username, course_id))\n            except HTTPError as error:\n                if error.response.status_code >= 500:\n                    raise\n\n        return CurrentGradesByUser(all_current_grades)", "response": "Returns a CurrentGradesByUser object representing the student current grades."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a CurrentGradesByCourse object representing the student current grades for all users in the specified course.", "response": "def get_course_current_grades(self, course_id):\n        \"\"\"\n        Returns a CurrentGradesByCourse object for all users in the specified course.\n\n        Args:\n            course_id (str): an edX course ids.\n\n        Returns:\n            CurrentGradesByCourse: object representing the student current grades\n\n        Authorization:\n            The authenticated user must have staff permissions to see grades for all users\n            in a course.\n        \"\"\"\n        resp = self.requester.get(\n            urljoin(\n                self.base_url,\n                '/api/grades/v1/courses/{course_key}/'.format(course_key=course_id)\n            )\n        )\n        resp.raise_for_status()\n        resp_json = resp.json()\n        if 'results' in resp_json:\n            grade_entries = [CurrentGrade(entry) for entry in resp_json[\"results\"]]\n            while resp_json['next'] is not None:\n                resp = self.requester.get(resp_json['next'])\n                resp.raise_for_status()\n                resp_json = resp.json()\n                grade_entries.extend((CurrentGrade(entry) for entry in resp_json[\"results\"]))\n        else:\n            grade_entries = [CurrentGrade(entry) for entry in resp_json]\n\n        return CurrentGradesByCourse(grade_entries)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an object to make authenticated requests.", "response": "def get_requester(self):\n        \"\"\"\n        Returns an object to make authenticated requests. See python `requests` for the API.\n        \"\"\"\n        # TODO(abrahms): Perhaps pull this out into a factory function for\n        # generating an EdxApi instance with the proper requester & credentials.\n        session = requests.session()\n        session.headers.update({\n            'Authorization': 'Bearer {}'.format(self.credentials['access_token'])\n        })\n\n        old_request = session.request\n\n        def patched_request(*args, **kwargs):\n            \"\"\"\n            adds timeout param to session.request\n            \"\"\"\n            return old_request(*args, timeout=self.timeout, **kwargs)\n\n        session.request = patched_request\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a CCX entry in the master course.", "response": "def create(self, master_course_id, coach_email, max_students_allowed, title, modules=None):\n        \"\"\"\n        Creates a CCX\n\n        Args:\n            master_course_id (str): edx course id of the master course\n            coach_email (str): email of the user to make a coach. This user must exist on edx.\n            max_students_allowed (int): Maximum number of students to allow in this ccx.\n            title (str): Title of the CCX to be created\n            modules (optional list): A list of locator_ids (str) for the modules to enable.\n\n        Returns:\n           ccx_id (str): The ID of the ccx.\n        \"\"\"\n        payload = {\n            'master_course_id': master_course_id,\n            'coach_email': coach_email,\n            'max_students_allowed': max_students_allowed,\n            'display_name': title,\n        }\n\n        if modules is not None:\n            payload['course_modules'] = modules\n\n        resp = self.requester.post(\n            parse.urljoin(self.base_url, '/api/ccx/v0/ccx/'),\n            json=payload\n        )\n\n        try:\n            resp.raise_for_status()\n        except:\n            log.error(resp.json())\n            raise\n\n        return resp.json()['ccx_course_id']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubmit request to retrieve course enrollments list page.", "response": "def _get_enrollments_list_page(self, params=None):\n        \"\"\"\n        Submit request to retrieve enrollments list.\n\n        Args:\n            params (dict): Query parameters to use in the request. Valid parameters are:\n                * course_id: Filters the result to course enrollments for the course\n                    corresponding to the given course ID. The value must be URL encoded.\n                    Optional.\n                * username: username: List of comma-separated usernames. Filters the result to the\n                    course enrollments of the given users. Optional.\n        \"\"\"\n        req_url = urljoin(self.base_url, self.enrollment_list_url)\n        resp = self.requester.get(req_url, params=params)\n        resp.raise_for_status()\n        resp_json = resp.json()\n        results = resp_json['results']\n        next_url_str = resp_json.get('next')\n        cursor = None\n        qstr_cursor = None\n        if next_url_str:\n            next_url = urlparse(next_url_str)\n            qstr = parse_qs(next_url.query)\n            qstr_cursor = qstr.get('cursor')\n\n        if qstr_cursor and isinstance(qstr_cursor, list):\n            cursor = qstr_cursor[0]\n\n        return results, cursor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_enrollments(self, course_id=None, usernames=None):\n        params = {}\n        if course_id is not None:\n            params['course_id'] = course_id\n        if usernames is not None and isinstance(usernames, list):\n            params['username'] = ','.join(usernames)\n\n        done = False\n        while not done:\n            enrollments, next_cursor = self._get_enrollments_list_page(params)\n            for enrollment in enrollments:\n                yield Enrollment(enrollment)\n\n            if next_cursor:\n                params['cursor'] = next_cursor\n            else:\n                done = True", "response": "Returns an iterator that returns all course enrollments for a specific course id and usernames."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an Enrollments object representing the student enrollments", "response": "def get_student_enrollments(self):\n        \"\"\"\n        Returns an Enrollments object with the user enrollments\n\n        Returns:\n            Enrollments: object representing the student enrollments\n        \"\"\"\n        # the request is done in behalf of the current logged in user\n        resp = self.requester.get(\n            urljoin(self.base_url, self.enrollment_url))\n        resp.raise_for_status()\n        return Enrollments(resp.json())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an audit enrollment for the user in a given course", "response": "def create_audit_student_enrollment(self, course_id):\n        \"\"\"\n        Creates an audit enrollment for the user in a given course\n\n        Args:\n            course_id (str): an edX course id\n\n        Returns:\n            Enrollment: object representing the student enrollment in the provided course\n        \"\"\"\n        audit_enrollment = {\n            \"mode\": \"audit\",\n            \"course_details\": {\"course_id\": course_id}\n        }\n        # the request is done in behalf of the current logged in user\n        resp = self.requester.post(\n            urljoin(self.base_url, self.enrollment_url),\n            json=audit_enrollment\n        )\n        resp.raise_for_status()\n        return Enrollment(resp.json())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an Certificate object representing the student certificate for a user.", "response": "def get_student_certificate(self, username, course_id):\n        \"\"\"\n        Returns an Certificate object with the user certificates\n\n        Args:\n            username (str): an edx user's username\n            course_id (str): an edX course id.\n\n        Returns:\n            Certificate: object representing the student certificate for a course\n        \"\"\"\n        # the request is done in behalf of the current logged in user\n        resp = self.requester.get(\n            urljoin(\n                self.base_url,\n                '/api/certificates/v0/certificates/{username}/courses/{course_key}/'.format(\n                    username=username,\n                    course_key=course_id\n                )\n            )\n        )\n\n        resp.raise_for_status()\n\n        return Certificate(resp.json())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_student_certificates(self, username, course_ids=None):\n        # if no course ids are provided, let's get the user enrollments\n        if course_ids is None:\n            enrollments_client = CourseEnrollments(self.requester, self.base_url)\n            enrollments = enrollments_client.get_student_enrollments()\n            course_ids = list(enrollments.get_enrolled_course_ids())\n\n        all_certificates = []\n        for course_id in course_ids:\n            try:\n                all_certificates.append(self.get_student_certificate(username, course_id))\n            except HTTPError as error:\n                if error.response.status_code >= 500:\n                    raise\n\n        return Certificates(all_certificates)", "response": "Returns an Certificates object representing the student certificates for a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the image s colors.", "response": "def get_colors(img):\n    \"\"\"\n    Returns a list of all the image's colors.\n    \"\"\"\n    w, h = img.size\n    return [color[:3] for count, color in img.convert('RGB').getcolors(w * h)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclamps a color such that the value is between min_v and max_v.", "response": "def clamp(color, min_v, max_v):\n    \"\"\"\n    Clamps a color such that the value is between min_v and max_v.\n    \"\"\"\n    h, s, v = rgb_to_hsv(*map(down_scale, color))\n    min_v, max_v = map(down_scale, (min_v, max_v))\n    v = min(max(min_v, v), max_v)\n    return tuple(map(up_scale, hsv_to_rgb(h, s, v)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order_by_hue(colors):\n    hsvs = [rgb_to_hsv(*map(down_scale, color)) for color in colors]\n    hsvs.sort(key=lambda t: t[0])\n    return [tuple(map(up_scale, hsv_to_rgb(*hsv))) for hsv in hsvs]", "response": "Orders colors by hue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding or subtracts value to a color.", "response": "def brighten(color, brightness):\n    \"\"\"\n    Adds or subtracts value to a color.\n    \"\"\"\n    h, s, v = rgb_to_hsv(*map(down_scale, color))\n    return tuple(map(up_scale, hsv_to_rgb(h, s, v + down_scale(brightness))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the n most dominant colors of an image.", "response": "def colorz(fd, n=DEFAULT_NUM_COLORS, min_v=DEFAULT_MINV, max_v=DEFAULT_MAXV,\n           bold_add=DEFAULT_BOLD_ADD, order_colors=True):\n    \"\"\"\n    Get the n most dominant colors of an image.\n    Clamps value to between min_v and max_v.\n\n    Creates bold colors using bold_add.\n    Total number of colors returned is 2*n, optionally ordered by hue.\n    Returns as a list of pairs of RGB triples.\n\n    For terminal colors, the hue order is:\n    red, yellow, green, cyan, blue, magenta\n    \"\"\"\n    img = Image.open(fd)\n    img.thumbnail(THUMB_SIZE)\n\n    obs = get_colors(img)\n    clamped = [clamp(color, min_v, max_v) for color in obs]\n    clusters, _ = kmeans(array(clamped).astype(float), n)\n    colors = order_by_hue(clusters) if order_colors else clusters\n    return list(zip(colors, [brighten(c, bold_add) for c in colors]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an HTML preview of each color.", "response": "def html_preview(colors, font_size=DEFAULT_FONT_SIZE,\n                 bg_color=DEFAULT_BG_COLOR, bg_img=None,\n                 fd=None):\n    \"\"\"\n    Creates an HTML preview of each color.\n\n    Returns the Python file object for the HTML file.\n    \"\"\"\n\n    fd = fd or NamedTemporaryFile(mode='wt', suffix='.html', delete=False)\n\n    # Initial CSS styling is empty\n    style = \"\"\n\n    # Create the main body\n    body = '\\n'.join([\"\"\"\n        <div class=\"color\" style=\"color: {color}\">\n            <div>\u2588 {color}</div>\n            <div style=\"color: {color_bold}\">\n                <strong>\u2588 {color_bold}</strong>\n            </div>\n        </div>\n    \"\"\".format(color=hexify(c[0]), color_bold=hexify(c[1])) for c in colors])\n\n    if bg_img:\n        # Check if local or online image\n        if os.path.isfile(bg_img):\n            bg_img = os.path.abspath(bg_img)\n\n        bg_url = \"url('%s')\" % (\n            ('file://%s' % bg_img) if os.path.isfile(bg_img) else bg_img)\n\n        # Add preview box and image to the body\n        body = \"\"\"\n            <div id=\"preview-box\" class=\"box-shadow\">\n                <img id=\"preview-image\" class=\"box-shadow\" src=\"{bg_img}\" />\n                {body}\n            </div>\n        \"\"\".format(**locals())\n\n        # Add blurred background image styling\n        style += \"\"\"\n            body:before {{\n                content: '';\n                position: fixed;\n                z-index: -1;\n                left: 0;\n                right: 0;\n                width: 100%;\n                height: 100%;\n                display: block;\n\n                background-image: {bg_url};\n                background-size: cover;\n                background-repeat: no-repeat;\n                background-position: center center;\n                background-attachment: fixed;\n\n                -webkit-filter: blur(2rem);\n                -moz-filter: blur(2rem);\n                -o-filter: blur(2rem);\n                -ms-filter: blur(2rem);\n                filter: blur(2rem)\n            }}\n        \"\"\".format(**locals())\n\n    # CSS styling\n    style += \"\"\"\n        body {{\n            margin: 0;\n            background: {bg_color};\n\n            font-family: monospace;\n            font-size: {font_size}rem;\n            line-height: 1;\n        }}\n\n        #main-container {{\n            padding: 1rem;\n            text-align: center;\n        }}\n\n        #preview-box {{\n            display: inline-block;\n            margin: 3rem;\n            padding: 1rem;\n            background: {bg_color};\n        }}\n\n        #preview-image {{\n            width: 100%;\n        }}\n\n        .color {{\n            display: inline-block;\n            margin: 1rem;\n        }}\n\n        .box-shadow {{\n            -webkit-box-shadow: 0 0 1em 0 rgba(0, 0, 0, 0.75);\n            -moz-box-shadow:    0 0 1em 0 rgba(0, 0, 0, 0.75);\n            box-shadow:         0 0 1em 0 rgba(0, 0, 0, 0.75);\n        }}\n    \"\"\".format(**locals())\n\n    # Write the file\n    fd.write(\"\"\"\n        <!DOCTYPE html>\n        <html>\n            <head>\n                <title>\n                    Colorscheme Preview\n                </title>\n                <meta charset=\"utf-8\">\n                <style>\n                    {style}\n                </style>\n            </head>\n            <body>\n                <div id=\"main-container\">\n                    {body}\n                </div>\n            </body>\n        </html>\n    \"\"\".format(**locals()))\n\n    return fd"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a RST formated string.", "response": "def long_description(*paths):\n    '''Returns a RST formated string.\n    '''\n    result = ''\n\n    # attempt to import pandoc\n    try:\n        import pypandoc\n    except (ImportError, OSError) as e:\n        print(\"Unable to import pypandoc - %s\" % e)\n        return result\n\n    # attempt md -> rst conversion\n    try:\n        for path in paths:\n            result += '\\n' + pypandoc.convert(\n                path, 'rst', format='markdown'\n            )\n    except (OSError, IOError) as e:\n        print(\"Failed to convert with pypandoc - %s\" % e)\n        return result\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the memory is too full for further caching.", "response": "def memory_full():\n    \"\"\"Check if the memory is too full for further caching.\"\"\"\n    current_process = psutil.Process(os.getpid())\n    return (current_process.memory_percent() >\n            config.MAXIMUM_CACHE_MEMORY_PERCENTAGE)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MICECache(subsystem, parent_cache=None):\n    if config.REDIS_CACHE:\n        cls = RedisMICECache\n    else:\n        cls = DictMICECache\n    return cls(subsystem, parent_cache=parent_cache)", "response": "Construct a |MICE| cache object for the given subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncaches decorator for object-level method caches. Cache key generation is delegated to the cache. Args: cache_name (str): The name of the (already-instantiated) cache on the decorated object which should be used to store results of this method. *key_prefix: A constant to use as part of the cache key in addition to the method arguments.", "response": "def method(cache_name, key_prefix=None):\n    \"\"\"Caching decorator for object-level method caches.\n\n    Cache key generation is delegated to the cache.\n\n    Args:\n        cache_name (str): The name of the (already-instantiated) cache\n            on the decorated object which should be used to store results\n            of this method.\n        *key_prefix: A constant to use as part of the cache key in addition\n            to the method arguments.\n    \"\"\"\n    def decorator(func):\n        if (func.__name__ in ['cause_repertoire', 'effect_repertoire'] and\n                not config.CACHE_REPERTOIRES):\n            return func\n\n        @wraps(func)\n        def wrapper(obj, *args, **kwargs):\n            cache = getattr(obj, cache_name)\n\n            # Delegate key generation\n            key = cache.key(*args, _prefix=key_prefix, **kwargs)\n\n            # Get cached value, or compute\n            value = cache.get(key)\n            if value is None:  # miss\n                value = func(obj, *args, **kwargs)\n                cache.set(key, value)\n            return value\n\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a value out of the cache. Returns None if the key is not in the cache. Returns None if the key is not in the cache.", "response": "def get(self, key):\n        \"\"\"Get a value out of the cache.\n\n        Returns None if the key is not in the cache. Updates cache\n        statistics.\n        \"\"\"\n        if key in self.cache:\n            self.hits += 1\n            return self.cache[key]\n        self.misses += 1\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the cache key for the given function args.", "response": "def key(self, *args, _prefix=None, **kwargs):\n        \"\"\"Get the cache key for the given function args.\n\n        Kwargs:\n           prefix: A constant to prefix to the key.\n        \"\"\"\n        if kwargs:\n            raise NotImplementedError(\n                'kwarg cache keys not implemented')\n        return (_prefix,) + tuple(args)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(self):\n        info = redis_conn.info()\n        return _CacheInfo(info['keyspace_hits'],\n                          info['keyspace_misses'],\n                          self.size())", "response": "Return the information about the current cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a value from the cache.", "response": "def get(self, key):\n        \"\"\"Get a value from the cache.\n\n        Returns None if the key is not in the cache.\n        \"\"\"\n        value = redis_conn.get(key)\n\n        if value is not None:\n            value = pickle.loads(value)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a value in the cache.", "response": "def set(self, key, value):\n        \"\"\"Set a value in the cache.\"\"\"\n        value = pickle.dumps(value, protocol=constants.PICKLE_PROTOCOL)\n        redis_conn.set(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a value from the cache.", "response": "def get(self, key):\n        \"\"\"Get a value from the cache.\n\n        If the |MICE| cannot be found in this cache, try and find it in the\n        parent cache.\n        \"\"\"\n        mice = super().get(key)\n\n        if mice is not None:  # Hit\n            return mice\n\n        # Try and get the key from the parent cache.\n        if self.parent_subsystem_hash:\n            parent_key = key.replace(str(self.subsystem_hash),\n                                     str(self.parent_subsystem_hash), 1)\n            mice = super().get(parent_key)\n\n            if mice is not None and not mice.damaged_by_cut(self.subsystem):\n                return mice\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, key, value):\n        if not self.subsystem.is_cut:\n            super().set(key, value)", "response": "Set the value of the key in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the key for the cache entry.", "response": "def key(self, direction, mechanism, purviews=False, _prefix=None):\n        \"\"\"Cache key. This is the call signature of |Subsystem.find_mice()|.\"\"\"\n        return \"subsys:{}:{}:{}:{}:{}\".format(\n            self.subsystem_hash, _prefix, direction, mechanism, purviews)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the initial cache from the parent.", "response": "def _build(self, parent_cache):\n        \"\"\"Build the initial cache from the parent.\n\n        Only include the |MICE| which are unaffected by the subsystem cut.\n        A |MICE| is affected if either the cut splits the mechanism\n        or splits the connections between the purview and mechanism\n        \"\"\"\n        for key, mice in parent_cache.cache.items():\n            if not mice.damaged_by_cut(self.subsystem):\n                self.cache[key] = mice"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a value in the cache.", "response": "def set(self, key, mice):\n        \"\"\"Set a value in the cache.\n\n        Only cache if:\n          - The subsystem is uncut (caches are only inherited from\n            uncut subsystems so there is no reason to cache on cut\n            subsystems.)\n          - |small_phi| > 0. Ideally we would cache all mice, but the size\n            of the cache grows way too large, making parallel computations\n            incredibly inefficient because the caches have to be passed\n            between process. This will be changed once global caches are\n            implemented.\n          - Memory is not too full.\n        \"\"\"\n        if (not self.subsystem.is_cut and mice.phi > 0 and\n                not memory_full()):\n            self.cache[key] = mice"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the key for the cache.", "response": "def key(self, direction, mechanism, purviews=False, _prefix=None):\n        \"\"\"Cache key. This is the call signature of |Subsystem.find_mice()|.\"\"\"\n        return (_prefix, direction, mechanism, purviews)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, key, value):\n        if config.CACHE_POTENTIAL_PURVIEWS:\n            self.cache[key] = value", "response": "Only set if purview caching is enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves connections to or from external nodes.", "response": "def apply_boundary_conditions_to_cm(external_indices, cm):\n    \"\"\"Remove connections to or from external nodes.\"\"\"\n    cm = cm.copy()\n    cm[external_indices, :] = 0  # Zero-out row\n    cm[:, external_indices] = 0  # Zero-out columnt\n    return cm"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning indices of inputs to the node with the given index.", "response": "def get_inputs_from_cm(index, cm):\n    \"\"\"Return indices of inputs to the node with the given index.\"\"\"\n    return tuple(i for i in range(cm.shape[0]) if cm[i][index])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn indices of the outputs of node with the given index.", "response": "def get_outputs_from_cm(index, cm):\n    \"\"\"Return indices of the outputs of node with the given index.\"\"\"\n    return tuple(i for i in range(cm.shape[0]) if cm[index][i])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef causally_significant_nodes(cm):\n    inputs = cm.sum(0)\n    outputs = cm.sum(1)\n    nodes_with_inputs_and_outputs = np.logical_and(inputs > 0, outputs > 0)\n    return tuple(np.where(nodes_with_inputs_and_outputs)[0])", "response": "Return indices of nodes that have both inputs and outputs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relevant_connections(n, _from, to):\n    cm = np.zeros((n, n))\n\n    # Don't try and index with empty arrays. Older versions of NumPy\n    # (at least up to 1.9.3) break with empty array indices.\n    if not _from or not to:\n        return cm\n\n    cm[np.ix_(_from, to)] = 1\n    return cm", "response": "Construct a connectivity matrix that contains the relevant nodes from _from to."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef block_cm(cm):\n    if np.any(cm.sum(1) == 0):\n        return True\n    if np.all(cm.sum(1) == 1):\n        return True\n\n    outputs = list(range(cm.shape[1]))\n\n    # CM helpers:\n    def outputs_of(nodes):\n        \"\"\"Return all nodes that `nodes` connect to (output to).\"\"\"\n        return np.where(cm[nodes, :].sum(0))[0]\n\n    def inputs_to(nodes):\n        \"\"\"Return all nodes which connect to (input to) `nodes`.\"\"\"\n        return np.where(cm[:, nodes].sum(1))[0]\n\n    # Start: source node with most outputs\n    sources = [np.argmax(cm.sum(1))]\n    sinks = outputs_of(sources)\n    sink_inputs = inputs_to(sinks)\n\n    while True:\n        if np.array_equal(sink_inputs, sources):\n            # sources exclusively connect to sinks.\n            # There are no other nodes which connect sink nodes,\n            # hence set(sources) + set(sinks) form a component\n            # which is not connected to the rest of the graph\n            return True\n\n        # Recompute sources, sinks, and sink_inputs\n        sources = sink_inputs\n        sinks = outputs_of(sources)\n        sink_inputs = inputs_to(sinks)\n\n        # Considering all output nodes?\n        if np.array_equal(sinks, outputs):\n            return False", "response": "Return whether the given connectivity matrix can be arranged as a block of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef block_reducible(cm, nodes1, nodes2):\n    # Trivial case\n    if not nodes1 or not nodes2:\n        return True\n\n    cm = cm[np.ix_(nodes1, nodes2)]\n\n    # Validate the connectivity matrix.\n    if not cm.sum(0).all() or not cm.sum(1).all():\n        return True\n    if len(nodes1) > 1 and len(nodes2) > 1:\n        return block_cm(cm)\n    return False", "response": "Returns True if the connectivity matrix cm is reducible."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest connectivity for the connectivity matrix.", "response": "def _connected(cm, nodes, connection):\n    \"\"\"Test connectivity for the connectivity matrix.\"\"\"\n    if nodes is not None:\n        cm = cm[np.ix_(nodes, nodes)]\n\n    num_components, _ = connected_components(cm, connection=connection)\n    return num_components < 2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_full(cm, nodes1, nodes2):\n    if not nodes1 or not nodes2:\n        return True\n\n    cm = cm[np.ix_(nodes1, nodes2)]\n\n    # Do all nodes have at least one connection?\n    return cm.sum(0).all() and cm.sum(1).all()", "response": "Test connectivity of one set of nodes to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_cut(self, cm):\n        # Invert the cut matrix, creating a matrix of preserved connections\n        inverse = np.logical_not(self.cut_matrix(cm.shape[0])).astype(int)\n        return cm * inverse", "response": "Returns a modified connectivity matrix with all connections that are severed by this cut removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cuts_connections(self, a, b):\n        n = max(self.indices) + 1\n        return self.cut_matrix(n)[np.ix_(a, b)].any()", "response": "Check if this cut severs any connections from a to b."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield all mechanisms with elements on both sides of this cut.", "response": "def all_cut_mechanisms(self):\n        \"\"\"Return all mechanisms with elements on both sides of this cut.\n\n        Yields:\n            tuple[int]: The next cut mechanism.\n        \"\"\"\n        for mechanism in utils.powerset(self.indices, nonempty=True):\n            if self.splits_mechanism(mechanism):\n                yield mechanism"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the matrix that represents the relevant connections severed by this cut.", "response": "def cut_matrix(self, n):\n        \"\"\"Compute the cut matrix for this cut.\n\n        The cut matrix is a square matrix which represents connections severed\n        by the cut.\n\n        Args:\n           n (int): The size of the network.\n\n        Example:\n            >>> cut = Cut((1,), (2,))\n            >>> cut.cut_matrix(3)\n            array([[0., 0., 0.],\n                   [0., 0., 1.],\n                   [0., 0., 0.]])\n        \"\"\"\n        return connectivity.relevant_connections(n, self.from_nodes,\n                                                 self.to_nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a tuple of the nodes of the mechanism in the partition.", "response": "def mechanism(self):\n        \"\"\"tuple[int]: The nodes of the mechanism in the partition.\"\"\"\n        return tuple(sorted(\n            chain.from_iterable(part.mechanism for part in self)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef purview(self):\n        return tuple(sorted(\n            chain.from_iterable(part.purview for part in self)))", "response": "Tuple of nodes of the purview in the partition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef concept_distance(c1, c2):\n    # Calculate the sum of the cause and effect EMDs, expanding the repertoires\n    # to the combined purview of the two concepts, so that the EMD signatures\n    # are the same size.\n    cause_purview = tuple(set(c1.cause.purview + c2.cause.purview))\n    effect_purview = tuple(set(c1.effect.purview + c2.effect.purview))\n    # Take the sum\n    return (repertoire_distance(c1.expand_cause_repertoire(cause_purview),\n                                c2.expand_cause_repertoire(cause_purview)) +\n            repertoire_distance(c1.expand_effect_repertoire(effect_purview),\n                                c2.expand_effect_repertoire(effect_purview)))", "response": "Return the distance between two concepts in concept space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ces_distance_simple(C1, C2):\n    # Make C1 refer to the bigger CES.\n    if len(C2) > len(C1):\n        C1, C2 = C2, C1\n    destroyed = [c1 for c1 in C1 if not any(c1.emd_eq(c2) for c2 in C2)]\n    return sum(c.phi * concept_distance(c, c.subsystem.null_concept)\n               for c in destroyed)", "response": "Return the distance between two cause - effect structures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ces_distance_emd(unique_C1, unique_C2):\n    # Get the pairwise distances between the concepts in the unpartitioned and\n    # partitioned CESs.\n    distances = np.array([\n        [concept_distance(i, j) for j in unique_C2] for i in unique_C1\n    ])\n    # We need distances from all concepts---in both the unpartitioned and\n    # partitioned CESs---to the null concept, because:\n    # - often a concept in the unpartitioned CES is destroyed by a\n    #   cut (and needs to be moved to the null concept); and\n    # - in certain cases, the partitioned system will have *greater* sum of\n    #   small-phi, even though it has less big-phi, which means that some\n    #   partitioned-CES concepts will be moved to the null concept.\n    distances_to_null = np.array([\n        concept_distance(c, c.subsystem.null_concept)\n        for ces in (unique_C1, unique_C2) for c in ces\n    ])\n    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    # Now we make the distance matrix, which will look like this:\n    #\n    #        C1       C2     0\n    #    +~~~~~~~~+~~~~~~~~+~~~+\n    #    |        |        |   |\n    # C1 |   X    |    D   |   |\n    #    |        |        |   |\n    #    +~~~~~~~~+~~~~~~~~+ D |\n    #    |        |        | n |\n    # C2 |   D'   |    X   |   |\n    #    |        |        |   |\n    #    +~~~~~~~~+~~~~~~~~+~~~|\n    #  0 |        Dn'      | X |\n    #    +~~~~~~~~~~~~~~~~~~~~~+\n    #\n    # The diagonal blocks marked with an X are set to a value larger than any\n    # pairwise distance between concepts. This ensures that concepts are never\n    # moved to another concept within their own CES; they must always go either\n    # from one CES to another, or to the null concept N. The D block is filled\n    # with the pairwise distances between the two CESs, and Dn is filled with\n    # the distances from each concept to the null concept.\n    N, M = len(unique_C1), len(unique_C2)\n    # Add one to the side length for the null concept distances.\n    distance_matrix = np.empty([N + M + 1] * 2)\n    # Ensure that concepts are never moved within their own CES.\n    distance_matrix[:] = np.max(distances) + 1\n    # Set the top-right block to the pairwise CES distances.\n    distance_matrix[:N, N:-1] = distances\n    # Set the bottom-left block to the same, but transposed.\n    distance_matrix[N:-1, :N] = distances.T\n    # Do the same for the distances to the null concept.\n    distance_matrix[-1, :-1] = distances_to_null\n    distance_matrix[:-1, -1] = distances_to_null.T\n    distance_matrix[-1, -1] = 0\n    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    # Construct the two phi distributions, with an entry at the end for the\n    # null concept.\n    d1 = [c.phi for c in unique_C1] + [0] * M + [0]\n    d2 = [0] * N + [c.phi for c in unique_C2] + [0]\n    # Calculate how much phi disappeared and assign it to the null concept.\n    d2[-1] = sum(d1) - sum(d2)\n    # The sum of the two signatures should be the same.\n    assert utils.eq(sum(d1), sum(d2))\n    # Calculate!\n    return emd(np.array(d1), np.array(d2), distance_matrix)", "response": "Return the distance between two cause - effect structures."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the distance between two cause - effect structures in concept space.", "response": "def ces_distance(C1, C2):\n    \"\"\"Return the distance between two cause-effect structures.\n\n    Args:\n        C1 (CauseEffectStructure): The first |CauseEffectStructure|.\n        C2 (CauseEffectStructure): The second |CauseEffectStructure|.\n\n    Returns:\n        float: The distance between the two cause-effect structures in concept\n        space.\n    \"\"\"\n    if config.USE_SMALL_PHI_DIFFERENCE_FOR_CES_DISTANCE:\n        return round(small_phi_ces_distance(C1, C2), config.PRECISION)\n\n    concepts_only_in_C1 = [\n        c1 for c1 in C1 if not any(c1.emd_eq(c2) for c2 in C2)]\n    concepts_only_in_C2 = [\n        c2 for c2 in C2 if not any(c2.emd_eq(c1) for c1 in C1)]\n    # If the only difference in the CESs is that some concepts\n    # disappeared, then we don't need to use the EMD.\n    if not concepts_only_in_C1 or not concepts_only_in_C2:\n        dist = _ces_distance_simple(C1, C2)\n    else:\n        dist = _ces_distance_emd(concepts_only_in_C1, concepts_only_in_C2)\n\n    return round(dist, config.PRECISION)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the difference in |small_phi| between |CauseEffectStructure|.", "response": "def small_phi_ces_distance(C1, C2):\n    \"\"\"Return the difference in |small_phi| between |CauseEffectStructure|.\"\"\"\n    return sum(c.phi for c in C1) - sum(c.phi for c in C2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_nodes(tpm, cm, network_state, indices, node_labels=None):\n    if node_labels is None:\n        node_labels = NodeLabels(None, indices)\n\n    node_state = utils.state_of(indices, network_state)\n\n    return tuple(Node(tpm, cm, index, state, node_labels)\n                 for index, state in zip(indices, node_state))", "response": "Generate |Node| objects for a subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbroadcasts a node TPM over the full network.", "response": "def expand_node_tpm(tpm):\n    \"\"\"Broadcast a node TPM over the full network.\n\n    This is different from broadcasting the TPM of a full system since the last\n    dimension (containing the state of the node) contains only the probability\n    of *this* node being on, rather than the probabilities for each node.\n    \"\"\"\n    uc = np.ones([2 for node in tpm.shape])\n    return uc * tpm"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a TPM conditioned on the given fixed node indices whose states are fixed according to the given state - tuple.", "response": "def condition_tpm(tpm, fixed_nodes, state):\n    \"\"\"Return a TPM conditioned on the given fixed node indices, whose states\n    are fixed according to the given state-tuple.\n\n    The dimensions of the new TPM that correspond to the fixed nodes are\n    collapsed onto their state, making those dimensions singletons suitable for\n    broadcasting. The number of dimensions of the conditioned TPM will be the\n    same as the unconditioned TPM.\n    \"\"\"\n    conditioning_indices = [[slice(None)]] * len(state)\n    for i in fixed_nodes:\n        # Preserve singleton dimensions with `np.newaxis`\n        conditioning_indices[i] = [state[i], np.newaxis]\n    # Flatten the indices.\n    conditioning_indices = list(chain.from_iterable(conditioning_indices))\n    # Obtain the actual conditioned TPM by indexing with the conditioning\n    # indices.\n    return tpm[tuple(conditioning_indices)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_tpm(tpm):\n    unconstrained = np.ones([2] * (tpm.ndim - 1) + [tpm.shape[-1]])\n    return tpm * unconstrained", "response": "Broadcast a state - by - node TPM so that singleton dimensions are expanded over the full network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef infer_edge(tpm, a, b, contexts):\n\n    def a_in_context(context):\n        \"\"\"Given a context C(A), return the states of the full system with A\n        OFF and ON, respectively.\n        \"\"\"\n        a_off = context[:a] + OFF + context[a:]\n        a_on = context[:a] + ON + context[a:]\n        return (a_off, a_on)\n\n    def a_affects_b_in_context(context):\n        \"\"\"Return ``True`` if A has an effect on B, given a context.\"\"\"\n        a_off, a_on = a_in_context(context)\n        return tpm[a_off][b] != tpm[a_on][b]\n\n    return any(a_affects_b_in_context(context) for context in contexts)", "response": "Infer the presence or absence of an edge from node A to node B."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef infer_cm(tpm):\n    network_size = tpm.shape[-1]\n    all_contexts = tuple(all_states(network_size - 1))\n    cm = np.empty((network_size, network_size), dtype=int)\n    for a, b in np.ndindex(cm.shape):\n        cm[a][b] = infer_edge(tpm, a, b, all_contexts)\n    return cm", "response": "Infer the connectivity matrix associated with a state - by - node TPM in\n    multidimensional form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_num_processes():\n    cpu_count = multiprocessing.cpu_count()\n\n    if config.NUMBER_OF_CORES == 0:\n        raise ValueError(\n            'Invalid NUMBER_OF_CORES; value may not be 0.')\n\n    if config.NUMBER_OF_CORES > cpu_count:\n        log.info('Requesting %s cores; only %s available',\n                 config.NUMBER_OF_CORES, cpu_count)\n        return cpu_count\n\n    if config.NUMBER_OF_CORES < 0:\n        num = cpu_count + config.NUMBER_OF_CORES + 1\n        if num <= 0:\n            raise ValueError(\n                'Invalid NUMBER_OF_CORES; negative value is too negative: '\n                'requesting {} cores, {} available.'.format(num, cpu_count))\n\n        return num\n\n    return config.NUMBER_OF_CORES", "response": "Return the number of processes to use in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_progress_bar(self):\n        # Forked worker processes can't show progress bars.\n        disable = MapReduce._forked or not config.PROGRESS_BARS\n\n        # Don't materialize iterable unless we have to: huge iterables\n        # (e.g. of `KCuts`) eat memory.\n        if disable:\n            total = None\n        else:\n            self.iterable = list(self.iterable)\n            total = len(self.iterable)\n\n        return tqdm(total=total, disable=disable, leave=False,\n                    desc=self.description)", "response": "Initialize and return a progress bar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef worker(compute, task_queue, result_queue, log_queue, complete,\n               *context):\n        \"\"\"A worker process, run by ``multiprocessing.Process``.\"\"\"\n        try:\n            MapReduce._forked = True\n            log.debug('Worker process starting...')\n\n            configure_worker_logging(log_queue)\n\n            for obj in iter(task_queue.get, POISON_PILL):\n                if complete.is_set():\n                    log.debug('Worker received signal - exiting early')\n                    break\n\n                log.debug('Worker got %s', obj)\n                result_queue.put(compute(obj, *context))\n                log.debug('Worker finished %s', obj)\n\n            result_queue.put(POISON_PILL)\n            log.debug('Worker process exiting')\n\n        except Exception as e:  # pylint: disable=broad-except\n            result_queue.put(ExceptionWrapper(e))", "response": "A worker process, run by ``multiprocessing.Process``."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes all queues and start the worker processes and the log thread.", "response": "def start_parallel(self):\n        \"\"\"Initialize all queues and start the worker processes and the log\n        thread.\n        \"\"\"\n        self.num_processes = get_num_processes()\n\n        self.task_queue = multiprocessing.Queue(maxsize=Q_MAX_SIZE)\n        self.result_queue = multiprocessing.Queue()\n        self.log_queue = multiprocessing.Queue()\n\n        # Used to signal worker processes when a result is found that allows\n        # the computation to terminate early.\n        self.complete = multiprocessing.Event()\n\n        args = (self.compute, self.task_queue, self.result_queue,\n                self.log_queue, self.complete) + self.context\n        self.processes = [\n            multiprocessing.Process(target=self.worker, args=args, daemon=True)\n            for i in range(self.num_processes)]\n\n        for process in self.processes:\n            process.start()\n\n        self.log_thread = LogThread(self.log_queue)\n        self.log_thread.start()\n\n        self.initialize_tasks()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize_tasks(self):\n        # Add a poison pill to shutdown each process.\n        self.tasks = chain(self.iterable, [POISON_PILL] * self.num_processes)\n        for task in islice(self.tasks, Q_MAX_SIZE):\n            log.debug('Putting %s on queue', task)\n            self.task_queue.put(task)", "response": "Load the input queue to capacity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef maybe_put_task(self):\n        try:\n            task = next(self.tasks)\n        except StopIteration:\n            pass\n        else:\n            log.debug('Putting %s on queue', task)\n            self.task_queue.put(task)", "response": "Enqueue the next task in the queue if there are any waiting."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_parallel(self):\n        try:\n            self.start_parallel()\n\n            result = self.empty_result(*self.context)\n\n            while self.num_processes > 0:\n                r = self.result_queue.get()\n                self.maybe_put_task()\n\n                if r is POISON_PILL:\n                    self.num_processes -= 1\n\n                elif isinstance(r, ExceptionWrapper):\n                    r.reraise()\n\n                else:\n                    result = self.process_result(r, result)\n                    self.progress.update(1)\n\n                    # Did `process_result` decide to terminate early?\n                    if self.done:\n                        self.complete.set()\n\n            self.finish_parallel()\n        except Exception:\n            raise\n        finally:\n            log.debug('Removing progress bar')\n            self.progress.close()\n\n        return result", "response": "Perform the computation in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef finish_parallel(self):\n        for process in self.processes:\n            process.join()\n\n        # Shutdown the log thread\n        log.debug('Joining log thread')\n        self.log_queue.put(POISON_PILL)\n        self.log_thread.join()\n        self.log_queue.close()\n\n        # Close all queues\n        log.debug('Closing queues')\n        self.task_queue.close()\n        self.result_queue.close()", "response": "Orderly shutdown of processes and queues."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform the computation sequentially only holding two computed objects in memory at a time.", "response": "def run_sequential(self):\n        \"\"\"Perform the computation sequentially, only holding two computed\n        objects in memory at a time.\n        \"\"\"\n        try:\n            result = self.empty_result(*self.context)\n\n            for obj in self.iterable:\n                r = self.compute(obj, *self.context)\n                result = self.process_result(r, result)\n                self.progress.update(1)\n\n                # Short-circuited?\n                if self.done:\n                    break\n        except Exception as e:\n            raise e\n        finally:\n            self.progress.close()\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreconfiguring PyPhi logging based on the current configuration.", "response": "def configure_logging(conf):\n    \"\"\"Reconfigure PyPhi logging based on the current configuration.\"\"\"\n    logging.config.dictConfig({\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'standard': {\n                'format': '%(asctime)s [%(name)s] %(levelname)s '\n                          '%(processName)s: %(message)s'\n            }\n        },\n        'handlers': {\n            'file': {\n                'level': conf.LOG_FILE_LEVEL,\n                'filename': conf.LOG_FILE,\n                'class': 'logging.FileHandler',\n                'formatter': 'standard',\n            },\n            'stdout': {\n                'level': conf.LOG_STDOUT_LEVEL,\n                'class': 'pyphi.log.TqdmHandler',\n                'formatter': 'standard',\n            }\n        },\n        'root': {\n            'level': 'DEBUG',\n            'handlers': (['file'] if conf.LOG_FILE_LEVEL else []) +\n                        (['stdout'] if conf.LOG_STDOUT_LEVEL else [])\n        }\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate(self, value):\n        if self.values and value not in self.values:\n            raise ValueError(\n                '{} is not a valid value for {}'.format(value, self.name))", "response": "Validate the new value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of the Option objects for this config.", "response": "def options(cls):\n        \"\"\"Return a dictionary of the ``Option`` objects for this config.\"\"\"\n        return {k: v for k, v in cls.__dict__.items() if isinstance(v, Option)}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the default values of this configuration.", "response": "def defaults(self):\n        \"\"\"Return the default values of this configuration.\"\"\"\n        return {k: v.default for k, v in self.options().items()}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_dict(self, dct):\n        for k, v in dct.items():\n            setattr(self, k, v)", "response": "Load a dictionary of configuration values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading config from a YAML file.", "response": "def load_file(self, filename):\n        \"\"\"Load config from a YAML file.\"\"\"\n        filename = os.path.abspath(filename)\n\n        with open(filename) as f:\n            self.load_dict(yaml.load(f))\n\n        self._loaded_files.append(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef be2le_state_by_state(tpm):\n    le = np.empty(tpm.shape)\n    N = tpm.shape[0]\n    n = int(log2(N))\n    for i in range(N):\n        le[i, :] = tpm[be2le(i, n), :]\n    return le", "response": "Convert a state - by - state TPM from big - endian to little - endian or vice\n    versa."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a state - by - state TPM to a state - by - node TPM.", "response": "def state_by_state2state_by_node(tpm):\n    \"\"\"Convert a state-by-state TPM to a state-by-node TPM.\n\n    .. danger::\n        Many nondeterministic state-by-state TPMs can be represented by a\n        single a state-by-state TPM. However, the mapping can be made to be\n        one-to-one if we assume the state-by-state TPM is conditionally\n        independent, as this function does. **If the given TPM is not\n        conditionally independent, the conditional dependencies will be\n        silently lost.**\n\n    .. note::\n        The indices of the rows and columns of the state-by-state TPM are\n        assumed to follow the little-endian convention. The indices of the rows\n        of the resulting state-by-node TPM also follow the little-endian\n        convention. See the documentation on PyPhi the :ref:`tpm-conventions`\n        more information.\n\n    Args:\n        tpm (list[list] or np.ndarray): A square state-by-state TPM with row\n            and column indices following the little-endian convention.\n\n    Returns:\n        np.ndarray: A state-by-node TPM, with row indices following the\n        little-endian convention.\n\n    Example:\n        >>> tpm = np.array([[0.5, 0.5, 0.0, 0.0],\n        ...                 [0.0, 1.0, 0.0, 0.0],\n        ...                 [0.0, 0.2, 0.0, 0.8],\n        ...                 [0.0, 0.3, 0.7, 0.0]])\n        >>> state_by_state2state_by_node(tpm)\n        array([[[0.5, 0. ],\n                [1. , 0.8]],\n        <BLANKLINE>\n               [[1. , 0. ],\n                [0.3, 0.7]]])\n    \"\"\"\n    # Cast to np.array.\n    tpm = np.array(tpm)\n    # Get the number of states from the length of one side of the TPM.\n    S = tpm.shape[-1]\n    # Get the number of nodes from the number of states.\n    N = int(log2(S))\n    # Initialize the new state-by node TPM.\n    sbn_tpm = np.zeros(([2] * N + [N]))\n    # Map indices to state-tuples with the little-endian convention.\n    states = {i: le_index2state(i, N) for i in range(S)}\n    # Get an array for each node with 1 in positions that correspond to that\n    # node being on in the next state, and a 0 otherwise.\n    node_on = np.array([[states[i][n] for i in range(S)] for n in range(N)])\n    on_probabilities = [tpm * node_on[n] for n in range(N)]\n    for i, state in states.items():\n        # Get the probability of each node being on given the previous state i,\n        # i.e., a row of the state-by-node TPM.\n        # Assign that row to the ith state in the state-by-node TPM.\n        sbn_tpm[state] = [np.sum(on_probabilities[n][i]) for n in range(N)]\n    return sbn_tpm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef state_by_node2state_by_state(tpm):\n    # Cast to np.array.\n    tpm = np.array(tpm)\n    # Convert to multidimensional form.\n    tpm = to_multidimensional(tpm)\n    # Get the number of nodes from the last dimension of the TPM.\n    N = tpm.shape[-1]\n    # Get the number of states.\n    S = 2**N\n    # Initialize the state-by-state TPM.\n    sbs_tpm = np.zeros((S, S))\n    if not np.any(np.logical_and(tpm < 1, tpm > 0)):\n        # TPM is deterministic.\n        for previous_state_index in range(S):\n            # Use the little-endian convention to get the row and column\n            # indices.\n            previous_state = le_index2state(previous_state_index, N)\n            current_state_index = state2le_index(tpm[previous_state])\n            sbs_tpm[previous_state_index, current_state_index] = 1\n    else:\n        # TPM is nondeterministic.\n        for previous_state_index in range(S):\n            # Use the little-endian convention to get the row and column\n            # indices.\n            previous_state = le_index2state(previous_state_index, N)\n            marginal_tpm = tpm[previous_state]\n            for current_state_index in range(S):\n                current_state = np.array(\n                    [i for i in le_index2state(current_state_index, N)])\n                sbs_tpm[previous_state_index, current_state_index] = (\n                    np.prod(marginal_tpm[current_state == 1]) *\n                    np.prod(1 - marginal_tpm[current_state == 0]))\n    return sbs_tpm", "response": "Convert a state - by - node TPM to a state - by - state TPM."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading an array of repertoires in. / data. emd.", "response": "def load_repertoire(name):\n    \"\"\"Load an array of repertoires in ./data/emd/.\"\"\"\n    root = os.path.abspath(os.path.dirname(__file__))\n    filename = os.path.join(root, 'data', 'emd', name)\n\n    return np.load(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a network from a json file", "response": "def load_json_network(json_dict):\n    \"\"\"Load a network from a json file\"\"\"\n    network = pyphi.Network.from_json(json_dict['network'])\n    state = json_dict['state']\n    return (network, state)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_network_files():\n    # TODO: list explicitly since some are missing?\n    network_types = [\n        'AND-circle',\n        'MAJ-specialized',\n        'MAJ-complete',\n        'iit-3.0-modular'\n    ]\n    network_sizes = range(5, 8)\n    network_files = []\n    for n in network_sizes:\n        for t in network_types:\n            network_files.append('{}-{}'.format(n, t))\n    return network_files", "response": "Return a list of all network files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef profile_network(filename):\n    log = logging.getLogger(filename)\n    logfile = os.path.join(LOGS, filename + '.log')\n    os.makedirs(os.path.dirname(logfile), exist_ok=True)\n    handler = logging.FileHandler(logfile)\n    handler.setFormatter(formatter)\n    log.addHandler(handler)\n    log.setLevel(logging.INFO)\n\n    try:\n        with open(os.path.join(NETWORKS, filename + '.json')) as f:\n\n            network, state = load_json_network(json.load(f))\n\n            log.info('Profiling %s...', filename)\n            log.info('PyPhi configuration:\\n%s',\n                     pyphi.config.get_config_string())\n\n            start = time()\n            pr = cProfile.Profile()\n            pr.enable()\n\n            results = tuple(pyphi.compute.complexes(network, state))\n\n            pr.disable()\n            end = time()\n\n            pstatsfile = os.path.join(PSTATS, filename + '.pstats')\n            os.makedirs(os.path.dirname(pstatsfile), exist_ok=True)\n            pr.dump_stats(pstatsfile)\n\n            log.info('Finished in %i seconds.', end - start)\n\n            resultfile = os.path.join(RESULTS, filename + '-results.pkl')\n            os.makedirs(os.path.dirname(resultfile), exist_ok=True)\n            with open(resultfile, 'wb') as f:\n                pickle.dump(results, f)\n    except Exception as e:\n        log.error(e)\n        raise e", "response": "Profile a network.\n\n    Saves PyPhi results, pstats, and logs to respective directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate a TPM by the specified number of time steps.", "response": "def run_tpm(tpm, time_scale):\n    \"\"\"Iterate a TPM by the specified number of time steps.\n\n    Args:\n        tpm (np.ndarray): A state-by-node tpm.\n        time_scale (int): The number of steps to run the tpm.\n\n    Returns:\n        np.ndarray\n    \"\"\"\n    sbs_tpm = convert.state_by_node2state_by_state(tpm)\n    if sparse(tpm):\n        tpm = sparse_time(sbs_tpm, time_scale)\n    else:\n        tpm = dense_time(sbs_tpm, time_scale)\n    return convert.state_by_state2state_by_node(tpm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate a connectivity matrix at the specified number of steps.", "response": "def run_cm(cm, time_scale):\n    \"\"\"Iterate a connectivity matrix the specified number of steps.\n\n    Args:\n        cm (np.ndarray): A connectivity matrix.\n        time_scale (int): The number of steps to run.\n\n    Returns:\n        np.ndarray: The connectivity matrix at the new timescale.\n    \"\"\"\n    cm = np.linalg.matrix_power(cm, time_scale)\n    # Round non-unitary values back to 1\n    cm[cm > 1] = 1\n    return cm"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _reachable_subsystems(network, indices, state):\n    validate.is_network(network)\n\n    # Return subsystems largest to smallest to optimize parallel\n    # resource usage.\n    for subset in utils.powerset(indices, nonempty=True, reverse=True):\n        try:\n            yield Subsystem(network, state, subset)\n        except exceptions.StateUnreachableError:\n            pass", "response": "A generator over all subsystems in a valid state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_complexes(network, state):\n    engine = FindAllComplexes(subsystems(network, state))\n    return engine.run(config.PARALLEL_COMPLEX_EVALUATION)", "response": "Return a generator for all complexes in the given network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all irreducible complexes of the given network.", "response": "def complexes(network, state):\n    \"\"\"Return all irreducible complexes of the network.\n\n    Args:\n        network (Network): The |Network| of interest.\n        state (tuple[int]): The state of the network (a binary tuple).\n\n    Yields:\n        SystemIrreducibilityAnalysis: A |SIA| for each |Subsystem| of the\n        |Network|, excluding those with |big_phi = 0|.\n    \"\"\"\n    engine = FindIrreducibleComplexes(possible_complexes(network, state))\n    return engine.run(config.PARALLEL_COMPLEX_EVALUATION)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef major_complex(network, state):\n    log.info('Calculating major complex...')\n\n    result = complexes(network, state)\n    if result:\n        result = max(result)\n    else:\n        empty_subsystem = Subsystem(network, state, ())\n        result = _null_sia(empty_subsystem)\n\n    log.info(\"Finished calculating major complex.\")\n\n    return result", "response": "Return the major complex of the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef condensed(network, state):\n    result = []\n    covered_nodes = set()\n\n    for c in reversed(sorted(complexes(network, state))):\n        if not any(n in covered_nodes for n in c.subsystem.node_indices):\n            result.append(c)\n            covered_nodes = covered_nodes | set(c.subsystem.node_indices)\n\n    return result", "response": "Return a list of maximal non - overlapping complexes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef basic_network(cm=False):\n    tpm = np.array([\n        [0, 0, 0],\n        [0, 0, 1],\n        [1, 0, 1],\n        [1, 0, 0],\n        [1, 1, 0],\n        [1, 1, 1],\n        [1, 1, 1],\n        [1, 1, 0]\n    ])\n    if cm is False:\n        cm = np.array([\n            [0, 0, 1],\n            [1, 0, 1],\n            [1, 1, 0]\n        ])\n    else:\n        cm = None\n    return Network(tpm, cm=cm, node_labels=LABELS[:tpm.shape[1]])", "response": "A basic 3 - node network of logic gates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbase on the basic_selfloop_network but with added selfloops and noisy edges.", "response": "def basic_noisy_selfloop_network():\n    \"\"\"Based on the basic_network, but with added selfloops and noisy edges.\n\n    Nodes perform deterministic functions of their inputs, but those inputs\n    may be flipped (i.e. what should be a 0 becomes a 1, and vice versa) with\n    probability epsilon (eps = 0.1 here).\n\n    Diagram::\n\n                   +~~+\n                   |  v\n                +~~~~~~~~+\n          +~~~~>|   A    |<~~~~+\n          |     |  (OR)  +~~~+ |\n          |     +~~~~~~~~+   | |\n          |                  | |\n          |                  v |\n        +~+~~~~~~+       +~~~~~+~+\n        |   B    |<~~~~~~+   C   |\n      +>| (COPY) +~~~~~~>| (XOR) |<+\n      | +~~~~~~~~+       +~~~~~~~+ |\n      |   |                    |   |\n      +~~~+                    +~~~+\n\n    \"\"\"\n    tpm = np.array([\n        [0.271, 0.19, 0.244],\n        [0.919, 0.19, 0.756],\n        [0.919, 0.91, 0.756],\n        [0.991, 0.91, 0.244],\n        [0.919, 0.91, 0.756],\n        [0.991, 0.91, 0.244],\n        [0.991, 0.99, 0.244],\n        [0.999, 0.99, 0.756]\n    ])\n\n    cm = np.array([\n        [1, 0, 1],\n        [1, 1, 1],\n        [1, 1, 1]\n    ])\n\n    return Network(tpm, cm=cm)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef residue_network():\n    tpm = np.array([\n        [int(s) for s in bin(x)[2:].zfill(5)[::-1]] for x in range(32)\n    ])\n    tpm[np.where(np.sum(tpm[0:, 2:4], 1) == 2), 0] = 1\n    tpm[np.where(np.sum(tpm[0:, 3:5], 1) == 2), 1] = 1\n    tpm[np.where(np.sum(tpm[0:, 2:4], 1) < 2), 0] = 0\n    tpm[np.where(np.sum(tpm[0:, 3:5], 1) < 2), 1] = 0\n\n    cm = np.zeros((5, 5))\n    cm[2:4, 0] = 1\n    cm[3:, 1] = 1\n\n    return Network(tpm, cm=cm, node_labels=LABELS[:tpm.shape[1]])", "response": "The network for the residue example."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef macro_network():\n    tpm = np.array([[0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 1.0, 1.0],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 1.0, 1.0],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 0.3, 0.3],\n                    [0.3, 0.3, 1.0, 1.0],\n                    [1.0, 1.0, 0.3, 0.3],\n                    [1.0, 1.0, 0.3, 0.3],\n                    [1.0, 1.0, 0.3, 0.3],\n                    [1.0, 1.0, 1.0, 1.0]])\n    return Network(tpm, node_labels=LABELS[:tpm.shape[1]])", "response": "A macro network of micro elements which has greater integrated information than a macro scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef actual_causation():\n    tpm = np.array([\n        [1, 0, 0, 0],\n        [0, 1, 0, 0],\n        [0, 1, 0, 0],\n        [0, 0, 0, 1]\n    ])\n    cm = np.array([\n        [1, 1],\n        [1, 1]\n    ])\n    return Network(tpm, cm, node_labels=('OR', 'AND'))", "response": "The actual causation example network consisting of an OR and AND gate with self - loops."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all binary states of a system.", "response": "def all_states(n, big_endian=False):\n    \"\"\"Return all binary states for a system.\n\n    Args:\n        n (int): The number of elements in the system.\n        big_endian (bool): Whether to return the states in big-endian order\n            instead of little-endian order.\n\n    Yields:\n        tuple[int]: The next state of an ``n``-element system, in little-endian\n        order unless ``big_endian`` is ``True``.\n    \"\"\"\n    if n == 0:\n        return\n\n    for state in product((0, 1), repeat=n):\n        if big_endian:\n            yield state\n        else:\n            yield state[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a hash of a NumPy array.", "response": "def np_hash(a):\n    \"\"\"Return a hash of a NumPy array.\"\"\"\n    if a is None:\n        return hash(None)\n    # Ensure that hashes are equal whatever the ordering in memory (C or\n    # Fortran)\n    a = np.ascontiguousarray(a)\n    # Compute the digest and return a decimal int\n    return int(hashlib.sha1(a.view(a.dtype)).hexdigest(), 16)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef combs(a, r):\n    # Special-case for 0-length combinations\n    if r == 0:\n        return np.asarray([])\n\n    a = np.asarray(a)\n    data_type = a.dtype if r == 0 else np.dtype([('', a.dtype)] * r)\n    b = np.fromiter(combinations(a, r), data_type)\n    return b.view(a.dtype).reshape(-1, r)", "response": "NumPy implementation of itertools. combinations.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the indices of the k - combinations of n elements in the n - dimensional array.", "response": "def comb_indices(n, k):\n    \"\"\"``n``-dimensional version of itertools.combinations.\n\n    Args:\n        a (np.ndarray): The array from which to get combinations.\n        k (int): The desired length of the combinations.\n\n    Returns:\n        np.ndarray: Indices that give the ``k``-combinations of ``n`` elements.\n\n    Example:\n        >>> n, k = 3, 2\n        >>> data = np.arange(6).reshape(2, 3)\n        >>> data[:, comb_indices(n, k)]\n        array([[[0, 1],\n                [0, 2],\n                [1, 2]],\n        <BLANKLINE>\n               [[3, 4],\n                [3, 5],\n                [4, 5]]])\n    \"\"\"\n    # Count the number of combinations for preallocation\n    count = comb(n, k, exact=True)\n    # Get numpy iterable from ``itertools.combinations``\n    indices = np.fromiter(\n        chain.from_iterable(combinations(range(n), k)),\n        int,\n        count=(count * k))\n    # Reshape output into the array of combination indicies\n    return indices.reshape(-1, k)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef powerset(iterable, nonempty=False, reverse=False):\n    iterable = list(iterable)\n\n    if nonempty:  # Don't include 0-length subsets\n        start = 1\n    else:\n        start = 0\n\n    seq_sizes = range(start, len(iterable) + 1)\n\n    if reverse:\n        seq_sizes = reversed(seq_sizes)\n        iterable.reverse()\n\n    return chain.from_iterable(combinations(iterable, r) for r in seq_sizes)", "response": "Generate the power set of an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading numpy data from the data directory.", "response": "def load_data(directory, num):\n    \"\"\"Load numpy data from the data directory.\n\n    The files should stored in ``../data/<dir>`` and named\n    ``0.npy, 1.npy, ... <num - 1>.npy``.\n\n    Returns:\n        list: A list of loaded data, such that ``list[i]`` contains the the\n        contents of ``i.npy``.\n    \"\"\"\n    root = os.path.abspath(os.path.dirname(__file__))\n\n    def get_path(i):  # pylint: disable=missing-docstring\n        return os.path.join(root, 'data', directory, str(i) + '.npy')\n\n    return [np.load(get_path(i)) for i in range(num)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time_annotated(func, *args, **kwargs):\n    start = time()\n    result = func(*args, **kwargs)\n    end = time()\n    result.time = round(end - start, config.PRECISION)\n    return result", "response": "Annotate the decorated function or method with the total execution\n    time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _null_ria(direction, mechanism, purview, repertoire=None, phi=0.0):\n    # TODO Use properties here to infer mechanism and purview from\n    # partition yet access them with .mechanism and .partition\n    return RepertoireIrreducibilityAnalysis(\n        direction=direction,\n        mechanism=mechanism,\n        purview=purview,\n        partition=None,\n        repertoire=repertoire,\n        partitioned_repertoire=None,\n        phi=phi\n    )", "response": "The irreducibility analysis for a reducible mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a matrix of relevant connections for the given subsystem.", "response": "def _relevant_connections(self, subsystem):\n        \"\"\"Identify connections that \u201cmatter\u201d to this concept.\n\n        For a |MIC|, the important connections are those which connect the\n        purview to the mechanism; for a |MIE| they are the connections from the\n        mechanism to the purview.\n\n        Returns an |N x N| matrix, where `N` is the number of nodes in this\n        corresponding subsystem, that identifies connections that \u201cmatter\u201d to\n        this MICE:\n\n        ``direction == Direction.CAUSE``:\n            ``relevant_connections[i,j]`` is ``1`` if node ``i`` is in the\n            cause purview and node ``j`` is in the mechanism (and ``0``\n            otherwise).\n\n        ``direction == Direction.EFFECT``:\n            ``relevant_connections[i,j]`` is ``1`` if node ``i`` is in the\n            mechanism and node ``j`` is in the effect purview (and ``0``\n            otherwise).\n\n        Args:\n            subsystem (Subsystem): The |Subsystem| of this MICE.\n\n        Returns:\n            np.ndarray: A |N x N| matrix of connections, where |N| is the size\n            of the network.\n\n        Raises:\n            ValueError: If ``direction`` is invalid.\n        \"\"\"\n        _from, to = self.direction.order(self.mechanism, self.purview)\n        return connectivity.relevant_connections(subsystem.network.size,\n                                                 _from, to)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if this MICE is affected by the subsystem s cut.", "response": "def damaged_by_cut(self, subsystem):\n        \"\"\"Return ``True`` if this MICE is affected by the subsystem's cut.\n\n        The cut affects the MICE if it either splits the MICE's mechanism\n        or splits the connections between the purview and mechanism.\n        \"\"\"\n        return (subsystem.cut.splits_mechanism(self.mechanism) or\n                np.any(self._relevant_connections(subsystem) *\n                       subsystem.cut.cut_matrix(subsystem.network.size) == 1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eq_repertoires(self, other):\n        return (\n            np.array_equal(self.cause_repertoire, other.cause_repertoire) and\n            np.array_equal(self.effect_repertoire, other.effect_repertoire))", "response": "Return whether this concept has the same repertoires as another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether this concept is equal to another in the context of an EMD calculation.", "response": "def emd_eq(self, other):\n        \"\"\"Return whether this concept is equal to another in the context of\n        an EMD calculation.\n        \"\"\"\n        return (self.phi == other.phi and\n                self.mechanism == other.mechanism and\n                self.eq_repertoires(other))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_cause_repertoire(self, new_purview=None):\n        return self.subsystem.expand_cause_repertoire(\n            self.cause.repertoire, new_purview)", "response": "Expand the cause repertoire."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand_effect_repertoire(self, new_purview=None):\n        return self.subsystem.expand_effect_repertoire(\n            self.effect.repertoire, new_purview)", "response": "Expand the effect repertoire."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef directed_account(transition, direction, mechanisms=False, purviews=False,\n                     allow_neg=False):\n    \"\"\"Return the set of all |CausalLinks| of the specified direction.\"\"\"\n    if mechanisms is False:\n        mechanisms = utils.powerset(transition.mechanism_indices(direction),\n                                    nonempty=True)\n    links = [\n        transition.find_causal_link(direction, mechanism, purviews=purviews,\n                                    allow_neg=allow_neg)\n        for mechanism in mechanisms]\n\n    # Filter out causal links with zero alpha\n    return DirectedAccount(filter(None, links))", "response": "Return the set of all causal links of the specified direction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef account(transition, direction=Direction.BIDIRECTIONAL):\n    if direction != Direction.BIDIRECTIONAL:\n        return directed_account(transition, direction)\n\n    return Account(directed_account(transition, Direction.CAUSE) +\n                   directed_account(transition, Direction.EFFECT))", "response": "Returns the set of all causal links for a given transition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the distance between two accounts. Here that is just the difference in sum ( alpha )", "response": "def account_distance(A1, A2):\n    \"\"\"Return the distance between two accounts. Here that is just the\n    difference in sum(alpha)\n\n    Args:\n        A1 (Account): The first account.\n        A2 (Account): The second account\n\n    Returns:\n        float: The distance between the two accounts.\n    \"\"\"\n    return (sum([action.alpha for action in A1]) -\n            sum([action.alpha for action in A2]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _evaluate_cut(transition, cut, unpartitioned_account,\n                  direction=Direction.BIDIRECTIONAL):\n    \"\"\"Find the |AcSystemIrreducibilityAnalysis| for a given cut.\"\"\"\n    cut_transition = transition.apply_cut(cut)\n    partitioned_account = account(cut_transition, direction)\n\n    log.debug(\"Finished evaluating %s.\", cut)\n    alpha = account_distance(unpartitioned_account, partitioned_account)\n\n    return AcSystemIrreducibilityAnalysis(\n        alpha=round(alpha, config.PRECISION),\n        direction=direction,\n        account=unpartitioned_account,\n        partitioned_account=partitioned_account,\n        transition=transition,\n        cut=cut)", "response": "Evaluate a given cut."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the minimal information partition of a transition in a specific direction.", "response": "def sia(transition, direction=Direction.BIDIRECTIONAL):\n    \"\"\"Return the minimal information partition of a transition in a specific\n    direction.\n\n    Args:\n        transition (Transition): The candidate system.\n\n    Returns:\n        AcSystemIrreducibilityAnalysis: A nested structure containing all the\n        data from the intermediate calculations. The top level contains the\n        basic irreducibility information for the given subsystem.\n    \"\"\"\n    validate.direction(direction, allow_bi=True)\n    log.info(\"Calculating big-alpha for %s...\", transition)\n\n    if not transition:\n        log.info('Transition %s is empty; returning null SIA '\n                 'immediately.', transition)\n        return _null_ac_sia(transition, direction)\n\n    if not connectivity.is_weak(transition.network.cm,\n                                transition.node_indices):\n        log.info('%s is not strongly/weakly connected; returning null SIA '\n                 'immediately.', transition)\n        return _null_ac_sia(transition, direction)\n\n    log.debug(\"Finding unpartitioned account...\")\n    unpartitioned_account = account(transition, direction)\n    log.debug(\"Found unpartitioned account.\")\n\n    if not unpartitioned_account:\n        log.info('Empty unpartitioned account; returning null AC SIA '\n                 'immediately.')\n        return _null_ac_sia(transition, direction)\n\n    cuts = _get_cuts(transition, direction)\n    engine = ComputeACSystemIrreducibility(\n        cuts, transition, direction, unpartitioned_account)\n    result = engine.run_sequential()\n    log.info(\"Finished calculating big-ac-phi data for %s.\", transition)\n    log.debug(\"RESULT: \\n%s\", result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields all possible transitions in a single node.", "response": "def transitions(network, before_state, after_state):\n    \"\"\"Return a generator of all **possible** transitions of a network.\n    \"\"\"\n    # TODO: Does not return subsystems that are in an impossible transitions.\n\n    # Elements without inputs are reducibe effects,\n    # elements without outputs are reducible causes.\n    possible_causes = np.where(np.sum(network.cm, 1) > 0)[0]\n    possible_effects = np.where(np.sum(network.cm, 0) > 0)[0]\n\n    for cause_subset in utils.powerset(possible_causes, nonempty=True):\n        for effect_subset in utils.powerset(possible_effects, nonempty=True):\n            try:\n                yield Transition(network, before_state, after_state,\n                                 cause_subset, effect_subset)\n            except exceptions.StateUnreachableError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nexus(network, before_state, after_state,\n          direction=Direction.BIDIRECTIONAL):\n    \"\"\"Return a tuple of all irreducible nexus of the network.\"\"\"\n    validate.is_network(network)\n\n    sias = (sia(transition, direction) for transition in\n            transitions(network, before_state, after_state))\n    return tuple(sorted(filter(None, sias), reverse=True))", "response": "Return a tuple of irreducible nexus of the network."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the causal nexus of the network.", "response": "def causal_nexus(network, before_state, after_state,\n                 direction=Direction.BIDIRECTIONAL):\n    \"\"\"Return the causal nexus of the network.\"\"\"\n    validate.is_network(network)\n\n    log.info(\"Calculating causal nexus...\")\n    result = nexus(network, before_state, after_state, direction)\n    if result:\n        result = max(result)\n    else:\n        null_transition = Transition(\n            network, before_state, after_state, (), ())\n        result = _null_ac_sia(null_transition, direction)\n\n    log.info(\"Finished calculating causal nexus.\")\n    log.debug(\"RESULT: \\n%s\", result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting a true |CauseEffectStructure|.", "response": "def nice_true_ces(tc):\n    \"\"\"Format a true |CauseEffectStructure|.\"\"\"\n    cause_list = []\n    next_list = []\n    cause = '<--'\n    effect = '-->'\n    for event in tc:\n        if event.direction == Direction.CAUSE:\n            cause_list.append([\"{0:.4f}\".format(round(event.alpha, 4)),\n                               event.mechanism, cause, event.purview])\n        elif event.direction == Direction.EFFECT:\n            next_list.append([\"{0:.4f}\".format(round(event.alpha, 4)),\n                              event.mechanism, effect, event.purview])\n        else:\n            validate.direction(event.direction)\n\n    true_list = [(cause_list[event], next_list[event])\n                 for event in range(len(cause_list))]\n    return true_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef events(network, previous_state, current_state, next_state, nodes,\n           mechanisms=False):\n    \"\"\"Find all events (mechanisms with actual causes and actual effects).\"\"\"\n    actual_causes = _actual_causes(network, previous_state, current_state,\n                                   nodes, mechanisms)\n    actual_effects = _actual_effects(network, current_state, next_state,\n                                     nodes, mechanisms)\n    actual_mechanisms = (set(c.mechanism for c in actual_causes) &\n                         set(c.mechanism for c in actual_effects))\n\n    if not actual_mechanisms:\n        return ()\n\n    def index(actual_causes_or_effects):\n        \"\"\"Filter out unidirectional occurences and return a dictionary keyed\n        by the mechanism of the cause or effect.\n        \"\"\"\n        return {o.mechanism: o for o in actual_causes_or_effects\n                if o.mechanism in actual_mechanisms}\n\n    actual_causes = index(actual_causes)\n    actual_effects = index(actual_effects)\n\n    return tuple(Event(actual_causes[m], actual_effects[m])\n                 for m in sorted(actual_mechanisms))", "response": "Find all events that are in the same state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a set of all elements that have true causes and true effects.", "response": "def true_ces(subsystem, previous_state, next_state):\n    \"\"\"Set of all sets of elements that have true causes and true effects.\n\n    .. note::\n        Since the true |CauseEffectStructure| is always about the full system,\n        the background conditions don't matter and the subsystem should be\n        conditioned on the current state.\n    \"\"\"\n    network = subsystem.network\n    nodes = subsystem.node_indices\n    state = subsystem.state\n\n    _events = events(network, previous_state, state, next_state, nodes)\n\n    if not _events:\n        log.info(\"Finished calculating, no echo events.\")\n        return None\n\n    result = tuple([event.actual_cause for event in _events] +\n                   [event.actual_effect for event in _events])\n    log.info(\"Finished calculating true events.\")\n    log.debug(\"RESULT: \\n%s\", result)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all mechanisms that have true causes and true effects within the Taxonomy complex.", "response": "def true_events(network, previous_state, current_state, next_state,\n                indices=None, major_complex=None):\n    \"\"\"Return all mechanisms that have true causes and true effects within the\n    complex.\n\n    Args:\n        network (Network): The network to analyze.\n        previous_state (tuple[int]): The state of the network at ``t - 1``.\n        current_state (tuple[int]): The state of the network at ``t``.\n        next_state (tuple[int]): The state of the network at ``t + 1``.\n\n    Keyword Args:\n        indices (tuple[int]): The indices of the major complex.\n        major_complex (AcSystemIrreducibilityAnalysis): The major complex. If\n            ``major_complex`` is given then ``indices`` is ignored.\n\n    Returns:\n        tuple[Event]: List of true events in the major complex.\n    \"\"\"\n    # TODO: validate triplet of states\n\n    if major_complex:\n        nodes = major_complex.subsystem.node_indices\n    elif indices:\n        nodes = indices\n    else:\n        major_complex = compute.major_complex(network, current_state)\n        nodes = major_complex.subsystem.node_indices\n\n    return events(network, previous_state, current_state, next_state, nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all extrinsic events in the current state.", "response": "def extrinsic_events(network, previous_state, current_state, next_state,\n                     indices=None, major_complex=None):\n    \"\"\"Set of all mechanisms that are in the major complex but which have true\n    causes and effects within the entire network.\n\n    Args:\n        network (Network): The network to analyze.\n        previous_state (tuple[int]): The state of the network at ``t - 1``.\n        current_state (tuple[int]): The state of the network at ``t``.\n        next_state (tuple[int]): The state of the network at ``t + 1``.\n\n    Keyword Args:\n        indices (tuple[int]): The indices of the major complex.\n        major_complex (AcSystemIrreducibilityAnalysis): The major complex. If\n            ``major_complex`` is given then ``indices`` is ignored.\n\n    Returns:\n        tuple(actions): List of extrinsic events in the major complex.\n    \"\"\"\n    if major_complex:\n        mc_nodes = major_complex.subsystem.node_indices\n    elif indices:\n        mc_nodes = indices\n    else:\n        major_complex = compute.major_complex(network, current_state)\n        mc_nodes = major_complex.subsystem.node_indices\n\n    mechanisms = list(utils.powerset(mc_nodes, nonempty=True))\n    all_nodes = network.node_indices\n\n    return events(network, previous_state, current_state, next_state,\n                  all_nodes, mechanisms=mechanisms)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a JSON - serializable representation of the current object.", "response": "def to_json(self):\n        \"\"\"Return a JSON-serializable representation.\"\"\"\n        return {\n            'network': self.network,\n            'before_state': self.before_state,\n            'after_state': self.after_state,\n            'cause_indices': self.cause_indices,\n            'effect_indices': self.effect_indices,\n            'cut': self.cut\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_cut(self, cut):\n        return Transition(self.network, self.before_state, self.after_state,\n                          self.cause_indices, self.effect_indices, cut)", "response": "Return a cut version of this transition."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the cause repertoire.", "response": "def cause_repertoire(self, mechanism, purview):\n        \"\"\"Return the cause repertoire.\"\"\"\n        return self.repertoire(Direction.CAUSE, mechanism, purview)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef effect_repertoire(self, mechanism, purview):\n        return self.repertoire(Direction.EFFECT, mechanism, purview)", "response": "Return the effect repertoire."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the cause or effect repertoire function based on a direction.", "response": "def repertoire(self, direction, mechanism, purview):\n        \"\"\"Return the cause or effect repertoire function based on a direction.\n\n        Args:\n            direction (str): The temporal direction, specifiying the cause or\n                effect repertoire.\n        \"\"\"\n        system = self.system[direction]\n        node_labels = system.node_labels\n\n        if not set(purview).issubset(self.purview_indices(direction)):\n            raise ValueError('{} is not a {} purview in {}'.format(\n                fmt.fmt_mechanism(purview, node_labels), direction, self))\n\n        if not set(mechanism).issubset(self.mechanism_indices(direction)):\n            raise ValueError('{} is no a {} mechanism in {}'.format(\n                fmt.fmt_mechanism(mechanism, node_labels), direction, self))\n\n        return system.repertoire(direction, mechanism, purview)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state_probability(self, direction, repertoire, purview,):\n        purview_state = self.purview_state(direction)\n\n        index = tuple(node_state if node in purview else 0\n                      for node, node_state in enumerate(purview_state))\n        return repertoire[index]", "response": "Compute the probability of the purview in its current state given the repertoire the purview."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef probability(self, direction, mechanism, purview):\n        repertoire = self.repertoire(direction, mechanism, purview)\n\n        return self.state_probability(direction, repertoire, purview)", "response": "Return the probability that the purview is in the current state given the\n        state of the mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef purview_state(self, direction):\n        return {\n            Direction.CAUSE: self.before_state,\n            Direction.EFFECT: self.after_state\n        }[direction]", "response": "The state of the purview when we are computing coefficients in\n        in direction."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mechanism_indices(self, direction):\n        return {\n            Direction.CAUSE: self.effect_indices,\n            Direction.EFFECT: self.cause_indices\n        }[direction]", "response": "The indices of nodes in the mechanism system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partitioned_repertoire(self, direction, partition):\n        system = self.system[direction]\n        return system.partitioned_repertoire(direction, partition)", "response": "Compute the repertoire over the partition in the given direction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partitioned_probability(self, direction, partition):\n        repertoire = self.partitioned_repertoire(direction, partition)\n        return self.state_probability(direction, repertoire, partition.purview)", "response": "Compute the probability of the mechanism over the purview in the partition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the ratio minimum information partition for a mechanism over a purview. Args: direction (str): |CAUSE| or |EFFECT| mechanism (tuple[int]): A mechanism. purview (tuple[int]): A purview. Keyword Args: allow_neg (boolean): If true, ``alpha`` is allowed to be negative. Otherwise, negative values of ``alpha`` will be treated as if they were 0. Returns: AcRepertoireIrreducibilityAnalysis: The irreducibility analysis for the mechanism.", "response": "def find_mip(self, direction, mechanism, purview, allow_neg=False):\n        \"\"\"Find the ratio minimum information partition for a mechanism\n        over a purview.\n\n        Args:\n            direction (str): |CAUSE| or |EFFECT|\n            mechanism (tuple[int]): A mechanism.\n            purview (tuple[int]): A purview.\n\n        Keyword Args:\n            allow_neg (boolean): If true, ``alpha`` is allowed to be negative.\n                Otherwise, negative values of ``alpha`` will be treated as if\n                they were 0.\n\n        Returns:\n            AcRepertoireIrreducibilityAnalysis: The irreducibility analysis for\n            the mechanism.\n        \"\"\"\n        alpha_min = float('inf')\n        probability = self.probability(direction, mechanism, purview)\n\n        for partition in mip_partitions(mechanism, purview, self.node_labels):\n            partitioned_probability = self.partitioned_probability(\n                direction, partition)\n            alpha = log2(probability / partitioned_probability)\n\n            # First check for 0\n            # Default: don't count contrary causes and effects\n            if utils.eq(alpha, 0) or (alpha < 0 and not allow_neg):\n                return AcRepertoireIrreducibilityAnalysis(\n                    state=self.mechanism_state(direction),\n                    direction=direction,\n                    mechanism=mechanism,\n                    purview=purview,\n                    partition=partition,\n                    probability=probability,\n                    partitioned_probability=partitioned_probability,\n                    node_labels=self.node_labels,\n                    alpha=0.0\n                )\n            # Then take closest to 0\n            if (abs(alpha_min) - abs(alpha)) > constants.EPSILON:\n                alpha_min = alpha\n                acria = AcRepertoireIrreducibilityAnalysis(\n                    state=self.mechanism_state(direction),\n                    direction=direction,\n                    mechanism=mechanism,\n                    purview=purview,\n                    partition=partition,\n                    probability=probability,\n                    partitioned_probability=partitioned_probability,\n                    node_labels=self.node_labels,\n                    alpha=alpha_min\n                )\n        return acria"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef potential_purviews(self, direction, mechanism, purviews=False):\n        system = self.system[direction]\n        return [\n            purview for purview in system.potential_purviews(\n                direction, mechanism, purviews)\n            if set(purview).issubset(self.purview_indices(direction))\n        ]", "response": "Return all potential purviews of a mechanism in a given direction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_causal_link(self, direction, mechanism, purviews=False,\n                         allow_neg=False):\n        \"\"\"Return the maximally irreducible cause or effect ratio for a\n        mechanism.\n\n        Args:\n            direction (str): The temporal direction, specifying cause or\n                effect.\n            mechanism (tuple[int]): The mechanism to be tested for\n                irreducibility.\n\n        Keyword Args:\n            purviews (tuple[int]): Optionally restrict the possible purviews\n                to a subset of the subsystem. This may be useful for _e.g._\n                finding only concepts that are \"about\" a certain subset of\n                nodes.\n\n        Returns:\n            CausalLink: The maximally-irreducible actual cause or effect.\n        \"\"\"\n        purviews = self.potential_purviews(direction, mechanism, purviews)\n\n        # Find the maximal RIA over the remaining purviews.\n        if not purviews:\n            max_ria = _null_ac_ria(self.mechanism_state(direction),\n                                   direction, mechanism, None)\n        else:\n            # This max should be most positive\n            max_ria = max(self.find_mip(direction, mechanism, purview,\n                                        allow_neg)\n                          for purview in purviews)\n\n        # Construct the corresponding CausalLink\n        return CausalLink(max_ria)", "response": "Return the maximally irreducible cause or effect ratio for a given mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_actual_cause(self, mechanism, purviews=False):\n        return self.find_causal_link(Direction.CAUSE, mechanism, purviews)", "response": "Return the actual cause of a mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_actual_effect(self, mechanism, purviews=False):\n        return self.find_causal_link(Direction.EFFECT, mechanism, purviews)", "response": "Return the actual effect of a mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value associated with a key.", "response": "def find(key):\n    \"\"\"Return the value associated with a key.\n\n    If there is no value with the given key, returns ``None``.\n    \"\"\"\n    docs = list(collection.find({KEY_FIELD: key}))\n    # Return None if we didn't find anything.\n    if not docs:\n        return None\n    pickled_value = docs[0][VALUE_FIELD]\n    # Unpickle and return the value.\n    return pickle.loads(pickled_value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(key, value):\n    # Pickle the value.\n    value = pickle.dumps(value, protocol=constants.PICKLE_PROTOCOL)\n    # Store the value as binary data in a document.\n    doc = {\n        KEY_FIELD: key,\n        VALUE_FIELD: Binary(value)\n    }\n    # Pickle and store the value with its key. If the key already exists, we\n    # don't insert (since the key is a unique index), and we don't care.\n    try:\n        return collection.insert(doc)\n    except pymongo.errors.DuplicateKeyError:\n        return None", "response": "Store a value with a key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a key from some input.", "response": "def generate_key(filtered_args):\n    \"\"\"Get a key from some input.\n\n    This function should be used whenever a key is needed, to keep keys\n    consistent.\n    \"\"\"\n    # Convert the value to a (potentially singleton) tuple to be consistent\n    # with joblib.filtered_args.\n    if isinstance(filtered_args, Iterable):\n        return hash(tuple(filtered_args))\n    return hash((filtered_args,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cache(ignore=None):\n    def decorator(func):\n        # Initialize both cached versions\n        joblib_cached = constants.joblib_memory.cache(func, ignore=ignore)\n        db_cached = DbMemoizedFunc(func, ignore)\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            \"\"\"Dynamically choose the cache at call-time, not at import.\"\"\"\n            if func.__name__ == '_sia' and not config.CACHE_SIAS:\n                f = func\n            elif config.CACHING_BACKEND == 'fs':\n                f = joblib_cached\n            elif config.CACHING_BACKEND == 'db':\n                f = db_cached\n            return f(*args, **kwargs)\n\n        return wrapper\n    return decorator", "response": "Decorator for memoizing a function using either the filesystem or a\n    database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the key that the output should be cached with given arguments keyword arguments and a list of arguments to ignore.", "response": "def get_output_key(self, args, kwargs):\n        \"\"\"Return the key that the output should be cached with, given\n        arguments, keyword arguments, and a list of arguments to ignore.\n        \"\"\"\n        # Get a dictionary mapping argument names to argument values where\n        # ignored arguments are omitted.\n        filtered_args = joblib.func_inspect.filter_args(\n            self.func, self.ignore, args, kwargs)\n        # Get a sorted tuple of the filtered argument.\n        filtered_args = tuple(sorted(filtered_args.values()))\n        # Use native hash when hashing arguments.\n        return db.generate_key(filtered_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_output(self, args, kwargs):\n        return db.find(self.get_output_key(args, kwargs))", "response": "Load the output from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nodes(self, value):\n        # pylint: disable=attribute-defined-outside-init\n        self._nodes = value\n        self._index2node = {node.index: node for node in self._nodes}", "response": "Set the nodes attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreporting repertoire cache statistics.", "response": "def cache_info(self):\n        \"\"\"Report repertoire cache statistics.\"\"\"\n        return {\n            'single_node_repertoire':\n                self._single_node_repertoire_cache.info(),\n            'repertoire': self._repertoire_cache.info(),\n            'mice': self._mice_cache.info()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_caches(self):\n        self._single_node_repertoire_cache.clear()\n        self._repertoire_cache.clear()\n        self._mice_cache.clear()", "response": "Clear the mice and repertoire caches."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a JSON - serializable representation of the current object.", "response": "def to_json(self):\n        \"\"\"Return a JSON-serializable representation.\"\"\"\n        return {\n            'network': self.network,\n            'state': self.state,\n            'nodes': self.node_indices,\n            'cut': self.cut,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_cut(self, cut):\n        return Subsystem(self.network, self.state, self.node_indices,\n                         cut=cut, mice_cache=self._mice_cache)", "response": "Return a cut version of this |Subsystem|."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning |Nodes| for these indices.", "response": "def indices2nodes(self, indices):\n        \"\"\"Return |Nodes| for these indices.\n\n        Args:\n            indices (tuple[int]): The indices in question.\n\n        Returns:\n            tuple[Node]: The |Node| objects corresponding to these indices.\n\n        Raises:\n            ValueError: If requested indices are not in the subsystem.\n        \"\"\"\n        if set(indices) - set(self.node_indices):\n            raise ValueError(\n                \"`indices` must be a subset of the Subsystem's indices.\")\n        return tuple(self._index2node[n] for n in indices)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the cause repertoire of a mechanism over a purview.", "response": "def cause_repertoire(self, mechanism, purview):\n        \"\"\"Return the cause repertoire of a mechanism over a purview.\n\n        Args:\n            mechanism (tuple[int]): The mechanism for which to calculate the\n                cause repertoire.\n            purview (tuple[int]): The purview over which to calculate the\n                cause repertoire.\n\n        Returns:\n            np.ndarray: The cause repertoire of the mechanism over the purview.\n\n        .. note::\n            The returned repertoire is a distribution over purview node states,\n            not the states of the whole network.\n        \"\"\"\n        # If the purview is empty, the distribution is empty; return the\n        # multiplicative identity.\n        if not purview:\n            return np.array([1.0])\n        # If the mechanism is empty, nothing is specified about the previous\n        # state of the purview; return the purview's maximum entropy\n        # distribution.\n        if not mechanism:\n            return max_entropy_distribution(purview, self.tpm_size)\n        # Use a frozenset so the arguments to `_single_node_cause_repertoire`\n        # can be hashed and cached.\n        purview = frozenset(purview)\n        # Preallocate the repertoire with the proper shape, so that\n        # probabilities are broadcasted appropriately.\n        joint = np.ones(repertoire_shape(purview, self.tpm_size))\n        # The cause repertoire is the product of the cause repertoires of the\n        # individual nodes.\n        joint *= functools.reduce(\n            np.multiply, [self._single_node_cause_repertoire(m, purview)\n                          for m in mechanism]\n        )\n        # The resulting joint distribution is over previous states, which are\n        # rows in the TPM, so the distribution is a column. The columns of a\n        # TPM don't necessarily sum to 1, so we normalize.\n        return distribution.normalize(joint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the effect repertoire of a mechanism over a purview.", "response": "def effect_repertoire(self, mechanism, purview):\n        \"\"\"Return the effect repertoire of a mechanism over a purview.\n\n        Args:\n            mechanism (tuple[int]): The mechanism for which to calculate the\n                effect repertoire.\n            purview (tuple[int]): The purview over which to calculate the\n                effect repertoire.\n\n        Returns:\n            np.ndarray: The effect repertoire of the mechanism over the\n            purview.\n\n        .. note::\n            The returned repertoire is a distribution over purview node states,\n            not the states of the whole network.\n        \"\"\"\n        # If the purview is empty, the distribution is empty, so return the\n        # multiplicative identity.\n        if not purview:\n            return np.array([1.0])\n        # Use a frozenset so the arguments to `_single_node_effect_repertoire`\n        # can be hashed and cached.\n        mechanism = frozenset(mechanism)\n        # Preallocate the repertoire with the proper shape, so that\n        # probabilities are broadcasted appropriately.\n        joint = np.ones(repertoire_shape(purview, self.tpm_size))\n        # The effect repertoire is the product of the effect repertoires of the\n        # individual nodes.\n        return joint * functools.reduce(\n            np.multiply, [self._single_node_effect_repertoire(mechanism, p)\n                          for p in purview]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the cause or effect repertoire of the mechanism over the purview.", "response": "def repertoire(self, direction, mechanism, purview):\n        \"\"\"Return the cause or effect repertoire based on a direction.\n\n        Args:\n            direction (Direction): |CAUSE| or |EFFECT|.\n            mechanism (tuple[int]): The mechanism for which to calculate the\n                repertoire.\n            purview (tuple[int]): The purview over which to calculate the\n                repertoire.\n\n        Returns:\n            np.ndarray: The cause or effect repertoire of the mechanism over\n            the purview.\n\n        Raises:\n            ValueError: If ``direction`` is invalid.\n        \"\"\"\n        if direction == Direction.CAUSE:\n            return self.cause_repertoire(mechanism, purview)\n        elif direction == Direction.EFFECT:\n            return self.effect_repertoire(mechanism, purview)\n\n        return validate.direction(direction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef partitioned_repertoire(self, direction, partition):\n        repertoires = [\n            self.repertoire(direction, part.mechanism, part.purview)\n            for part in partition\n        ]\n        return functools.reduce(np.multiply, repertoires)", "response": "Compute the repertoire of a partitioned mechanism and purview."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands an effect repertoire over a larger purview.", "response": "def expand_repertoire(self, direction, repertoire, new_purview=None):\n        \"\"\"Distribute an effect repertoire over a larger purview.\n\n        Args:\n            direction (Direction): |CAUSE| or |EFFECT|.\n            repertoire (np.ndarray): The repertoire to expand.\n\n        Keyword Args:\n            new_purview (tuple[int]): The new purview to expand the repertoire\n                over. If ``None`` (the default), the new purview is the entire\n                network.\n\n        Returns:\n            np.ndarray: A distribution over the new purview, where probability\n            is spread out over the new nodes.\n\n        Raises:\n            ValueError: If the expanded purview doesn't contain the original\n                purview.\n        \"\"\"\n        if repertoire is None:\n            return None\n\n        purview = distribution.purview(repertoire)\n\n        if new_purview is None:\n            new_purview = self.node_indices  # full subsystem\n\n        if not set(purview).issubset(new_purview):\n            raise ValueError(\"Expanded purview must contain original purview.\")\n\n        # Get the unconstrained repertoire over the other nodes in the network.\n        non_purview_indices = tuple(set(new_purview) - set(purview))\n        uc = self.unconstrained_repertoire(direction, non_purview_indices)\n        # Multiply the given repertoire by the unconstrained one to get a\n        # distribution over all the nodes in the network.\n        expanded_repertoire = repertoire * uc\n\n        return distribution.normalize(expanded_repertoire)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpanding a cause repertoire.", "response": "def expand_cause_repertoire(self, repertoire, new_purview=None):\n        \"\"\"Alias for |expand_repertoire()| with ``direction`` set to |CAUSE|.\n        \"\"\"\n        return self.expand_repertoire(Direction.CAUSE, repertoire,\n                                      new_purview)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_effect_repertoire(self, repertoire, new_purview=None):\n        return self.expand_repertoire(Direction.EFFECT, repertoire,\n                                      new_purview)", "response": "Alias for |expand_repertoire()| with ``direction`` set to |EFFECT|."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the cause information for a mechanism over a purview.", "response": "def cause_info(self, mechanism, purview):\n        \"\"\"Return the cause information for a mechanism over a purview.\"\"\"\n        return repertoire_distance(\n            Direction.CAUSE,\n            self.cause_repertoire(mechanism, purview),\n            self.unconstrained_cause_repertoire(purview)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef effect_info(self, mechanism, purview):\n        return repertoire_distance(\n            Direction.EFFECT,\n            self.effect_repertoire(mechanism, purview),\n            self.unconstrained_effect_repertoire(purview)\n        )", "response": "Return the effect information for a mechanism over a purview."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the cause - effect information for a mechanism over a purview.", "response": "def cause_effect_info(self, mechanism, purview):\n        \"\"\"Return the cause-effect information for a mechanism over a purview.\n\n        This is the minimum of the cause and effect information.\n        \"\"\"\n        return min(self.cause_info(mechanism, purview),\n                   self.effect_info(mechanism, purview))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate_partition(self, direction, mechanism, purview, partition,\n                           repertoire=None):\n        \"\"\"Return the |small_phi| of a mechanism over a purview for the given\n        partition.\n\n        Args:\n            direction (Direction): |CAUSE| or |EFFECT|.\n            mechanism (tuple[int]): The nodes in the mechanism.\n            purview (tuple[int]): The nodes in the purview.\n            partition (Bipartition): The partition to evaluate.\n\n        Keyword Args:\n            repertoire (np.array): The unpartitioned repertoire.\n                If not supplied, it will be computed.\n\n        Returns:\n            tuple[int, np.ndarray]: The distance between the unpartitioned and\n            partitioned repertoires, and the partitioned repertoire.\n        \"\"\"\n        if repertoire is None:\n            repertoire = self.repertoire(direction, mechanism, purview)\n\n        partitioned_repertoire = self.partitioned_repertoire(direction,\n                                                             partition)\n\n        phi = repertoire_distance(\n            direction, repertoire, partitioned_repertoire)\n\n        return (phi, partitioned_repertoire)", "response": "Evaluate the partition over a mechanism over a purview."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the minimum information partition for a mechanism over a purview.", "response": "def find_mip(self, direction, mechanism, purview):\n        \"\"\"Return the minimum information partition for a mechanism over a\n        purview.\n\n        Args:\n            direction (Direction): |CAUSE| or |EFFECT|.\n            mechanism (tuple[int]): The nodes in the mechanism.\n            purview (tuple[int]): The nodes in the purview.\n\n        Returns:\n            RepertoireIrreducibilityAnalysis: The irreducibility analysis for\n            the mininum-information partition in one temporal direction.\n        \"\"\"\n        if not purview:\n            return _null_ria(direction, mechanism, purview)\n\n        # Calculate the unpartitioned repertoire to compare against the\n        # partitioned ones.\n        repertoire = self.repertoire(direction, mechanism, purview)\n\n        def _mip(phi, partition, partitioned_repertoire):\n            # Prototype of MIP with already known data\n            # TODO: Use properties here to infer mechanism and purview from\n            # partition yet access them with `.mechanism` and `.purview`.\n            return RepertoireIrreducibilityAnalysis(\n                phi=phi,\n                direction=direction,\n                mechanism=mechanism,\n                purview=purview,\n                partition=partition,\n                repertoire=repertoire,\n                partitioned_repertoire=partitioned_repertoire,\n                node_labels=self.node_labels\n            )\n\n        # State is unreachable - return 0 instead of giving nonsense results\n        if (direction == Direction.CAUSE and\n                np.all(repertoire == 0)):\n            return _mip(0, None, None)\n\n        mip = _null_ria(direction, mechanism, purview, phi=float('inf'))\n\n        for partition in mip_partitions(mechanism, purview, self.node_labels):\n            # Find the distance between the unpartitioned and partitioned\n            # repertoire.\n            phi, partitioned_repertoire = self.evaluate_partition(\n                direction, mechanism, purview, partition,\n                repertoire=repertoire)\n\n            # Return immediately if mechanism is reducible.\n            if phi == 0:\n                return _mip(0.0, partition, partitioned_repertoire)\n\n            # Update MIP if it's more minimal.\n            if phi < mip.phi:\n                mip = _mip(phi, partition, partitioned_repertoire)\n\n        return mip"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the irreducibility analysis for the cause MIP.", "response": "def cause_mip(self, mechanism, purview):\n        \"\"\"Return the irreducibility analysis for the cause MIP.\n\n        Alias for |find_mip()| with ``direction`` set to |CAUSE|.\n        \"\"\"\n        return self.find_mip(Direction.CAUSE, mechanism, purview)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef effect_mip(self, mechanism, purview):\n        return self.find_mip(Direction.EFFECT, mechanism, purview)", "response": "Return the irreducibility analysis for the effect MIP."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the small_phi of the cause MIP.", "response": "def phi_cause_mip(self, mechanism, purview):\n        \"\"\"Return the |small_phi| of the cause MIP.\n\n        This is the distance between the unpartitioned cause repertoire and the\n        MIP cause repertoire.\n        \"\"\"\n        mip = self.cause_mip(mechanism, purview)\n        return mip.phi if mip else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the small_phi of the effect MIP.", "response": "def phi_effect_mip(self, mechanism, purview):\n        \"\"\"Return the |small_phi| of the effect MIP.\n\n        This is the distance between the unpartitioned effect repertoire and\n        the MIP cause repertoire.\n        \"\"\"\n        mip = self.effect_mip(mechanism, purview)\n        return mip.phi if mip else 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the |small_phi| of a mechanism over a purview.", "response": "def phi(self, mechanism, purview):\n        \"\"\"Return the |small_phi| of a mechanism over a purview.\"\"\"\n        return min(self.phi_cause_mip(mechanism, purview),\n                   self.phi_effect_mip(mechanism, purview))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef potential_purviews(self, direction, mechanism, purviews=False):\n        if purviews is False:\n            purviews = self.network.potential_purviews(direction, mechanism)\n            # Filter out purviews that aren't in the subsystem\n            purviews = [purview for purview in purviews\n                        if set(purview).issubset(self.node_indices)]\n\n        # Purviews are already filtered in network.potential_purviews\n        # over the full network connectivity matrix. However, since the cm\n        # is cut/smaller we check again here.\n        return irreducible_purviews(self.cm, direction, mechanism, purviews)", "response": "Return all purviews that could belong to the given mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the MaximallyIrreducibleCauseOrEffect object for a mechanism.", "response": "def find_mice(self, direction, mechanism, purviews=False):\n        \"\"\"Return the |MIC| or |MIE| for a mechanism.\n\n        Args:\n            direction (Direction): :|CAUSE| or |EFFECT|.\n            mechanism (tuple[int]): The mechanism to be tested for\n                irreducibility.\n\n        Keyword Args:\n            purviews (tuple[int]): Optionally restrict the possible purviews\n                to a subset of the subsystem. This may be useful for _e.g._\n                finding only concepts that are \"about\" a certain subset of\n                nodes.\n\n        Returns:\n            MaximallyIrreducibleCauseOrEffect: The |MIC| or |MIE|.\n        \"\"\"\n        purviews = self.potential_purviews(direction, mechanism, purviews)\n\n        if not purviews:\n            max_mip = _null_ria(direction, mechanism, ())\n        else:\n            max_mip = max(self.find_mip(direction, mechanism, purview)\n                          for purview in purviews)\n\n        if direction == Direction.CAUSE:\n            return MaximallyIrreducibleCause(max_mip)\n        elif direction == Direction.EFFECT:\n            return MaximallyIrreducibleEffect(max_mip)\n        return validate.direction(direction)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mic(self, mechanism, purviews=False):\n        return self.find_mice(Direction.CAUSE, mechanism, purviews=purviews)", "response": "Return the maximally - irreducible cause for a mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the maximally - irreducible effect for a mechanism.", "response": "def mie(self, mechanism, purviews=False):\n        \"\"\"Return the mechanism's maximally-irreducible effect (|MIE|).\n\n        Alias for |find_mice()| with ``direction`` set to |EFFECT|.\n        \"\"\"\n        return self.find_mice(Direction.EFFECT, mechanism, purviews=purviews)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the maximum |small_phi| taken over all possible purviews of a mechanism.", "response": "def phi_max(self, mechanism):\n        \"\"\"Return the |small_phi_max| of a mechanism.\n\n        This is the maximum of |small_phi| taken over all possible purviews.\n        \"\"\"\n        return min(self.mic(mechanism).phi, self.mie(mechanism).phi)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef null_concept(self):\n        # Unconstrained cause repertoire.\n        cause_repertoire = self.cause_repertoire((), ())\n        # Unconstrained effect repertoire.\n        effect_repertoire = self.effect_repertoire((), ())\n\n        # Null cause.\n        cause = MaximallyIrreducibleCause(\n            _null_ria(Direction.CAUSE, (), (), cause_repertoire))\n        # Null effect.\n        effect = MaximallyIrreducibleEffect(\n            _null_ria(Direction.EFFECT, (), (), effect_repertoire))\n\n        # All together now...\n        return Concept(mechanism=(),\n                       cause=cause,\n                       effect=effect,\n                       subsystem=self)", "response": "Return the null concept of this subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the concept that constitutes the given mechanism.", "response": "def concept(self, mechanism, purviews=False, cause_purviews=False,\n                effect_purviews=False):\n        \"\"\"Return the concept specified by a mechanism within this subsytem.\n\n        Args:\n            mechanism (tuple[int]): The candidate set of nodes.\n\n        Keyword Args:\n            purviews (tuple[tuple[int]]): Restrict the possible purviews to\n                those in this list.\n            cause_purviews (tuple[tuple[int]]): Restrict the possible cause\n                purviews to those in this list. Takes precedence over\n                ``purviews``.\n            effect_purviews (tuple[tuple[int]]): Restrict the possible effect\n                purviews to those in this list. Takes precedence over\n                ``purviews``.\n\n        Returns:\n            Concept: The pair of maximally irreducible cause/effect repertoires\n            that constitute the concept specified by the given mechanism.\n        \"\"\"\n        log.debug('Computing concept %s...', mechanism)\n\n        # If the mechanism is empty, there is no concept.\n        if not mechanism:\n            log.debug('Empty concept; returning null concept')\n            return self.null_concept\n\n        # Calculate the maximally irreducible cause repertoire.\n        cause = self.mic(mechanism, purviews=(cause_purviews or purviews))\n\n        # Calculate the maximally irreducible effect repertoire.\n        effect = self.mie(mechanism, purviews=(effect_purviews or purviews))\n\n        log.debug('Found concept %s', mechanism)\n\n        # NOTE: Make sure to expand the repertoires to the size of the\n        # subsystem when calculating concept distance. For now, they must\n        # remain un-expanded so the concept doesn't depend on the subsystem.\n        return Concept(mechanism=mechanism, cause=cause, effect=effect,\n                       subsystem=self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _null_ac_sia(transition, direction, alpha=0.0):\n    return AcSystemIrreducibilityAnalysis(\n        transition=transition,\n        direction=direction,\n        alpha=alpha,\n        account=(),\n        partitioned_account=()\n    )", "response": "Return an |AcSystemIrreducibilityAnalysis| with zero |big_alpha| and empty accounts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mechanism(self):\n        assert self.actual_cause.mechanism == self.actual_effect.mechanism\n        return self.actual_cause.mechanism", "response": "The mechanism of the event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef irreducible_causes(self):\n        return tuple(link for link in self\n                     if link.direction is Direction.CAUSE)", "response": "The set of irreducible causes in this |Account|."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple of irreducible effects in this |Account|.", "response": "def irreducible_effects(self):\n        \"\"\"The set of irreducible effects in this |Account|.\"\"\"\n        return tuple(link for link in self\n                     if link.direction is Direction.EFFECT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a repr string for the object in question.", "response": "def make_repr(self, attrs):\n    \"\"\"Construct a repr string.\n\n    If `config.REPR_VERBOSITY` is ``1`` or ``2``, this function calls the\n    object's __str__ method. Although this breaks the convention that __repr__\n    should return a string which can reconstruct the object, readable reprs are\n    invaluable since the Python interpreter calls `repr` to represent all\n    objects in the shell. Since PyPhi is often used in the interpreter we want\n    to have meaningful and useful representations.\n\n    Args:\n        self (obj): The object in question\n        attrs (Iterable[str]): Attributes to include in the repr\n\n    Returns:\n        str: the ``repr``esentation of the object\n    \"\"\"\n    # TODO: change this to a closure so we can do\n    # __repr__ = make_repr(attrs) ???\n\n    if config.REPR_VERBOSITY in [MEDIUM, HIGH]:\n        return self.__str__()\n\n    elif config.REPR_VERBOSITY is LOW:\n        return '{}({})'.format(\n            self.__class__.__name__,\n            ', '.join(attr + '=' + repr(getattr(self, attr))\n                      for attr in attrs))\n\n    raise ValueError('Invalid value for `config.REPR_VERBOSITY`')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef indent(lines, amount=2, char=' '):\n    lines = str(lines)\n    padding = amount * char\n    return padding + ('\\n' + padding).join(lines.split('\\n'))", "response": "r Indents a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef margin(text):\n    lines = str(text).split('\\n')\n    return '\\n'.join('  {}  '.format(l) for l in lines)", "response": "r Add a margin to both ends of each line in the string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping a chunk of text in a box.", "response": "def box(text):\n    r\"\"\"Wrap a chunk of text in a box.\n\n    Example:\n        >>> print(box('line1\\nline2'))\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 line1 \u2502\n        \u2502 line2 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \"\"\"\n    lines = text.split('\\n')\n\n    width = max(len(l) for l in lines)\n    top_bar = (TOP_LEFT_CORNER + HORIZONTAL_BAR * (2 + width) +\n               TOP_RIGHT_CORNER)\n    bottom_bar = (BOTTOM_LEFT_CORNER + HORIZONTAL_BAR * (2 + width) +\n                  BOTTOM_RIGHT_CORNER)\n\n    lines = [LINES_FORMAT_STR.format(line=line, width=width) for line in lines]\n\n    return top_bar + '\\n' + '\\n'.join(lines) + '\\n' + bottom_bar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncenter a head over a block of text.", "response": "def header(head, text, over_char=None, under_char=None, center=True):\n    \"\"\"Center a head over a block of text.\n\n    The width of the text is the width of the longest line of the text.\n    \"\"\"\n    lines = list(text.split('\\n'))\n    width = max(len(l) for l in lines)\n\n    # Center or left-justify\n    if center:\n        head = head.center(width) + '\\n'\n    else:\n        head = head.ljust(width) + '\\n'\n\n    # Underline head\n    if under_char:\n        head = head + under_char * width + '\\n'\n\n    # 'Overline' head\n    if over_char:\n        head = over_char * width + '\\n' + head\n\n    return head + text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the labels for a tuple of mechanism indices.", "response": "def labels(indices, node_labels=None):\n    \"\"\"Get the labels for a tuple of mechanism indices.\"\"\"\n    if node_labels is None:\n        return tuple(map(str, indices))\n    return node_labels.indices2labels(indices)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fmt_number(p):\n    formatted = '{:n}'.format(p)\n\n    if not config.PRINT_FRACTIONS:\n        return formatted\n\n    fraction = Fraction(p)\n    nice = fraction.limit_denominator(128)\n    return (\n        str(nice) if (abs(fraction - nice) < constants.EPSILON and\n                      nice.denominator in NICE_DENOMINATORS)\n        else formatted\n    )", "response": "Format a number.\n\n    It will be printed as a fraction if the denominator isn't too big and as a\n    decimal otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat a |Part|. The returned string looks like:: 0,1 \u2500\u2500\u2500 \u2205", "response": "def fmt_part(part, node_labels=None):\n    \"\"\"Format a |Part|.\n\n    The returned string looks like::\n\n        0,1\n        \u2500\u2500\u2500\n         \u2205\n    \"\"\"\n    def nodes(x):  # pylint: disable=missing-docstring\n        return ','.join(labels(x, node_labels)) if x else EMPTY_SET\n\n    numer = nodes(part.mechanism)\n    denom = nodes(part.purview)\n\n    width = max(3, len(numer), len(denom))\n    divider = HORIZONTAL_BAR * width\n\n    return (\n        '{numer:^{width}}\\n'\n        '{divider}\\n'\n        '{denom:^{width}}'\n    ).format(numer=numer, divider=divider, denom=denom, width=width)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a |Bipartition|. The returned string looks like:: 0,1 \u2205 \u2500\u2500\u2500 \u2715 \u2500\u2500\u2500 2 0,1 Args: partition (Bipartition): The partition in question. Returns: str: A human-readable string representation of the partition.", "response": "def fmt_partition(partition):\n    \"\"\"Format a |Bipartition|.\n\n    The returned string looks like::\n\n        0,1    \u2205\n        \u2500\u2500\u2500 \u2715 \u2500\u2500\u2500\n         2    0,1\n\n    Args:\n        partition (Bipartition): The partition in question.\n\n    Returns:\n        str: A human-readable string representation of the partition.\n    \"\"\"\n    if not partition:\n        return ''\n\n    parts = [fmt_part(part, partition.node_labels).split('\\n')\n             for part in partition]\n\n    times = ('   ',\n             ' {} '.format(MULTIPLY),\n             '   ')\n    breaks = ('\\n', '\\n', '')  # No newline at the end of string\n    between = [times] * (len(parts) - 1) + [breaks]\n\n    # Alternate [part, break, part, ..., end]\n    elements = chain.from_iterable(zip(parts, between))\n\n    # Transform vertical stacks into horizontal lines\n    return ''.join(chain.from_iterable(zip(*elements)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fmt_account(account, title=None):\n    if title is None:\n        title = account.__class__.__name__  # `Account` or `DirectedAccount`\n\n    title = '{} ({} causal link{})'.format(\n        title, len(account), '' if len(account) == 1 else 's')\n\n    body = ''\n    body += 'Irreducible effects\\n'\n    body += '\\n'.join(fmt_ac_ria(m) for m in account.irreducible_effects)\n    body += '\\nIrreducible causes\\n'\n    body += '\\n'.join(fmt_ac_ria(m) for m in account.irreducible_causes)\n\n    return '\\n' + header(title, body, under_char='*')", "response": "Format an Account or a DirectedAccount."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef direction(direction, allow_bi=False):\n    valid = [Direction.CAUSE, Direction.EFFECT]\n    if allow_bi:\n        valid.append(Direction.BIDIRECTIONAL)\n\n    if direction not in valid:\n        raise ValueError('`direction` must be one of {}'.format(valid))\n\n    return True", "response": "Validate that the given direction is one of the allowed constants."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tpm(tpm, check_independence=True):\n    see_tpm_docs = (\n        'See the documentation on TPM conventions and the `pyphi.Network` '\n        'object for more information on TPM forms.'\n    )\n    # Cast to np.array.\n    tpm = np.array(tpm)\n    # Get the number of nodes from the state-by-node TPM.\n    N = tpm.shape[-1]\n    if tpm.ndim == 2:\n        if not ((tpm.shape[0] == 2**N and tpm.shape[1] == N) or\n                (tpm.shape[0] == tpm.shape[1])):\n            raise ValueError(\n                'Invalid shape for 2-D TPM: {}\\nFor a state-by-node TPM, '\n                'there must be ' '2^N rows and N columns, where N is the '\n                'number of nodes. State-by-state TPM must be square. '\n                '{}'.format(tpm.shape, see_tpm_docs))\n        if tpm.shape[0] == tpm.shape[1] and check_independence:\n            conditionally_independent(tpm)\n    elif tpm.ndim == (N + 1):\n        if tpm.shape != tuple([2] * N + [N]):\n            raise ValueError(\n                'Invalid shape for multidimensional state-by-node TPM: {}\\n'\n                'The shape should be {} for {} nodes. {}'.format(\n                    tpm.shape, ([2] * N) + [N], N, see_tpm_docs))\n    else:\n        raise ValueError(\n            'Invalid TPM: Must be either 2-dimensional or multidimensional. '\n            '{}'.format(see_tpm_docs))\n    return True", "response": "Validate a state - by - state TPM."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the TPM is conditionally independent.", "response": "def conditionally_independent(tpm):\n    \"\"\"Validate that the TPM is conditionally independent.\"\"\"\n    if not config.VALIDATE_CONDITIONAL_INDEPENDENCE:\n        return True\n    tpm = np.array(tpm)\n    if is_state_by_state(tpm):\n        there_and_back_again = convert.state_by_node2state_by_state(\n            convert.state_by_state2state_by_node(tpm))\n    else:\n        there_and_back_again = convert.state_by_state2state_by_node(\n            convert.state_by_node2state_by_state(tpm))\n    if np.any((tpm - there_and_back_again) >= EPSILON):\n        raise exceptions.ConditionallyDependentError(\n            'TPM is not conditionally independent.\\n'\n            'See the conditional independence example in the documentation '\n            'for more info.')\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connectivity_matrix(cm):\n    # Special case for empty matrices.\n    if cm.size == 0:\n        return True\n    if cm.ndim != 2:\n        raise ValueError(\"Connectivity matrix must be 2-dimensional.\")\n    if cm.shape[0] != cm.shape[1]:\n        raise ValueError(\"Connectivity matrix must be square.\")\n    if not np.all(np.logical_or(cm == 1, cm == 0)):\n        raise ValueError(\"Connectivity matrix must contain only binary \"\n                         \"values.\")\n    return True", "response": "Validate the given connectivity matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that there is a label for each node.", "response": "def node_labels(node_labels, node_indices):\n    \"\"\"Validate that there is a label for each node.\"\"\"\n    if len(node_labels) != len(node_indices):\n        raise ValueError(\"Labels {0} must label every node {1}.\".format(\n            node_labels, node_indices))\n\n    if len(node_labels) != len(set(node_labels)):\n        raise ValueError(\"Labels {0} must be unique.\".format(node_labels))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef network(n):\n    tpm(n.tpm)\n    connectivity_matrix(n.cm)\n    if n.cm.shape[0] != n.size:\n        raise ValueError(\"Connectivity matrix must be NxN, where N is the \"\n                         \"number of nodes in the network.\")\n    return True", "response": "Validate a |Network|.\n\n    Checks the TPM and connectivity matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state_length(state, size):\n    if len(state) != size:\n        raise ValueError('Invalid state: there must be one entry per '\n                         'node in the network; this state has {} entries, but '\n                         'there are {} nodes.'.format(len(state), size))\n    return True", "response": "Check that the state length is the given size."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef state_reachable(subsystem):\n    # If there is a row `r` in the TPM such that all entries of `r - state` are\n    # between -1 and 1, then the given state has a nonzero probability of being\n    # reached from some state.\n    # First we take the submatrix of the conditioned TPM that corresponds to\n    # the nodes that are actually in the subsystem...\n    tpm = subsystem.tpm[..., subsystem.node_indices]\n    # Then we do the subtraction and test.\n    test = tpm - np.array(subsystem.proper_state)\n    if not np.any(np.logical_and(-1 < test, test < 1).all(-1)):\n        raise exceptions.StateUnreachableError(subsystem.state)", "response": "Return whether a state can be reached according to the network s TPM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cut(cut, node_indices):\n    if cut.indices != node_indices:\n        raise ValueError('{} nodes are not equal to subsystem nodes '\n                         '{}'.format(cut, node_indices))", "response": "Check that the cut is for only the given nodes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subsystem(s):\n    node_states(s.state)\n    cut(s.cut, s.cut_indices)\n    if config.VALIDATE_SUBSYSTEM_STATES:\n        state_reachable(s)\n    return True", "response": "Validate a |Subsystem|.\n    Checks its state and cut.\n    Checks its state and cut indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate a partition - used by blackboxes and coarse grains.", "response": "def partition(partition):\n    \"\"\"Validate a partition - used by blackboxes and coarse grains.\"\"\"\n    nodes = set()\n    for part in partition:\n        for node in part:\n            if node in nodes:\n                raise ValueError(\n                    'Micro-element {} may not be partitioned into multiple '\n                    'macro-elements'.format(node))\n            nodes.add(node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating a macro coarse - graining.", "response": "def coarse_grain(coarse_grain):\n    \"\"\"Validate a macro coarse-graining.\"\"\"\n    partition(coarse_grain.partition)\n\n    if len(coarse_grain.partition) != len(coarse_grain.grouping):\n        raise ValueError('output and state groupings must be the same size')\n\n    for part, group in zip(coarse_grain.partition, coarse_grain.grouping):\n        if set(range(len(part) + 1)) != set(group[0] + group[1]):\n            # Check that all elements in the partition are in one of the two\n            # state groupings\n            raise ValueError('elements in output grouping {0} do not match '\n                             'elements in state grouping {1}'.format(\n                                 part, group))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates a macro blackboxing.", "response": "def blackbox(blackbox):\n    \"\"\"Validate a macro blackboxing.\"\"\"\n    if tuple(sorted(blackbox.output_indices)) != blackbox.output_indices:\n        raise ValueError('Output indices {} must be ordered'.format(\n            blackbox.output_indices))\n\n    partition(blackbox.partition)\n\n    for part in blackbox.partition:\n        if not set(part) & set(blackbox.output_indices):\n            raise ValueError(\n                'Every blackbox must have an output - {} does not'.format(\n                    part))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates that a coarse - graining properly combines the outputs of a blackboxing.", "response": "def blackbox_and_coarse_grain(blackbox, coarse_grain):\n    \"\"\"Validate that a coarse-graining properly combines the outputs of a\n    blackboxing.\n    \"\"\"\n    if blackbox is None:\n        return\n\n    for box in blackbox.partition:\n        # Outputs of the box\n        outputs = set(box) & set(blackbox.output_indices)\n\n        if coarse_grain is None and len(outputs) > 1:\n            raise ValueError(\n                'A blackboxing with multiple outputs per box must be '\n                'coarse-grained.')\n\n        if (coarse_grain and not any(outputs.issubset(part)\n                                     for part in coarse_grain.partition)):\n            raise ValueError(\n                'Multiple outputs from a blackbox must be partitioned into '\n                'the same macro-element of the coarse-graining')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, name):\n        def register_func(func):\n            self.store[name] = func\n            return func\n        return register_func", "response": "Decorator for registering a function with PyPhi.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ces(subsystem, mechanisms=False, purviews=False, cause_purviews=False,\n        effect_purviews=False, parallel=False):\n    \"\"\"Return the conceptual structure of this subsystem, optionally restricted\n    to concepts with the mechanisms and purviews given in keyword arguments.\n\n    If you don't need the full |CauseEffectStructure|, restricting the possible\n    mechanisms and purviews can make this function much faster.\n\n    Args:\n        subsystem (Subsystem): The subsystem for which to determine the\n            |CauseEffectStructure|.\n\n    Keyword Args:\n        mechanisms (tuple[tuple[int]]): Restrict possible mechanisms to those\n            in this list.\n        purviews (tuple[tuple[int]]): Same as in |Subsystem.concept()|.\n        cause_purviews (tuple[tuple[int]]): Same as in |Subsystem.concept()|.\n        effect_purviews (tuple[tuple[int]]): Same as in |Subsystem.concept()|.\n        parallel (bool): Whether to compute concepts in parallel. If ``True``,\n            overrides :data:`config.PARALLEL_CONCEPT_EVALUATION`.\n\n    Returns:\n        CauseEffectStructure: A tuple of every |Concept| in the cause-effect\n        structure.\n    \"\"\"\n    if mechanisms is False:\n        mechanisms = utils.powerset(subsystem.node_indices, nonempty=True)\n\n    engine = ComputeCauseEffectStructure(mechanisms, subsystem, purviews,\n                                         cause_purviews, effect_purviews)\n\n    return CauseEffectStructure(engine.run(parallel or\n                                           config.PARALLEL_CONCEPT_EVALUATION),\n                                subsystem=subsystem)", "response": "Return the conceptual structure of this subsystem optionally restricted\n    to concepts with the mechanisms and purviews given in keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conceptual_info(subsystem):\n    ci = ces_distance(ces(subsystem),\n                      CauseEffectStructure((), subsystem=subsystem))\n    return round(ci, config.PRECISION)", "response": "Return the conceptual information for a |Subsystem|."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating a given cut and return the irreducibility analysis for that cut.", "response": "def evaluate_cut(uncut_subsystem, cut, unpartitioned_ces):\n    \"\"\"Compute the system irreducibility for a given cut.\n\n    Args:\n        uncut_subsystem (Subsystem): The subsystem without the cut applied.\n        cut (Cut): The cut to evaluate.\n        unpartitioned_ces (CauseEffectStructure): The cause-effect structure of\n            the uncut subsystem.\n\n    Returns:\n        SystemIrreducibilityAnalysis: The |SystemIrreducibilityAnalysis| for\n        that cut.\n    \"\"\"\n    log.debug('Evaluating %s...', cut)\n\n    cut_subsystem = uncut_subsystem.apply_cut(cut)\n\n    if config.ASSUME_CUTS_CANNOT_CREATE_NEW_CONCEPTS:\n        mechanisms = unpartitioned_ces.mechanisms\n    else:\n        # Mechanisms can only produce concepts if they were concepts in the\n        # original system, or the cut divides the mechanism.\n        mechanisms = set(\n            unpartitioned_ces.mechanisms +\n            list(cut_subsystem.cut_mechanisms))\n\n    partitioned_ces = ces(cut_subsystem, mechanisms)\n\n    log.debug('Finished evaluating %s.', cut)\n\n    phi_ = ces_distance(unpartitioned_ces, partitioned_ces)\n\n    return SystemIrreducibilityAnalysis(\n        phi=phi_,\n        ces=unpartitioned_ces,\n        partitioned_ces=partitioned_ces,\n        subsystem=uncut_subsystem,\n        cut_subsystem=cut_subsystem)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sia_bipartitions(nodes, node_labels=None):\n    if config.CUT_ONE_APPROXIMATION:\n        bipartitions = directed_bipartition_of_one(nodes)\n    else:\n        # Don't consider trivial partitions where one part is empty\n        bipartitions = directed_bipartition(nodes, nontrivial=True)\n\n    return [Cut(bipartition[0], bipartition[1], node_labels)\n            for bipartition in bipartitions]", "response": "Return all |big_phi| cuts for the given nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sia(cache_key, subsystem):\n    # pylint: disable=unused-argument\n\n    log.info('Calculating big-phi data for %s...', subsystem)\n\n    # Check for degenerate cases\n    # =========================================================================\n    # Phi is necessarily zero if the subsystem is:\n    #   - not strongly connected;\n    #   - empty;\n    #   - an elementary micro mechanism (i.e. no nontrivial bipartitions).\n    # So in those cases we immediately return a null SIA.\n    if not subsystem:\n        log.info('Subsystem %s is empty; returning null SIA '\n                 'immediately.', subsystem)\n        return _null_sia(subsystem)\n\n    if not connectivity.is_strong(subsystem.cm, subsystem.node_indices):\n        log.info('%s is not strongly connected; returning null SIA '\n                 'immediately.', subsystem)\n        return _null_sia(subsystem)\n\n    # Handle elementary micro mechanism cases.\n    # Single macro element systems have nontrivial bipartitions because their\n    #   bipartitions are over their micro elements.\n    if len(subsystem.cut_indices) == 1:\n        # If the node lacks a self-loop, phi is trivially zero.\n        if not subsystem.cm[subsystem.node_indices][subsystem.node_indices]:\n            log.info('Single micro nodes %s without selfloops cannot have '\n                     'phi; returning null SIA immediately.', subsystem)\n            return _null_sia(subsystem)\n        # Even if the node has a self-loop, we may still define phi to be zero.\n        elif not config.SINGLE_MICRO_NODES_WITH_SELFLOOPS_HAVE_PHI:\n            log.info('Single micro nodes %s with selfloops cannot have '\n                     'phi; returning null SIA immediately.', subsystem)\n            return _null_sia(subsystem)\n    # =========================================================================\n\n    log.debug('Finding unpartitioned CauseEffectStructure...')\n    unpartitioned_ces = _ces(subsystem)\n\n    if not unpartitioned_ces:\n        log.info('Empty unpartitioned CauseEffectStructure; returning null '\n                 'SIA immediately.')\n        # Short-circuit if there are no concepts in the unpartitioned CES.\n        return _null_sia(subsystem)\n\n    log.debug('Found unpartitioned CauseEffectStructure.')\n\n    # TODO: move this into sia_bipartitions?\n    # Only True if SINGLE_MICRO_NODES...=True, no?\n    if len(subsystem.cut_indices) == 1:\n        cuts = [Cut(subsystem.cut_indices, subsystem.cut_indices,\n                    subsystem.cut_node_labels)]\n    else:\n        cuts = sia_bipartitions(subsystem.cut_indices,\n                                subsystem.cut_node_labels)\n\n    engine = ComputeSystemIrreducibility(\n        cuts, subsystem, unpartitioned_ces)\n    result = engine.run(config.PARALLEL_CUT_EVALUATION)\n\n    if config.CLEAR_SUBSYSTEM_CACHES_AFTER_COMPUTING_SIA:\n        log.debug('Clearing subsystem caches.')\n        subsystem.clear_caches()\n\n    log.info('Finished calculating big-phi data for %s.', subsystem)\n\n    return result", "response": "Return the minimal information partition of a subsystem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef concept_cuts(direction, node_indices, node_labels=None):\n    for partition in mip_partitions(node_indices, node_indices):\n        yield KCut(direction, partition, node_labels)", "response": "Generator over all concept - syle cuts for these nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates a concept - style SystemIrreducibilityAnalysisCause or SystemIrreducibilityAnalysisEffect.", "response": "def directional_sia(subsystem, direction, unpartitioned_ces=None):\n    \"\"\"Calculate a concept-style SystemIrreducibilityAnalysisCause or\n    SystemIrreducibilityAnalysisEffect.\n    \"\"\"\n    if unpartitioned_ces is None:\n        unpartitioned_ces = _ces(subsystem)\n\n    c_system = ConceptStyleSystem(subsystem, direction)\n    cuts = concept_cuts(direction, c_system.cut_indices, subsystem.node_labels)\n\n    # Run the default SIA engine\n    # TODO: verify that short-cutting works correctly?\n    engine = ComputeSystemIrreducibility(\n        cuts, c_system, unpartitioned_ces)\n    return engine.run(config.PARALLEL_CUT_EVALUATION)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute a concept - style SystemIrreducibilityAnalysis", "response": "def sia_concept_style(subsystem):\n    \"\"\"Compute a concept-style SystemIrreducibilityAnalysis\"\"\"\n    unpartitioned_ces = _ces(subsystem)\n\n    sia_cause = directional_sia(subsystem, Direction.CAUSE,\n                                unpartitioned_ces)\n    sia_effect = directional_sia(subsystem, Direction.EFFECT,\n                                 unpartitioned_ces)\n\n    return SystemIrreducibilityAnalysisConceptStyle(sia_cause, sia_effect)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute(mechanism, subsystem, purviews, cause_purviews,\n                effect_purviews):\n        \"\"\"Compute a |Concept| for a mechanism, in this |Subsystem| with the\n        provided purviews.\n        \"\"\"\n        concept = subsystem.concept(mechanism,\n                                    purviews=purviews,\n                                    cause_purviews=cause_purviews,\n                                    effect_purviews=effect_purviews)\n        # Don't serialize the subsystem.\n        # This is replaced on the other side of the queue, and ensures\n        # that all concepts in the CES reference the same subsystem.\n        concept.subsystem = None\n        return concept", "response": "Compute a |Concept| for a mechanism in this |Subsystem| with the provided purviews."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves all concepts with non - zero phi to the the |CauseEffectStructure|. The new_concept is appended to the list of concepts.", "response": "def process_result(self, new_concept, concepts):\n        \"\"\"Save all concepts with non-zero |small_phi| to the\n        |CauseEffectStructure|.\n        \"\"\"\n        if new_concept.phi > 0:\n            # Replace the subsystem\n            new_concept.subsystem = self.subsystem\n            concepts.append(new_concept)\n        return concepts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_result(self, new_sia, min_sia):\n        if new_sia.phi == 0:\n            self.done = True  # Short-circuit\n            return new_sia\n\n        elif new_sia < min_sia:\n            return new_sia\n\n        return min_sia", "response": "Check if the new SIA has smaller than the standing Arc entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef concept(self, mechanism, purviews=False, cause_purviews=False,\n                effect_purviews=False):\n        \"\"\"Compute a concept, using the appropriate system for each side of the\n        cut.\n        \"\"\"\n        cause = self.cause_system.mic(\n            mechanism, purviews=(cause_purviews or purviews))\n\n        effect = self.effect_system.mie(\n            mechanism, purviews=(effect_purviews or purviews))\n\n        return Concept(mechanism=mechanism, cause=cause, effect=effect,\n                       subsystem=self)", "response": "Compute a concept using the appropriate system for each side of the\n        cut."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncoerces nodes to integer indices.", "response": "def coerce_to_indices(self, nodes):\n        \"\"\"Return the nodes indices for nodes, where ``nodes`` is either\n        already integer indices or node labels.\n        \"\"\"\n        if nodes is None:\n            return self.node_indices\n\n        if all(isinstance(node, str) for node in nodes):\n            indices = self.labels2indices(nodes)\n        else:\n            indices = map(int, nodes)\n        return tuple(sorted(set(indices)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _null_sia(subsystem, phi=0.0):\n    return SystemIrreducibilityAnalysis(subsystem=subsystem,\n                                        cut_subsystem=subsystem,\n                                        phi=phi,\n                                        ces=_null_ces(subsystem),\n                                        partitioned_ces=_null_ces(subsystem))", "response": "Return a |SystemIrreducibilityAnalysis| with zero |big_phi| and empty\n    cause - effect structures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef order(self, mechanism, purview):\n        if self is Direction.CAUSE:\n            return purview, mechanism\n        elif self is Direction.EFFECT:\n            return mechanism, purview\n\n        from . import validate\n        return validate.direction(self)", "response": "Order the mechanism and purview in time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sametype(func):\n    @functools.wraps(func)\n    def wrapper(self, other):  # pylint: disable=missing-docstring\n        if type(other) is not type(self):\n            return NotImplemented\n        return func(self, other)\n    return wrapper", "response": "Decorator to return NotImplemented when the args of the wrapped\n    method are of different types."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if two objects are equal via recursion using numpy. array_equal for comparing numpy arays.", "response": "def numpy_aware_eq(a, b):\n    \"\"\"Return whether two objects are equal via recursion, using\n    :func:`numpy.array_equal` for comparing numpy arays.\n    \"\"\"\n    if isinstance(a, np.ndarray) or isinstance(b, np.ndarray):\n        return np.array_equal(a, b)\n    if ((isinstance(a, Iterable) and isinstance(b, Iterable)) and\n            not isinstance(a, str) and not isinstance(b, str)):\n        if len(a) != len(b):\n            return False\n        return all(numpy_aware_eq(x, y) for x, y in zip(a, b))\n    return a == b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef general_eq(a, b, attributes):\n    try:\n        for attr in attributes:\n            _a, _b = getattr(a, attr), getattr(b, attr)\n            if attr in ['phi', 'alpha']:\n                if not utils.eq(_a, _b):\n                    return False\n            elif attr in ['mechanism', 'purview']:\n                if _a is None or _b is None:\n                    if _a != _b:\n                        return False\n                elif not set(_a) == set(_b):\n                    return False\n            else:\n                if not numpy_aware_eq(_a, _b):\n                    return False\n        return True\n    except AttributeError:\n        return False", "response": "Return whether two objects are equal up to the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntiming an EMD command with the given data as arguments", "response": "def time_emd(emd_type, data):\n    \"\"\"Time an EMD command with the given data as arguments\"\"\"\n\n    emd = {\n        'cause': _CAUSE_EMD,\n        'effect': pyphi.subsystem.effect_emd,\n        'hamming': pyphi.utils.hamming_emd\n    }[emd_type]\n\n    def statement():\n        for (d1, d2) in data:\n            emd(d1, d2)\n\n    results = timeit.repeat(statement, number=NUMBER, repeat=REPEAT)\n\n    return min(results)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the uniform distribution over a set of binary nodes.", "response": "def uniform_distribution(number_of_nodes):\n    \"\"\"\n    Return the uniform distribution for a set of binary nodes, indexed by state\n    (so there is one dimension per node, the size of which is the number of\n    possible states for that node).\n\n    Args:\n        nodes (np.ndarray): A set of indices of binary nodes.\n\n    Returns:\n        np.ndarray: The uniform distribution over the set of nodes.\n    \"\"\"\n    # The size of the state space for binary nodes is 2^(number of nodes).\n    number_of_states = 2 ** number_of_nodes\n    # Generate the maximum entropy distribution\n    # TODO extend to nonbinary nodes\n    return (np.ones(number_of_states) /\n            number_of_states).reshape([2] * number_of_nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the marginal probability that the node is OFF.", "response": "def marginal_zero(repertoire, node_index):\n    \"\"\"Return the marginal probability that the node is OFF.\"\"\"\n    index = [slice(None)] * repertoire.ndim\n    index[node_index] = 0\n\n    return repertoire[tuple(index)].sum()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the marginal distribution for a node.", "response": "def marginal(repertoire, node_index):\n    \"\"\"Get the marginal distribution for a node.\"\"\"\n    index = tuple(i for i in range(repertoire.ndim) if i != node_index)\n\n    return repertoire.sum(index, keepdims=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether the repertoire is independent.", "response": "def independent(repertoire):\n    \"\"\"Check whether the repertoire is independent.\"\"\"\n    marginals = [marginal(repertoire, i) for i in range(repertoire.ndim)]\n\n    # TODO: is there a way to do without an explicit iteration?\n    joint = marginals[0]\n    for m in marginals[1:]:\n        joint = joint * m\n\n    # TODO: should we round here?\n    # repertoire = repertoire.round(config.PRECISION)\n    # joint = joint.round(config.PRECISION)\n\n    return np.array_equal(repertoire, joint)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening a repertoire in little - endian order.", "response": "def flatten(repertoire, big_endian=False):\n    \"\"\"Flatten a repertoire, removing empty dimensions.\n\n    By default, the flattened repertoire is returned in little-endian order.\n\n    Args:\n        repertoire (np.ndarray or None): A repertoire.\n\n    Keyword Args:\n        big_endian (boolean): If ``True``, flatten the repertoire in big-endian\n            order.\n\n    Returns:\n        np.ndarray: The flattened repertoire.\n    \"\"\"\n    if repertoire is None:\n        return None\n\n    order = 'C' if big_endian else 'F'\n    # For efficiency, use `ravel` (which returns a view of the array) instead\n    # of `np.flatten` (which copies the whole array).\n    return repertoire.squeeze().ravel(order=order)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef max_entropy_distribution(node_indices, number_of_nodes):\n    distribution = np.ones(repertoire_shape(node_indices, number_of_nodes))\n\n    return distribution / distribution.size", "response": "Return the maximum entropy distribution over a set of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating the TPM for the given number of timesteps.", "response": "def run_tpm(system, steps, blackbox):\n    \"\"\"Iterate the TPM for the given number of timesteps.\n\n    Returns:\n        np.ndarray: tpm * (noise_tpm^(t-1))\n    \"\"\"\n    # Generate noised TPM\n    # Noise the connections from every output element to elements in other\n    # boxes.\n    node_tpms = []\n    for node in system.nodes:\n        node_tpm = node.tpm_on\n        for input_node in node.inputs:\n            if not blackbox.in_same_box(node.index, input_node):\n                if input_node in blackbox.output_indices:\n                    node_tpm = marginalize_out([input_node], node_tpm)\n\n        node_tpms.append(node_tpm)\n\n    noised_tpm = rebuild_system_tpm(node_tpms)\n    noised_tpm = convert.state_by_node2state_by_state(noised_tpm)\n\n    tpm = convert.state_by_node2state_by_state(system.tpm)\n\n    # Muliply by noise\n    tpm = np.dot(tpm, np.linalg.matrix_power(noised_tpm, steps - 1))\n\n    return convert.state_by_state2state_by_node(tpm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of partitions of the N binary nodes.", "response": "def _partitions_list(N):\n    \"\"\"Return a list of partitions of the |N| binary nodes.\n\n    Args:\n        N (int): The number of nodes under consideration.\n\n    Returns:\n        list[list]: A list of lists, where each inner list is the set of\n        micro-elements corresponding to a macro-element.\n\n    Example:\n        >>> _partitions_list(3)\n        [[[0, 1], [2]], [[0, 2], [1]], [[0], [1, 2]], [[0], [1], [2]]]\n    \"\"\"\n    if N < (_NUM_PRECOMPUTED_PARTITION_LISTS):\n        return list(_partition_lists[N])\n    else:\n        raise ValueError(\n            'Partition lists not yet available for system with {} '\n            'nodes or more'.format(_NUM_PRECOMPUTED_PARTITION_LISTS))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_partitions(indices):\n    n = len(indices)\n    partitions = _partitions_list(n)\n    if n > 0:\n        partitions[-1] = [list(range(n))]\n\n    for partition in partitions:\n        yield tuple(tuple(indices[i] for i in part)\n                    for part in partition)", "response": "Return a list of all possible coarse grains of a network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_groupings(partition):\n    if not all(partition):\n        raise ValueError('Each part of the partition must have at least one '\n                         'element.')\n\n    micro_groupings = [_partitions_list(len(part) + 1) if len(part) > 1\n                       else [[[0], [1]]] for part in partition]\n\n    for grouping in itertools.product(*micro_groupings):\n        if all(len(element) < 3 for element in grouping):\n            yield tuple(tuple(tuple(tuple(state) for state in states)\n                              for states in grouping))", "response": "Return all possible groupings of states for a particular coarse graining\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_coarse_grains(indices):\n    for partition in all_partitions(indices):\n        for grouping in all_groupings(partition):\n            yield CoarseGrain(partition, grouping)", "response": "Generator over all possible |CoarseGrains| of these indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_coarse_grains_for_blackbox(blackbox):\n    for partition in all_partitions(blackbox.output_indices):\n        for grouping in all_groupings(partition):\n            coarse_grain = CoarseGrain(partition, grouping)\n            try:\n                validate.blackbox_and_coarse_grain(blackbox, coarse_grain)\n            except ValueError:\n                continue\n            yield coarse_grain", "response": "Generator over all |CoarseGrains| for the given blackbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coarse_graining(network, state, internal_indices):\n    max_phi = float('-inf')\n    max_coarse_grain = CoarseGrain((), ())\n\n    for coarse_grain in all_coarse_grains(internal_indices):\n        try:\n            subsystem = MacroSubsystem(network, state, internal_indices,\n                                       coarse_grain=coarse_grain)\n        except ConditionallyDependentError:\n            continue\n\n        phi = compute.phi(subsystem)\n        if (phi - max_phi) > constants.EPSILON:\n            max_phi = phi\n            max_coarse_grain = coarse_grain\n\n    return (max_phi, max_coarse_grain)", "response": "Find the maximal coarse - graining of a micro - system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_macro_systems(network, state, do_blackbox=False, do_coarse_grain=False,\n                      time_scales=None):\n    \"\"\"Generator over all possible macro-systems for the network.\"\"\"\n    if time_scales is None:\n        time_scales = [1]\n\n    def blackboxes(system):\n        # Returns all blackboxes to evaluate\n        if not do_blackbox:\n            return [None]\n        return all_blackboxes(system)\n\n    def coarse_grains(blackbox, system):\n        # Returns all coarse-grains to test\n        if not do_coarse_grain:\n            return [None]\n        if blackbox is None:\n            return all_coarse_grains(system)\n        return all_coarse_grains_for_blackbox(blackbox)\n\n    # TODO? don't consider the empty set here\n    # (pass `nonempty=True` to `powerset`)\n    for system in utils.powerset(network.node_indices):\n        for time_scale in time_scales:\n            for blackbox in blackboxes(system):\n                for coarse_grain in coarse_grains(blackbox, system):\n                    try:\n                        yield MacroSubsystem(\n                            network, state, system,\n                            time_scale=time_scale,\n                            blackbox=blackbox,\n                            coarse_grain=coarse_grain)\n                    except (StateUnreachableError,\n                            ConditionallyDependentError):\n                        continue", "response": "Generator over all possible macro - systems for the given network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck for the emergence of a micro - system into a macro - system.", "response": "def emergence(network, state, do_blackbox=False, do_coarse_grain=True,\n              time_scales=None):\n    \"\"\"Check for the emergence of a micro-system into a macro-system.\n\n    Checks all possible blackboxings and coarse-grainings of a system to find\n    the spatial scale with maximum integrated information.\n\n    Use the ``do_blackbox`` and ``do_coarse_grain`` args to specifiy whether to\n    use blackboxing, coarse-graining, or both. The default is to just\n    coarse-grain the system.\n\n    Args:\n        network (Network): The network of the micro-system under investigation.\n        state (tuple[int]): The state of the network.\n        do_blackbox (bool): Set to ``True`` to enable blackboxing. Defaults to\n            ``False``.\n        do_coarse_grain (bool): Set to ``True`` to enable coarse-graining.\n            Defaults to ``True``.\n        time_scales (list[int]): List of all time steps over which to check\n            for emergence.\n\n    Returns:\n        MacroNetwork: The maximal macro-system generated from the\n        micro-system.\n    \"\"\"\n    micro_phi = compute.major_complex(network, state).phi\n\n    max_phi = float('-inf')\n    max_network = None\n\n    for subsystem in all_macro_systems(network, state, do_blackbox=do_blackbox,\n                                       do_coarse_grain=do_coarse_grain,\n                                       time_scales=time_scales):\n        phi = compute.phi(subsystem)\n\n        if (phi - max_phi) > constants.EPSILON:\n            max_phi = phi\n            max_network = MacroNetwork(\n                network=network,\n                macro_phi=phi,\n                micro_phi=micro_phi,\n                system=subsystem.micro_node_indices,\n                time_scale=subsystem.time_scale,\n                blackbox=subsystem.blackbox,\n                coarse_grain=subsystem.coarse_grain)\n\n    return max_network"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef effective_info(network):\n    validate.is_network(network)\n\n    sbs_tpm = convert.state_by_node2state_by_state(network.tpm)\n    avg_repertoire = np.mean(sbs_tpm, 0)\n\n    return np.mean([entropy(repertoire, avg_repertoire, 2.0)\n                    for repertoire in sbs_tpm])", "response": "Return the effective information of the given network."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef node_labels(self):\n        assert list(self.node_indices)[0] == 0\n        labels = list(\"m{}\".format(i) for i in self.node_indices)\n        return NodeLabels(labels, self.node_indices)", "response": "Return the labels for macro nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsqueezes out all singleton dimensions in the Subsystem.", "response": "def _squeeze(system):\n        \"\"\"Squeeze out all singleton dimensions in the Subsystem.\n\n        Reindexes the subsystem so that the nodes are ``0..n`` where ``n`` is\n        the number of internal indices in the system.\n        \"\"\"\n        assert system.node_indices == tpm_indices(system.tpm)\n\n        internal_indices = tpm_indices(system.tpm)\n\n        tpm = remove_singleton_dimensions(system.tpm)\n\n        # The connectivity matrix is the network's connectivity matrix, with\n        # cut applied, with all connections to/from external nodes severed,\n        # shrunk to the size of the internal nodes.\n        cm = system.cm[np.ix_(internal_indices, internal_indices)]\n\n        state = utils.state_of(internal_indices, system.state)\n\n        # Re-index the subsystem nodes with the external nodes removed\n        node_indices = reindex(internal_indices)\n        nodes = generate_nodes(tpm, cm, state, node_indices)\n\n        # Re-calcuate the tpm based on the results of the cut\n        tpm = rebuild_system_tpm(node.tpm_on for node in nodes)\n\n        return SystemAttrs(tpm, cm, node_indices, state)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _blackbox_partial_noise(blackbox, system):\n        # Noise inputs from non-output elements hidden in other boxes\n        node_tpms = []\n        for node in system.nodes:\n            node_tpm = node.tpm_on\n            for input_node in node.inputs:\n                if blackbox.hidden_from(input_node, node.index):\n                    node_tpm = marginalize_out([input_node], node_tpm)\n\n            node_tpms.append(node_tpm)\n\n        tpm = rebuild_system_tpm(node_tpms)\n\n        return system._replace(tpm=tpm)", "response": "Noise connections from hidden elements to other boxes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nblacks box the CM and TPM over the given time_scale.", "response": "def _blackbox_time(time_scale, blackbox, system):\n        \"\"\"Black box the CM and TPM over the given time_scale.\"\"\"\n        blackbox = blackbox.reindex()\n\n        tpm = run_tpm(system, time_scale, blackbox)\n\n        # Universal connectivity, for now.\n        n = len(system.node_indices)\n        cm = np.ones((n, n))\n\n        return SystemAttrs(tpm, cm, system.node_indices, system.state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _blackbox_space(self, blackbox, system):\n        tpm = marginalize_out(blackbox.hidden_indices, system.tpm)\n\n        assert blackbox.output_indices == tpm_indices(tpm)\n\n        tpm = remove_singleton_dimensions(tpm)\n        n = len(blackbox)\n        cm = np.zeros((n, n))\n        for i, j in itertools.product(range(n), repeat=2):\n            # TODO: don't pull cm from self\n            outputs = self.blackbox.outputs_of(i)\n            to = self.blackbox.partition[j]\n            if self.cm[np.ix_(outputs, to)].sum() > 0:\n                cm[i, j] = 1\n\n        state = blackbox.macro_state(system.state)\n        node_indices = blackbox.macro_indices\n\n        return SystemAttrs(tpm, cm, node_indices, state)", "response": "Blackbox the TPM and CM in space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cut_mechanisms(self):\n        for mechanism in utils.powerset(self.node_indices, nonempty=True):\n            micro_mechanism = self.macro2micro(mechanism)\n            if self.cut.splits_mechanism(micro_mechanism):\n                yield mechanism", "response": "Yields the mechanisms that are currently cut."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a cut version of this |MacroSubsystem|.", "response": "def apply_cut(self, cut):\n        \"\"\"Return a cut version of this |MacroSubsystem|.\n\n        Args:\n            cut (Cut): The cut to apply to this |MacroSubsystem|.\n\n        Returns:\n            MacroSubsystem: The cut version of this |MacroSubsystem|.\n        \"\"\"\n        # TODO: is the MICE cache reusable?\n        return MacroSubsystem(\n            self.network,\n            self.network_state,\n            self.micro_node_indices,\n            cut=cut,\n            time_scale=self.time_scale,\n            blackbox=self.blackbox,\n            coarse_grain=self.coarse_grain)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef potential_purviews(self, direction, mechanism, purviews=False):\n        all_purviews = utils.powerset(self.node_indices)\n        return irreducible_purviews(\n            self.cm, direction, mechanism, all_purviews)", "response": "Override Subsystem implementation using Network - level indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all micro indices which compose the elements specified by macro_indices.", "response": "def macro2micro(self, macro_indices):\n        \"\"\"Return all micro indices which compose the elements specified by\n        ``macro_indices``.\n        \"\"\"\n        def from_partition(partition, macro_indices):\n            micro_indices = itertools.chain.from_iterable(\n                partition[i] for i in macro_indices)\n            return tuple(sorted(micro_indices))\n\n        if self.blackbox and self.coarse_grain:\n            cg_micro_indices = from_partition(self.coarse_grain.partition,\n                                              macro_indices)\n            return from_partition(self.blackbox.partition,\n                                  reindex(cg_micro_indices))\n        elif self.blackbox:\n            return from_partition(self.blackbox.partition, macro_indices)\n        elif self.coarse_grain:\n            return from_partition(self.coarse_grain.partition, macro_indices)\n        return macro_indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef macro2blackbox_outputs(self, macro_indices):\n        if not self.blackbox:\n            raise ValueError('System is not blackboxed')\n\n        return tuple(sorted(set(\n            self.macro2micro(macro_indices)\n        ).intersection(self.blackbox.output_indices)))", "response": "Given a set of macro elements return the blackbox output elements\n        which compose these elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef micro_indices(self):\n        return tuple(sorted(idx for part in self.partition for idx in part))", "response": "Indices of micro elements represented in this coarse - graining."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reindex(self):\n        _map = dict(zip(self.micro_indices, reindex(self.micro_indices)))\n        partition = tuple(\n            tuple(_map[index] for index in group)\n            for group in self.partition\n        )\n        return CoarseGrain(partition, self.grouping)", "response": "Re - index this coarse graining to use squeezed indices."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef macro_state(self, micro_state):\n        assert len(micro_state) == len(self.micro_indices)\n\n        # TODO: only reindex if this coarse grain is not already from 0..n?\n        # make_mapping calls this in a tight loop so it might be more efficient\n        # to reindex conditionally.\n        reindexed = self.reindex()\n\n        micro_state = np.array(micro_state)\n        return tuple(0 if sum(micro_state[list(reindexed.partition[i])])\n                     in self.grouping[i][0] else 1\n                     for i in self.macro_indices)", "response": "Translate a micro state to a macro state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a mapping from micro - state to macro - state based on the partition and state grouping of this coarse - grain.", "response": "def make_mapping(self):\n        \"\"\"Return a mapping from micro-state to the macro-states based on the\n        partition and state grouping of this coarse-grain.\n\n        Return:\n            (nd.ndarray): A mapping from micro-states to macro-states. The\n            |ith| entry in the mapping is the macro-state corresponding to the\n            |ith| micro-state.\n        \"\"\"\n        micro_states = utils.all_states(len(self.micro_indices))\n\n        # Find the corresponding macro-state for each micro-state.\n        # The i-th entry in the mapping is the macro-state corresponding to the\n        # i-th micro-state.\n        mapping = [convert.state2le_index(self.macro_state(micro_state))\n                   for micro_state in micro_states]\n        return np.array(mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef macro_tpm_sbs(self, state_by_state_micro_tpm):\n        validate.tpm(state_by_state_micro_tpm, check_independence=False)\n\n        mapping = self.make_mapping()\n\n        num_macro_states = 2 ** len(self.macro_indices)\n        macro_tpm = np.zeros((num_macro_states, num_macro_states))\n\n        micro_states = range(2 ** len(self.micro_indices))\n        micro_state_transitions = itertools.product(micro_states, repeat=2)\n\n        # For every possible micro-state transition, get the corresponding\n        # previous and next macro-state using the mapping and add that\n        # probability to the state-by-state macro TPM.\n        for previous_state, current_state in micro_state_transitions:\n            macro_tpm[mapping[previous_state], mapping[current_state]] += (\n                state_by_state_micro_tpm[previous_state, current_state])\n\n        # Re-normalize each row because we're going from larger to smaller TPM\n        return np.array([distribution.normalize(row) for row in macro_tpm])", "response": "Create a state - by - state coarse - grained macro - system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef macro_tpm(self, micro_tpm, check_independence=True):\n        if not is_state_by_state(micro_tpm):\n            micro_tpm = convert.state_by_node2state_by_state(micro_tpm)\n\n        macro_tpm = self.macro_tpm_sbs(micro_tpm)\n\n        if check_independence:\n            validate.conditionally_independent(macro_tpm)\n\n        return convert.state_by_state2state_by_node(macro_tpm)", "response": "Create a coarse - grained macro TPM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef outputs_of(self, partition_index):\n        partition = self.partition[partition_index]\n        outputs = set(partition).intersection(self.output_indices)\n        return tuple(sorted(outputs))", "response": "The outputs of the partition at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsqueeze the indices of this blackboxing to 0.. n.", "response": "def reindex(self):\n        \"\"\"Squeeze the indices of this blackboxing to ``0..n``.\n\n        Returns:\n            Blackbox: a new, reindexed |Blackbox|.\n\n        Example:\n            >>> partition = ((3,), (2, 4))\n            >>> output_indices = (2, 3)\n            >>> blackbox = Blackbox(partition, output_indices)\n            >>> blackbox.reindex()\n            Blackbox(partition=((1,), (0, 2)), output_indices=(0, 1))\n        \"\"\"\n        _map = dict(zip(self.micro_indices, reindex(self.micro_indices)))\n        partition = tuple(\n            tuple(_map[index] for index in group)\n            for group in self.partition\n        )\n        output_indices = tuple(_map[i] for i in self.output_indices)\n\n        return Blackbox(partition, output_indices)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef macro_state(self, micro_state):\n        assert len(micro_state) == len(self.micro_indices)\n\n        reindexed = self.reindex()\n        return utils.state_of(reindexed.output_indices, micro_state)", "response": "Compute the macro - state of this blackbox."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if nodes a and b are in the same box.", "response": "def in_same_box(self, a, b):\n        \"\"\"Return ``True`` if nodes ``a`` and ``b``` are in the same box.\"\"\"\n        assert a in self.micro_indices\n        assert b in self.micro_indices\n\n        for part in self.partition:\n            if a in part and b in part:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if a is hidden from b.", "response": "def hidden_from(self, a, b):\n        \"\"\"Return True if ``a`` is hidden in a different box than ``b``.\"\"\"\n        return a in self.hidden_indices and not self.in_same_box(a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef irreducible_purviews(cm, direction, mechanism, purviews):\n    def reducible(purview):\n        \"\"\"Return ``True`` if purview is trivially reducible.\"\"\"\n        _from, to = direction.order(mechanism, purview)\n        return connectivity.block_reducible(cm, _from, to)\n\n    return [purview for purview in purviews if not reducible(purview)]", "response": "Return all purviews which are irreducible for the mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_tpm(tpm):\n        tpm = np.array(tpm)\n\n        validate.tpm(tpm)\n\n        # Convert to multidimensional state-by-node form\n        if is_state_by_state(tpm):\n            tpm = convert.state_by_state2state_by_node(tpm)\n        else:\n            tpm = convert.to_multidimensional(tpm)\n\n        utils.np_immutable(tpm)\n\n        return (tpm, utils.np_hash(tpm))", "response": "Validate the TPM passed by the user and convert to multidimensional state - by - node form."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the passed CM to the proper format or construct the unitary CM.", "response": "def _build_cm(self, cm):\n        \"\"\"Convert the passed CM to the proper format, or construct the\n        unitary CM if none was provided.\n        \"\"\"\n        if cm is None:\n            # Assume all are connected.\n            cm = np.ones((self.size, self.size))\n        else:\n            cm = np.array(cm)\n\n        utils.np_immutable(cm)\n\n        return (cm, utils.np_hash(cm))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef potential_purviews(self, direction, mechanism):\n        all_purviews = utils.powerset(self._node_indices)\n        return irreducible_purviews(self.cm, direction, mechanism,\n                                    all_purviews)", "response": "Returns a list of all purviews which are irreducible over the given mechanism."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON - serializable representation of the object.", "response": "def to_json(self):\n        \"\"\"Return a JSON-serializable representation.\"\"\"\n        return {\n            'tpm': self.tpm,\n            'cm': self.cm,\n            'size': self.size,\n            'node_labels': self.node_labels\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a JSON - encodable representation of an object recursively using any available to_json methods converting NumPy arrays and datatypes to native lists and types along the way.", "response": "def jsonify(obj):  # pylint: disable=too-many-return-statements\n    \"\"\"Return a JSON-encodable representation of an object, recursively using\n    any available ``to_json`` methods, converting NumPy arrays and datatypes to\n    native lists and types along the way.\n    \"\"\"\n    # Call the `to_json` method if available and add metadata.\n    if hasattr(obj, 'to_json'):\n        d = obj.to_json()\n        _push_metadata(d, obj)\n        return jsonify(d)\n\n    # If we have a numpy array, convert it to a list.\n    if isinstance(obj, np.ndarray):\n        return obj.tolist()\n\n    # If we have NumPy datatypes, convert them to native types.\n    if isinstance(obj, (np.int32, np.int64)):\n        return int(obj)\n    if isinstance(obj, np.float64):\n        return float(obj)\n\n    # Recurse over dictionaries.\n    if isinstance(obj, dict):\n        return _jsonify_dict(obj)\n\n    # Recurse over object dictionaries.\n    if hasattr(obj, '__dict__'):\n        return _jsonify_dict(obj.__dict__)\n\n    # Recurse over lists and tuples.\n    if isinstance(obj, (list, tuple)):\n        return [jsonify(item) for item in obj]\n\n    # Otherwise, give up and hope it's serializable.\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize obj as a JSON - formatted stream and write to fp.", "response": "def dump(obj, fp, **user_kwargs):\n    \"\"\"Serialize ``obj`` as a JSON-formatted stream and write to ``fp`` (a\n    ``.write()``-supporting file-like object.\n    \"\"\"\n    return json.dump(obj, fp, **_encoder_kwargs(user_kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_version(version):\n    if version != pyphi.__version__:\n        raise pyphi.exceptions.JSONVersionError(\n            'Cannot load JSON from a different version of PyPhi. '\n            'JSON version = {0}, current version = {1}.'.format(\n                version, pyphi.__version__))", "response": "Check whether the JSON version matches the PyPhi version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a serialized PyPhi model.", "response": "def _load_model(self, dct):\n        \"\"\"Load a serialized PyPhi model.\n\n        The object is memoized for reuse elsewhere in the object graph.\n        \"\"\"\n        classname, version, _ = _pop_metadata(dct)\n\n        _check_version(version)\n        cls = self._models[classname]\n\n        # Use `from_json` if available\n        if hasattr(cls, 'from_json'):\n            return cls.from_json(dct)\n\n        # Default to object constructor\n        return cls(**dct)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing and store a Hamming matrix for the given number of nodes.", "response": "def _compute_hamming_matrix(N):\n    \"\"\"Compute and store a Hamming matrix for |N| nodes.\n\n    Hamming matrices have the following sizes::\n\n        N   MBs\n        ==  ===\n        9   2\n        10  8\n        11  32\n        12  128\n        13  512\n\n    Given these sizes and the fact that large matrices are needed infrequently,\n    we store computed matrices using the Joblib filesystem cache instead of\n    adding computed matrices to the ``_hamming_matrices`` global and clogging\n    up memory.\n\n    This function is only called when |N| >\n    ``_NUM_PRECOMPUTED_HAMMING_MATRICES``. Don't call this function directly;\n    use |_hamming_matrix| instead.\n    \"\"\"\n    possible_states = np.array(list(utils.all_states((N))))\n    return cdist(possible_states, possible_states, 'hamming') * N"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hamming_emd(d1, d2):\n    N = d1.squeeze().ndim\n    d1, d2 = flatten(d1), flatten(d2)\n    return emd(d1, d2, _hamming_matrix(N))", "response": "Return the Earth Mover s Distance between two distributions using the Hamming distance between states\n    by state one dimension per node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef effect_emd(d1, d2):\n    return sum(abs(marginal_zero(d1, i) - marginal_zero(d2, i))\n               for i in range(d1.ndim))", "response": "Compute the EMD between two effect repertoires."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kld(d1, d2):\n    d1, d2 = flatten(d1), flatten(d2)\n    return entropy(d1, d2, 2.0)", "response": "Return the Kullback - Leibler Divergence between two distributions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the difference in entropy between two distributions.", "response": "def entropy_difference(d1, d2):\n    \"\"\"Return the difference in entropy between two distributions.\"\"\"\n    d1, d2 = flatten(d1), flatten(d2)\n    return abs(entropy(d1, base=2.0) - entropy(d2, base=2.0))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the PSQ2 measure.", "response": "def psq2(d1, d2):\n    \"\"\"Compute the PSQ2 measure.\n\n    Args:\n        d1 (np.ndarray): The first distribution.\n        d2 (np.ndarray): The second distribution.\n    \"\"\"\n    d1, d2 = flatten(d1), flatten(d2)\n\n    def f(p):\n        return sum((p ** 2) * np.nan_to_num(np.log(p * len(p))))\n\n    return abs(f(d1) - f(d2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the MP2Q measure.", "response": "def mp2q(p, q):\n    \"\"\"Compute the MP2Q measure.\n\n    Args:\n        p (np.ndarray): The unpartitioned repertoire\n        q (np.ndarray): The partitioned repertoire\n    \"\"\"\n    p, q = flatten(p), flatten(q)\n    entropy_dist = 1 / len(p)\n    return sum(entropy_dist * np.nan_to_num((p ** 2) / q * np.log(p / q)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef klm(p, q):\n    p, q = flatten(p), flatten(q)\n    return max(abs(p * np.nan_to_num(np.log(p / q))))", "response": "Compute the KLM divergence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the EMD between two repertoires in a given direction.", "response": "def directional_emd(direction, d1, d2):\n    \"\"\"Compute the EMD between two repertoires for a given direction.\n\n    The full EMD computation is used for cause repertoires. A fast analytic\n    solution is used for effect repertoires.\n\n    Args:\n        direction (Direction): |CAUSE| or |EFFECT|.\n        d1 (np.ndarray): The first repertoire.\n        d2 (np.ndarray): The second repertoire.\n\n    Returns:\n        float: The EMD between ``d1`` and ``d2``, rounded to |PRECISION|.\n\n    Raises:\n        ValueError: If ``direction`` is invalid.\n    \"\"\"\n    if direction == Direction.CAUSE:\n        func = hamming_emd\n    elif direction == Direction.EFFECT:\n        func = effect_emd\n    else:\n        # TODO: test that ValueError is raised\n        validate.direction(direction)\n\n    return round(func(d1, d2), config.PRECISION)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the distance between two repertoires for the given direction.", "response": "def repertoire_distance(direction, r1, r2):\n    \"\"\"Compute the distance between two repertoires for the given direction.\n\n    Args:\n        direction (Direction): |CAUSE| or |EFFECT|.\n        r1 (np.ndarray): The first repertoire.\n        r2 (np.ndarray): The second repertoire.\n\n    Returns:\n        float: The distance between ``d1`` and ``d2``, rounded to |PRECISION|.\n    \"\"\"\n    if config.MEASURE == 'EMD':\n        dist = directional_emd(direction, r1, r2)\n    else:\n        dist = measures[config.MEASURE](r1, r2)\n\n    return round(dist, config.PRECISION)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef system_repertoire_distance(r1, r2):\n    if config.MEASURE in measures.asymmetric():\n        raise ValueError(\n            '{} is asymmetric and cannot be used as a system-level '\n            'irreducibility measure.'.format(config.MEASURE))\n\n    return measures[config.MEASURE](r1, r2)", "response": "Compute the distance between two repertoires of a system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef partitions(collection):\n    collection = list(collection)\n\n    # Special cases\n    if not collection:\n        return\n\n    if len(collection) == 1:\n        yield [collection]\n        return\n\n    first = collection[0]\n    for smaller in partitions(collection[1:]):\n        for n, subset in enumerate(smaller):\n            yield smaller[:n] + [[first] + subset] + smaller[n+1:]\n        yield [[first]] + smaller", "response": "Generate all set partitions of a collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn indices for undirected bipartitions of a sequence.", "response": "def bipartition_indices(N):\n    \"\"\"Return indices for undirected bipartitions of a sequence.\n\n    Args:\n        N (int): The length of the sequence.\n\n    Returns:\n        list: A list of tuples containing the indices for each of the two\n        parts.\n\n    Example:\n        >>> N = 3\n        >>> bipartition_indices(N)\n        [((), (0, 1, 2)), ((0,), (1, 2)), ((1,), (0, 2)), ((0, 1), (2,))]\n    \"\"\"\n    result = []\n    if N <= 0:\n        return result\n\n    for i in range(2**(N - 1)):\n        part = [[], []]\n        for n in range(N):\n            bit = (i >> n) & 1\n            part[bit].append(n)\n        result.append((tuple(part[1]), tuple(part[0])))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of bipartitions for a sequence.", "response": "def bipartition(seq):\n    \"\"\"Return a list of bipartitions for a sequence.\n\n    Args:\n        a (Iterable): The sequence to partition.\n\n    Returns:\n        list[tuple[tuple]]: A list of tuples containing each of the two\n        partitions.\n\n    Example:\n        >>> bipartition((1,2,3))\n        [((), (1, 2, 3)), ((1,), (2, 3)), ((2,), (1, 3)), ((1, 2), (3,))]\n    \"\"\"\n    return [(tuple(seq[i] for i in part0_idx),\n             tuple(seq[j] for j in part1_idx))\n            for part0_idx, part1_idx in bipartition_indices(len(seq))]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of directed bipartitions for a sequence.", "response": "def directed_bipartition(seq, nontrivial=False):\n    \"\"\"Return a list of directed bipartitions for a sequence.\n\n    Args:\n        seq (Iterable): The sequence to partition.\n\n    Returns:\n        list[tuple[tuple]]: A list of tuples containing each of the two\n        parts.\n\n    Example:\n        >>> directed_bipartition((1, 2, 3))  # doctest: +NORMALIZE_WHITESPACE\n        [((), (1, 2, 3)),\n         ((1,), (2, 3)),\n         ((2,), (1, 3)),\n         ((1, 2), (3,)),\n         ((3,), (1, 2)),\n         ((1, 3), (2,)),\n         ((2, 3), (1,)),\n         ((1, 2, 3), ())]\n    \"\"\"\n    bipartitions = [\n        (tuple(seq[i] for i in part0_idx), tuple(seq[j] for j in part1_idx))\n        for part0_idx, part1_idx in directed_bipartition_indices(len(seq))\n    ]\n    if nontrivial:\n        # The first and last partitions have a part that is empty; skip them.\n        # NOTE: This depends on the implementation of\n        # `directed_partition_indices`.\n        return bipartitions[1:-1]\n    return bipartitions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate bipartitions where one part is of length 1.", "response": "def bipartition_of_one(seq):\n    \"\"\"Generate bipartitions where one part is of length 1.\"\"\"\n    seq = list(seq)\n    for i, elt in enumerate(seq):\n        yield ((elt,), tuple(seq[:i] + seq[(i + 1):]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef directed_bipartition_of_one(seq):\n    bipartitions = list(bipartition_of_one(seq))\n    return chain(bipartitions, reverse_elements(bipartitions))", "response": "Generate directed bipartitions where one part is of length 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns indices for directed tripartitions of a sequence.", "response": "def directed_tripartition_indices(N):\n    \"\"\"Return indices for directed tripartitions of a sequence.\n\n    Args:\n        N (int): The length of the sequence.\n\n    Returns:\n        list[tuple]: A list of tuples containing the indices for each\n        partition.\n\n    Example:\n        >>> N = 1\n        >>> directed_tripartition_indices(N)\n        [((0,), (), ()), ((), (0,), ()), ((), (), (0,))]\n    \"\"\"\n    result = []\n    if N <= 0:\n        return result\n\n    base = [0, 1, 2]\n    for key in product(base, repeat=N):\n        part = [[], [], []]\n        for i, location in enumerate(key):\n            part[location].append(i)\n\n        result.append(tuple(tuple(p) for p in part))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef directed_tripartition(seq):\n    for a, b, c in directed_tripartition_indices(len(seq)):\n        yield (tuple(seq[i] for i in a),\n               tuple(seq[j] for j in b),\n               tuple(seq[k] for k in c))", "response": "Generator over all directed tripartitions of a sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates all k - partitions of a collection.", "response": "def k_partitions(collection, k):\n    \"\"\"Generate all ``k``-partitions of a collection.\n\n    Example:\n        >>> list(k_partitions(range(3), 2))\n        [[[0, 1], [2]], [[0], [1, 2]], [[0, 2], [1]]]\n    \"\"\"\n    collection = list(collection)\n    n = len(collection)\n\n    # Special cases\n    if n == 0 or k < 1:\n        return []\n    if k == 1:\n        return [[collection]]\n\n    a = [0] * (n + 1)\n    for j in range(1, k + 1):\n        a[n - k + j] = j - 1\n    return _f(k, n, 0, n, a, k, collection)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mip_partitions(mechanism, purview, node_labels=None):\n    func = partition_types[config.PARTITION_TYPE]\n    return func(mechanism, purview, node_labels)", "response": "Return a generator over all mechanism - purview partitions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator over all wedge partitions of a mechanism and purview.", "response": "def wedge_partitions(mechanism, purview, node_labels=None):\n    \"\"\"Return an iterator over all wedge partitions.\n\n    These are partitions which strictly split the mechanism and allow a subset\n    of the purview to be split into a third partition, e.g.::\n\n         A     B     \u2205\n        \u2500\u2500\u2500 \u2715 \u2500\u2500\u2500 \u2715 \u2500\u2500\u2500\n         B     C     D\n\n    See |PARTITION_TYPE| in |config| for more information.\n\n    Args:\n        mechanism (tuple[int]): A mechanism.\n        purview (tuple[int]): A purview.\n\n    Yields:\n        Tripartition: all unique tripartitions of this mechanism and purview.\n    \"\"\"\n    numerators = bipartition(mechanism)\n    denominators = directed_tripartition(purview)\n\n    yielded = set()\n\n    def valid(factoring):\n        \"\"\"Return whether the factoring should be considered.\"\"\"\n        # pylint: disable=too-many-boolean-expressions\n        numerator, denominator = factoring\n        return (\n            (numerator[0] or denominator[0]) and\n            (numerator[1] or denominator[1]) and\n            ((numerator[0] and numerator[1]) or\n             not denominator[0] or\n             not denominator[1])\n        )\n\n    for n, d in filter(valid, product(numerators, denominators)):\n        # Normalize order of parts to remove duplicates.\n        tripart = Tripartition(\n            Part(n[0], d[0]),\n            Part(n[1], d[1]),\n            Part((), d[2]),\n            node_labels=node_labels\n        ).normalize()  # pylint: disable=bad-whitespace\n\n        def nonempty(part):\n            \"\"\"Check that the part is not empty.\"\"\"\n            return part.mechanism or part.purview\n\n        def compressible(tripart):\n            \"\"\"Check if the tripartition can be transformed into a causally\n            equivalent partition by combing two of its parts; e.g., A/\u2205 \u00d7 B/\u2205 \u00d7\n            \u2205/CD is equivalent to AB/\u2205 \u00d7 \u2205/CD so we don't include it.\n            \"\"\"\n            pairs = [\n                (tripart[0], tripart[1]),\n                (tripart[0], tripart[2]),\n                (tripart[1], tripart[2])\n            ]\n            for x, y in pairs:\n                if (nonempty(x) and nonempty(y) and\n                        (x.mechanism + y.mechanism == () or\n                         x.purview + y.purview == ())):\n                    return True\n            return False\n\n        if not compressible(tripart) and tripart not in yielded:\n            yielded.add(tripart)\n            yield tripart"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all possible partitions of a mechanism and purview.", "response": "def all_partitions(mechanism, purview, node_labels=None):\n    \"\"\"Return all possible partitions of a mechanism and purview.\n\n    Partitions can consist of any number of parts.\n\n    Args:\n        mechanism (tuple[int]): A mechanism.\n        purview (tuple[int]): A purview.\n\n    Yields:\n        KPartition: A partition of this mechanism and purview into ``k`` parts.\n    \"\"\"\n    for mechanism_partition in partitions(mechanism):\n        mechanism_partition.append([])\n        n_mechanism_parts = len(mechanism_partition)\n        max_purview_partition = min(len(purview), n_mechanism_parts)\n        for n_purview_parts in range(1, max_purview_partition + 1):\n            n_empty = n_mechanism_parts - n_purview_parts\n            for purview_partition in k_partitions(purview, n_purview_parts):\n                purview_partition = [tuple(_list)\n                                     for _list in purview_partition]\n                # Extend with empty tuples so purview partition has same size\n                # as mechanism purview\n                purview_partition.extend([()] * n_empty)\n\n                # Unique permutations to avoid duplicates empties\n                for purview_permutation in set(\n                        permutations(purview_partition)):\n\n                    parts = [\n                        Part(tuple(m), tuple(p))\n                        for m, p in zip(mechanism_partition,\n                                        purview_permutation)\n                    ]\n\n                    # Must partition the mechanism, unless the purview is fully\n                    # cut away from the mechanism.\n                    if parts[0].mechanism == mechanism and parts[0].purview:\n                        continue\n\n                    yield KPartition(*parts, node_labels=node_labels)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_bootdev(self):\n        result = self._do_web_request(self.sysurl)\n        overridestate = result.get('Boot', {}).get(\n            'BootSourceOverrideEnabled', None)\n        if overridestate == 'Disabled':\n            return {'bootdev': 'default', 'persistent': True}\n        persistent = None\n        if overridestate == 'Once':\n            persistent = False\n        elif overridestate == 'Continuous':\n            persistent = True\n        else:\n            raise exc.PyghmiException('Unrecognized Boot state: '\n                                      + repr(overridestate))\n        uefimode = result.get('Boot', {}).get('BootSourceOverrideMode', None)\n        if uefimode == 'UEFI':\n            uefimode = True\n        elif uefimode == 'Legacy':\n            uefimode = False\n        else:\n            raise exc.PyghmiException('Unrecognized mode: ' + uefimode)\n        bootdev = result.get('Boot', {}).get('BootSourceOverrideTarget', None)\n        if bootdev not in boot_devices_read:\n            raise exc.PyghmiException('Unrecognized boot target: '\n                                      + repr(bootdev))\n        bootdev = boot_devices_read[bootdev]\n        return {'bootdev': bootdev, 'persistent': persistent,\n                'uefimode': uefimode}", "response": "Get current boot device override information."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting boot device to use on next reboot", "response": "def set_bootdev(self, bootdev, persist=False, uefiboot=None):\n        \"\"\"Set boot device to use on next reboot\n\n        :param bootdev:\n                        *network -- Request network boot\n                        *hd -- Boot from hard drive\n                        *safe -- Boot from hard drive, requesting 'safe mode'\n                        *optical -- boot from CD/DVD/BD drive\n                        *setup -- Boot into setup utility\n                        *default -- remove any directed boot device request\n        :param persist: If true, ask that system firmware use this device\n                        beyond next boot.  Be aware many systems do not honor\n                        this\n        :param uefiboot: If true, request UEFI boot explicitly.  If False,\n                         request BIOS style boot.\n                         None (default) does not modify the boot mode.\n        :raises: PyghmiException on an error.\n        :returns: dict or True -- If callback is not provided, the response\n        \"\"\"\n        reqbootdev = bootdev\n        if (bootdev not in boot_devices_write\n                and bootdev not in boot_devices_read):\n            raise exc.InvalidParameterValue('Unsupported device '\n                                            + repr(bootdev))\n        bootdev = boot_devices_write.get(bootdev, bootdev)\n        if bootdev == 'None':\n            payload = {'Boot': {'BootSourceOverrideEnabled': 'Disabled'}}\n        else:\n            payload = {'Boot': {\n                'BootSourceOverrideEnabled': 'Continuous' if persist\n                                             else 'Once',\n                'BootSourceOverrideTarget': bootdev,\n            }}\n            if uefiboot is not None:\n                uefiboot = 'UEFI' if uefiboot else 'Legacy'\n                payload['BootSourceOverrideMode'] = uefiboot\n        self._do_web_request(self.sysurl, payload, method='PATCH')\n        return {'bootdev': reqbootdev}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing the BIOS configuration", "response": "def clear_system_configuration(self):\n        \"\"\"Clear the BIOS/UEFI configuration\n\n        \"\"\"\n        biosinfo = self._do_web_request(self._biosurl)\n        rb = biosinfo.get('Actions', {}).get('#Bios.ResetBios', {})\n        rb = rb.get('target', '')\n        if not rb:\n            raise Exception('BIOS reset not detected on this system')\n        self._do_web_request(rb, {'Action': 'Bios.ResetBios'})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef naturalize_string(key):\n    return [int(text) if text.isdigit() else text.lower()\n            for text in re.split(numregex, key)]", "response": "Analyzes a string in a human way to enable natural sort\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_eventdata(sensor_type, offset, eventdata, sdr):\n    if sensor_type == 5 and offset == 4:  # link loss, indicates which port\n        return 'Port {0}'.format(eventdata[1])\n    elif sensor_type == 8 and offset == 6:  # PSU cfg error\n        errtype = eventdata[2] & 0b1111\n        return psucfg_errors.get(errtype, 'Unknown')\n    elif sensor_type == 0xc and offset == 8:  # Memory spare\n        return 'Module {0}'.format(eventdata[2])\n    elif sensor_type == 0xf:\n        if offset == 0:  # firmware error\n            return firmware_errors.get(eventdata[1], 'Unknown')\n        elif offset in (1, 2):\n            return firmware_progress.get(eventdata[1], 'Unknown')\n    elif sensor_type == 0x10:\n        if offset == 0:  # Correctable error logging on a specific memory part\n            return 'Module {0}'.format(eventdata[1])\n        elif offset == 1:\n            return 'Reading type {0:02X}h, offset {1:02X}h'.format(\n                eventdata[1], eventdata[2] & 0b1111)\n        elif offset == 5:\n            return '{0}%'.format(eventdata[2])\n        elif offset == 6:\n            return 'Processor {0}'.format(eventdata[1])\n    elif sensor_type == 0x12:\n        if offset == 3:\n            action = (eventdata[1] & 0b1111000) >> 4\n            return auxlog_actions.get(action, 'Unknown')\n        elif offset == 4:\n            sysactions = []\n            if eventdata[1] & 0b1 << 5:\n                sysactions.append('NMI')\n            if eventdata[1] & 0b1 << 4:\n                sysactions.append('OEM action')\n            if eventdata[1] & 0b1 << 3:\n                sysactions.append('Power Cycle')\n            if eventdata[1] & 0b1 << 2:\n                sysactions.append('Reset')\n            if eventdata[1] & 0b1 << 1:\n                sysactions.append('Power Down')\n            if eventdata[1] & 0b1:\n                sysactions.append('Alert')\n            return ','.join(sysactions)\n        elif offset == 5:  # Clock change event, either before or after\n            if eventdata[1] & 0b10000000:\n                return 'After'\n            else:\n                return 'Before'\n    elif sensor_type == 0x19 and offset == 0:\n        return 'Requested {0] while {1}'.format(eventdata[1], eventdata[2])\n    elif sensor_type == 0x1d and offset == 7:\n        return restart_causes.get(eventdata[1], 'Unknown')\n    elif sensor_type == 0x21:\n        return '{0} {1}'.format(slot_types.get(eventdata[1], 'Unknown'),\n                                eventdata[2])\n\n    elif sensor_type == 0x23:\n        phase = eventdata[1] & 0b1111\n        return watchdog_boot_phases.get(phase, 'Unknown')\n    elif sensor_type == 0x28:\n        if offset == 4:\n            return 'Sensor {0}'.format(eventdata[1])\n        elif offset == 5:\n            islogical = (eventdata[1] & 0b10000000)\n            if islogical:\n                if eventdata[2] in sdr.fru:\n                    return sdr.fru[eventdata[2]].fru_name\n                else:\n                    return 'FRU {0}'.format(eventdata[2])\n    elif sensor_type == 0x2a and offset == 3:\n        return 'User {0}'.format(eventdata[1])\n    elif sensor_type == 0x2b:\n        return version_changes.get(eventdata[1], 'Unknown')\n    elif sensor_type == 0x2c:\n        cause = (eventdata[1] & 0b11110000) >> 4\n        cause = fru_states.get(cause, 'Unknown')\n        oldstate = eventdata[1] & 0b1111\n        if oldstate != offset:\n            try:\n                cause += '(change from {0})'.format(\n                    ipmiconst.sensor_type_offsets[0x2c][oldstate]['desc'])\n            except KeyError:\n                pass", "response": "Decode extra event data from an alert or log."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_sel(self, ipmicmd, clear=False):\n        records = []\n        # First we do a fetch all without reservation, reducing the risk\n        # of having a long lived reservation that gets canceled in the middle\n        endat = self._fetch_entries(ipmicmd, 0, records)\n        if clear and records:  # don't bother clearing if there were no records\n            # To do clear, we make a reservation first...\n            rsp = ipmicmd.xraw_command(netfn=0xa, command=0x42)\n            rsvid = struct.unpack_from('<H', rsp['data'])[0]\n            # Then we refetch the tail with reservation (check for change)\n            del records[-1]  # remove the record that's about to be duplicated\n            self._fetch_entries(ipmicmd, endat, records, rsvid)\n            # finally clear the SEL\n            # 0XAA means start initiate, 0x524c43 is 'RCL' or 'CLR' backwards\n            clrdata = bytearray(struct.pack('<HI', rsvid, 0xAA524C43))\n            ipmicmd.xraw_command(netfn=0xa, command=0x47, data=clrdata)\n        # Now to fixup the record timestamps... first we need to get the BMC\n        # opinion of current time\n        _fix_sel_time(records, ipmicmd)\n        return records", "response": "Fetch the SEL entries from the specified command object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef oem_init(self):\n        if self._oemknown:\n            return\n        self._oem, self._oemknown = get_oem_handler(self._get_device_id(),\n                                                    self)", "response": "Initialize the command object for OEM capabilities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget current boot device override information.", "response": "def get_bootdev(self):\n        \"\"\"Get current boot device override information.\n\n        Provides the current requested boot device.  Be aware that not all IPMI\n        devices support this.  Even in BMCs that claim to, occasionally the\n        BIOS or UEFI fail to honor it. This is usually only applicable to the\n        next reboot.\n\n        :raises: IpmiException on an error.\n        :returns: dict --The response will be provided in the return as a dict\n        \"\"\"\n        response = self.raw_command(netfn=0, command=9, data=(5, 0, 0))\n        # interpret response per 'get system boot options'\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        # this should only be invoked for get system boot option complying to\n        # ipmi spec and targeting the 'boot flags' parameter\n        assert (response['command'] == 9 and\n                response['netfn'] == 1 and\n                response['data'][0] == 1 and\n                (response['data'][1] & 0b1111111) == 5)\n        if (response['data'][1] & 0b10000000 or\n                not response['data'][2] & 0b10000000):\n            return {'bootdev': 'default', 'persistent': True}\n        else:  # will consult data2 of the boot flags parameter for the data\n            persistent = False\n            uefimode = False\n            if response['data'][2] & 0b1000000:\n                persistent = True\n            if response['data'][2] & 0b100000:\n                uefimode = True\n            bootnum = (response['data'][3] & 0b111100) >> 2\n            bootdev = boot_devices.get(bootnum)\n            if bootdev:\n                return {'bootdev': bootdev,\n                        'persistent': persistent,\n                        'uefimode': uefimode}\n            else:\n                return {'bootdev': bootnum,\n                        'persistent': persistent,\n                        'uefimode': uefimode}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting system power state change.", "response": "def set_power(self, powerstate, wait=False):\n        \"\"\"Request power state change (helper)\n\n        :param powerstate:\n                            * on -- Request system turn on\n                            * off -- Request system turn off without waiting\n                                     for OS to shutdown\n                            * shutdown -- Have system request OS proper\n                                          shutdown\n                            * reset -- Request system reset without waiting for\n                              OS\n                            * boot -- If system is off, then 'on', else 'reset'\n        :param wait: If True, do not return until system actually completes\n                     requested state change for 300 seconds.\n                     If a non-zero number, adjust the wait time to the\n                     requested number of seconds\n        :raises: IpmiException on an error\n        :returns: dict -- A dict describing the response retrieved\n        \"\"\"\n        if powerstate not in power_states:\n            raise exc.InvalidParameterValue(\n                \"Unknown power state %s requested\" % powerstate)\n        newpowerstate = powerstate\n        response = self.raw_command(netfn=0, command=1)\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        oldpowerstate = 'on' if (response['data'][0] & 1) else 'off'\n        if oldpowerstate == newpowerstate:\n            return {'powerstate': oldpowerstate}\n        if newpowerstate == 'boot':\n            newpowerstate = 'on' if oldpowerstate == 'off' else 'reset'\n        response = self.raw_command(\n            netfn=0, command=2, data=[power_states[newpowerstate]])\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        lastresponse = {'pendingpowerstate': newpowerstate}\n        waitattempts = 300\n        if not isinstance(wait, bool):\n            waitattempts = wait\n        if (wait and\n           newpowerstate in ('on', 'off', 'shutdown', 'softoff')):\n            if newpowerstate in ('softoff', 'shutdown'):\n                waitpowerstate = 'off'\n            else:\n                waitpowerstate = newpowerstate\n            currpowerstate = None\n            while currpowerstate != waitpowerstate and waitattempts > 0:\n                response = self.raw_command(netfn=0, command=1, delay_xmit=1)\n                if 'error' in response:\n                    raise exc.IpmiException(response['error'])\n                currpowerstate = 'on' if (response['data'][0] & 1) else 'off'\n                waitattempts -= 1\n            if currpowerstate != waitpowerstate:\n                raise exc.IpmiException(\n                    \"System did not accomplish power state change\")\n            return {'powerstate': currpowerstate}\n        else:\n            return lastresponse"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_bmc(self):\n        response = self.raw_command(netfn=6, command=2)\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])", "response": "Do a cold reset in BMC\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_bootdev(self,\n                    bootdev,\n                    persist=False,\n                    uefiboot=False):\n        \"\"\"Set boot device to use on next reboot (helper)\n\n        :param bootdev:\n                        *network -- Request network boot\n                        *hd -- Boot from hard drive\n                        *safe -- Boot from hard drive, requesting 'safe mode'\n                        *optical -- boot from CD/DVD/BD drive\n                        *setup -- Boot into setup utility\n                        *default -- remove any IPMI directed boot device\n                                    request\n        :param persist: If true, ask that system firmware use this device\n                        beyond next boot.  Be aware many systems do not honor\n                        this\n        :param uefiboot: If true, request UEFI boot explicitly.  Strictly\n                         speaking, the spec sugests that if not set, the system\n                         should BIOS boot and offers no \"don't care\" option.\n                         In practice, this flag not being set does not preclude\n                         UEFI boot on any system I've encountered.\n        :raises: IpmiException on an error.\n        :returns: dict or True -- If callback is not provided, the response\n        \"\"\"\n        if bootdev not in boot_devices:\n            return {'error': \"Unknown bootdevice %s requested\" % bootdev}\n        bootdevnum = boot_devices[bootdev]\n        # first, we disable timer by way of set system boot options,\n        # then move on to set chassis capabilities\n        # Set System Boot Options is netfn=0, command=8, data\n        response = self.raw_command(netfn=0, command=8, data=(3, 8))\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        bootflags = 0x80\n        if uefiboot:\n            bootflags |= 1 << 5\n        if persist:\n            bootflags |= 1 << 6\n        if bootdevnum == 0:\n            bootflags = 0\n        data = (5, bootflags, bootdevnum, 0, 0, 0)\n        response = self.raw_command(netfn=0, command=8, data=data)\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        return {'bootdev': bootdev}", "response": "Set boot device to use on next reboot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef xraw_command(self, netfn, command, bridge_request=(), data=(),\n                     delay_xmit=None, retry=True, timeout=None):\n        \"\"\"Send raw ipmi command to BMC, raising exception on error\n\n        This is identical to raw_command, except it raises exceptions\n        on IPMI errors and returns data as a buffer.  This is the recommend\n        function to use.  The response['data'] being a buffer allows\n        traditional indexed access as well as works nicely with\n        struct.unpack_from when certain data is coming back.\n\n        :param netfn: Net function number\n        :param command: Command value\n        :param bridge_request: The target slave address and channel number for\n                               the bridge request.\n        :param data: Command data as a tuple or list\n        :param retry: Whether to retry this particular payload or not, defaults\n                      to true.\n        :param timeout: A custom time to wait for initial reply, useful for\n                        a slow command.  This may interfere with retry logic.\n        :returns: dict -- The response from IPMI device\n        \"\"\"\n        rsp = self.ipmi_session.raw_command(netfn=netfn, command=command,\n                                            bridge_request=bridge_request,\n                                            data=data, delay_xmit=delay_xmit,\n                                            retry=retry, timeout=timeout)\n        if 'error' in rsp:\n            raise exc.IpmiException(rsp['error'], rsp['code'])\n        rsp['data'] = buffer(rsp['data'])\n        return rsp", "response": "Send a raw ipmi command to the BMC and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raw_command(self, netfn, command, bridge_request=(), data=(),\n                    delay_xmit=None, retry=True, timeout=None):\n        \"\"\"Send raw ipmi command to BMC\n\n        This allows arbitrary IPMI bytes to be issued.  This is commonly used\n        for certain vendor specific commands.\n\n        Example: ipmicmd.raw_command(netfn=0,command=4,data=(5))\n\n        :param netfn: Net function number\n        :param command: Command value\n        :param bridge_request: The target slave address and channel number for\n                               the bridge request.\n        :param data: Command data as a tuple or list\n        :param retry: Whether or not to retry command if no response received.\n                      Defaults to True\n        :param timeout: A custom amount of time to wait for initial reply\n        :returns: dict -- The response from IPMI device\n        \"\"\"\n        rsp = self.ipmi_session.raw_command(netfn=netfn, command=command,\n                                            bridge_request=bridge_request,\n                                            data=data, delay_xmit=delay_xmit,\n                                            retry=retry, timeout=timeout)\n        if 'data' in rsp:\n            rsp['data'] = list(rsp['data'])\n        return rsp", "response": "Send raw ipmi command to BMC and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_power(self):\n        response = self.raw_command(netfn=0, command=1)\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])\n        assert (response['command'] == 1 and response['netfn'] == 1)\n        powerstate = 'on' if (response['data'][0] & 1) else 'off'\n        return {'powerstate': powerstate}", "response": "Get current power state of the managed system."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequests the identify light to turn on or off for a duration or indefinitely.", "response": "def set_identify(self, on=True, duration=None):\n        \"\"\"Request identify light\n\n        Request the identify light to turn off, on for a duration,\n        or on indefinitely.  Other than error exceptions,\n\n        :param on: Set to True to force on or False to force off\n        :param duration: Set if wanting to request turn on for a duration\n                         rather than indefinitely on\n        \"\"\"\n        self.oem_init()\n        try:\n            self._oem.set_identify(on, duration)\n            return\n        except exc.UnsupportedFunctionality:\n            pass\n        if duration is not None:\n            duration = int(duration)\n            if duration > 255:\n                duration = 255\n            if duration < 0:\n                duration = 0\n            response = self.raw_command(netfn=0, command=4, data=[duration])\n            if 'error' in response:\n                raise exc.IpmiException(response['error'])\n            return\n        forceon = 0\n        if on:\n            forceon = 1\n        if self.ipmi_session.ipmiversion < 2.0:\n            # ipmi 1.5 made due with just one byte, make best effort\n            # to imitate indefinite as close as possible\n            identifydata = [255 * forceon]\n        else:\n            identifydata = [0, forceon]\n        response = self.raw_command(netfn=0, command=4, data=identifydata)\n        if 'error' in response:\n            raise exc.IpmiException(response['error'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_sdr(self):\n        # For now, return current sdr if it exists and still connected\n        # future, check SDR timestamp for continued relevance\n        # further future, optionally support a cache directory/file\n        # to store cached copies for given device id, product id, mfg id,\n        # sdr timestamp, our data version revision, aux firmware revision,\n        # and oem defined field\n        if self._sdr is None:\n            self._sdr = sdr.SDR(self, self._sdrcachedir)\n        return self._sdr", "response": "Initialize the SDR object for the current management controller and return it"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the log of events optionally clearing", "response": "def get_event_log(self, clear=False):\n        \"\"\"Retrieve the log of events, optionally clearing\n\n        The contents of the SEL are returned as an iterable.  Timestamps\n        are given as local time, ISO 8601 (whether the target has an accurate\n        clock or not).  Timestamps may be omitted for events that cannot be\n        given a timestamp, leaving only the raw timecode to provide relative\n        time information.  clear set to true will result in the log being\n        cleared as it is returned.  This allows an atomic fetch and clear\n        behavior so that no log entries will be lost between the fetch and\n        clear actions.  There is no 'clear_event_log' function to encourage\n        users to create code that is not at risk for losing events.\n\n        :param clear:  Whether to remove the SEL entries from the target BMC\n        \"\"\"\n        self.oem_init()\n        return sel.EventHandler(self.init_sdr(), self).fetch_sel(self, clear)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode_pet(self, specifictrap, petdata):\n        self.oem_init()\n        return sel.EventHandler(self.init_sdr(), self).decode_pet(specifictrap,\n                                                                  petdata)", "response": "Decode PET to an event dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves list of things that could be inventoried", "response": "def get_inventory_descriptions(self):\n        \"\"\"Retrieve list of things that could be inventoried\n\n        This permits a caller to examine the available items\n        without actually causing the inventory data to be gathered.  It\n        returns an iterable of string descriptions\n        \"\"\"\n        yield \"System\"\n        self.init_sdr()\n        for fruid in sorted(self._sdr.fru):\n            yield self._sdr.fru[fruid].fru_name\n        self.oem_init()\n        for compname in self._oem.get_oem_inventory_descriptions():\n            yield compname"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_inventory_of_component(self, component):\n        self.oem_init()\n        if component == 'System':\n            return self._get_zero_fru()\n        self.init_sdr()\n        for fruid in self._sdr.fru:\n            if self._sdr.fru[fruid].fru_name == component:\n                return self._oem.process_fru(fru.FRU(\n                    ipmicmd=self, fruid=fruid, sdr=self._sdr.fru[fruid]).info,\n                                             component)\n        return self._oem.get_inventory_of_component(component)", "response": "Retrieve detailed inventory information for a requested component."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_inventory(self):\n        self.oem_init()\n        yield (\"System\", self._get_zero_fru())\n        self.init_sdr()\n        for fruid in sorted(self._sdr.fru):\n            fruinf = fru.FRU(\n                ipmicmd=self, fruid=fruid, sdr=self._sdr.fru[fruid]).info\n            if fruinf is not None:\n                fruinf = self._oem.process_fru(fruinf,\n                                               self._sdr.fru[fruid].fru_name)\n            yield (self._sdr.fru[fruid].fru_name, fruinf)\n        for componentpair in self._oem.get_oem_inventory():\n            yield componentpair", "response": "Retrieve inventory of system\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsummarize health of the managed system.", "response": "def get_health(self):\n        \"\"\"Summarize health of managed system\n\n        This provides a summary of the health of the managed system.\n        It additionally provides an iterable list of reasons for\n        warning, critical, or failed assessments.\n        \"\"\"\n        summary = {'badreadings': [], 'health': const.Health.Ok}\n        fallbackreadings = []\n        try:\n            self.oem_init()\n            fallbackreadings = self._oem.get_health(summary)\n            for reading in self.get_sensor_data():\n                if reading.health != const.Health.Ok:\n                    summary['health'] |= reading.health\n                    summary['badreadings'].append(reading)\n        except exc.BypassGenericBehavior:\n            pass\n        if not summary['badreadings']:\n            summary['badreadings'] = fallbackreadings\n        return summary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_sensor_reading(self, sensorname):\n        self.init_sdr()\n        for sensor in self._sdr.get_sensor_numbers():\n            if self._sdr.sensors[sensor].name == sensorname:\n                rsp = self.raw_command(command=0x2d, netfn=4, data=(sensor,))\n                if 'error' in rsp:\n                    raise exc.IpmiException(rsp['error'], rsp['code'])\n                return self._sdr.sensors[sensor].decode_sensor_reading(\n                    rsp['data'])\n        self.oem_init()\n        return self._oem.get_sensor_reading(sensorname)", "response": "Get a sensor reading by name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_net_configuration(self, ipv4_address=None, ipv4_configuration=None,\n                              ipv4_gateway=None, channel=None):\n        \"\"\"Set network configuration data.\n\n        Apply desired network configuration data, leaving unspecified\n        parameters alone.\n\n        :param ipv4_address:  CIDR notation for IP address and netmask\n                          Example: '192.168.0.10/16'\n        :param ipv4_configuration: Method to use to configure the network.\n                        'DHCP' or 'Static'.\n        :param ipv4_gateway: IP address of gateway to use.\n        :param channel:  LAN channel to configure, defaults to autodetect\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        if ipv4_configuration is not None:\n            cmddata = [channel, 4, 0]\n            if ipv4_configuration.lower() == 'dhcp':\n                cmddata[-1] = 2\n            elif ipv4_configuration.lower() == 'static':\n                cmddata[-1] = 1\n            else:\n                raise Exception('Unrecognized ipv4cfg parameter {0}'.format(\n                    ipv4_configuration))\n            self.xraw_command(netfn=0xc, command=1, data=cmddata)\n        if ipv4_address is not None:\n            netmask = None\n            if '/' in ipv4_address:\n                ipv4_address, prefix = ipv4_address.split('/')\n                netmask = _cidr_to_mask(int(prefix))\n            cmddata = bytearray((channel, 3)) + socket.inet_aton(ipv4_address)\n            self.xraw_command(netfn=0xc, command=1, data=cmddata)\n            if netmask is not None:\n                cmddata = bytearray((channel, 6)) + netmask\n                self.xraw_command(netfn=0xc, command=1, data=cmddata)\n        if ipv4_gateway is not None:\n            cmddata = bytearray((channel, 12)) + socket.inet_aton(ipv4_gateway)\n            self.xraw_command(netfn=0xc, command=1, data=cmddata)", "response": "Set network configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_net_configuration(self, channel=None, gateway_macs=True):\n        if channel is None:\n            channel = self.get_network_channel()\n        retdata = {}\n        v4addr = self._fetch_lancfg_param(channel, 3)\n        if v4addr is None:\n            retdata['ipv4_address'] = None\n        else:\n            v4masklen = self._fetch_lancfg_param(channel, 6, prefixlen=True)\n            retdata['ipv4_address'] = '{0}/{1}'.format(v4addr, v4masklen)\n        v4cfgmethods = {\n            0: 'Unspecified',\n            1: 'Static',\n            2: 'DHCP',\n            3: 'BIOS',\n            4: 'Other',\n        }\n        retdata['ipv4_configuration'] = v4cfgmethods[self._fetch_lancfg_param(\n            channel, 4)]\n        retdata['mac_address'] = self._fetch_lancfg_param(channel, 5)\n        retdata['ipv4_gateway'] = self._fetch_lancfg_param(channel, 12)\n        retdata['ipv4_backup_gateway'] = self._fetch_lancfg_param(channel, 14)\n        if gateway_macs:\n            retdata['ipv4_gateway_mac'] = self._fetch_lancfg_param(channel, 13)\n            retdata['ipv4_backup_gateway_mac'] = self._fetch_lancfg_param(\n                channel, 15)\n        self.oem_init()\n        self._oem.add_extra_net_configuration(retdata)\n        return retdata", "response": "Get network configuration data from the target network channel"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the sensor data for the currently set of objects.", "response": "def get_sensor_data(self):\n        \"\"\"Get sensor reading objects\n\n        Iterates sensor reading objects pertaining to the currently\n        managed BMC.\n\n        :returns: Iterator of sdr.SensorReading objects\n        \"\"\"\n        self.init_sdr()\n        for sensor in self._sdr.get_sensor_numbers():\n            rsp = self.raw_command(command=0x2d, netfn=4, data=(sensor,))\n            if 'error' in rsp:\n                if rsp['code'] == 203:  # Sensor does not exist, optional dev\n                    continue\n                raise exc.IpmiException(rsp['error'], code=rsp['code'])\n            yield self._sdr.sensors[sensor].decode_sensor_reading(rsp['data'])\n        self.oem_init()\n        for reading in self._oem.get_sensor_data():\n            yield reading"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sensor_descriptions(self):\n        self.init_sdr()\n        for sensor in self._sdr.get_sensor_numbers():\n            yield {'name': self._sdr.sensors[sensor].name,\n                   'type': self._sdr.sensors[sensor].sensor_type}\n        self.oem_init()\n        for sensor in self._oem.get_sensor_descriptions():\n            yield sensor", "response": "Get available sensor names and their descriptions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a reasonable default network channel.", "response": "def get_network_channel(self):\n        \"\"\"Get a reasonable 'default' network channel.\n\n        When configuring/examining network configuration, it's desirable to\n        find the correct channel.  Here we run with the 'real' number of the\n        current channel if it is a LAN channel, otherwise it evaluates\n        all of the channels to find the first workable LAN channel and returns\n        that\n        \"\"\"\n        if self._netchannel is None:\n            for channel in chain((0xe,), range(1, 0xc)):\n                try:\n                    rsp = self.xraw_command(\n                        netfn=6, command=0x42, data=(channel,))\n                except exc.IpmiException as ie:\n                    if ie.ipmicode == 0xcc:\n                        # We have hit an invalid channel, move on to next\n                        # candidate\n                        continue\n                    else:\n                        raise\n                chantype = ord(rsp['data'][1]) & 0b1111111\n                if chantype in (4, 6):\n                    try:\n                        # Some implementations denote an inactive channel\n                        # by refusing to do parameter retrieval\n                        if channel != 0xe:\n                            # skip checking if channel is active if we are\n                            # actively using the channel\n                            self.xraw_command(\n                                netfn=0xc, command=2, data=(channel, 5, 0, 0))\n                        # If still here, the channel seems serviceable...\n                        # However some implementations may still have\n                        # ambiguous channel info, that will need to be\n                        # picked up on an OEM extension...\n                        self._netchannel = ord(rsp['data'][0]) & 0b1111\n                        break\n                    except exc.IpmiException as ie:\n                        # This means the attempt to fetch parameter 5 failed,\n                        # therefore move on to next candidate channel\n                        continue\n        return self._netchannel"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the number of supported alert destinations.", "response": "def get_alert_destination_count(self, channel=None):\n        \"\"\"Get the number of supported alert destinations\n\n        :param channel: Channel for alerts to be examined, defaults to current\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        rqdata = (channel, 0x11, 0, 0)\n        rsp = self.xraw_command(netfn=0xc, command=2, data=rqdata)\n        return ord(rsp['data'][1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_alert_destination(self, destination=0, channel=None):\n        destinfo = {}\n        if channel is None:\n            channel = self.get_network_channel()\n        rqdata = (channel, 18, destination, 0)\n        rsp = self.xraw_command(netfn=0xc, command=2, data=rqdata)\n        dtype, acktimeout, retries = struct.unpack('BBB', rsp['data'][2:])\n        destinfo['acknowledge_required'] = dtype & 0b10000000 == 0b10000000\n        # Ignore destination type for now...\n        if destinfo['acknowledge_required']:\n            destinfo['acknowledge_timeout'] = acktimeout\n        destinfo['retries'] = retries\n        rqdata = (channel, 19, destination, 0)\n        rsp = self.xraw_command(netfn=0xc, command=2, data=rqdata)\n        if ord(rsp['data'][2]) & 0b11110000 == 0:\n            destinfo['address_format'] = 'ipv4'\n            destinfo['address'] = socket.inet_ntoa(rsp['data'][4:8])\n        elif ord(rsp['data'][2]) & 0b11110000 == 0b10000:\n            destinfo['address_format'] = 'ipv6'\n            destinfo['address'] = socket.inet_ntop(socket.AF_INET6,\n                                                   rsp['data'][3:])\n        return destinfo", "response": "Get a specific alert destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear_alert_destination(self, destination=0, channel=None):\n        if channel is None:\n            channel = self.get_network_channel()\n        self.set_alert_destination(\n            '0.0.0.0', False, 0, 0, destination, channel)", "response": "Clear an alert destination"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_alert_community(self, community, channel=None):\n        if channel is None:\n            channel = self.get_network_channel()\n        community = community.encode('utf-8')\n        community += b'\\x00' * (18 - len(community))\n        cmddata = bytearray((channel, 16))\n        cmddata += community\n        self.xraw_command(netfn=0xc, command=1, data=cmddata)", "response": "Set the community string for alerts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassuring that an alert policy exists for the specified channel and destination.", "response": "def _assure_alert_policy(self, channel, destination):\n        \"\"\"Make sure an alert policy exists\n\n        Each policy will be a dict with the following keys:\n        -'index' - The policy index number\n        :returns: An iterable of currently configured alert policies\n        \"\"\"\n        # First we do a get PEF configuration parameters to get the count\n        # of entries.  We have no guarantee that the meaningful data will\n        # be contiguous\n        rsp = self.xraw_command(netfn=4, command=0x13, data=(8, 0, 0))\n        numpol = ord(rsp['data'][1])\n        desiredchandest = (channel << 4) | destination\n        availpolnum = None\n        for polnum in range(1, numpol + 1):\n            currpol = self.xraw_command(netfn=4, command=0x13,\n                                        data=(9, polnum, 0))\n            polidx, chandest = struct.unpack_from('>BB', currpol['data'][2:4])\n            if not polidx & 0b1000:\n                if availpolnum is None:\n                    availpolnum = polnum\n                continue\n            if chandest == desiredchandest:\n                return True\n        # If chandest did not equal desiredchandest ever, we need to use a slot\n        if availpolnum is None:\n            raise Exception(\"No available alert policy entry\")\n        # 24 = 1 << 4 | 8\n        # 1 == set to which this rule belongs\n        # 8 == 0b1000, in other words, enable this policy, always send to\n        # indicated destination\n        self.xraw_command(netfn=4, command=0x12,\n                          data=(9, availpolnum, 24,\n                                desiredchandest, 0))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_alert_community(self, channel=None):\n        if channel is None:\n            channel = self.get_network_channel()\n        rsp = self.xraw_command(netfn=0xc, command=2, data=(channel, 16, 0, 0))\n        return rsp['data'][1:].partition('\\x00')[0]", "response": "Get the current community string for alerts\nOID"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_alert_destination(self, ip=None, acknowledge_required=None,\n                              acknowledge_timeout=None, retries=None,\n                              destination=0, channel=None):\n        \"\"\"Configure one or more parameters of an alert destination\n\n        If any parameter is 'None' (default), that parameter is left unchanged.\n        Otherwise, all given parameters are set by this command.\n\n        :param ip: IP address of the destination.  It is currently expected\n                   that the calling code will handle any name lookup and\n                   present this data as IP address.\n        :param acknowledge_required: Whether or not the target should expect\n                                     an acknowledgement from this alert target.\n        :param acknowledge_timeout: Time to wait for acknowledgement if enabled\n        :param retries:  How many times to attempt transmit of an alert.\n        :param destination:  Destination index, defaults to 0.\n        :param channel: The channel to configure the alert on.  Defaults to\n                current\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        if ip is not None:\n            destdata = bytearray((channel, 19, destination))\n            try:\n                parsedip = socket.inet_aton(ip)\n                destdata.extend((0, 0))\n                destdata.extend(parsedip)\n                destdata.extend(b'\\x00\\x00\\x00\\x00\\x00\\x00')\n            except socket.error:\n                if self._supports_standard_ipv6:\n                    parsedip = socket.inet_pton(socket.AF_INET6, ip)\n                    destdata.append(0b10000000)\n                    destdata.extend(parsedip)\n                else:\n                    destdata = None\n                    self.oem_init()\n                    self._oem.set_alert_ipv6_destination(ip, destination,\n                                                         channel)\n            if destdata:\n                self.xraw_command(netfn=0xc, command=1, data=destdata)\n        if (acknowledge_required is not None or retries is not None or\n                acknowledge_timeout is not None):\n            currtype = self.xraw_command(netfn=0xc, command=2, data=(\n                channel, 18, destination, 0))\n            if currtype['data'][0] != b'\\x11':\n                raise exc.PyghmiException(\"Unknown parameter format\")\n            currtype = bytearray(currtype['data'][1:])\n            if acknowledge_required is not None:\n                if acknowledge_required:\n                    currtype[1] |= 0b10000000\n                else:\n                    currtype[1] &= 0b1111111\n            if acknowledge_timeout is not None:\n                currtype[2] = acknowledge_timeout\n            if retries is not None:\n                currtype[3] = retries\n            destreq = bytearray((channel, 18))\n            destreq.extend(currtype)\n            self.xraw_command(netfn=0xc, command=1, data=destreq)\n        if not ip == '0.0.0.0':\n            self._assure_alert_policy(channel, destination)", "response": "Configure one or more parameters of an alert destination."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the hostname used by the BMC in various contexts", "response": "def get_hostname(self):\n        \"\"\"Get the hostname used by the BMC in various contexts\n\n        This can vary somewhat in interpretation, but generally speaking\n        this should be the name that shows up on UIs and in DHCP requests and\n        DNS registration requests, as applicable.\n\n        :return: current hostname\n        \"\"\"\n        self.oem_init()\n        try:\n            return self._oem.get_hostname()\n        except exc.UnsupportedFunctionality:\n            # Use the DCMI MCI field as a fallback, since it's the closest\n            # thing in the IPMI Spec for this\n            return self.get_mci()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_hostname(self, hostname):\n        self.oem_init()\n        try:\n            return self._oem.set_hostname(hostname)\n        except exc.UnsupportedFunctionality:\n            return self.set_mci(hostname)", "response": "Set the hostname to be used by the BMC in various contexts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the channel access.", "response": "def set_channel_access(self, channel=None,\n                           access_update_mode='non_volatile',\n                           alerting=False, per_msg_auth=False,\n                           user_level_auth=False, access_mode='always',\n                           privilege_update_mode='non_volatile',\n                           privilege_level='administrator'):\n        \"\"\"Set channel access\n\n        :param channel: number [1:7]\n\n        :param access_update_mode:\n            dont_change  = don't set or change Channel Access\n            non_volatile = set non-volatile Channel Access\n            volatile     = set volatile (active) setting of Channel Access\n\n        :param alerting: PEF Alerting Enable/Disable\n        True  = enable PEF Alerting\n        False = disable PEF Alerting on this channel\n                (Alert Immediate command can still be used to generate alerts)\n\n        :param per_msg_auth: Per-message Authentication\n        True  = enable\n        False = disable Per-message Authentication. [Authentication required to\n                activate any session on this channel, but authentication not\n                used on subsequent packets for the session.]\n\n        :param user_level_auth: User Level Authentication Enable/Disable.\n        True  = enable User Level Authentication. All User Level commands are\n            to be authenticated per the Authentication Type that was\n            negotiated when the session was activated.\n        False = disable User Level Authentication. Allow User Level commands to\n            be executed without being authenticated.\n            If the option to disable User Level Command authentication is\n            accepted, the BMC will accept packets with Authentication Type\n            set to None if they contain user level commands.\n            For outgoing packets, the BMC returns responses with the same\n            Authentication Type that was used for the request.\n\n        :param access_mode: Access Mode for IPMI messaging\n        (PEF Alerting is enabled/disabled separately from IPMI messaging)\n        disabled = disabled for IPMI messaging\n        pre_boot = pre-boot only channel only available when system is in a\n                powered down state or in BIOS prior to start of boot.\n        always   = channel always available regardless of system mode.\n                BIOS typically dedicates the serial connection to the BMC.\n        shared   = same as always available, but BIOS typically leaves the\n                serial port available for software use.\n\n        :param privilege_update_mode: Channel Privilege Level Limit.\n            This value sets the maximum privilege level\n            that can be accepted on the specified channel.\n            dont_change  = don't set or change channel Privilege Level Limit\n            non_volatile = non-volatile Privilege Level Limit according\n            volatile     = volatile setting of Privilege Level Limit\n\n        :param privilege_level: Channel Privilege Level Limit\n            * reserved      = unused\n            * callback\n            * user\n            * operator\n            * administrator\n            * proprietary   = used by OEM\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        data = []\n        data.append(channel & 0b00001111)\n        access_update_modes = {\n            'dont_change': 0,\n            'non_volatile': 1,\n            'volatile': 2,\n            # 'reserved': 3\n        }\n        b = 0\n        b |= (access_update_modes[access_update_mode] << 6) & 0b11000000\n        if alerting:\n            b |= 0b00100000\n        if per_msg_auth:\n            b |= 0b00010000\n        if user_level_auth:\n            b |= 0b00001000\n        access_modes = {\n            'disabled': 0,\n            'pre_boot': 1,\n            'always': 2,\n            'shared': 3,\n        }\n        b |= access_modes[access_mode] & 0b00000111\n        data.append(b)\n        b = 0\n        privilege_update_modes = {\n            'dont_change': 0,\n            'non_volatile': 1,\n            'volatile': 2,\n            # 'reserved': 3\n        }\n        b |= (privilege_update_modes[privilege_update_mode] << 6) & 0b11000000\n        privilege_levels = {\n            'reserved': 0,\n            'callback': 1,\n            'user': 2,\n            'operator': 3,\n            'administrator': 4,\n            'proprietary': 5,\n            # 'no_access': 0x0F,\n        }\n        b |= privilege_levels[privilege_level] & 0b00000111\n        data.append(b)\n        response = self.raw_command(netfn=0x06, command=0x40, data=data)\n        if 'error' in response:\n            raise Exception(response['error'])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets channel access :param channel: number [1:7] :param read_mode: non_volatile = get non-volatile Channel Access volatile = get present volatile (active) setting of Channel Access :return: A Python dict with the following keys/values: { - alerting: - per_msg_auth: - user_level_auth: - access_mode:{ 0: 'disabled', 1: 'pre_boot', 2: 'always', 3: 'shared' } - privilege_level: { 1: 'callback', 2: 'user', 3: 'operator', 4: 'administrator', 5: 'proprietary', } }", "response": "def get_channel_access(self, channel=None, read_mode='volatile'):\n        \"\"\"Get channel access\n\n        :param channel: number [1:7]\n        :param read_mode:\n        non_volatile  = get non-volatile Channel Access\n        volatile      = get present volatile (active) setting of Channel Access\n\n        :return: A Python dict with the following keys/values:\n          {\n            - alerting:\n            - per_msg_auth:\n            - user_level_auth:\n            - access_mode:{\n                0: 'disabled',\n                1: 'pre_boot',\n                2: 'always',\n                3: 'shared'\n              }\n            - privilege_level: {\n                1: 'callback',\n                2: 'user',\n                3: 'operator',\n                4: 'administrator',\n                5: 'proprietary',\n              }\n           }\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        data = []\n        data.append(channel & 0b00001111)\n        b = 0\n        read_modes = {\n            'non_volatile': 1,\n            'volatile': 2,\n        }\n        b |= (read_modes[read_mode] << 6) & 0b11000000\n        data.append(b)\n\n        response = self.raw_command(netfn=0x06, command=0x41, data=data)\n        if 'error' in response:\n            raise Exception(response['error'])\n\n        data = response['data']\n        if len(data) != 2:\n            raise Exception('expecting 2 data bytes')\n\n        r = {}\n        r['alerting'] = data[0] & 0b10000000 > 0\n        r['per_msg_auth'] = data[0] & 0b01000000 > 0\n        r['user_level_auth'] = data[0] & 0b00100000 > 0\n        access_modes = {\n            0: 'disabled',\n            1: 'pre_boot',\n            2: 'always',\n            3: 'shared'\n        }\n        r['access_mode'] = access_modes[data[0] & 0b00000011]\n        privilege_levels = {\n            0: 'reserved',\n            1: 'callback',\n            2: 'user',\n            3: 'operator',\n            4: 'administrator',\n            5: 'proprietary',\n            # 0x0F: 'no_access'\n        }\n        r['privilege_level'] = privilege_levels[data[1] & 0b00001111]\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget channel info :param channel: number [1:7] :return: session_support: no_session: channel is session-less single: channel is single-session multi: channel is multi-session auto: channel is session-based (channel could alternate between single- and multi-session operation, as can occur with a serial/modem channel that supports connection mode auto-detect)", "response": "def get_channel_info(self, channel=None):\n        \"\"\"Get channel info\n\n        :param channel: number [1:7]\n\n        :return:\n        session_support:\n            no_session: channel is session-less\n            single: channel is single-session\n            multi: channel is multi-session\n            auto: channel is session-based (channel could alternate between\n                single- and multi-session operation, as can occur with a\n                serial/modem channel that supports connection mode auto-detect)\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        data = []\n        data.append(channel & 0b00001111)\n        response = self.raw_command(netfn=0x06, command=0x42, data=data)\n        if 'error' in response:\n            raise Exception(response['error'])\n        data = response['data']\n        if len(data) != 9:\n            raise Exception('expecting 10 data bytes got: {0}'.format(data))\n        r = {}\n        r['Actual channel'] = data[0] & 0b00000111\n        channel_medium_types = {\n            0: 'reserved',\n            1: 'IPMB',\n            2: 'ICMB v1.0',\n            3: 'ICMB v0.9',\n            4: '802.3 LAN',\n            5: 'Asynch. Serial/Modem (RS-232)',\n            6: 'Other LAN',\n            7: 'PCI SMBus',\n            8: 'SMBus v1.0/1.1',\n            9: 'SMBus v2.0',\n            0x0a: 'reserved for USB 1.x',\n            0x0b: 'reserved for USB 2.x',\n            0x0c: 'System Interface (KCS, SMIC, or BT)',\n            # 60h-7Fh: OEM\n            # all other  reserved\n        }\n        t = data[1] & 0b01111111\n        if t in channel_medium_types:\n            r['Channel Medium type'] = channel_medium_types[t]\n        else:\n            r['Channel Medium type'] = 'OEM {:02X}'.format(t)\n        r['5-bit Channel IPMI Messaging Protocol Type'] = data[2] & 0b00001111\n        session_supports = {\n            0: 'no_session',\n            1: 'single',\n            2: 'multi',\n            3: 'auto'\n        }\n        r['session_support'] = session_supports[(data[3] & 0b11000000) >> 6]\n        r['active_session_count'] = data[3] & 0b00111111\n        r['Vendor ID'] = [data[4], data[5], data[6]]\n        r['Auxiliary Channel Info'] = [data[7], data[8]]\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the user access for the given uid and channel.", "response": "def set_user_access(self, uid, channel=None, callback=False,\n                        link_auth=True, ipmi_msg=True, privilege_level='user'):\n        \"\"\"Set user access\n\n        :param uid: user number [1:16]\n\n        :param channel: number [1:7]\n\n        :parm callback: User Restricted to Callback\n        False = User Privilege Limit is determined by the User Privilege Limit\n            parameter, below, for both callback and non-callback connections.\n        True  = User Privilege Limit is determined by the User Privilege Limit\n            parameter for callback connections, but is restricted to Callback\n            level for non-callback connections. Thus, a user can only initiate\n            a Callback when they 'call in' to the BMC, but once the callback\n            connection has been made, the user could potentially establish a\n            session as an Operator.\n\n        :param link_auth: User Link authentication\n        enable/disable (used to enable whether this\n        user's name and password information will be used for link\n        authentication, e.g. PPP CHAP) for the given channel. Link\n        authentication itself is a global setting for the channel and is\n        enabled/disabled via the serial/modem configuration parameters.\n\n        :param ipmi_msg: User IPMI Messaginge:\n        (used to enable/disable whether\n        this user's name and password information will be used for IPMI\n        Messaging. In this case, 'IPMI Messaging' refers to the ability to\n        execute generic IPMI commands that are not associated with a\n        particular payload type. For example, if IPMI Messaging is disabled for\n        a user, but that user is enabled for activatallow_authing the SOL\n        payload type, then IPMI commands associated with SOL and session\n        management, such as Get SOL Configuration Parameters and Close Session\n        are available, but generic IPMI commands such as Get SEL Time are\n        unavailable.)\n\n        :param privilege_level:\n        User Privilege Limit. (Determines the maximum privilege level that the\n        user is allowed to switch to on the specified channel.)\n            * callback\n            * user\n            * operator\n            * administrator\n            * proprietary\n            * no_access\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        b = 0b10000000\n        if callback:\n            b |= 0b01000000\n        if link_auth:\n            b |= 0b00100000\n        if ipmi_msg:\n            b |= 0b00010000\n        b |= channel & 0b00001111\n        privilege_levels = {\n            'reserved': 0,\n            'callback': 1,\n            'user': 2,\n            'operator': 3,\n            'administrator': 4,\n            'proprietary': 5,\n            'no_access': 0x0F,\n        }\n        self.oem_init()\n        self._oem.set_user_access(\n            uid, channel, callback, link_auth, ipmi_msg, privilege_level)\n        data = [b, uid & 0b00111111,\n                privilege_levels[privilege_level] & 0b00001111, 0]\n        response = self.raw_command(netfn=0x06, command=0x43, data=data)\n        if 'error' in response:\n            raise Exception(response['error'])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets user access for a specific user.", "response": "def get_user_access(self, uid, channel=None):\n        \"\"\"Get user access\n\n        :param uid: user number [1:16]\n        :param channel: number [1:7]\n\n        :return:\n        channel_info:\n            max_user_count = maximum number of user IDs on this channel\n            enabled_users = count of User ID slots presently in use\n            users_with_fixed_names = count of user IDs with fixed names\n\n        access:\n            callback\n            link_auth\n            ipmi_msg\n            privilege_level: [reserved, callback, user,\n                              operatorm administrator, proprietary, no_access]\n        \"\"\"\n        # user access available during call-in or callback direct connection\n        if channel is None:\n            channel = self.get_network_channel()\n        data = [channel, uid]\n        response = self.raw_command(netfn=0x06, command=0x44, data=data)\n        if 'error' in response:\n            raise Exception(response['error'])\n        data = response['data']\n        if len(data) != 4:\n            raise Exception('expecting 4 data bytes')\n        r = {'channel_info': {}, 'access': {}}\n        r['channel_info']['max_user_count'] = data[0]\n        r['channel_info']['enabled_users'] = data[1] & 0b00111111\n        r['channel_info']['users_with_fixed_names'] = data[2] & 0b00111111\n        r['access']['callback'] = (data[3] & 0b01000000) != 0\n        r['access']['link_auth'] = (data[3] & 0b00100000) != 0\n        r['access']['ipmi_msg'] = (data[3] & 0b00010000) != 0\n        privilege_levels = {\n            0: 'reserved',\n            1: 'callback',\n            2: 'user',\n            3: 'operator',\n            4: 'administrator',\n            5: 'proprietary',\n            0x0F: 'no_access'\n        }\n        r['access']['privilege_level'] = privilege_levels[data[3] & 0b00001111]\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets user name :param uid: user number [1:16] :param name: username (limit of 16bytes)", "response": "def set_user_name(self, uid, name):\n        \"\"\"Set user name\n\n        :param uid: user number [1:16]\n        :param name: username (limit of 16bytes)\n        \"\"\"\n        data = [uid]\n        if len(name) > 16:\n            raise Exception('name must be less than or = 16 chars')\n        name = name.ljust(16, \"\\x00\")\n        data.extend([ord(x) for x in name])\n        self.xraw_command(netfn=0x06, command=0x45, data=data)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget user name from user number.", "response": "def get_user_name(self, uid, return_none_on_error=True):\n        \"\"\"Get user name\n\n        :param uid: user number [1:16]\n        :param return_none_on_error: return None on error\n            TODO: investigate return code on error\n        \"\"\"\n        response = self.raw_command(netfn=0x06, command=0x46, data=(uid,))\n        if 'error' in response:\n            if return_none_on_error:\n                return None\n            raise Exception(response['error'])\n        name = None\n        if 'data' in response:\n            data = response['data']\n            if len(data) == 16:\n                # convert int array to string\n                n = ''.join(chr(data[i]) for i in range(0, len(data)))\n                # remove padded \\x00 chars\n                n = n.rstrip(\"\\x00\")\n                if len(n) > 0:\n                    name = n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets user password and return True on success False on bad password", "response": "def set_user_password(self, uid, mode='set_password', password=None):\n        \"\"\"Set user password and (modes)\n\n        :param uid: id number of user.  see: get_names_uid()['name']\n\n        :param mode:\n            disable       = disable user connections\n            enable        = enable user connections\n            set_password  = set or ensure password\n            test_password = test password is correct\n\n        :param password: max 16 char string\n            (optional when mode is [disable or enable])\n\n        :return:\n            True on success\n            when mode = test_password, return False on bad password\n        \"\"\"\n        mode_mask = {\n            'disable': 0,\n            'enable': 1,\n            'set_password': 2,\n            'test_password': 3\n        }\n        data = [uid, mode_mask[mode]]\n        if password:\n            password = str(password)\n            if 21 > len(password) > 16:\n                password = password.ljust(20, b'\\x00')\n                data[0] |= 0b10000000\n            elif len(password) > 20:\n                raise Exception('password has limit of 20 chars')\n            else:\n                password = password.ljust(16, \"\\x00\")\n            data.extend([ord(x) for x in password])\n        try:\n            self.xraw_command(netfn=0x06, command=0x47, data=data)\n        except exc.IpmiException as ie:\n            if mode == 'test_password':\n                return False\n            elif mode in ('enable', 'disable') and ie.ipmicode == 0xcc:\n                # Some BMCs see redundant calls to password disable/enable\n                # as invalid\n                return True\n            raise\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget max users in channel", "response": "def get_channel_max_user_count(self, channel=None):\n        \"\"\"Get max users in channel (helper)\n\n        :param channel: number [1:7]\n        :return: int -- often 16\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        access = self.get_user_access(channel=channel, uid=1)\n        return access['channel_info']['max_user_count']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting user (helper) :param uid: user number [1:16] :param channel: number [1:7] :return: name: (str) uid: (int) channel: (int) access: callback (bool) link_auth (bool) ipmi_msg (bool) privilege_level: (str)[callback, user, operatorm administrator, proprietary, no_access]", "response": "def get_user(self, uid, channel=None):\n        \"\"\"Get user (helper)\n\n        :param uid: user number [1:16]\n        :param channel: number [1:7]\n\n        :return:\n            name: (str)\n            uid: (int)\n            channel: (int)\n            access:\n                callback (bool)\n                link_auth (bool)\n                ipmi_msg (bool)\n                privilege_level: (str)[callback, user, operatorm administrator,\n                                       proprietary, no_access]\n        \"\"\"\n        if channel is None:\n            channel = self.get_network_channel()\n        name = self.get_user_name(uid)\n        access = self.get_user_access(uid, channel)\n        data = {'name': name, 'uid': uid, 'channel': channel,\n                'access': access['access']}\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name_uids(self, name, channel=None):\n        if channel is None:\n            channel = self.get_network_channel()\n        uid_list = []\n        max_ids = self.get_channel_max_user_count(channel)\n        for uid in range(1, max_ids):\n            if name == self.get_user_name(uid=uid):\n                uid_list.append(uid)\n        return uid_list", "response": "get list of users with the given name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_users(self, channel=None):\n        if channel is None:\n            channel = self.get_network_channel()\n        names = {}\n        max_ids = self.get_channel_max_user_count(channel)\n        for uid in range(1, max_ids + 1):\n            name = self.get_user_name(uid=uid)\n            if name is not None:\n                names[uid] = self.get_user(uid=uid, channel=channel)\n        return names", "response": "get list of users and channel access information"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a user in the current network", "response": "def create_user(self, uid, name, password, channel=None, callback=False,\n                    link_auth=True, ipmi_msg=True,\n                    privilege_level='user'):\n        \"\"\"create/ensure a user is created with provided settings (helper)\n\n        :param privilege_level:\n            User Privilege Limit. (Determines the maximum privilege level that\n            the user is allowed to switch to on the specified channel.)\n            * callback\n            * user\n            * operator\n            * administrator\n            * proprietary\n            * no_access\n        \"\"\"\n        # current user might be trying to update.. dont disable\n        # set_user_password(uid, password, mode='disable')\n        if channel is None:\n            channel = self.get_network_channel()\n        self.set_user_name(uid, name)\n        self.set_user_password(uid, password=password)\n        self.set_user_password(uid, mode='enable', password=password)\n        self.set_user_access(uid, channel, callback=callback,\n                             link_auth=link_auth, ipmi_msg=ipmi_msg,\n                             privilege_level=privilege_level)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_delete(self, uid, channel=None):\n        # TODO(jjohnson2): Provide OEM extensibility to cover user deletion\n        if channel is None:\n            channel = self.get_network_channel()\n        self.set_user_password(uid, mode='disable', password=None)\n        # TODO(steveweber) perhaps should set user access on all channels\n        # so new users dont get extra access\n        self.set_user_access(uid, channel=channel, callback=False,\n                             link_auth=False, ipmi_msg=False,\n                             privilege_level='no_access')\n        try:\n            # First try to set name to all \\x00 explicitly\n            self.set_user_name(uid, '')\n        except exc.IpmiException as ie:\n            if ie.ipmicode != 0xcc:\n                raise\n            # An invalid data field in request  is frequently reported.\n            # however another convention that exists is all '\\xff'\n            # if this fails, pass up the error so that calling code knows\n            # that the deletion did not go as planned for now\n            self.set_user_name(uid, b'\\xff' * 16)\n        return True", "response": "This function deletes a user from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_firmware(self, components=()):\n        self.oem_init()\n        mcinfo = self.xraw_command(netfn=6, command=1)\n        bmcver = '{0}.{1}'.format(\n            ord(mcinfo['data'][2]), hex(ord(mcinfo['data'][3]))[2:])\n        return self._oem.get_oem_firmware(bmcver, components)", "response": "Retrieve the OEM Firmware information for the given components"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend file to BMC to perform firmware update", "response": "def update_firmware(self, file, data=None, progress=None, bank=None):\n        \"\"\"Send file to BMC to perform firmware update\n\n         :param filename:  The filename to upload to the target BMC\n         :param data:  The payload of the firmware.  Default is to read from\n                       specified filename.\n         :param progress:  A callback that will be given a dict describing\n                           update process.  Provide if\n         :param bank: Indicate a target 'bank' of firmware if supported\n        \"\"\"\n        self.oem_init()\n        if progress is None:\n            progress = lambda x: True\n        return self._oem.update_firmware(file, data, progress, bank)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attach_remote_media(self, url, username=None, password=None):\n        self.oem_init()\n        return self._oem.attach_remote_media(url, username, password)", "response": "Attach remote media by url"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuploads a file to the target BMC and returns the ID of the uploaded file.", "response": "def upload_media(self, filename, progress=None):\n        \"\"\"Upload a file to be hosted on the target BMC\n\n        This will upload the specified data to\n        the BMC so that it will make it available to the system as an emulated\n        USB device.\n\n        :param filename: The filename to use, the basename of the parameter\n                         will be given to the bmc.\n        :param filename: Optional callback for progress updates\n        \"\"\"\n        self.oem_init()\n        return self._oem.upload_media(filename, progress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmodifies an event according with OEM understanding.", "response": "def process_event(self, event, ipmicmd, seldata):\n        \"\"\"Modify an event according with OEM understanding.\n\n        Given an event, allow an OEM module to augment it.  For example,\n        event data fields can have OEM bytes.  Other times an OEM may wish\n        to apply some transform to some field to suit their conventions.\n        \"\"\"\n        event['oem_handler'] = None\n        evdata = event['event_data_bytes']\n        if evdata[0] & 0b11000000 == 0b10000000:\n            event['oem_byte2'] = evdata[1]\n        if evdata[0] & 0b110000 == 0b100000:\n            event['oem_byte3'] = evdata[2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _got_cons_input(self, handle):\n        self._addpendingdata(handle.read())\n        if not self.awaitingack:\n            self._sendpendingoutput()", "response": "Callback for ipmi session events detected by ipmi session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshutting down an SOL session and remove the keepalive from the ipmi session", "response": "def close(self):\n        \"\"\"Shut down an SOL session,\n        \"\"\"\n        if self.ipmi_session:\n            self.ipmi_session.unregister_keepalive(self.keepaliveid)\n        if self.activated:\n            try:\n                self.ipmi_session.raw_command(netfn=6, command=0x49,\n                                              data=(1, 1, 0, 0, 0, 0))\n            except exc.IpmiException:\n                # if underlying ipmi session is not working, then\n                # run with the implicit success\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _got_sol_payload(self, payload):\n        # TODO(jbjohnso) test cases to throw some likely scenarios at functions\n        # for example, retry with new data, retry with no new data\n        # retry with unexpected sequence number\n        if type(payload) == dict:  # we received an error condition\n            self.activated = False\n            self._print_error(payload)\n            return\n        newseq = payload[0] & 0b1111\n        ackseq = payload[1] & 0b1111\n        ackcount = payload[2]\n        nacked = payload[3] & 0b1000000\n        breakdetected = payload[3] & 0b10000\n        # for now, ignore overrun.  I assume partial NACK for this reason or\n        # for no reason would be treated the same, new payload with partial\n        # data.\n        remdata = \"\"\n        remdatalen = 0\n        flag = 0\n        if not self.poweredon:\n            flag |= 0b1100000\n        if not self.activated:\n            flag |= 0b1010000\n        if newseq != 0:  # this packet at least has some data to send to us..\n            if len(payload) > 4:\n                remdatalen = len(payload[4:])  # store remote len before dupe\n                # retry logic, we must ack *this* many even if it is\n                # a retry packet with new partial data\n                remdata = bytes(payload[4:])\n            if newseq == self.remseq:  # it is a retry, but could have new data\n                if remdatalen > self.lastsize:\n                    remdata = bytes(remdata[4 + self.lastsize:])\n                else:  # no new data...\n                    remdata = \"\"\n            else:  # TODO(jbjohnso) what if remote sequence number is wrong??\n                self.remseq = newseq\n            self.lastsize = remdatalen\n            ackpayload = bytearray((0, self.remseq, remdatalen, flag))\n            # Why not put pending data into the ack? because it's rare\n            # and might be hard to decide what to do in the context of\n            # retry situation\n            try:\n                self.send_payload(ackpayload, retry=False)\n            except exc.IpmiException:\n                # if the session is broken, then close the SOL session\n                self.close()\n            if remdata:  # Do not subject callers to empty data\n                self._print_data(remdata)\n        if self.myseq != 0 and ackseq == self.myseq:  # the bmc has something\n            # to say about last xmit\n            self.awaitingack = False\n            if nacked and not breakdetected:  # the BMC was in some way unhappy\n                newtext = self.lastpayload[4 + ackcount:]\n                with self.outputlock:\n                    if (self.pendingoutput and\n                            not isinstance(self.pendingoutput[0], dict)):\n                        self.pendingoutput[0] = newtext + self.pendingoutput[0]\n                    else:\n                        self.pendingoutput = [newtext] + self.pendingoutput\n            # self._sendpendingoutput() checks len(self._sendpendingoutput)\n            self._sendpendingoutput()\n        elif ackseq != 0 and self.awaitingack:\n            # if an ack packet came in, but did not match what we\n            # expected, retry our payload now.\n            # the situation that was triggered was a senseless retry\n            # when data came in while we xmitted.  In theory, a BMC\n            # should handle a retry correctly, but some do not, so\n            # try to mitigate by avoiding overeager retries\n            # occasional retry of a packet\n            # sooner than timeout suggests is evidently a big deal\n            self.send_payload(payload=self.lastpayload)", "response": "This function is called when a Sol packet is received from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruing if the target is a Lenovo nextscale fan power controller.", "response": "def is_fpc(self):\n        \"\"\"True if the target is a Lenovo nextscale fan power controller\n        \"\"\"\n        if self.has_imm or self.has_xcc:\n            return None\n        if self._fpc_variant is not None:\n            return self._fpc_variant\n        fpc_ids = ((19046, 32, 1063), (20301, 32, 462))\n        smm_id = (19046, 32, 1180)\n        currid = (self.oemid['manufacturer_id'], self.oemid['device_id'],\n                  self.oemid['product_id'])\n        if currid in fpc_ids:\n            self._fpc_variant = 6\n        elif currid == smm_id:\n            self._fpc_variant = 2\n        return self._fpc_variant"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrue if this particular server has a TSM based service processor.", "response": "def has_tsm(self):\n        \"\"\"True if this particular server have a TSM based service processor\n        \"\"\"\n        if (self.oemid['manufacturer_id'] == 19046 and\n                self.oemid['device_id'] == 32):\n            try:\n                self.ipmicmd.xraw_command(netfn=0x3a, command=0xf)\n            except pygexc.IpmiException as ie:\n                if ie.ipmicode == 193:\n                    return False\n                raise\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenable or disable power capping for the oem.", "response": "def set_oem_capping_enabled(self, enable):\n        \"\"\"Set PSU based power capping\n\n        :param enable: True for enable and False for disable\n        \"\"\"\n        # 1 - Enable power capping(default)\n        if enable:\n            statecode = 1\n        # 0 - Disable power capping\n        else:\n            statecode = 0\n        if self.has_tsm:\n            self.ipmicmd.xraw_command(netfn=0x3a, command=0x1a,\n                                      data=(3, statecode))\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a wire format UUID into a string like dmidecode would output.", "response": "def decode_wireformat_uuid(rawguid):\n    \"\"\"Decode a wire format UUID\n\n    It handles the rather particular scheme where half is little endian\n    and half is big endian.  It returns a string like dmidecode would output.\n    \"\"\"\n    if isinstance(rawguid, list):\n        rawguid = bytearray(rawguid)\n    lebytes = struct.unpack_from('<IHH', buffer(rawguid[:8]))\n    bebytes = struct.unpack_from('>HHI', buffer(rawguid[8:]))\n    return '{0:08X}-{1:04X}-{2:04X}-{3:04X}-{4:04X}{5:08X}'.format(\n        lebytes[0], lebytes[1], lebytes[2], bebytes[0], bebytes[1], bebytes[2])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef urlsplit(url):\n    proto, rest = url.split(':', 1)\n    host = ''\n    if rest[:2] == '//':\n        host, rest = rest[2:].split('/', 1)\n        rest = '/' + rest\n    return proto, host, rest", "response": "Split an arbitrary url into protocol host and rest"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets list of ipv4 addresses for hostname", "response": "def get_ipv4(hostname):\n    \"\"\"Get list of ipv4 addresses for hostname\n\n    \"\"\"\n    addrinfo = socket.getaddrinfo(hostname, None, socket.AF_INET,\n                                  socket.SOCK_STREAM)\n    return [addrinfo[x][4][0] for x in range(len(addrinfo))]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_request_entry(self, entry=()):\n        if not self._lookup_request_entry(entry):\n            self.request_entry.append(entry)", "response": "This function record the request with netfn sequence number and command which will be used in parse_ipmi_payload."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a payload over the IPMI session.", "response": "def send_payload(self, payload=(), payload_type=None, retry=True,\n                     delay_xmit=None, needskeepalive=False, timeout=None):\n        \"\"\"Send payload over the IPMI Session\n\n        :param needskeepalive: If the payload is expected not to count as\n                               'active' by the BMC, set this to True\n                               to avoid Session considering the\n                               job done because of this payload.\n                               Notably, 0-length SOL packets\n                               are prone to confusion.\n        :param timeout: Specify a custom timeout for long-running request\n        \"\"\"\n        if payload and self.lastpayload:\n            # we already have a packet outgoing, make this\n            # a pending payload\n            # this way a simplistic BMC won't get confused\n            # and we also avoid having to do more complicated\n            # retry mechanism where each payload is\n            # retried separately\n            self.pendingpayloads.append((payload, payload_type, retry))\n            return\n        if payload_type is None:\n            payload_type = self.last_payload_type\n        if not payload:\n            payload = self.lastpayload\n        message = bytearray(b'\\x06\\x00\\xff\\x07')  # constant IPMI RMCP header\n        if retry:\n            self.lastpayload = payload\n            self.last_payload_type = payload_type\n        if not isinstance(payload, bytearray):\n            payload = bytearray(payload)\n        message.append(self.authtype)\n        baretype = payload_type\n        if self.integrityalgo:\n            payload_type |= 0b01000000\n        if self.confalgo:\n            payload_type |= 0b10000000\n        if self.ipmiversion == 2.0:\n            message.append(payload_type)\n            if baretype == 2:\n                # TODO(jbjohnso): OEM payload types\n                raise NotImplementedError(\"OEM Payloads\")\n            elif baretype not in constants.payload_types.values():\n                raise NotImplementedError(\n                    \"Unrecognized payload type %d\" % baretype)\n            message += struct.pack(\"<I\", self.sessionid)\n        message += struct.pack(\"<I\", self.sequencenumber)\n        if self.ipmiversion == 1.5:\n            message += struct.pack(\"<I\", self.sessionid)\n            if not self.authtype == 0:\n                message += self._ipmi15authcode(payload)\n            message.append(len(payload))\n            message += payload\n            # Guessing the ipmi spec means the whole\n            totlen = 34 + len(message)\n            # packet and assume no tag in old 1.5 world\n            if totlen in (56, 84, 112, 128, 156):\n                message.append(0)  # Legacy pad as mandated by ipmi spec\n        elif self.ipmiversion == 2.0:\n            psize = len(payload)\n            if self.confalgo:\n                pad = (psize + 1) % 16  # pad has to cope with one byte\n                # field like the _aespad function\n                if pad:  # if no pad needed, then we take no more action\n                    pad = 16 - pad\n                # new payload size grew according to pad\n                newpsize = psize + pad + 17\n                # size, plus pad length, plus 16 byte IV\n                # (Table 13-20)\n                message.append(newpsize & 0xff)\n                message.append(newpsize >> 8)\n                iv = os.urandom(16)\n                message += iv\n                payloadtocrypt = bytes(payload + _aespad(payload))\n                crypter = Cipher(\n                    algorithm=algorithms.AES(self.aeskey),\n                    mode=modes.CBC(iv),\n                    backend=self._crypto_backend\n                )\n                encryptor = crypter.encryptor()\n                message += encryptor.update(payloadtocrypt\n                                            ) + encryptor.finalize()\n            else:  # no confidetiality algorithm\n                message.append(psize & 0xff)\n                message.append(psize >> 8)\n                message += payload\n            if self.integrityalgo:  # see table 13-8,\n                # RMCP+ packet format\n                # TODO(jbjohnso): SHA256 which is now\n                # allowed\n                neededpad = (len(message) - 2) % 4\n                if neededpad:\n                    neededpad = 4 - neededpad\n                message += b'\\xff' * neededpad\n                message.append(neededpad)\n                message.append(7)  # reserved, 7 is the required value for the\n                # specification followed\n                message += hmac.new(self.k1,\n                                    bytes(message[4:]),\n                                    hashlib.sha1).digest()[:12]  # SHA1-96\n                # per RFC2404 truncates to 96 bits\n        self.netpacket = message\n        # advance idle timer since we don't need keepalive while sending\n        # packets out naturally\n        with util.protect(KEEPALIVE_SESSIONS):\n            if (self in Session.keepalive_sessions and not needskeepalive and\n                    not self._customkeepalives):\n                Session.keepalive_sessions[self]['timeout'] = \\\n                    _monotonic_time() + MAX_IDLE - (random.random() * 4.9)\n            self._xmit_packet(retry, delay_xmit=delay_xmit, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a custom keepalive for the given command.", "response": "def register_keepalive(self, cmd, callback):\n        \"\"\"Register  custom keepalive IPMI command\n\n        This is mostly intended for use by the console code.\n        calling code would have an easier time just scheduling in their\n        own threading scheme.  Such a behavior would naturally cause\n        the default keepalive to not occur anyway if the calling code\n        is at least as aggressive about timing as pyghmi\n        :param cmd: A dict of arguments to be passed into raw_command\n        :param callback: A function to be called with results of the keepalive\n\n        :returns: value to identify registration for unregister_keepalive\n        \"\"\"\n        regid = random.random()\n        if self._customkeepalives is None:\n            self._customkeepalives = {regid: (cmd, callback)}\n        else:\n            while regid in self._customkeepalives:\n                regid = random.random()\n            self._customkeepalives[regid] = (cmd, callback)\n        return regid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _keepalive(self):\n        try:\n            keptalive = False\n            if self._customkeepalives:\n                kaids = list(self._customkeepalives.keys())\n                for keepalive in kaids:\n                    try:\n                        cmd, callback = self._customkeepalives[keepalive]\n                    except TypeError:\n                        # raw_command made customkeepalives None\n                        break\n                    except KeyError:\n                        # raw command ultimately caused a keepalive to\n                        # deregister\n                        continue\n                    if callable(cmd):\n                        cmd()\n                        continue\n                    keptalive = True\n                    cmd['callback'] = self._keepalive_wrapper(callback)\n                    self.raw_command(**cmd)\n            if not keptalive:\n                if self.incommand:\n                    # if currently in command, no cause to keepalive\n                    return\n                self.raw_command(netfn=6, command=1,\n                                 callback=self._keepalive_wrapper(None))\n        except exc.IpmiException:\n            self._mark_broken()", "response": "Performs a keepalive to avoid idle disconnect\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(self, url, file):\n        if isinstance(file, str) or isinstance(file, unicode):\n            file = open(file, 'wb')\n        webclient = self.dupe()\n        webclient.request('GET', url)\n        rsp = webclient.getresponse()\n        self._currdl = rsp\n        self._dlfile = file\n        for chunk in iter(lambda: rsp.read(16384), ''):\n            file.write(chunk)\n        self._currdl = None\n        file.close()", "response": "Download a file to file object or file object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upload(self, url, filename, data=None, formname=None,\n               otherfields=()):\n        \"\"\"Upload a file to the url\n\n        :param url:\n        :param filename: The name of the file\n        :param data: A file object or data to use rather than reading from\n                     the file.\n        :return:\n        \"\"\"\n        if data is None:\n            data = open(filename, 'rb')\n        self._upbuffer = StringIO.StringIO(get_upload_form(filename, data,\n                                                           formname,\n                                                           otherfields))\n        ulheaders = self.stdheaders.copy()\n        ulheaders['Content-Type'] = 'multipart/form-data; boundary=' + BND\n        ulheaders['Content-Length'] = len(uploadforms[filename])\n        self.ulsize = len(uploadforms[filename])\n        webclient = self.dupe()\n        webclient.request('POST', url, self._upbuffer, ulheaders)\n        rsp = webclient.getresponse()\n        # peer updates in progress should already have pointers,\n        # subsequent transactions will cause memory to needlessly double,\n        # but easiest way to keep memory relatively low\n        try:\n            del uploadforms[filename]\n        except KeyError:  # something could have already deleted it\n            pass\n        self.rspstatus = rsp.status\n        if rsp.status != 200:\n            raise Exception('Unexpected response in file upload: ' +\n                            rsp.read())\n        return rsp.read()", "response": "Uploads a file to the url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simplestring(self):\n        repr = self.name + \": \"\n        if self.value is not None:\n            repr += str(self.value)\n            repr += \" \u00b1 \" + str(self.imprecision)\n            repr += self.units\n        for state in self.states:\n            repr += state + \",\"\n        if self.health >= const.Health.Failed:\n            repr += '(Failed)'\n        elif self.health >= const.Health.Critical:\n            repr += '(Critical)'\n        elif self.health >= const.Health.Warning:\n            repr += '(Warning)'\n        return repr", "response": "Return a summary string of the reading."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing every entry in an inventory category.", "response": "def parse_inventory_category(name, info, countable=True):\n    \"\"\"Parses every entry in an inventory category (CPU, memory, PCI, drives,\n    etc).\n\n    Expects the first byte to be a count of the number of entries, followed\n    by a list of elements to be parsed by a dedicated parser (below).\n\n    :param name: the name of the parameter (e.g.: \"cpu\")\n    :param info: a list of integers with raw data read from an IPMI requests\n    :param countable: whether the data have an entries count field\n\n    :returns: dict -- a list of entries in the category.\n    \"\"\"\n    raw = info[\"data\"][1:]\n\n    cur = 0\n    if countable:\n        count = struct.unpack(\"B\", raw[cur])[0]\n        cur += 1\n    else:\n        count = 0\n    discarded = 0\n\n    entries = []\n    while cur < len(raw):\n        read, cpu = categories[name][\"parser\"](raw[cur:])\n        cur = cur + read\n        # Account for discarded entries (because they are not present)\n        if cpu is None:\n            discarded += 1\n            continue\n        if not countable:\n            # count by myself\n            count += 1\n            cpu[\"index\"] = count\n        entries.append(cpu)\n\n    # TODO(avidal): raise specific exception to point that there's data left in\n    # the buffer\n    if cur != len(raw):\n        raise Exception\n    # TODO(avidal): raise specific exception to point that the number of\n    # entries is different than the expected\n    if count - discarded != len(entries):\n        raise Exception\n    return entries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_inventory_category_entry(raw, fields):\n    r = raw\n\n    obj = {}\n    bytes_read = 0\n    discard = False\n    for field in fields:\n        value = struct.unpack_from(field.fmt, r)[0]\n        read = struct.calcsize(field.fmt)\n        bytes_read += read\n        r = r[read:]\n        # If this entry is not actually present, just parse and then discard it\n        if field.presence and not bool(value):\n            discard = True\n        if not field.include:\n            continue\n\n        if (field.fmt[-1] == \"s\"):\n            value = value.rstrip(\"\\x00\")\n        if (field.mapper and value in field.mapper):\n            value = field.mapper[value]\n        if (field.valuefunc):\n            value = field.valuefunc(value)\n\n        if not field.multivaluefunc:\n            obj[field.name] = value\n        else:\n            for key in value:\n                obj[key] = value[key]\n\n    if discard:\n        obj = None\n    return bytes_read, obj", "response": "Parses one entry in an inventory category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sessionless_data(self, data, sockaddr):\n        if len(data) < 22:\n            return\n        data = bytearray(data)\n        if not (data[0] == 6 and data[2:4] == b'\\xff\\x07'):  # not ipmi\n            return\n        if data[4] == 6:  # ipmi 2 payload...\n            payloadtype = data[5]\n            if payloadtype not in (0, 16):\n                return\n            if payloadtype == 16:  # new session to handle conversation\n                ServerSession(self.authdata, self.kg, sockaddr,\n                              self.serversocket, data[16:], self.uuid,\n                              bmc=self)\n                return\n            # ditch two byte, because ipmi2 header is two\n            # bytes longer than ipmi1 (payload type added, payload length 2).\n            data = data[2:]\n        myaddr, netfnlun = struct.unpack('2B', bytes(data[14:16]))\n        netfn = (netfnlun & 0b11111100) >> 2\n        mylun = netfnlun & 0b11\n        if netfn == 6:  # application request\n            if data[19] == 0x38:  # cmd = get channel auth capabilities\n                verchannel, level = struct.unpack('2B', bytes(data[20:22]))\n                version = verchannel & 0b10000000\n                if version != 0b10000000:\n                    return\n                channel = verchannel & 0b1111\n                if channel != 0xe:\n                    return\n                (clientaddr, clientlun) = struct.unpack(\n                    'BB', bytes(data[17:19]))\n                clientseq = clientlun >> 2\n                clientlun &= 0b11  # Lun is only the least significant bits\n                level &= 0b1111\n                self.send_auth_cap(myaddr, mylun, clientaddr, clientlun,\n                                   clientseq, sockaddr)", "response": "Examines unsolocited packet and decides appropriate action."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_kg(self, kg):\n        try:\n            self.kg = kg.encode('utf-8')\n        except AttributeError:\n            self.kg = kg", "response": "Sets the Kg for the BMC to use\n\n        In RAKP the Kg is a BMC - specific integrity key that can be set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef source_debianize_name(name):\n    \"make name acceptable as a Debian source package name\"\n    name = name.replace('_','-')\n    name = name.replace('.','-')\n    name = name.lower()\n    return name", "response": "make name acceptable as a Debian source package name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn output of 822 - date command", "response": "def get_date_822():\n    \"\"\"return output of 822-date command\"\"\"\n    cmd = '/bin/date'\n    if not os.path.exists(cmd):\n        raise ValueError('%s command does not exist.'%cmd)\n    args = [cmd,'-R']\n    result = get_cmd_stdout(args).strip()\n    result = normstr(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a setuptools requirements list return a list of the dependencies that satisfy the given requirements.", "response": "def get_deb_depends_from_setuptools_requires(requirements, on_failure=\"warn\"):\n    \"\"\"\n    Suppose you can't confidently figure out a .deb which satisfies a given\n    requirement.  If on_failure == 'warn', then log a warning.  If on_failure\n    == 'raise' then raise CantSatisfyRequirement exception.  If on_failure ==\n    'guess' then guess that python-$FOO will satisfy the dependency and that\n    the Python version numbers will apply to the Debian packages (in addition\n    to logging a warning message).\n    \"\"\"\n    assert on_failure in (\"raise\", \"warn\", \"guess\"), on_failure\n\n    import pkg_resources\n\n    depends = [] # This will be the return value from this function.\n\n    parsed_reqs=[]\n\n    for extra,reqs in pkg_resources.split_sections(requirements):\n        if extra: continue\n        parsed_reqs.extend(pkg_resources.parse_requirements(reqs))\n\n    if not parsed_reqs:\n        return depends\n\n    if not os.path.exists('/usr/bin/apt-file'):\n        raise ValueError('apt-file not in /usr/bin. Please install '\n                         'with: sudo apt-get install apt-file')\n\n    # Ask apt-file for any packages which have a .egg-info file by\n    # these names.\n\n    # Note that apt-file appears to think that some packages\n    # e.g. setuptools itself have \"foo.egg-info/BLAH\" files but not a\n    # \"foo.egg-info\" directory.\n\n    egginfore=(\"(/(%s)(?:-[^/]+)?(?:-py[0-9]\\.[0-9.]+)?\\.egg-info)\"\n               % '|'.join(req.project_name.replace('-', '_') for req in parsed_reqs))\n\n    args = [\"apt-file\", \"search\", \"--ignore-case\", \"--regexp\", egginfore]\n\n    if 1:\n        # do dry run on apt-file\n        dry_run_args = args[:] + ['--dummy','--non-interactive']\n        cmd = subprocess.Popen(dry_run_args,stderr=subprocess.PIPE)\n        returncode = cmd.wait()\n        if returncode:\n            err_output = cmd.stderr.read()\n            raise RuntimeError('Error running \"apt-file search\": ' +\n                               err_output.strip())\n\n    try:\n        cmd = subprocess.Popen(args, stdin=subprocess.PIPE,\n                               stdout=subprocess.PIPE,\n                               universal_newlines=True)\n    except Exception as le:\n        # TODO: catch rc=1 and \"E: The cache directory is empty. You need to\n        # run 'apt-file update' first.\", and tell the user to follow those\n        # instructions.\n        log.error('ERROR running: %s', ' '.join(args))\n        raise RuntimeError('exception %s from subprocess %s' % (le,args))\n    returncode = cmd.wait()\n    if returncode:\n        log.error('ERROR running: %s', ' '.join(args))\n        raise RuntimeError('returncode %d from subprocess %s' % (returncode,\n                                                                 args))\n\n    inlines = cmd.stdout.readlines()\n\n    dd = {} # {pydistname: {pydist: set(debpackagename)}}\n    E=re.compile(egginfore, re.I)\n    D=re.compile(\"^([^:]*):\", re.I)\n    eggsndebs = set()\n    for l in inlines:\n        if l:\n            emo = E.search(l)\n            assert emo, l\n            dmo = D.search(l)\n            assert dmo, l\n            eggsndebs.add((emo.group(1), dmo.group(1)))\n\n    for (egginfo, debname) in eggsndebs:\n        pydist = pkg_resources.Distribution.from_filename(egginfo)\n        try:\n            dd.setdefault(\n                pydist.project_name.lower(), {}).setdefault(\n                pydist, set()).add(debname)\n        except ValueError as le:\n            log.warn(\"I got an error parsing a .egg-info file named \\\"%s\\\" \"\n                     \"from Debian package \\\"%s\\\" as a pkg_resources \"\n                     \"Distribution: %s\" % (egginfo, debname, le,))\n            pass\n\n    # Now for each requirement, see if a Debian package satisfies it.\n    ops = {'<':'<<','>':'>>','==':'=','<=':'<=','>=':'>='}\n    for req in parsed_reqs:\n        reqname = req.project_name.lower()\n        gooddebs = set()\n        for pydist, debs in dd.get(reqname, {}).iteritems():\n            if pydist in req:\n                ## log.info(\"I found Debian packages \\\"%s\\\" which provides \"\n                ##          \"Python package \\\"%s\\\", version \\\"%s\\\", which \"\n                ##          \"satisfies our version requirements: \\\"%s\\\"\"\n                ##          % (', '.join(debs), req.project_name, ver, req)\n                gooddebs |= (debs)\n            else:\n                log.info(\"I found Debian packages \\\"%s\\\" which provides \"\n                         \"Python package \\\"%s\\\" which \"\n                         \"does not satisfy our version requirements: \"\n                         \"\\\"%s\\\" -- ignoring.\"\n                         % (', '.join(debs), req.project_name, req))\n        if not gooddebs:\n            if on_failure == 'warn':\n                log.warn(\n                    \"I found no Debian package which provides the required \"\n                    \"Python package \\\"%s\\\" with version requirements \"\n                    \"\\\"%s\\\".\"% (req.project_name, req.specs))\n            elif on_failure == \"raise\":\n                raise CantSatisfyRequirement(\n                    \"I found no Debian package which \"\n                    \"provides the required Python package \\\"%s\\\" with version \"\n                    \"requirements \\\"%s\\\".\" % (req.project_name, req.specs), req)\n            elif on_failure == \"guess\":\n                log.warn(\"I found no Debian package which provides the \"\n                         \"required Python package \\\"%s\\\" with version \"\n                         \"requirements \\\"%s\\\".  Guessing blindly that the \"\n                         \"name \\\"python-%s\\\" will be it, and that the Python \"\n                         \"package version number requirements will apply to \"\n                         \"the Debian package.\" % (req.project_name,\n                                                  req.specs, reqname))\n                gooddebs.add(\"python-\" + reqname)\n        elif len(gooddebs) == 1:\n            log.info(\"I found a Debian package which provides the require \"\n                     \"Python package.  Python package: \\\"%s\\\", \"\n                     \"Debian package: \\\"%s\\\";  adding Depends specifications \"\n                     \"for the following version(s): \\\"%s\\\"\"\n                     % (req.project_name, tuple(gooddebs)[0], req.specs))\n        else:\n            log.warn(\"I found multiple Debian packages which provide the \"\n                     \"Python distribution required.  I'm listing them all \"\n                     \"as alternates.  Candidate debs which claim to provide \"\n                     \"the Python package \\\"%s\\\" are: \\\"%s\\\"\"\n                     % (req.project_name, ', '.join(gooddebs),))\n\n        alts = []\n        for deb in gooddebs:\n            added_any_alt = False\n            for spec in req.specs:\n                # Here we blithely assume that the Debian package\n                # versions are enough like the Python package versions\n                # that the requirement can be ported straight over...\n                alts.append(\"%s (%s %s)\" % (deb, ops[spec[0]], spec[1]))\n                added_any_alt = True\n\n            if not added_any_alt:\n                # No alternates were added, but we have the name of a\n                # good package.\n                alts.append(\"%s\"%deb)\n\n        if len(alts):\n            depends.append(' | '.join(alts))\n\n    return depends"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_tarball(tarball_fname,directory,cwd=None):\n    \"create a tarball from a directory\"\n    if tarball_fname.endswith('.gz'): opts = 'czf'\n    else: opts = 'cf'\n    args = ['/bin/tar',opts,tarball_fname,directory]\n    process_command(args, cwd=cwd)", "response": "create a tarball from a directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dpkg_buildpackage(*args,**kwargs):\n    cwd=kwargs.pop('cwd',None)\n    if len(kwargs)!=0:\n        raise ValueError('only kwarg can be \"cwd\"')\n    \"call dpkg-buildpackage [arg1] [...] [argN]\"\n    args = ['/usr/bin/dpkg-buildpackage']+list(args)\n    process_command(args, cwd=cwd)", "response": "call dpkg - buildpackage [ arg1... argN ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls dpkg - source - b | x arg1 [ arg2 ]", "response": "def dpkg_source(b_or_x,arg1,cwd=None):\n    \"call dpkg-source -b|x arg1 [arg2]\"\n    assert b_or_x in ['-b','-x']\n    args = ['/usr/bin/dpkg-source',b_or_x,arg1]\n    process_command(args, cwd=cwd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a patch file to the current dpkg - source", "response": "def apply_patch(patchfile,cwd=None,posix=False,level=0):\n    \"\"\"call 'patch -p[level] [--posix] < arg1'\n\n    posix mode is sometimes necessary. It keeps empty files so that\n    dpkg-source removes their contents.\n\n    \"\"\"\n    if not os.path.exists(patchfile):\n        raise RuntimeError('patchfile \"%s\" does not exist'%patchfile)\n    fd = open(patchfile,mode='r')\n\n    level_str = '-p%d'%level\n    args = ['/usr/bin/patch',level_str]\n    if posix:\n        args.append('--posix')\n\n    log.info('PATCH COMMAND: %s < %s', ' '.join(args), patchfile)\n    log.info('  PATCHING in dir: %s', cwd)\n#    print >> sys.stderr, 'PATCH COMMAND:',' '.join(args),'<',patchfile\n#    print >> sys.stderr, '  PATCHING in dir:',cwd\n    res = subprocess.Popen(\n        args, cwd=cwd,\n        stdin=fd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        universal_newlines=True\n        )\n    returncode=None\n    while returncode is None:\n        returncode = res.poll()\n        ready = select.select( [res.stdout,res.stderr],[],[],0.1)\n        # XXX figure out how to do this without reading byte-by-byte\n        if res.stdout in ready[0]:\n            sys.stdout.write(res.stdout.read(1))\n            sys.stdout.flush()\n        if res.stderr in ready[0]:\n            sys.stderr.write(res.stderr.read(1))\n            sys.stderr.flush()\n    # finish outputting file\n    sys.stdout.write(res.stdout.read())\n    sys.stdout.flush()\n    sys.stderr.write(res.stderr.read())\n    sys.stderr.flush()\n\n    if returncode:\n        log.error('ERROR running: %s', ' '.join(args))\n        log.error('ERROR in %s', cwd)\n#        print >> sys.stderr, 'ERROR running: %s'%(' '.join(args),)\n#        print >> sys.stderr, 'ERROR in',cwd\n        raise RuntimeError('returncode %d'%returncode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse comma separated values in debian control file style from. cfg", "response": "def parse_vals(cfg,section,option):\n    \"\"\"parse comma separated values in debian control file style from .cfg\"\"\"\n    try:\n        vals = cfg.get(section,option)\n    except ConfigParser.NoSectionError as err:\n        if section != 'DEFAULT':\n            vals = cfg.get('DEFAULT',option)\n        else:\n            raise err\n    vals = vals.split('#')[0]\n    vals = vals.strip()\n    vals = vals.split(',')\n    vals = [v.strip() for v in vals]\n    vals = [v for v in vals if len(v)]\n    return vals"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract a single value from. cfg", "response": "def parse_val(cfg,section,option):\n    \"\"\"extract a single value from .cfg\"\"\"\n    vals = parse_vals(cfg,section,option)\n    if len(vals)==0:\n        return ''\n    else:\n        assert len(vals)==1, (section, option, vals, type(vals))\n    return vals[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the configuration files actually specify something", "response": "def check_cfg_files(cfg_files,module_name):\n    \"\"\"check if the configuration files actually specify something\n\n    If config files are given, give warning if they don't contain\n    information. This may indicate a wrong module name name, for\n    example.\n    \"\"\"\n\n    cfg = ConfigParser.SafeConfigParser()\n    cfg.read(cfg_files)\n    if cfg.has_section(module_name):\n        section_items = cfg.items(module_name)\n    else:\n        section_items = []\n    default_items = cfg.items('DEFAULT')\n\n    n_items = len(section_items) + len(default_items)\n    if n_items==0:\n        log.warn('configuration files were specified, but no options were '\n                 'found in \"%s\" or \"DEFAULT\" sections.' % (module_name,) )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a debian source package.", "response": "def build_dsc(debinfo,\n              dist_dir,\n              repackaged_dirname,\n              orig_sdist=None,\n              patch_posix=0,\n              remove_expanded_source_dir=0,\n              debian_dir_only=False,\n              sign_dsc=False,\n              ):\n    \"\"\"make debian source package\"\"\"\n    #    A. Find new dirname and delete any pre-existing contents\n\n    # dist_dir is usually 'deb_dist'\n\n    # the location of the copied original source package (it was\n    # re-recreated in dist_dir)\n    if debian_dir_only:\n        fullpath_repackaged_dirname = os.path.abspath(os.curdir)\n    else:\n        fullpath_repackaged_dirname = os.path.join(dist_dir,repackaged_dirname)\n\n    ###############################################\n    # 1. make temporary original source tarball\n\n    #    Note that, for the final tarball, best practices suggest\n    #    using \"dpkg-source -b\".  See\n    #    http://www.debian.org/doc/developers-reference/ch-best-pkging-practices.en.html\n\n    # Create the name of the tarball that qualifies as the upstream\n    # source. If the original was specified, we'll link to\n    # it. Otherwise, we generate our own .tar.gz file from the output\n    # of \"python setup.py sdist\" (done above) so that we avoid\n    # packaging .svn directories, for example.\n\n    if not debian_dir_only:\n        repackaged_orig_tarball = ('%(source)s_%(upstream_version)s.orig.tar.gz'%\n                                   debinfo.__dict__)\n        repackaged_orig_tarball_path = os.path.join(dist_dir,\n                                                    repackaged_orig_tarball)\n        if orig_sdist is not None:\n            if os.path.exists(repackaged_orig_tarball_path):\n                os.unlink(repackaged_orig_tarball_path)\n            link_func(orig_sdist,repackaged_orig_tarball_path)\n        else:\n            make_tarball(repackaged_orig_tarball,\n                         repackaged_dirname,\n                         cwd=dist_dir)\n\n        # apply patch\n        if debinfo.patch_file != '':\n            apply_patch(debinfo.patch_file,\n                        posix=patch_posix,\n                        level=debinfo.patch_level,\n                        cwd=fullpath_repackaged_dirname)\n\n    for fname in ['Makefile','makefile']:\n        if os.path.exists(os.path.join(fullpath_repackaged_dirname,fname)):\n            sys.stderr.write('*'*1000 + '\\n')\n            sys.stderr.write('WARNING: a Makefile exists in this package. '\n                             'stdeb will tell debhelper 7 to use setup.py '\n                             'to build and install the package, and the '\n                             'Makefile will be ignored.\\n')\n            sys.stderr.write('*'*1000 + '\\n')\n\n\n    ###############################################\n    # 2. create debian/ directory and contents\n    debian_dir = os.path.join(fullpath_repackaged_dirname,'debian')\n    if not os.path.exists(debian_dir):\n        os.mkdir(debian_dir)\n\n    #    A. debian/changelog\n    changelog = CHANGELOG_FILE%debinfo.__dict__\n    with codecs.open( os.path.join(debian_dir,'changelog'),\n                 mode='w', encoding='utf-8') as fd:\n        fd.write(changelog)\n\n    #    B. debian/control\n    if debinfo.uploaders:\n        debinfo.uploaders = 'Uploaders: %s\\n' % ', '.join(debinfo.uploaders)\n    else:\n        debinfo.uploaders = ''\n    control = CONTROL_FILE%debinfo.__dict__\n    with codecs.open( os.path.join(debian_dir,'control'),\n                      mode='w', encoding='utf-8') as fd:\n        fd.write(control)\n\n    #    C. debian/rules\n    debinfo.percent_symbol = '%'\n    rules = RULES_MAIN%debinfo.__dict__\n\n    rules = rules.replace('        ','\\t')\n    rules_fname = os.path.join(debian_dir,'rules')\n    with codecs.open( rules_fname,\n                      mode='w', encoding='utf-8') as fd:\n        fd.write(rules)\n    os.chmod(rules_fname,0o755)\n\n    #    D. debian/compat\n    fd = open( os.path.join(debian_dir,'compat'), mode='w')\n    fd.write('7\\n')\n    fd.close()\n\n    #    E. debian/package.mime\n    if debinfo.mime_file != '':\n        if not os.path.exists(debinfo.mime_file):\n            raise ValueError(\n                'a MIME file was specified, but does not exist: %s'%(\n                debinfo.mime_file,))\n        link_func( debinfo.mime_file,\n                 os.path.join(debian_dir,debinfo.package+'.mime'))\n    if debinfo.shared_mime_file != '':\n        if not os.path.exists(debinfo.shared_mime_file):\n            raise ValueError(\n                'a shared MIME file was specified, but does not exist: %s'%(\n                debinfo.shared_mime_file,))\n        link_func( debinfo.shared_mime_file,\n                 os.path.join(debian_dir,\n                              debinfo.package+'.sharedmimeinfo'))\n\n    #    F. debian/copyright\n    if debinfo.copyright_file != '':\n        link_func( debinfo.copyright_file,\n                 os.path.join(debian_dir,'copyright'))\n\n    #    H. debian/<package>.install\n    if len(debinfo.install_file_lines):\n        fd = open( os.path.join(debian_dir,'%s.install'%debinfo.package), mode='w')\n        fd.write('\\n'.join(debinfo.install_file_lines)+'\\n')\n        fd.close()\n\n    #    I. debian/<package>.udev\n    if debinfo.udev_rules != '':\n        fname = debinfo.udev_rules\n        if not os.path.exists(fname):\n            raise ValueError('udev rules file specified, but does not exist')\n        link_func(fname,\n                  os.path.join(debian_dir,'%s.udev'%debinfo.package))\n\n    #    J. debian/source/format\n    os.mkdir(os.path.join(debian_dir,'source'))\n    fd = open( os.path.join(debian_dir,'source','format'), mode='w')\n    fd.write('3.0 (quilt)\\n')\n    fd.close()\n\n    fd = open( os.path.join(debian_dir,'source','options'), mode='w')\n    fd.write('extend-diff-ignore=\"\\.egg-info$\"')\n    fd.close()\n\n    if debian_dir_only:\n        return\n\n    ###############################################\n    # 3. unpack original source tarball\n\n    debianized_package_dirname = fullpath_repackaged_dirname+'.debianized'\n    if os.path.exists(debianized_package_dirname):\n        raise RuntimeError('debianized_package_dirname exists: %s' %\n                           debianized_package_dirname)\n    #    A. move debianized tree away\n    os.rename(fullpath_repackaged_dirname, debianized_package_dirname )\n    if orig_sdist is not None:\n        #    B. expand repackaged original tarball\n        tmp_dir = os.path.join(dist_dir,'tmp-expand')\n        os.mkdir(tmp_dir)\n        try:\n            expand_tarball(orig_sdist,cwd=tmp_dir)\n            orig_tarball_top_contents = os.listdir(tmp_dir)\n\n            # make sure original tarball has exactly one directory\n            assert len(orig_tarball_top_contents)==1\n            orig_dirname = orig_tarball_top_contents[0]\n            fullpath_orig_dirname = os.path.join(tmp_dir,orig_dirname)\n\n            #    C. remove original repackaged tree\n            shutil.rmtree(fullpath_orig_dirname)\n\n        finally:\n            shutil.rmtree(tmp_dir)\n\n    if 1:\n        # check versions of debhelper and python-all\n        debhelper_version_str = get_version_str('debhelper')\n        if len(debhelper_version_str)==0:\n            log.warn('This version of stdeb requires debhelper >= %s, but you '\n                     'do not have debhelper installed. '\n                     'Could not check compatibility.'%DH_MIN_VERS)\n        else:\n            if not dpkg_compare_versions(\n                debhelper_version_str, 'ge', DH_MIN_VERS ):\n                log.warn('This version of stdeb requires debhelper >= %s. '\n                         'Use stdeb 0.3.x to generate source packages '\n                         'compatible with older versions of debhelper.'%(\n                    DH_MIN_VERS,))\n\n        python_defaults_version_str = get_version_str('python-all')\n        if len(python_defaults_version_str)==0:\n            log.warn('This version of stdeb requires python-all >= %s, '\n                     'but you do not have this package installed. '\n                     'Could not check compatibility.'%PYTHON_ALL_MIN_VERS)\n        else:\n            if not dpkg_compare_versions(\n                python_defaults_version_str, 'ge', PYTHON_ALL_MIN_VERS):\n                log.warn('This version of stdeb requires python-all >= %s. '\n                         'Use stdeb 0.6.0 or older to generate source packages '\n                         'that use python-support.'%(\n                    PYTHON_ALL_MIN_VERS,))\n\n    #    D. restore debianized tree\n    os.rename(fullpath_repackaged_dirname+'.debianized',\n              fullpath_repackaged_dirname)\n\n    #    Re-generate tarball using best practices see\n    #    http://www.debian.org/doc/developers-reference/ch-best-pkging-practices.en.html\n\n    if sign_dsc:\n        args = ()\n    else:\n        args = ('-uc','-us')\n\n    dpkg_buildpackage('-S','-sa',*args,cwd=fullpath_repackaged_dirname)\n\n    if 1:\n        shutil.rmtree(fullpath_repackaged_dirname)\n\n    if not remove_expanded_source_dir:\n        # expand the debian source package\n        dsc_name = debinfo.source + '_' + debinfo.dsc_version + '.dsc'\n        dpkg_source('-x',dsc_name,\n                    cwd=dist_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an xmlrpc request.", "response": "def request(self, host, handler, request_body, verbose):\n        \"\"\"\n        Make an xmlrpc request.\n        \"\"\"\n        headers = {'User-Agent': self.user_agent,\n                   'Content-Type': 'text/xml',\n                   }\n        url = self._build_url(host, handler)\n        kwargs = {}\n        if StrictVersion(requests.__version__) >= StrictVersion('0.8.8'):\n            kwargs['verify']=True\n        else:\n            if self.use_https:\n                warnings.warn('using https transport but no certificate '\n                              'verification. (Hint: upgrade requests package.)')\n        try:\n            resp = requests.post(url, data=request_body, headers=headers,\n                                 **kwargs)\n        except ValueError:\n            raise\n        except Exception:\n            raise # something went wrong\n        else:\n            try:\n                resp.raise_for_status()\n            except requests.RequestException as e:\n                raise xmlrpc.ProtocolError(url, resp.status_code, \n                                                        str(e), resp.headers)\n            else:\n                return self.parse_response(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_response(self, resp):\n        p, u = self.getparser()\n\n        if hasattr(resp,'text'):\n            # modern requests will do this for us\n            text = resp.text # this is unicode(py2)/str(py3)\n        else:\n\n            encoding = requests.utils.get_encoding_from_headers(resp.headers)\n            if encoding is None:\n                encoding='utf-8' # FIXME: what to do here?\n\n            if sys.version_info[0]==2:\n                text = unicode(resp.content, encoding, errors='replace')\n            else:\n                assert sys.version_info[0]==3\n                text = str(resp.content, encoding, errors='replace')\n        p.feed(text)\n        p.close()\n        return u.close()", "response": "Parse the xmlrpc response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _build_url(self, host, handler):\n        scheme = 'https' if self.use_https else 'http'\n        return '%s://%s/%s' % (scheme, host, handler)", "response": "Build a url based on the host handler and use_http\n        property."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setting(self, opt, val):\n        opt = opt.encode()\n        if isinstance(val, basestring):\n            fluid_settings_setstr(self.settings, opt, val)\n        elif isinstance(val, int):\n            fluid_settings_setint(self.settings, opt, val)\n        elif isinstance(val, float):\n            fluid_settings_setnum(self.settings, opt, val)", "response": "change an arbitrary synth setting type - smart"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self, driver=None, device=None, midi_driver=None):\n        if driver is not None:\n            assert (driver in ['alsa', 'oss', 'jack', 'portaudio', 'sndmgr', 'coreaudio', 'Direct Sound', 'pulseaudio']) \n            fluid_settings_setstr(self.settings, b'audio.driver', driver.encode())\n            if device is not None:\n                fluid_settings_setstr(self.settings, str('audio.%s.device' % (driver)).encode(), device.encode())\n            self.audio_driver = new_fluid_audio_driver(self.settings, self.synth)\n        if midi_driver is not None:\n            assert (midi_driver in ['alsa_seq', 'alsa_raw', 'oss', 'winmidi', 'midishare', 'coremidi'])\n            fluid_settings_setstr(self.settings, b'midi.driver', midi_driver.encode())\n            self.router = new_fluid_midi_router(self.settings, fluid_synth_handle_midi_event, self.synth)\n            fluid_synth_set_midi_router(self.synth, self.router)\n            self.midi_driver = new_fluid_midi_driver(self.settings, fluid_midi_router_handle_midi_event, self.router)", "response": "Start audio output driver in separate background thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads SoundFont and return its ID", "response": "def sfload(self, filename, update_midi_preset=0):\n        \"\"\"Load SoundFont and return its ID\"\"\"\n        return fluid_synth_sfload(self.synth, filename.encode(), update_midi_preset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting soundfont bank prog preset name of channel", "response": "def channel_info(self, chan):\n        \"\"\"get soundfont, bank, prog, preset name of channel\"\"\"\n        info=fluid_synth_channel_info_t()\n        fluid_synth_get_channel_info(self.synth, chan, byref(info))\n        return (info.sfont_id, info.bank, info.program, info.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the reverb of the current user.", "response": "def set_reverb(self, roomsize=-1.0, damping=-1.0, width=-1.0, level=-1.0):\n        \"\"\"                                  \n        roomsize Reverb room size value (0.0-1.2)\n        damping Reverb damping value (0.0-1.0)\n        width Reverb width value (0.0-100.0)\n        level Reverb level value (0.0-1.0)\n        \"\"\"\n        set=0\n        if roomsize>=0:\n            set+=0b0001\n        if damping>=0:\n            set+=0b0010\n        if width>=0:\n            set+=0b0100\n        if level>=0:\n            set+=0b1000\n        return fluid_synth_set_reverb_full(self.synth, set, roomsize, damping, width, level)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the current Chorus frequency of the current entry in the system.", "response": "def set_chorus(self, nr=-1, level=-1.0, speed=-1.0, depth=-1.0, type=-1):\n        \"\"\"                                  \n        nr Chorus voice count (0-99, CPU time consumption proportional to this value)\n        level Chorus level (0.0-10.0)\n        speed Chorus speed in Hz (0.29-5.0)\n        depth_ms Chorus depth (max value depends on synth sample rate, 0.0-21.0 is safe for sample rate values up to 96KHz)\n        type Chorus waveform type (0=sine, 1=triangle)\n        \"\"\"\n        set=0\n        if nr>=0:\n            set+=0b00001\n        if level>=0:\n            set+=0b00010\n        if speed>=0:\n            set+=0b00100\n        if depth>=0:\n            set+=0b01000\n        if type>=0:\n            set+=0b10000\n        return fluid_synth_set_chorus_full(self.synth, set, nr, level, speed, depth, type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef consume_messages(self, max_next_messages):\n        # get messages list from kafka\n        if self.__next_messages == 0:\n            self.set_next_messages(min(1000, max_next_messages))\n        self.set_next_messages(min(self.__next_messages, max_next_messages))\n        mark = time.time()\n        for record in self._get_messages_from_consumer():\n            yield record.partition, record.offset, record.key, record.value\n        newmark = time.time()\n        if newmark - mark > 30:\n            self.set_next_messages(self.__next_messages / 2 or 1)\n        elif newmark - mark < 5:\n            self.set_next_messages(min(self.__next_messages + 100, max_next_messages))", "response": "Get messages batch from Kafka"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decompress_messages(self, partitions_offmsgs):\n\n        for pomsg in partitions_offmsgs:\n            if pomsg['message']:\n                pomsg['message'] = self.decompress_fun(pomsg['message'])\n            yield pomsg", "response": "Decompress pre - defined compressed fields for each message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunpacking a message to python structures", "response": "def unpack_messages(self, partitions_msgs):\n        \"\"\" Deserialize a message to python structures \"\"\"\n\n        for pmsg in partitions_msgs:\n            key = pmsg['_key']\n            partition = pmsg['partition']\n            offset = pmsg['offset']\n            msg = pmsg.pop('message')\n            if msg:\n                try:\n                    record = self.deserialize_fun(msg)\n                except Exception as e:\n                    log.error('Error unpacking record at partition:offset {}:{} (key: {} : {})'.format(partition, offset, key, repr(e)))\n                    continue\n                else:\n                    if isinstance(record, dict):\n                        pmsg['record'] = record\n                        yield pmsg\n                    else:\n                        log.info('Record {} has wrong type'.format(key))\n            else:\n                yield pmsg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a stat variable to the stats logline", "response": "def append_stat_var(self, name, get_func):\n        \"\"\"\n        get_func is a function that returns a tuple (name, value)\n        \"\"\"\n        self._stats_getters.append(get_func)\n        self._stats_logline += '%s: {}. ' % name\n        self._stats_logline_totals += 'Total %s: {}. ' % name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_offsets(self, batchsize):\n        upper_offsets = previous_lower_offsets = self._lower_offsets\n        if not upper_offsets:\n            upper_offsets = self.latest_offsets\n        self._upper_offsets = {p: o for p, o in upper_offsets.items() if o > self._min_lower_offsets[p]}\n\n        # remove db dupes not used anymore\n        if self._dupes:\n            for p in list(six.iterkeys(self._dupes)):\n                if p not in self._upper_offsets:\n                    db = self._dupes.pop(p)\n                    db.close()\n                    os.remove(db.filename)\n\n        partition_batchsize = 0\n        if self._upper_offsets:\n            partition_batchsize = max(int(batchsize * self.__scan_excess), batchsize)\n            self._lower_offsets = self._upper_offsets.copy()\n            total_offsets_run = 0\n            for p in sorted(self._upper_offsets.keys()):\n                # readjust partition_batchsize when a partition scan starts from latest offset\n                if total_offsets_run > 0 and partition_batchsize > batchsize:\n                    partition_batchsize = batchsize\n                if partition_batchsize > 0:\n                    self._lower_offsets[p] = max(self._upper_offsets[p] - partition_batchsize, self._min_lower_offsets[p])\n                    offsets_run = self._upper_offsets[p] - self._lower_offsets[p]\n                    total_offsets_run += offsets_run\n                    partition_batchsize = partition_batchsize - offsets_run\n                else:\n                    break\n            log.info('Offset run: %d', total_offsets_run)\n            # create new consumer if partition list changes\n            if previous_lower_offsets is not None and set(previous_lower_offsets.keys()) != set(self._lower_offsets):\n                self._create_scan_consumer(self._lower_offsets.keys())\n\n            # consumer must restart from newly computed lower offsets\n            self._update_offsets(self._lower_offsets)\n        log.info('Initial offsets for topic %s: %s', self._topic, repr(self._lower_offsets))\n        log.info('Target offsets for topic %s: %s', self._topic, repr(self._upper_offsets))\n\n        return batchsize", "response": "Compute new initial and target offsets and do other maintenance tasks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _filter_deleted_records(self, batches):\n        for batch in batches:\n            for record in batch:\n                if not self.must_delete_record(record):\n                    yield record", "response": "Filter out deleted records from a list of batches."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_catalog(mid):\n    if isinstance(mid, _uuid.UUID):\n        mid = mid.hex\n    return _get_catalog(mid)", "response": "Return the catalog entry for the specified ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_field(self, key, value):\n        convert = self.converters.get(key, bytes.decode)\n        try:\n            return convert(value)\n        except ValueError:\n            # Leave in default bytes\n            return value", "response": "Convert value using self. converters [ key ].\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting entire journal entry utilising _convert_field.", "response": "def _convert_entry(self, entry):\n        \"\"\"Convert entire journal entry utilising _convert_field.\"\"\"\n        result = {}\n        for key, value in entry.items():\n            if isinstance(value, list):\n                result[key] = [self._convert_field(key, val) for val in value]\n            else:\n                result[key] = self._convert_field(key, value)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_match(self, *args, **kwargs):\n        args = list(args)\n        args.extend(_make_line(key, val) for key, val in kwargs.items())\n        for arg in args:\n            super(Reader, self).add_match(arg)", "response": "Add one or more matches to the filter journal log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next(self, skip=1):\n        if super(Reader, self)._next(skip):\n            entry = super(Reader, self)._get_all()\n            if entry:\n                entry['__REALTIME_TIMESTAMP'] = self._get_realtime()\n                entry['__MONOTONIC_TIMESTAMP'] = self._get_monotonic()\n                entry['__CURSOR'] = self._get_cursor()\n                return self._convert_entry(entry)\n        return dict()", "response": "r Return the next log entry as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of unique values appearing in the journal for the given field.", "response": "def query_unique(self, field):\n        \"\"\"Return a list of unique values appearing in the journal for the given\n        `field`.\n\n        Note this does not respect any journal matches.\n\n        Entries will be processed with converters specified during\n        Reader creation.\n        \"\"\"\n        return set(self._convert_field(field, value)\n                   for value in super(Reader, self).query_unique(field))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait(self, timeout=None):\n        us = -1 if timeout is None else int(timeout * 1000000)\n        return super(Reader, self).wait(us)", "response": "Wait for a change in the journal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seek_realtime(self, realtime):\n        if isinstance(realtime, _datetime.datetime):\n            realtime = int(float(realtime.strftime(\"%s.%f\")) * 1000000)\n        elif not isinstance(realtime, int):\n            realtime = int(realtime * 1000000)\n        return super(Reader, self).seek_realtime(realtime)", "response": "Seek to a matching journal entry nearest to a given realtime time."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nseeks to a matching journal entry nearest to monotonic time.", "response": "def seek_monotonic(self, monotonic, bootid=None):\n        \"\"\"Seek to a matching journal entry nearest to `monotonic` time.\n\n        Argument `monotonic` is a timestamp from boot in either seconds or a\n        datetime.timedelta instance. Argument `bootid` is a string or UUID\n        representing which boot the monotonic time is reference to. Defaults to\n        current bootid.\n        \"\"\"\n        if isinstance(monotonic, _datetime.timedelta):\n            monotonic = monotonic.total_seconds()\n        monotonic = int(monotonic * 1000000)\n        if isinstance(bootid, _uuid.UUID):\n            bootid = bootid.hex\n        return super(Reader, self).seek_monotonic(monotonic, bootid)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting maximum log level by setting matches for PRIORITY.", "response": "def log_level(self, level):\n        \"\"\"Set maximum log `level` by setting matches for PRIORITY.\n        \"\"\"\n        if 0 <= level <= 7:\n            for i in range(level+1):\n                self.add_match(PRIORITY=\"%d\" % i)\n        else:\n            raise ValueError(\"Log level must be 0 <= level <= 7\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef messageid_match(self, messageid):\n        if isinstance(messageid, _uuid.UUID):\n            messageid = messageid.hex\n        self.add_match(MESSAGE_ID=messageid)", "response": "Add match for log entries with specified messageid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef this_boot(self, bootid=None):\n        if bootid is None:\n            bootid = _id128.get_boot().hex\n        else:\n            bootid = getattr(bootid, 'hex', bootid)\n        self.add_match(_BOOT_ID=bootid)", "response": "Add match for _BOOT_ID for current boot or the specified boot ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd match for _MACHINE_ID equal to the ID of this machine.", "response": "def this_machine(self, machineid=None):\n        \"\"\"Add match for _MACHINE_ID equal to the ID of this machine.\n\n        If specified, machineid should be either a UUID or a 32 digit hex\n        number.\n\n        Equivalent to add_match(_MACHINE_ID='machineid').\n        \"\"\"\n        if machineid is None:\n            machineid = _id128.get_machine().hex\n        else:\n            machineid = getattr(machineid, 'hex', machineid)\n        self.add_match(_MACHINE_ID=machineid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef emit(self, record):\n        try:\n            msg = self.format(record)\n            pri = self.map_priority(record.levelno)\n            # defaults\n            extras = self._extra.copy()\n\n            # higher priority\n            if record.exc_text:\n                extras['EXCEPTION_TEXT'] = record.exc_text\n\n            if record.exc_info:\n                extras['EXCEPTION_INFO'] = record.exc_info\n\n            if record.args:\n                extras['CODE_ARGS'] = str(record.args)\n\n            # explicit arguments \u2014 highest priority\n            extras.update(record.__dict__)\n\n            self.send(msg,\n                      PRIORITY=format(pri),\n                      LOGGER=record.name,\n                      THREAD_NAME=record.threadName,\n                      PROCESS_NAME=record.processName,\n                      CODE_FILE=record.pathname,\n                      CODE_LINE=record.lineno,\n                      CODE_FUNC=record.funcName,\n                      **extras)\n        except Exception:\n            self.handleError(record)", "response": "Write record as a journal event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck socket type address and port flowinfo and listening state.", "response": "def is_socket_sockaddr(fileobj, address, type=0, flowinfo=0, listening=-1):\n    \"\"\"Check socket type, address and/or port, flowinfo, listening state.\n\n    Wraps sd_is_socket_inet_sockaddr(3).\n\n    `address` is a systemd-style numerical IPv4 or IPv6 address as used in\n    ListenStream=. A port may be included after a colon (\":\").\n    See systemd.socket(5) for details.\n\n    Constants for `family` are defined in the socket module.\n    \"\"\"\n    fd = _convert_fileobj(fileobj)\n    return _is_socket_sockaddr(fd, address, type, flowinfo, listening)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of socket activated descriptors in a primary window.", "response": "def listen_fds(unset_environment=True):\n    \"\"\"Return a list of socket activated descriptors\n\n    Example::\n\n      (in primary window)\n      $ systemd-activate -l 2000 python3 -c \\\\\n          'from systemd.daemon import listen_fds; print(listen_fds())'\n      (in another window)\n      $ telnet localhost 2000\n      (in primary window)\n      ...\n      Execing python3 (...)\n      [3]\n    \"\"\"\n    num = _listen_fds(unset_environment)\n    return list(range(LISTEN_FDS_START, LISTEN_FDS_START + num))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self):\n        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._socket.settimeout(self._connect_timeout)\n        SocketError.wrap(self._socket.connect, (self.host, self.port))\n        self._socket.settimeout(None)\n        self._socket_file = self._socket.makefile('rb')", "response": "Connect to beanstalkd server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        try:\n            self._socket.sendall('quit\\r\\n')\n        except socket.error:\n            pass\n        try:\n            self._socket.close()\n        except socket.error:\n            pass", "response": "Close connection to server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput a job into the current tube. Returns job id.", "response": "def put(self, body, priority=DEFAULT_PRIORITY, delay=0, ttr=DEFAULT_TTR):\n        \"\"\"Put a job into the current tube. Returns job id.\"\"\"\n        assert isinstance(body, str), 'Job body must be a str instance'\n        jid = self._interact_value('put %d %d %d %d\\r\\n%s\\r\\n' % (\n                                       priority, delay, ttr, len(body), body),\n                                   ['INSERTED'],\n                                   ['JOB_TOO_BIG', 'BURIED', 'DRAINING'])\n        return int(jid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreserve a job from one of the watched tubes with optional timeout in seconds. Returns a Job object or None.", "response": "def reserve(self, timeout=None):\n        \"\"\"Reserve a job from one of the watched tubes, with optional timeout\n        in seconds. Returns a Job object, or None if the request times out.\"\"\"\n        if timeout is not None:\n            command = 'reserve-with-timeout %d\\r\\n' % timeout\n        else:\n            command = 'reserve\\r\\n'\n        try:\n            return self._interact_job(command,\n                                      ['RESERVED'],\n                                      ['DEADLINE_SOON', 'TIMED_OUT'])\n        except CommandFailed:\n            exc = sys.exc_info()[1]\n            _, status, results = exc.args\n            if status == 'TIMED_OUT':\n                return None\n            elif status == 'DEADLINE_SOON':\n                raise DeadlineSoon(results)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef release(self, jid, priority=DEFAULT_PRIORITY, delay=0):\n        self._interact('release %d %d %d\\r\\n' % (jid, priority, delay),\n                       ['RELEASED', 'BURIED'],\n                       ['NOT_FOUND'])", "response": "Release a reserved job back into the ready queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef release(self, priority=None, delay=0):\n        if self.reserved:\n            self.conn.release(self.jid, priority or self._priority(), delay)\n            self.reserved = False", "response": "Release this job back into the ready queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(\n    path,\n    base_url,\n    version=None,\n    version_dev=\"master\",\n    env=None,\n    registry=None,\n    urls=None,\n):\n    \"\"\"\n    Create a new :class:`~pooch.Pooch` with sensible defaults to fetch data files.\n\n    If a version string is given, the Pooch will be versioned, meaning that the local\n    storage folder and the base URL depend on the project version. This is necessary\n    if your users have multiple versions of your library installed (using virtual\n    environments) and you updated the data files between versions. Otherwise, every time\n    a user switches environments would trigger a re-download of the data. The version\n    string will be appended to the local storage path (for example,\n    ``~/.mypooch/cache/v0.1``) and inserted into the base URL (for example,\n    ``https://github.com/fatiando/pooch/raw/v0.1/data``). If the version string contains\n    ``+XX.XXXXX``, it will be interpreted as a development version.\n\n    Parameters\n    ----------\n    path : str, PathLike, list or tuple\n        The path to the local data storage folder. If this is a list or tuple, we'll\n        join the parts with the appropriate separator. The *version* will be appended to\n        the end of this path. Use :func:`pooch.os_cache` for a sensible default.\n    base_url : str\n        Base URL for the remote data source. All requests will be made relative to this\n        URL. The string should have a ``{version}`` formatting mark in it. We will call\n        ``.format(version=version)`` on this string. If the URL is a directory path, it\n        must end in a ``'/'`` because we will not include it.\n    version : str or None\n        The version string for your project. Should be PEP440 compatible. If None is\n        given, will not attempt to format *base_url* and no subfolder will be appended\n        to *path*.\n    version_dev : str\n        The name used for the development version of a project. If your data is hosted\n        on Github (and *base_url* is a Github raw link), then ``\"master\"`` is a good\n        choice (default). Ignored if *version* is None.\n    env : str or None\n        An environment variable that can be used to overwrite *path*. This allows users\n        to control where they want the data to be stored. We'll append *version* to the\n        end of this value as well.\n    registry : dict or None\n        A record of the files that are managed by this Pooch. Keys should be the file\n        names and the values should be their SHA256 hashes. Only files in the registry\n        can be fetched from the local storage. Files in subdirectories of *path* **must\n        use Unix-style separators** (``'/'``) even on Windows.\n    urls : dict or None\n        Custom URLs for downloading individual files in the registry. A dictionary with\n        the file names as keys and the custom URLs as values. Not all files in\n        *registry* need an entry in *urls*. If a file has an entry in *urls*, the\n        *base_url* will be ignored when downloading it in favor of ``urls[fname]``.\n\n\n    Returns\n    -------\n    pooch : :class:`~pooch.Pooch`\n        The :class:`~pooch.Pooch` initialized with the given arguments.\n\n    Examples\n    --------\n\n    Create a :class:`~pooch.Pooch` for a release (v0.1):\n\n    >>> pup = create(path=\"myproject\",\n    ...              base_url=\"http://some.link.com/{version}/\",\n    ...              version=\"v0.1\",\n    ...              registry={\"data.txt\": \"9081wo2eb2gc0u...\"})\n    >>> print(pup.path.parts)  # The path is a pathlib.Path\n    ('myproject', 'v0.1')\n    >>> print(pup.base_url)\n    http://some.link.com/v0.1/\n    >>> print(pup.registry)\n    {'data.txt': '9081wo2eb2gc0u...'}\n    >>> print(pup.registry_files)\n    ['data.txt']\n\n    If this is a development version (12 commits ahead of v0.1), then the\n    ``version_dev`` will be used (defaults to ``\"master\"``):\n\n    >>> pup = create(path=\"myproject\",\n    ...              base_url=\"http://some.link.com/{version}/\",\n    ...              version=\"v0.1+12.do9iwd\")\n    >>> print(pup.path.parts)\n    ('myproject', 'master')\n    >>> print(pup.base_url)\n    http://some.link.com/master/\n\n    Versioning is optional (but highly encouraged):\n\n    >>> pup = create(path=\"myproject\",\n    ...              base_url=\"http://some.link.com/\",\n    ...              registry={\"data.txt\": \"9081wo2eb2gc0u...\"})\n    >>> print(pup.path.parts)  # The path is a pathlib.Path\n    ('myproject',)\n    >>> print(pup.base_url)\n    http://some.link.com/\n\n    To place the storage folder at a subdirectory, pass in a list and we'll join the\n    path for you using the appropriate separator for your operating system:\n\n    >>> pup = create(path=[\"myproject\", \"cache\", \"data\"],\n    ...              base_url=\"http://some.link.com/{version}/\",\n    ...              version=\"v0.1\")\n    >>> print(pup.path.parts)\n    ('myproject', 'cache', 'data', 'v0.1')\n\n    The user can overwrite the storage path by setting an environment variable:\n\n    >>> # The variable is not set so we'll use *path*\n    >>> pup = create(path=[\"myproject\", \"not_from_env\"],\n    ...              base_url=\"http://some.link.com/{version}/\",\n    ...              version=\"v0.1\",\n    ...              env=\"MYPROJECT_DATA_DIR\")\n    >>> print(pup.path.parts)\n    ('myproject', 'not_from_env', 'v0.1')\n    >>> # Set the environment variable and try again\n    >>> import os\n    >>> os.environ[\"MYPROJECT_DATA_DIR\"] = os.path.join(\"myproject\", \"from_env\")\n    >>> pup = create(path=[\"myproject\", \"not_from_env\"],\n    ...              base_url=\"http://some.link.com/{version}/\",\n    ...              version=\"v0.1\",\n    ...              env=\"MYPROJECT_DATA_DIR\")\n    >>> print(pup.path.parts)\n    ('myproject', 'from_env', 'v0.1')\n\n    \"\"\"\n    if isinstance(path, (list, tuple)):\n        path = os.path.join(*path)\n    if env is not None and env in os.environ and os.environ[env]:\n        path = os.environ[env]\n    if version is not None:\n        version = check_version(version, fallback=version_dev)\n        path = os.path.join(str(path), version)\n        base_url = base_url.format(version=version)\n    path = os.path.expanduser(str(path))\n    # Check that the data directory is writable\n    try:\n        if not os.path.exists(path):\n            os.makedirs(path)\n        else:\n            tempfile.NamedTemporaryFile(dir=path)\n    except PermissionError:\n        message = (\n            \"Cannot write to data cache '{}'. \"\n            \"Will not be able to download remote data files. \".format(path)\n        )\n        if env is not None:\n            message = (\n                message\n                + \"Use environment variable '{}' to specify another directory.\".format(\n                    env\n                )\n            )\n        warn(message)\n    pup = Pooch(path=Path(path), base_url=base_url, registry=registry, urls=urls)\n    return pup", "response": "Create a new virtual node in the local data storage folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef abspath(self):\n        \"Absolute path to the local storage\"\n        return Path(os.path.abspath(os.path.expanduser(str(self.path))))", "response": "Absolute path to the local storage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the file from the local storage and return the absolute path to the file.", "response": "def fetch(self, fname, processor=None):\n        \"\"\"\n        Get the absolute path to a file in the local storage.\n\n        If it's not in the local storage, it will be downloaded. If the hash of the file\n        in local storage doesn't match the one in the registry, will download a new copy\n        of the file. This is considered a sign that the file was updated in the remote\n        storage. If the hash of the downloaded file still doesn't match the one in the\n        registry, will raise an exception to warn of possible file corruption.\n\n        Post-processing actions sometimes need to be taken on downloaded files\n        (unzipping, conversion to a more efficient format, etc). If these actions are\n        time or memory consuming, it would be best to do this only once when the file is\n        actually downloaded. Use the *processor* argument to specify a function that is\n        executed after the downloaded (if required) to perform these actions. See below.\n\n        Parameters\n        ----------\n        fname : str\n            The file name (relative to the *base_url* of the remote data storage) to\n            fetch from the local storage.\n        processor : None or callable\n            If not None, then a function (or callable object) that will be called\n            before returning the full path and after the file has been downloaded (if\n            required). See below.\n\n        Returns\n        -------\n        full_path : str\n            The absolute path (including the file name) of the file in the local\n            storage.\n\n        Notes\n        -----\n\n        Processor functions should have the following format:\n\n        .. code:: python\n\n            def myprocessor(fname, action, update):\n                '''\n                Processes the downloaded file and returns a new file name.\n\n                The function **must** take as arguments (in order):\n\n                fname : str\n                    The full path of the file in the local data storage\n                action : str\n                    Either:\n                    \"download\" (file doesn't exist and will be downloaded),\n                    \"update\" (file is outdated and will be downloaded), or\n                    \"fetch\" (file exists and is updated so no download is necessary).\n                pooch : pooch.Pooch\n                    The instance of the Pooch class that is calling this function.\n\n                The return value can be anything but is usually a full path to a file\n                (or list of files). This is what will be returned by *fetch* in place of\n                the original file path.\n                '''\n                ...\n\n        \"\"\"\n        self._assert_file_in_registry(fname)\n\n        # Create the local data directory if it doesn't already exist\n        if not self.abspath.exists():\n            os.makedirs(str(self.abspath))\n\n        full_path = self.abspath / fname\n\n        in_storage = full_path.exists()\n        if not in_storage:\n            action = \"download\"\n        elif in_storage and file_hash(str(full_path)) != self.registry[fname]:\n            action = \"update\"\n        else:\n            action = \"fetch\"\n\n        if action in (\"download\", \"update\"):\n            action_word = dict(download=\"Downloading\", update=\"Updating\")\n            warn(\n                \"{} data file '{}' from remote data store '{}' to '{}'.\".format(\n                    action_word[action], fname, self.get_url(fname), str(self.path)\n                )\n            )\n            self._download_file(fname)\n\n        if processor is not None:\n            return processor(str(full_path), action, self)\n\n        return str(full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url(self, fname):\n        self._assert_file_in_registry(fname)\n        return self.urls.get(fname, \"\".join([self.base_url, fname]))", "response": "Get the full URL to download a file from the local storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _download_file(self, fname):\n        destination = self.abspath / fname\n        source = self.get_url(fname)\n        # Stream the file to a temporary so that we can safely check its hash before\n        # overwriting the original\n        fout = tempfile.NamedTemporaryFile(delete=False, dir=str(self.abspath))\n        try:\n            with fout:\n                response = requests.get(source, stream=True)\n                response.raise_for_status()\n                for chunk in response.iter_content(chunk_size=1024):\n                    if chunk:\n                        fout.write(chunk)\n            tmphash = file_hash(fout.name)\n            if tmphash != self.registry[fname]:\n                raise ValueError(\n                    \"Hash of downloaded file '{}' doesn't match the entry in the registry:\"\n                    \" Expected '{}' and got '{}'.\".format(\n                        fout.name, self.registry[fname], tmphash\n                    )\n                )\n            # Make sure the parent directory exists in case the file is in a subdirectory.\n            # Otherwise, move will cause an error.\n            if not os.path.exists(str(destination.parent)):\n                os.makedirs(str(destination.parent))\n            shutil.move(fout.name, str(destination))\n        except Exception:\n            os.remove(fout.name)\n            raise", "response": "Download a file from the remote data storage to the local storage."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_registry(self, fname):\n        with open(fname) as fin:\n            for linenum, line in enumerate(fin):\n                elements = line.strip().split()\n                if len(elements) > 3 or len(elements) < 2:\n                    raise IOError(\n                        \"Expected 2 or 3 elements in line {} but got {}.\".format(\n                            linenum, len(elements)\n                        )\n                    )\n                file_name = elements[0]\n                file_sha256 = elements[1]\n                if len(elements) == 3:\n                    file_url = elements[2]\n                    self.urls[file_name] = file_url\n                self.registry[file_name] = file_sha256", "response": "Load entries from a file and add them to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_available(self, fname):\n        self._assert_file_in_registry(fname)\n        source = self.get_url(fname)\n        response = requests.head(source, allow_redirects=True)\n        return bool(response.status_code == 200)", "response": "Check availability of a remote file without downloading it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_hash(fname):\n    # Calculate the hash in chunks to avoid overloading the memory\n    chunksize = 65536\n    hasher = hashlib.sha256()\n    with open(fname, \"rb\") as fin:\n        buff = fin.read(chunksize)\n        while buff:\n            hasher.update(buff)\n            buff = fin.read(chunksize)\n    return hasher.hexdigest()", "response": "Calculate the SHA256 hash of a given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_version(version, fallback=\"master\"):\n    parse = Version(version)\n    if parse.local is not None:\n        return fallback\n    return version", "response": "Checks that a version string is PEP440 compliant and returns the fallback."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_registry(directory, output, recursive=True):\n    directory = Path(directory)\n    if recursive:\n        pattern = \"**/*\"\n    else:\n        pattern = \"*\"\n\n    files = sorted(\n        [\n            str(path.relative_to(directory))\n            for path in directory.glob(pattern)\n            if path.is_file()\n        ]\n    )\n\n    hashes = [file_hash(str(directory / fname)) for fname in files]\n\n    with open(output, \"w\") as outfile:\n        for fname, fhash in zip(files, hashes):\n            # Only use Unix separators for the registry so that we don't go insane\n            # dealing with file paths.\n            outfile.write(\"{} {}\\n\".format(fname.replace(\"\\\\\", \"/\"), fhash))", "response": "This function creates a registry of files and hashes for the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(fp, encoding=None, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None,\n        use_decimal=False, **kw):\n    \"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    *encoding* determines the encoding used to interpret any\n    :class:`str` objects decoded by this instance (``'utf-8'`` by\n    default).  It has no effect when decoding :class:`unicode` objects.\n\n    Note that currently only encodings that are a superset of ASCII work,\n    strings of other encodings should be passed in as :class:`unicode`.\n\n    *object_hook*, if specified, will be called with the result of every\n    JSON object decoded and its return value will be used in place of the\n    given :class:`dict`.  This can be used to provide custom\n    deserializations (e.g. to support JSON-RPC class hinting).\n\n    *object_pairs_hook* is an optional function that will be called with\n    the result of any object literal decode with an ordered list of pairs.\n    The return value of *object_pairs_hook* will be used instead of the\n    :class:`dict`.  This feature can be used to implement custom decoders\n    that rely on the order that the key and value pairs are decoded (for\n    example, :func:`collections.OrderedDict` will remember the order of\n    insertion). If *object_hook* is also defined, the *object_pairs_hook*\n    takes priority.\n\n    *parse_float*, if specified, will be called with the string of every\n    JSON float to be decoded.  By default, this is equivalent to\n    ``float(num_str)``. This can be used to use another datatype or parser\n    for JSON floats (e.g. :class:`decimal.Decimal`).\n\n    *parse_int*, if specified, will be called with the string of every\n    JSON int to be decoded.  By default, this is equivalent to\n    ``int(num_str)``.  This can be used to use another datatype or parser\n    for JSON integers (e.g. :class:`float`).\n\n    *parse_constant*, if specified, will be called with one of the\n    following strings: ``'-Infinity'``, ``'Infinity'``, ``'NaN'``.  This\n    can be used to raise an exception if invalid JSON numbers are\n    encountered.\n\n    If *use_decimal* is true (default: ``False``) then it implies\n    parse_float=decimal.Decimal for parity with ``dump``.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg.\n\n    \"\"\"\n    return loads(fp.read(),\n        encoding=encoding, cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook,\n        use_decimal=use_decimal, **kw)", "response": "Deserialize a JSON document into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON representation of a Python string", "response": "def encode_basestring(s):\n    \"\"\"Return a JSON representation of a Python string\n\n    \"\"\"\n    if isinstance(s, str) and HAS_UTF8.search(s) is not None:\n        s = s.decode('utf-8')\n    def replace(match):\n        return ESCAPE_DCT[match.group(0)]\n    return u'\"' + ESCAPE.sub(replace, s) + u'\"'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dumps(o, **kwargs):\n\n    try:\n        return _engine[1](o)\n\n    except:\n        ExceptionClass, why = sys.exc_info()[:2]\n\n        if any([(issubclass(ExceptionClass, e)) for e in _engine[2]]):\n            raise JSONError(why)\n        else:\n            raise why", "response": "Dumps a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(self, s, _w=WHITESPACE.match):\n        obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n        end = _w(s, end).end()\n        if end != len(s):\n            raise JSONDecodeError(\"Extra data\", s, end, len(s))\n        return obj", "response": "Decode a string or unicode object into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_query(query, engine=None, limit=None):\n    if limit is not None:\n        query = query.limit(limit)\n    result_proxy = execute_query_return_result_proxy(query)\n    return from_db_cursor(result_proxy.cursor)", "response": "Execute an ORM style query and return the result in\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new object from a database table.", "response": "def from_table(table, engine, limit=None):\n    \"\"\"\n    Select data in a database table and put into prettytable.\n\n    Create a :class:`prettytable.PrettyTable` from :class:`sqlalchemy.Table`.\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06\u6570\u636e\u8868\u4e2d\u7684\u6570\u636e\u653e\u5165prettytable\u4e2d.\n    \"\"\"\n    sql = select([table])\n    if limit is not None:\n        sql = sql.limit(limit)\n    result_proxy = engine.execute(sql)\n    return from_db_cursor(result_proxy.cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_object(orm_class, engine, limit=None):\n    Session = sessionmaker(bind=engine)\n    ses = Session()\n    query = ses.query(orm_class)\n    if limit is not None:\n        query = query.limit(limit)\n    result_proxy = execute_query_return_result_proxy(query)\n    ses.close()\n    return from_db_cursor(result_proxy.cursor)", "response": "Create a new object from an ORM class and return it as a prettytable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a Prettytable from list of rows.", "response": "def from_data(data):\n    \"\"\"\n    Construct a Prettytable from list of rows.\n    \"\"\"\n    if len(data) == 0:  # pragma: no cover\n        return None\n    else:\n        ptable = PrettyTable()\n        ptable.field_names = data[0].keys()\n        for row in data:\n            ptable.add_row(row)\n        return ptable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_everything(everything, engine, limit=None):\n    if isinstance(everything, Table):\n        return from_table(everything, engine, limit=limit)\n\n    if type(everything) is DeclarativeMeta:\n        return from_object(everything, engine, limit=limit)\n\n    if isinstance(everything, Query):\n        return from_query(everything, engine, limit=limit)\n\n    if isinstance(everything, Select):\n        return from_sql(everything, engine, limit=limit)\n\n    if isinstance(everything, ResultProxy):\n        return from_resultproxy(everything)\n\n    if isinstance(everything, list):\n        return from_data(everything)", "response": "Construct a Prettytable from any kinds of sqlalchemy query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef great_circle(point1, point2, miles=True):\n    # unpack latitude/longitude\n    lat1, lng1 = point1\n    lat2, lng2 = point2\n\n    # convert all latitudes/longitudes from decimal degrees to radians\n    lat1, lng1, lat2, lng2 = list(map(radians, [lat1, lng1, lat2, lng2]))\n\n    # calculate haversine\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = sin(lat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(lng / 2) ** 2\n    h = 2 * AVG_EARTH_RADIUS * asin(sqrt(d))\n    if miles:\n        return h * 0.621371  # in miles\n    else:\n        return h", "response": "Calculate the great - circle distance bewteen two points on the Earth surface."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a PrettyTable object from a list of rows a PrettyTable object.", "response": "def generate_table(self, rows):\n        \"\"\"\n        Generates from a list of rows a PrettyTable object.\n        \"\"\"\n        table = PrettyTable(**self.kwargs)\n        for row in self.rows:\n            if len(row[0]) < self.max_row_width:\n                appends = self.max_row_width - len(row[0])\n                for i in range(1, appends):\n                    row[0].append(\"-\")\n\n            if row[1] is True:\n                self.make_fields_unique(row[0])\n                table.field_names = row[0]\n            else:\n                table.add_row(row[0])\n        return table"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sql_to_csv(sql, engine, filepath, chunksize=1000, overwrite=False):\n    if overwrite:  # pragma: no cover\n        if os.path.exists(filepath):\n            raise Exception(\"'%s' already exists!\" % filepath)\n\n    import pandas as pd\n\n    columns = [str(column.name) for column in sql.columns]\n    with open(filepath, \"w\") as f:\n        # write header\n        df = pd.DataFrame([], columns=columns)\n        df.to_csv(f, header=True, index=False)\n\n        # iterate big database table\n        result_proxy = engine.execute(sql)\n        while True:\n            data = result_proxy.fetchmany(chunksize)\n            if len(data) == 0:\n                break\n            else:\n                df = pd.DataFrame(data, columns=columns)\n                df.to_csv(f, header=False, index=False)", "response": "Export sql result to csv file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports entire table to a csv file.", "response": "def table_to_csv(table, engine, filepath, chunksize=1000, overwrite=False):\n    \"\"\"\n    Export entire table to a csv file.\n\n    :param table: :class:`sqlalchemy.Table` instance.\n    :param engine: :class:`sqlalchemy.engine.base.Engine`.\n    :param filepath: file path.\n    :param chunksize: number of rows write to csv each time.\n    :param overwrite: bool, if True, avoid to overite existing file.\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06\u6574\u4e2a\u8868\u4e2d\u7684\u6240\u6709\u6570\u636e, \u5199\u5165csv\u6587\u4ef6\u3002\n    \"\"\"\n    sql = select([table])\n    sql_to_csv(sql, engine, filepath, chunksize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating all the data by its primary_key column.", "response": "def update_all(engine, table, data, upsert=False):\n    \"\"\"\n    Update data by its primary_key column.\n    \"\"\"\n    data = ensure_list(data)\n\n    ins = table.insert()\n    upd = table.update()\n\n    # Find all primary key columns\n    pk_cols = OrderedDict()\n    for column in table._columns:\n        if column.primary_key:\n            pk_cols[column.name] = column\n\n    data_to_insert = list()\n\n    # Multiple primary key column\n    if len(pk_cols) >= 2:\n        for row in data:\n            result = engine.execute(\n                upd.\n                where(\n                    and_(\n                        *[col == row[name] for name, col in pk_cols.items()]\n                    )\n                ).\n                values(**row)\n            )\n            if result.rowcount == 0:\n                data_to_insert.append(row)\n\n    # Single primary key column\n    elif len(pk_cols) == 1:\n        for row in data:\n            result = engine.execute(\n                upd.\n                where(\n                    [col == row[name] for name, col in pk_cols.items()][0]\n                ).\n                values(**row)\n            )\n            if result.rowcount == 0:\n                data_to_insert.append(row)\n\n    else:  # pragma: no cover\n        data_to_insert = data\n\n    # Insert rest of data\n    if upsert:\n        if len(data_to_insert):\n            engine.execute(ins, data_to_insert)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating all entries in the database.", "response": "def upsert_all(engine, table, data):\n    \"\"\"\n    Update data by primary key columns. If not able to update, do insert.\n\n    Example::\n\n        # suppose in database we already have {\"id\": 1, \"name\": \"Alice\"}\n        >>> data = [\n        ...     {\"id\": 1, \"name\": \"Bob\"}, # this will be updated\n        ...     {\"id\": 2, \"name\": \"Cathy\"}, # this will be added\n        ... ]\n        >>> upsert_all(engine, table_user, data)\n        >>> engine.execute(select([table_user])).fetchall()\n        [{\"id\": 1, \"name\": \"Bob\"}, {\"id\": 2, \"name\": \"Cathy\"}]\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u6279\u91cf\u66f4\u65b0\u6587\u6863. \u5982\u679c\u8be5\u8868\u683c\u5b9a\u4e49\u4e86Primary Key, \u5219\u7528Primary Key\u7ea6\u675fwhere\u8bed\u53e5. \u5bf9\u4e8e\n    where\u8bed\u53e5\u65e0\u6cd5\u627e\u5230\u7684\u884c, \u81ea\u52a8\u8fdb\u884c\u6279\u91cfbulk insert.\n    \"\"\"\n    update_all(engine, table, data, upsert=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_session(engine_or_session):\n    if isinstance(engine_or_session, Engine):\n        ses = sessionmaker(bind=engine_or_session)()\n        auto_close = True\n    elif isinstance(engine_or_session, Session):\n        ses = engine_or_session\n        auto_close = False\n    return ses, auto_close", "response": "Ensures that the session is open."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pk_names(cls):\n        if cls._cache_pk_names is None:\n            cls._cache_pk_names = cls._get_primary_key_names()\n        return cls._cache_pk_names", "response": "Return a list of column names that are primary key columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the primary key field of the cache item.", "response": "def id_field_name(cls):\n        \"\"\"\n        If only one primary_key, then return it. Otherwise, raise ValueError.\n        \"\"\"\n        if cls._cache_id_field_name is None:\n            pk_names = cls.pk_names()\n            if len(pk_names) == 1:\n                cls._cache_id_field_name = pk_names[0]\n            else:  # pragma: no cover\n                raise ValueError(\n                    \"{classname} has more than 1 primary key!\"\n                    .format(classname=cls.__name__)\n                )\n        return cls._cache_id_field_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of all values of all declared columns.", "response": "def values(self):\n        \"\"\"\n        return list of value of all declared columns.\n        \"\"\"\n        return [getattr(self, c.name, None) for c in self.__table__._columns]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef items(self):\n        return [\n            (c.name, getattr(self, c.name, None))\n            for c in self.__table__._columns\n        ]", "response": "return list of pair of name and value of all declared columns."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef absorb(self, other):\n        if not isinstance(other, self.__class__):\n            raise TypeError(\"`other` has to be a instance of %s!\" %\n                            self.__class__)\n\n        for attr, value in other.items():\n            if value is not None:\n                setattr(self, attr, deepcopy(value))", "response": "This method absorbs the contents of another object to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revise(self, data):\n        if not isinstance(data, dict):\n            raise TypeError(\"`data` has to be a dict!\")\n\n        for key, value in data.items():\n            if value is not None:\n                setattr(self, key, deepcopy(value))", "response": "Revise attributes value with dictionary data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets one object by primary key value.", "response": "def by_id(cls, _id, engine_or_session):\n        \"\"\"\n        Get one object by primary_key value.\n        \"\"\"\n        ses, auto_close = ensure_session(engine_or_session)\n        obj = ses.query(cls).get(_id)\n        if auto_close:\n            ses.close()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries with sql statement or texture sql.", "response": "def by_sql(cls, sql, engine_or_session):\n        \"\"\"\n        Query with sql statement or texture sql.\n        \"\"\"\n        ses, auto_close = ensure_session(engine_or_session)\n        result = ses.query(cls).from_statement(sql).all()\n        if auto_close:\n            ses.close()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_all(cls, engine, obj_or_data, upsert=False):\n        obj_or_data = ensure_list(obj_or_data)\n        update_all(\n            engine=engine,\n            table=cls.__table__,\n            data=[obj.to_dict(include_null=False) for obj in obj_or_data],\n            upsert=upsert,\n        )", "response": "The sqlalchemy. crud. updating. update_all function in ORM syntax."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upsert_all(cls, engine, obj_or_data):\n        cls.update_all(\n            engine=engine,\n            obj_or_data=obj_or_data,\n            upsert=True,\n        )", "response": "The sqlalchemy. crud. updating. upsert_all function in ORM syntax."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn only those data rows that should be printed based on slicing and sorting.", "response": "def _get_rows(self, options):\n        \"\"\"Return only those data rows that should be printed, based on slicing and sorting.\n\n        Arguments:\n\n        options - dictionary of option settings.\"\"\"\n\n        if options[\"oldsortslice\"]:\n            rows = copy.deepcopy(self._rows[options[\"start\"]:options[\"end\"]])\n        else:\n            rows = copy.deepcopy(self._rows)\n\n        # Sort\n        if options[\"sortby\"]:\n            sortindex = self._field_names.index(options[\"sortby\"])\n            # Decorate\n            rows = [[row[sortindex]] + row for row in rows]\n            # Sort\n            rows.sort(reverse=options[\"reversesort\"], key=options[\"sort_key\"])\n            # Undecorate\n            rows = [row[1:] for row in rows]\n\n        # Slice if necessary\n        if not options[\"oldsortslice\"]:\n            rows = rows[options[\"start\"]:options[\"end\"]]\n\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_string(self, **kwargs):\n\n        options = self._get_options(kwargs)\n\n        lines = []\n\n        # Don't think too hard about an empty table\n        # Is this the desired behaviour?  Maybe we should still print the\n        # header?\n        if self.rowcount == 0 and (not options[\"print_empty\"] or not options[\"border\"]):\n            return \"\"\n\n        # Get the rows we need to print, taking into account slicing, sorting,\n        # etc.\n        rows = self._get_rows(options)\n\n        # Turn all data in all rows into Unicode, formatted as desired\n        formatted_rows = self._format_rows(rows, options)\n\n        # Compute column widths\n        self._compute_widths(formatted_rows, options)\n        self._hrule = self._stringify_hrule(options)\n\n        # Add title\n        title = options[\"title\"] or self._title\n        if title:\n            lines.append(self._stringify_title(title, options))\n\n        # Add header or top of border\n        if options[\"header\"]:\n            lines.append(self._stringify_header(options))\n        elif options[\"border\"] and options[\"hrules\"] in (ALL, FRAME):\n            lines.append(self._hrule)\n\n        # Add rows\n        for row in formatted_rows:\n            lines.append(self._stringify_row(row, options))\n\n        # Add bottom of border\n        if options[\"border\"] and options[\"hrules\"] == FRAME:\n            lines.append(self._hrule)\n\n        return self._unicode(\"\\n\").join(lines)", "response": "Returns a string representation of the current state of the table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_postgresql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_postgresql(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a postgresql database using psycopg2.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an engine connected to a postgresql database using psycopg2", "response": "def create_postgresql_psycopg2(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a postgresql database using psycopg2.\n    \"\"\"\n    return create_engine(\n        _create_postgresql_psycopg2(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an engine connected to a postgresql database using pg8000.", "response": "def create_postgresql_pg8000(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a postgresql database using pg8000.\n    \"\"\"\n    return create_engine(\n        _create_postgresql_pg8000(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_postgresql_pygresql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_postgresql_pygresql(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a postgresql database using pygresql"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_postgresql_psycopg2cffi(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_postgresql_psycopg2cffi(\n            username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a postgresql database using psycopg2cffi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an engine connected to a postgresql database using pypostgresql.", "response": "def create_postgresql_pypostgresql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a postgresql database using pypostgresql.\n    \"\"\"\n    return create_engine(\n        _create_postgresql_pypostgresql(\n            username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an engine connected to a mysql database using mysqldb.", "response": "def create_mysql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a mysql database using mysqldb.\n    \"\"\"\n    return create_engine(\n        _create_mysql(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_mysql_mysqldb(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_mysql_mysqldb(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a mysql database using mysqldb."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_mysql_mysqlconnector(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_mysql_mysqlconnector(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a mysql database using mysqlconnector."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_mysql_oursql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_mysql_oursql(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a mysql database using oursql."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_mysql_pymysql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_mysql_pymysql(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a mysql database using pymysql"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an engine connected to a mysql database using cymysql. cymysql.", "response": "def create_mysql_cymysql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a mysql database using cymysql.\n    \"\"\"\n    return create_engine(\n        _create_mysql_cymysql(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_oracle(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_oracle(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to an oracle database using cx_oracle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_oracle_cx_oracle(username, password, host, port, database, **kwargs):  # pragma: no cover\n    return create_engine(\n        _create_oracle_cx_oracle(username, password, host, port, database),\n        **kwargs\n    )", "response": "create an engine connected to a oracle database using cx_oracle."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an engine connected to a mssql database using pyodbc", "response": "def create_mssql_pyodbc(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a mssql database using pyodbc.\n    \"\"\"\n    return create_engine(\n        _create_mssql_pyodbc(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an engine connected to a mssql database using pymssql.", "response": "def create_mssql_pymssql(username, password, host, port, database, **kwargs):  # pragma: no cover\n    \"\"\"\n    create an engine connected to a mssql database using pymssql.\n    \"\"\"\n    return create_engine(\n        _create_mssql_pymssql(username, password, host, port, database),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef titleize(text):\n    if len(text) == 0: # if empty string, return it\n        return text\n    else:\n        text = text.lower() # lower all char\n        # delete redundant empty space \n        chunks = [chunk[0].upper() + chunk[1:] for chunk in text.split(\" \") if len(chunk) >= 1]\n        return \" \".join(chunks)", "response": "Capitalizes all the words and replaces some characters in the string \n    to create a nicer looking title."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef grouper_list(l, n):\n    chunk = list()\n    counter = 0\n    for item in l:\n        counter += 1\n        chunk.append(item)\n        if counter == n:\n            yield chunk\n            chunk = list()\n            counter = 0\n    if len(chunk) > 0:\n        yield chunk", "response": "Evenly divide list into fixed - length piece no filled value if chunk\n    size smaller than fixed - length."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_query_to_sql_statement(query):\n    context = query._compile_context()\n    context.statement.use_labels = False\n    return context.statement", "response": "Convert a Query object created from orm query into executable sql statement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a query yield result proxy.", "response": "def execute_query_return_result_proxy(query):\n    \"\"\"\n    Execute a query, yield result proxy.\n\n    :param query: :class:`sqlalchemy.orm.Query`,\n        has to be created from ``session.query(Object)``\n\n    :return: :class:`sqlalchemy.engine.result.ResultProxy`\n    \"\"\"\n    context = query._compile_context()\n    context.statement.use_labels = False\n    if query._autoflush and not query._populate_existing:\n        query.session._autoflush()\n\n    conn = query._get_bind_args(\n        context,\n        query._connection_from_session,\n        close_with_result=True)\n\n    return conn.execute(context.statement, query._params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_city(self, city, state=None, best_match=True, min_similarity=70):\n        # find out what is the city that user looking for\n        if state:\n            state_sort = self.find_state(state, best_match=True)[0]\n            city_pool = self.state_to_city_mapper[state_sort.upper()]\n        else:\n            city_pool = self.city_list\n\n        result_city_list = list()\n\n        if best_match:\n            city, confidence = extractOne(city, city_pool)\n            if confidence >= min_similarity:\n                result_city_list.append(city)\n        else:\n            for city, confidence in extract(city, city_pool):\n                if confidence >= min_similarity:\n                    result_city_list.append(city)\n\n        if len(result_city_list) == 0:\n            raise ValueError(\"'%s' is not a valid city name\" % city)\n\n        return result_city_list", "response": "Fuzzy search correct city."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresult ``sort_by`` argument. :param sort_by: str, or sqlalchemy ORM attribute. :param flag_radius_query: :return:", "response": "def _resolve_sort_by(sort_by, flag_radius_query):\n        \"\"\"\n        Result ``sort_by`` argument.\n\n        :param sort_by: str, or sqlalchemy ORM attribute.\n        :param flag_radius_query:\n        :return:\n        \"\"\"\n        if sort_by is None:\n            if flag_radius_query:\n                sort_by = SORT_BY_DIST\n        elif isinstance(sort_by, string_types):\n            if sort_by.lower() == SORT_BY_DIST:\n                if flag_radius_query is False:\n                    msg = \"`sort_by` arg can be 'dist' only under distance based query!\"\n                    raise ValueError(msg)\n                sort_by = SORT_BY_DIST\n            elif sort_by not in SimpleZipcode.__table__.columns:\n                msg = \"`sort_by` arg has to be one of the Zipcode attribute or 'dist'!\"\n                raise ValueError(msg)\n        else:\n            sort_by = sort_by.name\n\n        return sort_by"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self,\n              zipcode=None,\n              prefix=None,\n              pattern=None,\n              city=None,\n              state=None,\n              lat=None,\n              lng=None,\n              radius=None,\n\n              population_lower=None,\n              population_upper=None,\n              population_density_lower=None,\n              population_density_upper=None,\n\n              land_area_in_sqmi_lower=None,\n              land_area_in_sqmi_upper=None,\n              water_area_in_sqmi_lower=None,\n              water_area_in_sqmi_upper=None,\n\n              housing_units_lower=None,\n              housing_units_upper=None,\n              occupied_housing_units_lower=None,\n              occupied_housing_units_upper=None,\n\n              median_home_value_lower=None,\n              median_home_value_upper=None,\n              median_household_income_lower=None,\n              median_household_income_upper=None,\n\n              zipcode_type=ZipcodeType.Standard,\n              sort_by=SimpleZipcode.zipcode.name,\n              ascending=True,\n              returns=DEFAULT_LIMIT):\n        \"\"\"\n        Query zipcode the simple way.\n\n        :param zipcode: int or str, find the exactly matched zipcode. Will be\n            automatically zero padding to 5 digits\n        :param prefix: str, zipcode prefix.\n        :param pattern: str, zipcode wildcard.\n        :param city: str, city name.\n        :param state: str, state name, two letter abbr or state full name.\n        :param lat: latitude.\n        :param lng: longitude.\n        :param radius: number, only returns zipcodes within a specific circle.\n        :param population_lower:\n        :param population_upper:\n        :param population_density_lower:\n        :param population_density_upper:\n        :param land_area_in_sqmi_lower:\n        :param land_area_in_sqmi_upper:\n        :param water_area_in_sqmi_lower:\n        :param water_area_in_sqmi_upper:\n        :param housing_units_lower:\n        :param housing_units_upper:\n        :param occupied_housing_units_lower:\n        :param occupied_housing_units_upper:\n        :param median_home_value_lower:\n        :param median_home_value_upper:\n        :param median_household_income_lower:\n        :param median_household_income_upper:\n        :param zipcode_type: str or :class`~uszipcode.model.ZipcodeType` attribute.\n            if None, allows to return any type of zipcode.\n            if specified, only return specified zipcode type.\n        :param sort_by: str or :class:`~uszipcode.model.Zipcode` attribute,\n            specified which field is used for sorting.\n        :param ascending: bool, True means ascending, False means descending.\n        :param returns: int or None, limit the number of result to returns.\n\n        :return: list of :class:`~uszipcode.model.SimpleZipcode` or\n            :class:`~uszipcode.model.Zipcode`.\n        \"\"\"\n        filters = list()\n\n        # by coordinates\n        _n_radius_param_not_null = sum([\n            isinstance(lat, (integer_types, float)),\n            isinstance(lng, (integer_types, float)),\n            isinstance(radius, (integer_types, float)),\n        ])\n        if _n_radius_param_not_null == 3:\n            flag_radius_query = True\n            if radius <= 0:  # pragma: no cover\n                raise ValueError(\"`radius` parameters can't less than 0!\")\n            elif radius <= 50:  # pragma: no cover\n                radius_coef = 1.05\n            elif radius <= 100:  # pragma: no cover\n                radius_coef = 1.10\n            elif radius <= 250:  # pragma: no cover\n                radius_coef = 1.25\n            elif radius <= 500:  # pragma: no cover\n                radius_coef = 1.5\n            else:  # pragma: no cover\n                radius_coef = 2.0\n\n            if radius >= 250:  # pragma: no cover\n                msg = (\"\\nwarning! search within radius >= 250 miles \"\n                       \"may greatly slow down the query!\")\n                sys.stdout.write(msg)\n\n            # define lat lng boundary\n            dist_btwn_lat_deg = 69.172\n            dist_btwn_lon_deg = math.cos(lat) * 69.172\n            lat_degr_rad = abs(radius * radius_coef / dist_btwn_lat_deg)\n            lon_degr_rad = abs(radius * radius_coef / dist_btwn_lon_deg)\n\n            lat_lower = lat - lat_degr_rad\n            lat_upper = lat + lat_degr_rad\n            lng_lower = lng - lon_degr_rad\n            lng_upper = lng + lon_degr_rad\n\n            filters.append(self.zip_klass.lat >= lat_lower)\n            filters.append(self.zip_klass.lat <= lat_upper)\n            filters.append(self.zip_klass.lng >= lng_lower)\n            filters.append(self.zip_klass.lng <= lng_upper)\n        elif _n_radius_param_not_null == 0:\n            flag_radius_query = False\n        else:\n            msg = \"You can either specify all of `lat`, `lng`, `radius` or none of them\"\n            raise ValueError(msg)\n\n        # by city or state\n        if (state is not None) and (city is not None):\n            try:\n                state = self.find_state(state, best_match=True)[0]\n                city = self.find_city(city, state, best_match=True)[0]\n                filters.append(self.zip_klass.state == state)\n                filters.append(self.zip_klass.major_city == city)\n            except ValueError:  # pragma: no cover\n                return []\n        elif (state is not None):\n            try:\n                state = self.find_state(state, best_match=True)[0]\n                filters.append(self.zip_klass.state == state)\n            except ValueError:  # pragma: no cover\n                return []\n        elif (city is not None):\n            try:\n                city = self.find_city(city, None, best_match=True)[0]\n                filters.append(self.zip_klass.major_city == city)\n            except ValueError:  # pragma: no cover\n                return []\n        else:\n            pass\n\n        # by common filter\n        if sum([zipcode is None, prefix is None, pattern is None]) <= 1:\n            msg = \"You can only specify one of the `zipcode`, `prefix` and `pattern`!\"\n            raise ValueError(msg)\n\n        if zipcode_type is not None:\n            filters.append(self.zip_klass.zipcode_type == zipcode_type)\n\n        if zipcode is not None:\n            filters.append(self.zip_klass.zipcode == str(zipcode))\n        if prefix is not None:\n            filters.append(self.zip_klass.zipcode.startswith(str(prefix)))\n        if pattern is not None:\n            filters.append(self.zip_klass.zipcode.like(\n                \"%%%s%%\" % str(pattern)))\n\n        if population_lower is not None:\n            filters.append(self.zip_klass.population >= population_lower)\n        if population_upper is not None:\n            filters.append(self.zip_klass.population <= population_upper)\n\n        if population_density_lower is not None:\n            filters.append(self.zip_klass.population_density >=\n                           population_density_lower)\n        if population_density_upper is not None:\n            filters.append(self.zip_klass.population_density <=\n                           population_density_upper)\n\n        if land_area_in_sqmi_lower is not None:\n            filters.append(self.zip_klass.land_area_in_sqmi >=\n                           land_area_in_sqmi_lower)\n        if land_area_in_sqmi_upper is not None:\n            filters.append(self.zip_klass.land_area_in_sqmi <=\n                           land_area_in_sqmi_upper)\n\n        if water_area_in_sqmi_lower is not None:\n            filters.append(self.zip_klass.water_area_in_sqmi >=\n                           water_area_in_sqmi_lower)\n        if water_area_in_sqmi_upper is not None:\n            filters.append(self.zip_klass.water_area_in_sqmi <=\n                           water_area_in_sqmi_upper)\n\n        if housing_units_lower is not None:\n            filters.append(self.zip_klass.housing_units >= housing_units_lower)\n        if housing_units_upper is not None:\n            filters.append(self.zip_klass.housing_units <= housing_units_upper)\n\n        if occupied_housing_units_lower is not None:\n            filters.append(self.zip_klass.occupied_housing_units >=\n                           occupied_housing_units_lower)\n        if occupied_housing_units_upper is not None:\n            filters.append(self.zip_klass.occupied_housing_units <=\n                           occupied_housing_units_upper)\n\n        if median_home_value_lower is not None:\n            filters.append(self.zip_klass.median_home_value >=\n                           median_home_value_lower)\n        if median_home_value_upper is not None:\n            filters.append(self.zip_klass.median_home_value <=\n                           median_home_value_upper)\n\n        if median_household_income_lower is not None:\n            filters.append(self.zip_klass.median_household_income >=\n                           median_household_income_lower)\n        if median_household_income_upper is not None:\n            filters.append(self.zip_klass.median_household_income <=\n                           median_household_income_upper)\n\n        # --- solve coordinates and other search sort_by conflict ---\n        sort_by = self._resolve_sort_by(sort_by, flag_radius_query)\n\n        q = self.ses.query(self.zip_klass).filter(*filters)\n\n        if sort_by is None:\n            pass\n        elif sort_by == SORT_BY_DIST:\n            pass\n        else:\n            field = getattr(self.zip_klass, sort_by)\n            if ascending:\n                by = field.asc()\n            else:\n                by = field.desc()\n            q = q.order_by(by)\n\n        if flag_radius_query:\n            # if we query by radius, then ignore returns limit before the\n            # distance calculation, and then manually limit the returns\n            pairs = list()\n            for z in q:\n                dist = z.dist_from(lat, lng)\n                if dist <= radius:\n                    pairs.append((dist, z))\n\n            if sort_by == SORT_BY_DIST:\n                if ascending:\n                    if returns:\n                        pairs_new = heapq.nsmallest(\n                            returns, pairs, key=lambda x: x[0])\n                    else:\n                        pairs_new = list(sorted(pairs, key=lambda x: x[0]))\n                else:\n                    if returns:\n                        pairs_new = heapq.nlargest(\n                            returns, pairs, key=lambda x: x[0])\n                    else:\n                        pairs_new = list(\n                            sorted(pairs, key=lambda x: x[0], reverse=True))\n                return [z for _, z in pairs_new]\n            else:\n                return [z for _, z in pairs[:returns]]\n        else:\n            if returns:\n                return q.limit(returns).all()\n            else:\n                return q.all()", "response": "Query the simple way of the zipcode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef by_zipcode(self,\n                   zipcode,\n                   zipcode_type=None,\n                   zero_padding=True):\n        \"\"\"\n        Search zipcode by exact 5 digits zipcode. No zero padding is needed.\n\n        :param zipcode: int or str, the zipcode will be automatically\n            zero padding to 5 digits.\n        :param zipcode_type: str or :class`~uszipcode.model.ZipcodeType` attribute.\n            by default, it returns any zipcode type.\n        :param zero_padding: bool, toggle on and off automatic zero padding.\n        \"\"\"\n        if zero_padding:\n            zipcode = str(zipcode).zfill(5)\n        else:  # pragma: no cover\n            zipcode = str(zipcode)\n\n        res = self.query(\n            zipcode=zipcode,\n            sort_by=None,\n            returns=1,\n            zipcode_type=zipcode_type,\n        )\n        if len(res):\n            return res[0]\n        else:\n            return self.zip_klass()", "response": "Search the entry by the given zipcode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches zipcode information by prefix.", "response": "def by_prefix(self,\n                  prefix,\n                  zipcode_type=ZipcodeType.Standard,\n                  sort_by=SimpleZipcode.zipcode.name,\n                  ascending=True,\n                  returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by first N digits.\n\n        Returns multiple results.\n        \"\"\"\n        return self.query(\n            prefix=prefix,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef by_pattern(self,\n                   pattern,\n                   zipcode_type=ZipcodeType.Standard,\n                   sort_by=SimpleZipcode.zipcode.name,\n                   ascending=True,\n                   returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode by wildcard.\n\n        Returns multiple results.\n        \"\"\"\n        return self.query(\n            pattern=pattern,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )", "response": "Search zipcode by pattern."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch zipcode information by state.", "response": "def by_state(self,\n                 state,\n                 zipcode_type=ZipcodeType.Standard,\n                 sort_by=SimpleZipcode.zipcode.name,\n                 ascending=True,\n                 returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by fuzzy State name.\n\n        My engine use fuzzy match and guess what is the state you want.\n        \"\"\"\n        return self.query(\n            state=state,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches zipcode information near a coordinates on a map.", "response": "def by_coordinates(self,\n                       lat,\n                       lng,\n                       radius=25.0,\n                       zipcode_type=ZipcodeType.Standard,\n                       sort_by=SORT_BY_DIST,\n                       ascending=True,\n                       returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information near a coordinates on a map.\n\n        Returns multiple results.\n\n        :param lat: center latitude.\n        :param lng: center longitude.\n        :param radius: only returns zipcode within X miles from ``lat``, ``lng``.\n\n        **\u4e2d\u6587\u6587\u6863**\n\n        1. \u8ba1\u7b97\u51fa\u5728\u4e2d\u5fc3\u5750\u6807\u5904, \u6bcf\u4e00\u7ecf\u5ea6\u548c\u7eac\u5ea6\u5206\u522b\u4ee3\u8868\u591a\u5c11miles.\n        2. \u4ee5\u7ed9\u5b9a\u5750\u6807\u4e3a\u4e2d\u5fc3, \u753b\u51fa\u4e00\u4e2a\u77e9\u5f62, \u957f\u5bbd\u5206\u522b\u4e3a\u534a\u5f84\u76842\u500d\u591a\u4e00\u70b9, \u627e\u5230\u8be5\n          \u77e9\u5f62\u5185\u6240\u6709\u7684Zipcode.\n        3. \u5bf9\u8fd9\u4e9bZipcode\u8ba1\u7b97\u51fa\u4ed6\u4eec\u7684\u8ddd\u79bb, \u7136\u540e\u6309\u7167\u8ddd\u79bb\u8fdc\u8fd1\u6392\u5e8f\u3002\u8ddd\u79bb\u8d85\u8fc7\u6211\u4eec\n          \u9650\u5b9a\u7684\u534a\u5f84\u7684\u76f4\u63a5\u4e22\u5f03.\n        \"\"\"\n        return self.query(\n            lat=lat, lng=lng, radius=radius,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef by_population(self,\n                      lower=-1,\n                      upper=2 ** 31,\n                      zipcode_type=ZipcodeType.Standard,\n                      sort_by=SimpleZipcode.population.name,\n                      ascending=False,\n                      returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by population range.\n        \"\"\"\n        return self.query(\n            population_lower=lower,\n            population_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )", "response": "Search zipcode information by population range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch zipcode information by population density range.", "response": "def by_population_density(self,\n                              lower=-1,\n                              upper=2 ** 31,\n                              zipcode_type=ZipcodeType.Standard,\n                              sort_by=SimpleZipcode.population_density.name,\n                              ascending=False,\n                              returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by population density range.\n\n        `population density` is `population per square miles on land`\n        \"\"\"\n        return self.query(\n            population_density_lower=lower,\n            population_density_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch zipcode information by land area in sqmi range.", "response": "def by_land_area_in_sqmi(self,\n                             lower=-1,\n                             upper=2 ** 31,\n                             zipcode_type=ZipcodeType.Standard,\n                             sort_by=SimpleZipcode.land_area_in_sqmi.name,\n                             ascending=False,\n                             returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by land area / sq miles range.\n        \"\"\"\n        return self.query(\n            land_area_in_sqmi_lower=lower,\n            land_area_in_sqmi_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch zipcode information by water area in sqmi range.", "response": "def by_water_area_in_sqmi(self,\n                              lower=-1,\n                              upper=2 ** 31,\n                              zipcode_type=ZipcodeType.Standard,\n                              sort_by=SimpleZipcode.water_area_in_sqmi.name,\n                              ascending=False,\n                              returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by water area / sq miles range.\n        \"\"\"\n        return self.query(\n            water_area_in_sqmi_lower=lower,\n            water_area_in_sqmi_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching zipcode information by house of units.", "response": "def by_housing_units(self,\n                         lower=-1,\n                         upper=2 ** 31,\n                         zipcode_type=ZipcodeType.Standard,\n                         sort_by=SimpleZipcode.housing_units.name,\n                         ascending=False,\n                         returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by house of units.\n        \"\"\"\n        return self.query(\n            housing_units_lower=lower,\n            housing_units_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching zipcode information by occupied house of units.", "response": "def by_occupied_housing_units(self,\n                                  lower=-1,\n                                  upper=2 ** 31,\n                                  zipcode_type=ZipcodeType.Standard,\n                                  sort_by=SimpleZipcode.occupied_housing_units.name,\n                                  ascending=False,\n                                  returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by occupied house of units.\n        \"\"\"\n        return self.query(\n            occupied_housing_units_lower=lower,\n            occupied_housing_units_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches zipcode information by median home value.", "response": "def by_median_home_value(self,\n                             lower=-1,\n                             upper=2 ** 31,\n                             zipcode_type=ZipcodeType.Standard,\n                             sort_by=SimpleZipcode.median_home_value.name,\n                             ascending=False,\n                             returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by median home value.\n        \"\"\"\n        return self.query(\n            median_home_value_lower=lower,\n            median_home_value_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching zipcode information by median household income.", "response": "def by_median_household_income(self,\n                                   lower=-1,\n                                   upper=2 ** 31,\n                                   zipcode_type=ZipcodeType.Standard,\n                                   sort_by=SimpleZipcode.median_household_income.name,\n                                   ascending=False,\n                                   returns=DEFAULT_LIMIT):\n        \"\"\"\n        Search zipcode information by median household income.\n        \"\"\"\n        return self.query(\n            median_household_income_lower=lower,\n            median_household_income_upper=upper,\n            sort_by=sort_by, zipcode_type=zipcode_type,\n            ascending=ascending, returns=returns,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting data from single column.", "response": "def select_single_column(engine, column):\n    \"\"\"\n    Select data from single column.\n\n    Example::\n\n        >>> select_single_column(engine, table_user.c.id)\n        [1, 2, 3]\n\n        >>> select_single_column(engine, table_user.c.name)\n        [\"Alice\", \"Bob\", \"Cathy\"]\n    \"\"\"\n    s = select([column])\n    return column.name, [row[0] for row in engine.execute(s)]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_many_column(engine, *columns):\n    if isinstance(columns[0], Column):\n        pass\n    elif isinstance(columns[0], (list, tuple)):\n        columns = columns[0]\n    s = select(columns)\n    headers = [str(column) for column in columns]\n    data = [tuple(row) for row in engine.execute(s)]\n    return headers, data", "response": "Select data from multiple columns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_distinct_column(engine, *columns):\n    if isinstance(columns[0], Column):\n        pass\n    elif isinstance(columns[0], (list, tuple)):  # pragma: no cover\n        columns = columns[0]\n    s = select(columns).distinct()\n    if len(columns) == 1:\n        return [row[0] for row in engine.execute(s)]\n    else:\n        return [tuple(row) for row in engine.execute(s)]", "response": "Select distinct column(columns).\n\n    :returns: if single column, return list, if multiple column, return matrix.\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    distinct\u8bed\u53e5\u7684\u8bed\u6cd5\u7cd6\u51fd\u6570\u3002"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_random(engine, table_or_columns, limit=5):\n    s = select(table_or_columns).order_by(func.random()).limit(limit)\n    return engine.execute(s).fetchall()", "response": "Randomly select some rows from table.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef smart_insert(engine, table, data, minimal_size=5):\n    insert = table.insert()\n\n    if isinstance(data, list):\n        # \u9996\u5148\u8fdb\u884c\u5c1d\u8bd5bulk insert\n        try:\n            engine.execute(insert, data)\n        # \u5931\u8d25\u4e86\n        except IntegrityError:\n            # \u5206\u6790\u6570\u636e\u91cf\n            n = len(data)\n            # \u5982\u679c\u6570\u636e\u6761\u6570\u591a\u4e8e\u4e00\u5b9a\u6570\u91cf\n            if n >= minimal_size ** 2:\n                # \u5219\u8fdb\u884c\u5206\u5305\n                n_chunk = math.floor(math.sqrt(n))\n                for chunk in grouper_list(data, n_chunk):\n                    smart_insert(engine, table, chunk, minimal_size)\n            # \u5426\u5219\u5219\u4e00\u6761\u6761\u5730\u9010\u6761\u63d2\u5165\n            else:\n                for row in data:\n                    try:\n                        engine.execute(insert, row)\n                    except IntegrityError:\n                        pass\n    else:\n        try:\n            engine.execute(insert, data)\n        except IntegrityError:\n            pass", "response": "A smart insert strategy."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file_extension_type(filename):\n    ext = get_file_extension(filename)\n    if ext:\n        for name, group in EXTENSIONS.items():\n            if ext in group:\n                return name\n    return \"OTHER\"", "response": "Returns the type of the file extension associated to the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_driver_class(provider):\n    if \".\" in provider:\n        parts = provider.split('.')\n        kls = parts.pop()\n        path = '.'.join(parts)\n        module = import_module(path)\n        if not hasattr(module, kls):\n            raise ImportError('{0} provider not found at {1}'.format(\n                kls,\n                path))\n        driver = getattr(module, kls)\n    else:\n        driver = getattr(Provider, provider.upper())\n    return get_driver(driver)", "response": "Returns the driver class for the given provider name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the provider name from the driver class", "response": "def get_provider_name(driver):\n    \"\"\"\n    Return the provider name from the driver class\n    :param driver: obj\n    :return: str\n    \"\"\"\n    kls = driver.__class__.__name__\n    for d, prop in DRIVERS.items():\n        if prop[1] == kls:\n            return d\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_app(self, app):\n        provider = app.config.get(\"STORAGE_PROVIDER\", None)\n        key = app.config.get(\"STORAGE_KEY\", None)\n        secret = app.config.get(\"STORAGE_SECRET\", None)\n        container = app.config.get(\"STORAGE_CONTAINER\", None)\n        allowed_extensions = app.config.get(\"STORAGE_ALLOWED_EXTENSIONS\", None)\n        serve_files = app.config.get(\"STORAGE_SERVER\", True)\n        serve_files_url = app.config.get(\"STORAGE_SERVER_URL\", \"files\")\n\n        self.config[\"serve_files\"] = serve_files\n        self.config[\"serve_files_url\"] = serve_files_url\n\n        if not provider:\n            raise ValueError(\"'STORAGE_PROVIDER' is missing\")\n\n        if provider.upper() == \"LOCAL\":\n            if not os.path.isdir(container):\n                raise IOError(\"Local Container (directory) '%s' is not a \"\n                              \"directory or doesn't exist for LOCAL provider\" % container)\n\n        self.__init__(provider=provider,\n                      key=key,\n                      secret=secret,\n                      container=container,\n                      allowed_extensions=allowed_extensions)\n\n        self._register_file_server(app)", "response": "Initialize with Flask application object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an object or None if it doesn t exist.", "response": "def get(self, object_name):\n        \"\"\"\n        Return an object or None if it doesn't exist\n        :param object_name:\n        :return: Object\n        \"\"\"\n        if object_name in self:\n            return Object(obj=self.container.get_object(object_name))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new object in the cache", "response": "def create(self, object_name, size=0, hash=None, extra=None, meta_data=None):\n        \"\"\"\n        create a new object\n        :param object_name:\n        :param size:\n        :param hash:\n        :param extra:\n        :param meta_data:\n        :return: Object\n        \"\"\"\n        obj = BaseObject(container=self.container,\n                         driver=self.driver,\n                         name=object_name,\n                         size=size,\n                         hash=hash,\n                         extra=extra,\n                         meta_data=meta_data)\n        return Object(obj=obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading an object to the tree.", "response": "def upload(self,\n               file,\n               name=None,\n               prefix=None,\n               extensions=None,\n               overwrite=False,\n               public=False,\n               random_name=False,\n               **kwargs):\n        \"\"\"\n        To upload file\n        :param file: FileStorage object or string location\n        :param name: The name of the object.\n        :param prefix: A prefix for the object. Can be in the form of directory tree\n        :param extensions: list of extensions to allow. If empty, it will use all extension.\n        :param overwrite: bool - To overwrite if file exists\n        :param public: bool - To set acl to private or public-read. Having acl in kwargs will override it\n        :param random_name - If True and Name is None it will create a random name.\n                Otherwise it will use the file name. `name` will always take precedence\n        :param kwargs: extra params: ie: acl, meta_data etc.\n        :return: Object\n        \"\"\"\n        tmp_file = None\n        try:\n            if \"acl\" not in kwargs:\n                kwargs[\"acl\"] = \"public-read\" if public else \"private\"\n            extra = kwargs\n\n            # It seems like this is a url, we'll try to download it first\n            if isinstance(file, string_types) and re.match(URL_REGEXP, file):\n                tmp_file = self._download_from_url(file)\n                file = tmp_file\n\n            # Create a random name\n            if not name and random_name:\n                name = uuid.uuid4().hex\n\n            # coming from a flask, or upload object\n            if isinstance(file, FileStorage):\n                extension = get_file_extension(file.filename)\n                if not name:\n                    fname = get_file_name(file.filename).split(\".\" + extension)[0]\n                    name = slugify.slugify(fname)\n            else:\n                extension = get_file_extension(file)\n                if not name:\n                    name = get_file_name(file)\n\n            if len(get_file_extension(name).strip()) == 0:\n                name += \".\" + extension\n\n            name = name.strip(\"/\").strip()\n\n            if isinstance(self.driver, local.LocalStorageDriver):\n                name = secure_filename(name)\n\n            if prefix:\n                name = prefix.lstrip(\"/\") + name\n\n            if not overwrite:\n                name = self._safe_object_name(name)\n\n            # For backwards compatibility, kwargs now holds `allowed_extensions`\n            allowed_extensions = extensions or kwargs.get(\"allowed_extensions\")\n            if not allowed_extensions:\n                allowed_extensions = self.allowed_extensions\n            if extension.lower() not in allowed_extensions:\n                raise InvalidExtensionError(\"Invalid file extension: '.%s' \" % extension)\n\n            if isinstance(file, FileStorage):\n                obj = self.container.upload_object_via_stream(iterator=file.stream,\n                                                              object_name=name,\n                                                              extra=extra)\n            else:\n                obj = self.container.upload_object(file_path=file,\n                                                   object_name=name,\n                                                   extra=extra)\n            return Object(obj=obj)\n        except Exception as e:\n            raise e\n        finally:\n            if tmp_file and os.path.isfile(tmp_file):\n                os.remove(tmp_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _download_from_url(self, url):\n        ext = get_file_extension(url)\n        if \"?\" in url:\n            ext = get_file_extension(os.path.splitext(url.split(\"?\")[0]))\n        filepath = \"/tmp/%s.%s\" % (uuid.uuid4().hex, ext)\n        request.urlretrieve(url, filepath)\n        return filepath", "response": "Download a url and return the tmp path\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a UUID if it exists. To prevent overwrites .", "response": "def _safe_object_name(self, object_name):\n        \"\"\" Add a UUID if to a object name if it exists. To prevent overwrites\n        :param object_name:\n        :return str:\n        \"\"\"\n        extension = get_file_extension(object_name)\n        file_name = os.path.splitext(object_name)[0]\n        while object_name in self:\n            nuid = uuid.uuid4().hex\n            object_name = \"%s__%s.%s\" % (file_name, nuid, extension)\n        return object_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _register_file_server(self, app):\n        if isinstance(self.driver, local.LocalStorageDriver) \\\n                and self.config[\"serve_files\"]:\n            server_url = self.config[\"serve_files_url\"].strip(\"/\").strip()\n            if server_url:\n                url = \"/%s/<path:object_name>\" % server_url\n\n                @app.route(url, endpoint=SERVER_ENDPOINT)\n                def files_server(object_name):\n                    obj = self.get(object_name)\n                    if obj is not None:\n                        dl = flask_request.args.get(\"dl\")\n                        name = flask_request.args.get(\"name\", obj.name)\n\n                        if get_file_extension(name) != obj.extension:\n                            name += \".%s\" % obj.extension\n\n                        _url = obj.get_cdn_url()\n                        return send_file(_url,\n                                         as_attachment=True if dl else False,\n                                         attachment_filename=name,\n                                         conditional=True)\n                    else:\n                        abort(404)\n            else:\n                warnings.warn(\"Flask-Cloudy can't serve files. 'STORAGE_SERVER_FILES_URL' is not set\")", "response": "Register a file server for the local storage driver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(self):\n        return {\n            \"name\": self.name,\n            \"size\": self.size,\n            \"extension\": self.extension,\n            \"url\": self.url,\n            \"full_url\": self.full_url,\n            \"type\": self.type,\n            \"path\": self.path,\n            \"provider_name\": self.provider_name\n        }", "response": "Return all the info of this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url(self, secure=False, longurl=False):\n        driver_name = self.driver.name.lower()\n        try:\n            # Currently only Cloudfiles and Local supports it\n            url = self._obj.get_cdn_url()\n            if \"local\" in driver_name:\n                url = url_for(SERVER_ENDPOINT,\n                              object_name=self.name,\n                              _external=longurl)\n        except NotImplementedError as e:\n            object_path = '%s/%s' % (self.container.name, self.name)\n            if 's3' in driver_name:\n                base_url = 'http://%s' % self.driver.connection.host\n                url = urljoin(base_url, object_path)\n            elif 'google' in driver_name:\n                url = urljoin('http://storage.googleapis.com', object_path)\n            elif 'azure' in driver_name:\n                base_url = ('http://%s.blob.core.windows.net' % self.driver.key)\n                url = urljoin(base_url, object_path)\n            else:\n                raise e\n\n        if secure:\n            if 'cloudfiles' in driver_name:\n                parsed_url = urlparse(url)\n                if parsed_url.scheme != 'http':\n                    return url\n                split_netloc = parsed_url.netloc.split('.')\n                split_netloc[1] = 'ssl'\n                url = urlunparse(\n                    'https',\n                    '.'.join(split_netloc),\n                    parsed_url.path,\n                    parsed_url.params, parsed_url.query,\n                    parsed_url.fragment\n                )\n            if ('s3' in driver_name or\n                    'google' in driver_name or\n                    'azure' in driver_name):\n                url = url.replace('http://', 'https://')\n        return url", "response": "Return the url for the object in the current container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the full path of the local object", "response": "def full_path(self):\n        \"\"\"\n        Return the full path of the local object\n        If not local, it will return self.path\n        :return: str\n        \"\"\"\n        if \"local\" in self.driver.name.lower():\n            return \"%s/%s\" % self.container.key, self.path\n        return self.path"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_to(self, destination, name=None, overwrite=False, delete_on_failure=True):\n        if not os.path.isdir(destination):\n            raise IOError(\"'%s' is not a valid directory\")\n\n        obj_path = \"%s/%s\" % (destination, self._obj.name)\n        if name:\n            obj_path = \"%s/%s.%s\" % (destination, name, self.extension)\n\n        file = self._obj.download(obj_path,\n                                  overwrite_existing=overwrite,\n                                  delete_on_failure=delete_on_failure)\n        return obj_path if file else None", "response": "Saves the object to a local path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads the file from the remote server.", "response": "def download_url(self, timeout=60, name=None):\n        \"\"\"\n        Trigger a browse download\n        :param timeout: int - Time in seconds to expire the download\n        :param name: str - for LOCAL only, to rename the file being downloaded\n        :return: str\n        \"\"\"\n        if \"local\" in self.driver.name.lower():\n            return url_for(SERVER_ENDPOINT,\n                           object_name=self.name,\n                           dl=1,\n                           name=name,\n                           _external=True)\n        else:\n            driver_name = self.driver.name.lower()\n            expires = (datetime.datetime.now()\n                       + datetime.timedelta(seconds=timeout)).strftime(\"%s\")\n\n            if 's3' in driver_name or 'google' in driver_name:\n\n                s2s = \"GET\\n\\n\\n{expires}\\n/{object_name}\"\\\n                    .format(expires=expires, object_name=self.path)\n                h = hmac.new(self.driver.secret.encode('utf-8'), s2s.encode('utf-8'), hashlib.sha1)\n                s = base64.encodestring(h.digest()).strip()\n                _keyIdName = \"AWSAccessKeyId\" if \"s3\" in driver_name else \"GoogleAccessId\"\n                params = {\n                    _keyIdName: self.driver.key,\n                    \"Expires\": expires,\n                    \"Signature\": s\n                }\n                urlkv = urlencode(params)\n                return \"%s?%s\" % (self.secure_url, urlkv)\n\n            elif 'cloudfiles' in driver_name:\n                return self.driver.ex_get_object_temp_url(self._obj,\n                                                               method=\"GET\",\n                                                               timeout=expires)\n            else:\n                raise NotImplemented(\"This provider '%s' doesn't support or \"\n                                     \"doesn't have a signed url \"\n                                     \"implemented yet\" % self.provider_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_keys():\n    consumer_key = os.environ.get('CONSUMER_KEY')\n    consumer_secret = os.environ.get('CONSUMER_SECRET')\n    access_token = os.environ.get('ACCESS_TOKEN')\n    access_token_secret = os.environ.get('ACCESS_TOKEN_SECRET')\n\n    return consumer_key, consumer_secret, access_token, access_token_secret", "response": "Loads Twitter keys.\n\n    Returns:\n        tuple: consumer_key, consumer_secret, access_token, access_token_secret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch tweets by keyword. is a wrapper around the _api. search method.", "response": "def search(self, q):\n        \"\"\"Search tweets by keyword.\n\n        Args:\n            q: keyword\n\n        Returns:\n            list: tweet list\n        \"\"\"\n        results = self._api.search(q=q)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_by_user(self, screen_name, count=100):\n        results = self._api.user_timeline(screen_name=screen_name, count=count)\n\n        return results", "response": "Search tweets by user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreacts to the successful login attempt by first forgetting any previously stored identity and then saving the new identity.", "response": "def on_successful_login(self, subject, authc_token, account_id):\n        \"\"\"\n        Reacts to the successful login attempt by first always\n        forgetting any previously stored identity.  Then if the authc_token\n        is a ``RememberMe`` type of token, the associated identity\n        will be remembered for later retrieval during a new user session.\n\n        :param subject: the subject whose identifying attributes are being\n                        remembered\n        :param authc_token:  the token that resulted in a successful\n                             authentication attempt\n        :param account_id: id of authenticated account\n        \"\"\"\n        # always clear any previous identity:\n        self.forget_identity(subject)\n\n        # now save the new identity:\n        if authc_token.is_remember_me:\n            self.remember_identity(subject, authc_token, account_id)\n        else:\n            msg = (\"AuthenticationToken did not indicate that RememberMe is \"\n                   \"requested.  RememberMe functionality will not be executed \"\n                   \"for corresponding account.\")\n            logger.debug(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remember_identity(self, subject, authc_token, account_id):\n        try:\n            identifiers = self.get_identity_to_remember(subject, account_id)\n        except AttributeError:\n            msg = \"Neither account_id nor identifier arguments passed\"\n            raise AttributeError(msg)\n        encrypted = self.convert_identifiers_to_bytes(identifiers)\n        self.remember_encrypted_identity(subject, encrypted)", "response": "This method will remember the subject - unique identity for the given subject."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_bytes_to_identifiers(self, encrypted, subject_context):\n\n        # unlike Shiro, Yosai assumes that the message is encrypted:\n        decrypted = self.decrypt(encrypted)\n\n        return self.serialization_manager.deserialize(decrypted)", "response": "This method decrypts and deserialize the bytes to identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_remembered_identifiers_failure(self, exc, subject_context):\n        msg = (\"There was a failure while trying to retrieve remembered \"\n               \"identifier.  This could be due to a configuration problem or \"\n               \"corrupted identifier.  This could also be due to a recently \"\n               \"changed encryption key.  The remembered identity will be \"\n               \"forgotten and not used for this request. \", exc)\n        logger.debug(msg)\n\n        self.forget_identity(subject_context)\n\n        # propagate - security manager implementation will handle and warn\n        # appropriately:\n        raise exc", "response": "Called when an exception is thrown while trying to retrieve identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencrypting the serialized message using Fernet", "response": "def encrypt(self, serialized):\n        \"\"\"\n        Encrypts the serialized message using Fernet\n\n        :param serialized: the serialized object to encrypt\n        :type serialized: bytes\n        :returns: an encrypted bytes returned by Fernet\n        \"\"\"\n\n        fernet = Fernet(self.encryption_cipher_key)\n        return fernet.encrypt(serialized)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_realms(self):\n        self.authenticator.init_realms(self.realms)\n        self.authorizer.init_realms(self.realms)", "response": "Applies the realms to the authentication and authorizer objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn true if the authorizer is permitted to collect the resource for the given set of identifiers and permission_s.", "response": "def is_permitted_collective(self, identifiers, permission_s, logical_operator):\n        \"\"\"\n        :type identifiers: SimpleIdentifierCollection\n\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of Permission object(s) or String(s)\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :returns: a Boolean\n        \"\"\"\n        return self.authorizer.is_permitted_collective(identifiers,\n                                                       permission_s,\n                                                       logical_operator)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the permission is granted for the given set of identifiers.", "response": "def check_permission(self, identifiers, permission_s, logical_operator):\n        \"\"\"\n        :type identifiers: SimpleIdentifierCollection\n\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of Permission objects or Strings\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :returns: a List of Booleans corresponding to the permission elements\n        \"\"\"\n        return self.authorizer.check_permission(identifiers,\n                                                permission_s,\n                                                logical_operator)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the authorizer has the role collective for the given set of roles", "response": "def has_role_collective(self, identifiers, role_s, logical_operator):\n        \"\"\"\n        :type identifiers: SimpleIdentifierCollection\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :param role_s: 1..N role identifier\n        :type role_s:  a Set of Strings\n\n        :returns: a Boolean\n        \"\"\"\n        return self.authorizer.has_role_collective(identifiers,\n                                                   role_s, logical_operator)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a subject has a given role.", "response": "def check_role(self, identifiers, role_s, logical_operator):\n        \"\"\"\n        :type identifiers: SimpleIdentifierCollection\n\n        :param role_s: 1..N role identifier\n        :type role_s:  a Set of Strings\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :raises UnauthorizedException: if Subject not assigned to all roles\n        \"\"\"\n        return self.authorizer.check_role(identifiers,\n                                          role_s, logical_operator)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Subject instance for the user represented by the given authc_token account_id and existing_subject.", "response": "def create_subject(self,\n                       authc_token=None,\n                       account_id=None,\n                       existing_subject=None,\n                       subject_context=None):\n        \"\"\"\n        Creates a ``Subject`` instance for the user represented by the given method\n        arguments.\n\n        It is an overloaded method, due to porting java to python, and is\n        consequently highly likely to be refactored.\n\n        It gets called in one of two ways:\n        1) when creating an anonymous subject, passing create_subject\n           a subject_context argument\n\n        2) following a after successful login, passing all but the context argument\n\n        This implementation functions as follows:\n\n        - Ensures that the ``SubjectContext`` exists and is as populated as it can be,\n          using heuristics to acquire data that may not have already been available\n          to it (such as a referenced session or remembered identifiers).\n        - Calls subject_context.do_create_subject to perform the Subject\n          instance creation\n        - Calls subject.save to ensure the constructed Subject's state is\n          accessible for future requests/invocations if necessary\n        - Returns the constructed Subject instance\n\n        :type authc_token:  subject_abcs.AuthenticationToken\n\n        :param account_id:  the identifiers of a newly authenticated user\n        :type account:  SimpleIdentifierCollection\n\n        :param existing_subject: the existing Subject instance that initiated the\n                                 authentication attempt\n        :type subject:  subject_abcs.Subject\n\n        :type subject_context:  subject_abcs.SubjectContext\n\n        :returns:  the Subject instance that represents the context and session\n                   data for the newly authenticated subject\n        \"\"\"\n        if subject_context is None:  # this that means a successful login just happened\n            # passing existing_subject is new to yosai:\n            context = self.create_subject_context(existing_subject)\n\n            context.authenticated = True\n            context.authentication_token = authc_token\n            context.account_id = account_id\n\n            if (existing_subject):\n                context.subject = existing_subject\n\n        else:\n            context = copy.copy(subject_context)  # if this necessary? TBD.\n\n        context = self.ensure_security_manager(context)\n        context = self.resolve_session(context)\n        context = self.resolve_identifiers(context)\n\n        subject = self.do_create_subject(context)  # DelegatingSubject\n\n        # save this subject for future reference if necessary:\n        # (this is needed here in case remember_me identifiers were resolved\n        # and they need to be stored in the session, so we don't constantly\n        # re-hydrate the remember_me identifier_collection on every operation).\n        self.save(subject)\n        return subject"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a user into the Subject.", "response": "def login(self, subject, authc_token):\n        \"\"\"\n        Login authenticates a user using an AuthenticationToken.  If authentication is\n        successful AND the Authenticator has determined that authentication is\n        complete for the account, login constructs a Subject instance representing\n        the authenticated account's identity. Once a subject instance is constructed,\n        it is bound to the application for subsequent access before being returned\n        to the caller.\n\n        If login successfully authenticates a token but the Authenticator has\n        determined that subject's account isn't considered authenticated,\n        the account is configured for multi-factor authentication.\n\n        Sessionless environments must pass all authentication tokens to login\n        at once.\n\n        :param authc_token: the authenticationToken to process for the login attempt\n        :type authc_token:  authc_abcs.authenticationToken\n\n        :returns: a Subject representing the authenticated user\n        :raises AuthenticationException:  if there is a problem authenticating\n                                          the specified authc_token\n        :raises AdditionalAuthenticationRequired: during multi-factor authentication\n                                                  when additional tokens are required\n        \"\"\"\n        try:\n            # account_id is a SimpleIdentifierCollection\n            account_id = self.authenticator.authenticate_account(subject.identifiers,\n                                                                 authc_token)\n        # implies multi-factor authc not complete:\n        except AdditionalAuthenticationRequired as exc:\n            # identity needs to be accessible for subsequent authentication:\n            self.update_subject_identity(exc.account_id, subject)\n            # no need to propagate account further:\n            raise AdditionalAuthenticationRequired\n\n        except AuthenticationException as authc_ex:\n            try:\n                self.on_failed_login(authc_token, authc_ex, subject)\n            except Exception:\n                msg = (\"on_failed_login method raised an exception.  Logging \"\n                       \"and propagating original AuthenticationException.\")\n                logger.info(msg, exc_info=True)\n            raise\n\n        logged_in = self.create_subject(authc_token=authc_token,\n                                        account_id=account_id,\n                                        existing_subject=subject)\n        self.on_successful_login(authc_token, account_id, logged_in)\n        return logged_in"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that the SubjectContext has a security manager.", "response": "def ensure_security_manager(self, subject_context):\n        \"\"\"\n        Determines whether there is a ``SecurityManager`` instance in the context,\n        and if not, adds 'self' to the context.  This ensures that do_create_subject\n        will have access to a ``SecurityManager`` during Subject construction.\n\n        :param subject_context: the subject context data that may contain a\n                                SecurityManager instance\n        :returns: the SubjectContext\n        \"\"\"\n        if (subject_context.resolve_security_manager() is not None):\n            msg = (\"Subject Context resolved a security_manager \"\n                   \"instance, so not re-assigning.  Returning.\")\n            logger.debug(msg)\n            return subject_context\n\n        msg = (\"No security_manager found in context.  Adding self \"\n               \"reference.\")\n        logger.debug(msg)\n\n        subject_context.security_manager = self\n\n        return subject_context"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_session(self, subject_context):\n        if (subject_context.resolve_session() is not None):\n            msg = (\"Context already contains a session.  Returning.\")\n            logger.debug(msg)\n            return subject_context\n\n        try:\n            # Context couldn't resolve it directly, let's see if we can\n            # since we  have direct access to the session manager:\n            session = self.resolve_context_session(subject_context)\n\n            # if session is None, given that subject_context.session\n            # is None there is no harm done by setting it to None again\n            subject_context.session = session\n\n        except InvalidSessionException:\n            msg = (\"Resolved subject_subject_context context session is \"\n                   \"invalid.  Ignoring and creating an anonymous \"\n                   \"(session-less) Subject instance.\")\n            logger.debug(msg, exc_info=True)\n\n        return subject_context", "response": "Resolves any associated session based on the subject_context and returns a new context that represents this resolved Session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_identifiers(self, subject_context):\n        session = subject_context.session\n        identifiers = subject_context.resolve_identifiers(session)\n\n        if (not identifiers):\n            msg = (\"No identity (identifier_collection) found in the \"\n                   \"subject_context.  Looking for a remembered identity.\")\n            logger.debug(msg)\n\n            identifiers = self.get_remembered_identity(subject_context)\n\n            if identifiers:\n                msg = (\"Found remembered IdentifierCollection.  Adding to the \"\n                       \"context to be used for subject construction.\")\n                logger.debug(msg)\n\n                subject_context.identifiers = identifiers\n                subject_context.remembered = True\n\n            else:\n                msg = (\"No remembered identity found.  Returning original \"\n                       \"context.\")\n                logger.debug(msg)\n\n        return subject_context", "response": "Resolves the identifiers of a subject_context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logout(self, subject):\n        if (subject is None):\n            msg = \"Subject argument cannot be None.\"\n            raise ValueError(msg)\n\n        self.before_logout(subject)\n\n        identifiers = copy.copy(subject.identifiers)   # copy is new to yosai\n        if (identifiers):\n            msg = (\"Logging out subject with primary identifier {0}\".format(\n                   identifiers.primary_identifier))\n            logger.debug(msg)\n\n        try:\n            # this removes two internal attributes from the session:\n            self.delete(subject)\n        except Exception:\n            msg = \"Unable to cleanly unbind Subject.  Ignoring (logging out).\"\n            logger.debug(msg, exc_info=True)\n\n        finally:\n            try:\n                self.stop_session(subject)\n            except Exception:\n                msg2 = (\"Unable to cleanly stop Session for Subject. \"\n                        \"Ignoring (logging out).\")\n                logger.debug(msg2, exc_info=True)", "response": "Logs out the specified Subject from the system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_remembered_identity(self, subject_context):\n        rmm = self.remember_me_manager\n        if rmm is not None:\n            try:\n                return rmm.get_remembered_identifiers(subject_context)\n            except Exception as ex:\n                msg = (\"Delegate RememberMeManager instance of type [\" +\n                       rmm.__class__.__name__ + \"] raised an exception during \"\n                       \"get_remembered_identifiers().\")\n                logger.warning(msg, exc_info=True)\n        return None", "response": "Returns any previously remembered identifiers for the subject_context."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_clear_cache(self, identifier):\n        msg = \"Clearing cache for: \" + str(identifier)\n        logger.debug(msg)\n\n        self.clear_cached_authc_info(identifier)\n        self.clear_cached_authorization_info(identifier)", "response": "Clear the cache for the given identifier"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the authc_info for the given identifier from the cache.", "response": "def clear_cached_authc_info(self, identifier):\n        \"\"\"\n        When cached credentials are no longer needed, they can be manually\n        cleared with this method.  However, account credentials may be\n        cached with a short expiration time (TTL), making the manual clearing\n        of cached credentials an alternative use case.\n\n        :param identifier: the identifier of a specific source, extracted from\n                           the SimpleIdentifierCollection (identifiers)\n        \"\"\"\n        msg = \"Clearing cached authc_info for [{0}]\".format(identifier)\n        logger.debug(msg)\n\n        self.cache_handler.delete('authentication:' + self.name, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lock_account(self, identifier):\n        locked_time = int(time.time() * 1000)  # milliseconds\n        self.account_store.lock_account(identifier, locked_time)", "response": "Locks the given account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the authentication information for a specific user id.", "response": "def get_authentication_info(self, identifier):\n        \"\"\"\n        The default authentication caching policy is to cache an account's\n        credentials that are queried from an account store, for a specific\n        user, so to facilitate any subsequent authentication attempts for\n        that user. Naturally, in order to cache one must have a CacheHandler.\n        If a user were to fail to authenticate, perhaps due to an\n        incorrectly entered password, during the the next authentication\n        attempt (of that user id) the cached account will be readily\n        available from cache and used to match credentials, boosting\n        performance.\n\n        :returns: an Account object\n        \"\"\"\n        account_info = None\n        ch = self.cache_handler\n\n        def query_authc_info(self):\n            msg = (\"Could not obtain cached credentials for [{0}].  \"\n                   \"Will try to acquire credentials from account store.\"\n                   .format(identifier))\n            logger.debug(msg)\n\n            # account_info is a dict\n            account_info = self.account_store.get_authc_info(identifier)\n\n            if account_info is None:\n                msg = \"Could not get stored credentials for {0}\".format(identifier)\n                raise ValueError(msg)\n\n            return account_info\n\n        try:\n            msg2 = (\"Attempting to get cached credentials for [{0}]\"\n                    .format(identifier))\n            logger.debug(msg2)\n\n            # account_info is a dict\n            account_info = ch.get_or_create(domain='authentication:' + self.name,\n                                            identifier=identifier,\n                                            creator_func=query_authc_info,\n                                            creator=self)\n\n        except AttributeError:\n            # this means the cache_handler isn't configured\n            account_info = query_authc_info(self)\n        except ValueError:\n            msg3 = (\"No account credentials found for identifiers [{0}].  \"\n                    \"Returning None.\".format(identifier))\n            logger.warning(msg3)\n\n        if account_info:\n            account_info['account_id'] = SimpleIdentifierCollection(source_name=self.name,\n                                                                    identifier=identifier)\n        return account_info"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate_account(self, authc_token):\n        try:\n            identifier = authc_token.identifier\n        except AttributeError:\n            msg = 'Failed to obtain authc_token.identifiers'\n            raise AttributeError(msg)\n\n        tc = authc_token.__class__\n        try:\n            verifier = self.token_resolver[tc]\n        except KeyError:\n            raise TypeError('realm does not support token type: ', tc.__name__)\n\n        account = self.get_authentication_info(identifier)\n\n        try:\n            if account.get('account_locked'):\n                msg = \"Account Locked:  {0} locked at: {1}\".\\\n                    format(account['account_id'], account['account_locked'])\n                raise LockedAccountException(msg)\n        except (AttributeError, TypeError):\n            if not account:\n                msg = \"Could not obtain account credentials for: \" + str(identifier)\n                raise AccountException(msg)\n\n        self.assert_credentials_match(verifier, authc_token, account)\n\n        return account", "response": ":type authc_token: authc_abcs.AuthenticationToken\n        :rtype: dict\n        :raises IncorrectCredentialsException:  when authentication fails"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassert that the credentials of the given token match the given account.", "response": "def assert_credentials_match(self, verifier, authc_token, account):\n        \"\"\"\n        :type verifier: authc_abcs.CredentialsVerifier\n        :type authc_token: authc_abcs.AuthenticationToken\n        :type account:  account_abcs.Account\n        :returns: account_abcs.Account\n        :raises IncorrectCredentialsException:  when authentication fails,\n                                                including unix epoch timestamps\n                                                of recently failed attempts\n        \"\"\"\n        cred_type = authc_token.token_info['cred_type']\n\n        try:\n            verifier.verify_credentials(authc_token, account['authc_info'])\n        except IncorrectCredentialsException:\n            updated_account = self.update_failed_attempt(authc_token, account)\n\n            failed_attempts = updated_account['authc_info'][cred_type].\\\n                get('failed_attempts', [])\n\n            raise IncorrectCredentialsException(failed_attempts)\n        except ConsumedTOTPToken:\n            account['authc_info'][cred_type]['consumed_token'] = authc_token.credentials\n            self.cache_handler.set(domain='authentication:' + self.name,\n                                   identifier=authc_token.identifier,\n                                   value=account)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the authz_info for the given identifier and perm_domain.", "response": "def get_authzd_permissions(self, identifier, perm_domain):\n        \"\"\"\n        :type identifier:  str\n        :type domain:  str\n\n        :returns: a list of relevant json blobs, each a list of permission dicts\n        \"\"\"\n        related_perms = []\n        keys = ['*', perm_domain]\n\n        def query_permissions(self):\n            msg = (\"Could not obtain cached permissions for [{0}].  \"\n                   \"Will try to acquire permissions from account store.\"\n                   .format(identifier))\n            logger.debug(msg)\n\n            # permissions is a dict:  {'domain': json blob of lists of dicts}\n            permissions = self.account_store.get_authz_permissions(identifier)\n            if not permissions:\n                msg = \"Could not get permissions from account_store for {0}\".\\\n                    format(identifier)\n                raise ValueError(msg)\n            return permissions\n\n        try:\n            msg2 = (\"Attempting to get cached authz_info for [{0}]\"\n                    .format(identifier))\n            logger.debug(msg2)\n\n            domain = 'authorization:permissions:' + self.name\n\n            # related_perms is a list of json blobs whose contents are ordered\n            # such that the order matches that in the keys parameter:\n            related_perms = self.cache_handler.\\\n                hmget_or_create(domain=domain,\n                                identifier=identifier,\n                                keys=keys,\n                                creator_func=query_permissions,\n                                creator=self)\n        except ValueError:\n            msg3 = (\"No permissions found for identifiers [{0}].  \"\n                    \"Returning None.\".format(identifier))\n            logger.warning(msg3)\n\n        except AttributeError:\n            # this means the cache_handler isn't configured\n            queried_permissions = query_permissions(self)\n\n            related_perms = [queried_permissions.get('*'),\n                             queried_permissions.get(perm_domain)]\n\n        return related_perms"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of permissions and whether the user is permitted to access the object.", "response": "def is_permitted(self, identifiers, permission_s):\n        \"\"\"\n        If the authorization info cannot be obtained from the accountstore,\n        permission check tuple yields False.\n\n        :type identifiers:  subject_abcs.IdentifierCollection\n\n        :param permission_s: a collection of one or more permissions, represented\n                             as string-based permissions or Permission objects\n                             and NEVER comingled types\n        :type permission_s: list of string(s)\n\n        :yields: tuple(Permission, Boolean)\n        \"\"\"\n        identifier = identifiers.primary_identifier\n\n        for required in permission_s:\n            domain = Permission.get_domain(required)\n\n            # assigned is a list of json blobs:\n            assigned = self.get_authzd_permissions(identifier, domain)\n\n            is_permitted = False\n            for perms_blob in assigned:\n                is_permitted = self.permission_verifier.\\\n                    is_permitted_from_json(required, perms_blob)\n\n            yield (required, is_permitted)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_role(self, identifiers, required_role_s):\n        identifier = identifiers.primary_identifier\n\n        # assigned_role_s is a set\n        assigned_role_s = self.get_authzd_roles(identifier)\n\n        if not assigned_role_s:\n            msg = 'has_role:  no roles obtained from account_store for [{0}]'.\\\n                format(identifier)\n            logger.warning(msg)\n            for role in required_role_s:\n                yield (role, False)\n        else:\n            for role in required_role_s:\n                hasrole = ({role} <= assigned_role_s)\n                yield (role, hasrole)", "response": "Returns a generator that yields True if the subject is a member of one or more roles."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_start(self, session, session_context):\n        session_id = session.session_id\n        web_registry = session_context['web_registry']\n\n        if self.is_session_id_cookie_enabled:\n            web_registry.session_id = session_id\n            logger.debug(\"Set SessionID cookie using id: \" + str(session_id))\n\n        else:\n            msg = (\"Session ID cookie is disabled.  No cookie has been set for \"\n                   \"new session with id: \" + str(session_id))\n            logger.debug(msg)", "response": "Called when the session is started."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when the session is expired.", "response": "def on_expiration(self, session, ese=None, session_key=None):\n        \"\"\"\n        :type session: session_abcs.Session\n        :type ese: ExpiredSessionException\n        :type session_key:  session_abcs.SessionKey\n        \"\"\"\n        super().on_expiration(session, ese, session_key)\n        self.on_invalidation(session_key)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_invalidation(self, session_key, session=None, ise=None):\n        if session:\n            super().on_invalidation(session, ise, session_key)\n\n        web_registry = session_key.web_registry\n\n        del web_registry.session_id", "response": "Called by the session manager when the session is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_exposed_session(self, session, key=None, context=None):\n        if key:\n            return WebDelegatingSession(self, key)\n\n        web_registry = context['web_registry']\n        session_key = WebSessionKey(session.session_id,\n                                    web_registry=web_registry)\n\n        return WebDelegatingSession(self, session_key)", "response": "Creates an exposed session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_csrf_token(self, session_key):\n        try:\n            csrf_token = self._generate_csrf_token()\n\n            session = self._lookup_required_session(session_key)\n            session.set_internal_attribute('csrf_token', csrf_token)\n            self.session_handler.on_change(session)\n\n        except AttributeError:\n            raise CSRFTokenException('Could not save CSRF_TOKEN to session.')\n\n        return csrf_token", "response": "Creates a new CSRF token and saves it to the session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop_flash(self, queue='default'):\n        flash_messages = self.get_internal_attribute('flash_messages')\n        messages = flash_messages.pop(queue, None)\n        self.set_internal_attribute('flash_messages', flash_messages)\n        return messages", "response": "Removes a flash message from the flash_messages list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if session storage is generally available for the subject.", "response": "def is_session_storage_enabled(self, subject=None):\n        \"\"\"\n        Returns ``True`` if session storage is generally available (as determined\n        by the super class's global configuration property is_session_storage_enabled\n        and no request-specific override has turned off session storage, False\n        otherwise.\n\n        This means session storage is disabled if the is_session_storage_enabled\n        property is False or if a request attribute is discovered that turns off\n        session storage for the current request.\n\n        :param subject: the ``Subject`` for which session state persistence may\n                        be enabled\n\n        :returns: ``True`` if session storage is generally available (as\n                  determined by the super class's global configuration property\n                  is_session_storage_enabled and no request-specific override has\n                  turned off session storage, False otherwise.\n        \"\"\"\n        if subject.get_session(False):\n            # then use what already exists\n            return True\n\n        if not self.session_storage_enabled:\n            # honor global setting:\n            return False\n\n        # non-web subject instances can't be saved to web-only session managers:\n        if (not hasattr(subject, 'web_registry') and self.session_manager and\n                not isinstance(self.session_manager, session_abcs.NativeSessionManager)):\n            return False\n\n        return subject.web_registry.session_creation_enabled"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting marshaller for the class.", "response": "def default_marshaller(obj):\n    \"\"\"\n    Retrieve the state of the given object.\n\n    Calls the ``__getstate__()`` method of the object if available, otherwise returns the\n    ``__dict__`` of the object.\n\n    :param obj: the object to marshal\n    :return: the marshalled object state\n\n    \"\"\"\n    if hasattr(obj, '__getstate__'):\n        return obj.__getstate__()\n\n    try:\n        return obj.__dict__\n    except AttributeError:\n        raise TypeError('{!r} has no __dict__ attribute and does not implement __getstate__()'\n                        .format(obj.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrestore the state of an object.", "response": "def default_unmarshaller(instance, state):\n    \"\"\"\n    Restore the state of an object.\n\n    If the ``__setstate__()`` method exists on the instance, it is called with the state object\n    as the argument. Otherwise, the instance's ``__dict__`` is replaced with ``state``.\n\n    :param instance: an uninitialized instance\n    :param state: the state object, as returned by :func:`default_marshaller`\n\n    \"\"\"\n    if hasattr(instance, '__setstate__'):\n        instance.__setstate__(state)\n    else:\n        try:\n            instance.__dict__.update(state)\n        except AttributeError:\n            raise TypeError('{!r} has no __dict__ attribute and does not implement __setstate__()'\n                            .format(instance.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate_account(self, identifiers, authc_token, second_factor_token=None):\n        msg = (\"Authentication submission received for authentication \"\n               \"token [\" + str(authc_token) + \"]\")\n        logger.debug(msg)\n\n        # the following conditions verify correct authentication sequence\n        if not getattr(authc_token, 'identifier', None):\n            if not identifiers:\n                msg = \"Authentication must be performed in expected sequence.\"\n                raise InvalidAuthenticationSequenceException(msg)\n            authc_token.identifier = identifiers.primary_identifier\n\n        # add token metadata before sending it onward:\n        authc_token.token_info = token_info[authc_token.__class__]\n\n        try:\n            account = self.do_authenticate_account(authc_token)\n            if (account is None):\n                msg2 = (\"No account returned by any configured realms for \"\n                        \"submitted authentication token [{0}]\".\n                        format(authc_token))\n\n                raise AccountException(msg2)\n\n        except AdditionalAuthenticationRequired as exc:\n            if second_factor_token:\n                return self.authenticate_account(exc.account_id, second_factor_token, None)\n\n            self.notify_event(authc_token.identifier, 'AUTHENTICATION.PROGRESS')\n            raise exc  # the security_manager saves subject identifiers\n\n        except AccountException:\n            self.notify_event(authc_token.identifier,\n                              'AUTHENTICATION.ACCOUNT_NOT_FOUND')\n            raise\n\n        except LockedAccountException:\n            self.notify_event(authc_token.identifier, 'AUTHENTICATION.FAILED')\n            self.notify_event(authc_token.identifier, 'AUTHENTICATION.ACCOUNT_LOCKED')\n            raise\n\n        except IncorrectCredentialsException as exc:\n            self.notify_event(authc_token.identifier, 'AUTHENTICATION.FAILED')\n            self.validate_locked(authc_token, exc.failed_attempts)\n            # this won't be called if the Account is locked:\n            raise IncorrectCredentialsException\n\n        self.notify_event(account['account_id'].primary_identifier,\n                          'AUTHENTICATION.SUCCEEDED')\n\n        return account['account_id']", "response": "Authenticate the account with the given authentication token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_authenticate_account(self, authc_token):\n        try:\n            realms = self.token_realm_resolver[authc_token.__class__]\n        except KeyError:\n            raise KeyError('Unsupported Token Type Provided: ', authc_token.__class__.__name__)\n\n        if (len(self.realms) == 1):\n            account = self.authenticate_single_realm_account(realms[0], authc_token)\n        else:\n            account = self.authenticate_multi_realm_account(self.realms, authc_token)\n\n        cred_type = authc_token.token_info['cred_type']\n        attempts = account['authc_info'][cred_type].get('failed_attempts', [])\n        self.validate_locked(authc_token, attempts)\n\n        # TODO:  refactor this to something less rigid as it is unreliable:\n        if len(account['authc_info']) > authc_token.token_info['tier']:\n            if self.mfa_dispatcher:\n                realm = self.token_realm_resolver[TOTPToken][0]  # s/b only one\n                totp_token = realm.generate_totp_token(account)\n                mfa_info = account['authc_info']['totp_key']['2fa_info']\n                self.mfa_dispatcher.dispatch(authc_token.identifier,\n                                             mfa_info,\n                                             totp_token)\n            raise AdditionalAuthenticationRequired(account['account_id'])\n        return account", "response": "Returns an Account object only when the current token authenticates AND\n        the authentication process is complete and raises AdditionalAuthenticationRequired if additional tokens are required"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_cache(self, items=None, topic=EVENT_TOPIC):\n        try:\n            for realm in self.realms:\n                identifier = items.identifiers.from_source(realm.name)\n                if identifier:\n                    realm.clear_cached_authc_info(identifier)\n        except AttributeError:\n            msg = ('Could not clear authc_info from cache after event. '\n                   'items: ' + str(items))\n            logger.warn(msg)", "response": "Clear the cache for the items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_locked(self, authc_token, failed_attempts):\n        if self.locking_limit and len(failed_attempts) > self.locking_limit:\n            msg = ('Authentication attempts breached threshold.  Account'\n                   ' is now locked for: ' + str(authc_token.identifier))\n            self.locking_realm.lock_account(authc_token.identifier)\n            self.notify_event(authc_token.identifier, 'AUTHENTICATION.ACCOUNT_LOCKED')\n            raise LockedAccountException(msg)", "response": "Validates that the account is locked."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the extra dictionary you passed to logger.", "response": "def extra_from_record(self, record):\n        \"\"\"Returns `extra` dict you passed to logger.\n\n        The `extra` keyword argument is used to populate the `__dict__` of\n        the `LogRecord`.\n\n        \"\"\"\n        return {\n            attr_name: record.__dict__[attr_name]\n            for attr_name in record.__dict__\n            if attr_name not in BUILTIN_ATTRS\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_record(self, message, extra, record, traceback):\n        extra['message'] = message\n        if 'time' not in extra:\n            extra['time'] = datetime.now(pytz.utc)\n        if traceback is not None:\n            extra['traceback'] = traceback\n        return extra", "response": "Prepares a JSON payload which will be logged."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef identifiers(self, identifiers):\n        if (isinstance(identifiers, subject_abcs.IdentifierCollection) or\n                identifiers is None):\n            self._identifiers = identifiers\n        else:\n            raise ValueError('must use IdentifierCollection')", "response": "set the _identifiers attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the user is allowed to perform the given permission.", "response": "def is_permitted(self, permission_s):\n        \"\"\"\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of authz_abcs.Permission object(s) or String(s)\n\n        :returns: a List of tuple(s), containing the authz_abcs.Permission and a\n                  Boolean indicating whether the permission is granted\n        \"\"\"\n        if self.authorized:\n            self.check_security_manager()\n            return (self.security_manager.is_permitted(\n                    self.identifiers, permission_s))\n\n        msg = 'Cannot check permission when user isn\\'t authenticated nor remembered'\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the current user is permitted to collect the objects in the named permission_s.", "response": "def is_permitted_collective(self, permission_s, logical_operator=all):\n        \"\"\"\n        :param permission_s:  a List of authz_abcs.Permission objects\n\n        :param logical_operator:  indicates whether *all* or at least one\n                                  permission check is true, *any*\n        :type: any OR all (functions from python stdlib)\n\n        :returns: a Boolean\n        \"\"\"\n        sm = self.security_manager\n        if self.authorized:\n            return sm.is_permitted_collective(self.identifiers,\n                                              permission_s,\n                                              logical_operator)\n\n        msg = 'Cannot check permission when user isn\\'t authenticated nor remembered'\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the user has permission on the specified set of permissions.", "response": "def check_permission(self, permission_s, logical_operator=all):\n        \"\"\"\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of authz_abcs.Permission objects or Strings\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python stdlib)\n\n        :raises UnauthorizedException: if any permission is unauthorized\n        \"\"\"\n        self.assert_authz_check_possible()\n        if self.authorized:\n            self.security_manager.check_permission(self.identifiers,\n                                                   permission_s,\n                                                   logical_operator)\n        else:\n            msg = 'Cannot check permission when user isn\\'t authenticated nor remembered'\n            raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the user is a member of the role_s.", "response": "def has_role(self, role_s):\n        \"\"\"\n        :param role_s: 1..N role identifiers (strings)\n        :type role_s:  Set of Strings\n\n        :returns: a set of tuple(s), containing the role and a Boolean\n                  indicating whether the user is a member of the Role\n        \"\"\"\n        if self.authorized:\n            return self.security_manager.has_role(self.identifiers, role_s)\n        msg = 'Cannot check permission when identifiers aren\\'t set!'\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_role_collective(self, role_s, logical_operator=all):\n        if self.authorized:\n            return self.security_manager.has_role_collective(self.identifiers,\n                                                              role_s,\n                                                              logical_operator)\n        else:\n            msg = 'Cannot check permission when identifiers aren\\'t set!'\n            raise ValueError(msg)", "response": "Check if the user has the specified role collective."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the user has permission to perform a set of roles.", "response": "def check_role(self, role_ids, logical_operator=all):\n        \"\"\"\n        :param role_ids:  1 or more RoleIds\n        :type role_ids: a Set of Strings\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python stdlib)\n\n        :raises UnauthorizedException: if Subject not assigned to all roles\n        \"\"\"\n        if self.authorized:\n            self.security_manager.check_role(self.identifiers,\n                                             role_ids,\n                                             logical_operator)\n        else:\n            msg = 'Cannot check permission when identifiers aren\\'t set!'\n            raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs-in to the specified authc_token.", "response": "def login(self, authc_token):\n        \"\"\"\n        :type authc_token: authc_abcs.AuthenticationToken\n\n        authc_token's password is cleartext that is stored as a bytearray.\n        The authc_token password is cleared in memory, within the authc_token,\n        when authentication is successful.\n        \"\"\"\n        self.clear_run_as_identities_internal()\n        # login raises an AuthenticationException if it fails to authenticate:\n        subject = self.security_manager.login(subject=self,\n                                              authc_token=authc_token)\n        identifiers = None\n        host = None\n        if isinstance(subject, DelegatingSubject):\n            # directly reference the attributes in case there are assumed\n            # identities (Run-As) -- we don't want to lose the 'real' identifiers\n            identifiers = subject._identifiers\n            host = subject.host\n        else:\n            identifiers = subject.identifiers  # use the property accessor\n\n        if not identifiers:\n            msg = (\"Identifiers returned from security_manager.login(authc_token\" +\n                   \") returned None or empty value. This value must be\" +\n                   \" non-None and populated with one or more elements.\")\n            raise ValueError(msg)\n\n        self._identifiers = identifiers\n        self.authenticated = True\n\n        if not host:\n            try:\n                host = authc_token.host\n            except AttributeError:  # likely not using a HostAuthenticationToken\n                host = None\n        self.host = host\n\n        session = subject.get_session(False)\n        if session:\n            session.stop_session_callback = self.session_stopped\n            self.session = session\n        else:\n            self.session = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a session for this Subject", "response": "def get_session(self, create=True):\n        \"\"\"\n        :type create:  bool\n        \"\"\"\n        msg = (\"{0} attempting to get session; create = {1}; \\'session is None\\' =\"\n               \"{2} ; \\'session has id\\' = {3}\".\n               format(self.__class__.__name__, create, (self.session is None), str(\n                      self.session is not None and bool(self.session.session_id))))\n        logger.debug(msg)\n\n        if self.session and not create:  # touching a new session is redundant\n            self.session.touch()  # this is used to reset the idle timer (new to yosai)\n            return self.session\n\n        if (not self.session and create):\n            if (not self.is_session_creation_enabled()):\n                msg = (\"Session creation is disabled for the current subject. \"\n                       \"This exception indicates that there is \"\n                       \"either a programming error (using a session when \"\n                       \"it should never be used) or that Yosai's \"\n                       \"configuration needs to be adjusted to allow \"\n                       \"Sessions to be created for the current Subject.\")\n                raise ValueError(msg)\n\n            msg = (\"Starting session for host \", str(self.host))\n            logger.debug(msg)\n\n            session_context = self.create_session_context()\n            session = self.security_manager.start(session_context)\n            session.stop_session_callback = self.session_stopped\n            self.session = session\n\n        return self.session"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns as a new identity for this subject.", "response": "def run_as(self, identifiers):\n        \"\"\"\n        :type identifiers:  subject_abcs.IdentifierCollection\n        \"\"\"\n        if (not self.has_identifiers):\n            msg = (\"This subject does not yet have an identity.  Assuming the \"\n                   \"identity of another Subject is only allowed for Subjects \"\n                   \"with an existing identity.  Try logging this subject in \"\n                   \"first, or using the DelegatingSubject.Builder \"\n                   \"to build ad hoc Subject instances with identities as \"\n                   \"necessary.\")\n            raise ValueError(msg)\n        self.push_identity(identifiers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the previous identifiers for the current node.", "response": "def get_previous_identifiers(self):\n        \"\"\"\n        :returns: SimpleIdentifierCollection\n        \"\"\"\n        previous_identifiers = None\n        stack = self.get_run_as_identifiers_stack()  # TBD:  must confirm logic\n\n        if stack:\n            if (len(stack) == 1):\n                previous_identifiers = self.identifiers\n            else:\n                # always get the one behind the current\n                previous_identifiers = stack[1]\n        return previous_identifiers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_run_as_identifiers_stack(self):\n        session = self.get_session(False)\n\n        try:\n            return session.get_internal_attribute(self.run_as_identifiers_session_key)\n        except AttributeError:\n            return None", "response": "returns an IdentifierCollection object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef push_identity(self, identifiers):\n        if (not identifiers):\n            msg = (\"Specified Subject identifiers cannot be None or empty \"\n                   \"for 'run as' functionality.\")\n            raise ValueError(msg)\n\n        stack = self.get_run_as_identifiers_stack()\n\n        if (not stack):\n            stack = []\n\n        stack.append(identifiers)\n        session = self.get_session()\n        session.set_internal_attribute(self.run_as_identifiers_session_key, stack)", "response": "Pushes the specified identifiers onto the run as identifiers stack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop_identity(self):\n        popped = None\n        stack = self.get_run_as_identifiers_stack()\n\n        if (stack):\n            popped = stack.pop()\n            if (stack):\n                # persist the changed stack to the session\n                session = self.get_session()\n                session.set_internal_attribute(self.run_as_identifiers_session_key, stack)\n\n            else:\n                # stack is empty, remove it from the session:\n                self.clear_run_as_identities()\n        return popped", "response": "Pops the last identity from the run - as - identifiers stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the subject s state to the subject s Session only", "response": "def save(self, subject):\n        \"\"\"\n        Saves the subject's state to the subject's ``Session`` only\n        if session storage is enabled for the subject.  If session storage is\n        not enabled for the specific Subject, this method does nothing.\n\n        In either case, the argument Subject is returned directly (a new\n        ``Subject`` instance is not created).\n\n        :param subject: the Subject instance for which its state will be\n                        created or updated\n        :type subject:  subject_abcs.Subject\n\n        :returns: the same Subject passed in (a new Subject instance is\n                  not created).\n        \"\"\"\n        if (self.is_session_storage_enabled(subject)):\n            self.merge_identity(subject)\n        else:\n            msg = (\"Session storage of subject state for Subject [{0}] has \"\n                   \"been disabled: identity and authentication state are \"\n                   \"expected to be initialized on every request or \"\n                   \"invocation.\".format(subject))\n            logger.debug(msg)\n\n        return subject"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_identity(self, subject):\n        current_identifiers = None\n\n        if subject.is_run_as:\n            # avoid the other steps of attribute access when referencing by\n            # property by referencing the underlying attribute directly:\n            current_identifiers = subject._identifiers\n\n        if not current_identifiers:\n            # if direct attribute access did not work, use the property-\n            # decorated attribute access method:\n            current_identifiers = subject.identifiers\n\n        session = subject.get_session(False)\n\n        if not session:\n            to_set = []\n\n            if current_identifiers or subject.authenticated:\n                session = subject.get_session()\n\n                to_set.append([self.dsc_isk, current_identifiers])\n                to_set.append([self.dsc_ask, True])\n\n                msg = ('merge_identity _DID NOT_ find a session for current subject '\n                       'and so created a new one (session_id: {0}). Now merging '\n                       'internal attributes: {1}'.format(session.session_id, to_set))\n                logger.debug(msg)\n                session.set_internal_attributes(to_set)\n        else:\n            self.merge_identity_with_session(current_identifiers, subject, session)", "response": "Merges the Subject s identifying attributes and authc status with the Subject s session."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, subject):\n        session = subject.get_session(False)\n        if (session):\n            session.remove_internal_attribute(self.dsc_ask)\n            session.remove_internal_attribute(self.dsc_isk)", "response": "Removes the attribute from the subject s session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_subject(self):\n        subject_context = SubjectContext(yosai=self, security_manager=self.security_manager)\n        subject = self.security_manager.create_subject(subject_context=subject_context)\n        global_subject_context.stack.append(subject)\n        return subject", "response": "Returns the currently accessible Subject"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef requires_authentication(fn):\n\n        @functools.wraps(fn)\n        def wrap(*args, **kwargs):\n            subject = Yosai.get_current_subject()\n\n            if not subject.authenticated:\n                msg = \"The current Subject is not authenticated.  ACCESS DENIED.\"\n                raise UnauthenticatedException(msg)\n\n            return fn(*args, **kwargs)\n        return wrap", "response": "Decorator that ensures that the calling Subject is authenticated before allowing access."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequires that the calling Subject be *either* authenticated *or* remembered via RememberMe services before allowing access. This method essentially ensures that subject.identifiers IS NOT None :raises UnauthenticatedException: indicating that the decorated method is not allowed to be executed because the Subject attempted to perform a user-only operation", "response": "def requires_user(fn):\n        \"\"\"\n        Requires that the calling Subject be *either* authenticated *or* remembered\n        via RememberMe services before allowing access.\n\n        This method essentially ensures that subject.identifiers IS NOT None\n\n        :raises UnauthenticatedException: indicating that the decorated method is\n                                          not allowed to be executed because the\n                                          Subject attempted to perform a user-only\n                                          operation\n        \"\"\"\n        @functools.wraps(fn)\n        def wrap(*args, **kwargs):\n\n            subject = Yosai.get_current_subject()\n\n            if subject.identifiers is None:\n                msg = (\"Attempting to perform a user-only operation.  The \"\n                       \"current Subject is NOT a user (they haven't been \"\n                       \"authenticated or remembered from a previous login). \"\n                       \"ACCESS DENIED.\")\n                raise UnauthenticatedException(msg)\n\n            return fn(*args, **kwargs)\n        return wrap"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequires that the calling Subject be authorized to the extent that is required to satisfy the permission_s specified and the logical operation upon them. :param permission_s: the permission(s) required :type permission_s: a List of Strings or List of Permission instances :param logical_operator: indicates whether all or at least one permission is true (and, any) :type: and OR all (from python standard library) :raises AuthorizationException: if the user does not have sufficient permission Elaborate Example: requires_permission( permission_s=['domain1:action1,action2', 'domain2:action1'], logical_operator=any) Basic Example: requires_permission(['domain1:action1,action2'])", "response": "def requires_permission(permission_s, logical_operator=all):\n        \"\"\"\n        Requires that the calling Subject be authorized to the extent that is\n        required to satisfy the permission_s specified and the logical operation\n        upon them.\n\n        :param permission_s:   the permission(s) required\n        :type permission_s:  a List of Strings or List of Permission instances\n\n        :param logical_operator:  indicates whether all or at least one permission\n                                  is true (and, any)\n        :type: and OR all (from python standard library)\n\n        :raises  AuthorizationException:  if the user does not have sufficient\n                                          permission\n\n        Elaborate Example:\n            requires_permission(\n                permission_s=['domain1:action1,action2', 'domain2:action1'],\n                logical_operator=any)\n\n        Basic Example:\n            requires_permission(['domain1:action1,action2'])\n        \"\"\"\n        def outer_wrap(fn):\n            @functools.wraps(fn)\n            def inner_wrap(*args, **kwargs):\n\n                subject = Yosai.get_current_subject()\n                subject.check_permission(permission_s, logical_operator)\n\n                return fn(*args, **kwargs)\n            return inner_wrap\n        return outer_wrap"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires_dynamic_permission(permission_s, logical_operator=all):\n        def outer_wrap(fn):\n            @functools.wraps(fn)\n            def inner_wrap(*args, **kwargs):\n                newperms = [perm.format(**kwargs) for perm in permission_s]\n\n                subject = Yosai.get_current_subject()\n\n                subject.check_permission(newperms, logical_operator)\n\n                return fn(*args, **kwargs)\n            return inner_wrap\n        return outer_wrap", "response": "Decorator that ensures that the calling Subject has sufficient permission to satisfy the specified permissions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requires_role(role_s, logical_operator=all):\n        def outer_wrap(fn):\n            @functools.wraps(fn)\n            def inner_wrap(*args, **kwargs):\n\n                subject = Yosai.get_current_subject()\n\n                subject.check_role(role_s, logical_operator)\n\n                return fn(*args, **kwargs)\n            return inner_wrap\n        return outer_wrap", "response": "Decorator that ensures that the calling Subject is authorized to the extent that is isn t required to satisfy the role_s specified and the logical operation\n        upon them."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new security manager instance.", "response": "def create_manager(self, yosai, settings, session_attributes):\n        \"\"\"\n        Order of execution matters.  The sac must be set before the cache_handler is\n        instantiated so that the cache_handler's serialization manager instance\n        registers the sac.\n        \"\"\"\n        mgr_settings = SecurityManagerSettings(settings)\n        attributes = mgr_settings.attributes\n\n        realms = self._init_realms(settings, attributes['realms'])\n\n        session_attributes = self._init_session_attributes(session_attributes, attributes)\n\n        serialization_manager =\\\n            SerializationManager(session_attributes,\n                                 serializer_scheme=attributes['serializer'])\n\n        # the cache_handler doesn't initialize a cache_realm until it gets\n        # a serialization manager, which is assigned within the SecurityManager\n        cache_handler = self._init_cache_handler(settings,\n                                                 attributes['cache_handler'],\n                                                 serialization_manager)\n\n        manager = mgr_settings.security_manager(yosai,\n                                                settings,\n                                                realms=realms,\n                                                cache_handler=cache_handler,\n                                                serialization_manager=serialization_manager)\n\n        return manager"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve realms from attributes.", "response": "def resolve_realms(self, attributes):\n        \"\"\"\n        The format of realm settings is:\n            {'name_of_realm':\n                {'cls': 'location to realm class',\n                 'account_store': 'location to realm account_store class'}}\n\n            - 'name of realm' is a label used for internal tracking\n            - 'cls' and 'account_store' are static key names and are not to be changed\n            - the location of classes should follow dotted notation: pkg.module.class\n        \"\"\"\n        realms = []\n\n        for realm, realm_attributes in attributes['realms'].items():\n            realm_cls = maybe_resolve(realm)\n            account_store_cls = maybe_resolve(realm_attributes['account_store'])\n\n            verifiers = {}\n\n            authc_verifiers = realm_attributes.get('authc_verifiers')\n            if authc_verifiers:\n                if isinstance(authc_verifiers, list):\n                    authc_verifiers_cls = tuple(maybe_resolve(verifier)(self.settings) for\n                                                verifier in authc_verifiers)\n                else:\n                    authc_verifiers_cls = tuple([maybe_resolve(authc_verifiers)(self.settings)])\n                verifiers['authc_verifiers'] = authc_verifiers_cls\n\n            authz_verifier = realm_attributes.get('authz_verifier')\n            if authz_verifier:\n                permission_verifier_cls = maybe_resolve(authz_verifier)\n                if permission_verifier_cls:\n                    verifiers['permission_verifier'] = maybe_resolve(permission_verifier_cls)()\n\n            realms.append([realm_cls, account_store_cls, verifiers])\n\n        return realms"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the realms attribute.", "response": "def init_realms(self, realms):\n        \"\"\"\n        :type realms: tuple\n        \"\"\"\n        # this eliminates the need for an authorizing_realms attribute:\n        self.realms = tuple(realm for realm in realms\n                            if isinstance(realm, realm_abcs.AuthorizingRealm))\n        self.register_cache_clear_listener()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _has_role(self, identifiers, role_s):\n        for realm in self.realms:\n            # the realm's has_role returns a generator\n            yield from realm.has_role(identifiers, role_s)", "response": "A generator that returns a generator for the has_role method of all the realms in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_permitted(self, identifiers, permission_s):\n\n        for realm in self.realms:\n            # the realm's is_permitted returns a generator\n            yield from realm.is_permitted(identifiers, permission_s)", "response": "returns a generator that yields True if the user is allowed to access the object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_permitted(self, identifiers, permission_s, log_results=True):\n        self.assert_realms_configured()\n\n        results = collections.defaultdict(bool)  # defaults to False\n\n        is_permitted_results = self._is_permitted(identifiers, permission_s)\n\n        for permission, is_permitted in is_permitted_results:\n            # permit expected format is: (Permission, Boolean)\n            # As long as one realm returns True for a Permission, that Permission\n            # is granted.  Given that (True or False == True), assign accordingly:\n            results[permission] = results[permission] or is_permitted\n\n        if log_results:\n            self.notify_event(identifiers,\n                              list(results.items()),\n                              'AUTHORIZATION.RESULTS')\n\n        results = set(results.items())\n        return results", "response": "This method checks whether a permission is granted for a set of identifiers and permission_s."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a boolean value indicating whether the collective is permitted for the given set of identifiers and permission_s.", "response": "def is_permitted_collective(self, identifiers,\n                                permission_s, logical_operator):\n        \"\"\"\n        :param identifiers: a collection of Identifier objects\n        :type identifiers:  subject_abcs.IdentifierCollection\n\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of Permission object(s) or String(s)\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :returns: a Boolean\n        \"\"\"\n        self.assert_realms_configured()\n\n        # interim_results is a set of tuples:\n        interim_results = self.is_permitted(identifiers, permission_s,\n                                            log_results=False)\n\n        results = logical_operator(is_permitted for perm, is_permitted\n                                   in interim_results)\n\n        if results:\n            self.notify_event(identifiers,\n                              permission_s,\n                              'AUTHORIZATION.GRANTED',\n                              logical_operator)\n        else:\n            self.notify_event(identifiers,\n                              permission_s,\n                              'AUTHORIZATION.DENIED',\n                              logical_operator)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a Subject has the requested permission", "response": "def check_permission(self, identifiers, permission_s, logical_operator):\n        \"\"\"\n        like Yosai's authentication process, the authorization process will\n        raise an Exception to halt further authz checking once Yosai determines\n        that a Subject is unauthorized to receive the requested permission\n\n        :param identifiers: a collection of identifiers\n        :type identifiers:  subject_abcs.IdentifierCollection\n\n        :param permission_s: a collection of 1..N permissions\n        :type permission_s: List of Permission objects or Strings\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :raises UnauthorizedException: if any permission is unauthorized\n        \"\"\"\n        self.assert_realms_configured()\n        permitted = self.is_permitted_collective(identifiers,\n                                                 permission_s,\n                                                 logical_operator)\n        if not permitted:\n            msg = \"Subject lacks permission(s) to satisfy logical operation\"\n            raise UnauthorizedException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_role(self, identifiers, role_s, log_results=True):\n        self.assert_realms_configured()\n\n        results = collections.defaultdict(bool)  # defaults to False\n\n        for role, has_role in self._has_role(identifiers, role_s):\n            # checkrole expected format is: (role, Boolean)\n            # As long as one realm returns True for a role, a subject is\n            # considered a member of that Role.\n            # Given that (True or False == True), assign accordingly:\n            results[role] = results[role] or has_role\n\n        if log_results:\n            self.notify_event(identifiers,\n                              list(results.items()),\n                              'AUTHORIZATION.RESULTS')  # before freezing\n        results = set(results.items())\n        return results", "response": "Returns a set of tuples containing the role and a Boolean containing whether the user is a member of the Role."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the subject has at least one role in the set of roles", "response": "def has_role_collective(self, identifiers, role_s, logical_operator):\n        \"\"\"\n        :param identifiers: a collection of identifiers\n        :type identifiers:  subject_abcs.IdentifierCollection\n\n        :param role_s: a collection of 1..N Role identifiers\n        :type role_s: Set of String(s)\n\n        :param logical_operator:  indicates whether all or at least one\n                                  permission check is true (any)\n        :type: any OR all (from python standard library)\n\n        :returns: a Boolean\n        \"\"\"\n        self.assert_realms_configured()\n\n        # interim_results is a set of tuples:\n        interim_results = self.has_role(identifiers, role_s, log_results=False)\n\n        results = logical_operator(has_role for role, has_role\n                                   in interim_results)\n\n        if results:\n            self.notify_event(identifiers,\n                              list(role_s),\n                              'AUTHORIZATION.GRANTED',\n                              logical_operator)\n        else:\n            self.notify_event(identifiers,\n                              list(role_s),\n                              'AUTHORIZATION.DENIED',\n                              logical_operator)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_role(self, identifiers, role_s, logical_operator):\n        self.assert_realms_configured()\n        has_role_s = self.has_role_collective(identifiers,\n                                              role_s, logical_operator)\n        if not has_role_s:\n            msg = \"Subject does not have role(s) assigned.\"\n            raise UnauthorizedException(msg)", "response": "Checks if a Subject has a role assigned to a set of roles."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a collection of source identifiers to the set of source identifiers.", "response": "def add_collection(self, identifier_collection):\n        \"\"\"\n        :type identifier_collection: a SimpleIdentifierCollection\n        \"\"\"\n        try:\n            new_source_identifiers = identifier_collection.source_identifiers\n            self.source_identifiers.update(new_source_identifiers)\n        except AttributeError:\n            msg = \"Invalid identifier collection passed as argument\"\n            raise AttributeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all unique instances of a type of identifier_class", "response": "def by_type(self, identifier_class):\n        \"\"\"\n        returns all unique instances of a type of identifier\n\n        :param identifier_class: the class to match identifier with\n        :returns: a tuple\n        \"\"\"\n        myidentifiers = set()\n        for identifier in self.source_identifiers.values():\n            if (isinstance(identifier, identifier_class)):\n                myidentifiers.update([identifier])\n        return set(myidentifiers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new session and caches the session and returns the sessionid", "response": "def create(self, session):\n        \"\"\"\n        caches the session and caches an entry to associate the cached session\n        with the subject\n        \"\"\"\n        sessionid = super().create(session)  # calls _do_create and verify\n        self._cache(session, sessionid)\n        return sessionid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine whether or not the session has been expired or not.", "response": "def is_timed_out(self):\n        \"\"\"\n        determines whether a Session has been inactive/idle for too long a time\n        OR exceeds the absolute time that a Session may exist\n        \"\"\"\n        if (self.is_expired):\n            return True\n\n        try:\n            if (not self.last_access_time):\n                msg = (\"session.last_access_time for session with id [\" +\n                       str(self.session_id) + \"] is null. This value must be\"\n                       \"set at least once, preferably at least upon \"\n                       \"instantiation. Please check the \" +\n                       self.__class__.__name__ +\n                       \" implementation and ensure self value will be set \"\n                       \"(perhaps in the constructor?)\")\n                raise ValueError(msg)\n\n            \"\"\"\n             Calculate at what time a session would have been last accessed\n             for it to be expired at this point.  In other words, subtract\n             from the current time the amount of time that a session can\n             be inactive before expiring.  If the session was last accessed\n             before this time, it is expired.\n            \"\"\"\n            if self.is_absolute_timed_out:\n                return True\n\n            if self.is_idle_timed_out:\n                return True\n\n        except AttributeError:\n            msg2 = (\"Timeouts not set for session with id [\" +\n                    str(self.session_id) + \"]. Session is not considered \"\n                    \"expired.\")\n            logger.debug(msg2)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a session from the session store.", "response": "def _retrieve_session(self, session_key):\n        \"\"\"\n        :type session_key: SessionKey\n        :returns: SimpleSession\n        \"\"\"\n        session_id = session_key.session_id\n        if (session_id is None):\n            msg = (\"Unable to resolve session ID from SessionKey [{0}].\"\n                   \"Returning null to indicate a session could not be \"\n                   \"found.\".format(session_key))\n            logger.debug(msg)\n            return None\n\n        session = self.session_store.read(session_id)\n\n        if (session is None):\n            # session ID was provided, meaning one is expected to be found,\n            # but we couldn't find one:\n            msg2 = \"Could not find session with ID [{0}]\".format(session_id)\n            raise ValueError(msg2)\n\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_get_session(self, session_key):\n        session_id = session_key.session_id\n        msg = (\"do_get_session: Attempting to retrieve session with key \" +\n               str(session_id))\n        logger.debug(msg)\n\n        session = self._retrieve_session(session_key)\n\n        if (session is not None):\n            self.validate(session, session_key)\n\n        return session", "response": "Returns a session object for the specified session key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef notify_event(self, session_info, topic):\n        try:\n            self.event_bus.sendMessage(topic, items=session_info)\n        except AttributeError:\n            msg = \"Could not publish {} event\".format(topic)\n            raise AttributeError(msg)", "response": "Notify the event bus of an event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self, session_context):\n        # is a SimpleSesson:\n        session = self._create_session(session_context)\n\n        self.session_handler.on_start(session, session_context)\n\n        mysession = session_tuple(None, session.session_id)\n        self.notify_event(mysession, 'SESSION.START')\n\n        # Don't expose the EIS-tier Session object to the client-tier, but\n        # rather a DelegatingSession:\n        return self.create_exposed_session(session=session, context=session_context)", "response": "Start the session with the specified context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_exposed_session(self, session, key=None, context=None):\n        # shiro ignores key and context parameters\n        return DelegatingSession(self, SessionKey(session.session_id))", "response": "Creates a new session that is exposed to the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a DelegatingSession object for the given key.", "response": "def get_session(self, key):\n        \"\"\"\n        :returns: DelegatingSession\n        \"\"\"\n        # a SimpleSession:\n        session = self.session_handler.do_get_session(key)\n        if (session):\n            return self.create_exposed_session(session, key)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _lookup_required_session(self, key):\n        session = self.session_handler.do_get_session(key)\n        if (not session):\n            msg = (\"Unable to locate required Session instance based \"\n                   \"on session_key [\" + str(key) + \"].\")\n            raise ValueError(msg)\n        return session", "response": "Returns a required session instance based on the key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_attributes(self, session_key, attributes):\n        session = self._lookup_required_session(session_key)\n        session.set_attributes(attributes)\n        self.session_handler.on_change(session)", "response": "Set the attributes of the specified session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the specified attributes from the specified session.", "response": "def remove_attributes(self, session_key, attribute_keys):\n        \"\"\"\n        :type attribute_keys: a list of strings\n        \"\"\"\n        session = self._lookup_required_session(session_key)\n        removed = session.remove_attributes(attribute_keys)\n        if removed:\n            self.session_handler.on_change(session)\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_reference(ref):\n    if not isinstance(ref, str) or ':' not in ref:\n        return ref\n\n    modulename, rest = ref.split(':', 1)\n    try:\n        obj = import_module(modulename)\n    except ImportError as e:\n        raise LookupError(\n            'error resolving reference {}: could not import module'.format(ref)) from e\n\n    try:\n        for name in rest.split('.'):\n            obj = getattr(obj, name)\n        return obj\n    except AttributeError:\n        raise LookupError('error resolving reference {}: error looking up object'.format(ref))", "response": "Resolve a reference to a base class object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef qualified_name(obj):\n    try:\n        module = obj.__module__\n        qualname = obj.__qualname__\n    except AttributeError:\n        type_ = type(obj)\n        module = type_.__module__\n        qualname = type_.__qualname__\n\n    return qualname if module in ('typing', 'builtins') else '{}.{}'.format(module, qualname)", "response": "Return the qualified name for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_item(session, item, quantity=1):\n        shopping_cart = session.get_attribute('shopping_cart')\n        if shopping_cart:\n            shopping_cart.add_item(item, quantity)\n        else:\n            shopping_cart = ShoppingCart()\n            shopping_cart.add_item(item, quantity)\n        session.set_attribute('shopping_cart', shopping_cart)", "response": "Adds a new item to the shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _setup(self, name=None):\n        envvar = self.__dict__['env_var']\n        if envvar:\n            settings_file = os.environ.get(envvar)\n        else:\n            settings_file = self.__dict__['file_path']\n\n        if not settings_file:\n            msg = (\"Requested settings, but none can be obtained for the envvar.\"\n                   \"Since no config filepath can be obtained, a default config \"\n                   \"will be used.\")\n            logger.error(msg)\n            raise OSError(msg)\n\n        self._wrapped = Settings(settings_file)", "response": "Load the settings module referenced by env_var. This environment - specific environment - specific configuration process is called during the settings\nAttributeNames configuration process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the currently accessible Subject", "response": "def _get_subject(self):\n        \"\"\"\n        Returns the currently accessible Subject available to the calling code\n        depending on runtime environment.\n\n        :param web_registry:  The WebRegistry instance that knows how to interact\n                              with the web application's request and response APIs\n\n        :returns: the Subject currently accessible to the calling code\n        \"\"\"\n        web_registry = WebYosai.get_current_webregistry()\n        subject_context = WebSubjectContext(yosai=self,\n                                            security_manager=self.security_manager,\n                                            web_registry=web_registry)\n        subject = self.security_manager.create_subject(subject_context=subject_context)\n\n        if not hasattr(subject, 'web_registry'):\n            msg = (\"Subject implementation returned from the SecurityManager\"\n                   \"was not a WebSubject implementation.  Please ensure a \"\n                   \"Web-enabled SecurityManager has been configured and made\"\n                   \"available to this builder.\")\n            raise AttributeError(msg)\n\n        return subject"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires_authentication(fn):\n\n        @functools.wraps(fn)\n        def wrap(*args, **kwargs):\n            subject = WebYosai.get_current_subject()\n\n            if not subject.authenticated:\n                msg = \"The current Subject is not authenticated.  ACCESS DENIED.\"\n                raise WebYosai.get_current_webregistry().raise_unauthorized(msg)\n\n            return fn(*args, **kwargs)\n        return wrap", "response": "Decorator that ensures that the calling Subject is authenticated before allowing access."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires_user(fn):\n        @functools.wraps(fn)\n        def wrap(*args, **kwargs):\n\n            subject = WebYosai.get_current_subject()\n\n            if subject.identifiers is None:\n                msg = (\"Attempting to perform a user-only operation.  The \"\n                       \"current Subject is NOT a user (they haven't been \"\n                       \"authenticated or remembered from a previous login). \"\n                       \"ACCESS DENIED.\")\n                raise WebYosai.get_current_webregistry().raise_unauthorized(msg)\n            return fn(*args, **kwargs)\n        return wrap", "response": "Decorator that ensures that the calling Subject is either authenticated or remembered."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requires_permission(permission_s, logical_operator=all):\n        def outer_wrap(fn):\n            @functools.wraps(fn)\n            def inner_wrap(*args, **kwargs):\n\n                subject = WebYosai.get_current_subject()\n                try:\n                    subject.check_permission(permission_s, logical_operator)\n\n                except ValueError:\n                    msg = (\"Attempting to perform a user-only operation.  The \"\n                           \"current Subject is NOT a user (they haven't been \"\n                           \"authenticated or remembered from a previous login). \"\n                           \"ACCESS DENIED.\")\n                    raise WebYosai.get_current_webregistry().raise_unauthorized(msg)\n\n                except AuthorizationException:\n                    msg = \"Access Denied.  Insufficient Permissions.\"\n                    raise WebYosai.get_current_webregistry().raise_forbidden(msg)\n\n                return fn(*args, **kwargs)\n            return inner_wrap\n        return outer_wrap", "response": "Decorator that ensures that the calling Subject is authorized to the extent that is used to perform a specific operation on the specified permission set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequire that the calling Subject be authorized to the extent that is required to satisfy the role_s specified and the logical operation upon them. :param role_s: a collection of the role(s) required, specified by identifiers (such as a role name) :type role_s: a List of Strings :param logical_operator: indicates whether all or at least one permission is true (and, any) :type: and OR all (from python standard library) Elaborate Example: requires_role(role_s=['sysadmin', 'developer'], logical_operator=any) Basic Example: requires_role('physician')", "response": "def requires_role(role_s, logical_operator=all):\n        \"\"\"\n        Requires that the calling Subject be authorized to the extent that is\n        required to satisfy the role_s specified and the logical operation\n        upon them.\n\n        :param role_s:   a collection of the role(s) required, specified by\n                           identifiers (such as a role name)\n        :type role_s:  a List of Strings\n\n        :param logical_operator:  indicates whether all or at least one permission\n                                  is true (and, any)\n        :type: and OR all (from python standard library)\n\n        Elaborate Example:\n            requires_role(role_s=['sysadmin', 'developer'], logical_operator=any)\n\n        Basic Example:\n            requires_role('physician')\n        \"\"\"\n        def outer_wrap(fn):\n            @functools.wraps(fn)\n            def inner_wrap(*args, **kwargs):\n\n                subject = WebYosai.get_current_subject()\n\n                try:\n                    subject.check_role(role_s, logical_operator)\n\n                except ValueError:\n                    msg = (\"Attempting to perform a user-only operation.  The \"\n                           \"current Subject is NOT a user (they haven't been \"\n                           \"authenticated or remembered from a previous login). \"\n                           \"ACCESS DENIED.\")\n                    raise WebYosai.get_current_webregistry().raise_unauthorized(msg)\n\n                except AuthorizationException:\n                    msg = \"Access Denied.  Insufficient Role Membership.\"\n                    raise WebYosai.get_current_webregistry().raise_forbidden(msg)\n\n                return fn(*args, **kwargs)\n            return inner_wrap\n        return outer_wrap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_create_subject(self, subject_context):\n        if not isinstance(subject_context, web_subject_abcs.WebSubjectContext):\n            return super().do_create_subject(subject_context=subject_context)\n\n        security_manager = subject_context.resolve_security_manager()\n        session = subject_context.resolve_session()\n        session_creation_enabled = subject_context.session_creation_enabled\n\n        # passing the session arg is new to yosai, eliminating redunant\n        # get_session calls:\n        identifiers = subject_context.resolve_identifiers(session)\n        authenticated = subject_context.resolve_authenticated(session)\n        host = subject_context.resolve_host(session)\n\n        # must run after resolve_identifiers:\n        remembered = getattr(subject_context, 'remembered', None)\n\n        return WebDelegatingSubject(identifiers=identifiers,\n                                    remembered=remembered,\n                                    authenticated=authenticated,\n                                    host=host,\n                                    session=session,\n                                    session_creation_enabled=session_creation_enabled,\n                                    security_manager=security_manager,\n                                    web_registry=subject_context.web_registry)", "response": "This method is used to create a Subject instance from a SubjectContext."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_remembered_encrypted_identity(self, subject_context):\n        if (self.is_identity_removed(subject_context)):\n            if not isinstance(subject_context, web_subject_abcs.WebSubjectContext):\n                msg = (\"SubjectContext argument is not an HTTP-aware instance. \"\n                       \"This is required to obtain a web registry \"\n                       \"in order to retrieve the RememberMe cookie. Returning \"\n                       \"immediately and ignoring rememberMe operation.\")\n                logger.debug(msg)\n\n            return None\n\n        remember_me = subject_context.web_registry.remember_me\n\n        # TBD:\n        # Browsers do not always remove cookies immediately\n        # ignore cookies that are scheduled for removal\n        # if (web_wsgi_abcs.Cookie.DELETED_COOKIE_VALUE.equals(base64)):\n        #     return None\n\n        if remember_me:\n\n            logger.debug(\"Acquired encoded identity [\" + str(remember_me) + \"]\")\n\n            encrypted = base64.b64decode(remember_me)\n\n            return encrypted\n        else:\n            # no cookie set - new site visitor?\n            return None", "response": "This method retrieves the previously serialized identity byte array or None if the byte array could not be acquired."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_raw_temp(self):\n        self._device.write8(BMP085_CONTROL, BMP085_READTEMPCMD)\n        time.sleep(0.005)  # Wait 5ms\n        raw = self._device.readU16BE(BMP085_TEMPDATA)\n        self._logger.debug('Raw temp 0x{0:X} ({1})'.format(raw & 0xFFFF, raw))\n        return raw", "response": "Reads the raw temperature from the sensor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_raw_pressure(self):\n        self._device.write8(BMP085_CONTROL, BMP085_READPRESSURECMD + (self._mode << 6))\n        if self._mode == BMP085_ULTRALOWPOWER:\n            time.sleep(0.005)\n        elif self._mode == BMP085_HIGHRES:\n            time.sleep(0.014)\n        elif self._mode == BMP085_ULTRAHIGHRES:\n            time.sleep(0.026)\n        else:\n            time.sleep(0.008)\n        msb = self._device.readU8(BMP085_PRESSUREDATA)\n        lsb = self._device.readU8(BMP085_PRESSUREDATA+1)\n        xlsb = self._device.readU8(BMP085_PRESSUREDATA+2)\n        raw = ((msb << 16) + (lsb << 8) + xlsb) >> (8 - self._mode)\n        self._logger.debug('Raw pressure 0x{0:04X} ({1})'.format(raw & 0xFFFF, raw))\n        return raw", "response": "Reads the raw pressure level from the sensor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the altitude in meters.", "response": "def read_altitude(self, sealevel_pa=101325.0):\n        \"\"\"Calculates the altitude in meters.\"\"\"\n        # Calculation taken straight from section 3.6 of the datasheet.\n        pressure = float(self.read_pressure())\n        altitude = 44330.0 * (1.0 - pow(pressure / sealevel_pa, (1.0/5.255)))\n        self._logger.debug('Altitude {0} m'.format(altitude))\n        return altitude"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the pressure at sealevel when given a known altitude in meters. Returns a value in Pascals.", "response": "def read_sealevel_pressure(self, altitude_m=0.0):\n        \"\"\"Calculates the pressure at sealevel when given a known altitude in\n        meters. Returns a value in Pascals.\"\"\"\n        pressure = float(self.read_pressure())\n        p0 = pressure / pow(1.0 - altitude_m/44330.0, 5.255)\n        self._logger.debug('Sealevel pressure {0} Pa'.format(p0))\n        return p0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login_open_sheet(email, password, spreadsheet):\n\ttry:\n\t\tgc = gspread.login(email, password)\n\t\tworksheet = gc.open(spreadsheet).sheet1\n\t\treturn worksheet\n\texcept:\n\t\tprint 'Unable to login and get spreadsheet.  Check email, password, spreadsheet name.'\n\t\tsys.exit(1)", "response": "Connect to Google Docs spreadsheet and return the first worksheet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_settings_class():\n    if not hasattr(django_settings, \"AUTH_ADFS\"):\n        msg = \"The configuration directive 'AUTH_ADFS' was not found in your Django settings\"\n        raise ImproperlyConfigured(msg)\n    cls = django_settings.AUTH_ADFS.get('SETTINGS_CLASS', DEFAULT_SETTINGS_CLASS)\n    return import_string(cls)", "response": "Get the class name of the AUTH_ADFS setting from the Django settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_authorization_endpoint(self, request, disable_sso=None):\n        self.load_config()\n        redirect_to = request.GET.get(REDIRECT_FIELD_NAME, None)\n        if not redirect_to:\n            redirect_to = django_settings.LOGIN_REDIRECT_URL\n        redirect_to = base64.urlsafe_b64encode(redirect_to.encode()).decode()\n        query = QueryDict(mutable=True)\n        query.update({\n            \"response_type\": \"code\",\n            \"client_id\": settings.CLIENT_ID,\n            \"resource\": settings.RELYING_PARTY_ID,\n            \"redirect_uri\": self.redirect_uri(request),\n            \"state\": redirect_to,\n        })\n        if self._mode == \"openid_connect\":\n            query[\"scope\"] = \"openid\"\n            if (disable_sso is None and settings.DISABLE_SSO) or disable_sso is True:\n                query[\"prompt\"] = \"login\"\n\n        return \"{0}?{1}\".format(self.authorization_endpoint, query.urlencode())", "response": "This function returns the ADFS authorization URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vote(self, request, pk=None):\n        choice = self.get_object()\n        choice.vote()\n        serializer = self.get_serializer(choice)\n        return Response(serializer.data)", "response": "post:\n        A description of the post method on the custom action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the user if it doesn t exist yet", "response": "def create_user(self, claims):\n        \"\"\"\n        Create the user if it doesn't exist yet\n\n        Args:\n            claims (dict): claims from the access token\n\n        Returns:\n            django.contrib.auth.models.User: A Django user\n        \"\"\"\n        # Create the user\n        username_claim = settings.USERNAME_CLAIM\n        usermodel = get_user_model()\n        user, created = usermodel.objects.get_or_create(**{\n            usermodel.USERNAME_FIELD: claims[username_claim]\n        })\n        if created or not user.password:\n            user.set_unusable_password()\n            logger.debug(\"User '{}' has been created.\".format(claims[username_claim]))\n\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate user attributes based on CLAIM_MAPPING setting.", "response": "def update_user_attributes(self, user, claims):\n        \"\"\"\n        Updates user attributes based on the CLAIM_MAPPING setting.\n\n        Args:\n            user (django.contrib.auth.models.User): User model instance\n            claims (dict): claims from the access token\n        \"\"\"\n\n        required_fields = [field.name for field in user._meta.fields if field.blank is False]\n\n        for field, claim in settings.CLAIM_MAPPING.items():\n            if hasattr(user, field):\n                if claim in claims:\n                    setattr(user, field, claims[claim])\n                    logger.debug(\"Attribute '{}' for user '{}' was set to '{}'.\".format(field, user, claims[claim]))\n                else:\n                    if field in required_fields:\n                        msg = \"Claim not found in access token: '{}'. Check ADFS claims mapping.\"\n                        raise ImproperlyConfigured(msg.format(claim))\n                    else:\n                        msg = \"Claim '{}' for user field '{}' was not found in the access token for user '{}'. \" \\\n                              \"Field is not required and will be left empty\".format(claim, field, user)\n                        logger.warning(msg)\n            else:\n                msg = \"User model has no field named '{}'. Check ADFS claims mapping.\"\n                raise ImproperlyConfigured(msg.format(field))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the user s group memberships based on the GROUPS_CLAIM setting.", "response": "def update_user_groups(self, user, claims):\n        \"\"\"\n        Updates user group memberships based on the GROUPS_CLAIM setting.\n\n        Args:\n            user (django.contrib.auth.models.User): User model instance\n            claims (dict): Claims from the access token\n        \"\"\"\n        if settings.GROUPS_CLAIM is not None:\n            # Update the user's group memberships\n            django_groups = [group.name for group in user.groups.all()]\n\n            if settings.GROUPS_CLAIM in claims:\n                claim_groups = claims[settings.GROUPS_CLAIM]\n                if not isinstance(claim_groups, list):\n                    claim_groups = [claim_groups, ]\n            else:\n                logger.debug(\n                    \"The configured groups claim '{}' was not found in the access token\".format(settings.GROUPS_CLAIM))\n                claim_groups = []\n\n            # Make a diff of the user's groups.\n            # Removing a user from all groups and then re-add them would cause\n            # the autoincrement value for the database table storing the\n            # user-to-group mappings to increment for no reason.\n            groups_to_remove = set(django_groups) - set(claim_groups)\n            groups_to_add = set(claim_groups) - set(django_groups)\n\n            # Loop through the groups in the group claim and\n            # add the user to these groups as needed.\n            for group_name in groups_to_remove:\n                group = Group.objects.get(name=group_name)\n                user.groups.remove(group)\n                logger.debug(\"User removed from group '{}'\".format(group_name))\n\n            for group_name in groups_to_add:\n                try:\n                    if settings.MIRROR_GROUPS:\n                        group, _ = Group.objects.get_or_create(name=group_name)\n                        logger.debug(\"Created group '{}'\".format(group_name))\n                    else:\n                        group = Group.objects.get(name=group_name)\n                    user.groups.add(group)\n                    logger.debug(\"User added to group '{}'\".format(group_name))\n                except ObjectDoesNotExist:\n                    # Silently fail for non-existing groups.\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_user_flags(self, user, claims):\n        if settings.GROUPS_CLAIM is not None:\n            if settings.GROUPS_CLAIM in claims:\n                access_token_groups = claims[settings.GROUPS_CLAIM]\n                if not isinstance(access_token_groups, list):\n                    access_token_groups = [access_token_groups, ]\n            else:\n                logger.debug(\"The configured group claim was not found in the access token\")\n                access_token_groups = []\n\n            for flag, group in settings.GROUP_TO_FLAG_MAPPING.items():\n                if hasattr(user, flag):\n                    if group in access_token_groups:\n                        value = True\n                    else:\n                        value = False\n                    setattr(user, flag, value)\n                    logger.debug(\"Attribute '{}' for user '{}' was set to '{}'.\".format(user, flag, value))\n                else:\n                    msg = \"User model has no field named '{}'. Check ADFS boolean claims mapping.\"\n                    raise ImproperlyConfigured(msg.format(flag))\n\n        for field, claim in settings.BOOLEAN_CLAIM_MAPPING.items():\n            if hasattr(user, field):\n                bool_val = False\n                if claim in claims and str(claims[claim]).lower() in ['y', 'yes', 't', 'true', 'on', '1']:\n                    bool_val = True\n                setattr(user, field, bool_val)\n                logger.debug('Attribute \"{}\" for user \"{}\" was set to \"{}\".'.format(user, field, bool_val))\n            else:\n                msg = \"User model has no field named '{}'. Check ADFS boolean claims mapping.\"\n                raise ImproperlyConfigured(msg.format(field))", "response": "Updates the user attributes based on the BOOLEAN_CLAIM_MAPPING setting."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the redirect from ADFS to our site.", "response": "def get(self, request):\n        \"\"\"\n        Handles the redirect from ADFS to our site.\n        We try to process the passed authorization code and login the user.\n\n        Args:\n            request (django.http.request.HttpRequest): A Django Request object\n        \"\"\"\n        code = request.GET.get(\"code\")\n\n        if not code:\n            # Return an error message\n            return render(request, 'django_auth_adfs/login_failed.html', {\n                'error_message': \"No authorization code was provided.\",\n            }, status=400)\n\n        redirect_to = request.GET.get(\"state\")\n\n        user = authenticate(request=request, authorization_code=code)\n\n        if user is not None:\n            if user.is_active:\n                login(request, user)\n                # Redirect to the \"after login\" page.\n                # Because we got redirected from ADFS, we can't know where the\n                # user came from.\n                if redirect_to:\n                    redirect_to = base64.urlsafe_b64decode(redirect_to.encode()).decode()\n                else:\n                    redirect_to = django_settings.LOGIN_REDIRECT_URL\n                url_is_safe = is_safe_url(\n                    url=redirect_to,\n                    allowed_hosts=[request.get_host()],\n                    require_https=request.is_secure(),\n                )\n                redirect_to = redirect_to if url_is_safe else '/'\n                return redirect(redirect_to)\n            else:\n                # Return a 'disabled account' error message\n                return render(request, 'django_auth_adfs/login_failed.html', {\n                    'error_message': \"Your account is disabled.\",\n                }, status=403)\n        else:\n            # Return an 'invalid login' error message\n            return render(request, 'django_auth_adfs/login_failed.html', {\n                'error_message': \"Login failed.\",\n            }, status=401)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authenticate(self, request):\n        auth = get_authorization_header(request).split()\n\n        if not auth or auth[0].lower() != b'bearer':\n            return None\n\n        if len(auth) == 1:\n            msg = 'Invalid authorization header. No credentials provided.'\n            raise exceptions.AuthenticationFailed(msg)\n        elif len(auth) > 2:\n            msg = 'Invalid authorization header. Access token should not contain spaces.'\n            raise exceptions.AuthenticationFailed(msg)\n\n        # Authenticate the user\n        # The AdfsAuthCodeBackend authentication backend will notice the \"access_token\" parameter\n        # and skip the request for an access token using the authorization code\n        user = authenticate(access_token=auth[1])\n\n        if user is None:\n            raise exceptions.AuthenticationFailed('Invalid access token.')\n\n        if not user.is_active:\n            raise exceptions.AuthenticationFailed('User inactive or deleted.')\n\n        return user, auth[1]", "response": "Authenticate the user using the authorization code provided in the request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef molecular_orbital(coords, mocoeffs, gbasis):\n    '''Return a molecular orbital given the nuclei coordinates, as well as\n       molecular orbital coefficients and basis set specification as given by the cclib library.\n\n       The molecular orbital is represented as a function that takes x, y, z coordinates (in a vectorized fashion)\n       and returns a real number.\n\n    '''\n    \n    # Making a closure\n    def f(x, y, z, coords=coords, mocoeffs=mocoeffs, gbasis=gbasis):\n        # The other functions take nanometers\n        return sum(c * bf(x * 10, y*10, z*10) for c, bf in zip(mocoeffs, getbfs(coords * 10, gbasis)))\n\n    return f", "response": "Return a molecular orbital given the nuclei coordinates as well as a molecular orbital coefficients and basis set specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef V(a,b,C):\n    if b.contracted:\n        return sum(cb*V(pb,a,C) for (cb,pb) in b)\n    elif a.contracted:\n        return sum(ca*V(b,pa,C) for (ca,pa) in a)\n    return a.norm*b.norm*nuclear_attraction(a.exponent,a.powers,a.origin,\n                                            b.exponent,b.powers,b.origin,C)", "response": "Simple interface to the nuclear attraction function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef overlap(alpha1,lmn1,A,alpha2,lmn2,B):\n    l1,m1,n1 = lmn1\n    l2,m2,n2 = lmn2\n    rab2 = norm2(A-B)\n    gamma = alpha1+alpha2\n    P = gaussian_product_center(alpha1,A,alpha2,B)\n\n    pre = pow(pi/gamma,1.5)*exp(-alpha1*alpha2*rab2/gamma)\n\n    wx = overlap1d(l1,l2,P[0]-A[0],P[0]-B[0],gamma)\n    wy = overlap1d(m1,m2,P[1]-A[1],P[1]-B[1],gamma)\n    wz = overlap1d(n1,n2,P[2]-A[2],P[2]-B[2],gamma)\n    return pre*wx*wy*wz", "response": "Returns the integral of the overlap integral."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of components that overlap l1 and l2.", "response": "def overlap1d(l1,l2,PAx,PBx,gamma):\n    \"\"\"\n    The one-dimensional component of the overlap integral. Taken from THO eq. 2.12\n    >>> isclose(overlap1d(0,0,0,0,1),1.0)\n    True\n    \"\"\"\n    total = 0\n    for i in range(1+int(floor(0.5*(l1+l2)))):\n        total += binomial_prefactor(2*i,l1,l2,PAx,PBx)* \\\n                 fact2(2*i-1)/pow(2*gamma,i)\n    return total"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gaussian_product_center(alpha1,A,alpha2,B):\n    return (alpha1*A+alpha2*B)/(alpha1+alpha2)", "response": "Returns the center of the Gaussian resulting from the product of two Gaussians."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef binomial_prefactor(s,ia,ib,xpa,xpb):\n    total= 0\n    for t in range(s+1):\n        if s-ia <= t <= ib:\n            total +=  binomial(ia,s-t)*binomial(ib,t)* \\\n                     pow(xpa,ia-s+t)*pow(xpb,ib-t)\n    return total", "response": "Returns the integral prefactor of the given integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the full form of the kinetic energy integral", "response": "def kinetic(alpha1,lmn1,A,alpha2,lmn2,B):\n    \"\"\"\n    The full form of the kinetic energy integral\n    >>> isclose(kinetic(1,(0,0,0),array((0,0,0),'d'),1,(0,0,0),array((0,0,0),'d')),2.953052)\n    True\n    \"\"\"\n    l1,m1,n1 = lmn1\n    l2,m2,n2 = lmn2\n    term0 = alpha2*(2*(l2+m2+n2)+3)*\\\n            overlap(alpha1,(l1,m1,n1),A,\\\n                           alpha2,(l2,m2,n2),B)\n    term1 = -2*pow(alpha2,2)*\\\n            (overlap(alpha1,(l1,m1,n1),A,\n                            alpha2,(l2+2,m2,n2),B)\n             + overlap(alpha1,(l1,m1,n1),A,\n                              alpha2,(l2,m2+2,n2),B)\n             + overlap(alpha1,(l1,m1,n1),A,\n                              alpha2,(l2,m2,n2+2),B))\n    term2 = -0.5*(l2*(l2-1)*overlap(alpha1,(l1,m1,n1),A,\n                                           alpha2,(l2-2,m2,n2),B) +\n                  m2*(m2-1)*overlap(alpha1,(l1,m1,n1),A,\n                                           alpha2,(l2,m2-2,n2),B) +\n                  n2*(n2-1)*overlap(alpha1,(l1,m1,n1),A,\n                                           alpha2,(l2,m2,n2-2),B))\n    return term0+term1+term2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nuclear_attraction(alpha1,lmn1,A,alpha2,lmn2,B,C):\n    l1,m1,n1 = lmn1\n    l2,m2,n2 = lmn2\n    gamma = alpha1+alpha2\n\n    P = gaussian_product_center(alpha1,A,alpha2,B)\n    rab2 = norm2(A-B)\n    rcp2 = norm2(C-P)\n\n    dPA = P-A\n    dPB = P-B\n    dPC = P-C\n\n    Ax = A_array(l1,l2,dPA[0],dPB[0],dPC[0],gamma)\n    Ay = A_array(m1,m2,dPA[1],dPB[1],dPC[1],gamma)\n    Az = A_array(n1,n2,dPA[2],dPB[2],dPC[2],gamma)\n\n    total = 0.\n    for I in range(l1+l2+1):\n        for J in range(m1+m2+1):\n            for K in range(n1+n2+1):\n                total += Ax[I]*Ay[J]*Az[K]*Fgamma(I+J+K,rcp2*gamma)\n                \n    val= -2*pi/gamma*exp(-alpha1*alpha2*rab2/gamma)*total\n    return val", "response": "Return the nuclear attraction integral for a given set of alpha1 and alpha2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef A_term(i,r,u,l1,l2,PAx,PBx,CPx,gamma):\n    return pow(-1,i)*binomial_prefactor(i,l1,l2,PAx,PBx)*\\\n           pow(-1,u)*factorial(i)*pow(CPx,i-2*r-2*u)*\\\n           pow(0.25/gamma,r+u)/factorial(r)/factorial(u)/factorial(i-2*r-2*u)", "response": "A term in the A - term basis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef A_array(l1,l2,PA,PB,CP,g):\n    Imax = l1+l2+1\n    A = [0]*Imax\n    for i in range(Imax):\n        for r in range(int(floor(i/2)+1)):\n            for u in range(int(floor((i-2*r)/2)+1)):\n                I = i-2*r-u\n                A[I] = A[I] + A_term(i,r,u,l1,l2,PA,PB,CP,g)\n    return A", "response": "A function that returns an array of all the A terms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating basis function on a mesh of points xyzs.", "response": "def mesh(self,xyzs):\n        \"\"\"\n        Evaluate basis function on a mesh of points *xyz*.\n        \"\"\"\n        I,J,K = self.powers\n        d = np.asarray(xyzs,'d')-self.origin\n        # Got help from stackoverflow user @unutbu with this.\n        # See: http://stackoverflow.com/questions/17391052/compute-square-distances-from-numpy-array\n        d2 = np.einsum('ij,ij -> i',d,d)\n        return self.norm*d[:,0]**I*d[:,1]**J*d[:,2]**K*np.exp(-self.exponent*d2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _normalize(self):\n        \"Normalize basis function. From THO eq. 2.2\"\n        l,m,n = self.powers\n        self.norm = np.sqrt(pow(2,2*(l+m+n)+1.5)*\n                            pow(self.exponent,l+m+n+1.5)/\n                            fact2(2*l-1)/fact2(2*m-1)/\n                            fact2(2*n-1)/pow(np.pi,1.5))\n        return", "response": "Normalize basis function. From THO eq. 2. 2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a selection in this representation. BallAndStickRenderer support selections of atoms and bonds.", "response": "def select(self, selections):\n        '''Make a selection in this\n        representation. BallAndStickRenderer support selections of\n        atoms and bonds.\n        \n        To select the first atom and the first bond you can use the\n        following code::\n        \n            from chemlab.mviewer.state import Selection        \n            representation.select({'atoms': Selection([0], system.n_atoms),\n                                   'bonds': Selection([0], system.n_bonds)})\n\n        Returns the current Selection\n        '''\n        if 'atoms' in selections:\n            self.selection_state['atoms'] = selections['atoms']\n            self.on_atom_selection_changed()\n\n        if 'bonds' in selections:\n            self.selection_state['bonds'] = selections['bonds']\n            self.on_bond_selection_changed()\n\n        if 'box' in selections:\n            self.selection_state['box'] = selections['box']\n\n        return self.selection_state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhide objects in this representation. BallAndStickRepresentation support selections of atoms and bonds.", "response": "def hide(self, selections):\n        '''Hide objects in this representation. BallAndStickRepresentation\n        support selections of atoms and bonds.\n\n        To hide the first atom and the first bond you can use the\n        following code::\n\n            from chemlab.mviewer.state import Selection\n            representation.hide({'atoms': Selection([0], system.n_atoms),\n                                   'bonds': Selection([0], system.n_bonds)})\n\n        Returns the current Selection of hidden atoms and bonds.\n\n        '''\n        if 'atoms' in selections:\n            self.hidden_state['atoms'] = selections['atoms']\n            self.on_atom_hidden_changed()\n\n        if 'bonds' in selections:\n            self.hidden_state['bonds'] = selections['bonds']\n            self.on_bond_hidden_changed()\n\n        if 'box' in selections:\n            self.hidden_state['box'] = box_s = selections['box']\n            if box_s.mask[0]:\n                if self.viewer.has_renderer(self.box_renderer):\n                    self.viewer.remove_renderer(self.box_renderer)\n            else:\n                if not self.viewer.has_renderer(self.box_renderer):\n                    self.viewer.add_renderer(self.box_renderer)\n\n        return self.hidden_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscales the objects represented by selections up to a specific factor.", "response": "def scale(self, selections, factor):\n        '''Scale the objects represented by *selections* up to a\n        certain *factor*.\n\n        '''\n        if 'atoms' in selections:\n            atms = selections['atoms'].mask\n            if factor is None:\n                    self.scale_factors[atms] = 1.0\n            else:\n                self.scale_factors[atms] = factor\n    \n        self.update_scale_factors(self.scale_factors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the radius of each atom by a certain value", "response": "def change_radius(self, selections, value):\n        '''Change the radius of each atom by a certain value\n        \n        '''\n        if 'atoms' in selections:\n            atms = selections['atoms'].mask\n            if value is None:\n                self.radii_state.array[atms] = [vdw_radii.get(t) * 0.3  for t in self.system.type_array[atms]]\n            else:\n                self.radii_state.array[atms] = value\n    \n        self.update_scale_factors(self.scale_factors)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_color(self, selections, value):\n        '''Change the color of each atom by a certain value. *value*\n        should be a tuple.\n\n        '''\n        if 'atoms' in selections:\n            atms = selections['atoms'].mask\n            if value is None:\n                #self.radii_state.array[atms] = [vdw_radii.get(t) * 0.3  for t in self.system.type_array[atms]]\n                self.atom_colors.array[atms, 0:3] = [self.color_scheme.get(t, colors.deep_pink)[0:3]\n                                                     for t in self.system.type_array[atms]]\n            else:\n                self.atom_colors.array[atms, 0:3] = value[0:3]\n    \n        self.atom_renderer.update_colors(self.atom_colors.array)\n        self.on_atom_colors_changed()", "response": "Change the color of each atom in the system by a certain value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning called every time a frame is drawn", "response": "def paintGL(self):\n        '''GL function called each time a frame is drawn'''\n\n        if self.post_processing:\n            # Render to the first framebuffer\n            glBindFramebuffer(GL_FRAMEBUFFER, self.fb0)\n            glViewport(0, 0, self.width(), self.height())\n\n            status = glCheckFramebufferStatus(GL_FRAMEBUFFER)\n            if (status != GL_FRAMEBUFFER_COMPLETE):\n                reason = dict(GL_FRAMEBUFFER_UNDEFINED='UNDEFINED',\n                              GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT='INCOMPLETE_ATTACHMENT',\n                              GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT='INCOMPLETE_MISSING_ATTACHMENT',\n                              GL_FRAMEBUFFER_INCOMPLETE_DRAW_BUFFER='INCOMPLETE_DRAW_BUFFER',\n                              GL_FRAMEBUFFER_INCOMPLETE_READ_BUFFER='INCOMPLETE_READ_BUFFER',\n                              GL_FRAMEBUFFER_UNSUPPORTED='UNSUPPORTED',\n                          )[status]\n\n                raise Exception('Framebuffer is not complete: {}'.format(reason))\n        else:\n            glBindFramebuffer(GL_FRAMEBUFFER, DEFAULT_FRAMEBUFFER)\n\n\n        # Clear color take floats\n        bg_r, bg_g, bg_b, bg_a = self.background_color\n        glClearColor(bg_r/255, bg_g/255, bg_b/255, bg_a/255)\n        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n\n        proj = self.camera.projection\n        cam = self.camera.matrix\n\n        self.mvproj = np.dot(proj, cam)\n\n        self.ldir = cam[:3, :3].T.dot(self.light_dir)\n\n\n\n        # Draw World\n        self.on_draw_world()\n\n        # Iterate over all of the post processing effects\n        if self.post_processing:\n            if len(self.post_processing) > 1:\n                newarg = self.textures.copy()\n\n                # Ping-pong framebuffer rendering\n                for i, pp in enumerate(self.post_processing[:-1]):\n                    if i % 2:\n                        outfb = self.fb1\n                        outtex = self._extra_textures['fb1']\n                    else:\n                        outfb = self.fb2\n                        outtex = self._extra_textures['fb2']\n\n                    pp.render(outfb, newarg)\n\n                    newarg['color'] = outtex\n\n                self.post_processing[-1].render(DEFAULT_FRAMEBUFFER, newarg)\n\n            else:\n                self.post_processing[0].render(DEFAULT_FRAMEBUFFER, self.textures)\n\n        # Draw the UI at the very last step\n        self.on_draw_ui()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toimage(self, width=None, height=None):\n        '''Return the current scene as a PIL Image.\n\n        **Example**\n\n        You can build your molecular viewer as usual and dump an image\n        at any resolution supported by the video card (up to the\n        memory limits)::\n\n            v = QtViewer()\n\n            # Add the renderers\n            v.add_renderer(...)\n\n            # Add post processing effects\n            v.add_post_processing(...)\n\n            # Move the camera\n            v.widget.camera.autozoom(...)\n            v.widget.camera.orbit_x(...)\n            v.widget.camera.orbit_y(...)\n\n            # Save the image\n            image = v.widget.toimage(1024, 768)\n            image.save(\"mol.png\")\n\n\n        .. seealso::\n\n            https://pillow.readthedocs.org/en/latest/PIL.html#module-PIL.Image\n\n        '''\n        from .postprocessing import NoEffect\n        effect = NoEffect(self)\n\n        self.post_processing.append(effect)\n\n        oldwidth, oldheight = self.width(), self.height()\n\n        #self.initializeGL()\n\n        if None not in (width, height):\n            self.resize(width, height)\n            self.resizeGL(width, height)\n        else:\n            width = self.width()\n            height = self.height()\n\n        self.paintGL()\n        self.post_processing.remove(effect)\n        coltex = effect.texture\n        coltex.bind()\n        glActiveTexture(GL_TEXTURE0)\n        data = glGetTexImage(GL_TEXTURE_2D, 0, GL_RGBA, GL_UNSIGNED_BYTE)\n        image = pil_Image.frombuffer('RGBA', (width, height), data, 'raw', 'RGBA', 0, -1)\n\n        #self.resize(oldwidth, oldheight)\n        #self.resizeGL(oldwidth, oldheight)\n\n        return image", "response": "Return the current scene as a PIL Image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse Stewarts STO-6G fits to create a contracted Gaussian approximation to a Slater function. Fits of other expansion lengths (1G, 3G, etc) are in the paper. Reference: RF Stewart, JCP 52, 431 (1970) >>> s = sto(1) >>> np.isclose(s(0,0,0),0.530121) True", "response": "def sto(zeta,N=1,L=0,M=0,origin=(0,0,0)):\n    \"\"\"\n    Use Stewarts STO-6G fits to create a contracted Gaussian approximation to a\n    Slater function. Fits of other expansion lengths (1G, 3G, etc) are in the paper.\n\n    Reference: RF Stewart, JCP 52, 431 (1970)\n\n    >>> s = sto(1)\n    >>> np.isclose(s(0,0,0),0.530121)\n    True\n    \"\"\"\n    nlm2powers = {\n        (1,0,0) : (0,0,0,0),   # x,y,z,r\n        (2,0,0) : (0,0,0,1),\n        (3,0,0) : (0,0,0,2),\n        (2,1,0) : (1,0,0,0),\n        (2,1,1) : (0,1,0,0),\n        (2,1,-1) : (0,0,1,0),\n        (3,1,0) : (1,0,0,1),\n        (3,1,1) : (0,1,0,1),\n        (3,1,-1) : (0,0,1,1)\n        }\n\n    gexps_1s = [2.310303149e01,4.235915534e00,1.185056519e00,\n                4.070988982e-01,1.580884151e-01,6.510953954e-02]\n    gcoefs_1s = [9.163596280e-03,4.936149294e-02,1.685383049e-01,\n                 3.705627997e-01,4.164915298e-01,1.303340841e-01]\n    \n    gexps_2s = [2.768496241e01,5.077140627e00,1.426786050e00,\n                2.040335729e-01,9.260298399e-02,4.416183978e-02]\n    gcoefs_2s = [-4.151277819e-03,-2.067024148e-02,-5.150303337e-02,\n                 3.346271174e-01,5.621061301e-01,1.712994697e-01]\n    \n    gexps_2p = [5.868285913e00,1.530329631e00,5.475665231e-01,\n                2.288932733e-01,1.046655969e-01,4.948220127e-02]\n    gcoefs_2p = [7.924233646e-03,5.144104825e-02,1.898400060e-01,\n                 4.049863191e-01,4.012362861e-01,1.051855189e-01]\n    \n    gexps_3s = [3.273031938e00,9.200611311e-01,3.593349765e-01,\n                8.636686991e-02,4.797373812e-02,2.724741144e-02]\n    gcoefs_3s = [-6.775596947e-03,-5.639325779e-02,-1.587856086e-01,\n                 5.534527651e-01,5.015351020e-01,7.223633674e-02]\n    \n    gexps_3p = [5.077973607e00,1.340786940e00,2.248434849e-01,\n                1.131741848e-01,6.076408893e-02,3.315424265e-02]\n    gcoefs_3p = [-3.329929840e-03,-1.419488340e-02,1.639395770e-01,\n                 4.485358256e-01,3.908813050e-01,7.411456232e-02]\n    gexps_3d = [2.488296923,7.981487853e-1,3.311327490e-1,\n                1.559114463e-1,7.877734732e-2,4.058484363e-2]\n    gcoefs_3d = [7.283828112e-3,5.386799363e-2,2.072139149e-1,\n                 4.266269092e-1,3.843100204e-1,8.902827546e-2]\n    \n    gexps_4s = [3.232838646,3.605788802e-1,1.717902487e-1,\n                5.277666487e-2,3.163400284e-2,1.874093091e-2]\n    gcoefs_4s = [1.374817488e-3,-8.666390043e-2,-3.130627309e-1,\n                 7.812787397e-1,4.389247988-1,2.487178756e-2]\n    gexps_4p = [2.389722618, 7.960947826e-1,3.415541380e-1,\n                8.847434525e-2,4.958248334e-2,2.816929784e-2]\n    gcoefs_4p = [-1.665913575e-3,-1.657464971e-2,-5.958513378e-2,\n                 4.053115554e-1,5.433958189e-1,1.20970491e-1]\n    \n    gexps = { # indexed by N,s_or_p:\n        (1,0) : gexps_1s,\n        (2,0) : gexps_2s,\n        (2,1) : gexps_2p,\n        (3,0) : gexps_3s,\n        (3,1) : gexps_3p\n        }\n\n    gcoefs = {  # indexed by N,s_or_p:\n        (1,0) : gcoefs_1s,\n        (2,0) : gcoefs_2s,\n        (2,1) : gcoefs_2p,\n        (3,0) : gcoefs_3s,\n        (3,1) : gcoefs_3p\n        }\n\n    I,J,K,R = nlm2powers[(N,L,M)]\n    exps = [zeta**2*expn for expn in gexps[(N,L)]]\n    coefs = gcoefs[N,L]\n    return cgbf(origin,(I,J,K),exps,coefs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating basis function on a mesh of points xyzs.", "response": "def mesh(self,xyzs):\n        \"\"\"\n        Evaluate basis function on a mesh of points *xyz*.\n        \"\"\"\n        return sum(c*p.mesh(xyzs) for c,p in self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating ewald real part of ewald.", "response": "def _real(coords1, charges1, coords2, charges2, rcut, alpha, box):\n    \"\"\"Calculate ewald real part. Box has to be a cuboidal box you should\n    transform any other box shape to a cuboidal box before using this.\n    \n    \"\"\"\n    n = coords1.shape[0]\n    m = coords2.shape[0]\n    # Unit vectors\n    a = box[0]\n    b = box[1]\n    c = box[2]\n    \n    \n    # This is helpful to add the correct number of boxes\n    l_max = int(np.ceil(2.0 * rcut / np.min(np.trace(box))))\n    result = np.zeros(n)\n    \n    \n    for i in range(n):\n        q_i = charges1[i]\n        r_i = coords1[i]\n\n        for j in range(m):\n            q_j = charges2[j]\n            r_j = coords2[j]\n\n            for l_i in range(-l_max, l_max + 1):\n                for l_j in range(-l_max, l_max + 1):\n                    for l_k in range(-l_max, l_max + 1):\n                        nv = l_i * a + l_j * b + l_k * c\n                        r_j_n = r_j + nv\n                        \n                        r_ij = _dist(r_i, r_j_n)\n                        if r_ij < 1e-10 or r_ij > rcut:\n                            continue\n                        value = q_i * q_j * math.erfc(alpha * r_ij) / r_ij\n                        result[i] += value\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reciprocal(coords1, charges1, coords2, charges2, kmax, kappa, box):\n    n = coords1.shape[0]\n    m = coords2.shape[0]\n    result = np.zeros(n, dtype=np.float64)\n    need_self = np.zeros(n, dtype=np.uint8)\n\n    # Reciprocal unit vectors\n    g1, g2, g3 = reciprocal_vectors(box)\n    \n    V = box_volume(box)\n    \n    prefac = 1.0 / (np.pi * V)\n    for i in range(n):\n        q_i = charges1[i]\n        r_i = coords1[i]\n        \n        for j in range(m):\n            q_j = charges2[j]\n            r_j = coords2[j]\n            \n            r_ij = _dist(r_i, r_j)\n            if r_ij < 1e-10:\n                need_self[i] = 1\n        \n            for k_i in range(-kmax, kmax + 1):\n                for k_j in range(-kmax, kmax + 1):\n                    for k_k in range(-kmax, kmax + 1):\n                        if k_i == 0 and k_j == 0 and k_k == 0:\n                            continue\n                        # Reciprocal vector\n                        k = k_i * g1 + k_j * g2 + k_k * g3\n                        \n                        k_sq = sqsum(k)\n                        \n                        result[i] += (prefac * q_i * q_j *\n                                      4.0 * np.pi ** 2 / k_sq *\n                                      math.exp(-k_sq / (4.0 * kappa ** 2)) *\n                                      math.cos(np.dot(k, r_i - r_j)))\n        \n    # Self-energy correction\n    # I had to do some FUCKED UP stuff because NUMBA SUCKS BALLS and \n    # breaks compatibility with simple expressions such as that one\n    # apparently doing result -= something is too hard in numba\n    self_energy = 2 * (need_self * kappa * charges1 ** 2) / (np.pi**0.5)\n    return result - self_energy", "response": "Calculate ewald reciprocal part of a cuboidal box."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating cylinders start and end positions", "response": "def update_bounds(self, bounds):\n        '''Update cylinders start and end positions\n\n        '''\n        starts =  bounds[:,0,:]\n        ends = bounds[:,1,:]\n\n        self.bounds = bounds\n        self.lengths =  np.sqrt(((ends - starts)**2).sum(axis=1))\n        \n        vertices, normals, colors = self._process_reference()\n        \n        self.tr.update_vertices(vertices)\n        self.tr.update_normals(normals)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncompiling a shader source of given type returning a GLuint compiled shader reference", "response": "def compileShader( source, shaderType ):\n    \"\"\"Compile shader source of given type\n    \n    source -- GLSL source-code for the shader\n    shaderType -- GLenum GL_VERTEX_SHADER, GL_FRAGMENT_SHADER, etc,\n    \n    returns GLuint compiled shader reference\n    raises RuntimeError when a compilation failure occurs\n    \"\"\"\n    if isinstance(source, str):\n        source = [source]\n    elif isinstance(source, bytes):\n        source = [source.decode('utf-8')]\n    \n    shader = glCreateShader(shaderType)\n    glShaderSource(shader, source)\n    glCompileShader(shader)\n    result = glGetShaderiv(shader, GL_COMPILE_STATUS)\n    \n    if not(result):\n        # TODO: this will be wrong if the user has \n        # disabled traditional unpacking array support.\n        raise RuntimeError(\n            \"\"\"Shader compile failure (%s): %s\"\"\"%(\n                result,\n                glGetShaderInfoLog( shader ),\n            ),\n            source,\n            shaderType,\n        )\n    return shader"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_key(self, key):\n        k = self._lowerOrReturn(key)\n        return k in self.data", "response": "Case insensitive test whether key exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, dict):\n        for k,v in dict.items():\n            self[k] = v", "response": "Copy ( key value pairs from dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the sphere positions.", "response": "def update_positions(self, positions):\n        '''Update the sphere positions.\n        '''\n        sphs_verts = self.sphs_verts_radii.copy()\n        sphs_verts += positions.reshape(self.n_spheres, 1, 3)\n\n        self.tr.update_vertices(sphs_verts)\n        self.poslist = positions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_ball_point(self, x, r, p=2., eps=0):\n        x = np.asarray(x).astype(np.float)\n        if x.shape[-1] != self.m:\n            raise ValueError(\"Searching for a %d-dimensional point in a \" \\\n                             \"%d-dimensional KDTree\" % (x.shape[-1], self.m))\n        if len(x.shape) == 1:\n            return self.__query_ball_point(x, r, p, eps)\n        else:\n            retshape = x.shape[:-1]\n            result = np.empty(retshape, dtype=np.object)\n            for c in np.ndindex(retshape):\n                result[c] = self.__query_ball_point(x[c], r, p, eps)\n            return result", "response": "This method searches for all points within distance r of point x and returns a list of lists of neighbors of the nearest point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_molecule(mol, style='ball-and-stick'):\n    '''Display the molecule *mol* with the default viewer.\n\n    '''\n    v = QtViewer()\n\n    \n    if style == 'ball-and-stick':\n        bs = v.add_renderer(BallAndStickRenderer,\n                            mol.r_array,\n                            mol.type_array,\n                            mol.bonds)\n    elif style == 'vdw':\n        sr = v.add_renderer(AtomRenderer, mol.r_array, mol.type_array,\n                            backend='impostors')\n    else:\n        raise Exception(\"Rendering style unknown\")\n    \n    v.widget.camera.autozoom(mol.r_array)\n    v.run()", "response": "Display the molecule *mol* with the default viewer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef display_system(sys, style='vdw'):\n    '''Display the system *sys* with the default viewer.\n\n    '''\n    \n    v = QtViewer()\n\n    #v.add_post_processing(FXAAEffect)\n    v.add_post_processing(SSAOEffect)    \n    \n    if style == 'vdw':\n        sr = v.add_renderer(AtomRenderer, sys.r_array, sys.type_array,\n                            backend='impostors')\n    if style == 'ball-and-stick':\n        sr = v.add_renderer(BallAndStickRenderer,\n                            sys.r_array,\n                            sys.type_array,\n                            sys.bonds)\n    \n    if sys.box_vectors is not None:\n        v.add_renderer(BoxRenderer, sys.box_vectors)\n        \n        # We autozoom on the box\n        a, b, c = sys.box_vectors\n        box_vertices = np.array([[0.0, 0.0, 0.0],\n                                 a, b, c,\n                                 a + b, a + c, b + c,\n                                 a + b + c])\n        v.widget.camera.autozoom(box_vertices)\n    else:\n        v.widget.camera.autozoom(sys.r_array)\n    \n    v.run()", "response": "Display the system sys with the default viewer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay the system sys and instrument the trajectory viewer with frames information.", "response": "def display_trajectory(sys, times, coords_list, box_vectors=None,\n                       style='spheres'):\n    '''Display the the system *sys* and instrument the trajectory\n    viewer with frames information.\n    \n    .. image:: /_static/display_trajectory.png\n    \n    **Parameters**\n\n    sys: :py:class:`~chemlab.core.System`\n        The system to be displayed\n    times: np.ndarray(NFRAMES, dtype=float)\n        The time corresponding to each frame. This is used\n        only for feedback reasons.\n    coords_list: list of np.ndarray((NFRAMES, 3), dtype=float)\n        Atomic coordinates at each frame.\n    \n    '''\n    \n    v = QtTrajectoryViewer()\n    \n    v.add_post_processing(SSAOEffect)\n    v.add_post_processing(FXAAEffect)\n    v.add_post_processing(GammaCorrectionEffect, 1.60)\n    \n    if style == 'spheres':\n        backend = 'impostors'\n    elif style == 'points':\n        backend = 'points'\n    else:\n        raise Exception(\"No such style\")\n        \n    sr = v.add_renderer(AtomRenderer, sys.r_array, sys.type_array,\n                        backend=backend)\n\n    \n    if sys.box_vectors is not None:\n        br = v.add_renderer(BoxRenderer, sys.box_vectors)\n        # We autozoom on the box\n        a, b, c = sys.box_vectors\n        box_vertices = np.array([[0.0, 0.0, 0.0],\n                                 a, b, c,\n                                 a + b, a + c, b + c,\n                                 a + b + c])\n        v.widget.camera.autozoom(box_vertices)\n    else:\n        v.widget.camera.autozoom(sys.r_array)\n\n    \n    v.set_ticks(len(coords_list))\n    @v.update_function\n    def on_update(index):\n        sr.update_positions(coords_list[index])\n        if box_vectors is not None:\n            br.update(box_vectors[index])\n        v.set_text(format_time(times[index]))\n        v.widget.repaint()\n\n    v.run()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_colors(self, colors):\n        \n        colors = np.array(colors, dtype=np.uint8)\n        self._vbo_c.set_data(colors)\n        self._vbo_c.unbind()", "response": "Update the colors of the current log entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trajectory(start=None, stop=None, step=None):\n    '''Useful command to iterate on the trajectory frames by time (in\n    ns). It is meant to be used in a for loop::\n\n        for i in trajectory(0, 10, 0.1):\n            coords = current_frame()\n            t = current_time()\n            # Do something\n\n    The previous snippet will stop at every frame from 0 to 10 ns with\n    a step of 0.1 ns.\n\n    '''\n    import numpy as np\n    from PyQt4 import QtGui\n\n    times = np.array(current_frame_times()) / 1000\n\n    if start is None:\n        start = 0\n\n    if stop is None:\n        stop = times[-1]\n\n    start = times.searchsorted(start)\n    stop = times.searchsorted(stop)\n\n    nsteps = (times[stop] - times[start])/(step)\n    step = int((stop - start)/nsteps) or 1\n\n    sl = slice(start, stop, step)\n    for i in range(*sl.indices(current_nframes())):\n        viewer.traj_controls.goto_frame(i)\n        yield i\n        QtGui.qApp.processEvents()", "response": "Yields the trajectory frames by time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frames(skip=1):\n    '''Useful command to iterate on the trajectory frames. It can be\n    used in a for loop.\n\n    ::\n    \n        for i in frames():\n            coords = current_trajectory()[i]\n            # Do operation on coords\n\n    You can use the option *skip* to take every i :sup:`th` frame.\n    \n    '''\n    from PyQt4 import QtGui\n    \n    for i in range(0, viewer.traj_controls.max_index, skip):\n        viewer.traj_controls.goto_frame(i)\n        yield i\n        QtGui.qApp.processEvents()", "response": "Yields the trajectory frames."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_system(system, autozoom=True):\n    '''Display a `~chemlab.core.System` instance at screen'''\n    viewer.clear()\n    viewer.add_representation(BallAndStickRepresentation, system)\n\n    if autozoom:\n        autozoom_()\n    \n    viewer.update()\n    msg(str(system))", "response": "Display a ~chemlab. core. System instance at screen"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_molecule(mol, autozoom=True):\n    '''Display a `~chemlab.core.Molecule` instance in the viewer.\n\n    This function wraps the molecule in a system before displaying\n    it.\n\n    '''\n    s = System([mol])\n    display_system(s, autozoom=True)", "response": "Display a ~chemlab. core. molecule instance in the viewer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_molecule(name, format=None):\n    '''Read a `~chemlab.core.Molecule` from a file.\n\n    .. seealso:: `chemlab.io.datafile`\n    \n    '''    \n    mol = datafile(name, format=format).read('molecule')\n    display_system(System([mol]))", "response": "Read a ~chemlab. core. molecule from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a trajectory file from a remote location specified by url.", "response": "def load_remote_trajectory(url, format=None):\n    '''Load a trajectory file from a remote location specified by *url*.\n\n    .. seealso:: load_remote_system\n    \n    '''\n    from urllib import urlretrieve\n    filename, headers = urlretrieve(url)\n    load_trajectory(filename, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the system currently displayed to a file.", "response": "def write_system(filename, format=None):\n    '''Write the system currently displayed to a file.'''\n    datafile(filename, format=format, mode='w').write('system',\n                                                      current_system())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the system displayed in a file as a molecule.", "response": "def write_molecule(filename, format=None):\n    '''Write the system displayed in a file as a molecule.'''\n    datafile(filename, format=format,\n             mode='w').write('molecule',current_system())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef goto_time(timeval):\n    '''Go to a specific time (in nanoseconds) in the current\n    trajectory.\n\n    '''\n    i = bisect.bisect(viewer.frame_times, timeval * 1000)\n    goto_frame(i)", "response": "Go to a specific time in the current\n    trajectory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a trajectory file into chemlab.", "response": "def load_trajectory(name, skip=1, format=None):\n    '''Load a trajectory file into chemlab. You should call this\n    command after you load a `~chemlab.core.System` through\n    load_system or load_remote_system.\n\n    '''\n    df = datafile(name, format=format)\n    dt, coords = df.read('trajectory', skip=skip)\n    boxes = df.read('boxes')\n    viewer.current_traj = coords\n    viewer.frame_times = dt\n    \n    viewer.traj_controls.set_ticks(len(dt))\n    \n    def update(index):\n        \n        f = coords[index]        \n        \n        for fp in _frame_processors:\n            f = fp(coords, index)\n\n        # update the current representation\n        viewer.representation.update_positions(f)\n        viewer.representation.update_box(boxes[index])\n        current_system().r_array = f\n        current_system().box_vectors = boxes[index]\n        viewer.traj_controls.set_time(dt[index])\n        viewer.update()\n    \n    viewer.traj_controls.show()\n    viewer.traj_controls.frame_changed.connect(update)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_systems(sysa, sysb, bounding=0.2):\n    '''Generate a system by merging *sysa* and *sysb*.\n\n    Overlapping molecules are removed by cutting the molecules of\n    *sysa* that have atoms near the atoms of *sysb*. The cutoff distance\n    is defined by the *bounding* parameter.\n\n    **Parameters**\n\n    sysa: System\n       First system\n    sysb: System\n       Second system\n    bounding: float or False\n       Extra space used when cutting molecules in *sysa* to make space\n       for *sysb*. If it is False, no overlap handling will be performed.\n\n    '''\n\n    if bounding is not False:\n        # Delete overlaps.\n        if sysa.box_vectors is not None:\n            periodicity = sysa.box_vectors.diagonal()\n        else:\n            periodicity = False\n\n        p = overlapping_points(sysb.r_array, sysa.r_array,\n                               cutoff=bounding, periodic=periodicity)\n\n        sel = np.ones(len(sysa.r_array), dtype=np.bool)\n        sel[p] = False\n\n        # Rebuild sysa without water molecules\n        sysa = subsystem_from_atoms(sysa, sel)\n    \n    sysres = System.empty(sysa.n_mol + sysb.n_mol, sysa.n_atoms + sysb.n_atoms)\n    \n    # Assign the attributes\n    for attr in type(sysa).attributes:\n        attr.assign(sysres,\n                    attr.concatenate(sysa, sysb))\n    \n    # edit the mol_indices and n_mol\n    offset = sysa.mol_indices[-1] + sysa.mol_n_atoms[-1]\n    sysres.mol_indices[0:sysa.n_mol] = sysa.mol_indices.copy()\n    sysres.mol_indices[sysa.n_mol:] = sysb.mol_indices.copy() + offset\n    sysres.mol_n_atoms = np.concatenate([sysa.mol_n_atoms, sysb.mol_n_atoms])\n    \n    sysres.box_vectors = sysa.box_vectors\n    \n    return sysres", "response": "Generate a new system by merging sysa and sysb."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naligns the system according to the minimum image convention", "response": "def minimum_image(self):\n        \"\"\"Align the system according to the minimum image convention\"\"\"\n        if self.box_vectors is None:\n            raise ValueError('No periodic vectors defined')\n        else:\n            self.r_array = minimum_image(self.r_array, self.box_vectors.diagonal())\n        \n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the atoms at the given indices.", "response": "def remove_atoms(self, indices):\n        \"\"\"Remove the atoms positioned at *indices*. The molecule\n        containing the atom is removed as well.\n\n        If you have a system of 10 water molecules (and 30 atoms), if\n        you remove the atoms at indices 0, 1 and 29 you will remove\n        the first and last water molecules.\n\n        **Parameters**\n\n        indices: np.ndarray((N,), dtype=int)\n            Array of integers between 0 and System.n_atoms\n\n        \"\"\"\n        mol_indices = self.atom_to_molecule_indices(indices)\n        self.copy_from(self.sub(molecule_index=mol_indices))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns indices that met the conditions", "response": "def where(self, within_of=None, inplace=False, **kwargs):\n        \"\"\"Return indices that met the conditions\"\"\"\n        masks = super(System, self).where(inplace=inplace, **kwargs)\n        \n        def index_to_mask(index, n):\n            val = np.zeros(n, dtype='bool')\n            val[index] = True\n            return val\n        \n        def masks_and(dict1, dict2):\n            return {k: dict1[k] & index_to_mask(dict2[k], len(dict1[k])) for k in dict1 }\n        \n        if within_of is not None:\n            if self.box_vectors is None:\n                raise Exception('Only periodic distance supported')\n            thr, ref = within_of\n            \n            if isinstance(ref, int):\n                a = self.r_array[ref][np.newaxis, np.newaxis, :] # (1, 1, 3,)\n            elif len(ref) == 1:\n                a = self.r_array[ref][np.newaxis, :] # (1, 1, 3)\n            else:\n                a = self.r_array[ref][:, np.newaxis, :] # (2, 1, 3)\n            \n            b = self.r_array[np.newaxis, :, :]\n            dist = periodic_distance(a, b,\n                                     periodic=self.box_vectors.diagonal())\n            \n            atoms = (dist <= thr).sum(axis=0, dtype='bool')\n            m = self._propagate_dim(atoms, 'atom')\n            masks = masks_and(masks, m)\n        \n        return masks"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts cartesian coordinates passed as ( N 3 ) shaped arrays.", "response": "def cartesian_to_spherical(cartesian):\n    \"\"\"Convert cartesian to spherical coordinates passed as (N,3) shaped arrays.\"\"\"\n    xyz = cartesian\n    xy = xyz[:,0]**2 + xyz[:,1]**2\n    r = np.sqrt(xy + xyz[:,2]**2)\n    phi = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n    #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n    theta = np.arctan2(xyz[:,1], xyz[:,0])\n    return np.array([r, theta, phi]).T"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef binomial(n,k):\n    if n==k: return 1\n    assert n>k, \"Attempting to call binomial(%d,%d)\" % (n,k)\n    return factorial(n)//(factorial(k)*factorial(n-k))", "response": "Return a random n - k binomial sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gamm_inc(a,x):\n    assert (x > 0 and a >= 0), \"Invalid arguments in routine gamm_inc: %s,%s\" % (x,a)\n\n    if x < (a+1.0): #Use the series representation\n        gam,gln = _gser(a,x)\n    else: #Use continued fractions\n        gamc,gln = _gcf(a,x)\n        gam = 1-gamc\n    return np.exp(gln)*gam", "response": "Incomple gamma function \\ gamma ; computed from NumRec routine gammp."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _gser(a,x):\n    \"Series representation of Gamma. NumRec sect 6.1.\"\n    ITMAX=100\n    EPS=3.e-7\n\n    gln=lgamma(a)\n    assert(x>=0),'x < 0 in gser'\n    if x == 0 : return 0,gln\n\n    ap = a\n    delt = sum = 1./a\n    for i in range(ITMAX):\n        ap=ap+1.\n        delt=delt*x/ap\n        sum=sum+delt\n        if abs(delt) < abs(sum)*EPS: break\n    else:\n        print('a too large, ITMAX too small in gser')\n    gamser=sum*np.exp(-x+a*np.log(x)-gln)\n    return gamser,gln", "response": "Series representation of Gamma. NumRec sect 6. 1."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncontinuing fraction representation of Gamma. NumRec sect 6. 1", "response": "def _gcf(a,x):\n    \"Continued fraction representation of Gamma. NumRec sect 6.1\"\n    ITMAX=100\n    EPS=3.e-7\n    FPMIN=1.e-30\n\n    gln=lgamma(a)\n    b=x+1.-a\n    c=1./FPMIN\n    d=1./b\n    h=d\n    for i in range(1,ITMAX+1):\n        an=-i*(i-a)\n        b=b+2.\n        d=an*d+b\n        if abs(d) < FPMIN: d=FPMIN\n        c=b+an/c\n        if abs(c) < FPMIN: c=FPMIN\n        d=1./d\n        delt=d*c\n        h=h*delt\n        if abs(delt-1.) < EPS: break\n    else:\n        print('a too large, ITMAX too small in gcf')\n    gammcf=np.exp(-x+a*np.log(x)-gln)*h\n    return gammcf,gln"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dmat(c,nocc):\n    \"Form the density matrix from the first nocc orbitals of c\"\n    return np.dot(c[:,:nocc],c[:,:nocc].T)", "response": "Form the density matrix from the first nocc orbitals of c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef canorth(S):\n    \"Canonical orthogonalization U/sqrt(lambda)\"\n    E,U = np.linalg.eigh(S)\n    for i in range(len(E)):\n        U[:,i] = U[:,i] / np.sqrt(E[i])\n    return U", "response": "Canonical orthogonalization U / sqrt ( lambda )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geigh(H,S):\n    \"Solve the generalized eigensystem Hc = ESc\"\n    A = cholorth(S)\n    E,U = np.linalg.eigh(simx(H,A))\n    return E,np.dot(A,U)", "response": "Solve the generalized eigensystem Hc = ESc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseline(line,format):\n    xlat = {'x':None,'s':str,'f':float,'d':int,'i':int}\n    result = []\n    words = line.split()\n    for i in range(len(format)):\n        f = format[i]\n        trans = xlat.get(f,None)\n        if trans: result.append(trans(words[i]))\n    if len(result) == 0: return None\n    if len(result) == 1: return result[0]\n    return result", "response": "This function parses a line into a list of python objects that are returned by the parseline function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef colorscale(mag, cmin, cmax):\n    # Normalize to 0-1\n    try:\n        x = float(mag-cmin)/(cmax-cmin)\n    except ZeroDivisionError:\n        x = 0.5  # cmax == cmin\n    blue = min((max((4*(0.75-x), 0.)), 1.))\n    red = min((max((4*(x-0.25), 0.)), 1.))\n    green = min((max((4*abs(x-0.5)-1., 0.)), 1.))\n    return red, green, blue", "response": "Return a tuple of floats between 0 and 1 for R G and B."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_fields(cls, **kwargs):\n        '''\n        Create an `Atom` instance from a set of fields. This is a\n        slightly faster way to initialize an Atom.\n        \n        **Example**\n\n        >>> Atom.from_fields(type='Ar',\n                             r_array=np.array([0.0, 0.0, 0.0]),\n                             mass=39.948,\n                             export={})\n        '''\n        obj = cls.__new__(cls)\n        \n        for name, field in obj.__fields__.items():\n            if name in kwargs:\n                field.value = kwargs[name]\n        \n        return obj", "response": "Create an Atom instance from a set of fields. This is slightly faster way to initialize an Atom. a\n        \n        **Example**"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_neighbors(coordinates_a, coordinates_b, periodic, r):\n    '''Count the neighbours number of neighbors.\n\n    :param np.ndarray coordinates_a: Either an array of coordinates of shape (N,3)\n                                     or a single point of shape (3,)\n    :param np.ndarray coordinates_b: Same as coordinates_a\n    :param np.ndarray periodic: Either a matrix of box vectors (3, 3) or an\n                                array of box lengths of shape (3,). Only\n                                orthogonal boxes are supported.\n    :param float r: Radius of neighbor search\n\n    '''\n    indices = nearest_neighbors(coordinates_a, coordinates_b, periodic, r=r)[0]\n\n    if len(indices) == 0:\n        return 0\n\n    if isinstance(indices[0], collections.Iterable):\n        return [len(ix) for ix in indices]\n    else:\n        return len(indices)", "response": "Count the number of neighbors in a tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_background(color):\n    viewer.widget.background_color = colors.any_to_rgb(color)\n    viewer.update()", "response": "Setup the background color to any color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscaling the currently selected atoms by a certain factor.", "response": "def scale_atoms(fac):\n    '''Scale the currently selected atoms atoms by a certain factor\n    *fac*.\n\n    Use the value *fac=1.0* to reset the scale.\n\n    '''\n    rep = current_representation()\n    atms = selected_atoms()\n    rep.scale_factors[atms] = fac\n    \n    rep.update_scale_factors(rep.scale_factors)\n    viewer.update()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the color of the currently selected objects.", "response": "def change_color(color):\n    \"\"\"Change the color of the currently selected objects. *color* is\n    represented as a string. Otherwise color can be passed as an rgba\n    tuple of values between 0, 255\n\n    Reset the color by passing *color=None*.\n    \n    You can call this function interactively by using::\n\n        change_color.interactive()\n    \n    A new dialog will popup with a color chooser.\n    \n    \"\"\"\n    rep = current_representation()\n    \n    # Let's parse the color first\n    if isinstance(color, str):\n        # The color should be a string\n        col = color_from_string(color)\n\n    if isinstance(color, tuple):\n        col = color\n        \n    if color is None:\n        col = None\n\n    # Color array\n    rep.change_color(rep.selection_state, col)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nchange the default radii of the current node", "response": "def change_default_radii(def_map):\n    \"\"\"Change the default radii\n    \"\"\"\n    s = current_system()\n    rep = current_representation()\n    rep.radii_state.default = [def_map[t] for t in s.type_array]\n    rep.radii_state.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef screenshot(filename, width=None, height=None):\n    '''Make a screenshot of the current view. You can tweak the\n    resolution up to what your GPU memory supports.\n    \n    By defaults it uses the current window resolution.\n    \n    Example::\n\n      screenshot('screen.png', 1200, 1200)\n    \n    '''\n    width = width or viewer.widget.width()\n    height = height or viewer.widget.height()\n    \n    img = viewer.widget.toimage(width, height)\n    img.save(filename)", "response": "Make a screenshot of the current view."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_post_processing(effect,  **options):\n\n    from chemlab.graphics.postprocessing import SSAOEffect, OutlineEffect, FXAAEffect, GammaCorrectionEffect\n    \n    pp_map = {'ssao': SSAOEffect,\n              'outline': OutlineEffect,\n              'fxaa': FXAAEffect,\n              'gamma': GammaCorrectionEffect}\n    \n    pp = viewer.add_post_processing(pp_map[effect], **options)    \n    viewer.update()\n\n\n    global _counter\n    _counter += 1\n    \n    str_id = effect + str(_counter)    \n    _effect_map[str_id] = pp # saving it for removal for later...\n    \n    return str_id", "response": "Adds a post processing effect to the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a list of strings *lines* return the lines that match a pattern.", "response": "def greplines(pattern, lines):\n    \"\"\"Given a list of strings *lines* return the lines that match\n    pattern.\n\n    \"\"\"\n    res = []\n    for line in lines:\n        match = re.search(pattern, line)\n        if match is not None:\n            res.append(line)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sections(start, end, text, line=True):\n    if not line:\n        return re.findall(start+\"(.*?)\"+end, text, re.DOTALL)\n    \n    lines = text.splitlines()\n    \n    # This is a state-machine with the states MATCHING = True/False\n    MATCHING = False\n    section_list = []\n    sre = re.compile(start)\n    ere = re.compile(end)\n    \n    for line in lines:\n        if MATCHING == False:\n            if sre.search(line):\n                # Start to take stuff\n                MATCHING = True\n                section = [] \n                continue\n        \n        if MATCHING == True:\n            if ere.search(line):\n                MATCHING = False\n                section_list.append('\\n'.join(section))\n            else:\n                section.append(line)\n    return section_list", "response": "Given the text to analyze return the list of sections that match the start and end matchers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking the lines in text and split them each time the pattern matches a line.", "response": "def grep_split(pattern, text):\n    '''Take the lines in *text* and split them each time the pattern\n    matches a line.\n\n    '''\n    lines = text.splitlines()\n    indices = [i for i, line in enumerate(lines)\n               if re.search(pattern, line)]\n    \n    return ['\\n'.join(part) for part in partition(lines, indices)]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unit_vector(x):\n    y = np.array(x, dtype='float')\n    return y/norm(y)", "response": "Return a unit vector in the same direction as x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef angle(x, y):\n    return arccos(dot(x, y)/(norm(x)*norm(y)))*180./pi", "response": "Return the angle between vectors a and b in degrees."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cell_to_cellpar(cell):\n    va, vb, vc = cell\n    a = np.linalg.norm(va)\n    b = np.linalg.norm(vb)\n    c = np.linalg.norm(vc)\n    alpha = 180.0/pi*arccos(dot(vb, vc)/(b*c))\n    beta  = 180.0/pi*arccos(dot(vc, va)/(c*a))\n    gamma = 180.0/pi*arccos(dot(va, vb)/(a*b))\n    return np.array([a, b, c, alpha, beta, gamma])", "response": "Returns the cell parameters as a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a 3x3 cell matrix from a 3x3 cell matrix.", "response": "def cellpar_to_cell(cellpar, ab_normal=(0,0,1), a_direction=None):\n    \"\"\"Return a 3x3 cell matrix from `cellpar` = [a, b, c, alpha,\n    beta, gamma].  The returned cell is orientated such that a and b\n    are normal to `ab_normal` and a is parallel to the projection of\n    `a_direction` in the a-b plane.\n\n    Default `a_direction` is (1,0,0), unless this is parallel to\n    `ab_normal`, in which case default `a_direction` is (0,0,1).\n\n    The returned cell has the vectors va, vb and vc along the rows. The\n    cell will be oriented such that va and vb are normal to `ab_normal`\n    and va will be along the projection of `a_direction` onto the a-b\n    plane.\n\n    Example:\n\n    >>> cell = cellpar_to_cell([1, 2, 4,  10,  20, 30], (0,1,1), (1,2,3))\n    >>> np.round(cell, 3)\n    array([[ 0.816, -0.408,  0.408],\n           [ 1.992, -0.13 ,  0.13 ],\n           [ 3.859, -0.745,  0.745]])\n\n    \"\"\"\n    if a_direction is None:\n        if np.linalg.norm(np.cross(ab_normal, (1,0,0))) < 1e-5:\n            a_direction = (0,0,1)\n        else:\n            a_direction = (1,0,0)\n\n    # Define rotated X,Y,Z-system, with Z along ab_normal and X along\n    # the projection of a_direction onto the normal plane of Z.\n    ad = np.array(a_direction)\n    Z = unit_vector(ab_normal)\n    X = unit_vector(ad - dot(ad, Z)*Z)\n    Y = np.cross(Z, X)\n\n    # Express va, vb and vc in the X,Y,Z-system\n    alpha, beta, gamma = 90., 90., 90.\n    if isinstance(cellpar, (int, float)):\n        a = b = c = cellpar\n    elif len(cellpar) == 1:\n        a = b = c = cellpar[0]\n    elif len(cellpar) == 3:\n        a, b, c = cellpar\n        alpha, beta, gamma = 90., 90., 90.\n    else:\n        a, b, c, alpha, beta, gamma = cellpar\n    alpha *= pi/180.0\n    beta *= pi/180.0\n    gamma *= pi/180.0\n    va = a * np.array([1, 0, 0])\n    vb = b * np.array([cos(gamma), sin(gamma), 0])\n    cx = cos(beta)\n    cy = (cos(alpha) - cos(beta)*cos(gamma))/sin(gamma)\n    cz = sqrt(1. - cx*cx - cy*cy)\n    vc = c * np.array([cx, cy, cz])\n\n    # Convert to the Cartesian x,y,z-system\n    abc = np.vstack((va, vb, vc))\n    T = np.vstack((X, Y, Z))\n    cell = dot(abc, T)\n    return cell"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef metric_from_cell(cell):\n    cell = np.asarray(cell, dtype=float)\n    return np.dot(cell, cell.T)", "response": "Calculates the metric matrix from the cell which is given in the\n    Cartesian system."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a new default handler for a given format.", "response": "def add_default_handler(ioclass, format, extension=None):\n    \"\"\"Register a new data handler for a given format in\n       the default handler list.\n\n       This is a convenience function used internally to setup the\n       default handlers. It can be used to add other handlers at\n       runtime even if this isn't a suggested practice.\n\n       **Parameters**\n\n       ioclass: IOHandler subclass\n       format: str\n         A string identifier representing the format\n       extension: str, optional\n         The file extension associated with the format.\n\n    \"\"\"\n    if format in _handler_map:\n        print(\"Warning: format {} already present.\".format(format))\n\n    _handler_map[format] = ioclass\n\n    if extension in _extensions_map:\n        print(\"Warning: extension {} already handled by {} handler.\"\n              .format(extension, _extensions_map[extension]))\n\n    if extension is not None:\n        _extensions_map[extension] = format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the IOHandler that can handle the extension ext.", "response": "def get_handler_class(ext):\n    \"\"\"Get the IOHandler that can handle the extension *ext*.\"\"\"\n\n    if ext in _extensions_map:\n        format = _extensions_map[ext]\n    else:\n        raise ValueError(\"Unknown format for %s extension.\" % ext)\n\n    if format in _handler_map:\n        hc = _handler_map[format]\n        return hc\n    else:\n        matches = difflib.get_close_matches(format, _handler_map.keys())\n        raise ValueError(\"Unknown Handler for format %s, close matches: %s\"\n                         % (format, str(matches)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the appropriate filehandle for a given file.", "response": "def datafile(filename, mode=\"rb\", format=None):\n    \"\"\"Initialize the appropriate\n    :py:class:`~chemlab.io.iohandler.IOHandler` for a given file\n    extension or file format.\n\n    The *datafile* function can be conveniently used to quickly read\n    or write data in a certain format::\n\n        >>> handler = datafile(\"molecule.pdb\")\n        >>> mol = handler.read(\"molecule\")\n        # You can also use this shortcut\n        >>> mol = datafile(\"molecule.pdb\").read(\"molecule\")\n\n    **Parameters**\n\n    filename: str\n          Path of the file to open.\n    format: str or None\n          When different from *None*, can be used to specify a\n          format identifier for that file. It should be used when\n          the extension is ambiguous or when there isn't a specified\n          filename. See below for a list of the formats supported by chemlab.\n\n    \"\"\"\n\n    filename = os.path.expanduser(filename)\n    base, ext = os.path.splitext(filename)\n\n    if format is None:\n        hc = get_handler_class(ext)\n    else:\n        hc = _handler_map.get(format)\n        if hc is None:\n            raise ValueError('Format {} not supported.'.format(format))\n\n    fd = open(filename, mode)\n\n    handler = hc(fd)\n    return handler"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remotefile(url, format=None):\n\n    if format is None:\n        res = urlparse(url)\n        filename, ext = os.path.splitext(res.path)\n\n        hc = get_handler_class(ext)\n    else:\n        hc = _handler_map.get(format)\n        if hc is None:\n            raise ValueError('Format {} not supported.'.format(format))\n\n    fd = urlopen(url)\n    handler = hc(fd)\n    return handler", "response": "A function to download a file from a remote url."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a vector collection of atom positions wrapped into the central periodic image or primary simulation cell.", "response": "def minimum_image(coords, pbc):\n    \"\"\"\n    Wraps a vector collection of atom positions into the central periodic\n    image or primary simulation cell.\n\n    Parameters\n    ----------\n    pos : :class:`numpy.ndarray`, (Nx3)\n    Vector collection of atom positions.\n\n    Returns\n    -------\n    wrap : :class:`numpy.ndarray`, (Nx3)\n    Returns atomic positions wrapped into the primary simulation\n    cell, or periodic image.\n\n    \"\"\"\n    # This will do the broadcasting\n    coords = np.array(coords)\n    pbc = np.array(pbc)\n\n    # For each coordinate this number represents which box we are in\n    image_number = np.floor(coords / pbc)\n\n    wrap = coords - pbc * image_number\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef noperiodic(r_array, periodic, reference=None):\n    '''Rearrange the array of coordinates *r_array* in a way that doensn't\n       cross the periodic boundary.\n\n       Parameters\n       ----------\n       r_array : :class:`numpy.ndarray`, (Nx3)\n       Array of 3D coordinates.\n\n       periodic: :class:`numpy.ndarray`, (3)\n       Periodic boundary dimensions.\n\n       reference: ``None`` or :class:`numpy.ndarray` (3)\n       The points will be moved to be in the periodic image centered on the reference. \n       If None, the first point will be taken as a reference\n\n       Returns\n       -------\n\n       A (N, 3) array of coordinates, all in the same periodic image.\n\n       Example\n       -------\n\n           >>> coordinates = np.array([[0.1, 0.0, 0.0], [0.9, 0.0, 0.0]])\n           >>> periodic = np.array([1, 1, 1])\n           >>> noperiodic(coordinates, periodic)\n           [[ 0.1, 0.0, 0.0],\n            [-0.1, 0.0, 0.0]]\n\n    '''\n    if reference is None:\n        center = r_array[0]\n    else:\n        center = reference\n\n    # Find the displacements\n    dr = (center - r_array)\n    drsign = np.sign(dr)\n\n    # Move things when the displacement is more than half the box size\n    tomove = np.abs(dr) >= periodic / 2.0\n    r_array[tomove] += (drsign * periodic)[tomove]\n    return r_array", "response": "Rearrange the array of coordinates r_array in a way that doensn t cross the periodic boundary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the difference of the points vec_a - vec_b subject to the periodic boundary conditions.", "response": "def subtract_vectors(a, b, periodic):\n    '''Returns the difference of the points vec_a - vec_b subject \n       to the periodic boundary conditions.\n\n    '''\n    r = a - b\n    delta = np.abs(r)\n    sign = np.sign(r)\n    return np.where(delta > 0.5 * periodic, sign * (periodic - delta), r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_vectors(vec_a, vec_b, periodic):\n    '''Returns the sum of the points vec_a - vec_b subject \n       to the periodic boundary conditions.\n\n    '''\n    moved = noperiodic(np.array([vec_a, vec_b]), periodic)\n    return vec_a + vec_b", "response": "Returns the sum of the points vec_a - vec_b subject \n       to the periodic boundary conditions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate a distrance matrix between coordinates sets a and b", "response": "def distance_matrix(a, b, periodic):\n    '''Calculate a distrance matrix between coordinates sets a and b\n    '''\n    a = a\n    b = b[:, np.newaxis]\n    return periodic_distance(a, b, periodic)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef periodic_distance(a, b, periodic):\n    '''\n    Periodic distance between two arrays. Periodic is a 3\n    dimensional array containing the 3 box sizes.\n\n    '''\n    a = np.array(a)\n    b = np.array(b)\n    periodic = np.array(periodic)\n\n    delta = np.abs(a - b)\n    delta = np.where(delta > 0.5 * periodic, periodic - delta, delta)\n    return np.sqrt((delta ** 2).sum(axis=-1))", "response": "Calculates the periodic distance between two arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the square root of the mean distance squared from the center of gravity.", "response": "def radius_of_gyration(coords, periodic):\n    '''Calculate the square root of the mean distance squared from the center of gravity.\n\n    '''\n    gc = geometric_center(coords, periodic)\n    return (periodic_distance(coords, gc, periodic) ** 2).sum() / len(coords)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(query):\n    assert type(query) == str or type(query) == str, 'query not a string object'\n    searchurl = 'http://www.chemspider.com/Search.asmx/SimpleSearch?query=%s&token=%s' % (urlquote(query), TOKEN)\n    response = urlopen(searchurl)\n    tree = ET.parse(response)\n    elem = tree.getroot()\n    csid_tags = elem.getiterator('{http://www.chemspider.com/}int')\n    compoundlist = []\n    for tag in csid_tags:\n        compoundlist.append(Compound(tag.text))\n    return compoundlist if compoundlist else None", "response": "Search by name smiLES inchi key etc. Returns first 100 Compounds"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the URL of a png image of the 2D structure", "response": "def imageurl(self):\n        \"\"\" Return the URL of a png image of the 2D structure \"\"\"\n        if self._imageurl is None:\n            self._imageurl = 'http://www.chemspider.com/ImagesHandler.ashx?id=%s' % self.csid\n        return self._imageurl"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadextendedcompoundinfo(self):\n        apiurl = 'http://www.chemspider.com/MassSpecAPI.asmx/GetExtendedCompoundInfo?CSID=%s&token=%s' % (self.csid,TOKEN)\n        response = urlopen(apiurl)\n        tree = ET.parse(response)\n        mf = tree.find('{http://www.chemspider.com/}MF')\n        self._mf = mf.text if mf is not None else None\n        smiles = tree.find('{http://www.chemspider.com/}SMILES')\n        self._smiles = smiles.text if smiles is not None else None\n        inchi = tree.find('{http://www.chemspider.com/}InChI')\n        self._inchi = inchi.text if inchi is not None else None\n        inchikey = tree.find('{http://www.chemspider.com/}InChIKey')\n        self._inchikey = inchikey.text if inchikey is not None else None\n        averagemass = tree.find('{http://www.chemspider.com/}AverageMass')\n        self._averagemass = float(averagemass.text) if averagemass is not None else None\n        molecularweight = tree.find('{http://www.chemspider.com/}MolecularWeight')\n        self._molecularweight = float(molecularweight.text) if molecularweight is not None else None\n        monoisotopicmass = tree.find('{http://www.chemspider.com/}MonoisotopicMass')\n        self._monoisotopicmass = float(monoisotopicmass.text) if monoisotopicmass is not None else None\n        nominalmass = tree.find('{http://www.chemspider.com/}NominalMass')\n        self._nominalmass = float(nominalmass.text) if nominalmass is not None else None\n        alogp = tree.find('{http://www.chemspider.com/}ALogP')\n        self._alogp = float(alogp.text) if alogp is not None else None\n        xlogp = tree.find('{http://www.chemspider.com/}XLogP')\n        self._xlogp = float(xlogp.text) if xlogp is not None else None\n        commonname = tree.find('{http://www.chemspider.com/}CommonName')\n        self._commonname = commonname.text if commonname is not None else None", "response": "Load extended compound info from the Mass Spec API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image(self):\n        if self._image is None:\n            apiurl = 'http://www.chemspider.com/Search.asmx/GetCompoundThumbnail?id=%s&token=%s' % (self.csid,TOKEN)\n            response = urlopen(apiurl)\n            tree = ET.parse(response)\n            self._image = tree.getroot().text\n        return self._image", "response": "Return PNG binary image data of 2D structure image"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mol(self):\n        if self._mol is None:\n            apiurl = 'http://www.chemspider.com/MassSpecAPI.asmx/GetRecordMol?csid=%s&calc3d=false&token=%s' % (self.csid,TOKEN)\n            response = urlopen(apiurl)\n            tree = ET.parse(response)\n            self._mol = tree.getroot().text\n        return self._mol", "response": "Return record in MOL format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning record in MOL format with 3D coordinates calculated", "response": "def mol3d(self):\n        \"\"\" Return record in MOL format with 3D coordinates calculated \"\"\"\n        if self._mol3d is None:\n            apiurl = 'http://www.chemspider.com/MassSpecAPI.asmx/GetRecordMol?csid=%s&calc3d=true&token=%s' % (self.csid,TOKEN)\n            response = urlopen(apiurl)\n            tree = ET.parse(response)\n            self._mol3d = tree.getroot().text\n        return self._mol3d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_positions(self, r_array):\n        '''Update the coordinate array r_array'''\n        self.ar.update_positions(r_array)\n        \n        if self.has_bonds:\n            self.br.update_positions(r_array)", "response": "Update the coordinate array r_array"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_feature(self, feature, readwrite):\n\n        if readwrite == \"read\":\n            features = self.can_read\n        if readwrite == \"write\":\n            features = self.can_write\n            \n        if feature not in features:\n            matches = difflib.get_close_matches(feature, features)\n            raise FeatureNotAvailable(\"Feature %s not present in %s. Close matches: %s\"\n                                      % (feature, str(type(self).__name__),\n                                         str(matches)))", "response": "Check if the feature is supported in the handler and raise an exception otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconcatenate InstanceAttribute to return a bigger one.", "response": "def concatenate_attributes(attributes):\n    '''Concatenate InstanceAttribute to return a bigger one.'''\n    # We get a template/\n    tpl = attributes[0]\n    attr = InstanceAttribute(tpl.name, tpl.shape, \n                             tpl.dtype, tpl.dim, alias=None)\n    \n    # Special case, not a single array has size bigger than 0\n    if all(a.size == 0 for a in attributes):\n        return attr\n    else: \n        attr.value = np.concatenate([a.value for a in attributes if a.size > 0], axis=0)\n        return attr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef concatenate_fields(fields, dim):\n    'Create an INstanceAttribute from a list of InstnaceFields'\n    if len(fields) == 0:\n        raise ValueError('fields cannot be an empty list')\n    \n    if len(set((f.name, f.shape, f.dtype) for f in fields)) != 1:\n        raise ValueError('fields should have homogeneous name, shape and dtype')\n    tpl = fields[0]\n    attr = InstanceAttribute(tpl.name, shape=tpl.shape, dtype=tpl.dtype, \n                             dim=dim, alias=None)\n    \n    attr.value = np.array([f.value for f in fields], dtype=tpl.dtype)\n    return attr", "response": "Create an INstanceAttribute from a list of InstnaceFields"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the entity contains the attribute name", "response": "def has_attribute(self, name, alias=False):\n        \"\"\"Check if the entity contains the attribute *name*\"\"\"\n        prop_dict = merge_dicts(self.__attributes__,\n                                self.__fields__,\n                                self.__relations__)\n        if alias:\n            prop_dict.update({v.alias : v for v in prop_dict.values() if v.alias is not None})\n        \n        return name in prop_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict(self):\n        \n        ret = merge_dicts(self.__attributes__, self.__relations__, self.__fields__)\n        ret = {k : v.value for k,v in ret.items()}\n        ret['maps'] = {k : v.value for k,v in self.maps.items()}\n        return ret", "response": "Return a dict representing the ChemicalEntity that can be read back\n        using from_dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a ChemicalEntity from a json string", "response": "def from_json(cls, string):\n        \"\"\"Create a ChemicalEntity from a json string \n        \"\"\"\n        exp_dict = json_to_data(string)\n        version = exp_dict.get('version', 0)\n        if version == 0:\n            return cls.from_dict(exp_dict)\n        elif version == 1:\n            return cls.from_dict(exp_dict)\n        else:\n            raise ValueError(\"Version %d not supported\" % version)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a copy of this ChemicalEntity", "response": "def copy(self):\n        \"\"\"Create a copy of this ChemicalEntity\n        \n        \"\"\"\n        inst = super(type(self), type(self)).empty(**self.dimensions)\n        \n        # Need to copy all attributes, fields, relations\n        inst.__attributes__ = {k: v.copy() for k, v in self.__attributes__.items()}\n        inst.__fields__ = {k: v.copy() for k, v in self.__fields__.items()}\n        inst.__relations__ = {k: v.copy() for k, v in self.__relations__.items()}\n        inst.maps = {k: m.copy() for k, m in self.maps.items()}\n        inst.dimensions = self.dimensions.copy()\n        \n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_from(self, other):\n        # Need to copy all attributes, fields, relations\n        self.__attributes__ = {k: v.copy() for k, v in other.__attributes__.items()}\n        self.__fields__ = {k: v.copy() for k, v in other.__fields__.items()}\n        self.__relations__ = {k: v.copy() for k, v in other.__relations__.items()}\n        self.maps = {k: m.copy() for k, m in other.maps.items()}\n        self.dimensions = other.dimensions.copy()", "response": "Copy properties from another ChemicalEntity\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the current chemical entity from a dictionary of attributes", "response": "def update(self, dictionary):\n        \"\"\"Update the current chemical entity from a dictionary of attributes\"\"\"\n        allowed_attrs = list(self.__attributes__.keys())\n        allowed_attrs += [a.alias for a in self.__attributes__.values()]\n        for k in dictionary:\n            # We only update existing attributes\n            if k in allowed_attrs:\n                setattr(self, k, dictionary[k])\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subentity(self, Entity, index):\n        dim = Entity.__dimension__\n        entity = Entity.empty()\n        \n        if index >= self.dimensions[dim]:\n            raise ValueError('index {} out of bounds for dimension {} (size {})'\n                             .format(index, dim, self.dimensions[dim]))\n        \n        \n        for name, attr in self.__attributes__.items():\n            if attr.dim == dim:\n                # If the dimension of the attributes is the same of the\n                # dimension of the entity, we generate a field\n                entity.__fields__[name] = attr.field(index)\n            elif attr.dim in entity.dimensions:\n                # Special case, we don't need to do anything\n                if self.dimensions[attr.dim] == 0:\n                    continue\n\n                # Else, we generate a subattribute\n                mapped_index = self.maps[attr.dim, dim].value == index\n                entity.__attributes__[name] = attr.sub(mapped_index)\n                entity.dimensions[attr.dim] = np.count_nonzero(mapped_index)\n\n        for name, rel in self.__relations__.items():\n            if rel.map == dim:\n                # The relation is between entities we need to return\n                # which means the entity doesn't know about that\n                pass\n            if rel.map in entity.dimensions:\n                # Special case, we don't need to do anything\n                if self.dimensions[rel.dim] == 0:\n                    continue\n                mapped_index = self.maps[rel.dim, dim].value == index\n                entity.__relations__[name] = rel.sub(mapped_index)\n                entity.dimensions[rel.dim] = np.count_nonzero(mapped_index)\n                \n                # We need to remap values\n                convert_index = self.maps[rel.map, dim].value == index\n                entity.__relations__[name].remap(convert_index.nonzero()[0],\n                                                 range(entity.dimensions[rel.map]))\n        \n        return entity", "response": "Return a child entity with the given index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sub_dimension(self, index, dimension, propagate=True, inplace=False):\n        filter_ = self._propagate_dim(index, dimension, propagate)\n        return self.subindex(filter_, inplace)", "response": "Return a ChemicalEntity sliced through a dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef concat(self, other, inplace=False):\n        '''Concatenate two ChemicalEntity of the same kind'''\n        \n        # Create new entity\n        if inplace:\n            obj = self\n        else:\n            obj = self.copy()\n        \n        # Stitch every attribute\n        for name, attr in obj.__attributes__.items():\n            attr.append(other.__attributes__[name])\n            \n        # Stitch every relation\n        for name, rel in obj.__relations__.items():\n            rel.append(other.__relations__[name])\n        \n        # Update maps\n        \n        # Update dimensions\n        if obj.is_empty():\n            obj.maps = {k: m.copy() for k, m in other.maps.items()}\n            obj.dimensions = other.dimensions.copy()\n        else:\n            for (a, b), rel in obj.maps.items():\n                rel.append(other.maps[a, b])\n            for d in obj.dimensions:\n                obj.dimensions[d] += other.dimensions[d]\n        \n        return obj", "response": "Concatenate two ChemicalEntity objects of the same kind."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef where(self, inplace=False, **kwargs):\n        masks = {k: np.ones(v, dtype='bool') for k,v in self.dimensions.items()} \n        \n        def index_to_mask(index, n):\n            val = np.zeros(n, dtype='bool')\n            val[index] = True\n            return val\n        \n        def masks_and(dict1, dict2):\n            return {k: dict1[k] & index_to_mask(dict2[k], len(dict1[k])) for k in dict1 }\n        \n        for key in kwargs:\n            value = kwargs[key]\n            if key.endswith('_index'):\n                if isinstance(value, int):\n                    value = [value]\n                \n                dim = key[:-len('_index')]\n                m = self._propagate_dim(value, dim)\n                masks = masks_and(masks, m)\n            else:\n                attribute = self.get_attribute(key)\n                \n                if isinstance(value, list):\n                    mask = reduce(operator.or_, [attribute.value == m for m in value])\n                else:\n                    mask = attribute.value == value\n            \n                m = self._propagate_dim(mask, attribute.dim)\n                masks = masks_and(masks, m)\n        \n        return masks", "response": "Returns a new array with only the elements that satisfy the condition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sub(self, inplace=False, **kwargs):\n        filter_ = self.where(**kwargs)\n        return self.subindex(filter_, inplace)", "response": "Return a new index of the entries in the log table where the conditions are met"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sub(self, index):\n        index = np.asarray(index)\n        if index.dtype == 'bool':\n            index = index.nonzero()[0]\n        \n        if self.size < len(index):\n            raise ValueError('Can\\'t subset \"{}\": index ({}) is bigger than the number of elements ({})'.format(self.name, len(index), self.size))\n        \n        inst = self.copy()\n        size = len(index)\n        inst.empty(size)\n        \n        if len(index) > 0:\n            inst.value = self.value.take(index, axis=0)\n        \n        return inst", "response": "Return a sub - attribute of the object with the specified index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve(input, representation, resolvers=None, **kwargs):\n    resultdict = query(input, representation, resolvers, **kwargs)\n    result = resultdict[0]['value'] if resultdict else None\n    if result and len(result) == 1:\n        result = result[0]\n    return result", "response": "Resolve input to the specified output representation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery the specified input to the specified output representation.", "response": "def query(input, representation, resolvers=None, **kwargs):\n    \"\"\" Get all results for resolving input to the specified output representation \"\"\"\n    apiurl = API_BASE+'/%s/%s/xml' % (urlquote(input), representation)\n    if resolvers:\n        kwargs['resolver'] = \",\".join(resolvers)\n    if kwargs:\n        apiurl+= '?%s' % urlencode(kwargs)\n    result = []\n    try:\n        tree = ET.parse(urlopen(apiurl))\n        for data in tree.findall(\".//data\"):\n            datadict = {'resolver':data.attrib['resolver'],\n                        'notation':data.attrib['notation'],\n                        'value':[]}\n            for item in data.findall(\"item\"):\n                datadict['value'].append(item.text)\n            if len(datadict['value']) == 1:\n                datadict['value'] = datadict['value'][0]\n            result.append(datadict)\n    except HTTPError:\n        # TODO: Proper handling of 404, for now just returns None\n        pass\n    return result if result else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a structure as a file", "response": "def download(input, filename, format='sdf', overwrite=False, resolvers=None, **kwargs):\n    \"\"\" Resolve and download structure as a file \"\"\"\n    kwargs['format'] = format\n    if resolvers:\n        kwargs['resolver'] = \",\".join(resolvers)\n    url = API_BASE+'/%s/file?%s' % (urlquote(input), urlencode(kwargs))\n    try:\n        servefile = urlopen(url)\n        if not overwrite and os.path.isfile(filename):\n            raise IOError(\"%s already exists. Use 'overwrite=True' to overwrite it.\" % filename)\n        file = open(filename, \"w\")\n        file.write(servefile.read())\n        file.close()\n    except urllib.error.HTTPError:\n        # TODO: Proper handling of 404, for now just does nothing\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading the resolved structure as a file", "response": "def download(self, filename, format='sdf', overwrite=False, resolvers=None, **kwargs):\n        \"\"\" Download the resolved structure as a file \"\"\"\n        download(self.input, filename, format, overwrite, resolvers, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect bonds given the coordinates r_array and types of the .", "response": "def guess_bonds(r_array, type_array, threshold=0.1, maxradius=0.3, radii_dict=None):\n    '''Detect bonds given the coordinates (r_array) and types of the \n    atoms involved (type_array), based on their covalent radii.\n    \n    To fine-tune the detection, it is possible to set a **threshold** and a \n    maximum search radius **maxradius**, and the radii lookup **radii_dict**.\n    '''\n    if radii_dict is None:\n        covalent_radii = cdb.get('data', 'covalentdict')\n    else:\n        covalent_radii = radii_dict\n    \n    # Find all the pairs\n    ck = cKDTree(r_array)\n    pairs = ck.query_pairs(maxradius)\n    \n    bonds = []\n    for i,j in pairs:\n        a, b = covalent_radii[type_array[i]], covalent_radii[type_array[j]]\n        rval = a + b\n        \n        thr_a = rval - threshold\n        thr_b = rval + threshold \n        \n        thr_a2 = thr_a**2\n        thr_b2 = thr_b**2\n        \n        dr2  = ((r_array[i] - r_array[j])**2).sum()\n        # print(thr_a, dr2**0.5, thr_b)\n        if thr_a2 < dr2 < thr_b2:\n            bonds.append((i, j))\n    return np.array(bonds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate the molecule to a new position * r*.", "response": "def move_to(self, r):\n        '''Translate the molecule to a new position *r*.\n        '''\n        dx = r - self.r_array[0]\n        self.r_array += dx"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef periodic_distance(a, b, periodic):\n    '''Periodic distance between two arrays. Periodic is a 3\n    dimensional array containing the 3 box sizes.\n\n    '''\n    delta = np.abs(a - b)\n    delta = np.where(delta > 0.5 * periodic, periodic - delta, delta)\n    return np.sqrt((delta ** 2).sum(axis=-1))", "response": "Periodic distance between two arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dipole moment of a neutral system.", "response": "def dipole_moment(r_array, charge_array):\n    '''Return the dipole moment of a neutral system.\n    '''\n    return np.sum(r_array * charge_array[:, np.newaxis], axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_gro_lines(lines):\n    '''Reusable parsing'''\n    title = lines.pop(0)\n    natoms = int(lines.pop(0))\n    atomlist = []\n\n    # I need r_array, type_array\n    datalist = []\n    for l in lines:\n        fields = l.split()\n        line_length = len(l)\n\n        if line_length in (45, 46, 69, 70):\n            #Only positions are provided\n            molidx = int(l[0:5])\n            moltyp = l[5:10].strip()\n            attyp = l[10:15].strip()\n            atidx = int(l[15:20])\n            rx = float(l[20:28])\n            ry = float(l[28:36])\n            rz = float(l[36:44])\n\n            hasvel = False\n            if line_length == 69:\n                hasvel = True\n                # Provide velocities\n                vx = float(l[44:52])\n                vy = float(l[52:60])\n                vz = float(l[60:68])\n\n            # Do I have to convert back the atom types, probably yes???\n            #if attyp.lower() not in symbol_list:\n            #    attyp = gro_to_cl[attyp]\n            datalist.append((molidx, moltyp, attyp, rx, ry, rz))\n        else:\n            # This is the box size\n            stuff  = [float(f) for f in fields]\n            a,b,c = stuff[0], stuff[1], stuff[2]\n            box_vectors = np.array([[a, 0, 0], [0, b, 0], [0, 0, c]])\n            break\n\n    dataarr = np.array(datalist,\n                       dtype=np.dtype([('f0', int), ('f1', object),\n                                       ('f2', object), ('f3', np.float64),\n                                       ('f4', np.float64), ('f5', np.float64)]\n                                      )\n                       )\n\n    # Molecule indices: unique elements in molidx\n    mol_id, mol_indices = np.unique(dataarr['f0'], return_index=True)\n    \n    maps = {('atom', 'molecule') : dataarr['f0'] - 1}\n    \n    r_array = np.vstack([dataarr['f3'],\n                         dataarr['f4'],\n                         dataarr['f5']]).transpose()\n    grotype_array = dataarr['f2']\n    grores_array = dataarr['f1'][mol_indices]\n    \n    molecule_export = np.array([dict(groname=g)\n                           for g in dataarr['f1'][mol_indices]])\n    atom_export = np.array([dict(grotype=g) for g in grotype_array])\n\n    # Gromacs Defaults to Unknown Atom type\n    \n    # We need to parse the gromacs type in some way...\n    # grotype_array = [re.sub('[0-9+-]+$', '', g) for g in grotype_array]\n    type_array = np.array([gro_to_cl.get(re.sub('[0-9+-]+$','', g), \"Unknown\") for g in grotype_array])\n\n    # Molecular Formula Arrays\n    mol_formula = []\n    end = len(r_array)\n    for i, _ in enumerate(mol_indices):\n        s = mol_indices[i]\n        e = mol_indices[i+1] if i+1 < len(mol_indices) else end\n        mol_formula.append(make_formula(type_array[s:e]))\n\n    mol_formula = np.array(mol_formula)\n\n    # n_mol, n_at\n    sys = System.from_arrays(r_array=r_array,\n                             maps=maps,\n                             type_array=type_array,\n                             atom_name=grotype_array,\n                             atom_export=atom_export,\n                             molecule_export=molecule_export,\n                             molecule_name=grores_array,\n                             box_vectors=box_vectors)\n    return sys", "response": "Reusable parsing of GRO file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distances_within(coords_a, coords_b, cutoff,\n                     periodic=False, method=\"simple\"):\n    \"\"\"Calculate distances between the array of coordinates *coord_a*\n    and *coord_b* within a certain cutoff.\n    \n    This function is a wrapper around different routines and data structures\n    for distance searches. It return a np.ndarray containing the distances.\n    \n    **Parameters**\n\n    coords_a: np.ndarray((N, 3), dtype=float)\n       First coordinate array\n    coords_b: np.ndarray((N, 3), dtype=float)\n       Second coordinate array\n    cutoff: float\n       Maximum distance to search for\n    periodic: False or np.ndarray((3,), dtype=float)\n       If False, don't consider periodic images. Otherwise\n       periodic is an array containing the periodicity in the\n       3 dimensions.\n    method: \"simple\" | \"cell-lists\"\n       The method to use. *simple* is a brute-force \n       distance search, *kdtree* uses scipy ``ckdtree`` module\n       (periodic not available) and *cell-lists* uses the cell\n       linked list method.\n    \"\"\"\n    mat = distance_matrix(coords_a, coords_b, cutoff, periodic, method)\n    return mat[mat.nonzero()]", "response": "Calculates the distances between the array of coordinates coord_a and coord_b within a certain cutoff."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distance_matrix(coords_a, coords_b, cutoff,\n                    periodic=False, method=\"simple\"):\n    \"\"\"Calculate distances matrix the array of coordinates *coord_a*\n    and *coord_b* within a certain cutoff.\n    \n    This function is a wrapper around different routines and data structures\n    for distance searches. It return a np.ndarray containing the distances.\n    \n    Returns a matrix with all the computed distances. When using the\n    \"cell-lists\" method it returns a scipy.sparse.dok_matrix.\n    \n    **Parameters**\n\n    coords_a: np.ndarray((N, 3), dtype=float)\n       First coordinate array\n    coords_b: np.ndarray((N, 3), dtype=float)\n       Second coordinate array\n    cutoff: float\n       Maximum distance to search for\n    periodic: False or np.ndarray((3,), dtype=float)\n       If False, don't consider periodic images. Otherwise\n       periodic is an array containing the periodicity in the\n       3 dimensions.\n    method: \"simple\" | \"cell-lists\"\n       The method to use. *simple* is a brute-force \n       distance search, and *cell-lists* uses the cell\n       linked list method.\n\n    \"\"\"\n    coords_a = np.array(coords_a)\n    coords_b = np.array(coords_b)\n    if method==\"simple\":\n        if periodic is not False:\n            return distance_array(coords_a, coords_b, cutoff=cutoff,\n                                  period=periodic.astype(np.double))\n        else:\n            dist = cdist(coords_a, coords_b)\n            dist[dist > cutoff] = 0\n            return dist\n            \n    elif method==\"cell-lists\":\n        if periodic is not False:\n            if np.any(cutoff > periodic/2):\n                raise Exception(\"Not working with such a big cutoff.\")\n            \n        # We need all positive elements\n        mina = coords_a[:, 0].min(), coords_a[:, 1].min(), coords_a[:, 2].min()\n        minb = coords_b[:, 0].min(), coords_b[:, 1].min(), coords_b[:, 2].min()\n        # Find the lowest        \n        origin = np.minimum(mina, minb)\n        \n        a = CellLinkedList(coords_a - origin, cutoff, periodic)\n        b = CellLinkedList(coords_b - origin, cutoff, periodic)\n        dist = a.query_distances_other(b, cutoff)\n        return dist\n            \n            \n    else:\n        raise Exception(\"Method {} not available.\".format(method))", "response": "Calculates the distances matrix between two array of coordinates coords_a and coords_b within a certain cutoff."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef overlapping_points(coords_a, coords_b, cutoff, periodic=False):\n    '''Return the indices of *coords_b* points that overlap with\n    *coords_a* points. The overlap is calculated based on *cutoff*.\n\n    **Parameters**\n    \n    coords_a: np.ndarray((NA, 3))\n    \n    coords_b: np.ndarray((NB, 3))\n    \n    cutoff: float\n       Distance within two points are considered overlapping.\n    \n    periodic: False or np.ndarray(3)\n       Periodicity in x, y, z dimensions\n    \n    '''\n    \n    res = distance_matrix(coords_a, coords_b, periodic=periodic, \n                          cutoff=cutoff, method=\"cell-lists\")\n    overlaps = res.nonzero()[1]\n    return np.unique(overlaps)", "response": "Return the indices of coords_a * points that overlap with coords_b * points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_lattice_box(mol_list, mol_number, size,\n                       spacing=np.array([0.3, 0.3, 0.3])):\n    '''Make a box by placing the molecules specified in *mol_list* on\n    random points of an evenly spaced lattice.\n\n    Using a lattice automatically ensures that no two molecules are\n    overlapping.\n\n    **Parameters**\n\n    mol_list: list of Molecule instances\n       A list of each kind of molecules to add to the system.\n    mol_number: list of int\n       The number of molecules to place for each kind.\n    size: np.ndarray((3,), float)\n       The box size in nm\n    spacing: np.ndarray((3,), float), [0.3 0.3 0.3]\n       The lattice spacing in nm.\n\n    **Returns**\n    \n    A System instance.\n    \n    **Example**\n    \n    Typical box with 1000 water molecules randomly placed in a box of size\n    ``[2.0 2.0 2.0]``::\n\n      from chemlab.db import ChemlabDB\n      \n      # Example water molecule\n      water = ChemlabDB().get('molecule', 'example.water')\n      \n      s = random_water_box([water], [1000], [2.0, 2.0, 2.0])\n    \n    '''\n    # Generate the coordinates\n    positions = spaced_lattice(size, spacing)\n    # Randomize them\n    np.random.shuffle(positions)\n\n    n_mol = sum(mol_number)\n    n_atoms = sum(nmol*mol.n_atoms for mol, nmol in zip(mol_list, mol_number))\n    \n    # Assert that we have enough space\n    assert len(positions) >= n_mol, \"Can't fit {} molecules in {} spaces\".format(n_mol,\n                                                                                   len(positions))\n    box_vectors = np.zeros((3, 3))\n    box_vectors[0,0] = size[0]\n    box_vectors[1,1] = size[1]\n    box_vectors[2,2] = size[2]\n    \n    # Initialize a system\n    s = System.empty()\n    with s.batch() as b:\n        mol_list = [m.copy() for m in mol_list]\n        # Add the molecules\n        pi = 0\n        for i, mol in enumerate(mol_list):\n            for j in range(mol_number[i]):\n                mol.move_to(positions[pi])\n                b.append(mol.copy())\n                pi += 1\n            \n    return s", "response": "Generates a random lattice box from a list of molecules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_box(molecules, total=None, proportions=None, size=[1.,1.,1.], maxtries=100):\n    '''Create a System made of a series of random molecules.\n    \n    Parameters:\n    \n    total:\n    molecules:\n    proportions:\n    '''\n    \n    # Setup proportions to be right\n    if proportions is None:\n        proportions = np.ones(len(molecules)) / len(molecules)\n    else:\n        proportions = np.array(proportions)\n    \n    size = np.array(size)\n    \n    tree = CoverTree(metric=\"periodic\", metric_args={'cell_lengths': size})\n    \n    type_array = []\n    result = []\n    vdw_radii = []\n    max_vdw = max(vdw_radius(np.concatenate([m.type_array for m in molecules])))\n    \n    first = True\n    for l, n in enumerate((proportions * total).astype(int)):\n        \n        # We try to insert each molecule    \n        for i in range(n):\n            \n            # Attempts\n            for k in range(maxtries):\n                template = molecules[l].copy()\n                reference = np.random.uniform(0, 1, 3) * size\n                r_array = template.r_array + reference\n\n                # Find all collision candidates\n                pts_list, distances_list = tree.query_ball_many(r_array, vdw_radius(template.type_array) + max_vdw)\n                # print pts_list, distances_list\n                # Check if there is any collision\n                ok = True\n                for i, (dist, pts) in enumerate(zip(distances_list, pts_list)):\n                    if len(dist) == 0:\n                        break\n\n                    found_vdw = np.array([vdw_radii[p] for p in pts])\n                    ok &= all(dist > found_vdw + vdw_radius(template.type_array[i]))\n\n                if ok:\n                    tree.insert_many(r_array)\n                    template.r_array = r_array\n                    result.append(template)\n                    vdw_radii.extend(vdw_radius(template.type_array))\n                    break\n            if not ok:\n                raise Exception(\"Trials exceeded\")\n    \n    system = System(result)\n    system.box_vectors[0, 0] = size[0]\n    system.box_vectors[1, 1] = size[1]\n    system.box_vectors[2, 2] = size[2]\n    return system", "response": "Create a random system of a series of random molecules."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nschedules a function to be called repeated time.", "response": "def schedule(self, callback, timeout=100):\n        '''Schedule a function to be called repeated time.\n\n        This method can be used to perform animations.\n        \n        **Example**\n        \n        This is a typical way to perform an animation, just::\n        \n            from chemlab.graphics.qt import QtViewer\n            from chemlab.graphics.renderers import SphereRenderer\n            \n            v = QtViewer()\n            sr = v.add_renderer(SphereRenderer, centers, radii, colors)\n             \n            def update():\n               # calculate new_positions\n               sr.update_positions(new_positions)\n               v.widget.repaint()\n            \n            v.schedule(update)\n            v.run()\n        \n        .. note:: remember to call QtViewer.widget.repaint() each\n                  once you want to update the display.\n        \n\n        **Parameters**\n        \n        callback: function()\n            A function that takes no arguments that will be \n            called at intervals.\n        timeout: int\n            Time in milliseconds between calls of the *callback*\n            function.\n\n        **Returns**\n        a `QTimer`, to stop the animation you can use `Qtimer.stop`\n        '''\n        timer = QTimer(self)\n        timer.timeout.connect(callback)\n        timer.start(timeout)\n        return timer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_renderer(self, klass, *args, **kwargs):\n        '''Add a renderer to the current scene.\n        \n        **Parameter**\n        \n        klass: renderer class\n            The renderer class to be added\n        args, kwargs:\n            Arguments used by the renderer constructor,\n            except for the *widget* argument.\n        \n        .. seealso:: :py:class:`~chemlab.graphics.renderers.AbstractRenderer`\n        .. seealso:: :doc:`/api/chemlab.graphics.renderers`\n        \n        **Return**\n\n        The istantiated renderer. You should keep the return value to\n        be able to update the renderer at run-time.\n\n        '''\n        renderer = klass(self.widget, *args, **kwargs)\n        self.widget.renderers.append(renderer)\n        return renderer", "response": "Add a renderer to the current scene."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_renderer(self, rend):\n        '''Remove a renderer from the current view.\n        \n        **Example**\n        \n        ::\n\n            rend = v.add_renderer(AtomRenderer)\n            v.remove_renderer(rend)\n\n        .. versionadded:: 0.3\n        '''\n        if rend in self.widget.renderers:\n            self.widget.renderers.remove(rend)\n        else:\n            raise Exception(\"The renderer is not in this viewer\")", "response": "Remove a renderer from the current view."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_ui(self, klass, *args, **kwargs):\n        '''Add an UI element for the current scene. The approach is\n        the same as renderers.\n\n        .. warning:: The UI api is not yet finalized\n\n        '''\n        ui = klass(self.widget, *args, **kwargs)\n        self.widget.uis.append(ui)\n        return ui", "response": "Add an UI element for the current scene. The approach is\n        the same as renderers. is\n       .. warning :: The UI api is not yet finalized."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a post processing effect to the current scene.", "response": "def add_post_processing(self, klass, *args, **kwargs):\n        '''Add a post processing effect to the current scene.\n        \n        The usage is as following::\n        \n            from chemlab.graphics.qt import QtViewer\n            from chemlab.graphics.postprocessing import SSAOEffect\n            \n            v = QtViewer()\n            effect = v.add_post_processing(SSAOEffect)\n        \n        .. seealso:: :doc:`/api/chemlab.graphics.postprocessing`\n        \n        **Return**\n        \n        an instance of :py:class:`~chemlab.graphics.postprocessing.base.AbstractEffect`\n        \n        .. versionadded:: 0.3\n        '''\n        pp = klass(self.widget, *args, **kwargs)\n        self.widget.post_processing.append(pp)\n        return pp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crystal(positions, molecules, group,\n            cellpar=[1.0, 1.0, 1.0, 90, 90, 90], repetitions=[1, 1, 1]):\n    '''Build a crystal from atomic positions, space group and cell\n    parameters.\n    \n    **Parameters**\n\n    positions: list of coordinates\n        A list of the atomic positions \n    molecules: list of Molecule\n        The molecules corresponding to the positions, the molecule will be\n        translated in all the equivalent positions.\n    group: int | str\n        Space group given either as its number in International Tables\n        or as its Hermann-Mauguin symbol.\n    repetitions:\n        Repetition of the unit cell in each direction\n    cellpar:\n        Unit cell parameters\n\n    This function was taken and adapted from the *spacegroup* module \n    found in `ASE <https://wiki.fysik.dtu.dk/ase/>`_.\n\n    The module *spacegroup* module was originally developed by Jesper\n    Frills.\n\n    '''\n    sp = Spacegroup(group)\n    sites, kind = sp.equivalent_sites(positions)\n\n    nx, ny, nz = repetitions\n    reptot = nx*ny*nz\n    \n    # Unit cell parameters\n    a,b,c = cellpar_to_cell(cellpar)\n    \n    cry = System()\n    i = 0\n    with cry.batch() as batch:\n        for x in range(nx):\n            for y in range(ny):\n                for z in range(nz):\n                    for s, ki in zip(sites, kind):\n                        tpl = molecules[ki]\n                        tpl.move_to(s[0]*a +s[1]*b + s[2]*c + a*x + b*y + c*z)\n                        batch.append(tpl.copy())\n\n    # Computing the box_vectors\n    cry.box_vectors = np.array([a*nx, b*ny, c*nz])\n    \n    return cry", "response": "Build a crystal from atomic positions molecules and group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_card(card, text, default=None):\n    match = re.search(card.lower() + r\"\\s*=\\s*(\\w+)\", text.lower())\n    return match.group(1) if match else default", "response": "Parse a card from an input string\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the intrinsic reaction coordinate calculation.", "response": "def _parse_irc(self):\n        \"\"\"Parse intrinsic reaction coordinate calculation.\n        returns a dictionary containing:\n\n        geometries : a list of Molecule instances representing each point in the IRC\n        energies   : a list of total energies (Hartree)\n        distances   : distance from the starting point in mass-weighted coords (bohr \\sqrt(amu))\n        \"\"\"\n        irc_geoms = sections(re.escape(\"***** NEXT POINT ON IRC FOUND *****\"),\n                             re.escape(\"INTERNUCLEAR DISTANCES (ANGS.)\"),\n                             self.text)\n        \n        # get and store the energy\n        energies = [entry.splitlines()[5] for entry in irc_geoms] # The total energy line\n        energies = [float(entry.split()[3]) for entry in energies]\n\n        # get and store the distance\n        distances = [entry.splitlines()[4] for entry in irc_geoms] # The path distance line\n        distances = [float(entry.split()[5]) for entry in distances]\n        \n        # strip the garbage\n        irc_geoms = ['\\n'.join(i.splitlines()[11:-1]) for i in irc_geoms]\n        irc_geoms = [self._parse_geometry(i) for i in irc_geoms]\n        \n        return {\"geometries\": irc_geoms,\n                \"energies\": energies,\n                \"distances\": distances}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a string and return a Molecule object from it.", "response": "def _parse_geometry(self, geom):\n        \"\"\"Parse a geometry string and return Molecule object from\n        it.\n\n        \"\"\"\n        atoms = []\n        for i, line in enumerate(geom.splitlines()):\n           sym, atno, x, y, z = line.split()\n           atoms.append(Atom(sym, [float(x), float(y), float(z)], id=i))\n        \n        return Molecule(atoms)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_optimize(self):\n        match = re.search(\"EQUILIBRIUM GEOMETRY LOCATED\", self.text)\n        spmatch = \"SADDLE POINT LOCATED\" in self.text\n        located = True if match or spmatch else False\n\n        points = grep_split(\" BEGINNING GEOMETRY SEARCH POINT NSERCH=\",\n                            self.text)\n        if self.tddft == \"excite\":\n            points = [self.parse_energy(point) for point in points[1:]]\n        else:\n            regex = re.compile(r'NSERCH:\\s+\\d+\\s+E=\\s+([+-]?\\d+\\.\\d+)')\n            points = [Energy(states=[State(0,None,float(m.group(1)), 0.0, 0.0)]) for m in regex.finditer(self.text)]\n        \n        # Error handling\n        if \"FAILURE TO LOCATE STATIONARY POINT, TOO MANY STEPS TAKEN\" in self.text:\n            self.errcode = GEOM_NOT_LOCATED\n            self.errmsg = \"too many steps taken: %i\"%len(points)\n        \n        if located:\n            self.errcode = OK\n        \n        return Optimize(points=points)", "response": "Parse the ouput resulted of a geometry optimization. Or a\n        saddle point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_tddft(self):\n        text = self.text\n        energies = sections(\"SUMMARY OF TDDFT RESULTS\",\n                            \"DONE WITH TD-DFT EXCITATION ENERGIES\",\n                            text)\n\n        lines = energies[0].splitlines()\n        regex = re.compile(\"\"\"\n                           \\s+(\\d+)   # State Number\n                           \\s+([ ^]+)  # State sym\n                           \\s+([+-]?\\d+\\.\\d+) # Tot Energy  \n                           \\s+([+-]?\\d+\\.\\d+) # Exc Energy\n                               (\\s+([+-]?\\d+\\.\\d+) # \n                                \\s+([+-]?\\d+\\.\\d+) # Dipole moment\n                                \\s+([+-]?\\d+\\.\\d+) # \n                                \\s+([+-]?\\d+\\.\\d+))? # Oscillator strength\n                           \"\"\", flags=re.VERBOSE)\n\n        states = []\n        for line in lines:\n            match = regex.match(line)\n            if match:\n                # Check for strange behaviour of symmetry\n                if not re.match(\"\\w+\",match.group(4)):\n                    raise ValueError(\"Strange symmetry string: %s\"%match.group(4))\n                 \n                osc_strength = float(match.group(9)) if match.group(9) else 0.000\n                states.append({\"num\": int(match.group(1)), \"sym\": match.group(4),\n                               \"strength\": osc_strength})\n        return {\"states\": states}", "response": "Parse the output resulted from a tddft calculation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_attributes(self, bounds, radii, colors):\n        \n        self.n_cylinders = len(bounds)\n        self.is_empty = True if self.n_cylinders == 0 else False\n        \n        if self.is_empty:\n            self.bounds = bounds\n            self.radii = radii\n            self.colors = colors\n            return # Do nothing\n        \n        # We pass the starting position 8 times, and each of these has\n        # a mapping to the bounding box corner.\n        self.bounds = np.array(bounds, dtype='float32')\n        vertices, directions = self._gen_bounds(self.bounds) \n        \n        self.radii = np.array(radii, dtype='float32')\n        prim_radii = self._gen_radii(self.radii)\n\n        self.colors = np.array(colors, dtype='uint8')\n        prim_colors = self._gen_colors(self.colors)\n       \n        local = np.array([\n           # First face -- front\n          0.0, 0.0, 0.0,\n          0.0, 1.0, 0.0, \n          1.0, 1.0, 0.0,\n        \n          0.0, 0.0, 0.0,\n          1.0, 1.0, 0.0,\n          1.0, 0.0, 0.0,\n\n          # Second face -- back\n          0.0, 0.0, 1.0,\n          0.0, 1.0, 1.0, \n          1.0, 1.0, 1.0,\n\n          0.0, 0.0, 1.0,\n          1.0, 1.0, 1.0,\n          1.0, 0.0, 1.0,\n          \n          # Third face -- left\n          0.0, 0.0, 0.0,\n          0.0, 0.0, 1.0, \n          0.0, 1.0, 1.0,\n\n          0.0, 0.0, 0.0,\n          0.0, 1.0, 1.0,\n          0.0, 1.0, 0.0,\n\n          # Fourth face -- right\n          1.0, 0.0, 0.0,\n          1.0, 0.0, 1.0, \n          1.0, 1.0, 1.0,\n\n          1.0, 0.0, 0.0,\n          1.0, 1.0, 1.0,\n          1.0, 1.0, 0.0,\n\n          # Fifth face -- up\n          0.0, 1.0, 0.0,\n          0.0, 1.0, 1.0,\n          1.0, 1.0, 1.0,\n\n          0.0, 1.0, 0.0,\n          1.0, 1.0, 1.0,\n          1.0, 1.0, 0.0,\n          \n          # Sixth face -- down\n          0.0, 0.0, 0.0,\n          0.0, 0.0, 1.0,\n          1.0, 0.0, 1.0,\n\n          0.0, 0.0, 0.0,\n          1.0, 0.0, 1.0,\n          1.0, 0.0, 0.0,\n          \n        ]).astype('float32')\n        \n        local = np.tile(local, self.n_cylinders)\n        \n        self._verts_vbo = VertexBuffer(vertices,GL_DYNAMIC_DRAW)\n        self._directions_vbo = VertexBuffer(directions, GL_DYNAMIC_DRAW)\n        \n        self._local_vbo = VertexBuffer(local,GL_DYNAMIC_DRAW)\n        self._color_vbo = VertexBuffer(prim_colors, GL_DYNAMIC_DRAW)\n        self._radii_vbo = VertexBuffer(prim_radii, GL_DYNAMIC_DRAW)", "response": "Reinitialize the buffers to accomodate the new hasical attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_bounds(self, bounds):\n        '''Update the bounds inplace'''\n        self.bounds = np.array(bounds, dtype='float32')\n        vertices, directions = self._gen_bounds(self.bounds) \n        \n        self._verts_vbo.set_data(vertices)\n        self._directions_vbo.set_data(directions)\n        self.widget.update()", "response": "Update the bounds inplace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the radii inplace", "response": "def update_radii(self, radii):\n        '''Update the radii inplace'''\n        self.radii = np.array(radii, dtype='float32')\n        prim_radii = self._gen_radii(self.radii)\n        \n        self._radii_vbo.set_data(prim_radii)\n        self.widget.update()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the colors inplace", "response": "def update_colors(self, colors):\n        '''Update the colors inplace'''\n        self.colors = np.array(colors, dtype='uint8')\n        prim_colors = self._gen_colors(self.colors)\n        \n        self._color_vbo.set_data(prim_colors)\n        self.widget.update()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_process_async(process):\n    for fd in [process.stderr.fileno(), process.stdout.fileno()]:\n        fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n        fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)", "response": "Make the process read and write methods unblocking"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the gromacs directory structure.", "response": "def make_gromacs(simulation, directory, clean=False):\n    \"\"\"Create gromacs directory structure\"\"\"\n    if clean is False and os.path.exists(directory):\n        raise ValueError(\n            'Cannot override {}, use option clean=True'.format(directory))\n    else:\n        shutil.rmtree(directory, ignore_errors=True)\n        os.mkdir(directory)\n\n    # Check custom simulation potential\n    \n    if simulation.potential.intermolecular.type == 'custom':\n        \n        for pair in simulation.potential.intermolecular.special_pairs:\n            table = to_table(simulation.potential.intermolecular.pair_interaction(*pair), \n                             simulation.cutoff)\n            fname1 = os.path.join(directory, \n                                  'table_{}_{}.xvg'.format(pair[0], pair[1]))\n            fname2 = os.path.join(directory, \n                                  'table_{}_{}.xvg'.format(pair[1], pair[0]))\n            \n            with open(fname1, 'w') as fd:\n                fd.write(table)\n\n            with open(fname2, 'w') as fd:\n                fd.write(table)\n            \n\n        ndx = {'System' : np.arange(simulation.system.n_atoms, dtype='int')}\n        for particle in simulation.potential.intermolecular.particles:\n            idx = simulation.system.where(atom_name=particle)['atom'].nonzero()[0]\n            ndx[particle] = idx\n        \n        with open(os.path.join(directory, 'index.ndx'), 'w') as fd:\n            fd.write(to_ndx(ndx))\n            \n    # Parameter file\n    mdpfile = to_mdp(simulation)\n    with open(os.path.join(directory, 'grompp.mdp'), 'w') as fd:\n        fd.write(mdpfile)\n\n    # Topology file\n    topfile = to_top(simulation.system, simulation.potential)\n    with open(os.path.join(directory, 'topol.top'), 'w') as fd:\n        fd.write(topfile)\n\n    # Simulation file\n    datafile(os.path.join(directory, 'conf.gro'),\n             'w').write('system', simulation.system)\n\n    return directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the triangle vertices.", "response": "def update_vertices(self, vertices):\n        \"\"\"\n        Update the triangle vertices.\n        \"\"\"\n\n        vertices = np.array(vertices, dtype=np.float32)\n        self._vbo_v.set_data(vertices)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the triangle normals.", "response": "def update_normals(self, normals):\n        \"\"\"\n        Update the triangle normals.\n        \"\"\"\n\n        normals = np.array(normals, dtype=np.float32)\n        self._vbo_n.set_data(normals)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_ticks(self, number):\n        '''Set the number of frames to animate.\n\n        '''\n        self.max_index = number\n        self.current_index = 0\n        self.slider.setMaximum(self.max_index-1)\n        self.slider.setMinimum(0)\n        self.slider.setPageStep(1)", "response": "Set the number of frames to animate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the time indicator in the interface.", "response": "def set_text(self, text):\n        '''Update the time indicator in the interface.\n\n        '''\n        self.traj_controls.timelabel.setText(self.traj_controls._label_tmp.format(text))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the function to be called when it s time to display a frame.", "response": "def update_function(self, func, frames=None):\n        '''Set the function to be called when it's time to display a frame.\n\n        *func* should be a function that takes one integer argument that\n        represents the frame that has to be played::\n\n            def func(index):\n                # Update the renderers to match the\n                # current animation index\n\n        '''\n        # Back-compatibility\n        if frames is not None:\n            self.traj_controls.set_ticks(frames)\n        \n        self._update_function = func"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotation_matrix(angle, direction):\n     d = numpy.array(direction, dtype=numpy.float64)\n     d /= numpy.linalg.norm(d)\n\n     eye = numpy.eye(3, dtype=numpy.float64)\n     ddt = numpy.outer(d, d)\n     skew = numpy.array([[    0,  d[2],  -d[1]],\n                      [-d[2],     0,  d[0]],\n                      [d[1], -d[0],    0]], dtype=numpy.float64)\n\n     mtx = ddt + numpy.cos(angle) * (eye - ddt) + numpy.sin(angle) * skew\n     \n     M = numpy.eye(4)\n     M[:3,:3] = mtx\n     return M", "response": "Create a rotation matrix corresponding to the rotation around a general\n     axis by a specified angle and direction."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns rotation angle and axis from rotation matrix.", "response": "def rotation_from_matrix(matrix):\n    \"\"\"Return rotation angle and axis from rotation matrix.\n\n    >>> angle = (random.random() - 0.5) * (2*math.pi)\n    >>> direc = numpy.random.random(3) - 0.5\n    >>> point = numpy.random.random(3) - 0.5\n    >>> R0 = rotation_matrix(angle, direc, point)\n    >>> angle, direc, point = rotation_from_matrix(R0)\n    >>> R1 = rotation_matrix(angle, direc, point)\n    >>> is_same_transform(R0, R1)\n    True\n\n    \"\"\"\n    R = numpy.array(matrix, dtype=numpy.float64, copy=False)\n    R33 = R[:3, :3]\n    # direction: unit eigenvector of R33 corresponding to eigenvalue of 1\n    w, W = numpy.linalg.eig(R33.T)\n    i = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\n    if not len(i):\n        raise ValueError(\"no unit eigenvector corresponding to eigenvalue 1\")\n    direction = numpy.real(W[:, i[-1]]).squeeze()\n    # point: unit eigenvector of R33 corresponding to eigenvalue of 1\n    w, Q = numpy.linalg.eig(R)\n    i = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\n    if not len(i):\n        raise ValueError(\"no unit eigenvector corresponding to eigenvalue 1\")\n    point = numpy.real(Q[:, i[-1]]).squeeze()\n    point /= point[3]\n    # rotation angle depending on direction\n    cosa = (numpy.trace(R33) - 1.0) / 2.0\n    if abs(direction[2]) > 1e-8:\n        sina = (R[1, 0] + (cosa-1.0)*direction[0]*direction[1]) / direction[2]\n    elif abs(direction[1]) > 1e-8:\n        sina = (R[0, 2] + (cosa-1.0)*direction[0]*direction[2]) / direction[1]\n    else:\n        sina = (R[2, 1] + (cosa-1.0)*direction[1]*direction[2]) / direction[0]\n    angle = math.atan2(sina, cosa)\n    return angle, direction, point"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scale_matrix(factor, origin=None, direction=None):\n    if direction is None:\n        # uniform scaling\n        M = numpy.diag([factor, factor, factor, 1.0])\n        if origin is not None:\n            M[:3, 3] = origin[:3]\n            M[:3, 3] *= 1.0 - factor\n    else:\n        # nonuniform scaling\n        direction = unit_vector(direction[:3])\n        factor = 1.0 - factor\n        M = numpy.identity(4)\n        M[:3, :3] -= factor * numpy.outer(direction, direction)\n        if origin is not None:\n            M[:3, 3] = (factor * numpy.dot(origin[:3], direction)) * direction\n    return M", "response": "Return matrix to scale by factor around origin in direction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning scaling factor origin and direction from scaling matrix.", "response": "def scale_from_matrix(matrix):\n    \"\"\"Return scaling factor, origin and direction from scaling matrix.\n\n    >>> factor = random.random() * 10 - 5\n    >>> origin = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> S0 = scale_matrix(factor, origin)\n    >>> factor, origin, direction = scale_from_matrix(S0)\n    >>> S1 = scale_matrix(factor, origin, direction)\n    >>> is_same_transform(S0, S1)\n    True\n    >>> S0 = scale_matrix(factor, origin, direct)\n    >>> factor, origin, direction = scale_from_matrix(S0)\n    >>> S1 = scale_matrix(factor, origin, direction)\n    >>> is_same_transform(S0, S1)\n    True\n\n    \"\"\"\n    M = numpy.array(matrix, dtype=numpy.float64, copy=False)\n    M33 = M[:3, :3]\n    factor = numpy.trace(M33) - 2.0\n    try:\n        # direction: unit eigenvector corresponding to eigenvalue factor\n        w, V = numpy.linalg.eig(M33)\n        i = numpy.where(abs(numpy.real(w) - factor) < 1e-8)[0][0]\n        direction = numpy.real(V[:, i]).squeeze()\n        direction /= vector_norm(direction)\n    except IndexError:\n        # uniform scaling\n        factor = (factor + 2.0) / 3.0\n        direction = None\n    # origin: any eigenvector corresponding to eigenvalue 1\n    w, V = numpy.linalg.eig(M)\n    i = numpy.where(abs(numpy.real(w) - 1.0) < 1e-8)[0]\n    if not len(i):\n        raise ValueError(\"no eigenvector corresponding to eigenvalue 1\")\n    origin = numpy.real(V[:, i[-1]]).squeeze()\n    origin /= origin[3]\n    return factor, origin, direction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef simple_clip_matrix(scale, znear, zfar, aspectratio=1.0):\n    '''Given the parameters for a frustum returns a 4x4 perspective\n    projection matrix \n    \n    Parameters:\n      float scale: \n      float znear,zfar: near/far plane z, float\n\n    Return: a 4x4 perspective matrix\n    '''\n    m = numpy.zeros((4,4))\n    m[0,0] = scale/aspectratio\n    m[1,1] = scale\n    m[2,2] = (zfar + znear) / (znear - zfar)\n    m[2,3] = 2*zfar*znear / (znear - zfar)\n    m[3,2] = -1\n\n    return m", "response": "This function returns a 4x4 perspective matrix that is a simple clip of the frustum."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decompose_matrix(matrix):\n    M = numpy.array(matrix, dtype=numpy.float64, copy=True).T\n    if abs(M[3, 3]) < _EPS:\n        raise ValueError(\"M[3, 3] is zero\")\n    M /= M[3, 3]\n    P = M.copy()\n    P[:, 3] = 0.0, 0.0, 0.0, 1.0\n    if not numpy.linalg.det(P):\n        raise ValueError(\"matrix is singular\")\n\n    scale = numpy.zeros((3, ))\n    shear = [0.0, 0.0, 0.0]\n    angles = [0.0, 0.0, 0.0]\n\n    if any(abs(M[:3, 3]) > _EPS):\n        perspective = numpy.dot(M[:, 3], numpy.linalg.inv(P.T))\n        M[:, 3] = 0.0, 0.0, 0.0, 1.0\n    else:\n        perspective = numpy.array([0.0, 0.0, 0.0, 1.0])\n\n    translate = M[3, :3].copy()\n    M[3, :3] = 0.0\n\n    row = M[:3, :3].copy()\n    scale[0] = vector_norm(row[0])\n    row[0] /= scale[0]\n    shear[0] = numpy.dot(row[0], row[1])\n    row[1] -= row[0] * shear[0]\n    scale[1] = vector_norm(row[1])\n    row[1] /= scale[1]\n    shear[0] /= scale[1]\n    shear[1] = numpy.dot(row[0], row[2])\n    row[2] -= row[0] * shear[1]\n    shear[2] = numpy.dot(row[1], row[2])\n    row[2] -= row[1] * shear[2]\n    scale[2] = vector_norm(row[2])\n    row[2] /= scale[2]\n    shear[1:] /= scale[2]\n\n    if numpy.dot(row[0], numpy.cross(row[1], row[2])) < 0:\n        numpy.negative(scale, scale)\n        numpy.negative(row, row)\n\n    angles[1] = math.asin(-row[0, 2])\n    if math.cos(angles[1]):\n        angles[0] = math.atan2(row[1, 2], row[2, 2])\n        angles[2] = math.atan2(row[0, 1], row[0, 0])\n    else:\n        #angles[0] = math.atan2(row[1, 0], row[1, 1])\n        angles[0] = math.atan2(-row[2, 1], row[1, 1])\n        angles[2] = 0.0\n\n    return scale, shear, angles, translate, perspective", "response": "Decomposes a homogeneous matrix into a sequence of transformations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef orthogonalization_matrix(lengths, angles):\n    a, b, c = lengths\n    angles = numpy.radians(angles)\n    sina, sinb, _ = numpy.sin(angles)\n    cosa, cosb, cosg = numpy.cos(angles)\n    co = (cosa * cosb - cosg) / (sina * sinb)\n    return numpy.array([\n        [ a*sinb*math.sqrt(1.0-co*co),  0.0,    0.0, 0.0],\n        [-a*sinb*co,                    b*sina, 0.0, 0.0],\n        [ a*cosb,                       b*cosa, c,   0.0],\n        [ 0.0,                          0.0,    0.0, 1.0]])", "response": "Return orthogonalization matrix for crystallographic cell coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an affine transform matrix to register two point sets.", "response": "def affine_matrix_from_points(v0, v1, shear=True, scale=True, usesvd=True):\n    \"\"\"Return affine transform matrix to register two point sets.\n\n    v0 and v1 are shape (ndims, \\*) arrays of at least ndims non-homogeneous\n    coordinates, where ndims is the dimensionality of the coordinate space.\n\n    If shear is False, a similarity transformation matrix is returned.\n    If also scale is False, a rigid/Eucledian transformation matrix\n    is returned.\n\n    By default the algorithm by Hartley and Zissermann [15] is used.\n    If usesvd is True, similarity and Eucledian transformation matrices\n    are calculated by minimizing the weighted sum of squared deviations\n    (RMSD) according to the algorithm by Kabsch [8].\n    Otherwise, and if ndims is 3, the quaternion based algorithm by Horn [9]\n    is used, which is slower when using this Python implementation.\n\n    The returned matrix performs rotation, translation and uniform scaling\n    (if specified).\n\n    >>> v0 = [[0, 1031, 1031, 0], [0, 0, 1600, 1600]]\n    >>> v1 = [[675, 826, 826, 677], [55, 52, 281, 277]]\n    >>> affine_matrix_from_points(v0, v1)\n    array([[   0.14549,    0.00062,  675.50008],\n           [   0.00048,    0.14094,   53.24971],\n           [   0.     ,    0.     ,    1.     ]])\n    >>> T = translation_matrix(numpy.random.random(3)-0.5)\n    >>> R = random_rotation_matrix(numpy.random.random(3))\n    >>> S = scale_matrix(random.random())\n    >>> M = concatenate_matrices(T, R, S)\n    >>> v0 = (numpy.random.rand(4, 100) - 0.5) * 20\n    >>> v0[3] = 1\n    >>> v1 = numpy.dot(M, v0)\n    >>> v0[:3] += numpy.random.normal(0, 1e-8, 300).reshape(3, -1)\n    >>> M = affine_matrix_from_points(v0[:3], v1[:3])\n    >>> numpy.allclose(v1, numpy.dot(M, v0))\n    True\n\n    More examples in superimposition_matrix()\n\n    \"\"\"\n    v0 = numpy.array(v0, dtype=numpy.float64, copy=True)\n    v1 = numpy.array(v1, dtype=numpy.float64, copy=True)\n\n    ndims = v0.shape[0]\n    if ndims < 2 or v0.shape[1] < ndims or v0.shape != v1.shape:\n        raise ValueError(\"input arrays are of wrong shape or type\")\n\n    # move centroids to origin\n    t0 = -numpy.mean(v0, axis=1)\n    M0 = numpy.identity(ndims+1)\n    M0[:ndims, ndims] = t0\n    v0 += t0.reshape(ndims, 1)\n    t1 = -numpy.mean(v1, axis=1)\n    M1 = numpy.identity(ndims+1)\n    M1[:ndims, ndims] = t1\n    v1 += t1.reshape(ndims, 1)\n\n    if shear:\n        # Affine transformation\n        A = numpy.concatenate((v0, v1), axis=0)\n        u, s, vh = numpy.linalg.svd(A.T)\n        vh = vh[:ndims].T\n        B = vh[:ndims]\n        C = vh[ndims:2*ndims]\n        t = numpy.dot(C, numpy.linalg.pinv(B))\n        t = numpy.concatenate((t, numpy.zeros((ndims, 1))), axis=1)\n        M = numpy.vstack((t, ((0.0,)*ndims) + (1.0,)))\n    elif usesvd or ndims != 3:\n        # Rigid transformation via SVD of covariance matrix\n        u, s, vh = numpy.linalg.svd(numpy.dot(v1, v0.T))\n        # rotation matrix from SVD orthonormal bases\n        R = numpy.dot(u, vh)\n        if numpy.linalg.det(R) < 0.0:\n            # R does not constitute right handed system\n            R -= numpy.outer(u[:, ndims-1], vh[ndims-1, :]*2.0)\n            s[-1] *= -1.0\n        # homogeneous transformation matrix\n        M = numpy.identity(ndims+1)\n        M[:ndims, :ndims] = R\n    else:\n        # Rigid transformation matrix via quaternion\n        # compute symmetric matrix N\n        xx, yy, zz = numpy.sum(v0 * v1, axis=1)\n        xy, yz, zx = numpy.sum(v0 * numpy.roll(v1, -1, axis=0), axis=1)\n        xz, yx, zy = numpy.sum(v0 * numpy.roll(v1, -2, axis=0), axis=1)\n        N = [[xx+yy+zz, 0.0,      0.0,      0.0],\n             [yz-zy,    xx-yy-zz, 0.0,      0.0],\n             [zx-xz,    xy+yx,    yy-xx-zz, 0.0],\n             [xy-yx,    zx+xz,    yz+zy,    zz-xx-yy]]\n        # quaternion: eigenvector corresponding to most positive eigenvalue\n        w, V = numpy.linalg.eigh(N)\n        q = V[:, numpy.argmax(w)]\n        q /= vector_norm(q)  # unit quaternion\n        # homogeneous transformation matrix\n        M = quaternion_matrix(q)\n\n    if scale and not shear:\n        # Affine transformation; scale is ratio of RMS deviations from centroid\n        v0 *= v0\n        v1 *= v1\n        M[:ndims, :ndims] *= math.sqrt(numpy.sum(v1) / numpy.sum(v0))\n\n    # move centroids back\n    M = numpy.dot(numpy.linalg.inv(M1), numpy.dot(M, M0))\n    M /= M[ndims, ndims]\n    return M"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef superimposition_matrix(v0, v1, scale=False, usesvd=True):\n    v0 = numpy.array(v0, dtype=numpy.float64, copy=False)[:3]\n    v1 = numpy.array(v1, dtype=numpy.float64, copy=False)[:3]\n    return affine_matrix_from_points(v0, v1, shear=False,\n                                     scale=scale, usesvd=usesvd)", "response": "Return matrix to transform given 3D point set into second point set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quaternion_matrix(quaternion):\n    q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\n    n = numpy.dot(q, q)\n    if n < _EPS:\n        return numpy.identity(4)\n    q *= math.sqrt(2.0 / n)\n    q = numpy.outer(q, q)\n    return numpy.array([\n        [1.0-q[2, 2]-q[3, 3],     q[1, 2]-q[3, 0],     q[1, 3]+q[2, 0], 0.0],\n        [    q[1, 2]+q[3, 0], 1.0-q[1, 1]-q[3, 3],     q[2, 3]-q[1, 0], 0.0],\n        [    q[1, 3]-q[2, 0],     q[2, 3]+q[1, 0], 1.0-q[1, 1]-q[2, 2], 0.0],\n        [                0.0,                 0.0,                 0.0, 1.0]])", "response": "Return homogeneous rotation matrix from quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning quaternion from rotation matrix.", "response": "def quaternion_from_matrix(matrix, isprecise=False):\n    \"\"\"Return quaternion from rotation matrix.\n\n    If isprecise is True, the input matrix is assumed to be a precise rotation\n    matrix and a faster algorithm is used.\n\n    >>> q = quaternion_from_matrix(numpy.identity(4), True)\n    >>> numpy.allclose(q, [1, 0, 0, 0])\n    True\n    >>> q = quaternion_from_matrix(numpy.diag([1, -1, -1, 1]))\n    >>> numpy.allclose(q, [0, 1, 0, 0]) or numpy.allclose(q, [0, -1, 0, 0])\n    True\n    >>> R = rotation_matrix(0.123, (1, 2, 3))\n    >>> q = quaternion_from_matrix(R, True)\n    >>> numpy.allclose(q, [0.9981095, 0.0164262, 0.0328524, 0.0492786])\n    True\n    >>> R = [[-0.545, 0.797, 0.260, 0], [0.733, 0.603, -0.313, 0],\n    ...      [-0.407, 0.021, -0.913, 0], [0, 0, 0, 1]]\n    >>> q = quaternion_from_matrix(R)\n    >>> numpy.allclose(q, [0.19069, 0.43736, 0.87485, -0.083611])\n    True\n    >>> R = [[0.395, 0.362, 0.843, 0], [-0.626, 0.796, -0.056, 0],\n    ...      [-0.677, -0.498, 0.529, 0], [0, 0, 0, 1]]\n    >>> q = quaternion_from_matrix(R)\n    >>> numpy.allclose(q, [0.82336615, -0.13610694, 0.46344705, -0.29792603])\n    True\n    >>> R = random_rotation_matrix()\n    >>> q = quaternion_from_matrix(R)\n    >>> is_same_transform(R, quaternion_matrix(q))\n    True\n\n    \"\"\"\n    M = numpy.array(matrix, dtype=numpy.float64, copy=False)[:4, :4]\n    if isprecise:\n        q = numpy.empty((4, ))\n        t = numpy.trace(M)\n        if t > M[3, 3]:\n            q[0] = t\n            q[3] = M[1, 0] - M[0, 1]\n            q[2] = M[0, 2] - M[2, 0]\n            q[1] = M[2, 1] - M[1, 2]\n        else:\n            i, j, k = 1, 2, 3\n            if M[1, 1] > M[0, 0]:\n                i, j, k = 2, 3, 1\n            if M[2, 2] > M[i, i]:\n                i, j, k = 3, 1, 2\n            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n            q[i] = t\n            q[j] = M[i, j] + M[j, i]\n            q[k] = M[k, i] + M[i, k]\n            q[3] = M[k, j] - M[j, k]\n        q *= 0.5 / math.sqrt(t * M[3, 3])\n    else:\n        m00 = M[0, 0]\n        m01 = M[0, 1]\n        m02 = M[0, 2]\n        m10 = M[1, 0]\n        m11 = M[1, 1]\n        m12 = M[1, 2]\n        m20 = M[2, 0]\n        m21 = M[2, 1]\n        m22 = M[2, 2]\n        # symmetric matrix K\n        K = numpy.array([[m00-m11-m22, 0.0,         0.0,         0.0],\n                         [m01+m10,     m11-m00-m22, 0.0,         0.0],\n                         [m02+m20,     m12+m21,     m22-m00-m11, 0.0],\n                         [m21-m12,     m02-m20,     m10-m01,     m00+m11+m22]])\n        K /= 3.0\n        # quaternion is eigenvector of K that corresponds to largest eigenvalue\n        w, V = numpy.linalg.eigh(K)\n        q = V[[3, 0, 1, 2], numpy.argmax(w)]\n    if q[0] < 0.0:\n        numpy.negative(q, q)\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning multiplication of two quaternions.", "response": "def quaternion_multiply(quaternion1, quaternion0):\n    \"\"\"Return multiplication of two quaternions.\n\n    >>> q = quaternion_multiply([4, 1, -2, 3], [8, -5, 6, 7])\n    >>> numpy.allclose(q, [28, -44, -14, 48])\n    True\n\n    \"\"\"\n    w0, x0, y0, z0 = quaternion0\n    w1, x1, y1, z1 = quaternion1\n    return numpy.array([-x1*x0 - y1*y0 - z1*z0 + w1*w0,\n                         x1*w0 + y1*z0 - z1*y0 + w1*x0,\n                        -x1*z0 + y1*w0 + z1*x0 + w1*y0,\n                         x1*y0 - y1*x0 + z1*w0 + w1*z0], dtype=numpy.float64)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quaternion_conjugate(quaternion):\n    q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\n    numpy.negative(q[1:], q[1:])\n    return q", "response": "Return conjugate of quaternion."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quaternion_inverse(quaternion):\n    q = numpy.array(quaternion, dtype=numpy.float64, copy=True)\n    numpy.negative(q[1:], q[1:])\n    return q / numpy.dot(q, q)", "response": "Return inverse of quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quaternion_imag(quaternion):\n    return numpy.array(quaternion[1:4], dtype=numpy.float64, copy=True)", "response": "Return imaginary part of quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arcball_map_to_sphere(point, center, radius):\n    v0 = (point[0] - center[0]) / radius\n    v1 = (center[1] - point[1]) / radius\n    n = v0*v0 + v1*v1\n    if n > 1.0:\n        # position outside of sphere\n        n = math.sqrt(n)\n        return numpy.array([v0/n, v1/n, 0.0])\n    else:\n        return numpy.array([v0, v1, math.sqrt(1.0 - n)])", "response": "Return unit sphere coordinates from window coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef vector_product(v0, v1, axis=0):\n    return numpy.cross(v0, v1, axis=axis)", "response": "Return vector perpendicular to vectors."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef angle_between_vectors(v0, v1, directed=True, axis=0):\n    v0 = numpy.array(v0, dtype=numpy.float64, copy=False)\n    v1 = numpy.array(v1, dtype=numpy.float64, copy=False)\n    dot = numpy.sum(v0 * v1, axis=axis)\n    dot /= vector_norm(v0, axis=axis) * vector_norm(v1, axis=axis)\n    return numpy.arccos(dot if directed else numpy.fabs(dot))", "response": "Return the angle between vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _import_module(name, package='vlfd', warn=True, prefix='_py_', ignore='_'):\n    import warnings\n    from importlib import import_module\n    try:\n        try:\n            module = import_module(name)\n        except ImportError:\n            module = import_module('.' + name, package=package)\n    except ImportError:\n        if warn:\n            warnings.warn(\"failed to import module %s\" % name)\n    else:\n        for attr in dir(module):\n            if ignore and attr.startswith(ignore):\n                continue\n            if prefix:\n                if attr in globals():\n                    globals()[prefix + attr] = globals()[attr]\n                elif warn:\n                    warnings.warn(\"no Python implementation of \" + attr)\n            globals()[attr] = getattr(module, attr)\n        return True", "response": "Try import all public attributes from module into global namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates current cursor window coordinates.", "response": "def drag(self, point):\n        \"\"\"Update current cursor window coordinates.\"\"\"\n        vnow = arcball_map_to_sphere(point, self._center, self._radius)\n        if self._axis is not None:\n            vnow = arcball_constrain_to_axis(vnow, self._axis)\n        self._qpre = self._qnow\n        t = numpy.cross(self._vdown, vnow)\n        if numpy.dot(t, t) < _EPS:\n            self._qnow = self._qdown\n        else:\n            q = [numpy.dot(self._vdown, vnow), t[0], t[1], t[2]]\n            self._qnow = quaternion_multiply(q, self._qdown)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_trajectory(name, format=None, skip=1):\n    '''Read a trajectory from a file.\n\n    .. seealso:: `chemlab.io.datafile`\n\n    '''\n    df = datafile(name, format=format)\n\n    ret = {}\n    t, coords = df.read('trajectory', skip=skip)\n    boxes = df.read('boxes')\n    ret['t'] = t\n    ret['coords'] = coords\n    ret['boxes'] = boxes\n\n    return ret", "response": "Read a trajectory from a file.\n   .. seealso :: ChEMlab. io. datafile"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a molecule from the remote location specified by url.", "response": "def load_remote_molecule(url, format=None):\n    '''Load a molecule from the remote location specified by *url*.\n\n    **Example**\n\n    ::\n\n        load_remote_molecule('https://raw.github.com/chemlab/chemlab-testdata/master/benzene.mol')\n\n    '''\n    filename, headers = urlretrieve(url)\n    return load_molecule(filename, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a system from the remote location specified by url.", "response": "def load_remote_system(url, format=None):\n    '''Load a system from the remote location specified by *url*.\n\n    **Example**\n\n    ::\n\n        load_remote_system('https://raw.github.com/chemlab/chemlab-testdata/master/naclwater.gro')\n    '''\n    filename, headers = urlretrieve(url)\n    return load_system(filename, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a trajectory file from a remote location specified by url.", "response": "def load_remote_trajectory(url, format=None, skip=1):\n    '''Load a trajectory file from a remote location specified by *url*.\n\n    .. seealso:: load_remote_system\n\n    '''\n    filename, headers = urlretrieve(url)\n    return load_trajectory(filename, format, skip)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_atoms(indices):\n    '''Select atoms by their indices.\n\n    You can select the first 3 atoms as follows::\n\n      select_atoms([0, 1, 2])\n    \n    Return the current selection dictionary.\n\n    '''\n    rep = current_representation()\n    rep.select({'atoms': Selection(indices, current_system().n_atoms)})\n    return rep.selection_state", "response": "Select atoms by their indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting the bonds connected to the currently selected atoms.", "response": "def select_connected_bonds():\n    '''Select the bonds connected to the currently selected atoms.'''\n    s = current_system()\n    start, end = s.bonds.transpose()\n    selected = np.zeros(s.n_bonds, 'bool')\n    for i in selected_atoms():\n        selected |= (i == start) | (i == end)\n\n    csel = current_selection()\n    bsel = csel['bonds'].add(\n        Selection(selected.nonzero()[0], s.n_bonds))\n    \n    ret = csel.copy()\n    ret['bonds'] = bsel\n\n    return select_selection(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_molecules(name):\n    '''Select all the molecules corresponding to the formulas.'''\n    mol_formula = current_system().get_derived_molecule_array('formula')\n    mask = mol_formula == name\n    ind = current_system().mol_to_atom_indices(mask.nonzero()[0])\n\n    selection = {'atoms': Selection(ind, current_system().n_atoms)}\n\n    # Need to find the bonds between the atoms\n    b = current_system().bonds\n    if len(b) == 0:\n        selection['bonds'] = Selection([], 0)\n    else:\n        molbonds = np.zeros(len(b), 'bool')\n        for i in ind:\n            matching = (i == b).sum(axis=1).astype('bool')\n            molbonds[matching] = True\n        \n        selection['bonds'] = Selection(molbonds.nonzero()[0], len(b))\n\n    return select_selection(selection)", "response": "Select all the molecules corresponding to the formulas."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hide_selected():    \n    '''Hide the selected objects.'''\n    ss = current_representation().selection_state\n    hs = current_representation().hidden_state\n    res = {}\n    \n    for k in ss:\n        res[k] = hs[k].add(ss[k])\n    \n    current_representation().hide(res)", "response": "Hide the selected objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unhide_selected():\n    '''Unhide the selected objects'''\n    \n    hidden_state = current_representation().hidden_state\n    selection_state = current_representation().selection_state\n\n    res = {}\n    # Take the hidden state and flip the selected atoms bits.\n    for k in selection_state:\n        visible = hidden_state[k].invert()\n        visible_and_selected = visible.add(selection_state[k]) # Add some atoms to be visible\n        res[k] = visible_and_selected.invert()\n    \n    current_representation().hide(res)", "response": "Unhide the selected objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef orbit_y(self, angle):\n        '''Orbit around the point ``Camera.pivot`` by the angle\n        *angle* expressed in radians. The axis of rotation is the\n        camera \"right\" vector, ``Camera.a``.\n\n        In practice, we move around a point like if we were on a Ferris\n        wheel.\n\n        '''\n        \n        # Subtract pivot point\n        self.position -= self.pivot\n        \n        # Rotate\n        rot = rotation_matrix(-angle, self.b)[:3,:3]\n        self.position = np.dot(rot, self.position)\n        \n        # Add again the pivot point\n        self.position += self.pivot\n        \n        self.a = np.dot(rot, self.a)\n        self.b = np.dot(rot, self.b)\n        self.c = np.dot(rot, self.c)", "response": "Orbit around the point Camera. pivot by the angle in radians."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mouse_zoom(self, inc):\n        '''Convenience function to implement a zoom function.\n\n        This is achieved by moving ``Camera.position`` in the\n        direction of the ``Camera.c`` vector.\n\n        '''\n        # Square Distance from pivot\n        dsq = np.linalg.norm(self.position - self.pivot)\n        minsq = 1.0**2  # How near can we be to the pivot\n        maxsq = 7.0**2 # How far can we go \n\n        scalefac = 0.25\n\n        if dsq > maxsq and inc < 0: \n            # We're going too far\n            pass\n        elif dsq < minsq and inc > 0:\n            # We're going too close\n            pass\n        else:\n            # We're golden\n            self.position += self.c*inc*scalefac", "response": "Convenience function to implement a zoom function. This is achieved by moving the camera. position in the camera. c vector in the camera. c vector."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unproject(self, x, y, z=-1.0):\n\n        source = np.array([x,y,z,1.0])\n    \n        # Invert the combined matrix\n        matrix = self.projection.dot(self.matrix)\n        IM = LA.inv(matrix)\n        res = np.dot(IM, source)\n        \n        return res[0:3]/res[3]", "response": "This function unprojects a 2d point into a 3d point in world coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit the current view to the correct zoom level to display all points.", "response": "def autozoom(self, points):\n        '''Fit the current view to the correct zoom level to display\n        all *points*.\n\n        The camera viewing direction and rotation pivot match the\n        geometric center of the points and the distance from that\n        point is calculated in order for all points to be in the field\n        of view. This is currently used to provide optimal\n        visualization for molecules and systems\n\n        **Parameters**\n        \n        points: np.ndarray((N, 3))\n             Array of points.\n        \n        '''\n        points = np.asarray(points)\n        extraoff = 0.01\n        \n        # Project points on the plane defined by camera up and right\n        # vector. This is achieved by using dot product on camera a\n        # and b vectors\n        abc = np.array([self.a, self.b, self.c])\n\n        old_geom_center = points.sum(axis=0)/len(points)\n        # Translate points\n        points = points.copy() + self.position\n        \n        # Translate position to geometric_center along directions\n        # a and b\n        geom_center = points.sum(axis=0)/len(points)\n        self.position += self.a * np.dot(geom_center, self.a)\n        self.position += self.b * np.dot(geom_center, self.b)\n\n        # Translate pivot to the geometric center\n        self.pivot = old_geom_center\n        \n        # Get the bounding sphere radius by searching for the most\n        # distant point\n        bound_radius = np.sqrt(((points-geom_center) * (points-geom_center)).sum(axis=1).max())\n\n        # Calculate the distance in order to have the most distant\n        # point in our field of view (top/bottom)\n        fov_topbottom = self.fov*np.pi/180.0\n        \n        dist = (bound_radius + self.z_near)/np.tan(fov_topbottom * 0.5)\n        \n        # Set the c-component of the position at the calculated distance\n        # 1) translate the position on the pivot\n        self.position = self.pivot.copy() \n        # 2) add the distance plus a little extra room\n        self.position -= self.c * (dist*(1 + extraoff))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef state(self):\n        '''Return the current camera state as a dictionary, it can be\n        restored with `Camera.restore`.\n\n        '''\n        return dict(a=self.a.tolist(), b=self.b.tolist(), c=self.c.tolist(),\n                    pivot=self.pivot.tolist(), position=self.position.tolist())", "response": "Return the current camera state as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore(self, state):\n        '''Restore the camera state, passed as a *state*\n        dictionary. You can obtain a previous state from the method\n        `Camera.state`.\n\n        '''\n        self.a = np.array(state['a']).copy()\n        self.b = np.array(state['b']).copy()\n        self.c = np.array(state['c']).copy()\n        self.pivot = np.array(state['pivot']).copy()\n        self.position = np.array(state['position']).copy()", "response": "Restore the camera state passed as a *state* dictionary. You can obtain a previous state from the method\n        Camera. state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ray_spheres_intersection(origin, direction, centers, radii):\n    b_v = 2.0 * ((origin - centers) * direction).sum(axis=1)\n    c_v = ((origin - centers)**2).sum(axis=1) - radii ** 2\n    det_v = b_v * b_v - 4.0 * c_v\n\n    inters_mask = det_v >= 0\n    intersections = (inters_mask).nonzero()[0]\n    distances = (-b_v[inters_mask] - np.sqrt(det_v[inters_mask])) / 2.0\n\n    # We need only the thing in front of us, that corresponts to\n    # positive distances.\n    dist_mask = distances > 0.0\n\n    # We correct this aspect to get an absolute distance\n    distances = distances[dist_mask]\n    intersections = intersections[dist_mask].tolist()\n\n    if intersections:\n        distances, intersections = zip(*sorted(zip(distances, intersections)))\n        return list(intersections), list(distances)\n    else:\n        return [], []", "response": "Calculate the intersection points between a ray and multiple\n    spheres."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts any color to rgb tuple.", "response": "def any_to_rgb(color):\n    '''If color is an rgb tuple return it, if it is a string, parse it\n    and return the respective rgb tuple.\n\n    '''\n    if isinstance(color, tuple):\n        if len(color) == 3:\n            color = color + (255,)\n        return color\n        \n    if isinstance(color, str):\n        return parse_color(color)\n        \n    raise ValueError(\"Color not recognized: {}\".format(color))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an HTML color string to RGB tuple", "response": "def html_to_rgb(colorstring):\n    \"\"\" convert #RRGGBB to an (R, G, B) tuple \"\"\"\n    colorstring = colorstring.strip()\n    if colorstring[0] == '#':\n        colorstring = colorstring[1:]\n\n    if len(colorstring) != 6:\n        raise ValueError(\"input #%s is not in #RRGGBB format\" % colorstring)\n\n    r, g, b = colorstring[:2], colorstring[2:4], colorstring[4:]\n    r, g, b = [int(n, 16) for n in (r, g, b)]\n\n    return (r, g, b, 255)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_color(color):\n    '''Return the RGB 0-255 representation of the current string\n    passed.\n\n    It first tries to match the string with DVI color names.\n\n    '''\n    \n    # Let's parse the color string\n    if isinstance(color, str):\n        # Try dvi names\n        try:\n            col = get(color)\n        except ValueError:\n            # String is not present\n            pass\n\n        # Try html names\n        try:\n            col = html_to_rgb(color)\n        except ValueError:\n            raise ValueError(\"Can't parse color string: {}'\".format(color))\n        \n    return col", "response": "Parses the color string passed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert RGB image data to HSV or HSL.", "response": "def rgb_to_hsl_hsv(a, isHSV=True):\n    \"\"\"\n    Converts RGB image data to HSV or HSL.\n    :param a: 3D array. Retval of numpy.asarray(Image.open(...), int)\n    :param isHSV: True = HSV, False = HSL\n    :return: H,S,L or H,S,V array\n    \"\"\"\n    R, G, B = a.T\n\n    m = np.min(a, 1).T\n    M = np.max(a, 1).T\n\n    C = M - m #chroma\n    Cmsk = C != 0\n\n    # Hue\n    H = np.zeros(R.shape, int)\n    mask = (M == R) & Cmsk\n    H[mask] = np.mod(60 * (G[mask] - B[mask]) / C[mask], 360)\n    mask = (M == G) & Cmsk\n    H[mask] = (60 * (B[mask] - R[mask]) / C[mask] + 120)\n    mask = (M == B) & Cmsk\n    H[mask] = (60 * (R[mask] - G[mask]) / C[mask] + 240)\n    H *= 255\n    H /= 360 # if you prefer, leave as 0-360, but don't convert to uint8\n\n\n    # Saturation\n    S = np.zeros(R.shape, int)\n\n    if isHSV:\n        # This code is for HSV:\n        # Value\n        V = M\n\n        # Saturation\n        S[Cmsk] = ((255 * C[Cmsk]) / V[Cmsk])\n        # H, S, and V are now defined as integers 0-255\n        return np.array((H.swapaxes(0, 1), S.swapaxes(0, 1), V.swapaxes(0, 1))).T\n    else:\n        # This code is for HSL:\n        # Value\n        L = 0.5 * (M + m)\n\n        # Saturation\n        S[Cmsk] = ((C[Cmsk]) / (1 - np.absolute(2 * L[Cmsk]/255.0 - 1)))\n        # H, S, and L are now defined as integers 0-255\n        return np.array((H.swapaxes(0, 1), S.swapaxes(0, 1), L.swapaxes(0, 1))).T"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hsl_to_rgb(arr):\n    H, S, L = arr.T\n    \n    H = (H.copy()/255.0) * 360\n    S = S.copy()/255.0\n    L = L.copy()/255.0\n    \n    C = (1 - np.absolute(2 * L - 1)) * S\n\n    Hp = H / 60.0\n    X = C * (1 - np.absolute(np.mod(Hp, 2) - 1))\n\n    # initilize with zero\n    R = np.zeros(H.shape, float)\n    G = np.zeros(H.shape, float)\n    B = np.zeros(H.shape, float)\n\n    # handle each case:\n\n    mask = (Hp >= 0) == ( Hp < 1)\n    R[mask] = C[mask]\n    G[mask] = X[mask]\n\n    mask = (Hp >= 1) == ( Hp < 2)\n    R[mask] = X[mask]\n    G[mask] = C[mask]\n\n    mask = (Hp >= 2) == ( Hp < 3)\n    G[mask] = C[mask]\n    B[mask] = X[mask]\n\n    mask = (Hp >= 3) == ( Hp < 4)\n    G[mask] = X[mask]\n    B[mask] = C[mask]\n\n    mask = (Hp >= 4) == ( Hp < 5)\n    R[mask] = X[mask]\n    B[mask] = C[mask]\n\n    mask = (Hp >= 5) == ( Hp < 6)\n    R[mask] = C[mask]\n    B[mask] = X[mask]\n\n    m = L - 0.5*C\n    R += m\n    G += m\n    B += m\n\n    R *= 255.0\n    G *= 255.0\n    B *= 255.0\n\n    return np.array((R.astype(int),G.astype(int),B.astype(int))).T", "response": "Converts a HSL color array to RGB array"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_symbol(symbol):\n    fixed = []\n    s = symbol.strip()\n    s = s[0].upper() + s[1:].lower()\n    for c in s:\n        if c.isalpha():\n            fixed.append(' ' + c + ' ')\n        elif c.isspace():\n            fixed.append(' ')\n        elif c.isdigit():\n            fixed.append(c)\n        elif c == '-':\n            fixed.append(' ' + c)\n        elif c == '/':\n            fixed.append(' ' + c)\n    s = ''.join(fixed).strip()\n    return ' '.join(s.split())", "response": "Returns well formatted Hermann - Mauguin symbol as extected by\n    the database by correcting the case and adding missing spaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread lines from f until a blank line is encountered.", "response": "def _skip_to_blank(f, spacegroup, setting):\n    \"\"\"Read lines from f until a blank line is encountered.\"\"\"\n    while True:\n        line = f.readline()\n        if not line:\n            raise SpacegroupNotFoundError(\n                'invalid spacegroup %s, setting %i not found in data base' % \n                ( spacegroup, setting ) )\n        if not line.strip():\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread lines from f until a nonblank line is encountered and returns this and the next line.", "response": "def _skip_to_nonblank(f, spacegroup, setting):\n    \"\"\"Read lines from f until a nonblank line not starting with a\n    hash (#) is encountered and returns this and the next line.\"\"\"\n    while True:\n        line1 = f.readline()\n        if not line1:\n            raise SpacegroupNotFoundError(\n                'invalid spacegroup %s, setting %i not found in data base' %\n                ( spacegroup, setting ) )\n        line1.strip()\n        if line1 and not line1.startswith('#'):\n            line2 = f.readline()\n            break\n    return line1, line2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_datafile_entry(spg, no, symbol, setting, f):\n    spg._no = no\n    spg._symbol = symbol.strip()\n    spg._setting = setting\n    spg._centrosymmetric = bool(int(f.readline().split()[1]))\n    # primitive vectors\n    f.readline()\n    spg._scaled_primitive_cell = np.array([\n        list(map(float, f.readline().split())) \n        for i in range(3)],\n        dtype='float')\n    \n    # primitive reciprocal vectors\n    f.readline()\n    spg._reciprocal_cell = np.array([list(map(int, f.readline().split())) \n                                        for i in range(3)],\n                                       dtype=np.int)\n    # subtranslations\n    spg._nsubtrans = int(f.readline().split()[0])\n    spg._subtrans = np.array([list(map(float, f.readline().split())) \n                              for i in range(spg._nsubtrans)],\n                             dtype=np.float)\n    # symmetry operations\n    nsym = int(f.readline().split()[0])\n    symop = np.array([list(map(float, f.readline().split())) for i in range(nsym)],\n                     dtype=np.float)\n    spg._nsymop = nsym\n    spg._rotations = np.array(symop[:,:9].reshape((nsym,3,3)), dtype=np.int)\n    spg._translations = symop[:,9:]", "response": "Read data file entry into a single space group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a sequence of site symmetries in the form x y z and returns corresponding rotation and translation arrays.", "response": "def parse_sitesym(symlist, sep=','):\n    \"\"\"Parses a sequence of site symmetries in the form used by\n    International Tables and returns corresponding rotation and\n    translation arrays.\n\n    Example:\n\n    >>> symlist = [\n    ...     'x,y,z',\n    ...     '-y+1/2,x+1/2,z',\n    ...     '-y,-x,-z',\n    ... ]\n    >>> rot, trans = parse_sitesym(symlist)\n    >>> rot\n    array([[[ 1,  0,  0],\n            [ 0,  1,  0],\n            [ 0,  0,  1]],\n    <BLANKLINE>\n           [[ 0, -1,  0],\n            [ 1,  0,  0],\n            [ 0,  0,  1]],\n    <BLANKLINE>\n           [[ 0, -1,  0],\n            [-1,  0,  0],\n            [ 0,  0, -1]]])\n    >>> trans\n    array([[ 0. ,  0. ,  0. ],\n           [ 0.5,  0.5,  0. ],\n           [ 0. ,  0. ,  0. ]])\n    \"\"\"\n    nsym = len(symlist)\n    rot = np.zeros((nsym, 3, 3), dtype='int')\n    trans = np.zeros((nsym, 3))\n    for i, sym in enumerate(symlist):\n        for j, s in enumerate (sym.split(sep)):\n            s = s.lower().strip()\n            while s:\n                sign = 1\n                if s[0] in '+-':\n                    if s[0] == '-':\n                        sign = -1\n                    s = s[1:]\n                if s[0] in 'xyz':\n                    k = ord(s[0]) - ord('x')\n                    rot[i, j, k] = sign\n                    s = s[1:]\n                elif s[0].isdigit() or s[0] == '.':\n                    n = 0\n                    while n < len(s) and (s[n].isdigit() or s[n] in '/.'):\n                        n += 1\n                    t = s[:n]\n                    s = s[n:]\n                    if '/' in t:\n                        q, r = t.split('/')\n                        trans[i,j] = float(q)/float(r)\n                    else:\n                        trans[i,j] = float(t)\n                else:\n                    raise SpacegroupValueError(\n                        'Error parsing %r. Invalid site symmetry: %s' % \n                        (s, sym))\n    return rot, trans"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn total number of symmetry operations.", "response": "def _get_nsymop(self):\n        \"\"\"Returns total number of symmetry operations.\"\"\"\n        if self.centrosymmetric:\n            return 2 * len(self._rotations) * len(self._subtrans)\n        else:\n            return len(self._rotations) * len(self._subtrans)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_symop(self):\n        symop = []\n        parities = [1]\n        if self.centrosymmetric:\n            parities.append(-1)\n        for parity in parities:\n            for subtrans in self.subtrans:\n                for rot, trans in zip(self.rotations, self.translations):\n                    newtrans = np.mod(trans + subtrans, 1)\n                    symop.append((parity*rot, newtrans))\n        return symop", "response": "Returns all symmetry operations including inversions and subtranslations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_op(self):\n        if self.centrosymmetric:\n            rot = np.tile(np.vstack((self.rotations, -self.rotations)), \n                          (self.nsubtrans, 1, 1))\n            trans = np.repeat(self.subtrans, 2*len(self.rotations), axis=0)\n        else:\n            rot = np.tile(self.rotations, (self.nsubtrans, 1, 1))\n            trans = np.repeat(self.subtrans, len(self.rotations), axis=0)\n        return rot, trans", "response": "Returns all symmetry operations including inversions and\n        subtranslations but unlike get_symop but unlike get_symop returns all symmetry operations including inversions and\n        subtranslations and two ndarrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_rotations(self):\n        if self.centrosymmetric:\n            return np.vstack((self.rotations, -self.rotations))\n        else:\n            return self.rotations", "response": "Return all rotations including inversions for a centrosymmetric crystals."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all equivalent reflections to the list of Miller indices in hkl.", "response": "def equivalent_reflections(self, hkl):\n        \"\"\"Return all equivalent reflections to the list of Miller indices\n        in hkl.\n\n        Example:\n\n        >>> from ase.lattice.spacegroup import Spacegroup\n        >>> sg = Spacegroup(225)  # fcc\n        >>> sg.equivalent_reflections([[0, 0, 2]])\n        array([[ 0,  0, -2],\n               [ 0, -2,  0],\n               [-2,  0,  0],\n               [ 2,  0,  0],\n               [ 0,  2,  0],\n               [ 0,  0,  2]])\n        \"\"\"\n        hkl = np.array(hkl, dtype='int', ndmin=2)\n        rot = self.get_rotations()\n        n, nrot = len(hkl), len(rot)\n        R = rot.transpose(0, 2, 1).reshape((3*nrot, 3)).T\n        refl = np.dot(hkl, R).reshape((n*nrot, 3))\n        ind = np.lexsort(refl.T)\n        refl = refl[ind]\n        diff = np.diff(refl, axis=0)\n        mask = np.any(diff, axis=1)\n        return np.vstack((refl[mask], refl[-1,:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef symmetry_normalised_reflections(self, hkl):\n        hkl = np.array(hkl, dtype=int, ndmin=2)\n        normalised = np.empty(hkl.shape, int)\n        R = self.get_rotations().transpose(0, 2, 1)\n        for i, g in enumerate(hkl):\n            gsym = np.dot(R, g)\n            j = np.lexsort(gsym.T)[0]\n            normalised[i,:] = gsym[j]\n        return normalised", "response": "Returns an array containing the symmetry - equivalent reflections of lowest\n        indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a subset of hkl containing only the symmetry - unique reflections.", "response": "def unique_reflections(self, hkl):\n        \"\"\"Returns a subset *hkl* containing only the symmetry-unique\n        reflections.\n\n        Example:\n\n        >>> from ase.lattice.spacegroup import Spacegroup\n        >>> sg = Spacegroup(225)  # fcc\n        >>> sg.unique_reflections([[ 2,  0,  0], \n        ...                        [ 0, -2,  0], \n        ...                        [ 2,  2,  0], \n        ...                        [ 0, -2, -2]])\n        array([[2, 0, 0],\n               [2, 2, 0]])\n        \"\"\"\n        hkl = np.array(hkl, dtype=int, ndmin=2)\n        hklnorm = self.symmetry_normalised_reflections(hkl)\n        perm = np.lexsort(hklnorm.T)\n        iperm = perm.argsort()\n        xmask = np.abs(np.diff(hklnorm[perm], axis=0)).any(axis=1)\n        mask = np.concatenate(([True], xmask))\n        imask = mask[iperm]\n        return hkl[imask]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef equivalent_sites(self, scaled_positions, ondublicates='error', \n                         symprec=1e-3):\n        \"\"\"Returns the scaled positions and all their equivalent sites.\n\n        Parameters:\n\n        scaled_positions: list | array\n            List of non-equivalent sites given in unit cell coordinates.\n        ondublicates : 'keep' | 'replace' | 'warn' | 'error'\n            Action if `scaled_positions` contain symmetry-equivalent\n            positions:\n            \n            'keep'\n               ignore additional symmetry-equivalent positions\n            'replace'\n                replace\n            'warn'\n                like 'keep', but issue an UserWarning\n            'error'\n                raises a SpacegroupValueError\n                    \n        symprec: float\n            Minimum \"distance\" betweed two sites in scaled coordinates\n            before they are counted as the same site.\n\n        Returns:\n\n        sites: array\n            A NumPy array of equivalent sites.\n        kinds: list\n            A list of integer indices specifying which input site is \n            equivalent to the corresponding returned site.\n\n        Example:\n\n        >>> from ase.lattice.spacegroup import Spacegroup\n        >>> sg = Spacegroup(225)  # fcc\n        >>> sites, kinds = sg.equivalent_sites([[0, 0, 0], [0.5, 0.0, 0.0]])\n        >>> sites\n        array([[ 0. ,  0. ,  0. ],\n               [ 0. ,  0.5,  0.5],\n               [ 0.5,  0. ,  0.5],\n               [ 0.5,  0.5,  0. ],\n               [ 0.5,  0. ,  0. ],\n               [ 0. ,  0.5,  0. ],\n               [ 0. ,  0. ,  0.5],\n               [ 0.5,  0.5,  0.5]])\n        >>> kinds\n        [0, 0, 0, 0, 1, 1, 1, 1]\n        \"\"\"\n        kinds = []\n        sites = []\n        symprec2 = symprec**2\n        scaled = np.array(scaled_positions, ndmin=2)\n        for kind, pos in enumerate(scaled):\n            for rot, trans in self.get_symop():\n                site = np.mod(np.dot(rot, pos) + trans, 1.)\n                if not sites:\n                    sites.append(site)\n                    kinds.append(kind)\n                    continue\n                t = site - sites\n                mask = np.sum(t*t, 1) < symprec2\n                if np.any(mask):\n                    ind = np.argwhere(mask)[0][0]\n                    if kinds[ind] == kind:\n                        pass\n                    elif ondublicates == 'keep':\n                        pass\n                    elif ondublicates == 'replace':\n                        kinds[ind] = kind\n                    elif ondublicates == 'warn':\n                        warnings.warn('scaled_positions %d and %d '\n                                      'are equivalent'%(kinds[ind], kind))\n                    elif ondublicates == 'error':\n                        raise SpacegroupValueError(\n                            'scaled_positions %d and %d are equivalent'%(\n                                kinds[ind], kind))\n                    else:\n                        raise SpacegroupValueError(\n                            'Argument \"ondublicates\" must be one of: '\n                            '\"keep\", \"replace\", \"warn\" or \"error\".')\n                else:\n                    sites.append(site)\n                    kinds.append(kind)\n        return np.array(sites), kinds", "response": "Returns the scaled positions and all their equivalent sites."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef symmetry_normalised_sites(self, scaled_positions):\n        scaled = np.array(scaled_positions, ndmin=2)\n        normalised = np.empty(scaled.shape, np.float)\n        rot, trans = self.get_op()\n        for i, pos in enumerate(scaled):\n            sympos = np.dot(rot, pos) + trans\n            # Must be done twice, see the scaled_positions.py test\n            sympos %= 1.0\n            sympos %= 1.0\n            j = np.lexsort(sympos.T)[0]\n            normalised[i,:] = sympos[j]\n        return normalised", "response": "Returns an array of same size as scaled_positions containing the corresponding symmetry - equivalent sites within the unit cell of lowest indices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a subset of scaled_positions containing only the symmetry - unique positions.", "response": "def unique_sites(self, scaled_positions, symprec=1e-3, output_mask=False):\n        \"\"\"Returns a subset of *scaled_positions* containing only the\n        symmetry-unique positions.  If *output_mask* is True, a boolean\n        array masking the subset is also returned.\n\n        Example:\n\n        >>> from ase.lattice.spacegroup import Spacegroup\n        >>> sg = Spacegroup(225)  # fcc\n        >>> sg.unique_sites([[0.0, 0.0, 0.0], \n        ...                  [0.5, 0.5, 0.0], \n        ...                  [1.0, 0.0, 0.0], \n        ...                  [0.5, 0.0, 0.0]])\n        array([[ 0. ,  0. ,  0. ],\n               [ 0.5,  0. ,  0. ]])\n        \"\"\"\n        scaled = np.array(scaled_positions, ndmin=2)\n        symnorm = self.symmetry_normalised_sites(scaled)\n        perm = np.lexsort(symnorm.T)\n        iperm = perm.argsort()\n        xmask = np.abs(np.diff(symnorm[perm], axis=0)).max(axis=1) > symprec\n        mask = np.concatenate(([True], xmask))\n        imask = mask[iperm]\n        if output_mask:\n            return scaled[imask], imask\n        else:\n            return scaled[imask]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an integer array of the same length as * scaled_positions* and the same length as the current object.", "response": "def tag_sites(self, scaled_positions, symprec=1e-3):\n        \"\"\"Returns an integer array of the same length as *scaled_positions*, \n        tagging all equivalent atoms with the same index.\n\n        Example:\n\n        >>> from ase.lattice.spacegroup import Spacegroup\n        >>> sg = Spacegroup(225)  # fcc\n        >>> sg.tag_sites([[0.0, 0.0, 0.0], \n        ...               [0.5, 0.5, 0.0], \n        ...               [1.0, 0.0, 0.0], \n        ...               [0.5, 0.0, 0.0]])\n        array([0, 0, 0, 1])\n        \"\"\"\n        scaled = np.array(scaled_positions, ndmin=2)\n        scaled %= 1.0\n        scaled %= 1.0\n        tags = -np.ones((len(scaled), ), dtype=int)\n        mask = np.ones((len(scaled), ), dtype=np.bool)\n        rot, trans = self.get_op()\n        i = 0\n        while mask.any():\n            pos = scaled[mask][0]\n            sympos = np.dot(rot, pos) + trans\n            # Must be done twice, see the scaled_positions.py test\n            sympos %= 1.0\n            sympos %= 1.0\n            m = ~np.all(np.any(np.abs(scaled[np.newaxis,:,:] - \n                                      sympos[:,np.newaxis,:]) > symprec, \n                               axis=2), axis=0)\n            assert not np.any((~mask) & m)\n            tags[m] = i\n            mask &= ~m\n            i += 1\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nguesses the atom type from purely heuristic considerations.", "response": "def guess_type(typ):\n    '''Guess the atom type from purely heuristic considerations.'''\n    # Strip useless numbers\n    match = re.match(\"([a-zA-Z]+)\\d*\", typ)\n    if match:\n        typ = match.groups()[0]\n        return typ"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register(*dim: List[int], use_3d: bool = False, use_polar: bool = False, collection: bool = False):\n    if use_3d and use_polar:\n        raise RuntimeError(\"Cannot have polar and 3d coordinates simultaneously.\")\n    \n    # TODO: Add some kind of class parameter\n\n    def decorate(function):\n        types.append(function.__name__)\n        dims[function.__name__] = dim\n\n        @wraps(function)\n        def f(hist, write_to: Optional[str] = None, dpi:Optional[float] = None, **kwargs):\n            fig, ax = _get_axes(kwargs, use_3d=use_3d, use_polar=use_polar)\n\n            from physt.histogram_collection import HistogramCollection\n            if collection and isinstance(hist, HistogramCollection):\n                title = kwargs.pop(\"title\", hist.title)\n                if not hist:\n                    raise ValueError(\"Cannot plot empty histogram collection\")\n                for i, h in enumerate(hist):\n                    # TODO: Add some mechanism for argument maps (like sklearn?)\n                    function(h, ax=ax,  **kwargs)\n                ax.legend()\n                ax.set_title(title)\n            else:\n                function(hist, ax=ax, **kwargs)\n\n            if write_to:\n                fig = ax.figure\n                fig.tight_layout()\n                fig.savefig(write_to, dpi=dpi or default_dpi)\n            return ax\n        return f\n    return decorate", "response": "Decorator to register a function with the internal plotting system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bar(h1: Histogram1D, ax: Axes, *, errors: bool = False, **kwargs):\n    show_stats = kwargs.pop(\"show_stats\", False)\n    show_values = kwargs.pop(\"show_values\", False)\n    value_format = kwargs.pop(\"value_format\", None)\n    density = kwargs.pop(\"density\", False)\n    cumulative = kwargs.pop(\"cumulative\", False)\n    label = kwargs.pop(\"label\", h1.name)\n    lw = kwargs.pop(\"linewidth\", kwargs.pop(\"lw\", 0.5))\n    text_kwargs = pop_kwargs_with_prefix(\"text_\", kwargs)\n\n    data = get_data(h1, cumulative=cumulative, density=density)\n\n    if \"cmap\" in kwargs:\n        cmap = _get_cmap(kwargs)\n        _, cmap_data = _get_cmap_data(data, kwargs)\n        colors = cmap(cmap_data)\n    else:\n        colors = kwargs.pop(\"color\", None)\n\n    _apply_xy_lims(ax, h1, data, kwargs)\n    _add_ticks(ax, h1, kwargs)\n\n    if errors:\n        err_data = get_err_data(h1, cumulative=cumulative, density=density)\n        kwargs[\"yerr\"] = err_data\n        if \"ecolor\" not in kwargs:\n            kwargs[\"ecolor\"] = \"black\"\n\n    _add_labels(ax, h1, kwargs)\n    ax.bar(h1.bin_left_edges, data, h1.bin_widths, align=\"edge\",\n           label=label, color=colors, linewidth=lw, **kwargs)\n\n    if show_values:\n        _add_values(ax, h1, data, value_format=value_format, **text_kwargs)\n    if show_stats:\n        _add_stats_box(h1, ax, stats=show_stats)", "response": "Bar plot of 1D histograms."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscatter plot of 1D histogram.", "response": "def scatter(h1: Histogram1D, ax: Axes, *, errors: bool = False, **kwargs):\n    \"\"\"Scatter plot of 1D histogram.\"\"\"\n    show_stats = kwargs.pop(\"show_stats\", False)\n    show_values = kwargs.pop(\"show_values\", False)\n    density = kwargs.pop(\"density\", False)\n    cumulative = kwargs.pop(\"cumulative\", False)\n    value_format = kwargs.pop(\"value_format\", None)\n    text_kwargs = pop_kwargs_with_prefix(\"text_\", kwargs)\n\n    data = get_data(h1, cumulative=cumulative, density=density)\n\n    if \"cmap\" in kwargs:\n        cmap = _get_cmap(kwargs)\n        _, cmap_data = _get_cmap_data(data, kwargs)\n        kwargs[\"color\"] = cmap(cmap_data)\n    else:\n        kwargs[\"color\"] = kwargs.pop(\"color\", \"blue\")\n\n    _apply_xy_lims(ax, h1, data, kwargs)\n    _add_ticks(ax, h1, kwargs)\n    _add_labels(ax, h1, kwargs)\n\n    if errors:\n        err_data = get_err_data(h1, cumulative=cumulative, density=density)\n        ax.errorbar(h1.bin_centers, data, yerr=err_data, fmt=kwargs.pop(\"fmt\", \"o\"),\n                    ecolor=kwargs.pop(\"ecolor\", \"black\"), ms=0)\n    ax.scatter(h1.bin_centers, data, **kwargs)\n\n    if show_values:\n        _add_values(ax, h1, data, value_format=value_format, **text_kwargs)\n    if show_stats:\n        _add_stats_box(h1, ax, stats=show_stats)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nline plot of 1D histogram.", "response": "def line(h1: Union[Histogram1D, \"HistogramCollection\"], ax: Axes, *, errors: bool = False, **kwargs):\n    \"\"\"Line plot of 1D histogram.\"\"\"\n\n\n    show_stats = kwargs.pop(\"show_stats\", False)\n    show_values = kwargs.pop(\"show_values\", False)\n    density = kwargs.pop(\"density\", False)\n    cumulative = kwargs.pop(\"cumulative\", False)\n    value_format = kwargs.pop(\"value_format\", None)\n    text_kwargs = pop_kwargs_with_prefix(\"text_\", kwargs)\n    kwargs[\"label\"] = kwargs.get(\"label\", h1.name)\n\n    data = get_data(h1, cumulative=cumulative, density=density)\n    _apply_xy_lims(ax, h1, data, kwargs)\n    _add_ticks(ax, h1, kwargs)\n    _add_labels(ax, h1, kwargs)\n\n    if errors:\n        err_data = get_err_data(h1, cumulative=cumulative, density=density)\n        ax.errorbar(h1.bin_centers, data, yerr=err_data, fmt=kwargs.pop(\n            \"fmt\", \"-\"), ecolor=kwargs.pop(\"ecolor\", \"black\"), **kwargs)\n    else:\n        ax.plot(h1.bin_centers, data, **kwargs)\n\n    if show_stats:\n        _add_stats_box(h1, ax, stats=show_stats)\n    if show_values:\n        _add_values(ax, h1, data, value_format=value_format, **text_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fill(h1: Histogram1D, ax: Axes, **kwargs):\n    show_stats = kwargs.pop(\"show_stats\", False)\n    # show_values = kwargs.pop(\"show_values\", False)\n    density = kwargs.pop(\"density\", False)\n    cumulative = kwargs.pop(\"cumulative\", False)\n    kwargs[\"label\"] = kwargs.get(\"label\", h1.name)\n\n    data = get_data(h1, cumulative=cumulative, density=density)\n    _apply_xy_lims(ax, h1, data, kwargs)\n    _add_ticks(ax, h1, kwargs)\n    _add_labels(ax, h1, kwargs)\n\n    ax.fill_between(h1.bin_centers, 0, data, **kwargs)\n\n    if show_stats:\n        _add_stats_box(h1, ax, stats=show_stats)\n    # if show_values:\n    #     _add_values(ax, h1, data)\n    return ax", "response": "Fill plot of 1D histogram."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef step(h1: Histogram1D, ax: Axes, **kwargs):\n    show_stats = kwargs.pop(\"show_stats\", False)\n    show_values = kwargs.pop(\"show_values\", False)\n    density = kwargs.pop(\"density\", False)\n    cumulative = kwargs.pop(\"cumulative\", False)\n    value_format = kwargs.pop(\"value_format\", None)\n    text_kwargs = pop_kwargs_with_prefix(\"text_\", kwargs)\n    kwargs[\"label\"] = kwargs.get(\"label\", h1.name)\n\n    data = get_data(h1, cumulative=cumulative, density=density)\n    _apply_xy_lims(ax, h1, data, kwargs)\n    _add_ticks(ax, h1, kwargs)\n    _add_labels(ax, h1, kwargs)\n\n    ax.step(h1.numpy_bins, np.concatenate([data[:1], data]), **kwargs)\n\n    if show_stats:\n        _add_stats_box(h1, ax, stats=show_stats)\n    if show_values:\n        _add_values(ax, h1, data, value_format=value_format, **text_kwargs)", "response": "Step line - plot of 1D histogram."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting a 2D histogram in a 2D plot.", "response": "def map(h2: Histogram2D, ax: Axes, *, show_zero: bool = True, show_values: bool = False, show_colorbar: bool = True, x=None, y=None, **kwargs):\n    \"\"\"Coloured-rectangle plot of 2D histogram.\n\n    Parameters\n    ----------\n    show_zero : Whether to show coloured box for bins with 0 frequency (otherwise background).\n    show_values : Whether to show labels with frequencies/densities in the middle of the bin\n\n\n    text_color : Optional\n        Colour of text descriptions\n    text_alpha : Optional[float]\n        Alpha for the text labels only\n    x : Optional[Callable]\n        Transformation of x bin coordinates\n    y : Optional[Callable]\n        Transformation of y bin coordinates\n    zorder : float\n        z-order in the axis (higher number above lower)\n\n    See Also\n    --------\n    image, polar_map, surface_map\n\n    Notes\n    -----\n    If you transform axes using x or y parameters, the deduction of axis limits\n    does not work well automatically. Please, make sure to attend to it yourself.\n    The densities in transformed maps are calculated from original bins.\n    \"\"\"\n    # Detect transformation\n    transformed = False\n    if x is not None or y is not None:\n        if not x:\n            x = lambda x, y: x\n        if not y:\n            y = lambda x, y: y\n        transformed = True\n\n    value_format = kwargs.pop(\"value_format\", lambda x: str(x))\n    # TODO: Implement correctly the text_kwargs\n\n    if isinstance(value_format, str):\n        format_str = \"{0:\" + value_format + \"}\"\n        value_format = lambda x: format_str.format(x)\n\n    rect_args = {}\n    if \"zorder\" in kwargs:\n        rect_args[\"zorder\"] = kwargs.pop(\"zorder\")\n\n    data = get_data(h2, cumulative=False, flatten=True,\n                    density=kwargs.pop(\"density\", False))\n\n    cmap = _get_cmap(kwargs)\n    norm, cmap_data = _get_cmap_data(data, kwargs)\n    colors = cmap(cmap_data)\n\n    xpos, ypos = (arr.flatten() for arr in h2.get_bin_left_edges())\n    dx, dy = (arr.flatten() for arr in h2.get_bin_widths())\n    text_x, text_y = (arr.flatten() for arr in h2.get_bin_centers())\n\n    _apply_xy_lims(ax, h2, data=data, kwargs=kwargs)\n    _add_labels(ax, h2, kwargs)\n\n    ax.autoscale_view()\n\n    alphas = _get_alpha_data(cmap_data, kwargs)\n    if np.isscalar(alphas):\n        alphas = np.ones_like(data) * alphas\n\n    for i in range(len(xpos)):\n        bin_color = colors[i]\n        alpha = alphas[i]\n\n        if data[i] != 0 or show_zero:\n            if not transformed:\n                rect = plt.Rectangle([xpos[i], ypos[i]], dx[i], dy[i],\n                                     facecolor=bin_color, edgecolor=kwargs.get(\n                                         \"grid_color\", cmap(0.5)),\n                                     lw=kwargs.get(\"lw\", 0.5), alpha=alpha, **rect_args)\n                tx, ty = text_x[i], text_y[i]\n\n            else:\n                # See http://matplotlib.org/users/path_tutorial.html\n                points = (\n                    (xpos[i], ypos[i]),\n                    (xpos[i] + dx[i], ypos[i]),\n                    (xpos[i] + dx[i], ypos[i] + dy[i]),\n                    (xpos[i], ypos[i] + dy[i]),\n                    (xpos[i], ypos[i])\n                )\n\n                verts = [(x(*p), y(*p)) for p in points]\n\n                codes = [path.Path.MOVETO,\n                         path.Path.LINETO,\n                         path.Path.LINETO,\n                         path.Path.LINETO,\n                         path.Path.CLOSEPOLY,\n                         ]\n\n                rect_path = path.Path(verts, codes)\n                rect = patches.PathPatch(rect_path, facecolor=bin_color,\n                                         edgecolor=kwargs.get(\"grid_color\", cmap(0.5)),\n                                         lw=kwargs.get(\"lw\", 0.5), alpha=alpha,\n                                         **rect_args)\n\n                tx = x(text_x[i], text_y[i])\n                ty = y(text_x[i], text_y[i])\n            ax.add_patch(rect)\n\n            if show_values:\n                text = value_format(data[i])\n                yiq_y = np.dot(bin_color[:3], [0.299, 0.587, 0.114])\n\n                text_color = kwargs.get(\"text_color\", None)\n                if not text_color:\n                    if yiq_y > 0.5:\n                        text_color = (0.0, 0.0, 0.0, kwargs.get(\n                            \"text_alpha\", alpha))\n                    else:\n                        text_color = (1.0, 1.0, 1.0, kwargs.get(\n                            \"text_alpha\", alpha))\n                ax.text(tx, ty, text, horizontalalignment='center',\n                        verticalalignment='center', color=text_color, clip_on=True, **rect_args)\n\n    if show_colorbar:\n        _add_colorbar(ax, cmap, cmap_data, norm)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting of 2D histograms as 3D boxes.", "response": "def bar3d(h2: Histogram2D, ax: Axes3D, **kwargs):\n    \"\"\"Plot of 2D histograms as 3D boxes.\"\"\"\n    density = kwargs.pop(\"density\", False)\n    data = get_data(h2, cumulative=False, flatten=True, density=density)\n\n    if \"cmap\" in kwargs:\n        cmap = _get_cmap(kwargs)\n        _, cmap_data = _get_cmap_data(data, kwargs)\n        colors = cmap(cmap_data)\n    else:\n        colors = kwargs.pop(\"color\", \"blue\")\n\n    xpos, ypos = (arr.flatten() for arr in h2.get_bin_centers())\n    zpos = np.zeros_like(ypos)\n    dx, dy = (arr.flatten() for arr in h2.get_bin_widths())\n\n    _add_labels(ax, h2, kwargs)\n    ax.bar3d(xpos, ypos, zpos, dx, dy, data, color=colors, **kwargs)\n    ax.set_zlabel(\"density\" if density else \"frequency\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots 2D histograms on a matplotlib axes.", "response": "def image(h2: Histogram2D, ax: Axes, *, show_colorbar: bool = True, interpolation: str = \"nearest\", **kwargs):\n    \"\"\"Plot of 2D histograms based on pixmaps.\n\n    Similar to map, but it:\n    - has fewer options\n    - is much more effective (enables thousands)\n    - does not support irregular bins\n\n    Parameters\n    ----------\n    interpolation: interpolation parameter passed to imshow, default: \"nearest\" (creates rectangles)\n    \"\"\"\n    cmap = _get_cmap(kwargs)   # h2 as well?\n    data = get_data(h2, cumulative=False, density=kwargs.pop(\"density\", False))\n    norm, cmap_data = _get_cmap_data(data, kwargs)\n    # zorder = kwargs.pop(\"zorder\", None)\n\n    for binning in h2._binnings:\n        if not binning.is_regular():\n            raise RuntimeError(\n                \"Histograms with irregular bins cannot be plotted using image method.\")\n\n    kwargs[\"interpolation\"] = interpolation\n    if kwargs.get(\"xscale\") == \"log\" or kwargs.get(\"yscale\") == \"log\":\n        raise RuntimeError(\"Cannot use logarithmic axes with image plots.\")\n\n    _apply_xy_lims(ax, h2, data=data, kwargs=kwargs)\n\n    _add_labels(ax, h2, kwargs)\n    ax.imshow(data.T[::-1, :], cmap=cmap, norm=norm,\n              extent=(h2.bins[0][0, 0], h2.bins[0][-1, 1],\n                      h2.bins[1][0, 0], h2.bins[1][-1, 1]),\n              aspect=\"auto\", **kwargs)\n\n    if show_colorbar:\n        _add_colorbar(ax, cmap, cmap_data, norm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef polar_map(hist: Histogram2D, ax: Axes, *, show_zero: bool = True, show_colorbar: bool = True, **kwargs):\n    data = get_data(hist, cumulative=False, flatten=True,\n                    density=kwargs.pop(\"density\", False))\n\n    cmap = _get_cmap(kwargs)\n    norm, cmap_data = _get_cmap_data(data, kwargs)\n    colors = cmap(cmap_data)\n\n    rpos, phipos = (arr.flatten() for arr in hist.get_bin_left_edges())\n    dr, dphi = (arr.flatten() for arr in hist.get_bin_widths())\n    rmax, _ = (arr.flatten() for arr in hist.get_bin_right_edges())\n\n    bar_args = {}\n    if \"zorder\" in kwargs:\n        bar_args[\"zorder\"] = kwargs.pop(\"zorder\")\n\n    alphas = _get_alpha_data(cmap_data, kwargs)\n    if np.isscalar(alphas):\n        alphas = np.ones_like(data) * alphas\n\n    for i in range(len(rpos)):\n        if data[i] > 0 or show_zero:\n            bin_color = colors[i]\n            # TODO: align = \"edge\"\n            bars = ax.bar(phipos[i], dr[i], width=dphi[i], bottom=rpos[i], align='edge', color=bin_color,\n                          edgecolor=kwargs.get(\"grid_color\", cmap(0.5)), lw=kwargs.get(\"lw\", 0.5),\n                          alpha=alphas[i], **bar_args)\n\n    ax.set_rmax(rmax.max())\n    if show_colorbar:\n        _add_colorbar(ax, cmap, cmap_data, norm)", "response": "Polar map of polar histograms."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a globe map plotted on the surface of a sphere.", "response": "def globe_map(hist: Union[Histogram2D, DirectionalHistogram], ax: Axes3D, *, show_zero: bool = True, **kwargs):\n    \"\"\"Heat map plotted on the surface of a sphere.\"\"\"\n    data = get_data(hist, cumulative=False, flatten=False,\n                    density=kwargs.pop(\"density\", False))\n\n    cmap = _get_cmap(kwargs)\n    norm, cmap_data = _get_cmap_data(data, kwargs)\n    colors = cmap(cmap_data)\n    lw = kwargs.pop(\"lw\", 1)\n\n    r = 1\n    xs = r * np.outer(np.sin(hist.numpy_bins[0]), np.cos(hist.numpy_bins[1]))\n    ys = r * np.outer(np.sin(hist.numpy_bins[0]), np.sin(hist.numpy_bins[1]))\n    zs = r * np.outer(np.cos(hist.numpy_bins[0]), np.ones(hist.shape[1] + 1))\n\n    for i in range(hist.shape[0]):\n        for j in range(hist.shape[1]):\n            if not show_zero and not data[i, j]:\n                continue\n            x = xs[i, j], xs[i, j + 1], xs[i + 1, j + 1], xs[i + 1, j]\n            y = ys[i, j], ys[i, j + 1], ys[i + 1, j + 1], ys[i + 1, j]\n            z = zs[i, j], zs[i, j + 1], zs[i + 1, j + 1], zs[i + 1, j]\n            verts = [list(zip(x, y, z))]\n            col = Poly3DCollection(verts)\n            col.set_facecolor(colors[i, j])\n            col.set_edgecolor(\"black\")\n            col.set_linewidth(lw)\n            ax.add_collection3d(col)\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n\n    if matplotlib.__version__ < \"2\":\n        ax.plot_surface([], [], [], color=\"b\")\n    ax.set_xlim(-1.1, 1.1)\n    ax.set_ylim(-1.1, 1.1)\n    ax.set_zlim(-1.1, 1.1)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef surface_map(hist, ax: Axes3D, *, show_zero: bool = True, x=(lambda x, y: x),\n                y=(lambda x, y: y), z=(lambda x, y: 0), **kwargs):\n    \"\"\"Coloured-rectangle plot of 2D histogram, placed on an arbitrary surface.\n\n    Each bin is mapped to a rectangle in 3D space using the x,y,z functions.\n\n    Parameters\n    ----------\n    hist : Histogram2D\n    show_zero : Optional[bool]\n        Whether to show coloured box for bins with 0 frequency (otherwise background).\n    x : function\n        Function with 2 parameters used to map bins to spatial x coordinate\n    y : function\n        Function with 2 parameters used to map bins to spatial y coordinate\n    z : function\n        Function with 2 parameters used to map bins to spatial z coordinate\n\n    Returns\n    -------\n    matplotlib.axes._subplots.Axes3DSubplot\n\n    See Also\n    --------\n    map, cylinder_map, globe_map\n    \"\"\"\n    data = get_data(hist, cumulative=False, flatten=False,\n                    density=kwargs.pop(\"density\", False))\n\n    cmap = _get_cmap(kwargs)\n    norm, cmap_data = _get_cmap_data(data, kwargs)\n    colors = cmap(cmap_data)\n\n    xs = np.ndarray((hist.shape[0] + 1, hist.shape[1] + 1), dtype=float)\n    ys = np.ndarray((hist.shape[0] + 1, hist.shape[1] + 1), dtype=float)\n    zs = np.ndarray((hist.shape[0] + 1, hist.shape[1] + 1), dtype=float)\n\n    edges_x = hist.numpy_bins[0]\n    edges_y = hist.numpy_bins[1]\n\n    for i in range(hist.shape[0] + 1):\n        for j in range(hist.shape[1] + 1):\n            xs[i, j] = x(edges_x[i], edges_y[j])\n            ys[i, j] = y(edges_x[i], edges_y[j])\n            zs[i, j] = z(edges_x[i], edges_y[j])\n\n    for i in range(hist.shape[0]):\n        for j in range(hist.shape[1]):\n            if not show_zero and not data[i, j]:\n                continue\n            x = xs[i, j], xs[i, j + 1], xs[i + 1, j + 1], xs[i + 1, j]\n            y = ys[i, j], ys[i, j + 1], ys[i + 1, j + 1], ys[i + 1, j]\n            z = zs[i, j], zs[i, j + 1], zs[i + 1, j + 1], zs[i + 1, j]\n            verts = [list(zip(x, y, z))]\n            col = Poly3DCollection(verts)\n            col.set_facecolor(colors[i, j])\n            ax.add_collection3d(col)\n\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n\n    if matplotlib.__version__ < \"2\":\n        ax.plot_surface([], [], [], color=\"b\")   # Dummy plot\n    ax.set_xlim(xs.min(), xs.max())\n    ax.set_ylim(ys.min(), ys.max())\n    ax.set_zlim(zs.min(), zs.max())\n\n    # ax.plot_surface(x, y, z, rstride=hist.shape[0], color=\"b\")\n\n    return ax", "response": "Coloured - rectangle plot of 2D histogram."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrawing two different histograms mirrored in one figure.", "response": "def pair_bars(first: Histogram1D, second: Histogram2D, *, orientation: str = \"vertical\", kind: str = \"bar\", **kwargs):\n    \"\"\"Draw two different histograms mirrored in one figure.\n\n    Parameters\n    ----------\n    first: Histogram1D\n    second: Histogram1D\n    color1:\n    color2:\n    orientation: str\n\n    Returns\n    -------\n    plt.Axes\n    \"\"\"\n    # TODO: enable vertical as well as horizontal\n    _, ax = _get_axes(kwargs)\n    color1 = kwargs.pop(\"color1\", \"red\")\n    color2 = kwargs.pop(\"color2\", \"blue\")\n    title = kwargs.pop(\"title\", \"{0} - {1}\".format(first.name, second.name))\n    xlim = kwargs.pop(\"xlim\", (min(first.bin_left_edges[0], first.bin_left_edges[\n                      0]), max(first.bin_right_edges[-1], second.bin_right_edges[-1])))\n\n    bar(first * (-1), color=color1, ax=ax, ylim=\"keep\", **kwargs)\n    bar(second, color=color2, ax=ax, ylim=\"keep\", **kwargs)\n    ax.set_title(title)\n    ticks = np.abs(ax.get_yticks())\n    if np.allclose(np.rint(ticks), ticks):\n        ax.set_yticklabels(ticks.astype(int))\n    else:\n        ax.set_yticklabels(ticks)\n    ax.set_xlim(xlim)\n    ax.legend()\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_axes(kwargs: Dict[str, Any], *, use_3d: bool = False, use_polar: bool = False) -> Tuple[Figure, Union[Axes, Axes3D]]:\n    figsize = kwargs.pop(\"figsize\", default_figsize)\n    if \"ax\" in kwargs:\n        ax = kwargs.pop(\"ax\")\n        fig = ax.get_figure()\n    elif use_3d:\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111, projection='3d')\n    elif use_polar:\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111, projection='polar')\n    else:\n        fig, ax = plt.subplots(figsize=figsize)\n    return fig, ax", "response": "Prepare the axes to draw into."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cmap(kwargs: dict) -> colors.Colormap:\n    from matplotlib.colors import ListedColormap\n\n    cmap = kwargs.pop(\"cmap\", default_cmap)\n    if isinstance(cmap, list):\n        return ListedColormap(cmap)\n    if isinstance(cmap, str):\n        try:\n            cmap = plt.get_cmap(cmap)\n        except BaseException as exc:\n            try:\n                # Try to use seaborn palette\n                import seaborn as sns\n                sns_palette = sns.color_palette(cmap, n_colors=256)\n                cmap = ListedColormap(sns_palette, name=cmap)\n            except ImportError:\n                raise exc\n    return cmap", "response": "Get the colour map for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget normalized values to be used with a colormap.", "response": "def _get_cmap_data(data, kwargs) -> Tuple[colors.Normalize, np.ndarray]:\n    \"\"\"Get normalized values to be used with a colormap.\n\n    Parameters\n    ----------\n    data : array_like\n    cmap_min : Optional[float] or \"min\"\n        By default 0. If \"min\", minimum value of the data.\n    cmap_max : Optional[float]\n        By default, maximum value of the data\n    cmap_normalize : str or colors.Normalize\n\n    Returns\n    -------\n    normalizer : colors.Normalize\n    normalized_data : array_like\n    \"\"\"\n    norm = kwargs.pop(\"cmap_normalize\", None)\n    if norm == \"log\":\n        cmap_max = kwargs.pop(\"cmap_max\", data.max())\n        cmap_min = kwargs.pop(\"cmap_min\", data[data > 0].min())\n        norm = colors.LogNorm(cmap_min, cmap_max)\n    elif not norm:\n        cmap_max = kwargs.pop(\"cmap_max\", data.max())\n        cmap_min = kwargs.pop(\"cmap_min\", 0)\n        if cmap_min == \"min\":\n            cmap_min = data.min()\n        norm = colors.Normalize(cmap_min, cmap_max, clip=True)\n    return norm, norm(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget alpha values for all data points.", "response": "def _get_alpha_data(data: np.ndarray, kwargs) -> Union[float, np.ndarray]:\n    \"\"\"Get alpha values for all data points.\n\n    Parameters\n    ----------\n    alpha: Callable or float\n        This can be a fixed value or a function of the data.\n    \"\"\"\n    alpha = kwargs.pop(\"alpha\", 1)\n    if hasattr(alpha, \"__call__\"):\n        return np.vectorize(alpha)(data)\n    return alpha"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding axis and plot labels.", "response": "def _add_labels(ax: Axes, h: Union[Histogram1D, Histogram2D], kwargs: dict):\n    \"\"\"Add axis and plot labels.\n    \n    TODO: Document kwargs\n    \"\"\"\n    title = kwargs.pop(\"title\", h.title)\n    xlabel = kwargs.pop(\"xlabel\", h.axis_names[0])\n    ylabel = kwargs.pop(\"ylabel\", h.axis_names[1] if len(h.axis_names) == 2 else None)\n\n    if title:\n        ax.set_title(title)\n    if xlabel:\n        ax.set_xlabel(xlabel)\n    if ylabel:\n        ax.set_ylabel(ylabel)\n    ax.get_figure().tight_layout()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd values to a 1D histogram.", "response": "def _add_values(ax: Axes, h1: Histogram1D, data, *, value_format=lambda x: x, **kwargs):\n    \"\"\"Show values next to each bin in a 1D plot.\n\n    Parameters\n    ----------\n    ax : plt.Axes\n    h1 : physt.histogram1d.Histogram1D\n    data : array_like\n        The values to be displayed\n    kwargs : dict\n        Parameters to be passed to matplotlib to override standard text params.\n    \"\"\"\n    from .common import get_value_format\n    value_format = get_value_format(value_format)\n    text_kwargs = {\"ha\": \"center\", \"va\": \"bottom\", \"clip_on\" : True}\n    text_kwargs.update(kwargs)\n\n    for x, y in zip(h1.bin_centers, data):\n        ax.text(x, y, str(value_format(y)), **text_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_colorbar(ax: Axes, cmap: colors.Colormap, cmap_data: np.ndarray, norm: colors.Normalize):\n    fig = ax.get_figure()\n    mappable = cm.ScalarMappable(cmap=cmap, norm=norm)\n    mappable.set_array(cmap_data)   # TODO: Or what???\n    fig.colorbar(mappable, ax=ax)", "response": "Show a colorbar right of the plot."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_stats_box(h1: Histogram1D, ax: Axes, stats: Union[str, bool] = \"all\"):\n\n    # place a text box in upper left in axes coords\n    if stats in [\"all\", True]:\n        text = \"Total: {0}\\nMean: {1:.2f}\\nStd.dev: {2:.2f}\".format(\n            h1.total, h1.mean(), h1.std())\n    elif stats == \"total\":\n        text = \"Total: {0}\".format(h1.total)\n    else:\n        raise ValueError(\"Invalid stats specification\")\n        \n    ax.text(0.05, 0.95, text, transform=ax.transAxes,\n            verticalalignment='top', horizontalalignment='left')", "response": "Adds a small legend - like box with statistical information."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies limits and scales to the base axes of the base element of the base element of the base element of the base element of the base element of the base element of the base element of the base element.", "response": "def _apply_xy_lims(ax: Axes, h: Union[Histogram1D, Histogram2D], data: np.ndarray, kwargs: dict):\n    \"\"\"Apply axis limits and scales from kwargs.\n\n    Note: if exponential binning is used, the scale defaults to \"log\"\n\n    Parameters\n    ----------\n    data : np.ndarray\n        The frequencies or densities or otherwise manipulated data\n    kwargs: dict\n        xscale : Optional[str]\n            If \"log\", the horizontal axis will use logarithmic scale\n        yscale : Optional[str]\n            If \"log\", the vertical axis will use logarithmic scale\n        xlim : { \"keep\", \"auto\" } or tuple(float)\n            \"auto\" (default) - the axis will fit first and last bin edges\n            \"keep\" - let matlotlib figure this out\n            tuple - standard parameter for set_xlim\n        ylim : { \"keep\", \"auto\" } or tuple(float)\n            \"auto\" (default)\n                - the axis will fit first and last bin edges (2D)\n                - the axis will exceed a bit the maximum value (1D)\n            \"keep\" - let matlotlib figure this out\n            tuple - standard parameter for set_ylim\n        invert_y : Optional[bool]\n            If True, higher values go down\n\n    See Also\n    --------\n    plt.Axes.set_xlim, plt.Axes.set_ylim, plt.Axes.set_xscale, plt.Axes.set_yscale\n    \"\"\"\n    ylim = kwargs.pop(\"ylim\", \"auto\")\n    xlim = kwargs.pop(\"xlim\", \"auto\")\n    invert_y = kwargs.pop(\"invert_y\", False)\n    xscale = yscale = None\n\n    from ..binnings import ExponentialBinning\n\n    if ylim is not \"keep\":\n        if isinstance(ylim, tuple):\n            pass\n        elif ylim:\n            ylim = ax.get_ylim()\n            if h.ndim == 1:\n                xscale = kwargs.pop(\"xscale\", \"log\" if isinstance(h.binning, ExponentialBinning) else None)\n                yscale = kwargs.pop(\"yscale\", None)\n                if data.size > 0 and data.max() > 0:\n                    ylim = (0, max(ylim[1], data.max() +\n                                   (data.max() - ylim[0]) * 0.1))\n                if yscale == \"log\":\n                    ylim = (abs(data[data > 0].min()) * 0.9, ylim[1] * 1.1)\n            elif h.ndim == 2:\n                xscale = kwargs.pop(\"xscale\", \"log\" if isinstance(h.binnings[0], ExponentialBinning) else None)\n                yscale = kwargs.pop(\"yscale\", \"log\" if isinstance(h.binnings[1], ExponentialBinning) else None)\n                if h.shape[1] >= 2:\n                    ylim = (h.get_bin_left_edges(1)[0],\n                            h.get_bin_right_edges(1)[-1])\n                    if yscale == \"log\":\n                        if ylim[0] <= 0:\n                            raise RuntimeError(\n                                \"Cannot use logarithmic scale for non-positive bins.\")\n            else:\n                raise RuntimeError(\"Invalid dimension: {0}\".format(h.ndim))\n\n            if invert_y:\n                ylim = ylim[::-1]\n                # ax.xaxis.tick_top()\n                # ax.xaxis.set_label_position('top')\n        ax.set_ylim(ylim)\n\n    if xlim is not \"keep\":\n        if isinstance(xlim, tuple):\n            pass\n        elif xlim:\n            xlim = ax.get_xlim()\n            if h.shape[0] >= 1:\n                if h.ndim == 1:\n                    xlim = (h.bin_left_edges[0], h.bin_right_edges[-1])\n                elif h.ndim == 2:\n                    xlim = (h.get_bin_left_edges(0)[\n                            0], h.get_bin_right_edges(0)[-1])\n                else:\n                    raise RuntimeError(\n                        \"Invalid dimension: {0}\".format(h.ndim))\n                if xscale == \"log\":\n                    if xlim[0] <= 0:\n                        raise RuntimeError(\n                            \"Cannot use logarithmic scale for non-positive bins.\")\n        ax.set_xlim(*xlim)\n\n    if xscale:\n        ax.set_xscale(xscale)\n    if yscale:\n        ax.set_yscale(yscale)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncustomizes ticks for an axis.", "response": "def _add_ticks(ax: Axes, h1: Histogram1D, kwargs: dict):\n    \"\"\"Customize ticks for an axis (1D histogram).\n\n    Parameters\n    ----------\n    ticks: {\"center\", \"edge\"}, optional\n        Position of the ticks\n    tick_handler: Callable[[Histogram1D, float, float], Tuple[List[float], List[str]]]\n        ...\n    \"\"\"\n    ticks = kwargs.pop(\"ticks\", None)\n    tick_handler = kwargs.pop(\"tick_handler\", None)\n\n    if tick_handler:\n        if ticks:\n            raise ValueError(\"Cannot specify both tick and tick_handler\")\n        ticks, labels = tick_handler(h1, *ax.get_xlim())\n        ax.set_xticks(ticks)\n        ax.set_xticklabels(labels)\n\n    if ticks == \"center\":\n        ax.set_xticks(h1.bin_centers)\n    if ticks == \"edge\":\n        ax.set_xticks(h1.bin_left_edges)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normal_h1(size: int = 10000, mean: float = 0, sigma: float = 1) -> Histogram1D:\n    data = np.random.normal(mean, sigma, (size,))\n    return h1(data, name=\"normal\", axis_name=\"x\", title=\"1D normal distribution\")", "response": "A simple 1D histogram with normal distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normal_h2(size: int = 10000) -> Histogram2D:\n    data1 = np.random.normal(0, 1, (size,))\n    data2 = np.random.normal(0, 1, (size,))\n    return h2(data1, data2, name=\"normal\", axis_names=tuple(\"xy\"), title=\"2D normal distribution\")", "response": "A simple 2D histogram with normal distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_from_dict(data: dict, format_name: str, check_version: bool = True) -> Union[HistogramBase, HistogramCollection]:\n    # Version\n    if check_version:\n        compatible_version = data[\"physt_compatible\"]\n        require_compatible_version(compatible_version, format_name)\n\n    # Construction\n    histogram_type = data[\"histogram_type\"]\n    if histogram_type == \"histogram_collection\":\n        klass = HistogramCollection\n    else:\n        klass = find_subclass(HistogramBase, histogram_type)\n    return klass.from_dict(data)", "response": "Create a new object from a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef require_compatible_version(compatible_version, word=\"File\"):\n    if isinstance(compatible_version, str):\n        compatible_version = parse_version(compatible_version)\n    elif not isinstance(compatible_version, Version):\n        raise ValueError(\"Type of `compatible_version` not understood.\")\n    \n    current_version = parse_version(CURRENT_VERSION)\n    if current_version < compatible_version:\n        raise VersionError(\"{0} written for version >= {1}, this is {2}.\".format(\n            word, str(compatible_version), CURRENT_VERSION\n        ))", "response": "Check that the current version of the input data is not too new."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_json(histogram: Union[HistogramBase, HistogramCollection], path: Optional[str] = None, **kwargs) -> str:\n    # TODO: Implement multiple histograms in one file?\n    data = histogram.to_dict()\n\n    data[\"physt_version\"] = CURRENT_VERSION\n    if isinstance(histogram, HistogramBase):\n        data[\"physt_compatible\"] = COMPATIBLE_VERSION\n    elif isinstance(histogram, HistogramCollection):\n        data[\"physt_compatible\"] = COLLECTION_COMPATIBLE_VERSION\n    else:\n        raise TypeError(\"Cannot save unknown type: {0}\".format(type(histogram)))\n\n    text = json.dumps(data, **kwargs)\n    if path:\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            f.write(text)\n    return text", "response": "Save histogram to JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a histogram from a JSON file.", "response": "def load_json(path: str, encoding: str = \"utf-8\") -> HistogramBase:\n    \"\"\"Load histogram from a JSON file.\"\"\"\n    with open(path, \"r\", encoding=encoding) as f:\n        text = f.read()\n        return parse_json(text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_json(text: str, encoding: str = \"utf-8\") -> HistogramBase:\n    data = json.loads(text, encoding=encoding)\n    return create_from_dict(data, format_name=\"JSON\")", "response": "Create histogram from a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef histogramdd(data, bins=10, *args, **kwargs):\n    import numpy as np\n    from . import histogram_nd\n    from .binnings import calculate_bins_nd\n\n    adaptive = kwargs.pop(\"adaptive\", False)\n    dropna = kwargs.pop(\"dropna\", True)\n    name = kwargs.pop(\"name\", None)\n    title = kwargs.pop(\"title\", None)\n    dim = kwargs.pop(\"dim\", None)\n    axis_names = kwargs.pop(\"axis_names\", None)\n\n    # pandas - guess axis names\n    if not \"axis_names\" in kwargs:\n        if hasattr(data, \"columns\"):\n            try:\n                kwargs[\"axis_names\"] = tuple(data.columns)\n            except:\n                pass # Perhaps columns has different meaning here.\n\n    # Prepare and check data\n    # Convert to array\n    if data is not None:\n        data = np.asarray(data)\n        if data.ndim != 2:\n            raise RuntimeError(\"Array must have shape (n, d)\")\n        if dim is not None and dim != data.shape[1]:\n            raise RuntimeError(\"Dimension mismatch: {0}!={1}\".format(dim, data.shape[1]))\n        _, dim = data.shape\n        if dropna:\n            data = data[~np.isnan(data).any(axis=1)]\n        check_nan = not dropna\n    else:\n        if dim is None:\n            raise RuntimeError(\"You have to specify either data or its dimension.\")\n        data = np.zeros((0, dim))\n        check_nan = False\n\n    # Prepare bins\n    bin_schemas = calculate_bins_nd(data, bins, *args, check_nan=check_nan, adaptive=adaptive,\n                                    **kwargs)\n    #bins = [binning.bins for binning in bin_schemas]\n\n    # Prepare remaining data\n    weights = kwargs.pop(\"weights\", None)\n    frequencies, errors2, missed = histogram_nd.calculate_frequencies(data, ndim=dim,\n                                                                      binnings=bin_schemas,\n                                                                      weights=weights)\n\n    kwargs[\"name\"] = name\n    if title:\n        kwargs[\"title\"] = title\n    if axis_names:\n        kwargs[\"axis_names\"] = axis_names\n    if dim == 2:\n        return histogram_nd.Histogram2D(binnings=bin_schemas, frequencies=frequencies,\n                                        errors2=errors2, **kwargs)\n    else:\n        return histogram_nd.HistogramND(dimension=dim, binnings=bin_schemas,\n                                        frequencies=frequencies, errors2=errors2, **kwargs)", "response": "Returns a 3D histogram of the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef h3(data, *args, **kwargs):\n    import numpy as np\n\n    if data is not None and isinstance(data, (list, tuple)) and not np.isscalar(data[0]):\n        if \"axis_names\" not in kwargs:\n            kwargs[\"axis_names\"] = [(column.name if hasattr(column, \"name\") else None) for column in data]\n        data = np.concatenate([item[:, np.newaxis] for item in data], axis=1)\n    else:\n        kwargs[\"dim\"] = 3    \n    return histogramdd(data, *args, **kwargs)", "response": "Facade function to create 3D histograms."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating histogram collection with shared binnning.", "response": "def collection(data, bins=10, *args, **kwargs):\n    \"\"\"Create histogram collection with shared binnning.\"\"\"\n    from physt.histogram_collection import HistogramCollection\n    if hasattr(data, \"columns\"):\n        data = {column: data[column] for column in data.columns}\n    return HistogramCollection.multi_h1(data, bins, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_root(histogram: HistogramBase, hfile: uproot.write.TFile.TFileUpdate, name: str):\n    hfile[name] = histogram", "response": "Write histogram to an open ROOT file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites histogram to a ROOT file.", "response": "def save_root(histogram: HistogramBase, path: str, name: Optional[str] = None):\n    \"\"\"Write histogram to a (new) ROOT file.\n\n    Parameters\n    ----------\n    histogram : Any histogram\n    path: path for the output file (perhaps should not exist?)\n    name : The name of the histogram inside the file\n    \"\"\"\n    if name is None:\n        name = histogram.name\n    if os.path.isfile(path):\n        # TODO: Not supported currently\n        hfile = uproot.write.TFile.TFileUpdate(path)\n    else:\n        hfile = uproot.write.TFile.TFileCreate(path)\n    write_root(histogram, hfile, name)\n    hfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a histogram to a protobuf message.", "response": "def write(histogram):\n    \"\"\"Convert a histogram to a protobuf message.\n\n    Note: Currently, all binnings are converted to\n      static form. When you load the histogram again,\n      you will lose any related behaviour.\n\n    Note: A histogram collection is also planned.\n    \n    Parameters\n    ----------\n    histogram : HistogramBase | list | dict\n        Any histogram\n\n    Returns\n    -------\n    message : google.protobuf.message.Message\n        A protocol buffer message\n    \"\"\"\n    \n    histogram_dict = histogram.to_dict()\n    message = Histogram()\n\n    for field in SIMPLE_CONVERSION_FIELDS:\n        setattr(message, field, histogram_dict[field])\n\n    # Main numerical data - TODO: Optimize!\n    message.frequencies.extend(histogram.frequencies.flatten())\n    message.errors2.extend(histogram.errors2.flatten())\n\n    # Binnings\n    for binning in histogram._binnings:\n        binning_message = message.binnings.add()\n        for edges in binning.bins:\n            limits = binning_message.bins.add()\n            limits.lower = edges[0]\n            limits.upper = edges[1]\n\n    # All meta data\n    meta_message = message.meta\n    # user_defined = {}\n    # for key, value in histogram.meta_data.items():\n    #     if key not in PREDEFINED:\n    #         user_defined[str(key)] = str(value)\n    for key in SIMPLE_META_KEYS:\n        if key in histogram.meta_data:\n            setattr(meta_message, key, str(histogram.meta_data[key]))\n    if \"axis_names\" in histogram.meta_data:\n        meta_message.axis_names.extend(histogram.meta_data[\"axis_names\"])\n\n    message.physt_version = CURRENT_VERSION\n    message.physt_compatible = COMPATIBLE_VERSION\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a parsed protobuf message into a histogram.", "response": "def read(message):\n    \"\"\"Convert a parsed protobuf message into a histogram.\"\"\"\n    require_compatible_version(message.physt_compatible)\n\n    # Currently the only implementation\n    a_dict = _dict_from_v0342(message)\n    return create_from_dict(a_dict, \"Message\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_bin_array(bins) -> np.ndarray:\n    bins = np.asarray(bins)\n    if bins.ndim == 1:\n        # if bins.shape[0] == 0:\n        #     raise RuntimeError(\"Needs at least one bin\")\n        return np.hstack((bins[:-1, np.newaxis], bins[1:, np.newaxis]))\n    elif bins.ndim == 2:\n        if bins.shape[1] != 2:\n            raise RuntimeError(\"Binning schema with ndim==2 must have 2 columns\")\n        # if bins.shape[0] == 0:\n        #     raise RuntimeError(\"Needs at least one bin\")\n        return bins  # Already correct, just pass\n    else:\n        raise RuntimeError(\"Binning schema must have ndim==1 or ndim==2\")", "response": "Turn bin data into array understood by HistogramXX classes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_numpy_bins(bins) -> np.ndarray:\n    bins = np.asarray(bins)\n    if bins.ndim == 1:     # Already in the proper format\n        return bins\n    if not is_consecutive(bins):\n        raise RuntimeError(\"Cannot create numpy bins from inconsecutive edges\")\n    return np.concatenate([bins[:1, 0], bins[:, 1]])", "response": "Convert physt bin format to numpy edges."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a numpy array of bins into a numpy array of lists of indices that correspond to the ones that have to be included in the tree.", "response": "def to_numpy_bins_with_mask(bins) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Numpy binning edges including gaps.\n\n    Parameters\n    ----------\n    bins: array_like\n        1-D (n) or 2-D (n, 2) array of edges\n\n    Returns\n    -------\n    edges: np.ndarray\n        all edges\n    mask: np.ndarray\n        List of indices that correspond to bins that have to be included\n\n    Examples\n    --------\n    >>> to_numpy_bins_with_mask([0, 1, 2])\n    (array([0.,   1.,   2.]), array([0, 1]))\n\n    >>> to_numpy_bins_with_mask([[0, 1], [2, 3]])\n    (array([0, 1, 2, 3]), array([0, 2])\n    \"\"\"\n    bins = np.asarray(bins)\n    if bins.ndim == 1:\n        edges = bins\n        if bins.shape[0] > 1:\n            mask = np.arange(bins.shape[0] - 1)\n        else:\n            mask = []\n    elif bins.ndim == 2:\n        edges = []\n        mask = []\n        j = 0\n        if bins.shape[0] > 0:\n            edges.append(bins[0, 0])\n            for i in range(bins.shape[0] - 1):\n                mask.append(j)\n                edges.append(bins[i, 1])\n                if bins[i, 1] != bins[i+1, 0]:\n                    edges.append(bins[i+1, 0])\n                    j += 1\n                j += 1\n            mask.append(j)\n            edges.append(bins[-1, 1])\n    else:\n        raise RuntimeError(\"to_numpy_bins_with_mask: array with dim=1 or 2 expected\")\n    if not np.all(np.diff(edges) > 0):\n        raise RuntimeError(\"to_numpy_bins_with_mask: edges array not monotone.\")\n    return edges, mask"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_rising(bins) -> bool:\n    # TODO: Optimize for numpy bins\n    bins = make_bin_array(bins)\n    if np.any(bins[:, 0] >= bins[:, 1]):\n        return False\n    if np.any(bins[1:, 0] < bins[:-1, 1]):\n        return False\n    return True", "response": "Checks whether the bins are in raising order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_consecutive(bins, rtol: float = 1.e-5, atol: float = 1.e-8) -> bool:\n    bins = np.asarray(bins)\n    if bins.ndim == 1:\n        return True\n    else:\n        bins = make_bin_array(bins)\n        return np.allclose(bins[1:, 0], bins[:-1, 1], rtol, atol)", "response": "Check whether the given bins are consecutive."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_bin_subset(sub, sup) -> bool:\n    sub = make_bin_array(sub)\n    sup = make_bin_array(sup)\n\n    for row in sub:\n        if not (row == sup).all(axis=1).any():\n            # TODO: Enable also approximate equality\n            return False\n    return True", "response": "Check whether all bins in one binning are present also in another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_data(histogram: HistogramBase, density: bool = False, cumulative: bool = False, flatten: bool = False) -> np.ndarray:\n    if density:\n        if cumulative:\n            data = (histogram / histogram.total).cumulative_frequencies\n        else:\n            data = histogram.densities\n    else:\n        if cumulative:\n            data = histogram.cumulative_frequencies\n        else:\n            data = histogram.frequencies\n\n    if flatten:\n        data = data.flatten()\n    return data", "response": "Get histogram data based on plotting parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting histogram error data based on plotting parameters.", "response": "def get_err_data(histogram: HistogramBase, density: bool = False, cumulative: bool = False, flatten: bool = False) -> np.ndarray:\n    \"\"\"Get histogram error data based on plotting parameters.\n\n    Parameters\n    ----------\n    density : Whether to divide bin contents by bin size\n    cumulative : Whether to return cumulative sums instead of individual\n    flatten : Whether to flatten multidimensional bins\n    \"\"\"\n    if cumulative:\n        raise RuntimeError(\"Error bars not supported for cumulative plots.\")\n    if density:\n        data = histogram.errors / histogram.bin_sizes\n    else:\n        data = histogram.errors\n    if flatten:\n        data = data.flatten()\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a formatting function from a generic value_format argument.", "response": "def get_value_format(value_format: Union[Callable, str] = str) -> Callable[[float], str]:\n    \"\"\"Create a formatting function from a generic value_format argument.\n    \"\"\"\n    if value_format is None:\n        value_format = \"\"\n    if isinstance(value_format, str):\n        format_str = \"{0:\" + value_format + \"}\"\n\n        def value_format(x): return format_str.format(x)\n\n    return value_format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop_kwargs_with_prefix(prefix: str, kwargs: dict) -> dict:\n    keys = [key for key in kwargs if key.startswith(prefix)]\n    return {key[len(prefix):]: kwargs.pop(key) for key in keys}", "response": "Pop all items from a dictionary that have keys beginning with a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets frequencies and bin errors from the data ( n - dimensional variant.", "response": "def calculate_frequencies(data, ndim: int, binnings, weights=None, dtype=None) -> Tuple[np.ndarray, np.ndarray, float]:\n    \"\"\"\"Get frequencies and bin errors from the data (n-dimensional variant).\n\n    Parameters\n    ----------\n    data : array_like\n        2D array with ndim columns and row for each entry.\n    ndim : int\n        Dimensionality od the data.\n    binnings:\n        Binnings to apply in all axes.\n    weights : Optional[array_like]\n        1D array of weights to assign to values.\n        (If present, must have same length as the number of rows.)\n    dtype : Optional[type]\n        Underlying type for the histogram.\n        (If weights are specified, default is float. Otherwise int64.)\n\n    Returns\n    -------\n    frequencies : array_like\n    errors2 : array_like\n    missing : scalar[dtype]\n    \"\"\"\n\n    # TODO: Remove ndim\n    # TODO: What if data is None\n\n    # Prepare numpy array of data\n    if data is not None:\n        data = np.asarray(data)\n        if data.ndim != 2:\n            raise RuntimeError(\"histogram_nd.calculate_frequencies requires 2D input data.\")\n            # TODO: If somewhere, here we would check ndim\n\n    # Guess correct dtype and apply to weights\n    if weights is None:\n        if not dtype:\n            dtype = np.int64\n        if data is not None:\n            weights = np.ones(data.shape[0], dtype=dtype)\n    else:\n        weights = np.asarray(weights)\n        if data is None:\n            raise RuntimeError(\"Weights specified but data not.\")\n        else:\n            if data.shape[0] != weights.shape[0]:\n                raise RuntimeError(\"Different number of entries in data and weights.\")\n        if dtype:\n            dtype = np.dtype(dtype)\n            if dtype.kind in \"iu\" and weights.dtype.kind == \"f\":\n                raise RuntimeError(\"Integer histogram requested but float weights entered.\")\n        else:\n            dtype = weights.dtype\n\n    edges_and_mask = [binning.numpy_bins_with_mask for binning in binnings]\n    edges = [em[0] for em in edges_and_mask]\n    masks = [em[1] for em in edges_and_mask]\n\n    ixgrid = np.ix_(*masks)  # Indexer to select parts we want\n\n    # TODO: Right edges are not taken into account because they fall into inf bin\n\n    if data.shape[0]:\n        frequencies, _ = np.histogramdd(data, edges, weights=weights)\n        frequencies = frequencies.astype(dtype)      # Automatically copy\n        frequencies = frequencies[ixgrid]\n        missing = weights.sum() - frequencies.sum()\n        err_freq, _ = np.histogramdd(data, edges, weights=weights ** 2)\n        errors2 = err_freq[ixgrid].astype(dtype)  # Automatically copy\n    else:\n        frequencies = None\n        missing = 0\n        errors2 = None\n\n    return frequencies, errors2, missing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist of bin matrices.", "response": "def bins(self) -> List[np.ndarray]:\n        \"\"\"List of bin matrices.\"\"\"\n        return [binning.bins for binning in self._binnings]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef numpy_bins(self) -> List[np.ndarray]:\n        return [binning.numpy_bins for binning in self._binnings]", "response": "List of numpy - like bins."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, axis: AxisIdentifier, index, force_copy: bool = False) -> HistogramBase:\n        if index == slice(None) and not force_copy:\n            return self\n\n        axis_id = self._get_axis(axis)\n        array_index = [slice(None, None, None) for i in range(self.ndim)]\n        array_index[axis_id] = index\n\n        frequencies = self._frequencies[tuple(array_index)].copy()\n        errors2 = self._errors2[tuple(array_index)].copy()\n\n        if isinstance(index, int):\n            return self._reduce_dimension([ax for ax in range(self.ndim) if ax != axis_id], frequencies, errors2)\n        elif isinstance(index, slice):\n            if index.step is not None and index.step < 0:\n                raise IndexError(\"Cannot change the order of bins\")\n            copy = self.copy()\n            copy._frequencies = frequencies\n            copy._errors2 = errors2\n            copy._binnings[axis_id] = self._binnings[axis_id][index]\n            return copy\n        else:\n            raise ValueError(\"Invalid index.\")", "response": "Select an entry in an axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_bin(self, value, axis: Optional[AxisIdentifier] = None):\n        if axis is not None:\n            axis = self._get_axis(axis)\n            ixbin = np.searchsorted(self.get_bin_left_edges(axis), value, side=\"right\")\n            if ixbin == 0:\n                return None\n            elif ixbin == self.shape[axis]:\n                if value <= self.get_bin_right_edges(axis)[-1]:\n                    return ixbin - 1\n                else:\n                    return None\n            elif value < self.get_bin_right_edges(axis)[ixbin - 1]:\n                return ixbin - 1\n            elif ixbin == self.shape[axis]:\n                return None\n            else:\n                return None\n        else:\n            ixbin = tuple(self.find_bin(value[i], i) for i in range(self.ndim))\n            if None in ixbin:\n                return None\n            else:\n                return ixbin", "response": "Returns the index of the bin corresponding to a value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd more values at once.", "response": "def fill_n(self, values, weights=None, dropna: bool = True, columns: bool = False):\n        \"\"\"Add more values at once.\n\n        Parameters\n        ----------\n        values: array_like\n            Values to add. Can be array of shape (count, ndim) or\n            array of shape (ndim, count) [use columns=True] or something\n            convertible to it\n        weights: array_like\n            Weights for values (optional)\n        dropna: bool\n            Whether to remove NaN values. If False and such value is met,\n            exception is thrown.\n        columns: bool\n            Signal that the data are transposed (in columns, instead of rows).\n            This allows to pass list of arrays in values.\n        \"\"\"\n        values = np.asarray(values)\n        if values.ndim != 2:\n            raise RuntimeError(\"Expecting 2D array of values.\")\n        if columns:\n            values = values.T\n        if values.shape[1] != self.ndim:\n            raise RuntimeError(\"Expecting array with {0} columns\".format(self.ndim))\n        if dropna:\n            values = values[~np.isnan(values).any(axis=1)]\n        if weights is not None:\n            weights = np.asarray(weights)\n            # TODO: Check for weights size?\n            self._coerce_dtype(weights.dtype)\n        for i, binning in enumerate(self._binnings):\n            if binning.is_adaptive():\n                map = binning.force_bin_existence(values[:, i])   # TODO: Add to some test\n                self._reshape_data(binning.bin_count, map, i)\n        frequencies, errors2, missed = calculate_frequencies(values, self.ndim,\n                                                             self._binnings, weights=weights)\n        self._frequencies += frequencies\n        self._errors2 += errors2\n        self._missed[0] += missed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_projection_axes(self, *axes: AxisIdentifier) -> Tuple[Tuple[int, ...], Tuple[int, ...]]:\n        axes = [self._get_axis(ax) for ax in axes]\n        if not axes:\n            raise ValueError(\"No axis selected for projection\")\n        if len(axes) != len(set(axes)):\n            raise ValueError(\"Duplicate axes in projection\")\n        invert = list(range(self.ndim))\n        for axis in axes:\n            invert.remove(axis)\n        axes = tuple(axes)\n        invert = tuple(invert)\n        return axes, invert", "response": "Find axes to include in the projection and all the remaining ones."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate cumulative frequencies along a certain axis.", "response": "def accumulate(self, axis: AxisIdentifier) -> HistogramBase:\n        \"\"\"Calculate cumulative frequencies along a certain axis.\n\n        Returns\n        -------\n        new_hist: Histogram of the same type & size\n        \"\"\"\n        # TODO: Merge with Histogram1D.cumulative_frequencies\n        # TODO: Deal with errors and totals etc.\n        # TODO: inplace\n        new_one = self.copy()\n        axis_id = self._get_axis(axis)\n        new_one._frequencies = np.cumsum(new_one.frequencies, axis_id[0])\n        return new_one"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef projection(self, *axes: AxisIdentifier, **kwargs) -> HistogramBase:\n        # TODO: rename to project in 0.5\n        axes, invert = self._get_projection_axes(*axes)\n        frequencies = self.frequencies.sum(axis=invert)\n        errors2 = self.errors2.sum(axis=invert)\n        return self._reduce_dimension(axes, frequencies, errors2, **kwargs)", "response": "Return a new histogram with the sum of the frequencies along the specified axes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef T(self) -> \"Histogram2D\":\n        a_copy = self.copy()\n        a_copy._binnings = list(reversed(a_copy._binnings))\n        a_copy.axis_names = list(reversed(a_copy.axis_names))\n        a_copy._frequencies = a_copy._frequencies.T\n        a_copy._errors2 = a_copy._errors2.T\n        return a_copy", "response": "Return a copy of the histogram with swapped axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef partial_normalize(self, axis: AxisIdentifier = 0, inplace: bool = False):\n        # TODO: Is this applicable for HistogramND?\n        axis = self._get_axis(axis)\n        if not inplace:\n            copy = self.copy()\n            copy.partial_normalize(axis, inplace=True)\n            return copy\n        else:\n            self._coerce_dtype(float)\n            if axis == 0:\n                divisor = self._frequencies.sum(axis=0)\n            else:\n                divisor = self._frequencies.sum(axis=1)[:, np.newaxis]\n            divisor[divisor == 0] = 1             # Prevent division errors\n            self._frequencies /= divisor\n            self._errors2 /= (divisor * divisor)  # Has its limitations\n            return self", "response": "Normalize in rows or columns."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef numpy_binning(data, bins=10, range=None, *args, **kwargs) -> NumpyBinning:\n    if isinstance(bins, int):\n        if range:\n            bins = np.linspace(range[0], range[1], bins + 1)\n        else:\n            start = data.min()\n            stop = data.max()\n            bins = np.linspace(start, stop, bins + 1)\n    elif np.iterable(bins):\n        bins = np.asarray(bins)\n    else:\n        # Some numpy edge case\n        _, bins = np.histogram(data, bins, **kwargs)\n    return NumpyBinning(bins)", "response": "Construct binning schema compatible with numpy. histogram\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef human_binning(data=None, bin_count: Optional[int] = None, *, range=None, **kwargs) -> FixedWidthBinning:\n    subscales = np.array([0.5, 1, 2, 2.5, 5, 10])\n\n    # TODO: remove colliding kwargs\n    if data is None and range is None:\n        raise RuntimeError(\"Cannot guess optimum bin width without data.\")\n    if bin_count is None:\n        bin_count = ideal_bin_count(data)\n    min_ = range[0] if range else data.min()\n    max_ = range[1] if range else data.max()\n    bw = (max_ - min_) / bin_count\n\n    power = np.floor(np.log10(bw)).astype(int)\n    best_index = np.argmin(np.abs(np.log(subscales * (10.0 ** power) / bw)))\n    bin_width = (10.0 ** power) * subscales[best_index]\n    return fixed_width_binning(bin_width=bin_width, data=data, range=range, **kwargs)", "response": "Construct fixed - width ninning schema with bins automatically optimized to human - friendly widths."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbins schema based on quantile ranges.", "response": "def quantile_binning(data=None, bins=10, *, qrange=(0.0, 1.0), **kwargs) -> StaticBinning:\n    \"\"\"Binning schema based on quantile ranges.\n\n    This binning finds equally spaced quantiles. This should lead to\n    all bins having roughly the same frequencies.\n\n    Note: weights are not (yet) take into account for calculating\n    quantiles.\n\n    Parameters\n    ----------\n    bins: sequence or Optional[int]\n        Number of bins\n    qrange: Optional[tuple]\n        Two floats as minimum and maximum quantile (default: 0.0, 1.0)\n\n    Returns\n    -------\n    StaticBinning\n    \"\"\"\n\n    if np.isscalar(bins):\n        bins = np.linspace(qrange[0] * 100, qrange[1] * 100, bins + 1)\n    bins = np.percentile(data, bins)\n    return static_binning(bins=make_bin_array(bins), includes_right_edge=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef static_binning(data=None, bins=None, **kwargs) -> StaticBinning:\n    return StaticBinning(bins=make_bin_array(bins), **kwargs)", "response": "Construct static binning with whatever bins."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing fixed - width binning schema with bins centered around integers.", "response": "def integer_binning(data=None, **kwargs) -> StaticBinning:\n    \"\"\"Construct fixed-width binning schema with bins centered around integers.\n\n    Parameters\n    ----------\n    range: Optional[Tuple[int]]\n        min (included) and max integer (excluded) bin\n    bin_width: Optional[int]\n        group \"bin_width\" integers into one bin (not recommended)\n    \"\"\"\n    if \"range\" in kwargs:\n        kwargs[\"range\"] = tuple(r - 0.5 for r in kwargs[\"range\"])\n    return fixed_width_binning(data=data, bin_width=kwargs.pop(\"bin_width\", 1),\n                               align=True, bin_shift=0.5, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fixed_width_binning(data=None, bin_width: Union[float, int] = 1, *, range=None, includes_right_edge=False, **kwargs) -> FixedWidthBinning:\n    result = FixedWidthBinning(bin_width=bin_width, includes_right_edge=includes_right_edge,\n                               **kwargs)\n    if range:\n        result._force_bin_existence(range[0])\n        result._force_bin_existence(range[1], includes_right_edge=True)\n        if not kwargs.get(\"adaptive\"):\n            return result  # Otherwise we want to adapt to data\n    if data is not None and data.shape[0]:\n        # print(\"Jo, tady\")\n        result._force_bin_existence([np.min(data), np.max(data)],\n                                    includes_right_edge=includes_right_edge)\n    return result", "response": "Construct a fixed - width binning schema."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct exponential binning schema.", "response": "def exponential_binning(data=None, bin_count: Optional[int] = None, *, range=None, **kwargs) -> ExponentialBinning:\n    \"\"\"Construct exponential binning schema.\n\n    Parameters\n    ----------\n    bin_count: Optional[int]\n        Number of bins\n    range: Optional[tuple]\n        (min, max)\n\n    See also\n    --------\n    numpy.logspace - note that our range semantics is different\n    \"\"\"\n    if bin_count is None:\n        bin_count = ideal_bin_count(data)\n\n    if range:\n        range = (np.log10(range[0]), np.log10(range[1]))\n    else:\n        range = (np.log10(data.min()), np.log10(data.max()))\n    log_width = (range[1] - range[0]) / bin_count\n    return ExponentialBinning(log_min=range[0], log_width=log_width, bin_count=bin_count, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_bins(array, _=None, *args, **kwargs) -> BinningBase:\n    if array is not None:\n        if kwargs.pop(\"check_nan\", True):\n            if np.any(np.isnan(array)):\n                raise RuntimeError(\"Cannot calculate bins in presence of NaN's.\")\n        if kwargs.get(\"range\", None):   # TODO: re-consider the usage of this parameter\n            array = array[(array >= kwargs[\"range\"][0]) & (array <= kwargs[\"range\"][1])]\n    if _ is None:\n        bin_count = 10  # kwargs.pop(\"bins\", ideal_bin_count(data=array)) - same as numpy\n        binning = numpy_binning(array, bin_count, *args, **kwargs)\n    elif isinstance(_, BinningBase):\n        binning = _\n    elif isinstance(_, int):\n        binning = numpy_binning(array, _, *args, **kwargs)\n    elif isinstance(_, str):\n        # What about the ranges???\n        if _ in bincount_methods:\n            bin_count = ideal_bin_count(array, method=_)\n            binning = numpy_binning(array, bin_count, *args, **kwargs)\n        elif _ in binning_methods:\n            method = binning_methods[_]\n            binning = method(array, *args, **kwargs)\n        else:\n            raise RuntimeError(\"No binning method {0} available.\".format(_))\n    elif callable(_):\n        binning = _(array, *args, **kwargs)\n    elif np.iterable(_):\n        binning = static_binning(array, _, *args, **kwargs)\n    else:\n        raise RuntimeError(\"Binning {0} not understood.\".format(_))\n    return binning", "response": "Calculate optimal binning from a 2 - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates optimal binning from arguments.", "response": "def calculate_bins_nd(array, bins=None, *args, **kwargs):\n    \"\"\"Find optimal binning from arguments (n-dimensional variant)\n\n    Usage similar to `calculate_bins`.\n\n    Returns\n    -------\n    List[BinningBase]\n    \"\"\"\n    if kwargs.pop(\"check_nan\", True):\n        if np.any(np.isnan(array)):\n            raise RuntimeError(\"Cannot calculate bins in presence of NaN's.\")\n\n    if array is not None:\n        _, dim = array.shape\n\n    # Prepare bins\n    if isinstance(bins, (list, tuple)):\n        if len(bins) != dim:\n            raise RuntimeError(\"List of bins not understood, expected {0} items, got {1}.\"\n                               .format(dim, len(bins)))\n    else:\n        bins = [bins] * dim\n\n    # Prepare arguments\n    args = list(args)\n    range_ = kwargs.pop(\"range\", None)\n    if range_:\n        if len(range_) == 2 and all(np.isscalar(i) for i in range_):\n            range_ = dim * [range_]\n        elif len(range_) != dim:\n            raise RuntimeError(\"Wrong dimensionality of range\")\n    for i in range(len(args)):\n        if isinstance(args[i], (list, tuple)):\n            if len(args[i]) != dim:\n                raise RuntimeError(\"Argument not understood.\")\n        else:\n            args[i] = dim * [args[i]]\n    for key in list(kwargs.keys()):\n        if isinstance(kwargs[key], (list, tuple)):\n            if len(kwargs[key]) != dim:\n                raise RuntimeError(\"Argument not understood.\")\n        else:\n            kwargs[key] = dim * [kwargs[key]]\n\n    if range_:\n        kwargs[\"range\"] = range_\n\n    bins = [\n        calculate_bins(array[:, i], bins[i],\n                       *(arg[i] for arg in args if arg[i] is not None),\n                       **{k: kwarg[i] for k, kwarg in kwargs.items() if kwarg[i] is not None})\n        for i in range(dim)\n        ]\n    return bins"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_binning(obj, copy: bool = False) -> BinningBase:\n    if isinstance(obj, BinningBase):\n        if copy:\n            return obj.copy()\n        else:\n            return obj\n    else:\n        bins = make_bin_array(obj)\n        return StaticBinning(bins)", "response": "Ensure that an object is a binning"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary representation of the binning schema.", "response": "def to_dict(self) -> OrderedDict:\n        \"\"\"Dictionary representation of the binning schema.\n\n        This serves as template method, please implement _update_dict\n        \"\"\"\n        result = OrderedDict()\n        result[\"adaptive\"] = self._adaptive\n        result[\"binning_type\"] = type(self).__name__\n        self._update_dict(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adapt(self, other: 'BinningBase'):\n        # TODO: in-place arg\n        if np.array_equal(self.bins, other.bins):\n            return None, None\n        elif not self.is_adaptive():\n            raise RuntimeError(\"Cannot adapt non-adaptive binning.\")\n        else:\n            return self._adapt(other)", "response": "Adapt this binning so that it contains all bins of another binning."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_adaptive(self, value: bool = True):\n        if value and not self.adaptive_allowed:\n            raise RuntimeError(\"Cannot change binning to adaptive.\")\n        self._adaptive = value", "response": "Set or unset the adaptive property of the binning."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bins(self):\n        if self._bins is None:\n            self._bins = make_bin_array(self.numpy_bins)\n        return self._bins", "response": "Bins in the wider format as edge pairs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef numpy_bins(self) -> np.ndarray:\n        if self._numpy_bins is None:\n            self._numpy_bins = to_numpy_bins(self.bins)\n        return self._numpy_bins", "response": "Returns the numpy binnings of the log entry in the numpy format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef numpy_bins_with_mask(self) -> Tuple[np.ndarray, np.ndarray]:\n        bwm = to_numpy_bins_with_mask(self.bins)\n        if not self.includes_right_edge:\n            bwm[0].append(np.inf)\n        return bwm", "response": "Returns a list of numpy bins and a mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_fixed_width(self, copy=True):\n        if self.bin_count == 0:\n            raise RuntimeError(\"Cannot guess binning width with zero bins\")\n        elif self.bin_count == 1 or self.is_consecutive() and self.is_regular():\n            return FixedWidthBinning(min=self.bins[0][0], bin_count=self.bin_count, bin_width=self.bins[1] - self.bins[0])\n        else:\n            raise RuntimeError(\"Cannot create fixed-width binning from differing bin widths.\")", "response": "Convert the binning to recipe with fixed width."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_static(self, copy: bool = True) -> 'StaticBinning':\n        if copy:\n            return StaticBinning(bins=self.bins.copy(),\n                                 includes_right_edge=self.includes_right_edge)\n        else:\n            return self", "response": "Convert this binning to a static form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_subclass(base: type, name: str) -> type:\n    class_candidates = [klass\n                        for klass in all_subclasses(base)\n                        if klass.__name__ == name\n                        ]\n    if len(class_candidates) == 0:\n        raise RuntimeError(\"No \\\"{0}\\\" subclass of \\\"{1}\\\".\".format(base.__name__, name))\n    elif len(class_candidates) > 1:\n        raise RuntimeError(\"Multiple \\\"{0}\\\" subclasses of \\\"{1}\\\".\".format(base.__name__, name))\n    return class_candidates[0]", "response": "Find a named subclass of a base class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopping multiple items from a dictionary.", "response": "def pop_many(a_dict: Dict[str, Any], *args: str,  **kwargs) -> Dict[str, Any]:\n    \"\"\"Pop multiple items from a dictionary.\n    \n    Parameters\n    ----------\n    a_dict : Dictionary from which the items will popped\n    args: Keys which will be popped (and not included if not present)\n    kwargs: Keys + default value pairs (if key not found, this default is included)\n\n    Returns\n    -------\n    A dictionary of collected items.\n    \"\"\"\n    result = {}\n    for arg in args:\n        if arg in a_dict:\n            result[arg] = a_dict.pop(arg)\n    for key, value in kwargs.items():\n        result[key] = a_dict.pop(key, value)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, histogram: Histogram1D):\n        if self.binning and not self.binning == histogram.binning:\n            raise ValueError(\"Cannot add histogram with different binning.\")\n        self.histograms.append(histogram)", "response": "Add a histogram to the collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize_bins(self, inplace: bool = False) -> \"HistogramCollection\":\n        col = self if inplace else self.copy()\n        sums = self.sum().frequencies\n        for h in col.histograms:\n            h.set_dtype(float)\n            h._frequencies /= sums\n            h._errors2 /= sums ** 2  # TODO: Does this make sense?\n        return col", "response": "Normalize each bin in the histogram collection so that the sum is 1. 0 for each bin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a collection from multiple datasets.", "response": "def multi_h1(cls, a_dict: Dict[str, Any], bins=None, **kwargs) -> \"HistogramCollection\":\n        \"\"\"Create a collection from multiple datasets.\"\"\"\n        from physt.binnings import calculate_bins\n        mega_values = np.concatenate(list(a_dict.values()))\n        binning = calculate_bins(mega_values, bins, **kwargs)\n\n        title = kwargs.pop(\"title\", None)\n        name = kwargs.pop(\"name\", None)\n\n        collection = HistogramCollection(binning=binning, title=title, name=name)\n        for key, value in a_dict.items():\n            collection.create(key, value)\n        return collection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting to JSON representation.", "response": "def to_json(self, path: Optional[str] = None, **kwargs) -> str:\n        \"\"\"Convert to JSON representation.\n\n        Parameters\n        ----------\n        path: Where to write the JSON.\n\n        Returns\n        -------\n        The JSON representation.\n        \"\"\"\n        from .io import save_json\n        return save_json(self, path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnames of axes stored in meta - data.", "response": "def axis_names(self) -> Tuple[str, ...]:\n        \"\"\"Names of axes (stored in meta-data).\"\"\"\n        default = [\"axis{0}\".format(i) for i in range(self.ndim)]\n        return tuple(self._meta_data.get(\"axis_names\", None) or default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a zero - based index of an axis and check its existence.", "response": "def _get_axis(self, name_or_index: AxisIdentifier) -> int:\n        \"\"\"Get a zero-based index of an axis and check its existence.\"\"\"\n        # TODO: Add unit test\n        if isinstance(name_or_index, int):\n            if name_or_index < 0 or name_or_index >= self.ndim:\n                raise ValueError(\"No such axis, must be from 0 to {0}\".format(self.ndim-1))\n            return name_or_index\n        elif isinstance(name_or_index, str):\n            if name_or_index not in self.axis_names:\n                named_axes = [name for name in self.axis_names if name]\n                raise ValueError(\"No axis with such name: {0}, available names: {1}. In most places, you can also use numbers.\"\n                                   .format(name_or_index, \", \".join(named_axes)))\n            return self.axis_names.index(name_or_index)\n        else:\n            raise TypeError(\"Argument of type {0} not understood, int or str expected.\".format(type(name_or_index)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshaping of histogram s data.", "response": "def shape(self) -> Tuple[int, ...]:\n        \"\"\"Shape of histogram's data.\n\n        Returns\n        -------\n        One-element tuple with the number of bins along each axis.\n        \"\"\"\n        return tuple(bins.bin_count for bins in self._binnings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _eval_dtype(cls, value):\n        value = np.dtype(value)\n        if value.kind in \"iu\":\n            type_info = np.iinfo(value)\n        elif value.kind == \"f\":\n            type_info = np.finfo(value)\n        else:\n            raise RuntimeError(\"Unsupported dtype. Only integer/floating-point types are supported.\")\n\n        return value, type_info", "response": "Convert dtype into canonical form check its applicability and return info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the data type of the bin contents.", "response": "def set_dtype(self, value, check: bool = True):\n        \"\"\"Change data type of the bin contents.\n\n        Allowed conversions:\n        - from integral to float types\n        - between the same category of type (float/integer)\n        - from float types to integer if weights are trivial\n\n        Parameters\n        ----------\n        value: np.dtype or something convertible to it.\n        check: bool\n            If True (default), all values are checked against the limits\n        \"\"\"\n        # TODO? Deal with unsigned types\n        value, type_info = self._eval_dtype(value)\n        if value == self._dtype:\n            return\n\n        if self.dtype is None or np.can_cast(self.dtype, value):\n            pass    # Ok\n        elif check:\n            if np.issubdtype(value, np.integer):\n                if self.dtype.kind == \"f\":\n                    for array in (self._frequencies, self._errors2):\n                        if np.any(array % 1.0):\n                            raise RuntimeError(\"Data contain non-integer values.\")\n            for array in (self._frequencies, self._errors2):\n                if np.any((array > type_info.max) | (array < type_info.min)):\n                    raise RuntimeError(\"Data contain values outside the specified range.\")\n\n        self._dtype = value\n        self._frequencies = self._frequencies.astype(value)\n        self._errors2 = self._errors2.astype(value)\n        self._missed = self._missed.astype(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _coerce_dtype(self, other_dtype):\n        if self._dtype is None:\n            new_dtype = np.dtype(other_dtype)\n        else:\n            new_dtype = np.find_common_type([self._dtype, np.dtype(other_dtype)], [])\n        if new_dtype != self.dtype:\n            self.set_dtype(new_dtype)", "response": "Change the bin content type to allow correct operations with other operand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing the histogram so that the total weight is equal to 1.", "response": "def normalize(self, inplace: bool = False, percent: bool = False) -> \"HistogramBase\":\n        \"\"\"Normalize the histogram, so that the total weight is equal to 1.\n\n        Parameters\n        ----------\n        inplace: If True, updates itself. If False (default), returns copy\n        percent: If True, normalizes to percent instead of 1. Default: False\n\n        Returns\n        -------\n        HistogramBase : either modified copy or self\n\n        See also\n        --------\n        densities\n        HistogramND.partial_normalize\n        \"\"\"\n        if inplace:\n            self /= self.total * (.01 if percent else 1)\n            return self\n        else:\n            return self / self.total * (100 if percent else 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_adaptive(self, value: bool = True):\n        # TODO: remove in favour of adaptive property\n        if not all(b.adaptive_allowed for b in self._binnings):\n            raise RuntimeError(\"All binnings must allow adaptive behaviour.\")\n        for binning in self._binnings:\n            binning.set_adaptive(value)", "response": "Change the histogram binning to ( non ) adaptive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the binnning and update the bin contents according to a map.", "response": "def _change_binning(self, new_binning, bin_map: Iterable[Tuple[int, int]], axis: int = 0):\n        \"\"\"Set new binnning and update the bin contents according to a map.\n\n        Fills frequencies and errors with 0.\n        It's the caller's responsibility to provide correct binning and map.\n\n        Parameters\n        ----------\n        new_binning: physt.binnings.BinningBase\n        bin_map: Iterable[tuple]\n            tuples contain bin indices (old, new)\n        axis: int\n            What axis does the binning describe(0..ndim-1)\n        \"\"\"\n        axis = int(axis)\n        if axis < 0 or axis >= self.ndim:\n            raise RuntimeError(\"Axis must be in range 0..(ndim-1)\")\n        self._reshape_data(new_binning.bin_count, bin_map, axis)\n        self._binnings[axis] = new_binning"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreducing the number of adjacent bins and add their content to each bin.", "response": "def merge_bins(self, amount: Optional[int] = None, *, min_frequency: Optional[float] = None,\n                   axis: Optional[AxisIdentifier] = None, inplace: bool = False) -> 'HistogramBase':\n        \"\"\"Reduce the number of bins and add their content:\n\n        Parameters\n        ----------\n        amount: How many adjacent bins to join together.\n        min_frequency: Try to have at least this value in each bin\n            (this is not enforce e.g. for minima between high bins)\n        axis: int or None\n            On which axis to do this (None => all)\n        inplace: Whether to modify this histogram or return a new one\n        \"\"\"\n        if not inplace:\n            histogram = self.copy()\n            histogram.merge_bins(amount, min_frequency=min_frequency, axis=axis, inplace=True)\n            return histogram\n        elif axis is None:\n            for i in range(self.ndim):\n                self.merge_bins(amount=amount, min_frequency=min_frequency, axis=i, inplace=True)\n        else:\n            axis = self._get_axis(axis)\n            if amount is not None:\n                if not amount == int(amount):\n                    raise RuntimeError(\"Amount must be integer\")\n                bin_map = [(i, i // amount) for i in range(self.shape[axis])]\n            elif min_frequency is not None:\n                if self.ndim == 1:\n                    check = self.frequencies\n                else:\n                    check = self.projection(axis).frequencies\n                bin_map = []\n                current_new = 0\n                current_sum = 0\n                for i, freq in enumerate(check):\n                    if freq >= min_frequency and current_sum > 0:\n                        current_sum = 0\n                        current_new += 1\n                    bin_map.append((i, current_new))\n                    current_sum += freq\n                    if current_sum > min_frequency:\n                        current_sum = 0\n                        current_new += 1\n            else:\n                raise NotImplementedError(\"Not yet implemented.\")\n            new_binning = self._binnings[axis].apply_bin_map(bin_map)\n            self._change_binning(new_binning, bin_map, axis=axis)\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reshape_data(self, new_size, bin_map, axis=0):\n        if bin_map is None:\n            return\n        else:\n            new_shape = list(self.shape)\n            new_shape[axis] = new_size\n            new_frequencies = np.zeros(new_shape, dtype=self._frequencies.dtype)\n            new_errors2 = np.zeros(new_shape, dtype=self._frequencies.dtype)\n            self._apply_bin_map(\n                old_frequencies=self._frequencies, new_frequencies=new_frequencies,\n                old_errors2=self._errors2, new_errors2=new_errors2,\n                bin_map=bin_map, axis=axis)\n            self._frequencies = new_frequencies\n            self._errors2 = new_errors2", "response": "Reshape data to match new binning schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _apply_bin_map(self, old_frequencies, new_frequencies, old_errors2,\n                       new_errors2, bin_map, axis=0):\n        \"\"\"Fill new data arrays using a map.\n\n        Parameters\n        ----------\n        old_frequencies : np.ndarray\n            Source of frequencies data\n        new_frequencies : np.ndarray\n            Target of frequencies data\n        old_errors2 : np.ndarray\n            Source of errors data\n        new_errors2 : np.ndarray\n            Target of errors data\n        bin_map: Iterable[(old, new)] or int or None\n            As in _reshape_data\n        axis: int\n            On which axis to apply\n\n        See also\n        --------\n        HistogramBase._reshape_data\n        \"\"\"\n        if old_frequencies is not None and old_frequencies.shape[axis] > 0:\n            if isinstance(bin_map, int):\n                new_index = [slice(None) for i in range(self.ndim)]\n                new_index[axis] = slice(bin_map, bin_map + old_frequencies.shape[axis])\n                new_frequencies[tuple(new_index)] += old_frequencies\n                new_errors2[tuple(new_index)] += old_errors2\n            else:\n                for (old, new) in bin_map:      # Generic enough\n                    new_index = [slice(None) for i in range(self.ndim)]\n                    new_index[axis] = new\n                    old_index = [slice(None) for i in range(self.ndim)]\n                    old_index[axis] = old\n                    new_frequencies[tuple(new_index)] += old_frequencies[tuple(old_index)]\n                    new_errors2[tuple(new_index)] += old_errors2[tuple(old_index)]", "response": "Fill new data arrays using a map."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_same_bins(self, other: \"HistogramBase\") -> bool:\n        if self.shape != other.shape:\n            return False\n        elif self.ndim == 1:\n            return np.allclose(self.bins, other.bins)\n        elif self.ndim > 1:\n            for i in range(self.ndim):\n                if not np.allclose(self.bins[i], other.bins[i]):\n                    return False\n            return True", "response": "Whether two histograms share the same binning."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, include_frequencies: bool = True) -> \"HistogramBase\":\n        if include_frequencies:\n            frequencies = np.copy(self.frequencies)\n            missed = self._missed.copy()\n            errors2 = np.copy(self.errors2)\n            stats = self._stats or None\n        else:\n            frequencies = np.zeros_like(self._frequencies)\n            errors2 = np.zeros_like(self._errors2)\n            missed = np.zeros_like(self._missed)\n            stats = None\n        a_copy = self.__class__.__new__(self.__class__)\n        a_copy._binnings = [binning.copy() for binning in self._binnings]\n        a_copy._dtype = self.dtype\n        a_copy._frequencies = frequencies\n        a_copy._errors2 = errors2\n        a_copy._meta_data = self._meta_data.copy()\n        a_copy.keep_missed = self.keep_missed\n        a_copy._missed = missed\n        a_copy._stats = stats\n        return a_copy", "response": "Returns a copy of the histogram."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fill_n(self, values, weights=None, **kwargs):\n        if weights is not None:\n            if weights.shape != values.shape[0]:\n                raise RuntimeError(\"Wrong shape of weights\")\n        for i, value in enumerate(values):\n            if weights is not None:\n                self.fill(value, weights[i], **kwargs)\n            else:\n                self.fill(value, **kwargs)", "response": "Add more values at once."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an OrderedDict with all data in the histogram.", "response": "def to_dict(self) -> OrderedDict:\n        \"\"\"Dictionary with all data in the histogram.\n\n        This is used for export into various formats (e.g. JSON)\n        If a descendant class needs to update the dictionary in some way\n        (put some more information), override the _update_dict method.\n        \"\"\"\n        result = OrderedDict()\n        result[\"histogram_type\"] = type(self).__name__\n        result[\"binnings\"] = [binning.to_dict() for binning in self._binnings]\n        result[\"frequencies\"] = self.frequencies.tolist()\n        result[\"dtype\"] = str(np.dtype(self.dtype))\n\n        # TODO: Optimize for _errors == _frequencies\n        result[\"errors2\"] = self.errors2.tolist()\n        result[\"meta_data\"] = self._meta_data\n        result[\"missed\"] = self._missed.tolist()\n        result[\"missed_keep\"] = self.keep_missed\n        self._update_dict(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying __init__ arguments from an external dictionary.", "response": "def _kwargs_from_dict(cls, a_dict: dict) -> dict:\n        \"\"\"Modify __init__ arguments from an external dictionary.\n\n        Template method for from dict.\n        Override if necessary (like it's done in Histogram1D).\n        \"\"\"\n        from .binnings import BinningBase\n        kwargs = {\n            \"binnings\": [BinningBase.from_dict(binning_data) for binning_data in a_dict[\"binnings\"]],\n            \"dtype\": np.dtype(a_dict[\"dtype\"]),\n            \"frequencies\": a_dict.get(\"frequencies\"),\n            \"errors2\": a_dict.get(\"errors2\"),\n        }\n        if \"missed\" in a_dict:\n            kwargs[\"missed\"] = a_dict[\"missed\"]\n        kwargs.update(a_dict.get(\"meta_data\", {}))\n        if len(kwargs[\"binnings\"]) > 2:\n            kwargs[\"dimension\"] = len(kwargs[\"binnings\"])\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an instance from a dictionary.", "response": "def from_dict(cls, a_dict: Mapping[str, Any]) -> \"HistogramBase\":\n        \"\"\"Create an instance from a dictionary.\n\n        If customization is necessary, override the _from_dict_kwargs\n        template method, not this one.\n        \"\"\"\n        kwargs = cls._kwargs_from_dict(a_dict)\n        return cls(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge meta data of two histograms leaving only the equal values.", "response": "def _merge_meta_data(cls, first: \"HistogramBase\", second: \"HistogramBase\") -> dict:\n        \"\"\"Merge meta data of two histograms leaving only the equal values.\n\n        (Used in addition and subtraction)\n        \"\"\"\n        keys = set(first._meta_data.keys())\n        keys = keys.union(set(second._meta_data.keys()))\n        return {key:\n                (first._meta_data.get(key, None) if first._meta_data.get(key, None) == second._meta_data.get(key, None) else None)\n                for key in keys}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_frequencies(data, binning, weights=None, validate_bins=True,\n                          already_sorted=False, dtype=None):\n    \"\"\"Get frequencies and bin errors from the data.\n\n    Parameters\n    ----------\n    data : array_like\n        Data items to work on.\n    binning : physt.binnings.BinningBase\n        A set of bins.\n    weights : array_like, optional\n        Weights of the items.\n    validate_bins : bool, optional\n        If True (default), bins are validated to be in ascending order.\n    already_sorted : bool, optional\n        If True, the data being entered are already sorted, no need to sort them once more.\n    dtype: Optional[type]\n        Underlying type for the histogram.\n        (If weights are specified, default is float. Otherwise long.)\n\n    Returns\n    -------\n    frequencies : numpy.ndarray\n        Bin contents\n    errors2 : numpy.ndarray\n        Error squares of the bins\n    underflow : float\n        Weight of items smaller than the first bin\n    overflow : float\n        Weight of items larger than the last bin\n    stats: dict\n        { sum: ..., sum2: ...}\n\n    Note\n    ----\n    Checks that the bins are in a correct order (not necessarily consecutive).\n    Does not check for numerical overflows in bins.\n    \"\"\"\n\n    # TODO: Is it possible to merge with histogram_nd.calculate_frequencies?\n    # TODO: What if data is None\n    # TODO: Change stats into namedtuple\n\n    # Statistics\n    sum = 0.0\n    sum2 = 0.0\n\n    # Ensure correct binning\n    bins = binning.bins  # bin_utils.make_bin_array(bins)\n    if validate_bins:\n        if bins.shape[0] == 0:\n            raise RuntimeError(\"Cannot have histogram with 0 bins.\")\n        if not bin_utils.is_rising(bins):\n            raise RuntimeError(\"Bins must be rising.\")\n\n    # Prepare 1D numpy array of data\n    data = np.asarray(data)\n    if data.ndim > 1:\n        data = data.flatten()\n\n    # Prepare 1D numpy array of weights\n    if weights is not None:\n        weights = np.asarray(weights)\n        if weights.ndim > 1:\n            weights = weights.flatten()\n\n        # Check compatibility of weights\n        if weights.shape != data.shape:\n            raise RuntimeError(\"Weights must have the same shape as data.\")\n\n        # Ensure proper dtype for the bin contents\n        if dtype is None:\n            dtype = weights.dtype\n\n    if dtype is None:\n        dtype = int\n    dtype = np.dtype(dtype)\n    if dtype.kind in \"iu\" and weights is not None and weights.dtype.kind == \"f\":\n        raise RuntimeError(\"Integer histogram requested but float weights entered.\")\n\n    # Data sorting\n    if not already_sorted:\n        args = np.argsort(data)     # Memory: another copy\n        data = data[args]           # Memory: another copy\n        if weights is not None:\n            weights = weights[args]\n        del args\n\n    # Fill frequencies and errors\n    frequencies = np.zeros(bins.shape[0], dtype=dtype)\n    errors2 = np.zeros(bins.shape[0], dtype=dtype)\n    for xbin, bin in enumerate(bins):\n        start = np.searchsorted(data, bin[0], side=\"left\")\n        stop = np.searchsorted(data, bin[1], side=\"left\")\n\n        if xbin == 0:\n            if weights is not None:\n                underflow = weights[0:start].sum()\n            else:\n                underflow = start\n        if xbin == len(bins) - 1:\n            stop = np.searchsorted(data, bin[1], side=\"right\")   # TODO: Understand and explain\n            if weights is not None:\n                overflow = weights[stop:].sum()\n            else:\n                overflow = data.shape[0] - stop\n\n        if weights is not None:\n            frequencies[xbin] = weights[start:stop].sum()\n            errors2[xbin] = (weights[start:stop] ** 2).sum()\n            sum += (data[start:stop] * weights[start:stop]).sum()\n            sum2 += ((data[start:stop]) ** 2 * weights[start:stop]).sum()\n        else:\n            frequencies[xbin] = stop - start\n            errors2[xbin] = stop - start\n            sum += data[start:stop].sum()\n            sum2 += (data[start:stop] ** 2).sum()\n\n    # Underflow and overflow don't make sense for unconsecutive binning.\n    if not bin_utils.is_consecutive(bins):\n        underflow = np.nan\n        overflow = np.nan\n\n    stats = {\"sum\": sum, \"sum2\": sum2}\n\n    return frequencies, errors2, underflow, overflow, stats", "response": "Calculate the frequencies and bin errors from the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects the item at the given index.", "response": "def select(self, axis, index, force_copy: bool = False):\n        \"\"\"Alias for [] to be compatible with HistogramND.\"\"\"\n        if axis == 0:\n            if index == slice(None) and not force_copy:\n                return self\n            return self[index]\n        else:\n            raise ValueError(\"In Histogram1D.select(), axis must be 0.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef numpy_like(self) -> Tuple[np.ndarray, np.ndarray]:\n        return self.frequencies, self.numpy_bins", "response": "Return the numpy - like version of the frequency histogram."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the standard deviation of all values entered into histogram.", "response": "def std(self) -> Optional[float]:  #, ddof=0):\n        \"\"\"Standard deviation of all values entered into histogram.\n\n        This number is precise, because we keep the necessary data\n        separate from bin contents.\n\n        Returns\n        -------\n        float\n        \"\"\"\n        # TODO: Add DOF\n        if self._stats:\n            return np.sqrt(self.variance())\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_bin(self, value):\n        ixbin = np.searchsorted(self.bin_left_edges, value, side=\"right\")\n        if ixbin == 0:\n            return -1\n        elif ixbin == self.bin_count:\n            if value <= self.bin_right_edges[-1]:\n                return ixbin - 1\n            else:\n                return self.bin_count\n        elif value < self.bin_right_edges[ixbin - 1]:\n            return ixbin - 1\n        elif ixbin == self.bin_count:\n            return self.bin_count\n        else:\n            return None", "response": "Returns the index of the bin corresponding to a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fill(self, value, weight=1):\n        self._coerce_dtype(type(weight))\n        if self._binning.is_adaptive():\n            map = self._binning.force_bin_existence(value)\n            self._reshape_data(self._binning.bin_count, map)\n\n        ixbin = self.find_bin(value)\n        if ixbin is None:\n            self.overflow = np.nan\n            self.underflow = np.nan\n        elif ixbin == -1 and self.keep_missed:\n            self.underflow += weight\n        elif ixbin == self.bin_count and self.keep_missed:\n            self.overflow += weight\n        else:\n            self._frequencies[ixbin] += weight\n            self._errors2[ixbin] += weight ** 2\n            if self._stats:\n                self._stats[\"sum\"] += weight * value\n                self._stats[\"sum2\"] += weight * value ** 2\n        return ixbin", "response": "Update the histogram with a new value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the histogram with a set of values.", "response": "def fill_n(self, values, weights=None, dropna: bool = True):\n        \"\"\"Update histograms with a set of values.\n\n        Parameters\n        ----------\n        values: array_like\n        weights: Optional[array_like]\n        drop_na: Optional[bool]\n            If true (default), all nan's are skipped.\n        \"\"\"\n        # TODO: Unify with HistogramBase\n        values = np.asarray(values)\n        if dropna:\n            values = values[~np.isnan(values)]\n        if self._binning.is_adaptive():\n            map = self._binning.force_bin_existence(values)\n            self._reshape_data(self._binning.bin_count, map)\n        if weights:\n            weights = np.asarray(weights)\n            self._coerce_dtype(weights.dtype)\n        (frequencies, errors2, underflow, overflow, stats) = \\\n            calculate_frequencies(values, self._binning, dtype=self.dtype,\n                                  weights=weights, validate_bins=False)\n        self._frequencies += frequencies\n        self._errors2 += errors2\n        # TODO: check that adaptive does not produce under-/over-flows?\n        if self.keep_missed:\n            self.underflow += underflow\n            self.overflow += overflow\n        if self._stats:\n            for key in self._stats:\n                self._stats[key] += stats.get(key, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert to pandas DataFrame.", "response": "def to_dataframe(self) -> \"pandas.DataFrame\":\n        \"\"\"Convert to pandas DataFrame.\n\n        This is not a lossless conversion - (under/over)flow info is lost.\n        \"\"\"\n        import pandas as pd\n        df = pd.DataFrame(\n            {\n                \"left\": self.bin_left_edges,\n                \"right\": self.bin_right_edges,\n                \"frequency\": self.frequencies,\n                \"error\": self.errors,\n            },\n            columns=[\"left\", \"right\", \"frequency\", \"error\"])\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting to xarray. Dataset", "response": "def to_xarray(self) -> \"xarray.Dataset\":\n        \"\"\"Convert to xarray.Dataset\"\"\"\n        import xarray as xr\n        data_vars = {\n            \"frequencies\": xr.DataArray(self.frequencies, dims=\"bin\"),\n            \"errors2\": xr.DataArray(self.errors2, dims=\"bin\"),\n            \"bins\": xr.DataArray(self.bins, dims=(\"bin\", \"x01\"))\n        }\n        coords = {}\n        attrs = {\n            \"underflow\": self.underflow,\n            \"overflow\": self.overflow,\n            \"inner_missed\": self.inner_missed,\n            \"keep_missed\": self.keep_missed\n        }\n        attrs.update(self._meta_data)\n        # TODO: Add stats\n        return xr.Dataset(data_vars, coords, attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_xarray(cls, arr: \"xarray.Dataset\") -> \"Histogram1D\":\n        kwargs = {'frequencies': arr[\"frequencies\"],\n                  'binning': arr[\"bins\"],\n                  'errors2': arr[\"errors2\"],\n                  'overflow': arr.attrs[\"overflow\"],\n                  'underflow': arr.attrs[\"underflow\"],\n                  'keep_missed': arr.attrs[\"keep_missed\"]}\n        # TODO: Add stats\n        return cls(**kwargs)", "response": "Convert form xarray. Dataset to histogram1D"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_default_backend(name: str):\n    global _default_backend\n    if name == \"bokeh\":\n        raise RuntimeError(\"Support for bokeh has been discontinued. At some point, we may return to support holoviews.\")\n    if not name in backends:\n        raise RuntimeError(\"Backend {0} is not supported and cannot be set as default.\".format(name))\n    _default_backend = name", "response": "Choose a default backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a plotting backend. Tries to get it using the name - or the default one.", "response": "def _get_backend(name: str = None):\n    \"\"\"Get a plotting backend.\n\n    Tries to get it using the name - or the default one.\n    \"\"\"\n    if not backends:\n        raise RuntimeError(\"No plotting backend available. Please, install matplotlib (preferred) or bokeh (limited).\")\n    if not name:\n        name = _default_backend\n    if name == \"bokeh\":\n        raise RuntimeError(\"Support for bokeh has been discontinued. At some point, we may return to support holoviews.\")\n    backend = backends.get(name)\n    if not backend:\n        raise RuntimeError(\"Backend {0} does not exist. Use one of the following: {1}\".format(name, \", \".join(backends.keys())))\n    return name, backends[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(histogram: HistogramBase, kind: Optional[str] = None, backend: Optional[str] = None, **kwargs):\n    backend_name, backend = _get_backend(backend)\n    if kind is None:\n        kinds = [t for t in backend.types if histogram.ndim in backend.dims[t]]\n        if not kinds:\n            raise RuntimeError(\"No plot type is supported for {0}\"\n                               .format(histogram.__class__.__name__))\n        kind = kinds[0]\n    if kind in backend.types:\n        method = getattr(backend, kind)\n        return method(histogram, **kwargs)\n    else:\n        raise RuntimeError(\"Histogram type error: {0} missing in backend {1}\"\n                           .format(kind, backend_name))", "response": "Plot a histogram in a new node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_vega(vega_data, *, title: Optional[str], write_to: str, write_format: str = \"auto\", indent: int = 2):\n    spec = json.dumps(vega_data, indent=indent)\n    if write_format == \"html\" or write_format is \"auto\" and write_to.endswith(\".html\"):\n        output = HTML_TEMPLATE.replace(\"{{ title }}\", title or \"Histogram\").replace(\"{{ spec }}\", spec)\n    elif write_format == \"json\" or write_format is \"auto\" and write_to.endswith(\".json\"):\n        output = spec\n    else:\n        raise RuntimeError(\"Format not understood.\")\n    with codecs.open(write_to, \"w\", encoding=\"utf-8\") as out:\n        out.write(output)", "response": "Write vega dictionary to an external file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef display_vega(vega_data: dict, display: bool = True) -> Union['Vega', dict]:\n    if VEGA_IPYTHON_PLUGIN_ENABLED and display:\n        from vega3 import Vega\n        return Vega(vega_data)\n    else:\n        return vega_data", "response": "Optionally display vega dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a 1D bar plot of the 1D histogram.", "response": "def bar(h1: Histogram1D, **kwargs) -> dict:\n    \"\"\"Bar plot of 1D histogram.\n\n    Parameters\n    ----------\n    lw : float\n        Width of the line between bars\n    alpha : float\n        Opacity of the bars\n    hover_alpha: float\n        Opacity of the bars when hover on\n    \"\"\"\n    # TODO: Enable collections\n    # TODO: Enable legend\n\n    vega = _create_figure(kwargs)\n    _add_title(h1, vega, kwargs)\n    _create_scales(h1, vega, kwargs)\n    _create_axes(h1, vega, kwargs)\n\n    data = get_data(h1, kwargs.pop(\"density\", None), kwargs.pop(\"cumulative\", None)).tolist()\n    lefts = h1.bin_left_edges.astype(float).tolist()\n    rights = h1.bin_right_edges.astype(float).tolist()\n\n    vega[\"data\"] = [{\n        \"name\": \"table\",\n        \"values\": [{\n                \"x\": lefts[i],\n                \"x2\": rights[i],\n                \"y\": data[i],\n            }\n            for i in range(h1.bin_count)\n        ]\n    }]\n\n    alpha = kwargs.pop(\"alpha\", 1)\n    # hover_alpha = kwargs.pop(\"hover_alpha\", alpha)\n\n    vega[\"marks\"] = [\n        {\n            \"type\": \"rect\",\n            \"from\": {\"data\": \"table\"},\n            \"encode\": {\n                \"enter\": {\n                    \"x\": {\"scale\": \"xscale\", \"field\": \"x\"},\n                    \"x2\": {\"scale\": \"xscale\", \"field\": \"x2\"},\n                    \"y\": {\"scale\": \"yscale\", \"value\": 0},\n                    \"y2\": {\"scale\": \"yscale\", \"field\": \"y\"},\n                    # \"stroke\": {\"scale\": \"color\", \"field\": \"c\"},\n                    \"strokeWidth\": {\"value\": kwargs.pop(\"lw\", 2)}\n                },\n                \"update\": {\n                    \"fillOpacity\": [\n                        # {\"test\": \"datum === tooltip\", \"value\": hover_alpha},\n                        {\"value\": alpha}\n                    ]\n                },\n            }\n        }\n    ]\n    _create_tooltips(h1, vega, kwargs)\n\n    return vega"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscatter plot of 1D histogram values.", "response": "def scatter(h1: Histogram1D, **kwargs) -> dict:\n    \"\"\"Scatter plot of 1D histogram values.\n\n    Points are horizontally placed in bin centers.\n\n    Parameters\n    ----------\n    shape : str\n    \"\"\"\n    shape = kwargs.pop(\"shape\", DEFAULT_SCATTER_SHAPE)\n    # size = kwargs.pop(\"size\", DEFAULT_SCATTER_SIZE)\n\n    mark_template = [{\n        \"type\": \"symbol\",\n        \"from\": {\"data\": \"series\"},\n        \"encode\": {\n            \"enter\": {\n                \"x\": {\"scale\": \"xscale\", \"field\": \"x\"},\n                \"y\": {\"scale\": \"yscale\", \"field\": \"y\"},\n                \"shape\": {\"value\": shape},\n                # \"size\": {\"value\": size},\n                \"fill\": {\"scale\": \"series\", \"field\": \"c\"},\n            },\n        }\n    }]\n    vega = _scatter_or_line(h1, mark_template=mark_template, kwargs=kwargs)\n    return vega"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef line(h1: Histogram1D, **kwargs) -> dict:\n\n    lw = kwargs.pop(\"lw\", DEFAULT_STROKE_WIDTH)\n\n    mark_template = [{\n        \"type\": \"line\",\n        \"encode\": {\n            \"enter\": {\n                \"x\": {\"scale\": \"xscale\", \"field\": \"x\"},\n                \"y\": {\"scale\": \"yscale\", \"field\": \"y\"},\n                \"stroke\": {\"scale\": \"series\", \"field\": \"c\"},\n                \"strokeWidth\": {\"value\": lw}\n            }\n        },\n        \"from\": {\"data\": \"series\"},\n    }]\n    vega = _scatter_or_line(h1, mark_template=mark_template, kwargs=kwargs)\n    return vega", "response": "Plots a line plot of 1D histogram values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nheat - map of two - dimensional histogram.", "response": "def map(h2: Histogram2D, *, show_zero: bool = True, show_values: bool = False, **kwargs) -> dict:\n    \"\"\"Heat-map of two-dimensional histogram.\"\"\"\n    vega = _create_figure(kwargs)\n\n    values_arr = get_data(h2, kwargs.pop(\"density\", None), kwargs.pop(\"cumulative\", None))\n    values = values_arr.tolist()\n    value_format = get_value_format(kwargs.pop(\"value_format\", None))\n\n    _add_title(h2, vega, kwargs)\n    _create_scales(h2, vega, kwargs)\n    _create_axes(h2, vega, kwargs)\n    _create_cmap_scale(values_arr, vega, kwargs)\n    _create_colorbar(vega, kwargs)\n\n    x = h2.get_bin_centers(0)\n    y = h2.get_bin_centers(1)\n    x1 = h2.get_bin_left_edges(0)\n    x2 = h2.get_bin_right_edges(0)\n    y1 = h2.get_bin_left_edges(1)\n    y2 = h2.get_bin_right_edges(1)\n\n    data = []\n    for i in range(h2.shape[0]):\n        for j in range(h2.shape[1]):\n            if not show_zero and values[i][j] == 0:\n                continue\n            item = {\n                \"x\": float(x[i]),\n                \"x1\": float(x1[i]),\n                \"x2\": float(x2[i]),\n                \"y\": float(y[j]),\n                \"y1\": float(y1[j]),\n                \"y2\": float(y2[j]),\n                \"c\": float(values[i][j])\n            }\n            if show_values:\n                item[\"label\"] = value_format(values[i][j])\n            data.append(item)\n\n    vega[\"data\"] = [{\n        \"name\": \"table\",\n        \"values\": data\n    }]\n\n    vega[\"marks\"] = [\n        {\n            \"type\": \"rect\",\n            \"from\": {\"data\": \"table\"},\n            \"encode\": {\n                \"enter\": {\n                    \"x\": {\"scale\": \"xscale\", \"field\": \"x1\"},\n                    \"x2\": {\"scale\": \"xscale\", \"field\": \"x2\"},\n                    \"y\": {\"scale\": \"yscale\", \"field\": \"y1\"},\n                    \"y2\": {\"scale\": \"yscale\", \"field\": \"y2\"},\n                    \"fill\": {\"scale\": \"color\", \"field\": \"c\"},\n                    \"stroke\": {\"value\": 0},\n                    # \"strokeWidth\": {\"value\": 0},\n                    # \"fillColor\": {\"value\": \"#ffff00\"}\n                },\n                \"update\": {\n                    \"fillOpacity\": {\"value\": kwargs.pop(\"alpha\", 1)}\n                },\n                # \"hover\": {\n                #     \"fillOpacity\": {\"value\": 0.5}\n                # }\n            }\n        }\n    ]\n\n    if show_values:\n        vega[\"marks\"].append(\n            {\n                \"type\": \"text\",\n                \"from\": {\"data\": \"table\"},\n                \"encode\": {\n                    \"enter\": {\n                        \"align\": {\"value\": \"center\"},\n                        \"baseline\": {\"value\": \"middle\"},\n                        \"fontSize\": {\"value\": 13},\n                        \"fontWeight\": {\"value\": \"bold\"},\n                        \"text\": {\"field\": \"label\"},\n                        \"x\": {\"scale\": \"xscale\", \"field\": \"x\"},\n                        \"y\": {\"scale\": \"yscale\", \"field\": \"y\"},\n                    }\n                }\n            }\n        )\n\n    return vega"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_with_slider(h3: HistogramND, *, show_zero: bool = True, show_values: bool = False, **kwargs) -> dict:\n    vega = _create_figure(kwargs)\n\n    values_arr = get_data(h3, kwargs.pop(\"density\", None), kwargs.pop(\"cumulative\", None))\n    values = values_arr.tolist()\n    value_format = get_value_format(kwargs.pop(\"value_format\", None))\n\n    _add_title(h3, vega, kwargs)\n    _create_scales(h3, vega, kwargs)\n    _create_axes(h3, vega, kwargs)\n    _create_cmap_scale(values_arr, vega, kwargs)\n    _create_colorbar(vega, kwargs)\n\n    x = h3.get_bin_centers(0)\n    y = h3.get_bin_centers(1)\n    x1 = h3.get_bin_left_edges(0)\n    x2 = h3.get_bin_right_edges(0)\n    y1 = h3.get_bin_left_edges(1)\n    y2 = h3.get_bin_right_edges(1)\n\n    data = []\n    for i in range(h3.shape[0]):\n        for j in range(h3.shape[1]):\n            for k in range(h3.shape[2]):\n                if not show_zero and values[i][j][k] == 0:\n                    continue\n                item = {\n                    \"x\": float(x[i]),\n                    \"x1\": float(x1[i]),\n                    \"x2\": float(x2[i]),\n                    \"y\": float(y[j]),\n                    \"y1\": float(y1[j]),\n                    \"y2\": float(y2[j]),\n                    \"k\": k,\n                    \"c\": float(values[i][j][k]),\n                }\n                if show_values:\n                    item[\"label\"] = value_format(values[i][j][k])\n                data.append(item)\n\n    vega[\"signals\"] = [\n        {\n            \"name\": \"k\", \"value\": h3.shape[2] // 2,\n            \"bind\": {\n                \"input\": \"range\", \"min\": 0, \"max\": h3.shape[2] - 1,\n                \"step\": 1, \"name\": (h3.axis_names[2] or \"axis2\") + \" [slice]\"\n            }\n        }\n    ]\n\n    vega[\"data\"] = [{\n        \"name\": \"table\",\n        \"values\": data,\n        \"transform\": [\n             {\n                 \"type\": \"filter\",\n                 \"expr\": \"k == datum.k\",\n             }\n        ]\n    }]\n\n    vega[\"marks\"] = [\n        {\n            \"type\": \"rect\",\n            \"from\": {\"data\": \"table\"},\n            \"encode\": {\n                \"enter\": {\n                    \"x\": {\"scale\": \"xscale\", \"field\": \"x1\"},\n                    \"x2\": {\"scale\": \"xscale\", \"field\": \"x2\"},\n                    \"y\": {\"scale\": \"yscale\", \"field\": \"y1\"},\n                    \"y2\": {\"scale\": \"yscale\", \"field\": \"y2\"},\n                    \"fill\": {\"scale\": \"color\", \"field\": \"c\"},\n                    \"stroke\": {\"value\": 0},\n                    # \"strokeWidth\": {\"value\": 0},\n                    # \"fillColor\": {\"value\": \"#ffff00\"}\n                },\n                # \"update\": {\n                #     \"fillOpacity\": {\"value\": 0.6}\n                # },\n                # \"hover\": {\n                #     \"fillOpacity\": {\"value\": 0.5}\n                # }\n            }\n        }\n    ]\n\n    if show_values:\n        vega[\"marks\"].append(\n            {\n                \"type\": \"text\",\n                \"from\": {\"data\": \"table\"},\n                \"encode\": {\n                    \"enter\": {\n                        \"align\": {\"value\": \"center\"},\n                        \"baseline\": {\"value\": \"middle\"},\n                        \"fontSize\": {\"value\": 13},\n                        \"fontWeight\": {\"value\": \"bold\"},\n                        \"text\": {\"field\": \"label\"},\n                        \"x\": {\"scale\": \"xscale\", \"field\": \"x\"},\n                        \"y\": {\"scale\": \"yscale\", \"field\": \"y\"},\n                    }\n                }\n            }\n        )\n\n    return vega", "response": "Heatmap showing slice in first two dimensions third dimension represented as a slider."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate shared properties for scatter or line plot.", "response": "def _scatter_or_line(h1: Histogram1D, mark_template: list, kwargs: dict) -> dict:\n    \"\"\"Create shared properties for scatter / line plot.\"\"\"\n    from physt.histogram_collection import HistogramCollection\n    if isinstance(h1, HistogramCollection):\n        collection = h1\n        h1 = h1[0]\n    else:\n        collection = HistogramCollection(h1)\n\n    vega = _create_figure(kwargs)\n\n    legend = kwargs.pop(\"legend\", len(collection) > 1)\n\n    vega[\"data\"] = [\n        {\n            \"name\": \"table\",\n            \"values\": []\n        },\n        {\n            \"name\": \"labels\",\n            \"values\": [h.name for h in collection]\n        }]\n\n    for hist_i, histogram in enumerate(collection):\n        centers = histogram.bin_centers.tolist()\n        data = get_data(histogram, kwargs.pop(\"density\", None), kwargs.pop(\"cumulative\", None)).tolist()\n        vega[\"data\"][0][\"values\"] += [{\"x\": centers[i], \"y\": data[i], \"c\": hist_i} for i in range(histogram.bin_count)]\n\n    _add_title(collection, vega, kwargs)\n    _create_scales(collection, vega, kwargs)\n    _create_axes(collection, vega, kwargs)\n    _create_series_scales(vega)\n    _create_series_faceted_marks(vega, mark_template)\n    _create_tooltips(h1, vega, kwargs)  # TODO: Make it work!\n    if legend:\n        _create_series_legend(vega)\n\n    return vega"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_figure(kwargs: Mapping[str, Any]) -> dict:\n    return {\n        \"$schema\": \"https://vega.github.io/schema/vega/v3.json\",\n        \"width\": kwargs.pop(\"width\", DEFAULT_WIDTH),\n        \"height\": kwargs.pop(\"height\", DEFAULT_HEIGHT),\n        \"padding\": kwargs.pop(\"padding\", DEFAULT_PADDING)\n    }", "response": "Create basic dictionary object with figure properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates proper scales for axes.", "response": "def _create_scales(hist: HistogramBase, vega: dict, kwargs: dict):\n    \"\"\"Find proper scales for axes.\"\"\"\n    if hist.ndim == 1:\n        bins0 = hist.bins.astype(float)\n    else:\n        bins0 = hist.bins[0].astype(float)\n\n    xlim = kwargs.pop(\"xlim\", \"auto\")\n    ylim = kwargs.pop(\"ylim\", \"auto\")\n\n    if xlim is \"auto\":\n        nice_x = True\n    else:\n        nice_x = False\n\n    if ylim is \"auto\":\n        nice_y = True\n    else:\n        nice_y = False\n\n    # TODO: Unify xlim & ylim parameters with matplotlib\n    # TODO: Apply xscale & yscale parameters\n\n    vega[\"scales\"] = [\n        {\n            \"name\": \"xscale\",\n            \"type\": \"linear\",\n            \"range\": \"width\",\n            \"nice\": nice_x,\n            \"zero\": None,\n            \"domain\": [bins0[0, 0], bins0[-1, 1]] if xlim == \"auto\" else [float(xlim[0]), float(xlim[1])],\n            # \"domain\": {\"data\": \"table\", \"field\": \"x\"}\n        },\n        {\n            \"name\": \"yscale\",\n            \"type\": \"linear\",\n            \"range\": \"height\",\n            \"nice\": nice_y,\n            \"zero\": True if hist.ndim == 1 else None,\n            \"domain\": {\"data\": \"table\", \"field\": \"y\"} if ylim == \"auto\" else [float(ylim[0]), float(ylim[1])]\n        }\n    ]\n\n    if hist.ndim >= 2:\n        bins1 = hist.bins[1].astype(float)\n        vega[\"scales\"][1][\"domain\"] = [bins1[0, 0], bins1[-1, 1]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating axes in the figure.", "response": "def _create_axes(hist: HistogramBase, vega: dict, kwargs: dict):\n    \"\"\"Create axes in the figure.\"\"\"\n    xlabel = kwargs.pop(\"xlabel\", hist.axis_names[0])\n    ylabel = kwargs.pop(\"ylabel\", hist.axis_names[1] if len(hist.axis_names) >= 2 else None)\n    vega[\"axes\"] = [\n        {\"orient\": \"bottom\", \"scale\": \"xscale\", \"title\": xlabel},\n        {\"orient\": \"left\", \"scale\": \"yscale\", \"title\": ylabel}\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_title(hist: HistogramBase, vega: dict, kwargs: dict):\n    title = kwargs.pop(\"title\", hist.title)\n    if title:\n        vega[\"title\"] = {\n            \"text\": title\n        }", "response": "Display plot title if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming data for binning. Returns ------- np. ndarray data", "response": "def _prepare_data(data, transformed, klass,  *args, **kwargs):\n    \"\"\"Transform data for binning.\n\n    Returns\n    -------\n    np.ndarray\n    \"\"\"\n    # TODO: Maybe include in the class itself?\n    data = np.asarray(data)\n    if not transformed:\n        data = klass.transform(data)\n    dropna = kwargs.get(\"dropna\", False)\n    if dropna:\n        data = data[~np.isnan(data).any(axis=1)]\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a PolarHistogram object for the given data and data.", "response": "def polar_histogram(xdata, ydata, radial_bins=\"numpy\", phi_bins=16,\n                    transformed=False, *args, **kwargs):\n    \"\"\"Facade construction function for the PolarHistogram.\n\n    Parameters\n    ----------\n    transformed : bool\n    phi_range : Optional[tuple]\n    range\n    \"\"\"\n    dropna = kwargs.pop(\"dropna\", True)\n    data = np.concatenate([xdata[:, np.newaxis], ydata[:, np.newaxis]], axis=1)\n    data = _prepare_data(data, transformed=transformed, klass=PolarHistogram, dropna=dropna)\n\n    if isinstance(phi_bins, int):\n        phi_range = (0, 2 * np.pi)\n        if \"phi_range\" in \"kwargs\":\n            phi_range = kwargs[\"phi_range\"]\n        elif \"range\" in \"kwargs\":\n            phi_range = kwargs[\"range\"][1]\n        phi_range = list(phi_range) + [phi_bins + 1]\n        phi_bins = np.linspace(*phi_range)\n\n    bin_schemas = binnings.calculate_bins_nd(data, [radial_bins, phi_bins], *args,\n                                             check_nan=not dropna, **kwargs)\n    weights = kwargs.pop(\"weights\", None)\n    frequencies, errors2, missed = histogram_nd.calculate_frequencies(data, ndim=2,\n                                                                      binnings=bin_schemas,\n                                                                      weights=weights)\n    return PolarHistogram(binnings=bin_schemas, frequencies=frequencies, errors2=errors2, missed=missed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spherical_histogram(data=None, radial_bins=\"numpy\", theta_bins=16, phi_bins=16, transformed=False, *args, **kwargs):\n\n    dropna = kwargs.pop(\"dropna\", True)\n    data = _prepare_data(data, transformed=transformed, klass=SphericalHistogram, dropna=dropna)\n\n    if isinstance(theta_bins, int):\n        theta_range = (0, np.pi)\n        if \"theta_range\" in \"kwargs\":\n            theta_range = kwargs[\"theta_range\"]\n        elif \"range\" in \"kwargs\":\n            theta_range = kwargs[\"range\"][1]\n        theta_range = list(theta_range) + [theta_bins + 1]\n        theta_bins = np.linspace(*theta_range)\n\n    if isinstance(phi_bins, int):\n        phi_range = (0, 2 * np.pi)\n        if \"phi_range\" in \"kwargs\":\n            phi_range = kwargs[\"phi_range\"]\n        elif \"range\" in \"kwargs\":\n            phi_range = kwargs[\"range\"][2]\n        phi_range = list(phi_range) + [phi_bins + 1]\n        phi_bins = np.linspace(*phi_range)\n\n    bin_schemas = binnings.calculate_bins_nd(data, [radial_bins, theta_bins, phi_bins], *args,\n                                             check_nan=not dropna, **kwargs)\n    weights = kwargs.pop(\"weights\", None)\n    frequencies, errors2, missed = histogram_nd.calculate_frequencies(data, ndim=3,\n                                                                  binnings=bin_schemas,\n                                                                  weights=weights)\n    return SphericalHistogram(binnings=bin_schemas, frequencies=frequencies, errors2=errors2, missed=missed)", "response": "A basic method to create a SphericalHistogram object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef projection(self, *axes, **kwargs):\n        axes, _ = self._get_projection_axes(*axes)\n        axes = tuple(sorted(axes))\n        if axes in self._projection_class_map:\n            klass = self._projection_class_map[axes]\n            return HistogramND.projection(self, *axes, type=klass, **kwargs)\n        else:\n            return HistogramND.projection(self, *axes, **kwargs)", "response": "Projection to lower - dimensional histogram. The class attribute _projection_class_map_\n        is used to suggest class for the projection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enable_collection(f):\n    @wraps(f)\n    def new_f(h: AbstractHistogram1D, **kwargs):\n        from physt.histogram_collection import HistogramCollection\n        if isinstance(h, HistogramCollection):\n            return f(h, **kwargs)\n        else:\n            return f(HistogramCollection(h), **kwargs)\n    return new_f", "response": "Decorator to enable a histogram collection as argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_ticks(xaxis: go.layout.XAxis, histogram: HistogramBase, kwargs: dict):\n    ticks = kwargs.pop(\"ticks\", None)\n    tick_handler = kwargs.pop(\"tick_handler\", None)\n\n    if tick_handler:\n        if ticks:\n            raise ValueError(\"Cannot specify both tick and tick_handler\")\n        ticks, labels = tick_handler(histogram, histogram.min_edge, histogram.max_edge)\n\n        xaxis.tickvals = ticks\n        xaxis.ticktext = labels\n\n    elif ticks == \"center\":\n        xaxis.tickvals = histogram.bin_centers\n    elif ticks == \"edge\":\n        xaxis.tickvals = histogram.bin_left_edges\n    else:\n        xaxis.tickvals = ticks", "response": "Customize ticks for an axis."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bar(h: Histogram2D, *,\n        barmode: str = DEFAULT_BARMODE,\n        alpha: float = DEFAULT_ALPHA,\n        **kwargs):\n    \"\"\"Bar plot.\n\n    Parameters\n    ----------\n    alpha: Opacity (0.0 - 1.0)\n    barmode : \"overlay\" | \"group\" | \"stack\"\n    \"\"\"\n    get_data_kwargs = pop_many(kwargs, \"density\", \"cumulative\", \"flatten\")\n    data = [go.Bar(\n        x=histogram.bin_centers,\n        y=get_data(histogram, **get_data_kwargs),\n        width=histogram.bin_widths,\n        name=histogram.name,\n        opacity=alpha,\n        **kwargs\n    ) for histogram in h]\n\n    layout = go.Layout(barmode=barmode)\n\n    _add_ticks(layout.xaxis, h[0], kwargs)\n\n    figure = go.Figure(data=data, layout=layout)\n    return figure", "response": "Generate a bar plot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating GeoJSON representation of histogram bins", "response": "def _bins_to_json(h2):\n    \"\"\"Create GeoJSON representation of histogram bins\n\n    Parameters\n    ----------\n    h2: physt.histogram_nd.Histogram2D\n        A histogram of coordinates (in degrees)\n\n    Returns\n    -------\n    geo_json : dict\n    \"\"\"\n    south = h2.get_bin_left_edges(0)\n    north = h2.get_bin_right_edges(0)\n    west = h2.get_bin_left_edges(1)\n    east = h2.get_bin_right_edges(1)\n    return {\n        \"type\":\"FeatureCollection\",\n        \"features\": [\n            {\n                \"type\": \"Feature\",\n                \"geometry\": {\n                    \"type\": \"Polygon\",\n                    # Note that folium and GeoJson have them swapped\n                    \"coordinates\": [[\n                        [east[j], south[i]],\n                        [east[j], north[i]],\n                        [west[j], north[i]],\n                        [west[j], south[i]],\n                        [east[j], south[i]]]],\n                },\n                \"properties\" : {\n                    \"count\": float(h2.frequencies[i, j])\n                }\n            }\n            for i in range(h2.shape[0])\n            for j in range(h2.shape[1])\n        ]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows rectangular grid over a map.", "response": "def geo_map(h2, map=None, tiles='stamenterrain', cmap=\"wk\", alpha=0.5, lw=1, fit_bounds=None, layer_name=None):\n    \"\"\"Show rectangular grid over a map.\n\n    Parameters\n    ----------\n    h2: physt.histogram_nd.Histogram2D\n        A histogram of coordinates (in degrees: latitude, longitude)\n    map : folium.folium.Map\n\n    Returns\n    -------\n    map : folium.folium.Map\n    \"\"\"\n    if not map:\n        latitude = h2.get_bin_centers(0).mean()\n        longitude = h2.get_bin_centers(1).mean()\n        zoom_start = 10\n        map = folium.Map(location=[latitude, longitude], tiles=tiles)\n        if fit_bounds == None:\n            fit_bounds = True\n\n    geo_json = _bins_to_json(h2)\n\n    if not layer_name:\n        layer_name = h2.name\n\n    from branca.colormap import LinearColormap\n\n    color_map = LinearColormap(cmap, vmin=h2.frequencies.min(), vmax=h2.frequencies.max())\n\n    # legend = folium.Html(\"<div>Legend</div>\")\n    # legend_div = folium.Div(\"20%\", \"20%\", \"75%\", \"5%\")\n    #\n    # legend_div.add_to(map)\n    # legend_div.add_child(legend)\n\n    #xx = h2.frequencies.max()\n\n    def styling_function(bin):\n        count = bin[\"properties\"][\"count\"]\n        return {\n            \"fillColor\": color_map(count),\n            \"color\": \"black\",\n            \"fillOpacity\": alpha if count > 0 else 0,\n            \"weight\": lw,\n            # \"strokeWidth\": lw,\n            \"opacity\": alpha if count > 0 else 0,\n        }# .update(styling)\n\n    layer = folium.GeoJson(geo_json, style_function=styling_function, name=layer_name)\n    layer.add_to(map)\n    if fit_bounds:\n        map.fit_bounds(layer.get_bounds())\n    return map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_csv(path):\n    meta = []\n    data = []\n    with codecs.open(path, encoding=\"ASCII\") as in_file:\n        for line in in_file:\n            if line.startswith(\"#\"):\n                key, value = line[1:].strip().split(\" \", 1)\n                meta.append((key, value))   # TODO: There are duplicit entries :-()\n            else:\n                try:\n                    data.append([float(frag) for frag in line.split(\",\")])\n                except:\n                    pass\n    data = np.asarray(data)\n    ndim = int(_get(meta, \"dimension\"))\n    if ndim == 1:\n        return _create_h1(data, meta)\n    elif ndim == 2:\n        return _create_h2(data, meta)", "response": "Loads a histogram as output from Geant4 analysis tools in CSV format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef queryURL(self, xri, service_type=None):\n        # Trim off the xri:// prefix.  The proxy resolver didn't accept it\n        # when this code was written, but that may (or may not) change for\n        # XRI Resolution 2.0 Working Draft 11.\n        qxri = toURINormal(xri)[6:]\n        hxri = self.proxy_url + qxri\n        args = {\n            # XXX: If the proxy resolver will ensure that it doesn't return\n            # bogus CanonicalIDs (as per Steve's message of 15 Aug 2006\n            # 11:13:42), then we could ask for application/xrd+xml instead,\n            # which would give us a bit less to process.\n            '_xrd_r': 'application/xrds+xml',\n            }\n        if service_type:\n            args['_xrd_t'] = service_type\n        else:\n            # Don't perform service endpoint selection.\n            args['_xrd_r'] += ';sep=false'\n        query = _appendArgs(hxri, args)\n        return query", "response": "Builds a URL to query the proxy resolver for the given XRI and optional service type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query(self, xri, service_types):\n        # FIXME: No test coverage!\n        services = []\n        # Make a seperate request to the proxy resolver for each service\n        # type, as, if it is following Refs, it could return a different\n        # XRDS for each.\n\n        canonicalID = None\n\n        for service_type in service_types:\n            url = self.queryURL(xri, service_type)\n            response = fetchers.fetch(url)\n            if response.status not in (200, 206):\n                # XXX: sucks to fail silently.\n                # print \"response not OK:\", response\n                continue\n            et = etxrd.parseXRDS(response.body)\n            canonicalID = etxrd.getCanonicalID(xri, et)\n            some_services = list(iterServices(et))\n            services.extend(some_services)\n        # TODO:\n        #  * If we do get hits for multiple service_types, we're almost\n        #    certainly going to have duplicated service entries and\n        #    broken priority ordering.\n        return canonicalID, services", "response": "Query some services for an XRI."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generateAcceptHeader(*elements):\n    parts = []\n    for element in elements:\n        if type(element) is str:\n            qs = \"1.0\"\n            mtype = element\n        else:\n            mtype, q = element\n            q = float(q)\n            if q > 1 or q <= 0:\n                raise ValueError('Invalid preference factor: %r' % q)\n\n            qs = '%0.1f' % (q,)\n\n        parts.append((qs, mtype))\n\n    parts.sort()\n    chunks = []\n    for q, mtype in parts:\n        if q == '1.0':\n            chunks.append(mtype)\n        else:\n            chunks.append('%s; q=%s' % (mtype, q))\n\n    return ', '.join(chunks)", "response": "Generate an accept header value for the given list of elements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parseAcceptHeader(value):\n    chunks = [chunk.strip() for chunk in value.split(',')]\n    accept = []\n    for chunk in chunks:\n        parts = [s.strip() for s in chunk.split(';')]\n\n        mtype = parts.pop(0)\n        if '/' not in mtype:\n            # This is not a MIME type, so ignore the bad data\n            continue\n\n        main, sub = mtype.split('/', 1)\n\n        for ext in parts:\n            if '=' in ext:\n                k, v = ext.split('=', 1)\n                if k == 'q':\n                    try:\n                        q = float(v)\n                        break\n                    except ValueError:\n                        # Ignore poorly formed q-values\n                        pass\n        else:\n            q = 1.0\n\n        accept.append((q, main, sub))\n\n    accept.sort()\n    accept.reverse()\n    return [(main, sub, q) for (q, main, sub) in accept]", "response": "Parse an accept header ignoring any accept - extensions returning a list of tuples containing main MIME type MIME subtype and quality markdown."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving the result of parsing an Accept header and the available MIME types return the acceptable types with their quality markdowns.", "response": "def matchTypes(accept_types, have_types):\n    \"\"\"Given the result of parsing an Accept: header, and the\n    available MIME types, return the acceptable types with their\n    quality markdowns.\n\n    For example:\n\n    >>> acceptable = parseAcceptHeader('text/html, text/plain; q=0.5')\n    >>> matchTypes(acceptable, ['text/plain', 'text/html', 'image/jpeg'])\n    [('text/html', 1.0), ('text/plain', 0.5)]\n\n\n    Type signature: ([(str, str, float)], [str]) -> [(str, float)]\n    \"\"\"\n    if not accept_types:\n        # Accept all of them\n        default = 1\n    else:\n        default = 0\n\n    match_main = {}\n    match_sub = {}\n    for (main, sub, q) in accept_types:\n        if main == '*':\n            default = max(default, q)\n            continue\n        elif sub == '*':\n            match_main[main] = max(match_main.get(main, 0), q)\n        else:\n            match_sub[(main, sub)] = max(match_sub.get((main, sub), 0), q)\n\n    accepted_list = []\n    order_maintainer = 0\n    for mtype in have_types:\n        main, sub = mtype.split('/')\n        if (main, sub) in match_sub:\n            q = match_sub[(main, sub)]\n        else:\n            q = match_main.get(main, default)\n\n        if q:\n            accepted_list.append((1 - q, order_maintainer, q, mtype))\n            order_maintainer += 1\n\n    accepted_list.sort()\n    return [(mtype, q) for (_, _, q, mtype) in accepted_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the accept header and return a list of available types in preferred order.", "response": "def getAcceptable(accept_header, have_types):\n    \"\"\"Parse the accept header and return a list of available types in\n    preferred order. If a type is unacceptable, it will not be in the\n    resulting list.\n\n    This is a convenience wrapper around matchTypes and\n    parseAcceptHeader.\n\n    (str, [str]) -> [str]\n    \"\"\"\n    accepted = parseAcceptHeader(accept_header)\n    preferred = matchTypes(accepted, have_types)\n    return [mtype for (mtype, _) in preferred]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a Message containing a set of POST arguments.", "response": "def fromPostArgs(cls, args):\n        \"\"\"Construct a Message containing a set of POST arguments.\n\n        \"\"\"\n        self = cls()\n\n        # Partition into \"openid.\" args and bare args\n        openid_args = {}\n        for key, value in args.items():\n            if isinstance(value, list):\n                raise TypeError(\"query dict must have one value for each key, \"\n                                \"not lists of values.  Query is %r\" % (args,))\n\n\n            try:\n                prefix, rest = key.split('.', 1)\n            except ValueError:\n                prefix = None\n\n            if prefix != 'openid':\n                self.args[(BARE_NS, key)] = value\n            else:\n                openid_args[rest] = value\n\n        self._fromOpenIDArgs(openid_args)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the OpenID namespace URI used in this message.", "response": "def setOpenIDNamespace(self, openid_ns_uri, implicit):\n        \"\"\"Set the OpenID namespace URI used in this message.\n\n        @raises InvalidOpenIDNamespace: if the namespace is not in\n            L{Message.allowed_openid_namespaces}\n        \"\"\"\n        if openid_ns_uri not in self.allowed_openid_namespaces:\n            raise InvalidOpenIDNamespace(openid_ns_uri)\n\n        self.namespaces.addAlias(openid_ns_uri, NULL_NAMESPACE, implicit)\n        self._openid_ns_uri = openid_ns_uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toFormMarkup(self, action_url, form_tag_attrs=None,\n                     submit_text=u\"Continue\"):\n        \"\"\"Generate HTML form markup that contains the values in this\n        message, to be HTTP POSTed as x-www-form-urlencoded UTF-8.\n\n        @param action_url: The URL to which the form will be POSTed\n        @type action_url: str\n\n        @param form_tag_attrs: Dictionary of attributes to be added to\n            the form tag. 'accept-charset' and 'enctype' have defaults\n            that can be overridden. If a value is supplied for\n            'action' or 'method', it will be replaced.\n        @type form_tag_attrs: {unicode: unicode}\n\n        @param submit_text: The text that will appear on the submit\n            button for this form.\n        @type submit_text: unicode\n\n        @returns: A string containing (X)HTML markup for a form that\n            encodes the values in this Message object.\n        @rtype: str or unicode\n        \"\"\"\n        if ElementTree is None:\n            raise RuntimeError('This function requires ElementTree.')\n\n        assert action_url is not None\n\n        form = ElementTree.Element(u'form')\n\n        if form_tag_attrs:\n            for name, attr in form_tag_attrs.iteritems():\n                form.attrib[name] = attr\n\n        form.attrib[u'action'] = oidutil.toUnicode(action_url)\n        form.attrib[u'method'] = u'post'\n        form.attrib[u'accept-charset'] = u'UTF-8'\n        form.attrib[u'enctype'] = u'application/x-www-form-urlencoded'\n\n        for name, value in self.toPostArgs().iteritems():\n            attrs = {u'type': u'hidden',\n                     u'name': oidutil.toUnicode(name),\n                     u'value': oidutil.toUnicode(value)}\n            form.append(ElementTree.Element(u'input', attrs))\n\n        submit = ElementTree.Element(u'input',\n            {u'type':'submit', u'value':oidutil.toUnicode(submit_text)})\n        form.append(submit)\n\n        return ElementTree.tostring(form, encoding='utf-8')", "response": "Generates an HTML form markup that contains the values in this Message object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toURLEncoded(self):\n        args = self.toPostArgs().items()\n        args.sort()\n        return urllib.urlencode(args)", "response": "Generate an x - www - urlencoded string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts an input value into the internally used values of this object is returned", "response": "def _fixNS(self, namespace):\n        \"\"\"Convert an input value into the internally used values of\n        this object\n\n        @param namespace: The string or constant to convert\n        @type namespace: str or unicode or BARE_NS or OPENID_NS\n        \"\"\"\n        if namespace == OPENID_NS:\n            if self._openid_ns_uri is None:\n                raise UndefinedOpenIDNamespace('OpenID namespace not set')\n            else:\n                namespace = self._openid_ns_uri\n\n        if namespace != BARE_NS and type(namespace) not in [str, unicode]:\n            raise TypeError(\n                \"Namespace must be BARE_NS, OPENID_NS or a string. got %r\"\n                % (namespace,))\n\n        if namespace != BARE_NS and ':' not in namespace:\n            fmt = 'OpenID 2.0 namespace identifiers SHOULD be URIs. Got %r'\n            warnings.warn(fmt % (namespace,), DeprecationWarning)\n\n            if namespace == 'sreg':\n                fmt = 'Using %r instead of \"sreg\" as namespace'\n                warnings.warn(fmt % (SREG_URI,), DeprecationWarning,)\n                return SREG_URI\n\n        return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getKey(self, namespace, ns_key):\n        namespace = self._fixNS(namespace)\n        if namespace == BARE_NS:\n            return ns_key\n\n        ns_alias = self.namespaces.getAlias(namespace)\n\n        # No alias is defined, so no key can exist\n        if ns_alias is None:\n            return None\n\n        if ns_alias == NULL_NAMESPACE:\n            tail = ns_key\n        else:\n            tail = '%s.%s' % (ns_alias, ns_key)\n\n        return 'openid.' + tail", "response": "Get the key for a particular namespaced argument"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getArg(self, namespace, key, default=None):\n        namespace = self._fixNS(namespace)\n        args_key = (namespace, key)\n        try:\n            return self.args[args_key]\n        except KeyError:\n            if default is no_default:\n                raise KeyError((namespace, key))\n            else:\n                return default", "response": "Get a value for a namespaced key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the arguments that are defined for this namespace URI", "response": "def getArgs(self, namespace):\n        \"\"\"Get the arguments that are defined for this namespace URI\n\n        @returns: mapping from namespaced keys to values\n        @returntype: dict\n        \"\"\"\n        namespace = self._fixNS(namespace)\n        return dict([\n            (ns_key, value)\n            for ((pair_ns, ns_key), value)\n            in self.args.iteritems()\n            if pair_ns == namespace\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting multiple key value pairs in one call", "response": "def updateArgs(self, namespace, updates):\n        \"\"\"Set multiple key/value pairs in one call\n\n        @param updates: The values to set\n        @type updates: {unicode:unicode}\n        \"\"\"\n        namespace = self._fixNS(namespace)\n        for k, v in updates.iteritems():\n            self.setArg(namespace, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setArg(self, namespace, key, value):\n        assert key is not None\n        assert value is not None\n        namespace = self._fixNS(namespace)\n        self.args[(namespace, key)] = value\n        if not (namespace is BARE_NS):\n            self.namespaces.add(namespace)", "response": "Set a single argument in this namespace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, namespace_uri):\n        # See if this namespace is already mapped to an alias\n        alias = self.namespace_to_alias.get(namespace_uri)\n        if alias is not None:\n            return alias\n\n        # Fall back to generating a numerical alias\n        i = 0\n        while True:\n            alias = 'ext' + str(i)\n            try:\n                self.addAlias(namespace_uri, alias)\n            except KeyError:\n                i += 1\n            else:\n                return alias\n\n        assert False, \"Not reached\"", "response": "Add this namespace URI to the mapping without caring what\n        alias it ends up with"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlooking for a meta http - equiv tag with the YADIS header name.", "response": "def findHTMLMeta(stream):\n    \"\"\"Look for a meta http-equiv tag with the YADIS header name.\n\n    @param stream: Source of the html text\n    @type stream: Object that implements a read() method that works\n        like file.read\n\n    @return: The URI from which to fetch the XRDS document\n    @rtype: str\n\n    @raises MetaNotFound: raised with the content that was\n        searched as the first parameter.\n    \"\"\"\n    parser = YadisHTMLParser()\n    chunks = []\n\n    while 1:\n        chunk = stream.read(CHUNK_SIZE)\n        if not chunk:\n            # End of file\n            break\n\n        chunks.append(chunk)\n        try:\n            parser.feed(chunk)\n        except HTMLParseError, why:\n            # HTML parse error, so bail\n            chunks.append(stream.read())\n            break\n        except ParseDone, why:\n            uri = why[0]\n            if uri is None:\n                # Parse finished, but we may need the rest of the file\n                chunks.append(stream.read())\n                break\n            else:\n                return uri\n\n    content = ''.join(chunks)\n    raise MetaNotFound(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a namespace mapping and a string containing comma - separated list of namespace aliases return a list of type URIs that correspond to those aliases.", "response": "def toTypeURIs(namespace_map, alias_list_s):\n    \"\"\"Given a namespace mapping and a string containing a\n    comma-separated list of namespace aliases, return a list of type\n    URIs that correspond to those aliases.\n\n    @param namespace_map: The mapping from namespace URI to alias\n    @type namespace_map: openid.message.NamespaceMap\n\n    @param alias_list_s: The string containing the comma-separated\n        list of aliases. May also be None for convenience.\n    @type alias_list_s: str or NoneType\n\n    @returns: The list of namespace URIs that corresponds to the\n        supplied list of aliases. If the string was zero-length or\n        None, an empty list will be returned.\n\n    @raise KeyError: If an alias is present in the list of aliases but\n        is not present in the namespace map.\n    \"\"\"\n    uris = []\n\n    if alias_list_s:\n        for alias in alias_list_s.split(','):\n            type_uri = namespace_map.getNamespaceURI(alias)\n            if type_uri is None:\n                raise KeyError(\n                    'No type is defined for attribute name %r' % (alias,))\n            else:\n                uris.append(type_uri)\n\n    return uris"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _checkMode(self, ax_args):\n        mode = ax_args.get('mode')\n        if mode != self.mode:\n            if not mode:\n                raise NotAXMessage()\n            else:\n                raise AXError(\n                    'Expected mode %r; got %r' % (self.mode, mode))", "response": "Raise an exception if the mode in the attribute exchange\n        arguments does not match what is expected for this class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an attribute to this attribute exchange request.", "response": "def add(self, attribute):\n        \"\"\"Add an attribute to this attribute exchange request.\n\n        @param attribute: The attribute that is being requested\n        @type attribute: C{L{AttrInfo}}\n\n        @returns: None\n\n        @raise KeyError: when the requested attribute is already\n            present in this fetch request.\n        \"\"\"\n        if attribute.type_uri in self.requested_attributes:\n            raise KeyError('The attribute %r has already been requested'\n                           % (attribute.type_uri,))\n\n        self.requested_attributes[attribute.type_uri] = attribute"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the type URIs for all attributes that have been marked as required.", "response": "def getRequiredAttrs(self):\n        \"\"\"Get the type URIs for all attributes that have been marked\n        as required.\n\n        @returns: A list of the type URIs for attributes that have\n            been marked as required.\n        @rtype: [str]\n        \"\"\"\n        required = []\n        for type_uri, attribute in self.requested_attributes.iteritems():\n            if attribute.required:\n                required.append(type_uri)\n\n        return required"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addValue(self, type_uri, value):\n        try:\n            values = self.data[type_uri]\n        except KeyError:\n            values = self.data[type_uri] = []\n\n        values.append(value)", "response": "Adds a value for the given attribute type to the the\n            party."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the extension arguments for the key - value pairs contained in this message.", "response": "def _getExtensionKVArgs(self, aliases=None):\n        \"\"\"Get the extension arguments for the key/value pairs\n        contained in this message.\n\n        @param aliases: An alias mapping. Set to None if you don't\n            care about the aliases for this request.\n        \"\"\"\n        if aliases is None:\n            aliases = NamespaceMap()\n\n        ax_args = {}\n\n        for type_uri, values in self.data.iteritems():\n            alias = aliases.add(type_uri)\n\n            ax_args['type.' + alias] = type_uri\n            ax_args['count.' + alias] = str(len(values))\n\n            for i, value in enumerate(values):\n                key = 'value.%s.%d' % (alias, i + 1)\n                ax_args[key] = value\n\n        return ax_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the attribute exchange key value arguments into this object.", "response": "def parseExtensionArgs(self, ax_args):\n        \"\"\"Parse attribute exchange key/value arguments into this\n        object.\n\n        @param ax_args: The attribute exchange fetch_response\n            arguments, with namespacing removed.\n        @type ax_args: {unicode:unicode}\n\n        @returns: None\n\n        @raises ValueError: If the message has bad values for\n            particular fields\n\n        @raises KeyError: If the namespace mapping is bad or required\n            arguments are missing\n        \"\"\"\n        self._checkMode(ax_args)\n\n        aliases = NamespaceMap()\n\n        for key, value in ax_args.iteritems():\n            if key.startswith('type.'):\n                type_uri = value\n                alias = key[5:]\n                checkAlias(alias)\n                aliases.addAlias(type_uri, alias)\n\n        for type_uri, alias in aliases.iteritems():\n            try:\n                count_s = ax_args['count.' + alias]\n            except KeyError:\n                value = ax_args['value.' + alias]\n\n                if value == u'':\n                    values = []\n                else:\n                    values = [value]\n            else:\n                count = int(count_s)\n                values = []\n                for i in range(1, count + 1):\n                    value_key = 'value.%s.%d' % (alias, i)\n                    value = ax_args[value_key]\n                    values.append(value)\n\n            self.data[type_uri] = values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a single value for an attribute.", "response": "def getSingle(self, type_uri, default=None):\n        \"\"\"Get a single value for an attribute. If no value was sent\n        for this attribute, use the supplied default. If there is more\n        than one value for this attribute, this method will fail.\n\n        @type type_uri: str\n        @param type_uri: The URI for the attribute\n\n        @param default: The value to return if the attribute was not\n            sent in the fetch_response.\n\n        @returns: The value of the attribute in the fetch_response\n            message, or the default supplied\n        @rtype: unicode or NoneType\n\n        @raises ValueError: If there is more than one value for this\n            parameter in the fetch_response message.\n        @raises KeyError: If the attribute was not sent in this response\n        \"\"\"\n        values = self.data.get(type_uri)\n        if not values:\n            return default\n        elif len(values) == 1:\n            return values[0]\n        else:\n            raise AXError(\n                'More than one value present for %r' % (type_uri,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getExtensionArgs(self):\n\n        aliases = NamespaceMap()\n\n        zero_value_types = []\n\n        if self.request is not None:\n            # Validate the data in the context of the request (the\n            # same attributes should be present in each, and the\n            # counts in the response must be no more than the counts\n            # in the request)\n\n            for type_uri in self.data:\n                if type_uri not in self.request:\n                    raise KeyError(\n                        'Response attribute not present in request: %r'\n                        % (type_uri,))\n\n            for attr_info in self.request.iterAttrs():\n                # Copy the aliases from the request so that reading\n                # the response in light of the request is easier\n                if attr_info.alias is None:\n                    aliases.add(attr_info.type_uri)\n                else:\n                    aliases.addAlias(attr_info.type_uri, attr_info.alias)\n\n                try:\n                    values = self.data[attr_info.type_uri]\n                except KeyError:\n                    values = []\n                    zero_value_types.append(attr_info)\n\n                if (attr_info.count != UNLIMITED_VALUES) and \\\n                       (attr_info.count < len(values)):\n                    raise AXError(\n                        'More than the number of requested values were '\n                        'specified for %r' % (attr_info.type_uri,))\n\n        kv_args = self._getExtensionKVArgs(aliases)\n\n        # Add the KV args into the response with the args that are\n        # unique to the fetch_response\n        ax_args = self._newArgs()\n\n        # For each requested attribute, put its type/alias and count\n        # into the response even if no data were returned.\n        for attr_info in zero_value_types:\n            alias = aliases.getAlias(attr_info.type_uri)\n            kv_args['type.' + alias] = attr_info.type_uri\n            kv_args['count.' + alias] = '0'\n\n        update_url = ((self.request and self.request.update_url)\n                      or self.update_url)\n\n        if update_url:\n            ax_args['update_url'] = update_url\n\n        ax_args.update(kv_args)\n\n        return ax_args", "response": "Serialize this object into arguments in the attribute exchange namespace\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromSuccessResponse(cls, success_response, signed=True):\n        self = cls()\n        ax_args = success_response.extensionResponse(self.ns_uri, signed)\n\n        try:\n            self.parseExtensionArgs(ax_args)\n        except NotAXMessage, err:\n            return None\n        else:\n            return self", "response": "Construct a FetchResponse object from an OpenID library s SuccessResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSRegNS(message):\n    # See if there exists an alias for one of the two defined simple\n    # registration types.\n    for sreg_ns_uri in [ns_uri_1_1, ns_uri_1_0]:\n        alias = message.namespaces.getAlias(sreg_ns_uri)\n        if alias is not None:\n            break\n    else:\n        # There is no alias for either of the types, so try to add\n        # one. We default to using the modern value (1.1)\n        sreg_ns_uri = ns_uri_1_1\n        try:\n            message.namespaces.addAlias(ns_uri_1_1, 'sreg')\n        except KeyError, why:\n            # An alias for the string 'sreg' already exists, but it's\n            # defined for something other than simple registration\n            raise SRegNamespaceError(why[0])\n\n    # we know that sreg_ns_uri defined, because it's defined in the\n    # else clause of the loop as well, so disable the warning\n    return sreg_ns_uri", "response": "Extracts the simple registration namespace URI for the given message. Handles OpenID 1 and 2 and returns the simple registration namespace URI for the given message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseExtensionArgs(self, args, strict=False):\n        for list_name in ['required', 'optional']:\n            required = (list_name == 'required')\n            items = args.get(list_name)\n            if items:\n                for field_name in items.split(','):\n                    try:\n                        self.requestField(field_name, required, strict)\n                    except ValueError:\n                        if strict:\n                            raise\n\n        self.policy_url = args.get('policy_url')", "response": "Parse the unqualified simple registration request and add them to this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting the specified field from the OpenID user.", "response": "def requestField(self, field_name, required=False, strict=False):\n        \"\"\"Request the specified field from the OpenID user\n\n        @param field_name: the unqualified simple registration field name\n        @type field_name: str\n\n        @param required: whether the given field should be presented\n            to the user as being a required to successfully complete\n            the request\n\n        @param strict: whether to raise an exception when a field is\n            added to a request more than once\n\n        @raise ValueError: when the field requested is not a simple\n            registration field or strict is set and the field was\n            requested more than once\n        \"\"\"\n        checkFieldName(field_name)\n\n        if strict:\n            if field_name in self.required or field_name in self.optional:\n                raise ValueError('That field has already been requested')\n        else:\n            if field_name in self.required:\n                return\n\n            if field_name in self.optional:\n                if required:\n                    self.optional.remove(field_name)\n                else:\n                    return\n\n        if required:\n            self.required.append(field_name)\n        else:\n            self.optional.append(field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requestFields(self, field_names, required=False, strict=False):\n        if isinstance(field_names, basestring):\n            raise TypeError('Fields should be passed as a list of '\n                            'strings (not %r)' % (type(field_names),))\n\n        for field_name in field_names:\n            self.requestField(field_name, required, strict=strict)", "response": "Add the given list of fields to the request\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getExtensionArgs(self):\n        args = {}\n\n        if self.required:\n            args['required'] = ','.join(self.required)\n\n        if self.optional:\n            args['optional'] = ','.join(self.optional)\n\n        if self.policy_url:\n            args['policy_url'] = self.policy_url\n\n        return args", "response": "Returns a dictionary of unqualified simple registration\n        arguments representing this request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extractResponse(cls, request, data):\n        self = cls()\n        self.ns_uri = request.ns_uri\n        for field in request.allRequestedFields():\n            value = data.get(field)\n            if value is not None:\n                self.data[field] = value\n        return self", "response": "Takes a C{L{SRegRequest} and a dictionary of simple key - value registration values and creates a C{L{SRegResponse}} object containing that data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a C{SRegResponse object from a successful OpenID library response.", "response": "def fromSuccessResponse(cls, success_response, signed_only=True):\n        \"\"\"Create a C{L{SRegResponse}} object from a successful OpenID\n        library response\n        (C{L{openid.consumer.consumer.SuccessResponse}}) response\n        message\n\n        @param success_response: A SuccessResponse from consumer.complete()\n        @type success_response: C{L{openid.consumer.consumer.SuccessResponse}}\n\n        @param signed_only: Whether to process only data that was\n            signed in the id_res message from the server.\n        @type signed_only: bool\n\n        @rtype: SRegResponse\n        @returns: A simple registration response containing the data\n            that was supplied with the C{id_res} response.\n        \"\"\"\n        self = cls()\n        self.ns_uri = self._getSRegNS(success_response.message)\n        if signed_only:\n            args = success_response.getSignedNS(self.ns_uri)\n        else:\n            args = success_response.message.getArgs(self.ns_uri)\n\n        if not args:\n            return None\n\n        for field_name in data_fields:\n            if field_name in args:\n                self.data[field_name] = args[field_name]\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nliking dict. get except that the field name is not defined by the simple registration specification.", "response": "def get(self, field_name, default=None):\n        \"\"\"Like dict.get, except that it checks that the field name is\n        defined by the simple registration specification\"\"\"\n        checkFieldName(field_name)\n        return self.data.get(field_name, default)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the return_to URL is under one of the supplied allowed_return_to_urls.", "response": "def returnToMatches(allowed_return_to_urls, return_to):\n    \"\"\"Is the return_to URL under one of the supplied allowed\n    return_to URLs?\n\n    @since: 2.1.0\n    \"\"\"\n\n    for allowed_return_to in allowed_return_to_urls:\n        # A return_to pattern works the same as a realm, except that\n        # it's not allowed to use a wildcard. We'll model this by\n        # parsing it as a realm, and not trying to match it if it has\n        # a wildcard.\n\n        return_realm = TrustRoot.parse(allowed_return_to)\n        if (# Parses as a trust root\n            return_realm is not None and\n\n            # Does not have a wildcard\n            not return_realm.wildcard and\n\n            # Matches the return_to that we passed in with it\n            return_realm.validateURL(return_to)\n            ):\n            return True\n\n    # No URL in the list matched\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getAllowedReturnURLs(relying_party_url):\n    (rp_url_after_redirects, return_to_urls) = services.getServiceEndpoints(\n        relying_party_url, _extractReturnURL)\n\n    if rp_url_after_redirects != relying_party_url:\n        # Verification caused a redirect\n        raise RealmVerificationRedirected(\n            relying_party_url, rp_url_after_redirects)\n\n    return return_to_urls", "response": "Given a relying party discovery URL return a list of return_to URLs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verifyReturnTo(realm_str, return_to, _vrfy=getAllowedReturnURLs):\n    realm = TrustRoot.parse(realm_str)\n    if realm is None:\n        # The realm does not parse as a URL pattern\n        return False\n\n    try:\n        allowable_urls = _vrfy(realm.buildDiscoveryURL())\n    except RealmVerificationRedirected, err:\n        logging.exception(str(err))\n        return False\n\n    if returnToMatches(allowable_urls, return_to):\n        return True\n    else:\n        logging.error(\"Failed to validate return_to %r for realm %r, was not \"\n                    \"in %s\" % (return_to, realm_str, allowable_urls))\n        return False", "response": "Verify that a return_to URL is valid for the given realm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isSane(self):\n\n        if self.host == 'localhost':\n            return True\n\n        host_parts = self.host.split('.')\n        if self.wildcard:\n            assert host_parts[0] == '', host_parts\n            del host_parts[0]\n\n        # If it's an absolute domain name, remove the empty string\n        # from the end.\n        if host_parts and not host_parts[-1]:\n            del host_parts[-1]\n\n        if not host_parts:\n            return False\n\n        # Do not allow adjacent dots\n        if '' in host_parts:\n            return False\n\n        tld = host_parts[-1]\n        if tld not in _top_level_domains:\n            return False\n\n        if len(host_parts) == 1:\n            return False\n\n        if self.wildcard:\n            if len(tld) == 2 and len(host_parts[-2]) <= 3:\n                # It's a 2-letter tld with a short second to last segment\n                # so there needs to be more than two segments specified \n                # (e.g. *.co.uk is insane)\n                return len(host_parts) > 2\n\n        # Passed all tests for insanity.\n        return True", "response": "This method checks to see if a trust root represents a reasonable set of URLs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validateURL(self, url):\n\n        url_parts = _parseURL(url)\n        if url_parts is None:\n            return False\n\n        proto, host, port, path = url_parts\n\n        if proto != self.proto:\n            return False\n\n        if port != self.port:\n            return False\n\n        if '*' in host:\n            return False\n\n        if not self.wildcard:\n            if host != self.host:\n                return False\n        elif ((not host.endswith(self.host)) and\n              ('.' + host) != self.host):\n            return False\n\n        if path != self.path:\n            path_len = len(self.path)\n            trust_prefix = self.path[:path_len]\n            url_prefix = path[:path_len]\n\n            # must be equal up to the length of the path, at least\n            if trust_prefix != url_prefix:\n                return False\n\n            # These characters must be on the boundary between the end\n            # of the trust root's path and the start of the URL's\n            # path.\n            if '?' in self.path:\n                allowed = '&'\n            else:\n                allowed = '?/'\n\n            return (self.path[-1] in allowed or\n                path[path_len] in allowed)\n\n        return True", "response": "Validates a URL against this trust root."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkSanity(cls, trust_root_string):\n        trust_root = cls.parse(trust_root_string)\n        if trust_root is None:\n            return False\n        else:\n            return trust_root.isSane()", "response": "Check if a trust root is sane or not"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a discovery URL for this realm.", "response": "def buildDiscoveryURL(self):\n        \"\"\"Return a discovery URL for this realm.\n\n        This function does not check to make sure that the realm is\n        valid. Its behaviour on invalid inputs is undefined.\n\n        @rtype: str\n\n        @returns: The URL upon which relying party discovery should be run\n            in order to verify the return_to URL\n\n        @since: 2.1.0\n        \"\"\"\n        if self.wildcard:\n            # Use \"www.\" in place of the star\n            assert self.host.startswith('.'), self.host\n            www_domain = 'www' + self.host\n            return '%s://%s%s' % (self.proto, www_domain, self.path)\n        else:\n            return self.unparsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next(self):\n        try:\n            self._current = self.services.pop(0)\n        except IndexError:\n            raise StopIteration\n        else:\n            return self._current", "response": "Return the next service in the sequence until the next call to this method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the next authentication service for the pair of user_input and session. This function handles fallback. @param discover: a callable that takes a URL and returns a list of services @type discover: str -> [service] @return: the next available service", "response": "def getNextService(self, discover):\n        \"\"\"Return the next authentication service for the pair of\n        user_input and session.  This function handles fallback.\n\n\n        @param discover: a callable that takes a URL and returns a\n            list of services\n\n        @type discover: str -> [service]\n\n\n        @return: the next available service\n        \"\"\"\n        manager = self.getManager()\n        if manager is not None and not manager:\n            self.destroyManager()\n\n        if not manager:\n            yadis_url, services = discover(self.url)\n            manager = self.createManager(services, yadis_url)\n\n        if manager:\n            service = manager.next()\n            manager.store(self.session)\n        else:\n            service = None\n\n        return service"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup(self, force=False):\n        manager = self.getManager(force=force)\n        if manager is not None:\n            service = manager.current()\n            self.destroyManager(force=force)\n        else:\n            service = None\n\n        return service", "response": "Clean up Yadis - related services in the session and return\n        the most recently - attempted service if one is available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the YadisServiceManager for this object s URL and suffix from the session.", "response": "def getManager(self, force=False):\n        \"\"\"Extract the YadisServiceManager for this object's URL and\n        suffix from the session.\n\n        @param force: True if the manager should be returned\n        regardless of whether it's a manager for self.url.\n\n        @return: The current YadisServiceManager, if it's for this\n            URL, or else None\n        \"\"\"\n        manager = self.session.get(self.getSessionKey())\n        if (manager is not None and (manager.forURL(self.url) or force)):\n            return manager\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createManager(self, services, yadis_url=None):\n        key = self.getSessionKey()\n        if self.getManager():\n            raise KeyError('There is already a %r manager for %r' %\n                           (key, self.url))\n\n        if not services:\n            return None\n\n        manager = YadisServiceManager(self.url, yadis_url, services, key)\n        manager.store(self.session)\n        return manager", "response": "Create a new YadisServiceManager for this starting URL and\n        suffix and store it in the session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting any YadisServiceManager with this starting URL and suffix from the session.", "response": "def destroyManager(self, force=False):\n        \"\"\"Delete any YadisServiceManager with this starting URL and\n        suffix from the session.\n\n        If there is no service manager or the service manager is for a\n        different URL, it silently does nothing.\n\n        @param force: True if the manager should be deleted regardless\n        of whether it's a manager for self.url.\n        \"\"\"\n        if self.getManager(force=force) is not None:\n            key = self.getSessionKey()\n            del self.session[key]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct me from an OpenID check authentication message.", "response": "def fromMessage(klass, message, op_endpoint=UNUSED):\n        \"\"\"Construct me from an OpenID Message.\n\n        @param message: An OpenID check_authentication Message\n        @type message: L{openid.message.Message}\n\n        @returntype: L{CheckAuthRequest}\n        \"\"\"\n        self = klass.__new__(klass)\n        self.message = message\n        self.namespace = message.getOpenIDNamespace()\n        self.assoc_handle = message.getArg(OPENID_NS, 'assoc_handle')\n        self.sig = message.getArg(OPENID_NS, 'sig')\n\n        if (self.assoc_handle is None or\n            self.sig is None):\n            fmt = \"%s request missing required parameter from message %s\"\n            raise ProtocolError(\n                message, text=fmt % (self.mode, message))\n\n        self.invalidate_handle = message.getArg(OPENID_NS, 'invalidate_handle')\n\n        self.signed = message.copy()\n        # openid.mode is currently check_authentication because\n        # that's the mode of this request.  But the signature\n        # was made on something with a different openid.mode.\n        # http://article.gmane.org/gmane.comp.web.openid.general/537\n        if self.signed.hasKey(OPENID_NS, \"mode\"):\n            self.signed.setArg(OPENID_NS, \"mode\", \"id_res\")\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresponds to this request.", "response": "def answer(self, signatory):\n        \"\"\"Respond to this request.\n\n        Given a L{Signatory}, I can check the validity of the signature and\n        the X{C{invalidate_handle}}.\n\n        @param signatory: The L{Signatory} to use to check the signature.\n        @type signatory: L{Signatory}\n\n        @returns: A response with an X{C{is_valid}} (and, if\n           appropriate X{C{invalidate_handle}}) field.\n        @returntype: L{OpenIDResponse}\n        \"\"\"\n        is_valid = signatory.verify(self.assoc_handle, self.signed)\n        # Now invalidate that assoc_handle so it this checkAuth message cannot\n        # be replayed.\n        signatory.invalidate(self.assoc_handle, dumb=True)\n        response = OpenIDResponse(self)\n        valid_str = (is_valid and \"true\") or \"false\"\n        response.fields.setArg(OPENID_NS, 'is_valid', valid_str)\n\n        if self.invalidate_handle:\n            assoc = signatory.getAssociation(self.invalidate_handle, dumb=False)\n            if not assoc:\n                response.fields.setArg(\n                    OPENID_NS, 'invalidate_handle', self.invalidate_handle)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromMessage(cls, message):\n        dh_modulus = message.getArg(OPENID_NS, 'dh_modulus')\n        dh_gen = message.getArg(OPENID_NS, 'dh_gen')\n        if (dh_modulus is None and dh_gen is not None or\n            dh_gen is None and dh_modulus is not None):\n\n            if dh_modulus is None:\n                missing = 'modulus'\n            else:\n                missing = 'generator'\n\n            raise ProtocolError(message,\n                                'If non-default modulus or generator is '\n                                'supplied, both must be supplied. Missing %s'\n                                % (missing,))\n\n        if dh_modulus or dh_gen:\n            dh_modulus = cryptutil.base64ToLong(dh_modulus)\n            dh_gen = cryptutil.base64ToLong(dh_gen)\n            dh = DiffieHellman(dh_modulus, dh_gen)\n        else:\n            dh = DiffieHellman.fromDefaults()\n\n        consumer_pubkey = message.getArg(OPENID_NS, 'dh_consumer_public')\n        if consumer_pubkey is None:\n            raise ProtocolError(message, \"Public key for DH-SHA1 session \"\n                                \"not found in message %s\" % (message,))\n\n        consumer_pubkey = cryptutil.base64ToLong(consumer_pubkey)\n\n        return cls(dh, consumer_pubkey)", "response": "Creates a new instance of the class from a message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromMessage(klass, message, op_endpoint=UNUSED):\n        if message.isOpenID1():\n            session_type = message.getArg(OPENID_NS, 'session_type')\n            if session_type == 'no-encryption':\n                logging.warn('Received OpenID 1 request with a no-encryption '\n                            'assocaition session type. Continuing anyway.')\n            elif not session_type:\n                session_type = 'no-encryption'\n        else:\n            session_type = message.getArg(OPENID2_NS, 'session_type')\n            if session_type is None:\n                raise ProtocolError(message,\n                                    text=\"session_type missing from request\")\n\n        try:\n            session_class = klass.session_classes[session_type]\n        except KeyError:\n            raise ProtocolError(message,\n                                \"Unknown session type %r\" % (session_type,))\n\n        try:\n            session = session_class.fromMessage(message)\n        except ValueError, why:\n            raise ProtocolError(message, 'Error parsing %s session: %s' %\n                                (session_class.session_type, why[0]))\n\n        assoc_type = message.getArg(OPENID_NS, 'assoc_type', 'HMAC-SHA1')\n        if assoc_type not in session.allowed_assoc_types:\n            fmt = 'Session type %s does not support association type %s'\n            raise ProtocolError(message, fmt % (session_type, assoc_type))\n\n        self = klass(session, assoc_type)\n        self.message = message\n        self.namespace = message.getOpenIDNamespace()\n        return self", "response": "Construct me from an OpenID message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrespond to this request indicating that the association type or association session type is not supported.", "response": "def answerUnsupported(self, message, preferred_association_type=None,\n                          preferred_session_type=None):\n        \"\"\"Respond to this request indicating that the association\n        type or association session type is not supported.\"\"\"\n        if self.message.isOpenID1():\n            raise ProtocolError(self.message)\n\n        response = OpenIDResponse(self)\n        response.fields.setArg(OPENID_NS, 'error_code', 'unsupported-type')\n        response.fields.setArg(OPENID_NS, 'error', message)\n\n        if preferred_association_type:\n            response.fields.setArg(\n                OPENID_NS, 'assoc_type', preferred_association_type)\n\n        if preferred_session_type:\n            response.fields.setArg(\n                OPENID_NS, 'session_type', preferred_session_type)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fromMessage(klass, message, op_endpoint):\n        self = klass.__new__(klass)\n        self.message = message\n        self.op_endpoint = op_endpoint\n        mode = message.getArg(OPENID_NS, 'mode')\n        if mode == \"checkid_immediate\":\n            self.immediate = True\n            self.mode = \"checkid_immediate\"\n        else:\n            self.immediate = False\n            self.mode = \"checkid_setup\"\n\n        self.return_to = message.getArg(OPENID_NS, 'return_to')\n        if message.isOpenID1() and not self.return_to:\n            fmt = \"Missing required field 'return_to' from %r\"\n            raise ProtocolError(message, text=fmt % (message,))\n\n        self.identity = message.getArg(OPENID_NS, 'identity')\n        self.claimed_id = message.getArg(OPENID_NS, 'claimed_id')\n        if message.isOpenID1():\n            if self.identity is None:\n                s = \"OpenID 1 message did not contain openid.identity\"\n                raise ProtocolError(message, text=s)\n        else:\n            if self.identity and not self.claimed_id:\n                s = (\"OpenID 2.0 message contained openid.identity but not \"\n                     \"claimed_id\")\n                raise ProtocolError(message, text=s)\n            elif self.claimed_id and not self.identity:\n                s = (\"OpenID 2.0 message contained openid.claimed_id but not \"\n                     \"identity\")\n                raise ProtocolError(message, text=s)\n\n        # There's a case for making self.trust_root be a TrustRoot\n        # here.  But if TrustRoot isn't currently part of the \"public\" API,\n        # I'm not sure it's worth doing.\n\n        if message.isOpenID1():\n            trust_root_param = 'trust_root'\n        else:\n            trust_root_param = 'realm'\n\n        # Using 'or' here is slightly different than sending a default\n        # argument to getArg, as it will treat no value and an empty\n        # string as equivalent.\n        self.trust_root = (message.getArg(OPENID_NS, trust_root_param)\n                           or self.return_to)\n\n        if not message.isOpenID1():\n            if self.return_to is self.trust_root is None:\n                raise ProtocolError(message, \"openid.realm required when \" +\n                                    \"openid.return_to absent\")\n\n        self.assoc_handle = message.getArg(OPENID_NS, 'assoc_handle')\n\n        # Using TrustRoot.parse here is a bit misleading, as we're not\n        # parsing return_to as a trust root at all.  However, valid URLs\n        # are valid trust roots, so we can use this to get an idea if it\n        # is a valid URL.  Not all trust roots are valid return_to URLs,\n        # however (particularly ones with wildcards), so this is still a\n        # little sketchy.\n        if self.return_to is not None and \\\n               not TrustRoot.parse(self.return_to):\n            raise MalformedReturnURL(message, self.return_to)\n\n        # I first thought that checking to see if the return_to is within\n        # the trust_root is premature here, a logic-not-decoding thing.  But\n        # it was argued that this is really part of data validation.  A\n        # request with an invalid trust_root/return_to is broken regardless of\n        # application, right?\n        if not self.trustRootValid():\n            raise UntrustedReturnURL(message, self.return_to, self.trust_root)\n\n        return self", "response": "Construct me from an OpenID message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trustRootValid(self):\n        if not self.trust_root:\n            return True\n        tr = TrustRoot.parse(self.trust_root)\n        if tr is None:\n            raise MalformedTrustRoot(self.message, self.trust_root)\n\n        if self.return_to is not None:\n            return tr.validateURL(self.return_to)\n        else:\n            return True", "response": "Is the return_to under my trust_root?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef answer(self, allow, server_url=None, identity=None, claimed_id=None):\n        assert self.message is not None\n\n        if not self.return_to:\n            raise NoReturnToError\n\n        if not server_url:\n            if not self.message.isOpenID1() and not self.op_endpoint:\n                # In other words, that warning I raised in Server.__init__?\n                # You should pay attention to it now.\n                raise RuntimeError(\"%s should be constructed with op_endpoint \"\n                                   \"to respond to OpenID 2.0 messages.\" %\n                                   (self,))\n            server_url = self.op_endpoint\n\n        if allow:\n            mode = 'id_res'\n        elif self.message.isOpenID1():\n             if self.immediate:\n                 mode = 'id_res'\n             else:\n                 mode = 'cancel'\n        else:\n            if self.immediate:\n                mode = 'setup_needed'\n            else:\n                mode = 'cancel'\n\n        response = OpenIDResponse(self)\n\n        if claimed_id and self.message.isOpenID1():\n            namespace = self.message.getOpenIDNamespace()\n            raise VersionError(\"claimed_id is new in OpenID 2.0 and not \"\n                               \"available for %s\" % (namespace,))\n\n        if allow:\n            if self.identity == IDENTIFIER_SELECT:\n                if not identity:\n                    raise ValueError(\n                        \"This request uses IdP-driven identifier selection.\"\n                        \"You must supply an identifier in the response.\")\n                response_identity = identity\n                response_claimed_id = claimed_id or identity\n\n            elif self.identity:\n                if identity and (self.identity != identity):\n                    normalized_request_identity = urinorm(self.identity)\n                    normalized_answer_identity = urinorm(identity)\n\n                    if (normalized_request_identity !=\n                        normalized_answer_identity):\n                        raise ValueError(\n                            \"Request was for identity %r, cannot reply \"\n                            \"with identity %r\" % (self.identity, identity))\n\n                # The \"identity\" value in the response shall always be\n                # the same as that in the request, otherwise the RP is\n                # likely to not validate the response.\n                response_identity = self.identity\n                response_claimed_id = self.claimed_id\n            else:\n                if identity:\n                    raise ValueError(\n                        \"This request specified no identity and you \"\n                        \"supplied %r\" % (identity,))\n                response_identity = None\n\n            if self.message.isOpenID1() and response_identity is None:\n                raise ValueError(\n                    \"Request was an OpenID 1 request, so response must \"\n                    \"include an identifier.\"\n                    )\n\n            response.fields.updateArgs(OPENID_NS, {\n                'mode': mode,\n                'return_to': self.return_to,\n                'response_nonce': mkNonce(),\n                })\n\n            if server_url:\n                response.fields.setArg(OPENID_NS, 'op_endpoint', server_url)\n\n            if response_identity is not None:\n                response.fields.setArg(\n                    OPENID_NS, 'identity', response_identity)\n                if self.message.isOpenID2():\n                    response.fields.setArg(\n                        OPENID_NS, 'claimed_id', response_claimed_id)\n        else:\n            response.fields.setArg(OPENID_NS, 'mode', mode)\n            if self.immediate:\n                if self.message.isOpenID1() and not server_url:\n                    raise ValueError(\"setup_url is required for allow=False \"\n                                     \"in OpenID 1.x immediate mode.\")\n                # Make a new request just like me, but with immediate=False.\n                setup_request = self.__class__(\n                    self.identity, self.return_to, self.trust_root,\n                    immediate=False, assoc_handle=self.assoc_handle,\n                    op_endpoint=self.op_endpoint, claimed_id=self.claimed_id)\n\n                # XXX: This API is weird.\n                setup_request.message = self.message\n\n                setup_url = setup_request.encodeToURL(server_url)\n                response.fields.setArg(OPENID_NS, 'user_setup_url', setup_url)\n\n        return response", "response": "Respond to this request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encodeToURL(self, server_url):\n        if not self.return_to:\n            raise NoReturnToError\n\n        # Imported from the alternate reality where these classes are used\n        # in both the client and server code, so Requests are Encodable too.\n        # That's right, code imported from alternate realities all for the\n        # love of you, id_res/user_setup_url.\n        q = {'mode': self.mode,\n             'identity': self.identity,\n             'claimed_id': self.claimed_id,\n             'return_to': self.return_to}\n        if self.trust_root:\n            if self.message.isOpenID1():\n                q['trust_root'] = self.trust_root\n            else:\n                q['realm'] = self.trust_root\n        if self.assoc_handle:\n            q['assoc_handle'] = self.assoc_handle\n\n        response = Message(self.message.getOpenIDNamespace())\n        response.updateArgs(OPENID_NS, q)\n        return response.toURL(server_url)", "response": "Encode this request as a URL to GET."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getCancelURL(self):\n        if not self.return_to:\n            raise NoReturnToError\n\n        if self.immediate:\n            raise ValueError(\"Cancel is not an appropriate response to \"\n                             \"immediate mode requests.\")\n\n        response = Message(self.message.getOpenIDNamespace())\n        response.setArg(OPENID_NS, 'mode', 'cancel')\n        return response.toURL(self.return_to)", "response": "Returns the URL to cancel this request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the form markup for this response.", "response": "def toFormMarkup(self, form_tag_attrs=None):\n        \"\"\"Returns the form markup for this response.\n\n        @param form_tag_attrs: Dictionary of attributes to be added to\n            the form tag. 'accept-charset' and 'enctype' have defaults\n            that can be overridden. If a value is supplied for\n            'action' or 'method', it will be replaced.\n\n        @returntype: str\n\n        @since: 2.1.0\n        \"\"\"\n        return self.fields.toFormMarkup(self.request.return_to,\n                                        form_tag_attrs=form_tag_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify(self, assoc_handle, message):\n        assoc = self.getAssociation(assoc_handle, dumb=True)\n        if not assoc:\n            logging.error(\"failed to get assoc with handle %r to verify \"\n                        \"message %r\"\n                        % (assoc_handle, message))\n            return False\n\n        try:\n            valid = assoc.checkMessageSignature(message)\n        except ValueError, ex:\n            logging.exception(\"Error in verifying %s with %s: %s\" % (message,\n                                                               assoc,\n                                                               ex))\n            return False\n        return valid", "response": "Verify that the signature for some data is valid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsign a response. I take a L{OpenIDResponse}, create a signature for everything in its L{signed<OpenIDResponse.signed>} list, and return a new copy of the response object with that signature included. @param response: A response to sign. @type response: L{OpenIDResponse} @returns: A signed copy of the response. @returntype: L{OpenIDResponse}", "response": "def sign(self, response):\n        \"\"\"Sign a response.\n\n        I take a L{OpenIDResponse}, create a signature for everything\n        in its L{signed<OpenIDResponse.signed>} list, and return a new\n        copy of the response object with that signature included.\n\n        @param response: A response to sign.\n        @type response: L{OpenIDResponse}\n\n        @returns: A signed copy of the response.\n        @returntype: L{OpenIDResponse}\n        \"\"\"\n        signed_response = deepcopy(response)\n        assoc_handle = response.request.assoc_handle\n        if assoc_handle:\n            # normal mode\n            # disabling expiration check because even if the association\n            # is expired, we still need to know some properties of the\n            # association so that we may preserve those properties when\n            # creating the fallback association.\n            assoc = self.getAssociation(assoc_handle, dumb=False,\n                                        checkExpiration=False)\n\n            if not assoc or assoc.expiresIn <= 0:\n                # fall back to dumb mode\n                signed_response.fields.setArg(\n                    OPENID_NS, 'invalidate_handle', assoc_handle)\n                assoc_type = assoc and assoc.assoc_type or 'HMAC-SHA1'\n                if assoc and assoc.expiresIn <= 0:\n                    # now do the clean-up that the disabled checkExpiration\n                    # code didn't get to do.\n                    self.invalidate(assoc_handle, dumb=False)\n                assoc = self.createAssociation(dumb=True, assoc_type=assoc_type)\n        else:\n            # dumb mode.\n            assoc = self.createAssociation(dumb=True)\n\n        try:\n            signed_response.fields = assoc.signMessage(signed_response.fields)\n        except kvform.KVFormError, err:\n            raise EncodingError(response, explanation=str(err))\n        return signed_response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new association.", "response": "def createAssociation(self, dumb=True, assoc_type='HMAC-SHA1'):\n        \"\"\"Make a new association.\n\n        @param dumb: Is this association for a dumb-mode transaction?\n        @type dumb: bool\n\n        @param assoc_type: The type of association to create.  Currently\n            there is only one type defined, C{HMAC-SHA1}.\n        @type assoc_type: str\n\n        @returns: the new association.\n        @returntype: L{openid.association.Association}\n        \"\"\"\n        secret = cryptutil.getBytes(getSecretSize(assoc_type))\n        uniq = oidutil.toBase64(cryptutil.getBytes(4))\n        handle = '{%s}{%x}{%s}' % (assoc_type, int(time.time()), uniq)\n\n        assoc = Association.fromExpiresIn(\n            self.SECRET_LIFETIME, handle, secret, assoc_type)\n\n        if dumb:\n            key = self._dumb_key\n        else:\n            key = self._normal_key\n        self.store.storeAssociation(key, assoc)\n        return assoc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the association with the specified handle.", "response": "def getAssociation(self, assoc_handle, dumb, checkExpiration=True):\n        \"\"\"Get the association with the specified handle.\n\n        @type assoc_handle: str\n\n        @param dumb: Is this association used with dumb mode?\n        @type dumb: bool\n\n        @returns: the association, or None if no valid association with that\n            handle was found.\n        @returntype: L{openid.association.Association}\n        \"\"\"\n        # Hmm.  We've created an interface that deals almost entirely with\n        # assoc_handles.  The only place outside the Signatory that uses this\n        # (and thus the only place that ever sees Association objects) is\n        # when creating a response to an association request, as it must have\n        # the association's secret.\n\n        if assoc_handle is None:\n            raise ValueError(\"assoc_handle must not be None\")\n\n        if dumb:\n            key = self._dumb_key\n        else:\n            key = self._normal_key\n        assoc = self.store.getAssociation(key, assoc_handle)\n        if assoc is not None and assoc.expiresIn <= 0:\n            logging.info(\"requested %sdumb key %r is expired (by %s seconds)\" %\n                        ((not dumb) and 'not-' or '',\n                         assoc_handle, assoc.expiresIn))\n            if checkExpiration:\n                self.store.removeAssociation(key, assoc_handle)\n                assoc = None\n        return assoc"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninvalidates the association with the given handle.", "response": "def invalidate(self, assoc_handle, dumb):\n        \"\"\"Invalidates the association with the given handle.\n\n        @type assoc_handle: str\n\n        @param dumb: Is this association used with dumb mode?\n        @type dumb: bool\n        \"\"\"\n        if dumb:\n            key = self._dumb_key\n        else:\n            key = self._normal_key\n        self.store.removeAssociation(key, assoc_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(self, response):\n        encode_as = response.whichEncoding()\n        if encode_as == ENCODE_KVFORM:\n            wr = self.responseFactory(body=response.encodeToKVForm())\n            if isinstance(response, Exception):\n                wr.code = HTTP_ERROR\n        elif encode_as == ENCODE_URL:\n            location = response.encodeToURL()\n            wr = self.responseFactory(code=HTTP_REDIRECT,\n                                      headers={'location': location})\n        elif encode_as == ENCODE_HTML_FORM:\n            wr = self.responseFactory(code=HTTP_OK,\n                                      body=response.toHTML())\n        else:\n            # Can't encode this to a protocol message.  You should probably\n            # render it to HTML and show it to the user.\n            raise EncodingError(response)\n        return wr", "response": "Encode a response to a L { WebResponse."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self, response):\n        # the isinstance is a bit of a kludge... it means there isn't really\n        # an adapter to make the interfaces quite match.\n        if (not isinstance(response, Exception)) and response.needsSigning():\n            if not self.signatory:\n                raise ValueError(\n                    \"Must have a store to sign this request: %s\" %\n                    (response,), response)\n            if response.fields.hasKey(OPENID_NS, 'sig'):\n                raise AlreadySigned(response)\n            response = self.signatory.sign(response)\n        return super(SigningEncoder, self).encode(response)", "response": "Encode a response to a L { WebResponse } if appropriate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling to decode queries when no handler for that mode is found.", "response": "def defaultDecoder(self, message, server):\n        \"\"\"Called to decode queries when no handler for that mode is found.\n\n        @raises ProtocolError: This implementation always raises\n            L{ProtocolError}.\n        \"\"\"\n        mode = message.getArg(OPENID_NS, 'mode')\n        fmt = \"Unrecognized OpenID mode %r\"\n        raise ProtocolError(message, text=fmt % (mode,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a request. Give me a request, I will give you a response. Unless it's a type of request I cannot handle myself, in which case I will raise C{NotImplementedError}. In that case, you can handle it yourself, or add a method to me for handling that request type. @raises NotImplementedError: When I do not have a handler defined for that type of request. @returntype: L{OpenIDResponse}", "response": "def handleRequest(self, request):\n        \"\"\"Handle a request.\n\n        Give me a request, I will give you a response.  Unless it's a type\n        of request I cannot handle myself, in which case I will raise\n        C{NotImplementedError}.  In that case, you can handle it yourself,\n        or add a method to me for handling that request type.\n\n        @raises NotImplementedError: When I do not have a handler defined\n            for that type of request.\n\n        @returntype: L{OpenIDResponse}\n        \"\"\"\n        handler = getattr(self, 'openid_' + request.mode, None)\n        if handler is not None:\n            return handler(request)\n        else:\n            raise NotImplementedError(\n                \"%s has no handler for a request of mode %r.\" %\n                (self, request.mode))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle and respond to C { associate requests.", "response": "def openid_associate(self, request):\n        \"\"\"Handle and respond to C{associate} requests.\n\n        @returntype: L{OpenIDResponse}\n        \"\"\"\n        # XXX: TESTME\n        assoc_type = request.assoc_type\n        session_type = request.session.session_type\n        if self.negotiator.isAllowed(assoc_type, session_type):\n            assoc = self.signatory.createAssociation(dumb=False,\n                                                     assoc_type=assoc_type)\n            return request.answer(assoc)\n        else:\n            message = ('Association type %r is not supported with '\n                       'session type %r' % (assoc_type, session_type))\n            (preferred_assoc_type, preferred_session_type) = \\\n                                   self.negotiator.getAllowedType()\n            return request.answerUnsupported(\n                message,\n                preferred_assoc_type,\n                preferred_session_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toMessage(self):\n        namespace = self.openid_message.getOpenIDNamespace()\n        reply = Message(namespace)\n        reply.setArg(OPENID_NS, 'mode', 'error')\n        reply.setArg(OPENID_NS, 'error', str(self))\n\n        if self.contact is not None:\n            reply.setArg(OPENID_NS, 'contact', str(self.contact))\n\n        if self.reference is not None:\n            reply.setArg(OPENID_NS, 'reference', str(self.reference))\n\n        return reply", "response": "Generate a Message object for sending to the relying party."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef whichEncoding(self):\n        if self.hasReturnTo():\n            if self.openid_message.isOpenID1() and \\\n               len(self.encodeToURL()) > OPENID1_URL_LIMIT:\n                return ENCODE_HTML_FORM\n            else:\n                return ENCODE_URL\n\n        if self.openid_message is None:\n            return None\n\n        mode = self.openid_message.getArg(OPENID_NS, 'mode')\n        if mode:\n            if mode not in BROWSER_REQUEST_MODES:\n                return ENCODE_KVFORM\n\n        # According to the OpenID spec as of this writing, we are probably\n        # supposed to switch on request type here (GET versus POST) to figure\n        # out if we're supposed to print machine-readable or human-readable\n        # content at this point.  GET/POST seems like a pretty lousy way of\n        # making the distinction though, as it's just as possible that the\n        # user agent could have mistakenly been directed to post to the\n        # server URL.\n\n        # Basically, if your request was so broken that you didn't manage to\n        # include an openid.mode, I'm not going to worry too much about\n        # returning you something you can't parse.\n        return None", "response": "Return the encoding of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting OpenID authentication process.", "response": "def startOpenID(request):\n    \"\"\"\n    Start the OpenID authentication process.  Renders an\n    authentication form and accepts its POST.\n\n    * Renders an error message if OpenID cannot be initiated\n\n    * Requests some Simple Registration data using the OpenID\n      library's Simple Registration machinery\n\n    * Generates the appropriate trust root and return URL values for\n      this application (tweak where appropriate)\n\n    * Generates the appropriate redirect based on the OpenID protocol\n      version.\n    \"\"\"\n    if request.POST:\n        # Start OpenID authentication.\n        openid_url = request.POST['openid_identifier']\n        c = getConsumer(request)\n        error = None\n\n        try:\n            auth_request = c.begin(openid_url)\n        except DiscoveryFailure, e:\n            # Some other protocol-level failure occurred.\n            error = \"OpenID discovery error: %s\" % (str(e),)\n\n        if error:\n            # Render the page with an error.\n            return renderIndexPage(request, error=error)\n\n        # Add Simple Registration request information.  Some fields\n        # are optional, some are required.  It's possible that the\n        # server doesn't support sreg or won't return any of the\n        # fields.\n        sreg_request = sreg.SRegRequest(optional=['email', 'nickname'],\n                                        required=['dob'])\n        auth_request.addExtension(sreg_request)\n\n        # Add Attribute Exchange request information.\n        ax_request = ax.FetchRequest()\n        # XXX - uses myOpenID-compatible schema values, which are\n        # not those listed at axschema.org.\n        ax_request.add(\n            ax.AttrInfo('http://schema.openid.net/namePerson',\n                        required=True))\n        ax_request.add(\n            ax.AttrInfo('http://schema.openid.net/contact/web/default',\n                        required=False, count=ax.UNLIMITED_VALUES))\n        auth_request.addExtension(ax_request)\n\n        # Add PAPE request information.  We'll ask for\n        # phishing-resistant auth and display any policies we get in\n        # the response.\n        requested_policies = []\n        policy_prefix = 'policy_'\n        for k, v in request.POST.iteritems():\n            if k.startswith(policy_prefix):\n                policy_attr = k[len(policy_prefix):]\n                if policy_attr in PAPE_POLICIES:\n                    requested_policies.append(getattr(pape, policy_attr))\n\n        if requested_policies:\n            pape_request = pape.Request(requested_policies)\n            auth_request.addExtension(pape_request)\n\n        # Compute the trust root and return URL values to build the\n        # redirect information.\n        trust_root = util.getViewURL(request, startOpenID)\n        return_to = util.getViewURL(request, finishOpenID)\n\n        # Send the browser to the server either by sending a redirect\n        # URL or by generating a POST form.\n        if auth_request.shouldSendRedirect():\n            url = auth_request.redirectURL(trust_root, return_to)\n            return HttpResponseRedirect(url)\n        else:\n            # Beware: this renders a template whose content is a form\n            # and some javascript to submit it upon page load.  Non-JS\n            # users will have to click the form submit button to\n            # initiate OpenID authentication.\n            form_id = 'openid_message'\n            form_html = auth_request.formMarkup(trust_root, return_to,\n                                                False, {'id': form_id})\n            return direct_to_template(\n                request, 'consumer/request_form.html', {'html': form_html})\n\n    return renderIndexPage(request)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rpXRDS(request):\n    return util.renderXRDS(\n        request,\n        [RP_RETURN_TO_URL_TYPE],\n        [util.getViewURL(request, finishOpenID)])", "response": "Return a relying party verification XRDS document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the existing session or a new one if one is not set", "response": "def getSession(self):\n        \"\"\"Return the existing session or a new session\"\"\"\n        if self.session is not None:\n            return self.session\n\n        # Get value of cookie header that was sent\n        cookie_str = self.headers.get('Cookie')\n        if cookie_str:\n            cookie_obj = SimpleCookie(cookie_str)\n            sid_morsel = cookie_obj.get(self.SESSION_COOKIE_NAME, None)\n            if sid_morsel is not None:\n                sid = sid_morsel.value\n            else:\n                sid = None\n        else:\n            sid = None\n\n        # If a session id was not set, create a new one\n        if sid is None:\n            sid = randomString(16, '0123456789abcdef')\n            session = None\n        else:\n            session = self.server.sessions.get(sid)\n\n        # If no session exists for this session ID, create one\n        if session is None:\n            session = self.server.sessions[sid] = {}\n\n        session['id'] = sid\n        self.session = session\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_GET(self):\n        try:\n            self.parsed_uri = urlparse.urlparse(self.path)\n            self.query = {}\n            for k, v in cgi.parse_qsl(self.parsed_uri[4]):\n                self.query[k] = v.decode('utf-8')\n\n            path = self.parsed_uri[2]\n            if path == '/':\n                self.render()\n            elif path == '/verify':\n                self.doVerify()\n            elif path == '/process':\n                self.doProcess()\n            elif path == '/affiliate':\n                self.doAffiliate()\n            else:\n                self.notFound()\n\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except:\n            self.send_response(500)\n            self.send_header('Content-type', 'text/html')\n            self.setSessionCookie()\n            self.end_headers()\n            self.wfile.write(cgitb.html(sys.exc_info(), context=10))", "response": "Dispatching logic. There are three paths defined:\n\n          / - Display an empty form asking for an identity URL to\n              verify\n          /verify - Handle form submission, initiating OpenID verification\n          /process - Handle a redirect from an OpenID server\n\n        Any other path gets a 404 response. This function also parses\n        the query parameters.\n\n        If an exception occurs in this function, a traceback is\n        written to the requesting browser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doProcess(self):\n        oidconsumer = self.getConsumer()\n\n        # Ask the library to check the response that the server sent\n        # us.  Status is a code indicating the response type. info is\n        # either None or a string containing more information about\n        # the return type.\n        url = 'http://'+self.headers.get('Host')+self.path\n        info = oidconsumer.complete(self.query, url)\n\n        sreg_resp = None\n        pape_resp = None\n        css_class = 'error'\n        display_identifier = info.getDisplayIdentifier()\n\n        if info.status == consumer.FAILURE and display_identifier:\n            # In the case of failure, if info is non-None, it is the\n            # URL that we were verifying. We include it in the error\n            # message to help the user figure out what happened.\n            fmt = \"Verification of %s failed: %s\"\n            message = fmt % (cgi.escape(display_identifier),\n                             info.message)\n        elif info.status == consumer.SUCCESS:\n            # Success means that the transaction completed without\n            # error. If info is None, it means that the user cancelled\n            # the verification.\n            css_class = 'alert'\n\n            # This is a successful verification attempt. If this\n            # was a real application, we would do our login,\n            # comment posting, etc. here.\n            fmt = \"You have successfully verified %s as your identity.\"\n            message = fmt % (cgi.escape(display_identifier),)\n            sreg_resp = sreg.SRegResponse.fromSuccessResponse(info)\n            pape_resp = pape.Response.fromSuccessResponse(info)\n            if info.endpoint.canonicalID:\n                # You should authorize i-name users by their canonicalID,\n                # rather than their more human-friendly identifiers.  That\n                # way their account with you is not compromised if their\n                # i-name registration expires and is bought by someone else.\n                message += (\"  This is an i-name, and its persistent ID is %s\"\n                            % (cgi.escape(info.endpoint.canonicalID),))\n        elif info.status == consumer.CANCEL:\n            # cancelled\n            message = 'Verification cancelled'\n        elif info.status == consumer.SETUP_NEEDED:\n            if info.setup_url:\n                message = '<a href=%s>Setup needed</a>' % (\n                    quoteattr(info.setup_url),)\n            else:\n                # This means auth didn't succeed, but you're welcome to try\n                # non-immediate mode.\n                message = 'Setup needed'\n        else:\n            # Either we don't understand the code or there is no\n            # openid_url included with the error. Give a generic\n            # failure message. The library should supply debug\n            # information in a log.\n            message = 'Verification failed.'\n\n        self.render(message, css_class, display_identifier,\n                    sreg_data=sreg_resp, pape_data=pape_resp)", "response": "Handle the redirect from the OpenID server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doAffiliate(self):\n        sreg_req = sreg.SRegRequest(['nickname'], ['fullname', 'email'])\n        href = sreg_req.toMessage().toURL(OPENID_PROVIDER_URL)\n\n        message = \"\"\"Get an OpenID at <a href=%s>%s</a>\"\"\" % (\n            quoteattr(href), OPENID_PROVIDER_NAME)\n        self.render(message)", "response": "Direct the user sign up with an affiliate OpenID provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef buildURL(self, action, **query):\n        base = urlparse.urljoin(self.server.base_url, action)\n        return appendArgs(base, query)", "response": "Build a URL relative to the server base_url with the given\n        query parameters added."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a page with a 404 return code and a message.", "response": "def notFound(self):\n        \"\"\"Render a page with a 404 return code and a message.\"\"\"\n        fmt = 'The path <q>%s</q> was not understood by this server.'\n        msg = fmt % (self.path,)\n        openid_url = self.query.get('openid_identifier')\n        self.render(msg, 'error', openid_url, status=404)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the page header", "response": "def pageHeader(self, title):\n        \"\"\"Render the page header\"\"\"\n        self.setSessionCookie()\n        self.wfile.write('''\\\nContent-type: text/html; charset=UTF-8\n\n<html>\n  <head><title>%s</title></head>\n  <style type=\"text/css\">\n      * {\n        font-family: verdana,sans-serif;\n      }\n      body {\n        width: 50em;\n        margin: 1em;\n      }\n      div {\n        padding: .5em;\n      }\n      tr.odd td {\n        background-color: #dddddd;\n      }\n      table.sreg {\n        border: 1px solid black;\n        border-collapse: collapse;\n      }\n      table.sreg th {\n        border-bottom: 1px solid black;\n      }\n      table.sreg td, table.sreg th {\n        padding: 0.5em;\n        text-align: left;\n      }\n      table {\n        margin: 0;\n        padding: 0;\n      }\n      .alert {\n        border: 1px solid #e7dc2b;\n        background: #fff888;\n      }\n      .error {\n        border: 1px solid #ff0000;\n        background: #ffaaaa;\n      }\n      #verify-form {\n        border: 1px solid #777777;\n        background: #dddddd;\n        margin-top: 1em;\n        padding-bottom: 0em;\n      }\n  </style>\n  <body>\n    <h1>%s</h1>\n    <p>\n      This example consumer uses the <a href=\n      \"http://github.com/openid/python-openid\" >Python\n      OpenID</a> library. It just verifies that the identifier that you enter\n      is your identifier.\n    </p>\n''' % (title, title))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the page footer", "response": "def pageFooter(self, form_contents):\n        \"\"\"Render the page footer\"\"\"\n        if not form_contents:\n            form_contents = ''\n\n        self.wfile.write('''\\\n    <div id=\"verify-form\">\n      <form method=\"get\" accept-charset=\"UTF-8\" action=%s>\n        Identifier:\n        <input type=\"text\" name=\"openid_identifier\" value=%s />\n        <input type=\"submit\" value=\"Verify\" /><br />\n        <input type=\"checkbox\" name=\"immediate\" id=\"immediate\" /><label for=\"immediate\">Use immediate mode</label>\n        <input type=\"checkbox\" name=\"use_sreg\" id=\"use_sreg\" /><label for=\"use_sreg\">Request registration data</label>\n        <input type=\"checkbox\" name=\"use_pape\" id=\"use_pape\" /><label for=\"use_pape\">Request phishing-resistent auth policy (PAPE)</label>\n        <input type=\"checkbox\" name=\"use_stateless\" id=\"use_stateless\" /><label for=\"use_stateless\">Use stateless mode</label>\n      </form>\n    </div>\n  </body>\n</html>\n''' % (quoteattr(self.buildURL('verify')), quoteattr(form_contents)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _callInTransaction(self, func, *args, **kwargs):\n        # No nesting of transactions\n        self.conn.rollback()\n\n        try:\n            self.cur = self.conn.cursor()\n            try:\n                ret = func(*args, **kwargs)\n            finally:\n                self.cur.close()\n                self.cur = None\n        except:\n            self.conn.rollback()\n            raise\n        else:\n            self.conn.commit()\n\n        return ret", "response": "Execute the given function inside of a transaction."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef txn_storeAssociation(self, server_url, association):\n        a = association\n        self.db_set_assoc(\n            server_url,\n            a.handle,\n            self.blobEncode(a.secret),\n            a.issued,\n            a.lifetime,\n            a.assoc_type)", "response": "Set the association for the server URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the association for the given server URL and handle. Returns True if the association existed at all.", "response": "def txn_removeAssociation(self, server_url, handle):\n        \"\"\"Remove the association for the given server URL and handle,\n        returning whether the association existed at all.\n\n        (str, str) -> bool\n        \"\"\"\n        self.db_remove_assoc(server_url, handle)\n        return self.cur.rowcount > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning whether this nonce is present and remove it from the set.", "response": "def txn_useNonce(self, server_url, timestamp, salt):\n        \"\"\"Return whether this nonce is present, and if it is, then\n        remove it from the set.\n\n        str -> bool\"\"\"\n        if abs(timestamp - time.time()) > nonce.SKEW:\n            return False\n\n        try:\n            self.db_add_nonce(server_url, timestamp, salt)\n        except self.exceptions.IntegrityError:\n            # The key uniqueness check failed\n            return False\n        else:\n            # The nonce was successfully added\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef db_set_assoc(self, server_url, handle, secret, issued, lifetime, assoc_type):\n        result = self.db_get_assoc(server_url, handle)\n        rows = self.cur.fetchall()\n        if len(rows):\n            # Update the table since this associations already exists.\n            return self.db_update_assoc(secret, issued, lifetime, assoc_type,\n                                        server_url, handle)\n        else:\n            # Insert a new record because this association wasn't\n            # found.\n            return self.db_new_assoc(server_url, handle, secret, issued,\n                                     lifetime, assoc_type)", "response": "This method sets an association. This method is used to set an association."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nescaping things that need to be escaped if they re in a cross - reference.", "response": "def _escape_xref(xref_match):\n    \"\"\"Escape things that need to be escaped if they're in a cross-reference.\n    \"\"\"\n    xref = xref_match.group()\n    xref = xref.replace('/', '%2F')\n    xref = xref.replace('?', '%3F')\n    xref = xref.replace('#', '%23')\n    return xref"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef escapeForIRI(xri):\n    xri = xri.replace('%', '%25')\n    xri = _xref_re.sub(_escape_xref, xri)\n    return xri", "response": "Escape things that need to be escaped when transforming to an IRI."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef providerIsAuthoritative(providerID, canonicalID):\n    # XXX: can't use rsplit until we require python >= 2.4.\n    lastbang = canonicalID.rindex('!')\n    parent = canonicalID[:lastbang]\n    return parent == providerID", "response": "Is this provider ID authoritative for this XRI?"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the root authority for an XRI.", "response": "def rootAuthority(xri):\n    \"\"\"Return the root authority for an XRI.\n\n    Example::\n\n        rootAuthority(\"xri://@example\") == \"xri://@\"\n\n    @type xri: unicode\n    @returntype: unicode\n    \"\"\"\n    if xri.startswith('xri://'):\n        xri = xri[6:]\n    authority = xri.split('/', 1)[0]\n    if authority[0] == '(':\n        # Cross-reference.\n        # XXX: This is incorrect if someone nests cross-references so there\n        #   is another close-paren in there.  Hopefully nobody does that\n        #   before we have a real xriparse function.  Hopefully nobody does\n        #   that *ever*.\n        root = authority[:authority.index(')') + 1]\n    elif authority[0] in XRI_AUTHORITIES:\n        # Other XRI reference.\n        root = authority[0]\n    else:\n        # IRI reference.  XXX: Can IRI authorities have segments?\n        segments = authority.split('!')\n        segments = reduce(list.__add__,\n            map(lambda s: s.split('*'), segments))\n        root = segments[0]\n\n    return XRI(root)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef toMessage(self, message=None):\n        if message is None:\n            warnings.warn('Passing None to Extension.toMessage is deprecated. '\n                          'Creating a message assuming you want OpenID 2.',\n                          DeprecationWarning, stacklevel=2)\n            message = message_module.Message(message_module.OPENID2_NS)\n\n        implicit = message.isOpenID1()\n\n        try:\n            message.namespaces.addAlias(self.ns_uri, self.ns_alias,\n                                        implicit=implicit)\n        except KeyError:\n            if message.namespaces.getAlias(self.ns_uri) != self.ns_alias:\n                raise\n\n        message.updateArgs(self.ns_uri, self.getExtensionArgs())\n        return message", "response": "Adds the arguments from this extension to the provided message or creates a new message containing only those those\n        arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ensureDir(dir_name):\n    try:\n        os.makedirs(dir_name)\n    except OSError, why:\n        if why.errno != EEXIST or not os.path.isdir(dir_name):\n            raise", "response": "Create dir_name as a directory if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that the directories in which we store our data exist.", "response": "def _setup(self):\n        \"\"\"Make sure that the directories in which we store our data\n        exist.\n\n        () -> NoneType\n        \"\"\"\n        _ensureDir(self.nonce_dir)\n        _ensureDir(self.association_dir)\n        _ensureDir(self.temp_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a temporary file on the same filesystem as the association_dir.", "response": "def _mktemp(self):\n        \"\"\"Create a temporary file on the same filesystem as\n        self.association_dir.\n\n        The temporary directory should not be cleaned if there are any\n        processes using the store. If there is no active process using\n        the store, it is safe to remove all of the files in the\n        temporary directory.\n\n        () -> (file, str)\n        \"\"\"\n        fd, name = mkstemp(dir=self.temp_dir)\n        try:\n            file_obj = os.fdopen(fd, 'wb')\n            return file_obj, name\n        except:\n            _removeIfPresent(name)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a unique filename for a given server url and handle.", "response": "def getAssociationFilename(self, server_url, handle):\n        \"\"\"Create a unique filename for a given server url and\n        handle. This implementation does not assume anything about the\n        format of the handle. The filename that is returned will\n        contain the domain name from the server URL for ease of human\n        inspection of the data directory.\n\n        (str, str) -> str\n        \"\"\"\n        if server_url.find('://') == -1:\n            raise ValueError('Bad server URL: %r' % server_url)\n\n        proto, rest = server_url.split('://', 1)\n        domain = _filenameEscape(rest.split('/', 1)[0])\n        url_hash = _safe64(server_url)\n        if handle:\n            handle_hash = _safe64(handle)\n        else:\n            handle_hash = ''\n\n        filename = '%s-%s-%s-%s' % (proto, domain, url_hash, handle_hash)\n\n        return os.path.join(self.association_dir, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAssociation(self, server_url, handle=None):\n        if handle is None:\n            handle = ''\n\n        # The filename with the empty handle is a prefix of all other\n        # associations for the given server URL.\n        filename = self.getAssociationFilename(server_url, handle)\n\n        if handle:\n            return self._getAssociation(filename)\n        else:\n            association_files = os.listdir(self.association_dir)\n            matching_files = []\n            # strip off the path to do the comparison\n            name = os.path.basename(filename)\n            for association_file in association_files:\n                if association_file.startswith(name):\n                    matching_files.append(association_file)\n\n            matching_associations = []\n            # read the matching files and sort by time issued\n            for name in matching_files:\n                full_name = os.path.join(self.association_dir, name)\n                association = self._getAssociation(full_name)\n                if association is not None:\n                    matching_associations.append(\n                        (association.issued, association))\n\n            matching_associations.sort()\n\n            # return the most recently issued one.\n            if matching_associations:\n                (_, assoc) = matching_associations[-1]\n                return assoc\n            else:\n                return None", "response": "Retrieve an association. If no handle is specified, return\n        the association with the latest expiration.\n\n        (str, str or NoneType) -> Association or NoneType"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves an association if it exists. Do nothing.", "response": "def removeAssociation(self, server_url, handle):\n        \"\"\"Remove an association if it exists. Do nothing if it does not.\n\n        (str, str) -> bool\n        \"\"\"\n        assoc = self.getAssociation(server_url, handle)\n        if assoc is None:\n            return 0\n        else:\n            filename = self.getAssociationFilename(server_url, handle)\n            return _removeIfPresent(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether this nonce is valid.", "response": "def useNonce(self, server_url, timestamp, salt):\n        \"\"\"Return whether this nonce is valid.\n\n        str -> bool\n        \"\"\"\n        if abs(timestamp - time.time()) > nonce.SKEW:\n            return False\n\n        if server_url:\n            proto, rest = server_url.split('://', 1)\n        else:\n            # Create empty proto / rest values for empty server_url,\n            # which is part of a consumer-generated nonce.\n            proto, rest = '', ''\n\n        domain = _filenameEscape(rest.split('/', 1)[0])\n        url_hash = _safe64(server_url)\n        salt_hash = _safe64(salt)\n\n        filename = '%08x-%s-%s-%s-%s' % (timestamp, proto, domain,\n                                         url_hash, salt_hash)\n\n        filename = os.path.join(self.nonce_dir, filename)\n        try:\n            fd = os.open(filename, os.O_CREAT | os.O_EXCL | os.O_WRONLY, 0200)\n        except OSError, why:\n            if why.errno == EEXIST:\n                return False\n            else:\n                raise\n        else:\n            os.close(fd)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the OP - Local Identifier for this service element.", "response": "def findOPLocalIdentifier(service_element, type_uris):\n    \"\"\"Find the OP-Local Identifier for this xrd:Service element.\n\n    This considers openid:Delegate to be a synonym for xrd:LocalID if\n    both OpenID 1.X and OpenID 2.0 types are present. If only OpenID\n    1.X is present, it returns the value of openid:Delegate. If only\n    OpenID 2.0 is present, it returns the value of xrd:LocalID. If\n    there is more than one LocalID tag and the values are different,\n    it raises a DiscoveryFailure. This is also triggered when the\n    xrd:LocalID and openid:Delegate tags are different.\n\n    @param service_element: The xrd:Service element\n    @type service_element: ElementTree.Node\n\n    @param type_uris: The xrd:Type values present in this service\n        element. This function could extract them, but higher level\n        code needs to do that anyway.\n    @type type_uris: [str]\n\n    @raises DiscoveryFailure: when discovery fails.\n\n    @returns: The OP-Local Identifier for this service element, if one\n        is present, or None otherwise.\n    @rtype: str or unicode or NoneType\n    \"\"\"\n    # XXX: Test this function on its own!\n\n    # Build the list of tags that could contain the OP-Local Identifier\n    local_id_tags = []\n    if (OPENID_1_1_TYPE in type_uris or\n        OPENID_1_0_TYPE in type_uris):\n        local_id_tags.append(nsTag(OPENID_1_0_NS, 'Delegate'))\n\n    if OPENID_2_0_TYPE in type_uris:\n        local_id_tags.append(nsTag(XRD_NS_2_0, 'LocalID'))\n\n    # Walk through all the matching tags and make sure that they all\n    # have the same value\n    local_id = None\n    for local_id_tag in local_id_tags:\n        for local_id_element in service_element.findall(local_id_tag):\n            if local_id is None:\n                local_id = local_id_element.text\n            elif local_id != local_id_element.text:\n                format = 'More than one %r tag found in one service element'\n                message = format % (local_id_tag,)\n                raise DiscoveryFailure(message, None)\n\n    return local_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalizeURL(url):\n    try:\n        normalized = urinorm.urinorm(url)\n    except ValueError, why:\n        raise DiscoveryFailure('Normalizing identifier: %s' % (why[0],), None)\n    else:\n        return urlparse.urldefrag(normalized)[0]", "response": "Normalize a URL converting normalization failures to\n    DiscoveryFailure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrearrange service_list in a new list so services are ordered by priority.", "response": "def arrangeByType(service_list, preferred_types):\n    \"\"\"Rearrange service_list in a new list so services are ordered by\n    types listed in preferred_types.  Return the new list.\"\"\"\n\n    def enumerate(elts):\n        \"\"\"Return an iterable that pairs the index of an element with\n        that element.\n\n        For Python 2.2 compatibility\"\"\"\n        return zip(range(len(elts)), elts)\n\n    def bestMatchingService(service):\n        \"\"\"Return the index of the first matching type, or something\n        higher if no type matches.\n\n        This provides an ordering in which service elements that\n        contain a type that comes earlier in the preferred types list\n        come before service elements that come later. If a service\n        element has more than one type, the most preferred one wins.\n        \"\"\"\n        for i, t in enumerate(preferred_types):\n            if preferred_types[i] in service.type_uris:\n                return i\n\n        return len(preferred_types)\n\n    # Build a list with the service elements in tuples whose\n    # comparison will prefer the one with the best matching service\n    prio_services = [(bestMatchingService(s), orig_index, s)\n                     for (orig_index, s) in enumerate(service_list)]\n    prio_services.sort()\n\n    # Now that the services are sorted by priority, remove the sort\n    # keys from the list.\n    for i in range(len(prio_services)):\n        prio_services[i] = prio_services[i][2]\n\n    return prio_services"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getOPOrUserServices(openid_services):\n\n    op_services = arrangeByType(openid_services, [OPENID_IDP_2_0_TYPE])\n\n    openid_services = arrangeByType(openid_services,\n                                    OpenIDServiceEndpoint.openid_type_uris)\n\n    return op_services or openid_services", "response": "Extract OP Identifier services. If none found return the\n    rest sorted with most preferred first according to\n                                    OpenIDServiceEndpoint. openid_type_uris."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef discoverYadis(uri):\n    # Might raise a yadis.discover.DiscoveryFailure if no document\n    # came back for that URI at all.  I don't think falling back\n    # to OpenID 1.0 discovery on the same URL will help, so don't\n    # bother to catch it.\n    response = yadisDiscover(uri)\n\n    yadis_url = response.normalized_uri\n    body = response.response_text\n    try:\n        openid_services = OpenIDServiceEndpoint.fromXRDS(yadis_url, body)\n    except XRDSError:\n        # Does not parse as a Yadis XRDS file\n        openid_services = []\n\n    if not openid_services:\n        # Either not an XRDS or there are no OpenID services.\n\n        if response.isXRDS():\n            # if we got the Yadis content-type or followed the Yadis\n            # header, re-fetch the document without following the Yadis\n            # header, with no Accept header.\n            return discoverNoYadis(uri)\n\n        # Try to parse the response as HTML.\n        # <link rel=\"...\">\n        openid_services = OpenIDServiceEndpoint.fromHTML(yadis_url, body)\n\n    return (yadis_url, getOPOrUserServices(openid_services))", "response": "Discover OpenID services for a URI. Tries Yadis and falls back to OpenID 1. 0 XRDS file and returns a list of OpenIDServiceEndpoint objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo this endpoint support this type?", "response": "def supportsType(self, type_uri):\n        \"\"\"Does this endpoint support this type?\n\n        I consider C{/server} endpoints to implicitly support C{/signon}.\n        \"\"\"\n        return (\n            (type_uri in self.type_uris) or \n            (type_uri == OPENID_2_0_TYPE and self.isOPIdentifier())\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the display identifier if set else return the claimed_id.", "response": "def getDisplayIdentifier(self):\n        \"\"\"Return the display_identifier if set, else return the claimed_id.\n        \"\"\"\n        if self.display_identifier is not None:\n            return self.display_identifier\n        if self.claimed_id is None:\n            return None\n        else:\n            return urlparse.urldefrag(self.claimed_id)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseService(self, yadis_url, uri, type_uris, service_element):\n        self.type_uris = type_uris\n        self.server_url = uri\n        self.used_yadis = True\n\n        if not self.isOPIdentifier():\n            # XXX: This has crappy implications for Service elements\n            # that contain both 'server' and 'signon' Types.  But\n            # that's a pathological configuration anyway, so I don't\n            # think I care.\n            self.local_id = findOPLocalIdentifier(service_element,\n                                                  self.type_uris)\n            self.claimed_id = yadis_url", "response": "Parse the contents of the service element and set the state of this object based on the contents of the service element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getLocalID(self):\n        # I looked at this conditional and thought \"ah-hah! there's the bug!\"\n        # but Python actually makes that one big expression somehow, i.e.\n        # \"x is x is x\" is not the same thing as \"(x is x) is x\".\n        # That's pretty weird, dude.  -- kmt, 1/07\n        if (self.local_id is self.canonicalID is None):\n            return self.claimed_id\n        else:\n            return self.local_id or self.canonicalID", "response": "Return the local ID of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an instance of this class from the basic service endpoint object passed in.", "response": "def fromBasicServiceEndpoint(cls, endpoint):\n        \"\"\"Create a new instance of this class from the endpoint\n        object passed in.\n\n        @return: None or OpenIDServiceEndpoint for this endpoint object\"\"\"\n        type_uris = endpoint.matchTypes(cls.openid_type_uris)\n\n        # If any Type URIs match and there is an endpoint URI\n        # specified, then this is an OpenID endpoint\n        if type_uris and endpoint.uri is not None:\n            openid_endpoint = cls()\n            openid_endpoint.parseService(\n                endpoint.yadis_url,\n                endpoint.uri,\n                endpoint.type_uris,\n                endpoint.service_element)\n        else:\n            openid_endpoint = None\n\n        return openid_endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromHTML(cls, uri, html):\n        discovery_types = [\n            (OPENID_2_0_TYPE, 'openid2.provider', 'openid2.local_id'),\n            (OPENID_1_1_TYPE, 'openid.server', 'openid.delegate'),\n            ]\n\n        link_attrs = html_parse.parseLinkAttrs(html)\n        services = []\n        for type_uri, op_endpoint_rel, local_id_rel in discovery_types:\n            op_endpoint_url = html_parse.findFirstHref(\n                link_attrs, op_endpoint_rel)\n            if op_endpoint_url is None:\n                continue\n\n            service = cls()\n            service.claimed_id = uri\n            service.local_id = html_parse.findFirstHref(\n                link_attrs, local_id_rel)\n            service.server_url = op_endpoint_url\n            service.type_uris = [type_uri]\n\n            services.append(service)\n\n        return services", "response": "Parse the given document as HTML looking for an OpenID <link\n            rel =... > and return a list of OpenIDServiceEndpoint objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a list of endpoints from a DiscoveryResult.", "response": "def fromDiscoveryResult(cls, discoveryResult):\n        \"\"\"Create endpoints from a DiscoveryResult.\n\n        @type discoveryResult: L{DiscoveryResult}\n\n        @rtype: list of L{OpenIDServiceEndpoint}\n\n        @raises XRDSError: When the XRDS does not parse.\n\n        @since: 2.1.0\n        \"\"\"\n        if discoveryResult.isXRDS():\n            method = cls.fromXRDS\n        else:\n            method = cls.fromHTML\n        return method(discoveryResult.normalized_uri,\n                      discoveryResult.response_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fromOPEndpointURL(cls, op_endpoint_url):\n        service = cls()\n        service.server_url = op_endpoint_url\n        service.type_uris = [OPENID_IDP_2_0_TYPE]\n        return service", "response": "Construct an OpenIDServiceEndpoint object for the given OP Endpoint URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setAllowedTypes(self, allowed_types):\n        for (assoc_type, session_type) in allowed_types:\n            checkSessionType(assoc_type, session_type)\n\n        self.allowed_types = allowed_types", "response": "Set the allowed association types checking to make sure that each combination is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addAllowedType(self, assoc_type, session_type=None):\n        if self.allowed_types is None:\n            self.allowed_types = []\n\n        if session_type is None:\n            available = getSessionTypes(assoc_type)\n\n            if not available:\n                raise ValueError('No session available for association type %r'\n                                 % (assoc_type,))\n\n            for session_type in getSessionTypes(assoc_type):\n                self.addAllowedType(assoc_type, session_type)\n        else:\n            checkSessionType(assoc_type, session_type)\n            self.allowed_types.append((assoc_type, session_type))", "response": "Add an association type and session type to the allowed_types list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbeing this combination of association type and session type allowed?", "response": "def isAllowed(self, assoc_type, session_type):\n        \"\"\"Is this combination of association type and session type allowed?\"\"\"\n        assoc_good = (assoc_type, session_type) in self.allowed_types\n        matches = session_type in getSessionTypes(assoc_type)\n        return assoc_good and matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize(self):\n        data = {\n            'version':'2',\n            'handle':self.handle,\n            'secret':oidutil.toBase64(self.secret),\n            'issued':str(int(self.issued)),\n            'lifetime':str(int(self.lifetime)),\n            'assoc_type':self.assoc_type\n            }\n\n        assert len(data) == len(self.assoc_keys)\n        pairs = []\n        for field_name in self.assoc_keys:\n            pairs.append((field_name, data[field_name]))\n\n        return kvform.seqToKV(pairs, strict=True)", "response": "Convert an association to KV form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(cls, assoc_s):\n        pairs = kvform.kvToSeq(assoc_s, strict=True)\n        keys = []\n        values = []\n        for k, v in pairs:\n            keys.append(k)\n            values.append(v)\n\n        if keys != cls.assoc_keys:\n            raise ValueError('Unexpected key values: %r', keys)\n\n        version, handle, secret, issued, lifetime, assoc_type = values\n        if version != '2':\n            raise ValueError('Unknown version: %r' % version)\n        issued = int(issued)\n        lifetime = int(lifetime)\n        secret = oidutil.fromBase64(secret)\n        return cls(handle, secret, issued, lifetime, assoc_type)", "response": "Parse an association as stored by serialize()."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign(self, pairs):\n        kv = kvform.seqToKV(pairs)\n\n        try:\n            mac = self._macs[self.assoc_type]\n        except KeyError:\n            raise ValueError(\n                'Unknown association type: %r' % (self.assoc_type,))\n\n        return mac(self.secret, kv)", "response": "Generate a signature for a sequence of key value pairs in order\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getMessageSignature(self, message):\n        pairs = self._makePairs(message)\n        return oidutil.toBase64(self.sign(pairs))", "response": "Return the signature of a message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signMessage(self, message):\n        if (message.hasKey(OPENID_NS, 'sig') or\n            message.hasKey(OPENID_NS, 'signed')):\n            raise ValueError('Message already has signed list or signature')\n\n        extant_handle = message.getArg(OPENID_NS, 'assoc_handle')\n        if extant_handle and extant_handle != self.handle:\n            raise ValueError(\"Message has a different association handle\")\n\n        signed_message = message.copy()\n        signed_message.setArg(OPENID_NS, 'assoc_handle', self.handle)\n        message_keys = signed_message.toPostArgs().keys()\n        signed_list = [k[7:] for k in message_keys\n                       if k.startswith('openid.')]\n        signed_list.append('signed')\n        signed_list.sort()\n        signed_message.setArg(OPENID_NS, 'signed', ','.join(signed_list))\n        sig = self.getMessageSignature(signed_message)\n        signed_message.setArg(OPENID_NS, 'sig', sig)\n        return signed_message", "response": "Adds a signature and a signed list to a message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checkMessageSignature(self, message):\n        message_sig = message.getArg(OPENID_NS, 'sig')\n        if not message_sig:\n            raise ValueError(\"%s has no sig.\" % (message,))\n        calculated_sig = self.getMessageSignature(message)\n        return cryptutil.const_eq(calculated_sig, message_sig)", "response": "Given a message with a signature calculate a new signature\n            and return whether it matches the signature in the message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addPolicyURI(self, policy_uri):\n        if policy_uri not in self.preferred_auth_policies:\n            self.preferred_auth_policies.append(policy_uri)", "response": "Add an acceptable authentication policy URI to this request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseExtensionArgs(self, args):\n\n        # preferred_auth_policies is a space-separated list of policy URIs\n        self.preferred_auth_policies = []\n\n        policies_str = args.get('preferred_auth_policies')\n        if policies_str:\n            for uri in policies_str.split(' '):\n                if uri not in self.preferred_auth_policies:\n                    self.preferred_auth_policies.append(uri)\n\n        # max_auth_age is base-10 integer number of seconds\n        max_auth_age_str = args.get('max_auth_age')\n        self.max_auth_age = None\n\n        if max_auth_age_str:\n            try:\n                self.max_auth_age = int(max_auth_age_str)\n            except ValueError:\n                pass", "response": "Parse the arguments passed to the PAPE extension method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addPolicyURI(self, policy_uri):\n        if policy_uri not in self.auth_policies:\n            self.auth_policies.append(policy_uri)", "response": "Add a authentication policy to this response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a C{L{Response} object from a successful OpenID authentication policy response.", "response": "def fromSuccessResponse(cls, success_response):\n        \"\"\"Create a C{L{Response}} object from a successful OpenID\n        library response\n        (C{L{openid.consumer.consumer.SuccessResponse}}) response\n        message\n\n        @param success_response: A SuccessResponse from consumer.complete()\n        @type success_response: C{L{openid.consumer.consumer.SuccessResponse}}\n\n        @rtype: Response or None\n        @returns: A provider authentication policy response from the\n            data that was supplied with the C{id_res} response or None\n            if the provider sent no signed PAPE response arguments.\n        \"\"\"\n        self = cls()\n\n        # PAPE requires that the args be signed.\n        args = success_response.getSignedNS(self.ns_uri)\n\n        # Only try to construct a PAPE response if the arguments were\n        # signed in the OpenID response.  If not, return None.\n        if args is not None:\n            self.parseExtensionArgs(args)\n            return self\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseExtensionArgs(self, args, strict=False):\n        policies_str = args.get('auth_policies')\n        if policies_str and policies_str != 'none':\n            self.auth_policies = policies_str.split(' ')\n\n        nist_level_str = args.get('nist_auth_level')\n        if nist_level_str:\n            try:\n                nist_level = int(nist_level_str)\n            except ValueError:\n                if strict:\n                    raise ValueError('nist_auth_level must be an integer between '\n                                     'zero and four, inclusive')\n                else:\n                    self.nist_auth_level = None\n            else:\n                if 0 <= nist_level < 5:\n                    self.nist_auth_level = nist_level\n\n        auth_time = args.get('auth_time')\n        if auth_time:\n            if TIME_VALIDATOR.match(auth_time):\n                self.auth_time = auth_time\n            elif strict:\n                raise ValueError(\"auth_time must be in RFC3339 format\")", "response": "Parse the provider authentication policy arguments into the internal state of this object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an auth level URI alias to this request.", "response": "def _addAuthLevelAlias(self, auth_level_uri, alias=None):\n        \"\"\"Add an auth level URI alias to this request.\n\n        @param auth_level_uri: The auth level URI to send in the\n            request.\n\n        @param alias: The namespace alias to use for this auth level\n            in this message. May be None if the alias is not\n            important.\n        \"\"\"\n        if alias is None:\n            try:\n                alias = self._getAlias(auth_level_uri)\n            except KeyError:\n                alias = self._generateAlias()\n        else:\n            existing_uri = self.auth_level_aliases.get(alias)\n            if existing_uri is not None and existing_uri != auth_level_uri:\n                raise KeyError('Attempting to redefine alias %r from %r to %r',\n                               alias, existing_uri, auth_level_uri)\n\n        self.auth_level_aliases[alias] = auth_level_uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generateAlias(self):\n        for i in xrange(1000):\n            alias = 'cust%d' % (i,)\n            if alias not in self.auth_level_aliases:\n                return alias\n\n        raise RuntimeError('Could not find an unused alias (tried 1000!)')", "response": "Generate an unused auth level alias"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the alias for the specified auth level URI.", "response": "def _getAlias(self, auth_level_uri):\n        \"\"\"Return the alias for the specified auth level URI.\n\n        @raises KeyError: if no alias is defined\n        \"\"\"\n        for (alias, existing_uri) in self.auth_level_aliases.iteritems():\n            if auth_level_uri == existing_uri:\n                return alias\n\n        raise KeyError(auth_level_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parseExtensionArgs(self, args, is_openid1, strict=False):\n\n        # preferred_auth_policies is a space-separated list of policy URIs\n        self.preferred_auth_policies = []\n\n        policies_str = args.get('preferred_auth_policies')\n        if policies_str:\n            for uri in policies_str.split(' '):\n                if uri not in self.preferred_auth_policies:\n                    self.preferred_auth_policies.append(uri)\n\n        # max_auth_age is base-10 integer number of seconds\n        max_auth_age_str = args.get('max_auth_age')\n        self.max_auth_age = None\n\n        if max_auth_age_str:\n            try:\n                self.max_auth_age = int(max_auth_age_str)\n            except ValueError:\n                if strict:\n                    raise\n\n        # Parse auth level information\n        preferred_auth_level_types = args.get('preferred_auth_level_types')\n        if preferred_auth_level_types:\n            aliases = preferred_auth_level_types.strip().split()\n\n            for alias in aliases:\n                key = 'auth_level.ns.%s' % (alias,)\n                try:\n                    uri = args[key]\n                except KeyError:\n                    if is_openid1:\n                        uri = self._default_auth_level_aliases.get(alias)\n                    else:\n                        uri = None\n\n                if uri is None:\n                    if strict:\n                        raise ValueError('preferred auth level %r is not '\n                                         'defined in this message' % (alias,))\n                else:\n                    self.addAuthLevel(uri, alias)", "response": "Parse the arguments of an extension request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setAuthLevel(self, level_uri, level, alias=None):\n        self._addAuthLevelAlias(level_uri, alias)\n        self.auth_levels[level_uri] = level", "response": "Set the value for the given auth level type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addPolicyURI(self, policy_uri):\n        if policy_uri == AUTH_NONE:\n            raise RuntimeError(\n                'To send no policies, do not set any on the response.')\n\n        if policy_uri not in self.auth_policies:\n            self.auth_policies.append(policy_uri)", "response": "Add a authentication policy to this response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseExtensionArgs(self, args, is_openid1, strict=False):\n        policies_str = args.get('auth_policies')\n        if policies_str:\n            auth_policies = policies_str.split(' ')\n        elif strict:\n            raise ValueError('Missing auth_policies')\n        else:\n            auth_policies = []\n\n        if (len(auth_policies) > 1 and strict and AUTH_NONE in auth_policies):\n            raise ValueError('Got some auth policies, as well as the special '\n                             '\"none\" URI: %r' % (auth_policies,))\n\n        if 'none' in auth_policies:\n            msg = '\"none\" used as a policy URI (see PAPE draft < 5)'\n            if strict:\n                raise ValueError(msg)\n            else:\n                warnings.warn(msg, stacklevel=2)\n\n        auth_policies = [u for u in auth_policies\n                         if u not in ['none', AUTH_NONE]]\n\n        self.auth_policies = auth_policies\n\n        for (key, val) in args.iteritems():\n            if key.startswith('auth_level.'):\n                alias = key[11:]\n\n                # skip the already-processed namespace declarations\n                if alias.startswith('ns.'):\n                    continue\n\n                try:\n                    uri = args['auth_level.ns.%s' % (alias,)]\n                except KeyError:\n                    if is_openid1:\n                        uri = self._default_auth_level_aliases.get(alias)\n                    else:\n                        uri = None\n\n                if uri is None:\n                    if strict:\n                        raise ValueError(\n                            'Undefined auth level alias: %r' % (alias,))\n                else:\n                    self.setAuthLevel(uri, val, alias)\n\n        auth_time = args.get('auth_time')\n        if auth_time:\n            if TIME_VALIDATOR.match(auth_time):\n                self.auth_time = auth_time\n            elif strict:\n                raise ValueError(\"auth_time must be in RFC3339 format\")", "response": "Parse the provider authentication policy arguments into the internal state of this object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discover(uri):\n    result = DiscoveryResult(uri)\n    resp = fetchers.fetch(uri, headers={'Accept': YADIS_ACCEPT_HEADER})\n    if resp.status not in (200, 206):\n        raise DiscoveryFailure(\n            'HTTP Response status from identity URL host is not 200. '\n            'Got status %r' % (resp.status,), resp)\n\n    # Note the URL after following redirects\n    result.normalized_uri = resp.final_url\n\n    # Attempt to find out where to go to discover the document\n    # or if we already have it\n    result.content_type = resp.headers.get('content-type')\n\n    result.xrds_uri = whereIsYadis(resp)\n\n    if result.xrds_uri and result.usedYadisLocation():\n        resp = fetchers.fetch(result.xrds_uri)\n        if resp.status not in (200, 206):\n            exc = DiscoveryFailure(\n                'HTTP Response status from Yadis host is not 200. '\n                'Got status %r' % (resp.status,), resp)\n            exc.identity_url = result.normalized_uri\n            raise exc\n        result.content_type = resp.headers.get('content-type')\n\n    result.response_text = resp.body\n    return result", "response": "Discover services for a given URI."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a HTTPResponse return the location of the Yadis document.", "response": "def whereIsYadis(resp):\n    \"\"\"Given a HTTPResponse, return the location of the Yadis document.\n\n    May be the URL just retrieved, another URL, or None, if I can't\n    find any.\n\n    [non-blocking]\n\n    @returns: str or None\n    \"\"\"\n    # Attempt to find out where to go to discover the document\n    # or if we already have it\n    content_type = resp.headers.get('content-type')\n\n    # According to the spec, the content-type header must be an exact\n    # match, or else we have to look for an indirection.\n    if (content_type and\n        content_type.split(';', 1)[0].lower() == YADIS_CONTENT_TYPE):\n        return resp.final_url\n    else:\n        # Try the header\n        yadis_loc = resp.headers.get(YADIS_HEADER_NAME.lower())\n\n        if not yadis_loc:\n            # Parse as HTML if the header is missing.\n            #\n            # XXX: do we want to do something with content-type, like\n            # have a whitelist or a blacklist (for detecting that it's\n            # HTML)?\n\n            # Decode body by encoding of file\n            content_type = content_type or ''\n            encoding = content_type.rsplit(';', 1)\n            if len(encoding) == 2 and encoding[1].strip().startswith('charset='):\n                encoding = encoding[1].split('=', 1)[1].strip()\n            else:\n                encoding = 'UTF-8'\n\n            try:\n                content = resp.body.decode(encoding)\n            except UnicodeError:\n                # Keep encoded version in case yadis location can be found before encoding shut this up.\n                # Possible errors will be caught lower.\n                content = resp.body\n\n            try:\n                yadis_loc = findHTMLMeta(StringIO(content))\n            except (MetaNotFound, UnicodeError):\n                # UnicodeError: Response body could not be encoded and xrds location\n                # could not be found before troubles occurs.\n                pass\n\n        return yadis_loc"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresponds to requests for the server s primary web page.", "response": "def server(request):\n    \"\"\"\n    Respond to requests for the server's primary web page.\n    \"\"\"\n    return direct_to_template(\n        request,\n        'server/index.html',\n        {'user_url': getViewURL(request, idPage),\n         'server_xrds_url': getViewURL(request, idpXrds),\n         })"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresponding to low - level OpenID protocol messages.", "response": "def endpoint(request):\n    \"\"\"\n    Respond to low-level OpenID protocol messages.\n    \"\"\"\n    s = getServer(request)\n\n    query = util.normalDict(request.GET or request.POST)\n\n    # First, decode the incoming request into something the OpenID\n    # library can use.\n    try:\n        openid_request = s.decodeRequest(query)\n    except ProtocolError, why:\n        # This means the incoming request was invalid.\n        return direct_to_template(\n            request,\n            'server/endpoint.html',\n            {'error': str(why)})\n\n    # If we did not get a request, display text indicating that this\n    # is an endpoint.\n    if openid_request is None:\n        return direct_to_template(\n            request,\n            'server/endpoint.html',\n            {})\n\n    # We got a request; if the mode is checkid_*, we will handle it by\n    # getting feedback from the user or by checking the session.\n    if openid_request.mode in [\"checkid_immediate\", \"checkid_setup\"]:\n        return handleCheckIDRequest(request, openid_request)\n    else:\n        # We got some other kind of OpenID request, so we let the\n        # server handle this.\n        openid_response = s.handleRequest(openid_request)\n        return displayResponse(request, openid_response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handleCheckIDRequest(request, openid_request):\n    # If the request was an IDP-driven identifier selection request\n    # (i.e., the IDP URL was entered at the RP), then return the\n    # default identity URL for this server. In a full-featured\n    # provider, there could be interaction with the user to determine\n    # what URL should be sent.\n    if not openid_request.idSelect():\n\n        id_url = getViewURL(request, idPage)\n\n        # Confirm that this server can actually vouch for that\n        # identifier\n        if id_url != openid_request.identity:\n            # Return an error response\n            error_response = ProtocolError(\n                openid_request.message,\n                \"This server cannot verify the URL %r\" %\n                (openid_request.identity,))\n\n            return displayResponse(request, error_response)\n\n    if openid_request.immediate:\n        # Always respond with 'cancel' to immediate mode requests\n        # because we don't track information about a logged-in user.\n        # If we did, then the answer would depend on whether that user\n        # had trusted the request's trust root and whether the user is\n        # even logged in.\n        openid_response = openid_request.answer(False)\n        return displayResponse(request, openid_response)\n    else:\n        # Store the incoming request object in the session so we can\n        # get to it later.\n        setRequest(request, openid_request)\n        return showDecidePage(request, openid_request)", "response": "Handle a checkid request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a page to the user so a trust decision can be made.", "response": "def showDecidePage(request, openid_request):\n    \"\"\"\n    Render a page to the user so a trust decision can be made.\n\n    @type openid_request: openid.server.server.CheckIDRequest\n    \"\"\"\n    trust_root = openid_request.trust_root\n    return_to = openid_request.return_to\n\n    try:\n        # Stringify because template's ifequal can only compare to strings.\n        trust_root_valid = verifyReturnTo(trust_root, return_to) \\\n                           and \"Valid\" or \"Invalid\"\n    except DiscoveryFailure, err:\n        trust_root_valid = \"DISCOVERY_FAILED\"\n    except HTTPFetchingError, err:\n        trust_root_valid = \"Unreachable\"\n\n    pape_request = pape.Request.fromOpenIDRequest(openid_request)\n\n    return direct_to_template(\n        request,\n        'server/trust.html',\n        {'trust_root': trust_root,\n         'trust_handler_url':getViewURL(request, processTrustResult),\n         'trust_root_valid': trust_root_valid,\n         'pape_request': pape_request,\n         })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef processTrustResult(request):\n    # Get the request from the session so we can construct the\n    # appropriate response.\n    openid_request = getRequest(request)\n\n    # The identifier that this server can vouch for\n    response_identity = getViewURL(request, idPage)\n\n    # If the decision was to allow the verification, respond\n    # accordingly.\n    allowed = 'allow' in request.POST\n\n    # Generate a response with the appropriate answer.\n    openid_response = openid_request.answer(allowed,\n                                            identity=response_identity)\n\n    # Send Simple Registration data in the response, if appropriate.\n    if allowed:\n        sreg_data = {\n            'fullname': 'Example User',\n            'nickname': 'example',\n            'dob': '1970-01-01',\n            'email': 'invalid@example.com',\n            'gender': 'F',\n            'postcode': '12345',\n            'country': 'ES',\n            'language': 'eu',\n            'timezone': 'America/New_York',\n            }\n\n        sreg_req = sreg.SRegRequest.fromOpenIDRequest(openid_request)\n        sreg_resp = sreg.SRegResponse.extractResponse(sreg_req, sreg_data)\n        openid_response.addExtension(sreg_resp)\n\n        pape_response = pape.Response()\n        pape_response.setAuthLevel(pape.LEVELS_NIST, 0)\n        openid_response.addExtension(pape_response)\n\n    return displayResponse(request, openid_response)", "response": "Handle the result of a trust decision and respond to the RP\n    accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying an OpenID response.", "response": "def displayResponse(request, openid_response):\n    \"\"\"\n    Display an OpenID response.  Errors will be displayed directly to\n    the user; successful responses and other protocol-level messages\n    will be sent using the proper mechanism (i.e., direct response,\n    redirection, etc.).\n    \"\"\"\n    s = getServer(request)\n\n    # Encode the response into something that is renderable.\n    try:\n        webresponse = s.encodeResponse(openid_response)\n    except EncodingError, why:\n        # If it couldn't be encoded, display an error.\n        text = why.response.encodeToKVForm()\n        return direct_to_template(\n            request,\n            'server/endpoint.html',\n            {'error': cgi.escape(text)})\n\n    # Construct the appropriate django framework response.\n    r = http.HttpResponse(webresponse.body)\n    r.status_code = webresponse.code\n\n    for header, value in webresponse.headers.iteritems():\n        r[header] = value\n\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting all files in a directory to apache mod_asis files in another directory.", "response": "def buildDiscover(base_url, out_dir):\n    \"\"\"Convert all files in a directory to apache mod_asis files in\n    another directory.\"\"\"\n    test_data = discoverdata.readTests(discoverdata.default_test_file)\n\n    def writeTestFile(test_name):\n        template = test_data[test_name]\n\n        data = discoverdata.fillTemplate(\n            test_name, template, base_url, discoverdata.example_xrds)\n\n        out_file_name = os.path.join(out_dir, test_name)\n        out_file = file(out_file_name, 'w')\n        out_file.write(data)\n\n    manifest = [manifest_header]\n    for success, input_name, id_name, result_name in discoverdata.testlist:\n        if not success:\n            continue\n        writeTestFile(input_name)\n\n        input_url = urlparse.urljoin(base_url, input_name)\n        id_url = urlparse.urljoin(base_url, id_name)\n        result_url = urlparse.urljoin(base_url, result_name)\n\n        manifest.append('\\t'.join((input_url, id_url, result_url)))\n        manifest.append('\\n')\n\n    manifest_file_name = os.path.join(out_dir, 'manifest.txt')\n    manifest_file = file(manifest_file_name, 'w')\n    for chunk in manifest:\n        manifest_file.write(chunk)\n    manifest_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef best(self):\n        best = None\n        for assoc in self.assocs.values():\n            if best is None or best.issued < assoc.issued:\n                best = assoc\n        return best", "response": "Returns the association with the oldest issued date."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove expired associations. @return: tuple of (removed associations, remaining associations)", "response": "def cleanup(self):\n        \"\"\"Remove expired associations.\n\n        @return: tuple of (removed associations, remaining associations)\n        \"\"\"\n        remove = []\n        for handle, assoc in self.assocs.iteritems():\n            if assoc.getExpiresIn() == 0:\n                remove.append(handle)\n        for handle in remove:\n            del self.assocs[handle]\n        return len(remove), len(self.assocs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a timestamp from the given nonce string", "response": "def split(nonce_string):\n    \"\"\"Extract a timestamp from the given nonce string\n\n    @param nonce_string: the nonce from which to extract the timestamp\n    @type nonce_string: str\n\n    @returns: A pair of a Unix timestamp and the salt characters\n    @returntype: (int, str)\n\n    @raises ValueError: if the nonce does not start with a correctly\n        formatted time string\n    \"\"\"\n    timestamp_str = nonce_string[:time_str_len]\n    try:\n        timestamp = timegm(strptime(timestamp_str, time_fmt))\n    except AssertionError: # Python 2.2\n        timestamp = -1\n    if timestamp < 0:\n        raise ValueError('time out of range')\n    return timestamp, nonce_string[time_str_len:]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkTimestamp(nonce_string, allowed_skew=SKEW, now=None):\n    try:\n        stamp, _ = split(nonce_string)\n    except ValueError:\n        return False\n    else:\n        if now is None:\n            now = time()\n\n        # Time after which we should not use the nonce\n        past = now - allowed_skew\n\n        # Time that is too far in the future for us to allow\n        future = now + allowed_skew\n\n        # the stamp is not too far in the future and is not too far in\n        # the past\n        return past <= stamp <= future", "response": "Checks if the timestamp that is part of the specified nonce string within the allowed clock skew of the current time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a one - way nonce with the current timestamp", "response": "def mkNonce(when=None):\n    \"\"\"Generate a nonce with the current timestamp\n\n    @param when: Unix timestamp representing the issue time of the\n        nonce. Defaults to the current time.\n    @type when: int\n\n    @returntype: str\n    @returns: A string that should be usable as a one-way nonce\n\n    @see: time\n    \"\"\"\n    salt = cryptutil.randomString(6, NONCE_CHARS)\n    if when is None:\n        t = gmtime()\n    else:\n        t = gmtime(when)\n\n    time_str = strftime(time_fmt, t)\n    return time_str + salt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninvoke the fetch method on the default fetcher.", "response": "def fetch(url, body=None, headers=None):\n    \"\"\"Invoke the fetch method on the default fetcher. Most users\n    should need only this method.\n\n    @raises Exception: any exceptions that may be raised by the default fetcher\n    \"\"\"\n    fetcher = getDefaultFetcher()\n    return fetcher.fetch(url, body, headers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the default fetcher for the .", "response": "def setDefaultFetcher(fetcher, wrap_exceptions=True):\n    \"\"\"Set the default fetcher\n\n    @param fetcher: The fetcher to use as the default HTTP fetcher\n    @type fetcher: HTTPFetcher\n\n    @param wrap_exceptions: Whether to wrap exceptions thrown by the\n        fetcher wil HTTPFetchingError so that they may be caught\n        easier. By default, exceptions will be wrapped. In general,\n        unwrapped fetchers are useful for debugging of fetching errors\n        or if your fetcher raises well-known exceptions that you would\n        like to catch.\n    @type wrap_exceptions: bool\n    \"\"\"\n    global _default_fetcher\n    if fetcher is None or not wrap_exceptions:\n        _default_fetcher = fetcher\n    else:\n        _default_fetcher = ExceptionWrappingFetcher(fetcher)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef usingCurl():\n    fetcher = getDefaultFetcher()\n    if isinstance(fetcher, ExceptionWrappingFetcher):\n        fetcher = fetcher.fetcher\n    return isinstance(fetcher, CurlHTTPFetcher)", "response": "Whether the currently set HTTP fetcher is a Curl HTTP fetcher."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms an HTTP request to the given URL.", "response": "def fetch(self, url, body=None, headers=None):\n        \"\"\"Perform an HTTP request\n\n        @raises Exception: Any exception that can be raised by httplib2\n\n        @see: C{L{HTTPFetcher.fetch}}\n        \"\"\"\n        if body:\n            method = 'POST'\n        else:\n            method = 'GET'\n\n        if headers is None:\n            headers = {}\n\n        # httplib2 doesn't check to make sure that the URL's scheme is\n        # 'http' so we do it here.\n        if not (url.startswith('http://') or url.startswith('https://')):\n            raise ValueError('URL is not a HTTP URL: %r' % (url,))\n\n        httplib2_response, content = self.httplib2.request(\n            url, method, body=body, headers=headers)\n\n        # Translate the httplib2 response to our HTTP response abstraction\n\n        # When a 400 is returned, there is no \"content-location\"\n        # header set. This seems like a bug to me. I can't think of a\n        # case where we really care about the final URL when it is an\n        # error response, but being careful about it can't hurt.\n        try:\n            final_url = httplib2_response['content-location']\n        except KeyError:\n            # We're assuming that no redirects occurred\n            assert not httplib2_response.previous\n\n            # And this should never happen for a successful response\n            assert httplib2_response.status != 200\n            final_url = url\n\n        return HTTPResponse(\n            body=content,\n            final_url=final_url,\n            headers=dict(httplib2_response.items()),\n            status=httplib2_response.status,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getServiceEndpoints(input_url, flt=None):\n    result = discover(input_url)\n    try:\n        endpoints = applyFilter(result.normalized_uri,\n                                result.response_text, flt)\n    except XRDSError, err:\n        raise DiscoveryFailure(str(err), None)\n    return (result.normalized_uri, endpoints)", "response": "Perform the Yadis protocol on the input URL and return an iterable of endpoint objects generated by the filter function flt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef applyFilter(normalized_uri, xrd_data, flt=None):\n    flt = mkFilter(flt)\n    et = parseXRDS(xrd_data)\n\n    endpoints = []\n    for service_element in iterServices(et):\n        endpoints.extend(\n            flt.getServiceEndpoints(normalized_uri, service_element))\n\n    return endpoints", "response": "Generate an iterable of endpoint objects given this input data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a sequence of strings as newline - terminated key - value pairs into a single string.", "response": "def seqToKV(seq, strict=False):\n    \"\"\"Represent a sequence of pairs of strings as newline-terminated\n    key:value pairs. The pairs are generated in the order given.\n\n    @param seq: The pairs\n    @type seq: [(str, (unicode|str))]\n\n    @return: A string representation of the sequence\n    @rtype: str\n    \"\"\"\n    def err(msg):\n        formatted = 'seqToKV warning: %s: %r' % (msg, seq)\n        if strict:\n            raise KVFormError(formatted)\n        else:\n            logging.warn(formatted)\n\n    lines = []\n    for k, v in seq:\n        if isinstance(k, types.StringType):\n            k = k.decode('UTF8')\n        elif not isinstance(k, types.UnicodeType):\n            err('Converting key to string: %r' % k)\n            k = str(k)\n\n        if '\\n' in k:\n            raise KVFormError(\n                'Invalid input for seqToKV: key contains newline: %r' % (k,))\n\n        if ':' in k:\n            raise KVFormError(\n                'Invalid input for seqToKV: key contains colon: %r' % (k,))\n\n        if k.strip() != k:\n            err('Key has whitespace at beginning or end: %r' % (k,))\n\n        if isinstance(v, types.StringType):\n            v = v.decode('UTF8')\n        elif not isinstance(v, types.UnicodeType):\n            err('Converting value to string: %r' % (v,))\n            v = str(v)\n\n        if '\\n' in v:\n            raise KVFormError(\n                'Invalid input for seqToKV: value contains newline: %r' % (v,))\n\n        if v.strip() != v:\n            err('Value has whitespace at beginning or end: %r' % (v,))\n\n        lines.append(k + ':' + v + '\\n')\n\n    return ''.join(lines).encode('UTF8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all link tags in a string representing a HTML document and return a list of their attributes.", "response": "def parseLinkAttrs(html):\n    \"\"\"Find all link tags in a string representing a HTML document and\n    return a list of their attributes.\n\n    @param html: the text to parse\n    @type html: str or unicode\n\n    @return: A list of dictionaries of attributes, one for each link tag\n    @rtype: [[(type(html), type(html))]]\n    \"\"\"\n    stripped = removed_re.sub('', html)\n    html_mo = html_find.search(stripped)\n    if html_mo is None or html_mo.start('contents') == -1:\n        return []\n\n    start, end = html_mo.span('contents')\n    head_mo = head_find.search(stripped, start, end)\n    if head_mo is None or head_mo.start('contents') == -1:\n        return []\n\n    start, end = head_mo.span('contents')\n    link_mos = link_find.finditer(stripped, head_mo.start(), head_mo.end())\n\n    matches = []\n    for link_mo in link_mos:\n        start = link_mo.start() + 5\n        link_attrs = {}\n        for attr_mo in attr_find.finditer(stripped, start):\n            if attr_mo.lastgroup == 'end_link':\n                break\n\n            # Either q_val or unq_val must be present, but not both\n            # unq_val is a True (non-empty) value if it is present\n            attr_name, q_val, unq_val = attr_mo.group(\n                'attr_name', 'q_val', 'unq_val')\n            attr_val = ent_replace.sub(replaceEnt, unq_val or q_val)\n\n            link_attrs[attr_name] = attr_val\n\n        matches.append(link_attrs)\n\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo this target_rel appear in the rel_str?", "response": "def relMatches(rel_attr, target_rel):\n    \"\"\"Does this target_rel appear in the rel_str?\"\"\"\n    # XXX: TESTME\n    rels = rel_attr.strip().split()\n    for rel in rels:\n        rel = rel.lower()\n        if rel == target_rel:\n            return 1\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef linkHasRel(link_attrs, target_rel):\n    # XXX: TESTME\n    rel_attr = link_attrs.get('rel')\n    return rel_attr and relMatches(rel_attr, target_rel)", "response": "Does this link have target_rel as a relationship?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findFirstHref(link_attrs_list, target_rel):\n    # XXX: TESTME\n    matches = findLinksRel(link_attrs_list, target_rel)\n    if not matches:\n        return None\n    first = matches[0]\n    return first.get('href')", "response": "Return the value of the href attribute for the first link tag\n    in the list that has target_rel as a relationship."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an OpenID association store object based on the database engine chosen for this Django application.", "response": "def getOpenIDStore(filestore_path, table_prefix):\n    \"\"\"\n    Returns an OpenID association store object based on the database\n    engine chosen for this Django application.\n\n    * If no database engine is chosen, a filesystem-based store will\n      be used whose path is filestore_path.\n\n    * If a database engine is chosen, a store object for that database\n      type will be returned.\n\n    * If the chosen engine is not supported by the OpenID library,\n      raise ImproperlyConfigured.\n\n    * If a database store is used, this will create the tables\n      necessary to use it.  The table names will be prefixed with\n      table_prefix.  DO NOT use the same table prefix for both an\n      OpenID consumer and an OpenID server in the same database.\n\n    The result of this function should be passed to the Consumer\n    constructor as the store parameter.\n    \"\"\"\n    if not settings.DATABASES.get('default', {'ENGINE':None}).get('ENGINE'):\n        return FileOpenIDStore(filestore_path)\n\n    # Possible side-effect: create a database connection if one isn't\n    # already open.\n    connection.cursor()\n\n    # Create table names to specify for SQL-backed stores.\n    tablenames = {\n        'associations_table': table_prefix + 'openid_associations',\n        'nonces_table': table_prefix + 'openid_nonces',\n        }\n\n    types = {\n        'django.db.backends.postgresql': sqlstore.PostgreSQLStore,\n        'django.db.backends.mysql': sqlstore.MySQLStore,\n        'django.db.backends.sqlite3': sqlstore.SQLiteStore,\n        }\n\n    try:\n        s = types[settings.DATABASES.get('default', {'ENGINE':None}).get('ENGINE')](connection.connection,\n                                            **tablenames)\n    except KeyError:\n        raise ImproperlyConfigured, \\\n              \"Database engine %s not supported by OpenID library\" % \\\n              (settings.DATABASES.get('default', {'ENGINE':None}).get('ENGINE'),)\n\n    try:\n        s.createTables()\n    except (SystemExit, KeyboardInterrupt, MemoryError), e:\n        raise\n    except:\n        # XXX This is not the Right Way to do this, but because the\n        # underlying database implementation might differ in behavior\n        # at this point, we can't reliably catch the right\n        # exception(s) here.  Ideally, the SQL store in the OpenID\n        # library would catch exceptions that it expects and fail\n        # silently, but that could be bad, too.  More ideally, the SQL\n        # store would not attempt to create tables it knows already\n        # exists.\n        pass\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the base URL for the OpenID trust root for that request.", "response": "def getBaseURL(req):\n    \"\"\"\n    Given a Django web request object, returns the OpenID 'trust root'\n    for that request; namely, the absolute URL to the site root which\n    is serving the Django request.  The trust root will include the\n    proper scheme and authority.  It will lack a port if the port is\n    standard (80, 443).\n    \"\"\"\n    name = req.META['HTTP_HOST']\n    try:\n        name = name[:name.index(':')]\n    except:\n        pass\n\n    try:\n        port = int(req.META['SERVER_PORT'])\n    except:\n        port = 80\n\n    proto = req.META['SERVER_PROTOCOL']\n\n    if 'HTTPS' in proto:\n        proto = 'https'\n    else:\n        proto = 'http'\n\n    if port in [80, 443] or not port:\n        port = ''\n    else:\n        port = ':%s' % (port,)\n\n    url = \"%s://%s%s/\" % (proto, name, port)\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering an XRDS page with the specified type URIs and endpoint_urls in one service block and return a response with the appropriate content - type.", "response": "def renderXRDS(request, type_uris, endpoint_urls):\n    \"\"\"Render an XRDS page with the specified type URIs and endpoint\n    URLs in one service block, and return a response with the\n    appropriate content-type.\n    \"\"\"\n    response = direct_to_template(\n        request, 'xrds.xml',\n        {'type_uris':type_uris, 'endpoint_urls':endpoint_urls,})\n    response['Content-Type'] = YADIS_CONTENT_TYPE\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a working ElementTree implementation using the standard XML tree module.", "response": "def importElementTree(module_names=None):\n    \"\"\"Find a working ElementTree implementation, trying the standard\n    places that such a thing might show up.\n\n    >>> ElementTree = importElementTree()\n\n    @param module_names: The names of modules to try to use as\n        ElementTree. Defaults to C{L{elementtree_modules}}\n\n    @returns: An ElementTree module\n    \"\"\"\n    if module_names is None:\n        module_names = elementtree_modules\n\n    for mod_name in module_names:\n        try:\n            ElementTree = __import__(mod_name, None, None, ['unused'])\n        except ImportError:\n            pass\n        else:\n            # Make sure it can actually parse XML\n            try:\n                ElementTree.XML('<unused/>')\n            except (SystemExit, MemoryError, AssertionError):\n                raise\n            except:\n                logging.exception('Not using ElementTree library %r because it failed to '\n                    'parse a trivial document: %s' % mod_name)\n            else:\n                return ElementTree\n    else:\n        raise ImportError('No ElementTree library found. '\n                          'You may need to install one. '\n                          'Tried importing %r' % (module_names,)\n                          )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef appendArgs(url, args):\n    if hasattr(args, 'items'):\n        args = args.items()\n        args.sort()\n    else:\n        args = list(args)\n\n    if len(args) == 0:\n        return url\n\n    if '?' in url:\n        sep = '&'\n    else:\n        sep = '?'\n\n    # Map unicode to UTF-8 if present. Do not make any assumptions\n    # about the encodings of plain bytes (str).\n    i = 0\n    for k, v in args:\n        if type(k) is not str:\n            k = k.encode('UTF-8')\n\n        if type(v) is not str:\n            v = v.encode('UTF-8')\n\n        args[i] = (k, v)\n        i += 1\n\n    return '%s%s%s' % (url, sep, urlencode(args))", "response": "Append query arguments to a HTTP ( s ) URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseXRDS(text):\n    try:\n        element = ElementTree.XML(text)\n    except XMLError, why:\n        exc = XRDSError('Error parsing document as XML')\n        exc.reason = why\n        raise exc\n    else:\n        tree = ElementTree.ElementTree(element)\n        if not isXRDS(tree):\n            raise XRDSError('Not an XRDS document')\n\n        return tree", "response": "Parse the given text as an XRDS document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getYadisXRD(xrd_tree):\n    xrd = None\n\n    # for the side-effect of assigning the last one in the list to the\n    # xrd variable\n    for xrd in xrd_tree.findall(xrd_tag):\n        pass\n\n    # There were no elements found, or else xrd would be set to the\n    # last one\n    if xrd is None:\n        raise XRDSError('No XRD present in tree')\n\n    return xrd", "response": "Return the XRD element that should contain the Yadis services"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getXRDExpiration(xrd_element, default=None):\n    expires_element = xrd_element.find(expires_tag)\n    if expires_element is None:\n        return default\n    else:\n        expires_string = expires_element.text\n\n        # Will raise ValueError if the string is not the expected format\n        expires_time = strptime(expires_string, \"%Y-%m-%dT%H:%M:%SZ\")\n        return datetime(*expires_time[0:6])", "response": "Returns the expiration date of this XRD element or None if no expiration was specified in the XRD element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the CanonicalID from this XRDS document.", "response": "def getCanonicalID(iname, xrd_tree):\n    \"\"\"Return the CanonicalID from this XRDS document.\n\n    @param iname: the XRI being resolved.\n    @type iname: unicode\n\n    @param xrd_tree: The XRDS output from the resolver.\n    @type xrd_tree: ElementTree\n\n    @returns: The XRI CanonicalID or None.\n    @returntype: unicode or None\n    \"\"\"\n    xrd_list = xrd_tree.findall(xrd_tag)\n    xrd_list.reverse()\n\n    try:\n        canonicalID = xri.XRI(xrd_list[0].findall(canonicalID_tag)[0].text)\n    except IndexError:\n        return None\n\n    childID = canonicalID.lower()\n\n    for xrd in xrd_list[1:]:\n        # XXX: can't use rsplit until we require python >= 2.4.\n        parent_sought = childID[:childID.rindex('!')]\n        parent = xri.XRI(xrd.findtext(canonicalID_tag))\n        if parent_sought != parent.lower():\n            raise XRDSFraud(\"%r can not come from %s\" % (childID, parent))\n\n        childID = parent_sought\n\n    root = xri.rootAuthority(iname)\n    if not xri.providerIsAuthoritative(root, childID):\n        raise XRDSFraud(\"%r can not come from root %r\" % (childID, root))\n\n    return canonicalID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the priority of this element.", "response": "def getPriorityStrict(element):\n    \"\"\"Get the priority of this element.\n\n    Raises ValueError if the value of the priority is invalid. If no\n    priority is specified, it returns a value that compares greater\n    than any other value.\n    \"\"\"\n    prio_str = element.get('priority')\n    if prio_str is not None:\n        prio_val = int(prio_str)\n        if prio_val >= 0:\n            return prio_val\n        else:\n            raise ValueError('Priority values must be non-negative integers')\n\n    # Any errors in parsing the priority fall through to here\n    return Max"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prioSort(elements):\n    # Randomize the services before sorting so that equal priority\n    # elements are load-balanced.\n    random.shuffle(elements)\n\n    prio_elems = [(getPriority(e), e) for e in elements]\n    prio_elems.sort()\n    sorted_elems = [s for (_, s) in prio_elems]\n    return sorted_elems", "response": "Sort a list of elements that have priority attributes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expandService(service_element):\n    uris = sortedURIs(service_element)\n    if not uris:\n        uris = [None]\n\n    expanded = []\n    for uri in uris:\n        type_uris = getTypeURIs(service_element)\n        expanded.append((type_uris, uri, service_element))\n\n    return expanded", "response": "Take a service element and expand it into an iterator of type_uri uri and service_element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expandServices(service_elements):\n    expanded = []\n    for service_element in service_elements:\n        expanded.extend(expandService(service_element))\n\n    return expanded", "response": "Take a sorted iterator of service elements and expand it into a\n    sorted iterator of service elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makeKVPost(request_message, server_url):\n    # XXX: TESTME\n    resp = fetchers.fetch(server_url, body=request_message.toURLEncoded())\n\n    # Process response in separate function that can be shared by async code.\n    return _httpResponseToMessage(resp, server_url)", "response": "Make a Direct Request to an OpenID Provider and return the result as a Message object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _httpResponseToMessage(response, server_url):\n    # Should this function be named Message.fromHTTPResponse instead?\n    response_message = Message.fromKVForm(response.body)\n    if response.status == 400:\n        raise ServerError.fromMessage(response_message)\n\n    elif response.status not in (200, 206):\n        fmt = 'bad status code from server %s: %s'\n        error_message = fmt % (server_url, response.status)\n        raise fetchers.HTTPFetchingError(error_message)\n\n    return response_message", "response": "Adapt a HTTP response to a Message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete(self, query, current_url):\n\n        endpoint = self.session.get(self._token_key)\n\n        message = Message.fromPostArgs(query)\n        response = self.consumer.complete(message, endpoint, current_url)\n\n        try:\n            del self.session[self._token_key]\n        except KeyError:\n            pass\n\n        if (response.status in ['success', 'cancel'] and\n            response.identity_url is not None):\n\n            disco = Discovery(self.session,\n                              response.identity_url,\n                              self.session_key_prefix)\n            # This is OK to do even if we did not do discovery in\n            # the first place.\n            disco.cleanup(force=True)\n\n        return response", "response": "This method is called to interpret the server s response to an OpenID\n            request. It is called by the server s flow described in the OpenID\n            consumer overview. It is called by the server s flow described in step 4 of the flow described in the OpenID\n            consumer overview."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a ServerError instance from an error message.", "response": "def fromMessage(cls, message):\n        \"\"\"Generate a ServerError instance, extracting the error text\n        and the error code from the message.\"\"\"\n        error_text = message.getArg(\n            OPENID_NS, 'error', '<no error message supplied>')\n        error_code = message.getArg(OPENID_NS, 'error_code')\n        return cls(error_text, error_code, message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an AuthRequest object for the specified service_endpoint. This method will create an association if necessary.", "response": "def begin(self, service_endpoint):\n        \"\"\"Create an AuthRequest object for the specified\n        service_endpoint. This method will create an association if\n        necessary.\"\"\"\n        if self.store is None:\n            assoc = None\n        else:\n            assoc = self._getAssociation(service_endpoint)\n\n        request = AuthRequest(service_endpoint, assoc)\n        request.return_to_args[self.openid1_nonce_query_arg_name] = mkNonce()\n\n        if request.message.isOpenID1():\n            request.return_to_args[self.openid1_return_to_identifier_name] = \\\n                request.endpoint.claimed_id\n\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the OpenID message using the specified endpoint and return_to URL as context.", "response": "def complete(self, message, endpoint, return_to):\n        \"\"\"Process the OpenID message, using the specified endpoint\n        and return_to URL as context. This method will handle any\n        OpenID message that is sent to the return_to URL.\n        \"\"\"\n        mode = message.getArg(OPENID_NS, 'mode', '<No mode set>')\n\n        modeMethod = getattr(self, '_complete_' + mode,\n                             self._completeInvalid)\n\n        return modeMethod(message, endpoint, return_to)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck an id_res message to see if it is a checkid_immediate cancel response.", "response": "def _checkSetupNeeded(self, message):\n        \"\"\"Check an id_res message to see if it is a\n        checkid_immediate cancel response.\n\n        @raises SetupNeededError: if it is a checkid_immediate cancellation\n        \"\"\"\n        # In OpenID 1, we check to see if this is a cancel from\n        # immediate mode by the presence of the user_setup_url\n        # parameter.\n        if message.isOpenID1():\n            user_setup_url = message.getArg(OPENID1_NS, 'user_setup_url')\n            if user_setup_url is not None:\n                raise SetupNeededError(user_setup_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle id_res responses that are not cancellations of immediate mode requests. @param message: the response paramaters. @param endpoint: the discovered endpoint object. May be None. @raises ProtocolError: If the message contents are not well-formed according to the OpenID specification. This includes missing fields or not signing fields that should be signed. @raises DiscoveryFailure: If the subject of the id_res message does not match the supplied endpoint, and discovery on the identifier in the message fails (this should only happen when using OpenID 2) @returntype: L{Response}", "response": "def _doIdRes(self, message, endpoint, return_to):\n        \"\"\"Handle id_res responses that are not cancellations of\n        immediate mode requests.\n\n        @param message: the response paramaters.\n        @param endpoint: the discovered endpoint object. May be None.\n\n        @raises ProtocolError: If the message contents are not\n            well-formed according to the OpenID specification. This\n            includes missing fields or not signing fields that should\n            be signed.\n\n        @raises DiscoveryFailure: If the subject of the id_res message\n            does not match the supplied endpoint, and discovery on the\n            identifier in the message fails (this should only happen\n            when using OpenID 2)\n\n        @returntype: L{Response}\n        \"\"\"\n        # Checks for presence of appropriate fields (and checks\n        # signed list fields)\n        self._idResCheckForFields(message)\n\n        if not self._checkReturnTo(message, return_to):\n            raise ProtocolError(\n                \"return_to does not match return URL. Expected %r, got %r\"\n                % (return_to, message.getArg(OPENID_NS, 'return_to')))\n\n\n        # Verify discovery information:\n        endpoint = self._verifyDiscoveryResults(message, endpoint)\n        logging.info(\"Received id_res response from %s using association %s\" %\n                    (endpoint.server_url,\n                     message.getArg(OPENID_NS, 'assoc_handle')))\n\n        self._idResCheckSignature(message, endpoint.server_url)\n\n        # Will raise a ProtocolError if the nonce is bad\n        self._idResCheckNonce(message, endpoint)\n\n        signed_list_str = message.getArg(OPENID_NS, 'signed', no_default)\n        signed_list = signed_list_str.split(',')\n        signed_fields = [\"openid.\" + s for s in signed_list]\n        return SuccessResponse(endpoint, message, signed_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verifyReturnToArgs(query):\n        message = Message.fromPostArgs(query)\n        return_to = message.getArg(OPENID_NS, 'return_to')\n\n        if return_to is None:\n            raise ProtocolError('Response has no return_to')\n\n        parsed_url = urlparse(return_to)\n        rt_query = parsed_url[4]\n        parsed_args = cgi.parse_qsl(rt_query)\n\n        for rt_key, rt_value in parsed_args:\n            try:\n                value = query[rt_key]\n                if rt_value != value:\n                    format = (\"parameter %s value %r does not match \"\n                              \"return_to's value %r\")\n                    raise ProtocolError(format % (rt_key, value, rt_value))\n            except KeyError:\n                format = \"return_to parameter %s absent from query %r\"\n                raise ProtocolError(format % (rt_key, query))\n\n        # Make sure all non-OpenID arguments in the response are also\n        # in the signed return_to.\n        bare_args = message.getArgs(BARE_NS)\n        for pair in bare_args.iteritems():\n            if pair not in parsed_args:\n                raise ProtocolError(\"Parameter %s not in return_to URL\" % (pair[0],))", "response": "Verify that all arguments in the return_to URL are present in this response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the information from an OpenID assertion message and verify it against the original one.", "response": "def _verifyDiscoveryResults(self, resp_msg, endpoint=None):\n        \"\"\"\n        Extract the information from an OpenID assertion message and\n        verify it against the original\n\n        @param endpoint: The endpoint that resulted from doing discovery\n        @param resp_msg: The id_res message object\n\n        @returns: the verified endpoint\n        \"\"\"\n        if resp_msg.getOpenIDNamespace() == OPENID2_NS:\n            return self._verifyDiscoveryResultsOpenID2(resp_msg, endpoint)\n        else:\n            return self._verifyDiscoveryResultsOpenID1(resp_msg, endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verifyDiscoverySingle(self, endpoint, to_match):\n        # Every type URI that's in the to_match endpoint has to be\n        # present in the discovered endpoint.\n        for type_uri in to_match.type_uris:\n            if not endpoint.usesExtension(type_uri):\n                raise TypeURIMismatch(type_uri, endpoint)\n\n        # Fragments do not influence discovery, so we can't compare a\n        # claimed identifier with a fragment to discovered information.\n        defragged_claimed_id, _ = urldefrag(to_match.claimed_id)\n        if defragged_claimed_id != endpoint.claimed_id:\n            raise ProtocolError(\n                'Claimed ID does not match (different subjects!), '\n                'Expected %s, got %s' %\n                (defragged_claimed_id, endpoint.claimed_id))\n\n        if to_match.getLocalID() != endpoint.getLocalID():\n            raise ProtocolError('local_id mismatch. Expected %s, got %s' %\n                                (to_match.getLocalID(), endpoint.getLocalID()))\n\n        # If the server URL is None, this must be an OpenID 1\n        # response, because op_endpoint is a required parameter in\n        # OpenID 2. In that case, we don't actually care what the\n        # discovered server_url is, because signature checking or\n        # check_auth should take care of that check for us.\n        if to_match.server_url is None:\n            assert to_match.preferredNamespace() == OPENID1_NS, (\n                \"\"\"The code calling this must ensure that OpenID 2\n                responses have a non-none `openid.op_endpoint' and\n                that it is set as the `server_url' attribute of the\n                `to_match' endpoint.\"\"\")\n\n        elif to_match.server_url != endpoint.server_url:\n            raise ProtocolError('OP Endpoint mismatch. Expected %s, got %s' %\n                                (to_match.server_url, endpoint.server_url))", "response": "Verify that the given endpoint matches the information in the OpenID assertion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _discoverAndVerify(self, claimed_id, to_match_endpoints):\n        logging.info('Performing discovery on %s' % (claimed_id,))\n        _, services = self._discover(claimed_id)\n        if not services:\n            raise DiscoveryFailure('No OpenID information found at %s' %\n                                   (claimed_id,), None)\n        return self._verifyDiscoveredServices(claimed_id, services,\n                                              to_match_endpoints)", "response": "Perform discovery and verify the discovery\n            identifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a check_authentication request message given an anonymized message.", "response": "def _createCheckAuthRequest(self, message):\n        \"\"\"Generate a check_authentication request message given an\n        id_res message.\n        \"\"\"\n        signed = message.getArg(OPENID_NS, 'signed')\n        if signed:\n            for k in signed.split(','):\n                logging.info(k)\n                val = message.getAliasedArg(k)\n\n                # Signed value is missing\n                if val is None:\n                    logging.info('Missing signed field %r' % (k,))\n                    return None\n\n        check_auth_message = message.copy()\n        check_auth_message.setArg(OPENID_NS, 'mode', 'check_authentication')\n        return check_auth_message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _processCheckAuthResponse(self, response, server_url):\n        is_valid = response.getArg(OPENID_NS, 'is_valid', 'false')\n\n        invalidate_handle = response.getArg(OPENID_NS, 'invalidate_handle')\n        if invalidate_handle is not None:\n            logging.info(\n                'Received \"invalidate_handle\" from server %s' % (server_url,))\n            if self.store is None:\n                logging.error('Unexpectedly got invalidate_handle without '\n                            'a store!')\n            else:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n        if is_valid == 'true':\n            return True\n        else:\n            logging.error('Server responds that checkAuth call is not valid')\n            return False", "response": "Process the response message from a checkAuth request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getAssociation(self, endpoint):\n        assoc = self.store.getAssociation(endpoint.server_url)\n\n        if assoc is None or assoc.expiresIn <= 0:\n            assoc = self._negotiateAssociation(endpoint)\n            if assoc is not None:\n                self.store.storeAssociation(endpoint.server_url, assoc)\n\n        return assoc", "response": "Get an association for the endpoint s server_url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extractSupportedAssociationType(self, server_error, endpoint,\n                                         assoc_type):\n        \"\"\"Handle ServerErrors resulting from association requests.\n\n        @returns: If server replied with an C{unsupported-type} error,\n            return a tuple of supported C{association_type}, C{session_type}.\n            Otherwise logs the error and returns None.\n        @rtype: tuple or None\n        \"\"\"\n        # Any error message whose code is not 'unsupported-type'\n        # should be considered a total failure.\n        if server_error.error_code != 'unsupported-type' or \\\n               server_error.message.isOpenID1():\n            logging.error(\n                'Server error when requesting an association from %r: %s'\n                % (endpoint.server_url, server_error.error_text))\n            return None\n\n        # The server didn't like the association/session type\n        # that we sent, and it sent us back a message that\n        # might tell us how to handle it.\n        logging.error(\n            'Unsupported association type %s: %s' % (assoc_type,\n                                                     server_error.error_text,))\n\n        # Extract the session_type and assoc_type from the\n        # error message\n        assoc_type = server_error.message.getArg(OPENID_NS, 'assoc_type')\n        session_type = server_error.message.getArg(OPENID_NS, 'session_type')\n\n        if assoc_type is None or session_type is None:\n            logging.error('Server responded with unsupported association '\n                        'session but did not supply a fallback.')\n            return None\n        elif not self.negotiator.isAllowed(assoc_type, session_type):\n            fmt = ('Server sent unsupported session/association type: '\n                   'session_type=%s, assoc_type=%s')\n            logging.error(fmt % (session_type, assoc_type))\n            return None\n        else:\n            return assoc_type, session_type", "response": "Handles ServerErrors resulting from association requests and returns a tuple of supported association_type session_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes and process one association request to this endpoint s NX - OP endpoint URL.", "response": "def _requestAssociation(self, endpoint, assoc_type, session_type):\n        \"\"\"Make and process one association request to this endpoint's\n        OP endpoint URL.\n\n        @returns: An association object or None if the association\n            processing failed.\n\n        @raises ServerError: when the remote OpenID server returns an error.\n        \"\"\"\n        assoc_session, args = self._createAssociateRequest(\n            endpoint, assoc_type, session_type)\n\n        try:\n            response = self._makeKVPost(args, endpoint.server_url)\n        except fetchers.HTTPFetchingError, why:\n            logging.exception('openid.associate request failed: %s' % (why[0],))\n            return None\n\n        try:\n            assoc = self._extractAssociation(response, assoc_session)\n        except KeyError, why:\n            logging.exception('Missing required parameter in response from %s: %s'\n                        % (endpoint.server_url, why[0]))\n            return None\n        except ProtocolError, why:\n            logging.exception('Protocol error parsing response from %s: %s' % (\n                endpoint.server_url, why[0]))\n            return None\n        else:\n            return assoc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _createAssociateRequest(self, endpoint, assoc_type, session_type):\n        session_type_class = self.session_types[session_type]\n        assoc_session = session_type_class()\n\n        args = {\n            'mode': 'associate',\n            'assoc_type': assoc_type,\n            }\n\n        if not endpoint.compatibilityMode():\n            args['ns'] = OPENID2_NS\n\n        # Leave out the session type if we're in compatibility mode\n        # *and* it's no-encryption.\n        if (not endpoint.compatibilityMode() or\n            assoc_session.session_type != 'no-encryption'):\n            args['session_type'] = assoc_session.session_type\n\n        args.update(assoc_session.getRequest())\n        message = Message.fromOpenIDArgs(args)\n        return assoc_session, message", "response": "Create an association request for the given association type and session type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getOpenID1SessionType(self, assoc_response):\n        # If it's an OpenID 1 message, allow session_type to default\n        # to None (which signifies \"no-encryption\")\n        session_type = assoc_response.getArg(OPENID1_NS, 'session_type')\n\n        # Handle the differences between no-encryption association\n        # respones in OpenID 1 and 2:\n\n        # no-encryption is not really a valid session type for\n        # OpenID 1, but we'll accept it anyway, while issuing a\n        # warning.\n        if session_type == 'no-encryption':\n            logging.warn('OpenID server sent \"no-encryption\"'\n                        'for OpenID 1.X')\n\n        # Missing or empty session type is the way to flag a\n        # 'no-encryption' response. Change the session type to\n        # 'no-encryption' so that it can be handled in the same\n        # way as OpenID 2 'no-encryption' respones.\n        elif session_type == '' or session_type is None:\n            session_type = 'no-encryption'\n\n        return session_type", "response": "Given an association response message extract the OpenID 1. X session type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extractAssociation(self, assoc_response, assoc_session):\n        # Extract the common fields from the response, raising an\n        # exception if they are not found\n        assoc_type = assoc_response.getArg(\n            OPENID_NS, 'assoc_type', no_default)\n        assoc_handle = assoc_response.getArg(\n            OPENID_NS, 'assoc_handle', no_default)\n\n        # expires_in is a base-10 string. The Python parsing will\n        # accept literals that have whitespace around them and will\n        # accept negative values. Neither of these are really in-spec,\n        # but we think it's OK to accept them.\n        expires_in_str = assoc_response.getArg(\n            OPENID_NS, 'expires_in', no_default)\n        try:\n            expires_in = int(expires_in_str)\n        except ValueError, why:\n            raise ProtocolError('Invalid expires_in field: %s' % (why[0],))\n\n        # OpenID 1 has funny association session behaviour.\n        if assoc_response.isOpenID1():\n            session_type = self._getOpenID1SessionType(assoc_response)\n        else:\n            session_type = assoc_response.getArg(\n                OPENID2_NS, 'session_type', no_default)\n\n        # Session type mismatch\n        if assoc_session.session_type != session_type:\n            if (assoc_response.isOpenID1() and\n                session_type == 'no-encryption'):\n                # In OpenID 1, any association request can result in a\n                # 'no-encryption' association response. Setting\n                # assoc_session to a new no-encryption session should\n                # make the rest of this function work properly for\n                # that case.\n                assoc_session = PlainTextConsumerSession()\n            else:\n                # Any other mismatch, regardless of protocol version\n                # results in the failure of the association session\n                # altogether.\n                fmt = 'Session type mismatch. Expected %r, got %r'\n                message = fmt % (assoc_session.session_type, session_type)\n                raise ProtocolError(message)\n\n        # Make sure assoc_type is valid for session_type\n        if assoc_type not in assoc_session.allowed_assoc_types:\n            fmt = 'Unsupported assoc_type for session %s returned: %s'\n            raise ProtocolError(fmt % (assoc_session.session_type, assoc_type))\n\n        # Delegate to the association session to extract the secret\n        # from the response, however is appropriate for that session\n        # type.\n        try:\n            secret = assoc_session.extractSecret(assoc_response)\n        except ValueError, why:\n            fmt = 'Malformed response for %s session: %s'\n            raise ProtocolError(fmt % (assoc_session.session_type, why[0]))\n\n        return Association.fromExpiresIn(\n            expires_in, assoc_handle, secret, assoc_type)", "response": "Attempt to extract an association from the response message and the established association session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset whether this request should be made anonymously.", "response": "def setAnonymous(self, is_anonymous):\n        \"\"\"Set whether this request should be made anonymously. If a\n        request is anonymous, the identifier will not be sent in the\n        request. This is only useful if you are making another kind of\n        request with an extension in this request.\n\n        Anonymous requests are not allowed when the request is made\n        with OpenID 1.\n\n        @raises ValueError: when attempting to set an OpenID1 request\n            as anonymous\n        \"\"\"\n        if is_anonymous and self.message.isOpenID1():\n            raise ValueError('OpenID 1 requests MUST include the '\n                             'identifier in the request')\n        else:\n            self._anonymous = is_anonymous"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an extension argument to this OpenID authentication request.", "response": "def addExtensionArg(self, namespace, key, value):\n        \"\"\"Add an extension argument to this OpenID authentication\n        request.\n\n        Use caution when adding arguments, because they will be\n        URL-escaped and appended to the redirect URL, which can easily\n        get quite long.\n\n        @param namespace: The namespace for the extension. For\n            example, the simple registration extension uses the\n            namespace C{sreg}.\n\n        @type namespace: str\n\n        @param key: The key within the extension namespace. For\n            example, the nickname field in the simple registration\n            extension's key is C{nickname}.\n\n        @type key: str\n\n        @param value: The value to provide to the server for this\n            argument.\n\n        @type value: str\n        \"\"\"\n        self.message.setArg(namespace, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getMessage(self, realm, return_to=None, immediate=False):\n        if return_to:\n            return_to = oidutil.appendArgs(return_to, self.return_to_args)\n        elif immediate:\n            raise ValueError(\n                '\"return_to\" is mandatory when using \"checkid_immediate\"')\n        elif self.message.isOpenID1():\n            raise ValueError('\"return_to\" is mandatory for OpenID 1 requests')\n        elif self.return_to_args:\n            raise ValueError('extra \"return_to\" arguments were specified, '\n                             'but no return_to was specified')\n\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        message = self.message.copy()\n        if message.isOpenID1():\n            realm_key = 'trust_root'\n        else:\n            realm_key = 'realm'\n\n        message.updateArgs(OPENID_NS,\n            {\n            realm_key:realm,\n            'mode':mode,\n            'return_to':return_to,\n            })\n\n        if not self._anonymous:\n            if self.endpoint.isOPIdentifier():\n                # This will never happen when we're in compatibility\n                # mode, as long as isOPIdentifier() returns False\n                # whenever preferredNamespace() returns OPENID1_NS.\n                claimed_id = request_identity = IDENTIFIER_SELECT\n            else:\n                request_identity = self.endpoint.getLocalID()\n                claimed_id = self.endpoint.claimed_id\n\n            # This is true for both OpenID 1 and 2\n            message.setArg(OPENID_NS, 'identity', request_identity)\n\n            if message.isOpenID2():\n                message.setArg(OPENID2_NS, 'claimed_id', claimed_id)\n\n        if self.assoc:\n            message.setArg(OPENID_NS, 'assoc_handle', self.assoc.handle)\n            assoc_log_msg = 'with association %s' % (self.assoc.handle,)\n        else:\n            assoc_log_msg = 'using stateless mode.'\n\n        logging.info(\"Generated %s request to %s %s\" %\n                    (mode, self.endpoint.server_url, assoc_log_msg))\n\n        return message", "response": "Produce a message representing this request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a URL that is the OpenID provider s endpoint URL with an encoded OpenID request.", "response": "def redirectURL(self, realm, return_to=None, immediate=False):\n        \"\"\"Returns a URL with an encoded OpenID request.\n\n        The resulting URL is the OpenID provider's endpoint URL with\n        parameters appended as query arguments.  You should redirect\n        the user agent to this URL.\n\n        OpenID 2.0 endpoints also accept POST requests, see\n        C{L{shouldSendRedirect}} and C{L{formMarkup}}.\n\n        @param realm: The URL (or URL pattern) that identifies your\n            web site to the user when she is authorizing it.\n\n        @type realm: str\n\n        @param return_to: The URL that the OpenID provider will send the\n            user back to after attempting to verify her identity.\n\n            Not specifying a return_to URL means that the user will not\n            be returned to the site issuing the request upon its\n            completion.\n\n        @type return_to: str\n\n        @param immediate: If True, the OpenID provider is to send back\n            a response immediately, useful for behind-the-scenes\n            authentication attempts.  Otherwise the OpenID provider\n            may engage the user before providing a response.  This is\n            the default case, as the user may need to provide\n            credentials or approve the request before a positive\n            response can be sent.\n\n        @type immediate: bool\n\n        @returns: The URL to redirect the user agent to.\n\n        @returntype: str\n        \"\"\"\n        message = self.getMessage(realm, return_to, immediate)\n        return message.toURL(self.endpoint.server_url)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formMarkup(self, realm, return_to=None, immediate=False,\n            form_tag_attrs=None):\n        \"\"\"Get html for a form to submit this request to the IDP.\n\n        @param form_tag_attrs: Dictionary of attributes to be added to\n            the form tag. 'accept-charset' and 'enctype' have defaults\n            that can be overridden. If a value is supplied for\n            'action' or 'method', it will be replaced.\n        @type form_tag_attrs: {unicode: unicode}\n        \"\"\"\n        message = self.getMessage(realm, return_to, immediate)\n        return message.toFormMarkup(self.endpoint.server_url,\n                    form_tag_attrs)", "response": "Returns the html for a form to submit this request to the IDP."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef htmlMarkup(self, realm, return_to=None, immediate=False,\n            form_tag_attrs=None):\n        \"\"\"Get an autosubmitting HTML page that submits this request to the\n        IDP.  This is just a wrapper for formMarkup.\n\n        @see: formMarkup\n\n        @returns: str\n        \"\"\"\n        return oidutil.autoSubmitHTML(self.formMarkup(realm, \n                                                      return_to,\n                                                      immediate, \n                                                      form_tag_attrs))", "response": "Return an HTML page that submits this request to the IDP."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn whether a particular key is signed regardless of its namespace alias", "response": "def isSigned(self, ns_uri, ns_key):\n        \"\"\"Return whether a particular key is signed, regardless of\n        its namespace alias\n        \"\"\"\n        return self.message.getKey(ns_uri, ns_key) in self.signed_fields"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getSigned(self, ns_uri, ns_key, default=None):\n        if self.isSigned(ns_uri, ns_key):\n            return self.message.getArg(ns_uri, ns_key, default)\n        else:\n            return default", "response": "Return the specified signed field if available otherwise return default."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getSignedNS(self, ns_uri):\n        msg_args = self.message.getArgs(ns_uri)\n\n        for key in msg_args.iterkeys():\n            if not self.isSigned(ns_uri, key):\n                logging.info(\"SuccessResponse.getSignedNS: (%s, %s) not signed.\"\n                            % (ns_uri, key))\n                return None\n\n        return msg_args", "response": "Get all of the signed arguments in the specified namespace. Return a\n        dict of all of the arguments in the specified namespace. Return None if no signed arguments are found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extensionResponse(self, namespace_uri, require_signed):\n        if require_signed:\n            return self.getSignedNS(namespace_uri)\n        else:\n            return self.message.getArgs(namespace_uri)", "response": "Return the response arguments in the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mkFilter(parts):\n    # Convert the parts into a list, and pass to mkCompoundFilter\n    if parts is None:\n        parts = [BasicServiceEndpoint]\n\n    try:\n        parts = list(parts)\n    except TypeError:\n        return mkCompoundFilter([parts])\n    else:\n        return mkCompoundFilter(parts)", "response": "Convert a filter - convertable thing into a filter - convertable thing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a compound filter out of a list of filter - like things Used by mkFilter", "response": "def mkCompoundFilter(parts):\n    \"\"\"Create a filter out of a list of filter-like things\n\n    Used by mkFilter\n\n    @param parts: list of filter, endpoint, callable or list of any of these\n    \"\"\"\n    # Separate into a list of callables and a list of filter objects\n    transformers = []\n    filters = []\n    for subfilter in parts:\n        try:\n            subfilter = list(subfilter)\n        except TypeError:\n            # If it's not an iterable\n            if hasattr(subfilter, 'getServiceEndpoints'):\n                # It's a full filter\n                filters.append(subfilter)\n            elif hasattr(subfilter, 'fromBasicServiceEndpoint'):\n                # It's an endpoint object, so put its endpoint\n                # conversion attribute into the list of endpoint\n                # transformers\n                transformers.append(subfilter.fromBasicServiceEndpoint)\n            elif callable(subfilter):\n                # It's a simple callable, so add it to the list of\n                # endpoint transformers\n                transformers.append(subfilter)\n            else:\n                raise filter_type_error\n        else:\n            filters.append(mkCompoundFilter(subfilter))\n\n    if transformers:\n        filters.append(TransformFilterMaker(transformers))\n\n    if len(filters) == 1:\n        return filters[0]\n    else:\n        return CompoundFilter(filters)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getServiceEndpoints(self, yadis_url, service_element):\n        endpoints = []\n\n        # Do an expansion of the service element by xrd:Type and xrd:URI\n        for type_uris, uri, _ in expandService(service_element):\n\n            # Create a basic endpoint object to represent this\n            # yadis_url, Service, Type, URI combination\n            endpoint = BasicServiceEndpoint(\n                yadis_url, type_uris, uri, service_element)\n\n            e = self.applyFilters(endpoint)\n            if e is not None:\n                endpoints.append(e)\n\n        return endpoints", "response": "Returns an iterator of the basic endpoint objects produced by the clf filter functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef applyFilters(self, endpoint):\n        for filter_function in self.filter_functions:\n            e = filter_function(endpoint)\n            if e is not None:\n                # Once one of the filters has returned an\n                # endpoint, do not apply any more.\n                return e\n\n        return None", "response": "Apply the filter functions to an endpoint until one of them\n        returns non - None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getServiceEndpoints(self, yadis_url, service_element):\n        endpoints = []\n        for subfilter in self.subfilters:\n            endpoints.extend(\n                subfilter.getServiceEndpoints(yadis_url, service_element))\n        return endpoints", "response": "Generate all of the endpoint objects for all of the subfilters of\n        this filter and return their concatenation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproduces a random string of length random bytes chosen from chrs.", "response": "def randomString(length, chrs=None):\n    \"\"\"Produce a string of length random bytes, chosen from chrs.\"\"\"\n    if chrs is None:\n        return getBytes(length)\n    else:\n        n = len(chrs)\n        return ''.join([chrs[randrange(n)] for _ in xrange(length)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _hasher_first_run(self, preimage):\n        '''\n        Invoke the backend on-demand, and check an expected hash result,\n        then replace this first run with the new hasher method.\n        This is a bit of a hacky way to minimize overhead on hash calls after this first one.\n        '''\n        new_hasher = self._backend.keccak256\n        assert new_hasher(b'') == b\"\\xc5\\xd2F\\x01\\x86\\xf7#<\\x92~}\\xb2\\xdc\\xc7\\x03\\xc0\\xe5\\x00\\xb6S\\xca\\x82';\\x7b\\xfa\\xd8\\x04]\\x85\\xa4p\"  # noqa: E501\n        self.hasher = new_hasher\n        return new_hasher(preimage)", "response": "Invoke the backend on - demand and check an expected hash result and replace this first run with a new hasher method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the directory component of a pathname.", "response": "def dirname(path: Optional[str]) -> Optional[str]:\n    \"\"\" Returns the directory component of a pathname and None if the argument is None \"\"\"\n    if path is not None:\n        return os.path.dirname(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef basename(path: Optional[str]) -> Optional[str]:\n    if path is not None:\n        return os.path.basename(path)", "response": "Returns the final component of a pathname."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes the path returns None if the argument is None", "response": "def normpath(path: Optional[str]) -> Optional[str]:\n    \"\"\" Normalizes the path, returns None if the argument is None \"\"\"\n    if path is not None:\n        return os.path.normpath(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join_paths(path1: Optional[str], path2: Optional[str]) -> Optional[str]:\n    if path1 is not None and path2 is not None:\n        return os.path.join(path1, path2)", "response": "Joins two paths if both are None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run(self, name, *args, **kwargs):\r\n\r\n        \"\"\" Run a git command specified by name and args/kwargs. \"\"\"\r\n\r\n        stdout = six.b('')\r\n        cmd = getattr(self.git, name)\r\n\r\n        # Ask cmd(...) to return a (status, stdout, stderr) tuple\r\n        kwargs['with_extended_output'] = True\r\n\r\n        # Execute command\r\n        try:\r\n            (_, stdout, _) = cmd(*args, **kwargs)\r\n        except GitCommandError as error:\r\n            # Add more meta-information to errors\r\n            message = \"'{0}' returned exit status {1}\".format(\r\n                ' '.join(str(c) for c in error.command),\r\n                error.status\r\n            )\r\n\r\n            raise GitError(message, stderr=error.stderr, stdout=stdout)\r\n\r\n        return stdout.strip()", "response": "Run a git command specified by name and args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stasher(self):\r\n        # nonlocal for python2\r\n        stashed = [False]\r\n        clean = [False]\r\n\r\n        def stash():\r\n            if clean[0] or not self.repo.is_dirty(submodules=False):\r\n                clean[0] = True\r\n                return\r\n            if stashed[0]:\r\n                return\r\n\r\n            if self.change_count > 1:\r\n                message = 'stashing {0} changes'\r\n            else:\r\n                message = 'stashing {0} change'\r\n            print(colored(\r\n                message.format(self.change_count),\r\n                'magenta'\r\n            ))\r\n            try:\r\n                self._run('stash')\r\n            except GitError as e:\r\n                raise StashError(stderr=e.stderr, stdout=e.stdout)\r\n\r\n            stashed[0] = True\r\n\r\n        yield stash\r\n\r\n        if stashed[0]:\r\n            print(colored('unstashing', 'magenta'))\r\n            try:\r\n                self._run('stash', 'pop')\r\n            except GitError as e:\r\n                raise UnstashError(stderr=e.stderr, stdout=e.stdout)", "response": "A stasher that stashs the current state of the contextmanager."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef checkout(self, branch_name):\r\n        try:\r\n            find(\r\n                self.repo.branches, lambda b: b.name == branch_name\r\n            ).checkout()\r\n        except OrigCheckoutError as e:\r\n            raise CheckoutError(branch_name, details=e)", "response": "Checkout a branch by name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rebase(self, target_branch):\r\n        current_branch = self.repo.active_branch\r\n\r\n        arguments = (\r\n                ([self.config('git-up.rebase.arguments')] or []) +\r\n                [target_branch.name]\r\n        )\r\n        try:\r\n            self._run('rebase', *arguments)\r\n        except GitError as e:\r\n            raise RebaseError(current_branch.name, target_branch.name,\r\n                              **e.__dict__)", "response": "Rebase to target branch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push(self, *args, **kwargs):\r\n        ''' Push commits to remote '''\r\n        stdout = six.b('')\r\n\r\n        # Execute command\r\n        cmd = self.git.push(as_process=True, *args, **kwargs)\r\n\r\n        # Capture output\r\n        while True:\r\n            output = cmd.stdout.read(1)\r\n\r\n            sys.stdout.write(output.decode('utf-8'))\r\n            sys.stdout.flush()\r\n\r\n            stdout += output\r\n\r\n            # Check for EOF\r\n            if output == six.b(\"\"):\r\n                break\r\n\r\n        # Wait for the process to quit\r\n        try:\r\n            cmd.wait()\r\n        except GitCommandError as error:\r\n            # Add more meta-information to errors\r\n            message = \"'{0}' returned exit status {1}\".format(\r\n                ' '.join(str(c) for c in error.command),\r\n                error.status\r\n            )\r\n\r\n            raise GitError(message, stderr=error.stderr, stdout=stdout)\r\n\r\n        return stdout.strip()", "response": "Push commits to remote"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_count(self):\r\n        status = self.git.status(porcelain=True, untracked_files='no').strip()\r\n        if not status:\r\n            return 0\r\n        else:\r\n            return len(status.split('\\n'))", "response": "Returns the number of changes in the working directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of seq without duplicates.", "response": "def uniq(seq):\r\n    \"\"\" Return a copy of seq without duplicates. \"\"\"\r\n    seen = set()\r\n    return [x for x in seq if str(x) not in seen and not seen.add(str(x))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a command and return its output.", "response": "def execute(cmd, cwd=None):\r\n    \"\"\" Execute a command and return it's output. \"\"\"\r\n    try:\r\n        lines = subprocess \\\r\n            .check_output(cmd, cwd=cwd, stderr=DEVNULL) \\\r\n            .splitlines()\r\n    except subprocess.CalledProcessError:\r\n        return None\r\n    else:\r\n        if lines:\r\n            return decode(lines[0].strip())\r\n        else:\r\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(s):\r\n    if isinstance(s, bytes):\r\n        return s.decode(sys.getdefaultencoding())\r\n    else:\r\n        return s", "response": "Decode a string using the system encoding if needed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef current_version():\n    # Monkeypatch setuptools.setup so we get the verison number\n    import setuptools\n\n    version = [None]\n\n    def monkey_setup(**settings):\n        version[0] = settings['version']\n\n    old_setup = setuptools.setup\n    setuptools.setup = monkey_setup\n\n    import setup  # setup.py\n    reload(setup)\n    setuptools.setup = old_setup\n\n    return version[0]", "response": "Get the current version number from setup. py\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(version, quiet, no_fetch, push, **kwargs):  # pragma: no cover\r\n    if version:\r\n        if NO_DISTRIBUTE:\r\n            print(colored('Please install \\'git-up\\' via pip in order to '\r\n                          'get version information.', 'yellow'))\r\n        else:\r\n            GitUp(sparse=True).version_info()\r\n        return\r\n\r\n    if quiet:\r\n        sys.stdout = StringIO()\r\n\r\n    try:\r\n        gitup = GitUp()\r\n\r\n        if push is not None:\r\n            gitup.settings['push.auto'] = push\r\n\r\n        # if arguments['--no-fetch'] or arguments['--no-f']:\r\n        if no_fetch:\r\n            gitup.should_fetch = False\r\n\r\n    except GitError:\r\n        sys.exit(1)  # Error in constructor\r\n    else:\r\n        gitup.run()", "response": "A nicer git pull."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns all the git - up stuff.", "response": "def run(self):\r\n        \"\"\" Run all the git-up stuff. \"\"\"\r\n        try:\r\n            if self.should_fetch:\r\n                self.fetch()\r\n\r\n            self.rebase_all_branches()\r\n\r\n            if self.with_bundler():\r\n                self.check_bundler()\r\n\r\n            if self.settings['push.auto']:\r\n                self.push()\r\n\r\n        except GitError as error:\r\n            self.print_error(error)\r\n\r\n            # Used for test cases\r\n            if self.testing:\r\n                raise\r\n            else:  # pragma: no cover\r\n                sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the recent refs from the remotes.", "response": "def fetch(self):\r\n        \"\"\"\r\n        Fetch the recent refs from the remotes.\r\n\r\n        Unless git-up.fetch.all is set to true, all remotes with\r\n        locally existent branches will be fetched.\r\n        \"\"\"\r\n        fetch_kwargs = {'multiple': True}\r\n        fetch_args = []\r\n\r\n        if self.is_prune():\r\n            fetch_kwargs['prune'] = True\r\n\r\n        if self.settings['fetch.all']:\r\n            fetch_kwargs['all'] = True\r\n        else:\r\n            if '.' in self.remotes:\r\n                self.remotes.remove('.')\r\n\r\n                if not self.remotes:\r\n                    # Only local target branches,\r\n                    # `git fetch --multiple` will fail\r\n                    return\r\n\r\n            fetch_args.append(self.remotes)\r\n\r\n        try:\r\n            self.git.fetch(*fetch_args, **fetch_kwargs)\r\n        except GitError as error:\r\n            error.message = \"`git fetch` failed\"\r\n            raise error"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push(self):\r\n        print('pushing...')\r\n        push_kwargs = {}\r\n        push_args = []\r\n\r\n        if self.settings['push.tags']:\r\n            push_kwargs['push'] = True\r\n\r\n        if self.settings['push.all']:\r\n            push_kwargs['all'] = True\r\n        else:\r\n            if '.' in self.remotes:\r\n                self.remotes.remove('.')\r\n\r\n                if not self.remotes:\r\n                    # Only local target branches,\r\n                    # `git push` will fail\r\n                    return\r\n\r\n            push_args.append(self.remotes)\r\n\r\n        try:\r\n            self.git.push(*push_args, **push_kwargs)\r\n            self.pushed = True\r\n        except GitError as error:\r\n            error.message = \"`git push` failed\"\r\n            raise error", "response": "Push the changes back to the remote"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls a log - command if set by git - up. fetch. all.", "response": "def log(self, branch, remote):\r\n        \"\"\" Call a log-command, if set by git-up.fetch.all. \"\"\"\r\n        log_hook = self.settings['rebase.log-hook']\r\n\r\n        if log_hook:\r\n            if ON_WINDOWS:  # pragma: no cover\r\n                # Running a string in CMD from Python is not that easy on\r\n                # Windows. Running 'cmd /C log_hook' produces problems when\r\n                # using multiple statements or things like 'echo'. Therefore,\r\n                # we write the string to a bat file and execute it.\r\n\r\n                # In addition, we replace occurences of $1 with %1 and so forth\r\n                # in case the user is used to Bash or sh.\r\n                # If there are occurences of %something, we'll replace it with\r\n                # %%something. This is the case when running something like\r\n                # 'git log --pretty=format:\"%Cred%h...\"'.\r\n                # Also, we replace a semicolon with a newline, because if you\r\n                # start with 'echo' on Windows, it will simply echo the\r\n                # semicolon and the commands behind instead of echoing and then\r\n                # running other commands\r\n\r\n                # Prepare log_hook\r\n                log_hook = re.sub(r'\\$(\\d+)', r'%\\1', log_hook)\r\n                log_hook = re.sub(r'%(?!\\d)', '%%', log_hook)\r\n                log_hook = re.sub(r'; ?', r'\\n', log_hook)\r\n\r\n                # Write log_hook to an temporary file and get it's path\r\n                with NamedTemporaryFile(\r\n                        prefix='PyGitUp.', suffix='.bat', delete=False\r\n                ) as bat_file:\r\n                    # Don't echo all commands\r\n                    bat_file.file.write(b'@echo off\\n')\r\n                    # Run log_hook\r\n                    bat_file.file.write(log_hook.encode('utf-8'))\r\n\r\n                # Run bat_file\r\n                state = subprocess.call(\r\n                    [bat_file.name, branch.name, remote.name]\r\n                )\r\n\r\n                # Clean up file\r\n                os.remove(bat_file.name)\r\n            else:  # pragma: no cover\r\n                # Run log_hook via 'shell -c'\r\n                state = subprocess.call(\r\n                    [log_hook, 'git-up', branch.name, remote.name],\r\n                    shell=True\r\n                )\r\n\r\n            if self.testing:\r\n                assert state == 0, 'log_hook returned != 0'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version_info(self):\r\n\r\n        # Retrive and show local version info\r\n        package = pkg.get_distribution('git-up')\r\n        local_version_str = package.version\r\n        local_version = package.parsed_version\r\n\r\n        print('GitUp version is: ' + colored('v' + local_version_str, 'green'))\r\n\r\n        if not self.settings['updates.check']:\r\n            return\r\n\r\n        # Check for updates\r\n        print('Checking for updates...', end='')\r\n\r\n        try:\r\n            # Get version information from the PyPI JSON API\r\n            reader = codecs.getreader('utf-8')\r\n            details = json.load(reader(urlopen(PYPI_URL)))\r\n            online_version = details['info']['version']\r\n        except (HTTPError, URLError, ValueError):\r\n            recent = True  # To not disturb the user with HTTP/parsing errors\r\n        else:\r\n            recent = local_version >= pkg.parse_version(online_version)\r\n\r\n        if not recent:\r\n            # noinspection PyUnboundLocalVariable\r\n            print(\r\n                '\\rRecent version is: '\r\n                + colored('v' + online_version, color='yellow', attrs=['bold'])\r\n            )\r\n            print('Run \\'pip install -U git-up\\' to get the update.')\r\n        else:\r\n            # Clear the update line\r\n            sys.stdout.write('\\r' + ' ' * 80 + '\\n')", "response": "Tell what version we re running at and if it s up to date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the configuration from git config.", "response": "def load_config(self):\r\n        \"\"\"\r\n        Load the configuration from git config.\r\n        \"\"\"\r\n        for key in self.settings:\r\n            value = self.config(key)\r\n            # Parse true/false\r\n            if value == '' or value is None:\r\n                continue  # Not set by user, go on\r\n            if value.lower() == 'true':\r\n                value = True\r\n            elif value.lower() == 'false':\r\n                value = False\r\n            elif value:\r\n                pass  # A user-defined string, store the value later\r\n\r\n            self.settings[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_prune(self):\r\n        required_version = \"1.6.6\"\r\n        config_value = self.settings['fetch.prune']\r\n\r\n        if self.git.is_version_min(required_version):\r\n            return config_value is not False\r\n        else:  # pragma: no cover\r\n            if config_value == 'true':\r\n                print(colored(\r\n                    \"Warning: fetch.prune is set to 'true' but your git\"\r\n                    \"version doesn't seem to support it ({0} < {1}).\"\r\n                    \"Defaulting to 'false'.\".format(self.git.version,\r\n                                                    required_version),\r\n                    'yellow'\r\n                ))", "response": "Return True if fetch. prune is allowed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the user wants to check for new gems and return False otherwise.", "response": "def with_bundler(self):\r\n        \"\"\"\r\n        Check, if bundler check is requested.\r\n\r\n        Check, if the user wants us to check for new gems and return True in\r\n        this case.\r\n        :rtype : bool\r\n        \"\"\"\r\n\r\n        def gemfile_exists():\r\n            \"\"\"\r\n            Check, if a Gemfile exists in the current repo.\r\n            \"\"\"\r\n            return os.path.exists('Gemfile')\r\n\r\n        if 'GIT_UP_BUNDLER_CHECK' in os.environ:\r\n            print(colored(\r\n                '''The GIT_UP_BUNDLER_CHECK environment variable is deprecated.\r\nYou can now tell git-up to check (or not check) for missing\r\ngems on a per-project basis using git's config system. To\r\nset it globally, run this command anywhere:\r\n\r\ngit config --global git-up.bundler.check true\r\n\r\nTo set it within a project, run this command inside that\r\nproject's directory:\r\n\r\ngit config git-up.bundler.check true\r\n\r\nReplace 'true' with 'false' to disable checking.''', 'yellow'))\r\n\r\n        if self.settings['bundler.check']:\r\n            return gemfile_exists()\r\n\r\n        if ('GIT_UP_BUNDLER_CHECK' in os.environ\r\n                and os.environ['GIT_UP_BUNDLER_CHECK'] == 'true'):\r\n            return gemfile_exists()\r\n\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the bundler check.", "response": "def check_bundler(self):\r\n        \"\"\"\r\n        Run the bundler check.\r\n        \"\"\"\r\n\r\n        def get_config(name):\r\n            return name if self.config('bundler.' + name) else ''\r\n\r\n        from pkg_resources import Requirement, resource_filename\r\n        relative_path = os.path.join('PyGitUp', 'check-bundler.rb')\r\n        bundler_script = resource_filename(Requirement.parse('git-up'),\r\n                                           relative_path)\r\n        assert os.path.exists(bundler_script), 'check-bundler.rb doesn\\'t ' \\\r\n                                               'exist!'\r\n\r\n        return_value = subprocess.call(\r\n            ['ruby', bundler_script, get_config('autoinstall'),\r\n             get_config('local'), get_config('rbenv')]\r\n        )\r\n\r\n        if self.testing:\r\n            assert return_value == 0, 'Errors while executing check-bundler.rb'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint more information about an error.", "response": "def print_error(self, error):\r\n        \"\"\"\r\n        Print more information about an error.\r\n\r\n        :type error: GitError\r\n        \"\"\"\r\n        print(colored(error.message, 'red'), file=self.stderr)\r\n\r\n        if error.stdout or error.stderr:\r\n            print(file=self.stderr)\r\n            print(\"Here's what git said:\", file=self.stderr)\r\n            print(file=self.stderr)\r\n\r\n            if error.stdout:\r\n                print(error.stdout, file=self.stderr)\r\n            if error.stderr:\r\n                print(error.stderr, file=self.stderr)\r\n\r\n        if error.details:\r\n            print(file=self.stderr)\r\n            print(\"Here's what we know:\", file=self.stderr)\r\n            print(str(error.details), file=self.stderr)\r\n            print(file=self.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef opendocx(file):\n    '''Open a docx file, return a document XML tree'''\n    mydoc = zipfile.ZipFile(file)\n    xmlcontent = mydoc.read('word/document.xml')\n    document = etree.fromstring(xmlcontent)\n    return document", "response": "Open a docx file return a document XML tree"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeelement(tagname, tagtext=None, nsprefix='w', attributes=None,\n                attrnsprefix=None):\n    '''Create an element & return it'''\n    # Deal with list of nsprefix by making namespacemap\n    namespacemap = None\n    if isinstance(nsprefix, list):\n        namespacemap = {}\n        for prefix in nsprefix:\n            namespacemap[prefix] = nsprefixes[prefix]\n        # FIXME: rest of code below expects a single prefix\n        nsprefix = nsprefix[0]\n    if nsprefix:\n        namespace = '{%s}' % nsprefixes[nsprefix]\n    else:\n        # For when namespace = None\n        namespace = ''\n    newelement = etree.Element(namespace+tagname, nsmap=namespacemap)\n    # Add attributes with namespaces\n    if attributes:\n        # If they haven't bothered setting attribute namespace, use an empty\n        # string (equivalent of no namespace)\n        if not attrnsprefix:\n            # Quick hack: it seems every element that has a 'w' nsprefix for\n            # its tag uses the same prefix for it's attributes\n            if nsprefix == 'w':\n                attributenamespace = namespace\n            else:\n                attributenamespace = ''\n        else:\n            attributenamespace = '{'+nsprefixes[attrnsprefix]+'}'\n\n        for tagattribute in attributes:\n            newelement.set(attributenamespace+tagattribute,\n                           attributes[tagattribute])\n    if tagtext:\n        newelement.text = tagtext\n    return newelement", "response": "Create an element & return it"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pagebreak(type='page', orient='portrait'):\n    '''Insert a break, default 'page'.\n    See http://openxmldeveloper.org/forums/thread/4075.aspx\n    Return our page break element.'''\n    # Need to enumerate different types of page breaks.\n    validtypes = ['page', 'section']\n    if type not in validtypes:\n        tmpl = 'Page break style \"%s\" not implemented. Valid styles: %s.'\n        raise ValueError(tmpl % (type, validtypes))\n    pagebreak = makeelement('p')\n    if type == 'page':\n        run = makeelement('r')\n        br = makeelement('br', attributes={'type': type})\n        run.append(br)\n        pagebreak.append(run)\n    elif type == 'section':\n        pPr = makeelement('pPr')\n        sectPr = makeelement('sectPr')\n        if orient == 'portrait':\n            pgSz = makeelement('pgSz', attributes={'w': '12240', 'h': '15840'})\n        elif orient == 'landscape':\n            pgSz = makeelement('pgSz', attributes={'h': '12240', 'w': '15840',\n                                                   'orient': 'landscape'})\n        sectPr.append(pgSz)\n        pPr.append(sectPr)\n        pagebreak.append(pPr)\n    return pagebreak", "response": "Insert a break default page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paragraph(paratext, style='BodyText', breakbefore=False, jc='left'):\n    # Make our elements\n    paragraph = makeelement('p')\n\n    if not isinstance(paratext, list):\n        paratext = [(paratext, '')]\n    text_tuples = []\n    for pt in paratext:\n        text, char_styles_str = (pt if isinstance(pt, (list, tuple))\n                                 else (pt, ''))\n        text_elm = makeelement('t', tagtext=text)\n        if len(text.strip()) < len(text):\n            text_elm.set('{http://www.w3.org/XML/1998/namespace}space',\n                         'preserve')\n        text_tuples.append([text_elm, char_styles_str])\n    pPr = makeelement('pPr')\n    pStyle = makeelement('pStyle', attributes={'val': style})\n    pJc = makeelement('jc', attributes={'val': jc})\n    pPr.append(pStyle)\n    pPr.append(pJc)\n\n    # Add the text to the run, and the run to the paragraph\n    paragraph.append(pPr)\n    for text_elm, char_styles_str in text_tuples:\n        run = makeelement('r')\n        rPr = makeelement('rPr')\n        # Apply styles\n        if 'b' in char_styles_str:\n            b = makeelement('b')\n            rPr.append(b)\n        if 'i' in char_styles_str:\n            i = makeelement('i')\n            rPr.append(i)\n        if 'u' in char_styles_str:\n            u = makeelement('u', attributes={'val': 'single'})\n            rPr.append(u)\n        run.append(rPr)\n        # Insert lastRenderedPageBreak for assistive technologies like\n        # document narrators to know when a page break occurred.\n        if breakbefore:\n            lastRenderedPageBreak = makeelement('lastRenderedPageBreak')\n            run.append(lastRenderedPageBreak)\n        run.append(text_elm)\n        paragraph.append(run)\n    # Return the combined paragraph\n    return paragraph", "response": "Create a new paragraph element containing the text of the given text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a new heading return the heading element", "response": "def heading(headingtext, headinglevel, lang='en'):\n    '''Make a new heading, return the heading element'''\n    lmap = {'en': 'Heading', 'it': 'Titolo'}\n    # Make our elements\n    paragraph = makeelement('p')\n    pr = makeelement('pPr')\n    pStyle = makeelement(\n        'pStyle', attributes={'val': lmap[lang]+str(headinglevel)})\n    run = makeelement('r')\n    text = makeelement('t', tagtext=headingtext)\n    # Add the text the run, and the run to the paragraph\n    pr.append(pStyle)\n    run.append(text)\n    paragraph.append(pr)\n    paragraph.append(run)\n    # Return the combined paragraph\n    return paragraph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new table element based on specified parameters.", "response": "def table(contents, heading=True, colw=None, cwunit='dxa', tblw=0,\n          twunit='auto', borders={}, celstyle=None):\n    \"\"\"\n    Return a table element based on specified parameters\n\n    @param list contents: A list of lists describing contents. Every item in\n                          the list can be a string or a valid XML element\n                          itself. It can also be a list. In that case all the\n                          listed elements will be merged into the cell.\n    @param bool heading:  Tells whether first line should be treated as\n                          heading or not\n    @param list colw:     list of integer column widths specified in wunitS.\n    @param str  cwunit:   Unit used for column width:\n                            'pct'  : fiftieths of a percent\n                            'dxa'  : twentieths of a point\n                            'nil'  : no width\n                            'auto' : automagically determined\n    @param int  tblw:     Table width\n    @param str  twunit:   Unit used for table width. Same possible values as\n                          cwunit.\n    @param dict borders:  Dictionary defining table border. Supported keys\n                          are: 'top', 'left', 'bottom', 'right',\n                          'insideH', 'insideV', 'all'.\n                          When specified, the 'all' key has precedence over\n                          others. Each key must define a dict of border\n                          attributes:\n                            color : The color of the border, in hex or\n                                    'auto'\n                            space : The space, measured in points\n                            sz    : The size of the border, in eighths of\n                                    a point\n                            val   : The style of the border, see\n                http://www.schemacentral.com/sc/ooxml/t-w_ST_Border.htm\n    @param list celstyle: Specify the style for each colum, list of dicts.\n                          supported keys:\n                          'align' : specify the alignment, see paragraph\n                                    documentation.\n    @return lxml.etree:   Generated XML etree element\n    \"\"\"\n    table = makeelement('tbl')\n    columns = len(contents[0])\n    # Table properties\n    tableprops = makeelement('tblPr')\n    tablestyle = makeelement('tblStyle', attributes={'val': ''})\n    tableprops.append(tablestyle)\n    tablewidth = makeelement(\n        'tblW', attributes={'w': str(tblw), 'type': str(twunit)})\n    tableprops.append(tablewidth)\n    if len(borders.keys()):\n        tableborders = makeelement('tblBorders')\n        for b in ['top', 'left', 'bottom', 'right', 'insideH', 'insideV']:\n            if b in borders.keys() or 'all' in borders.keys():\n                k = 'all' if 'all' in borders.keys() else b\n                attrs = {}\n                for a in borders[k].keys():\n                    attrs[a] = unicode(borders[k][a])\n                borderelem = makeelement(b, attributes=attrs)\n                tableborders.append(borderelem)\n        tableprops.append(tableborders)\n    tablelook = makeelement('tblLook', attributes={'val': '0400'})\n    tableprops.append(tablelook)\n    table.append(tableprops)\n    # Table Grid\n    tablegrid = makeelement('tblGrid')\n    for i in range(columns):\n        attrs = {'w': str(colw[i]) if colw else '2390'}\n        tablegrid.append(makeelement('gridCol', attributes=attrs))\n    table.append(tablegrid)\n    # Heading Row\n    row = makeelement('tr')\n    rowprops = makeelement('trPr')\n    cnfStyle = makeelement('cnfStyle', attributes={'val': '000000100000'})\n    rowprops.append(cnfStyle)\n    row.append(rowprops)\n    if heading:\n        i = 0\n        for heading in contents[0]:\n            cell = makeelement('tc')\n            # Cell properties\n            cellprops = makeelement('tcPr')\n            if colw:\n                wattr = {'w': str(colw[i]), 'type': cwunit}\n            else:\n                wattr = {'w': '0', 'type': 'auto'}\n            cellwidth = makeelement('tcW', attributes=wattr)\n            cellstyle = makeelement('shd', attributes={'val': 'clear',\n                                                       'color': 'auto',\n                                                       'fill': 'FFFFFF',\n                                                       'themeFill': 'text2',\n                                                       'themeFillTint': '99'})\n            cellprops.append(cellwidth)\n            cellprops.append(cellstyle)\n            cell.append(cellprops)\n            # Paragraph (Content)\n            if not isinstance(heading, (list, tuple)):\n                heading = [heading]\n            for h in heading:\n                if isinstance(h, etree._Element):\n                    cell.append(h)\n                else:\n                    cell.append(paragraph(h, jc='center'))\n            row.append(cell)\n            i += 1\n        table.append(row)\n    # Contents Rows\n    for contentrow in contents[1 if heading else 0:]:\n        row = makeelement('tr')\n        i = 0\n        for content in contentrow:\n            cell = makeelement('tc')\n            # Properties\n            cellprops = makeelement('tcPr')\n            if colw:\n                wattr = {'w': str(colw[i]), 'type': cwunit}\n            else:\n                wattr = {'w': '0', 'type': 'auto'}\n            cellwidth = makeelement('tcW', attributes=wattr)\n            cellprops.append(cellwidth)\n            cell.append(cellprops)\n            # Paragraph (Content)\n            if not isinstance(content, (list, tuple)):\n                content = [content]\n            for c in content:\n                if isinstance(c, etree._Element):\n                    cell.append(c)\n                else:\n                    if celstyle and 'align' in celstyle[i].keys():\n                        align = celstyle[i]['align']\n                    else:\n                        align = 'left'\n                    cell.append(paragraph(c, jc=align))\n            row.append(cell)\n            i += 1\n        table.append(row)\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef picture(\n        relationshiplist, picname, picdescription, pixelwidth=None,\n        pixelheight=None, nochangeaspect=True, nochangearrowheads=True,\n        imagefiledict=None):\n    \"\"\"\n    Take a relationshiplist, picture file name, and return a paragraph\n    containing the image and an updated relationshiplist\n    \"\"\"\n    if imagefiledict is None:\n        warn(\n            'Using picture() without imagefiledict parameter will be depreca'\n            'ted in the future.', PendingDeprecationWarning\n        )\n\n    # http://openxmldeveloper.org/articles/462.aspx\n    # Create an image. Size may be specified, otherwise it will based on the\n    # pixel size of image. Return a paragraph containing the picture\n\n    # Set relationship ID to that of the image or the first available one\n    picid = '2'\n    picpath = abspath(picname)\n\n    if imagefiledict is not None:\n        # Keep track of the image files in a separate dictionary so they don't\n        # need to be copied into the template directory\n        if picpath not in imagefiledict:\n            picrelid = 'rId' + str(len(relationshiplist) + 1)\n            imagefiledict[picpath] = picrelid\n\n            relationshiplist.append([\n                'http://schemas.openxmlformats.org/officeDocument/2006/relat'\n                'ionships/image',\n                'media/%s_%s' % (picrelid, basename(picpath))\n            ])\n        else:\n            picrelid = imagefiledict[picpath]\n    else:\n        # Copy files into template directory for backwards compatibility\n        # Images still accumulate in the template directory this way\n        picrelid = 'rId' + str(len(relationshiplist) + 1)\n\n        relationshiplist.append([\n            'http://schemas.openxmlformats.org/officeDocument/2006/relations'\n            'hips/image', 'media/' + picname\n        ])\n\n        media_dir = join(template_dir, 'word', 'media')\n        if not os.path.isdir(media_dir):\n            os.mkdir(media_dir)\n        shutil.copyfile(picname, join(media_dir, picname))\n\n    image = Image.open(picpath)\n\n    # Extract EXIF data, if available\n    try:\n        exif = image._getexif()\n        exif = {} if exif is None else exif\n    except:\n        exif = {}\n\n    imageExif = {}\n    for tag, value in exif.items():\n        imageExif[TAGS.get(tag, tag)] = value\n\n    imageOrientation = imageExif.get('Orientation', 1)\n    imageAngle = {\n        1: 0, 2: 0, 3: 180, 4: 0, 5: 90, 6: 90, 7: 270, 8: 270\n    }[imageOrientation]\n    imageFlipH = 'true' if imageOrientation in (2, 5, 7) else 'false'\n    imageFlipV = 'true' if imageOrientation == 4 else 'false'\n\n    # Check if the user has specified a size\n    if not pixelwidth or not pixelheight:\n        # If not, get info from the picture itself\n        pixelwidth, pixelheight = image.size[0:2]\n\n    # Swap width and height if necessary\n    if imageOrientation in (5, 6, 7, 8):\n        pixelwidth, pixelheight = pixelheight, pixelwidth\n\n    # OpenXML measures on-screen objects in English Metric Units\n    # 1cm = 36000 EMUs\n    emuperpixel = 12700\n    width = str(pixelwidth * emuperpixel)\n    height = str(pixelheight * emuperpixel)\n\n    # There are 3 main elements inside a picture\n    # 1. The Blipfill - specifies how the image fills the picture area\n    #    (stretch, tile, etc.)\n    blipfill = makeelement('blipFill', nsprefix='pic')\n    blipfill.append(makeelement('blip', nsprefix='a', attrnsprefix='r',\n                    attributes={'embed': picrelid}))\n    stretch = makeelement('stretch', nsprefix='a')\n    stretch.append(makeelement('fillRect', nsprefix='a'))\n    blipfill.append(makeelement('srcRect', nsprefix='a'))\n    blipfill.append(stretch)\n\n    # 2. The non visual picture properties\n    nvpicpr = makeelement('nvPicPr', nsprefix='pic')\n    cnvpr = makeelement(\n        'cNvPr', nsprefix='pic',\n        attributes={'id': '0', 'name': 'Picture 1', 'descr': picdescription}\n    )\n    nvpicpr.append(cnvpr)\n    cnvpicpr = makeelement('cNvPicPr', nsprefix='pic')\n    cnvpicpr.append(makeelement(\n        'picLocks', nsprefix='a',\n        attributes={'noChangeAspect': str(int(nochangeaspect)),\n                    'noChangeArrowheads': str(int(nochangearrowheads))}))\n    nvpicpr.append(cnvpicpr)\n\n    # 3. The Shape properties\n    sppr = makeelement('spPr', nsprefix='pic', attributes={'bwMode': 'auto'})\n    xfrm = makeelement(\n        'xfrm', nsprefix='a', attributes={\n            'rot': str(imageAngle * 60000), 'flipH': imageFlipH,\n            'flipV': imageFlipV\n        }\n    )\n    xfrm.append(\n        makeelement('off', nsprefix='a', attributes={'x': '0', 'y': '0'})\n    )\n    xfrm.append(\n        makeelement(\n            'ext', nsprefix='a', attributes={'cx': width, 'cy': height}\n        )\n    )\n    prstgeom = makeelement(\n        'prstGeom', nsprefix='a', attributes={'prst': 'rect'}\n    )\n    prstgeom.append(makeelement('avLst', nsprefix='a'))\n    sppr.append(xfrm)\n    sppr.append(prstgeom)\n\n    # Add our 3 parts to the picture element\n    pic = makeelement('pic', nsprefix='pic')\n    pic.append(nvpicpr)\n    pic.append(blipfill)\n    pic.append(sppr)\n\n    # Now make the supporting elements\n    # The following sequence is just: make element, then add its children\n    graphicdata = makeelement(\n        'graphicData', nsprefix='a',\n        attributes={'uri': ('http://schemas.openxmlformats.org/drawingml/200'\n                            '6/picture')})\n    graphicdata.append(pic)\n    graphic = makeelement('graphic', nsprefix='a')\n    graphic.append(graphicdata)\n\n    framelocks = makeelement('graphicFrameLocks', nsprefix='a',\n                             attributes={'noChangeAspect': '1'})\n    framepr = makeelement('cNvGraphicFramePr', nsprefix='wp')\n    framepr.append(framelocks)\n    docpr = makeelement('docPr', nsprefix='wp',\n                        attributes={'id': picid, 'name': 'Picture 1',\n                                    'descr': picdescription})\n    effectextent = makeelement('effectExtent', nsprefix='wp',\n                               attributes={'l': '25400', 't': '0', 'r': '0',\n                                           'b': '0'})\n    extent = makeelement('extent', nsprefix='wp',\n                         attributes={'cx': width, 'cy': height})\n    inline = makeelement('inline', attributes={'distT': \"0\", 'distB': \"0\",\n                                               'distL': \"0\", 'distR': \"0\"},\n                         nsprefix='wp')\n    inline.append(extent)\n    inline.append(effectextent)\n    inline.append(docpr)\n    inline.append(framepr)\n    inline.append(graphic)\n    drawing = makeelement('drawing')\n    drawing.append(inline)\n    run = makeelement('r')\n    run.append(drawing)\n    paragraph = makeelement('p')\n    paragraph.append(run)\n\n    if imagefiledict is not None:\n        return relationshiplist, paragraph, imagefiledict\n    else:\n        return relationshiplist, paragraph", "response": "Create a new image and a new relationshiplist containing the image and an updated relationshiplist."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches a document for a regex return success / fail result", "response": "def search(document, search):\n    '''Search a document for a regex, return success / fail result'''\n    result = False\n    searchre = re.compile(search)\n    for element in document.iter():\n        if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n            if element.text:\n                if searchre.search(element.text):\n                    result = True\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace all occurences of string with a different string.", "response": "def replace(document, search, replace):\n    \"\"\"\n    Replace all occurences of string with a different string, return updated\n    document\n    \"\"\"\n    newdocument = document\n    searchre = re.compile(search)\n    for element in newdocument.iter():\n        if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n            if element.text:\n                if searchre.search(element.text):\n                    element.text = re.sub(search, replace, element.text)\n    return newdocument"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms misc cleaning operations on documents. Returns cleaned document.", "response": "def clean(document):\n    \"\"\" Perform misc cleaning operations on documents.\n        Returns cleaned document.\n    \"\"\"\n\n    newdocument = document\n\n    # Clean empty text and r tags\n    for t in ('t', 'r'):\n        rmlist = []\n        for element in newdocument.iter():\n            if element.tag == '{%s}%s' % (nsprefixes['w'], t):\n                if not element.text and not len(element):\n                    rmlist.append(element)\n        for element in rmlist:\n            element.getparent().remove(element)\n\n    return newdocument"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findTypeParent(element, tag):\n\n    p = element\n    while True:\n        p = p.getparent()\n        if p.tag == tag:\n            return p\n\n    # Not found\n    return None", "response": "Finds the parent of the given type of element of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn set of all regex matches This is an advanced version of python-docx.search() that takes into account blocks of <bs> elements at a time. What it does: It searches the entire document body for text blocks. Since the text to search could be spawned across multiple text blocks, we need to adopt some sort of algorithm to handle this situation. The smaller matching group of blocks (up to bs) is then adopted. If the matching group has more than one block, blocks other than first are cleared and all the replacement text is put on first block. Examples: original text blocks : [ 'Hel', 'lo,', ' world!' ] search : 'Hello,' output blocks : [ 'Hello,' ] original text blocks : [ 'Hel', 'lo', ' __', 'name', '__!' ] search : '(__[a-z]+__)' output blocks : [ '__name__' ] @param instance document: The original document @param str search: The text to search for (regexp) append, or a list of etree elements @param int bs: See above @return set All occurences of search string", "response": "def AdvSearch(document, search, bs=3):\n    '''Return set of all regex matches\n\n    This is an advanced version of python-docx.search() that takes into\n    account blocks of <bs> elements at a time.\n\n    What it does:\n    It searches the entire document body for text blocks.\n    Since the text to search could be spawned across multiple text blocks,\n    we need to adopt some sort of algorithm to handle this situation.\n    The smaller matching group of blocks (up to bs) is then adopted.\n    If the matching group has more than one block, blocks other than first\n    are cleared and all the replacement text is put on first block.\n\n    Examples:\n    original text blocks : [ 'Hel', 'lo,', ' world!' ]\n    search : 'Hello,'\n    output blocks : [ 'Hello,' ]\n\n    original text blocks : [ 'Hel', 'lo', ' __', 'name', '__!' ]\n    search : '(__[a-z]+__)'\n    output blocks : [ '__name__' ]\n\n    @param instance  document: The original document\n    @param str       search: The text to search for (regexp)\n                          append, or a list of etree elements\n    @param int       bs: See above\n\n    @return set      All occurences of search string\n\n    '''\n\n    # Compile the search regexp\n    searchre = re.compile(search)\n\n    matches = []\n\n    # Will match against searchels. Searchels is a list that contains last\n    # n text elements found in the document. 1 < n < bs\n    searchels = []\n\n    for element in document.iter():\n        if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n            if element.text:\n                # Add this element to searchels\n                searchels.append(element)\n                if len(searchels) > bs:\n                    # Is searchels is too long, remove first elements\n                    searchels.pop(0)\n\n                # Search all combinations, of searchels, starting from\n                # smaller up to bigger ones\n                # l = search lenght\n                # s = search start\n                # e = element IDs to merge\n                found = False\n                for l in range(1, len(searchels)+1):\n                    if found:\n                        break\n                    for s in range(len(searchels)):\n                        if found:\n                            break\n                        if s+l <= len(searchels):\n                            e = range(s, s+l)\n                            txtsearch = ''\n                            for k in e:\n                                txtsearch += searchels[k].text\n\n                            # Searcs for the text in the whole txtsearch\n                            match = searchre.search(txtsearch)\n                            if match:\n                                matches.append(match.group())\n                                found = True\n    return set(matches)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace all occurences of string with a different string, return updated document This is a modified version of python-docx.replace() that takes into account blocks of <bs> elements at a time. The replace element can also be a string or an xml etree element. What it does: It searches the entire document body for text blocks. Then scan thos text blocks for replace. Since the text to search could be spawned across multiple text blocks, we need to adopt some sort of algorithm to handle this situation. The smaller matching group of blocks (up to bs) is then adopted. If the matching group has more than one block, blocks other than first are cleared and all the replacement text is put on first block. Examples: original text blocks : [ 'Hel', 'lo,', ' world!' ] search / replace: 'Hello,' / 'Hi!' output blocks : [ 'Hi!', '', ' world!' ] original text blocks : [ 'Hel', 'lo,', ' world!' ] search / replace: 'Hello, world' / 'Hi!' output blocks : [ 'Hi!!', '', '' ] original text blocks : [ 'Hel', 'lo,', ' world!' ] search / replace: 'Hel' / 'Hal' output blocks : [ 'Hal', 'lo,', ' world!' ] @param instance document: The original document @param str search: The text to search for (regexp) @param mixed replace: The replacement text or lxml.etree element to append, or a list of etree elements @param int bs: See above @return instance The document with replacement applied", "response": "def advReplace(document, search, replace, bs=3):\n    \"\"\"\n    Replace all occurences of string with a different string, return updated\n    document\n\n    This is a modified version of python-docx.replace() that takes into\n    account blocks of <bs> elements at a time. The replace element can also\n    be a string or an xml etree element.\n\n    What it does:\n    It searches the entire document body for text blocks.\n    Then scan thos text blocks for replace.\n    Since the text to search could be spawned across multiple text blocks,\n    we need to adopt some sort of algorithm to handle this situation.\n    The smaller matching group of blocks (up to bs) is then adopted.\n    If the matching group has more than one block, blocks other than first\n    are cleared and all the replacement text is put on first block.\n\n    Examples:\n    original text blocks : [ 'Hel', 'lo,', ' world!' ]\n    search / replace: 'Hello,' / 'Hi!'\n    output blocks : [ 'Hi!', '', ' world!' ]\n\n    original text blocks : [ 'Hel', 'lo,', ' world!' ]\n    search / replace: 'Hello, world' / 'Hi!'\n    output blocks : [ 'Hi!!', '', '' ]\n\n    original text blocks : [ 'Hel', 'lo,', ' world!' ]\n    search / replace: 'Hel' / 'Hal'\n    output blocks : [ 'Hal', 'lo,', ' world!' ]\n\n    @param instance  document: The original document\n    @param str       search: The text to search for (regexp)\n    @param mixed     replace: The replacement text or lxml.etree element to\n                         append, or a list of etree elements\n    @param int       bs: See above\n\n    @return instance The document with replacement applied\n\n    \"\"\"\n    # Enables debug output\n    DEBUG = False\n\n    newdocument = document\n\n    # Compile the search regexp\n    searchre = re.compile(search)\n\n    # Will match against searchels. Searchels is a list that contains last\n    # n text elements found in the document. 1 < n < bs\n    searchels = []\n\n    for element in newdocument.iter():\n        if element.tag == '{%s}t' % nsprefixes['w']:  # t (text) elements\n            if element.text:\n                # Add this element to searchels\n                searchels.append(element)\n                if len(searchels) > bs:\n                    # Is searchels is too long, remove first elements\n                    searchels.pop(0)\n\n                # Search all combinations, of searchels, starting from\n                # smaller up to bigger ones\n                # l = search lenght\n                # s = search start\n                # e = element IDs to merge\n                found = False\n                for l in range(1, len(searchels)+1):\n                    if found:\n                        break\n                    #print \"slen:\", l\n                    for s in range(len(searchels)):\n                        if found:\n                            break\n                        if s+l <= len(searchels):\n                            e = range(s, s+l)\n                            #print \"elems:\", e\n                            txtsearch = ''\n                            for k in e:\n                                txtsearch += searchels[k].text\n\n                            # Searcs for the text in the whole txtsearch\n                            match = searchre.search(txtsearch)\n                            if match:\n                                found = True\n\n                                # I've found something :)\n                                if DEBUG:\n                                    log.debug(\"Found element!\")\n                                    log.debug(\"Search regexp: %s\",\n                                              searchre.pattern)\n                                    log.debug(\"Requested replacement: %s\",\n                                              replace)\n                                    log.debug(\"Matched text: %s\", txtsearch)\n                                    log.debug(\"Matched text (splitted): %s\",\n                                              map(lambda i: i.text, searchels))\n                                    log.debug(\"Matched at position: %s\",\n                                              match.start())\n                                    log.debug(\"matched in elements: %s\", e)\n                                    if isinstance(replace, etree._Element):\n                                        log.debug(\"Will replace with XML CODE\")\n                                    elif isinstance(replace(list, tuple)):\n                                        log.debug(\"Will replace with LIST OF\"\n                                                  \" ELEMENTS\")\n                                    else:\n                                        log.debug(\"Will replace with:\",\n                                                  re.sub(search, replace,\n                                                         txtsearch))\n\n                                curlen = 0\n                                replaced = False\n                                for i in e:\n                                    curlen += len(searchels[i].text)\n                                    if curlen > match.start() and not replaced:\n                                        # The match occurred in THIS element.\n                                        # Puth in the whole replaced text\n                                        if isinstance(replace, etree._Element):\n                                            # Convert to a list and process\n                                            # it later\n                                            replace = [replace]\n                                        if isinstance(replace, (list, tuple)):\n                                            # I'm replacing with a list of\n                                            # etree elements\n                                            # clear the text in the tag and\n                                            # append the element after the\n                                            # parent paragraph\n                                            # (because t elements cannot have\n                                            # childs)\n                                            p = findTypeParent(\n                                                searchels[i],\n                                                '{%s}p' % nsprefixes['w'])\n                                            searchels[i].text = re.sub(\n                                                search, '', txtsearch)\n                                            insindex = p.getparent().index(p)+1\n                                            for r in replace:\n                                                p.getparent().insert(\n                                                    insindex, r)\n                                                insindex += 1\n                                        else:\n                                            # Replacing with pure text\n                                            searchels[i].text = re.sub(\n                                                search, replace, txtsearch)\n                                        replaced = True\n                                        log.debug(\n                                            \"Replacing in element #: %s\", i)\n                                    else:\n                                        # Clears the other text elements\n                                        searchels[i].text = ''\n    return newdocument"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the raw text of a document as a list of paragraphs.", "response": "def getdocumenttext(document):\n    '''Return the raw text of a document, as a list of paragraphs.'''\n    paratextlist = []\n    # Compile a list of all paragraph (p) elements\n    paralist = []\n    for element in document.iter():\n        # Find p (paragraph) elements\n        if element.tag == '{'+nsprefixes['w']+'}p':\n            paralist.append(element)\n    # Since a single sentence might be spread over multiple text elements,\n    # iterate through each paragraph, appending all text (t) children to that\n    # paragraphs text.\n    for para in paralist:\n        paratext = u''\n        # Loop through each paragraph\n        for element in para.iter():\n            # Find t (text) elements\n            if element.tag == '{'+nsprefixes['w']+'}t':\n                if element.text:\n                    paratext = paratext+element.text\n            elif element.tag == '{'+nsprefixes['w']+'}tab':\n                paratext = paratext + '\\t'\n        # Add our completed paragraph text to the list of paragraph text\n        if not len(paratext) == 0:\n            paratextlist.append(paratext)\n    return paratextlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coreproperties(title, subject, creator, keywords, lastmodifiedby=None):\n    coreprops = makeelement('coreProperties', nsprefix='cp')\n    coreprops.append(makeelement('title', tagtext=title, nsprefix='dc'))\n    coreprops.append(makeelement('subject', tagtext=subject, nsprefix='dc'))\n    coreprops.append(makeelement('creator', tagtext=creator, nsprefix='dc'))\n    coreprops.append(makeelement('keywords', tagtext=','.join(keywords),\n                     nsprefix='cp'))\n    if not lastmodifiedby:\n        lastmodifiedby = creator\n    coreprops.append(makeelement('lastModifiedBy', tagtext=lastmodifiedby,\n                     nsprefix='cp'))\n    coreprops.append(makeelement('revision', tagtext='1', nsprefix='cp'))\n    coreprops.append(\n        makeelement('category', tagtext='Examples', nsprefix='cp'))\n    coreprops.append(\n        makeelement('description', tagtext='Examples', nsprefix='dc'))\n    currenttime = time.strftime('%Y-%m-%dT%H:%M:%SZ')\n    # Document creation and modify times\n    # Prob here: we have an attribute who name uses one namespace, and that\n    # attribute's value uses another namespace.\n    # We're creating the element from a string as a workaround...\n    for doctime in ['created', 'modified']:\n        elm_str = (\n            '<dcterms:%s xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instanc'\n            'e\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xsi:type=\"dcterms:'\n            'W3CDTF\">%s</dcterms:%s>'\n        ) % (doctime, currenttime, doctime)\n        coreprops.append(etree.fromstring(elm_str))\n    return coreprops", "response": "Create a core properties element for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate app - specific properties.", "response": "def appproperties():\n    \"\"\"\n    Create app-specific properties. See docproperties() for more common\n    document properties.\n\n    \"\"\"\n    appprops = makeelement('Properties', nsprefix='ep')\n    appprops = etree.fromstring(\n        '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><Properties x'\n        'mlns=\"http://schemas.openxmlformats.org/officeDocument/2006/extended'\n        '-properties\" xmlns:vt=\"http://schemas.openxmlformats.org/officeDocum'\n        'ent/2006/docPropsVTypes\"></Properties>')\n    props =\\\n        {'Template':             'Normal.dotm',\n         'TotalTime':            '6',\n         'Pages':                '1',\n         'Words':                '83',\n         'Characters':           '475',\n         'Application':          'Microsoft Word 12.0.0',\n         'DocSecurity':          '0',\n         'Lines':                '12',\n         'Paragraphs':           '8',\n         'ScaleCrop':            'false',\n         'LinksUpToDate':        'false',\n         'CharactersWithSpaces': '583',\n         'SharedDoc':            'false',\n         'HyperlinksChanged':    'false',\n         'AppVersion':           '12.0000'}\n    for prop in props:\n        appprops.append(makeelement(prop, tagtext=props[prop], nsprefix=None))\n    return appprops"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wordrelationships(relationshiplist):\n    '''Generate a Word relationships file'''\n    # Default list of relationships\n    # FIXME: using string hack instead of making element\n    #relationships = makeelement('Relationships', nsprefix='pr')\n    relationships = etree.fromstring(\n        '<Relationships xmlns=\"http://schemas.openxmlformats.org/package/2006'\n        '/relationships\"></Relationships>')\n    count = 0\n    for relationship in relationshiplist:\n        # Relationship IDs (rId) start at 1.\n        rel_elm = makeelement('Relationship', nsprefix=None,\n                              attributes={'Id':     'rId'+str(count+1),\n                                          'Type':   relationship[0],\n                                          'Target': relationship[1]}\n                              )\n        relationships.append(rel_elm)\n        count += 1\n    return relationships", "response": "Generate a Word relationships file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef savedocx(\n        document, coreprops, appprops, contenttypes, websettings,\n        wordrelationships, output, imagefiledict=None):\n    \"\"\"\n    Save a modified document\n    \"\"\"\n    if imagefiledict is None:\n        warn(\n            'Using savedocx() without imagefiledict parameter will be deprec'\n            'ated in the future.', PendingDeprecationWarning\n        )\n\n    assert os.path.isdir(template_dir)\n    docxfile = zipfile.ZipFile(\n        output, mode='w', compression=zipfile.ZIP_DEFLATED)\n\n    # Move to the template data path\n    prev_dir = os.path.abspath('.')  # save previous working dir\n    os.chdir(template_dir)\n\n    # Serialize our trees into out zip file\n    treesandfiles = {\n        document:          'word/document.xml',\n        coreprops:         'docProps/core.xml',\n        appprops:          'docProps/app.xml',\n        contenttypes:      '[Content_Types].xml',\n        websettings:       'word/webSettings.xml',\n        wordrelationships: 'word/_rels/document.xml.rels'\n    }\n    for tree in treesandfiles:\n        log.info('Saving: %s' % treesandfiles[tree])\n        treestring = etree.tostring(tree, pretty_print=True)\n        docxfile.writestr(treesandfiles[tree], treestring)\n\n    # Add & compress images, if applicable\n    if imagefiledict is not None:\n        for imagepath, picrelid in imagefiledict.items():\n            archivename = 'word/media/%s_%s' % (picrelid, basename(imagepath))\n            log.info('Saving: %s', archivename)\n            docxfile.write(imagepath, archivename)\n\n    # Add & compress support files\n    files_to_ignore = ['.DS_Store']  # nuisance from some os's\n    for dirpath, dirnames, filenames in os.walk('.'):\n        for filename in filenames:\n            if filename in files_to_ignore:\n                continue\n            templatefile = join(dirpath, filename)\n            archivename = templatefile[2:]\n            log.info('Saving: %s', archivename)\n            docxfile.write(templatefile, archivename)\n\n    log.info('Saved new file to: %r', output)\n    docxfile.close()\n    os.chdir(prev_dir)  # restore previous working dir\n    return", "response": "Save a modified document into a zip file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_json_converters(encode, decode):\n    ret = _LCB._modify_helpers(json_encode=encode, json_decode=decode)\n    return (ret['json_encode'], ret['json_decode'])", "response": "Modify the default JSON conversion functions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_pickle_converters(encode, decode):\n    ret = _LCB._modify_helpers(pickle_encode=encode, pickle_decode=decode)\n    return (ret['pickle_encode'], ret['pickle_decode'])", "response": "Modify the default Pickle conversion functions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, key, value, ttl=0, format=None, persist_to=0, replicate_to=0):\n        return _Base.insert(self, key, value, ttl=ttl, format=format,\n                            persist_to=persist_to, replicate_to=replicate_to)", "response": "Store an object in Couchbase unless it already exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepend(self, key, value, cas=0, format=None,\n                persist_to=0, replicate_to=0):\n        \"\"\"Prepend a string to an existing value in Couchbase.\n\n        .. seealso:: :meth:`append`, :meth:`prepend_multi`\n        \"\"\"\n        return _Base.prepend(self, key, value, cas=cas, format=format,\n                             persist_to=persist_to, replicate_to=replicate_to)", "response": "Prepend a string to an existing value in Couchbase."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves an object stored in Couchbase by given key.", "response": "def get(self, key, ttl=0, quiet=None, replica=False, no_format=False):\n        \"\"\"Obtain an object stored in Couchbase by given key.\n\n        :param string key: The key to fetch. The type of key is the same\n            as mentioned in :meth:`upsert`\n\n        :param int ttl: If specified, indicates that the key's expiration\n            time should be *modified* when retrieving the value.\n\n        :param boolean quiet: causes `get` to return None instead of\n            raising an exception when the key is not found. It defaults\n            to the value set by :attr:`~quiet` on the instance. In\n            `quiet` mode, the error may still be obtained by inspecting\n            the :attr:`~.Result.rc` attribute of the :class:`.Result`\n            object, or checking :attr:`.Result.success`.\n\n            Note that the default value is `None`, which means to use\n            the :attr:`quiet`. If it is a boolean (i.e. `True` or\n            `False`) it will override the `couchbase.bucket.Bucket`-level\n            :attr:`quiet` attribute.\n\n        :param bool replica: Whether to fetch this key from a replica\n            rather than querying the master server. This is primarily\n            useful when operations with the master fail (possibly due to\n            a configuration change). It should normally be used in an\n            exception handler like so\n\n            Using the ``replica`` option::\n\n                try:\n                    res = c.get(\"key\", quiet=True) # suppress not-found errors\n                catch CouchbaseError:\n                    res = c.get(\"key\", replica=True, quiet=True)\n\n        :param bool no_format: If set to ``True``, then the value will\n            always be delivered in the :class:`~couchbase.result.Result`\n            object as being of :data:`~couchbase.FMT_BYTES`. This is a\n            item-local equivalent of using the :attr:`data_passthrough`\n            option\n\n        :raise: :exc:`.NotFoundError` if the key does not exist\n        :raise: :exc:`.CouchbaseNetworkError`\n        :raise: :exc:`.ValueFormatError` if the value cannot be\n            deserialized with chosen decoder, e.g. if you try to\n            retreive an object stored with an unrecognized format\n        :return: A :class:`~.Result` object\n\n        Simple get::\n\n            value = cb.get('key').value\n\n        Get multiple values::\n\n            cb.get_multi(['foo', 'bar'])\n            # { 'foo' : <Result(...)>, 'bar' : <Result(...)> }\n\n        Inspect the flags::\n\n            rv = cb.get(\"key\")\n            value, flags, cas = rv.value, rv.flags, rv.cas\n\n        Update the expiration time::\n\n            rv = cb.get(\"key\", ttl=10)\n            # Expires in ten seconds\n\n        .. seealso:: :meth:`get_multi`\n        \"\"\"\n\n        return _Base.get(self, key, ttl=ttl, quiet=quiet,\n                         replica=replica, no_format=no_format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef touch(self, key, ttl=0):\n        return _Base.touch(self, key, ttl=ttl)", "response": "Update a key s expiration time and return the new expiration time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self, key, ttl=0):\n        return _Base.lock(self, key, ttl=ttl)", "response": "Lock and retrieve a key - value entry in Couchbase."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unlock(self, key, cas):\n        return _Base.unlock(self, key, cas=cas)", "response": "Unlock a Locked Key in Couchbase."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, key, cas=0, quiet=None, persist_to=0, replicate_to=0):\n        return _Base.remove(self, key, cas=cas, quiet=quiet,\n                            persist_to=persist_to, replicate_to=replicate_to)", "response": "Removes the key - value entry for a given key in Couchbase."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nincrement or decrement the numeric value of an item in the given key.", "response": "def counter(self, key, delta=1, initial=None, ttl=0):\n        \"\"\"Increment or decrement the numeric value of an item.\n\n        This method instructs the server to treat the item stored under\n        the given key as a numeric counter.\n\n        Counter operations require that the stored value\n        exists as a string representation of a number (e.g. ``123``). If\n        storing items using the :meth:`upsert` family of methods, and\n        using the default :const:`couchbase.FMT_JSON` then the value\n        will conform to this constraint.\n\n        :param string key: A key whose counter value is to be modified\n        :param int delta: an amount by which the key should be modified.\n            If the number is negative then this number will be\n            *subtracted* from the current value.\n        :param initial: The initial value for the key, if it does not\n            exist. If the key does not exist, this value is used, and\n            `delta` is ignored. If this parameter is `None` then no\n            initial value is used\n        :type initial: int or `None`\n        :param int ttl: The lifetime for the key, after which it will\n            expire\n        :raise: :exc:`.NotFoundError` if the key does not exist on the\n            bucket (and `initial` was `None`)\n        :raise: :exc:`.DeltaBadvalError` if the key exists, but the\n            existing value is not numeric\n        :return: A :class:`.Result` object. The current value of the\n            counter may be obtained by inspecting the return value's\n            `value` attribute.\n\n        Simple increment::\n\n            rv = cb.counter(\"key\")\n            rv.value\n            # 42\n\n        Increment by 10::\n\n            rv = cb.counter(\"key\", delta=10)\n\n        Decrement by 5::\n\n            rv = cb.counter(\"key\", delta=-5)\n\n        Increment by 20, set initial value to 5 if it does not exist::\n\n            rv = cb.counter(\"key\", delta=20, initial=5)\n\n        Increment three keys::\n\n            kv = cb.counter_multi([\"foo\", \"bar\", \"baz\"])\n            for key, result in kv.items():\n                print \"Key %s has value %d now\" % (key, result.value)\n\n        .. seealso:: :meth:`counter_multi`\n        \"\"\"\n        return _Base.counter(self, key, delta=delta, initial=initial, ttl=ttl)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mutate_in(self, key, *specs, **kwargs):\n\n        # Note we don't verify the validity of the options. lcb does that for\n        # us.\n        sdflags = kwargs.pop('_sd_doc_flags', 0)\n\n        if kwargs.pop('insert_doc', False):\n            sdflags |= _P.CMDSUBDOC_F_INSERT_DOC\n        if kwargs.pop('upsert_doc', False):\n            sdflags |= _P.CMDSUBDOC_F_UPSERT_DOC\n\n        kwargs['_sd_doc_flags'] = sdflags\n        return super(Bucket, self).mutate_in(key, specs, **kwargs)", "response": "Perform multiple atomic modifications within a document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lookup_in(self, key, *specs, **kwargs):\n        return super(Bucket, self).lookup_in({key: specs}, **kwargs)", "response": "Atomically retrieve one or more paths from a document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_in(self, key, *paths, **kwargs):\n        import couchbase.subdocument as SD\n        return self.lookup_in(key, *tuple(SD.get(x) for x in paths), **kwargs)", "response": "Atomically fetch one or more paths from a document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats(self, keys=None, keystats=False):\n        if keys and not isinstance(keys, (tuple, list)):\n            keys = (keys,)\n        return self._stats(keys, keystats=keystats)", "response": "Request server statistics.\n\n        Fetches stats from each node in the cluster. Without a key\n        specified the server will respond with a default set of\n        statistical information. It returns the a `dict` with stats keys\n        and node-value pairs as a value.\n\n        :param keys: One or several stats to query\n        :type keys: string or list of string\n        :raise: :exc:`.CouchbaseNetworkError`\n        :return: `dict` where keys are stat keys and values are\n            host-value pairs\n\n        Find out how many items are in the bucket::\n\n            total = 0\n            for key, value in cb.stats()['total_items'].items():\n                total += value\n\n        Get memory stats (works on couchbase buckets)::\n\n            cb.stats('memory')\n            # {'mem_used': {...}, ...}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef observe(self, key, master_only=False):\n        return _Base.observe(self, key, master_only=master_only)", "response": "Return the storage information for a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef endure(self, key, persist_to=-1, replicate_to=-1, cas=0,\n               check_removed=False, timeout=5.0, interval=0.010):\n        \"\"\"Wait until a key has been distributed to one or more nodes\n\n        By default, when items are stored to Couchbase, the operation is\n        considered successful if the vBucket master (i.e. the \"primary\"\n        node) for the key has successfully stored the item in its\n        memory.\n\n        In most situations, this is sufficient to assume that the item\n        has successfully been stored. However the possibility remains\n        that the \"master\" server will go offline as soon as it sends\n        back the successful response and the data is lost.\n\n        The ``endure`` function allows you to provide stricter criteria\n        for success. The criteria may be expressed in terms of number of\n        nodes for which the item must exist in that node's RAM and/or on\n        that node's disk. Ensuring that an item exists in more than one\n        place is a safer way to guarantee against possible data loss.\n\n        We call these requirements `Durability Constraints`, and thus\n        the method is called `endure`.\n\n        :param string key: The key to endure.\n        :param int persist_to: The minimum number of nodes which must\n            contain this item on their disk before this function\n            returns. Ensure that you do not specify too many nodes;\n            otherwise this function will fail. Use the\n            :attr:`server_nodes` to determine how many nodes exist in\n            the cluster.\n\n            The maximum number of nodes an item can reside on is\n            currently fixed to 4 (i.e. the \"master\" node, and up to\n            three \"replica\" nodes). This limitation is current as of\n            Couchbase Server version 2.1.0.\n\n            If this parameter is set to a negative value, the maximum\n            number of possible nodes the key can reside on will be used.\n\n        :param int replicate_to: The minimum number of replicas which\n            must contain this item in their memory for this method to\n            succeed. As with ``persist_to``, you may specify a negative\n            value in which case the requirement will be set to the\n            maximum number possible.\n\n        :param float timeout: A timeout value in seconds before this\n            function fails with an exception. Typically it should take\n            no longer than several milliseconds on a functioning cluster\n            for durability requirements to be satisfied (unless\n            something has gone wrong).\n\n        :param float interval: The polling interval in seconds to use\n            for checking the key status on the respective nodes.\n            Internally, ``endure`` is implemented by polling each server\n            individually to see if the key exists on that server's disk\n            and memory. Once the status request is sent to all servers,\n            the client will check if their replies are satisfactory; if\n            they are then this function succeeds, otherwise the client\n            will wait a short amount of time and try again. This\n            parameter sets this \"wait time\".\n\n        :param bool check_removed: This flag inverts the check. Instead\n            of checking that a given key *exists* on the nodes, this\n            changes the behavior to check that the key is *removed* from\n            the nodes.\n\n        :param long cas: The CAS value to check against. It is possible\n            for an item to exist on a node but have a CAS value from a\n            prior operation. Passing the CAS ensures that only replies\n            from servers with a CAS matching this parameter are accepted.\n\n        :return: A :class:`~.OperationResult`\n        :raise: see :meth:`upsert` and :meth:`get` for possible errors\n\n        .. seealso:: :meth:`upsert`, :meth:`endure_multi`\n        \"\"\"\n        # We really just wrap 'endure_multi'\n        kv = {key: cas}\n        rvs = self.endure_multi(keys=kv, persist_to=persist_to,\n                                replicate_to=replicate_to,\n                                check_removed=check_removed, timeout=timeout,\n                                interval=interval)\n        return rvs[key]", "response": "This method is used to endure a key in the vBucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef durability(self, persist_to=-1, replicate_to=-1, timeout=0.0):\n        return DurabilityContext(self, persist_to, replicate_to, timeout)", "response": "Returns a new context manager which will apply the given persistence and replication settings to all active mutation operations when the given ttl is reached."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upsert_multi(self, keys, ttl=0, format=None, persist_to=0, replicate_to=0):\n        return _Base.upsert_multi(self, keys, ttl=ttl, format=format,\n                                  persist_to=persist_to,\n                                  replicate_to=replicate_to)", "response": "Write multiple items to the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_multi(self, keys, ttl=0, format=None, persist_to=0, replicate_to=0):\n        return _Base.insert_multi(self, keys, ttl=ttl, format=format,\n                                  persist_to=persist_to,\n                                  replicate_to=replicate_to)", "response": "Add multiple keys. Multi variant of :meth:`insert`\n\n        .. seealso:: :meth:`insert`, :meth:`upsert_multi`, :meth:`upsert`"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_multi(self, keys, ttl=0, format=None,\n                      persist_to=0, replicate_to=0):\n        \"\"\"Replace multiple keys. Multi variant of :meth:`replace`\n\n        .. seealso:: :meth:`replace`, :meth:`upsert_multi`, :meth:`upsert`\n        \"\"\"\n        return _Base.replace_multi(self, keys, ttl=ttl, format=format,\n                                   persist_to=persist_to,\n                                   replicate_to=replicate_to)", "response": "Replace multiple keys. Multi variant of :meth:`replace`\n\n        .. seealso:: :meth:`replace`, :meth:`upsert_multi`, :meth:`upsert`"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append_multi(self, keys, format=None, persist_to=0, replicate_to=0):\n        return _Base.append_multi(self, keys, format=format,\n                                  persist_to=persist_to,\n                                  replicate_to=replicate_to)", "response": "Append to multiple keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_multi(self, keys, ttl=0, quiet=None, replica=False, no_format=False):\n        return _Base.get_multi(self, keys, ttl=ttl, quiet=quiet,\n                               replica=replica, no_format=no_format)", "response": "Get multiple keys. Multi variant of get."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef touch_multi(self, keys, ttl=0):\n        return _Base.touch_multi(self, keys, ttl=ttl)", "response": "Touch multiple keys. Multi variant of :meth:`touch`\n\n        :param keys: the keys to touch\n        :type keys: :ref:`iterable<argtypes>`.\n            ``keys`` can also be a dictionary with values being\n            integers, in which case the value for each key will be used\n            as the TTL instead of the global one (i.e. the one passed to\n            this function)\n        :param int ttl: The new expiration time\n        :return: A :class:`~.MultiResult` object\n\n        Update three keys to expire in 10 seconds ::\n\n            cb.touch_multi((\"key1\", \"key2\", \"key3\"), ttl=10)\n\n        Update three keys with different expiration times ::\n\n            cb.touch_multi({\"foo\" : 1, \"bar\" : 5, \"baz\" : 10})\n\n        .. seealso:: :meth:`touch`"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lock_multi(self, keys, ttl=0):\n        return _Base.lock_multi(self, keys, ttl=ttl)", "response": "Lock multiple keys. Multi variant of :meth:`lock`\n\n        :param keys: the keys to lock\n        :type keys: :ref:`iterable<argtypes>`\n        :param int ttl: The lock timeout for all keys\n\n        :return: a :class:`~.MultiResult` object\n\n        .. seealso:: :meth:`lock`"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenduring a set of keys in a multi - operation operation.", "response": "def endure_multi(self, keys, persist_to=-1, replicate_to=-1,\n                     timeout=5.0, interval=0.010, check_removed=False):\n        \"\"\"Check durability requirements for multiple keys\n\n        :param keys: The keys to check\n\n        The type of keys may be one of the following:\n            * Sequence of keys\n            * A :class:`~couchbase.result.MultiResult` object\n            * A ``dict`` with CAS values as the dictionary value\n            * A sequence of :class:`~couchbase.result.Result` objects\n\n        :return: A :class:`~.MultiResult` object\n            of :class:`~.OperationResult` items.\n\n        .. seealso:: :meth:`endure`\n        \"\"\"\n        return _Base.endure_multi(self, keys, persist_to=persist_to,\n                                  replicate_to=replicate_to,\n                                  timeout=timeout, interval=interval,\n                                  check_removed=check_removed)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving multiple items from the cluster.", "response": "def remove_multi(self, kvs, quiet=None):\n        \"\"\"Remove multiple items from the cluster\n\n        :param kvs: Iterable of keys to delete from the cluster. If you wish\n            to specify a CAS for each item, then you may pass a dictionary\n            of keys mapping to cas, like `remove_multi({k1:cas1, k2:cas2}`)\n        :param quiet: Whether an exception should be raised if one or more\n            items were not found\n        :return: A :class:`~.MultiResult` containing :class:`~.OperationResult`\n            values.\n        \"\"\"\n        return _Base.remove_multi(self, kvs, quiet=quiet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef counter_multi(self, kvs, initial=None, delta=1, ttl=0):\n        return _Base.counter_multi(self, kvs, initial=initial, delta=delta,\n                                   ttl=ttl)", "response": "Perform counter operations on multiple items in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an item from a replica node.", "response": "def rget(self, key, replica_index=None, quiet=None):\n        \"\"\"Get an item from a replica node\n\n        :param string key: The key to fetch\n        :param int replica_index: The replica index to fetch.\n            If this is ``None`` then this method will return once any\n            replica responds. Use :attr:`configured_replica_count` to\n            figure out the upper bound for this parameter.\n\n            The value for this parameter must be a number between 0 and\n            the value of :attr:`configured_replica_count`-1.\n        :param boolean quiet: Whether to suppress errors when the key is\n            not found\n\n        This method (if `replica_index` is not supplied) functions like\n        the :meth:`get` method that has been passed the `replica`\n        parameter::\n\n            c.get(key, replica=True)\n\n        .. seealso:: :meth:`get` :meth:`rget_multi`\n        \"\"\"\n        if replica_index is not None:\n            return _Base._rgetix(self, key, replica=replica_index, quiet=quiet)\n        else:\n            return _Base._rget(self, key, quiet=quiet)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _view(self, ddoc, view,\n              use_devmode=False,\n              params=None,\n              unrecognized_ok=False,\n              passthrough=False):\n        \"\"\"Internal method to Execute a view (MapReduce) query\n\n        :param string ddoc: Name of the design document\n        :param string view: Name of the view function to execute\n        :param params: Extra options to pass to the view engine\n        :type params: string or dict\n        :return: a :class:`~couchbase.result.HttpResult` object.\n        \"\"\"\n\n        if params:\n            if not isinstance(params, str):\n                params = make_options_string(\n                    params,\n                    unrecognized_ok=unrecognized_ok,\n                    passthrough=passthrough)\n        else:\n            params = \"\"\n\n        ddoc = self._mk_devmode(ddoc, use_devmode)\n        url = make_dvpath(ddoc, view) + params\n\n        ret = self._http_request(type=_LCB.LCB_HTTP_TYPE_VIEW,\n                                 path=url,\n                                 method=_LCB.LCB_HTTP_METHOD_GET,\n                                 response_format=FMT_JSON)\n        return ret", "response": "Execute a view on the specified design document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries a specific MapReduce view on the cluster.", "response": "def query(self, design, view, use_devmode=False, **kwargs):\n        \"\"\"\n        Query a pre-defined MapReduce view, passing parameters.\n\n        This method executes a view on the cluster. It accepts various\n        parameters for the view and returns an iterable object\n        (specifically, a :class:`~.View`).\n\n        :param string design: The design document\n        :param string view: The view function contained within the design\n            document\n        :param boolean use_devmode: Whether the view name should be\n            transformed into a development-mode view. See documentation\n            on :meth:`~.BucketManager.design_create` for more\n            explanation.\n        :param kwargs: Extra arguments passed to the :class:`~.View`\n            object constructor.\n        :param kwargs: Additional parameters passed to the\n            :class:`~.View` constructor. See that class'\n            documentation for accepted parameters.\n\n        .. seealso::\n\n            :class:`~.View`\n                contains more extensive documentation and examples\n\n            :class:`couchbase.views.params.Query`\n                contains documentation on the available query options\n\n            :class:`~.SpatialQuery`\n                contains documentation on the available query options\n                for Geospatial views.\n\n        .. note::\n\n            To query a spatial view, you must explicitly use the\n            :class:`.SpatialQuery`. Passing key-value view parameters\n            in ``kwargs`` is not supported for spatial views.\n\n        \"\"\"\n        design = self._mk_devmode(design, use_devmode)\n        itercls = kwargs.pop('itercls', View)\n        return itercls(self, design, view, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a N1QL query and return a generator which yields rows.", "response": "def n1ql_query(self, query, *args, **kwargs):\n        \"\"\"\n        Execute a N1QL query.\n\n        This method is mainly a wrapper around the :class:`~.N1QLQuery`\n        and :class:`~.N1QLRequest` objects, which contain the inputs\n        and outputs of the query.\n\n        Using an explicit :class:`~.N1QLQuery`::\n\n            query = N1QLQuery(\n                'SELECT airportname FROM `travel-sample` WHERE city=$1', \"Reno\")\n            # Use this option for often-repeated queries\n            query.adhoc = False\n            for row in cb.n1ql_query(query):\n                print 'Name: {0}'.format(row['airportname'])\n\n        Using an implicit :class:`~.N1QLQuery`::\n\n            for row in cb.n1ql_query(\n                'SELECT airportname, FROM `travel-sample` WHERE city=\"Reno\"'):\n                print 'Name: {0}'.format(row['airportname'])\n\n        With the latter form, *args and **kwargs are forwarded to the\n        N1QL Request constructor, optionally selected in kwargs['iterclass'],\n        otherwise defaulting to :class:`~.N1QLRequest`.\n\n        :param query: The query to execute. This may either be a\n            :class:`.N1QLQuery` object, or a string (which will be\n            implicitly converted to one).\n        :param kwargs: Arguments for :class:`.N1QLRequest`.\n        :return: An iterator which yields rows. Each row is a dictionary\n            representing a single result\n        \"\"\"\n        if not isinstance(query, N1QLQuery):\n            query = N1QLQuery(query)\n\n        itercls = kwargs.pop('itercls', N1QLRequest)\n        return itercls(query, self, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef analytics_query(self, query, host, *args, **kwargs):\n        if not isinstance(query, AnalyticsQuery):\n            query = AnalyticsQuery(query, *args, **kwargs)\n        else:\n            query.update(*args, **kwargs)\n\n        return couchbase.analytics.gen_request(query, host, self)", "response": "Execute an Analytics query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, index, query, **kwargs):\n        itercls = kwargs.pop('itercls', _FTS.SearchRequest)\n        iterargs = itercls.mk_kwargs(kwargs)\n        params = kwargs.pop('params', _FTS.Params(**kwargs))\n        body = _FTS.make_search_body(index, query, params)\n        return itercls(body, self, **iterargs)", "response": "Perform full - text search of the specified index."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append_items(self, items, **kwargs):\n        rv = self.append_multi(items, **kwargs)\n        # Assume this is an 'ItemOptionDict'\n        for k, v in items.dict.items():\n            if k.success:\n                k.value += v['fragment']\n\n        return rv", "response": "Method to append items to multiple items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn whether SSL is used for this connection.", "response": "def is_ssl(self):\n        \"\"\"\n        Read-only boolean property indicating whether SSL is used for\n        this connection.\n\n        If this property is true, then all communication between this\n        object and the Couchbase cluster is encrypted using SSL.\n\n        See :meth:`__init__` for more information on connection options.\n        \"\"\"\n        mode = self._cntl(op=_LCB.LCB_CNTL_SSL_MODE, value_type='int')\n        return mode & _LCB.LCB_SSL_ENABLED != 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the wrappers for all the memcached operations.", "response": "def _gen_memd_wrappers(cls, factory):\n        \"\"\"Generates wrappers for all the memcached operations.\n        :param factory: A function to be called to return the wrapped\n            method. It will be called with two arguments; the first is\n            the unbound method being wrapped, and the second is the name\n            of such a method.\n\n          The factory shall return a new unbound method\n\n        :return: A dictionary of names mapping the API calls to the\n            wrapped functions\n        \"\"\"\n        d = {}\n        for n in cls._MEMCACHED_OPERATIONS:\n            for variant in (n, n + \"_multi\"):\n                try:\n                    d[variant] = factory(getattr(cls, variant), variant)\n                except AttributeError:\n                    if n in cls._MEMCACHED_NOMULTI:\n                        continue\n                    raise\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclears the bucket's contents. .. note:: This functionality requires that the flush option be enabled for the bucket by the cluster administrator. You can enable flush on the bucket using the administrative console (See http://docs.couchbase.com/admin/admin/UI/ui-data-buckets.html) .. note:: This is a destructive operation, as it will clear all the data from the bucket. .. note:: A successful execution of this method means that the bucket will have started the flush process. This does not necessarily mean that the bucket is actually empty.", "response": "def flush(self):\n        \"\"\"\n        Clears the bucket's contents.\n\n        .. note::\n\n            This functionality requires that the flush option be\n            enabled for the bucket by the cluster administrator. You\n            can enable flush on the bucket using the administrative\n            console (See http://docs.couchbase.com/admin/admin/UI/ui-data-buckets.html)\n\n        .. note::\n\n            This is a destructive operation, as it will clear all the\n            data from the bucket.\n\n        .. note::\n\n            A successful execution of this method means that the bucket\n            will have started the flush process. This does not\n            necessarily mean that the bucket is actually empty.\n        \"\"\"\n        path = '/pools/default/buckets/{0}/controller/doFlush'\n        path = path.format(self.bucket)\n        return self._http_request(type=_LCB.LCB_HTTP_TYPE_MANAGEMENT,\n                                  path=path, method=_LCB.LCB_HTTP_METHOD_POST)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a value to a key in a map.", "response": "def map_add(self, key, mapkey, value, create=False, **kwargs):\n        \"\"\"\n        Set a value for a key in a map.\n\n        .. warning::\n\n            The functionality of the various `map_*`, `list_*`, `queue_*`\n            and `set_*` functions are considered experimental and are included\n            in the library to demonstrate new functionality.\n            They may change in the future or be removed entirely!\n\n            These functions are all wrappers around the :meth:`mutate_in` or\n            :meth:`lookup_in` methods.\n\n        :param key: The document ID of the map\n        :param mapkey: The key in the map to set\n        :param value: The value to use (anything serializable to JSON)\n        :param create: Whether the map should be created if it does not exist\n        :param kwargs: Additional arguments passed to :meth:`mutate_in`\n        :return: A :class:`~.OperationResult`\n        :raise: :cb_exc:`NotFoundError` if the document does not exist.\n            and `create` was not specified\n\n        .. Initialize a map and add a value\n\n            cb.upsert('a_map', {})\n            cb.map_add('a_map', 'some_key', 'some_value')\n            cb.map_get('a_map', 'some_key').value  # => 'some_value'\n            cb.get('a_map').value  # => {'some_key': 'some_value'}\n\n        \"\"\"\n        op = SD.upsert(mapkey, value)\n        sdres = self.mutate_in(key, op, **kwargs)\n        return self._wrap_dsop(sdres)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_get(self, key, mapkey):\n        op = SD.get(mapkey)\n        sdres = self.lookup_in(key, op)\n        return self._wrap_dsop(sdres, True)", "response": "Retrieve a value from a map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_remove(self, key, mapkey, **kwargs):\n        op = SD.remove(mapkey)\n        sdres = self.mutate_in(key, op, **kwargs)\n        return self._wrap_dsop(sdres)", "response": "Remove an item from a map."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_size(self, key):\n        # TODO: This should use get_count, but we need to check for compat\n        # with server version (i.e. >= 4.6) first; otherwise it just\n        # disconnects.\n\n        rv = self.get(key)\n        return len(rv.value)", "response": "Get the number of items in the map."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_append(self, key, value, create=False, **kwargs):\n        op = SD.array_append('', value)\n        sdres = self.mutate_in(key, op, **kwargs)\n        return self._wrap_dsop(sdres)", "response": "Adds an item to the end of a list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an item to the beginning of a list.", "response": "def list_prepend(self, key, value, create=False, **kwargs):\n        \"\"\"\n        Add an item to the beginning of a list.\n\n        :param str key: Document ID\n        :param value: Value to prepend\n        :param bool create:\n            Whether the list should be created if it does not exist\n        :param kwargs: Additional arguments to :meth:`mutate_in`.\n        :return: :class:`OperationResult`.\n        :raise: :cb_exc:`NotFoundError` if the document does not exist.\n            and `create` was not specified.\n\n        This function is identical to :meth:`list_append`, except for prepending\n        rather than appending the item\n\n        .. seealso:: :meth:`list_append`, :meth:`map_add`\n        \"\"\"\n        op = SD.array_prepend('', value)\n        sdres = self.mutate_in(key, op, **kwargs)\n        return self._wrap_dsop(sdres)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset an item within a list at a given position.", "response": "def list_set(self, key, index, value, **kwargs):\n        \"\"\"\n        Sets an item within a list at a given position.\n\n        :param key: The key of the document\n        :param index: The position to replace\n        :param value: The value to be inserted\n        :param kwargs: Additional arguments to :meth:`mutate_in`\n        :return: :class:`OperationResult`\n        :raise: :cb_exc:`NotFoundError` if the list does not exist\n        :raise: :exc:`IndexError` if the index is out of bounds\n\n        example::\n\n            cb.upsert('a_list', ['hello', 'world'])\n            cb.list_set('a_list', 1, 'good')\n            cb.get('a_list').value # => ['hello', 'good']\n\n        .. seealso:: :meth:`map_add`, :meth:`list_append`\n        \"\"\"\n        op = SD.replace('[{0}]'.format(index), value)\n        sdres = self.mutate_in(key, op, **kwargs)\n        return self._wrap_dsop(sdres)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an item to a set if the item does not yet exist.", "response": "def set_add(self, key, value, create=False, **kwargs):\n        \"\"\"\n        Add an item to a set if the item does not yet exist.\n\n        :param key: The document ID\n        :param value: Value to add\n        :param create: Create the set if it does not exist\n        :param kwargs: Arguments to :meth:`mutate_in`\n        :return: A :class:`~.OperationResult` if the item was added,\n        :raise: :cb_exc:`NotFoundError` if the document does not exist\n            and `create` was not specified.\n\n        .. seealso:: :meth:`map_add`\n        \"\"\"\n        op = SD.array_addunique('', value)\n        try:\n            sdres = self.mutate_in(key, op, **kwargs)\n            return self._wrap_dsop(sdres)\n        except E.SubdocPathExistsError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an item from a set.", "response": "def set_remove(self, key, value, **kwargs):\n        \"\"\"\n        Remove an item from a set.\n\n        :param key: The docuent ID\n        :param value: Value to remove\n        :param kwargs: Arguments to :meth:`mutate_in`\n        :return: A :class:`OperationResult` if the item was removed, false\n                 otherwise\n        :raise: :cb_exc:`NotFoundError` if the set does not exist.\n\n        .. seealso:: :meth:`set_add`, :meth:`map_add`\n        \"\"\"\n        while True:\n            rv = self.get(key)\n            try:\n                ix = rv.value.index(value)\n                kwargs['cas'] = rv.cas\n                return self.list_remove(key, ix, **kwargs)\n            except E.KeyExistsError:\n                pass\n            except ValueError:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_contains(self, key, value):\n        rv = self.get(key)\n        return value in rv.value", "response": "Determines if an item exists in a set containing the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the element at a specific index from a list.", "response": "def list_remove(self, key, index, **kwargs):\n        \"\"\"\n        Remove the element at a specific index from a list.\n\n        :param key: The document ID of the list\n        :param index: The index to remove\n        :param kwargs: Arguments to :meth:`mutate_in`\n        :return: :class:`OperationResult`\n        :raise: :exc:`IndexError` if the index does not exist\n        :raise: :cb_exc:`NotFoundError` if the list does not exist\n        \"\"\"\n        return self.map_remove(key, '[{0}]'.format(index), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an item to the end of a queue.", "response": "def queue_push(self, key, value, create=False, **kwargs):\n        \"\"\"\n        Add an item to the end of a queue.\n\n        :param key: The document ID of the queue\n        :param value: The item to add to the queue\n        :param create: Whether the queue should be created if it does not exist\n        :param kwargs: Arguments to pass to :meth:`mutate_in`\n        :return: :class:`OperationResult`\n        :raise: :cb_exc:`NotFoundError` if the queue does not exist and\n            `create` was not specified.\n\n        example::\n\n            # Ensure it's removed first\n\n            cb.remove('a_queue')\n            cb.queue_push('a_queue', 'job9999', create=True)\n            cb.queue_pop('a_queue').value  # => job9999\n        \"\"\"\n        return self.list_prepend(key, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving and returns the first item in the queue.", "response": "def queue_pop(self, key, **kwargs):\n        \"\"\"\n        Remove and return the first item queue.\n\n        :param key: The document ID\n        :param kwargs: Arguments passed to :meth:`mutate_in`\n        :return: A :class:`ValueResult`\n        :raise: :cb_exc:`QueueEmpty` if there are no items in the queue.\n        :raise: :cb_exc:`NotFoundError` if the queue does not exist.\n        \"\"\"\n        while True:\n            try:\n                itm = self.list_get(key, -1)\n            except IndexError:\n                raise E.QueueEmpty\n\n            kwargs['cas'] = itm.cas\n            try:\n                self.list_remove(key, -1, **kwargs)\n                return itm\n            except E.KeyExistsError:\n                pass\n            except IndexError:\n                raise E.QueueEmpty"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encrypt_fields(self, document, fieldspec, prefix):\n        json_encoded = json.dumps(document)\n        encrypted_string = _Base.encrypt_fields(self, json_encoded, fieldspec, prefix)\n        if not encrypted_string:\n            raise couchbase.exceptions.CouchbaseError(\"Encryption failed\")\n        return json.loads(encrypted_string)", "response": "Encrypt a document using the registered encryption providers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a basic structure of a player s key - set.", "response": "def create(cls, name, email, cb):\n        \"\"\"\n        Create the basic structure of a player\n        \"\"\"\n        it = cls(name, create_structure=True)\n        it.value['email'] = email\n\n        # In an actual application you'd probably want to use 'add',\n        # but since this app might be run multiple times, you don't\n        # want to get KeyExistsError\n        cb.upsert_multi(ItemSequence([it]))\n        return it"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _doc_rev(self, res):\n        jstr = res.headers['X-Couchbase-Meta']\n        jobj = json.loads(jstr)\n        return jobj['rev']", "response": "Returns the rev id from the header"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _poll_vq_single(self, dname, use_devmode, ddresp):\n        vname = None\n        query = None\n        v_mr = ddresp.get('views', {})\n        v_spatial = ddresp.get('spatial', {})\n        if v_mr:\n            vname = single_dict_key(v_mr)\n            query = Query()\n        elif v_spatial:\n            vname = single_dict_key(v_spatial)\n            query = SpatialQuery()\n\n        if not vname:\n            return False\n\n        query.stale = STALE_OK\n        query.limit = 1\n\n        for r in self._cb.query(dname, vname, use_devmode=use_devmode,\n                                query=query):\n            pass\n        return True", "response": "Initiate a view query for a single view located in a design document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _design_poll(self, name, mode, oldres, timeout=5, use_devmode=False):\n        if not timeout:\n            return True\n\n        if timeout < 0:\n            raise ArgumentError.pyexc(\"Interval must not be negative\")\n\n        t_end = time.time() + timeout\n        old_rev = None\n\n        if oldres:\n            old_rev = self._doc_rev(oldres)\n\n        while time.time() < t_end:\n            try:\n                cur_resp = self.design_get(name, use_devmode=use_devmode)\n                if old_rev and self._doc_rev(cur_resp) == old_rev:\n                    continue\n\n                try:\n                    if not self._poll_vq_single(\n                            name, use_devmode, cur_resp.value):\n                        continue\n                    return True\n\n                except CouchbaseError:\n                    continue\n\n            except CouchbaseError:\n                if mode == 'del':\n                    # Deleted, whopee!\n                    return True\n\n        raise exceptions.TimeoutError.pyexc(\n            \"Wait time for design action completion exceeded\")", "response": "Poll for an async design action to be complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef design_create(self, name, ddoc, use_devmode=True, syncwait=0):\n        name = self._cb._mk_devmode(name, use_devmode)\n\n        fqname = \"_design/{0}\".format(name)\n        if not isinstance(ddoc, dict):\n            ddoc = json.loads(ddoc)\n\n        ddoc = ddoc.copy()\n        ddoc['_id'] = fqname\n        ddoc = json.dumps(ddoc)\n\n        existing = None\n        if syncwait:\n            try:\n                existing = self.design_get(name, use_devmode=False)\n            except CouchbaseError:\n                pass\n\n        ret = self._cb._http_request(\n            type=_LCB.LCB_HTTP_TYPE_VIEW, path=fqname,\n            method=_LCB.LCB_HTTP_METHOD_PUT, post_data=ddoc,\n            content_type=\"application/json\")\n\n        self._design_poll(name, 'add', existing, syncwait,\n                          use_devmode=use_devmode)\n        return ret", "response": "Create a new design document in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef design_get(self, name, use_devmode=True):\n        name = self._mk_devmode(name, use_devmode)\n\n        existing = self._http_request(type=_LCB.LCB_HTTP_TYPE_VIEW,\n                                      path=\"_design/\" + name,\n                                      method=_LCB.LCB_HTTP_METHOD_GET,\n                                      content_type=\"application/json\")\n        return existing", "response": "Retrieve a design document by its name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a development mode view into a production mode view.", "response": "def design_publish(self, name, syncwait=0):\n        \"\"\"\n        Convert a development mode view into a production mode views.\n        Production mode views, as opposed to development views, operate on the\n        entire cluster data (rather than a restricted subset thereof).\n\n        :param string name: The name of the view to convert.\n\n        Once the view has been converted, ensure that all functions (such as\n        :meth:`design_get`) have the ``use_devmode`` parameter disabled,\n        otherwise an error will be raised when those functions are used.\n\n        Note that the ``use_devmode`` option is missing. This is intentional\n        as the design document must currently be a development view.\n\n        :return: An :class:`~couchbase.result.HttpResult` object.\n\n        :raise: :exc:`couchbase.exceptions.HTTPError` if the design does not\n            exist\n\n        .. seealso:: :meth:`design_create`, :meth:`design_delete`,\n            :meth:`design_get`\n        \"\"\"\n        existing = self.design_get(name, use_devmode=True)\n        rv = self.design_create(name, existing.value, use_devmode=False,\n                           syncwait=syncwait)\n        self.design_delete(name, use_devmode=True,\n                           syncwait=syncwait)\n        self._design_poll(name, 'add', None,\n                          timeout=syncwait, use_devmode=False)\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef design_delete(self, name, use_devmode=True, syncwait=0):\n        name = self._mk_devmode(name, use_devmode)\n        existing = None\n        if syncwait:\n            try:\n                existing = self.design_get(name, use_devmode=False)\n            except CouchbaseError:\n                pass\n\n        ret = self._http_request(type=_LCB.LCB_HTTP_TYPE_VIEW,\n                                 path=\"_design/\" + name,\n                                 method=_LCB.LCB_HTTP_METHOD_DELETE)\n\n        self._design_poll(name, 'del', existing, syncwait)\n        return ret", "response": "Delete a design document."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef design_list(self):\n        ret = self._http_request(\n            type=_LCB.LCB_HTTP_TYPE_MANAGEMENT,\n            path=\"/pools/default/buckets/{0}/ddocs\".format(self._cb.bucket),\n            method=_LCB.LCB_HTTP_METHOD_GET)\n\n        real_rows = {}\n        for r in ret.value['rows']:\n            real_rows[r['doc']['meta']['id']] = r['doc']['json']\n\n        # Can't use normal assignment because 'value' is read-only\n        ret.value.clear()\n        ret.value.update(real_rows)\n        return ret", "response": "This method returns a list of all design documents for the current bucket."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an index for use with N1QL.", "response": "def n1ql_index_create(self, ix, **kwargs):\n        \"\"\"\n        Create an index for use with N1QL.\n\n        :param str ix: The name of the index to create\n        :param bool defer: Whether the building of indexes should be\n            deferred. If creating multiple indexes on an existing\n            dataset, using the `defer` option in conjunction with\n            :meth:`build_deferred_indexes` and :meth:`watch_indexes` may\n            result in substantially reduced build times.\n        :param bool ignore_exists: Do not throw an exception if the index\n            already exists.\n        :param list fields: A list of fields that should be supplied\n            as keys for the index. For non-primary indexes, this must\n            be specified and must contain at least one field name.\n        :param bool primary: Whether this is a primary index. If creating\n            a primary index, the name may be an empty string and `fields`\n            must be empty.\n        :param str condition: Specify a condition for indexing. Using\n            a condition reduces an index size\n        :raise: :exc:`~.KeyExistsError` if the index already exists\n\n        .. seealso:: :meth:`n1ql_index_create_primary`\n        \"\"\"\n        defer = kwargs.pop('defer', False)\n        ignore_exists = kwargs.pop('ignore_exists', False)\n        primary = kwargs.pop('primary', False)\n        fields = kwargs.pop('fields', [])\n        cond = kwargs.pop('condition', None)\n\n        if kwargs:\n            raise TypeError('Unknown keyword arguments', kwargs)\n\n        info = self._mk_index_def(ix, primary)\n\n        if primary and fields:\n            raise TypeError('Cannot create primary index with explicit fields')\n        elif not primary and not fields:\n            raise ValueError('Fields required for non-primary index')\n\n        if fields:\n            info.fields = fields\n\n        if primary and info.name is N1QL_PRIMARY_INDEX:\n            del info.name\n\n        if cond:\n            if primary:\n                raise ValueError('cannot specify condition for primary index')\n            info.condition = cond\n\n        options = {\n            'ignore_exists': ignore_exists,\n            'defer': defer\n        }\n\n        # Now actually create the indexes\n        return IxmgmtRequest(self._cb, 'create', info, **options).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the primary index on the bucket.", "response": "def n1ql_index_create_primary(self, defer=False, ignore_exists=False):\n        \"\"\"\n        Create the primary index on the bucket.\n\n        Equivalent to::\n\n            n1ql_index_create('', primary=True, **kwargs)\n\n        :param bool defer:\n        :param bool ignore_exists:\n\n        .. seealso:: :meth:`create_index`\n        \"\"\"\n        return self.n1ql_index_create(\n            '', defer=defer, primary=True, ignore_exists=ignore_exists)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete an index from the cluster.", "response": "def n1ql_index_drop(self, ix, primary=False, **kwargs):\n        \"\"\"\n        Delete an index from the cluster.\n\n        :param str ix: the name of the index\n        :param bool primary: if this index is a primary index\n        :param bool ignore_missing: Do not raise an exception if the index\n            does not exist\n        :raise: :exc:`~.NotFoundError` if the index does not exist and\n            `ignore_missing` was not specified\n        \"\"\"\n        info = self._mk_index_def(ix, primary)\n        return IxmgmtRequest(self._cb, 'drop', info, **kwargs).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef n1ql_index_build_deferred(self, other_buckets=False):\n        info = N1qlIndex()\n        if not other_buckets:\n            info.keyspace = self._cb.bucket\n            return IxmgmtRequest(self._cb, 'build', info).execute()", "response": "This method is used to build any deferred indexes in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nawaiting completion of index building This method will wait up to `timeout` seconds for every index in `indexes` to have been built. It will poll the cluster every `interval` seconds. :param list indexes: A list of indexes to check. This is returned by :meth:`build_deferred_indexes` :param float timeout: How long to wait for the indexes to become ready. :param float interval: How often to poll the cluster. :param bool watch_primary: Whether to also watch the primary index. This parameter should only be used when manually constructing a list of string indexes :raise: :exc:`~.TimeoutError` if the timeout was reached before all indexes were built :raise: :exc:`~.NotFoundError` if one of the indexes passed no longer exists.", "response": "def n1ql_index_watch(self, indexes,\n                         timeout=30, interval=0.2, watch_primary=False):\n        \"\"\"\n        Await completion of index building\n\n        This method will wait up to `timeout` seconds for every index in\n        `indexes` to have been built. It will poll the cluster every\n        `interval` seconds.\n\n        :param list indexes: A list of indexes to check. This is returned by\n            :meth:`build_deferred_indexes`\n        :param float timeout: How long to wait for the indexes to become ready.\n        :param float interval: How often to poll the cluster.\n        :param bool watch_primary: Whether to also watch the primary index.\n            This parameter should only be used when manually constructing a\n            list of string indexes\n        :raise: :exc:`~.TimeoutError` if the timeout was reached before all\n            indexes were built\n        :raise: :exc:`~.NotFoundError` if one of the indexes passed no longer\n            exists.\n        \"\"\"\n        kwargs = {\n            'timeout_us': int(timeout * 1000000),\n            'interval_us': int(interval * 1000000)\n        }\n        ixlist = [N1qlIndex.from_any(x, self._cb.bucket) for x in indexes]\n        if watch_primary:\n            ixlist.append(\n                N1qlIndex.from_any(N1QL_PRIMARY_INDEX, self._cb.bucket))\n        return IxmgmtRequest(self._cb, 'watch', ixlist, **kwargs).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the common options for the specified range of the user - side convenience keys.", "response": "def _set_range_common(self, k_sugar, k_start, k_end, value):\n        \"\"\"\n        Checks to see if the client-side convenience key is present, and if so\n        converts the sugar convenience key into its real server-side\n        equivalents.\n\n        :param string k_sugar: The client-side convenience key\n        :param string k_start: The server-side key specifying the beginning of\n            the range\n        :param string k_end: The server-side key specifying the end of the\n            range\n        \"\"\"\n\n        if not isinstance(value, (list, tuple, _Unspec)):\n            raise ArgumentError.pyexc(\n                \"Range specification for {0} must be a list, tuple or UNSPEC\"\n                .format(k_sugar))\n\n        if self._user_options.get(k_start, UNSPEC) is not UNSPEC or (\n                self._user_options.get(k_end, UNSPEC) is not UNSPEC):\n\n            raise ArgumentError.pyexc(\n                \"Cannot specify {0} with either {1} or {2}\"\n                .format(k_sugar, k_start, k_end))\n\n        if not value:\n            self._set_common(k_start, UNSPEC, set_user=False)\n            self._set_common(k_end, UNSPEC, set_user=False)\n            self._user_options[k_sugar] = UNSPEC\n            return\n\n        if len(value) not in (1, 2):\n            raise ArgumentError.pyexc(\"Range specification \"\n                                      \"must have one or two elements\",\n                                      value)\n\n        value = value[::]\n        if len(value) == 1:\n            value.append(UNSPEC)\n\n        for p, ix in ((k_start, 0), (k_end, 1)):\n            self._set_common(p, value[ix], set_user=False)\n\n        self._user_options[k_sugar] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchain assignment operator. This may be used to quickly assign extra parameters to the :class:`Query` object. Example:: q = Query(reduce=True, full_sec=True) # Someplace later v = View(design, view, query=q.update(mapkey_range=[\"foo\"])) Its primary use is to easily modify the query object (in-place). :param boolean copy: If set to true, the original object is copied before new attributes are added to it :param params: Extra arguments. These must be valid query options. :return: A :class:`Query` object. If ``copy`` was set to true, this will be a new instance, otherwise it is the same instance on which this method was called", "response": "def update(self, copy=False, **params):\n        \"\"\"\n        Chained assignment operator.\n\n        This may be used to quickly assign extra parameters to the\n        :class:`Query` object.\n\n        Example::\n\n            q = Query(reduce=True, full_sec=True)\n\n            # Someplace later\n\n            v = View(design, view, query=q.update(mapkey_range=[\"foo\"]))\n\n        Its primary use is to easily modify the query object (in-place).\n\n        :param boolean copy:\n            If set to true, the original object is copied before new attributes\n            are added to it\n        :param params: Extra arguments. These must be valid query options.\n\n        :return: A :class:`Query` object. If ``copy`` was set to true, this\n            will be a new instance, otherwise it is the same instance on which\n            this method was called\n\n        \"\"\"\n        if copy:\n            self = deepcopy(self)\n\n        for k, v in params.items():\n            if not hasattr(self, k):\n                if not self.unrecognized_ok:\n                    raise ArgumentError.pyexc(\"Unknown option\", k)\n                self._set_common(k, v)\n\n            else:\n                setattr(self, k, v)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_any(cls, params, **ctor_opts):\n        if isinstance(params, cls):\n            return deepcopy(params)\n\n        elif isinstance(params, dict):\n            ctor_opts.update(**params)\n            if cls is QueryBase:\n                if ('bbox' in params or 'start_range' in params or\n                            'end_range' in params):\n                    return SpatialQuery(**ctor_opts)\n                else:\n                    return ViewQuery(**ctor_opts)\n\n        elif isinstance(params, basestring):\n            ret = cls()\n            ret._base_str = params\n            return ret\n\n        else:\n            raise ArgumentError.pyexc(\"Params must be Query, dict, or string\")", "response": "Creates a new Query object from input."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an encoded form of the query", "response": "def encoded(self):\n        \"\"\"\n        Returns an encoded form of the query\n        \"\"\"\n        if not self._encoded:\n            self._encoded = self._encode()\n\n        if self._base_str:\n            return '&'.join((self._base_str, self._encoded))\n\n        else:\n            return self._encoded"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _long_query_encoded(self):\n        uristr = self._encode(omit_keys=True)\n        kstr = \"{}\"\n\n        klist = self._real_options.get('keys', UNSPEC)\n        if klist != UNSPEC:\n            kstr = '{{\"keys\":{0}}}'.format(klist)\n\n        return (uristr, kstr)", "response": "Returns the URI part and the post_data_part for a long query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_rows(self, rowiter):\n        self.__rows = rowiter\n        self._d.callback(self)\n        self._d = None", "response": "Reimplemented from ~AsyncViewBase. on_rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when an error occurs.", "response": "def on_error(self, ex):\n        \"\"\"\n        Reimplemented from :meth:`~AsyncViewBase.on_error`\n        \"\"\"\n        if self._d:\n            self._d.errback()\n            self._d = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_done(self):\n        if self._d:\n            self._d.callback(self)\n            self._d = None", "response": "Called when the async view is done."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a deferred to be triggered at the firing of a specific event.", "response": "def registerDeferred(self, event, d):\n        \"\"\"\n        Register a defer to be fired at the firing of a specific event.\n\n        :param string event: Currently supported values are `connect`. Another\n          value may be `_dtor` which will register an event to fire when this\n          object has been completely destroyed.\n\n        :param event: The defered to fire when the event succeeds or failes\n        :type event: :class:`Deferred`\n\n        If this event has already fired, the deferred will be triggered\n        asynchronously.\n\n        Example::\n\n          def on_connect(*args):\n              print(\"I'm connected\")\n          def on_connect_err(*args):\n              print(\"Connection failed\")\n\n          d = Deferred()\n          cb.registerDeferred('connect', d)\n          d.addCallback(on_connect)\n          d.addErrback(on_connect_err)\n\n        :raise: :exc:`ValueError` if the event name is unrecognized\n        \"\"\"\n        try:\n            self._evq[event].schedule(d)\n        except KeyError:\n            raise ValueError(\"No such event type\", event)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a raw : class : ~couchbase. results. AsyncResult object into a Deferred object.", "response": "def defer(self, opres):\n        \"\"\"\n        Converts a raw :class:`couchbase.results.AsyncResult` object\n        into a :class:`Deferred`.\n\n        This is shorthand for the following \"non-idiom\"::\n\n          d = Deferred()\n          opres = cb.upsert(\"foo\", \"bar\")\n          opres.callback = d.callback\n\n          def d_err(res, ex_type, ex_val, ex_tb):\n              d.errback(opres, ex_type, ex_val, ex_tb)\n\n          opres.errback = d_err\n          return d\n\n        :param opres: The operation to wrap\n        :type opres: :class:`couchbase.results.AsyncResult`\n\n        :return: a :class:`Deferred` object.\n\n        Example::\n\n          opres = cb.upsert(\"foo\", \"bar\")\n          d = cb.defer(opres)\n          def on_ok(res):\n              print(\"Result OK. Cas: {0}\".format(res.cas))\n          d.addCallback(opres)\n\n\n        \"\"\"\n        d = Deferred()\n        opres.callback = d.callback\n\n        def _on_err(mres, ex_type, ex_val, ex_tb):\n            try:\n                raise ex_type(ex_val)\n            except CouchbaseError:\n                d.errback()\n        opres.errback = _on_err\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef queryEx(self, viewcls, *args, **kwargs):\n\n        kwargs['itercls'] = viewcls\n        o = super(AsyncBucket, self).query(*args, **kwargs)\n        if not self.connected:\n            self.connect().addCallback(lambda x: o.start())\n        else:\n            o.start()\n\n        return o", "response": "Query a view with the viewcls instance receiving events\n        of the query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef queryAll(self, *args, **kwargs):\n\n        if not self.connected:\n            cb = lambda x: self.queryAll(*args, **kwargs)\n            return self.connect().addCallback(cb)\n\n        kwargs['itercls'] = BatchedView\n        o = super(RawBucket, self).query(*args, **kwargs)\n        o.start()\n        return o._getDeferred()", "response": "Query all entries in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a N1QL query providing a custom handler for rows.", "response": "def n1qlQueryEx(self, cls, *args, **kwargs):\n        \"\"\"\n        Execute a N1QL statement providing a custom handler for rows.\n\n        This method allows you to define your own subclass (of\n        :class:`~AsyncN1QLRequest`) which can handle rows as they are\n        received from the network.\n\n        :param cls: The subclass (not instance) to use\n        :param args: Positional arguments for the class constructor\n        :param kwargs: Keyword arguments for the class constructor\n\n        .. seealso:: :meth:`queryEx`, around which this method wraps\n        \"\"\"\n        kwargs['itercls'] = cls\n        o = super(AsyncBucket, self).n1ql_query(*args, **kwargs)\n        if not self.connected:\n            self.connect().addCallback(lambda x: o.start())\n        else:\n            o.start()\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef n1qlQueryAll(self, *args, **kwargs):\n        if not self.connected:\n            cb = lambda x: self.n1qlQueryAll(*args, **kwargs)\n            return self.connect().addCallback(cb)\n\n        kwargs['itercls'] = BatchedN1QLRequest\n        o = super(RawBucket, self).n1ql_query(*args, **kwargs)\n        o.start()\n        return o._getDeferred()", "response": "Execute a N1QL query and retrieve all rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a Search query providing a custom handler for rows.", "response": "def searchQueryEx(self, cls, *args, **kwargs):\n        \"\"\"\n        Experimental Method\n\n        Execute a Search query providing a custom handler for rows.\n\n        This method allows you to define your own subclass (of\n        :class:`~AsyncSearchRequest`) which can handle rows as they are\n        received from the network.\n\n        :param cls: The subclass (not instance) to use\n        :param args: Positional arguments for the class constructor\n        :param kwargs: Keyword arguments for the class constructor\n\n        .. seealso:: :meth:`search`, around which this method wraps\n        \"\"\"\n        kwargs['itercls'] = cls\n        o = super(AsyncBucket, self).search(*args, **kwargs)\n        if not self.connected:\n            self.connect().addCallback(lambda x: o.start())\n        else:\n            o.start()\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a Search query and retrieving all rows.", "response": "def searchQueryAll(self, *args, **kwargs):\n        \"\"\"\n        Experimental Method\n\n        Execute a Search query, retrieving all rows.\n\n        This method returns a :class:`Deferred` object which is executed\n        with a :class:`~.SearchRequest` object. The object may be iterated\n        over to yield the rows in the result set.\n\n        This method is similar to :meth:`~couchbase.bucket.Bucket.search`\n        in its arguments.\n\n        Example::\n\n            def handler(req):\n                for row in req:\n                    # ... handle row\n\n            d = cb.search('name', ft.MatchQuery('nosql'), limit=10)\n            d.addCallback(handler)\n\n        :return: A :class:`Deferred`\n\n        .. seealso:: :meth:`~couchbase.bucket.Bucket.search`\n        \"\"\"\n\n        if not self.connected:\n            cb = lambda x: self.searchQueryAll(*args, **kwargs)\n            return self.connect().addCallback(cb)\n\n        kwargs['itercls'] = BatchedSearchRequest\n        o = super(AsyncBucket, self).search(*args, **kwargs)\n        o.start()\n        return o._getDeferred()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a method with the appropriate arguments and return a Deferred that will be called when the instance is connected to the server.", "response": "def _wrap(self, meth, *args, **kwargs):\n        \"\"\"\n        Calls a given method with the appropriate arguments, or defers such\n        a call until the instance has been connected\n        \"\"\"\n        if not self.connected:\n            return self._connectSchedule(self._wrap, meth, *args, **kwargs)\n\n        opres = meth(self, *args, **kwargs)\n        return self.defer(opres)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_decode_format(flags):\n    c_flags = flags & FMT_COMMON_MASK\n    l_flags = flags & FMT_LEGACY_MASK\n\n    if c_flags:\n        if c_flags not in COMMON_FORMATS:\n            return FMT_BYTES, False\n        else:\n            return COMMON2UNIFIED[c_flags], True\n    else:\n        if not l_flags in LEGACY_FORMATS:\n            return FMT_BYTES, False\n        else:\n            return LEGACY2UNIFIED[l_flags], True", "response": "Returns a tuple of format recognized by the flags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index_to_rawjson(ix):\n    if isinstance(ix, N1qlIndex):\n        ix = ix.raw\n    return _to_json(ix)", "response": "Convert a N1qlIndex object to a raw JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_any(cls, obj, bucket):\n        if isinstance(obj, cls):\n            return cls(obj.raw)\n\n        return cls({\n            'namespace_id': 'default',\n            'keyspace_id': bucket,\n            'name': obj if obj else N1QL_PRIMARY_INDEX,\n            'using': 'gsi'\n        })", "response": "Ensure the current object is an index. Always returns a new object\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming an administrative HTTP request. This request is sent out to the administrative API interface (i.e. the \"Management/REST API\") of the cluster. Note that this is a fairly low level function. You should use one of the helper methods in this class to perform your task, if possible. :param string path: The path portion (not including the host) of the rest call to perform. This should also include any encoded arguments. :param string method: This is the HTTP method to perform. Currently supported values are `GET`, `POST`, `PUT`, and `DELETE` :param bytes content: Content to be passed along in the request body. This is only applicable on `PUT` and `POST` methods. :param string content_type: Value for the HTTP ``Content-Type`` header. Currently this is ``application-json``, and should probably not be set to something else. :param int response_format: Hint about how to format the response. This goes into the :attr:`~.HttpResult.value` field of the :class:`~.HttpResult` object. The default is :const:`~couchbase.FMT_JSON`. Note that if the conversion fails, the content will be returned as ``bytes`` :raise: :exc:`~.ArgumentError` if the method supplied was incorrect. :exc:`~.ConnectError` if there was a problem establishing a connection. :exc:`~.HTTPError` if the server responded with a negative reply :return: a :class:`~.HttpResult` object. .. seealso:: :meth:`bucket_create`, :meth:`bucket_remove`", "response": "def http_request(self,\n                     path,\n                     method='GET',\n                     content=None,\n                     content_type=\"application/json\",\n                     response_format=FMT_JSON):\n        \"\"\"\n        Perform an administrative HTTP request. This request is sent out to\n        the administrative API interface (i.e. the \"Management/REST API\")\n        of the cluster.\n\n        Note that this is a fairly low level function. You should use one\n        of the helper methods in this class to perform your task, if\n        possible.\n\n        :param string path: The path portion (not including the host) of the\n          rest call to perform. This should also include any encoded arguments.\n\n        :param string method: This is the HTTP method to perform. Currently\n          supported values are `GET`, `POST`, `PUT`, and `DELETE`\n\n        :param bytes content: Content to be passed along in the request body.\n          This is only applicable on `PUT` and `POST` methods.\n\n        :param string content_type: Value for the HTTP ``Content-Type`` header.\n          Currently this is ``application-json``, and should probably not be\n          set to something else.\n\n        :param int response_format:\n          Hint about how to format the response. This goes into the\n          :attr:`~.HttpResult.value` field of the\n          :class:`~.HttpResult` object. The default is\n          :const:`~couchbase.FMT_JSON`.\n\n          Note that if the conversion fails, the content will be returned as\n          ``bytes``\n\n        :raise:\n          :exc:`~.ArgumentError`\n            if the method supplied was incorrect.\n          :exc:`~.ConnectError`\n            if there was a problem establishing a connection.\n          :exc:`~.HTTPError`\n            if the server responded with a negative reply\n\n        :return: a :class:`~.HttpResult` object.\n\n        .. seealso:: :meth:`bucket_create`, :meth:`bucket_remove`\n        \"\"\"\n        imeth = None\n        if not method in METHMAP:\n            raise E.ArgumentError.pyexc(\"Unknown HTTP Method\", method)\n\n        imeth = METHMAP[method]\n        return self._http_request(type=LCB.LCB_HTTP_TYPE_MANAGEMENT,\n                                  path=path,\n                                  method=imeth,\n                                  content_type=content_type,\n                                  post_data=content,\n                                  response_format=response_format)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new bucket in the local cache.", "response": "def bucket_create(self, name, bucket_type='couchbase',\n                      bucket_password='', replicas=0, ram_quota=1024,\n                      flush_enabled=False):\n        \"\"\"\n        Create a new bucket\n\n        :param string name: The name of the bucket to create\n        :param string bucket_type: The type of bucket to create. This\n            can either be `couchbase` to create a couchbase style\n            bucket (which persists data and supports replication) or\n            `memcached` (which is memory-only and does not support\n            replication).\n            Since Couchbase version 5.0, you can also specify\n            `ephemeral`, which is a replicated bucket which does\n            not have strict disk persistence requirements\n        :param string bucket_password: The bucket password. This can be\n            empty to disable authentication. This can be changed later on\n            using :meth:`bucket_update`\n        :param int replicas: The number of replicas to use for this\n            bucket. The maximum number of replicas is currently 3.\n            This setting can be changed via :meth:`bucket_update`\n        :param int ram_quota:\n            The maximum amount of memory (per node) that this bucket\n            may use, in megabytes. The minimum for this value is 100.\n            This setting may be changed via :meth:`bucket_update`.\n        :param bool flush_enabled:\n            Whether the flush API is enabled. When the flush API is\n            enabled, any client connected to the bucket is able to\n            clear its contents. This may be useful in development but\n            not recommended in production. This setting may be changed\n            via :meth:`bucket_update`\n        :return: A :class:`~.HttpResult`\n        :raise: :exc:`~.HTTPError` if the bucket could not be created.\n        \"\"\"\n        params = {\n            'name': name,\n            'bucketType': bucket_type,\n            'authType': 'sasl',\n            'saslPassword': bucket_password if bucket_password else '',\n            'flushEnabled': int(flush_enabled),\n            'ramQuotaMB': ram_quota\n        }\n        if bucket_type in ('couchbase', 'membase', 'ephemeral'):\n            params['replicaNumber'] = replicas\n\n        return self.http_request(\n            path='/pools/default/buckets', method='POST',\n            content=self._mk_formstr(params),\n            content_type='application/x-www-form-urlencoded')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for a newly created bucket to be ready.", "response": "def wait_ready(self, name, timeout=5.0, sleep_interval=0.2):\n        \"\"\"\n        Wait for a newly created bucket to be ready.\n\n        :param string name: the name to wait for\n        :param seconds timeout: the maximum amount of time to wait\n        :param seconds sleep_interval: the number of time to sleep\n            between each probe\n        :raise: :exc:`.CouchbaseError` on internal HTTP error\n        :raise: :exc:`NotReadyError` if all nodes could not be\n            ready in time\n        \"\"\"\n        end = time() + timeout\n        while True:\n            try:\n                info = self.bucket_info(name).value\n                for node in info['nodes']:\n                    if node['status'] != 'healthy':\n                        raise NotReadyError.pyexc('Not all nodes are healthy')\n                return  # No error and all OK\n            except E.CouchbaseError:\n                if time() + sleep_interval > end:\n                    raise\n                sleep(sleep_interval)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an existing bucket s settings.", "response": "def bucket_update(self, name, current, bucket_password=None, replicas=None,\n                      ram_quota=None, flush_enabled=None):\n        \"\"\"\n        Update an existing bucket's settings.\n\n        :param string name: The name of the bucket to update\n        :param dict current: Current state of the bucket.\n            This can be retrieve from :meth:`bucket_info`\n        :param str bucket_password: Change the bucket's password\n        :param int replicas: The number of replicas for the bucket\n        :param int ram_quota: The memory available to the bucket\n            on each node.\n        :param bool flush_enabled: Whether the flush API should be allowed\n            from normal clients\n        :return: A :class:`~.HttpResult` object\n        :raise: :exc:`~.HTTPError` if the request could not be\n            completed\n\n\n        .. note::\n\n            The default value for all options in this method is\n            ``None``. If a value is set to something else, it will\n            modify the setting.\n\n\n        Change the bucket password::\n\n            adm.bucket_update('a_bucket', adm.bucket_info('a_bucket'),\n                              bucket_password='n3wpassw0rd')\n\n        Enable the flush API::\n\n            adm.bucket_update('a_bucket', adm.bucket_info('a_bucket'),\n                              flush_enabled=True)\n        \"\"\"\n        params = {}\n        current = current.value\n\n        # Merge params\n        params['authType'] = current['authType']\n        if 'saslPassword' in current:\n            params['saslPassword'] = current['saslPassword']\n\n        if bucket_password is not None:\n            params['authType'] = 'sasl'\n            params['saslPassword'] = bucket_password\n\n        params['replicaNumber'] = (\n            replicas if replicas is not None else current['replicaNumber'])\n\n        if ram_quota:\n            params['ramQuotaMB'] = ram_quota\n        else:\n            params['ramQuotaMB'] = current['quota']['ram'] / 1024 / 1024\n\n        if flush_enabled is not None:\n            params['flushEnabled'] = int(flush_enabled)\n\n        params['proxyPort'] = current['proxyPort']\n        return self.http_request(path='/pools/default/buckets/' + name,\n                                 method='POST',\n                                 content_type='application/x-www-form-urlencoded',\n                                 content=self._mk_formstr(params))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a list of users from the server.", "response": "def users_get(self, domain):\n        \"\"\"\n        Retrieve a list of users from the server.\n\n        :param AuthDomain domain: The authentication domain to retrieve users from.\n        :return: :class:`~.HttpResult`. The list of users can be obtained from\n            the returned object's `value` property.\n        \"\"\"\n        path = self._get_management_path(domain)\n        return self.http_request(path=path,\n                                 method='GET')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_get(self, domain, userid):\n        path = self._get_management_path(domain, userid)\n        return self.http_request(path=path,\n                                 method='GET')", "response": "Retrieve a user from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a user from the cache.", "response": "def user_remove(self, domain, userid):\n        \"\"\"\n        Remove a user\n        :param AuthDomain domain: The authentication domain for the user.\n        :param userid: The user ID to remove\n        :raise: :exc:`couchbase.exceptions.HTTPError` if the user does not exist.\n        :return: :class:`~.HttpResult`\n        \"\"\"\n        path = self._get_management_path(domain, userid)\n        return self.http_request(path=path,\n                                 method='DELETE')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a 1. x host : port specification to a connection string", "response": "def _build_connstr(host, port, bucket):\n    \"\"\"\n    Converts a 1.x host:port specification to a connection string\n    \"\"\"\n    hostlist = []\n    if isinstance(host, (tuple, list)):\n        for curhost in host:\n            if isinstance(curhost, (list, tuple)):\n                hostlist.append(_fmthost(*curhost))\n            else:\n                hostlist.append(curhost)\n    else:\n        hostlist.append(_fmthost(host, port))\n\n    return 'http://{0}/{1}'.format(','.join(hostlist), bucket)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert arguments for 1. x constructors to their 2. x forms", "response": "def convert_1x_args(bucket, **kwargs):\n    \"\"\"\n    Converts arguments for 1.x constructors to their 2.x forms\n    \"\"\"\n    host = kwargs.pop('host', 'localhost')\n    port = kwargs.pop('port', None)\n    if not 'connstr' in kwargs and 'connection_string' not in kwargs:\n        kwargs['connection_string'] = _build_connstr(host, port, bucket)\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an existing connection string and returns a new object containing the contents of the object.", "response": "def parse(cls, ss):\n        \"\"\"\n        Parses an existing connection string\n\n        This method will return a :class:`~.ConnectionString` object\n        which will allow further inspection on the input parameters.\n\n        :param string ss: The existing connection string\n        :return: A new :class:`~.ConnectionString` object\n        \"\"\"\n\n        up = urlparse(ss)\n        path = up.path\n        query = up.query\n\n        if '?' in path:\n            path, _ = up.path.split('?')\n\n        if path.startswith('/'):\n            path = path[1:]\n\n        bucket = path\n        options = parse_qs(query)\n        scheme = up.scheme\n        hosts = up.netloc.split(',')\n        return cls(bucket=bucket, options=options, hosts=hosts, scheme=scheme)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode the current state of the object into a string.", "response": "def encode(self):\n        \"\"\"\n        Encodes the current state of the object into a string.\n\n        :return: The encoded string\n        \"\"\"\n        opt_dict = {}\n        for k, v in self.options.items():\n            opt_dict[k] = v[0]\n\n        ss = '{0}://{1}'.format(self.scheme, ','.join(self.hosts))\n        if self.bucket:\n            ss += '/' + self.bucket\n\n        # URL encode options then decoded forward slash /\n        ss += '?' + urlencode(opt_dict).replace('%2F', '/')\n\n        return ss"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new exception class derived from the appropriate exceptions.", "response": "def _mk_lcberr(rc, name=None, default=CouchbaseError, docstr=\"\", extrabase=[]):\n    \"\"\"\n    Create a new error class derived from the appropriate exceptions.\n    :param int rc: libcouchbase error code to map\n    :param str name: The name of the new exception\n    :param class default: Default exception to return if no categories are found\n    :return: a new exception derived from the appropriate categories, or the\n             value supplied for `default`\n    \"\"\"\n    categories = C._get_errtype(rc)\n    if not categories:\n        return default\n\n    bases = extrabase[::]\n\n    for cat, base in _LCB_ERRCAT_MAP.items():\n        if cat & categories:\n            bases.append(base)\n\n    if name is None:\n        name = \"LCB_0x{0:0X} (generated, catch: {1})\".format(\n            rc, \", \".join(x.__name__ for x in bases))\n\n    d = { '__doc__' : docstr }\n\n    if not bases:\n        bases = [CouchbaseError]\n\n    return type(name, tuple(bases), d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a raisable exception from a given error code.", "response": "def exc_from_rc(rc, msg=None, obj=None):\n    \"\"\"\n    .. warning:: INTERNAL\n\n    For those rare cases when an exception needs to be thrown from\n    Python using a libcouchbase error code.\n\n    :param rc: The error code\n    :param msg: Message (description)\n    :param obj: Context\n    :return: a raisable exception\n    \"\"\"\n    newcls = CouchbaseError.rc_to_exctype(rc)\n    return newcls(params={'rc': rc, 'objextra': obj, 'message': msg})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rc_to_exctype(cls, rc):\n        try:\n            return _LCB_ERRNO_MAP[rc]\n        except KeyError:\n            newcls = _mk_lcberr(rc)\n            _LCB_ERRNO_MAP[rc] = newcls\n            return newcls", "response": "Map an error code to an exception exception."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_event(self, event, action, flags):\n        if action == PYCBC_EVACTION_UNWATCH:\n            if event.flags & LCB_READ_EVENT:\n                self.reactor.removeReader(event)\n            if event.flags & LCB_WRITE_EVENT:\n                self.reactor.removeWriter(event)\n\n        elif action == PYCBC_EVACTION_WATCH:\n            if flags & LCB_READ_EVENT:\n                self.reactor.addReader(event)\n            if flags & LCB_WRITE_EVENT:\n                self.reactor.addWriter(event)\n\n            if flags & LCB_READ_EVENT == 0:\n                self.reactor.removeReader(event)\n            if flags & LCB_WRITE_EVENT == 0:\n                self.reactor.removeWriter(event)", "response": "Called by libcouchbase to update the event with the new flags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall by libcouchbase to update the timer.", "response": "def update_timer(self, timer, action, usecs):\n        \"\"\"\n        Called by libcouchbase to add/remove timers\n        \"\"\"\n        if action == PYCBC_EVACTION_WATCH:\n            timer.schedule(usecs, self.reactor)\n\n        elif action == PYCBC_EVACTION_UNWATCH:\n            timer.cancel()\n\n        elif action == PYCBC_EVACTION_CLEANUP:\n            timer.cleanup()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts watching the log files for new entries.", "response": "def start_watching(self):\n        \"\"\"\n        Start/Stop operations. This is a no-op in twisted because\n        it's a continuously running async loop\n        \"\"\"\n        if not self.is_sync:\n            return\n\n        self._stop = False\n        while not self._stop:\n            self.reactor.doIteration(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an item together with a series of options.", "response": "def add(self, itm, **options):\n        \"\"\"\n        Convenience method to add an item together with a series of options.\n\n        :param itm: The item to add\n        :param options: keyword arguments which will be placed in the item's\n            option entry.\n\n        If the item already exists, it (and its options) will be overidden. Use\n        :attr:`dict` instead to update options\n\n        \"\"\"\n        if not options:\n            options = None\n        self._d[itm] = options"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate and adds an item.", "response": "def create_and_add(self, key, value=None, cas=0, **options):\n        \"\"\"\n        Creates and adds an item.\n        :param key: The key to use for the item\n        :param value: The value to use for the item\n        :param options: Additional operation-specific options\n        \"\"\"\n        itm = Item(key, value)\n        itm.cas = cas\n        return self.add(itm, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deprecate_module_attribute(mod, deprecated):\n    deprecated = set(deprecated)\n\n    class Wrapper(object):\n        def __getattr__(self, attr):\n            if attr in deprecated:\n                warnings.warn(\"Property %s is deprecated\" % attr)\n\n            return getattr(mod, attr)\n\n        def __setattr__(self, attr, value):\n            if attr in deprecated:\n                warnings.warn(\"Property %s is deprecated\" % attr)\n            return setattr(mod, attr, value)\n    return Wrapper()", "response": "Returns a wrapped object that warns about deprecated accesses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets details about a given result.", "response": "def get(self, path_or_index, default=None):\n        \"\"\"\n        Get details about a given result\n\n        :param path_or_index: The path (or index) of the result to fetch.\n        :param default: If the given result does not exist, return this value\n            instead\n        :return: A tuple of `(error, value)`. If the entry does not exist\n            then `(err, default)` is returned, where `err` is the actual error\n            which occurred.\n            You can use :meth:`couchbase.exceptions.CouchbaseError.rc_to_exctype`\n            to convert the error code to a proper exception class\n        :raise: :exc:`IndexError` or :exc:`KeyError` if `path_or_index`\n            is not an initially requested path. This is a programming error\n            as opposed to a constraint error where the path is not found.\n        \"\"\"\n        err, value = self._resolve(path_or_index)\n        value = default if err else value\n        return err, value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exists(self, path_or_index):\n        result = self._resolve(path_or_index)\n        if not result[0]:\n            return True\n        elif E.SubdocPathNotFoundError._can_derive(result[0]):\n            return False\n        else:\n            raise E.exc_from_rc(result[0])", "response": "Checks if a path exists in the document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until a client instance is available in the pool.", "response": "def get_client(self, initial_timeout=0.05, next_timeout=200):\n        \"\"\"\n        Wait until a client instance is available\n        :param float initial_timeout:\n          how long to wait initially for an existing client to complete\n        :param float next_timeout:\n          if the pool could not obtain a client during the initial timeout,\n          and we have allocated the maximum available number of clients, wait\n          this long until we can retrieve another one\n\n        :return: A connection object\n        \"\"\"\n        try:\n            return self._q.get(True, initial_timeout)\n        except Empty:\n            try:\n                self._lock.acquire()\n                if self._cur_clients == self._max_clients:\n                    raise ClientUnavailableError(\"Too many clients in use\")\n                cb = self._make_client()\n                self._cur_clients += 1\n                cb.start_using()\n                return cb\n            except ClientUnavailableError as ex:\n                try:\n                    return self._q.get(True, next_timeout)\n                except Empty:\n                    raise ex\n            finally:\n                self._lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrelease a connection from the pool", "response": "def release_client(self, cb):\n        \"\"\"\n        Return a Connection object to the pool\n        :param Connection cb: the client to release\n        \"\"\"\n        cb.stop_using()\n        self._q.put(cb, True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a 3 - tuple suitable for passing to the underlying C extension.", "response": "def _gen_3spec(op, path, xattr=False):\n    \"\"\"\n    Returns a Spec tuple suitable for passing to the underlying C extension.\n    This variant is called for operations that lack an input value.\n\n    :param str path: The path to fetch\n    :param bool xattr: Whether this is an extended attribute\n    :return: a spec suitable for passing to the underlying C extension\n    \"\"\"\n    flags = 0\n    if xattr:\n        flags |= _P.SDSPEC_F_XATTR\n    return Spec(op, path, flags)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike _gen_3spec but also accepts a mandatory value as its third argument.", "response": "def _gen_4spec(op, path, value,\n               create_path=False, xattr=False, _expand_macros=False):\n    \"\"\"\n    Like `_gen_3spec`, but also accepts a mandatory value as its third argument\n    :param bool _expand_macros: Whether macros in the value should be expanded.\n        The macros themselves are defined at the server side\n    \"\"\"\n    flags = 0\n    if create_path:\n        flags |= _P.SDSPEC_F_MKDIR_P\n    if xattr:\n        flags |= _P.SDSPEC_F_XATTR\n    if _expand_macros:\n        flags |= _P.SDSPEC_F_EXPANDMACROS\n    return Spec(op, path, flags, value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upsert(path, value, create_parents=False, **kwargs):\n    return _gen_4spec(LCB_SDCMD_DICT_UPSERT, path, value,\n                      create_path=create_parents, **kwargs)", "response": "Create or replace a dictionary path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing an existing path with a new value.", "response": "def replace(path, value, **kwargs):\n    \"\"\"\n    Replace an existing path. This works on any valid path if the path already\n    exists. Valid only in :cb_bmeth:`mutate_in`\n\n    :param path: The path to replace\n    :param value: The new value\n    \"\"\"\n    return _gen_4spec(LCB_SDCMD_REPLACE, path, value,\n                      create_path=False, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new path in the document.", "response": "def insert(path, value, create_parents=False, **kwargs):\n    \"\"\"\n    Create a new path in the document. The final path element points to a\n    dictionary key that should be created. Valid only in :cb_bmeth:`mutate_in`\n\n    :param path: The path to create\n    :param value: Value for the path\n    :param create_parents: Whether intermediate parents should be created\n    \"\"\"\n    return _gen_4spec(LCB_SDCMD_DICT_ADD, path, value,\n                      create_path=create_parents, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef array_append(path, *values, **kwargs):\n    return _gen_4spec(LCB_SDCMD_ARRAY_ADD_LAST, path,\n                      MultiValue(*values),\n                      create_path=kwargs.pop('create_parents', False),\n                      **kwargs)", "response": "Adds new values to the end of an array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef array_prepend(path, *values, **kwargs):\n    return _gen_4spec(LCB_SDCMD_ARRAY_ADD_FIRST, path,\n                      MultiValue(*values),\n                      create_path=kwargs.pop('create_parents', False),\n                      **kwargs)", "response": "Adds new values to the beginning of an array."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts items at a given position within an array.", "response": "def array_insert(path, *values, **kwargs):\n    \"\"\"\n    Insert items at a given position within an array.\n\n    :param path: The path indicating where the item should be placed. The path\n        _should_ contain the desired position\n    :param values: Values to insert\n\n    This operation is only valid in :cb_bmeth:`mutate_in`.\n\n    .. seealso:: :func:`array_prepend`, :func:`upsert`\n    \"\"\"\n    return _gen_4spec(LCB_SDCMD_ARRAY_INSERT, path,\n                      MultiValue(*values), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new value to an array if the value does not exist.", "response": "def array_addunique(path, value, create_parents=False, **kwargs):\n    \"\"\"\n    Add a new value to an array if the value does not exist.\n\n    :param path: The path to the array\n    :param value: Value to add to the array if it does not exist.\n        Currently the value is restricted to primitives: strings, numbers,\n        booleans, and `None` values.\n    :param create_parents: Create the array if it does not exist\n\n    .. note::\n\n        The actual position of the new item is unspecified. This means\n        it may be at the beginning, end, or middle of the existing\n        array)\n\n    This operation is only valid in :cb_bmeth:`mutate_in`.\n\n    .. seealso:: :func:`array_append`, :func:`upsert`\n    \"\"\"\n    return _gen_4spec(LCB_SDCMD_ARRAY_ADD_UNIQUE, path, value,\n                      create_path=create_parents, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nincrementing or decrement a counter in a document.", "response": "def counter(path, delta, create_parents=False, **kwargs):\n    \"\"\"\n    Increment or decrement a counter in a document.\n\n    :param path: Path to the counter\n    :param delta: Amount by which to modify the value. The delta\n        can be negative but not 0. It must be an integer (not a float)\n        as well.\n    :param create_parents: Create the counter (and apply the modification) if it\n        does not exist\n\n    .. note::\n\n        Unlike :meth:`couchbase.bucket.Bucket.counter`,\n        there is no `initial` argument. If the counter does not exist\n        within the document (but its parent does, or `create_parents`\n        is true), it will be initialized with the value of the `delta`.\n\n    This operation is only valid in :cb_bmeth:`mutate_in`.\n\n    .. seealso:: :func:`upsert`, :cb_bmeth:`counter` (in `Bucket`)\n    \"\"\"\n    if not delta:\n        raise ValueError(\"Delta must be positive or negative!\")\n    return _gen_4spec(LCB_SDCMD_COUNTER, path, delta,\n                      create_path=create_parents, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_bucket(self):\n        self.logger.info('Deleting old bucket first')\n        del_url = '{0}/buckets/{1}'.format(self.cluster_prefix, self.bucket)\n        r = self._htsess.delete(del_url)\n\n        try:\n            r.raise_for_status()\n        except:\n            self.logger.exception(\"Couldn't delete bucket\")\n\n        cr_url = '{0}/buckets'.format(self.cluster_prefix)\n        data = {\n            'name': self.bucket,\n            'ramQuotaMB': '{0}'.format(self.quota),\n            'bucketType': 'couchbase',\n            'authType': 'sasl',\n            'saslPassword': '',\n            'replicaNumber': '0'\n        }\n        r = self._htsess.post(cr_url, data)\n        r.raise_for_status()", "response": "Prepares the destination bucket for use."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the type of authenticator to use when opening buckets or performing cluster management operations.", "response": "def authenticate(self, authenticator=None, username=None, password=None):\n        \"\"\"\n        Set the type of authenticator to use when opening buckets or performing\n        cluster management operations\n        :param authenticator: The new authenticator to use\n        :param username: The username to authenticate with\n        :param password: The password to authenticate with\n        \"\"\"\n        if authenticator is None:\n            if not username:\n                raise ValueError('username must not be empty.')\n            if not password:\n                raise ValueError('password must not be empty.')\n            authenticator = PasswordAuthenticator(username, password)\n\n        self.authenticator = authenticator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_bucket(self, bucket_name, **kwargs):\n        # type: (str, str) -> Bucket\n        \"\"\"\n        Open a new connection to a Couchbase bucket\n        :param bucket_name: The name of the bucket to open\n        :param kwargs: Additional arguments to provide to the constructor\n        :return: An instance of the `bucket_class` object provided to\n            :meth:`__init__`\n        \"\"\"\n        if self.authenticator:\n            auth_credentials_full = self.authenticator.get_auto_credentials(bucket_name)\n        else:\n            auth_credentials_full = {'options': {}}\n\n        auth_credentials = auth_credentials_full['options']\n\n        connstr = ConnectionString.parse(str(self.connstr))\n\n        connstr.bucket = bucket_name\n        for attrib in set(auth_credentials) - {'password'}:\n            connstr.set_option(attrib, auth_credentials[attrib])\n\n        # Check if there are conflicting authentication types in any of the parameters\n        # Also sets its own 'auth_type' field to the type of authentication it\n        # thinks is being specified\n\n        normalizer = Cluster.ParamNormaliser(self.authenticator, connstr, **kwargs)\n\n        # we don't do anything with this information unless the Normaliser thinks\n        # Cert Auth is involved as this is outside the remit of PYCBC-487/488/489\n\n        if issubclass(normalizer.auth_type, CertAuthenticator) or issubclass(type(self.authenticator),\n                                                                             CertAuthenticator):\n            # TODO: check_clash_free_params/check_no_unwanted_keys including connstr options\n            # should probably apply to PasswordAuthenticator as well,\n            # but outside remit of PYCBC-487\n\n            # TODO: do we accept clashing/unwanted options in connstr/kwargs e.g. password?\n            # Here, we throw an exception\n            # in the case of any clash/unwanted options, but we could scrub\n            # clashing/unwanted options from connstr/kwargs\n\n            normalizer.check_no_unwanted_keys()\n            normalizer.check_clash_free_params()\n            normalizer.assert_no_critical_complaints()\n\n        if 'password' in kwargs:\n            if isinstance(self.authenticator, PasswordAuthenticator):\n                raise MixedAuthError(\"Cannot override \"\n                                     \"PasswordAuthenticators password\")\n        else:\n            kwargs['password'] = auth_credentials.get('password', None)\n        connstr.scheme = auth_credentials_full.get('scheme', connstr.scheme)\n        rv = self.bucket_class(str(connstr), **kwargs)\n        self._buckets[bucket_name] = weakref.ref(rv)\n        if isinstance(self.authenticator, ClassicAuthenticator):\n            for bucket, passwd in self.authenticator.buckets.items():\n                if passwd:\n                    rv.add_bucket_creds(bucket, passwd)\n        return rv", "response": "Open a new connection to a Couchbase bucket."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cluster_manager(self):\n        credentials = self.authenticator.get_credentials()['options']\n        connection_string = str(self.connstr)\n        return Admin(credentials.get('username'), credentials.get('password'), connection_string=connection_string)", "response": "Returns an instance of ~. couchbase. admin. Admin which may be\n        used to create and manage buckets in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nissues a cluster - level query. This requires that at least one active bucket is active.", "response": "def n1ql_query(self, query, *args, **kwargs):\n        \"\"\"\n        Issue a \"cluster-level\" query. This requires that at least one\n        connection to a bucket is active.\n        :param query: The query string or object\n        :param args: Additional arguments to :cb_bmeth:`n1ql_query`\n\n        .. seealso:: :cb_bmeth:`n1ql_query`\n        \"\"\"\n        from couchbase.n1ql import N1QLQuery\n        if not isinstance(query, N1QLQuery):\n            query = N1QLQuery(query)\n\n        query.cross_bucket = True\n\n        to_purge = []\n        for k, v in self._buckets.items():\n            bucket = v()\n            if bucket:\n                return bucket.n1ql_query(query, *args, **kwargs)\n            else:\n                to_purge.append(k)\n\n        for k in to_purge:\n            del self._buckets[k]\n\n        raise NoBucketError('Must have at least one active bucket for query')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_auto_credentials(self, bucket):\n\n        result = {k: v(self) for k, v in self.get_unique_creds_dict().items()}\n        if bucket:\n            result.update(self.get_cred_bucket(bucket))\n        else:\n            result.update(self.get_cred_not_bucket())\n        return result", "response": "returns a dictionary of credentials for bucket and admin"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(cls, s):\n        d = couchbase._from_json(s)\n        o = MutationState()\n        o._sv = d", "response": "Create a new MutationState from the encoded string s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_results(self, *rvs, **kwargs):\n        if not rvs:\n            raise MissingTokenError.pyexc(message='No results passed')\n        for rv in rvs:\n            mi = rv._mutinfo\n            if not mi:\n                if kwargs.get('quiet'):\n                    return False\n                raise MissingTokenError.pyexc(\n                    message='Result does not contain token')\n            self._add_scanvec(mi)\n        return True", "response": "Adds the given result to the state."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_all(self, bucket, quiet=False):\n        added = False\n        for mt in bucket._mutinfo():\n            added = True\n            self._add_scanvec(mt)\n        if not added and not quiet:\n            raise MissingTokenError('Bucket object contains no tokens!')\n        return added", "response": "Adds all the mutations performed by a given bucket to the query result."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns all keyword arguments to a given instance.", "response": "def _assign_kwargs(self, kwargs):\n    \"\"\"\n    Assigns all keyword arguments to a given instance, raising an exception\n    if one of the keywords is not already the name of a property.\n    \"\"\"\n    for k in kwargs:\n        if not hasattr(self, k):\n            raise AttributeError(k, 'Not valid for', self.__class__.__name__)\n        setattr(self, k, kwargs[k])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a named range specification for encoding.", "response": "def _mk_range_bucket(name, n1, n2, r1, r2):\n    \"\"\"\n    Create a named range specification for encoding.\n\n    :param name: The name of the range as it should appear in the result\n    :param n1: The name of the lower bound of the range specifier\n    :param n2: The name of the upper bound of the range specified\n    :param r1: The value of the lower bound (user value)\n    :param r2: The value of the upper bound (user value)\n    :return: A dictionary containing the range bounds. The upper and lower\n        bounds are keyed under ``n1`` and ``n2``.\n\n    More than just a simple wrapper, this will not include any range bound\n    which has a user value of `None`. Likewise it will raise an exception if\n    both range values are ``None``.\n    \"\"\"\n    d = {}\n    if r1 is not None:\n        d[n1] = r1\n    if r2 is not None:\n        d[n2] = r2\n    if not d:\n        raise TypeError('Must specify at least one range boundary!')\n    d['name'] = name\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclasses decorator to include common query fields :param fields: List of fields to include. These should be keys of the `_COMMON_FIELDS` dict", "response": "def _with_fields(*fields):\n    \"\"\"\n    Class decorator to include common query fields\n    :param fields: List of fields to include. These should be keys of the\n        `_COMMON_FIELDS` dict\n    \"\"\"\n    dd = {}\n    for x in fields:\n        dd[x] = _COMMON_FIELDS[x]\n\n    def wrap(cls):\n        dd.update(cls.__dict__)\n        return type(cls.__name__, cls.__bases__, dd)\n\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_search_body(index, query, params=None):\n    dd = {}\n\n    if not isinstance(query, Query):\n        query = QueryStringQuery(query)\n\n    dd['query'] = query.encodable\n    if params:\n        dd.update(params.as_encodable(index))\n    dd['indexName'] = index\n    return dd", "response": "Generates a dictionary suitable for encoding as the search body"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_range(self, name, start=None, end=None):\n        self._ranges.append(_mk_range_bucket(name, 'start', 'end', start, end))\n        return self", "response": "Adds a date range to the given facet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a numeric range to the set of results.", "response": "def add_range(self, name, min=None, max=None):\n        \"\"\"\n        Add a numeric range.\n\n        :param str name:\n            the name by which the range is accessed in the results\n        :param int | float min: Lower range bound\n        :param int | float max: Upper range bound\n        :return: This object; suitable for method chaining\n        \"\"\"\n        self._ranges.append(_mk_range_bucket(name, 'min', 'max', min, max))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_encodable(self, index_name):\n        if self.facets:\n            encoded_facets = {}\n            for name, facet in self.facets.items():\n                encoded_facets[name] = facet.encodable\n            self._json_['facets'] = encoded_facets\n\n        if self._ms:\n            # Encode according to scan vectors..\n            sv_val = {\n                'level': 'at_plus',\n                'vectors': {\n                    index_name: self._ms._to_fts_encodable()\n                }\n            }\n            self._json_.setdefault('ctl', {})['consistency'] = sv_val\n\n        if self.sort:\n            if isinstance(self.sort, Sort):\n                self._json_['sort'] = self.sort.as_encodable()\n            else:\n                self._json_['sort'] = self.sort\n\n        return self._json_", "response": "Returns the json representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of keyword arguments pop recognized arguments from a keyword list.", "response": "def mk_kwargs(cls, kwargs):\n        \"\"\"\n        Pop recognized arguments from a keyword list.\n        \"\"\"\n        ret = {}\n        kws = ['row_factory', 'body', 'parent']\n        for k in kws:\n            if k in kwargs:\n                ret[k] = kwargs.pop(k)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef meta(self):\n        if not self.__meta_received:\n            raise RuntimeError(\n                'This property only valid once all rows are received!')\n\n        if isinstance(self.raw.value, dict):\n            return self.raw.value\n        return {}", "response": "Get metadata from the query itself. This is guaranteed to only\n        return a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_named_args(self, **kv):\n        for k in kv:\n            self._body['${0}'.format(k)] = kv[k]\n        return self", "response": "Set a named parameter in the query."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_pos_args(self, *args):\n        arg_array = self._body.setdefault('args', [])\n        arg_array.extend(args)", "response": "Add positional placeholders to the request body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef consistent_with(self, state):\n        if self.consistency not in (UNBOUNDED, NOT_BOUNDED, 'at_plus'):\n            raise TypeError(\n                'consistent_with not valid with other consistency options')\n\n        if not state:\n            raise TypeError('Passed empty or invalid state', state)\n        self.consistency = 'at_plus'\n        self._body['scan_vectors'] = state._sv", "response": "Indicate that the query should be consistent with one or more mutations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the effective timeout for the query.", "response": "def timeout(self):\n        \"\"\"\n        Optional per-query timeout. If set, this will limit the amount\n        of time in which the query can be executed and waited for.\n\n        .. note::\n\n            The effective timeout for the query will be either this property\n            or the value of :attr:`couchbase.bucket.Bucket.n1ql_timeout`\n            property, whichever is *lower*.\n\n        .. seealso:: couchbase.bucket.Bucket.n1ql_timeout\n        \"\"\"\n        value = self._body.get('timeout', '0s')\n        value = value[:-1]\n        return float(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the profile of the N1QL object.", "response": "def profile(self, value):\n        \"\"\"\n        Sets the N1QL profile type. Must be one of: 'off', 'phases', 'timings'\n        :param value: The profile type to use.\n        :return:\n        \"\"\"\n        if value not in VALID_PROFILES:\n            raise TypeError('Profile option must be one of: ' + ', '.join(VALID_PROFILES))\n\n        self._body['profile'] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef meta_retrieve(self, meta_lookahead = None):\n        if not self.__meta_received:\n            if meta_lookahead or self.meta_lookahead:\n                self.buffered_remainder = list(self)\n            else:\n                raise RuntimeError(\n                    'This property only valid once all rows are received!')\n\n        if isinstance(self.raw.value, dict):\n            return self.raw.value\n        return {}", "response": "This method is called by the query_retrieve method of the base class to retrieve the metadata from the query itself. This method is called by the meta_retrieve method of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_ready(self):\n        while not self.finish_time or time.time() < self.finish_time:\n            result=self._poll_deferred()\n            if result=='success':\n                return True\n            if result=='failed':\n                raise couchbase.exceptions.InternalError(\"Failed exception\")\n            time.sleep(self.interval)\n\n        raise couchbase.exceptions.TimeoutError(\"Deferred query timed out\")", "response": "Check if a final result has been received and if it has not been received."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the version from the generated version file without actually loading it.", "response": "def get_version():\n    \"\"\"\n    Returns the version from the generated version file without actually\n    loading it (and thus trying to load the extension module).\n    \"\"\"\n    if not os.path.exists(VERSION_FILE):\n        raise VersionNotFound(VERSION_FILE + \" does not exist\")\n    fp = open(VERSION_FILE, \"r\")\n    vline = None\n    for x in fp.readlines():\n        x = x.rstrip()\n        if not x:\n            continue\n        if not x.startswith(\"__version__\"):\n            continue\n\n        vline = x.split('=')[1]\n        break\n    if not vline:\n        raise VersionNotFound(\"version file present but has no contents\")\n\n    return vline.strip().rstrip().replace(\"'\", '')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_version(do_write=True, txt=None):\n\n    if txt is None:\n        txt = get_git_describe()\n\n    try:\n        info = VersionInfo(txt)\n        vstr = info.package_version\n    except MalformedGitTag:\n        warnings.warn(\"Malformed input '{0}'\".format(txt))\n        vstr = '0.0.0'+txt\n\n    if not do_write:\n        print(vstr)\n        return\n\n    lines = (\n        '# This file automatically generated by',\n        '#    {0}'.format(__file__),\n        '# at',\n        '#    {0}'.format(datetime.datetime.now().isoformat(' ')),\n        \"__version__ = '{0}'\".format(vstr)\n    )\n    with open(VERSION_FILE, \"w\") as fp:\n        fp.write(\"\\n\".join(lines))", "response": "Generate a version based on git tag info."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef base_version(self):\n        components = [self.xyz_version]\n        if self.ver_extra:\n            components.append(self.ver_extra)\n        return ''.join(components)", "response": "Returns the actual upstream version without dev info"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef package_version(self):\n        vbase = self.base_version\n        if self.ncommits:\n            vbase += '.dev{0}+{1}'.format(self.ncommits, self.sha)\n        return vbase", "response": "Returns the well formed PEP - 440 version of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads and install something if prerequisite fails", "response": "def download_and_bootstrap(src, name, prereq=None):\n    \"\"\"\n    Download and install something if 'prerequisite' fails\n    \"\"\"\n    if prereq:\n        prereq_cmd = '{0} -c \"{1}\"'.format(PY_EXE, prereq)\n        rv = os.system(prereq_cmd)\n        if rv == 0:\n            return\n\n    ulp = urllib2.urlopen(src)\n    fp = open(name, \"wb\")\n    fp.write(ulp.read())\n    fp.close()\n    cmdline = \"{0} {1}\".format(PY_EXE, name)\n    rv = os.system(cmdline)\n    assert rv == 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _register_opt(parser, *args, **kwargs):\n        try:\n            # Flake8 3.x registration\n            parser.add_option(*args, **kwargs)\n        except (optparse.OptionError, TypeError):\n            # Flake8 2.x registration\n            parse_from_config = kwargs.pop('parse_from_config', False)\n            option = parser.add_option(*args, **kwargs)\n            if parse_from_config:\n                parser.config_options.append(option.get_opt_string().lstrip('-'))", "response": "Handler to register an option for both Flake8 3. x and 2. x."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a dict and returns an immutable hashable version of that dict that can be used as a key in dicts or as a set value.", "response": "def dict_to_hashable(d):\n    \"\"\"\n    Takes a dict and returns an immutable, hashable version of that dict that can be used as a key in dicts or as a\n    set value. Any two dicts passed in with the same content are guaranteed to return the same value. Any two dicts\n    passed in with different content are guaranteed to return different values. Performs comparatively to `repr`.\n\n    >> %timeit repr(d1)\n    The slowest run took 5.76 times longer than the fastest. This could mean that an intermediate result is being cached\n    100000 loops, best of 3: 3.48 \u00b5s per loop\n\n    >> %timeit dict_to_hashable(d1)\n    The slowest run took 4.16 times longer than the fastest. This could mean that an intermediate result is being cached\n    100000 loops, best of 3: 4.07 \u00b5s per loop\n\n    :param d: The dict\n    :return: The hashable representation of the dict\n    \"\"\"\n    return frozenset(\n        (k, tuple(v) if isinstance(v, list) else (dict_to_hashable(v) if isinstance(v, dict) else v))\n        for k, v in six.iteritems(d)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_python_path(path):\n    # Get the module\n    module_path, local_path = path.split(':', 1)\n    thing = importlib.import_module(module_path)\n    # Traverse the local sections\n    local_bits = local_path.split('.')\n    for bit in local_bits:\n        thing = getattr(thing, bit)\n    return thing", "response": "Converts a python path like module. name. here. ClassName. SubClass into an object\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, request):\n        if request.body.get('action_name'):\n            return self._get_response_for_single_action(request.body.get('action_name'))\n\n        return self._get_response_for_all_actions()", "response": "Introspects all of the actions on the server and returns their documentation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_middleware_stack(middleware, base):\n        for ware in reversed(middleware):\n            base = ware(base)\n        return base", "response": "Given a list of in - order middleware callables and a base function base returns the top level ready to call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_request(self, job_request, message_expiry_in_seconds=None):\n        request_id = self.request_counter\n        self.request_counter += 1\n        meta = {}\n        wrapper = self._make_middleware_stack(\n            [m.request for m in self.middleware],\n            self._base_send_request,\n        )\n        try:\n            with self.metrics.timer('client.send.including_middleware', resolution=TimerResolution.MICROSECONDS):\n                wrapper(request_id, meta, job_request, message_expiry_in_seconds)\n            return request_id\n        finally:\n            self.metrics.commit()", "response": "Send a JobRequest and return the request ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator that yields all available responses from the transport.", "response": "def get_all_responses(self, receive_timeout_in_seconds=None):\n        \"\"\"\n        Receive all available responses from the transport as a generator.\n\n        :param receive_timeout_in_seconds: How long to block without receiving a message before raising\n                                           `MessageReceiveTimeout` (defaults to five seconds unless the settings are\n                                           otherwise).\n        :type receive_timeout_in_seconds: int\n\n        :return: A generator that yields (request ID, job response)\n        :rtype: generator\n\n        :raise: ConnectionError, MessageReceiveError, MessageReceiveTimeout, InvalidMessage, StopIteration\n        \"\"\"\n\n        wrapper = self._make_middleware_stack(\n            [m.response for m in self.middleware],\n            self._get_response,\n        )\n        try:\n            while True:\n                with self.metrics.timer('client.receive.including_middleware', resolution=TimerResolution.MICROSECONDS):\n                    request_id, response = wrapper(receive_timeout_in_seconds)\n                if response is None:\n                    break\n                yield request_id, response\n        finally:\n            self.metrics.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild and sends a single action request with one action.", "response": "def call_action(self, service_name, action, body=None, **kwargs):\n        \"\"\"\n        Build and send a single job request with one action.\n\n        Returns the action response or raises an exception if the action response is an error (unless\n        `raise_action_errors` is passed as `False`) or if the job response is an error (unless `raise_job_errors` is\n        passed as `False`).\n\n        :param service_name: The name of the service to call\n        :type service_name: union[str, unicode]\n        :param action: The name of the action to call\n        :type action: union[str, unicode]\n        :param body: The action request body\n        :type body: dict\n        :param expansions: A dictionary representing the expansions to perform\n        :type expansions: dict\n        :param raise_job_errors: Whether to raise a JobError if the job response contains errors (defaults to `True`)\n        :type raise_job_errors: bool\n        :param raise_action_errors: Whether to raise a CallActionError if any action responses contain errors (defaults\n                                    to `True`)\n        :type raise_action_errors: bool\n        :param timeout: If provided, this will override the default transport timeout values to; requests will expire\n                        after this number of seconds plus some buffer defined by the transport, and the client will not\n                        block waiting for a response for longer than this amount of time.\n        :type timeout: int\n        :param switches: A list of switch value integers\n        :type switches: list\n        :param correlation_id: The request correlation ID\n        :type correlation_id: union[str, unicode]\n        :param continue_on_error: Whether to continue executing further actions once one action has returned errors\n        :type continue_on_error: bool\n        :param context: A dictionary of extra values to include in the context header\n        :type context: dict\n        :param control_extra: A dictionary of extra values to include in the control header\n        :type control_extra: dict\n\n        :return: The action response\n        :rtype: ActionResponse\n\n        :raise: ConnectionError, InvalidField, MessageSendError, MessageSendTimeout, MessageTooLarge,\n                MessageReceiveError, MessageReceiveTimeout, InvalidMessage, JobError, CallActionError\n        \"\"\"\n        return self.call_action_future(service_name, action, body, **kwargs).result()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_actions(\n        self,\n        service_name,\n        actions,\n        expansions=None,\n        raise_job_errors=True,\n        raise_action_errors=True,\n        timeout=None,\n        **kwargs\n    ):\n        \"\"\"\n        Build and send a single job request with one or more actions.\n\n        Returns a list of action responses, one for each action in the same order as provided, or raises an exception\n        if any action response is an error (unless `raise_action_errors` is passed as `False`) or if the job response\n        is an error (unless `raise_job_errors` is passed as `False`).\n\n        This method performs expansions if the Client is configured with an expansion converter.\n\n        :param service_name: The name of the service to call\n        :type service_name: union[str, unicode]\n        :param actions: A list of `ActionRequest` objects and/or dicts that can be converted to `ActionRequest` objects\n        :type actions: iterable[union[ActionRequest, dict]]\n        :param expansions: A dictionary representing the expansions to perform\n        :type expansions: dict\n        :param raise_job_errors: Whether to raise a JobError if the job response contains errors (defaults to `True`)\n        :type raise_job_errors: bool\n        :param raise_action_errors: Whether to raise a CallActionError if any action responses contain errors (defaults\n                                    to `True`)\n        :type raise_action_errors: bool\n        :param timeout: If provided, this will override the default transport timeout values to; requests will expire\n                        after this number of seconds plus some buffer defined by the transport, and the client will not\n                        block waiting for a response for longer than this amount of time.\n        :type timeout: int\n        :param switches: A list of switch value integers\n        :type switches: list\n        :param correlation_id: The request correlation ID\n        :type correlation_id: union[str, unicode]\n        :param continue_on_error: Whether to continue executing further actions once one action has returned errors\n        :type continue_on_error: bool\n        :param context: A dictionary of extra values to include in the context header\n        :type context: dict\n        :param control_extra: A dictionary of extra values to include in the control header\n        :type control_extra: dict\n\n        :return: The job response\n        :rtype: JobResponse\n\n        :raise: ConnectionError, InvalidField, MessageSendError, MessageSendTimeout, MessageTooLarge,\n                MessageReceiveError, MessageReceiveTimeout, InvalidMessage, JobError, CallActionError\n        \"\"\"\n        return self.call_actions_future(\n            service_name,\n            actions,\n            expansions,\n            raise_job_errors,\n            raise_action_errors,\n            timeout,\n            **kwargs\n        ).result()", "response": "Builds and sends a single job request with one or more actions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_actions_parallel(self, service_name, actions, **kwargs):\n        return self.call_actions_parallel_future(service_name, actions, **kwargs).result()", "response": "Builds and sends multiple job requests to one service each action with one action to be executed in parallel and returns once all responses have been received."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef call_jobs_parallel(\n        self,\n        jobs,\n        expansions=None,\n        raise_job_errors=True,\n        raise_action_errors=True,\n        catch_transport_errors=False,\n        timeout=None,\n        **kwargs\n    ):\n        \"\"\"\n        Build and send multiple job requests to one or more services, each with one or more actions, to be executed in\n        parallel, and return once all responses have been received.\n\n        Returns a list of job responses, one for each job in the same order as provided, or raises an exception if any\n        job response is an error (unless `raise_job_errors` is passed as `False`) or if any action response is an\n        error (unless `raise_action_errors` is passed as `False`).\n\n        This method performs expansions if the Client is configured with an expansion converter.\n\n        :param jobs: A list of job request dicts, each containing `service_name` and `actions`, where `actions` is a\n                     list of `ActionRequest` objects and/or dicts that can be converted to `ActionRequest` objects\n        :type jobs: iterable[dict(service_name=union[str, unicode], actions=list[union[ActionRequest, dict]])]\n        :param expansions: A dictionary representing the expansions to perform\n        :type expansions: dict\n        :param raise_job_errors: Whether to raise a JobError if any job responses contain errors (defaults to `True`)\n        :type raise_job_errors: bool\n        :param raise_action_errors: Whether to raise a CallActionError if any action responses contain errors (defaults\n                                    to `True`)\n        :type raise_action_errors: bool\n        :param catch_transport_errors: Whether to catch transport errors and return them instead of letting them\n                                       propagate. By default (`False`), the errors `ConnectionError`,\n                                       `InvalidMessageError`, `MessageReceiveError`, `MessageReceiveTimeout`,\n                                       `MessageSendError`, `MessageSendTimeout`, and `MessageTooLarge`, when raised by\n                                       the transport, cause the entire process to terminate, potentially losing\n                                       responses. If this argument is set to `True`, those errors are, instead, caught,\n                                       and they are returned in place of their corresponding responses in the returned\n                                       list of job responses.\n        :type catch_transport_errors: bool\n        :param timeout: If provided, this will override the default transport timeout values to; requests will expire\n                        after this number of seconds plus some buffer defined by the transport, and the client will not\n                        block waiting for a response for longer than this amount of time.\n        :type timeout: int\n        :param switches: A list of switch value integers\n        :type switches: list\n        :param correlation_id: The request correlation ID\n        :type correlation_id: union[str, unicode]\n        :param continue_on_error: Whether to continue executing further actions once one action has returned errors\n        :type continue_on_error: bool\n        :param context: A dictionary of extra values to include in the context header\n        :type context: dict\n        :param control_extra: A dictionary of extra values to include in the control header\n        :type control_extra: dict\n\n        :return: The job response\n        :rtype: list[union(JobResponse, Exception)]\n\n        :raise: ConnectionError, InvalidField, MessageSendError, MessageSendTimeout, MessageTooLarge,\n                MessageReceiveError, MessageReceiveTimeout, InvalidMessage, JobError, CallActionError\n        \"\"\"\n        return self.call_jobs_parallel_future(\n            jobs,\n            expansions=expansions,\n            raise_job_errors=raise_job_errors,\n            raise_action_errors=raise_action_errors,\n            catch_transport_errors=catch_transport_errors,\n            timeout=timeout,\n            **kwargs\n        ).result()", "response": "This method builds and sends multiple jobs to one or more services each with one or more actions to be executed in the same order as provided in the base base."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_actions_future(\n        self,\n        service_name,\n        actions,\n        expansions=None,\n        raise_job_errors=True,\n        raise_action_errors=True,\n        timeout=None,\n        **kwargs\n    ):\n        \"\"\"\n        This method is identical in signature and behavior to `call_actions`, except that it sends the request and\n        then immediately returns a `FutureResponse` instead of blocking waiting on a response and returning a\n        `JobResponse`. Just call `result(timeout=None)` on the future response to block for an available\n        response. Some of the possible exceptions may be raised when this method is called; others may be raised when\n        the future is used.\n\n        :return: A future from which the job response can later be retrieved\n        :rtype: Client.FutureResponse\n        \"\"\"\n        kwargs.pop('suppress_response', None)  # If this kwarg is used, this method would always result in a timeout\n        if timeout:\n            kwargs['message_expiry_in_seconds'] = timeout\n\n        expected_request_id = self.send_request(service_name, actions, **kwargs)\n\n        def get_response(_timeout=None):\n            # Get all responses\n            responses = list(self.get_all_responses(service_name, receive_timeout_in_seconds=_timeout or timeout))\n\n            # Try to find the expected response\n            found = False\n            response = None\n            for request_id, response in responses:\n                if request_id == expected_request_id:\n                    found = True\n                    break\n            if not found:\n                # This error should be impossible if `get_all_responses` is behaving correctly, but let's raise a\n                # meaningful error just in case.\n                raise Exception(\n                    'Got unexpected response(s) with ID(s) {} for request with ID {}'.format(\n                        [r[0] for r in responses],\n                        expected_request_id,\n                    )\n                )\n\n            # Process errors at the Job and Action level\n            if response.errors and raise_job_errors:\n                raise self.JobError(response.errors)\n            if raise_action_errors:\n                error_actions = [action for action in response.actions if action.errors]\n                if error_actions:\n                    raise self.CallActionError(error_actions)\n\n            if expansions:\n                kwargs.pop('continue_on_error', None)\n                self._perform_expansion(response.actions, expansions, **kwargs)\n\n            return response\n\n        return self.FutureResponse(get_response)", "response": "This method sends a request to the specified service and returns a FutureResponse that can be used to block until the response is available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_jobs_parallel_future(\n        self,\n        jobs,\n        expansions=None,\n        raise_job_errors=True,\n        raise_action_errors=True,\n        catch_transport_errors=False,\n        timeout=None,\n        **kwargs\n    ):\n        \"\"\"\n        This method is identical in signature and behavior to `call_jobs_parallel`, except that it sends the requests\n        and then immediately returns a `FutureResponse` instead of blocking waiting on all responses and returning\n        a `list` of `JobResponses`. Just call `result(timeout=None)` on the future response to block for an available\n        response. Some of the possible exceptions may be raised when this method is called; others may be raised when\n        the future is used.\n\n        :return: A future from which the list of job responses can later be retrieved\n        :rtype: Client.FutureResponse\n        \"\"\"\n        kwargs.pop('suppress_response', None)  # If this kwarg is used, this method would always result in a timeout\n        if timeout:\n            kwargs['message_expiry_in_seconds'] = timeout\n\n        error_key = 0\n        transport_errors = {}\n\n        response_reassembly_keys = []\n        service_request_ids = {}\n        for job in jobs:\n            try:\n                sent_request_id = self.send_request(job['service_name'], job['actions'], **kwargs)\n                service_request_ids.setdefault(job['service_name'], set()).add(sent_request_id)\n            except (ConnectionError, InvalidMessageError, MessageSendError, MessageSendTimeout, MessageTooLarge) as e:\n                if not catch_transport_errors:\n                    raise\n                sent_request_id = error_key = error_key - 1\n                transport_errors[(job['service_name'], sent_request_id)] = e\n\n            response_reassembly_keys.append((job['service_name'], sent_request_id))\n\n        def get_response(_timeout):\n            service_responses = {}\n            for service_name, request_ids in six.iteritems(service_request_ids):\n                try:\n                    for request_id, response in self.get_all_responses(\n                        service_name,\n                        receive_timeout_in_seconds=_timeout or timeout,\n                    ):\n                        if request_id not in request_ids:\n                            raise Exception(\n                                'Got response ID {}, not in set of expected IDs {}'.format(request_id, request_ids)\n                            )\n                        service_responses[(service_name, request_id)] = response\n                        if catch_transport_errors:\n                            # We don't need the set to be reduced unless we're catching errors\n                            request_ids.remove(request_id)\n                except (ConnectionError, InvalidMessageError, MessageReceiveError, MessageReceiveTimeout) as e:\n                    if not catch_transport_errors:\n                        raise\n                    for request_id in request_ids:\n                        transport_errors[(service_name, request_id)] = e\n\n            responses = []\n            actions_to_expand = []\n            for service_name, request_id in response_reassembly_keys:\n                if request_id < 0:\n                    # A transport error occurred during send, and we are catching errors, so add it to the list\n                    responses.append(transport_errors[(service_name, request_id)])\n                    continue\n\n                if (service_name, request_id) not in service_responses:\n                    if (service_name, request_id) in transport_errors:\n                        # A transport error occurred during receive, and we are catching errors, so add it to the list\n                        responses.append(transport_errors[(service_name, request_id)])\n                        continue\n\n                    # It shouldn't be possible for this to happen unless the code has a bug, but let's raise a\n                    # meaningful exception just in case a bug exists, because KeyError will not be helpful.\n                    raise Exception('There was no response for service {}, request {}'.format(service_name, request_id))\n\n                response = service_responses[(service_name, request_id)]\n                if raise_job_errors and response.errors:\n                    raise self.JobError(response.errors)\n                if raise_action_errors:\n                    error_actions = [action for action in response.actions if action.errors]\n                    if error_actions:\n                        raise self.CallActionError(error_actions)\n                if expansions:\n                    actions_to_expand.extend(response.actions)\n\n                responses.append(response)\n\n            if expansions:\n                kwargs.pop('continue_on_error', None)\n                self._perform_expansion(actions_to_expand, expansions, **kwargs)\n\n            return responses\n\n        return self.FutureResponse(get_response)", "response": "This method sends the requests to the specified jobs and returns a FutureResponse that is returned when the response is received."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds and sends a JobRequest and returns the request ID.", "response": "def send_request(\n        self,\n        service_name,\n        actions,\n        switches=None,\n        correlation_id=None,\n        continue_on_error=False,\n        context=None,\n        control_extra=None,\n        message_expiry_in_seconds=None,\n        suppress_response=False,\n    ):\n        \"\"\"\n        Build and send a JobRequest, and return a request ID.\n\n        The context and control_extra arguments may be used to include extra values in the\n        context and control headers, respectively.\n\n        :param service_name: The name of the service from which to receive responses\n        :type service_name: union[str, unicode]\n        :param actions: A list of `ActionRequest` objects\n        :type actions: list\n        :param switches: A list of switch value integers\n        :type switches: union[list, set]\n        :param correlation_id: The request correlation ID\n        :type correlation_id: union[str, unicode]\n        :param continue_on_error: Whether to continue executing further actions once one action has returned errors\n        :type continue_on_error: bool\n        :param context: A dictionary of extra values to include in the context header\n        :type context: dict\n        :param control_extra: A dictionary of extra values to include in the control header\n        :type control_extra: dict\n        :param message_expiry_in_seconds: How soon the message will expire if not received by a server (defaults to\n                                          sixty seconds unless the settings are otherwise)\n        :type message_expiry_in_seconds: int\n        :param suppress_response: If `True`, the service will process the request normally but omit the step of\n                                  sending a response back to the client (use this feature to implement send-and-forget\n                                  patterns for asynchronous execution)\n        :type suppress_response: bool\n\n        :return: The request ID\n        :rtype: int\n\n        :raise: ConnectionError, InvalidField, MessageSendError, MessageSendTimeout, MessageTooLarge\n        \"\"\"\n\n        control_extra = control_extra.copy() if control_extra else {}\n        if message_expiry_in_seconds and 'timeout' not in control_extra:\n            control_extra['timeout'] = message_expiry_in_seconds\n\n        handler = self._get_handler(service_name)\n        control = self._make_control_header(\n            continue_on_error=continue_on_error,\n            control_extra=control_extra,\n            suppress_response=suppress_response,\n        )\n        context = self._make_context_header(\n            switches=switches,\n            correlation_id=correlation_id,\n            context_extra=context,\n        )\n        job_request = JobRequest(actions=actions, control=control, context=context or {})\n        return handler.send_request(job_request, message_expiry_in_seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a generator that yields all available responses from the service.", "response": "def get_all_responses(self, service_name, receive_timeout_in_seconds=None):\n        \"\"\"\n        Receive all available responses from the service as a generator.\n\n        :param service_name: The name of the service from which to receive responses\n        :type service_name: union[str, unicode]\n        :param receive_timeout_in_seconds: How long to block without receiving a message before raising\n                                           `MessageReceiveTimeout` (defaults to five seconds unless the settings are\n                                           otherwise).\n        :type receive_timeout_in_seconds: int\n\n        :return: A generator that yields (request ID, job response)\n        :rtype: generator\n\n        :raise: ConnectionError, MessageReceiveError, MessageReceiveTimeout, InvalidMessage, StopIteration\n        \"\"\"\n\n        handler = self._get_handler(service_name)\n        return handler.get_all_responses(receive_timeout_in_seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_reloader(main_module_name, watch_modules, signal_forks=False):\n    if USE_PY_INOTIFY:\n        return _PyInotifyReloader(main_module_name, watch_modules, signal_forks)\n    return _PollingReloader(main_module_name, watch_modules, signal_forks)", "response": "Returns a new reloader instance for the given main module name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self, for_shutdown=False, **_kwargs):\n        if for_shutdown:\n            super(PySOAMemcachedCache, self).close()", "response": "Only call super. close if the server is shutting down."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default(self, obj):\n        if isinstance(obj, datetime.datetime):\n            # Serialize date-time objects. Make sure they're naive.\n            if obj.tzinfo is not None:\n                raise TypeError('Cannot encode time zone-aware date-times to MessagePack')\n            # Then, work out the timestamp in seconds.\n            seconds = (obj - datetime.datetime(1970, 1, 1)).total_seconds()\n            microseconds = int(seconds * 1000000.0)\n            # Then pack it into a big-endian signed 64-bit integer.\n            return msgpack.ExtType(\n                self.EXT_DATETIME,\n                self.STRUCT_DATETIME.pack(microseconds),\n            )\n        elif isinstance(obj, datetime.date):\n            # Serialize local-date objects by packing to a big-endian unsigned short and two big-endian unsigned chars.\n            return msgpack.ExtType(\n                self.EXT_DATE,\n                self.STRUCT_DATE.pack(obj.year, obj.month, obj.day),\n            )\n        elif isinstance(obj, datetime.time):\n            # Serialize dateless-time objects by packing to three big-endian unsigned chars and a big-endian unsigned\n            # 32-bit integer.\n            return msgpack.ExtType(\n                self.EXT_TIME,\n                self.STRUCT_TIME.pack(obj.hour, obj.minute, obj.second, obj.microsecond),\n            )\n        elif isinstance(obj, decimal.Decimal):\n            obj_str = six.text_type(obj)[:65535].encode('utf-8')\n            obj_len = len(obj_str)\n            obj_encoder = struct.Struct(str('!H{}s'.format(obj_len)))\n            return msgpack.ExtType(\n                self.EXT_DECIMAL,\n                obj_encoder.pack(obj_len, obj_str),\n            )\n        elif isinstance(obj, currint.Amount):\n            # Serialize Amount objects. Start with the lowercased currency code as bytes.\n            code = obj.currency.code.upper()\n            if isinstance(code, six.text_type):\n                code = code.encode('ascii')\n            # Then pack it in with the minor value.\n            return msgpack.ExtType(\n                self.EXT_CURRINT,\n                self.STRUCT_CURRINT.pack(code, obj.value),\n            )\n        else:\n            # Wuh-woh\n            raise TypeError('Cannot encode value of type {} to MessagePack: {}'.format(type(obj).__name__, obj))", "response": "Serializes an unknown object into a MessagePack object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding a custom extension type from a messagepack message.", "response": "def ext_hook(self, code, data):\n        \"\"\"\n        Decodes our custom extension types\n        \"\"\"\n        if code == self.EXT_DATETIME:\n            # Unpack datetime object from a big-endian signed 64-bit integer.\n            microseconds = self.STRUCT_DATETIME.unpack(data)[0]\n            return datetime.datetime.utcfromtimestamp(microseconds / 1000000.0)\n        elif code == self.EXT_DATE:\n            # Unpack local-date object from a big-endian unsigned short and two big-endian unsigned chars\n            return datetime.date(*self.STRUCT_DATE.unpack(data))\n        elif code == self.EXT_TIME:\n            # Unpack a dateless-time object from three big-endian unsigned chars and a big-endian unsigned\n            # 32-bit integer.\n            return datetime.time(*self.STRUCT_TIME.unpack(data))\n        elif code == self.EXT_DECIMAL:\n            obj_len = self.STRUCT_DECIMAL_LENGTH.unpack(data[:2])[0]\n            obj_decoder = struct.Struct(str('!{}s'.format(obj_len)))\n            return decimal.Decimal(obj_decoder.unpack(data[2:])[0].decode('utf-8'))\n        elif code == self.EXT_CURRINT:\n            # Unpack Amount object into (code, minor) from a 3-char ASCII string and a signed 64-bit integer.\n            code, minor_value = self.STRUCT_CURRINT.unpack(data)\n            return currint.Amount.from_code_and_minor(code.decode('ascii'), minor_value)\n        else:\n            raise TypeError('Cannot decode unknown extension type {} from MessagePack'.format(code))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_request_message(self, request_id, meta, body, _=None):\n        self._current_request = (request_id, meta, body)\n        try:\n            self.server.handle_next_request()\n        finally:\n            self._current_request = None", "response": "Sends a request message to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_response_message(self, request_id, meta, body):\n        self.response_messages.append((request_id, meta, body))", "response": "Add the response message to the deque."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a factory for creating a new status action class specific to a service.", "response": "def StatusActionFactory(version, build=None, base_class=BaseStatusAction):  # noqa\n    \"\"\"\n    A factory for creating a new status action class specific to a service.\n\n    :param version: The service version\n    :type version: union[str, unicode]\n    :param build: The optional service build identifier\n    :type build: union[str, unicode]\n    :param base_class: The optional base class, to override `BaseStatusAction` as the base class\n    :type base_class: BaseStatusAction\n\n    :return: A class named `StatusAction`, extending `base_class`, with version and build matching the input parameters\n    :rtype: class\n    \"\"\"\n    return type(\n        str('StatusAction'),\n        (base_class, ),\n        {str('_version'): version, str('_build'): build},\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, request):\n        status = {\n            'conformity': six.text_type(conformity.__version__),\n            'pysoa': six.text_type(pysoa.__version__),\n            'python': six.text_type(platform.python_version()),\n            'version': self._version,\n        }\n\n        if self._build:\n            status['build'] = self._build\n\n        if not request.body or request.body.get('verbose', True) is True:\n            errors = []\n            warnings = []\n            self.diagnostics = {}\n\n            # Find all things called \"check_<something>\" on this class.\n            # We can't just scan __dict__ because of class inheritance.\n            check_methods = [getattr(self, x) for x in dir(self) if x.startswith('check_')]\n            for check_method in check_methods:\n                # Call the check, and see if it returned anything\n                try:\n                    problems = check_method(request)\n                except TypeError as e:\n                    raise RuntimeError(\n                        'Status action check_* methods must accept a single argument of type ActionRequest',\n                        e,\n                    )\n                if problems:\n                    for is_error, code, description in problems:\n                        # Parcel out the values into the right return list\n                        if is_error:\n                            errors.append((code, description))\n                        else:\n                            warnings.append((code, description))\n\n            status['healthcheck'] = {\n                'errors': errors,\n                'warnings': warnings,\n                'diagnostics': self.diagnostics,\n            }\n\n        return status", "response": "Runs the action checks on the specified resource and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_client_settings(self, request):\n        if not request.client.settings:\n            # There's no need to even add diagnostic details if no client settings are configured\n            return\n\n        self.diagnostics['services'] = {}\n\n        service_names = list(six.iterkeys(request.client.settings))\n        try:\n            job_responses = request.client.call_jobs_parallel(\n                [\n                    {'service_name': service_name, 'actions': [{'action': 'status', 'body': {'verbose': False}}]}\n                    for service_name in service_names\n                ],\n                timeout=2,\n                catch_transport_errors=True,\n                raise_action_errors=False,\n                raise_job_errors=False,\n            )\n        except Exception as e:\n            return [(True, 'CHECK_SERVICES_UNKNOWN_ERROR', six.text_type(e))]\n\n        problems = []\n        for i, service_name in enumerate(service_names):\n            response = job_responses[i]\n            if isinstance(response, Exception):\n                problems.append(\n                    (True, '{}_TRANSPORT_ERROR'.format(service_name.upper()), six.text_type(response)),\n                )\n            elif response.errors:\n                problems.append(\n                    (True, '{}_CALL_ERROR'.format(service_name.upper()), six.text_type(response.errors)),\n                )\n            elif response.actions[0].errors:\n                problems.append(\n                    (True, '{}_STATUS_ERROR'.format(service_name.upper()), six.text_type(response.actions[0].errors)),\n                )\n            else:\n                self.diagnostics['services'][service_name] = response.actions[0].body\n\n        return problems", "response": "Checks if any client settings are configured for this service and calls the status action of each configured service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_next_request(self):\n        if not self._idle_timer:\n            # This method may be called multiple times before receiving a request, so we only create and start a timer\n            # if it's the first call or if the idle timer was stopped on the last call.\n            self._idle_timer = self.metrics.timer('server.idle_time', resolution=TimerResolution.MICROSECONDS)\n            self._idle_timer.start()\n\n        # Get the next JobRequest\n        try:\n            request_id, meta, job_request = self.transport.receive_request_message()\n        except MessageReceiveTimeout:\n            # no new message, nothing to do\n            self.perform_idle_actions()\n            return\n\n        # We are no longer idle, so stop the timer and reset for the next idle period\n        self._idle_timer.stop()\n        self._idle_timer = None\n\n        try:\n            PySOALogContextFilter.set_logging_request_context(request_id=request_id, **job_request.get('context', {}))\n        except TypeError:\n            # Non unicode keys in job_request['context'] will break keywording of a function call.\n            # Try to recover by coercing the keys\n            PySOALogContextFilter.set_logging_request_context(\n                request_id=request_id,\n                **{six.text_type(k): v for k, v in six.iteritems(job_request['context'])}\n            )\n\n        request_for_logging = self.logging_dict_wrapper_class(job_request)\n        self.job_logger.log(self.request_log_success_level, 'Job request: %s', request_for_logging)\n\n        try:\n            self.perform_pre_request_actions()\n\n            # Process and run the Job\n            job_response = self.process_job(job_request)\n\n            # Prepare the JobResponse for sending by converting it to a message dict\n            try:\n                response_message = attr.asdict(job_response, dict_factory=UnicodeKeysDict)\n            except Exception as e:\n                self.metrics.counter('server.error.response_conversion_failure').increment()\n                job_response = self.handle_job_exception(e, variables={'job_response': job_response})\n                response_message = attr.asdict(job_response, dict_factory=UnicodeKeysDict)\n\n            response_for_logging = self.logging_dict_wrapper_class(response_message)\n\n            # Send the response message\n            try:\n                if not job_request.get('control', {}).get('suppress_response', False):\n                    self.transport.send_response_message(request_id, meta, response_message)\n            except MessageTooLarge as e:\n                self.metrics.counter('server.error.response_too_large').increment()\n                job_response = self.handle_job_error_code(\n                    ERROR_CODE_RESPONSE_TOO_LARGE,\n                    'Could not send the response because it was too large',\n                    request_for_logging,\n                    response_for_logging,\n                    extra={'serialized_length_in_bytes': e.message_size_in_bytes},\n                )\n                self.transport.send_response_message(\n                    request_id,\n                    meta,\n                    attr.asdict(job_response, dict_factory=UnicodeKeysDict),\n                )\n            except InvalidField:\n                self.metrics.counter('server.error.response_not_serializable').increment()\n                job_response = self.handle_job_error_code(\n                    ERROR_CODE_RESPONSE_NOT_SERIALIZABLE,\n                    'Could not send the response because it failed to serialize',\n                    request_for_logging,\n                    response_for_logging,\n                )\n                self.transport.send_response_message(\n                    request_id,\n                    meta,\n                    attr.asdict(job_response, dict_factory=UnicodeKeysDict),\n                )\n            finally:\n                if job_response.errors or any(a.errors for a in job_response.actions):\n                    if (\n                        self.request_log_error_level > self.request_log_success_level and\n                        self.job_logger.getEffectiveLevel() > self.request_log_success_level\n                    ):\n                        # When we originally logged the request, it may have been hidden because the effective logging\n                        # level threshold was greater than the level at which we logged the request. So re-log the\n                        # request at the error level, if set higher.\n                        self.job_logger.log(self.request_log_error_level, 'Job request: %s', request_for_logging)\n                    self.job_logger.log(self.request_log_error_level, 'Job response: %s', response_for_logging)\n                else:\n                    self.job_logger.log(self.request_log_success_level, 'Job response: %s', response_for_logging)\n        finally:\n            PySOALogContextFilter.clear_logging_request_context()\n            self.perform_post_request_actions()", "response": "Handles the next request from the transport and processes it and sends the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list of in - order middleware callable objects and a base function base returns the top - level callable that calls the next middleware and the base function below.", "response": "def make_middleware_stack(middleware, base):\n        \"\"\"\n        Given a list of in-order middleware callable objects `middleware` and a base function `base`, chains them\n        together so each middleware is fed the function below, and returns the top level ready to call.\n\n        :param middleware: The middleware stack\n        :type middleware: iterable[callable]\n        :param base: The base callable that the lowest-order middleware wraps\n        :type base: callable\n\n        :return: The topmost middleware, which calls the next middleware ... which calls the lowest-order middleware,\n                 which calls the `base` callable.\n        :rtype: callable\n        \"\"\"\n        for ware in reversed(middleware):\n            base = ware(base)\n        return base"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate execute and run the job request and return a JobResponse object.", "response": "def process_job(self, job_request):\n        \"\"\"\n        Validate, execute, and run the job request, wrapping it with any applicable job middleware.\n\n        :param job_request: The job request\n        :type job_request: dict\n\n        :return: A `JobResponse` object\n        :rtype: JobResponse\n\n        :raise: JobError\n        \"\"\"\n\n        try:\n            # Validate JobRequest message\n            validation_errors = [\n                Error(\n                    code=error.code,\n                    message=error.message,\n                    field=error.pointer,\n                )\n                for error in (JobRequestSchema.errors(job_request) or [])\n            ]\n            if validation_errors:\n                raise JobError(errors=validation_errors)\n\n            # Add the client object in case a middleware wishes to use it\n            job_request['client'] = self.make_client(job_request['context'])\n\n            # Add the async event loop in case a middleware wishes to use it\n            job_request['async_event_loop'] = self._async_event_loop\n            if hasattr(self, '_async_event_loop_thread'):\n                job_request['run_coroutine'] = self._async_event_loop_thread.run_coroutine\n            else:\n                job_request['run_coroutine'] = None\n\n            # Build set of middleware + job handler, then run job\n            wrapper = self.make_middleware_stack(\n                [m.job for m in self.middleware],\n                self.execute_job,\n            )\n            job_response = wrapper(job_request)\n            if 'correlation_id' in job_request['context']:\n                job_response.context['correlation_id'] = job_request['context']['correlation_id']\n        except JobError as e:\n            self.metrics.counter('server.error.job_error').increment()\n            job_response = JobResponse(\n                errors=e.errors,\n            )\n        except Exception as e:\n            # Send an error response if no middleware caught this.\n            # Formatting the error might itself error, so try to catch that\n            self.metrics.counter('server.error.unhandled_error').increment()\n            return self.handle_job_exception(e)\n\n        return job_response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_job_exception(self, exception, variables=None):\n        # Get the error and traceback if we can\n        # noinspection PyBroadException\n        try:\n            error_str, traceback_str = six.text_type(exception), traceback.format_exc()\n        except Exception:\n            self.metrics.counter('server.error.error_formatting_failure').increment()\n            error_str, traceback_str = 'Error formatting error', traceback.format_exc()\n        # Log what happened\n        self.logger.exception(exception)\n        if not isinstance(traceback_str, six.text_type):\n            try:\n                # Try to\n                traceback_str = traceback_str.decode('utf-8')\n            except UnicodeDecodeError:\n                traceback_str = 'UnicodeDecodeError: Traceback could not be decoded'\n        # Make a bare bones job response\n        error_dict = {\n            'code': ERROR_CODE_SERVER_ERROR,\n            'message': 'Internal server error: %s' % error_str,\n            'traceback': traceback_str,\n        }\n\n        if variables is not None:\n            # noinspection PyBroadException\n            try:\n                error_dict['variables'] = {key: repr(value) for key, value in variables.items()}\n            except Exception:\n                self.metrics.counter('server.error.variable_formatting_failure').increment()\n                error_dict['variables'] = 'Error formatting variables'\n\n        return JobResponse(errors=[error_dict])", "response": "Handles an exception that occurred in the job and returns a JobResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_job(self, job_request):\n        # Run the Job's Actions\n        job_response = JobResponse()\n        job_switches = RequestSwitchSet(job_request['context']['switches'])\n        for i, raw_action_request in enumerate(job_request['actions']):\n            action_request = EnrichedActionRequest(\n                action=raw_action_request['action'],\n                body=raw_action_request.get('body', None),\n                switches=job_switches,\n                context=job_request['context'],\n                control=job_request['control'],\n                client=job_request['client'],\n                async_event_loop=job_request['async_event_loop'],\n                run_coroutine=job_request['run_coroutine'],\n            )\n            action_in_class_map = action_request.action in self.action_class_map\n            if action_in_class_map or action_request.action in ('status', 'introspect'):\n                # Get action to run\n                if action_in_class_map:\n                    action = self.action_class_map[action_request.action](self.settings)\n                elif action_request.action == 'introspect':\n                    from pysoa.server.action.introspection import IntrospectionAction\n                    action = IntrospectionAction(server=self)\n                else:\n                    if not self._default_status_action_class:\n                        from pysoa.server.action.status import make_default_status_action_class\n                        self._default_status_action_class = make_default_status_action_class(self.__class__)\n                    action = self._default_status_action_class(self.settings)\n                # Wrap it in middleware\n                wrapper = self.make_middleware_stack(\n                    [m.action for m in self.middleware],\n                    action,\n                )\n                # Execute the middleware stack\n                try:\n                    action_response = wrapper(action_request)\n                except ActionError as e:\n                    # Error: an error was thrown while running the Action (or Action middleware)\n                    action_response = ActionResponse(\n                        action=action_request.action,\n                        errors=e.errors,\n                    )\n            else:\n                # Error: Action not found.\n                action_response = ActionResponse(\n                    action=action_request.action,\n                    errors=[Error(\n                        code=ERROR_CODE_UNKNOWN,\n                        message='The action \"{}\" was not found on this server.'.format(action_request.action),\n                        field='action',\n                    )],\n                )\n\n            job_response.actions.append(action_response)\n            if (\n                action_response.errors and\n                not job_request['control'].get('continue_on_error', False)\n            ):\n                # Quit running Actions if an error occurred and continue_on_error is False\n                break\n\n        return job_response", "response": "Processes the actions contained in the job and runs them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_shutdown_signal(self, *_):\n        if self.shutting_down:\n            self.logger.warning('Received double interrupt, forcing shutdown')\n            sys.exit(1)\n        else:\n            self.logger.warning('Received interrupt, initiating shutdown')\n            self.shutting_down = True", "response": "Handles the reception of a shutdown signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the timeout signal indicating that a request has been processing for too long.", "response": "def harakiri(self, *_):\n        \"\"\"\n        Handles the reception of a timeout signal indicating that a request has been processing for too long, as\n        defined by the Harakiri settings.\n        \"\"\"\n        if self.shutting_down:\n            self.logger.warning('Graceful shutdown failed after {}s. Exiting now!'.format(\n                self.settings['harakiri']['shutdown_grace']\n            ))\n            sys.exit(1)\n        else:\n            self.logger.warning('No activity during {}s, triggering harakiri with grace {}s'.format(\n                self.settings['harakiri']['timeout'],\n                self.settings['harakiri']['shutdown_grace'],\n            ))\n            self.shutting_down = True\n            signal.alarm(self.settings['harakiri']['shutdown_grace'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns just before the server accepts a new request.", "response": "def perform_pre_request_actions(self):\n        \"\"\"\n        Runs just before the server accepts a new request. Call super().perform_pre_request_actions() if you override.\n        Be sure your purpose for overriding isn't better met with middleware. See the documentation for `Server.main`\n        for full details on the chain of `Server` method calls.\n        \"\"\"\n        if self.use_django:\n            if getattr(django_settings, 'DATABASES'):\n                self.logger.debug('Resetting Django query log')\n                # noinspection PyCallingNonCallable\n                django_reset_queries()\n\n        self._close_old_django_connections()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n\n        self.logger.info(\n            'Service \"{service}\" server starting up, pysoa version {pysoa}, listening on transport {transport}.'.format(\n                service=self.service_name,\n                pysoa=pysoa.version.__version__,\n                transport=self.transport,\n            )\n        )\n\n        self.setup()\n        self.metrics.commit()\n\n        if self._async_event_loop_thread:\n            self._async_event_loop_thread.start()\n\n        self._create_heartbeat_file()\n\n        signal.signal(signal.SIGINT, self.handle_shutdown_signal)\n        signal.signal(signal.SIGTERM, self.handle_shutdown_signal)\n        signal.signal(signal.SIGALRM, self.harakiri)\n\n        # noinspection PyBroadException\n        try:\n            while not self.shutting_down:\n                # reset harakiri timeout\n                signal.alarm(self.settings['harakiri']['timeout'])\n                # Get, process, and execute the next JobRequest\n                self.handle_next_request()\n                self.metrics.commit()\n        except MessageReceiveError:\n            self.logger.exception('Error receiving message from transport; shutting down')\n        except Exception:\n            self.metrics.counter('server.error.unknown').increment()\n            self.logger.exception('Unhandled server error; shutting down')\n        finally:\n            self.metrics.commit()\n            self.logger.info('Server shutting down')\n            if self._async_event_loop_thread:\n                self._async_event_loop_thread.join()\n            self._close_django_caches(shutdown=True)\n            self._delete_heartbeat_file()\n            self.logger.info('Server shutdown complete')", "response": "Starts the server run loop and returns after the server shuts down."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(cls):\n        parser = argparse.ArgumentParser(\n            description='Server for the {} SOA service'.format(cls.service_name),\n        )\n        parser.add_argument(\n            '-d', '--daemon',\n            action='store_true',\n            help='run the server process as a daemon',\n        )\n        if not cls.use_django:\n            # If Django mode is turned on, we use the Django settings framework to get our settings, so the caller\n            # needs to set DJANGO_SETTINGS_MODULE. Otherwise, the caller must pass in the -s/--settings argument.\n            parser.add_argument(\n                '-s', '--settings',\n                help='The settings module to use',\n                required=True,\n            )\n        cmd_options, _ = parser.parse_known_args(sys.argv[1:])\n\n        # Load settings from the given file (or use Django and grab from its settings)\n        if cls.use_django:\n            # noinspection PyUnresolvedReferences\n            if not django_settings:\n                raise ImportError(\n                    'Could not import Django. You must install Django if you enable Django support in your service.'\n                )\n            try:\n                settings = cls.settings_class(django_settings.SOA_SERVER_SETTINGS)\n            except AttributeError:\n                raise ValueError('Cannot find `SOA_SERVER_SETTINGS` in the Django settings.')\n        else:\n            try:\n                settings_module = importlib.import_module(cmd_options.settings)\n            except ImportError as e:\n                raise ValueError('Cannot import settings module `%s`: %s' % (cmd_options.settings, e))\n            try:\n                settings_dict = getattr(settings_module, 'SOA_SERVER_SETTINGS')\n            except AttributeError:\n                try:\n                    settings_dict = getattr(settings_module, 'settings')\n                except AttributeError:\n                    raise ValueError(\n                        \"Cannot find `SOA_SERVER_SETTINGS` or `settings` variable in settings module `{}`.\".format(\n                            cmd_options.settings,\n                        )\n                    )\n            settings = cls.settings_class(settings_dict)\n\n        PySOALogContextFilter.set_service_name(cls.service_name)\n\n        # Set up logging\n        logging.config.dictConfig(settings['logging'])\n\n        # Optionally daemonize\n        if cmd_options.daemon:\n            pid = os.fork()\n            if pid > 0:\n                print('PID={}'.format(pid))\n                sys.exit()\n\n        # Set up server and signal handling\n        server = cls.initialize(settings)(settings)\n\n        # Start server event loop\n        server.run()", "response": "Main entry point for the main method of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef emit(self, record):\n        # noinspection PyBroadException\n        try:\n            formatted_message = self.format(record)\n            encoded_message = formatted_message.encode('utf-8')\n\n            prefix = suffix = b''\n            if getattr(self, 'ident', False):\n                prefix = self.ident.encode('utf-8') if isinstance(self.ident, six.text_type) else self.ident\n            if getattr(self, 'append_nul', True):\n                suffix = '\\000'.encode('utf-8')\n\n            priority = '<{:d}>'.format(\n                self.encodePriority(self.facility, self.mapPriority(record.levelname))\n            ).encode('utf-8')\n\n            message_length = len(encoded_message)\n            message_length_limit = self.maximum_length - len(prefix) - len(suffix) - len(priority)\n\n            if message_length < message_length_limit:\n                parts = [priority + prefix + encoded_message + suffix]\n            elif self.overflow == self.OVERFLOW_BEHAVIOR_TRUNCATE:\n                truncated_message, _ = self._cleanly_slice_encoded_string(encoded_message, message_length_limit)\n                parts = [priority + prefix + truncated_message + suffix]\n            else:\n                # This can't work perfectly, but it's pretty unusual for a message to go before machine-parseable parts\n                # in the formatted record. So we split the record on the message part. Everything before the split\n                # becomes the preamble and gets repeated every packet. Everything after the split gets chunked. There's\n                # no reason to match on more than the first 40 characters of the message--the chances of that matching\n                # the wrong part of the record are astronomical.\n                try:\n                    index = formatted_message.index(record.getMessage()[:40])\n                    start_of_message, to_chunk = formatted_message[:index], formatted_message[index:]\n                except (TypeError, ValueError):\n                    # We can't locate the message in the formatted record? That's unfortunate. Let's make something up.\n                    start_of_message, to_chunk = '{} '.format(formatted_message[:30]), formatted_message[30:]\n\n                start_of_message = start_of_message.encode('utf-8')\n                to_chunk = to_chunk.encode('utf-8')\n\n                # 12 is the length of \"... (cont'd)\" in bytes\n                chunk_length_limit = message_length_limit - len(start_of_message) - 12\n\n                i = 1\n                parts = []\n                remaining_message = to_chunk\n                while remaining_message:\n                    message_id = b''\n                    subtractor = 0\n                    if i > 1:\n                        # If this is not the first message, we determine message # so that we can subtract that length\n                        message_id = '{}'.format(i).encode('utf-8')\n                        # 14 is the length of \"(cont'd #) ...\" in bytes\n                        subtractor = 14 + len(message_id)\n                    chunk, remaining_message = self._cleanly_slice_encoded_string(\n                        remaining_message,\n                        chunk_length_limit - subtractor,\n                    )\n                    if i > 1:\n                        # If this is not the first message, we prepend the chunk to indicate continuation\n                        chunk = b\"(cont'd #\" + message_id + b') ...' + chunk\n                    i += 1\n                    if remaining_message:\n                        # If this is not the last message, we append the chunk to indicate continuation\n                        chunk = chunk + b\"... (cont'd)\"\n                    parts.append(priority + prefix + start_of_message + chunk + suffix)\n\n            self._send(parts)\n        except Exception:\n            self.handleError(record)", "response": "Emits a record. The record is sent carefully, according to the following rules, to ensure that data is not\n        lost by exceeding the MTU of the connection.\n\n        - If the byte-encoded record length plus prefix length plus suffix length plus priority length is less than the\n          maximum allowed length, then a single packet is sent, containing the priority, prefix, full record, and\n          suffix, in that order.\n\n        - If it's greater than or equal to the maximum allowed length and the overflow behavior is set to \"truncate,\"\n          the record is cleanly truncated (being careful not to split in the middle of a multi-byte character), and\n          then a single packet is sent, containing the priority, prefix, truncated record, and suffix, in that order.\n\n        - If it's greater than or equal to the maximum allowed length and the overflow behavior is set to \"fragment,\"\n          the record preamble (things like file name, logger name, correlation ID, etc.) is extracted from the start\n          of the record to calculate a new chunk length. The remainder of the record (which should just be the true\n          message and any exception info) is then chunked (being careful not to split in the middle of a multi-byte\n          character) into lengths less than or equal to the chunk length, and then the record is sent as multiple\n          packets, each packet containing the priority, prefix, record preamble, message chunk, and suffix, in that\n          order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a byte string (a UTF-8 encoded string) and splits it into two pieces such that the first slice is no longer than argument `length_limit`, then returns a tuple containing the first slice and remainder of the byte string, respectively. The first slice may actually be shorter than `length_limit`, because this ensures that the string does not get split in the middle of a multi-byte character. This works because the first byte in a multi-byte unicode character encodes how many bytes compose that character, so we can determine empirically if we are splitting in the middle of the character and correct for that. You can read more about how this works here: https://en.wikipedia.org/wiki/UTF-8#Description :param encoded_string: The encoded string to split in two :param length_limit: The maximum length allowed for the first slice of the string :return: A tuple of (slice, remaining)", "response": "def _cleanly_slice_encoded_string(encoded_string, length_limit):\n        \"\"\"\n        Takes a byte string (a UTF-8 encoded string) and splits it into two pieces such that the first slice is no\n        longer than argument `length_limit`, then returns a tuple containing the first slice and remainder of the\n        byte string, respectively. The first slice may actually be shorter than `length_limit`, because this ensures\n        that the string does not get split in the middle of a multi-byte character.\n\n        This works because the first byte in a multi-byte unicode character encodes how many bytes compose that\n        character, so we can determine empirically if we are splitting in the middle of the character and correct for\n        that.\n\n        You can read more about how this works here: https://en.wikipedia.org/wiki/UTF-8#Description\n\n        :param encoded_string: The encoded string to split in two\n        :param length_limit: The maximum length allowed for the first slice of the string\n        :return: A tuple of (slice, remaining)\n        \"\"\"\n        sliced, remaining = encoded_string[:length_limit], encoded_string[length_limit:]\n        try:\n            sliced.decode('utf-8')\n        except UnicodeDecodeError as e:\n            sliced, remaining = sliced[:e.start], sliced[e.start:] + remaining\n\n        return sliced, remaining"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling this within `__main__` to start the service as a standalone server with Django support. Your server should have `use_django=True`. If it does not, see `simple_main`, instead. :param server_getter: A callable that returns the service's `Server` class (not an instance of it). Your service code should not be imported until the `server_getter` callable is called, otherwise Django errors will occur.", "response": "def django_main(server_getter):\n    \"\"\"\n    Call this within `__main__` to start the service as a standalone server with Django support. Your server should have\n    `use_django=True`. If it does not, see `simple_main`, instead.\n\n    :param server_getter: A callable that returns the service's `Server` class (not an instance of it). Your service\n                          code should not be imported until the `server_getter` callable is called, otherwise Django\n                          errors will occur.\n    \"\"\"\n    import os\n    # noinspection PyUnresolvedReferences,PyPackageRequirements\n    import django\n\n    parser = _get_arg_parser()\n    parser.add_argument(\n        '-s', '--settings',\n        help='The settings module to use (must be importable)',\n        required='DJANGO_SETTINGS_MODULE' not in os.environ,  # if env var does not exist, this argument is required\n    )\n    args = _get_args(parser)\n    if args.settings:\n        os.environ['DJANGO_SETTINGS_MODULE'] = args.settings\n\n    warn_about_logging = False\n\n    try:\n        # We have to import it manually, because we need to manipulate the settings before setup() is called, but we\n        # can't import django.conf.settings until after setup() is called.\n        django_settings = importlib.import_module(os.environ['DJANGO_SETTINGS_MODULE'])\n        if (\n            getattr(django_settings, 'LOGGING', None) and\n            django_settings.LOGGING != django_settings.SOA_SERVER_SETTINGS['logging']\n        ):\n            warn_about_logging = True\n        django_settings.LOGGING = django_settings.SOA_SERVER_SETTINGS['logging']\n    except ImportError:\n        raise ValueError('Cannot import Django settings module `{}`.'.format(os.environ['DJANGO_SETTINGS_MODULE']))\n    except AttributeError:\n        raise ValueError('Cannot find `SOA_SERVER_SETTINGS` in the Django settings module.')\n    except KeyError:\n        raise ValueError(\n            \"Cannot configure Django `LOGGING` setting because no setting `SOA_SERVER_SETTINGS['logging']` was found.\",\n        )\n\n    if django.VERSION >= (1, 7):\n        django.setup()\n\n    if warn_about_logging:\n        logging.warning(\n            \"Django setting `LOGGING` differs from `SOA_SERVER_SETTINGS['logging']` and has been overwritten with \"\n            \"the value of `SOA_SERVER_SETTINGS['logging']`.\"\n        )\n\n    _run_server_reloader_wrapper(args, server_getter())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_expansion(self, expansion_node):\n        # Check for existing expansion node with the same name\n        existing_expansion_node = self.get_expansion(expansion_node.name)\n        if existing_expansion_node:\n            # Expansion node exists with the same name, merge child expansions.\n            for child_expansion in expansion_node.expansions:\n                existing_expansion_node.add_expansion(child_expansion)\n        else:\n            # Add the expansion node.\n            self._expansions[expansion_node.name] = expansion_node", "response": "Adds a child expansion node to the type node s expansions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_objects(self, obj):\n        objects = []\n\n        if isinstance(obj, dict):\n            # obj is a dictionary, so it is a potential match...\n            object_type = obj.get('_type')\n            if object_type == self.type:\n                # Found a match!\n                objects.append(obj)\n            else:\n                # Not a match. Check each value of the dictionary for matches.\n                for sub_object in six.itervalues(obj):\n                    objects.extend(self.find_objects(sub_object))\n        elif isinstance(obj, list):\n            # obj is a list. Check each element of the list for matches.\n            for sub_object in obj:\n                objects.extend(self.find_objects(sub_object))\n\n        return objects", "response": "Find all objects in obj that match the type of this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_dict(self):\n        expansion_strings = []\n\n        for expansion in self.expansions:\n            expansion_strings.extend(expansion.to_strings())\n\n        return {\n            self.type: expansion_strings,\n        }", "response": "Convert the tree node to its dictionary representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the expansion node to a list of expansion strings.", "response": "def to_strings(self):\n        \"\"\"\n        Convert the expansion node to a list of expansion strings.\n\n        :return: a list of expansion strings that represent the leaf nodes of the expansion tree.\n        :rtype: list[union[str, unicode]]\n        \"\"\"\n        result = []\n\n        if not self.expansions:\n            result.append(self.name)\n        else:\n            for expansion in self.expansions:\n                result.extend('{}.{}'.format(self.name, es) for es in expansion.to_strings())\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict_to_trees(self, expansion_dict):\n        trees = []\n        for node_type, expansion_list in six.iteritems(expansion_dict):\n            type_node = TypeNode(node_type=node_type)\n\n            for expansion_string in expansion_list:\n                expansion_node = type_node\n\n                for expansion_name in expansion_string.split('.'):\n                    child_expansion_node = expansion_node.get_expansion(expansion_name)\n\n                    if not child_expansion_node:\n                        type_expansion = self.type_expansions[expansion_node.type][expansion_name]\n                        type_route = self.type_routes[type_expansion['route']]\n                        if type_expansion['destination_field'] == type_expansion['source_field']:\n                            raise ValueError(\n                                'Expansion configuration destination_field error: '\n                                'destination_field can not have the same name as the source_field: '\n                                '{}'.format(type_expansion['source_field'])\n                            )\n                        child_expansion_node = ExpansionNode(\n                            node_type=type_expansion['type'],\n                            name=expansion_name,\n                            source_field=type_expansion['source_field'],\n                            destination_field=type_expansion['destination_field'],\n                            service=type_route['service'],\n                            action=type_route['action'],\n                            request_field=type_route['request_field'],\n                            response_field=type_route['response_field'],\n                            raise_action_errors=type_expansion.get('raise_action_errors', False),\n                        )\n                        expansion_node.add_expansion(child_expansion_node)\n\n                    expansion_node = child_expansion_node\n\n            trees.append(type_node)\n\n        return trees", "response": "Convert an expansion dictionary to a list of TreeNodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a list of Tree instances to an expansion dictionary.", "response": "def trees_to_dict(trees_list):\n        \"\"\"\n        Convert a list of `TreeNode`s to an expansion dictionary.\n\n        :param trees_list: A list of `TreeNode` instances\n        :type trees_list: list[TreeNode]\n\n        :return: An expansion dictionary that represents the expansions detailed in the provided expansions tree nodes\n        :rtype: dict[union[str, unicode]]\n        \"\"\"\n        result = {}\n\n        for tree in trees_list:\n            result.update(tree.to_dict())\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of service names from Sentinel. Tries Sentinel hosts until one succeeds ; raises a ConnectionError.", "response": "def _get_service_names(self):\n        \"\"\"\n        Get a list of service names from Sentinel. Tries Sentinel hosts until one succeeds; if none succeed,\n        raises a ConnectionError.\n\n        :return: the list of service names from Sentinel.\n        \"\"\"\n        master_info = None\n        connection_errors = []\n        for sentinel in self._sentinel.sentinels:\n            # Unfortunately, redis.sentinel.Sentinel does not support sentinel_masters, so we have to step\n            # through all of its connections manually\n            try:\n                master_info = sentinel.sentinel_masters()\n                break\n            except (redis.ConnectionError, redis.TimeoutError) as e:\n                connection_errors.append('Failed to connect to {} due to error: \"{}\".'.format(sentinel, e))\n                continue\n        if master_info is None:\n            raise redis.ConnectionError(\n                'Could not get master info from Sentinel\\n{}:'.format('\\n'.join(connection_errors))\n            )\n        return list(master_info.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parseargs(argv):\n    '''handle --help, --version and our double-equal ==options'''\n    args = []\n    options = {}\n    key = None\n    for arg in argv:\n        if arg in DEFAULT_OPTION_VALUES:\n            key = arg.strip('=').replace('-', '_')\n            options[key] = ()\n        elif key is None:\n            args.append(arg)\n        else:\n            options[key] += (arg,)\n\n    if set(args) & {'-h', '--help'}:\n        print(__doc__, end='')\n        exit(0)\n    elif set(args) & {'-V', '--version'}:\n        print(__version__)\n        exit(0)\n    elif args:\n        exit('invalid option: %s\\nTry --help for more information.' % args[0])\n\n    return options", "response": "handle - h - V - h and our double - equal ==options"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timid_relpath(arg):\n    # TODO-TEST: unit tests\n    from os.path import isabs, relpath, sep\n    if isabs(arg):\n        result = relpath(arg)\n        if result.count(sep) + 1 < arg.count(sep):\n            return result\n\n    return arg", "response": "convert an argument to a relative path carefully"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exec_(argv):  # never returns\n    # info('EXEC' + colorize(argv))  # TODO: debug logging by environment variable\n\n    # in python3, sys.exitfunc has gone away, and atexit._run_exitfuncs seems to be the only pubic-ish interface\n    #   https://hg.python.org/cpython/file/3.4/Modules/atexitmodule.c#l289\n    import atexit\n    atexit._run_exitfuncs()\n\n    from os import execv\n    execv(argv[0], argv)", "response": "Wrapper to os. execv which shows the command and runs any atexit handlers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the virtualenv - update command in the scratch. venv.", "response": "def exec_scratch_virtualenv(args):\n    \"\"\"\n    goals:\n        - get any random site-packages off of the pythonpath\n        - ensure we can import virtualenv\n        - ensure that we're not using the interpreter that we may need to delete\n        - idempotency: do nothing if the above goals are already met\n    \"\"\"\n    scratch = Scratch()\n    if not exists(scratch.python):\n        run(('virtualenv', scratch.venv))\n\n    if not exists(join(scratch.src, 'virtualenv.py')):\n        scratch_python = venv_python(scratch.venv)\n        # TODO: do we allow user-defined override of which version of virtualenv to install?\n        tmp = scratch.src + '.tmp'\n        run((scratch_python, '-m', 'pip.__main__', 'install', 'virtualenv', '--target', tmp))\n\n        from os import rename\n        rename(tmp, scratch.src)\n\n    import sys\n    from os.path import realpath\n    # We want to compare the paths themselves as sometimes sys.path is the same\n    # as scratch.venv, but with a suffix of bin/..\n    if realpath(sys.prefix) != realpath(scratch.venv):\n        # TODO-TEST: sometimes we would get a stale version of venv-update\n        exec_((scratch.python, dotpy(__file__)) + args)  # never returns\n\n    # TODO-TEST: the original venv-update's directory was on sys.path (when using symlinking)\n    sys.path[0] = scratch.src"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures we have a valid virtualenv.", "response": "def ensure_virtualenv(args, return_values):\n    \"\"\"Ensure we have a valid virtualenv.\"\"\"\n    def adjust_options(options, args):\n        # TODO-TEST: proper error message with no arguments\n        venv_path = return_values.venv_path = args[0]\n\n        if venv_path == DEFAULT_VIRTUALENV_PATH or options.prompt == '<dirname>':\n            from os.path import abspath, basename, dirname\n            options.prompt = '(%s)' % basename(dirname(abspath(venv_path)))\n        # end of option munging.\n\n        # there are two python interpreters involved here:\n        # 1) the interpreter we're instructing virtualenv to copy\n        if options.python is None:\n            source_python = None\n        else:\n            source_python = virtualenv.resolve_interpreter(options.python)\n        # 2) the interpreter virtualenv will create\n        destination_python = venv_python(venv_path)\n\n        if exists(destination_python):\n            reason = invalid_virtualenv_reason(venv_path, source_python, destination_python, options)\n            if reason:\n                info('Removing invalidated virtualenv. (%s)' % reason)\n                run(('rm', '-rf', venv_path))\n            else:\n                info('Keeping valid virtualenv from previous run.')\n                raise SystemExit(0)  # looks good! we're done here.\n\n    # this is actually a documented extension point:\n    #   http://virtualenv.readthedocs.org/en/latest/reference.html#adjust_options\n    import virtualenv\n    virtualenv.adjust_options = adjust_options\n\n    from sys import argv\n    argv[:] = ('virtualenv',) + args\n    info(colorize(argv))\n    raise_on_failure(virtualenv.main)\n    # There might not be a venv_path if doing something like \"venv= --version\"\n    # and not actually asking virtualenv to make a venv.\n    if return_values.venv_path is not None:\n        run(('rm', '-rf', join(return_values.venv_path, 'local')))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the mtime of a file", "response": "def touch(filename, timestamp):\n    \"\"\"set the mtime of a file\"\"\"\n    if timestamp is not None:\n        timestamp = (timestamp, timestamp)  # atime, mtime\n\n    from os import utime\n    utime(filename, timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef venv_update(\n        venv=DEFAULT_OPTION_VALUES['venv='],\n        install=DEFAULT_OPTION_VALUES['install='],\n        pip_command=DEFAULT_OPTION_VALUES['pip-command='],\n        bootstrap_deps=DEFAULT_OPTION_VALUES['bootstrap-deps='],\n):\n    \"\"\"we have an arbitrary python interpreter active, (possibly) outside the virtualenv we want.\n\n    make a fresh venv at the right spot, make sure it has pip-faster, and use it\n    \"\"\"\n\n    # SMELL: mutable argument as return value\n    class return_values(object):\n        venv_path = None\n\n    try:\n        ensure_virtualenv(venv, return_values)\n        if return_values.venv_path is None:\n            return\n        # invariant: the final virtualenv exists, with the right python version\n        raise_on_failure(lambda: pip_faster(return_values.venv_path, pip_command, install, bootstrap_deps))\n    except BaseException:\n        mark_venv_invalid(return_values.venv_path)\n        raise\n    else:\n        mark_venv_valid(return_values.venv_path)", "response": "Update the virtualenv with the new ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls and run pip - faster", "response": "def pip_faster(venv_path, pip_command, install, bootstrap_deps):\n    \"\"\"install and run pip-faster\"\"\"\n    # activate the virtualenv\n    execfile_(venv_executable(venv_path, 'activate_this.py'))\n\n    # disable a useless warning\n    # FIXME: ensure a \"true SSLContext\" is available\n    from os import environ\n    environ['PIP_DISABLE_PIP_VERSION_CHECK'] = '1'\n\n    # we always have to run the bootstrap, because the presense of an\n    # executable doesn't imply the right version. pip is able to validate the\n    # version in the fastpath case quickly anyway.\n    run(('pip', 'install') + bootstrap_deps)\n\n    run(pip_command + install)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raise_on_failure(mainfunc):\n    try:\n        errors = mainfunc()\n        if errors:\n            exit(errors)\n    except CalledProcessError as error:\n        exit(error.returncode)\n    except SystemExit as error:\n        if error.code:\n            raise\n    except KeyboardInterrupt:  # I don't plan to test-cover this.  :pragma:nocover:\n        exit(1)", "response": "raise if and only if mainfunc fails"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cache_installed_wheels(index_url, installed_packages):\n    for installed_package in installed_packages:\n        if not _can_be_cached(installed_package):\n            continue\n        _store_wheel_in_cache(installed_package.link.path, index_url)", "response": "Cache the wheels in the cache directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns pip in - process.", "response": "def pip(args):\n    \"\"\"Run pip, in-process.\"\"\"\n    from sys import stdout\n    stdout.write(colorize(('pip',) + args))\n    stdout.write('\\n')\n    stdout.flush()\n\n    return pipmodule._internal.main(list(args))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a pip. FrozenRequirement from a pkg_resources distribution object", "response": "def dist_to_req(dist):\n    \"\"\"Make a pip.FrozenRequirement from a pkg_resources distribution object\"\"\"\n    try:  # :pragma:nocover: (pip>=10)\n        from pip._internal.operations.freeze import FrozenRequirement\n    except ImportError:  # :pragma:nocover: (pip<10)\n        from pip import FrozenRequirement\n\n    # normalize the casing, dashes in the req name\n    orig_name, dist.project_name = dist.project_name, dist.key\n    result = FrozenRequirement.from_dist(dist, [])\n    # put things back the way we found it.\n    dist.project_name = orig_name\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pip_get_installed():\n    from pip._internal.utils.misc import dist_is_local\n\n    return tuple(\n        dist_to_req(dist)\n        for dist in fresh_working_set()\n        if dist_is_local(dist)\n        if dist.key != 'python'  # See #220\n    )", "response": "Return a tuple of the installed packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a fresh working set with the currently installed packages.", "response": "def fresh_working_set():\n    \"\"\"return a pkg_resources \"working set\", representing the *currently* installed packages\"\"\"\n    class WorkingSetPlusEditableInstalls(pkg_resources.WorkingSet):\n\n        def __init__(self, *args, **kwargs):\n            self._normalized_name_mapping = {}\n            super(WorkingSetPlusEditableInstalls, self).__init__(*args, **kwargs)\n\n        def add_entry(self, entry):\n            \"\"\"Same as the original .add_entry, but sets only=False, so that egg-links are honored.\"\"\"\n            logger.debug('working-set entry: %r', entry)\n            self.entry_keys.setdefault(entry, [])\n            self.entries.append(entry)\n            for dist in pkg_resources.find_distributions(entry, False):\n\n                # eggs override anything that's installed normally\n                # fun fact: pkg_resources.working_set's results depend on the\n                # ordering of os.listdir since the order of os.listdir is\n                # entirely arbitrary (an implemenation detail of file system),\n                # without calling site.main(), an .egg-link file may or may not\n                # be honored, depending on the filesystem\n                replace = (dist.precedence == pkg_resources.EGG_DIST)\n                self._normalized_name_mapping[normalize_name(dist.key)] = dist.key\n                self.add(dist, entry, False, replace=replace)\n\n        def find_normalized(self, req):\n            req = _package_req_to_pkg_resources_req(str(req))\n            req.key = self._normalized_name_mapping.get(normalize_name(req.key), req.key)\n            return self.find(req)\n\n    return WorkingSetPlusEditableInstalls()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef req_cycle(req):\n    cls = req.__class__\n    seen = {req.name}\n    while isinstance(req.comes_from, cls):\n        req = req.comes_from\n        if req.name in seen:\n            return True\n        else:\n            seen.add(req.name)\n    return False", "response": "is this requirement cyclic?"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pretty_req(req):\n    from copy import copy\n    req = copy(req)\n    req.link = None\n    req.satisfied_by = None\n    return req", "response": "Returns a copy of a pip requirement that is a bit more readable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_requirements(requirements):\n    requirements = tuple(pretty_req(r) for r in requirements)\n    working_set = fresh_working_set()\n\n    # breadth-first traversal:\n    from collections import deque\n    queue = deque(requirements)\n    queued = {_package_req_to_pkg_resources_req(req.req) for req in queue}\n    errors = []\n    result = []\n    while queue:\n        req = queue.popleft()\n\n        logger.debug('tracing: %s', req)\n        try:\n            dist = working_set.find_normalized(_package_req_to_pkg_resources_req(req.req))\n        except pkg_resources.VersionConflict as conflict:\n            dist = conflict.args[0]\n            errors.append('Error: version conflict: {} ({}) <-> {}'.format(\n                dist, timid_relpath(dist.location), req\n            ))\n\n        assert dist is not None, 'Should be unreachable in pip8+'\n        result.append(dist_to_req(dist))\n\n        # TODO: pip does no validation of extras. should we?\n        extras = [extra for extra in req.extras if extra in dist.extras]\n        for sub_req in sorted(dist.requires(extras=extras), key=lambda req: req.key):\n            sub_req = InstallRequirement(sub_req, req)\n\n            if req_cycle(sub_req):\n                logger.warning('Circular dependency! %s', sub_req)\n                continue\n            elif sub_req.req in queued:\n                logger.debug('already queued: %s', sub_req)\n                continue\n            else:\n                logger.debug('adding sub-requirement %s', sub_req)\n                queue.append(sub_req)\n                queued.add(sub_req.req)\n\n    if errors:\n        raise InstallationError('\\n'.join(errors))\n\n    return result", "response": "given an iterable of pip InstallRequirements return the set of required packages given their transitive requirements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a set of updates to a dictionary return the original values.", "response": "def patch(attrs, updates):\n    \"\"\"Perform a set of updates to a attribute dictionary, return the original values.\"\"\"\n    orig = {}\n    for attr, value in updates:\n        orig[attr] = attrs[attr]\n        attrs[attr] = value\n    return orig"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprovides a short - circuited search when the requirement is pinned and appears on disk.", "response": "def pipfaster_packagefinder():\n    \"\"\"Provide a short-circuited search when the requirement is pinned and appears on disk.\n\n    Suggested upstream at: https://github.com/pypa/pip/pull/2114\n    \"\"\"\n    # A poor man's dependency injection: monkeypatch :(\n    try:  # :pragma:nocover: pip>=18.1\n        from pip._internal.cli import base_command\n    except ImportError:  # :pragma:nocover: pip<18.1\n        from pip._internal import basecommand as base_command\n    return patched(vars(base_command), {'PackageFinder': FasterPackageFinder})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, options, args):\n        if options.prune:\n            previously_installed = pip_get_installed()\n\n        index_urls = [options.index_url] + options.extra_index_urls\n        with pipfaster_download_cacher(index_urls):\n            requirement_set = super(FasterInstallCommand, self).run(\n                options, args,\n            )\n\n        required = requirement_set.requirements.values()\n\n        # With extra_index_urls we don't know where the wheel is from\n        if not options.extra_index_urls:\n            cache_installed_wheels(options.index_url, requirement_set.successfully_downloaded)\n\n        if not options.ignore_dependencies:\n            # transitive requirements, previously installed, are also required\n            # this has a side-effect of finding any missing / conflicting requirements\n            required = trace_requirements(required)\n\n            if not options.prune:\n                return requirement_set\n\n            extraneous = (\n                reqnames(previously_installed) -\n                reqnames(required) -\n                # the stage1 bootstrap packages\n                reqnames(trace_requirements([install_req_from_line('venv-update')])) -\n                # See #186\n                frozenset(('pkg-resources',))\n            )\n\n            if extraneous:\n                extraneous = sorted(extraneous)\n                pip(('uninstall', '--yes') + tuple(extraneous))", "response": "update install options with caching values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bulk_of_jsons(d):\n    \"Replace serialized JSON values with objects in a bulk array response (list)\"\n    def _f(b):\n        for index, item in enumerate(b):\n            if item is not None:\n                b[index] = d(item)\n        return b\n    return _f", "response": "Replace serialized JSON values with objects in a bulk array response ( list )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the client s encoder to be an instance of json. JSONEncoder class.", "response": "def setEncoder(self, encoder):\n        \"\"\"\n        Sets the client's encoder\n        ``encoder`` should be an instance of a ``json.JSONEncoder`` class\n        \"\"\"\n        if not encoder:\n            self._encoder = json.JSONEncoder()\n        else:\n            self._encoder = encoder\n        self._encode = self._encoder.encode"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the client s decoder to be an instance of json. JSONDecoder class.", "response": "def setDecoder(self, decoder):\n        \"\"\"\n        Sets the client's decoder\n        ``decoder`` should be an instance of a ``json.JSONDecoder`` class\n        \"\"\"\n        if not decoder:\n            self._decoder = json.JSONDecoder()\n        else:\n            self._decoder = decoder\n        self._decode = self._decoder.decode"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jsondel(self, name, path=Path.rootPath()):\n        return self.execute_command('JSON.DEL', name, str_path(path))", "response": "Deletes the JSON value stored at key name under path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the object stored as a JSON value at key name with optional path arguments.", "response": "def jsonget(self, name, *args):\n        \"\"\"\n        Get the object stored as a JSON value at key ``name``\n        ``args`` is zero or more paths, and defaults to root path\n        \"\"\"\n        pieces = [name]\n        if len(args) == 0:\n            pieces.append(Path.rootPath())\n        else:\n            for p in args:\n                    pieces.append(str_path(p))\n\n        # Handle case where key doesn't exist. The JSONDecoder would raise a\n        # TypeError exception since it can't decode None\n        try:\n            return self.execute_command('JSON.GET', *pieces)\n        except TypeError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the values stored under path from a JSON object under the given path.", "response": "def jsonmget(self, path, *args):\n        \"\"\"\n        Gets the objects stored as a JSON values under ``path`` from \n        keys ``args``\n        \"\"\"\n        pieces = []\n        pieces.extend(args)\n        pieces.append(str_path(path))\n        return self.execute_command('JSON.MGET', *pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the JSON value at key name under the path to obj.", "response": "def jsonset(self, name, path, obj, nx=False, xx=False):\n        \"\"\"\n        Set the JSON value at key ``name`` under the ``path`` to ``obj``\n        ``nx`` if set to True, set ``value`` only if it does not exist\n        ``xx`` if set to True, set ``value`` only if it exists\n        \"\"\"\n        pieces = [name, str_path(path), self._encode(obj)]\n\n        # Handle existential modifiers\n        if nx and xx:\n            raise Exception('nx and xx are mutually exclusive: use one, the '\n                            'other or neither - but not both')\n        elif nx:\n            pieces.append('NX')\n        elif xx:\n            pieces.append('XX')\n        return self.execute_command('JSON.SET', *pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jsontype(self, name, path=Path.rootPath()):\n        return self.execute_command('JSON.TYPE', name, str_path(path))", "response": "Gets the type of the JSON value under path under key name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jsonnumincrby(self, name, path, number):\n        return self.execute_command('JSON.NUMINCRBY', name, str_path(path), self._encode(number))", "response": "Increment the numeric value under key name under path at key path at key name by number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsonnummultby(self, name, path, number):\n        return self.execute_command('JSON.NUMMULTBY', name, str_path(path), self._encode(number))", "response": "Multiplies the numeric value under key name at key path at key name with the provided number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsonstrappend(self, name, string, path=Path.rootPath()):\n        return self.execute_command('JSON.STRAPPEND', name, str_path(path), self._encode(string))", "response": "Appends string to the string value under key name under path at key name under path at key path at key name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the length of the string JSON value under path at keyname.", "response": "def jsonstrlen(self, name, path=Path.rootPath()):\n        \"\"\"\n        Returns the length of the string JSON value under ``path`` at key\n        ``name``\n        \"\"\"\n        return self.execute_command('JSON.STRLEN', name, str_path(path))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nappend the objects args to the array under the path in key name.", "response": "def jsonarrappend(self, name, path=Path.rootPath(), *args):\n        \"\"\"\n        Appends the objects ``args`` to the array under the ``path` in key\n        ``name``\n        \"\"\"\n        pieces = [name, str_path(path)]\n        for o in args:\n            pieces.append(self._encode(o))\n        return self.execute_command('JSON.ARRAPPEND', *pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsonarrindex(self, name, path, scalar, start=0, stop=-1):\n        return self.execute_command('JSON.ARRINDEX', name, str_path(path), self._encode(scalar), start, stop)", "response": "Returns the index of scalar in the JSON array under path at key\n        name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef jsonarrinsert(self, name, path, index, *args):\n        pieces = [name, str_path(path), index]\n        for o in args:\n            pieces.append(self._encode(o))\n        return self.execute_command('JSON.ARRINSERT', *pieces)", "response": "Inserts the objects args to the array at index under the key name under path under the key name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jsonarrlen(self, name, path=Path.rootPath()):\n        return self.execute_command('JSON.ARRLEN', name, str_path(path))", "response": "Returns the length of the array JSON value under path at key name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npop the element at index in the array JSON value under path under key name.", "response": "def jsonarrpop(self, name, path=Path.rootPath(), index=-1):\n        \"\"\"\n        Pops the element at ``index`` in the array JSON value under ``path`` at\n        key ``name``\n        \"\"\"\n        return self.execute_command('JSON.ARRPOP', name, str_path(path), index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsonarrtrim(self, name, path, start, stop):\n        return self.execute_command('JSON.ARRTRIM', name, str_path(path), start, stop)", "response": "Trim the array JSON value under path at key name to the \n        inclusive range given by start and stop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jsonobjkeys(self, name, path=Path.rootPath()):\n        return self.execute_command('JSON.OBJKEYS', name, str_path(path))", "response": "Returns the keys in the dictionary JSON value under path at key name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef jsonobjlen(self, name, path=Path.rootPath()):\n        return self.execute_command('JSON.OBJLEN', name, str_path(path))", "response": "Returns the length of the dictionary JSON value under path at key name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new pipeline object that can queue multiple commands for a specific key.", "response": "def pipeline(self, transaction=True, shard_hint=None):\n        \"\"\"\n        Return a new pipeline object that can queue multiple commands for\n        later execution. ``transaction`` indicates whether all commands\n        should be executed atomically. Apart from making a group of operations\n        atomic, pipelines are useful for reducing the back-and-forth overhead\n        between the client and server.\n\n        Overridden in order to provide the right client through the pipeline.\n        \"\"\"\n        p = Pipeline(\n            connection_pool=self.connection_pool,\n            response_callbacks=self.response_callbacks,\n            transaction=transaction,\n            shard_hint=shard_hint)\n        p.setEncoder(self._encoder)\n        p.setDecoder(self._decoder)\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pg_info():\n    from psycopg2 import connect, OperationalError\n    log.debug(\"entered get_pg_info\")\n    try:\n        conf = settings.DATABASES['default']\n        database = conf[\"NAME\"]\n        user = conf[\"USER\"]\n        host = conf[\"HOST\"]\n        port = conf[\"PORT\"]\n        password = conf[\"PASSWORD\"]\n    except (AttributeError, KeyError):\n        log.error(\"No PostgreSQL connection info found in settings.\")\n        return {\"status\": NO_CONFIG}\n    except TypeError:\n        return {\"status\": DOWN}\n    log.debug(\"got past getting conf\")\n    try:\n        start = datetime.now()\n        connection = connect(\n            database=database, user=user, host=host,\n            port=port, password=password, connect_timeout=TIMEOUT_SECONDS,\n        )\n        log.debug(\"at end of context manager\")\n        micro = (datetime.now() - start).microseconds\n        connection.close()\n    except (OperationalError, KeyError) as ex:\n        log.error(\"No PostgreSQL connection info found in settings. %s Error: %s\",\n                  conf, ex)\n        return {\"status\": DOWN}\n    log.debug(\"got to end of postgres check successfully\")\n    return {\"status\": UP, \"response_microseconds\": micro}", "response": "Check PostgreSQL connection and return the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck Redis connection and return information about the current item.", "response": "def get_redis_info():\n    \"\"\"Check Redis connection.\"\"\"\n    from kombu.utils.url import _parse_url as parse_redis_url\n    from redis import (\n        StrictRedis,\n        ConnectionError as RedisConnectionError,\n        ResponseError as RedisResponseError,\n    )\n    for conf_name in ('REDIS_URL', 'BROKER_URL', 'CELERY_BROKER_URL'):\n        if hasattr(settings, conf_name):\n            url = getattr(settings, conf_name)\n            if url.startswith('redis://'):\n                break\n    else:\n        log.error(\"No redis connection info found in settings.\")\n        return {\"status\": NO_CONFIG}\n    _, host, port, _, password, database, _ = parse_redis_url(url)\n\n    start = datetime.now()\n    try:\n        rdb = StrictRedis(\n            host=host, port=port, db=database,\n            password=password, socket_timeout=TIMEOUT_SECONDS,\n        )\n        info = rdb.info()\n    except (RedisConnectionError, TypeError) as ex:\n        log.error(\"Error making Redis connection: %s\", ex.args)\n        return {\"status\": DOWN}\n    except RedisResponseError as ex:\n        log.error(\"Bad Redis response: %s\", ex.args)\n        return {\"status\": DOWN, \"message\": \"auth error\"}\n    micro = (datetime.now() - start).microseconds\n    del rdb  # the redis package does not support Redis's QUIT.\n    ret = {\n        \"status\": UP, \"response_microseconds\": micro,\n    }\n    fields = (\"uptime_in_seconds\", \"used_memory\", \"used_memory_peak\")\n    ret.update({x: info[x] for x in fields})\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck celery availability and return celery info.", "response": "def get_celery_info():\n    \"\"\"\n    Check celery availability\n    \"\"\"\n    import celery\n    if not getattr(settings, 'USE_CELERY', False):\n        log.error(\"No celery config found. Set USE_CELERY in settings to enable.\")\n        return {\"status\": NO_CONFIG}\n    start = datetime.now()\n    try:\n        # pylint: disable=no-member\n        app = celery.Celery('tasks')\n        app.config_from_object('django.conf:settings', namespace='CELERY')\n        # Make sure celery is connected with max_retries=1\n        # and not the default of max_retries=None if the connection\n        # is made lazily\n        app.connection().ensure_connection(max_retries=1)\n\n        celery_stats = celery.task.control.inspect().stats()\n        if not celery_stats:\n            log.error(\"No running Celery workers were found.\")\n            return {\"status\": DOWN, \"message\": \"No running Celery workers\"}\n    except Exception as exp:  # pylint: disable=broad-except\n        log.error(\"Error connecting to the backend: %s\", exp)\n        return {\"status\": DOWN, \"message\": \"Error connecting to the backend\"}\n    return {\"status\": UP, \"response_microseconds\": (datetime.now() - start).microseconds}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks app certificate expiry status", "response": "def get_certificate_info():\n    \"\"\"\n    checks app certificate expiry status\n    \"\"\"\n    if hasattr(settings, 'MIT_WS_CERTIFICATE') and settings.MIT_WS_CERTIFICATE:\n        mit_ws_certificate = settings.MIT_WS_CERTIFICATE\n    else:\n        return {\"status\": NO_CONFIG}\n\n    app_cert = OpenSSL.crypto.load_certificate(\n        OpenSSL.crypto.FILETYPE_PEM, (\n            mit_ws_certificate if not isinstance(mit_ws_certificate, str)\n            else mit_ws_certificate.encode().decode('unicode_escape').encode()\n        )\n    )\n\n    app_cert_expiration = datetime.strptime(\n        app_cert.get_notAfter().decode('ascii'),\n        '%Y%m%d%H%M%SZ'\n    )\n    date_delta = app_cert_expiration - datetime.now()\n\n    # if more then 30 days left in expiry of certificate then app is safe\n    return {\n        'app_cert_expires': app_cert_expiration.strftime('%Y-%m-%dT%H:%M:%S'),\n        'status': UP if date_delta.days > 30 else DOWN\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(request):  # pylint: disable=unused-argument\n    token = request.GET.get(\"token\", \"\")\n    if not token or token != settings.STATUS_TOKEN:\n        raise Http404()\n\n    info = {}\n    check_mapping = {\n        'REDIS': (get_redis_info, 'redis'),\n        'ELASTIC_SEARCH': (get_elasticsearch_info, 'elasticsearch'),\n        'POSTGRES': (get_pg_info, 'postgresql'),\n        'CELERY': (get_celery_info, 'celery'),\n        'CERTIFICATE': (get_certificate_info, 'certificate'),\n    }\n\n    for setting, (check_fn, key) in check_mapping.items():\n        if setting in settings.HEALTH_CHECK:\n            log.debug('getting: %s', key)\n            info[key] = check_fn()\n            log.debug('%s done', key)\n\n    code = HTTP_OK\n    status_all = UP\n    for key in info:\n        if info[key][\"status\"] == DOWN:\n            code = SERVICE_UNAVAILABLE\n            status_all = DOWN\n            break\n\n    info[\"status_all\"] = status_all\n\n    resp = JsonResponse(info)\n    resp.status_code = code\n    return resp", "response": "Get the status of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_response(self, request, response):\n        # A higher middleware layer may return a request which does not contain\n        # messages storage, so make no assumption that it will be there.\n        if hasattr(request, '_messages'):\n            unstored_messages = request._messages.update(response)\n            if unstored_messages and settings.DEBUG:  # pragma: no-cover\n                raise ValueError('Not all temporary messages could be stored.')\n        if hasattr(request, '_alarms'):\n            unstored_alarms = request._alarms.update(response)\n            if unstored_alarms and settings.DEBUG:  # pragma: no-cover\n                raise ValueError('Not all temporary alarms could be stored.')\n        return response", "response": "Update the storage backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequest bot information based on current api_key and sets self. whoami to dictionary with username first_name and id of the configured bot.", "response": "def _start(self):\n        '''Requests bot information based on current api_key, and sets\n        self.whoami to dictionary with username, first_name, and id of the\n        configured bot.\n\n        '''\n        if self.whoami is None:\n            me = self.get_me()\n            if me.get('ok', False):\n                self.whoami = me['result']\n            else:\n                raise ValueError('Bot Cannot request information, check '\n                                 'api_key')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npoll the database for updates.", "response": "def poll(self, offset=None, poll_timeout=600, cooldown=60, debug=False):\n        '''These should also be in the config section, but some here for\n        overrides\n\n        '''\n        if self.config['api_key'] is None:\n            raise ValueError('config api_key is undefined')\n\n        if offset or self.config.get('offset', None):\n            self.offset = offset or self.config.get('offset', None)\n\n        self._start()\n\n        while True:\n            try:\n                response = self.get_updates(poll_timeout, self.offset)\n                if response.get('ok', False) is False:\n                    raise ValueError(response['error'])\n                else:\n                    self.process_updates(response)\n            except Exception as e:\n                print('Error: Unknown Exception')\n                print(e)\n                if debug:\n                    raise e\n                else:\n                    time.sleep(cooldown)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the value of a given environment variable.", "response": "def get_value(self, var, cast=None, default=environ.Env.NOTSET,  # noqa: C901\n                  parse_default=False, raw=False):\n        \"\"\"Return value for given environment variable.\n\n                :param var: Name of variable.\n                :param cast: Type to cast return value as.\n                :param default: If var not present in environ, return this instead.\n                :param parse_default: force to parse default..\n\n                :returns: Value from environment or default (if set)\n                \"\"\"\n\n        if raw:\n            env_var = var\n        else:\n            env_var = f'{self.prefix}{var}'\n\n        # logger.debug(f\"get '{env_var}' casted as '{cast}' with default '{default}'\")\n\n        if var in self.scheme:\n            var_info = self.scheme[var]\n\n            try:\n                has_default = len(var_info) == 2\n            except TypeError:\n                has_default = False\n\n            if has_default:\n                if not cast:\n                    cast = var_info[0]\n\n                if default is self.NOTSET:\n                    default = var_info[1]\n            else:\n                if not cast:\n                    cast = var_info\n\n        try:\n            value = self.ENVIRON[env_var]\n        except KeyError:\n            if default is self.NOTSET:\n                error_msg = f'Set the {env_var} environment variable'\n                raise ImproperlyConfigured(error_msg)\n\n            value = default\n\n        # Resolve any proxied values\n        if hasattr(value, 'startswith') and '${' in value:\n            m = environ.re.search(r'(\\${(.*?)})', value)\n            while m:\n                value = re.sub(re.escape(m.group(1)), self.get_value(m.group(2), raw=True), value)\n                m = environ.re.search(r'(\\${(.*?)})', value)\n\n        if value != default or (parse_default and value):\n            value = self.parse_value(value, cast)\n\n        logger.debug(f\"get '{var}' returns '{value}'\")\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fqn(o):\n    parts = []\n    if isinstance(o, (str, bytes)):\n        return o\n    if not hasattr(o, '__module__'):\n        raise ValueError('Invalid argument `%s`' % o)\n    parts.append(o.__module__)\n    if isclass(o):\n        parts.append(o.__name__)\n    elif isinstance(o, types.FunctionType):\n        parts.append(o.__name__)\n    else:\n        parts.append(o.__class__.__name__)\n    return '.'.join(parts)", "response": "Returns the fully qualified class name of an object or a class\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_otp(self, message_list):\n        if isinstance(message_list, six.string_types):\n            message_list = [message_list, ]\n        for x in message_list:\n            if self.separator in x:\n                raise ValueError('Messages cannot contain separator')\n        message_list = self.separator.join(message_list)\n        dt = int(time.time())\n        prefix = ''.join([random.choice(string.ascii_letters) for x in range(random.randint(0, 20))])\n        tail = ''.join([random.choice(string.ascii_letters) for x in range(random.randint(0, 20))])\n        message_list = f'{message_list}{self.separator}{prefix}{dt}{tail}'\n        message_list = self.encryption_suite.encrypt(message_list.encode())\n        return base64.urlsafe_b64encode(message_list)", "response": "Generates a url - safe base64 encoded encypted message together with current timestamp to the second."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asset(path):\n    commit = bitcaster.get_full_version()\n    return mark_safe('{0}?{1}'.format(_static(path), commit))", "response": "Returns a static file that can be used to serve the given path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_client_ip(request):\n    try:\n        return request.META['HTTP_X_FORWARDED_FOR'].split(',')[0].strip()\n    except (KeyError, IndexError):\n        return request.META.get('REMOTE_ADDR')", "response": "Returns the client IP address from the request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rows(thelist, n):\n    try:\n        n = int(n)\n        thelist = list(thelist)\n    except (ValueError, TypeError):\n        return [thelist]\n    list_len = len(thelist)\n    split = list_len // n\n\n    if list_len % n != 0:\n        split += 1\n    return [thelist[split * i:split * (i + 1)] for i in range(n)]", "response": "Return a list of n rows filled up to the maximum equal\n    length possible."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of rows with n elements distributing columns as evenly as possible AttributeNames.", "response": "def rows_distributed(thelist, n):\n    \"\"\"\n    Break a list into ``n`` rows, distributing columns as evenly as possible\n    across the rows. For example::\n\n        >>> l = range(10)\n\n        >>> rows_distributed(l, 2)\n        [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n\n        >>> rows_distributed(l, 3)\n        [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n        >>> rows_distributed(l, 4)\n        [[0, 1, 2], [3, 4, 5], [6, 7], [8, 9]]\n\n        >>> rows_distributed(l, 5)\n        [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n\n        >>> rows_distributed(l, 9)\n        [[0, 1], [2], [3], [4], [5], [6], [7], [8], [9]]\n\n        # This filter will always return `n` rows, even if some are empty:\n        >>> rows(range(2), 3)\n        [[0], [1], []]\n    \"\"\"\n    try:\n        n = int(n)\n        thelist = list(thelist)\n    except (ValueError, TypeError):\n        return [thelist]\n    list_len = len(thelist)\n    split = list_len // n\n\n    remainder = list_len % n\n    offset = 0\n    rows = []\n    for i in range(n):\n        if remainder:\n            start, end = (split + 1) * i, (split + 1) * (i + 1)\n        else:\n            start, end = split * i + offset, split * (i + 1) + offset\n        rows.append(thelist[start:end])\n        if remainder:\n            remainder -= 1\n            offset += 1\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a status of a specific resource", "response": "def update_status(self, *args, **kwargs):\n        \"\"\" :reference: https://dev.twitter.com/rest/reference/post/statuses/update\n            :allowed_param:'status', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'auto_populate_reply_metadata', 'lat', 'long', 'source', 'place_id', 'display_coordinates', 'media_ids'\n        \"\"\"\n        post_data = {}\n        media_ids = kwargs.pop('media_ids', None)\n        if media_ids is not None:\n            post_data['media_ids'] = list_to_csv(media_ids)\n\n        return bind_api(\n            api=self,\n            path='/statuses/update.json',\n            method='POST',\n            payload_type='status',\n            allowed_param=['status', 'in_reply_to_status_id', 'in_reply_to_status_id_str',\n                           'auto_populate_reply_metadata', 'lat', 'long', 'source', 'place_id', 'display_coordinates'],\n            require_auth=True\n        )(post_data=post_data, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_direct_message_new(self, messageobject):\n        headers, post_data = API._buildmessageobject(messageobject)\n        return bind_api(\n            api=self,\n            path='/direct_messages/events/new.json',\n            method='POST',\n            require_auth=True\n        )(self, post_data=post_data, headers=headers)", "response": "Send a new message to the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npacks image from file into multipart - formdata post body", "response": "def _pack_image(filename, max_size, form_field='image', f=None):\n        \"\"\"Pack image from file into multipart-formdata post body\"\"\"\n        # image must be less than 700kb in size\n        if f is None:\n            try:\n                if os.path.getsize(filename) > (max_size * 1024):\n                    raise TweepError('File is too big, must be less than %skb.' % max_size)\n            except os.error as e:\n                raise TweepError('Unable to access file: %s' % e.strerror)\n\n            # build the mulitpart-formdata body\n            fp = open(filename, 'rb')\n        else:\n            f.seek(0, 2)  # Seek to end of file\n            if f.tell() > (max_size * 1024):\n                raise TweepError('File is too big, must be less than %skb.' % max_size)\n            f.seek(0)  # Reset to beginning of file\n            fp = f\n\n        # image must be gif, jpeg, or png\n        file_type = mimetypes.guess_type(filename)\n        if file_type is None:\n            raise TweepError('Could not determine file type')\n        file_type = file_type[0]\n        if file_type not in ['image/gif', 'image/jpeg', 'image/png']:\n            raise TweepError('Invalid file type for image: %s' % file_type)\n\n        if isinstance(filename, six.text_type):\n            filename = filename.encode('utf-8')\n\n        BOUNDARY = b'Tw3ePy'\n        body = []\n        body.append(b'--' + BOUNDARY)\n        body.append('Content-Disposition: form-data; name=\"{0}\";'\n                    ' filename=\"{1}\"'.format(form_field, filename)\n                    .encode('utf-8'))\n        body.append('Content-Type: {0}'.format(file_type).encode('utf-8'))\n        body.append(b'')\n        body.append(fp.read())\n        body.append(b'--' + BOUNDARY + b'--')\n        body.append(b'')\n        fp.close()\n        body = b'\\r\\n'.join(body)\n\n        # build headers\n        headers = {\n            'Content-Type': 'multipart/form-data; boundary=Tw3ePy',\n            'Content-Length': str(len(body))\n        }\n\n        return headers, body"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef channel_submit_row(context):\n    change = context['change']\n    is_popup = context['is_popup']\n    save_as = context['save_as']\n    show_save = context.get('show_save', True)\n    show_save_and_continue = context.get('show_save_and_continue', True)\n\n    can_delete = context['has_delete_permission']\n    can_add = context['has_add_permission']\n    can_change = context['has_change_permission']\n\n    ctx = Context(context)\n    ctx.update({\n        'show_delete_link': (not is_popup and\n                             can_delete and\n                             change and\n                             context.get('show_delete', True)\n                             ),\n        'show_save_as_new': not is_popup and change and save_as,\n        'show_save_and_add_another': (can_add and\n                                      not is_popup and\n                                      (not save_as or context['add'])\n                                      ),\n        'show_save_and_continue': (not is_popup and can_change and show_save_and_continue),\n        'show_save': show_save,\n    })\n    return ctx", "response": "Display the row of buttons for delete and save."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget configuration from constance. config first", "response": "def get_setting(self, name):\n        notfound = object()\n        \"get configuration from 'constance.config' first \"\n        value = getattr(config, name, notfound)\n        if name.endswith('_WHITELISTED_DOMAINS'):\n            if value:\n                return value.split(',')\n            else:\n                return []\n\n        if value is notfound:\n            value = getattr(settings, name)\n        # Force text on URL named settings that are instance of Promise\n        if name.endswith('_URL'):\n            if isinstance(value, Promise):\n                value = force_text(value)\n            value = resolve_url(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload user data from service", "response": "def user_data(self, access_token, *args, **kwargs):\n        \"\"\"Loads user data from service\"\"\"\n        try:\n            user_data = super().user_data(access_token, *args, **kwargs)\n            if not user_data.get('email'):\n                raise AuthFailed(self, _('You must have a public email configured in GitHub. '\n                                         'Goto Settings/Profile and choose your public email'))\n        except AuthFailed:\n            raise AuthFailed(self, _('Sorry, you do not seem to be a public member of %s') % self.setting('NAME'))\n\n        return user_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef debug(self, request, message, extra_tags='', fail_silently=False):\n        add(self.target_name, request, constants.DEBUG, message, extra_tags=extra_tags,\n            fail_silently=fail_silently)", "response": "Add a message with the DEBUG level."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a message with the INFO level.", "response": "def info(self, request, message, extra_tags='', fail_silently=False):\n        \"\"\"Add a message with the ``INFO`` level.\"\"\"\n        add(self.target_name,\n            request, constants.INFO, message, extra_tags=extra_tags,\n            fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a message with the SUCCESS level.", "response": "def success(self, request, message, extra_tags='', fail_silently=False):\n        \"\"\"Add a message with the ``SUCCESS`` level.\"\"\"\n        add(self.target_name, request, constants.SUCCESS, message, extra_tags=extra_tags,\n            fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef warning(self, request, message, extra_tags='', fail_silently=False):\n        add(self.target_name, request, constants.WARNING, message, extra_tags=extra_tags,\n            fail_silently=fail_silently)", "response": "Add a message with the WARNING level."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a message with the ERROR level.", "response": "def error(self, request, message, extra_tags='', fail_silently=False):\n        \"\"\"Add a message with the ``ERROR`` level.\"\"\"\n        add(self.target_name, request, constants.ERROR, message, extra_tags=extra_tags,\n            fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new user.", "response": "def createuser(ctx, email, password, superuser, no_password, prompt):\n    'Create a new user.'\n\n    if prompt:\n        if not email:\n            email = click.prompt('Email')\n\n        if not (password or no_password):\n            password = click.prompt('Password')\n\n        if superuser is None:\n            superuser = click.confirm('Should this user be a superuser?', default=False)\n\n    if superuser is None:\n        superuser = False\n\n    if not email:\n        raise click.ClickException('Invalid or missing email address.')\n\n    if not no_password and not password:\n        raise click.ClickException('No password set and --no-password not passed.')\n\n    import django\n    django.setup()\n\n    from bitcaster.models import User\n\n    user = User.objects.filter(email=email).first()\n\n    if user:\n        if prompt:\n            change = click.confirm(f'User {email} already exists. Proceed updating it?', default=False)\n            if not change:\n                ctx.exit()\n            user.set_password(password)\n            if superuser:\n                user.is_superuser = superuser\n\n            op = 'updated'\n        else:\n            click.echo('Nothing to do. User exists', err=True, color='red')\n            sys.exit(1)\n    else:\n        op = 'created'\n        user = User(\n            email=email,\n            is_superuser=superuser,\n            is_staff=superuser,\n            is_active=True,\n        )\n        if password:\n            user.set_password(password)\n\n    try:\n        user.save()\n    except Exception as e:\n        raise click.ClickException(e)\n\n    click.echo(f'User {email} {op}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signout(request, next_page=userena_settings.USERENA_REDIRECT_ON_SIGNOUT,\n            template_name='userena/signout.html', *args, **kwargs):\n    \"\"\"\n    Signs out the user and adds a success message ``You have been signed\n    out.`` If next_page is defined you will be redirected to the URI. If\n    not the template in template_name is used.\n\n    :param next_page:\n        A string which specifies the URI to redirect to.\n\n    :param template_name:\n        String defining the name of the template to use. Defaults to\n        ``userena/signout.html``.\n\n    \"\"\"\n    if request.user.is_authenticated() and userena_settings.USERENA_USE_MESSAGES: # pragma: no cover\n        messages.success(request, _('You have been signed out.'), fail_silently=True)\n    userena_signals.account_signout.send(sender=None, user=request.user)\n    return Signout(request, next_page, template_name, *args, **kwargs)", "response": "Signout the user and add a success message to the userena_signals. account_signout. send is called when the user is signed out."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new HyperparameterDefaults instance containing the current instance combined with those from other.", "response": "def extend(self, other):\n        \"\"\"\n        Return a new HyperparameterDefaults instance containing the\n        hyperparameters from the current instance combined with\n        those from other.\n\n        It is an error if self and other have any hyperparameters in\n        common.\n        \"\"\"\n        overlap = [key for key in other.defaults if key in self.defaults]\n        if overlap:\n            raise ValueError(\n                \"Duplicate hyperparameter(s): %s\" % \" \".join(overlap))\n        new = dict(self.defaults)\n        new.update(other.defaults)\n        return HyperparameterDefaults(**new)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a dict containing hyperparameter settings return a dict containing those settings augmented by the defaults for any keys missing from", "response": "def with_defaults(self, obj):\n        \"\"\"\n        Given a dict of hyperparameter settings, return a dict containing\n        those settings augmented by the defaults for any keys missing from\n        the dict.\n        \"\"\"\n        self.check_valid_keys(obj)\n        obj = dict(obj)\n        for (key, value) in self.defaults.items():\n            if key not in obj:\n                obj[key] = value\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subselect(self, obj):\n        return dict(\n            (key, value) for (key, value)\n            in obj.items()\n            if key in self.defaults)", "response": "Filter a dict of hyperparameter settings to only those keys defined\n        in this HyperparameterDefaults."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the keys in obj are defined in self. defaults and raise an exception if they are not.", "response": "def check_valid_keys(self, obj):\n        \"\"\"\n        Given a dict of hyperparameter settings, throw an exception if any\n        keys are not defined in this HyperparameterDefaults instance.\n        \"\"\"\n        invalid_keys = [\n            x for x in obj if x not in self.defaults\n        ]\n        if invalid_keys:\n            raise ValueError(\n                \"No such model parameters: %s. Valid parameters are: %s\"\n                % (\" \".join(invalid_keys),\n                    \" \".join(self.defaults)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef models_grid(self, **kwargs):\n        '''\n        Make a grid of models by taking the cartesian product of all specified\n        model parameter lists.\n\n        Parameters\n        -----------\n        The valid kwarg parameters are the entries of this\n        HyperparameterDefaults instance. Each parameter must be a list\n        giving the values to search across.\n\n        Returns\n        -----------\n        list of dict giving the parameters for each model. The length of the\n        list is the product of the lengths of the input lists.\n        '''\n\n        # Check parameters\n        self.check_valid_keys(kwargs)\n        for (key, value) in kwargs.items():\n            if not isinstance(value, list):\n                raise ValueError(\n                    \"All parameters must be lists, but %s is %s\"\n                    % (key, str(type(value))))\n\n        # Make models, using defaults.\n        parameters = dict(\n            (key, [value]) for (key, value) in self.defaults.items())\n        parameters.update(kwargs)\n        parameter_names = list(parameters)\n        parameter_values = [parameters[name] for name in parameter_names]\n\n        models = [\n            dict(zip(parameter_names, model_values))\n            for model_values in itertools.product(*parameter_values)\n        ]\n        return models", "response": "Make a grid of models for all specified HyperparameterDefaults instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fixed_length_vector_encoded_sequences(self, vector_encoding_name):\n        cache_key = (\n            \"fixed_length_vector_encoding\",\n            vector_encoding_name)\n        if cache_key not in self.encoding_cache:\n            index_encoded_matrix = amino_acid.index_encoding(\n                self.fixed_length_sequences.values,\n                amino_acid.AMINO_ACID_INDEX)\n            vector_encoded = amino_acid.fixed_vectors_encoding(\n                index_encoded_matrix,\n                amino_acid.ENCODING_DATA_FRAMES[vector_encoding_name])\n            result = vector_encoded[self.indices]\n            self.encoding_cache[cache_key] = result\n        return self.encoding_cache[cache_key]", "response": "Encode the fixed length vectors of the given amino acid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a `n` x `k` matrix of integers such as that returned by `index_encoding()` and a dataframe mapping each index to an arbitrary vector, return a `n * k * m` array where the (`i`, `j`)'th element is `letter_to_vector_df.iloc[sequence[i][j]]`. The dataframe index and columns names are ignored here; the indexing is done entirely by integer position in the dataframe. Parameters ---------- index_encoded_sequences : `n` x `k` array of integers letter_to_vector_df : pandas.DataFrame of shape (`alphabet size`, `m`) Returns ------- numpy.array of integers with shape (`n`, `k`, `m`)", "response": "def fixed_vectors_encoding(index_encoded_sequences, letter_to_vector_df):\n    \"\"\"\n    Given a `n` x `k` matrix of integers such as that returned by `index_encoding()` and\n    a dataframe mapping each index to an arbitrary vector, return a `n * k * m`\n    array where the (`i`, `j`)'th element is `letter_to_vector_df.iloc[sequence[i][j]]`.\n\n    The dataframe index and columns names are ignored here; the indexing is done\n    entirely by integer position in the dataframe.\n\n    Parameters\n    ----------\n    index_encoded_sequences : `n` x `k` array of integers\n\n    letter_to_vector_df : pandas.DataFrame of shape (`alphabet size`, `m`)\n\n    Returns\n    -------\n    numpy.array of integers with shape (`n`, `k`, `m`)\n    \"\"\"\n    (num_sequences, sequence_length) = index_encoded_sequences.shape\n    target_shape = (\n        num_sequences, sequence_length, letter_to_vector_df.shape[0])\n    result = letter_to_vector_df.iloc[\n        index_encoded_sequences.flatten()\n    ].values.reshape(target_shape)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_hyperparameter_renames(cls, hyperparameters):\n        for (from_name, to_name) in cls.hyperparameter_renames.items():\n            if from_name in hyperparameters:\n                value = hyperparameters.pop(from_name)\n                if to_name:\n                    hyperparameters[to_name] = value\n        return hyperparameters", "response": "Applies the hyperparameter renames to the hyperparameters dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a keras Model with the specified architecture and weights.", "response": "def borrow_cached_network(klass, network_json, network_weights):\n        \"\"\"\n        Return a keras Model with the specified architecture and weights.\n        As an optimization, when possible this will reuse architectures from a\n        process-wide cache.\n\n        The returned object is \"borrowed\" in the sense that its weights can\n        change later after subsequent calls to this method from other objects.\n\n        If you're using this from a parallel implementation you'll need to\n        hold a lock while using the returned object.\n\n        Parameters\n        ----------\n        network_json : string of JSON\n        network_weights : list of numpy.array\n\n        Returns\n        -------\n        keras.models.Model\n        \"\"\"\n        assert network_weights is not None\n        key = klass.keras_network_cache_key(network_json)\n        if key not in klass.KERAS_MODELS_CACHE:\n            # Cache miss.\n            import keras.models\n            network = keras.models.model_from_json(network_json)\n            existing_weights = None\n        else:\n            # Cache hit.\n            (network, existing_weights) = klass.KERAS_MODELS_CACHE[key]\n        if existing_weights is not network_weights:\n            network.set_weights(network_weights)\n            klass.KERAS_MODELS_CACHE[key] = (network, network_weights)\n\n        # As an added safety check we overwrite the fit method on the returned\n        # model to throw an error if it is called.\n        def throw(*args, **kwargs):\n            raise NotImplementedError(\"Do not call fit on cached model.\")\n\n        network.fit = throw\n        return network"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef network(self, borrow=False):\n        if self._network is None and self.network_json is not None:\n            self.load_weights()\n            if borrow:\n                return self.borrow_cached_network(\n                    self.network_json,\n                    self.network_weights)\n            else:\n                import keras.models\n                self._network = keras.models.model_from_json(self.network_json)\n                if self.network_weights is not None:\n                    self._network.set_weights(self.network_weights)\n                self.network_json = None\n                self.network_weights = None\n        return self._network", "response": "Returns the keras model associated with this predictor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self):\n        self.update_network_description()\n        result = dict(self.__dict__)\n        result['_network'] = None\n        result['network_weights'] = None\n        result['network_weights_loader'] = None\n        result['prediction_cache'] = None\n        return result", "response": "Returns a dict containing all attributes except model weights\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_weights(self):\n        if self.network_weights_loader:\n            self.network_weights = self.network_weights_loader()\n            self.network_weights_loader = None", "response": "Load weights by evaluating self. network_weights_loader."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding a list of peptides to the fixed - length encoding expected by the neural network.", "response": "def peptides_to_network_input(self, peptides):\n        \"\"\"\n        Encode peptides to the fixed-length encoding expected by the neural\n        network (which depends on the architecture).\n        \n        Parameters\n        ----------\n        peptides : EncodableSequences or list of string\n\n        Returns\n        -------\n        numpy.array\n        \"\"\"\n        encoder = EncodableSequences.create(peptides)\n        if (self.hyperparameters['peptide_amino_acid_encoding'] == \"embedding\"):\n            encoded = encoder.variable_length_to_fixed_length_categorical(\n                max_length=self.hyperparameters['kmer_size'],\n                **self.input_encoding_hyperparameter_defaults.subselect(\n                    self.hyperparameters))\n        elif (\n                self.hyperparameters['peptide_amino_acid_encoding'] in\n                    available_vector_encodings()):\n            encoded = encoder.variable_length_to_fixed_length_vector_encoding(\n                self.hyperparameters['peptide_amino_acid_encoding'],\n                max_length=self.hyperparameters['kmer_size'],\n                **self.input_encoding_hyperparameter_defaults.subselect(\n                    self.hyperparameters))\n        else:\n            raise ValueError(\"Unsupported peptide_amino_acid_encoding: %s\" %\n                             self.hyperparameters['peptide_amino_acid_encoding'])\n        assert len(encoded) == len(peptides)\n        return encoded"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(\n            self,\n            peptides,\n            affinities,\n            allele_encoding=None,\n            inequalities=None,\n            sample_weights=None,\n            shuffle_permutation=None,\n            verbose=1,\n            progress_preamble=\"\",\n            progress_print_interval=5.0):\n        \"\"\"\n        Fit the neural network.\n        \n        Parameters\n        ----------\n        peptides : EncodableSequences or list of string\n        \n        affinities : list of float\n            nM affinities. Must be same length of as peptides.\n        \n        allele_encoding : AlleleEncoding, optional\n            If not specified, the model will be a single-allele predictor.\n\n        inequalities : list of string, each element one of \">\", \"<\", or \"=\".\n            Inequalities to use for fitting. Same length as affinities.\n            Each element must be one of \">\", \"<\", or \"=\". For example, a \">\"\n            will train on y_pred > y_true for that element in the training set.\n            Requires using a custom losses that support inequalities (e.g.\n            mse_with_ineqalities).\n            If None all inequalities are taken to be \"=\".\n            \n        sample_weights : list of float, optional\n            If not specified, all samples (including random negatives added\n            during training) will have equal weight. If specified, the random\n            negatives will be assigned weight=1.0.\n\n        shuffle_permutation : list of int, optional\n            Permutation (integer list) of same length as peptides and affinities\n            If None, then a random permutation will be generated.\n\n        verbose : int\n            Keras verbosity level\n\n        progress_preamble : string\n            Optional string of information to include in each progress update\n\n        progress_print_interval : float\n            How often (in seconds) to print progress update. Set to None to\n            disable.\n        \"\"\"\n        encodable_peptides = EncodableSequences.create(peptides)\n        peptide_encoding = self.peptides_to_network_input(encodable_peptides)\n\n        length_counts = (\n            pandas.Series(encodable_peptides.sequences)\n            .str.len().value_counts().to_dict())\n\n        num_random_negative = {}\n        for length in range(8, 16):\n            num_random_negative[length] = int(\n                length_counts.get(length, 0) *\n                self.hyperparameters['random_negative_rate'] +\n                self.hyperparameters['random_negative_constant'])\n        num_random_negative = pandas.Series(num_random_negative)\n        logging.info(\"Random negative counts per length:\\n%s\" % (\n            str(num_random_negative.to_dict())))\n\n        aa_distribution = None\n        if self.hyperparameters['random_negative_match_distribution']:\n            aa_distribution = amino_acid_distribution(\n                encodable_peptides.sequences,\n                smoothing=self.hyperparameters[\n                    'random_negative_distribution_smoothing'])\n            logging.info(\n                \"Using amino acid distribution for random negative:\\n%s\" % (\n                str(aa_distribution.to_dict())))\n\n        y_values = from_ic50(affinities)\n        assert numpy.isnan(y_values).sum() == 0, numpy.isnan(y_values).sum()\n        if inequalities is not None:\n            # Reverse inequalities because from_ic50() flips the direction\n            # (i.e. lower affinity results in higher y values).\n            adjusted_inequalities = pandas.Series(inequalities).map({\n                \"=\": \"=\",\n                \">\": \"<\",\n                \"<\": \">\",\n            }).values\n        else:\n            adjusted_inequalities = numpy.tile(\"=\", len(y_values))\n        if len(adjusted_inequalities) != len(y_values):\n            raise ValueError(\"Inequalities and y_values must have same length\")\n\n        x_dict_without_random_negatives = {\n            'peptide': peptide_encoding,\n        }\n        allele_encoding_dims = None\n        if allele_encoding is not None:\n            allele_encoding_input = self.allele_encoding_to_network_input(\n                allele_encoding)\n            allele_encoding_dims = allele_encoding_input.shape[1:]\n            x_dict_without_random_negatives['allele'] = allele_encoding_input\n\n        # Shuffle y_values and the contents of x_dict_without_random_negatives\n        # This ensures different data is used for the test set for early stopping\n        # when multiple models are trained.\n        if shuffle_permutation is None:\n            shuffle_permutation = numpy.random.permutation(len(y_values))\n        y_values = y_values[shuffle_permutation]\n        peptide_encoding = peptide_encoding[shuffle_permutation]\n        adjusted_inequalities = adjusted_inequalities[shuffle_permutation]\n        for key in x_dict_without_random_negatives:\n            x_dict_without_random_negatives[key] = (\n                x_dict_without_random_negatives[key][shuffle_permutation])\n        if sample_weights is not None:\n            sample_weights = sample_weights[shuffle_permutation]\n\n        if self.hyperparameters['loss'].startswith(\"custom:\"):\n            # Using a custom loss that supports inequalities\n            try:\n                custom_loss = CUSTOM_LOSSES[\n                    self.hyperparameters['loss'].replace(\"custom:\", \"\")\n                ]\n            except KeyError:\n                raise ValueError(\n                    \"No such custom loss function: %s. Supported losses are: %s\" % (\n                        self.hyperparameters['loss'],\n                        \", \".join([\n                            \"custom:\" + loss_name for loss_name in CUSTOM_LOSSES\n                        ])))\n            loss_name_or_function = custom_loss.loss\n            loss_supports_inequalities = custom_loss.supports_inequalities\n            loss_encode_y_function = custom_loss.encode_y\n        else:\n            # Using a regular keras loss. No inequalities supported.\n            loss_name_or_function = self.hyperparameters['loss']\n            loss_supports_inequalities = False\n            loss_encode_y_function = None\n\n        if not loss_supports_inequalities and (\n                any(inequality != \"=\" for inequality in adjusted_inequalities)):\n            raise ValueError(\"Loss %s does not support inequalities\" % (\n                loss_name_or_function))\n\n        if self.network() is None:\n            self._network = self.make_network(\n                allele_encoding_dims=allele_encoding_dims,\n                **self.network_hyperparameter_defaults.subselect(\n                    self.hyperparameters))\n            self.network().compile(\n                loss=loss_name_or_function,\n                optimizer=self.hyperparameters['optimizer'])\n\n        if self.hyperparameters['learning_rate'] is not None:\n            from keras import backend as K\n            K.set_value(\n                self.network().optimizer.lr,\n                self.hyperparameters['learning_rate'])\n\n        if loss_supports_inequalities:\n            # Do not sample negative affinities: just use an inequality.\n            random_negative_ic50 = self.hyperparameters['random_negative_affinity_min']\n            random_negative_target = from_ic50(random_negative_ic50)\n\n            y_dict_with_random_negatives = {\n                \"output\": numpy.concatenate([\n                    numpy.tile(\n                        random_negative_target, int(num_random_negative.sum())),\n                    y_values,\n                ]),\n            }\n            # Note: we are using \"<\" here not \">\" because the inequalities are\n            # now in target-space (0-1) not affinity-space.\n            adjusted_inequalities_with_random_negatives = (\n                [\"<\"] * int(num_random_negative.sum()) +\n                list(adjusted_inequalities))\n        else:\n            # Randomly sample random negative affinities\n            y_dict_with_random_negatives = {\n                \"output\": numpy.concatenate([\n                    from_ic50(\n                        numpy.random.uniform(\n                            self.hyperparameters[\n                                'random_negative_affinity_min'],\n                            self.hyperparameters[\n                                'random_negative_affinity_max'],\n                            int(num_random_negative.sum()))),\n                    y_values,\n                ]),\n            }\n        if sample_weights is not None:\n            sample_weights_with_random_negatives = numpy.concatenate([\n                numpy.ones(int(num_random_negative.sum())),\n                sample_weights])\n        else:\n            sample_weights_with_random_negatives = None\n\n        if loss_encode_y_function is not None:\n            y_dict_with_random_negatives['output'] = loss_encode_y_function(\n                y_dict_with_random_negatives['output'],\n                adjusted_inequalities_with_random_negatives)\n\n        val_losses = []\n        min_val_loss_iteration = None\n        min_val_loss = None\n\n        fit_info = collections.defaultdict(list)\n        start = time.time()\n        last_progress_print = None\n        x_dict_with_random_negatives = {}\n        for i in range(self.hyperparameters['max_epochs']):\n            random_negative_peptides_list = []\n            for (length, count) in num_random_negative.iteritems():\n                random_negative_peptides_list.extend(\n                    random_peptides(\n                        count,\n                        length=length,\n                        distribution=aa_distribution))\n            random_negative_peptides = EncodableSequences.create(\n                random_negative_peptides_list)\n            random_negative_peptides_encoding = (\n                self.peptides_to_network_input(random_negative_peptides))\n\n            if not x_dict_with_random_negatives:\n                if len(random_negative_peptides) > 0:\n                    x_dict_with_random_negatives[\"peptide\"] = numpy.concatenate([\n                        random_negative_peptides_encoding,\n                        peptide_encoding,\n                    ])\n                    if 'allele' in x_dict_without_random_negatives:\n                        x_dict_with_random_negatives['allele'] = numpy.concatenate([\n                            x_dict_without_random_negatives['allele'][\n                                numpy.random.choice(\n                                    x_dict_without_random_negatives[\n                                        'allele'].shape[0],\n                                    size=len(random_negative_peptides_list))],\n                            x_dict_without_random_negatives['allele']\n                        ])\n                else:\n                    x_dict_with_random_negatives = (\n                        x_dict_without_random_negatives)\n            else:\n                # Update x_dict_with_random_negatives in place.\n                # This is more memory efficient than recreating it as above.\n                if len(random_negative_peptides) > 0:\n                    x_dict_with_random_negatives[\"peptide\"][:len(random_negative_peptides)] = (\n                        random_negative_peptides_encoding\n                    )\n                    if 'allele' in x_dict_with_random_negatives:\n                        x_dict_with_random_negatives['allele'][:len(random_negative_peptides)] = (\n                            x_dict_with_random_negatives['allele'][\n                                len(random_negative_peptides) + numpy.random.choice(\n                                    x_dict_with_random_negatives['allele'].shape[0] -\n                                    len(random_negative_peptides),\n                                    size=len(random_negative_peptides))\n                            ]\n                        )\n\n            fit_history = self.network().fit(\n                x_dict_with_random_negatives,\n                y_dict_with_random_negatives,\n                shuffle=True,\n                batch_size=self.hyperparameters['minibatch_size'],\n                verbose=verbose,\n                epochs=1,\n                validation_split=self.hyperparameters['validation_split'],\n                sample_weight=sample_weights_with_random_negatives)\n\n            for (key, value) in fit_history.history.items():\n                fit_info[key].extend(value)\n\n            # Print progress no more often than once every few seconds.\n            if progress_print_interval is not None and (\n                    not last_progress_print or (\n                        time.time() - last_progress_print\n                        > progress_print_interval)):\n                print((progress_preamble + \" \" +\n                       \"Epoch %3d / %3d: loss=%g. \"\n                       \"Min val loss (%s) at epoch %s\" % (\n                           i,\n                           self.hyperparameters['max_epochs'],\n                           fit_info['loss'][-1],\n                           str(min_val_loss),\n                           min_val_loss_iteration)).strip())\n                last_progress_print = time.time()\n\n            if self.hyperparameters['validation_split']:\n                val_loss = fit_info['val_loss'][-1]\n                val_losses.append(val_loss)\n\n                if min_val_loss is None or val_loss <= min_val_loss:\n                    min_val_loss = val_loss\n                    min_val_loss_iteration = i\n\n                if self.hyperparameters['early_stopping']:\n                    threshold = (\n                        min_val_loss_iteration +\n                        self.hyperparameters['patience'])\n                    if i > threshold:\n                        if progress_print_interval is not None:\n                            print((progress_preamble + \" \" +\n                                \"Stopping at epoch %3d / %3d: loss=%g. \"\n                                \"Min val loss (%s) at epoch %s\" % (\n                                    i,\n                                    self.hyperparameters['max_epochs'],\n                                    fit_info['loss'][-1],\n                                    str(min_val_loss),\n                                    min_val_loss_iteration)).strip())\n                        break\n\n        fit_info[\"time\"] = time.time() - start\n        fit_info[\"num_points\"] = len(peptides)\n        self.fit_info.append(dict(fit_info))", "response": "Fit the neural network to a set of neural entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts the nM affinity of a set of peptides.", "response": "def predict(self, peptides, allele_encoding=None, batch_size=4096):\n        \"\"\"\n        Predict affinities.\n\n        If peptides are specified as EncodableSequences, then the predictions\n        will be cached for this predictor as long as the EncodableSequences object\n        remains in memory. The cache is keyed in the object identity of the\n        EncodableSequences, not the sequences themselves.\n\n        Parameters\n        ----------\n        peptides : EncodableSequences or list of string\n        \n        allele_encoding : AlleleEncoding, optional\n            Only required when this model is a pan-allele model\n\n        batch_size : int\n            batch_size passed to Keras\n\n        Returns\n        -------\n        numpy.array of nM affinity predictions \n        \"\"\"\n        assert self.prediction_cache is not None\n        use_cache = (\n            allele_encoding is None and\n            isinstance(peptides, EncodableSequences))\n        if use_cache and peptides in self.prediction_cache:\n            return self.prediction_cache[peptides].copy()\n\n        x_dict = {\n            'peptide': self.peptides_to_network_input(peptides)\n        }\n        if allele_encoding is not None:\n            allele_input = self.allele_encoding_to_network_input(allele_encoding)\n            x_dict['allele'] = allele_input\n\n        network = self.network(borrow=True)\n        raw_predictions = network.predict(x_dict, batch_size=batch_size)\n        predictions = numpy.array(raw_predictions, dtype = \"float64\")[:,0]\n        result = to_ic50(predictions)\n        if use_cache:\n            self.prediction_cache[peptides] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_network(\n            allele_encoding_dims,\n            kmer_size,\n            peptide_amino_acid_encoding,\n            embedding_input_dim,\n            embedding_output_dim,\n            allele_dense_layer_sizes,\n            peptide_dense_layer_sizes,\n            peptide_allele_merge_method,\n            peptide_allele_merge_activation,\n            layer_sizes,\n            dense_layer_l1_regularization,\n            dense_layer_l2_regularization,\n            activation,\n            init,\n            output_activation,\n            dropout_probability,\n            batch_normalization,\n            embedding_init_method,\n            locally_connected_layers):\n        \"\"\"\n        Helper function to make a keras network for class1 affinity prediction.\n        \"\"\"\n\n        # We import keras here to avoid tensorflow debug output, etc. unless we\n        # are actually about to use Keras.\n\n        from keras.layers import Input\n        import keras.layers\n        from keras.layers.core import Dense, Flatten, Dropout\n        from keras.layers.embeddings import Embedding\n        from keras.layers.normalization import BatchNormalization\n\n        if peptide_amino_acid_encoding == \"embedding\":\n            peptide_input = Input(\n                shape=(kmer_size,), dtype='int32', name='peptide')\n            current_layer = Embedding(\n                input_dim=embedding_input_dim,\n                output_dim=embedding_output_dim,\n                input_length=kmer_size,\n                embeddings_initializer=embedding_init_method,\n                name=\"peptide_embedding\")(peptide_input)\n        else:\n            peptide_input = Input(\n                shape=(\n                    kmer_size,\n                    vector_encoding_length(peptide_amino_acid_encoding)),\n                dtype='float32',\n                name='peptide')\n            current_layer = peptide_input\n\n        inputs = [peptide_input]\n\n        kernel_regularizer = None\n        l1 = dense_layer_l1_regularization\n        l2 = dense_layer_l2_regularization\n        if l1 > 0 or l2 > 0:\n            kernel_regularizer = keras.regularizers.l1_l2(l1, l2)\n\n        for (i, locally_connected_params) in enumerate(locally_connected_layers):\n            current_layer = keras.layers.LocallyConnected1D(\n                name=\"lc_%d\" % i,\n                **locally_connected_params)(current_layer)\n\n        current_layer = Flatten(name=\"flattened_0\")(current_layer)\n\n        for (i, layer_size) in enumerate(peptide_dense_layer_sizes):\n            current_layer = Dense(\n                layer_size,\n                name=\"peptide_dense_%d\" % i,\n                kernel_regularizer=kernel_regularizer,\n                activation=activation)(current_layer)\n\n        if batch_normalization:\n            current_layer = BatchNormalization(name=\"batch_norm_early\")(\n                current_layer)\n\n        if dropout_probability:\n            current_layer = Dropout(dropout_probability, name=\"dropout_early\")(\n                current_layer)\n\n        if allele_encoding_dims:\n            allele_input = Input(\n                shape=allele_encoding_dims,\n                dtype='float32',\n                name='allele')\n            inputs.append(allele_input)\n            allele_embedding_layer = Flatten(name=\"allele_flat\")(allele_input)\n\n            for (i, layer_size) in enumerate(allele_dense_layer_sizes):\n                allele_embedding_layer = Dense(\n                    layer_size,\n                    name=\"allele_dense_%d\" % i,\n                    kernel_regularizer=kernel_regularizer,\n                    activation=activation)(allele_embedding_layer)\n\n            if peptide_allele_merge_method == 'concatenate':\n                current_layer = keras.layers.concatenate([\n                    current_layer, allele_embedding_layer\n                ], name=\"allele_peptide_merged\")\n            elif peptide_allele_merge_method == 'multiply':\n                current_layer = keras.layers.multiply([\n                    current_layer, allele_embedding_layer\n                ], name=\"allele_peptide_merged\")\n            else:\n                raise ValueError(\n                    \"Unsupported peptide_allele_encoding_merge_method: %s\"\n                    % peptide_allele_merge_method)\n\n            if peptide_allele_merge_activation:\n                current_layer = keras.layers.Activation(\n                    peptide_allele_merge_activation,\n                    name=\"alelle_peptide_merged_%s\" %\n                         peptide_allele_merge_activation)(current_layer)\n            \n        for (i, layer_size) in enumerate(layer_sizes):\n            current_layer = Dense(\n                layer_size,\n                activation=activation,\n                kernel_regularizer=kernel_regularizer,\n                name=\"dense_%d\" % i)(current_layer)\n\n            if batch_normalization:\n                current_layer = BatchNormalization(name=\"batch_norm_%d\" % i)\\\n                    (current_layer)\n\n            if dropout_probability > 0:\n                current_layer = Dropout(\n                    dropout_probability, name=\"dropout_%d\" % i)(current_layer)\n\n        output = Dense(\n            1,\n            kernel_initializer=init,\n            activation=output_activation,\n            name=\"output\")(current_layer)\n        model = keras.models.Model(\n            inputs=inputs,\n            outputs=[output],\n            name=\"predictor\")\n        return model", "response": "Helper function to make a keras network for class1 affinity prediction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_scores(\n        ic50_y,\n        ic50_y_pred,\n        sample_weight=None,\n        threshold_nm=500,\n        max_ic50=50000):\n    \"\"\"\n    Calculate AUC, F1, and Kendall Tau scores.\n\n    Parameters\n    -----------\n    ic50_y : float list\n        true IC50s (i.e. affinities)\n\n    ic50_y_pred : float list\n        predicted IC50s\n\n    sample_weight : float list [optional]\n\n    threshold_nm : float [optional]\n\n    max_ic50 : float [optional]\n\n    Returns\n    -----------\n    dict with entries \"auc\", \"f1\", \"tau\"\n    \"\"\"\n\n    y_pred = from_ic50(ic50_y_pred, max_ic50)\n    try:\n        auc = sklearn.metrics.roc_auc_score(\n            ic50_y <= threshold_nm,\n            y_pred,\n            sample_weight=sample_weight)\n    except ValueError as e:\n        logging.warning(e)\n        auc = numpy.nan\n    try:\n        f1 = sklearn.metrics.f1_score(\n            ic50_y <= threshold_nm,\n            ic50_y_pred <= threshold_nm,\n            sample_weight=sample_weight)\n    except ValueError as e:\n        logging.warning(e)\n        f1 = numpy.nan\n    try:\n        tau = scipy.stats.kendalltau(ic50_y_pred, ic50_y)[0]\n    except ValueError as e:\n        logging.warning(e)\n        tau = numpy.nan\n\n    return dict(\n        auc=auc,\n        f1=f1,\n        tau=tau)", "response": "Calculates AUC F1 and Kendall Tau scores for the given IC50s and returns a dictionary with the scores for the AUC F1 and Kendall Tau scores."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef variable_length_to_fixed_length_categorical(\n            self, left_edge=4, right_edge=4, max_length=15):\n        \"\"\"\n        Encode variable-length sequences using a fixed-length encoding designed\n        for preserving the anchor positions of class I peptides.\n        \n        The sequences must be of length at least left_edge + right_edge, and at\n        most max_length.\n        \n        Parameters\n        ----------\n        left_edge : int, size of fixed-position left side\n        right_edge : int, size of the fixed-position right side\n        max_length : sequence length of the resulting encoding\n\n        Returns\n        -------\n        numpy.array of integers with shape (num sequences, max_length)\n        \"\"\"\n\n        cache_key = (\n            \"fixed_length_categorical\",\n            left_edge,\n            right_edge,\n            max_length)\n\n        if cache_key not in self.encoding_cache:\n            fixed_length_sequences = (\n                self.sequences_to_fixed_length_index_encoded_array(\n                    self.sequences,\n                    left_edge=left_edge,\n                    right_edge=right_edge,\n                    max_length=max_length))\n            self.encoding_cache[cache_key] = fixed_length_sequences\n        return self.encoding_cache[cache_key]", "response": "Encode a variable - length sequence using a fixed - length encoding designed to preserve anchor positions of class I peptides."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef variable_length_to_fixed_length_vector_encoding(\n            self, vector_encoding_name, left_edge=4, right_edge=4, max_length=15):\n        \"\"\"\n        Encode variable-length sequences using a fixed-length encoding designed\n        for preserving the anchor positions of class I peptides.\n\n        The sequences must be of length at least left_edge + right_edge, and at\n        most max_length.\n\n        Parameters\n        ----------\n        vector_encoding_name : string\n            How to represent amino acids.\n            One of \"BLOSUM62\", \"one-hot\", etc. Full list of supported vector\n            encodings is given by available_vector_encodings().\n        left_edge : int, size of fixed-position left side\n        right_edge : int, size of the fixed-position right side\n        max_length : sequence length of the resulting encoding\n\n        Returns\n        -------\n        numpy.array with shape (num sequences, max_length, m) where m is\n        vector_encoding_length(vector_encoding_name)\n        \"\"\"\n        cache_key = (\n            \"fixed_length_vector_encoding\",\n            vector_encoding_name,\n            left_edge,\n            right_edge,\n            max_length)\n        if cache_key not in self.encoding_cache:\n            fixed_length_sequences = (\n                self.sequences_to_fixed_length_index_encoded_array(\n                    self.sequences,\n                    left_edge=left_edge,\n                    right_edge=right_edge,\n                    max_length=max_length))\n            result = amino_acid.fixed_vectors_encoding(\n                fixed_length_sequences,\n                amino_acid.ENCODING_DATA_FRAMES[vector_encoding_name])\n            assert result.shape[0] == len(self.sequences)\n            self.encoding_cache[cache_key] = result\n        return self.encoding_cache[cache_key]", "response": "Encode a variable - length sequence using a fixed - length encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a sequence of strings where each string is of length at least left_edge + right_edge and at most max_length into a fixed length index encoded array.", "response": "def sequences_to_fixed_length_index_encoded_array(\n            klass, sequences, left_edge=4, right_edge=4, max_length=15):\n        \"\"\"\n        Transform a sequence of strings, where each string is of length at least\n        left_edge + right_edge and at most max_length into strings of length\n        max_length using a scheme designed to preserve the anchor positions of\n        class I peptides.\n\n        The first left_edge characters in the input always map to the first\n        left_edge characters in the output. Similarly for the last right_edge\n        characters. The middle characters are filled in based on the length,\n        with the X character filling in the blanks.\n\n        For example, using defaults:\n\n        AAAACDDDD -> AAAAXXXCXXXDDDD\n\n        The strings are also converted to int categorical amino acid indices.\n\n        Parameters\n        ----------\n        sequence : string\n        left_edge : int\n        right_edge : int\n        max_length : int\n\n        Returns\n        -------\n        numpy array of shape (len(sequences), max_length) and dtype int\n        \"\"\"\n\n        # Result array is int32, filled with X (null amino acid) value.\n        result = numpy.full(\n            fill_value=amino_acid.AMINO_ACID_INDEX['X'],\n            shape=(len(sequences), max_length),\n            dtype=\"int32\")\n\n        df = pandas.DataFrame({\"peptide\": sequences})\n        df[\"length\"] = df.peptide.str.len()\n\n        middle_length = max_length - left_edge - right_edge\n\n        # For efficiency we handle each supported peptide length using bulk\n        # array operations.\n        for (length, sub_df) in df.groupby(\"length\"):\n            if length < left_edge + right_edge:\n                raise ValueError(\n                    \"Sequence '%s' (length %d) unsupported: length must be at \"\n                    \"least %d. There are %d total peptides with this length.\" % (\n                        sub_df.iloc[0].peptide, length, left_edge + right_edge,\n                        len(sub_df)))\n            if length > max_length:\n                raise ValueError(\n                    \"Sequence '%s' (length %d) unsupported: length must be at \"\n                    \"most %d. There are %d total peptides with this length.\" % (\n                        sub_df.iloc[0].peptide, length, max_length,\n                        len(sub_df)))\n\n            # Array of shape (num peptides, length) giving fixed-length amino\n            # acid encoding each peptide of the current length.\n            fixed_length_sequences = numpy.stack(\n                sub_df.peptide.map(\n                    lambda s: numpy.array([\n                        amino_acid.AMINO_ACID_INDEX[char] for char in s\n                    ])).values)\n\n            num_null = max_length - length\n            num_null_left = int(math.ceil(num_null / 2))\n            num_middle_filled = middle_length - num_null\n            middle_start = left_edge + num_null_left\n\n            # Set left edge\n            result[sub_df.index, :left_edge] = fixed_length_sequences[\n                :, :left_edge\n            ]\n\n            # Set middle.\n            result[\n                sub_df.index,\n                middle_start : middle_start + num_middle_filled\n            ] = fixed_length_sequences[\n                :, left_edge : left_edge + num_middle_filled\n            ]\n\n            # Set right edge.\n            result[\n                sub_df.index,\n                -right_edge:\n            ] = fixed_length_sequences[:, -right_edge:]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef robust_mean(log_values):\n    if log_values.shape[1] <= 3:\n        # Too few values to use robust mean.\n        return numpy.nanmean(log_values, axis=1)\n    without_nans = numpy.nan_to_num(log_values)  # replace nan with 0\n    mask = (\n        (~numpy.isnan(log_values)) &\n        (without_nans <= numpy.nanpercentile(log_values, 75, axis=1).reshape((-1, 1))) &\n        (without_nans >= numpy.nanpercentile(log_values, 25, axis=1).reshape((-1, 1))))\n    return (without_nans * mask.astype(float)).sum(1) / mask.sum(1)", "response": "Calculates the robust mean of values falling within 25 - 75 percentiles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of the neural networks in the ensemble.", "response": "def neural_networks(self):\n        \"\"\"\n        List of the neural networks in the ensemble.\n\n        Returns\n        -------\n        list of `Class1NeuralNetwork`\n        \"\"\"\n        result = []\n        for models in self.allele_to_allele_specific_models.values():\n            result.extend(models)\n        result.extend(self.class1_pan_allele_models)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge(cls, predictors):\n        assert len(predictors) > 0\n        if len(predictors) == 1:\n            return predictors[0]\n\n        allele_to_allele_specific_models = collections.defaultdict(list)\n        class1_pan_allele_models = []\n        allele_to_fixed_length_sequence = predictors[0].allele_to_fixed_length_sequence\n\n        for predictor in predictors:\n            for (allele, networks) in (\n                    predictor.allele_to_allele_specific_models.items()):\n                allele_to_allele_specific_models[allele].extend(networks)\n            class1_pan_allele_models.extend(\n                predictor.class1_pan_allele_models)\n\n        return Class1AffinityPredictor(\n            allele_to_allele_specific_models=allele_to_allele_specific_models,\n            class1_pan_allele_models=class1_pan_allele_models,\n            allele_to_fixed_length_sequence=allele_to_fixed_length_sequence\n        )", "response": "Merge the ensembles of two or more Class1AffinityPredictor instances into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the models present other predictors into the current predictor.", "response": "def merge_in_place(self, others):\n        \"\"\"\n        Add the models present other predictors into the current predictor.\n\n        Parameters\n        ----------\n        others : list of Class1AffinityPredictor\n            Other predictors to merge into the current predictor.\n\n        Returns\n        -------\n        list of string : names of newly added models\n        \"\"\"\n\n        new_model_names = []\n        for predictor in others:\n            for model in predictor.class1_pan_allele_models:\n                model_name = self.model_name(\n                    \"pan-class1\",\n                    len(self.class1_pan_allele_models))\n                self.class1_pan_allele_models.append(model)\n                row = pandas.Series(collections.OrderedDict([\n                    (\"model_name\", model_name),\n                    (\"allele\", \"pan-class1\"),\n                    (\"config_json\", json.dumps(model.get_config())),\n                    (\"model\", model),\n                ])).to_frame().T\n                self._manifest_df = pandas.concat(\n                    [self.manifest_df, row], ignore_index=True)\n                new_model_names.append(model_name)\n\n            for allele in predictor.allele_to_allele_specific_models:\n                if allele not in self.allele_to_allele_specific_models:\n                    self.allele_to_allele_specific_models[allele] = []\n                current_models = self.allele_to_allele_specific_models[allele]\n                for model in predictor.allele_to_allele_specific_models[allele]:\n                    model_name = self.model_name(allele, len(current_models))\n                    row = pandas.Series(collections.OrderedDict([\n                        (\"model_name\", model_name),\n                        (\"allele\", allele),\n                        (\"config_json\", json.dumps(model.get_config())),\n                        (\"model\", model),\n                    ])).to_frame().T\n                    self._manifest_df = pandas.concat(\n                        [self.manifest_df, row], ignore_index=True)\n                    current_models.append(model)\n                    new_model_names.append(model_name)\n\n        self.clear_cache()\n        return new_model_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef supported_alleles(self):\n        if 'supported_alleles' not in self._cache:\n            result = set(self.allele_to_allele_specific_models)\n            if self.allele_to_fixed_length_sequence:\n                result = result.union(self.allele_to_fixed_length_sequence)\n            self._cache[\"supported_alleles\"] = sorted(result)\n        return self._cache[\"supported_alleles\"]", "response": "Returns a list of all the allele names that can be used for predictions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple of the maximum and minimum lengths of peptides supported by all models.", "response": "def supported_peptide_lengths(self):\n        \"\"\"\n        (minimum, maximum) lengths of peptides supported by *all models*,\n        inclusive.\n\n        Returns\n        -------\n        (int, int) tuple\n\n        \"\"\"\n        if 'supported_peptide_lengths' not in self._cache:\n            length_ranges = set(\n                network.supported_peptide_lengths\n                for network in self.neural_networks)\n            result = (\n                max(lower for (lower, upper) in length_ranges),\n                min(upper for (lower, upper) in length_ranges))\n            self._cache[\"supported_peptide_lengths\"] = result\n        return self._cache[\"supported_peptide_lengths\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing the predictor to a directory on disk.", "response": "def save(self, models_dir, model_names_to_write=None, write_metadata=True):\n        \"\"\"\n        Serialize the predictor to a directory on disk. If the directory does\n        not exist it will be created.\n        \n        The serialization format consists of a file called \"manifest.csv\" with\n        the configurations of each Class1NeuralNetwork, along with per-network\n        files giving the model weights. If there are pan-allele predictors in\n        the ensemble, the allele sequences are also stored in the\n        directory. There is also a small file \"index.txt\" with basic metadata:\n        when the models were trained, by whom, on what host.\n        \n        Parameters\n        ----------\n        models_dir : string\n            Path to directory\n            \n        model_names_to_write : list of string, optional\n            Only write the weights for the specified models. Useful for\n            incremental updates during training.\n\n        write_metadata : boolean, optional\n            Whether to write optional metadata\n        \"\"\"\n        num_models = len(self.class1_pan_allele_models) + sum(\n            len(v) for v in self.allele_to_allele_specific_models.values())\n        assert len(self.manifest_df) == num_models, (\n            \"Manifest seems out of sync with models: %d vs %d entries\" % (\n                len(self.manifest_df), num_models))\n\n        if model_names_to_write is None:\n            # Write all models\n            model_names_to_write = self.manifest_df.model_name.values\n\n        if not exists(models_dir):\n            mkdir(models_dir)\n\n        sub_manifest_df = self.manifest_df.ix[\n            self.manifest_df.model_name.isin(model_names_to_write)\n        ]\n\n        for (_, row) in sub_manifest_df.iterrows():\n            weights_path = self.weights_path(models_dir, row.model_name)\n            Class1AffinityPredictor.save_weights(\n                row.model.get_weights(), weights_path)\n            logging.info(\"Wrote: %s\" % weights_path)\n\n        write_manifest_df = self.manifest_df[[\n            c for c in self.manifest_df.columns if c != \"model\"\n        ]]\n        manifest_path = join(models_dir, \"manifest.csv\")\n        write_manifest_df.to_csv(manifest_path, index=False)\n        logging.info(\"Wrote: %s\" % manifest_path)\n\n        if write_metadata:\n            # Write \"info.txt\"\n            info_path = join(models_dir, \"info.txt\")\n            rows = [\n                (\"trained on\", time.asctime()),\n                (\"package   \", \"mhcflurry %s\" % __version__),\n                (\"hostname  \", gethostname()),\n                (\"user      \", getuser()),\n            ]\n            pandas.DataFrame(rows).to_csv(\n                info_path, sep=\"\\t\", header=False, index=False)\n\n            if self.metadata_dataframes:\n                for (name, df) in self.metadata_dataframes.items():\n                    metadata_df_path = join(models_dir, \"%s.csv.bz2\" % name)\n                    df.to_csv(metadata_df_path, index=False, compression=\"bz2\")\n\n        if self.allele_to_fixed_length_sequence is not None:\n            allele_to_sequence_df = pandas.DataFrame(\n                list(self.allele_to_fixed_length_sequence.items()),\n                columns=['allele', 'sequence']\n            )\n            allele_to_sequence_df.to_csv(\n                join(models_dir, \"allele_sequences.csv\"), index=False)\n            logging.info(\"Wrote: %s\" % join(models_dir, \"allele_sequences.csv\"))\n\n        if self.allele_to_percent_rank_transform:\n            percent_ranks_df = None\n            for (allele, transform) in self.allele_to_percent_rank_transform.items():\n                series = transform.to_series()\n                if percent_ranks_df is None:\n                    percent_ranks_df = pandas.DataFrame(index=series.index)\n                assert_equal(series.index.values, percent_ranks_df.index.values)\n                percent_ranks_df[allele] = series\n            percent_ranks_path = join(models_dir, \"percent_ranks.csv\")\n            percent_ranks_df.to_csv(\n                percent_ranks_path,\n                index=True,\n                index_label=\"bin\")\n            logging.info(\"Wrote: %s\" % percent_ranks_path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(models_dir=None, max_models=None):\n        if models_dir is None:\n            models_dir = get_default_class1_models_dir()\n\n        manifest_path = join(models_dir, \"manifest.csv\")\n        manifest_df = pandas.read_csv(manifest_path, nrows=max_models)\n\n        allele_to_allele_specific_models = collections.defaultdict(list)\n        class1_pan_allele_models = []\n        all_models = []\n        for (_, row) in manifest_df.iterrows():\n            weights_filename = Class1AffinityPredictor.weights_path(\n                models_dir, row.model_name)\n            config = json.loads(row.config_json)\n\n            # We will lazy-load weights when the network is used.\n            model = Class1NeuralNetwork.from_config(\n                config,\n                weights_loader=partial(\n                    Class1AffinityPredictor.load_weights,\n                    abspath(weights_filename)))\n            if row.allele == \"pan-class1\":\n                class1_pan_allele_models.append(model)\n            else:\n                allele_to_allele_specific_models[row.allele].append(model)\n            all_models.append(model)\n\n        manifest_df[\"model\"] = all_models\n\n        allele_to_fixed_length_sequence = None\n        if exists(join(models_dir, \"allele_sequences.csv\")):\n            allele_to_fixed_length_sequence = pandas.read_csv(\n                join(models_dir, \"allele_sequences.csv\"),\n                index_col=\"allele\").to_dict()\n\n        allele_to_percent_rank_transform = {}\n        percent_ranks_path = join(models_dir, \"percent_ranks.csv\")\n        if exists(percent_ranks_path):\n            percent_ranks_df = pandas.read_csv(percent_ranks_path, index_col=0)\n            for allele in percent_ranks_df.columns:\n                allele_to_percent_rank_transform[allele] = (\n                    PercentRankTransform.from_series(percent_ranks_df[allele]))\n\n        logging.info(\n            \"Loaded %d class1 pan allele predictors, %d allele sequences, \"\n            \"%d percent rank distributions, and %d allele specific models: %s\" % (\n                len(class1_pan_allele_models),\n                len(allele_to_fixed_length_sequence) if allele_to_fixed_length_sequence else 0,\n                len(allele_to_percent_rank_transform),\n                sum(len(v) for v in allele_to_allele_specific_models.values()),\n                \", \".join(\n                    \"%s (%d)\" % (allele, len(v))\n                    for (allele, v)\n                    in sorted(allele_to_allele_specific_models.items()))))\n\n        result = Class1AffinityPredictor(\n            allele_to_allele_specific_models=allele_to_allele_specific_models,\n            class1_pan_allele_models=class1_pan_allele_models,\n            allele_to_fixed_length_sequence=allele_to_fixed_length_sequence,\n            manifest_df=manifest_df,\n            allele_to_percent_rank_transform=allele_to_percent_rank_transform,\n        )\n        return result", "response": "Loads a predictor from a directory on disk."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a model name for a given allele and number", "response": "def model_name(allele, num):\n        \"\"\"\n        Generate a model name\n        \n        Parameters\n        ----------\n        allele : string\n        num : int\n\n        Returns\n        -------\n        string\n\n        \"\"\"\n        random_string = hashlib.sha1(\n            str(time.time()).encode()).hexdigest()[:16]\n        return \"%s-%d-%s\" % (allele.upper(), num, random_string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit_allele_specific_predictors(\n            self,\n            n_models,\n            architecture_hyperparameters_list,\n            allele,\n            peptides,\n            affinities,\n            inequalities=None,\n            train_rounds=None,\n            models_dir_for_save=None,\n            verbose=0,\n            progress_preamble=\"\",\n            progress_print_interval=5.0):\n        \"\"\"\n        Fit one or more allele specific predictors for a single allele using one\n        or more neural network architectures.\n        \n        The new predictors are saved in the Class1AffinityPredictor instance\n        and will be used on subsequent calls to `predict`.\n        \n        Parameters\n        ----------\n        n_models : int\n            Number of neural networks to fit\n        \n        architecture_hyperparameters_list : list of dict\n            List of hyperparameter sets.\n               \n        allele : string\n        \n        peptides : `EncodableSequences` or list of string\n        \n        affinities : list of float\n            nM affinities\n\n        inequalities : list of string, each element one of \">\", \"<\", or \"=\"\n            See Class1NeuralNetwork.fit for details.\n\n        train_rounds : sequence of int\n            Each training point i will be used on training rounds r for which\n            train_rounds[i] > r, r >= 0.\n        \n        models_dir_for_save : string, optional\n            If specified, the Class1AffinityPredictor is (incrementally) written\n            to the given models dir after each neural network is fit.\n        \n        verbose : int\n            Keras verbosity\n\n        progress_preamble : string\n            Optional string of information to include in each progress update\n\n        progress_print_interval : float\n            How often (in seconds) to print progress. Set to None to disable.\n\n        Returns\n        -------\n        list of `Class1NeuralNetwork`\n        \"\"\"\n\n        allele = mhcnames.normalize_allele_name(allele)\n        if allele not in self.allele_to_allele_specific_models:\n            self.allele_to_allele_specific_models[allele] = []\n\n        encodable_peptides = EncodableSequences.create(peptides)\n        peptides_affinities_inequalities_per_round = [\n            (encodable_peptides, affinities, inequalities)\n        ]\n\n        if train_rounds is not None:\n            for round in sorted(set(train_rounds)):\n                round_mask = train_rounds > round\n                if round_mask.any():\n                    sub_encodable_peptides = EncodableSequences.create(\n                        encodable_peptides.sequences[round_mask])\n                    peptides_affinities_inequalities_per_round.append((\n                        sub_encodable_peptides,\n                        affinities[round_mask],\n                        None if inequalities is None else inequalities[round_mask]))\n        n_rounds = len(peptides_affinities_inequalities_per_round)\n\n        n_architectures = len(architecture_hyperparameters_list)\n\n        # Adjust progress info to indicate number of models and\n        # architectures.\n        pieces = []\n        if n_models > 1:\n            pieces.append(\"Model {model_num:2d} / {n_models:2d}\")\n        if n_architectures > 1:\n            pieces.append(\n                \"Architecture {architecture_num:2d} / {n_architectures:2d}\")\n        if len(peptides_affinities_inequalities_per_round) > 1:\n            pieces.append(\"Round {round:2d} / {n_rounds:2d}\")\n        pieces.append(\"{n_peptides:4d} peptides\")\n        progress_preamble_template = \"[ %s ] {user_progress_preamble}\" % (\n            \", \".join(pieces))\n\n        models = []\n        for model_num in range(n_models):\n            for (architecture_num, architecture_hyperparameters) in enumerate(\n                    architecture_hyperparameters_list):\n                model = Class1NeuralNetwork(**architecture_hyperparameters)\n                for round_num in range(n_rounds):\n                    (round_peptides, round_affinities, round_inequalities) = (\n                        peptides_affinities_inequalities_per_round[round_num]\n                    )\n                    model.fit(\n                        round_peptides,\n                        round_affinities,\n                        inequalities=round_inequalities,\n                        verbose=verbose,\n                        progress_preamble=progress_preamble_template.format(\n                            n_peptides=len(round_peptides),\n                            round=round_num,\n                            n_rounds=n_rounds,\n                            user_progress_preamble=progress_preamble,\n                            model_num=model_num + 1,\n                            n_models=n_models,\n                            architecture_num=architecture_num + 1,\n                            n_architectures=n_architectures),\n                        progress_print_interval=progress_print_interval)\n\n                model_name = self.model_name(allele, model_num)\n                row = pandas.Series(collections.OrderedDict([\n                    (\"model_name\", model_name),\n                    (\"allele\", allele),\n                    (\"config_json\", json.dumps(model.get_config())),\n                    (\"model\", model),\n                ])).to_frame().T\n                self._manifest_df = pandas.concat(\n                    [self.manifest_df, row], ignore_index=True)\n                self.allele_to_allele_specific_models[allele].append(model)\n                if models_dir_for_save:\n                    self.save(\n                        models_dir_for_save, model_names_to_write=[model_name])\n                models.append(model)\n\n        self.clear_cache()\n        return models", "response": "Fits one or more allele specific predictors for a single allele."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting one or more pan - allele predictors using a single neural network.", "response": "def fit_class1_pan_allele_models(\n            self,\n            n_models,\n            architecture_hyperparameters,\n            alleles,\n            peptides,\n            affinities,\n            inequalities,\n            models_dir_for_save=None,\n            verbose=1,\n            progress_preamble=\"\",\n            progress_print_interval=5.0):\n        \"\"\"\n        Fit one or more pan-allele predictors using a single neural network\n        architecture.\n        \n        The new predictors are saved in the Class1AffinityPredictor instance\n        and will be used on subsequent calls to `predict`.\n        \n        Parameters\n        ----------\n        n_models : int\n            Number of neural networks to fit\n            \n        architecture_hyperparameters : dict\n        \n        alleles : list of string\n            Allele names (not sequences) corresponding to each peptide\n        \n        peptides : `EncodableSequences` or list of string\n        \n        affinities : list of float\n            nM affinities\n\n        inequalities : list of string, each element one of \">\", \"<\", or \"=\"\n            See Class1NeuralNetwork.fit for details.\n        \n        models_dir_for_save : string, optional\n            If specified, the Class1AffinityPredictor is (incrementally) written\n            to the given models dir after each neural network is fit.\n        \n        verbose : int\n            Keras verbosity\n\n        progress_preamble : string\n            Optional string of information to include in each progress update\n\n        progress_print_interval : float\n            How often (in seconds) to print progress. Set to None to disable.\n\n        Returns\n        -------\n        list of `Class1NeuralNetwork`\n        \"\"\"\n\n        alleles = pandas.Series(alleles).map(mhcnames.normalize_allele_name)\n        allele_encoding = AlleleEncoding(\n            alleles,\n            allele_to_fixed_length_sequence=self.allele_to_fixed_length_sequence)\n\n        encodable_peptides = EncodableSequences.create(peptides)\n        models = []\n        for i in range(n_models):\n            logging.info(\"Training model %d / %d\" % (i + 1, n_models))\n            model = Class1NeuralNetwork(**architecture_hyperparameters)\n            model.fit(\n                encodable_peptides,\n                affinities,\n                inequalities=inequalities,\n                allele_encoding=allele_encoding,\n                verbose=verbose,\n                progress_preamble=progress_preamble,\n                progress_print_interval=progress_print_interval)\n\n            model_name = self.model_name(\"pan-class1\", i)\n            self.class1_pan_allele_models.append(model)\n            row = pandas.Series(collections.OrderedDict([\n                (\"model_name\", model_name),\n                (\"allele\", \"pan-class1\"),\n                (\"config_json\", json.dumps(model.get_config())),\n                (\"model\", model),\n            ])).to_frame().T\n            self._manifest_df = pandas.concat(\n                [self.manifest_df, row], ignore_index=True)\n            if models_dir_for_save:\n                self.save(\n                    models_dir_for_save, model_names_to_write=[model_name])\n            models.append(model)\n\n        self.clear_cache()\n        return models"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef percentile_ranks(self, affinities, allele=None, alleles=None, throw=True):\n        if allele is not None:\n            try:\n                transform = self.allele_to_percent_rank_transform[allele]\n                return transform.transform(affinities)\n            except KeyError:\n                msg = \"Allele %s has no percentile rank information\" % allele\n                if throw:\n                    raise ValueError(msg)\n                else:\n                    warnings.warn(msg)\n                    # Return NaNs\n                    return numpy.ones(len(affinities)) * numpy.nan\n\n        if alleles is None:\n            raise ValueError(\"Specify allele or alleles\")\n\n        df = pandas.DataFrame({\"affinity\": affinities})\n        df[\"allele\"] = alleles\n        df[\"result\"] = numpy.nan\n        for (allele, sub_df) in df.groupby(\"allele\"):\n            df.loc[sub_df.index, \"result\"] = self.percentile_ranks(\n                sub_df.affinity, allele=allele, throw=throw)\n        return df.result.values", "response": "Returns the percentile ranks for the given ic50 affinities and alleles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npredicting the nM binding affinities for a set of peptides.", "response": "def predict(\n            self,\n            peptides,\n            alleles=None,\n            allele=None,\n            throw=True,\n            centrality_measure=DEFAULT_CENTRALITY_MEASURE):\n        \"\"\"\n        Predict nM binding affinities.\n        \n        If multiple predictors are available for an allele, the predictions are\n        the geometric means of the individual model predictions.\n        \n        One of 'allele' or 'alleles' must be specified. If 'allele' is specified\n        all predictions will be for the given allele. If 'alleles' is specified\n        it must be the same length as 'peptides' and give the allele\n        corresponding to each peptide.\n        \n        Parameters\n        ----------\n        peptides : `EncodableSequences` or list of string\n        alleles : list of string\n        allele : string\n        throw : boolean\n            If True, a ValueError will be raised in the case of unsupported\n            alleles or peptide lengths. If False, a warning will be logged and\n            the predictions for the unsupported alleles or peptides will be NaN.\n        centrality_measure : string or callable\n            Measure of central tendency to use to combine predictions in the\n            ensemble. Options include: mean, median, robust_mean.\n\n        Returns\n        -------\n        numpy.array of predictions\n        \"\"\"\n        df = self.predict_to_dataframe(\n            peptides=peptides,\n            alleles=alleles,\n            allele=allele,\n            throw=throw,\n            include_percentile_ranks=False,\n            include_confidence_intervals=False,\n            centrality_measure=centrality_measure,\n        )\n        return df.prediction.values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict_to_dataframe(\n            self,\n            peptides,\n            alleles=None,\n            allele=None,\n            throw=True,\n            include_individual_model_predictions=False,\n            include_percentile_ranks=True,\n            include_confidence_intervals=True,\n            centrality_measure=DEFAULT_CENTRALITY_MEASURE):\n        \"\"\"\n        Predict nM binding affinities. Gives more detailed output than `predict`\n        method, including 5-95% prediction intervals.\n        \n        If multiple predictors are available for an allele, the predictions are\n        the geometric means of the individual model predictions.\n        \n        One of 'allele' or 'alleles' must be specified. If 'allele' is specified\n        all predictions will be for the given allele. If 'alleles' is specified\n        it must be the same length as 'peptides' and give the allele\n        corresponding to each peptide. \n        \n        Parameters\n        ----------\n        peptides : `EncodableSequences` or list of string\n        alleles : list of string\n        allele : string\n        throw : boolean\n            If True, a ValueError will be raised in the case of unsupported\n            alleles or peptide lengths. If False, a warning will be logged and\n            the predictions for the unsupported alleles or peptides will be NaN.\n        include_individual_model_predictions : boolean\n            If True, the predictions of each individual model are included as\n            columns in the result dataframe.\n        include_percentile_ranks : boolean, default True\n            If True, a \"prediction_percentile\" column will be included giving the\n            percentile ranks. If no percentile rank information is available,\n            this will be ignored with a warning.\n        centrality_measure : string or callable\n            Measure of central tendency to use to combine predictions in the\n            ensemble. Options include: mean, median, robust_mean.\n\n        Returns\n        -------\n        `pandas.DataFrame` of predictions\n        \"\"\"\n        if isinstance(peptides, string_types):\n            raise TypeError(\"peptides must be a list or array, not a string\")\n        if isinstance(alleles, string_types):\n            raise TypeError(\"alleles must be a list or array, not a string\")\n        if allele is None and alleles is None:\n            raise ValueError(\"Must specify 'allele' or 'alleles'.\")\n\n        peptides = EncodableSequences.create(peptides)\n        df = pandas.DataFrame({\n            'peptide': peptides.sequences\n        }, copy=False)\n\n        if allele is not None:\n            if alleles is not None:\n                raise ValueError(\"Specify exactly one of allele or alleles\")\n            df[\"allele\"] = allele\n            normalized_allele = mhcnames.normalize_allele_name(allele)\n            df[\"normalized_allele\"] = normalized_allele\n            unique_alleles = [normalized_allele]\n        else:\n            df[\"allele\"] = numpy.array(alleles)\n            df[\"normalized_allele\"] = df.allele.map(\n                mhcnames.normalize_allele_name)\n            unique_alleles = df.normalized_allele.unique()\n\n        if len(df) == 0:\n            # No predictions.\n            logging.warning(\"Predicting for 0 peptides.\")\n            empty_result = pandas.DataFrame(\n                columns=[\n                    'peptide',\n                    'allele',\n                    'prediction',\n                    'prediction_low',\n                    'prediction_high'\n                ])\n            return empty_result\n\n        (min_peptide_length, max_peptide_length) = (\n            self.supported_peptide_lengths)\n\n        if (peptides.min_length < min_peptide_length or\n                peptides.max_length > max_peptide_length):\n            # Only compute this if needed\n            all_peptide_lengths_supported = False\n            sequence_length = df.peptide.str.len()\n            df[\"supported_peptide_length\"] = (\n                (sequence_length >= min_peptide_length) &\n                (sequence_length <= max_peptide_length))\n            if (~df.supported_peptide_length).any():\n                msg = (\n                    \"%d peptides have lengths outside of supported range [%d, %d]: \"\n                    \"%s\" % (\n                        (~df.supported_peptide_length).sum(),\n                        min_peptide_length,\n                        max_peptide_length,\n                        str(df.ix[~df.supported_peptide_length].peptide.unique())))\n                logging.warning(msg)\n                if throw:\n                    raise ValueError(msg)\n        else:\n            # Handle common case efficiently.\n            df[\"supported_peptide_length\"] = True\n            all_peptide_lengths_supported = True\n\n        num_pan_models = len(self.class1_pan_allele_models)\n        max_single_allele_models = max(\n            len(self.allele_to_allele_specific_models.get(allele, []))\n            for allele in unique_alleles\n        )\n        predictions_array = numpy.zeros(\n            shape=(df.shape[0], num_pan_models + max_single_allele_models),\n            dtype=\"float64\")\n        predictions_array[:] = numpy.nan\n\n        if self.class1_pan_allele_models:\n            unsupported_alleles = [\n                allele for allele in\n                df.normalized_allele.unique()\n                if allele not in self.allele_to_fixed_length_sequence\n            ]\n            if unsupported_alleles:\n                msg = (\n                    \"No sequences for allele(s): %s.\\n\"\n                    \"Supported alleles: %s\" % (\n                        \" \".join(unsupported_alleles),\n                        \" \".join(sorted(self.allele_to_fixed_length_sequence))))\n                logging.warning(msg)\n                if throw:\n                    raise ValueError(msg)\n            mask = df.supported_peptide_length\n            if mask.sum() > 0:\n                masked_allele_encoding = AlleleEncoding(\n                    df.loc[mask].normalized_allele,\n                    allele_to_fixed_length_sequence=self.allele_to_fixed_length_sequence)\n                masked_peptides = peptides.sequences[mask]\n                for (i, model) in enumerate(self.class1_pan_allele_models):\n                    predictions_array[mask, i] = model.predict(\n                        masked_peptides,\n                        allele_encoding=masked_allele_encoding)\n\n        if self.allele_to_allele_specific_models:\n            unsupported_alleles = [\n                allele for allele in unique_alleles\n                if not self.allele_to_allele_specific_models.get(allele)\n            ]\n            if unsupported_alleles:\n                msg = (\n                    \"No single-allele models for allele(s): %s.\\n\"\n                    \"Supported alleles are: %s\" % (\n                        \" \".join(unsupported_alleles),\n                        \" \".join(sorted(self.allele_to_allele_specific_models))))\n                logging.warning(msg)\n                if throw:\n                    raise ValueError(msg)\n\n            for allele in unique_alleles:\n                models = self.allele_to_allele_specific_models.get(allele, [])\n                if len(unique_alleles) == 1 and all_peptide_lengths_supported:\n                    mask = None\n                else:\n                    mask = (\n                        (df.normalized_allele == allele) &\n                        df.supported_peptide_length).values\n                if mask is None or mask.all():\n                    # Common case optimization\n                    for (i, model) in enumerate(models):\n                        predictions_array[:, num_pan_models + i] = (\n                            model.predict(peptides))\n                elif mask.sum() > 0:\n                    peptides_for_allele = EncodableSequences.create(\n                        df.ix[mask].peptide.values)\n                    for (i, model) in enumerate(models):\n                        predictions_array[\n                            mask,\n                            num_pan_models + i,\n                        ] = model.predict(peptides_for_allele)\n\n        if callable(centrality_measure):\n            centrality_function = centrality_measure\n        else:\n            centrality_function = CENTRALITY_MEASURES[centrality_measure]\n\n        logs = numpy.log(predictions_array)\n        log_centers = centrality_function(logs)\n        df[\"prediction\"] = numpy.exp(log_centers)\n\n        if include_confidence_intervals:\n            df[\"prediction_low\"] = numpy.exp(numpy.nanpercentile(logs, 5.0, axis=1))\n            df[\"prediction_high\"] = numpy.exp(numpy.nanpercentile(logs, 95.0, axis=1))\n\n        if include_individual_model_predictions:\n            for i in range(num_pan_models):\n                df[\"model_pan_%d\" % i] = predictions_array[:, i]\n\n            for i in range(max_single_allele_models):\n                df[\"model_single_%d\" % i] = predictions_array[\n                    :, num_pan_models + i\n                ]\n\n        if include_percentile_ranks:\n            if self.allele_to_percent_rank_transform:\n                df[\"prediction_percentile\"] = self.percentile_ranks(\n                    df.prediction,\n                    alleles=df.normalized_allele.values,\n                    throw=throw)\n            else:\n                warnings.warn(\"No percentile rank information available.\")\n\n        del df[\"supported_peptide_length\"]\n        del df[\"normalized_allele\"]\n        return df", "response": "Predicts the nM binding affinities of a set of peptides and returns a pandas. DataFrame containing the predicted nM binding affinities."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_weights(weights_list, filename):\n        numpy.savez(\n            filename,\n            **dict(((\"array_%d\" % i), w) for (i, w) in enumerate(weights_list)))", "response": "Save the model weights to a file using numpy s. npz format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the model weights from the given filename which should have been created with save_weights.", "response": "def load_weights(filename):\n        \"\"\"\n        Restore model weights from the given filename, which should have been\n        created with `save_weights`.\n    \n        Parameters\n        ----------\n        filename : string\n            Should end in \".npz\".\n\n        Returns\n        ----------\n        list of array\n        \"\"\"\n        loaded = numpy.load(filename)\n        weights = [\n            loaded[\"array_%d\" % i]\n            for i in range(len(loaded.keys()))\n        ]\n        loaded.close()\n        return weights"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calibrate_percentile_ranks(\n            self,\n            peptides=None,\n            num_peptides_per_length=int(1e5),\n            alleles=None,\n            bins=None):\n        \"\"\"\n        Compute the cumulative distribution of ic50 values for a set of alleles\n        over a large universe of random peptides, to enable computing quantiles in\n        this distribution later.\n\n        Parameters\n        ----------\n        peptides : sequence of string or EncodableSequences, optional\n            Peptides to use\n        num_peptides_per_length : int, optional\n            If peptides argument is not specified, then num_peptides_per_length\n            peptides are randomly sampled from a uniform distribution for each\n            supported length\n        alleles : sequence of string, optional\n            Alleles to perform calibration for. If not specified all supported\n            alleles will be calibrated.\n        bins : object\n            Anything that can be passed to numpy.histogram's \"bins\" argument\n            can be used here, i.e. either an integer or a sequence giving bin\n            edges. This is in ic50 space.\n\n        Returns\n        ----------\n        EncodableSequences : peptides used for calibration\n        \"\"\"\n        if bins is None:\n            bins = to_ic50(numpy.linspace(1, 0, 1000))\n\n        if alleles is None:\n            alleles = self.supported_alleles\n\n        if peptides is None:\n            peptides = []\n            lengths = range(\n                self.supported_peptide_lengths[0],\n                self.supported_peptide_lengths[1] + 1)\n            for length in lengths:\n                peptides.extend(\n                    random_peptides(num_peptides_per_length, length))\n\n        encoded_peptides = EncodableSequences.create(peptides)\n\n        for (i, allele) in enumerate(alleles):\n            predictions = self.predict(encoded_peptides, allele=allele)\n            transform = PercentRankTransform()\n            transform.fit(predictions, bins=bins)\n            self.allele_to_percent_rank_transform[allele] = transform\n\n        return encoded_peptides", "response": "Calibration for a set of supported alleles and a set of peptides."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new Class1AffinityPredictor containing a subset of this Class1AffinityPredictor s neural networks.", "response": "def filter_networks(self, predicate):\n        \"\"\"\n        Return a new Class1AffinityPredictor containing a subset of this\n        predictor's neural networks.\n\n        Parameters\n        ----------\n        predicate : Class1NeuralNetwork -> boolean\n            Function specifying which neural networks to include\n\n        Returns\n        -------\n        Class1AffinityPredictor\n        \"\"\"\n        allele_to_allele_specific_models = {}\n        for (allele, models) in self.allele_to_allele_specific_models.items():\n            allele_to_allele_specific_models[allele] = [\n                m for m in models if predicate(m)\n            ]\n        class1_pan_allele_models = [\n            m for m in self.class1_pan_allele_models if predicate(m)\n        ]\n\n        return Class1AffinityPredictor(\n            allele_to_allele_specific_models=allele_to_allele_specific_models,\n            class1_pan_allele_models=class1_pan_allele_models,\n            allele_to_fixed_length_sequence=self.allele_to_fixed_length_sequence,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms model selection using a user - specified scoring function.", "response": "def model_select(\n            self,\n            score_function,\n            alleles=None,\n            min_models=1,\n            max_models=10000):\n        \"\"\"\n        Perform model selection using a user-specified scoring function.\n\n        Model selection is done using a \"step up\" variable selection procedure,\n        in which models are repeatedly added to an ensemble until the score\n        stops improving.\n\n        Parameters\n        ----------\n        score_function : Class1AffinityPredictor -> float function\n            Scoring function\n\n        alleles : list of string, optional\n            If not specified, model selection is performed for all alleles.\n\n        min_models : int, optional\n            Min models to select per allele\n\n        max_models : int, optional\n            Max models to select per allele\n\n        Returns\n        -------\n        Class1AffinityPredictor : predictor containing the selected models\n        \"\"\"\n\n        if alleles is None:\n            alleles = self.supported_alleles\n\n        dfs = []\n        allele_to_allele_specific_models = {}\n        for allele in alleles:\n            df = pandas.DataFrame({\n                'model': self.allele_to_allele_specific_models[allele]\n            })\n            df[\"model_num\"] = df.index\n            df[\"allele\"] = allele\n            df[\"selected\"] = False\n\n            round_num = 1\n\n            while not df.selected.all() and sum(df.selected) < max_models:\n                score_col = \"score_%2d\" % round_num\n                prev_score_col = \"score_%2d\" % (round_num - 1)\n\n                existing_selected = list(df[df.selected].model)\n                df[score_col] = [\n                    numpy.nan if row.selected else\n                    score_function(\n                        Class1AffinityPredictor(\n                            allele_to_allele_specific_models={\n                                allele: [row.model] + existing_selected\n                            }\n                        )\n                    )\n                    for (_, row) in df.iterrows()\n                ]\n\n                if round_num > min_models and (\n                        df[score_col].max() < df[prev_score_col].max()):\n                    break\n\n                # In case of a tie, pick a model at random.\n                (best_model_index,) = df.loc[\n                    (df[score_col] == df[score_col].max())\n                ].sample(1).index\n                df.loc[best_model_index, \"selected\"] = True\n                round_num += 1\n\n            dfs.append(df)\n            allele_to_allele_specific_models[allele] = list(\n                df.loc[df.selected].model)\n\n        df = pandas.concat(dfs, ignore_index=True)\n\n        new_predictor = Class1AffinityPredictor(\n            allele_to_allele_specific_models,\n            metadata_dataframes={\n                \"model_selection\": df,\n            })\n        return new_predictor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting the transform to the given values using the cumulative distribution function.", "response": "def fit(self, values, bins):\n        \"\"\"\n        Fit the transform using the given values (in our case ic50s).\n\n        Parameters\n        ----------\n        values : ic50 values\n        bins : bins for the cumulative distribution function\n            Anything that can be passed to numpy.histogram's \"bins\" argument\n            can be used here.\n        \"\"\"\n        assert self.cdf is None\n        assert self.bin_edges is None\n        assert len(values) > 0\n        (hist, self.bin_edges) = numpy.histogram(values, bins=bins)\n        self.cdf = numpy.ones(len(hist) + 3) * numpy.nan\n        self.cdf[0] = 0.0\n        self.cdf[1] = 0.0\n        self.cdf[-1] = 100.0\n        numpy.cumsum(hist * 100.0 / numpy.sum(hist), out=self.cdf[2:-1])\n        assert not numpy.isnan(self.cdf).any()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(self, values):\n        assert self.cdf is not None\n        assert self.bin_edges is not None\n        indices = numpy.searchsorted(self.bin_edges, values)\n        result = self.cdf[indices]\n        assert len(result) == len(values)\n        return numpy.minimum(result, 100.0)", "response": "Return percent ranks for the given values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize the fit to a pandas. Series.", "response": "def to_series(self):\n        \"\"\"\n        Serialize the fit to a pandas.Series.\n\n        The index on the series gives the bin edges and the valeus give the CDF.\n\n        Returns\n        -------\n        pandas.Series\n\n        \"\"\"\n        return pandas.Series(\n            self.cdf, index=[numpy.nan] + list(self.bin_edges) + [numpy.nan])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_series(series):\n        result = PercentRankTransform()\n        result.cdf = series.values\n        result.bin_edges = series.index.values[1:-1]\n        return result", "response": "Deseralize a PercentRankTransform the given pandas. Series as returned\n        by to_series ()."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_default_class1_models_dir(test_exists=True):\n    if _MHCFLURRY_DEFAULT_CLASS1_MODELS_DIR:\n        result = join(get_downloads_dir(), _MHCFLURRY_DEFAULT_CLASS1_MODELS_DIR)\n        if test_exists and not exists(result):\n            raise IOError(\"No such directory: %s\" % result)\n        return result\n    else:\n        return get_path(\"models_class1\", \"models\", test_exists=test_exists)", "response": "Returns the absolute path to the default class1 models dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict of all available downloads in the current release.", "response": "def get_current_release_downloads():\n    \"\"\"\n    Return a dict of all available downloads in the current release.\n\n    The dict keys are the names of the downloads. The values are a dict\n    with two entries:\n\n    downloaded : bool\n        Whether the download is currently available locally\n\n    metadata : dict\n        Info about the download from downloads.yml such as URL\n    \"\"\"\n    downloads = (\n        get_downloads_metadata()\n        ['releases']\n        [get_current_release()]\n        ['downloads'])\n    return OrderedDict(\n        (download[\"name\"], {\n            'downloaded': exists(join(get_downloads_dir(), download[\"name\"])),\n            'metadata': download,\n        }) for download in downloads\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_path(download_name, filename='', test_exists=True):\n    assert '/' not in download_name, \"Invalid download: %s\" % download_name\n    path = join(get_downloads_dir(), download_name, filename)\n    if test_exists and not exists(path):\n        raise RuntimeError(\n            \"Missing MHCflurry downloadable file: %s. \"\n            \"To download this data, run:\\n\\tmhcflurry-downloads fetch %s\\n\"\n            \"in a shell.\"\n            % (quote(path), download_name))\n    return path", "response": "Get the local path to a file in a MHCflurry download"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_worker_pool(\n        processes=None,\n        initializer=None,\n        initializer_kwargs_per_process=None,\n        max_tasks_per_worker=None):\n    \"\"\"\n    Convenience wrapper to create a multiprocessing.Pool.\n\n    This function adds support for per-worker initializer arguments, which are\n    not natively supported by the multiprocessing module. The motivation for\n    this feature is to support allocating each worker to a (different) GPU.\n\n    IMPLEMENTATION NOTE:\n        The per-worker initializer arguments are implemented using a Queue. Each\n        worker reads its arguments from this queue when it starts. When it\n        terminates, it adds its initializer arguments back to the queue, so a\n        future process can initialize itself using these arguments.\n\n        There is one issue with this approach, however. If a worker crashes, it\n        never repopulates the queue of initializer arguments. This will prevent\n        any future worker from re-using those arguments. To deal with this\n        issue we add a second 'backup queue'. This queue always contains the\n        full set of initializer arguments: whenever a worker reads from it, it\n        always pushes the pop'd args back to the end of the queue immediately.\n        If the primary arg queue is ever empty, then workers will read\n        from this backup queue.\n\n    Parameters\n    ----------\n    processes : int\n        Number of workers. Default: num CPUs.\n\n    initializer : function, optional\n        Init function to call in each worker\n\n    initializer_kwargs_per_process : list of dict, optional\n        Arguments to pass to initializer function for each worker. Length of\n        list must equal the number of workers.\n\n    max_tasks_per_worker : int, optional\n        Restart workers after this many tasks. Requires Python >=3.2.\n\n    Returns\n    -------\n    multiprocessing.Pool\n    \"\"\"\n\n    if not processes:\n        processes = cpu_count()\n\n    pool_kwargs = {\n        'processes': processes,\n    }\n    if max_tasks_per_worker:\n        pool_kwargs[\"maxtasksperchild\"] = max_tasks_per_worker\n\n    if initializer:\n        if initializer_kwargs_per_process:\n            assert len(initializer_kwargs_per_process) == processes\n            kwargs_queue = Queue()\n            kwargs_queue_backup = Queue()\n            for kwargs in initializer_kwargs_per_process:\n                kwargs_queue.put(kwargs)\n                kwargs_queue_backup.put(kwargs)\n            pool_kwargs[\"initializer\"] = worker_init_entry_point\n            pool_kwargs[\"initargs\"] = (\n                initializer, kwargs_queue, kwargs_queue_backup)\n        else:\n            pool_kwargs[\"initializer\"] = initializer\n\n    worker_pool = Pool(**pool_kwargs)\n    print(\"Started pool: %s\" % str(worker_pool))\n    pprint(pool_kwargs)\n    return worker_pool", "response": "This function creates a multiprocessing. Pool that processes and initializer functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_ic50(ic50, max_ic50=50000.0):\n    x = 1.0 - (numpy.log(ic50) / numpy.log(max_ic50))\n    return numpy.minimum(\n        1.0,\n        numpy.maximum(0.0, x))", "response": "Convert an ic50 to regression targets in the range [ 0 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_keras_backend(backend=None, gpu_device_nums=None, num_threads=None):\n    os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\n    original_backend = backend\n\n    if not backend:\n        backend = \"tensorflow-default\"\n\n    if gpu_device_nums is not None:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(\n            [str(i) for i in gpu_device_nums])\n\n    if backend == \"tensorflow-cpu\" or gpu_device_nums == []:\n        print(\"Forcing tensorflow/CPU backend.\")\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n        device_count = {'CPU': 1, 'GPU': 0}\n    elif backend == \"tensorflow-gpu\":\n        print(\"Forcing tensorflow/GPU backend.\")\n        device_count = {'CPU': 0, 'GPU': 1}\n    elif backend == \"tensorflow-default\":\n        print(\"Forcing tensorflow backend.\")\n        device_count = None\n    else:\n        raise ValueError(\"Unsupported backend: %s\" % backend)\n\n    import tensorflow\n    from keras import backend as K\n    if K.backend() == 'tensorflow':\n        config = tensorflow.ConfigProto(device_count=device_count)\n        config.gpu_options.allow_growth = True\n        if num_threads:\n            config.inter_op_parallelism_threads = num_threads\n            config.intra_op_parallelism_threads = num_threads\n        session = tensorflow.Session(config=config)\n        K.set_session(session)\n    else:\n        if original_backend or gpu_device_nums or num_threads:\n            warnings.warn(\n                \"Only tensorflow backend can be customized. Ignoring \"\n                \" customization. Backend: %s\" % K.backend())", "response": "Configure Keras backend to use GPU or CPU."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef amino_acid_distribution(peptides, smoothing=0.0):\n    peptides = pandas.Series(peptides)\n    aa_counts = pandas.Series(peptides.map(collections.Counter).sum())\n    normalized = aa_counts / aa_counts.sum()\n    if smoothing:\n        normalized += smoothing\n        normalized /= normalized.sum()\n    return normalized", "response": "Compute the fraction of each amino acid across a collection of peptides."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating random peptides (kmers). Parameters ---------- num : int Number of peptides to return length : int Length of each peptide distribution : pandas.Series Maps 1-letter amino acid abbreviations to probabilities. If not specified a uniform distribution is used. Returns ---------- list of string", "response": "def random_peptides(num, length=9, distribution=None):\n    \"\"\"\n    Generate random peptides (kmers).\n\n    Parameters\n    ----------\n    num : int\n        Number of peptides to return\n\n    length : int\n        Length of each peptide\n\n    distribution : pandas.Series\n        Maps 1-letter amino acid abbreviations to\n        probabilities. If not specified a uniform\n        distribution is used.\n\n    Returns\n    ----------\n    list of string\n\n    \"\"\"\n    if num == 0:\n        return []\n    if distribution is None:\n        distribution = pandas.Series(\n            1, index=sorted(amino_acid.COMMON_AMINO_ACIDS))\n        distribution /= distribution.sum()\n\n    return [\n        ''.join(peptide_sequence)\n        for peptide_sequence in\n        numpy.random.choice(\n            distribution.index,\n            p=distribution.values,\n            size=(int(num), int(length)))\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a subranch of a tree and deep - copy the children of this subbranch into a new LabeledTree", "response": "def uproot(tree):\n        \"\"\"\n        Take a subranch of a tree and deep-copy the children\n        of this subbranch into a new LabeledTree\n        \"\"\"\n        uprooted = tree.copy()\n        uprooted.parent = None\n        for child in tree.all_children():\n            uprooted.add_general_child(child)\n        return uprooted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        return LabeledTree(\n            udepth = self.udepth,\n            depth = self.depth,\n            text = self.text,\n            label = self.label,\n            children = self.children.copy() if self.children != None else [],\n            parent = self.parent)", "response": "Deep Copy of a LabeledTree"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_child(self, child):\n        self.children.append(child)\n        child.parent = self\n        self.udepth = max([child.udepth for child in self.children]) + 1", "response": "Adds a branch to the current tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lowercase(self):\n        if len(self.children) > 0:\n            for child in self.children:\n                child.lowercase()\n        else:\n            self.text = self.text.lower()", "response": "Lowercase all strings in this object and all children."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_dict(self, index=0):\n        index += 1\n        rep = {}\n        rep[\"index\"] = index\n        rep[\"leaf\"] = len(self.children) == 0\n        rep[\"depth\"] = self.udepth\n        rep[\"scoreDistr\"] = [0.0] * len(LabeledTree.SCORE_MAPPING)\n        # dirac distribution at correct label\n        if self.label is not None:\n            rep[\"scoreDistr\"][self.label] = 1.0\n            mapping = LabeledTree.SCORE_MAPPING[:]\n            rep[\"rating\"] = mapping[self.label] - min(mapping)\n        # if you are using this method for printing predictions\n        # from a model, the the dot product with the model's output\n        # distribution should be taken with this list:\n        rep[\"numChildren\"] = len(self.children)\n        text = self.text if self.text != None else \"\"\n        seen_tokens = 0\n        witnessed_pixels = 0\n        for i, child in enumerate(self.children):\n            if i > 0:\n                text += \" \"\n            child_key = \"child%d\" % (i)\n            (rep[child_key], index) = child.to_dict(index)\n            text += rep[child_key][\"text\"]\n            seen_tokens += rep[child_key][\"tokens\"]\n            witnessed_pixels += rep[child_key][\"pixels\"]\n\n        rep[\"text\"] = text\n        rep[\"tokens\"] = 1 if (self.text != None and len(self.text) > 0) else seen_tokens\n        rep[\"pixels\"] = witnessed_pixels + 3 if len(self.children) > 0 else text_size(self.text)\n        return (rep, index)", "response": "Convert a LabeledTree into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inject_visualization_javascript(tree_width=1200, tree_height=400, tree_node_radius=10):\n        from .javascript import insert_sentiment_markup\n        insert_sentiment_markup(tree_width=tree_width, tree_height=tree_height, tree_node_radius=tree_node_radius)", "response": "In an Ipython notebook injects the JavaScript code that is used by Jason Chuang s visualisations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a list of paths that are files or directories.", "response": "def delete_paths(paths):\n    \"\"\"\n    Delete a list of paths that are files or directories.\n    If a file/directory does not exist, skip it.\n\n    Arguments:\n    ----------\n\n    paths : list<str>, names of files/directories to remove.\n\n    \"\"\"\n    for path in paths:\n        if exists(path):\n            if isfile(path):\n                remove(path)\n            else:\n                rmtree(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads from url the zip file corresponding to the Stanford Sentiment Treebank and expand the resulting files into the directory path.", "response": "def download_sst(path, url):\n    \"\"\"\"\n    Download from `url` the zip file corresponding to the\n    Stanford Sentiment Treebank and expand the resulting\n    files into the directory `path` (Note: if the files are\n    already present, the download is not actually run).\n\n    Arguments\n    ---------\n        path : str, directory to save the train, test, and dev files.\n        url : str, location of zip file on the web\n\n    Returns:\n    --------\n\n        dict<str, str>: file path for the keys train, test, dev.\n\n    \"\"\"\n    local_files = {\n        \"train\": join(path, \"train.txt\"),\n        \"test\": join(path, \"test.txt\"),\n        \"dev\": join(path, \"dev.txt\")\n    }\n    makedirs(path, exist_ok=True)\n    if all(exists(fname) and stat(fname).st_size > 100 for fname in local_files.values()):\n        return local_files\n\n    zip_local = join(path, 'trainDevTestTrees_PTB.zip')\n    delete_paths([zip_local, join(path, \"trees\")] + list(local_files.values()))\n    utils.urlretrieve(url, zip_local)\n    ZipFile(zip_local).extractall(path)\n    for fname in local_files.values():\n        move(join(path, 'trees', fname.split('/')[-1]), fname)\n    delete_paths([zip_local, join(path, 'trainDevTestTrees_PTB', 'trees'), join(path, 'trainDevTestTrees_PTB')])\n    return local_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to recover the label inside a string of the form '(3 hello)' where 3 is the label, and hello is the string. Label is not assigned if the string does not follow the expected format. Arguments: ---------- node : LabeledTree, current node that should possibly receive a label. current_word : str, input string.", "response": "def attribute_text_label(node, current_word):\n    \"\"\"\n    Tries to recover the label inside a string\n    of the form '(3 hello)' where 3 is the label,\n    and hello is the string. Label is not assigned\n    if the string does not follow the expected\n    format.\n\n    Arguments:\n    ----------\n        node : LabeledTree, current node that should\n            possibly receive a label.\n        current_word : str, input string.\n    \"\"\"\n    node.text = normalize_string(current_word)\n    node.text = node.text.strip(\" \")\n    node.udepth = 1\n    if len(node.text) > 0 and node.text[0].isdigit():\n        split_sent = node.text.split(\" \", 1)\n        label = split_sent[0]\n        if len(split_sent) > 1:\n            text = split_sent[1]\n            node.text = text\n\n        if all(c.isdigit() for c in label):\n            node.label = int(label)\n        else:\n            text = label + \" \" + text\n            node.text = text\n\n    if len(node.text) == 0:\n        node.text = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tree_from_string(line):\n    depth         = 0\n    current_word  = \"\"\n    root          = None\n    current_node  = root\n\n    for char in line:\n        if char == '(':\n            if current_node is not None and len(current_word) > 0:\n                attribute_text_label(current_node, current_word)\n                current_word = \"\"\n            depth += 1\n            if depth > 1:\n                # replace current head node by this node:\n                child = LabeledTree(depth=depth)\n                current_node.add_child(child)\n                current_node = child\n                root.add_general_child(child)\n            else:\n                root = LabeledTree(depth=depth)\n                root.add_general_child(root)\n                current_node = root\n\n        elif char == ')':\n            # assign current word:\n            if len(current_word) > 0:\n                attribute_text_label(current_node, current_word)\n                current_word = \"\"\n\n            # go up a level:\n            depth -= 1\n            if current_node.parent != None:\n                current_node.parent.udepth = max(current_node.udepth+1, current_node.parent.udepth)\n            current_node = current_node.parent\n        else:\n            # add to current read word\n            current_word += char\n    if depth != 0:\n        raise ParseError(\"Not an equal amount of closing and opening parentheses\")\n\n    return root", "response": "Parse and convert a string representation\n            into a LabeledTree datastructure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport a text file of treebank trees.", "response": "def import_tree_corpus(path):\n    \"\"\"\n    Import a text file of treebank trees.\n\n    Arguments:\n    ----------\n        path : str, filename for tree corpus.\n\n    Returns:\n    --------\n        list<LabeledTree> : loaded examples.\n    \"\"\"\n    tree_list = LabeledTreeCorpus()\n    with codecs.open(path, \"r\", \"UTF-8\") as f:\n        for line in f:\n            tree_list.append(create_tree_from_string(line))\n    return tree_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading and read in the Stanford Sentiment Treebank dataset into a dictionary with a train dev and test keys.", "response": "def load_sst(path=None,\n             url='http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip'):\n    \"\"\"\n    Download and read in the Stanford Sentiment Treebank dataset\n    into a dictionary with a 'train', 'dev', and 'test' keys. The\n    dictionary keys point to lists of LabeledTrees.\n\n    Arguments:\n    ----------\n        path : str, (optional defaults to ~/stanford_sentiment_treebank),\n            directory where the corpus should be downloaded (and\n            imported from).\n        url : str, where the corpus should be downloaded from (defaults\n            to nlp.stanford.edu address).\n\n    Returns:\n    --------\n        dict : loaded dataset\n    \"\"\"\n    if path is None:\n        # find a good temporary path\n        path = os.path.expanduser(\"~/stanford_sentiment_treebank/\")\n        makedirs(path, exist_ok=True)\n    fnames = download_sst(path, url)\n    return {key: import_tree_corpus(value) for key, value in fnames.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a dictionary of string - > int label pairs.", "response": "def labels(self):\n        \"\"\"\n        Construct a dictionary of string -> labels\n\n        Returns:\n        --------\n            OrderedDict<str, int> : string label pairs.\n        \"\"\"\n        labelings = OrderedDict()\n        for tree in self:\n            for label, line in tree.to_labeled_lines():\n                labelings[line] = label\n        return labelings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_file(self, path, mode=\"w\"):\n        with open(path, mode=mode) as f:\n            for tree in self:\n                for label, line in tree.to_labeled_lines():\n                    f.write(line + \"\\n\")", "response": "Save the corpus to a text file in the original format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_tree_corpus(labels_path, parents_path, texts_path):\n    with codecs.open(labels_path, \"r\", \"UTF-8\") as f:\n        label_lines = f.readlines()\n    with codecs.open(parents_path, \"r\", \"UTF-8\") as f:\n        parent_lines = f.readlines()\n    with codecs.open(texts_path, \"r\", \"UTF-8\") as f:\n        word_lines = f.readlines()\n    assert len(label_lines) == len(parent_lines)\n    assert len(label_lines) == len(word_lines)\n\n    trees = []\n\n    for labels, parents, words in zip(label_lines, parent_lines, word_lines):\n        labels  = [int(l) + 2 for l in labels.strip().split(\" \")]\n        parents = [int(l) for l in parents.strip().split(\" \")]\n        words   = words.strip().split(\" \")\n        assert len(labels) == len(parents)\n        trees.append(read_tree(parents, labels, words))\n    return trees", "response": "Imports dataset from TreeLSTM data generation scrips."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_texts(node, words, next_idx=0):\n    if len(node.children) == 0:\n        node.text = words[next_idx]\n        return next_idx + 1\n    else:\n        for child in node.children:\n            next_idx = assign_texts(child, words, next_idx)\n        return next_idx", "response": "Assign the words to nodes by finding and assigning strings to the leaves of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_tree(parents, labels, words):\n    trees = {}\n    root = None\n    for i in range(1, len(parents) + 1):\n        if not i in trees and parents[i - 1] != - 1:\n            idx = i\n            prev = None\n            while True:\n                parent = parents[idx - 1]\n                if parent == -1:\n                    break\n                tree = LabeledTree()\n                if prev is not None:\n                    tree.add_child(prev)\n                trees[idx] = tree\n                tree.label = labels[idx - 1]\n                if trees.get(parent) is not None:\n                    trees[parent].add_child(tree)\n                    break\n                elif parent == 0:\n                    root = tree\n                    break\n                else:\n                    prev = tree\n                    idx = parent\n    assert assign_texts(root, words) == len(words)\n    return root", "response": "Take as input a list of integers for parents\n    and labels along with a list of words and reconstruct a LabeledTree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding behaviour of DiffusionModel. set_initial_status generates random real values.", "response": "def set_initial_status(self, configuration=None):\n        \"\"\"\n        Override behaviour of methods in class DiffusionModel.\n        Overwrites initial status using random real values.\n        Generates random node profiles.\n        \"\"\"\n        super(CognitiveOpDynModel, self).set_initial_status(configuration)\n\n        # set node status\n        for node in self.status:\n            self.status[node] = np.random.random_sample()\n        self.initial_status = self.status.copy()\n\n        # set new node parameters\n        self.params['nodes']['cognitive'] = {}\n\n        # first correct the input model parameters and retreive T_range, B_range and R_distribution\n        T_range = (self.params['model']['T_range_min'], self.params['model']['T_range_max'])\n        if self.params['model']['T_range_min'] > self.params['model']['T_range_max']:\n            T_range = (self.params['model']['T_range_max'], self.params['model']['T_range_min'])\n\n        B_range = (self.params['model']['B_range_min'], self.params['model']['B_range_max'])\n        if self.params['model']['B_range_min'] > self.params['model']['B_range_max']:\n            B_range = (self.params['model']['B_range_max'], self.params['model']['B_range_min'])\n        s = float(self.params['model']['R_fraction_negative'] + self.params['model']['R_fraction_neutral'] +\n                  self.params['model']['R_fraction_positive'])\n        R_distribution = (self.params['model']['R_fraction_negative']/s, self.params['model']['R_fraction_neutral']/s,\n                          self.params['model']['R_fraction_positive']/s)\n\n        # then sample parameters from the ranges and distribution\n        for node in self.graph.nodes():\n            R_prob = np.random.random_sample()\n            if R_prob < R_distribution[0]:\n                R = -1\n            elif R_prob < (R_distribution[0] + R_distribution[1]):\n                R = 0\n            else:\n                R = 1\n            # R, B and T parameters in a tuple\n            self.params['nodes']['cognitive'][node] = (R,\n                                                       B_range[0] + (B_range[1] - B_range[0])*np.random.random_sample(),\n                                                       T_range[0] + (T_range[1] - T_range[0])*np.random.random_sample())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a single model iteration", "response": "def iteration(self, node_status=True):\n        \"\"\"\n        Execute a single model iteration\n\n        :return: Iteration_id, Incremental node status (dictionary node->status)\n        \"\"\"\n        # One iteration changes the opinion of all agents using the following procedure:\n        # - first all agents communicate with institutional information I using a deffuant like rule\n        # - then random pairs of agents are selected to interact  (N pairs)\n        # - interaction depends on state of agents but also internal cognitive structure\n\n        self.clean_initial_status(None)\n\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(self.status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": self.status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        # first interact with I\n        I = self.params['model']['I']\n        for node in self.graph.nodes():\n            T = self.params['nodes']['cognitive'][node][2]\n            R = self.params['nodes']['cognitive'][node][0]\n            actual_status[node] = actual_status[node] + T * (I - actual_status[node])\n            if R == 1:\n                actual_status[node] = 0.5 * (1 + actual_status[node])\n            if R == -1:\n                actual_status[node] *= 0.5\n\n        # then interact with peers\n        for i in range(0, self.graph.number_of_nodes()):\n            # select a random node\n            n1 = list(self.graph.nodes)[np.random.randint(0, self.graph.number_of_nodes())]\n\n            # select all of the nodes neighbours (no digraph possible)\n            neighbours = list(self.graph.neighbors(n1))\n            if len(neighbours) == 0:\n                continue\n\n            # select second node - a random neighbour\n            n2 = neighbours[np.random.randint(0, len(neighbours))]\n\n            # update status of n1 and n2\n            p1 = pow(actual_status[n1], 1.0 / self.params['nodes']['cognitive'][n1][1])\n            p2 = pow(actual_status[n2], 1.0 / self.params['nodes']['cognitive'][n2][1])\n\n            oldn1 = self.status[n1]\n            if np.random.random_sample() < p2:  # if node 2 talks, node 1 gets changed\n                T1 = self.params['nodes']['cognitive'][n1][2]\n                R1 = self.params['nodes']['cognitive'][n1][0]\n                actual_status[n1] += (1 - T1) * (actual_status[n2] - actual_status[n1])\n                if R1 == 1:\n                    actual_status[n1] = 0.5 * (1 + actual_status[n1])\n                if R1 == -1:\n                    actual_status[n1] *= 0.5\n            if np.random.random_sample() < p1:  # if node 1 talks, node 2 gets changed\n                T2 = self.params['nodes']['cognitive'][n2][2]\n                R2 = self.params['nodes']['cognitive'][n2][0]\n                actual_status[n2] += (1 - T2) * (oldn1 - actual_status[n2])\n                if R2 == 1:\n                    actual_status[n2] = 0.5 * (1 + actual_status[n2])\n                if R2 == -1:\n                    actual_status[n2] *= 0.5\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iteration(self, node_status=True):\n        self.clean_initial_status(self.available_statuses.values())\n\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            self.params['model']['queue'] = dict()\n            return 0, actual_status\n\n        gamma = float(self.params['model']['mu']) * float(self.actual_iteration) / float(self.params['model']['tau'])\n        list_node = self.graph.nodes()\n        start = min(list_node)\n        stop = max(list_node)\n        number_node_susceptible = len(self.graph.nodes()) - sum(self.status.values())\n\n        while gamma >= 1 and number_node_susceptible >= 1:\n            random_index = random.randrange(start, stop+1, 1)\n            if random_index in list_node and actual_status[random_index] == 0:\n                actual_status[random_index] = 1\n                gamma -= 1\n                number_node_susceptible -= 1\n\n        for u in self.graph.nodes():\n            if actual_status[u] == 1:\n                continue\n\n            neighbors = list(self.graph.neighbors(u))\n            if isinstance(self.graph, nx.DiGraph):\n                neighbors = list(self.graph.predecessors(u))\n\n            infected = 0\n            for v in neighbors:\n                infected += self.status[v]\n\n            if len(neighbors) > 0:\n                infected_ratio = float(infected)/len(neighbors)\n                if infected_ratio >= self.params['nodes']['threshold'][u]:\n                    if u not in self.inqueue:\n                        self.queue.put((self.actual_iteration, u))\n                        self.inqueue[u] = None\n\n        while not self.queue.empty():\n            next = self.queue.queue[0]\n            if self.actual_iteration - next[0] >= self.params['model']['tau']:\n                self.queue.get()\n            else:\n                break\n\n        delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        return self.actual_iteration - 1, delta", "response": "Execute a single iteration of the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_node_configuration(self, param_name, node_id, param_value):\n        if param_name not in self.config['nodes']:\n            self.config['nodes'][param_name] = {node_id: param_value}\n        else:\n            self.config['nodes'][param_name][node_id] = param_value", "response": "Add a parameter to a given node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_node_set_configuration(self, param_name, node_to_value):\n        for nid, val in future.utils.iteritems(node_to_value):\n            self.add_node_configuration(param_name, nid, val)", "response": "Add a parameter to the node set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a parameter for a given edge to the configuration dictionary.", "response": "def add_edge_configuration(self, param_name, edge, param_value):\n        \"\"\"\n        Set a parameter for a given edge\n\n        :param param_name: parameter identifier (as specified by the chosen model)\n        :param edge: edge identifier\n        :param param_value: parameter value\n        \"\"\"\n        if param_name not in self.config['edges']:\n            self.config['edges'][param_name] = {edge: param_value}\n        else:\n            self.config['edges'][param_name][edge] = param_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the edge set configuration to the current parameter.", "response": "def add_edge_set_configuration(self, param_name, edge_to_value):\n        \"\"\"\n        Set Edges parameter\n\n        :param param_name: parameter identifier (as specified by the chosen model)\n        :param edge_to_value: dictionary mapping each edge a parameter value\n        \"\"\"\n        for edge, val in future.utils.iteritems(edge_to_value):\n            self.add_edge_configuration(param_name, edge, val)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iteration(self, node_status=True):\n        # One iteration changes the opinion of several voters using the following procedure:\n        # - select randomly one voter (speaker 1)\n        # - select randomly one of its neighbours (speaker 2)\n        # - if the two voters agree, their neighbours take their opinion\n\n        self.clean_initial_status(self.available_statuses.values())\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(self.status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": self.status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        delta = {}\n        status_delta = {st: 0 for st in self.available_statuses.values()}\n\n        # select a random node\n        speaker1 = list(self.graph.nodes())[np.random.randint(0, self.graph.number_of_nodes())]\n\n        # select a random neighbour\n        neighbours = list(self.graph.neighbors(speaker1))\n        if isinstance(self.graph, nx.DiGraph):\n            # add also the predecessors\n            neighbours += list(self.graph.predecessors(speaker1))\n\n        speaker2 = neighbours[np.random.randint(0, len(neighbours))]\n\n        if self.status[speaker1] == self.status[speaker2]:\n            # select listeners (all neighbours of two speakers)\n            neighbours = list(self.graph.neighbors(speaker1)) + list(self.graph.neighbors(speaker2))\n\n            if isinstance(self.graph, nx.DiGraph):\n                # assumed if a->b then b can be influenced by a\n                # but not the other way around - the link between the speakers doesn't matter\n                neighbours = list(self.graph.successors(speaker1)) + list(self.graph.successors(speaker2))\n\n            # update status of listeners\n            for listener in neighbours:\n                if self.status[speaker1] != self.status[listener]:\n                    delta[listener] = self.status[speaker1]\n                    status_delta[self.status[listener]] += 1\n                    for x in self.available_statuses.values():\n                        if x != self.status[listener]:\n                            status_delta[x] -= 1\n\n                self.status[listener] = self.status[speaker1]\n\n        node_count = {st: len([n for n in self.status if self.status[n] == st])\n                      for st in self.available_statuses.values()}\n\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single model iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __execute(model, iteration_number):\n    iterations = model.iteration_bunch(iteration_number, False)\n    trends = model.build_trends(iterations)[0]\n    del iterations\n    del model\n    return trends", "response": "Execute a simulation model\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iteration(self, node_status=True):\n        self.clean_initial_status(self.available_statuses.values())\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": actual_status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        for u in self.graph.nodes():\n            u_status = self.status[u]\n            for i in range(0, self.compartment_progressive):\n\n                if u_status == self.available_statuses[self.compartment[i][0]]:\n                    rule = self.compartment[i][2]\n                    test = rule.execute(node=u, graph=self.graph, status=self.status,\n                                        status_map=self.available_statuses, params=self.params)\n                    if test:\n                        actual_status[u] = self.available_statuses[self.compartment[i][1]]\n                        break\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single model iteration and return the iteration_id and status"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a bokeh figure image containing the grid of the data in the ncols columns.", "response": "def plot(self, ncols=2):\n        \"\"\"\n        :param ncols: Number of grid columns\n        :return: a bokeh figure image\n        \"\"\"\n        grid = gridplot(self.plots, ncols=ncols)\n        return grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iteration(self, node_status=True):\n\n        # One iteration changes the opinion of at most q voters using the following procedure:\n        # - select randomly q voters\n        # - compute majority opinion\n        # - if tie all agents take opinion +1\n        # - if not tie, all agents take majority opinion\n\n        self.clean_initial_status(self.available_statuses.values())\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(self.status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": self.status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        # select q random nodes\n        discussion_group = [list(self.graph.nodes())[i]\n                            for i in np.random.randint(0, self.graph.number_of_nodes(), self.params['model']['q'])]\n\n        # compute majority\n        majority_vote = 1\n        vote_sum = sum([self.status[node] for node in discussion_group])\n        if vote_sum < (self.params[\"model\"][\"q\"] / 2.0):\n            majority_vote = 0  # in case of tie, majority_vote remains 1\n\n        # update status of nodes in discussion group\n        delta = {}\n        status_delta = {st: 0 for st in self.available_statuses.values()}\n\n        for listener in discussion_group:\n            if majority_vote != self.status[listener]:\n                delta[listener] = majority_vote\n\n                status_delta[self.status[listener]] += 1\n                for x in self.available_statuses.values():\n                    if x != self.status[listener]:\n                        status_delta[x] -= 1\n\n            self.status[listener] = majority_vote\n\n        # fix\n        node_count = {st: len([n for n in self.status if self.status[n] == st])\n                      for st in self.available_statuses.values()}\n\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single model iteration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a single model iteration and return the iteration_id and status", "response": "def iteration(self, node_status=True):\n        \"\"\"\n        Execute a single model iteration\n\n        :return: Iteration_id, Incremental node status (dictionary node->status)\n        \"\"\"\n        self.clean_initial_status(self.available_statuses.values())\n\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        # streaming\n        if self.stream_execution:\n            u, v = list(self.graph.edges())[0]\n            u_status = self.status[u]\n            v_status = self.status[v]\n\n            if u_status == 1 and v_status == 0:\n                p = np.random.random_sample()\n                if p < self.params['model']['beta']:\n                    actual_status[v] = 1\n\n            if v_status == 1 and u_status == 0:\n                p = np.random.random_sample()\n                if p < self.params['model']['beta']:\n                    actual_status[u] = 1\n\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            self.status = actual_status\n            self.actual_iteration += 1\n\n            if node_status:\n                return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        # snapshot\n        else:\n\n            if self.actual_iteration == 0:\n                self.actual_iteration += 1\n                delta, node_count, status_delta = self.status_delta(actual_status)\n                if node_status:\n                    return {\"iteration\": 0, \"status\": actual_status.copy(),\n                            \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n                else:\n                    return {\"iteration\": 0, \"status\": {},\n                            \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n            for u in self.graph.nodes():\n                u_status = self.status[u]\n                eventp = np.random.random_sample()\n                neighbors = self.graph.neighbors(u)\n                if isinstance(self.graph, nx.DiGraph):\n                    neighbors = self.graph.predecessors(u)\n\n                if u_status == 0:\n                    infected_neighbors = len([v for v in neighbors if self.status[v] == 1])\n                    if eventp < self.params['model']['beta'] * infected_neighbors:\n                        actual_status[u] = 1\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iteration(self, node_status=True):\n        self.clean_initial_status(self.available_statuses.values())\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": actual_status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        for u in self.graph.nodes():\n            if self.status[u] != 1:\n                continue\n\n            neighbors = list(self.graph.neighbors(u))  # neighbors and successors (in DiGraph) produce the same result\n\n            # Standard threshold\n            if len(neighbors) > 0:\n                threshold = 1.0/len(neighbors)\n\n                for v in neighbors:\n                    if actual_status[v] == 0:\n                        key = (u, v)\n\n                        # Individual specified thresholds\n                        if 'threshold' in self.params['edges']:\n                            if key in self.params['edges']['threshold']:\n                                threshold = self.params['edges']['threshold'][key]\n                            elif (v, u) in self.params['edges']['threshold'] and not nx.is_directed(self.graph):\n                                threshold = self.params['edges']['threshold'][(v, u)]\n\n                        flip = np.random.random_sample()\n                        if flip <= threshold:\n                            actual_status[v] = 1\n\n            actual_status[u] = 2\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single model iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a single model iteration", "response": "def iteration(self, node_status=True):\n        \"\"\"\n        Execute a single model iteration\n\n        :return: Iteration_id, Incremental node status (dictionary node->status)\n        \"\"\"\n        self.clean_initial_status(self.available_statuses.values())\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n\n            if min(actual_status.values()) == 0:\n                number_node_blocked = int(float(self.graph.number_of_nodes()) *\n                                          float(self.params['model']['percentage_blocked']))\n\n                i = 0\n                while i < number_node_blocked:\n                    # select a random node\n                    node = list(self.graph.nodes())[np.random.randint(0, self.graph.number_of_nodes())]\n\n                    # node not infected\n                    if actual_status[node] == 0:\n\n                        # node blocked\n                        actual_status[node] = -1\n                        self.status[node] = -1\n                        i += 1\n\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": actual_status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        for node in self.graph.nodes():\n            if self.status[node] == 0:\n                if self.params['model']['adopter_rate'] > 0:\n                    xk = (0, 1)\n                    pk = (1-self.params['model']['adopter_rate'], self.params['model']['adopter_rate'])\n                    probability = stats.rv_discrete(name='probability', values=(xk, pk))\n                    number_probability = probability.rvs()\n\n                    if number_probability == 1:\n                        actual_status[node] = 1\n                        continue\n\n                neighbors = list(self.graph.neighbors(node))\n                if len(neighbors) == 0:\n                    continue\n\n                if isinstance(self.graph, nx.DiGraph):\n                    neighbors = self.graph.predecessors(node)\n\n                infected = 0\n                for v in neighbors:\n                    if self.status[v] != -1:\n                        infected += self.status[v]\n\n                infected_ratio = float(infected)/len(neighbors)\n                if infected_ratio >= self.params['nodes']['threshold'][node]:\n                    actual_status[node] = 1\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iteration(self, node_status=True):\n        self.clean_initial_status(self.available_statuses.values())\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        # streaming\n        if self.stream_execution:\n            raise ValueError(\"Streaming network not allowed.\")\n        # snapshot\n        else:\n            if self.actual_iteration == 0:\n                self.actual_iteration += 1\n                delta, node_count, status_delta = self.status_delta(actual_status)\n                if node_status:\n                    return {\"iteration\": 0, \"status\": actual_status.copy(),\n                            \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n                else:\n                    return {\"iteration\": 0, \"status\": {},\n                            \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n            for u in self.graph.nodes():\n                if actual_status[u] != 0:\n                    continue\n\n                if self.params['model']['adopter_rate'] > 0:\n                    xk = (0, 1)\n                    pk = (1 - self.params['model']['adopter_rate'], self.params['model']['adopter_rate'])\n                    probability = stats.rv_discrete(name='probability', values=(xk, pk))\n                    number_probability = probability.rvs()\n\n                    if number_probability == 1:\n                        actual_status[u] = 1\n                        continue\n\n                neighbors = list(self.graph.neighbors(u))\n                if isinstance(self.graph, nx.DiGraph):\n                    neighbors = list(self.graph.predecessors(u))\n\n                infected = 0\n                for v in neighbors:\n                    infected += self.status[v]\n\n                if infected > 0 and actual_status[u] == 0:\n\n                    infected_ratio = float(infected) / len(neighbors)\n                    if infected_ratio >= self.params['nodes']['threshold'][u]:\n                        eventp = np.random.random_sample()\n                        if eventp >= self.params['nodes']['profile'][u]:\n                            actual_status[u] = 1\n                        else:\n                            if self.params['model']['blocked'] != 0:\n                                blip = np.random.random_sample()\n                                if blip > self.params['model']['blocked']:\n                                    actual_status[u] = -1\n\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            self.status = actual_status\n            self.actual_iteration += 1\n\n            if node_status:\n                return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single iteration of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_initial_status(self, configuration=None):\n        super(AlgorithmicBiasModel, self).set_initial_status(configuration)\n\n        # set node status\n        for node in self.status:\n            self.status[node] = np.random.random_sample()\n        self.initial_status = self.status.copy()", "response": "Override behaviour of DiffusionModel. set_initial_status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iteration(self, node_status=True):\n        # One iteration changes the opinion of N agent pairs using the following procedure:\n        # - first one agent is selected\n        # - then a second agent is selected based on a probability that decreases with the distance to the first agent\n        # - if the two agents have a distance smaller than epsilon, then they change their status to the average of\n        # their previous statuses\n\n        self.clean_initial_status(None)\n\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(self.status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": self.status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        # interact with peers\n        for i in range(0, self.graph.number_of_nodes()):\n            # select a random node\n            n1 = list(self.graph.nodes())[np.random.randint(0, self.graph.number_of_nodes())]\n            # select all of the node's neighbours (no digraph possible)\n            neighbours = list(self.graph.neighbors(n1))\n            if len(neighbours) == 0:\n                continue\n        \n            # compute probabilities to select a second node among the neighbours\n            selection_prob = np.array([self.prob(np.abs(actual_status[neighbours[i]]-actual_status[n1]),\n                                               self.params['model']['gamma'],0.00001) for i in range(len(neighbours))])\n            selection_prob = selection_prob/np.sum(selection_prob)\n            cumulative_selection_probability = np.cumsum(selection_prob)\n\n            # select second nodebased on selection probabilities above\n            r = np.random.random_sample()\n            n2 = 0\n            while cumulative_selection_probability[n2] < r:\n                n2 = n2+1\n\n            n2 = neighbours[n2]\n            # update status of n1 and n2\n            diff = np.abs(actual_status[n1]-actual_status[n2])\n            if diff < self.params['model']['epsilon']:\n                avg = (actual_status[n1]+actual_status[n2])/2.0\n                actual_status[n1] = avg\n                actual_status[n2] = avg\n            \n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}", "response": "Execute a single model iteration"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a single model iteration.", "response": "def iteration(self, node_status=True):\n        \"\"\"\n        Execute a single model iteration\n\n        :return: Iteration_id, Incremental node status (dictionary node->status)\n        \"\"\"\n        self.clean_initial_status(self.available_statuses.values())\n\n        actual_status = {node: nstatus for node, nstatus in future.utils.iteritems(self.status)}\n\n        if self.actual_iteration == 0:\n            self.actual_iteration += 1\n            delta, node_count, status_delta = self.status_delta(actual_status)\n            if node_status:\n                return {\"iteration\": 0, \"status\": actual_status.copy(),\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n            else:\n                return {\"iteration\": 0, \"status\": {},\n                        \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n\n        for u in self.graph.nodes():\n            if actual_status[u] == 1:\n                continue\n\n            neighbors = list(self.graph.neighbors(u))\n            if isinstance(self.graph, nx.DiGraph):\n                neighbors = list(self.graph.predecessors(u))\n\n            infected = 0\n            for v in neighbors:\n                infected += self.status[v]\n\n            if len(neighbors) > 0:\n                infected_ratio = float(infected)/len(neighbors)\n                if infected_ratio >= self.params['nodes']['threshold'][u]:\n                    actual_status[u] = 1\n\n        delta, node_count, status_delta = self.status_delta(actual_status)\n        self.status = actual_status\n        self.actual_iteration += 1\n\n        if node_status:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": delta.copy(),\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}\n        else:\n            return {\"iteration\": self.actual_iteration - 1, \"status\": {},\n                    \"node_count\": node_count.copy(), \"status_delta\": status_delta.copy()}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the player s name and real name.", "response": "def names(self):\n\t\t\"\"\"\n\t\tReturns the player's name and real name.\n\t\tReturns two empty strings if the player is unknown.\n\t\tAI real name is always an empty string.\n\t\t\"\"\"\n\t\tif self.name == self.UNKNOWN_HUMAN_PLAYER:\n\t\t\treturn \"\", \"\"\n\n\t\tif not self.is_ai and \" \" in self.name:\n\t\t\treturn \"\", self.name\n\n\t\treturn self.name, \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an item from the string", "response": "def _getitem(string, depth=0):\n    \"\"\"\n    Get an item from the string (where item is up to the next ',' or '}' or the\n    end of the string)\n    \"\"\"\n    out = [\"\"]\n    while string:\n        char = string[0]\n        if depth and (char == ',' or char == '}'):\n            return out, string\n        if char == '{':\n            groups_string = _getgroup(string[1:], depth+1)\n            if groups_string is not None:\n                groups, string = groups_string\n                out = [a + g for a in out for g in groups]\n                continue\n        if char == '\\\\' and len(string) > 1:\n            string, char = string[1:], char + string[1]\n\n        out, string = [a + char for a in out], string[1:]\n\n    return out, string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getgroup(string, depth):\n    out, comma = [], False\n    while string:\n        items, string = _getitem(string, depth)\n\n        if not string:\n            break\n        out += items\n\n        if string[0] == '}':\n            if comma:\n                return out, string[1:]\n            return ['{' + a + '}' for a in out], string[1:]\n\n        if string[0] == ',':\n            comma, string = True, string[1:]\n\n    return None", "response": "Get a group from the string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of columns that do not contain the noexpand prefix.", "response": "def filter_noexpand_columns(columns):\n    \"\"\"Return columns not containing and containing the noexpand prefix.\n\n    Parameters\n    ----------\n    columns: sequence of str\n      A sequence of strings to be split\n\n    Returns\n    -------\n      Two lists, the first containing strings without the noexpand prefix, the\n      second containing those that do with the prefix filtered out.\n    \"\"\"\n    prefix_len = len(NOEXPAND_PREFIX)\n    noexpand = [c[prefix_len:] for c in columns if c.startswith(NOEXPAND_PREFIX)]\n    other = [c for c in columns if not c.startswith(NOEXPAND_PREFIX)]\n    return other, noexpand"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_root(paths, key=None, columns=None, ignore=None, chunksize=None, where=None, flatten=False, *args, **kwargs):\n\n    if not isinstance(paths, list):\n        paths = [paths]\n    # Use a single file to search for trees and branches, ensuring the key exists\n    for seed_path in paths:\n        trees = list_trees(seed_path)\n        if key and key not in trees:\n            continue\n        break\n    else:\n        if key:\n            raise OSError('{} not found in any of the given paths'.format(key))\n        else:\n            raise OSError('No trees found in any of the given paths')\n\n    if not key:\n        if len(trees) == 1:\n            key = trees[0]\n        elif len(trees) == 0:\n            raise ValueError('No trees found in {}'.format(seed_path))\n        else:\n            raise ValueError('More than one tree found in {}'.format(seed_path))\n\n    branches = list_branches(seed_path, key)\n\n    if not columns:\n        all_vars = branches\n    else:\n        if isinstance(columns, string_types):\n            columns = [columns]\n        # __index__* is always loaded if it exists\n        # XXX Figure out what should happen with multi-dimensional indices\n        index_branches = list(filter(lambda x: x.startswith('__index__'), branches))\n        if index_branches:\n            columns = columns[:]\n            columns.append(index_branches[0])\n        columns, noexpand = filter_noexpand_columns(columns)\n        columns = list(itertools.chain.from_iterable(list(map(expand_braces, columns))))\n        all_vars = get_matching_variables(branches, columns) + noexpand\n\n    if ignore:\n        if isinstance(ignore, string_types):\n            ignore = [ignore]\n        ignored = get_matching_variables(branches, ignore, fail=False)\n        ignored = list(itertools.chain.from_iterable(list(map(expand_braces, ignored))))\n        if any(map(lambda x: x.startswith('__index__'), ignored)):\n            raise ValueError('__index__* branch is being ignored!')\n        for var in ignored:\n            all_vars.remove(var)\n\n    if chunksize:\n        tchain = ROOT.TChain(key)\n        for path in paths:\n            tchain.Add(path)\n        n_entries = tchain.GetEntries()\n        n_chunks = int(ceil(float(n_entries) / chunksize))\n        # XXX could explicitly clean up the opened TFiles with TChain::Reset\n\n        class genchunk(object):\n            def __len__(self):\n                return n_chunks\n\n            def __iter__(self):\n                current_index = 0\n                for chunk in range(n_chunks):\n                    arr = root2array(paths, key, all_vars, start=chunk * chunksize, stop=(chunk+1) * chunksize, selection=where, *args, **kwargs)\n                    if len(arr) == 0:\n                        continue\n                    if flatten:\n                        arr = do_flatten(arr, flatten)\n                    yield convert_to_dataframe(arr, start_index=current_index)\n                    current_index += len(arr)\n\n        return genchunk()\n\n    arr = root2array(paths, key, all_vars, selection=where, *args, **kwargs)\n    if flatten:\n        arr = do_flatten(arr, flatten)\n    return convert_to_dataframe(arr)", "response": "Read a ROOT file or list of ROOT files into a pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_root(df, path, key='my_ttree', mode='w', store_index=True, *args, **kwargs):\n\n    if mode == 'a':\n        mode = 'update'\n    elif mode == 'w':\n        mode = 'recreate'\n    else:\n        raise ValueError('Unknown mode: {}. Must be \"a\" or \"w\".'.format(mode))\n\n    from root_numpy import array2tree\n    # We don't want to modify the user's DataFrame here, so we make a shallow copy\n    df_ = df.copy(deep=False)\n\n    if store_index:\n        name = df_.index.name\n        if name is None:\n            # Handle the case where the index has no name\n            name = ''\n        df_['__index__' + name] = df_.index\n\n    # Convert categorical columns into something root_numpy can serialise\n    for col in df_.select_dtypes(['category']).columns:\n        name_components = ['__rpCaT', col, str(df_[col].cat.ordered)]\n        name_components.extend(df_[col].cat.categories)\n        if ['*' not in c for c in name_components]:\n            sep = '*'\n        else:\n            raise ValueError('Unable to find suitable separator for columns')\n        df_[col] = df_[col].cat.codes\n        df_.rename(index=str, columns={col: sep.join(name_components)}, inplace=True)\n\n    arr = df_.to_records(index=False)\n\n    root_file = ROOT.TFile.Open(path, mode)\n    if not root_file:\n        raise IOError(\"cannot open file {0}\".format(path))\n    if not root_file.IsWritable():\n        raise IOError(\"file {0} is not writable\".format(path))\n\n    # Navigate to the requested directory\n    open_dirs = [root_file]\n    for dir_name in key.split('/')[:-1]:\n        current_dir = open_dirs[-1].Get(dir_name)\n        if not current_dir:\n            current_dir = open_dirs[-1].mkdir(dir_name)\n        current_dir.cd()\n        open_dirs.append(current_dir)\n\n    # The key is now just the top component\n    key = key.split('/')[-1]\n\n    # If a tree with that name exists, we want to update it\n    tree = open_dirs[-1].Get(key)\n    if not tree:\n        tree = None\n    tree = array2tree(arr, name=key, tree=tree)\n    tree.Write(key, ROOT.TFile.kOverwrite)\n    root_file.Close()", "response": "Write a DataFrame to a ROOT file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the model for security details for a symbol.", "response": "def run(self, symbol: str) -> SecurityDetailsViewModel:\n        \"\"\" Loads the model for security details \"\"\"\n        from pydatum import Datum\n\n        svc = self._svc\n        sec_agg = svc.securities.get_aggregate_for_symbol(symbol)\n\n        model = SecurityDetailsViewModel()\n\n        model.symbol = sec_agg.security.namespace + \":\" + sec_agg.security.mnemonic\n        model.security = sec_agg.security\n\n        # Quantity\n        model.quantity = sec_agg.get_quantity()\n        model.value = sec_agg.get_value()\n        currency = sec_agg.get_currency()\n        if currency:\n            assert isinstance(currency, str)\n            model.currency = currency\n        model.price = sec_agg.get_last_available_price()\n\n        model.average_price = sec_agg.get_avg_price()\n        # Here we take only the amount paid for the remaining stock.\n        model.total_paid = sec_agg.get_total_paid_for_remaining_stock()\n\n        # Profit/loss\n        model.profit_loss = model.value - model.total_paid\n        if model.total_paid:\n            model.profit_loss_perc = abs(model.profit_loss) * 100 / model.total_paid\n        else:\n            model.profit_loss_perc = 0\n        if abs(model.value) < abs(model.total_paid):\n            model.profit_loss_perc *= -1\n\n        # Income\n        model.income = sec_agg.get_income_total()\n        if model.total_paid:\n            model.income_perc = model.income * 100 / model.total_paid\n        else:\n            model.income_perc = 0\n        # income in the last 12 months\n        start = Datum()\n        start.subtract_months(12)\n        end = Datum()\n        model.income_last_12m = sec_agg.get_income_in_period(start, end)\n        if model.total_paid == 0:\n            model.income_perc_last_12m = 0\n        else:\n            model.income_perc_last_12m = model.income_last_12m * 100 / model.total_paid\n\n        # Return of Capital\n        roc = sec_agg.get_return_of_capital()\n        model.return_of_capital = roc\n\n        # total return\n        model.total_return = model.profit_loss + model.income\n        if model.total_paid:\n            model.total_return_perc = model.total_return * 100 / model.total_paid\n        else:\n            model.total_return_perc = 0\n\n        # load all holding accounts\n        model.accounts = sec_agg.accounts\n        # Income accounts\n        model.income_accounts = sec_agg.get_income_accounts()\n\n        # Load asset classes to which this security belongs.\n        # todo load asset allocation, find the parents for this symbol\n        # svc.asset_allocation.load_config_only(svc.currencies.default_currency)\n        # stocks = svc.asset_allocation.get_stock(model.symbol)\n        #\n        # for stock in stocks:\n        #     model.asset_classes.append(stock.asset_class)\n        from asset_allocation import AppAggregate\n        aa = AppAggregate()\n        aa.open_session()\n        aa.get_asset_classes_for_security(None, model.symbol)\n\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the next occurrence date for the scheduled transaction.", "response": "def get_next_occurrence(tx: ScheduledTransaction) -> date:\n    \"\"\" Calculates the next occurrence date for scheduled transaction.\n    Mimics the recurrenceNextInstance() function from GnuCash.\n    Still not fully complete but handles the main cases I use. \"\"\"\n    # Reference documentation:\n    # https://github.com/MisterY/gnucash-portfolio/issues/3\n\n    # Preparing ref day is an important part before the calculation.\n    # It should be:\n    #   a) the last occurrence date + 1, or\n    #   b) the recurrence start date - 1.\n    # because the refDate is the date from which the due dates are being calculated. To include\n    # the ones starting today, we need to calculate from the day before.\n    ref_datum: Datum = Datum()\n    if tx.last_occur:\n        #ref_datum.set_value(tx.last_occur)\n        ref_datum.from_date(tx.last_occur)\n        ref_datum.add_days(1)\n    else:\n        ref_datum.from_date(tx.recurrence.recurrence_period_start)\n        ref_datum.subtract_days(1)\n    ref_date: datetime = ref_datum.value\n\n    # today = datetimeutils.today_date()\n    #today = Datum().today()\n    # skipped schedule\n    #if ref_date > today: \n    #    ref_date = today\n\n    ###########################################################\n    # The code below mimics the function\n    # recurrenceNextInstance(const Recurrence *r, const GDate *refDate, GDate *nextDate)\n    # https://github.com/Gnucash/gnucash/blob/115c0bf4a4afcae4269fe4b9d1e4a73ec7762ec6/libgnucash/engine/Recurrence.c#L172\n\n    start_date: Datum = Datum()\n    #start_date: datetime = tx.recurrence.recurrence_period_start\n    start_date.from_date(tx.recurrence.recurrence_period_start)\n    if ref_date < start_date.value:\n        # If the occurrence hasn't even started, the next date is the start date.\n        # this should also handle the \"once\" type in most cases.\n        return start_date.value.date()\n\n    # start at refDate.\n    next_date: Datum = Datum()\n    # next_date: datetime = ref_date\n    next_date.from_datetime(ref_date)\n\n    # last_date: datetime = tx.last_occur\n    # print(tx.name, base_date, tx.recurrence.recurrence_period_start,\n    #       tx.recurrence.recurrence_mult, tx.recurrence.recurrence_period_type)\n\n    # /* Step 1: move FORWARD one period, passing exactly one occurrence. */\n\n    mult: int = tx.recurrence.recurrence_mult\n    period: str = tx.recurrence.recurrence_period_type\n    wadj = tx.recurrence.recurrence_weekend_adjust\n\n    # Not all periods from the original file are included at the moment.\n    if period in ([RecurrencePeriod.YEAR.value, RecurrencePeriod.MONTH.value,\n                   RecurrencePeriod.END_OF_MONTH.value]):\n        if period == RecurrencePeriod.YEAR.value:\n            mult *= 12\n\n        # handle weekend adjustment here.\n        ## Takes care of short months.\n        # next_weekday = datetimeutils.get_day_name(next_date)\n        next_weekday = next_date.get_day_name()\n        if wadj == WeekendAdjustment.BACK.value and (\n                period in ([RecurrencePeriod.YEAR.value, RecurrencePeriod.MONTH.value,\n                            RecurrencePeriod.END_OF_MONTH.value]) and\n                (next_weekday == \"Saturday\" or next_weekday == \"Sunday\")):\n            # \"Allows the following Friday-based calculations to proceed if 'next'\n            #  is between Friday and the target day.\"\n            days_to_subtract = 1 if next_weekday == \"Saturday\" else 2\n\n            # next_date = datetimeutils.subtract_days(next_date, days_to_subtract)\n            next_date.subtract_days(days_to_subtract)\n\n        if wadj == WeekendAdjustment.BACK.value and (\n                period in ([RecurrencePeriod.YEAR.value, RecurrencePeriod.MONTH.value,\n                            RecurrencePeriod.END_OF_MONTH.value]) and next_weekday == \"Friday\"):\n            next_date = handle_friday(next_date, period, mult, start_date)\n\n        # Line 274.\n        temp_date = next_date.clone()\n        if (temp_date.is_end_of_month() or\n                (period in [RecurrencePeriod.MONTH.value, RecurrencePeriod.YEAR.value]\n                 and (next_date.get_day() >= start_date.get_day()))\n           ):\n            # next_date = datetimeutils.add_months(next_date, mult)\n            next_date.add_months(mult)\n            # Set at end of month again (?!)\n            #next_date = datetimeutils.get_end_of_month(next_date)\n        else:\n            # one fewer month fwd because of the occurrence in this month.\n            next_date.add_months(mult - 1)\n\n    # elif period == \"once\":\n    #     next_date = tx.recurrence.recurrence_period_start\n\n    elif period == RecurrencePeriod.DAY.value:\n        logging.warning(\"daily not handled\")\n\n    else:\n        logging.info(f\"recurrence not handled: {period}\")\n\n    #######################\n    # Step 2\n    # \"Back up to align to the base phase. To ensure forward\n    # progress, we never subtract as much as we added (x % mult < mult)\"\n\n    if period in ([RecurrencePeriod.YEAR.value, RecurrencePeriod.MONTH.value,\n                   RecurrencePeriod.END_OF_MONTH.value]):\n        n_months = (\n            12 * (next_date.get_year() - start_date.get_year()) +\n            (next_date.get_month() - start_date.get_month())\n        )\n        next_date.subtract_months(n_months % mult)\n\n        # dim\n        days_in_month = datetimeutils.get_days_in_month(\n            next_date.get_year(), next_date.get_month())\n\n        # Handle adjustment for 3 ways.\n        if (period == RecurrencePeriod.END_OF_MONTH.value or\n                next_date.get_day() >= days_in_month):\n            # Set to last day of the month.\n            next_date.set_day(days_in_month)\n        else:\n            # Same day as the start.\n            next_date.set_day(start_date.get_day())\n\n        # Adjust for dates on the weekend.\n        if (period == RecurrencePeriod.YEAR.value or period == RecurrencePeriod.MONTH.value or\n                period == RecurrencePeriod.END_OF_MONTH.value):\n            weekday = next_date.get_day_name()\n            if weekday == \"Saturday\" or weekday == \"Sunday\":\n                if wadj == WeekendAdjustment.BACK.value:\n                    next_date.subtract_days(1 if weekday == \"Saturday\" else 2)\n                elif wadj == WeekendAdjustment.FORWARD.value:\n                    next_date.add_days(2 if weekday == \"Saturday\" else 1)\n\n    return next_date.value.date()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the calculation for when the next_day is Friday.", "response": "def handle_friday(next_date: Datum, period: str, mult: int, start_date: Datum):\n    \"\"\" Extracted the calculation for when the next_day is Friday \"\"\"\n    assert isinstance(next_date, Datum)\n    assert isinstance(start_date, Datum)\n\n    # Starting from line 220.\n    tmp_sat = next_date.clone()\n    tmp_sat.add_days(1)\n\n    tmp_sun = next_date.clone()\n    tmp_sun.add_days(2)\n\n    if period == RecurrencePeriod.END_OF_MONTH.value:\n        if (next_date.is_end_of_month() or tmp_sat.is_end_of_month() or\n                tmp_sun.is_end_of_month()):\n            next_date.add_months(1)\n        else:\n            next_date.add_months(mult - 1)\n    else:\n        if tmp_sat.get_day_name() == start_date.get_day_name():\n            next_date.add_days(1)\n            next_date.add_months(mult)\n        elif tmp_sun.get_day_name() == start_date.get_day_name():\n            next_date.add_days(2)\n            next_date.add_months(mult)\n        elif next_date.get_day() >= start_date.get_day():\n            next_date.add_months(mult)\n        elif next_date.is_end_of_month():\n            next_date.add_months(mult)\n        elif tmp_sat.is_end_of_month():\n            next_date.add_days(1)\n            next_date.add_months(mult)\n        elif tmp_sun.is_end_of_month():\n            next_date.add_days(2)\n            next_date.add_months(mult)\n        else:\n            # /* one fewer month fwd because of the occurrence in this month */\n            next_date.subtract_months(1)\n\n    return next_date"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_next_occurrence(self) -> date:\n        result = get_next_occurrence(self.transaction)\n        assert isinstance(result, date)\n        return result", "response": "Returns the next occurrence date for transaction"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_upcoming(self, count: int) -> List[ScheduledTransaction]:\n        # load all enabled scheduled transactions\n        all_tx = self.query.filter(ScheduledTransaction.enabled == 1).all()\n\n        # calculate next occurrence date\n        for tx in all_tx:\n            next_date = get_next_occurrence(tx)\n            tx[\"next_date\"] = next_date\n\n        # order by next occurrence date\n        all_tx.sort(key=lambda tx: tx[\"next_date\"].value)\n        # get upcoming (top) 10\n        top_n = all_tx[:count]\n        return top_n", "response": "Returns the top count upcoming scheduled transactions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_enabled(self) -> List[ScheduledTransaction]:\n        query = (\n            self.query\n            .filter(ScheduledTransaction.enabled == True)\n        )\n        return query.all()", "response": "Returns only enabled scheduled transactions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch a scheduled transaction by id", "response": "def get_by_id(self, tx_id: str) -> ScheduledTransaction:\n        \"\"\" Fetches a tx by id \"\"\"\n        return self.query.filter(ScheduledTransaction.guid == tx_id).first()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an aggregate for a single entity", "response": "def get_aggregate_by_id(self, tx_id: str) -> ScheduledTxAggregate:\n        \"\"\" Creates an aggregate for single entity \"\"\"\n        tran = self.get_by_id(tx_id)\n        return self.get_aggregate_for(tran)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_avg_price_stat(self) -> Decimal:\n        avg_price = Decimal(0)\n\n        price_total = Decimal(0)\n        price_count = 0\n\n        for account in self.security.accounts:\n            # Ignore trading accounts.\n            if account.type == AccountType.TRADING.name:\n                continue\n\n            for split in account.splits:\n                # Don't count the non-transactions.\n                if split.quantity == 0:\n                    continue\n\n                price = split.value / split.quantity\n                price_count += 1\n                price_total += price\n\n        if price_count:\n            avg_price = price_total / price_count\n        return avg_price", "response": "Calculates the statistical average price for the security and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_avg_price_fifo(self) -> Decimal:\n        balance = self.get_quantity()\n        if not balance:\n            return Decimal(0)\n\n        paid = Decimal(0)\n        accounts = self.get_holding_accounts()\n        # get unused splits (quantity and total paid) per account.\n        for account in accounts:\n            splits = self.get_available_splits_for_account(account)\n\n            for split in splits:\n                paid += split.value\n\n        avg_price = paid / balance\n        return avg_price", "response": "Calculates the average price paid for the security."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all unused splits in the account. Used for the calculation of avg. price.", "response": "def get_available_splits_for_account(self, account: Account) -> List[Split]:\n        \"\"\" Returns all unused splits in the account. Used for the calculation of avg.price.\n        The split that has been partially used will have its quantity reduced to available\n        quantity only. \"\"\"\n        available_splits = []\n        # get all purchase splits in the account\n        query = (\n            self.get_splits_query()\n            .filter(Split.account == account)\n        )\n        buy_splits = (\n            query.filter(Split.quantity > 0)\n            .join(Transaction)\n            .order_by(desc(Transaction.post_date))\n        ).all()\n        buy_q = sum(split.quantity for split in buy_splits)\n        sell_splits = query.filter(Split.quantity < 0).all()\n        sell_q = sum(split.quantity for split in sell_splits)\n        balance = buy_q + sell_q\n        if balance == 0:\n            return available_splits\n\n        for real_split in buy_splits:\n            split = splitmapper.map_split(real_split, SplitModel())\n\n            if split.quantity < balance:\n                # take this split and reduce the balance.\n                balance -= split.quantity\n            else:\n                # This is the last split.\n                price = split.value / split.quantity\n                # Take only the remaining quantity.\n                split.quantity -= balance\n                # Also adjust the value for easier calculation elsewhere.\n                split.value = balance * price\n                # The remaining balance is now distributed into splits.\n                balance = 0\n            # add to the collection.\n            available_splits.append(split)\n            if balance == 0:\n                break\n\n        return available_splits"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_num_shares(self) -> Decimal:\n        from pydatum import Datum\n        today = Datum().today()\n        return self.get_num_shares_on(today)", "response": "Returns the number of shares at this time"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of shares for security on the given date.", "response": "def get_num_shares_on(self, on_date: datetime) -> Decimal:\n        \"\"\" Returns the number of shares for security on (and including) the given date. \"\"\"\n        total_quantity = Decimal(0)\n\n        accounts = self.get_holding_accounts()\n        for account in accounts:\n            acct_svc = AccountAggregate(self.book, account)\n            quantity = acct_svc.get_balance_on(on_date)\n\n            total_quantity += quantity\n\n        return total_quantity"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_last_available_price(self) -> PriceModel:\n        price_db = PriceDbApplication()\n        symbol = SecuritySymbol(self.security.namespace, self.security.mnemonic)\n        result = price_db.get_latest_price(symbol)\n        return result", "response": "Returns the last available price for security. Uses PriceDbApplication to find the last available price for security."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_holding_accounts(self) -> List[Account]:\n        if not self.__holding_accounts:\n            self.__holding_accounts = self.__get_holding_accounts_query().all()\n\n        return self.__holding_accounts", "response": "Returns the list of holding accounts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all holding accounts except Trading accounts.", "response": "def __get_holding_accounts_query(self):\n        \"\"\" Returns all holding accounts, except Trading accounts. \"\"\"\n        query = (\n            self.book.session.query(Account)\n            .filter(Account.commodity == self.security)\n            .filter(Account.type != AccountType.trading.value)\n        )\n        # generic.print_sql(query)\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_income_accounts(self) -> List[Account]:\n        # trading = self.book.trading_account(self.security)\n        # log(DEBUG, \"trading account = %s, %s\", trading.fullname, trading.guid)\n\n        # Example on how to self-link, i.e. parent account, using alias.\n        # parent_alias = aliased(Account)\n            # .join(parent_alias, Account.parent)\n        # parent_alias.parent_guid != trading.guid\n\n        query = (\n            self.book.session.query(Account)\n            .join(Commodity)\n            .filter(Account.name == self.security.mnemonic)\n            .filter(Commodity.namespace == \"CURRENCY\")\n            # .filter(Account.type != \"TRADING\")\n            .filter(Account.type == AccountType.income.value)\n        )\n        # generic.print_sql(query)\n        return query.all()", "response": "Returns all income accounts for this security."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_income_total(self) -> Decimal:\n        accounts = self.get_income_accounts()\n        # log(DEBUG, \"income accounts: %s\", accounts)\n        income = Decimal(0)\n        for acct in accounts:\n            income += acct.get_balance()\n        return income", "response": "Get the total income of all income accounts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_income_in_period(self, start: datetime, end: datetime) -> Decimal:\n        accounts = self.get_income_accounts()\n        income = Decimal(0)\n        for acct in accounts:\n            acc_agg = AccountAggregate(self.book, acct)\n            acc_bal = acc_agg.get_balance_in_period(start, end)\n            income += acc_bal\n\n        return income", "response": "Returns all income in the given period"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_prices(self) -> List[PriceModel]:\n        # return self.security.prices.order_by(Price.date)\n        from pricedb.dal import Price\n\n        pricedb = PriceDbApplication()\n        repo = pricedb.get_price_repository()\n        query = (repo.query(Price)\n            .filter(Price.namespace == self.security.namespace)\n            .filter(Price.symbol == self.security.mnemonic)\n            .orderby_desc(Price.date)\n        )\n        return query.all()", "response": "Returns all available prices for security"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_quantity(self) -> Decimal:\n        from pydatum import Datum\n        # Use today's date but reset hour and lower.\n        today = Datum()\n        today.today()\n        today.end_of_day()\n        return self.get_num_shares_on(today.value)", "response": "Returns the number of shares for the given security."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the query for all splits for this security", "response": "def get_splits_query(self):\n        \"\"\" Returns the query for all splits for this security \"\"\"\n        query = (\n            self.book.session.query(Split)\n            .join(Account)\n            .filter(Account.type != AccountType.trading.value)\n            .filter(Account.commodity_guid == self.security.guid)\n        )\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_total_paid_for_remaining_stock(self) -> Decimal:\n        paid = Decimal(0)\n\n        accounts = self.get_holding_accounts()\n        for acc in accounts:\n            splits = self.get_available_splits_for_account(acc)\n            paid += sum(split.value for split in splits)\n        return paid", "response": "Returns the amount paid only for the remaining stock"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_value(self) -> Decimal:\n        quantity = self.get_quantity()\n        price = self.get_last_available_price()\n        if not price:\n            # raise ValueError(\"no price found for\", self.full_symbol)\n            return Decimal(0)\n\n        value = quantity * price.value\n        return value", "response": "Returns the current value of the stock"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the value of security holdings in base currency", "response": "def get_value_in_base_currency(self) -> Decimal:\n        \"\"\" Calculates the value of security holdings in base currency \"\"\"\n        # check if the currency is the base currency.\n        amt_orig = self.get_value()\n        # Security currency\n        sec_cur = self.get_currency()\n        #base_cur = self.book.default_currency\n        cur_svc = CurrenciesAggregate(self.book)\n        base_cur = cur_svc.get_default_currency()\n\n        if sec_cur == base_cur:\n            return amt_orig\n\n        # otherwise recalculate\n        single_svc = cur_svc.get_currency_aggregate(sec_cur)\n        rate = single_svc.get_latest_rate(base_cur)\n\n        result = amt_orig * rate.value\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_return_of_capital(self) -> Decimal:\n        txs: List[Split] = self.get_splits_query().all()\n        roc_tx: List[Split] = []\n        sum = Decimal(0)\n\n        for tx in txs:\n            if tx.quantity == Decimal(0) and tx.value != Decimal(0):\n                # This is a return of capital transaction\n                roc_tx.append(tx)\n                sum += tx.value\n            #logging.debug(tx.quantity) \n\n        # roc_tx is a list of transactions, should they be useful.\n        return sum", "response": "Gets and adds all Return - of - Capital amounts."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the asset accounts in which the security is held", "response": "def accounts(self) -> List[Account]:\n        \"\"\" Returns the asset accounts in which the security is held \"\"\"\n        # use only Assets sub-accounts\n        result = (\n            [acct for acct in self.security.accounts if acct.fullname.startswith('Assets')]\n        )\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, search_term: str) -> List[Commodity]:\n        query = (\n            self.query\n            .filter(Commodity.mnemonic.like('%' + search_term + '%') |\n                    Commodity.fullname.like('%' + search_term + '%'))\n        )\n        return query.all()", "response": "Searches for security by part of the name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload all commodities assuming they are stocks.", "response": "def get_all(self) -> List[Commodity]:\n        \"\"\" Loads all non-currency commodities, assuming they are stocks. \"\"\"\n        query = (\n            self.query\n            .order_by(Commodity.namespace, Commodity.mnemonic)\n        )\n        return query.all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the commodity with the given symbol.", "response": "def get_by_symbol(self, symbol: str) -> Commodity:\n        \"\"\"\n        Returns the commodity with the given symbol.\n        If more are found, an exception will be thrown.\n        \"\"\"\n        # handle namespace. Accept GnuCash and Yahoo-style symbols.\n        full_symbol = self.__parse_gc_symbol(symbol)\n\n        query = (\n            self.query\n            .filter(Commodity.mnemonic == full_symbol[\"mnemonic\"])\n        )\n        if full_symbol[\"namespace\"]:\n            query = query.filter(Commodity.namespace == full_symbol[\"namespace\"])\n\n        return query.first()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the stock object for the given symbol", "response": "def get_stock(self, symbol: str) -> Commodity:\n        \"\"\"Returns the stock/commodity object for the given symbol\"\"\"\n\n        # Check if we have the exchange name (namespace).\n        if \":\" in symbol:\n            # We have a namespace\n            symbol_parts = symbol.split(\":\")\n            exchange = symbol_parts[0]\n            symbol = symbol_parts[1]\n            security = self.book.get(Commodity, namespace=exchange, mnemonic=symbol)\n        else:\n            #with database.Database().open_book() as book:\n            security = self.book.get(Commodity, mnemonic=symbol)\n\n        return security"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_stocks(self, symbols: List[str]) -> List[Commodity]:\n        query = (\n            self.query\n            .filter(Commodity.mnemonic.in_(symbols))\n        ).order_by(Commodity.namespace, Commodity.mnemonic)\n        return query.all()", "response": "loads stocks by symbol"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_aggregate(self, security: Commodity) -> SecurityAggregate:\n        assert security is not None\n        assert isinstance(security, Commodity)\n\n        return SecurityAggregate(self.book, security)", "response": "Returns the aggregate for the given security"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_aggregate_for_symbol(self, symbol: str) -> SecurityAggregate:\n        security = self.get_by_symbol(symbol)\n        if not security:\n            raise ValueError(f\"Security not found in GC book: {symbol}!\")\n        return self.get_aggregate(security)", "response": "Returns the aggregate for the security found by the symbol."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the base query which filters out data for all queries.", "response": "def query(self):\n        \"\"\" Returns the base query which filters out data for all queries. \"\"\"\n        query = (\n            self.book.session.query(Commodity)\n            .filter(Commodity.namespace != \"CURRENCY\",\n                    Commodity.namespace != \"template\")\n        )\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __parse_gc_symbol(self, gc_symbol: str):\n        result = {\n            \"namespace\": None,\n            \"mnemonic\": None\n        }\n\n        parts = gc_symbol.split(':')\n        if len(parts) > 1:\n            result[\"namespace\"] = parts[0]\n            result[\"mnemonic\"] = parts[1]\n        else:\n            result[\"mnemonic\"] = gc_symbol\n\n        return result", "response": "Parse GnuCash - style symbol namespace : mnemonic"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef book(self) -> Book:\n        if not self.__book:\n            # Create/open the book.\n            book_uri = self.settings.database_path\n            self.__book = Database(book_uri).open_book(\n                for_writing=self.__for_writing)\n\n        return self.__book", "response": "Opens the book or creates a database based on settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current settings object.", "response": "def settings(self):\n        \"\"\" Settings \"\"\"\n        if not self.__settings:\n            self.__settings: Settings = Settings()\n\n        return self.__settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accounts(self) -> AccountsAggregate:\n        if not self.__accounts_aggregate:\n            self.__accounts_aggregate = AccountsAggregate(self.book)\n        return self.__accounts_aggregate", "response": "Returns the Accounts aggregate"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef currencies(self) -> CurrenciesAggregate:\n        if not self.__currencies_aggregate:\n            self.__currencies_aggregate = CurrenciesAggregate(self.book)\n        return self.__currencies_aggregate", "response": "Returns the Currencies aggregate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prices(self):\n        if not self.__prices_aggregate:\n            self.__prices_aggregate = PricesAggregate(self.book)\n        return self.__prices_aggregate", "response": "Returns the prices aggregate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scheduled(self) -> ScheduledTxsAggregate:\n        if not self.__scheduled_tx_aggregate:\n            self.__scheduled_tx_aggregate = ScheduledTxsAggregate(self.book)\n        return self.__scheduled_tx_aggregate", "response": "Returns the scheduled transaction aggregate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the SplitsAggregate object for this object", "response": "def splits(self):\n        ''' Splits '''\n        if not self.__splits_aggregate:\n            self.__splits_aggregate = SplitsAggregate(self.book)\n        return self.__splits_aggregate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transactions(self) -> TransactionsAggregate:\n        if not self.__transactions_aggregate:\n            self.__transactions_aggregate = TransactionsAggregate(self.book)\n        return self.__transactions_aggregate", "response": "Returns the Transactions aggregate for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_currency_symbols(self) -> List[str]:\n        result = []\n        currencies = self.currencies.get_book_currencies()\n        for cur in currencies:\n            result.append(cur.mnemonic)\n        return result", "response": "Returns the used currencies symbols as an array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the jinja2 HTML template from the given file.", "response": "def load_jinja_template(file_name):\n    \"\"\"\n    Loads the jinja2 HTML template from the given file.\n    Assumes that the file is in the same directory as the script.\n    \"\"\"\n    original_script_path = sys.argv[0]\n    #script_path = os.path.dirname(os.path.realpath(__file__))\n    script_dir = os.path.dirname(original_script_path)\n    # file_path = os.path.join(script_path, file_name)\n    # with open(file_path, 'r') as template_file:\n    #     return template_file.read()\n    from jinja2 import Environment, FileSystemLoader\n\n    env = Environment(loader=FileSystemLoader(script_dir))\n    template = env.get_template(file_name)\n\n    return template"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_days_in_month(year: int, month: int) -> int:\n    month_range = calendar.monthrange(year, month)\n    return month_range[1]", "response": "Returns the number of days in the given month."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a datetime from GnuCash 2. 6 date string", "response": "def get_from_gnucash26_date(date_str: str) -> date:\n    \"\"\" Creates a datetime from GnuCash 2.6 date string \"\"\"\n    date_format = \"%Y%m%d\"\n    result = datetime.strptime(date_str, date_format).date()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_period(period: str):\n    period = period.split(\" - \")\n\n    date_from = Datum()\n    if len(period[0]) == 10:\n        date_from.from_iso_date_string(period[0])\n    else:\n        date_from.from_iso_long_date(period[0])\n    date_from.start_of_day()\n\n    date_to = Datum()\n    if len(period[1]) == 10:\n        date_to.from_iso_date_string(period[1])\n    else:\n        date_to.from_iso_long_date(period[1])\n    date_to.end_of_day()\n\n    return date_from.value, date_to.value", "response": "Parses period from date range picker."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the period string from the given dates", "response": "def get_period(date_from: date, date_to: date) -> str:\n    \"\"\" Returns the period string from the given dates \"\"\"\n    assert isinstance(date_from, date)\n    assert isinstance(date_to, date)\n\n    str_from: str = date_from.isoformat()\n    str_to: str = date_to.isoformat()\n\n    return str_from + \" - \" + str_to"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_period_last_week() -> str:\n    today = Datum()\n    today.start_of_day()\n    # start_date = today - timedelta(days=7)\n    start_date = today.clone()\n    start_date.subtract_days(7)\n\n    period = get_period(start_date.value, today.value)\n    return period", "response": "Returns the last week as a period string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the last 30 days as a period string", "response": "def get_period_last_30_days() -> str:\n    \"\"\" Returns the last week as a period string \"\"\"\n    today = Datum()\n    today.today()\n    # start_date = today - timedelta(days=30)\n    start_date = today.clone()\n    start_date.subtract_days(30)\n\n    period = get_period(start_date.value, today.value)\n    return period"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_period_last_3_months() -> str:\n    today = Datum()\n    today.today()\n\n    # start_date = today - timedelta(weeks=13)\n    start_date = today.clone()\n    start_date.subtract_months(3)\n\n    period = get_period(start_date.date, today.date)\n    return period", "response": "Returns the last 3 months period as a string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_json_file_contents(path: str) -> str:\n    assert isinstance(path, str)\n    content = None\n\n    file_path = os.path.abspath(path)\n    content = fileutils.read_text_from_file(file_path)\n    json_object = json.loads(content)\n    content = json.dumps(json_object, sort_keys=True, indent=4)\n\n    return content", "response": "Loads contents from a json file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate JSON by parsing string data. Returns the json dict.", "response": "def validate_json(data: str):\n    \"\"\" Validate JSON by parsing string data. Returns the json dict. \"\"\"\n    result = None\n    try:\n        result = json.loads(data)\n    except ValueError as error:\n        log(ERROR, \"invalid json: %s\", error)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the sql query for the given query", "response": "def get_sql(query):\n    \"\"\" Returns the sql query \"\"\"\n    sql = str(query.statement.compile(dialect=sqlite.dialect(),\n                                      compile_kwargs={\"literal_binds\": True}))\n    return sql"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the contents into a temp file.", "response": "def save_to_temp(content, file_name=None):\n    \"\"\"Save the contents into a temp file.\"\"\"\n\n    #output = \"results.html\"\n    temp_dir = tempfile.gettempdir()\n    #tempfile.TemporaryDirectory()\n    #tempfile.NamedTemporaryFile(mode='w+t') as f:\n    out_file = os.path.join(temp_dir, file_name)\n    #if os.path.exists(output) and os.path.isfile(output):\n    file = open(out_file, 'w')\n    file.write(content)\n    file.close()\n    #print(\"results saved in results.html file.\")\n    #return output\n    #output = str(pathlib.Path(f.name))\n    return out_file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprompt user to enter book url in console", "response": "def read_book_uri_from_console():\n    \"\"\" Prompts the user to enter book url in console \"\"\"\n    db_path: str = input(\"Enter book_url or leave blank for the default settings value: \")\n    if db_path:\n        # sqlite\n        if db_path.startswith(\"sqlite://\"):\n            db_path_uri = db_path\n        else:\n            # TODO: check if file exists.\n            db_path_uri = \"file:///\" + db_path\n    else:\n        cfg = settings.Settings()\n        db_path_uri = cfg.database_uri\n\n    return db_path_uri"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the report from the command line.", "response": "def run_report_from_console(output_file_name, callback):\n    \"\"\"\n    Runs the report from the command line. Receives the book url from the console.\n    \"\"\"\n    print(\"The report uses a read-only access to the book.\")\n    print(\"Now enter the data or ^Z to continue:\")\n\n    #report_method = kwargs[\"report_method\"]\n    result = callback()\n\n    #output_file_name = kwargs[\"output_file_name\"]\n    output = save_to_temp(result, output_file_name)\n    webbrowser.open(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a file stream containing a csv price list and returns a list of Price models.", "response": "def parse_prices_from_file_stream(self, file_stream) -> List[PriceModel]:\n        \"\"\"\n        Reads a file stream (i.e. from web form) containing a csv prices\n        into a list of Price models.\n        \"\"\"\n        content = file_stream.read().decode(\"utf-8\")\n        file_stream.close()\n\n        if not content:\n            raise ValueError(\"The file is empty!\")\n\n        result = self.get_prices_from_csv(content)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports prices from CSV content. See data folder for a sample file / content.", "response": "def get_prices_from_csv(self, content: str) -> List[PriceModel]:\n        \"\"\" Imports prices from CSV content. See data folder for a sample file/content. \"\"\"\n        from gnucash_portfolio.model.price_model import PriceModel_Csv\n\n        lines = content.splitlines()\n        prices = []\n\n        reader = csv.reader(lines)\n        for row in reader:\n            csv_price = PriceModel_Csv()\n            csv_price.parse(row)\n\n            price = PriceModel()\n            price.datetime = csv_price.date\n            price.symbol = csv_price.symbol\n            price.value = csv_price.value\n            price.currency = self.currency\n\n            prices.append(price)\n        return prices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dividend_sum(book: Book, income_account: Account):\n    splits = book.session.query(Split).filter(Split.account == income_account).all()\n    dividend_sum = Decimal(0)\n\n    for split in splits:\n        dividend_sum += split.value\n        # debug print split...\n\n    # Since the income comes from the distribution account, it is marked as debit.\n    return dividend_sum * (-1)", "response": "Returns the sum of all distributions in the given income account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate all income for a symbol", "response": "def get_dividend_sum_for_symbol(book: Book, symbol: str):\n    \"\"\" Calculates all income for a symbol \"\"\"\n    svc = SecuritiesAggregate(book)\n    security = svc.get_by_symbol(symbol)\n    sec_svc = SecurityAggregate(book, security)\n    accounts = sec_svc.get_income_accounts()\n    total = Decimal(0)\n\n    for account in accounts:\n        # get all dividends.\n        income = get_dividend_sum(book, account)\n        total += income\n\n    return total"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_file(filename):\n    #file_path = os.path.relpath(filename)\n    file_path = os.path.abspath(filename)\n    log(DEBUG, \"Loading prices from %s\", file_path)\n\n    prices = __read_prices_from_file(file_path)\n    with BookAggregate(for_writing=True) as svc:\n        svc.prices.import_prices(prices)\n\n        print(\"Saving book...\")\n        svc.book.save()", "response": "Imports the commodity prices from the given. csv file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a report from a book.", "response": "def generate_report(book_url):\n                    # commodity: CommodityOption(\n                    #     section=\"Commodity\",\n                    #     sort_tag=\"a\",\n                    #     documentation_string=\"This is a stock\",\n                    #     default_value=\"VTIP\"),\n                    # commodity_list: CommodityListOption(\n                    #     section=\"Commodity\",\n                    #     sort_tag=\"a\",\n                    #     documentation_string=\"This is a stock\",\n                    #     default_value=\"VTIP\")\n                    #):\n    \"\"\"\n    Generates an HTML report content.\n    \"\"\"\n    # Report variables\n    shares_no = None\n    avg_price = None\n\n    stock_template = templates.load_jinja_template(\"stock_template.html\")\n    stock_rows = \"\"\n\n    with piecash.open_book(book_url, readonly=True, open_if_lock=True) as book:\n        # get all commodities that are not currencies.\n        all_stocks = portfoliovalue.get_all_stocks(book)\n        for stock in all_stocks:\n            for_date = datetime.today().date\n            model = portfoliovalue.get_stock_model_from(book, stock, for_date)\n            stock_rows += stock_template.render(model)\n\n    # Load HTML template file.\n    template = templates.load_jinja_template(\"template.html\")\n    # Render the full report.\n    #return template.format(**locals())\n    result = template.render(**locals())\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(symbol: str):\n    print(\"Displaying the balance for\", symbol)\n\n    with BookAggregate() as svc:\n        security = svc.book.get(Commodity, mnemonic=symbol)\n\t\t#security.transactions, security.prices\n\n        sec_svc = SecurityAggregate(svc.book, security)\n\n        # Display number of shares\n        shares_no = sec_svc.get_quantity()\n        print(\"Quantity:\", shares_no)\n\n        # Calculate average price.\n        avg_price = sec_svc.get_avg_price()\n        print(\"Average price:\", avg_price)", "response": "Displays the balance for the security symbol."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the report HTML.", "response": "def generate_report(book_url):\n    \"\"\"\n    Generates the report HTML.\n    \"\"\"\n    with piecash.open_book(book_url, readonly=True, open_if_lock=True) as book:\n        accounts = [acc.fullname for acc in book.accounts]\n\n        return f\"\"\"<html>\n        <body>\n            Hello world from python !<br>\n            Book : {book_url}<br>\n            List of accounts : {accounts}\n        </body>\n        </html>\"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_project_files():\n    if is_git_project():\n        return get_git_project_files()\n\n    project_files = []\n    for top, subdirs, files in os.walk('.'):\n        for subdir in subdirs:\n            if subdir.startswith('.'):\n                subdirs.remove(subdir)\n\n        for f in files:\n            if f.startswith('.'):\n                continue\n            project_files.append(os.path.join(top, f))\n\n    return project_files", "response": "Retrieve a list of project files ignoring hidden files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a message indicating success in green color to STDOUT.", "response": "def print_success_message(message):\n    \"\"\"Print a message indicating success in green color to STDOUT.\n\n    :param message: the message to print\n    :type message: :class:`str`\n    \"\"\"\n    try:\n        import colorama\n\n        print(colorama.Fore.GREEN + message + colorama.Fore.RESET)\n    except ImportError:\n        print(message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a message indicating failure in red color to STDERR.", "response": "def print_failure_message(message):\n    \"\"\"Print a message indicating failure in red color to STDERR.\n\n    :param message: the message to print\n    :type message: :class:`str`\n    \"\"\"\n    try:\n        import colorama\n\n        print(colorama.Fore.RED + message + colorama.Fore.RESET,\n              file=sys.stderr)\n    except ImportError:\n        print(message, file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    importer = ExchangeRatesImporter()\n\n    print(\"####################################\")\n    latest_rates_json = importer.get_latest_rates()\n\n    # translate into an array of PriceModels\n    # TODO mapper = currencyrates.FixerioModelMapper()\n    mapper = None\n    rates = mapper.map_to_model(latest_rates_json)\n\n    print(\"####################################\")\n    print(\"importing rates into gnucash...\")\n    # For writing, use True below.\n    with BookAggregate(for_writing=False) as svc:\n        svc.currencies.import_fx_rates(rates)\n\n    print(\"####################################\")\n    print(\"displaying rates from gnucash...\")\n    importer.display_gnucash_rates()", "response": "Entry point for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a number of query results. This is faster than the. count method on the query .", "response": "def get_count(self, query):\n        \"\"\"\n        Returns a number of query results. This is faster than .count() on the query\n        \"\"\"\n        count_q = query.statement.with_only_columns(\n            [func.count()]).order_by(None)\n        count = query.session.execute(count_q).scalar()\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_asset_allocation_report(book_url):\n    model = load_asset_allocation_model(book_url)\n\n    # load display template\n    template = templates.load_jinja_template(\"report_asset_allocation.html\")\n    # render template\n    result = template.render(model=model)\n    # **locals()\n\n    return result", "response": "Generate the report for asset allocation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse dd MM YYYY dates", "response": "def parse_euro_date(self, date_string: str):\n        \"\"\" Parses dd/MM/yyyy dates \"\"\"\n        self.date = datetime.strptime(date_string, \"%d/%m/%Y\")\n        return self.date"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_value(self, value_string: str):\n        self.value = Decimal(value_string)\n        return self.value", "response": "Parses the amount string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the. csv row into own values", "response": "def parse(self, csv_row: str):\n        \"\"\" Parses the .csv row into own values \"\"\"\n        self.date = self.parse_euro_date(csv_row[2])\n        self.symbol = csv_row[0]\n        self.value = self.parse_value(csv_row[1])\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading all cash balances in given currency and return the total cash balances.", "response": "def get_cash_balance_with_children(self, root_account: Account, currency: Commodity) -> Decimal:\n        \"\"\"\n        Loads cash balances in given currency.\n        currency: the currency for the total\n        \"\"\"\n        total = Decimal(0)\n        svc = CurrenciesAggregate(self.book)\n\n        # get all child accounts in a list\n        cash_balances = self.load_cash_balances_with_children(\n            root_account.fullname)\n        # get the amounts\n        for cur_symbol in cash_balances:\n            # Currency symbol\n            value = cash_balances[cur_symbol][\"total\"]\n\n            if cur_symbol != currency.mnemonic:\n                # Convert the amount to the given currency.\n                other_cur = svc.get_by_symbol(cur_symbol)\n\n                cur_svc = svc.get_currency_aggregate(other_cur)\n\n                rate = cur_svc.get_latest_rate(currency)\n                value = value * rate.value\n\n            total += value\n\n        return total"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload data for cash balances with children", "response": "def load_cash_balances_with_children(self, root_account_fullname: str):\n        \"\"\" loads data for cash balances \"\"\"\n        assert isinstance(root_account_fullname, str)\n\n        svc = AccountsAggregate(self.book)\n        root_account = svc.get_by_fullname(root_account_fullname)\n        if not root_account:\n            raise ValueError(\"Account not found\", root_account_fullname)\n        accounts = self.__get_all_child_accounts_as_array(root_account)\n\n        # read cash balances\n        model = {}\n        for account in accounts:\n            if account.commodity.namespace != \"CURRENCY\" or account.placeholder:\n                continue\n\n            # separate per currency\n            currency_symbol = account.commodity.mnemonic\n\n            if not currency_symbol in model:\n                # Add the currency branch.\n                currency_record = {\n                    \"name\": currency_symbol,\n                    \"total\": 0,\n                    \"rows\": []\n                }\n                # Append to the root.\n                model[currency_symbol] = currency_record\n            else:\n                currency_record = model[currency_symbol]\n\n            #acct_svc = AccountAggregate(self.book, account)\n            balance = account.get_balance()\n            row = {\n                \"name\": account.name,\n                \"fullname\": account.fullname,\n                \"currency\": currency_symbol,\n                \"balance\": balance\n            }\n            currency_record[\"rows\"].append(row)\n\n            # add to total\n            total = Decimal(currency_record[\"total\"])\n            total += balance\n            currency_record[\"total\"] = total\n\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_start_balance(self, before: date) -> Decimal:\n        assert isinstance(before, datetime)\n\n        # create a new date without hours\n        datum = Datum()\n        datum.from_date(before)\n        #date_corrected = datetimeutils.start_of_day(before)\n        # now subtract 1 second.\n        #date_corrected -= timedelta(seconds=1)\n        #log(DEBUG, \"getting balance on %s\", date_corrected)\n        datum.yesterday()\n        datum.end_of_day()\n        return self.get_balance_on(datum.value)", "response": "Calculates the balance of the account at the given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_end_balance(self, after: date) -> Decimal:\n        # create a new date without hours\n        #date_corrected = datetimeutils.end_of_day(after)\n        datum = Datum()\n        datum.from_date(after)\n        datum.end_of_day()\n        #log(DEBUG, \"getting balance on %s\", date_corrected)\n        return self.get_balance_on(datum.value)", "response": "Calculates the balance of the account at the given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the balance of the current account", "response": "def get_balance(self):\n        \"\"\" Current account balance \"\"\"\n        on_date = Datum()\n        on_date.today()\n        return self.get_balance_on(on_date.value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_balance_on(self, on_date: datetime) -> Decimal:\n        assert isinstance(on_date, datetime)\n\n        total = Decimal(0)\n\n        splits = self.get_splits_up_to(on_date)\n\n        for split in splits:\n            total += split.quantity * self.account.sign\n        return total", "response": "Returns the balance of the user on a certain date"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_balance_in_period(self, start: Datum, end: Datum):\n        assert isinstance(start, Datum)\n        assert isinstance(end, Datum)\n\n        total = Decimal(0)\n\n        splits = self.get_splits_in_period(start, end)\n\n        for split in splits:\n            total += split.quantity * self.account.sign\n        return total", "response": "Calculates the balance of the account in a given time period."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all the splits in the account", "response": "def get_splits_query(self):\n        \"\"\" Returns all the splits in the account \"\"\"\n        query = (\n            self.book.session.query(Split)\n            .filter(Split.account == self.account)\n        )\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns splits only up to the given date", "response": "def get_splits_up_to(self, date_to: datetime) -> List[Split]:\n        \"\"\" returns splits only up to the given date \"\"\"\n        query = (\n            self.book.session.query(Split)\n            .join(Transaction)\n            .filter(Split.account == self.account,\n                    Transaction.post_date <= date_to.date())\n        )\n        return query.all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_splits_in_period(self, start: Datum, end: Datum) -> List[Split]:\n        # from gnucash_portfolio.lib import generic\n\n        query = (\n            self.book.session.query(Split)\n            .join(Transaction)\n            .filter(Split.account == self.account,\n                    Transaction.post_date >= start.value.date(),\n                    Transaction.post_date <= end.value.date()\n                    )\n        )\n        # sql = generic.get_sql(query)\n        return query.all()", "response": "returns splits only up to the given date"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the account transactions between two dates.", "response": "def get_transactions(self, date_from: datetime, date_to: datetime) -> List[Transaction]:\n        \"\"\" Returns account transactions \"\"\"\n        assert isinstance(date_from, datetime)\n        assert isinstance(date_to, datetime)\n\n        # fix up the parameters as we need datetime\n        dt_from = Datum()\n        dt_from.from_datetime(date_from)\n        dt_from.start_of_day()\n        dt_to = Datum()\n        dt_to.from_datetime(date_to)\n        dt_to.end_of_day()\n\n        query = (\n            self.book.session.query(Transaction)\n            .join(Split)\n            .filter(Split.account_guid == self.account.guid)\n            .filter(Transaction.post_date >= dt_from.date, Transaction.post_date <= dt_to.date)\n            .order_by(Transaction.post_date)\n        )\n        return query.all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_all_child_accounts_as_array(self, account: Account) -> List[Account]:\n        result = []\n        # ignore placeholders ? - what if a brokerage account has cash/stocks division?\n        # if not account.placeholder:\n        # continue\n        result.append(account)\n\n        for child in account.children:\n            sub_accounts = self.__get_all_child_accounts_as_array(child)\n            result += sub_accounts\n\n        return result", "response": "Returns the whole tree of child accounts in a list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_by_name(self, term: str, include_placeholders: bool = False) -> List[Account]:\n        query = (\n            self.query\n            .filter(Account.name.like('%' + term + '%'))\n            .order_by(Account.name)\n        )\n        # Exclude placeholder accounts?\n        if not include_placeholders:\n            query = query.filter(Account.placeholder == 0)\n\n        # print(generic.get_sql(query))\n        return query.all()", "response": "Search for accounts by part of the name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the aggregate for the given id", "response": "def get_aggregate_by_id(self, account_id: str) -> AccountAggregate:\n        \"\"\" Returns the aggregate for the given id \"\"\"\n        account = self.get_by_id(account_id)\n        return self.get_account_aggregate(account)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_by_fullname(self, fullname: str) -> Account:\n        # get all accounts and iterate, comparing the fullname. :S\n        query = (\n            self.book.session.query(Account)\n        )\n        # generic.get_sql()\n        # print(sql)\n        all_accounts = query.all()\n        for account in all_accounts:\n            if account.fullname == fullname:\n                return account\n        # else\n        return None", "response": "Loads account by full name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_account_id_by_fullname(self, fullname: str) -> str:\n        account = self.get_by_fullname(fullname)\n        return account.guid", "response": "Locates the account by fullname"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_children(self, fullname: str) -> List[Account]:\n        # find the account by fullname\n        root_acct = self.get_by_fullname(fullname)\n        if not root_acct:\n            raise NameError(\"Account not found in book!\")\n\n        acct_agg = self.get_account_aggregate(root_acct)\n        result = acct_agg.get_all_child_accounts_as_array()\n        # for child in root_acct.children:\n        #     log(DEBUG, \"found child %s\", child.fullname)\n        return result", "response": "Returns the whole child account tree for the given full name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all(self) -> List[Account]:\n        return [account for account in self.book.accounts if account.parent.name != \"Template Root\"]", "response": "Returns all book accounts as a list excluding templates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_favourite_accounts(self) -> List[Account]:\n        from gnucash_portfolio.lib.settings import Settings\n\n        settings = Settings()\n        favourite_accts = settings.favourite_accounts\n        accounts = self.get_list(favourite_accts)\n        return accounts", "response": "Provides a list of favourite accounts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the list of account aggregates for favourite accounts", "response": "def get_favourite_account_aggregates(self) -> List[AccountAggregate]:\n        \"\"\" Returns the list of aggregates for favourite accounts \"\"\"\n        accounts = self.get_favourite_accounts()\n        aggregates = []\n        for account in accounts:\n            aggregate = self.get_account_aggregate(account)\n            aggregates.append(aggregate)\n\n        return aggregates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_id(self, acct_id) -> Account:\n        return self.book.get(Account, guid=acct_id)", "response": "Loads an account entity by its ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_by_name(self, name: str) -> List[Account]:\n        # return self.query.filter(Account.name == name).all()\n        return self.get_by_name_from(self.book.root, name)", "response": "Searches accounts by name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch the child accounts by name starting from the given account.", "response": "def get_by_name_from(self, root: Account, name: str) -> List[Account]:\n        \"\"\" Searches child accounts by name, starting from the given account \"\"\"\n        result = []\n\n        if root.name == name:\n            result.append(root)\n\n        for child in root.children:\n            child_results = self.get_by_name_from(child, name)\n            result += child_results\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_list(self, ids: List[str]) -> List[Account]:\n        query = (\n            self.query\n            .filter(Account.guid.in_(ids))\n        )\n        return query.all()", "response": "Load accounts by the ids passed as an argument."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch accounts by passing parameters.", "response": "def search(self, name: str = None,\n               acc_type: str = None):\n        \"\"\" Search accounts by passing parameters.\n        name = exact name\n        name_part = part of name\n        parent_id = id of the parent account\n        type = account type\n        \"\"\"\n        query = self.query\n\n        if name is not None:\n            query = query.filter(Account.name == name)\n\n        if acc_type is not None:\n            # account type is capitalized\n            acc_type = acc_type.upper()\n            query = query.filter(Account.type == acc_type)\n\n        return query.all()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse stock and commodity and returns the StockViewModel object", "response": "def get_stock_model_from(book: Book, commodity: Commodity, as_of_date: date) -> StockViewModel:\n    \"\"\" Parses stock/commodity and returns the model for display \"\"\"\n    from decimal import Decimal\n    from pydatum import Datum\n\n    svc = SecurityAggregate(book, commodity)\n    model = StockViewModel()\n\n    model.exchange = commodity.namespace\n    model.symbol = commodity.mnemonic\n\n    model.shares_num = svc.get_num_shares_on(as_of_date)\n    # Ignore 0-balance\n    if model.shares_num == 0:\n        return None\n\n    model.avg_price = svc.get_avg_price()\n\n    # Last price\n    price_svc = PricesAggregate(book)\n    # last_price: Price = price_svc.get_price_as_of(commodity, as_of_date)\n    last_price: PriceModel = price_svc.get_latest_price(commodity)\n    if last_price is not None:\n        model.price = last_price.value\n    else:\n        model.price = Decimal(0)\n\n    # currency\n    if model.price:\n        model.currency = last_price.currency\n\n    # Cost\n    model.cost = model.shares_num * model.avg_price\n\n    # Balance (current value)\n    if model.shares_num > 0 and model.price:\n        model.balance = model.shares_num * model.price\n    else:\n        model.balance = Decimal(0)\n\n    # Gain/Loss\n    model.gain_loss = model.balance - model.cost\n\n    # Gain/loss percentage\n    gain_loss_perc = 0\n    if model.cost:\n        gain_loss_perc = abs(model.gain_loss) * 100 / model.cost\n        if model.gain_loss < 0:\n            gain_loss_perc *= -1\n    model.gain_loss_perc = gain_loss_perc\n\n    # Income\n    income = symbol_dividends.get_dividend_sum_for_symbol(book, model.symbol)\n    model.income = float(income)\n\n    #income_12m = symbol_dividends.\n    start = Datum()\n    start.subtract_months(12)\n    end = Datum()\n    model.income_last_12m = svc.get_income_in_period(start, end)\n    if model.balance > 0 and model.income_last_12m > 0:\n        model.income_last_12m_perc = model.income_last_12m * 100 / model.balance\n    else:\n        model.income_last_12m_perc = Decimal(0)\n\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_price_as_of(self, stock: Commodity, on_date: datetime):\n        # return self.get_price_as_of_query(stock, on_date).first()\n        prices = PriceDbApplication()\n        prices.get_prices_on(on_date.date().isoformat(), stock.namespace, stock.mnemonic)", "response": "Gets the latest price for the given stock as of the given date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports prices from csv into dict", "response": "def import_prices(self, prices: List[PriceModel]):\n        \"\"\" Import prices (from csv) \"\"\"\n        result = {}\n        for price in prices:\n            result[price.symbol] = self.import_price(price)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new Price entry for the given commodity and price.", "response": "def __create_price_for(self, commodity: Commodity, price: PriceModel):\n        \"\"\" Creates a new Price entry in the book, for the given commodity \"\"\"\n        logging.info(\"Adding a new price for %s, %s, %s\",\n                     commodity.mnemonic, price.datetime.strftime(\"%Y-%m-%d\"), price.value)\n\n        # safety check. Compare currencies.\n        sec_svc = SecurityAggregate(self.book, commodity)\n        currency = sec_svc.get_currency()\n\n        if currency != price.currency:\n            raise ValueError(\n                \"Requested currency does not match the currency previously used\",\n                currency, price.currency)\n\n        # Description of the source field values:\n        # https://www.gnucash.org/docs/v2.6/C/gnucash-help/tool-price.html\n\n        new_price = Price(commodity, currency, price.datetime.date(), price.value,\n                          source=\"Finance::Quote\")\n        commodity.prices.append(new_price)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_splits_query(self):\n        query = (\n            self.book.session.query(Split)\n            # .join(Transaction)\n            .filter(Split.transaction_guid == self.transaction.guid)\n        )\n        return query", "response": "Returns the query for related splits"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the sum of all values for all splits for the given account", "response": "def get_value_of_splits_for_account(self, account_id: str) -> Decimal:\n        \"\"\" Returns the sum of values for all splits for the given account \"\"\"\n        splits = self.get_split_for_account(account_id)\n        result = Decimal(0)\n        for split in splits:\n            result += split.value\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the sum of values for all splits for the given account", "response": "def get_quantity_of_splits_for_account(self, account_id: str) -> Decimal:\n        \"\"\" Returns the sum of values for all splits for the given account \"\"\"\n        splits = self.get_split_for_account(account_id)\n        result = Decimal(0)\n        for split in splits:\n            result += split.quantity\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload transaction by id", "response": "def get(self, tx_id: str) -> Transaction:\n        \"\"\" load transaction by id \"\"\"\n        query = (\n            self.book.session.query(Transaction)\n            .filter(Transaction.guid == tx_id)\n        )\n        return query.one()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_report(\n        book_url,\n        fund_ids: StringOption(\n            section=\"Funds\",\n            sort_tag=\"c\",\n            documentation_string=\"Comma-separated list of fund ids.\",\n            default_value=\"8123,8146,8148,8147\")\n    ):\n    \"\"\"Generates the report output\"\"\"\n    return render_report(book_url, fund_ids)", "response": "Generates the report from the given set of fund ids."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef searchAccount(searchTerm, book):\n    print(\"Search results:\\n\")\n\n    found = False\n\n    # search\n    for account in book.accounts:\n        # print(account.fullname)\n        # name\n        if searchTerm.lower() in account.fullname.lower():\n            print(account.fullname)\n            found = True\n\n    if not found:\n        print(\"Search term not found in account names.\")", "response": "Searches through account names and prints out the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef display_db_info(self):\n        with self.open_book() as book:\n            default_currency = book.default_currency\n            print(\"Default currency is \", default_currency.mnemonic)", "response": "Displays some basic info about the GnuCash book"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_book(self, for_writing=False) -> piecash.Book:\n        filename = None\n\n        # check if the file path is already a URL.\n        file_url = urllib.parse.urlparse(self.filename)\n        if file_url.scheme == \"file\" or file_url.scheme == \"sqlite\":\n            filename = file_url.path[1:]\n        else:\n            filename = self.filename\n\n        if not os.path.isfile(filename):\n            log(WARN, \"Database %s requested but not found. Creating an in-memory book.\", filename)\n            return self.create_book()\n\n        access_type = \"read/write\" if for_writing else \"readonly\"\n        log(INFO, \"Using %s in %s mode.\", filename, access_type)\n        # file_path = path.relpath(self.filename)\n        file_path = path.abspath(filename)\n\n        if not for_writing:\n            book = piecash.open_book(file_path, open_if_lock=True)\n        else:\n            book = piecash.open_book(file_path, open_if_lock=True, readonly=False)\n        # book = create_book()\n        return book", "response": "Opens the database. Call this using with."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_text_from_file(path: str) -> str:\n    with open(path) as text_file:\n        content = text_file.read()\n\n    return content", "response": "Reads text file contents"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves text to file", "response": "def save_text_to_file(content: str, path: str):\n    \"\"\" Saves text to file \"\"\"\n    with open(path, mode='w') as text_file:\n        text_file.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the amount in base currency", "response": "def get_amount_in_base_currency(self, currency: str, amount: Decimal) -> Decimal:\n        \"\"\" Calculates the amount in base currency \"\"\"\n        assert isinstance(amount, Decimal)\n\n        # If this is already the base currency, do nothing.\n        if currency == self.get_default_currency().mnemonic:\n            return amount\n\n        agg = self.get_currency_aggregate_by_symbol(currency)\n        if not agg:\n            raise ValueError(f\"Currency not found: {currency}!\")\n\n        # TODO use pricedb for the price.\n        rate_to_base = agg.get_latest_price()\n        if not rate_to_base:\n            raise ValueError(f\"Latest price not found for {currency}!\")\n        assert isinstance(rate_to_base.value, Decimal)\n\n        result = amount * rate_to_base.value\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default_currency(self) -> Commodity:\n        result = None\n\n        if self.default_currency:\n            result = self.default_currency\n        else:\n            def_currency = self.__get_default_currency()\n            self.default_currency = def_currency\n            result = def_currency\n\n        return result", "response": "returns the book default currency"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the currencies used in the book", "response": "def get_book_currencies(self) -> List[Commodity]:\n        \"\"\" Returns currencies used in the book \"\"\"\n        query = (\n            self.currencies_query\n                .order_by(Commodity.mnemonic)\n        )\n        return query.all()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_currency_aggregate_by_symbol(self, symbol: str) -> CurrencyAggregate:\n        currency = self.get_by_symbol(symbol)\n        result = self.get_currency_aggregate(currency)\n        return result", "response": "Creates currency aggregate for the given currency symbol"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_by_symbol(self, symbol: str) -> Commodity:\n        assert isinstance(symbol, str)\n\n        query = (\n            self.currencies_query\n                .filter(Commodity.mnemonic == symbol)\n        )\n        return query.one()", "response": "Loads currency by symbol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_fx_rates(self, rates: List[PriceModel]):\n        have_new_rates = False\n\n        base_currency = self.get_default_currency()\n\n        for rate in rates:\n            assert isinstance(rate, PriceModel)\n\n            currency = self.get_by_symbol(rate.symbol)\n            amount = rate.value\n\n            # Do not import duplicate prices.\n            # todo: if the price differs, update it!\n            # exists_query = exists(rates_query)\n            has_rate = currency.prices.filter(Price.date == rate.datetime.date()).first()\n            # has_rate = (\n            #     self.book.session.query(Price)\n            #     .filter(Price.date == rate.date.date())\n            #     .filter(Price.currency == currency)\n            # )\n            if not has_rate:\n                log(INFO, \"Creating entry for %s, %s, %s, %s\",\n                    base_currency.mnemonic, currency.mnemonic, rate.datetime.date(), amount)\n                # Save the price in the exchange currency, not the default.\n                # Invert the rate in that case.\n                inverted_rate = 1 / amount\n                inverted_rate = inverted_rate.quantize(Decimal('.00000000'))\n\n                price = Price(commodity=currency,\n                              currency=base_currency,\n                              date=rate.datetime.date(),\n                              value=str(inverted_rate))\n                have_new_rates = True\n\n        # Save the book after the prices have been created.\n        if have_new_rates:\n            log(INFO, \"Saving new prices...\")\n            self.book.flush()\n            self.book.save()\n        else:\n            log(INFO, \"No prices imported.\")", "response": "Imports the given prices into the database. Write operation!"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_default_currency(self):\n        # If we are on Windows, read from registry.\n        if sys.platform == \"win32\":\n            # read from registry\n            def_curr = self.book[\"default-currency\"] = self.__get_default_currency_windows()\n        else:\n            # return the currency from locale.\n            # todo: Read the preferences on other operating systems.\n            def_curr = self.book[\"default-currency\"] = self.__get_locale_currency()\n\n        return def_curr", "response": "Read the default currency from GnuCash preferences"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread currency from windows registry", "response": "def __get_registry_key(self, key):\n        \"\"\" Read currency from windows registry \"\"\"\n        import winreg\n\n        root = winreg.OpenKey(\n            winreg.HKEY_CURRENT_USER, r'SOFTWARE\\GSettings\\org\\gnucash\\general', 0, winreg.KEY_READ)\n        [pathname, regtype] = (winreg.QueryValueEx(root, key))\n        winreg.CloseKey(root)\n        return pathname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, split_id: str) -> Split:\n        query = (\n            self.query\n            .filter(Split.guid == split_id)\n        )\n        return query.one()", "response": "load transaction by id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all splits for the given accounts", "response": "def get_for_accounts(self, accounts: List[Account]):\n        ''' Get all splits for the given accounts '''\n        account_ids = [acc.guid for acc in accounts]\n        query = (\n            self.query\n            .filter(Split.account_guid.in_(account_ids))\n        )\n        splits = query.all()\n        return splits"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __get_model_for_portfolio_value(input_model: PortfolioValueInputModel\n        ) -> PortfolioValueViewModel:\n    \"\"\" loads the data for portfolio value \"\"\"\n    result = PortfolioValueViewModel()\n    result.filter = input_model\n\n    ref_datum = Datum()\n    ref_datum.from_datetime(input_model.as_of_date)\n    ref_date = ref_datum.end_of_day()\n\n    result.stock_rows = []\n    with BookAggregate() as svc:\n        book = svc.book\n        stocks_svc = svc.securities\n\n        if input_model.stock:\n            symbols = input_model.stock.split(\",\")\n            stocks = stocks_svc.get_stocks(symbols)\n        else:\n            stocks = stocks_svc.get_all()\n\n        for stock in stocks:\n            row: StockViewModel = portfoliovalue.get_stock_model_from(\n                book, stock, as_of_date=ref_date)\n            if row and row.balance > 0:\n                result.stock_rows.append(row)\n\n    return result", "response": "loads the data for portfolio value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __load_settings(self):\n        #file_path = path.relpath(settings_file_path)\n        #file_path = path.abspath(settings_file_path)\n        file_path = self.file_path\n\n        try:\n            self.data = json.load(open(file_path))\n        except FileNotFoundError:\n            print(\"Could not load\", file_path)", "response": "Load settings from. json file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the settings file exists.", "response": "def file_exists(self) -> bool:\n        \"\"\" Check if the settings file exists or not \"\"\"\n        cfg_path = self.file_path\n        assert cfg_path\n\n        return path.isfile(cfg_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the current settings to the file", "response": "def save(self):\n        \"\"\" Saves the settings contents \"\"\"\n        content = self.dumps()\n        fileutils.save_text_to_file(content, self.file_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef database_path(self):\n        filename = self.database_filename\n        db_path = \":memory:\" if filename == \":memory:\" else (\n            path.abspath(path.join(__file__, \"../..\", \"..\", \"data\", filename)))\n        return db_path", "response": "Full database path. Includes the default location + the database filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_path(self) -> str:\n        user_dir = self.__get_user_path()\n        file_path = path.abspath(path.join(user_dir, self.FILENAME))\n        return file_path", "response": "Returns the absolute path to the file that is used to store the current settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dumps(self) -> str:\n        return json.dumps(self.data, sort_keys=True, indent=4)", "response": "Dumps the json content as a string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __copy_template(self):\n        import shutil\n\n        template_filename = \"settings.json.template\"\n        template_path = path.abspath(\n            path.join(__file__, \"..\", \"..\", \"config\", template_filename))\n        settings_path = self.file_path\n        shutil.copyfile(template_path, settings_path)\n\n        self.__ensure_file_exists()", "response": "Copy the settings. json. template into the user s directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nis the value not empty?", "response": "def is_not_empty(self, value, strict=False):\n        \"\"\"if value is not empty\"\"\"\n        value = stringify(value)\n        if value is not None:\n            return\n        self.shout('Value %r is empty', strict, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if value is numeric", "response": "def is_numeric(self, value, strict=False):\n        \"\"\"if value is numeric\"\"\"\n        value = stringify(value)\n        if value is not None:\n            if value.isnumeric():\n                return\n        self.shout('value %r is not numeric', strict, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_integer(self, value, strict=False):\n        if value is not None:\n            if isinstance(value, numbers.Number):\n                return\n        value = stringify(value)\n        if value is not None and value.isnumeric():\n            return\n        self.shout('value %r is not an integer', strict, value)", "response": "Check if value is an integer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_date(self, value, strict=False):\n        value = stringify(value)\n        try:\n            parse(value)\n        except Exception:\n            self.shout('Value %r is not a valid date', strict, value)", "response": "Match the value of a date field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_regexp(self, value, q, strict=False):\n        value = stringify(value)\n        mr = re.compile(q)\n        if value is not None:\n            if mr.match(value):\n                return\n        self.shout('%r not matching the regexp %r', strict, value, q)", "response": "Check if the value matches a regexp q"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_length(self, value, q, strict=False):\n        value = stringify(value)\n        if value is not None:\n            if len(value) == q:\n                return\n        self.shout('Value %r not matching length %r', strict, value, q)", "response": "Check if value has a length of q"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that value contains q", "response": "def must_contain(self, value, q, strict=False):\n        \"\"\"if value must contain q\"\"\"\n        if value is not None:\n            if value.find(q) != -1:\n                return\n        self.shout('Value %r does not contain %r', strict, value, q)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract(context, data):\n    with context.http.rehash(data) as result:\n        file_path = result.file_path\n        content_type = result.content_type\n        extract_dir = random_filename(context.work_path)\n        if content_type in ZIP_MIME_TYPES:\n            extracted_files = extract_zip(file_path, extract_dir)\n        elif content_type in TAR_MIME_TYPES:\n            extracted_files = extract_tar(file_path, extract_dir, context)\n        elif content_type in SEVENZIP_MIME_TYPES:\n            extracted_files = extract_7zip(file_path, extract_dir, context)\n        else:\n            context.log.warning(\n                \"Unsupported archive content type: %s\", content_type\n            )\n            return\n        extracted_content_hashes = {}\n        for path in extracted_files:\n            relative_path = os.path.relpath(path, extract_dir)\n            content_hash = context.store_file(path)\n            extracted_content_hashes[relative_path] = content_hash\n            data['content_hash'] = content_hash\n            data['file_name'] = relative_path\n            context.emit(data=data.copy())", "response": "Extracts a compressed file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef size(cls, crawler):\n        key = make_key('queue_pending', crawler)\n        return unpack_int(conn.get(key))", "response": "Return the number of pending operations for this crawler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_word(image, whitelist=None, chars=None, spaces=False):\n    from tesserocr import PyTessBaseAPI\n    api = PyTessBaseAPI()\n    api.SetPageSegMode(8)\n    if whitelist is not None:\n        api.SetVariable(\"tessedit_char_whitelist\", whitelist)\n    api.SetImage(image)\n    api.Recognize()\n    guess = api.GetUTF8Text()\n\n    if not spaces:\n        guess = ''.join([c for c in guess if c != \" \"])\n        guess = guess.strip()\n\n    if chars is not None and len(guess) != chars:\n        return guess, None\n\n    return guess, api.MeanTextConf()", "response": "Read a single word from an image. Useful for captchas.\n    Image should be pre - processed to remove noise etc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_char(image, whitelist=None):\n    from tesserocr import PyTessBaseAPI\n    api = PyTessBaseAPI()\n    api.SetPageSegMode(10)\n    if whitelist is not None:\n        api.SetVariable(\"tessedit_char_whitelist\", whitelist)\n    api.SetImage(image)\n    api.Recognize()\n    return api.GetUTF8Text().strip()", "response": "OCR a single character from an image. Useful for captchas."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a configuration value and expand environment variables.", "response": "def get(self, name, default=None):\n        \"\"\"Get a configuration value and expand environment variables.\"\"\"\n        value = self.params.get(name, default)\n        if isinstance(value, str):\n            value = os.path.expandvars(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninvokes the next stage based on a handling rule.", "response": "def emit(self, rule='pass', stage=None, data={}, delay=None,\n             optional=False):\n        \"\"\"Invoke the next stage, either based on a handling rule, or by calling\n        the `pass` rule by default.\"\"\"\n        if stage is None:\n            stage = self.stage.handlers.get(rule)\n        if optional and stage is None:\n            return\n        if stage is None or stage not in self.crawler.stages:\n            self.log.info(\"No next stage: %s (%s)\" % (stage, rule))\n            return\n        state = self.dump_state()\n        delay = delay or self.crawler.delay\n        Queue.queue(stage, state, data, delay)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recurse(self, data={}, delay=None):\n        return self.emit(stage=self.stage.name,\n                         data=data,\n                         delay=delay)", "response": "Have a stage invoke itself with a modified set of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self, data):\n        if Crawl.is_aborted(self.crawler, self.run_id):\n            return\n\n        try:\n            Crawl.operation_start(self.crawler, self.stage, self.run_id)\n            self.log.info('[%s->%s(%s)]: %s',\n                          self.crawler.name,\n                          self.stage.name,\n                          self.stage.method_name,\n                          self.run_id)\n            return self.stage.method(self, data)\n        except Exception as exc:\n            self.emit_exception(exc)\n        finally:\n            Crawl.operation_end(self.crawler, self.run_id)\n            shutil.rmtree(self.work_path)", "response": "Execute the crawler and create a database record of having done\n        so."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef skip_incremental(self, *criteria):\n        if not self.incremental:\n            return False\n\n        # this is pure convenience, and will probably backfire at some point.\n        key = make_key(*criteria)\n        if key is None:\n            return False\n\n        if self.check_tag(key):\n            return True\n\n        self.set_tag(key, None)\n        return False", "response": "Perform an incremental check on a set of criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the given content into a file in the process.", "response": "def store_data(self, data, encoding='utf-8'):\n        \"\"\"Put the given content into a file, possibly encoding it as UTF-8\n        in the process.\"\"\"\n        path = random_filename(self.work_path)\n        try:\n            with open(path, 'wb') as fh:\n                if isinstance(data, str):\n                    data = data.encode(encoding)\n                if data is not None:\n                    fh.write(data)\n            return self.store_file(path)\n        finally:\n            try:\n                os.unlink(path)\n            except OSError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the last execution of this crawler is older than the scheduled interval.", "response": "def check_due(self):\n        \"\"\"Check if the last execution of this crawler is older than\n        the scheduled interval.\"\"\"\n        if self.disabled:\n            return False\n        if self.is_running:\n            return False\n        if self.delta is None:\n            return False\n        last_run = self.last_run\n        if last_run is None:\n            return True\n        now = datetime.utcnow()\n        if now > last_run + self.delta:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flush(self):\n        Queue.flush(self)\n        Event.delete(self)\n        Crawl.flush(self)", "response": "Delete all run - time data generated by this crawler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, incremental=None, run_id=None):\n        state = {\n            'crawler': self.name,\n            'run_id': run_id,\n            'incremental': settings.INCREMENTAL\n        }\n        if incremental is not None:\n            state['incremental'] = incremental\n\n        # Cancel previous runs:\n        self.cancel()\n        # Flush out previous events:\n        Event.delete(self)\n        Queue.queue(self.init_stage, state, {})", "response": "Queue the execution of a particular crawler."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(context, data):\n    url = data.get('url')\n    attempt = data.pop('retry_attempt', 1)\n    try:\n        result = context.http.get(url, lazy=True)\n        rules = context.get('rules', {'match_all': {}})\n        if not Rule.get_rule(rules).apply(result):\n            context.log.info('Fetch skip: %r', result.url)\n            return\n\n        if not result.ok:\n            err = (result.url, result.status_code)\n            context.emit_warning(\"Fetch fail [%s]: HTTP %s\" % err)\n            if not context.params.get('emit_errors', False):\n                return\n        else:\n            context.log.info(\"Fetched [%s]: %r\",\n                             result.status_code,\n                             result.url)\n\n        data.update(result.serialize())\n        if url != result.url:\n            tag = make_key(context.run_id, url)\n            context.set_tag(tag, None)\n        context.emit(data=data)\n    except RequestException as ce:\n        retries = int(context.get('retry', 3))\n        if retries >= attempt:\n            context.log.warn(\"Retry: %s (error: %s)\", url, ce)\n            data['retry_attempt'] = attempt + 1\n            context.recurse(data=data, delay=2 ** attempt)\n        else:\n            context.emit_warning(\"Fetch fail [%s]: %s\" % (url, ce))", "response": "Fetch the url specified in the inbound data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists files in a WebDAV directory.", "response": "def dav_index(context, data):\n    \"\"\"List files in a WebDAV directory.\"\"\"\n    # This is made to work with ownCloud/nextCloud, but some rumor has\n    # it they are \"standards compliant\" and it should thus work for\n    # other DAV servers.\n    url = data.get('url')\n    result = context.http.request('PROPFIND', url)\n    for resp in result.xml.findall('./{DAV:}response'):\n        href = resp.findtext('./{DAV:}href')\n        if href is None:\n            continue\n\n        rurl = urljoin(url, href)\n        rdata = data.copy()\n        rdata['url'] = rurl\n        rdata['foreign_id'] = rurl\n        if rdata['url'] == url:\n            continue\n\n        if resp.find('.//{DAV:}collection') is not None:\n            rdata['parent_foreign_id'] = rurl\n            context.log.info(\"Fetching contents of folder: %s\" % rurl)\n            context.recurse(data=rdata)\n        else:\n            rdata['parent_foreign_id'] = url\n\n        # Do GET requests on the urls\n        fetch(context, rdata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset some HTTP parameters for all subsequent requests.", "response": "def session(context, data):\n    \"\"\"Set some HTTP parameters for all subsequent requests.\n\n    This includes ``user`` and ``password`` for HTTP basic authentication,\n    and ``user_agent`` as a header.\n    \"\"\"\n    context.http.reset()\n\n    user = context.get('user')\n    password = context.get('password')\n\n    if user is not None and password is not None:\n        context.http.session.auth = (user, password)\n\n    user_agent = context.get('user_agent')\n    if user_agent is not None:\n        context.http.session.headers['User-Agent'] = user_agent\n\n    referer = context.get('url')\n    if referer is not None:\n        context.http.session.headers['Referer'] = referer\n\n    proxy = context.get('proxy')\n    if proxy is not None:\n        proxies = {'http': proxy, 'https': proxy}\n        context.http.session.proxies = proxies\n\n    # Explictly save the session because no actual HTTP requests were made.\n    context.http.save()\n    context.emit(data=data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an event possibly based on an exception.", "response": "def save(cls, crawler, stage, level, run_id, error=None, message=None):\n        \"\"\"Create an event, possibly based on an exception.\"\"\"\n        event = {\n            'stage': stage.name,\n            'level': level,\n            'timestamp': pack_now(),\n            'error': error,\n            'message': message\n        }\n        data = dump_json(event)\n        conn.lpush(make_key(crawler, \"events\"), data)\n        conn.lpush(make_key(crawler, \"events\", level), data)\n        conn.lpush(make_key(crawler, \"events\", stage), data)\n        conn.lpush(make_key(crawler, \"events\", stage, level), data)\n        conn.lpush(make_key(crawler, \"events\", run_id), data)\n        conn.lpush(make_key(crawler, \"events\", run_id, level), data)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget events from a particular stage", "response": "def get_stage_events(cls, crawler, stage_name, start, end, level=None):\n        \"\"\"events from a particular stage\"\"\"\n        key = make_key(crawler, \"events\", stage_name, level)\n        return cls.event_list(key, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_run_events(cls, crawler, run_id, start, end, level=None):\n        key = make_key(crawler, \"events\", run_id, level)\n        return cls.event_list(key, start, end)", "response": "Get the events from a particular run"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the total number of results from the DOM of a search index.", "response": "def search_results_total(html, xpath, check, delimiter):\n    \"\"\" Get the total number of results from the DOM of a search index. \"\"\"\n    for container in html.findall(xpath):\n        if check in container.findtext('.'):\n            text = container.findtext('.').split(delimiter)\n            total = int(text[-1].strip())\n            return total"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the URL of the last button in a search results listing.", "response": "def search_results_last_url(html, xpath, label):\n    \"\"\" Get the URL of the 'last' button in a search results listing. \"\"\"\n    for container in html.findall(xpath):\n        if container.text_content().strip() == label:\n            return container.find('.//a').get('href')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef op_count(cls, crawler, stage=None):\n        if stage:\n            total_ops = conn.get(make_key(crawler, stage))\n        else:\n            total_ops = conn.get(make_key(crawler, \"total_ops\"))\n        return unpack_int(total_ops)", "response": "Get the number of operations performed for this crawler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a list of all crawlers alphabetically with op counts.", "response": "def index():\n    \"\"\"Generate a list of all crawlers, alphabetically, with op counts.\"\"\"\n    crawlers = []\n    for crawler in manager:\n        data = Event.get_counts(crawler)\n        data['last_active'] = crawler.last_run\n        data['total_ops'] = crawler.op_count\n        data['running'] = crawler.is_running\n        data['crawler'] = crawler\n        crawlers.append(data)\n    return render_template('index.html', crawlers=crawlers)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_html(context, data):\n    doc = _get_html_document(context, data)\n    if doc is None:\n        context.emit(data=data)\n        return\n\n    remove_paths = context.params.get('remove_paths')\n    for path in ensure_list(remove_paths):\n        for el in doc.findall(path):\n            el.drop_tree()\n\n    html_text = html.tostring(doc, pretty_print=True)\n    content_hash = context.store_data(html_text)\n    data['content_hash'] = content_hash\n    context.emit(data=data)", "response": "Clean an HTML DOM and store the changed version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the operation, rate limiting allowing.", "response": "def execute(cls, stage, state, data, next_allowed_exec_time=None):\n        \"\"\"Execute the operation, rate limiting allowing.\"\"\"\n        try:\n            context = Context.from_state(state, stage)\n            now = datetime.utcnow()\n            if next_allowed_exec_time and now < next_allowed_exec_time:\n                # task not allowed to run yet; put it back in the queue\n                Queue.queue(stage, state, data, delay=next_allowed_exec_time)\n            elif context.crawler.disabled:\n                pass\n            elif context.stage.rate_limit:\n                try:\n                    with rate_limiter(context):\n                        context.execute(data)\n                except RateLimitException:\n                    delay = max(1, 1.0/context.stage.rate_limit)\n                    delay = random.randint(1, int(delay))\n                    context.log.info(\n                        \"Rate limit exceeded, delaying %d sec.\", delay\n                    )\n                    Queue.queue(stage, state, data, delay=delay)\n            else:\n                context.execute(data)\n        except Exception:\n            log.exception(\"Task failed to execute:\")\n        finally:\n            # Decrease the pending task count after excuting a task.\n            Queue.decr_pending(context.crawler)\n            # If we don't have anymore tasks to execute, time to clean up.\n            if not context.crawler.is_running:\n                context.crawler.aggregate(context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _upsert(context, params, data):\n    table = params.get(\"table\")\n    table = datastore.get_table(table, primary_id=False)\n    unique_keys = ensure_list(params.get(\"unique\"))\n    data[\"__last_seen\"] = datetime.datetime.utcnow()\n    if len(unique_keys):\n        updated = table.update(data, unique_keys, return_count=True)\n        if updated:\n            return\n    data[\"__first_seen\"] = data[\"__last_seen\"]\n    table.insert(data)", "response": "Insert or update data and add or update appropriate timestamps"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert or update nested dicts recursively into db tables", "response": "def _recursive_upsert(context, params, data):\n    \"\"\"Insert or update nested dicts recursively into db tables\"\"\"\n    children = params.get(\"children\", {})\n    nested_calls = []\n    for child_params in children:\n        key = child_params.get(\"key\")\n        child_data_list = ensure_list(data.pop(key))\n        if isinstance(child_data_list, dict):\n            child_data_list = [child_data_list]\n        if not (isinstance(child_data_list, list) and\n                all(isinstance(i, dict) for i in child_data_list)):\n            context.log.warn(\n                \"Expecting a dict or a lost of dicts as children for key\", key\n            )\n            continue\n        if child_data_list:\n            table_suffix = child_params.get(\"table_suffix\", key)\n            child_params[\"table\"] = params.get(\"table\") + \"_\" + table_suffix\n            # copy some properties over from parent to child\n            inherit = child_params.get(\"inherit\", {})\n            for child_data in child_data_list:\n                for dest, src in inherit.items():\n                    child_data[dest] = data.get(src)\n                nested_calls.append((child_params, child_data))\n    # Insert or update data\n    _upsert(context, params, data)\n    for child_params, child_data in nested_calls:\n        _recursive_upsert(context, child_params, child_data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert or update data as a row into specified db table", "response": "def db(context, data):\n    \"\"\"Insert or update `data` as a row into specified db table\"\"\"\n    table = context.params.get(\"table\", context.crawler.name)\n    params = context.params\n    params[\"table\"] = table\n    _recursive_upsert(context, params, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(debug, cache, incremental):\n    settings.HTTP_CACHE = cache\n    settings.INCREMENTAL = incremental\n    settings.DEBUG = debug\n    if settings.DEBUG:\n        logging.basicConfig(level=logging.DEBUG)\n    else:\n        logging.basicConfig(level=logging.INFO)\n    init_memorious()", "response": "A crawler framework for documents and structured scrapers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(crawler):\n    crawler = get_crawler(crawler)\n    crawler.run()\n    if is_sync_mode():\n        TaskRunner.run_sync()", "response": "Run a specified crawler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index():\n    crawler_list = []\n    for crawler in manager:\n        is_due = 'yes' if crawler.check_due() else 'no'\n        if crawler.disabled:\n            is_due = 'off'\n        crawler_list.append([crawler.name,\n                             crawler.description,\n                             crawler.schedule,\n                             is_due,\n                             Queue.size(crawler)])\n    headers = ['Name', 'Description', 'Schedule', 'Due', 'Pending']\n    print(tabulate(crawler_list, headers=headers))", "response": "List the available crawlers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun crawlers that are due.", "response": "def scheduled(wait=False):\n    \"\"\"Run crawlers that are due.\"\"\"\n    manager.run_scheduled()\n    while wait:\n        # Loop and try to run scheduled crawlers at short intervals\n        manager.run_scheduled()\n        time.sleep(settings.SCHEDULER_INTERVAL)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the storage path fro the output.", "response": "def _get_directory_path(context):\n    \"\"\"Get the storage path fro the output.\"\"\"\n    path = os.path.join(settings.BASE_PATH, 'store')\n    path = context.params.get('path', path)\n    path = os.path.join(path, context.crawler.name)\n    path = os.path.abspath(os.path.expandvars(path))\n    try:\n        os.makedirs(path)\n    except Exception:\n        pass\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the collected files to a given directory.", "response": "def directory(context, data):\n    \"\"\"Store the collected files to a given directory.\"\"\"\n    with context.http.rehash(data) as result:\n        if not result.ok:\n            return\n\n        content_hash = data.get('content_hash')\n        if content_hash is None:\n            context.emit_warning(\"No content hash in data.\")\n            return\n\n        path = _get_directory_path(context)\n        file_name = data.get('file_name', result.file_name)\n        file_name = safe_filename(file_name, default='raw')\n        file_name = '%s.%s' % (content_hash, file_name)\n        data['_file_name'] = file_name\n        file_path = os.path.join(path, file_name)\n        if not os.path.exists(file_path):\n            shutil.copyfile(result.file_path, file_path)\n\n        context.log.info(\"Store [directory]: %s\", file_name)\n\n        meta_path = os.path.join(path, '%s.json' % content_hash)\n        with open(meta_path, 'w') as fh:\n            json.dump(data, fh)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes a crawler with a set of seed URLs.", "response": "def seed(context, data):\n    \"\"\"Initialize a crawler with a set of seed URLs.\n\n    The URLs are given as a list or single value to the ``urls`` parameter.\n\n    If this is called as a second stage in a crawler, the URL will be formatted\n    against the supplied ``data`` values, e.g.:\n\n        https://crawl.site/entries/%(number)s.html\n    \"\"\"\n    for key in ('url', 'urls'):\n        for url in ensure_list(context.params.get(key)):\n            url = url % data\n            context.emit(data={'url': url})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enumerate(context, data):\n    items = ensure_list(context.params.get('items'))\n    for item in items:\n        data['item'] = item\n        context.emit(data=data)", "response": "Iterate through a set of items and emit each one of them."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a sequence of numbers.", "response": "def sequence(context, data):\n    \"\"\"Generate a sequence of numbers.\n\n    It is the memorious equivalent of the xrange function, accepting the\n    ``start``, ``stop`` and ``step`` parameters.\n\n    This can run in two ways:\n    * As a single function generating all numbers in the given range.\n    * Recursively, generating numbers one by one with an optional ``delay``.\n\n    The latter mode is useful in order to generate very large sequences\n    without completely clogging up the user queue.\n\n    If an optional ``tag`` is given, each number will be emitted only once\n    across multiple runs of the crawler.\n    \"\"\"\n    number = data.get('number', context.params.get('start', 1))\n    stop = context.params.get('stop')\n    step = context.params.get('step', 1)\n    delay = context.params.get('delay')\n    prefix = context.params.get('tag')\n    while True:\n        tag = None if prefix is None else '%s:%s' % (prefix, number)\n\n        if tag is None or not context.check_tag(tag):\n            context.emit(data={'number': number})\n\n        if tag is not None:\n            context.set_tag(tag, True)\n\n        number = number + step\n        if step > 0 and number >= stop:\n            break\n        if step < 0 and number <= stop:\n            break\n\n        if delay is not None:\n            context.recurse(data={'number': number}, delay=delay)\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(self):\n        if self._file_path is not None:\n            return self._file_path\n        temp_path = self.context.work_path\n        if self._content_hash is not None:\n            self._file_path = storage.load_file(self._content_hash,\n                                                temp_path=temp_path)\n            return self._file_path\n        if self.response is not None:\n            self._file_path = random_filename(temp_path)\n            content_hash = sha1()\n            with open(self._file_path, 'wb') as fh:\n                for chunk in self.response.iter_content(chunk_size=8192):\n                    content_hash.update(chunk)\n                    fh.write(chunk)\n            self._remove_file = True\n            chash = content_hash.hexdigest()\n            self._content_hash = storage.archive_file(self._file_path,\n                                                      content_hash=chash)\n            if self.http.cache and self.ok:\n                self.context.set_tag(self.request_id, self.serialize())\n            self.retrieved_at = datetime.utcnow().isoformat()\n        return self._file_path", "response": "Lazily trigger download of the data when requested."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_key(*criteria):\n    criteria = [stringify(c) for c in criteria]\n    criteria = [c for c in criteria if c is not None]\n    if len(criteria):\n        return ':'.join(criteria)", "response": "Make a string key out of many criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_filename(path=None):\n    filename = uuid4().hex\n    if path is not None:\n        filename = os.path.join(path, filename)\n    return filename", "response": "Make a UUID - based file name which is extremely unlikely to exist already."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef box(self, bottom_left_corner, top_right_corner, paint=None, blank=False):\n        ''' creates the visual frame/box in which we place the graph '''\n        path = [\n            bottom_left_corner,\n            Point(bottom_left_corner.x, top_right_corner.y),\n            top_right_corner,\n            Point(top_right_corner.x, bottom_left_corner.y),\n            bottom_left_corner\n        ]\n\n        # use the bottom left corner as the starting point\n        last_point = bottom_left_corner\n        for idx, point in enumerate(path):\n            # skipping the first item because we use it as starting point\n            if idx != 0:\n                self.line(last_point, point, paint=paint, character=\" \" if blank else None)\n            last_point = point", "response": "Creates the visual frame of the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sample_vMF(mu, kappa, num_samples):\n    dim = len(mu)\n    result = np.zeros((num_samples, dim))\n    for nn in range(num_samples):\n        # sample offset from center (on sphere) with spread kappa\n        w = _sample_weight(kappa, dim)\n\n        # sample a point v on the unit sphere that's orthogonal to mu\n        v = _sample_orthonormal_to(mu)\n\n        # compute new point\n        result[nn, :] = v * np.sqrt(1. - w ** 2) + w * mu\n\n    return result", "response": "Generate num_samples N - dimensional samples from von Mises Fisher\n    distribution around center mu \\ in R^N with concentration kappa."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sample_orthonormal_to(mu):\n    v = np.random.randn(mu.shape[0])\n    proj_mu_v = mu * np.dot(mu, v) / np.linalg.norm(mu)\n    orthto = v - proj_mu_v\n    return orthto / np.linalg.norm(orthto)", "response": "Sample point on sphere orthogonal to mu."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the k - means for a single - lloyd cluster.", "response": "def _spherical_kmeans_single_lloyd(\n    X,\n    n_clusters,\n    sample_weight=None,\n    max_iter=300,\n    init=\"k-means++\",\n    verbose=False,\n    x_squared_norms=None,\n    random_state=None,\n    tol=1e-4,\n    precompute_distances=True,\n):\n    \"\"\"\n    Modified from sklearn.cluster.k_means_.k_means_single_lloyd.\n    \"\"\"\n    random_state = check_random_state(random_state)\n\n    sample_weight = _check_sample_weight(X, sample_weight)\n\n    best_labels, best_inertia, best_centers = None, None, None\n\n    # init\n    centers = _init_centroids(\n        X, n_clusters, init, random_state=random_state, x_squared_norms=x_squared_norms\n    )\n    if verbose:\n        print(\"Initialization complete\")\n\n    # Allocate memory to store the distances for each sample to its\n    # closer center for reallocation in case of ties\n    distances = np.zeros(shape=(X.shape[0],), dtype=X.dtype)\n\n    # iterations\n    for i in range(max_iter):\n        centers_old = centers.copy()\n\n        # labels assignment\n        # TODO: _labels_inertia should be done with cosine distance\n        #       since ||a - b|| = 2(1 - cos(a,b)) when a,b are unit normalized\n        #       this doesn't really matter.\n        labels, inertia = _labels_inertia(\n            X,\n            sample_weight,\n            x_squared_norms,\n            centers,\n            precompute_distances=precompute_distances,\n            distances=distances,\n        )\n\n        # computation of the means\n        if sp.issparse(X):\n            centers = _k_means._centers_sparse(\n                X, sample_weight, labels, n_clusters, distances\n            )\n        else:\n            centers = _k_means._centers_dense(\n                X, sample_weight, labels, n_clusters, distances\n            )\n\n        # l2-normalize centers (this is the main contibution here)\n        centers = normalize(centers)\n\n        if verbose:\n            print(\"Iteration %2d, inertia %.3f\" % (i, inertia))\n\n        if best_inertia is None or inertia < best_inertia:\n            best_labels = labels.copy()\n            best_centers = centers.copy()\n            best_inertia = inertia\n\n        center_shift_total = squared_norm(centers_old - centers)\n        if center_shift_total <= tol:\n            if verbose:\n                print(\n                    \"Converged at iteration %d: \"\n                    \"center shift %e within tolerance %e\" % (i, center_shift_total, tol)\n                )\n            break\n\n    if center_shift_total > 0:\n        # rerun E-step in case of non-convergence so that predicted labels\n        # match cluster centers\n        best_labels, best_inertia = _labels_inertia(\n            X,\n            sample_weight,\n            x_squared_norms,\n            best_centers,\n            precompute_distances=precompute_distances,\n            distances=distances,\n        )\n\n    return best_labels, best_inertia, best_centers, i + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute k - means clustering for a set of clusters.", "response": "def spherical_k_means(\n    X,\n    n_clusters,\n    sample_weight=None,\n    init=\"k-means++\",\n    n_init=10,\n    max_iter=300,\n    verbose=False,\n    tol=1e-4,\n    random_state=None,\n    copy_x=True,\n    n_jobs=1,\n    algorithm=\"auto\",\n    return_n_iter=False,\n):\n    \"\"\"Modified from sklearn.cluster.k_means_.k_means.\n    \"\"\"\n    if n_init <= 0:\n        raise ValueError(\n            \"Invalid number of initializations.\"\n            \" n_init=%d must be bigger than zero.\" % n_init\n        )\n    random_state = check_random_state(random_state)\n\n    if max_iter <= 0:\n        raise ValueError(\n            \"Number of iterations should be a positive number,\"\n            \" got %d instead\" % max_iter\n        )\n\n    best_inertia = np.infty\n    # avoid forcing order when copy_x=False\n    order = \"C\" if copy_x else None\n    X = check_array(\n        X, accept_sparse=\"csr\", dtype=[np.float64, np.float32], order=order, copy=copy_x\n    )\n    # verify that the number of samples given is larger than k\n    if _num_samples(X) < n_clusters:\n        raise ValueError(\n            \"n_samples=%d should be >= n_clusters=%d\" % (_num_samples(X), n_clusters)\n        )\n    tol = _tolerance(X, tol)\n\n    if hasattr(init, \"__array__\"):\n        init = check_array(init, dtype=X.dtype.type, order=\"C\", copy=True)\n        _validate_center_shape(X, n_clusters, init)\n\n        if n_init != 1:\n            warnings.warn(\n                \"Explicit initial center position passed: \"\n                \"performing only one init in k-means instead of n_init=%d\" % n_init,\n                RuntimeWarning,\n                stacklevel=2,\n            )\n            n_init = 1\n\n    # precompute squared norms of data points\n    x_squared_norms = row_norms(X, squared=True)\n\n    if n_jobs == 1:\n        # For a single thread, less memory is needed if we just store one set\n        # of the best results (as opposed to one set per run per thread).\n        for it in range(n_init):\n            # run a k-means once\n            labels, inertia, centers, n_iter_ = _spherical_kmeans_single_lloyd(\n                X,\n                n_clusters,\n                sample_weight,\n                max_iter=max_iter,\n                init=init,\n                verbose=verbose,\n                tol=tol,\n                x_squared_norms=x_squared_norms,\n                random_state=random_state,\n            )\n\n            # determine if these results are the best so far\n            if best_inertia is None or inertia < best_inertia:\n                best_labels = labels.copy()\n                best_centers = centers.copy()\n                best_inertia = inertia\n                best_n_iter = n_iter_\n    else:\n        # parallelisation of k-means runs\n        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n        results = Parallel(n_jobs=n_jobs, verbose=0)(\n            delayed(_spherical_kmeans_single_lloyd)(\n                X,\n                n_clusters,\n                sample_weight,\n                max_iter=max_iter,\n                init=init,\n                verbose=verbose,\n                tol=tol,\n                x_squared_norms=x_squared_norms,\n                # Change seed to ensure variety\n                random_state=seed,\n            )\n            for seed in seeds\n        )\n\n        # Get results with the lowest inertia\n        labels, inertia, centers, n_iters = zip(*results)\n        best = np.argmin(inertia)\n        best_labels = labels[best]\n        best_inertia = inertia[best]\n        best_centers = centers[best]\n        best_n_iter = n_iters[best]\n\n    if return_n_iter:\n        return best_centers, best_labels, best_inertia, best_n_iter\n    else:\n        return best_centers, best_labels, best_inertia"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing k - means clustering.", "response": "def fit(self, X, y=None, sample_weight=None):\n        \"\"\"Compute k-means clustering.\n\n        Parameters\n        ----------\n\n        X : array-like or sparse matrix, shape=(n_samples, n_features)\n\n        y : Ignored\n            not used, present here for API consistency by convention.\n\n        sample_weight : array-like, shape (n_samples,), optional\n            The weights for each observation in X. If None, all observations\n            are assigned equal weight (default: None)\n        \"\"\"\n        if self.normalize:\n            X = normalize(X)\n\n        random_state = check_random_state(self.random_state)\n\n        # TODO: add check that all data is unit-normalized\n\n        self.cluster_centers_, self.labels_, self.inertia_, self.n_iter_ = spherical_k_means(\n            X,\n            n_clusters=self.n_clusters,\n            sample_weight=sample_weight,\n            init=self.init,\n            n_init=self.n_init,\n            max_iter=self.max_iter,\n            verbose=self.verbose,\n            tol=self.tol,\n            random_state=random_state,\n            copy_x=self.copy_x,\n            n_jobs=self.n_jobs,\n            return_n_iter=True,\n        )\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing inertia with cosine distance using known labels.", "response": "def _inertia_from_labels(X, centers, labels):\n    \"\"\"Compute inertia with cosine distance using known labels.\n    \"\"\"\n    n_examples, n_features = X.shape\n    inertia = np.zeros((n_examples,))\n    for ee in range(n_examples):\n        inertia[ee] = 1 - X[ee, :].dot(centers[int(labels[ee]), :].T)\n\n    return np.sum(inertia)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes labels and inertia with cosine distance.", "response": "def _labels_inertia(X, centers):\n    \"\"\"Compute labels and inertia with cosine distance.\n    \"\"\"\n    n_examples, n_features = X.shape\n    n_clusters, n_features = centers.shape\n\n    labels = np.zeros((n_examples,))\n    inertia = np.zeros((n_examples,))\n\n    for ee in range(n_examples):\n        dists = np.zeros((n_clusters,))\n        for cc in range(n_clusters):\n            dists[cc] = 1 - X[ee, :].dot(centers[cc, :].T)\n\n        labels[ee] = np.argmin(dists)\n        inertia[ee] = dists[int(labels[ee])]\n\n    return labels, np.sum(inertia)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _vmf_log(X, kappa, mu):\n    n_examples, n_features = X.shape\n    return np.log(_vmf_normalize(kappa, n_features) * np.exp(kappa * X.dot(mu).T))", "response": "Computes log of vMF."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _vmf_normalize(kappa, dim):\n    num = np.power(kappa, dim / 2. - 1.)\n\n    if dim / 2. - 1. < 1e-15:\n        denom = np.power(2. * np.pi, dim / 2.) * i0(kappa)\n    else:\n        denom = np.power(2. * np.pi, dim / 2.) * iv(dim / 2. - 1., kappa)\n\n    if np.isinf(num):\n        raise ValueError(\"VMF scaling numerator was inf.\")\n\n    if np.isinf(denom):\n        raise ValueError(\"VMF scaling denominator was inf.\")\n\n    if np.abs(denom) < 1e-15:\n        raise ValueError(\"VMF scaling denominator was 0.\")\n\n    return num / denom", "response": "Compute normalization constant using built - in numpy - scipy Bessel\n    approximations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _log_H_asymptotic(nu, kappa):\n    beta = np.sqrt((nu + 0.5) ** 2)\n    kappa_l = np.min([kappa, np.sqrt((3. * nu + 11. / 2.) * (nu + 3. / 2.))])\n    return _S(kappa, nu + 0.5, beta) + (\n        _S(kappa_l, nu, nu + 2.) - _S(kappa_l, nu + 0.5, beta)\n    )", "response": "Compute the Amos - type upper bound asymptotic approximation on H where H is a constant and nu is the number of nu^kappa."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the antiderivative of the Amos - type bound G on the modified Bessel function ratio.", "response": "def _S(kappa, alpha, beta):\n    \"\"\"Compute the antiderivative of the Amos-type bound G on the modified\n    Bessel function ratio.\n\n    Note:  Handles scalar kappa, alpha, and beta only.\n\n    See \"S <-\" in movMF.R and utility function implementation notes from\n    https://cran.r-project.org/web/packages/movMF/index.html\n    \"\"\"\n    kappa = 1. * np.abs(kappa)\n    alpha = 1. * alpha\n    beta = 1. * np.abs(beta)\n    a_plus_b = alpha + beta\n    u = np.sqrt(kappa ** 2 + beta ** 2)\n    if alpha == 0:\n        alpha_scale = 0\n    else:\n        alpha_scale = alpha * np.log((alpha + u) / a_plus_b)\n\n    return u - beta - alpha_scale"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _vmf_log_asymptotic(X, kappa, mu):\n    n_examples, n_features = X.shape\n    log_vfm = kappa * X.dot(mu).T + -_log_H_asymptotic(n_features / 2. - 1., kappa)\n\n    return log_vfm", "response": "Compute log of the log of the symmetry of the vector X."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the unit norm centers for the given set of clusters.", "response": "def _init_unit_centers(X, n_clusters, random_state, init):\n    \"\"\"Initializes unit norm centers.\n\n    Parameters\n    ----------\n    X : array-like or sparse matrix, shape=(n_samples, n_features)\n\n    n_clusters : int, optional, default: 8\n        The number of clusters to form as well as the number of\n        centroids to generate.\n\n    random_state : integer or numpy.RandomState, optional\n        The generator used to initialize the centers. If an integer is\n        given, it fixes the seed. Defaults to the global numpy random\n        number generator.\n\n    init:  (string) one of\n        k-means++ : uses sklearn k-means++ initialization algorithm\n        spherical-k-means : use centroids from one pass of spherical k-means\n        random : random unit norm vectors\n        random-orthonormal : random orthonormal vectors\n        If an ndarray is passed, it should be of shape (n_clusters, n_features)\n        and gives the initial centers.\n    \"\"\"\n    n_examples, n_features = np.shape(X)\n    if isinstance(init, np.ndarray):\n        n_init_clusters, n_init_features = init.shape\n        assert n_init_clusters == n_clusters\n        assert n_init_features == n_features\n\n        # ensure unit normed centers\n        centers = init\n        for cc in range(n_clusters):\n            centers[cc, :] = centers[cc, :] / np.linalg.norm(centers[cc, :])\n\n        return centers\n\n    elif init == \"spherical-k-means\":\n        labels, inertia, centers, iters = spherical_kmeans._spherical_kmeans_single_lloyd(\n            X, n_clusters, x_squared_norms=np.ones((n_examples,)), init=\"k-means++\"\n        )\n\n        return centers\n\n    elif init == \"random\":\n        centers = np.random.randn(n_clusters, n_features)\n        for cc in range(n_clusters):\n            centers[cc, :] = centers[cc, :] / np.linalg.norm(centers[cc, :])\n\n        return centers\n\n    elif init == \"k-means++\":\n        centers = _init_centroids(\n            X,\n            n_clusters,\n            \"k-means++\",\n            random_state=random_state,\n            x_squared_norms=np.ones((n_examples,)),\n        )\n\n        for cc in range(n_clusters):\n            centers[cc, :] = centers[cc, :] / np.linalg.norm(centers[cc, :])\n\n        return centers\n\n    elif init == \"random-orthonormal\":\n        centers = np.random.randn(n_clusters, n_features)\n        q, r = np.linalg.qr(centers.T, mode=\"reduced\")\n\n        return q.T\n\n    elif init == \"random-class\":\n        centers = np.zeros((n_clusters, n_features))\n        for cc in range(n_clusters):\n            while np.linalg.norm(centers[cc, :]) == 0:\n                labels = np.random.randint(0, n_clusters, n_examples)\n                centers[cc, :] = X[labels == cc, :].sum(axis=0)\n\n        for cc in range(n_clusters):\n            centers[cc, :] = centers[cc, :] / np.linalg.norm(centers[cc, :])\n\n        return centers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _expectation(X, centers, weights, concentrations, posterior_type=\"soft\"):\n    n_examples, n_features = np.shape(X)\n    n_clusters, _ = centers.shape\n\n    if n_features <= 50:  # works up to about 50 before numrically unstable\n        vmf_f = _vmf_log\n    else:\n        vmf_f = _vmf_log_asymptotic\n\n    f_log = np.zeros((n_clusters, n_examples))\n    for cc in range(n_clusters):\n        f_log[cc, :] = vmf_f(X, concentrations[cc], centers[cc, :])\n\n    posterior = np.zeros((n_clusters, n_examples))\n    if posterior_type == \"soft\":\n        weights_log = np.log(weights)\n        posterior = np.tile(weights_log.T, (n_examples, 1)).T + f_log\n        for ee in range(n_examples):\n            posterior[:, ee] = np.exp(posterior[:, ee] - logsumexp(posterior[:, ee]))\n\n    elif posterior_type == \"hard\":\n        weights_log = np.log(weights)\n        weighted_f_log = np.tile(weights_log.T, (n_examples, 1)).T + f_log\n        for ee in range(n_examples):\n            posterior[np.argmax(weighted_f_log[:, ee]), ee] = 1.0\n\n    return posterior", "response": "Compute the log - likelihood of each datapoint being in each cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nestimate new centers weights and concentrations from the posterior matrix.", "response": "def _maximization(X, posterior, force_weights=None):\n    \"\"\"Estimate new centers, weights, and concentrations from\n\n    Parameters\n    ----------\n    posterior : array, [n_centers, n_examples]\n        The posterior matrix from the expectation step.\n\n    force_weights : None or array, [n_centers, ]\n        If None is passed, will estimate weights.\n        If an array is passed, will use instead of estimating.\n\n    Returns\n    ----------\n    centers (mu) : array, [n_centers x n_features]\n    weights (alpha) : array, [n_centers, ] (alpha)\n    concentrations (kappa) : array, [n_centers, ]\n    \"\"\"\n    n_examples, n_features = X.shape\n    n_clusters, n_examples = posterior.shape\n    concentrations = np.zeros((n_clusters,))\n    centers = np.zeros((n_clusters, n_features))\n    if force_weights is None:\n        weights = np.zeros((n_clusters,))\n\n    for cc in range(n_clusters):\n        # update weights (alpha)\n        if force_weights is None:\n            weights[cc] = np.mean(posterior[cc, :])\n        else:\n            weights = force_weights\n\n        # update centers (mu)\n        X_scaled = X.copy()\n        if sp.issparse(X):\n            X_scaled.data *= posterior[cc, :].repeat(np.diff(X_scaled.indptr))\n        else:\n            for ee in range(n_examples):\n                X_scaled[ee, :] *= posterior[cc, ee]\n\n        centers[cc, :] = X_scaled.sum(axis=0)\n\n        # normalize centers\n        center_norm = np.linalg.norm(centers[cc, :])\n        if center_norm > 1e-8:\n            centers[cc, :] = centers[cc, :] / center_norm\n\n        # update concentration (kappa) [TODO: add other kappa approximations]\n        rbar = center_norm / (n_examples * weights[cc])\n        concentrations[cc] = rbar * n_features - np.power(rbar, 3.)\n        if np.abs(rbar - 1.0) < 1e-10:\n            concentrations[cc] = MAX_CONTENTRATION\n        else:\n            concentrations[cc] /= 1. - np.power(rbar, 2.)\n\n        # let python know we can free this (good for large dense X)\n        del X_scaled\n\n    return centers, weights, concentrations"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap for parallelization of _movMF and running n_init times.", "response": "def movMF(\n    X,\n    n_clusters,\n    posterior_type=\"soft\",\n    force_weights=None,\n    n_init=10,\n    n_jobs=1,\n    max_iter=300,\n    verbose=False,\n    init=\"random-class\",\n    random_state=None,\n    tol=1e-6,\n    copy_x=True,\n):\n    \"\"\"Wrapper for parallelization of _movMF and running n_init times.\n    \"\"\"\n    if n_init <= 0:\n        raise ValueError(\n            \"Invalid number of initializations.\"\n            \" n_init=%d must be bigger than zero.\" % n_init\n        )\n    random_state = check_random_state(random_state)\n\n    if max_iter <= 0:\n        raise ValueError(\n            \"Number of iterations should be a positive number,\"\n            \" got %d instead\" % max_iter\n        )\n\n    best_inertia = np.infty\n    X = as_float_array(X, copy=copy_x)\n    tol = _tolerance(X, tol)\n\n    if hasattr(init, \"__array__\"):\n        init = check_array(init, dtype=X.dtype.type, copy=True)\n        _validate_center_shape(X, n_clusters, init)\n\n        if n_init != 1:\n            warnings.warn(\n                \"Explicit initial center position passed: \"\n                \"performing only one init in k-means instead of n_init=%d\" % n_init,\n                RuntimeWarning,\n                stacklevel=2,\n            )\n            n_init = 1\n\n    # defaults\n    best_centers = None\n    best_labels = None\n    best_weights = None\n    best_concentrations = None\n    best_posterior = None\n    best_inertia = None\n\n    if n_jobs == 1:\n        # For a single thread, less memory is needed if we just store one set\n        # of the best results (as opposed to one set per run per thread).\n        for it in range(n_init):\n            # cluster on the sphere\n            (centers, weights, concentrations, posterior, labels, inertia) = _movMF(\n                X,\n                n_clusters,\n                posterior_type=posterior_type,\n                force_weights=force_weights,\n                max_iter=max_iter,\n                verbose=verbose,\n                init=init,\n                random_state=random_state,\n                tol=tol,\n            )\n\n            # determine if these results are the best so far\n            if best_inertia is None or inertia < best_inertia:\n                best_centers = centers.copy()\n                best_labels = labels.copy()\n                best_weights = weights.copy()\n                best_concentrations = concentrations.copy()\n                best_posterior = posterior.copy()\n                best_inertia = inertia\n    else:\n        # parallelisation of movMF runs\n        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n        results = Parallel(n_jobs=n_jobs, verbose=0)(\n            delayed(_movMF)(\n                X,\n                n_clusters,\n                posterior_type=posterior_type,\n                force_weights=force_weights,\n                max_iter=max_iter,\n                verbose=verbose,\n                init=init,\n                random_state=random_state,\n                tol=tol,\n            )\n            for seed in seeds\n        )\n\n        # Get results with the lowest inertia\n        centers, weights, concentrations, posteriors, labels, inertia = zip(*results)\n        best = np.argmin(inertia)\n        best_labels = labels[best]\n        best_inertia = inertia[best]\n        best_centers = centers[best]\n        best_concentrations = concentrations[best]\n        best_posterior = posteriors[best]\n        best_weights = weights[best]\n\n    return (\n        best_centers,\n        best_labels,\n        best_inertia,\n        best_weights,\n        best_concentrations,\n        best_posterior,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_fit_data(self, X):\n        X = check_array(X, accept_sparse=\"csr\", dtype=[np.float64, np.float32])\n        n_samples, n_features = X.shape\n        if X.shape[0] < self.n_clusters:\n            raise ValueError(\n                \"n_samples=%d should be >= n_clusters=%d\"\n                % (X.shape[0], self.n_clusters)\n            )\n\n        for ee in range(n_samples):\n            if sp.issparse(X):\n                n = sp.linalg.norm(X[ee, :])\n            else:\n                n = np.linalg.norm(X[ee, :])\n\n            if np.abs(n - 1.) > 1e-4:\n                raise ValueError(\"Data l2-norm must be 1, found {}\".format(n))\n\n        return X", "response": "Verify that the number of samples given is larger than k"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(self, X, y=None):\n        if self.normalize:\n            X = normalize(X)\n\n        self._check_force_weights()\n        random_state = check_random_state(self.random_state)\n        X = self._check_fit_data(X)\n\n        (\n            self.cluster_centers_,\n            self.labels_,\n            self.inertia_,\n            self.weights_,\n            self.concentrations_,\n            self.posterior_,\n        ) = movMF(\n            X,\n            self.n_clusters,\n            posterior_type=self.posterior_type,\n            force_weights=self.force_weights,\n            n_init=self.n_init,\n            n_jobs=self.n_jobs,\n            max_iter=self.max_iter,\n            verbose=self.verbose,\n            init=self.init,\n            random_state=random_state,\n            tol=self.tol,\n            copy_x=self.copy_x,\n        )\n\n        return self", "response": "Compute mixture of von Mises Fisher clustering."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform(self, X, y=None):\n        if self.normalize:\n            X = normalize(X)\n\n        check_is_fitted(self, \"cluster_centers_\")\n        X = self._check_test_data(X)\n        return self._transform(X)", "response": "Transform X to a cluster - distance space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npredict the closest cluster each sample in X belongs to.", "response": "def predict(self, X):\n        \"\"\"Predict the closest cluster each sample in X belongs to.\n        In the vector quantization literature, `cluster_centers_` is called\n        the code book and each value returned by `predict` is the index of\n        the closest code in the code book.\n\n        Note:  Does not check that each point is on the sphere.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n            New data to predict.\n\n        Returns\n        -------\n        labels : array, shape [n_samples,]\n            Index of the cluster each sample belongs to.\n        \"\"\"\n        if self.normalize:\n            X = normalize(X)\n\n        check_is_fitted(self, \"cluster_centers_\")\n\n        X = self._check_test_data(X)\n        return _labels_inertia(X, self.cluster_centers_)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef score(self, X, y=None):\n        if self.normalize:\n            X = normalize(X)\n\n        check_is_fitted(self, \"cluster_centers_\")\n        X = self._check_test_data(X)\n        return -_labels_inertia(X, self.cluster_centers_)[1]", "response": "Inertia score of the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the log - likelihood between the covariance and precision.", "response": "def log_likelihood(covariance, precision):\n    \"\"\"Computes the log-likelihood between the covariance and precision\n    estimate.\n\n    Parameters\n    ----------\n    covariance : 2D ndarray (n_features, n_features)\n        Maximum Likelihood Estimator of covariance\n\n    precision : 2D ndarray (n_features, n_features)\n        The precision matrix of the covariance model to be tested\n\n    Returns\n    -------\n    log-likelihood\n    \"\"\"\n    assert covariance.shape == precision.shape\n    dim, _ = precision.shape\n    log_likelihood_ = (\n        -np.sum(covariance * precision)\n        + fast_logdet(precision)\n        - dim * np.log(2 * np.pi)\n    )\n    log_likelihood_ /= 2.\n    return log_likelihood_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the KL divergence between precision estimate and reference covariance.", "response": "def kl_loss(covariance, precision):\n    \"\"\"Computes the KL divergence between precision estimate and\n    reference covariance.\n\n    The loss is computed as:\n\n        Trace(Theta_1 * Sigma_0) - log(Theta_0 * Sigma_1) - dim(Sigma)\n\n    Parameters\n    ----------\n    covariance : 2D ndarray (n_features, n_features)\n        Maximum Likelihood Estimator of covariance\n\n    precision : 2D ndarray (n_features, n_features)\n        The precision matrix of the covariance model to be tested\n\n    Returns\n    -------\n    KL-divergence\n    \"\"\"\n    assert covariance.shape == precision.shape\n    dim, _ = precision.shape\n    logdet_p_dot_c = fast_logdet(np.dot(precision, covariance))\n    return 0.5 * (np.sum(precision * covariance) - logdet_p_dot_c - dim)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quadratic_loss(covariance, precision):\n    assert covariance.shape == precision.shape\n    dim, _ = precision.shape\n    return np.trace((np.dot(covariance, precision) - np.eye(dim)) ** 2)", "response": "Computes the quadratic loss of a single node in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending Bayesian Information Criteria for model selection. When using path mode, use this as an alternative to cross-validation for finding lambda. See: \"Extended Bayesian Information Criteria for Gaussian Graphical Models\" R. Foygel and M. Drton, NIPS 2010 Parameters ---------- covariance : 2D ndarray (n_features, n_features) Maximum Likelihood Estimator of covariance (sample covariance) precision : 2D ndarray (n_features, n_features) The precision matrix of the model to be tested n_samples : int Number of examples. n_features : int Dimension of an example. lam: (float) Threshold value for precision matrix. This should be lambda scaling used to obtain this estimate. gamma : (float) \\in (0, 1) Choice of gamma=0 leads to classical BIC Positive gamma leads to stronger penalization of large graphs. Returns ------- ebic score (float). Caller should minimized this score.", "response": "def ebic(covariance, precision, n_samples, n_features, gamma=0):\n    \"\"\"\n    Extended Bayesian Information Criteria for model selection.\n\n    When using path mode, use this as an alternative to cross-validation for\n    finding lambda.\n\n    See:\n        \"Extended Bayesian Information Criteria for Gaussian Graphical Models\"\n        R. Foygel and M. Drton, NIPS 2010\n\n    Parameters\n    ----------\n    covariance : 2D ndarray (n_features, n_features)\n        Maximum Likelihood Estimator of covariance (sample covariance)\n\n    precision : 2D ndarray (n_features, n_features)\n        The precision matrix of the model to be tested\n\n    n_samples :  int\n        Number of examples.\n\n    n_features : int\n        Dimension of an example.\n\n    lam: (float)\n        Threshold value for precision matrix. This should be lambda scaling\n        used to obtain this estimate.\n\n    gamma : (float) \\in (0, 1)\n        Choice of gamma=0 leads to classical BIC\n        Positive gamma leads to stronger penalization of large graphs.\n\n    Returns\n    -------\n    ebic score (float).  Caller should minimized this score.\n    \"\"\"\n    l_theta = -np.sum(covariance * precision) + fast_logdet(precision)\n    l_theta *= n_features / 2.\n\n    # is something goes wrong with fast_logdet, return large value\n    if np.isinf(l_theta) or np.isnan(l_theta):\n        return 1e10\n\n    mask = np.abs(precision.flat) > np.finfo(precision.dtype).eps\n    precision_nnz = (np.sum(mask) - n_features) / 2.0  # lower off diagonal tri\n\n    return (\n        -2.0 * l_theta\n        + precision_nnz * np.log(n_samples)\n        + 4.0 * precision_nnz * np.log(n_features) * gamma\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lattice(prng, n_features, alpha, random_sign=False, low=0.3, high=0.7):\n    degree = int(1 + np.round(alpha * n_features / 2.))\n\n    if random_sign:\n        sign_row = -1.0 * np.ones(degree) + 2 * (\n            prng.uniform(low=0, high=1, size=degree) > .5\n        )\n    else:\n        sign_row = -1.0 * np.ones(degree)\n\n    # in the *very unlikely* event that we draw a bad row that sums to zero\n    # (which is only possible when random_sign=True), we try again up to\n    # MAX_ATTEMPTS=5 times.  If we are still unable to draw a good set of\n    # values something is probably wrong and we raise.\n    MAX_ATTEMPTS = 5\n    attempt = 0\n    row = np.zeros((n_features,))\n    while np.sum(row) == 0 and attempt < MAX_ATTEMPTS:\n        row = np.zeros((n_features,))\n        row[1 : 1 + degree] = sign_row * prng.uniform(low=low, high=high, size=degree)\n        attempt += 1\n\n    if np.sum(row) == 0:\n        raise Exception(\"InvalidLattice\", \"Rows sum to 0.\")\n        return\n\n    # sum-normalize and keep signs\n    row /= np.abs(np.sum(row))\n\n    return sp.linalg.toeplitz(c=row, r=row)", "response": "Returns the adjacency matrix for a single site."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef blocks(prng, block, n_blocks=2, chain_blocks=True):\n    n_block_features, _ = block.shape\n    n_features = n_block_features * n_blocks\n    adjacency = np.zeros((n_features, n_features))\n\n    dep_groups = np.eye(n_blocks)\n    if chain_blocks:\n        chain_alpha = np.round(0.01 + 0.5 / n_blocks, 2)\n        chain_groups = lattice(prng, n_blocks, chain_alpha, random_sign=False)\n        chain_groups *= -0.1\n        dep_groups += chain_groups\n\n    adjacency = np.kron(dep_groups, block)\n    adjacency[np.where(np.eye(n_features))] = 0\n    return adjacency", "response": "Replicates block matrix n_blocks times diagonally to create a\n    square matrix of size n_blocks along the diagonal."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes matrix unweighted diagonally dominant using the Laplacian.", "response": "def _to_diagonally_dominant(mat):\n    \"\"\"Make matrix unweighted diagonally dominant using the Laplacian.\"\"\"\n    mat += np.diag(np.sum(mat != 0, axis=1) + 0.01)\n    return mat"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_diagonally_dominant_weighted(mat):\n    mat += np.diag(np.sum(np.abs(mat), axis=1) + 0.01)\n    return mat", "response": "Make matrix weighted diagonally dominant using the Laplacian."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new graph with the given number of features and the given alpha.", "response": "def create(self, n_features, alpha):\n        \"\"\"Build a new graph with block structure.\n\n        Parameters\n        -----------\n        n_features : int\n\n        alpha : float (0,1)\n            The complexity / sparsity factor for each graph type.\n\n        Returns\n        -----------\n        (n_features, n_features) matrices: covariance, precision, adjacency\n        \"\"\"\n        n_block_features = int(np.floor(1. * n_features / self.n_blocks))\n        if n_block_features * self.n_blocks != n_features:\n            raise ValueError(\n                (\n                    \"Error: n_features {} not divisible by n_blocks {}.\"\n                    \"Use n_features = n_blocks * int\"\n                ).format(n_features, self.n_blocks)\n            )\n            return\n\n        block_adj = self.prototype_adjacency(n_block_features, alpha)\n        adjacency = blocks(\n            self.prng, block_adj, n_blocks=self.n_blocks, chain_blocks=self.chain_blocks\n        )\n\n        precision = self.to_precision(adjacency)\n        covariance = self.to_covariance(precision)\n        return covariance, precision, adjacency"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the change in precision coefficients as a function of changing lambda and l1 - norm.", "response": "def trace_plot(precisions, path, n_edges=20, ground_truth=None, edges=[]):\n    \"\"\"Plot the change in precision (or covariance) coefficients as a function\n    of changing lambda and l1-norm.  Always ignores diagonals.\n\n    Parameters\n    -----------\n    precisions : array of len(path) 2D ndarray, shape (n_features, n_features)\n        This is either precision_ or covariance_ from an InverseCovariance\n        estimator in path mode, or a list of results for individual runs of\n        the GraphLasso.\n\n    path :  array of floats (descending)\n        This is path of lambdas explored.\n\n    n_edges :  int (default=20)\n        Max number of edges to plot for each precision matrix along the path.\n        Only plots the maximum magnitude values (evaluating the last precision\n        matrix).\n\n    ground_truth : 2D ndarray, shape (n_features, n_features) (default=None)\n        If not None, plot the top n_edges/2 false positive and top n_edges/2\n        false negative indices when compared to ground_truth.\n\n    edges : list (default=[])\n        If not empty, use edges to determine which indicies of each precision\n        matrix to track.  Should be arranged to index precisions[0].flat.\n\n        If non-empty, n_edges and ground_truth will be ignored.\n    \"\"\"\n    _check_path(path)\n    assert len(path) == len(precisions)\n    assert len(precisions) > 0\n\n    path = np.array(path)\n    dim, _ = precisions[0].shape\n\n    # determine which indices to track\n    if not edges:\n        base_precision = np.copy(precisions[-1])\n        base_precision[np.triu_indices(base_precision.shape[0])] = 0\n\n        if ground_truth is None:\n            # top n_edges strongest coefficients\n            edges = np.argsort(np.abs(base_precision.flat))[::-1][:n_edges]\n        else:\n            # top n_edges/2 false positives and negatives compared to truth\n            assert ground_truth.shape == precisions[0].shape\n            masked_gt = np.copy(ground_truth)\n            masked_gt[np.triu_indices(ground_truth.shape[0])] = 0\n\n            intersection = np.intersect1d(\n                np.nonzero(base_precision.flat)[0], np.nonzero(masked_gt.flat)[0]\n            )\n\n            # false positives\n            fp_precision = np.copy(base_precision)\n            fp_precision.flat[intersection] = 0\n            fp_edges = np.argsort(np.abs(fp_precision.flat))[::-1][: n_edges / 2]\n\n            # false negatives\n            fn_precision = np.copy(masked_gt)\n            fn_precision.flat[intersection] = 0\n            fn_edges = np.argsort(np.abs(fn_precision.flat))[::-1][: n_edges / 2]\n\n            edges = list(fp_edges) + list(fn_edges)\n\n    assert len(edges) < len(precisions[0].flat)\n    assert np.max(edges) < len(precisions[0].flat)\n    assert np.min(edges) >= 0\n\n    # reshape data a bit:\n    # flatten each matrix into a column (so that coeffs are examples)\n    # compute l1-norm of each column\n    l1_norms = []\n    coeffs = np.zeros((dim ** 2, len(precisions)))\n    for ridx, result in enumerate(precisions):\n        coeffs[edges, ridx] = result.flat[edges]\n        l1_norms.append(np.linalg.norm(coeffs[:, ridx]))\n\n    # remove any zero rows\n    coeffs = coeffs[np.linalg.norm(coeffs, axis=1) > 1e-10, :]\n\n    plt.figure()\n\n    # show coefficients as a function of lambda\n    plt.subplot(1, 2, 1)\n    for result in precisions:\n        plt.plot(l1_norms, coeffs.T, lw=1)\n\n    plt.xlim([np.min(l1_norms), np.max(l1_norms)])\n    plt.ylabel(\"Coefficients\")\n    plt.xlabel(\"l1 Norm\")\n\n    # show coefficients as a function of lambda\n    log_path = np.log(path)\n    plt.subplot(1, 2, 2)\n    for result in precisions:\n        plt.plot(log_path, coeffs.T, lw=1)\n\n    plt.xlim([np.min(log_path), np.max(log_path)])\n    plt.ylabel(\"Coefficients\")\n    plt.xlabel(\"log-Lambda\")\n\n    plt.show()\n    r_input(\"Press any key to continue.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, X, y=None):\n        # default to QuicGraphicalLassoCV\n        estimator = self.estimator or QuicGraphicalLassoCV()\n\n        self.lam_ = None\n        self.estimator_ = None\n\n        X = check_array(X, ensure_min_features=2, estimator=self)\n        X = as_float_array(X, copy=False, force_all_finite=False)\n\n        n_samples_, n_features_ = X.shape\n\n        # perform first estimate\n        estimator.fit(X)\n\n        if self.method == \"binary\":\n            # generate weights\n            self.lam_ = self._binary_weights(estimator)\n\n            # perform second step adaptive estimate\n            self.estimator_ = QuicGraphicalLasso(\n                lam=self.lam_ * estimator.lam_,\n                mode=\"default\",\n                init_method=\"cov\",\n                auto_scale=False,\n            )\n            self.estimator_.fit(X)\n\n        elif self.method == \"inverse_squared\":\n            self.lam_ = self._inverse_squared_weights(estimator)\n\n            # perform second step adaptive estimate\n            self.estimator_ = QuicGraphicalLassoCV(\n                lam=self.lam_ * self.estimator.lam_, auto_scale=False\n            )\n            self.estimator_.fit(X)\n\n        elif self.method == \"inverse\":\n            self.lam_ = self._inverse_weights(estimator)\n\n            # perform second step adaptive estimate\n            self.estimator_ = QuicGraphicalLassoCV(\n                lam=self.lam_ * estimator.lam_, auto_scale=False\n            )\n            self.estimator_.fit(X)\n\n        else:\n            raise NotImplementedError(\n                (\n                    \"Only method='binary', 'inverse_squared', or\",\n                    \"'inverse' have been implemented.\",\n                )\n            )\n\n        self.is_fitted_ = True\n        return self", "response": "Estimate the precision using an adaptive maximum likelihood estimator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a multivariate normal sample from the graph defined by cov.", "response": "def _sample_mvn(n_samples, cov, prng):\n    \"\"\"Draw a multivariate normal sample from the graph defined by cov.\n\n    Parameters\n    -----------\n    n_samples : int\n\n    cov : matrix of shape (n_features, n_features)\n        Covariance matrix of the graph.\n\n    prng : np.random.RandomState instance.\n    \"\"\"\n    n_features, _ = cov.shape\n    return prng.multivariate_normal(np.zeros(n_features), cov, size=n_samples)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a symmetric random matrix with zeros along the diagonal.", "response": "def _fully_random_weights(n_features, lam_scale, prng):\n    \"\"\"Generate a symmetric random matrix with zeros along the diagonal.\"\"\"\n    weights = np.zeros((n_features, n_features))\n    n_off_diag = int((n_features ** 2 - n_features) / 2)\n    weights[np.triu_indices(n_features, k=1)] = 0.1 * lam_scale * prng.randn(\n        n_off_diag\n    ) + (0.25 * lam_scale)\n    weights[weights < 0] = 0\n    weights = weights + weights.T\n    return weights"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring random weight matrix is valid.", "response": "def _fix_weights(weight_fun, *args):\n    \"\"\"Ensure random weight matrix is valid.\n\n    TODO:  The diagonally dominant tuning currently doesn't make sense.\n           Our weight matrix has zeros along the diagonal, so multiplying by\n           a diagonal matrix results in a zero-matrix.\n    \"\"\"\n    weights = weight_fun(*args)\n\n    # TODO: fix this\n    # disable checks for now\n    return weights\n\n    # if positive semidefinite, then we're good as is\n    if _check_psd(weights):\n        return weights\n\n    # make diagonally dominant\n    off_diag_sums = np.sum(weights, axis=1)  # NOTE: assumes diag is zero\n    mod_mat = np.linalg.inv(np.sqrt(np.diag(off_diag_sums)))\n    return np.dot(mod_mat, weights, mod_mat)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap function for fitting a single model average trial.", "response": "def _fit(\n    indexed_params,\n    penalization,\n    lam,\n    lam_perturb,\n    lam_scale_,\n    estimator,\n    penalty_name,\n    subsample,\n    bootstrap,\n    prng,\n    X=None,\n):\n    \"\"\"Wrapper function outside of instance for fitting a single model average\n    trial.\n\n    If X is None, then we assume we are using a broadcast spark object. Else,\n    we expect X to get passed into this function.\n    \"\"\"\n    index = indexed_params\n\n    if isinstance(X, np.ndarray):\n        local_X = X\n    else:\n        local_X = X.value\n\n    n_samples, n_features = local_X.shape\n\n    prec_is_real = False\n    while not prec_is_real:\n        boot_lam = None\n        if penalization == \"subsampling\":\n            pass\n        elif penalization == \"random\":\n            boot_lam = _fix_weights(_random_weights, n_features, lam, lam_perturb, prng)\n        elif penalization == \"fully-random\":\n            boot_lam = _fix_weights(_fully_random_weights, n_features, lam_scale_, prng)\n        else:\n            raise NotImplementedError(\n                (\n                    \"Only penalization = 'subsampling', \"\n                    \"'random', and 'fully-random' have \"\n                    \"been implemented. Found {}.\".format(penalization)\n                )\n            )\n\n        # new instance of estimator\n        new_estimator = clone(estimator)\n        if boot_lam is not None:\n            new_estimator.set_params(**{penalty_name: boot_lam})\n\n        # fit estimator\n        num_subsamples = int(subsample * n_samples)\n        rp = bootstrap(n_samples, num_subsamples, prng)\n        new_estimator.fit(local_X[rp, :])\n\n        # check that new_estimator.precision_ is real\n        # if not, skip this boot_lam and try again\n        if isinstance(new_estimator.precision_, list):\n            prec_real_bools = []\n            for prec in new_estimator.precision_:\n                prec_real_bools.append(np.all(np.isreal(prec)))\n\n            prec_is_real = np.all(np.array(prec_real_bools) is True)\n\n        elif isinstance(new_estimator.precision_, np.ndarray):\n            prec_is_real = np.all(np.isreal(new_estimator.precision_))\n\n        else:\n            raise ValueError(\"Estimator returned invalid precision_.\")\n\n    return index, (boot_lam, rp, new_estimator)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _spark_map(fun, indexed_param_grid, sc, seed, X_bc):\n\n    def _wrap_random_state(split_index, partition):\n        prng = np.random.RandomState(seed + split_index)\n        yield map(partial(fun, prng=prng, X=X_bc), partition)\n\n    par_param_grid = sc.parallelize(indexed_param_grid)\n    indexed_results = par_param_grid.mapPartitionsWithIndex(\n        _wrap_random_state\n    ).collect()\n    return [item for sublist in indexed_results for item in sublist]", "response": "This function will be used to map a function over a Spark Spark"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, X, y=None):\n        # default to QuicGraphicalLasso\n        estimator = self.estimator or QuicGraphicalLasso()\n\n        if self.penalization != \"subsampling\" and not hasattr(\n            estimator, self.penalty_name\n        ):\n            raise ValueError(\n                (\n                    \"Must specify valid penalty for \"\n                    \"estimator: {}.\".format(self.penalty_name)\n                )\n            )\n\n        self.proportion_ = None\n        self.support_ = None\n        self.lam_ = None\n        self.lam_scale_ = None\n        self.estimators_ = []\n        self.lams_ = []\n        self.subsets_ = []\n\n        X = check_array(X, ensure_min_features=2, estimator=self)\n        X = as_float_array(X, copy=False, force_all_finite=False)\n\n        n_samples_, n_features_ = X.shape\n        _, self.lam_scale_ = _init_coefs(X, method=self.init_method)\n\n        fit_fun = partial(\n            _fit,\n            penalization=self.penalization,\n            lam=self.lam,\n            lam_perturb=self.lam_perturb,\n            lam_scale_=self.lam_scale_,\n            estimator=estimator,\n            penalty_name=self.penalty_name,\n            subsample=self.subsample,\n            bootstrap=self.bootstrap,\n        )\n        indexed_param_grid = [(nn,) for nn in range(self.n_trials)]\n\n        if self.sc is None:\n            results = _cpu_map(\n                partial(fit_fun, X=X, prng=self.prng),\n                indexed_param_grid,\n                n_jobs=self.n_jobs,\n            )\n        else:\n            X_bc = self.sc.broadcast(X)\n            results = _spark_map(fit_fun, indexed_param_grid, self.sc, self.seed, X_bc)\n            X_bc.unpersist()\n\n        self.estimators_ = [e for r, (l, s, e) in results]\n        self.subsets_ = [s for r, (l, s, e) in results]\n        self.lams_ = [l for r, (l, s, e) in results]\n\n        # reduce\n        self.lam_ = 0.0\n        self.proportion_ = np.zeros((n_features_, n_features_))\n        for new_estimator in self.estimators_:\n            # update proportions\n            if isinstance(new_estimator.precision_, list):\n                for prec in new_estimator.precision_:\n                    self.proportion_[np.nonzero(prec)] += 1.\n\n            elif isinstance(new_estimator.precision_, np.ndarray):\n                self.proportion_[np.nonzero(new_estimator.precision_)] += 1.\n\n            else:\n                raise ValueError(\"Estimator returned invalid precision_.\")\n\n            # currently, dont estimate self.lam_ if penalty_name is different\n            if self.penalty_name == \"lam\":\n                self.lam_ += np.mean(new_estimator.lam_.flat)\n\n        # estimate support locations\n        threshold = self.support_thresh * self.n_trials\n        self.support_ = np.zeros(self.proportion_.shape)\n        self.support_[self.proportion_ > threshold] = 1.0\n\n        self.lam_ /= self.n_trials\n        if self.normalize:\n            self.proportion_ /= self.n_trials\n\n        return self", "response": "Learn a model averaged proportion matrix for X."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adaptive_graph_lasso(X, model_selector, method):\n    metric = \"log_likelihood\"\n    print(\"Adaptive {} with:\".format(model_selector))\n    print(\"   adaptive-method: {}\".format(method))\n    if model_selector == \"QuicGraphicalLassoCV\":\n        print(\"   metric: {}\".format(metric))\n        model = AdaptiveGraphicalLasso(\n            estimator=QuicGraphicalLassoCV(\n                cv=2,  # cant deal w more folds at small size\n                n_refinements=6,\n                init_method=\"cov\",\n                score_metric=metric,\n                sc=spark.sparkContext,  # NOQA\n            ),\n            method=method,\n        )\n\n    elif model_selector == \"QuicGraphicalLassoEBIC\":\n        model = AdaptiveGraphicalLasso(\n            estimator=QuicGraphicalLassoEBIC(), method=method\n        )\n    model.fit(X)\n    lam_norm_ = np.linalg.norm(model.estimator_.lam_)\n    print(\"   ||lam_||_2: {}\".format(lam_norm_))\n    return model.estimator_.covariance_, model.estimator_.precision_, lam_norm_", "response": "Run AdaptiveGraphicalLassoCV or QuicGraphicalLassoEBIC to fit the data X."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning QuicGraphicalLasso with mode = path and gamma ; use EBIC criteria for model selection.", "response": "def quic_graph_lasso_ebic_manual(X, gamma=0):\n    \"\"\"Run QuicGraphicalLasso with mode='path' and gamma; use EBIC criteria for model\n    selection.\n\n    The EBIC criteria is built into InverseCovarianceEstimator base class\n    so we demonstrate those utilities here.\n    \"\"\"\n    print(\"QuicGraphicalLasso (manual EBIC) with:\")\n    print(\"   mode: path\")\n    print(\"   gamma: {}\".format(gamma))\n    model = QuicGraphicalLasso(\n        lam=1.0,\n        mode=\"path\",\n        init_method=\"cov\",\n        path=np.logspace(np.log10(0.01), np.log10(1.0), num=100, endpoint=True),\n    )\n    model.fit(X)\n    ebic_index = model.ebic_select(gamma=gamma)\n    covariance_ = model.covariance_[ebic_index]\n    precision_ = model.precision_[ebic_index]\n    lam_ = model.lam_at_index(ebic_index)\n    print(\"   len(path lams): {}\".format(len(model.path_)))\n    print(\"   lam_scale_: {}\".format(model.lam_scale_))\n    print(\"   lam_: {}\".format(lam_))\n    print(\"   ebic_index: {}\".format(ebic_index))\n    return covariance_, precision_, lam_"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns QuicGraphicalLassoEBIC with gamma.", "response": "def quic_graph_lasso_ebic(X, gamma=0):\n    \"\"\"Run QuicGraphicalLassoEBIC with gamma.\n\n    QuicGraphicalLassoEBIC is a convenience class.  Results should be identical to\n    those obtained via quic_graph_lasso_ebic_manual.\n    \"\"\"\n    print(\"QuicGraphicalLassoEBIC with:\")\n    print(\"   mode: path\")\n    print(\"   gamma: {}\".format(gamma))\n    model = QuicGraphicalLassoEBIC(lam=1.0, init_method=\"cov\", gamma=gamma)\n    model.fit(X)\n    print(\"   len(path lams): {}\".format(len(model.path_)))\n    print(\"   lam_scale_: {}\".format(model.lam_scale_))\n    print(\"   lam_: {}\".format(model.lam_))\n    return model.covariance_, model.precision_, model.lam_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing empirical covariance as baseline estimator.", "response": "def empirical(X):\n    \"\"\"Compute empirical covariance as baseline estimator.\n    \"\"\"\n    print(\"Empirical\")\n    cov = np.dot(X.T, X) / n_samples\n    return cov, np.linalg.inv(cov)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestimating inverse covariance via scikit - learn ledoit - wolf function.", "response": "def sk_ledoit_wolf(X):\n    \"\"\"Estimate inverse covariance via scikit-learn ledoit_wolf function.\n    \"\"\"\n    print(\"Ledoit-Wolf (sklearn)\")\n    lw_cov_, _ = ledoit_wolf(X)\n    lw_prec_ = np.linalg.inv(lw_cov_)\n    return lw_cov_, lw_prec_"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prototype_adjacency(self, n_block_features, alpha):\n        return make_sparse_spd_matrix(\n            n_block_features,\n            alpha=np.abs(1.0 - alpha),\n            smallest_coef=self.spd_low,\n            largest_coef=self.spd_high,\n            random_state=self.prng,\n        )", "response": "Build a new graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prototype_adjacency(self, n_block_features, alpha=None):\n        return -np.ones((n_block_features, n_block_features)) * 0.5 + self.prng.uniform(\n            low=self.low, high=self.high, size=(n_block_features, n_block_features)\n        )", "response": "Build a new graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nonzero_intersection(m, m_hat):\n    n_features, _ = m.shape\n\n    m_no_diag = m.copy()\n    m_no_diag[np.diag_indices(n_features)] = 0\n    m_hat_no_diag = m_hat.copy()\n    m_hat_no_diag[np.diag_indices(n_features)] = 0\n\n    m_hat_nnz = len(np.nonzero(m_hat_no_diag.flat)[0])\n    m_nnz = len(np.nonzero(m_no_diag.flat)[0])\n\n    intersection_nnz = len(\n        np.intersect1d(np.nonzero(m_no_diag.flat)[0], np.nonzero(m_hat_no_diag.flat)[0])\n    )\n\n    return m_nnz, m_hat_nnz, intersection_nnz", "response": "Count the number of nonzeros in and between m and m_hat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncount the number of false positive support elements in m_hat.", "response": "def support_false_positive_count(m, m_hat):\n    \"\"\"Count the number of false positive support elements in\n    m_hat in one triangle, not including the diagonal.\n    \"\"\"\n    m_nnz, m_hat_nnz, intersection_nnz = _nonzero_intersection(m, m_hat)\n    return int((m_hat_nnz - intersection_nnz) / 2.0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting the number of false negative support elements in m_hat in one triangle not including the diagonal.", "response": "def support_false_negative_count(m, m_hat):\n    \"\"\"Count the number of false negative support elements in\n    m_hat in one triangle, not including the diagonal.\n    \"\"\"\n    m_nnz, m_hat_nnz, intersection_nnz = _nonzero_intersection(m, m_hat)\n    return int((m_nnz - intersection_nnz) / 2.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef support_difference_count(m, m_hat):\n    m_nnz, m_hat_nnz, intersection_nnz = _nonzero_intersection(m, m_hat)\n    return int((m_nnz + m_hat_nnz - (2 * intersection_nnz)) / 2.0)", "response": "Count the number of different elements in the support in one triangle."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn 1 if m_hat has exactly one support.", "response": "def has_exact_support(m, m_hat):\n    \"\"\"Returns 1 if support_difference_count is zero, 0 else.\n    \"\"\"\n    m_nnz, m_hat_nnz, intersection_nnz = _nonzero_intersection(m, m_hat)\n    return int((m_nnz + m_hat_nnz - (2 * intersection_nnz)) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns 1 if model selection error is less than or equal to prob rate 0 otherwise.", "response": "def has_approx_support(m, m_hat, prob=0.01):\n    \"\"\"Returns 1 if model selection error is less than or equal to prob rate,\n    0 else.\n\n    NOTE: why does np.nonzero/np.flatnonzero create so much problems?\n    \"\"\"\n    m_nz = np.flatnonzero(np.triu(m, 1))\n    m_hat_nz = np.flatnonzero(np.triu(m_hat, 1))\n\n    upper_diagonal_mask = np.flatnonzero(np.triu(np.ones(m.shape), 1))\n    not_m_nz = np.setdiff1d(upper_diagonal_mask, m_nz)\n\n    intersection = np.in1d(m_hat_nz, m_nz)  # true positives\n    not_intersection = np.in1d(m_hat_nz, not_m_nz)  # false positives\n\n    true_positive_rate = 0.0\n    if len(m_nz):\n        true_positive_rate = 1. * np.sum(intersection) / len(m_nz)\n        true_negative_rate = 1. - true_positive_rate\n\n    false_positive_rate = 0.0\n    if len(not_m_nz):\n        false_positive_rate = 1. * np.sum(not_intersection) / len(not_m_nz)\n\n    return int(np.less_equal(true_negative_rate + false_positive_rate, prob))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compute_error(comp_cov, covariance_, precision_, score_metric=\"frobenius\"):\n    if score_metric == \"frobenius\":\n        return np.linalg.norm(np.triu(comp_cov - covariance_, 1), ord=\"fro\")\n    elif score_metric == \"spectral\":\n        error = comp_cov - covariance_\n        return np.amax(np.linalg.svdvals(np.dot(error.T, error)))\n    elif score_metric == \"kl\":\n        return metrics.kl_loss(comp_cov, precision_)\n    elif score_metric == \"quadratic\":\n        return metrics.quadratic_loss(comp_cov, precision_)\n    elif score_metric == \"log_likelihood\":\n        return -metrics.log_likelihood(comp_cov, precision_)\n    else:\n        raise NotImplementedError(\n            (\"Must be frobenius, spectral, kl, \" \"quadratic, or log_likelihood\")\n        )", "response": "Compute the error vs. covariance of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_path(path):\n    if path is None:\n        return None\n\n    new_path = np.array(sorted(set(path), reverse=True))\n    if new_path[0] != path[0]:\n        print(\"Warning: Path must be sorted largest to smallest.\")\n\n    return new_path", "response": "Sorts path values from largest to smallest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_coefs(self, X):\n        self.n_samples_, self.n_features_ = X.shape\n        self.sample_covariance_, self.lam_scale_ = _init_coefs(\n            X, method=self.init_method\n        )\n\n        if not self.auto_scale:\n            self.lam_scale_ = 1.0", "response": "Computes the coefficients of the log likelihood matrix for the given log likelihood matrix X."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the score between the covariance of X_test and X via score_metric.", "response": "def score(self, X_test, y=None):\n        \"\"\"Computes the score between cov/prec of sample covariance of X_test\n        and X via 'score_metric'.\n\n        Note: We want to maximize score so we return the negative error.\n\n        Parameters\n        ----------\n        X_test : array-like, shape = [n_samples, n_features]\n            Test data of which we compute the likelihood, where n_samples is\n            the number of samples and n_features is the number of features.\n            X_test is assumed to be drawn from the same distribution than\n            the data used in fit (including centering).\n\n        y : not used.\n\n        Returns\n        -------\n        result : float or list of floats\n            The negative of the min error between `self.covariance_` and\n            the sample covariance of X_test.\n        \"\"\"\n        if isinstance(self.precision_, list):\n            print(\"Warning: returning a list of scores.\")\n\n        S_test, lam_scale_test = _init_coefs(X_test, method=self.init_method)\n        error = self.cov_error(S_test, score_metric=self.score_metric)\n\n        # maximize score with -error\n        return -error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the error vs. the covariance error vs. the path error.", "response": "def cov_error(self, comp_cov, score_metric=\"frobenius\"):\n        \"\"\"Computes the covariance error vs. comp_cov.\n\n        May require self.path_\n\n        Parameters\n        ----------\n        comp_cov : array-like, shape = (n_features, n_features)\n            The precision to compare with.\n            This should normally be the test sample covariance/precision.\n\n        scaling : bool\n            If True, the squared error norm is divided by n_features.\n            If False (default), the squared error norm is not rescaled.\n\n        score_metric : str\n            The type of norm used to compute the error between the estimated\n            self.precision, self.covariance and the reference `comp_cov`.\n            Available error types:\n\n            - 'frobenius' (default): sqrt(tr(A^t.A))\n            - 'spectral': sqrt(max(eigenvalues(A^t.A))\n            - 'kl': kl-divergence\n            - 'quadratic': quadratic loss\n            - 'log_likelihood': negative log likelihood\n\n        squared : bool\n            Whether to compute the squared error norm or the error norm.\n            If True (default), the squared error norm is returned.\n            If False, the error norm is returned.\n\n        Returns\n        -------\n        The min error between `self.covariance_` and `comp_cov`.\n\n        If self.precision_ is a list, returns errors for each matrix, otherwise\n        returns a scalar.\n        \"\"\"\n        if not isinstance(self.precision_, list):\n            return _compute_error(\n                comp_cov, self.covariance_, self.precision_, score_metric\n            )\n\n        path_errors = []\n        for lidx, lam in enumerate(self.path_):\n            path_errors.append(\n                _compute_error(\n                    comp_cov,\n                    self.covariance_[lidx],\n                    self.precision_[lidx],\n                    score_metric,\n                )\n            )\n\n        return np.array(path_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the EBIC scores for each model.", "response": "def ebic(self, gamma=0):\n        \"\"\"Compute EBIC scores for each model. If model is not \"path\" then\n        returns a scalar score value.\n\n        May require self.path_\n\n        See:\n        Extended Bayesian Information Criteria for Gaussian Graphical Models\n        R. Foygel and M. Drton\n        NIPS 2010\n\n        Parameters\n        ----------\n        gamma : (float) \\in (0, 1)\n            Choice of gamma=0 leads to classical BIC\n            Positive gamma leads to stronger penalization of large graphs.\n\n        Returns\n        -------\n        Scalar ebic score or list of ebic scores.\n        \"\"\"\n        if not self.is_fitted_:\n            return\n\n        if not isinstance(self.precision_, list):\n            return metrics.ebic(\n                self.sample_covariance_,\n                self.precision_,\n                self.n_samples_,\n                self.n_features_,\n                gamma=gamma,\n            )\n\n        ebic_scores = []\n        for lidx, lam in enumerate(self.path_):\n            ebic_scores.append(\n                metrics.ebic(\n                    self.sample_covariance_,\n                    self.precision_[lidx],\n                    self.n_samples_,\n                    self.n_features_,\n                    gamma=gamma,\n                )\n            )\n\n        return np.array(ebic_scores)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ebic_select(self, gamma=0):\n        if not isinstance(self.precision_, list):\n            raise ValueError(\"EBIC requires multiple models to select from.\")\n            return\n\n        if not self.is_fitted_:\n            return\n\n        ebic_scores = self.ebic(gamma=gamma)\n        min_indices = np.where(np.abs(ebic_scores - ebic_scores.min()) < 1e-10)\n        return np.max(min_indices)", "response": "Uses Extended Bayesian Information Criteria for model selection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quic_graph_lasso(X, num_folds, metric):\n    print(\"QuicGraphicalLasso + GridSearchCV with:\")\n    print(\"   metric: {}\".format(metric))\n    search_grid = {\n        \"lam\": np.logspace(np.log10(0.01), np.log10(1.0), num=100, endpoint=True),\n        \"init_method\": [\"cov\"],\n        \"score_metric\": [metric],\n    }\n    model = GridSearchCV(QuicGraphicalLasso(), search_grid, cv=num_folds, refit=True)\n    model.fit(X)\n    bmodel = model.best_estimator_\n    print(\"   len(cv_lams): {}\".format(len(search_grid[\"lam\"])))\n    print(\"   cv-lam: {}\".format(model.best_params_[\"lam\"]))\n    print(\"   lam_scale_: {}\".format(bmodel.lam_scale_))\n    print(\"   lam_: {}\".format(bmodel.lam_))\n    return bmodel.covariance_, bmodel.precision_, bmodel.lam_", "response": "Run QuicGraphicalLasso with mode = default and use standard scikit\n    GridSearchCV to find the best lambda."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quic_graph_lasso_cv(X, metric):\n    print(\"QuicGraphicalLassoCV with:\")\n    print(\"   metric: {}\".format(metric))\n    model = QuicGraphicalLassoCV(\n        cv=2,  # cant deal w more folds at small size\n        n_refinements=6,\n        n_jobs=1,\n        init_method=\"cov\",\n        score_metric=metric,\n    )\n    model.fit(X)\n    print(\"   len(cv_lams): {}\".format(len(model.cv_lams_)))\n    print(\"   lam_scale_: {}\".format(model.lam_scale_))\n    print(\"   lam_: {}\".format(model.lam_))\n    return model.covariance_, model.precision_, model.lam_", "response": "Run QuicGraphicalLassoCV on data with metric of choice."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef model_average(X, penalization):\n    n_trials = 100\n    print(\"ModelAverage with:\")\n    print(\"   estimator: QuicGraphicalLasso (default)\")\n    print(\"   n_trials: {}\".format(n_trials))\n    print(\"   penalization: {}\".format(penalization))\n\n    # if penalization is random, first find a decent scalar lam_ to build\n    # random perturbation matrix around.  lam doesn't matter for fully-random.\n    lam = 0.5\n    if penalization == \"random\":\n        cv_model = QuicGraphicalLassoCV(\n            cv=2, n_refinements=6, n_jobs=1, init_method=\"cov\", score_metric=metric\n        )\n        cv_model.fit(X)\n        lam = cv_model.lam_\n        print(\"   lam: {}\".format(lam))\n\n    model = ModelAverage(\n        n_trials=n_trials, penalization=penalization, lam=lam, n_jobs=1\n    )\n    model.fit(X)\n    print(\"   lam_: {}\".format(model.lam_))\n    return model.proportion_, model.support_, model.lam_", "response": "Run ModelAverage with QuicGraphicalLassoCV to obtain proportion_ proportions and support_ and lam_."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef adaptive_model_average(X, penalization, method):\n    n_trials = 100\n    print(\"Adaptive ModelAverage with:\")\n    print(\"   estimator: QuicGraphicalLasso (default)\")\n    print(\"   n_trials: {}\".format(n_trials))\n    print(\"   penalization: {}\".format(penalization))\n    print(\"   adaptive-method: {}\".format(method))\n\n    # if penalization is random, first find a decent scalar lam_ to build\n    # random perturbation matrix around. lam doesn't matter for fully-random.\n    lam = 0.5\n    if penalization == \"random\":\n        cv_model = QuicGraphicalLassoCV(\n            cv=2, n_refinements=6, n_jobs=1, init_method=\"cov\", score_metric=metric\n        )\n        cv_model.fit(X)\n        lam = cv_model.lam_\n        print(\"   lam: {}\".format(lam))\n\n    model = AdaptiveGraphicalLasso(\n        estimator=ModelAverage(\n            n_trials=n_trials, penalization=penalization, lam=lam, n_jobs=1\n        ),\n        method=method,\n    )\n    model.fit(X)\n    lam_norm_ = np.linalg.norm(model.estimator_.lam_)\n    print(\"   ||lam_||_2: {}\".format(lam_norm_))\n    return model.estimator_.covariance_, model.estimator_.precision_, lam_norm_", "response": "Run AdaptiveGraphicalLassoCV to obtain proportion of the matrix X."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef graph_lasso(X, num_folds):\n    print(\"GraphLasso (sklearn)\")\n    model = GraphLassoCV(cv=num_folds)\n    model.fit(X)\n    print(\"   lam_: {}\".format(model.alpha_))\n    return model.covariance_, model.precision_, model.alpha_", "response": "Estimate inverse covariance via GraphLassoCV class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a new graph.", "response": "def prototype_adjacency(self, n_block_features, alpha):\n        \"\"\"Build a new graph.\n\n        Doc for \".create(n_features, alpha)\"\n\n        Parameters\n        -----------\n        n_features : int\n\n        alpha : float (0,1)\n            The complexity / sparsity factor.\n\n            Each graph will have a minimum of\n\n                n_blocks * ceil(alpha * n_block_features)\n\n                where\n\n                n_block_features = floor(n_features / self.n_blocks)\n\n            edges and exactly this amount if chain_blocks=False.\n\n        Returns\n        -----------\n        (n_features, n_features) matrices: covariance, precision, adjacency\n        \"\"\"\n        return lattice(\n            self.prng,\n            n_block_features,\n            alpha,\n            random_sign=self.random_sign,\n            low=self.low,\n            high=self.high,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit the inverse covariance model according to the given training data and parameters.", "response": "def quic(\n    S,\n    lam,\n    mode=\"default\",\n    tol=1e-6,\n    max_iter=1000,\n    Theta0=None,\n    Sigma0=None,\n    path=None,\n    msg=0,\n):\n    \"\"\"Fits the inverse covariance model according to the given training\n    data and parameters.\n\n    Parameters\n    -----------\n    S : 2D ndarray, shape (n_features, n_features)\n        Empirical covariance or correlation matrix.\n\n    Other parameters described in `class InverseCovariance`.\n\n    Returns\n    -------\n    Theta :\n    Sigma :\n    opt :\n    cputime :\n    iters :\n    dGap :\n    \"\"\"\n    assert mode in [\"default\", \"path\", \"trace\"], \"mode = 'default', 'path' or 'trace'.\"\n\n    Sn, Sm = S.shape\n    if Sn != Sm:\n        raise ValueError(\"Input data must be square. S shape = {}\".format(S.shape))\n        return\n\n    # Regularization parameter matrix L.\n    if isinstance(lam, float):\n        _lam = np.empty((Sn, Sm))\n        _lam[:] = lam\n        _lam[np.diag_indices(Sn)] = 0.  # make sure diagonal is zero\n    else:\n        assert lam.shape == S.shape, \"lam, S shape mismatch.\"\n        _lam = as_float_array(lam, copy=False, force_all_finite=False)\n\n    # Defaults.\n    optSize = 1\n    iterSize = 1\n    if mode is \"trace\":\n        optSize = max_iter\n\n    # Default Theta0, Sigma0 when both are None.\n    if Theta0 is None and Sigma0 is None:\n        Theta0 = np.eye(Sn)\n        Sigma0 = np.eye(Sn)\n\n    assert Theta0 is not None, \"Theta0 and Sigma0 must both be None or both specified.\"\n    assert Sigma0 is not None, \"Theta0 and Sigma0 must both be None or both specified.\"\n    assert Theta0.shape == S.shape, \"Theta0, S shape mismatch.\"\n    assert Sigma0.shape == S.shape, \"Theta0, Sigma0 shape mismatch.\"\n    Theta0 = as_float_array(Theta0, copy=False, force_all_finite=False)\n    Sigma0 = as_float_array(Sigma0, copy=False, force_all_finite=False)\n\n    if mode == \"path\":\n        assert path is not None, \"Please specify the path scaling values.\"\n\n        # path must be sorted from largest to smallest and have unique values\n        check_path = sorted(set(path), reverse=True)\n        assert_array_almost_equal(check_path, path)\n\n        path_len = len(path)\n        optSize = path_len\n        iterSize = path_len\n\n        # Note here: memory layout is important:\n        # a row of X/W holds a flattened Sn x Sn matrix,\n        # one row for every element in _path_.\n        Theta = np.empty((path_len, Sn * Sn))\n        Theta[0, :] = Theta0.ravel()\n        Sigma = np.empty((path_len, Sn * Sn))\n        Sigma[0, :] = Sigma0.ravel()\n    else:\n        path = np.empty(1)\n        path_len = len(path)\n\n        Theta = np.empty(Theta0.shape)\n        Theta[:] = Theta0\n        Sigma = np.empty(Sigma0.shape)\n        Sigma[:] = Sigma0\n\n    # Cython fix for Python3\n    # http://cython.readthedocs.io/en/latest/src/tutorial/strings.html\n    quic_mode = mode\n    if sys.version_info[0] >= 3:\n        quic_mode = quic_mode.encode(\"utf-8\")\n\n    # Run QUIC.\n    opt = np.zeros(optSize)\n    cputime = np.zeros(optSize)\n    dGap = np.zeros(optSize)\n    iters = np.zeros(iterSize, dtype=np.uint32)\n    pyquic.quic(\n        quic_mode,\n        Sn,\n        S,\n        _lam,\n        path_len,\n        path,\n        tol,\n        msg,\n        max_iter,\n        Theta,\n        Sigma,\n        opt,\n        cputime,\n        iters,\n        dGap,\n    )\n\n    if optSize == 1:\n        opt = opt[0]\n        cputime = cputime[0]\n        dGap = dGap[0]\n\n    if iterSize == 1:\n        iters = iters[0]\n\n    # reshape Theta, Sigma in path mode\n    Theta_out = Theta\n    Sigma_out = Sigma\n    if mode == \"path\":\n        Theta_out = []\n        Sigma_out = []\n        for lidx in range(path_len):\n            Theta_out.append(np.reshape(Theta[lidx, :], (Sn, Sn)))\n            Sigma_out.append(np.reshape(Sigma[lidx, :], (Sn, Sn)))\n\n    return Theta_out, Sigma_out, opt, cputime, iters, dGap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap to compute quic path for example X.", "response": "def _quic_path(\n    X,\n    path,\n    X_test=None,\n    lam=0.5,\n    tol=1e-6,\n    max_iter=1000,\n    Theta0=None,\n    Sigma0=None,\n    method=\"quic\",\n    verbose=0,\n    score_metric=\"log_likelihood\",\n    init_method=\"corrcoef\",\n):\n    \"\"\"Wrapper to compute path for example X.\n    \"\"\"\n    S, lam_scale_ = _init_coefs(X, method=init_method)\n\n    path = path.copy(order=\"C\")\n\n    if method == \"quic\":\n        (precisions_, covariances_, opt_, cputime_, iters_, duality_gap_) = quic(\n            S,\n            lam,\n            mode=\"path\",\n            tol=tol,\n            max_iter=max_iter,\n            Theta0=Theta0,\n            Sigma0=Sigma0,\n            path=path,\n            msg=verbose,\n        )\n    else:\n        raise NotImplementedError(\"Only method='quic' has been implemented.\")\n\n    if X_test is not None:\n        S_test, lam_scale_test = _init_coefs(X_test, method=init_method)\n\n        path_errors = []\n        for lidx, lam in enumerate(path):\n            path_errors.append(\n                _compute_error(\n                    S_test,\n                    covariances_[lidx],\n                    precisions_[lidx],\n                    score_metric=score_metric,\n                )\n            )\n        scores_ = [-e for e in path_errors]\n\n        return covariances_, precisions_, scores_\n\n    return covariances_, precisions_"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits the inverse covariance model according to the given training Arc X and parameters.", "response": "def fit(self, X, y=None, **fit_params):\n        \"\"\"Fits the inverse covariance model according to the given training\n        data and parameters.\n\n        Parameters\n        -----------\n        X : 2D ndarray, shape (n_features, n_features)\n            Input data.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        # quic-specific outputs\n        self.opt_ = None\n        self.cputime_ = None\n        self.iters_ = None\n        self.duality_gap_ = None\n\n        # these must be updated upon self.fit()\n        self.sample_covariance_ = None\n        self.lam_scale_ = None\n        self.is_fitted_ = False\n\n        self.path_ = _validate_path(self.path)\n        X = check_array(X, ensure_min_features=2, estimator=self)\n        X = as_float_array(X, copy=False, force_all_finite=False)\n        self.init_coefs(X)\n        if self.method == \"quic\":\n            (\n                self.precision_,\n                self.covariance_,\n                self.opt_,\n                self.cputime_,\n                self.iters_,\n                self.duality_gap_,\n            ) = quic(\n                self.sample_covariance_,\n                self.lam * self.lam_scale_,\n                mode=self.mode,\n                tol=self.tol,\n                max_iter=self.max_iter,\n                Theta0=self.Theta0,\n                Sigma0=self.Sigma0,\n                path=self.path_,\n                msg=self.verbose,\n            )\n        else:\n            raise NotImplementedError(\"Only method='quic' has been implemented.\")\n\n        self.is_fitted_ = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the scaled lambda used at index lidx.", "response": "def lam_at_index(self, lidx):\n        \"\"\"Compute the scaled lambda used at index lidx.\n        \"\"\"\n        if self.path_ is None:\n            return self.lam * self.lam_scale_\n\n        return self.lam * self.lam_scale_ * self.path_[lidx]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting the GraphLasso covariance model to X.", "response": "def fit(self, X, y=None):\n        \"\"\"Fits the GraphLasso covariance model to X.\n\n        Closely follows sklearn.covariance.graph_lasso.GraphLassoCV.\n\n        Parameters\n        ----------\n        X : ndarray, shape (n_samples, n_features)\n            Data from which to compute the covariance estimate\n        \"\"\"\n        # quic-specific outputs\n        self.opt_ = None\n        self.cputime_ = None\n        self.iters_ = None\n        self.duality_gap_ = None\n\n        # these must be updated upon self.fit()\n        self.sample_covariance_ = None\n        self.lam_scale_ = None\n        self.is_fitted_ = False\n\n        # initialize\n        X = check_array(X, ensure_min_features=2, estimator=self)\n        X = as_float_array(X, copy=False, force_all_finite=False)\n\n        if self.cv is None:\n            cv = (3, 10)\n        elif isinstance(self.cv, int):\n            cv = (self.cv, 10)  # upgrade with default number of trials\n        elif isinstance(self.cv, tuple):\n            cv = self.cv\n\n        cv = RepeatedKFold(n_splits=cv[0], n_repeats=cv[1])\n\n        self.init_coefs(X)\n\n        # get path\n        if isinstance(self.lams, int):\n            n_refinements = self.n_refinements\n            lam_1 = self.lam_scale_\n            lam_0 = 1e-2 * lam_1\n            path = np.logspace(np.log10(lam_0), np.log10(lam_1), self.lams)[::-1]\n        else:\n            path = self.lams\n            n_refinements = 1\n\n        # run this thing a bunch\n        results = list()\n        t0 = time.time()\n        for rr in range(n_refinements):\n            if self.sc is None:\n                # parallel version\n                this_result = Parallel(\n                    n_jobs=self.n_jobs, verbose=self.verbose, backend=self.backend\n                )(\n                    delayed(_quic_path)(\n                        X[train],\n                        path,\n                        X_test=X[test],\n                        lam=self.lam,\n                        tol=self.tol,\n                        max_iter=self.max_iter,\n                        Theta0=self.Theta0,\n                        Sigma0=self.Sigma0,\n                        method=self.method,\n                        verbose=self.verbose,\n                        score_metric=self.score_metric,\n                        init_method=self.init_method,\n                    )\n                    for train, test in cv.split(X)\n                )\n            else:\n                # parallel via spark\n                train_test_grid = [(train, test) for (train, test) in cv.split(X)]\n                indexed_param_grid = list(\n                    zip(range(len(train_test_grid)), train_test_grid)\n                )\n                par_param_grid = self.sc.parallelize(indexed_param_grid)\n                X_bc = self.sc.broadcast(X)\n\n                # wrap function parameters so we dont pick whole self object\n                quic_path = partial(\n                    _quic_path,\n                    path=path,\n                    lam=self.lam,\n                    tol=self.tol,\n                    max_iter=self.max_iter,\n                    Theta0=self.Theta0,\n                    Sigma0=self.Sigma0,\n                    method=self.method,\n                    verbose=self.verbose,\n                    score_metric=self.score_metric,\n                    init_method=self.init_method,\n                )\n\n                indexed_results = dict(\n                    par_param_grid.map(\n                        partial(_quic_path_spark, quic_path=quic_path, X_bc=X_bc)\n                    ).collect()\n                )\n                this_result = [\n                    indexed_results[idx] for idx in range(len(train_test_grid))\n                ]\n                X_bc.unpersist()\n\n            # Little dance to transform the list in what we need\n            covs, _, scores = zip(*this_result)\n            covs = zip(*covs)\n            scores = zip(*scores)\n            results.extend(zip(path, scores, covs))\n            results = sorted(results, key=operator.itemgetter(0), reverse=True)\n\n            # Find the maximum (avoid using built in 'max' function to\n            # have a fully-reproducible selection of the smallest alpha\n            # in case of equality)\n            best_score = -np.inf\n            last_finite_idx = 0\n            best_index = 0\n            for index, (lam, scores, _) in enumerate(results):\n                # sometimes we get -np.inf in the result (in kl-loss)\n                scores = [s for s in scores if not np.isinf(s)]\n                if len(scores) == 0:\n                    this_score = -np.inf\n                else:\n                    this_score = np.mean(scores)\n\n                if this_score >= .1 / np.finfo(np.float64).eps:\n                    this_score = np.nan\n\n                if np.isfinite(this_score):\n                    last_finite_idx = index\n\n                if this_score >= best_score:\n                    best_score = this_score\n                    best_index = index\n\n            # Refine the grid\n            if best_index == 0:\n                # We do not need to go back: we have chosen\n                # the highest value of lambda for which there are\n                # non-zero coefficients\n                lam_1 = results[0][0]\n                lam_0 = results[1][0]\n\n            elif best_index == last_finite_idx and not best_index == len(results) - 1:\n                # We have non-converged models on the upper bound of the\n                # grid, we need to refine the grid there\n                lam_1 = results[best_index][0]\n                lam_0 = results[best_index + 1][0]\n\n            elif best_index == len(results) - 1:\n                lam_1 = results[best_index][0]\n                lam_0 = 0.01 * results[best_index][0]\n\n            else:\n                lam_1 = results[best_index - 1][0]\n                lam_0 = results[best_index + 1][0]\n\n            if isinstance(self.lams, int):\n                path = np.logspace(np.log10(lam_1), np.log10(lam_0), self.lams + 2)\n                path = path[1:-1]\n\n            if self.verbose and n_refinements > 1:\n                print(\n                    \"[GraphLassoCV] Done refinement % 2i out of %i: % 3is\"\n                    % (rr + 1, n_refinements, time.time() - t0)\n                )\n\n        results = list(zip(*results))\n        grid_scores_ = list(results[1])\n        lams = list(results[0])\n\n        # Finally, compute the score with lambda = 0\n        lams.append(0)\n        grid_scores_.append(\n            cross_val_score(EmpiricalCovariance(), X, cv=cv, n_jobs=self.n_jobs)\n        )\n        self.grid_scores_ = np.array(grid_scores_)\n        self.lam_ = self.lam * lams[best_index]\n        self.cv_lams_ = [self.lam * l for l in lams]\n\n        # Finally fit the model with the selected lambda\n        if self.method == \"quic\":\n            (\n                self.precision_,\n                self.covariance_,\n                self.opt_,\n                self.cputime_,\n                self.iters_,\n                self.duality_gap_,\n            ) = quic(\n                self.sample_covariance_,\n                self.lam_,\n                mode=\"default\",\n                tol=self.tol,\n                max_iter=self.max_iter,\n                Theta0=self.Theta0,\n                Sigma0=self.Sigma0,\n                path=None,\n                msg=self.verbose,\n            )\n        else:\n            raise NotImplementedError(\"Only method='quic' has been implemented.\")\n\n        self.is_fitted_ = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits the inverse covariance model according to the given training Arc X and parameters.", "response": "def fit(self, X, y=None, **fit_params):\n        \"\"\"Fits the inverse covariance model according to the given training\n        data and parameters.\n\n        Parameters\n        -----------\n        X : 2D ndarray, shape (n_features, n_features)\n            Input data.\n\n        Returns\n        -------\n        self\n        \"\"\"\n        # quic-specific outputs\n        self.opt_ = None\n        self.cputime_ = None\n        self.iters_ = None\n        self.duality_gap_ = None\n\n        # these must be updated upon self.fit()\n        self.path_ = None\n        self.sample_covariance_ = None\n        self.lam_scale_ = None\n        self.lam_ = None\n        self.is_fitted_ = False\n\n        X = check_array(X, ensure_min_features=2, estimator=self)\n        X = as_float_array(X, copy=False, force_all_finite=False)\n        self.init_coefs(X)\n\n        # either use passed in path, or make our own path\n        lam_1 = self.lam_scale_\n        lam_0 = 1e-2 * lam_1\n        if self.path is None:\n            self.path_ = np.logspace(np.log10(lam_0), np.log10(lam_1), 100)[::-1]\n        elif isinstance(self.path, int):\n            self.path_ = np.logspace(np.log10(lam_0), np.log10(lam_1), self.path)[::-1]\n        else:\n            self.path_ = self.path\n\n        self.path_ = _validate_path(self.path_)\n\n        # fit along the path, temporarily populate\n        # self.precision_, self.covariance_ with path values so we can use our\n        # inherited selection function\n        if self.method == \"quic\":\n            (self.precision_, self.covariance_, _, _, _, _) = quic(\n                self.sample_covariance_,\n                self.lam * self.lam_scale_,\n                mode=\"path\",\n                tol=self.tol,\n                max_iter=self.max_iter,\n                Theta0=self.Theta0,\n                Sigma0=self.Sigma0,\n                path=self.path_,\n                msg=self.verbose,\n            )\n            self.is_fitted_ = True\n        else:\n            raise NotImplementedError(\"Only method='quic' has been implemented.\")\n\n        # apply EBIC criteria\n        best_lam_idx = self.ebic_select(gamma=self.gamma)\n        self.lam_ = self.lam * self.lam_scale_ * self.path_[best_lam_idx]\n        self.precision_ = self.precision_[best_lam_idx]\n        self.covariance_ = self.covariance_[best_lam_idx]\n\n        self.is_fitted_ = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _compute_ranks(X, winsorize=False, truncation=None, verbose=True):\n    n_samples, n_features = X.shape\n    Xrank = np.zeros(shape=X.shape)\n\n    if winsorize:\n        if truncation is None:\n            truncation = 1 / (\n                4 * np.power(n_samples, 0.25) * np.sqrt(np.pi * np.log(n_samples))\n            )\n\n        elif truncation > 1:\n            truncation = np.min(1.0, truncation)\n\n    for col in np.arange(n_features):\n        Xrank[:, col] = rankdata(X[:, col], method=\"average\")\n        Xrank[:, col] /= n_samples\n        if winsorize:\n            if n_samples > 100 * n_features:\n                Xrank[:, col] = n_samples * Xrank[:, col] / (n_samples + 1)\n            else:\n                lower_truncate = Xrank[:, col] <= truncation\n                upper_truncate = Xrank[:, col] > 1 - truncation\n                Xrank[lower_truncate, col] = truncation\n                Xrank[upper_truncate, col] = 1 - truncation\n\n    return Xrank", "response": "Compute ranks for a single node in a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the spearman correlation estimate of a set of nonparanormal graphical models.", "response": "def spearman_correlation(X, rowvar=False):\n    \"\"\"\n    Computes the spearman correlation estimate.\n    This is effectively a bias corrected pearson correlation\n    between rank transformed columns of X.\n\n    Parameters\n    ----------\n    X: array-like, shape = [n_samples, n_features]\n        Data matrix using which we compute the empirical\n        correlation\n\n    Returns\n    -------\n    rank_correlation\n\n    References\n    ----------\n\n    Xue, Lingzhou; Zou, Hui.\n    \"Regularized rank-based estimation of high-dimensional\n    nonparanormal graphical models.\"\n    Ann. Statist. 40 (2012), no. 5, 2541--2571. doi:10.1214/12-AOS1041.\n\n    Liu, Han, Fang; Yuan, Ming; Lafferty, John; Wasserman, Larry.\n    \"High-dimensional semiparametric Gaussian copula graphical models.\"\n    Ann. Statist. 40.4 (2012): 2293-2326. doi:10.1214/12-AOS1037\n    \"\"\"\n\n    Xrank = _compute_ranks(X)\n    rank_correlation = np.corrcoef(Xrank, rowvar=rowvar)\n\n    return 2 * np.sin(rank_correlation * np.pi / 6)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the kendall s tau correlation estimate.", "response": "def kendalltau_correlation(X, rowvar=False, weighted=False):\n    \"\"\"\n    Computes kendall's tau correlation estimate.\n    The option to use scipy.stats.weightedtau is not recommended\n    as the implementation does not appear to handle ties correctly.\n\n    Parameters\n    ----------\n    X: array-like, shape = [n_samples, n_features]\n        Data matrix using which we compute the empirical\n        correlation\n\n    Returns\n    -------\n    rank_correlation\n\n    References\n    ----------\n\n    Liu, Han, Fang; Yuan, Ming; Lafferty, John; Wasserman, Larry.\n    \"High-dimensional semiparametric Gaussian copula graphical models.\"\n    Ann. Statist. 40.4 (2012): 2293-2326. doi:10.1214/12-AOS1037\n\n    Barber, Rina Foygel; Kolar, Mladen.\n    \"ROCKET: Robust Confidence Intervals via Kendall's Tau\n    for Transelliptical Graphical Models.\"\n     arXiv:1502.07641\n    \"\"\"\n\n    if rowvar:\n        X = X.T\n\n    _, n_features = X.shape\n    rank_correlation = np.eye(n_features)\n    for row in np.arange(n_features):\n        for col in np.arange(1 + row, n_features):\n            if weighted:\n                rank_correlation[row, col], _ = weightedtau(\n                    X[:, row], X[:, col], rank=False\n                )\n            else:\n                rank_correlation[row, col], _ = kendalltau(X[:, row], X[:, col])\n    rank_correlation = np.triu(rank_correlation, 1) + rank_correlation.T\n\n    return np.sin(rank_correlation * np.pi / 2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the API version.", "response": "def version(self):\n        \"\"\"\n            This attribute retrieve the API version.\n\n            >>> Works().version\n            '1.0.0'\n        \"\"\"\n        request_params = dict(self.request_params)\n        request_url = str(self.request_url)\n\n        result = self.do_http_request(\n            'get',\n            request_url,\n            data=request_params,\n            custom_header=str(self.etiquette)\n        ).json()\n\n        return result['message-version']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url(self):\n        request_params = self._escaped_pagging()\n\n        sorted_request_params = sorted([(k, v) for k, v in request_params.items()])\n        req = requests.Request(\n            'get', self.request_url, params=sorted_request_params).prepare()\n\n        return req.url", "response": "This attribute retrieve the url that will be used as a HTTP request to the crossref API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select(self, *args):\n\n        context = str(self.context)\n        request_url = build_url_endpoint(self.ENDPOINT, context)\n        request_params = dict(self.request_params)\n\n        select_args = []\n\n        invalid_select_args = []\n        for item in args:\n            if isinstance(item, list):\n                select_args += [i.strip() for i in item]\n\n            if isinstance(item, str):\n                select_args += [i.strip() for i in item.split(',')]\n\n        invalid_select_args = set(select_args) - set(self.FIELDS_SELECT)\n\n        if len(invalid_select_args) != 0:\n            raise UrlSyntaxError(\n                'Select field\\'s specified as (%s) but must be one of: %s' % (\n                    ', '.join(invalid_select_args),\n                    ', '.join(self.FIELDS_SELECT)\n                )\n            )\n\n        request_params['select'] = ','.join(\n            sorted([i for i in set(request_params.get('select', '').split(',') + select_args) if i])\n        )\n\n        return self.__class__(request_url, request_params, context, self.etiquette)", "response": "This method returns an iterable object that implements the method\n            __iter__. The arguments given will compose the parameters in the request url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sample(self, sample_size=20):\n        context = str(self.context)\n        request_url = build_url_endpoint(self.ENDPOINT, context)\n        request_params = dict(self.request_params)\n\n        try:\n            if sample_size > 100:\n                raise UrlSyntaxError(\n                    'Integer specified as %s but must be a positive integer less than or equal to 100.' % str(sample_size)\n                )\n        except TypeError:\n            raise UrlSyntaxError(\n                'Integer specified as %s but must be a positive integer less than or equal to 100.' % str(sample_size)\n            )\n\n        request_params['sample'] = sample_size\n\n        return self.__class__(request_url, request_params, context, self.etiquette)", "response": "This method returns an iterable object that implements the method\n           __iter__."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef works(self, funder_id):\n        context = '%s/%s' % (self.ENDPOINT, str(funder_id))\n        return Works(context=context)", "response": "This method returns an iterable of Works of the given funder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef works(self, member_id):\n        context = '%s/%s' % (self.ENDPOINT, str(member_id))\n        return Works(context=context)", "response": "This method returns an iterable of Works of the given member."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_doi(self, submission_id, request_xml):\n\n        endpoint = self.get_endpoint('deposit')\n\n        files = {\n            'mdFile': ('%s.xml' % submission_id, request_xml)\n        }\n\n        params = {\n            'operation': 'doMDUpload',\n            'login_id': self.api_user,\n            'login_passwd': self.api_key\n        }\n\n        result = self.do_http_request(\n            'post',\n            endpoint,\n            data=params,\n            files=files,\n            timeout=10,\n            custom_header=str(self.etiquette)\n        )\n\n        return result", "response": "This method register a new DOI number in Crossref or update some DOI metadata."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request_doi_status_by_filename(self, file_name, data_type='result'):\n\n        endpoint = self.get_endpoint('submissionDownload')\n\n        params = {\n            'usr': self.api_user,\n            'pwd': self.api_key,\n            'file_name': file_name,\n            'type': data_type\n        }\n\n        result = self.do_http_request(\n            'get',\n            endpoint,\n            data=params,\n            timeout=10,\n            custom_header=str(self.etiquette)\n        )\n\n        return result", "response": "This method requests the status of a DOI request by filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request_doi_status_by_batch_id(self, doi_batch_id, data_type='result'):\n\n        endpoint = self.get_endpoint('submissionDownload')\n\n        params = {\n            'usr': self.api_user,\n            'pwd': self.api_key,\n            'doi_batch_id': doi_batch_id,\n            'type': data_type\n        }\n\n        result = self.do_http_request(\n            'get',\n            endpoint,\n            data=params,\n            timeout=10,\n            custom_header=str(self.etiquette)\n        )\n\n        return result", "response": "This method requests the status of a DOI request by the given batch ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asbool(s):\n    if s is None:\n        return False\n    if isinstance(s, bool):\n        return s\n    s = str(s).strip()\n    return s.lower() in truthy", "response": "Return the boolean value True if the case - lowered value of string\n    input s is a : term : truthy string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rule_from_pattern(pattern, base_path=None, source=None):\n\tif base_path and base_path != abspath(base_path):\n\t\traise ValueError('base_path must be absolute')\n\t# Store the exact pattern for our repr and string functions\n\torig_pattern = pattern\n\t# Early returns follow\n\t# Discard comments and seperators\n\tif pattern.strip() == '' or pattern[0] == '#':\n\t\treturn\n\t# Discard anything with more than two consecutive asterisks\n\tif pattern.find('***') > -1:\n\t\treturn\n\t# Strip leading bang before examining double asterisks\n\tif pattern[0] == '!':\n\t\tnegation = True\n\t\tpattern = pattern[1:]\n\telse:\n\t\tnegation = False\n\t# Discard anything with invalid double-asterisks -- they can appear\n\t# at the start or the end, or be surrounded by slashes\n\tfor m in re.finditer(r'\\*\\*', pattern):\n\t\tstart_index = m.start()\n\t\tif (start_index != 0 and start_index != len(pattern) - 2 and\n\t\t\t\t(pattern[start_index - 1] != '/' or\n\t\t\t\t pattern[start_index + 2] != '/')):\n\t\t\treturn\n\n\t# Special-casing '/', which doesn't match any files or directories\n\tif pattern.rstrip() == '/':\n\t\treturn\n\n\tdirectory_only = pattern[-1] == '/'\n\t# A slash is a sign that we're tied to the base_path of our rule\n\t# set.\n\tanchored = '/' in pattern[:-1]\n\tif pattern[0] == '/':\n\t\tpattern = pattern[1:]\n\tif pattern[0] == '*' and pattern[1] == '*':\n\t\tpattern = pattern[2:]\n\t\tanchored = False\n\tif pattern[0] == '/':\n\t\tpattern = pattern[1:]\n\tif pattern[-1] == '/':\n\t\tpattern = pattern[:-1]\n\tregex = fnmatch_pathname_to_regex(\n\t\tpattern\n\t)\n\tif anchored:\n\t\tregex = ''.join(['^', regex])\n\treturn IgnoreRule(\n\t\tpattern=orig_pattern,\n\t\tregex=regex,\n\t\tnegation=negation,\n\t\tdirectory_only=directory_only,\n\t\tanchored=anchored,\n\t\tbase_path=Path(base_path) if base_path else None,\n\t\tsource=source\n\t)", "response": "Given a pattern return a IgnoreRule suitable for matching against the base_path and source."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the directory containing the plugin definition for the given module type.", "response": "def _find_plugin_dir(module_type):\n    '''Find the directory containing the plugin definition for the given type.\n    Do this by searching all the paths where plugins can live for a dir that\n    matches the type name.'''\n\n    for install_dir in _get_plugin_install_dirs():\n        candidate = os.path.join(install_dir, module_type)\n        if os.path.isdir(candidate):\n            return candidate\n    else:\n        raise PluginCandidateError(\n            'No plugin found for `{}` module in paths:\\n{}'.format(\n                module_type, '\\n'.join(_get_plugin_install_dirs())))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all the places on the filesystem where we should look for plugin definitions.", "response": "def _get_plugin_install_dirs():\n    '''Return all the places on the filesystem where we should look for plugin\n    definitions. Order is significant here: user-installed plugins should be\n    searched first, followed by system-installed plugins, and last of all peru\n    builtins.'''\n    builtins_dir = os.path.join(compat.MODULE_ROOT, 'resources', 'plugins')\n    if os.name == 'nt':\n        # Windows\n        local_data_dir = os.path.expandvars('%LOCALAPPDATA%')\n        program_files_dir = os.path.expandvars('%PROGRAMFILES%')\n        return (\n            os.path.join(local_data_dir, 'peru', 'plugins'),\n            os.path.join(program_files_dir, 'peru', 'plugins'),\n            builtins_dir,\n        )\n    else:\n        # non-Windows\n        default_config_dir = os.path.expanduser('~/.config')\n        config_dir = os.environ.get('XDG_CONFIG_HOME', default_config_dir)\n        return (\n            os.path.join(config_dir, 'peru', 'plugins'),\n            '/usr/local/lib/peru/plugins',\n            '/usr/lib/peru/plugins',\n            builtins_dir,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unglobbed_prefix(glob):\n    '''Returns all the path components, starting from the beginning, up to the\n    first one with any kind of glob. So for example, if glob is 'a/b/c*/d',\n    return 'a/b'.'''\n    parts = []\n    for part in PurePosixPath(glob).parts:\n        if contains_unescaped_stars(part):\n            break\n        else:\n            parts.append(part)\n    return str(PurePosixPath(*parts)) if parts else ''", "response": "Returns all the path components starting from the beginning up to the beginning of the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a string on the star patterns and return a list of strings.", "response": "def split_on_stars_interpreting_backslashes(s):\n    r'''We don't want to do in-place substitutions of a regex for *, because we\n    need to be able to regex-escape the rest of the string. Instead, we split\n    the string on *'s, so that the rest can be regex-escaped and then rejoined\n    with the right regex. While we're doing this, check for backslash-escaped\n    *'s and \\'s, and leave them in as literals (to be regex-escaped in the next\n    step).'''\n\n    star_indices = [\n        match.end() - 1 for match in re.finditer(UNESCAPED_STAR_EXPR, s)\n    ]\n    literalized_parts = [\n        part.replace(r'\\*', '*').replace(r'\\\\', '\\\\')\n        for part in _split_on_indices(s, star_indices)\n    ]\n    return literalized_parts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a glob to a regex that can be used to match the path of a file or directory.", "response": "def glob_to_path_regex(glob):\n    '''Supports * and **. Backslashes can escape stars or other backslashes. As\n    in pathlib, ** may not adjoin any characters other than slash. Unlike\n    pathlib, because we're not talking to the actual filesystem, ** will match\n    files as well as directories. Paths get canonicalized before they're\n    converted, so duplicate and trailing slashes get dropped. You should make\n    sure the other paths you try to match are in canonical (Posix) form as\n    well.'''\n\n    canonical_glob = str(PurePosixPath(glob))\n\n    # The final regex starts with ^ and ends with $ to force it to match the\n    # whole path.\n    regex = '^'\n    components = canonical_glob.split('/')\n    for i, component in enumerate(components):\n        if component == '**':\n            if i == len(components) - 1:\n                raise GlobError(glob,\n                                '** may not be the last component in a path.')\n            else:\n                regex += r'(?:[^/]+/)*'\n        elif '**' in component:\n            raise GlobError(glob, '** must be an entire path component.')\n        else:\n            if component == '*':\n                # A lone * may not match empty.\n                regex += r'[^/]+'\n            else:\n                # A * with other characters may match empty. Escape all other\n                # regex special characters.\n                star_parts = split_on_stars_interpreting_backslashes(component)\n                escaped_parts = map(re.escape, star_parts)\n                regex += r'[^/]*'.join(escaped_parts)\n            # Add a trailing slash for every component except **.\n            if i < len(components) - 1:\n                regex += '/'\n\n    regex += '$'\n    return regex"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef force_utf8_in_ascii_mode_hack():\n    '''In systems without a UTF8 locale configured, Python will default to\n    ASCII mode for stdout and stderr. This causes our fancy display to fail\n    with encoding errors. In particular, you run into this if you try to run\n    peru inside of Docker. This is a hack to force emitting UTF8 in that case.\n    Hopefully it doesn't break anything important.'''\n    if sys.stdout.encoding == 'ANSI_X3.4-1968':\n        sys.stdout = open(\n            sys.stdout.fileno(), mode='w', encoding='utf8', buffering=1)\n        sys.stderr = open(\n            sys.stderr.fileno(), mode='w', encoding='utf8', buffering=1)", "response": "In systems with a UTF8 locale configured Python will default to\n    ASCII mode for stdout and stderr."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maybe_quote(val):\n    '''All of our values should be strings. Usually those can be passed in as\n    bare words, but if they're parseable as an int or float we need to quote\n    them.'''\n    assert isinstance(val, str), 'We should never set non-string values.'\n    needs_quoting = False\n    try:\n        int(val)\n        needs_quoting = True\n    except Exception:\n        pass\n    try:\n        float(val)\n        needs_quoting = True\n    except Exception:\n        pass\n    if needs_quoting:\n        return '\"{}\"'.format(val)\n    else:\n        return val", "response": "If we need to quote the value in as\n    then return val."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def gather_coalescing_exceptions(coros, display, *, verbose):\n    '''The tricky thing about running multiple coroutines in parallel is what\n    we're supposed to do when one of them raises an exception. The approach\n    we're using here is to catch exceptions and keep waiting for other tasks to\n    finish. At the end, we reraise a GatheredExceptions error, if any\n    exceptions were caught.\n\n    Another minor detail: We also want to make sure to start coroutines in the\n    order given, so that they end up appearing to the user alphabetically in\n    the fancy display. Note that asyncio.gather() puts coroutines in a set\n    internally, so we schedule coroutines *before* we give them to gather().\n    '''\n\n    exceptions = []\n    reprs = []\n\n    async def catching_wrapper(coro):\n        try:\n            return (await coro)\n        except Exception as e:\n            exceptions.append(e)\n            if isinstance(e, PrintableError) and not verbose:\n                reprs.append(e.message)\n            else:\n                reprs.append(traceback.format_exc())\n            return None\n\n    # Suppress a deprecation warning in Python 3.5, while continuing to support\n    # 3.3 and early 3.4 releases.\n    if hasattr(asyncio, 'ensure_future'):\n        schedule = getattr(asyncio, 'ensure_future')\n    else:\n        schedule = getattr(asyncio, 'async')\n\n    futures = [schedule(catching_wrapper(coro)) for coro in coros]\n\n    results = await asyncio.gather(*futures)\n\n    if exceptions:\n        raise GatheredExceptions(exceptions, reprs)\n    else:\n        return results", "response": "A helper function that returns a GatheredExceptions error if any of the coroutines raises an exception."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def create_subprocess_with_handle(command,\n                                        display_handle,\n                                        *,\n                                        shell=False,\n                                        cwd,\n                                        **kwargs):\n    '''Writes subprocess output to a display handle as it comes in, and also\n    returns a copy of it as a string. Throws if the subprocess returns an\n    error. Note that cwd is a required keyword-only argument, on theory that\n    peru should never start child processes \"wherever I happen to be running\n    right now.\"'''\n\n    # We're going to get chunks of bytes from the subprocess, and it's possible\n    # that one of those chunks ends in the middle of a unicode character. An\n    # incremental decoder keeps those dangling bytes around until the next\n    # chunk arrives, so that split characters get decoded properly. Use\n    # stdout's encoding, but provide a default for the case where stdout has\n    # been redirected to a StringIO. (This happens in tests.)\n    encoding = sys.stdout.encoding or 'utf8'\n    decoder_factory = codecs.getincrementaldecoder(encoding)\n    decoder = decoder_factory(errors='replace')\n\n    output_copy = io.StringIO()\n\n    # Display handles are context managers. Entering and exiting the display\n    # handle lets the display know when the job starts and stops.\n    with display_handle:\n        stdin = asyncio.subprocess.DEVNULL\n        stdout = asyncio.subprocess.PIPE\n        stderr = asyncio.subprocess.STDOUT\n        if shell:\n            proc = await asyncio.create_subprocess_shell(\n                command,\n                stdin=stdin,\n                stdout=stdout,\n                stderr=stderr,\n                cwd=cwd,\n                **kwargs)\n        else:\n            proc = await asyncio.create_subprocess_exec(\n                *command,\n                stdin=stdin,\n                stdout=stdout,\n                stderr=stderr,\n                cwd=cwd,\n                **kwargs)\n\n        # Read all the output from the subprocess as its comes in.\n        while True:\n            outputbytes = await proc.stdout.read(4096)\n            if not outputbytes:\n                break\n            outputstr = decoder.decode(outputbytes)\n            outputstr_unified = _unify_newlines(outputstr)\n            display_handle.write(outputstr_unified)\n            output_copy.write(outputstr_unified)\n\n        returncode = await proc.wait()\n\n    if returncode != 0:\n        raise subprocess.CalledProcessError(returncode, command,\n                                            output_copy.getvalue())\n\n    if hasattr(decoder, 'buffer'):\n        # The utf8 decoder has this attribute, but some others don't.\n        assert not decoder.buffer, 'decoder nonempty: ' + repr(decoder.buffer)\n\n    return output_copy.getvalue()", "response": "Creates a subprocess that will run the command and returns a copy of it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes an Imports struct and a dictionary of resolved trees and merge them into a single tree.", "response": "async def merge_imports_tree(cache, imports, target_trees, base_tree=None):\n    '''Take an Imports struct and a dictionary of resolved trees and merge the\n    unified imports tree. If base_tree is supplied, merge that too. There are a\n    couple reasons for structuring this function the way it is:\n        - We want to cache merged trees, so that we don't have to do expensive\n          git operations just to check whether a module is in cache.\n        - We want tree merging to know about target names, so that it can write\n          good error messages when there are conflicts.\n        - We need to use this for both toplevel imports and recursive module\n          imports.\n    '''\n    key = _cache_key(imports, target_trees, base_tree)\n    if key in cache.keyval:\n        return cache.keyval[key]\n    # We always want to merge imports in the same order, so that any conflicts\n    # we run into will be deterministic. Sort the imports alphabetically by\n    # target name.\n    unified_tree = base_tree or (await cache.get_empty_tree())\n    for target, paths in imports.items():\n        for path in paths:\n            try:\n                unified_tree = await cache.merge_trees(\n                    unified_tree, target_trees[target], path)\n            except MergeConflictError as e:\n                message = 'Merge conflict in import \"{}\" at \"{}\":\\n\\n{}'\n                e.message = message.format(target, path,\n                                           textwrap.indent(e.message, '  '))\n                raise\n    cache.keyval[key] = unified_tree\n    return unified_tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_request_filename(request):\n    '''Figure out the filename for an HTTP download.'''\n    # Check to see if a filename is specified in the HTTP headers.\n    if 'Content-Disposition' in request.info():\n        disposition = request.info()['Content-Disposition']\n        pieces = re.split(r'\\s*;\\s*', disposition)\n        for piece in pieces:\n            if piece.startswith('filename='):\n                filename = piece[len('filename='):]\n                # Strip exactly one \" from each end.\n                if filename.startswith('\"'):\n                    filename = filename[1:]\n                if filename.endswith('\"'):\n                    filename = filename[:-1]\n                # Interpret backslashed quotes.\n                filename = filename.replace('\\\\\"', '\"')\n                return filename\n    # If no filename was specified, pick a reasonable default.\n    return os.path.basename(urlsplit(request.url).path) or 'index.html'", "response": "Figure out the filename for an HTTP download."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_optional_list_field(blob, name):\n    '''Handle optional fields that can be either a string or a list of\n    strings.'''\n    value = _optional_list(typesafe_pop(blob, name, []))\n    if value is None:\n        raise ParserError(\n            '\"{}\" field must be a string or a list.'.format(name))\n    return value", "response": "Handle optional fields that can be either a string or a list of\n    strings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_multimap_field(blob, name):\n    '''Extracts multimap fields. Values can either be a scalar string or a list\n    of strings. We need to parse both. For example:\n        example:\n          a: foo/\n          b:\n            - bar/\n            - baz/'''\n    message = ('\"{}\" field must be a map whose values are either a string or '\n               'list of strings.'.format(name))\n    raw_map = typesafe_pop(blob, name, {}) or {}\n    if not isinstance(raw_map, dict):\n        raise ParserError(message)\n    # We use an `OrderedDict` to ensure that multimap fields are processed in a\n    # determinist order. This prevents obscure bugs caused by subtly different\n    # behavior.\n    multimap = collections.OrderedDict()\n    # Sort by key so that processing occurs in convenient lexographical order.\n    # This keeps things deterministic in a simple way.\n    for key, raw_value in sorted(raw_map.items()):\n        value = _optional_list(raw_value)\n        if value is None:\n            raise ParserError(message)\n        multimap[key] = value  # Remembers order.\n    return multimap", "response": "Extracts multimap fields. Values can either be a scalar string or a list\n    of strings. We need to parse both."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _optional_list(value):\n    '''Convert a value that may be a scalar (str) or list into a tuple. This\n    produces uniform output for fields that may supply a single value or list\n    of values, like the `imports` field.'''\n    if isinstance(value, str):\n        return (value, )\n    elif isinstance(value, list):\n        return tuple(value)\n\n    return None", "response": "Convert a value that may be a scalar list into a tuple. This assumes that the list contains only one item or a single item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop_all(self):\n        new_stack = type(self)()\n        new_stack._exit_callbacks = self._exit_callbacks\n        self._exit_callbacks = deque()\n        return new_stack", "response": "Preserve the context stack by transferring it to a new instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a callback with the standard __exit__ method signature.", "response": "def push(self, exit):\n        \"\"\"Registers a callback with the standard __exit__ method signature.\n        Can suppress exceptions the same way __exit__ method can.\n        Also accepts any object with an __exit__ method (registering a call\n        to the method instead of the object itself).\n        \"\"\"\n        # We use an unbound method rather than a bound method to follow\n        # the standard lookup behaviour for special methods.\n        _cb_type = type(exit)\n\n        try:\n            exit_method = _cb_type.__exit__\n        except AttributeError:\n            # Not a context manager, so assume it's a callable.\n            self._push_exit_callback(exit)\n        else:\n            self._push_cm_exit(exit, exit_method)\n        return exit"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nentering the supplied context manager. If successful also pushes its __exit__ method as a callback and returns the result of the __enter__ method.", "response": "def enter_context(self, cm):\n        \"\"\"Enters the supplied context manager.\n        If successful, also pushes its __exit__ method as a callback and\n        returns the result of the __enter__ method.\n        \"\"\"\n        # We look up the special methods on the type to match the with\n        # statement.\n        _cm_type = type(cm)\n        _exit = _cm_type.__exit__\n        result = _cm_type.__enter__(cm)\n        self._push_cm_exit(cm, _exit)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister an arbitrary callback and arguments.", "response": "def callback(self, callback, *args, **kwds):\n        \"\"\"Registers an arbitrary callback and arguments.\n        Cannot suppress exceptions.\n        \"\"\"\n        _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper)\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def enter_async_context(self, cm):\n        _cm_type = type(cm)\n        _exit = _cm_type.__aexit__\n        result = await _cm_type.__aenter__(cm)\n        self._push_async_cm_exit(cm, _exit)\n        return result", "response": "Enters the supplied async context manager. If successful also pushes its __aenter__ method as a callback and\n        returns the result of the __aenter__ method and returns the result of the __aexit__ method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_async_exit(self, exit):\n        _cb_type = type(exit)\n        try:\n            exit_method = _cb_type.__aexit__\n        except AttributeError:\n            # Not an async context manager, so assume it's a coroutine function\n            self._push_exit_callback(exit, False)\n        else:\n            self._push_async_cm_exit(exit, exit_method)\n        return exit", "response": "Registers a coroutine function with the standard __aexit__ method with the standard __aexit__ method signature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef push_async_callback(self, callback, *args, **kwds):\n        _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper, False)\n        return callback", "response": "Registers an arbitrary coroutine function and arguments. Can suppress exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwalk up the directory tree until we find a file of the given name.", "response": "def find_project_file(start_dir, basename):\n    '''Walk up the directory tree until we find a file of the given name.'''\n    prefix = os.path.abspath(start_dir)\n    while True:\n        candidate = os.path.join(prefix, basename)\n        if os.path.isfile(candidate):\n            return candidate\n        if os.path.exists(candidate):\n            raise PrintableError(\n                \"Found {}, but it's not a file.\".format(candidate))\n        if os.path.dirname(prefix) == prefix:\n            # We've walked all the way to the top. Bail.\n            raise PrintableError(\"Can't find \" + basename)\n        # Not found at this level. We must go...shallower.\n        prefix = os.path.dirname(prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the file at the given path if any exception is raised inside the context.", "response": "def delete_if_error(path):\n    '''If any exception is raised inside the context, delete the file at the\n    given path, and allow the exception to continue.'''\n    try:\n        yield\n    except Exception:\n        if os.path.exists(path):\n            os.remove(path)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a list of filenames that we re about to print limit it to a reasonable number of lines.", "response": "def _format_file_lines(files):\n    '''Given a list of filenames that we're about to print, limit it to a\n    reasonable number of lines.'''\n    LINES_TO_SHOW = 10\n    if len(files) <= LINES_TO_SHOW:\n        lines = '\\n'.join(files)\n    else:\n        lines = ('\\n'.join(files[:LINES_TO_SHOW - 1]) + '\\n...{} total'.format(\n            len(files)))\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of globs that can be used in git ls - files.", "response": "def dotperu_exclude_case_insensitive_git_globs():\n    \"\"\"These use the glob syntax accepted by `git ls-files` (NOT our own\n    glob.py). Note that ** must match at least one path component, so we have\n    to use separate globs for matches at the root and matches below.\"\"\"\n    globs = []\n    for capitalization in DOTPERU_CAPITALIZATIONS:\n        globs.append(capitalization + '/**')\n        globs.append('**/' + capitalization + '/**')\n    return globs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef git_env(self):\n        'Set the index file and prevent git from reading global configs.'\n        env = dict(os.environ)\n        for var in [\"HOME\", \"XDG_CONFIG_HOME\"]:\n            env.pop(var, None)\n        env[\"GIT_CONFIG_NOSYSTEM\"] = \"true\"\n        # Weirdly, GIT_INDEX_FILE is interpreted relative to the work tree. As\n        # a workaround, we absoluteify the path.\n        env[\"GIT_INDEX_FILE\"] = os.path.abspath(self.index_file)\n        return env", "response": "Set the index file and prevent git from reading global configs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying the contents of a tree.", "response": "async def modify_tree(self, tree, modifications):\n        '''The modifications are a map of the form, {path: TreeEntry}. The tree\n        can be None to indicate an empty starting tree. The entries can be\n        either blobs or trees, or None to indicate a deletion. The return value\n        is either the hash of the resulting tree, or None if the resulting tree\n        is empty. Modifications in parent directories are done before\n        modifications in subdirectories below them, so for example you can\n        insert a tree at a given path and also insert more new stuff beneath\n        that path, without fear of overwriting the new stuff.'''\n\n        # Read the original contents of the base tree.\n        if tree is None:\n            entries = {}\n        else:\n            entries = await self.ls_tree(tree, '.')\n\n        # Separate the modifications into two groups, those that refer to\n        # entries at the base of this tree (e.g. 'foo'), and those that refer\n        # to entries in subtrees (e.g. 'foo/bar').\n        modifications_at_base = dict()\n        modifications_in_subtrees = collections.defaultdict(dict)\n        for path_str, entry in modifications.items():\n            # Canonicalize paths to get rid of duplicate/trailing slashes.\n            path = pathlib.PurePosixPath(path_str)\n\n            # Check for nonsense paths.\n            # TODO: Maybe stop recursive calls from repeating these checks.\n            if len(path.parts) == 0:\n                raise ModifyTreeError('Cannot modify an empty path.')\n            elif path.parts[0] == '/':\n                raise ModifyTreeError('Cannot modify an absolute path.')\n            elif '..' in path.parts:\n                raise ModifyTreeError('.. is not allowed in tree paths.')\n\n            if len(path.parts) == 1:\n                modifications_at_base[str(path)] = entry\n            else:\n                first_dir = path.parts[0]\n                rest = str(pathlib.PurePosixPath(*path.parts[1:]))\n                modifications_in_subtrees[first_dir][rest] = entry\n\n        # Insert or delete entries in the base tree. Note that this happens\n        # before any subtree operations.\n        for name, entry in modifications_at_base.items():\n            if entry is None:\n                entries.pop(name, None)\n            else:\n                entries[name] = entry\n\n        # Recurse to compute modified subtrees. Note how we handle deletions:\n        # If 'a' is a file, inserting a new file at 'a/b' will implicitly\n        # delete 'a', but trying to delete 'a/b' will be a no-op and will not\n        # delete 'a'.\n        empty_tree = (await self.get_empty_tree())\n        for name, sub_modifications in modifications_in_subtrees.items():\n            subtree_base = None\n            if name in entries and entries[name].type == TREE_TYPE:\n                subtree_base = entries[name].hash\n            new_subtree = await self.modify_tree(subtree_base,\n                                                 sub_modifications)\n            if new_subtree != empty_tree:\n                entries[name] = TreeEntry(TREE_MODE, TREE_TYPE, new_subtree)\n            # Delete an empty tree if it was actually a tree to begin with.\n            elif name in entries and entries[name].type == TREE_TYPE:\n                del entries[name]\n\n        # Return the resulting tree, or None if empty.\n        if entries:\n            session = self.no_index_git_session()\n            tree = await session.make_tree_from_entries(entries)\n            return tree\n        else:\n            return empty_tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_states():\n\n    from pkg_resources import resource_stream\n\n    # load state data from pickle file\n    with resource_stream(__name__, 'states.pkl') as pklfile:\n        for s in pickle.load(pklfile):\n\n            state = State(**s)  # create state object\n\n            # create separate lists for obsolete, states, and territories\n            if state.is_obsolete:\n                OBSOLETE.append(state)\n            elif state.is_territory:\n                TERRITORIES.append(state)\n            else:\n                STATES.append(state)\n\n                if state.is_contiguous:\n                    STATES_CONTIGUOUS.append(state)\n                if state.is_continental:\n                    STATES_CONTINENTAL.append(state)\n\n            # also create list of all states and territories\n            STATES_AND_TERRITORIES.append(state)\n\n            # provide package-level abbreviation access: us.states.MD\n            globals()[state.abbr] = state", "response": "Load state data from pickle file distributed with this package."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery google scholar and return a list of citations.", "response": "def query(searchstr, outformat=FORMAT_BIBTEX, allresults=False):\n    \"\"\"Query google scholar.\n\n    This method queries google scholar and returns a list of citations.\n\n    Parameters\n    ----------\n    searchstr : str\n        the query\n    outformat : int, optional\n        the output format of the citations. Default is bibtex.\n    allresults : bool, optional\n        return all results or only the first (i.e. best one)\n\n    Returns\n    -------\n    result : list of strings\n        the list with citations\n\n    \"\"\"\n    logger.debug(\"Query: {sstring}\".format(sstring=searchstr))\n    searchstr = '/scholar?q='+quote(searchstr)\n    url = GOOGLE_SCHOLAR_URL + searchstr\n    header = HEADERS\n    header['Cookie'] = \"GSP=CF=%d\" % outformat\n    request = Request(url, headers=header)\n    response = urlopen(request)\n    html = response.read()\n    html = html.decode('utf8')\n    # grab the links\n    tmp = get_links(html, outformat)\n\n    # follow the bibtex links to get the bibtex entries\n    result = list()\n    if not allresults:\n        tmp = tmp[:1]\n    for link in tmp:\n        url = GOOGLE_SCHOLAR_URL+link\n        request = Request(url, headers=header)\n        response = urlopen(request)\n        bib = response.read()\n        bib = bib.decode('utf8')\n        result.append(bib)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_links(html, outformat):\n    if outformat == FORMAT_BIBTEX:\n        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.bib\\?[^\"]*)')\n    elif outformat == FORMAT_ENDNOTE:\n        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.enw\\?[^\"]*)\"')\n    elif outformat == FORMAT_REFMAN:\n        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.ris\\?[^\"]*)\"')\n    elif outformat == FORMAT_WENXIANWANG:\n        refre = re.compile(r'<a href=\"https://scholar.googleusercontent.com(/scholar\\.ral\\?[^\"]*)\"')\n    reflist = refre.findall(html)\n    # escape html entities\n    reflist = [re.sub('&(%s);' % '|'.join(name2codepoint), lambda m:\n                      chr(name2codepoint[m.group(1)]), s) for s in reflist]\n    return reflist", "response": "Return a list of reference links from the html."}
