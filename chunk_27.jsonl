{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new instance of the class from a JSON string.", "response": "def from_JSON(oauth_json, type = \"service\"):\n        '''At the time of writing, keys include:\n            client_secret, client_email, redirect_uris (list), client_x509_cert_url, client_id, javascript_origins (list)\n            auth_provider_x509_cert_url, auth_uri, token_uri.'''\n        assert(type == \"service\" or type == \"web\")\n        return NestedBunch(json.loads(oauth_json)[type])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all registrations for a section with the given is_active flag.", "response": "def _registrations_for_section_with_active_flag(section, is_active,\n                                                transcriptable_course=\"\"):\n    \"\"\"\n    Returns a list of all uw_sws.models.Registration objects\n    for a section. There can be duplicates for a person.\n    If is_active is True, the objects will have is_active set to True.\n    Otherwise, is_active is undefined, and out of scope for this method.\n    \"\"\"\n    instructor_reg_id = \"\"\n    if (section.is_independent_study and\n            section.independent_study_instructor_regid is not None):\n        instructor_reg_id = section.independent_study_instructor_regid\n\n    params = [\n        (\"curriculum_abbreviation\", section.curriculum_abbr),\n        (\"instructor_reg_id\", instructor_reg_id),\n        (\"course_number\", section.course_number),\n        (\"verbose\", \"true\"),\n        (\"year\", section.term.year),\n        (\"quarter\", section.term.quarter),\n        (\"is_active\", \"true\" if is_active else \"\"),\n        (\"section_id\", section.section_id),\n    ]\n\n    if transcriptable_course != \"\":\n        params.append((\"transcriptable_course\", transcriptable_course,))\n\n    url = \"{}?{}\".format(registration_res_url_prefix, urlencode(params))\n\n    return _json_to_registrations(get_resource(url), section)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _json_to_registrations(data, section):\n    registrations = []\n    person_threads = {}\n    for reg_data in data.get(\"Registrations\", []):\n        registration = Registration()\n        registration.section = section\n        registration.is_active = reg_data[\"IsActive\"]\n        registration.is_credit = reg_data[\"IsCredit\"]\n        registration.is_auditor = reg_data[\"Auditor\"]\n        registration.is_independent_start = reg_data[\"IsIndependentStart\"]\n        if len(reg_data[\"StartDate\"]):\n            registration.start_date = parse(reg_data[\"StartDate\"])\n        if len(reg_data[\"EndDate\"]):\n            registration.end_date = parse(reg_data[\"EndDate\"])\n        if len(reg_data[\"RequestDate\"]):\n            registration.request_date = parse(reg_data[\"RequestDate\"])\n        registration.request_status = reg_data[\"RequestStatus\"]\n        registration.duplicate_code = reg_data[\"DuplicateCode\"]\n        registration.credits = reg_data[\"Credits\"]\n        registration.repository_timestamp = datetime.strptime(\n            reg_data[\"RepositoryTimeStamp\"], \"%m/%d/%Y %H:%M:%S %p\")\n        registration.repeat_course = reg_data[\"RepeatCourse\"]\n        registration.grade = reg_data[\"Grade\"]\n\n        registration._uwregid = reg_data[\"Person\"][\"RegID\"]\n        if registration._uwregid not in person_threads:\n            thread = SWSPersonByRegIDThread()\n            thread.regid = registration._uwregid\n            thread.start()\n            person_threads[registration._uwregid] = thread\n\n        registrations.append(registration)\n\n    for registration in registrations:\n        thread = person_threads[registration._uwregid]\n        thread.join()\n        registration.person = thread.person\n        del registration._uwregid\n\n    return registrations", "response": "Convert JSON data to list of uw_sws. models. Registration objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_credits_by_section_and_regid(section, regid):\n    deprecation(\"Use get_credits_by_reg_url\")\n    # note trailing comma in URL, it's required for the optional dup_code param\n    url = \"{}{},{},{},{},{},{},.json\".format(\n        reg_credits_url_prefix,\n        section.term.year,\n        section.term.quarter,\n        re.sub(' ', '%20', section.curriculum_abbr),\n        section.course_number,\n        section.section_id,\n        regid\n    )\n\n    reg_data = get_resource(url)\n\n    try:\n        return Decimal(reg_data['Credits'].strip())\n    except InvalidOperation:\n        pass", "response": "Get the credits for a given section and regid."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the class schedule for the regid and term passed in.", "response": "def get_schedule_by_regid_and_term(regid, term,\n                                   non_time_schedule_instructors=True,\n                                   per_section_prefetch_callback=None,\n                                   transcriptable_course=\"\", **kwargs):\n    \"\"\"\n    Returns a uw_sws.models.ClassSchedule object\n    for the regid and term passed in.\n    \"\"\"\n\n    if \"include_instructor_not_on_time_schedule\" in kwargs:\n        include = kwargs[\"include_instructor_not_on_time_schedule\"]\n        non_time_schedule_instructors = include\n    params = [\n        ('reg_id', regid),\n    ]\n\n    if transcriptable_course != \"\":\n        params.append((\"transcriptable_course\", transcriptable_course,))\n\n    params.extend([\n        ('quarter', term.quarter),\n        ('is_active', 'true'),\n        ('year', term.year),\n    ])\n\n    url = \"{}?{}\".format(registration_res_url_prefix, urlencode(params))\n\n    return _json_to_schedule(get_resource(url), term, regid,\n                             non_time_schedule_instructors,\n                             per_section_prefetch_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding and return a transition in the model for the given gene and multiplexes. Raise an AttributeError if there is no transition in the model for the given gene and multiplexes.", "response": "def find_transition(self, gene: Gene, multiplexes: Tuple[Multiplex, ...]) -> Transition:\n        \"\"\" \n        Find and return a transition in the model for the given gene and multiplexes.\n        Raise an AttributeError if there is no multiplex in the graph with the given name.\n        \"\"\"\n        multiplexes = tuple(multiplex for multiplex in multiplexes if gene in multiplex.genes)\n        for transition in self.transitions:\n            if transition.gene == gene and set(transition.multiplexes) == set(multiplexes):\n                return transition\n        raise AttributeError(f'transition K_{gene.name}' + ''.join(f\"+{multiplex!r}\" for multiplex in multiplexes) + ' does not exist')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the available state for a given state.", "response": "def available_state(self, state: State) -> Tuple[State, ...]:\n        \"\"\" Return the state reachable from a given state. \"\"\"\n        result = []\n        for gene in self.genes:\n            result.extend(self.available_state_for_gene(gene, state))\n        if len(result) > 1 and state in result:\n            result.remove(state)\n        return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef available_state_for_gene(self, gene: Gene, state: State) -> Tuple[State, ...]:\n        result: List[State] = []\n        active_multiplex: Tuple[Multiplex] = gene.active_multiplex(state)\n        transition: Transition = self.find_transition(gene, active_multiplex)\n        current_state: int = state[gene]\n        done = set()\n        for target_state in transition.states:\n            target_state: int = self._state_after_transition(current_state, target_state)\n            if target_state not in done:\n                done.add(target_state)\n                new_state: State = state.copy()\n                new_state[gene] = target_state\n                result.append(new_state)\n        return tuple(result)", "response": "Return the state reachable from a given state for a particular gene."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _state_after_transition(self, current_state: int, target_state: int) -> int:\n        return current_state + (current_state < target_state) - (current_state > target_state)", "response": "Return the state after a transition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse the NCBI IP Converter API to convert a list of publication IDs to a list of publication IDs of the specified type from_type e. g. DOI identifiers to PubMed identifiers.", "response": "def convert(ids, from_type):\n    '''Uses the NCBI IP Converter API to converts a list of publication IDs in the same format e.g. DOI identifiers to\n    another format e.g. PubMed identifiers.\n        ids is a list of IDs of the type from_type e.g. a from_type of 'doi' specifies DOI identifiers.\n        The function returns a Python dict with the mappings from the input IDs to IDs of all other types.\n    '''\n\n    if from_type not in converter_types:\n        raise PubMedConverterTypeException(from_type)\n\n    # Avoid multiple requests of the same ID\n    mapping = {}\n    ids = list(set(ids))\n\n    # Request the mapping from the server\n    query_string = \"?ids=%s&idtype=%s\" % (urllib2.quote(\",\".join(ids), ''), from_type)\n    xml = get_resource(\"www.ncbi.nlm.nih.gov\", '/pmc/utils/idconv/v1.0/%s' % query_string).strip()\n\n    # Parse the response\n    try:\n        _dom = parseString(xml)\n        main_tag = _dom.getElementsByTagName(\"pmcids\")\n        assert(len(main_tag) == 1)\n        main_tag = main_tag[0]\n        request_status = main_tag.getAttribute('status')\n    except Exception, e:\n        raise PubMedIDRetrievalException('An error occurred retrieving the XML from the PubMed ID Converter API: %s.' % str(e))\n\n    if request_status == 'ok':\n        for record_tag in main_tag.getElementsByTagName(\"record\"):\n            attributes = record_tag.attributes\n            record_keys = attributes.keys()\n            assert('requested-id' in record_keys)\n            from_key = attributes['requested-id'].value\n            assert(from_key not in mapping)\n            mapping[from_key] = {}\n            for k in record_keys:\n                if k != 'requested-id':\n                    mapping[from_key][k] = attributes[k].value\n    else:\n        # todo: parse the error tag here to print more details\n        raise PubMedIDRetrievalException('The request to the PubMed ID Converter API failed. Please check that the IDs are of the correct types.')\n\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the value of the attribute.", "response": "def validate(self, value, model=None, context=None):\n        \"\"\" Perform validation \"\"\"\n        from boiler.user.services import user_service\n\n        self_id = None\n        if model:\n            if isinstance(model, dict):\n                self_id = model.get('id')\n            else:\n                self_id = getattr(model, 'id')\n\n        params = dict()\n        params[self.property] = value\n        found = user_service.first(**params)\n        if not found or (model and self_id == found.id):\n            return Error()\n\n        return Error(self.error)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the handle value.", "response": "def validate(self, value, model=None, context=None):\n        \"\"\" Perform validation \"\"\"\n        from boiler.user.services import role_service\n\n        self_id = None\n        if model:\n            if isinstance(model, dict):\n                self_id = model.get('id')\n            else:\n                self_id = getattr(model, 'id')\n\n        found = role_service.first(handle=value)\n        if not found or (model and self_id == found.id):\n            return Error()\n\n        return Error(self.error)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the command line arguments given to this program.", "response": "def _get_arguments():  # pragma: no cover\n    \"\"\" Handle the command line arguments given to this program \"\"\"\n    LOG.debug('Parse command line argument')\n    parser = argparse.ArgumentParser(\n        description='Command line interface for the MQ\u00b2 program')\n\n    parser.add_argument(\n        '-z', '--zipfile', dest='inputzip', default=None,\n        help='Zip file containing the input files.')\n    parser.add_argument(\n        '-d', '--dir', dest='inputdir', default=None,\n        help='Path to a local folder containing the input files.')\n    parser.add_argument(\n        '-f', '--file', dest='inputfile', default=None,\n        help='Path to a local input file.')\n\n    parser.add_argument(\n        '--lod', default=3,\n        help='LOD threshold to use to assess the significance of a LOD \\\n        value for a QTL.')\n\n    parser.add_argument(\n        '--session', default=None,\n        help='Session to analyze if required.')\n\n    parser.add_argument(\n        '--verbose', action='store_true',\n        help=\"Gives more info about what's going on\")\n    parser.add_argument(\n        '--debug', action='store_true',\n        help=\"Outputs debugging information\")\n    parser.add_argument(\n        '--version', action='version',\n        version='MQ\u00b2 version: %s' % __version__)\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the MQ2 plugin.", "response": "def run_mq2(plugin, folder, lod_threshold=None, session=None,\n            outputfolder=None):\n    \"\"\" Run the plugin. \"\"\"\n\n    qtls_file = 'qtls.csv'\n    matrix_file = 'qtls_matrix.csv'\n    map_file = 'map.csv'\n    map_qtl_file = 'map_with_qtls.csv'\n    qtls_mk_file = 'qtls_with_mk.csv'\n    map_chart_file = 'MapChart.map'\n    if outputfolder:  # pragma: no cover\n        qtls_file = '%s/%s' % (outputfolder, qtls_file)\n        qtls_mk_file = '%s/%s' % (outputfolder, qtls_mk_file)\n        matrix_file = '%s/%s' % (outputfolder, matrix_file)\n        map_file = '%s/%s' % (outputfolder, map_file)\n        map_qtl_file = '%s/%s' % (outputfolder, map_qtl_file)\n        map_chart_file = '%s/%s' % (outputfolder, map_chart_file)\n\n    LOG.debug('Call the plugin to create the map, qtls and matrix files')\n    if folder and os.path.isdir(folder):\n        plugin.convert_inputfiles(folder=folder, session=session,\n                                  lod_threshold=lod_threshold,\n                                  qtls_file=qtls_file,\n                                  matrix_file=matrix_file,\n                                  map_file=map_file)\n    else:\n        plugin.convert_inputfiles(inputfile=folder, session=session,\n                                  lod_threshold=lod_threshold,\n                                  qtls_file=qtls_file,\n                                  matrix_file=matrix_file,\n                                  map_file=map_file)\n\n    LOG.debug('Add the number of QTLs found on the matrix')\n    _append_count_to_matrix(matrix_file, lod_threshold)\n\n    LOG.debug('Append the closest marker to the peak')\n    add_marker_to_qtls(qtls_file, map_file, outputfile=qtls_mk_file)\n\n    LOG.debug('Put the number of QTLs found on each marker of the map')\n    add_qtl_to_map(qtls_mk_file, map_file, outputfile=map_qtl_file)\n\n    LOG.debug('Generate the mapchart file')\n    flanking_markers = generate_map_chart_file(\n        matrix_file, lod_threshold, map_chart_file=map_chart_file)\n\n    LOG.debug('Append flanking markers to qtl list')\n    flanking_markers = append_flanking_markers(\n        qtls_mk_file, flanking_markers)\n\n    if folder and os.path.isdir(folder) and os.path.exists(folder):\n        shutil.rmtree(folder)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _append_count_to_matrix(qtl_matrixfile, lod_threshold):\n    if not os.path.exists(qtl_matrixfile):  # pragma: no cover\n        raise MQ2Exception('File not found: \"%s\"' % qtl_matrixfile)\n    matrix = read_input_file(qtl_matrixfile, sep=',')\n    tmp = list(matrix[0])\n    tmp.append('# QTLs')\n    matrix[0] = tmp\n    cnt = 1\n    while cnt < len(matrix):\n        row = list(matrix[cnt])\n        nr_qtl = 0\n        for cel in row[3:]:\n            if cel and float(cel) > float(lod_threshold):\n                nr_qtl = nr_qtl + 1\n        row.append(str(nr_qtl))\n        matrix[cnt] = row\n        cnt = cnt + 1\n    write_matrix(qtl_matrixfile, matrix)", "response": "Append an extra column to the matrix file containing the number of QTLs found if the marker is known by the given LOD value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the demo suite in a loop.", "response": "def loop(self):\n        \"\"\"\n        Run the demo suite in a loop.\n        \"\"\"\n        logging.info(\"Running %s in loop mode.\" % self.service_name)\n\n        res = None\n        while True:\n            try:\n                res = self.run()\n                time.sleep(self.loop_duration)\n            except KeyboardInterrupt:\n                logging.warning(\"Keyboard Interrupt during loop, stopping %s service now...\" % self.service_name)\n                break\n            except Exception as e:\n                logging.exception(\"Error in %s main loop! (%s)\" % (self.service_name, e))\n                raise e\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prep(s, p, o):\n    '''\n    Prepare a triple for rdflib\n    '''\n    def bnode_check(r):\n        return isinstance(r, mock_bnode) or r.startswith('VERSABLANKNODE_')\n\n    s = BNode() if bnode_check(s) else URIRef(s)\n    p = URIRef(p)\n    o = BNode() if bnode_check(o) else (URIRef(o) if isinstance(o, I) else Literal(o))\n    return s, p, o", "response": "Prepare a triple for rdflib\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenriching the given list of objects so they have URL.", "response": "def url(request, json_list, nested, url_name='show_{}', ignore_get=None):\n    \"\"\"\n    Enrich the given list of objects, so they have URL.\n\n    Args:\n        request (django.http.request.HttpRequest): request which is currently processed\n        json_list (list): list of dicts (JSON objects to be enriched)\n        url_name (str|fun): pattern to create a url name taking object_type\n        ignore_get (list): list of GET parameters which are ignored when the URL is generated\n\n    Returns:\n        list: list of dicts (enriched JSON objects)\n    \"\"\"\n    if not ignore_get:\n        ignore_get = []\n    if isinstance(url_name, str):\n        url_string = str(url_name)\n        url_name = lambda x: url_string.format(x)\n    urls = cache.get('proso_urls')\n    if urls is None:\n        urls = {}\n    else:\n        urls = json_lib.loads(urls)\n    cache_updated = False\n    pass_string = pass_get_parameters_string(request, ignore_get)\n    for json in json_list:\n        if 'object_type' not in json or 'id' not in json:\n            continue\n        key = 'show_%s_%s' % (json['object_type'], json['id'])\n        if key in urls:\n            json['url'] = urls[key]\n        else:\n            cache_updated = True\n            json['url'] = reverse(url_name(json['object_type']), kwargs={'id': json['id']})\n            urls[key] = json['url']\n        json['url'] = append_get_parameters(json['url'], pass_string)\n    if cache_updated:\n        cache.set('proso_urls', json_lib.dumps(urls), CACHE_EXPIRATION)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sub_state_by_gene_name(self, *gene_names: str) -> 'State':\n        return State({gene: state for gene, state in self.items() if gene.name in gene_names})", "response": "Create a sub state with only the gene passed in names."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncombine pymongo. monitoring events to queries.", "response": "def combine_events_to_queries(_mongo_events):\n    \"\"\"Combines pymongo.monitoring events to queries.\n\n    CommandStartedEvent has queries information.\n    CommandSuccessfulEvent has timing information.\n\n    Iterate over events and map against mongo's request_id (the query).\n    \"\"\"\n    queries = {}  # map on the request_id\n\n    for event in _mongo_events:\n        if event.request_id not in queries:\n            try:\n                connection = ProfilingQueryConnection(*event.connection_id)\n            except NameError:\n                connection = event.connection_id\n            queries[event.request_id] = dict(  # all event types have this\n                command_name=event.command_name,\n                # Unpack host,\n                connection=connection,\n                operation_id=event.operation_id,\n            )\n\n        if isinstance(event, pymongo.monitoring.CommandStartedEvent):\n            queries[event.request_id].update(\n                command=sanitize_dict(event.command.to_dict()),\n                database_name=event.database_name,\n            )\n        elif isinstance(event, pymongo.monitoring.CommandSucceededEvent):\n            queries[event.request_id].update(duration=event.duration_micros / 1000)\n        elif isinstance(event, pymongo.monitoring.CommandFailedEvent):\n            queries[event.request_id].update(\n                failure=sanitize_dict(event.failure),\n                duration=event.duration_micros / 1000,\n            )\n\n    return queries.values()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an argument parser for the lograptor command line options and arguments parsing.", "response": "def create_argument_parser():\n    \"\"\"\n    Command line options and arguments parsing. This function return\n    a list of options and the list of arguments (pattern, filenames).\n    \"\"\"\n    parser = argparse.ArgumentParser(prog='lograptor', description=__description__, add_help=False)\n    parser.usage = \"\"\"%(prog)s [options] PATTERN [FILE ...]\n    %(prog)s [options] [-e PATTERN | -f FILE] [FILE ...]\n    Try '%(prog)s --help' for more information.\"\"\"\n\n    group = parser.add_argument_group(\"General Options\")\n    group.add_argument(\n        \"--conf\", dest=\"cfgfiles\", action='append', default=None, metavar=\"FILE\",\n        help=\"use a specific configuration file\"\n    )\n    group.add_argument(\n        \"-d\", dest=\"loglevel\", default=2, type=int, metavar=\"[0-4]\", choices=range(5),\n        help=\"Logging level (default is 2, use 4 for debug). A level of 0 suppress also \"\n             \"error messages about nonexistent or unreadable files.\"\n    )\n    group.add_argument('-V', '--version', action='version', version=__version__)\n    group.add_argument('--help', action='help', help=\"show this help message and exit\")\n\n    group = parser.add_argument_group(\"Scope Selection\")\n    group.add_argument(\n        \"-a\", \"--apps\", metavar='APP[,APP...]', type=comma_separated_string,\n        default=[], help=\"process the log lines related to a list of applications\"\n    )\n    group.add_argument(\n        \"--hosts\", metavar=\"HOSTNAME/IP[,HOSTNAME/IP...]\", type=comma_separated_string,\n        default=[], help=\"process the log lines related to an hostname/IP\"\n    )\n    group.add_argument(\n        \"-F\", \"--filter\", metavar=\"FIELD=PATTERN[,FIELD=PATTERN...]\",\n        action=\"append\", dest=\"filters\", type=filter_spec, default=[],\n        help=\"process the log lines that match all the conditions for rule's field values\"\n    )\n    group.add_argument(\n        \"--time\", metavar=\"HH:MM,HH:MM\", type=TimeRange, action=\"store\", dest=\"time_range\",\n        help=\"process the log lines related to a time range\"\n    )\n    group.add_argument(\n        \"--date\", metavar=\"[YYYY]MMDD[,[YYYY]MMDD]\", action=\"store\", dest=\"time_period\",\n        type=date_interval_spec, help=\"restrict the search scope to a date or a date interval\"\n    )\n    group.add_argument(\n        \"--last\", action=\"store\", dest=\"time_period\", type=last_period_spec,\n        metavar=\"[hour|day|week|month|Nh|Nd|Nw|Nm]\",\n        help=\"restrict the search scope to a previous time period\"\n    )\n\n    group = parser.add_argument_group(\"Matcher Selection\")\n    group.add_argument(\n        \"-G\", \"--ruled\", dest='matcher', action=StoreOptionAction,\n        help=\"use patterns and application rules (default)\"\n    )\n    group.add_argument(\n        \"-X\", \"--unruled\", dest='matcher', action=StoreOptionAction,\n        help=\"use patterns only, skip application rules\"\n    )\n    group.add_argument(\n        \"-U\", \"--unparsed\", dest='matcher', action=StoreOptionAction,\n        help=\"match the patterns, don't match any application rule\"\n    )\n\n    group = parser.add_argument_group(\"Matching Control\")\n    group.add_argument(\n        \"-e\", \"--regexp\", metavar=\"PATTERN\", dest=\"patterns\", default=[],\n        action=\"append\", help=\"use PATTERN for matching\"\n    )\n    group.add_argument(\n        \"-f\", \"--file\", metavar=\"FILE\", dest=\"pattern_files\", default=[],\n        action=\"append\", help=\"obtain patterns from FILE\"\n    )\n    group.add_argument(\n        \"-i\", \"--ignore-case\", action=\"store_true\", dest=\"case\", default=False,\n        help=\"ignore case distinctions\"\n    )\n    group.add_argument(\n        \"-v\", \"--invert-match\", action=\"store_true\", dest=\"invert\", default=False,\n        help=\"invert the sense of patterns regexp matching\"\n    )\n    group.add_argument(\n        \"-w\", \"--word-regexp\", action=\"store_true\", dest=\"word\", default=False,\n        help=\"force PATTERN to match only whole words\"\n    )\n\n    group = parser.add_argument_group(\"General Output Control\")\n    group.add_argument(\n        \"--output\", default=['stdout'], metavar='CHANNEL[,CHANNEL...]', dest='channels',\n        type=comma_separated_string, help=\"send output to channels (default: ['stdout'])\"\n    )\n    group.add_argument(\n        \"-c\", \"--count\", action=\"store_true\", default=False,\n        help=\"print only a count of matching lines per FILE\"\n    )\n    group.add_argument(\n        \"--color\", default='auto', nargs='?', choices=['auto', 'always', 'never'],\n        help=\"use markers to highlight the matching strings\"\n    )\n    group.add_argument(\n        \"-L\", \"--files-without-match\", action=\"store_false\", dest=\"files_with_match\", default=None,\n        help=\"print only names of FILEs containing no match\"\n    )\n    group.add_argument(\n        \"-l\", \"--files-with-match\", action=\"store_true\", dest=\"files_with_match\",\n        help=\"print only names of FILEs containing matches\"\n    )\n    group.add_argument(\n        \"-m\", \"--max-count\", metavar='NUM', action=\"store\", type=positive_integer, default=0,\n        help=\"stop after NUM matches\"\n    )\n    group.add_argument(\n        \"-o\", \"--only-matching\", action=\"store_true\", default=False,\n        help=\"show only the part of a line matching PATTERN\"\n    )\n    group.add_argument(\n        \"-q\", \"--quiet\", action=\"store_true\", default=False, help=\"suppress all normal output\"\n    )\n    group.add_argument(\n        \"-s\", \"--no-messages\", action=\"store_const\", const=0, dest='loglevel',\n        help=\"suppress error messages (equivalent to -d 0)\"\n    )\n\n    group = parser.add_argument_group(\"Output Data Control\")\n    group.add_argument(\n        \"--report\", metavar='NAME', nargs='?', default=False,\n        help=\"produce a report at the end of processing\"\n    )\n    group.add_argument(\n        \"--ip-lookup\", action=\"store_true\", default=False,\n        help=\"translate IP addresses to DNS names\"\n    )\n    group.add_argument(\n        \"--uid-lookup\", action=\"store_true\", default=False,\n        help=\"translate UIDs to usernames\"\n    )\n    group.add_argument(\n        \"--anonymize\", action=\"store_true\", default=False,\n        help=\"anonymize defined rule's fields value\"\n    )\n\n    group = parser.add_argument_group(\"Output Line Prefix Control\")\n    group.add_argument(\n        \"-n\", \"--line-number\", action=\"store_true\", default=False,\n        help=\"print line number with output lines\"\n    )\n    group.add_argument(\n        \"-H\", \"--with-filename\", action=\"store_true\", dest=\"with_filename\", default=None,\n        help=\"print the file name for each match\"\n    )\n    group.add_argument(\n        \"-h\", \"--no-filename\", action=\"store_false\", dest=\"with_filename\", default=None,\n        help=\"suppress the file name prefix on output\"\n    )\n\n    group = parser.add_argument_group(\"Context Line Control\")\n    group.add_argument(\n        \"-T\", \"--thread\", action=\"store_true\", default=False,\n        help=\"the context is the log thread of the application\"\n    )\n    group.add_argument(\n        \"-B\", \"--before-context\", metavar='NUM', type=positive_integer, default=0,\n        help=\"print NUM lines of leading context\"\n    )\n    group.add_argument(\n        \"-A\", \"--after-context\", metavar='NUM', type=positive_integer, default=0,\n        help=\"print NUM lines of trailing context\"\n    )\n    group.add_argument(\n        \"-C\", \"--context\", metavar='NUM', type=positive_integer, default=0,\n        help=\"print NUM lines of output context\"\n    )\n    group.add_argument(\n        \"--group-separator\", metavar='SEP', default='--',\n        help=\"use SEP as a group separator. By default SEP is double hyphen (--).\"\n    )\n    group.add_argument(\n        \"--no-group-separator\", dest=\"group_separator\", action=\"store_const\", const='',\n        help=\"use empty string as a group separator\"\n    )\n\n    group = parser.add_argument_group(\"File and Directory Selection\")\n    group.add_argument(\n        \"-r\", \"--recursive\", action=\"store_true\", default=False,\n        help=\"read all files under each directory, recursively\"\n    )\n    group.add_argument(\n        \"-R\", \"--dereference-recursive\", action=\"store_true\", default=False,\n        help=\"likewise, but follow all symlinks\"\n    )\n    group.add_argument(\n        \"--include\", metavar='GLOB', default=[], action=\"append\",\n        help=\"search only files that match GLOB\"\n    )\n    group.add_argument(\n        \"--exclude\", metavar='GLOB', default=[], action=\"append\",\n        help=\"skip files and directories matching GLOB\"\n    )\n    group.add_argument(\n        \"--exclude-from\", metavar='FILE', default=[], action=\"append\",\n        help=\"skip files matching any file pattern from FILE\"\n    )\n    group.add_argument(\n        \"--exclude-dir\", metavar='DIR', default=[], action=\"append\",\n        help=\"exclude directories matching the pattern DIR\"\n    )\n\n    parser.add_argument(\n        'files', metavar='[FILE ...]', nargs='*',\n        help='Input files. Each argument can be a file path or a glob pathname. '\n             'A \"-\" stands for standard input. If no arguments are given then processes '\n             'all the files included within the scope of the selected applications.'\n    )\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_void_args(argv):\n    n_args = len(argv)\n    return n_args == 1 or n_args == 2 and argv[1].startswith('--conf=') or n_args == 3 and argv[1] == '--conf'", "response": "Check if the command line has void arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lograptor(files, patterns=None, matcher='ruled', cfgfiles=None, apps=None, hosts=None,\n              filters=None, time_period=None, time_range=None, case=False, invert=False,\n              word=False, files_with_match=None, count=False, quiet=False, max_count=0,\n              only_matching=False, line_number=False, with_filename=None,\n              ip_lookup=False, uid_lookup=False, anonymize=False, thread=False,\n              before_context=0, after_context=0, context=0):\n    \"\"\"\n    Run lograptor with arguments. Experimental feature to use the log processor into\n    generic Python scripts. This part is still under development, do not use.\n\n    :param files: Input files. Each argument can be a file path or a glob pathname.\n    :param patterns: Regex patterns, select the log line if at least one pattern matches.\n    :param matcher: Matcher engine, can be 'ruled' (default), 'unruled' or 'unparsed'.\n    :param cfgfiles: use a specific configuration file.\n    :param apps: process the log lines related to a list of applications.\n    :param hosts: process the log lines related to a list of hosts.\n    :param filters: process the log lines that match all the conditions for rule's field values.\n    :param time_range: process the log lines related to a time range.\n    :param time_period: restrict the search scope to a date or a date interval.\n    :param case: ignore case distinctions, defaults to `False`.\n    :param invert: invert the sense of patterns regexp matching.\n    :param word: force PATTERN to match only whole words.\n    :param files_with_match: get only names of FILEs containing matches, defaults is `False`.\n    :param count: get only a count of matching lines per FILE.\n    :param quiet: suppress all normal output.\n    :param max_count: stop after NUM matches.\n    :param only_matching: get only the part of a line matching PATTERN.\n    :param line_number: get line number with output lines.\n    :param with_filename: get or suppress the file name for each match.\n    :param ip_lookup: translate IP addresses to DNS names.\n    :param uid_lookup: translate numeric UIDs to usernames.\n    :param anonymize: anonymize defined rule's fields value.\n    :param thread: get the lines of logs related to each log line selected.\n    :param before_context: get NUM lines of leading context for each log line selected.\n    :param after_context: get NUM lines of trailing context for each log line selected.\n    :param context: get NUM lines of output context for each log line selected.\n    :return:\n    \"\"\"\n    cli_parser = create_argument_parser()\n    args = cli_parser.parse_args()\n    args.files = files\n    args.matcher = matcher\n    args.cfgfiles = cfgfiles\n    args.time_period = time_period\n    args.time_range = time_range\n    args.case = case\n    args.invert = invert\n    args.word = word\n    args.files_with_match = files_with_match\n    args.count = count\n    args.quiet = quiet\n    args.max_count = max_count\n    args.only_matching = only_matching\n    args.line_number = line_number\n    args.with_filename = with_filename\n    args.anonymize = anonymize\n    args.ip_lookup = ip_lookup\n    args.uid_lookup = uid_lookup\n    args.thread = thread\n    args.context = context\n    args.after_context = after_context\n    args.before_context = before_context\n    args.patterns = [''] if patterns is None else patterns\n\n    if apps is not None:\n        args.apps = apps\n    if hosts is not None:\n        args.hosts = hosts\n    if filters is not None:\n        args.filters = filters\n\n    _lograptor = LogRaptor(args)\n    return _lograptor()", "response": "Log Processor with arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a configuration file for the next read read", "response": "def generate_config(conf):\n    \"\"\"\n    Generates a configuration file using the ConfigParser library that\n    can be saved to a file for subsequent reads\n    \"\"\"\n\n    c = {}\n    def to_key(key, default):\n        if conf.get(key):\n            c[key] = '{} = {}'.format(key, conf.get(key))\n        else:\n            c[key] = default\n\n    to_key('username', '# username = u1234...')\n    to_key('password', '# password = secret...')\n    to_key('from', '# from = elkme')\n    to_key('to', '# to = +46700000000')\n    return (True, c)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_file_from_RCSB(http_connection, resource, silent = True):\n    '''Retrieve a file from the RCSB.'''\n    if not silent:\n        colortext.printf(\"Retrieving %s from RCSB\" % os.path.split(resource)[1], color = \"aqua\")\n    return http_connection.get(resource)", "response": "Retrieve a file from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mail_logger(app, level = None):\n    credentials = None\n    if app.config['MAIL_USERNAME'] and app.config['MAIL_PASSWORD']:\n        credentials = (app.config['MAIL_USERNAME'], app.config['MAIL_PASSWORD'])\n\n    secure = None\n    if app.config['MAIL_USE_TLS']:\n        secure = tuple()\n\n    # @todo: move to configuration\n    config = dict(\n        mailhost=(app.config['MAIL_SERVER'], app.config['MAIL_PORT']),\n        fromaddr=app.config['MAIL_DEFAULT_SENDER'],\n        toaddrs=app.config['ADMINS'],\n        credentials = credentials,\n        subject='Application exception',\n        secure = secure,\n        timeout=1.0\n    )\n\n    mail_handler = SMTPHandler(**config)\n\n    if level is None: level = logging.ERROR\n    mail_handler.setLevel(level)\n\n    mail_log_format = '''\n    Message type:       %(levelname)s\n    Location:           %(pathname)s:%(lineno)d\n    Module:             %(module)s\n    Function:           %(funcName)s\n    Time:               %(asctime)s\n\n    Message:\n\n    %(message)s\n    '''\n\n    mail_handler.setFormatter(logging.Formatter(mail_log_format))\n    return mail_handler", "response": "Returns a new instance of SMTPHandler that will log mails."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_r_script(r_script_filename, cwd = '.'):\n    '''This function was adapted from the covariation benchmark.'''\n    p = subprocess.Popen([\"R\", \"CMD\", \"BATCH\", r_script_filename], cwd = cwd)\n    while True:\n        time.sleep(0.3)\n        errcode = p.poll()\n        if errcode != None:\n            break\n    rout = \"{0}out\".format(r_script_filename)\n    rout_contents = None\n    if os.path.exists(rout):\n        rout_contents = read_file(rout)\n        os.remove(rout)\n    rdata_file = os.path.join(os.path.split(r_script_filename)[0], '.RData')\n    if os.path.exists(rdata_file):\n        os.remove(rdata_file)\n    if errcode != 0:\n        print(rout_contents)\n        raise Exception(\"The R script failed with error code %d.\" % errcode)\n    return rout_contents", "response": "This function was adapted from the covariation benchmark."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiling suffix: pearsons_r_gplot Description: Pearson's r Filename: ggplot_pearsons.R Priority: 1", "response": "def correlation_coefficient_gplot(inputfname, output_filename, filetype, experiment_field = \"Experimental\", title = ''):\n        '''File suffix: pearsons_r_gplot\n           Description: Pearson's r\n           Filename: ggplot_pearsons.R\n           Priority: 1\n           '''\n        script_path = os.path.abspath(os.path.dirname(inspect.getsourcefile(sys.modules[__name__])))\n        r_script_filename = read_file(os.path.join(script_path, \"ggplot_pearsons.R\")) % vars()\n        return RInterface._runRScript(r_script_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding a Server - Sent Event.", "response": "def sse_event(event=None, data=None, id=None, retry=None, comment=None,\n        encoding='utf-8'):\n    \"\"\"Encode a Server-Sent Event (SSE).\n\n    At least one field must be present. All fields are strings, except retry,\n    which must be an integer. The event and id fields can not contain newlines.\n    \"\"\"\n    if all(x is None for x in [event, data, id, retry, comment]):\n        raise TypeError(\"Event must have at least one field\")\n    if event and any(c in event for c in '\\r\\n'):\n        raise ValueError(\"'event' can not contain newlines: '%s'\" % event)\n    if id and any(c in id for c in '\\r\\n'):\n        raise ValueError(\"'id' can not contain newlines: '%s'\" % id)\n    return ''.join([\n        _sse_encode('', comment) if comment is not None else '',\n        _sse_encode('id', id) if id is not None else '',\n        _sse_encode('event', event) if event is not None else '',\n        _sse_encode('retry', str(int(retry))) if retry is not None else '',\n        _sse_encode('data', data) if data is not None else '',\n        '\\n',\n    ]).encode(encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns a function into a decorator that can be called with or without arguments.", "response": "def dual_use_decorator(fn):\n    \"\"\"Turn a function into a decorator that can be called with or without\n    arguments.\"\"\"\n    @functools.wraps(fn)\n    def decorator(*args, **kw):\n        if len(args) == 1 and not kw and callable(args[0]):\n            return fn()(args[0])\n        else:\n            return fn(*args, **kw)\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of argument names for a callable.", "response": "def get_args(obj):\n    \"\"\"Get a list of argument names for a callable.\"\"\"\n    if inspect.isfunction(obj):\n        return inspect.getargspec(obj).args\n    elif inspect.ismethod(obj):\n        return inspect.getargspec(obj).args[1:]\n    elif inspect.isclass(obj):\n        return inspect.getargspec(obj.__init__).args[1:]\n    elif hasattr(obj, '__call__'):\n        return inspect.getargspec(obj.__call__).args[1:]\n    else:\n        raise TypeError(\"Can't inspect signature of '%s' object.\" % obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_ctx(fn, ctx):\n    if 'ctx' in get_args(fn):\n        return functools.partial(fn, ctx=ctx)\n    else:\n        return fn", "response": "Return fn with ctx applied if requested."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlog the exc_info tuple in the server log.", "response": "def log_exception(exc_info=None, stream=None):\n    \"\"\"Log the 'exc_info' tuple in the server log.\"\"\"\n    exc_info = exc_info or sys.exc_info()\n    stream = stream or sys.stderr\n    try:\n        from traceback import print_exception\n        print_exception(exc_info[0], exc_info[1], exc_info[2], None, stream)\n        stream.flush()\n    finally:\n        exc_info = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_get_request(self, resource, billomat_id='', command=None, params=None):\n        if not params:\n            params = {}\n\n        if not command:\n            command = ''\n        else:\n            command = '/' + command\n\n        assert (isinstance(resource, str))\n        if billomat_id:\n            assert (isinstance(billomat_id, int) or isinstance(billomat_id, str))\n\n            if isinstance(billomat_id, int):\n                billomat_id = str(billomat_id)\n        response = self.session.get(\n            url=self.api_url + resource + ('/' + billomat_id if billomat_id else '') + command,\n            params=params,\n        )\n\n        return self._handle_response(response)", "response": "Creates a get request and returns the response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_put_request(self, resource, billomat_id, command=None, send_data=None):\n        assert (isinstance(resource, str))\n\n        if isinstance(billomat_id, int):\n            billomat_id = str(billomat_id)\n\n        if not command:\n            command = ''\n        else:\n            command = '/' + command\n\n        response = self.session.put(\n            url=self.api_url + resource + '/' + billomat_id + command,\n            data=json.dumps(send_data),\n        )\n\n        return self._handle_response(response)", "response": "Creates a put request and returns the response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_delete_request(self, resource, billomat_id):\n        assert (isinstance(resource, str))\n\n        if isinstance(billomat_id, int):\n            billomat_id = str(billomat_id)\n\n        response = self.session.delete(\n            url=self.api_url + resource + '/' + billomat_id,\n        )\n\n        return self._handle_response(response)", "response": "Creates a post request and returns the response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_response(self, response):\n        if response.status_code == requests.codes.ok or response.status_code == requests.codes.created:\n            try:\n                return response.json()\n            except ValueError:\n                return response\n        else:\n            return self._handle_failed_response(response)", "response": "Handle all responses from the server"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_failed_response(self, response):\n        if response.status_code == requests.codes.too_many_requests:\n            return self.rate_limit_exceeded(response)\n        else:\n            response.raise_for_status()", "response": "Handle the failed response and raise an exception if rate limit exceeded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate through all pages and return the collected data.", "response": "def _iterate_through_pages(get_function, resource, **kwargs):\n        \"\"\"\n        Iterate through all pages and return the collected data\n        :rtype: list\n        \"\"\"\n\n        request_data = True\n        data = []\n        page = 1\n\n        while request_data:\n            temp_response = get_function(page=page, **kwargs)\n            if temp_response[resource]['@total'] != '0':\n                data.append(temp_response)\n\n            page += 1\n            if page > int(\n                math.ceil(\n                    float(temp_response[resource]['@total']) / float(temp_response[resource]['@per_page'])\n                )\n            ):\n                request_data = False\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_resource_per_page(self, resource, per_page=1000, page=1, params=None):\n        assert (isinstance(resource, str))\n\n        common_params = {'per_page': per_page, 'page': page}\n        if not params:\n            params = common_params\n        else:\n            params.update(common_params)\n        return self._create_get_request(resource=resource, params=params)", "response": "Gets specific data per resource page and per page"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves the responses you get from billomat", "response": "def resolve_response_data(head_key, data_key, data):\n        \"\"\"\n        Resolves the responses you get from billomat\n        If you have done a get_one_element request then you will get a dictionary\n        If you have done a get_all_elements request then you will get a list with all elements in it\n\n        :param head_key: the head key e.g: CLIENTS\n        :param data_key: the data key e.g: CLIENT\n        :param data: the responses you got\n        :return: dict or list\n        \"\"\"\n        new_data = []\n        if isinstance(data, list):\n            for data_row in data:\n                if head_key in data_row and data_key in data_row[head_key]:\n                    if isinstance(data_row[head_key][data_key], list):\n                        new_data += data_row[head_key][data_key]\n                    else:\n                        new_data.append(data_row[head_key][data_key])\n                elif data_key in data_row:\n                    return data_row[data_key]\n\n        else:\n            if head_key in data and data_key in data[head_key]:\n                new_data += data[head_key][data_key]\n            elif data_key in data:\n                    return data[data_key]\n        return new_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets clients per page", "response": "def get_clients_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get clients per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=CLIENTS, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_clients(self, params=None):\n        return self._iterate_through_pages(\n            get_function=self.get_clients_per_page,\n            resource=CLIENTS,\n            **{'params': params}\n        )", "response": "This will iterate over all the clients in the resource provider and return a list of all the clients in the system"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_client(self, client_id, client_dict):\n        return self._create_put_request(\n            resource=CLIENTS,\n            billomat_id=client_id,\n            send_data=client_dict\n        )", "response": "Updates a client s attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget client properties per page", "response": "def get_client_properties_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get client properties per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CLIENT_PROPERTIES,\n            per_page=per_page,\n            page=page,\n            params=params\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_client_properties(self, params=None):\n        return self._iterate_through_pages(\n            get_function=self.get_client_properties_per_page,\n            resource=CLIENT_PROPERTIES,\n            **{'params': params}\n        )", "response": "This will iterate over all contacts of client\n        and return a list of all client properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting client tags per page", "response": "def get_client_tags_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get client tags per page\n\n        If you search tags, you can only search by client_id\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CLIENT_TAGS,\n            per_page=per_page,\n            page=page,\n            params=params\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_client_tags(self, params=None):\n        return self._iterate_through_pages(\n            get_function=self.get_client_tags_per_page,\n            resource=CLIENT_TAGS,\n            **{'params': params}\n        )", "response": "This will iterate over all client tags and return a list of all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget contacts of a client per page", "response": "def get_contacts_of_client_per_page(self, client_id, per_page=1000, page=1):\n        \"\"\"\n        Get contacts of client per page\n\n        :param client_id: the client id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CONTACTS,\n            per_page=per_page,\n            page=page,\n            params={'client_id': client_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all contacts of client This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param client_id: The id of the client :return: list", "response": "def get_all_contacts_of_client(self, client_id):\n        \"\"\"\n        Get all contacts of client\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param client_id: The id of the client\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_contacts_of_client_per_page,\n            resource=CONTACTS,\n            **{'client_id': client_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a contact of a client", "response": "def update_contact_of_client(self, contact_id, contact_dict):\n        \"\"\"\n        Updates a contact\n\n        :param contact_id: the id of the contact\n        :param contact_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(resource=CONTACTS, billomat_id=contact_id, send_data=contact_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_suppliers_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=SUPPLIERS, per_page=per_page, page=page, params=params)", "response": "Get suppliers per page"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all suppliers This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_suppliers(self, params=None):\n        \"\"\"\n        Get all suppliers\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            get_function=self.get_suppliers_per_page,\n            resource=SUPPLIERS,\n            **{'params': params}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_supplier(self, supplier_id, supplier_dict):\n        return self._create_put_request(resource=SUPPLIERS, billomat_id=supplier_id, send_data=supplier_dict)", "response": "Updates a supplier\n\n        :param supplier_id: the supplier id\n        :param supplier_dict: dict\n        :return: dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget supplier properties per page", "response": "def get_supplier_properties_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get supplier properties per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=SUPPLIER_PROPERTIES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_supplier_properties(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            get_function=self.get_supplier_properties_per_page,\n            resource=SUPPLIER_PROPERTIES,\n            **{'params': params}\n        )", "response": "This will iterate over all supplier properties and return a list of all supplier properties"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_tags_of_supplier_per_page(self, supplier_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=SUPPLIER_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'supplier_id': supplier_id},\n        )", "response": "Get tags of suppliers per page"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all supplier properties This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param supplier_id: the supplier id :return: list", "response": "def get_all_tags_of_supplier(self, supplier_id):\n        \"\"\"\n        Get all supplier properties\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param supplier_id: the supplier id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_supplier_per_page,\n            resource=SUPPLIER_TAGS,\n            **{'supplier_id': supplier_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget articles per page", "response": "def get_articles_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get articles per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=ARTICLES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_articles(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_articles_per_page, resource=ARTICLES, **{'params': params})", "response": "This will iterate over all articles and return a list of all articles"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate an article s metadata", "response": "def update_article(self, article_id, article_dict):\n        \"\"\"\n        Updates an article\n\n        :param article_id: the article id\n        :param article_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(resource=ARTICLES, billomat_id=article_id, send_data=article_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_article_properties_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=ARTICLE_PROPERTIES, per_page=per_page, page=page, params=params)", "response": "Get article properties per page"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_article_properties(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            get_function=self.get_article_properties_per_page,\n            resource=ARTICLE_PROPERTIES,\n            **{'params': params}\n        )", "response": "This will iterate over all article properties and return a list of article properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tags_of_article_per_page(self, article_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=ARTICLE_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'article_id': article_id},\n        )", "response": "Get articles tags per page"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_tags_of_article(self, article_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_article_per_page,\n            resource=ARTICLE_TAGS,\n            **{'article_id': article_id}\n        )", "response": "This will iterate over all pages and get all tags of article"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_units_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=UNITS, per_page=per_page, page=page, params=params)", "response": "Get units per page"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_units(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_units_per_page, resource=UNITS, **{'params': params})", "response": "This will iterate over all units and returns a list of all units This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_unit(self, unit_id, unit_dict):\n        return self._create_put_request(resource=UNITS, billomat_id=unit_id, send_data=unit_dict)", "response": "Updates an unit\n\n        :param unit_id: the unit id\n        :param unit_dict: dict\n        :return: dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting invoices per page", "response": "def get_invoices_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get invoices per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=INVOICES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all invoices This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_invoices(self, params=None):\n        \"\"\"\n        Get all invoices\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_invoices_per_page, resource=INVOICES, **{'params': params})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate an invoice :param invoice_id: the invoice id :param invoice_dict: dict :return: dict", "response": "def update_invoice(self, invoice_id, invoice_dict):\n        \"\"\"\n        Updates an invoice\n\n        :param invoice_id: the invoice id\n        :param invoice_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(resource=INVOICES, billomat_id=invoice_id, send_data=invoice_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef complete_invoice(self, invoice_id, complete_dict):\n        return self._create_put_request(\n            resource=INVOICES,\n            billomat_id=invoice_id,\n            command=COMPLETE,\n            send_data=complete_dict\n        )", "response": "Completes an invoice\n\n        :param complete_dict: the complete dict with the template id\n        :param invoice_id: the invoice id\n        :return: Response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a pdf of an invoice", "response": "def invoice_pdf(self, invoice_id):\n        \"\"\"\n        Opens a pdf of an invoice\n\n        :param invoice_id: the invoice id\n        :return: dict\n        \"\"\"\n        return self._create_get_request(resource=INVOICES, billomat_id=invoice_id, command=PDF)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload_invoice_signature(self, invoice_id, signature_dict):\n        return self._create_put_request(\n            resource=INVOICES,\n            billomat_id=invoice_id,\n            send_data=signature_dict,\n            command=UPLOAD_SIGNATURE\n        )", "response": "Uploads a signature for the invoice"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_invoice_email(self, invoice_id, email_dict):\n        return self._create_post_request(\n            resource=INVOICES,\n            billomat_id=invoice_id,\n            send_data=email_dict,\n            command=EMAIL,\n        )", "response": "Sends an invoice by email_dict to the invoice by invoice_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uncancel_invoice(self, invoice_id):\n        return self._create_put_request(\n            resource=INVOICES,\n            billomat_id=invoice_id,\n            command=UNCANCEL,\n        )", "response": "Uncancelles an invoice\n\n        :param invoice_id: the invoice id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_items_of_invoice_per_page(self, invoice_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=INVOICE_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'invoice_id': invoice_id},\n        )", "response": "Get invoice items of invoice per page"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_items_of_invoice(self, invoice_id):\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_invoice_per_page,\n            resource=INVOICE_ITEMS,\n            **{'invoice_id': invoice_id}\n        )", "response": "This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_invoice_item(self, invoice_item_id, invoice_item_dict):\n        return self._create_put_request(\n            resource=INVOICE_ITEMS,\n            billomat_id=invoice_item_id,\n            send_data=invoice_item_dict\n        )", "response": "Updates an invoice item"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting comments of invoice per page", "response": "def get_comments_of_invoice_per_page(self, invoice_id, per_page=1000, page=1):\n        \"\"\"\n        Get comments of invoice per page\n\n        :param invoice_id: the invoice id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=INVOICE_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'invoice_id': invoice_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all invoice comments of invoice This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param invoice_id: the invoice id :return: list", "response": "def get_all_comments_of_invoice(self, invoice_id):\n        \"\"\"\n        Get all invoice comments of invoice\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param invoice_id: the invoice id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_invoice_per_page,\n            resource=INVOICE_COMMENTS,\n            **{'invoice_id': invoice_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates an invoice comment", "response": "def update_invoice_comment(self, invoice_comment_id, invoice_comment_dict):\n        \"\"\"\n        Updates an invoice comment\n\n        :param invoice_comment_id: the invoice comment id\n        :param invoice_comment_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=INVOICE_COMMENTS,\n            billomat_id=invoice_comment_id,\n            send_data=invoice_comment_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting invoice payments per page", "response": "def get_invoice_payments_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get invoice payments per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n\n        return self._get_resource_per_page(\n            resource=INVOICE_PAYMENTS,\n            per_page=per_page,\n            page=page,\n            params=params,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all invoice payments This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_invoice_payments(self, params=None):\n        \"\"\"\n        Get all invoice payments\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            get_function=self.get_invoice_payments_per_page,\n            resource=INVOICE_PAYMENTS,\n            **{'params': params}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget tags of invoice per page", "response": "def get_tags_of_invoice_per_page(self, invoice_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of invoice per page\n\n        :param invoice_id: the invoice id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=INVOICE_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'invoice_id': invoice_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all tags of invoice This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param invoice_id: the invoice id :return: list", "response": "def get_all_tags_of_invoice(self, invoice_id):\n        \"\"\"\n        Get all tags of invoice\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param invoice_id: the invoice id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_invoice_per_page,\n            resource=INVOICE_TAGS,\n            **{'invoice_id': invoice_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting recurrings per page", "response": "def get_recurrings_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get recurrings per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=RECURRINGS, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_recurrings(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_recurrings_per_page, resource=RECURRINGS, **{'params': params})", "response": "This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_recurring(self, recurring_id, recurring_dict):\n        return self._create_put_request(resource=RECURRINGS, billomat_id=recurring_id, send_data=recurring_dict)", "response": "Updates a recurring record set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_items_of_recurring_per_page(self, recurring_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=RECURRING_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'recurring_id': recurring_id},\n        )", "response": "Get items of recurring per page"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all items of recurring This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param recurring_id: the recurring id :return: list", "response": "def get_all_items_of_recurring(self, recurring_id):\n        \"\"\"\n        Get all items of recurring\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param recurring_id: the recurring id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_recurring_per_page,\n            resource=RECURRING_ITEMS,\n            **{'recurring_id': recurring_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a recurring item", "response": "def update_recurring_item(self, recurring_item_id, recurring_item_dict):\n        \"\"\"\n        Updates a recurring item\n\n        :param recurring_item_id: the recurring item id\n        :param recurring_item_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=RECURRING_ITEMS,\n            billomat_id=recurring_item_id,\n            send_data=recurring_item_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting tags of recurring in a specific page.", "response": "def get_tags_of_recurring_per_page(self, recurring_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of recurring per page\n\n        :param recurring_id: the recurring id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=RECURRING_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'recurring_id': recurring_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_tags_of_recurring(self, recurring_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_recurring_per_page,\n            resource=RECURRING_TAGS,\n            **{'recurring_id': recurring_id}\n        )", "response": "This will iterate over all pages and return a list of all tags of the recurring. If rate limit exceeded it will throw an Exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_email_receivers_of_recurring_per_page(self, recurring_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=RECURRING_EMAIL_RECEIVERS,\n            per_page=per_page,\n            page=page,\n            params={'recurring_id': recurring_id},\n        )", "response": "Get email receivers of recurring per page"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all email receivers of recurring This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param recurring_id: the recurring id :return: list", "response": "def get_all_email_receivers_of_recurring(self, recurring_id):\n        \"\"\"\n        Get all email receivers of recurring\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param recurring_id: the recurring id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_email_receivers_of_recurring_per_page,\n            resource=RECURRING_EMAIL_RECEIVERS,\n            **{'recurring_id': recurring_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting incomings per page", "response": "def get_incomings_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get incomings per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=INCOMINGS, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_incomings(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_incomings_per_page, resource=INCOMINGS, **{'params': params})", "response": "This will iterate over all incomings and returns a list of all incomings that match the passed in parameters"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_incoming(self, incoming_id, incoming_dict):\n        return self._create_put_request(resource=INCOMINGS, billomat_id=incoming_id, send_data=incoming_dict)", "response": "Updates an incoming record set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comments_of_incoming_per_page(self, incoming_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=INCOMING_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'incoming_id': incoming_id},\n        )", "response": "Get comments of incoming per page"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_comments_of_incoming(self, incoming_id):\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_incoming_per_page,\n            resource=INCOMING_COMMENTS,\n            **{'incoming_id': incoming_id}\n        )", "response": "This will iterate over all pages and return a list of all comments of the incoming"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_payments_of_incoming_per_page(self, incoming_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=INCOMING_PAYMENTS,\n            per_page=per_page,\n            page=page,\n            params={'incoming_id': incoming_id},\n        )", "response": "Get payments of incoming per page"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all payments of incoming This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param incoming_id: the incoming id :return: list", "response": "def get_all_payments_of_incoming(self, incoming_id):\n        \"\"\"\n        Get all payments of incoming\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param incoming_id: the incoming id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_payments_of_incoming_per_page,\n            resource=INCOMING_PAYMENTS,\n            **{'incoming_id': incoming_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget incoming properties per page", "response": "def get_incoming_properties_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get incoming properties per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=INCOMING_PROPERTIES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all incoming properties This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_incoming_properties(self, params=None):\n        \"\"\"\n        Get all incoming properties\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            self.get_incoming_properties_per_page,\n            resource=INCOMING_PROPERTIES,\n            **{'params': params}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets tags of incoming per page", "response": "def get_tags_of_incoming_per_page(self, incoming_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of incoming per page\n\n        :param incoming_id: the incoming id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=INCOMING_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'incoming_id': incoming_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_tags_of_incoming(self, incoming_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_incoming_per_page,\n            resource=INCOMING_TAGS,\n            **{'incoming_id': incoming_id}\n        )", "response": "This will iterate over all pages and get all tags of incoming. It will return a list of all tags of incoming. If rate limit exceeded it will throw an Exception."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_inbox_documents_per_page(self, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=INBOX_DOCUMENTS,\n            per_page=per_page,\n            page=page,\n        )", "response": "Get inbox documents per page"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget offers per page", "response": "def get_offers_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get offers per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=OFFERS, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_offers(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_offers_per_page, resource=OFFERS, **{'params': params})", "response": "This will iterate over all offers and get all elements"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates an offer s attributes", "response": "def update_offer(self, offer_id, offer_dict):\n        \"\"\"\n        Updates an offer\n\n        :param offer_id: the offer id\n        :param offer_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(resource=OFFERS, billomat_id=offer_id, send_data=offer_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef complete_offer(self, offer_id, complete_dict):\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=COMPLETE,\n            send_data=complete_dict\n        )", "response": "Completes an offer\n\n        :param complete_dict: the complete dict with the template id\n        :param offer_id: the offer id\n        :return: Response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a pdf of an offer", "response": "def offer_pdf(self, offer_id):\n        \"\"\"\n        Opens a pdf of an offer\n\n        :param offer_id: the offer id\n        :return: dict\n        \"\"\"\n        return self._create_get_request(resource=OFFERS, billomat_id=offer_id, command=PDF)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an offer by email_dict to the invoice", "response": "def send_offer_email(self, offer_id, email_dict):\n        \"\"\"\n        Sends an offer by email\n        If you want to send your email to more than one persons do:\n        'recipients': {'to': ['bykof@me.com', 'mbykovski@seibert-media.net']}}\n\n        :param offer_id: the invoice id\n        :param email_dict: the email dict\n        :return dict\n        \"\"\"\n        return self._create_post_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            send_data=email_dict,\n            command=EMAIL,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uncancel_offer(self, offer_id):\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=UNCANCEL,\n        )", "response": "Uncancelles an invoice from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmarks the offer as win", "response": "def mark_offer_as_win(self, offer_id):\n        \"\"\"\n        Mark offer as win\n\n        :param offer_id: the offer id\n        :return Response\n        \"\"\"\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=WIN,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmark the offer as lose", "response": "def mark_offer_as_lose(self, offer_id):\n        \"\"\"\n        Mark offer as lose\n\n        :param offer_id: the offer id\n        :return Response\n        \"\"\"\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=LOSE,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mark_offer_as_clear(self, offer_id):\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=CLEAR,\n        )", "response": "Mark the offer as clear"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mark_offer_as_unclear(self, offer_id):\n        return self._create_put_request(\n            resource=OFFERS,\n            billomat_id=offer_id,\n            command=UNCLEAR,\n        )", "response": "Mark the offer as unclear"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_items_of_offer_per_page(self, offer_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=OFFER_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'offer_id': offer_id},\n        )", "response": "Get items of offer per page"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all items of offer This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param offer_id: the offer id :return: list", "response": "def get_all_items_of_offer(self, offer_id):\n        \"\"\"\n        Get all items of offer\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param offer_id: the offer id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_offer_per_page,\n            resource=OFFER_ITEMS,\n            **{'offer_id': offer_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_offer_item(self, offer_item_id, offer_item_dict):\n        return self._create_put_request(resource=OFFER_ITEMS, billomat_id=offer_item_id, send_data=offer_item_dict)", "response": "Updates an offer item"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets comments of an offer per page", "response": "def get_comments_of_offer_per_page(self, offer_id, per_page=1000, page=1):\n        \"\"\"\n        Get comments of offer per page\n\n        :param offer_id: the offer id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=OFFER_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'offer_id': offer_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all comments of offer This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param offer_id: the offer id :return: list", "response": "def get_all_comments_of_offer(self, offer_id):\n        \"\"\"\n        Get all comments of offer\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param offer_id: the offer id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_offer_per_page,\n            resource=OFFER_COMMENTS,\n            **{'offer_id': offer_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates an offer comment", "response": "def update_offer_comment(self, offer_comment_id, offer_comment_dict):\n        \"\"\"\n        Updates an offer comment\n\n        :param offer_comment_id: the offer comment id\n        :param offer_comment_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=OFFER_COMMENTS,\n            billomat_id=offer_comment_id,\n            send_data=offer_comment_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tags_of_offer_per_page(self, offer_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=OFFER_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'offer_id': offer_id},\n        )", "response": "Get tags of an offer per page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_tags_of_offer(self, offer_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_offer_per_page,\n            resource=OFFER_TAGS,\n            **{'offer_id': offer_id}\n        )", "response": "This will iterate over all pages and get all tags of offer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_credit_notes_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=CREDIT_NOTES, per_page=per_page, page=page, params=params)", "response": "Get credit notes per page"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all credit notes This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_credit_notes(self, params=None):\n        \"\"\"\n        Get all credit notes\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_credit_notes_per_page, resource=CREDIT_NOTES, **{'params': params})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a credit note", "response": "def update_credit_note(self, credit_note_id, credit_note_dict):\n        \"\"\"\n        Updates a credit note\n\n        :param credit_note_id: the credit note id\n        :param credit_note_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(resource=CREDIT_NOTES, billomat_id=credit_note_id, send_data=credit_note_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete_credit_note(self, credit_note_it, complete_dict):\n        return self._create_put_request(\n            resource=CREDIT_NOTES,\n            billomat_id=credit_note_it,\n            command=COMPLETE,\n            send_data=complete_dict\n        )", "response": "Completes a credit note"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a pdf of a credit note", "response": "def credit_note_pdf(self, credit_note_it):\n        \"\"\"\n        Opens a pdf of a credit note\n\n        :param credit_note_it: the credit note id\n        :return: dict\n        \"\"\"\n        return self._create_get_request(resource=CREDIT_NOTES, billomat_id=credit_note_it, command=PDF)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_credit_note_signature(self, credit_note_it, signature_dict):\n        return self._create_put_request(\n            resource=CREDIT_NOTES,\n            billomat_id=credit_note_it,\n            send_data=signature_dict,\n            command=UPLOAD_SIGNATURE\n        )", "response": "Uploads a signature for the credit note"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_credit_note_email(self, credit_note_it, email_dict):\n        return self._create_post_request(\n            resource=CREDIT_NOTES,\n            billomat_id=credit_note_it,\n            send_data=email_dict,\n            command=EMAIL,\n        )", "response": "Sends an email to a credit note by email_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget items of credit note per page", "response": "def get_items_of_credit_note_per_page(self, credit_note_id, per_page=1000, page=1):\n        \"\"\"\n        Get items of credit note per page\n\n        :param credit_note_id: the credit note id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CREDIT_NOTE_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'credit_note_id': credit_note_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_items_of_credit_note(self, credit_note_id):\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_credit_note_per_page,\n            resource=CREDIT_NOTE_ITEMS,\n            **{'credit_note_id': credit_note_id}\n        )", "response": "This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_credit_note_item(self, credit_note_item_id, credit_note_item_dict):\n        return self._create_put_request(\n            resource=CREDIT_NOTE_ITEMS,\n            billomat_id=credit_note_item_id,\n            send_data=credit_note_item_dict\n        )", "response": "Updates a credit note item"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_comments_of_credit_note_per_page(self, credit_note_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=CREDIT_NOTE_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'credit_note_id': credit_note_id},\n        )", "response": "Get comments of a credit note per page"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_comments_of_credit_note(self, credit_note_id):\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_credit_note_per_page,\n            resource=CREDIT_NOTE_COMMENTS,\n            **{'credit_note_id': credit_note_id}\n        )", "response": "This will iterate over all pages and return a list of all comments of credit note"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_credit_note_comment(self, credit_note_comment_id, credit_note_comment_dict):\n        return self._create_put_request(\n            resource=CREDIT_NOTE_COMMENTS,\n            billomat_id=credit_note_comment_id,\n            send_data=credit_note_comment_dict\n        )", "response": "Updates a credit note comment"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets payments of a credit note per page", "response": "def get_payments_of_credit_note_per_page(self, credit_note_id, per_page=1000, page=1):\n        \"\"\"\n        Get payments of credit note per page\n\n        :param credit_note_id: the credit note id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CREDIT_NOTE_PAYMENTS,\n            per_page=per_page,\n            page=page,\n            params={'credit_note_id': credit_note_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all payments of credit note This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param credit_note_id: the credit note id :return: list", "response": "def get_all_payments_of_credit_note(self, credit_note_id):\n        \"\"\"\n        Get all payments of credit note\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param credit_note_id: the credit note id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_payments_of_credit_note_per_page,\n            resource=CREDIT_NOTE_PAYMENTS,\n            **{'credit_note_id': credit_note_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting tags of credit note per page", "response": "def get_tags_of_credit_note_per_page(self, credit_note_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of credit note per page\n\n        :param credit_note_id: the credit note id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CREDIT_NOTE_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'credit_note_id': credit_note_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_confirmations_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=CONFIRMATIONS, per_page=per_page, page=page, params=params)", "response": "Get confirmations per page"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_confirmations(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            self.get_confirmations_per_page,\n            resource=CONFIRMATIONS,\n            **{'params': params}\n        )", "response": "This will iterate over all confirmations pages and return a list of all confirmations"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a confirmation with the given dict", "response": "def update_confirmation(self, confirmation_id, confirmation_dict):\n        \"\"\"\n        Updates a confirmation\n\n        :param confirmation_id: the confirmation id\n        :param confirmation_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            send_data=confirmation_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompletes an confirmation with the given dict", "response": "def complete_confirmation(self, confirmation_id, complete_dict):\n        \"\"\"\n        Completes an confirmation\n\n        :param complete_dict: the complete dict with the template id\n        :param confirmation_id: the confirmation id\n        :return: Response\n        \"\"\"\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            command=COMPLETE,\n            send_data=complete_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a pdf of a confirmation", "response": "def confirmation_pdf(self, confirmation_id):\n        \"\"\"\n        Opens a pdf of a confirmation\n\n        :param confirmation_id: the confirmation id\n        :return: dict\n        \"\"\"\n        return self._create_get_request(resource=CONFIRMATIONS, billomat_id=confirmation_id, command=PDF)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_confirmation_email(self, confirmation_id, email_dict):\n        return self._create_post_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            send_data=email_dict,\n            command=EMAIL,\n        )", "response": "Sends an email to the user who s confirmation is given by email_dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancel_confirmation(self, confirmation_id):\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            command=CANCEL,\n        )", "response": "Cancelles an confirmation\n\n        :param confirmation_id: the confirmation id\n        :return Response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uncancel_confirmation(self, confirmation_id):\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            command=UNCANCEL,\n        )", "response": "Uncancelles an confirmation\n\n        :param confirmation_id: the confirmation id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mark_confirmation_as_clear(self, confirmation_id):\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            command=CLEAR,\n        )", "response": "Mark the confirmation as clear"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark the confirmation as unclear.", "response": "def mark_confirmation_as_unclear(self, confirmation_id):\n        \"\"\"\n        Mark confirmation as unclear\n\n        :param confirmation_id: the confirmation id\n        :return Response\n        \"\"\"\n        return self._create_put_request(\n            resource=CONFIRMATIONS,\n            billomat_id=confirmation_id,\n            command=UNCLEAR,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_items_of_confirmation_per_page(self, confirmation_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=CONFIRMATION_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'confirmation_id': confirmation_id},\n        )", "response": "Get items of confirmation per page"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all items of confirmation This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param confirmation_id: the confirmation id :return: list", "response": "def get_all_items_of_confirmation(self, confirmation_id):\n        \"\"\"\n        Get all items of confirmation\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param confirmation_id: the confirmation id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_confirmation_per_page,\n            resource=CONFIRMATION_ITEMS,\n            **{'confirmation_id': confirmation_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_confirmation_item(self, confirmation_item_id, confirmation_item_dict):\n        return self._create_put_request(\n            resource=CONFIRMATION_ITEMS,\n            billomat_id=confirmation_item_id,\n            send_data=confirmation_item_dict\n        )", "response": "Updates a confirmation item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_comments_of_confirmation_per_page(self, confirmation_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=CONFIRMATION_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'confirmation_id': confirmation_id},\n        )", "response": "Get comments of confirmation per page"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_comments_of_confirmation(self, confirmation_id):\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_confirmation_per_page,\n            resource=CONFIRMATION_COMMENTS,\n            **{'confirmation_id': confirmation_id}\n        )", "response": "This will iterate over all pages and return a list of all comments of confirmation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_confirmation_comment(self, confirmation_comment_id, confirmation_comment_dict):\n        return self._create_put_request(\n            resource=CONFIRMATION_COMMENTS,\n            billomat_id=confirmation_comment_id,\n            send_data=confirmation_comment_dict\n        )", "response": "Updates a confirmation comment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting tags of confirmation per page", "response": "def get_tags_of_confirmation_per_page(self, confirmation_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of confirmation per page\n\n        :param confirmation_id: the confirmation id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=CONFIRMATION_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'confirmation_id': confirmation_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_tags_of_confirmation(self, confirmation_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_confirmation_per_page,\n            resource=CONFIRMATION_TAGS,\n            **{'confirmation_id': confirmation_id}\n        )", "response": "This will iterate over all pages and return a list of all tags of confirmation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_reminders_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=REMINDERS, per_page=per_page, page=page, params=params)", "response": "Get reminders per page"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_reminders(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_reminders_per_page, resource=REMINDERS, **{'params': params})", "response": "This will iterate over all reminders and returns a list of all reminders"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_reminder(self, reminder_id, reminder_dict):\n        return self._create_put_request(\n            resource=REMINDERS,\n            billomat_id=reminder_id,\n            send_data=reminder_dict\n        )", "response": "Updates a reminder s metadata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef complete_reminder(self, reminder_id, complete_dict):\n        return self._create_put_request(\n            resource=REMINDERS,\n            billomat_id=reminder_id,\n            command=COMPLETE,\n            send_data=complete_dict\n        )", "response": "Completes a reminder\n\n        :param complete_dict: the complete dict with the template id\n        :param reminder_id: the reminder id\n        :return: Response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a pdf of a reminder", "response": "def reminder_pdf(self, reminder_id):\n        \"\"\"\n        Opens a pdf of a reminder\n\n        :param reminder_id: the reminder id\n        :return: dict\n        \"\"\"\n        return self._create_get_request(resource=REMINDERS, billomat_id=reminder_id, command=PDF)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an email to a reminder by email_dict", "response": "def send_reminder_email(self, reminder_id, email_dict):\n        \"\"\"\n        Sends an reminder by email\n        If you want to send your email to more than one persons do:\n        'recipients': {'to': ['bykof@me.com', 'mbykovski@seibert-media.net']}}\n\n        :param reminder_id: the reminder id\n        :param email_dict: the email dict\n        :return dict\n        \"\"\"\n        return self._create_post_request(\n            resource=REMINDERS,\n            billomat_id=reminder_id,\n            send_data=email_dict,\n            command=EMAIL,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_items_of_reminder_per_page(self, reminder_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=REMINDER_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'reminder_id': reminder_id},\n        )", "response": "Get items of reminder per page"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all items of reminder This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param reminder_id: the reminder id :return: list", "response": "def get_all_items_of_reminder(self, reminder_id):\n        \"\"\"\n        Get all items of reminder\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param reminder_id: the reminder id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_reminder_per_page,\n            resource=REMINDER_ITEMS,\n            **{'reminder_id': reminder_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_reminder_item(self, reminder_item_id, reminder_item_dict):\n        return self._create_put_request(\n            resource=REMINDER_ITEMS,\n            billomat_id=reminder_item_id,\n            send_data=reminder_item_dict\n        )", "response": "Updates a reminder item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tags_of_reminder_per_page(self, reminder_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=REMINDER_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'reminder_id': reminder_id},\n        )", "response": "Get tags of reminder per page"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_tags_of_reminder(self, reminder_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_reminder_per_page,\n            resource=REMINDER_TAGS,\n            **{'reminder_id': reminder_id}\n        )", "response": "This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_delivery_notes_per_page(self, per_page=1000, page=1, params=None):\n        return self._get_resource_per_page(resource=DELIVERY_NOTES, per_page=per_page, page=page, params=params)", "response": "Get delivery notes per page"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all delivery notes This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_delivery_notes(self, params=None):\n        \"\"\"\n        Get all delivery notes\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(\n            self.get_delivery_notes_per_page,\n            resource=DELIVERY_NOTES,\n            **{'params': params}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a delivery note", "response": "def update_delivery_note(self, delivery_note_id, delivery_note_dict):\n        \"\"\"\n        Updates a delivery note\n\n        :param delivery_note_id: the delivery note id\n        :param delivery_note_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=DELIVERY_NOTES,\n            billomat_id=delivery_note_id,\n            send_data=delivery_note_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncomplete a delivery note", "response": "def complete_delivery_note(self, delivery_note_id, complete_dict):\n        \"\"\"\n        Completes an delivery note\n\n        :param complete_dict: the complete dict with the template id\n        :param delivery_note_id: the delivery note id\n        :return: Response\n        \"\"\"\n        return self._create_put_request(\n            resource=DELIVERY_NOTES,\n            billomat_id=delivery_note_id,\n            command=COMPLETE,\n            send_data=complete_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delivery_note_pdf(self, delivery_note_id):\n        return self._create_get_request(resource=DELIVERY_NOTES, billomat_id=delivery_note_id, command=PDF)", "response": "Opens a pdf of a delivery note"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an email to a specific delivery note by email_dict.", "response": "def send_delivery_note_email(self, delivery_note_id, email_dict):\n        \"\"\"\n        Sends an delivery note by email\n        If you want to send your email to more than one persons do:\n        'recipients': {'to': ['bykof@me.com', 'mbykovski@seibert-media.net']}}\n\n        :param delivery_note_id: the delivery note id\n        :param email_dict: the email dict\n        :return dict\n        \"\"\"\n        return self._create_post_request(\n            resource=DELIVERY_NOTES,\n            billomat_id=delivery_note_id,\n            send_data=email_dict,\n            command=EMAIL,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget items of delivery note per page", "response": "def get_items_of_delivery_note_per_page(self, delivery_note_id, per_page=1000, page=1):\n        \"\"\"\n        Get items of delivery note per page\n\n        :param delivery_note_id: the delivery note id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=DELIVERY_NOTE_ITEMS,\n            per_page=per_page,\n            page=page,\n            params={'delivery_note_id': delivery_note_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all items of delivery note This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param delivery_note_id: the delivery note id :return: list", "response": "def get_all_items_of_delivery_note(self, delivery_note_id):\n        \"\"\"\n        Get all items of delivery note\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param delivery_note_id: the delivery note id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_items_of_delivery_note_per_page,\n            resource=DELIVERY_NOTE_ITEMS,\n            **{'delivery_note_id': delivery_note_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_delivery_note_item(self, delivery_note_item_id, delivery_note_item_dict):\n        return self._create_put_request(\n            resource=DELIVERY_NOTE_ITEMS,\n            billomat_id=delivery_note_item_id,\n            send_data=delivery_note_item_dict\n        )", "response": "Updates a delivery note item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_comments_of_delivery_note_per_page(self, delivery_note_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=DELIVERY_NOTE_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'delivery_note_id': delivery_note_id},\n        )", "response": "Get the comments of a delivery note per page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_comments_of_delivery_note(self, delivery_note_id):\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_delivery_note_per_page,\n            resource=DELIVERY_NOTE_COMMENTS,\n            **{'delivery_note_id': delivery_note_id}\n        )", "response": "This will iterate over all pages and get all comments of delivery note"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate a delivery note comment", "response": "def update_delivery_note_comment(self, delivery_note_comment_id, delivery_note_comment_dict):\n        \"\"\"\n        Updates a delivery note comment\n\n        :param delivery_note_comment_id: the delivery note comment id\n        :param delivery_note_comment_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=DELIVERY_NOTE_COMMENTS,\n            billomat_id=delivery_note_comment_id,\n            send_data=delivery_note_comment_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget tags of delivery note per page", "response": "def get_tags_of_delivery_note_per_page(self, delivery_note_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of delivery note per page\n\n        :param delivery_note_id: the delivery note id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=DELIVERY_NOTE_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'delivery_note_id': delivery_note_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_tags_of_delivery_note(self, delivery_note_id):\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_delivery_note_per_page,\n            resource=DELIVERY_NOTE_TAGS,\n            **{'delivery_note_id': delivery_note_id}\n        )", "response": "This will iterate over all pages until it gets all elements. If rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget letters per page", "response": "def get_letters_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get letters per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=LETTERS, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_letters(self, params=None):\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_letters_per_page, resource=LETTERS, **{'params': params})", "response": "This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_letter(self, letter_id, letter_dict):\n        return self._create_put_request(\n            resource=LETTERS,\n            billomat_id=letter_id,\n            send_data=letter_dict\n        )", "response": "Updates a letter s metadata"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_comments_of_letter_per_page(self, letter_id, per_page=1000, page=1):\n        return self._get_resource_per_page(\n            resource=LETTER_COMMENTS,\n            per_page=per_page,\n            page=page,\n            params={'letter_id': letter_id},\n        )", "response": "Get comments of a specific letter per page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_comments_of_letter(self, letter_id):\n        return self._iterate_through_pages(\n            get_function=self.get_comments_of_letter_per_page,\n            resource=LETTER_COMMENTS,\n            **{'letter_id': letter_id}\n        )", "response": "This will iterate over all pages and return a list of all comments of the given letter"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a letter comment", "response": "def update_letter_comment(self, letter_comment_id, letter_comment_dict):\n        \"\"\"\n        Updates a letter comment\n\n        :param letter_comment_id: the letter command id\n        :param letter_comment_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=LETTER_COMMENTS,\n            billomat_id=letter_comment_id,\n            send_data=letter_comment_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget tags of a specific letter per page", "response": "def get_tags_of_letter_per_page(self, letter_id, per_page=1000, page=1):\n        \"\"\"\n        Get tags of letter per page\n\n        :param letter_id: the letter id\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(\n            resource=LETTER_TAGS,\n            per_page=per_page,\n            page=page,\n            params={'letter_id': letter_id},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all tags of letter This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param letter_id: the letter id :return: list", "response": "def get_all_tags_of_letter(self, letter_id):\n        \"\"\"\n        Get all tags of letter\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param letter_id: the letter id\n        :return: list\n        \"\"\"\n        return self._iterate_through_pages(\n            get_function=self.get_tags_of_letter_per_page,\n            resource=LETTER_TAGS,\n            **{'letter_id': letter_id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets e - mail templates per page", "response": "def get_email_templates_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get e-mail templates per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=EMAIL_TEMPLATES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all e-mail templates This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_email_templates(self, params=None):\n        \"\"\"\n        Get all e-mail templates\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list \n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_email_templates_per_page, resource=EMAIL_TEMPLATES,\n                                           **{'params': params})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates an email template", "response": "def update_email_template(self, template_id, template_dict):\n        \"\"\"\n        Updates a emailtemplate\n\n        :param template_id: the template id\n        :param template_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=EMAIL_TEMPLATES,\n            billomat_id=template_id,\n            send_data=template_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting templates per page", "response": "def get_templates_per_page(self, per_page=1000, page=1, params=None):\n        \"\"\"\n        Get templates per page\n\n        :param per_page: How many objects per page. Default: 1000\n        :param page: Which page. Default: 1\n        :param params: Search parameters. Default: {}\n        :return: list\n        \"\"\"\n        return self._get_resource_per_page(resource=TEMPLATES, per_page=per_page, page=page, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all templates This will iterate over all pages until it gets all elements. So if the rate limit exceeded it will throw an Exception and you will get nothing :param params: search params :return: list", "response": "def get_all_templates(self, params=None):\n        \"\"\"\n        Get all templates\n        This will iterate over all pages until it gets all elements.\n        So if the rate limit exceeded it will throw an Exception and you will get nothing\n\n        :param params: search params\n        :return: list\n        \"\"\"\n        if not params:\n            params = {}\n        return self._iterate_through_pages(self.get_templates_per_page, resource=TEMPLATES, **{'params': params})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a template with the given id and dict", "response": "def update_template(self, template_id, template_dict):\n        \"\"\"\n        Updates a template\n\n        :param template_id: the template id\n        :param template_dict: dict\n        :return: dict\n        \"\"\"\n        return self._create_put_request(\n            resource=TEMPLATES,\n            billomat_id=template_id,\n            send_data=template_dict\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverse_translate(\n        protein_seq,\n        template_dna=None, leading_seq=None, trailing_seq=None,\n        forbidden_seqs=(), include_stop=True, manufacturer=None):\n    \"\"\"\n    Generate a well-behaved DNA sequence from the given protein sequence.  If a \n    template DNA sequence is specified, the returned DNA sequence will be as \n    similar to it  as possible.  Any given restriction sites will not be \n    present in the sequence.  And finally, the given leading and trailing \n    sequences will be appropriately concatenated.\n    \"\"\"\n\n    if manufacturer == 'gen9':\n        forbidden_seqs += gen9.reserved_restriction_sites\n\n    leading_seq = restriction_sites.get(leading_seq, leading_seq or '')\n    trailing_seq = restriction_sites.get(trailing_seq, trailing_seq or '')\n\n    codon_list = make_codon_list(protein_seq, template_dna, include_stop)\n    sanitize_codon_list(codon_list, forbidden_seqs)\n    dna_seq = leading_seq + ''.join(codon_list) + trailing_seq\n\n    if manufacturer == 'gen9':\n        gen9.apply_quality_control_checks(dna_seq)\n\n    return dna_seq", "response": "Reverse translate a given protein sequence into a well - behaved DNA sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of codons that would be translated to the given protein_seq.", "response": "def make_codon_list(protein_seq, template_dna=None, include_stop=True):\n    \"\"\"\n    Return a list of codons that would be translated to the given protein \n    sequence.  Codons are picked first to minimize the mutations relative to a \n    template DNA sequence and second to prefer \"optimal\" codons.\n    \"\"\"\n\n    codon_list = []\n\n    if template_dna is None:\n        template_dna = []\n\n    # Reverse translate each codon, preferring (in order):\n    # 1. The codon with the most similarity to the template codon.\n    # 2. The codon with the highest natural usage.\n\n    for i, res in enumerate(protein_seq.upper()):\n        try: template_codon = template_dna[3*i:3*i+3]\n        except IndexError: template_codon = '---'\n\n        # Already sorted by natural codon usage\n        possible_codons = dna.ecoli_reverse_translate[res]\n\n        # Sort by similarity.  Note that this is a stable sort.\n        possible_codons.sort(\n                key=lambda x: dna.num_mutations(x, template_codon))\n\n        # Pick the best codon.\n        codon_list.append(possible_codons[0])\n\n    # Make sure the sequence ends with a stop codon.\n    last_codon = codon_list[-1]\n    stop_codons = dna.ecoli_reverse_translate['.']\n\n    if include_stop and last_codon not in stop_codons:\n        codon_list.append(stop_codons[0])\n\n    return codon_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsanitizing a codon list to be consistent with the Gene9 module.", "response": "def sanitize_codon_list(codon_list, forbidden_seqs=()):\n    \"\"\"\n    Make silent mutations to the given codon lists to remove any undesirable \n    sequences that are present within it.  Undesirable sequences include \n    restriction sites, which may be optionally specified as a second argument, \n    and homopolymers above a pre-defined length.  The return value is the \n    number of corrections made to the codon list.\n    \"\"\"\n\n    # Unit test missing for:\n    #   Homopolymer fixing\n\n    for codon in codon_list:\n        if len(codon) != 3:\n            raise ValueError(\"Codons must have exactly 3 bases: '{}'\".format(codon))\n\n    # Compile a collection of all the sequences we don't want to appear in the \n    # gene.  This includes the given restriction sites and their reverse \n    # complements, plus any homopolymers above a pre-defined length.\n\n    bad_seqs = set()\n    \n    bad_seqs.union(\n            restriction_sites.get(seq, seq)\n            for seq in forbidden_seqs)\n\n    bad_seqs.union(\n            dna.reverse_complement(seq)\n            for seq in bad_seqs)\n\n    bad_seqs.union(\n            base * (gen9.homopolymer_max_lengths[base] + 1)\n            for base in dna.dna_bases)\n\n    bad_seqs = [\n            dna.dna_to_re(bs)\n            for bs in bad_seqs]\n\n    # Remove every bad sequence from the gene by making silent mutations to the \n    # codon list.\n    \n    num_corrections = 0\n\n    for bad_seq in bad_seqs:\n        while remove_bad_sequence(codon_list, bad_seq, bad_seqs):\n            num_corrections += 1\n\n    return num_corrections"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a silent mutation to the given codon list to remove the first instance of the given bad sequence found in the gene sequence. If the bad sequence isn't found, nothing happens and the function returns false. Otherwise the function returns true. You can use these return values to easily write a loop totally purges the bad sequence from the codon list. Both the specific bad sequence in question and the list of all bad sequences are expected to be regular expressions.", "response": "def remove_bad_sequence(codon_list, bad_seq, bad_seqs):\n    \"\"\"\n    Make a silent mutation to the given codon list to remove the first instance \n    of the given bad sequence found in the gene sequence.  If the bad sequence \n    isn't found, nothing happens and the function returns false.  Otherwise the \n    function returns true.  You can use these return values to easily write a \n    loop totally purges the bad sequence from the codon list.  Both the \n    specific bad sequence in question and the list of all bad sequences are \n    expected to be regular expressions.\n    \"\"\"\n\n    gene_seq = ''.join(codon_list)\n    problem = bad_seq.search(gene_seq)\n\n    if not problem:\n        return False\n\n    bs_start_codon = problem.start() // 3\n    bs_end_codon = problem.end() // 3\n\n    for i in range(bs_start_codon, bs_end_codon):\n        problem_codon = codon_list[i]\n        amino_acid = translate_dna(problem_codon)\n\n        alternate_codons = [\n                codon\n                for codon in dna.ecoli_reverse_translate[amino_acid]\n                if codon != problem_codon]\n\n        for alternate_codon in alternate_codons:\n            codon_list[i] = alternate_codon\n\n            if problem_with_codon(i, codon_list, bad_seqs):\n                codon_list[i] = problem_codon\n            else:\n                return True\n\n    raise RuntimeError(\"Could not remove bad sequence '{}' from gene.\".format(bs))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef problem_with_codon(codon_index, codon_list, bad_seqs):\n\n    base_1 = 3 * codon_index\n    base_3 = 3 * codon_index + 2\n\n    gene_seq = ''.join(codon_list)\n\n    for bad_seq in bad_seqs:\n        problem = bad_seq.search(gene_seq)\n        if problem and problem.start() < base_3 and problem.end() > base_1:\n            return True\n\n    return False", "response": "Return True if the given codon overlaps with a bad sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting multiple sequences from a FASTA file.", "response": "def sequences_from_fasta(path):\n    \"\"\"\n    Extract multiple sequences from a FASTA file.\n    \"\"\"\n    from Bio import SeqIO\n    return {x.description: x.seq for x in SeqIO.parse(path, 'fasta')}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sequence_from_pdb(pdb, chain=None, ref=None):\n\n    seqs = chains_from_pdb(pdb)\n    \n    if chain is None:\n        if len(seqs) == 1:\n            return next(iter(seqs.values()))\n        else:\n            raise scripting.UserError(\"'{}' contains multiple chains, but no chain was specified.\".format(pdb))\n\n    single = re.match('^([A-Z])$', chain)\n    merge = re.match('^(?:([A-Z])[~])+([A-Z])$', chain)\n    concat = re.match('^(?:([A-Z])[+])+([A-Z])$', chain)\n    \n    if single:\n        chain = single.group(1)\n        return seqs[chain]\n\n    if merge:\n        if ref is None:\n            raise ValueError('template required to merge sequences')\n\n        mutants = [seqs[k] for k in merge.groups()]\n        return merge_sequences(ref, *mutants)\n\n    if concat:\n        return ''.join(seqs[k] for k in concat.groups())\n\n    raise ValueError(\"chain '{}' not understood\".format(chain))", "response": "Extract a protein sequence from a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_sequences(path, seqs):\n    path = Path(path)\n\n    if path.suffix in ('.fa', '.fas', '.fasta'):\n        write_sequences_to_fasta(path, seqs)\n\n    elif path.suffix in ('.tsv', '.csv'):\n        write_sequences_to_tsv(path, seqs)\n\n    elif path.suffix in ('.xlsx',):\n        write_sequences_to_xlsx(path, seqs)\n\n    else:\n        raise scripting.UserError(\"\"\"\\\n'{}' has unknown output filetype '{}'.  Please provide a path with one of the \nfollowing extensions:\n\n- *.fa, *.fas, *.fasta\n- *.tsv, *.csv\n- *.xlsx\n\"\"\".format(path, path.suffix))", "response": "Writes the given dictionary of sequences to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a FASTA file listing the given sequences.", "response": "def write_sequences_to_fasta(path, seqs):\n    \"\"\"\n    Create a FASTA file listing the given sequences.\n\n    Arguments\n    =========\n    path: str or pathlib.Path\n        The name of the file to create.\n\n    seqs: dict\n        A mapping of names to sequences, which can be either protein or DNA.\n    \"\"\"\n    from Bio import SeqIO\n    from Bio.Seq import Seq\n    from Bio.SeqRecord import SeqRecord\n\n    path = Path(path)\n    records = []\n\n    for id, seq in seqs.items():\n        record = SeqRecord(Seq(seq), id=id, description='')\n        records.append(record)\n\n    SeqIO.write(records, str(path), 'fasta')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a TSV or CSV file listing the given dict of sequences.", "response": "def write_sequences_to_tsv(path, seqs):\n    \"\"\"\n    Create a TSV (or CSV, depending on the extension) file listing the given \n    sequences.\n\n    Arguments\n    =========\n    path: str or pathlib.Path\n        The name of the file to create.  If the path extension is '.tsv', \n        fields will be delimited by tabs.  If the extension is '.csv', fields \n        will be delimited by commas.\n\n    seqs: dict\n        A mapping of names to sequences, which can be either protein or DNA.\n    \"\"\"\n    import csv\n\n    path = Path(path)\n    delimiter = {'.tsv': '\\t', '.csv': ','}[path.suffix]\n    with path.open('w') as file:\n        w = csv.writer(file, delimiter=delimiter)\n        for row in seqs.items():\n            w.writerow(row)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XLSX file listing the given sequences.", "response": "def write_sequences_to_xlsx(path, seqs):\n    \"\"\"\n    Create a XLSX file listing the given sequences.\n\n    Arguments\n    =========\n    path: str or pathlib.Path\n        The name of the file to create.\n\n    seqs: dict\n        A mapping of names to sequences, which can be either protein or DNA.\n    \"\"\"\n    from openpyxl import Workbook\n\n    wb = Workbook()\n    ws = wb.active\n\n    for row, id in enumerate(seqs, 1):\n        ws.cell(row, 1).value = id\n        ws.cell(row, 2).value = seqs[id]\n\n    wb.save(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_node(self, node):\n        other_nodes = [n for n in self.nodes() if n.id != node.id]\n\n        if isinstance(node, Source) and other_nodes:\n            raise(Exception(\"Chain network already has a nodes, \"\n                            \"can't add a source.\"))\n\n        if other_nodes:\n            parent = max(other_nodes, key=attrgetter('creation_time'))\n            parent.connect(whom=node)", "response": "Add an agent connecting it to the previous node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlink the agent to a random member of the previous generation.", "response": "def add_node(self, node):\n        \"\"\"Link the agent to a random member of the previous generation.\"\"\"\n        nodes = [n for n in self.nodes() if not isinstance(n, Source)]\n        num_agents = len(nodes)\n        curr_generation = int((num_agents - 1) / float(self.generation_size))\n        node.generation = curr_generation\n\n        if curr_generation == 0:\n            if self.initial_source:\n                source = min(\n                    self.nodes(type=Source),\n                    key=attrgetter('creation_time'))\n                source.connect(whom=node)\n                source.transmit(to_whom=node)\n        else:\n            prev_agents = Node.query\\\n                .filter_by(failed=False,\n                           network_id=self.id,\n                           generation=(curr_generation - 1))\\\n                .all()\n            prev_fits = [p.fitness for p in prev_agents]\n            prev_probs = [(f / (1.0 * sum(prev_fits))) for f in prev_fits]\n\n            rnd = random.random()\n            temp = 0.0\n            for i, probability in enumerate(prev_probs):\n                temp += probability\n                if temp > rnd:\n                    parent = prev_agents[i]\n                    break\n\n            parent.connect(whom=node)\n            parent.transmit(to_whom=node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding newcomers one by one using linear preferential attachment.", "response": "def add_node(self, node):\n        \"\"\"Add newcomers one by one, using linear preferential attachment.\"\"\"\n        nodes = self.nodes()\n\n        # Start with a core of m0 fully-connected agents...\n        if len(nodes) <= self.m0:\n            other_nodes = [n for n in nodes if n.id != node.id]\n            for n in other_nodes:\n                node.connect(direction=\"both\", whom=n)\n\n        # ...then add newcomers one by one with preferential attachment.\n        else:\n            for idx_newvector in xrange(self.m):\n\n                these_nodes = [\n                    n for n in nodes if (\n                        n.id != node.id and\n                        not n.is_connected(direction=\"either\", whom=node))]\n\n                outdegrees = [\n                    len(n.vectors(direction=\"outgoing\")) for n in these_nodes]\n\n                # Select a member using preferential attachment\n                ps = [(d / (1.0 * sum(outdegrees))) for d in outdegrees]\n                rnd = random.random() * sum(ps)\n                cur = 0.0\n                for i, p in enumerate(ps):\n                    cur += p\n                    if rnd < cur:\n                        vector_to = these_nodes[i]\n\n                # Create vector from newcomer to selected member and back\n                node.connect(direction=\"both\", whom=vector_to)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_node(self, node):\n        nodes = sorted(\n            self.nodes(),\n            key=attrgetter('creation_time'), reverse=True)\n\n        other_nodes = [n for n in nodes if n.id != node.id]\n\n        connecting_nodes = other_nodes[0:(self.n - 1)]\n\n        for n in connecting_nodes:\n            n.connect(whom=node)", "response": "Add a node connecting it to all the active nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef docker_py_dict(self):\n        return {\n            'image': self.image,\n            'command': self.cmd,\n            'hostname': self.hostname,\n            'user': self.user,\n            'detach': self.detach,\n            'stdin_open': self.open_stdin,\n            'tty': self.tty,\n            'ports': self.exposed_ports,\n            'environment': self.env,\n            'volumes': self.volumes,\n            'network_disabled': self.network_disabled,\n            'entrypoint': self.entry_point,\n            'working_dir': self.working_dir,\n            'domainname': self.domain_name,\n            'labels': self.labels\n        }", "response": "Convert object to match valid docker - py properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_env(self, env):\n        # convert to dict to allow update\n        current_env = dict(item.split('=') for item in self._env)\n\n        # do validation and set new values.\n        self.env = env\n\n        # convert to dict to allow update\n        new_env = dict(item.split('=') for item in self._env)\n\n        # update old with new\n        current_env.update(new_env)\n\n        # apply updated values\n        self.env = current_env", "response": "Merge environment variables into current environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the hostname of the object", "response": "def hostname(self, hostname):\n        \"\"\" hostname setter\n\n        \"\"\"\n        if not isinstance(hostname, six.string_types):\n            raise TypeError(\"hostname must be a string.  {0} was passed.\".format(type(hostname)))\n\n        # if a host name is passed and its not valid raise else set hostname empty strings are the docker default.\n        if hostname and not is_valid_hostname(hostname):\n            raise ValueError(\"{0} isn't a valid hostname\").format(hostname)\n        else:\n            self._hostname = hostname"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_valid_port(self, port):\n        if '/' in port:\n            port, protocol = port.split('/')\n        else:\n            protocol = 'tcp'\n\n        try:\n            int(port)\n        except ValueError:\n            raise ValueError(\"{0} isn't a valid port number.\".format(port))\n\n        if protocol not in ('tcp', 'udp'):\n            raise ValueError(\"exposed ports only supports udp or tcp. {0} was passed\".format(protocol))\n\n        return \"{0}/{1}\".format(port, protocol)", "response": "Returns a valid port name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a restclients. Person object for the given regid.", "response": "def get_person_by_regid(self, regid):\n        \"\"\"\n        Returns a restclients.Person object for the given regid.  If the\n        regid isn't found, or if there is an error communicating with the PWS,\n        a DataFailureException will be thrown.\n        \"\"\"\n        if not self.valid_uwregid(regid):\n            raise InvalidRegID(regid)\n\n        url = \"{}/{}/full.json\".format(PERSON_PREFIX, regid.upper())\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        return self._person_from_json(response.data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_person_by_netid(self, netid):\n        if not self.valid_uwnetid(netid):\n            raise InvalidNetID(netid)\n\n        url = \"{}/{}/full.json\".format(PERSON_PREFIX, netid.lower())\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        return self._person_from_json(response.data)", "response": "Returns a restclients. Person object for the given netid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a restclients. Person object for the given employee id.", "response": "def get_person_by_employee_id(self, employee_id):\n        \"\"\"\n        Returns a restclients.Person object for the given employee id.  If the\n        employee id isn't found, or if there is an error communicating with the\n        PWS, a DataFailureException will be thrown.\n        \"\"\"\n        if not self.valid_employee_id(employee_id):\n            raise InvalidEmployeeID(employee_id)\n\n        url = \"{}.json?{}\".format(\n            PERSON_PREFIX, urlencode({\"employee_id\": employee_id}))\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        # Search does not return a full person resource\n        data = json.loads(response.data)\n        if not len(data[\"Persons\"]):\n            raise DataFailureException(url, 404, \"No person found\")\n\n        regid = data[\"Persons\"][0][\"PersonURI\"][\"UWRegID\"]\n        return self.get_person_by_regid(regid)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_person_by_student_number(self, student_number):\n        if not self.valid_student_number(student_number):\n            raise InvalidStudentNumber(student_number)\n\n        url = \"{}.json?{}\".format(\n            PERSON_PREFIX, urlencode({\"student_number\": student_number}))\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        # Search does not return a full person resource\n        data = json.loads(response.data)\n        if not len(data[\"Persons\"]):\n            raise DataFailureException(url, 404, \"No person found\")\n\n        regid = data[\"Persons\"][0][\"PersonURI\"][\"UWRegID\"]\n        return self.get_person_by_regid(regid)", "response": "Returns a restclients. Person object for the given student number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a restclients. Person object for the given rfid.", "response": "def get_person_by_prox_rfid(self, prox_rfid):\n        \"\"\"\n        Returns a restclients.Person object for the given rfid.  If the rfid\n        isn't found, or if there is an error communicating with the IdCard WS,\n        a DataFailureException will be thrown.\n        \"\"\"\n        if not self.valid_prox_rfid(prox_rfid):\n            raise InvalidProxRFID(prox_rfid)\n\n        url = \"{}.json?{}\".format(\n            CARD_PREFIX, urlencode({\"prox_rfid\": prox_rfid}))\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        data = json.loads(response.data)\n        if not len(data[\"Cards\"]):\n            raise DataFailureException(url, 404, \"No card found\")\n\n        regid = data[\"Cards\"][0][\"RegID\"]\n        return self.get_person_by_regid(regid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_entity_by_regid(self, regid):\n        if not self.valid_uwregid(regid):\n            raise InvalidRegID(regid)\n\n        url = \"{}/{}.json\".format(ENTITY_PREFIX, regid.upper())\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        return self._entity_from_json(response.data)", "response": "Returns a restclients. Entity object for the given regid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a restclients. Entity object for the given netid.", "response": "def get_entity_by_netid(self, netid):\n        \"\"\"\n        Returns a restclients.Entity object for the given netid.  If the\n        netid isn't found, or if there is an error communicating with the PWS,\n        a DataFailureException will be thrown.\n        \"\"\"\n        if not self.valid_uwnetid(netid):\n            raise InvalidNetID(netid)\n\n        url = \"{}/{}.json\".format(ENTITY_PREFIX, netid.lower())\n        response = DAO.getURL(url, {\"Accept\": \"application/json\"})\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        return self._entity_from_json(response.data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a jpeg image for the passed uwregid.", "response": "def get_idcard_photo(self, regid, size=\"medium\"):\n        \"\"\"\n        Returns a jpeg image, for the passed uwregid. Size is configured as:\n            \"small\" (20w x 25h px),\n            \"medium\" (120w x 150h px),\n            \"large\" (240w x 300h px),\n            {height in pixels} (custom height, default aspect ratio)\n        \"\"\"\n        if not self.valid_uwregid(regid):\n            raise InvalidRegID(regid)\n\n        size = str(size)\n        if (not re.match(r\"(?:small|medium|large)$\", size) and\n                not re.match(r\"[1-9]\\d{1,3}$\", size)):\n            raise InvalidIdCardPhotoSize(size)\n\n        url = \"{}/{}-{}.jpg\".format(PHOTO_PREFIX, regid.upper(), size)\n\n        headers = {\"Accept\": \"image/jpeg\"}\n\n        if self.actas is not None:\n            if not self.valid_uwnetid(self.actas):\n                raise InvalidNetID(self.actas)\n            headers[\"X-UW-Act-as\"] = self.actas\n\n        response = DAO.getURL(url, headers)\n\n        if response.status != 200:\n            raise DataFailureException(url, response.status, response.data)\n\n        return streamIO(response.data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_identifier(sender, instance, **kwargs):\n    identifier = Concept.create_identifier(instance.query)\n    qs = Concept.objects.filter(identifier=identifier, lang=instance.lang)\n    if instance.pk:\n        qs = qs.exclude(pk=instance.pk)\n    if qs.count() > 0:\n        raise ValueError(\"Concept identifier conflict\")\n    instance.identifier = identifier", "response": "Generate and set identifier of concept before saving object to DB\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_concept_item_mapping(self, concepts=None, lang=None):\n        if concepts is None:\n            concepts = self.filter(active=True)\n            if lang is not None:\n                concepts = concepts.filter(lang=lang)\n        if lang is None:\n            languages = set([concept.lang for concept in concepts])\n            if len(languages) > 1:\n                raise Exception('Concepts has multiple languages')\n            lang = list(languages)[0]\n        item_lists = Item.objects.filter_all_reachable_leaves_many([json.loads(concept.query)\n                                                                    for concept in concepts], lang)\n        return dict(zip([c.pk for c in concepts], item_lists))", "response": "Get mapping of concepts to items belonging to concept."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_item_concept_mapping(self, lang):\n        concepts = self.filter(active=True, lang=lang)\n        return group_keys_by_value_lists(Concept.objects.get_concept_item_mapping(concepts, lang))", "response": "Get mapping of items_ids to concepts containing these items\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget concept which have same changes and have to be recalculated", "response": "def get_concepts_to_recalculate(self, users, lang, concepts=None):\n        \"\"\"\n        Get concept which have same changes and have to be recalculated\n\n        Args:\n            users (list of users or user): users whose user stats we are interesting in\n            lang (str): language of used concepts\n            concepts (Optional[list of concepts]): list of primary keys of concepts or concepts\n                Defaults to None meaning all concepts.\n\n        Returns:\n            dict: user -> set of concepts (int) - in case of list of users\n            list of stats (str) - in case of one user\n        \"\"\"\n        only_one_user = False\n        if not isinstance(users, list):\n            only_one_user = True\n            users = [users]\n\n        mapping = self.get_item_concept_mapping(lang)\n        current_user_stats = defaultdict(lambda: {})\n        user_stats_qs = UserStat.objects.filter(user__in=users, stat=\"answer_count\")     # we need only one type\n        if concepts is not None:\n            user_stats_qs = user_stats_qs.filter(concept__in=concepts)\n        for user_stat in user_stats_qs:\n            current_user_stats[user_stat.user_id][user_stat.concept_id] = user_stat\n\n        concepts_to_recalculate = defaultdict(lambda: set())\n        for user, item, time in Answer.objects.filter(user__in=users)\\\n                .values_list(\"user_id\", \"item\").annotate(Max(\"time\")):\n            if item not in mapping:\n                # in reality this should by corner case, so it is efficient to not filter Answers\n                continue    # item is not in concept\n            time_expiration_lower_bound = get_config('proso_models', 'knowledge_overview.time_shift_hours', default=4)\n            time_expiration_factor = get_config('proso_models', 'knowledge_overview.time_expiration_factor', default=2)\n            for concept in mapping[item]:\n                if user in current_user_stats and concept in current_user_stats[user] \\\n                        and current_user_stats[user][concept].time > time:\n                    if not self.has_time_expired(current_user_stats[user][concept].time, time, time_expiration_lower_bound, time_expiration_factor):\n                        continue  # cache is up to date\n\n                if concepts is None or concept in ([c.pk for c in concepts] if type(concepts[0]) == Concept else Concept):\n                    concepts_to_recalculate[user].add(concept)\n\n        if only_one_user:\n            return concepts_to_recalculate[users[0]]\n        return concepts_to_recalculate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recalculate_concepts(self, concepts, lang=None):\n        if len(concepts) == 0:\n            return\n\n        if lang is None:\n            items = Concept.objects.get_concept_item_mapping(concepts=Concept.objects.filter(pk__in=set(flatten(concepts.values()))))\n        else:\n            items = Concept.objects.get_concept_item_mapping(lang=lang)\n\n        environment = get_environment()\n        mastery_threshold = get_mastery_trashold()\n        for user, concepts in concepts.items():\n            all_items = list(set(flatten([items[c] for c in concepts])))\n            answer_counts = environment.number_of_answers_more_items(all_items, user)\n            correct_answer_counts = environment.number_of_correct_answers_more_items(all_items, user)\n            predictions = dict(list(zip(all_items, get_predictive_model().\n                                        predict_more_items(environment, user, all_items, time=get_time_for_knowledge_overview()))))\n            new_user_stats = []\n            stats_to_delete_condition = Q()\n            for concept in concepts:\n                answer_aggregates = Answer.objects.filter(user=user, item__in=items[concept]).aggregate(\n                    time_spent=Sum(\"response_time\"),\n                    sessions=Count(\"session\", True),\n                    time_first=Min(\"time\"),\n                    time_last=Max(\"time\"),\n                )\n                stats = {\n                    \"answer_count\": sum(answer_counts[i] for i in items[concept]),\n                    \"correct_answer_count\": sum(correct_answer_counts[i] for i in items[concept]),\n                    \"item_count\": len(items[concept]),\n                    \"practiced_items_count\": sum([answer_counts[i] > 0 for i in items[concept]]),\n                    \"mastered_items_count\": sum([predictions[i] >= mastery_threshold for i in items[concept]]),\n                    \"prediction\": sum([predictions[i] for i in items[concept]]) / len(items[concept]),\n                    \"time_spent\": answer_aggregates[\"time_spent\"] / 1000,\n                    \"session_count\": answer_aggregates[\"sessions\"],\n                    \"time_first\": answer_aggregates[\"time_first\"].timestamp(),\n                    \"time_last\": answer_aggregates[\"time_last\"].timestamp(),\n                }\n                stats_to_delete_condition |= Q(user=user, concept=concept)\n                for stat_name, value in stats.items():\n                    new_user_stats.append(UserStat(user_id=user, concept_id=concept, stat=stat_name, value=value))\n            self.filter(stats_to_delete_condition).delete()\n            self.bulk_create(new_user_stats)", "response": "Recalculates given concepts for given users"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_user_stats(self, users, lang=None, concepts=None, since=None, recalculate=True):\n        only_one_user = False\n        if not isinstance(users, list):\n            users = [users]\n            only_one_user = True\n\n        if recalculate:\n            if lang is None:\n                raise ValueError('Recalculation without lang is not supported.')\n            time_start = time_lib()\n            concepts_to_recalculate = Concept.objects.get_concepts_to_recalculate(users, lang, concepts)\n            LOGGER.debug(\"user_stats - getting identifying concepts to recalculate: %ss\", (time_lib() - time_start))\n            time_start = time_lib()\n            self.recalculate_concepts(concepts_to_recalculate, lang)\n            LOGGER.debug(\"user_stats - recalculating concepts: %ss\", (time_lib() - time_start))\n\n        qs = self.prepare_related().filter(user__in=users, concept__active=True)\n        if concepts is not None:\n            qs = qs.filter(concept__in=concepts)\n        if lang is not None:\n            qs = qs.filter(concept__lang=lang)\n        if since is not None:\n            qs = qs.filter(time__gte=since)\n\n        data = defaultdict(lambda: defaultdict(lambda: {}))\n        for user_stat in qs:\n            data[user_stat.user_id][user_stat.concept.identifier][user_stat.stat] = user_stat.value\n        if only_one_user:\n            return data[users[0].pk if type(users[0]) == User else users[0]]\n        return data", "response": "Returns a dict of UserStats for given concepts and users."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getSortedString(o):\n\t# todo: replace this with something like pprint on Python upgrade\n\t# We assume here that any container type is either list or tuple which may not always hold\n\tif isinstance(o, (dict)):\n\t\tpkeys = sorted(o.keys(), key=_lowercaseToStr)\n\t\tl = []\n\t\tfor k in pkeys:\n\t\t\tl.append(str(k) + \":\" + _getSortedString(o[k]))\n\t\treturn \"{\" + join(l, \",\") + \"}\"\n\telse:\n\t\treturn str(o)", "response": "Returns a string describing o sorting the contents ( case - insensitive on keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting SQL query. This uses DictCursor by default.", "response": "def execute(self, sql, parameters = None, cursorClass = DictCursor, quiet = False, locked = False, do_commit = True):\n\t\t\"\"\"Execute SQL query. This uses DictCursor by default.\"\"\"\n\t\ti = 0\n\t\terrcode = 0\n\t\tcaughte = None\n\t\tcursor = None\n\t\tif sql.find(\";\") != -1 or sql.find(\"\\\\G\") != -1:\n\t\t\t# Catches some injections\n\t\t\traise Exception(\"The SQL command '%s' contains a semi-colon or \\\\G. This is a potential SQL injection.\" % sql)\n\t\twhile i < self.numTries:\n\t\t\ti += 1\n\t\t\ttry:\n\t\t\t\tassert(not(self.connection) or not(self.connection.open))\n\t\t\t\tself._get_connection(cursorClass)\n\t\t\t\tcursor = self.connection.cursor()\n\t\t\t\tif locked:\n\t\t\t\t\tcursor.execute(self.lockstring)\n\t\t\t\t\tself.locked = True\n\t\t\t\tif parameters:\n\t\t\t\t\terrcode = cursor.execute(sql, parameters)\n\t\t\t\telse:\n\t\t\t\t\terrcode = cursor.execute(sql)\n\t\t\t\tself.lastrowid = int(cursor.lastrowid)\n\t\t\t\tif do_commit and self.isInnoDB:\n\t\t\t\t\tself.connection.commit()\n\t\t\t\tresults = cursor.fetchall()\n\t\t\t\tif locked:\n\t\t\t\t\tcursor.execute(self.unlockstring)\n\t\t\t\t\tself.locked = False\n\t\t\t\tcursor.close()\n\t\t\t\tself._close_connection()\n\t\t\t\treturn results\n\t\t\texcept MySQLdb.OperationalError, e:\n\t\t\t\tif cursor:\n\t\t\t\t\tif self.locked:\n\t\t\t\t\t\tcursor.execute(self.unlockstring)\n\t\t\t\t\t\tself.locked = False\n\t\t\t\t\tcursor.close()\n\t\t\t\tself._close_connection()\n\t\t\t\tcaughte = str(e)\n\t\t\t\terrcode = e[0]\n\t\t\t\tcontinue\n\t\t\texcept Exception, e:\n\t\t\t\tif cursor:\n\t\t\t\t\tif self.locked:\n\t\t\t\t\t\tcursor.execute(self.unlockstring)\n\t\t\t\t\t\tself.locked = False\n\t\t\t\t\tcursor.close()\n\t\t\t\tself._close_connection()\n\t\t\t\tcaughte = str(e)\n\t\t\t\ttraceback.print_exc()\n\t\t\t\tbreak\n\t\t\tsleep(0.2)\n\t\t\n\t\tif not quiet:\n\t\t\tsys.stderr.write(\"\\nSQL execution error in query %s at %s:\" % (sql, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n\t\t\tsys.stderr.write(\"\\nErrorcode/Error: %d - '%s'.\\n\" % (errcode, str(caughte)))\n\t\t\tsys.stderr.flush()\n\t\traise MySQLdb.OperationalError(caughte)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getData4ID(self, tablename, ID):\n\t\t\t   \n\t\tfields = self._getFieldsInDB(tablename)\n\t\t#DATE_ADD(EndDate, INTERVAL 8 DAY), TIMEDIFF(DATE_ADD(EndDate, INTERVAL 7 DAY), NOW()), TIMEDIFF(EndDate, StartDate)\n\t\tSQL = '''SELECT *,DATE_ADD(EndDate, INTERVAL %s DAY),TIMEDIFF(DATE_ADD(EndDate, INTERVAL %s DAY), NOW()),TIMEDIFF(EndDate, StartDate) \n\t\t\t\t FROM %s WHERE ID=%s''' % (self.store_time, self.store_time, tablename, ID)\n\n\t\tarray_data = self.execQuery(SQL)\n\t\t\n\t\tif len(array_data) > 0:\n\t\t\tfor x in range( len(fields) ):\n\t\t\t\tself.data[fields[x]] = array_data[0][x]\n\t\t\tself.data['date_expiration']  = array_data[0][-3]\n\t\t\tself.data['time_expiration']  = array_data[0][-2]\n\t\t\tself.data['time_computation'] = array_data[0][-1]\n\n\t\treturn self.data", "response": "get the whole row from the database and store it in a dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the whole row from the database and store it in a dict", "response": "def getData4cryptID(self, tablename, ID):\n\t\t\"\"\"get the whole row from the database and store it in a dict\"\"\"\n\t\t\t   \n\t\tfields = self._getFieldsInDB(tablename)\n\t\t\n\t\tSQL = 'SELECT *,MAKETIME(0,0,TIMESTAMPDIFF(SECOND, StartDate, EndDate)),DATE_ADD(EndDate, INTERVAL %s DAY),TIMESTAMPDIFF(DAY,DATE_ADD(EndDate, INTERVAL %s DAY), NOW()),TIMESTAMPDIFF(HOUR,DATE_ADD(EndDate, INTERVAL %s DAY), NOW()) FROM %s WHERE cryptID=\"%s\"' % (self.store_time, self.store_time, self.store_time, tablename, ID)\n\t\t\n\t\tarray_data = self.execQuery(SQL)\n\t\t\n\t\tif len(array_data) > 0:\n\t\t\tfor x in range( len(fields) ):\n\t\t\t\tself.data[fields[x]] = array_data[0][x]\n\t\t\tself.data['date_expiration']  = array_data[0][-3]\n\t\t\ttime_expiration = None\n\t\t\tif array_data[0][-2] and array_data[0][-1]:\n\t\t\t\ttime_expiration = \"%d days, %d hours\" % (abs(array_data[0][-2]),abs(array_data[0][-1]) - abs(array_data[0][-2] * 24))\t\t\t\n\t\t\tself.data['time_expiration']  = time_expiration\n\t\t\tself.data['time_computation'] = array_data[0][-4]\n\t\t\t\t\t\t \n\t\treturn self.data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insertData(self, tablename, list_value_pairs, list_SQLCMD_pairs=None):\n\t\t\n\t\tfields = self._getFieldsInDB(tablename)\n\t\t\n\t\tlst_field = []\n\t\tlst_value = []\n\t\t\n\t\t# normal field-value-pairs\n\t\tfor pair in list_value_pairs:\n\t\t\tif pair[0] in fields:\n\t\t\t\tlst_field.append( pair[0] )\n\t\t\t\tlst_value.append( '\"%s\"' % pair[1] )\n\t\t\telse:\n\t\t\t\tprint \"err: field %s can't be found in the table\" % pair[0]\n\t\t\t\treturn False\n\t\t\t\n\t\t# field-SQL-command-pairs: the only difference is the missing double quotes in the SQL command\n\t\tif list_SQLCMD_pairs != None:\n\t\t\tfor pair in list_SQLCMD_pairs:\n\t\t\t\tif pair[0] in fields:\n\t\t\t\t\tlst_field.append( pair[0] )\n\t\t\t\t\tlst_value.append( pair[1] )\n\t\t\t\telse:\n\t\t\t\t\tprint \"err: field %s can't be found in the table\" % pair[0]\n\t\t\t\t\treturn False\n\t\t\t\t\n\t\t# build the command\n\t\tSQL = 'INSERT INTO %s (%s) VALUES (%s)' % ( tablename, join(lst_field, ','), join(lst_value, ',') )\n\t\tself.execQuery( SQL )\n\t\t\n\t\treturn True", "response": "insert data into table\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef callproc(self, procname, parameters = (), cursorClass = DictCursor, quiet = False):\n\t\ti = 0\n\t\terrcode = 0\n\t\tcaughte = None\n\t\twhile i < self.numTries:\n\t\t\ti += 1\n\t\t\ttry:\t\n\t\t\t\tcursor = self.connection.cursor(cursorClass)\n\t\t\t\tif type(parameters) != type(()):\n\t\t\t\t\tparameters = (parameters,)\n\t\t\t\terrcode = cursor.callproc(procname, parameters)\n\t\t\t\tresults = cursor.fetchall()\n\t\t\t\tself.lastrowid = int(cursor.lastrowid)\n\t\t\t\tcursor.close()\n\t\t\t\treturn results\n\t\t\texcept MySQLdb.OperationalError, e:\n\t\t\t\terrcode = e[0]\n\t\t\t\tself.connection.ping()\n\t\t\t\tcaughte = e\n\t\t\t\tcontinue\n\t\t\texcept:\t\t\t\t\n\t\t\t\ttraceback.print_exc()\n\t\t\t\tbreak\n\t\t\n\t\tif not quiet:\n\t\t\tsys.stderr.write(\"\\nSQL execution error call stored procedure %s at %s:\" % (procname, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n\t\t\tsys.stderr.write(\"\\nErrorcode/Error: %d - '%s'.\\n\" % (errcode, str(caughte)))\n\t\t\tsys.stderr.flush()\n\t\traise MySQLdb.OperationalError(caughte)", "response": "Calls a MySQL stored procedure procname. This uses DictCursor by default."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getFieldsInDB(self, tablename):\n\t\tSQL = 'SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.Columns where TABLE_NAME=\"%s\"' % tablename\n\t\n\t\tarray_data = self.execQuery(SQL)\n\t\t\n\t\treturn [x[0] for x in array_data]", "response": "get all the fields from a specific table"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if this is an ASCII based data stream by checking the bytes for the word solid.", "response": "def _is_ascii_stl(first_bytes):\n    \"\"\"\n    Determine if this is an ASCII based data stream, simply by checking the bytes for the word 'solid'.\n    \"\"\"\n    is_ascii = False\n    if 'solid' in first_bytes.decode(\"utf-8\").lower():\n        is_ascii = True\n\n    return is_ascii"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if this is a binary file.", "response": "def _is_binary_stl(data):\n    \"\"\"\n    Determine if this is a binary file through unpacking the first value after the 80th character\n    and testing whether this value is greater than zero.  This indicates the number of facets in the file.\n    Could possibly extend this to check that the remaining number of bytes is divisible by 50.\n    \"\"\"\n    is_bin = False\n    start_byte = 0\n    end_byte = 80\n    _ = data[start_byte:end_byte] # header data\n    start_byte = end_byte\n    end_byte += 4\n    facet_count = struct.unpack('I', data[start_byte:end_byte])[0]\n    if facet_count > 0:\n        is_bin = True\n\n    return is_bin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_bind_param(self, obj, dialect):\n        value = obj or {}\n        if isinstance(obj, flask_cloudy.Object):\n            value = {}\n            for k in self.DEFAULT_KEYS:\n                value[k] = getattr(obj, k)\n\n        return super(self.__class__, self).process_bind_param(value, dialect)", "response": "Get a flask_cloudy. Object and save it as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the object from the storage.", "response": "def from_storage(self, storage):\n        \"\"\"\n        To use a different storage\n        :param storage: flask_cloudy.Storage instance\n        \"\"\"\n        self._storage_obj = storage.get(self._data[\"name\"])\n        self._storage_loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_tasks(task_coro, addrs, *args, flatten=True, **kwargs):\n    '''Create and schedule a set of asynchronous tasks.\n\n    The function creates the tasks using a given list of agent addresses and\n    wraps each of them in :func:`asyncio.ensure_future`. The ``*args`` and\n    ``**kwargs`` are passed down to :func:`task_coro` when creating tasks for\n    each address in :attr:`addrs`.\n\n    Usage example for a method in a class derived from\n    :class:`~creamas.mp.MultiEnvironment`::\n\n        async def my_method(self, *args, **kwargs):\n            async def task(addr, *args, **kwargs):\n                r_manager = await self.env.connect(addr)\n                return await r_manager.my_method(*args, **kwargs)\n\n            return await util.create_tasks(task, self.addrs, *args, **kwargs)\n\n    :param task_coro:\n        Coroutine which is used for each address in :attr:`addrs`. The\n        coroutine should accept an agent address as the first parameter.\n    :param list addrs:\n        A list of agent addresses used as the first parameters of\n        :func:`task_coro`.\n    :param bool flatten:\n        If ``True`` the returned results are flattened into one list if the\n        tasks return iterable objects. The parameter does nothing if all the\n        results are not iterable.\n    :returns:\n        An awaitable coroutine which returns the results of tasks as a list or\n        as a flattened list\n    '''\n    tasks = []\n    for agent_addr in addrs:\n        task = asyncio.ensure_future(task_coro(agent_addr, *args, **kwargs))\n        tasks.append(task)\n    return wait_tasks(tasks, flatten)", "response": "Create and schedule a set of asynchronous tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngathers a list of asynchronous tasks and wait their completion.", "response": "async def wait_tasks(tasks, flatten=True):\n    '''Gather a list of asynchronous tasks and wait their completion.\n\n    :param list tasks:\n        A list of *asyncio* tasks wrapped in :func:`asyncio.ensure_future`.\n    :param bool flatten:\n        If ``True`` the returned results are flattened into one list if the\n        tasks return iterable objects. The parameter does nothing if all the\n        results are not iterable.\n    :returns:\n        The results of tasks as a list or as a flattened list\n    '''\n    rets = await asyncio.gather(*tasks)\n    if flatten and all(map(lambda x: hasattr(x, '__iter__'), rets)):\n        rets = list(itertools.chain(*rets))\n    return rets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(task=None, loop=None):\n    '''Run the event loop forever or until the task/future *task* is finished.\n\n    :param task:\n        Optional. Task or Future which is run until complete. If parameter is\n        ``None`` runs the event loop forever.\n    :param loop:\n        Optional. Event loop to use. If the parameter is ``None`` uses\n        asyncio's base event loop.\n\n    .. note::\n        This method has the same intent as :func:`aiomas.util.run`.\n    '''\n    if loop is None:\n        loop = asyncio.get_event_loop()\n    if task is None:\n        return loop.run_forever()\n    else:\n        return loop.run_until_complete(task)", "response": "Run the event loop forever or until the task is finished."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting addresses into dictionaries by hosts and ports.", "response": "def split_addrs(addrs):\n    '''Split addresses into dictionaries by hosts and ports.\n\n    :param list addrs: A list of addresses.\n\n    :returns:\n        A dictionary of dictionaries, where ``dict[HOST][PORT]`` holds a list\n        of all agent addresses in that environment.\n    '''\n    splitted = {}\n    for addr in addrs:\n        host, port, _ = _addr_key(addr)\n        if host not in splitted:\n            splitted[host] = {}\n        if port not in splitted[host]:\n            splitted[host][port] = []\n        splitted[host][port].append(addr)\n    return splitted"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps agent addresses to their assumed managers.", "response": "def addrs2managers(addrs):\n    '''Map agent addresses to their assumed managers.\n\n    .. seealso::\n\n        :func:`creamas.util.get_manager`\n    '''\n    mgrs = {}\n    for addr in addrs:\n        mgr_addr = get_manager(addr)\n        if mgr_addr not in mgrs:\n            mgrs[mgr_addr] = []\n        mgrs[mgr_addr].append(addr)\n    return mgrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a Jinja2 environment with a specific template path.", "response": "def create_jinja_env(template_path):\n    \"\"\"\n    Creates a Jinja2 environment with a specific template path.\n    \"\"\"\n    jinja_env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(template_path),\n        block_start_string='{%',\n        block_end_string='%}',\n        variable_start_string='${',\n        variable_end_string='}',\n        comment_start_string='{#',\n        comment_end_string='#}',\n        line_statement_prefix=None,\n        line_comment_prefix=None,\n        trim_blocks=True,\n        lstrip_blocks=True,\n        newline_sequence='\\n'\n    )\n    jinja_env.filters['regexreplace'] = regex_replace\n    jinja_env.globals.update(uuidgen=uuidgen)\n    return jinja_env"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender a jinja template", "response": "def render_template(env, filename, values=None):\n    \"\"\"\n    Render a jinja template\n    \"\"\"\n    if not values:\n        values = {}\n    tmpl = env.get_template(filename)\n    return tmpl.render(values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef template(filename):\n    def method_wrapper(method):\n\n        @wraps(method)\n        def jinja_wrapper(*args, **kwargs):\n            ret = method(*args, **kwargs)\n            return render_template(filename, ret)\n\n        return jinja_wrapper\n\n    return method_wrapper", "response": "Decorator for creating a Jinja2 template"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing a list of recently variables info.", "response": "def _debug_info(self):\n        \"\"\"Show a list of recently variables info.\n        \"\"\"\n        self._msg('DEBUG')\n        self._msg2('WorkDir: {0}'.format(self._curdir))\n        self._msg2('Cookies: {0}'.format(self._session.cookies))\n        self._msg2('Headers: {0}'.format(self._session.headers))\n        self._msg2('Configs: {0}'.format(self._config))\n        self._msg2('Customs: {0}'.format(self._custom))\n        self._msg2('Account: {0}'.format(self._account))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(self, argtypes=r'M', help_msg=None):\n\n        def format_args(method):\n            def wrapped_method(*args, **kwargs):\n                args_count = len(args)  # + len(kwargs)\n                argtypes_count = len(argtypes)\n                placeholder_count = argtypes.count('H') + argtypes.count('h')\n\n                # We check the placeholder count to select a way to\n                # format the args. If placeholder is not equals zero\n                # then we calculate the minimum args count at first.\n\n                if placeholder_count:\n                    min_args_count = (argtypes_count - placeholder_count)\n\n                    # If args_count less than minimum args count or bigger\n                    # than argtypes count then we raise a Exception to exit.\n                    if args_count < min_args_count or args_count > argtypes_count:\n                        raise KngetError(\"args count is invalid.\",\n                                         reason='args count is {0}'.format(args_count))\n\n                # Otherwise, we just check if args count equals argtypes count\n                elif args_count != argtypes_count:\n                    raise KngetError(\"args count is invalid\",\n                                     reason='args count is {0}'.format(args_count))\n\n                argv = []  # NOTE: We cannot modify the args.\n                for i in range(args_count):\n                    if argtypes[i] in ('m', 'M'):\n                        argv.append(args[i])\n                    elif argtypes[i] in ('i', 'I'):\n                        argv.append(int(args[i]))\n                    elif argtypes[i] in ('s', 'S'):\n                        argv.append(str(args[i]))\n                    elif argtypes[i] in ('h', 'H'):\n                        argv.append(args[i])\n                    else:\n                        raise KngetError('argtype {0} is invalid!'.format(argtypes[i]))\n\n                return method(*argv, **kwargs)\n\n            # Keep the docs.\n            wrapped_method.__doc__ = method.__doc__\n\n            self._commands[method.__name__] = (\n                wrapped_method, help_msg\n            )\n            return wrapped_method\n\n        # only format_args touched the method\n        return format_args", "response": "Register a method to a command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride method of class Knget", "response": "def run(self, tags, begin, end=False):\n        \"\"\"Override method of class Knget\n        \"\"\"\n        if not end:\n            end = begin\n\n        # Type `H` doesn't cast anything, so we\n        # manually cast the strings end to integer.\n        super(KngetShell, self).run(tags, begin, int(end))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the debug run.", "response": "def dbgrun(self, source):\n        \"\"\"Debug run. based on exec(), unsafe.\n        \"\"\"\n        try:\n            exec(source)\n        except Exception as e:\n            self._msg2('Error: {0}'.format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a list of Versa models to a file - like object out.", "response": "def write(models, out=None, base=None, propertybase=None, shorteners=None, logger=logging):\n    '''\n    models - input Versa models from which output is generated. Must be a sequence\n                object, not an iterator\n    '''\n    assert out is not None #Output stream required\n    if not isinstance(models, list): models = [models]\n    shorteners = shorteners or {}\n\n    all_propertybase = [propertybase] if propertybase else []\n    all_propertybase.append(VERSA_BASEIRI)\n\n    if any((base, propertybase, shorteners)):\n        out.write('# @docheader\\n\\n* @iri:\\n')\n    if base:\n        out.write('    * @base: {0}'.format(base))\n    #for k, v in shorteners:\n    #    out.write('    * @base: {0}'.format(base))\n\n    out.write('\\n\\n')\n\n    origin_space = set()\n    #base_out = models[0].base\n    for m in models:\n        origin_space.update(all_origins(m))\n\n    for o in origin_space:\n        out.write('# {0}\\n\\n'.format(o))\n        for o_, r, t, a in m.match(o):\n            abbr_r = abbreviate(r, all_propertybase)\n            value_format(t)\n            out.write('* {0}: {1}\\n'.format(abbr_r, value_format(t)))\n            for k, v in a.items():\n                abbr_k = abbreviate(k, all_propertybase)\n                out.write('    * {0}: {1}\\n'.format(k, value_format(v)))\n\n        out.write('\\n')\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction creates instances of controllers adds into bottle routes", "response": "def register_routes(self):\n        \"\"\"\n        Function creates instances of controllers, adds into bottle routes\n        \"\"\"\n        routes = self.flatten_urls(self.urls)\n        self.controllers = {}\n        controller_names = set()\n\n        for route in routes:\n            cname = route['endpoint'].split('.')[0]\n            controller_names.add(cname)\n\n        for cname in controller_names:\n            attr = getattr(self.mcontrollers, cname)\n            instance = attr(request, response)\n            self.controllers[cname] = instance\n\n        for route in routes:\n            cname, aname = route['endpoint'].split('.')\n            action = getattr(self.controllers[cname], aname)\n            self.wsgi.route(route['url'], route['methods'], action)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_extensions(self):\n        try:\n            for extension, config in self.config['extensions'].items():\n\n                extension_bstr = ''\n\n                # gather package name if exists\n                extension_pieces = extension.split('.')\n\n                # if the extensions is not in glim_extensions package\n                if len(extension_pieces) > 1:\n                    extension_bstr = '.'.join(extension_pieces)\n                else: # if the extension is in glim_extensions package\n                    extension_bstr = 'glim_extensions.%s' % extension_pieces[0]\n\n                extension_module = import_module(extension_bstr)\n\n                if extension_module:\n                    extension_startstr = '%s.%s' % (extension_bstr, 'start')\n                    extension_start = import_module(extension_startstr, pass_errors=True)\n\n                    extension_cmdsstr = '%s.%s' % (extension_bstr, 'commands')\n                    extension_cmds = import_module(extension_cmdsstr, pass_errors=True)\n\n                    if extension_start is not None:\n                        before = extension_start.before\n                        before(config)\n\n                    if extension_cmds is not None:\n                        if self.commandadapter is not None:\n                            self.commandadapter.register_extension(extension_cmds, extension_pieces[0])\n                else:\n                    GlimLog.error('Extension %s could not be loaded' % extension)\n\n        except Exception as e:\n            GlimLog.error(traceback.format_exc())", "response": "Function registers extensions given extensions list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_log(self):\n        if not empty('log', self.config):\n\n            if not empty('glim', self.config['log']):\n                GlimLog.boot(name='glim', config=self.config['log']['glim'])\n            else:\n                GlimLog.boot(name='glim')\n\n            if not empty('app', self.config['log']):\n                Log.boot(name='app', config=self.config['log']['app'])\n            else:\n                Log.boot(name='app')\n        else:\n            Log.boot(name='app')\n            GlimLog.boot(name='glim')", "response": "Function registers Log facade using configuration in app. config."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions detects ssl context", "response": "def register_ssl_context(self):\n        \"\"\"\n        Function detects ssl context\n        \"\"\"\n        if not empty('ssl', self.config['app']):\n            self.ssl_context = self.config['app']['ssl']\n        else:\n            self.ssl_context = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions flatten urls for route grouping feature of glim.", "response": "def flatten_urls(self, urls):\n        \"\"\"\n        Function flatten urls for route grouping feature of glim.\n\n        Args\n        ----\n          urls (dict): a dict of url definitions.\n          current_key (unknown type): a dict or a string marking the\n            current key that is used for recursive calls.\n          ruleset (dict): the ruleset that is eventually returned to\n            dispatcher.\n\n        Returns\n        -------\n          ruleset (list): a list of ruleset dict with endpoint, url and method functions\n        \"\"\"\n        available_methods = ['POST', 'PUT', 'OPTIONS', 'GET', 'DELETE', 'TRACE', 'COPY']\n        ruleset = []\n        for route, endpoint in urls.items():\n            route_pieces = route.split(' ')\n            try:\n                methods = url = None\n                if len(route_pieces) > 1:\n                    methods = [route_pieces[0]]\n                    url = route_pieces[1]\n                else:\n                    methods = available_methods\n                    url = route_pieces[0]\n\n                endpoint_pieces = endpoint.split('.')\n\n                if len(endpoint_pieces) > 1:\n                    rule = {'url': url, 'endpoint': endpoint, 'methods': methods}\n                    ruleset.append(rule)\n                else:\n                    for method in available_methods:\n                        rule = {\n                            'url': url,\n                            'endpoint': '%s.%s' % (endpoint, method.lower()),\n                            'methods': [method]\n                        }\n                        ruleset.append(rule)\n            except Exception as e:\n                raise InvalidRouteDefinitionError()\n        return ruleset"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _info(self, args, **extra_args):\n        if not isinstance(args, argparse.Namespace):\n            raise logger.error(Exception(\"args should of an instance of argparse.Namespace\"))\n\n        logger.info(\"Freight Forwarder: {0}\".format(VERSION))\n        logger.info(\"docker-py: {0}\".format(docker_py_version))\n        logger.info(\"Docker Api: {0}\".format(DOCKER_API_VERSION))\n        logger.info(\"{0} version: {1}\".format(platform.python_implementation(), platform.python_version()))", "response": "Print freight forwarder info to the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_plugin_class(self, typ):\n        if typ in self._class:\n            return self._class[typ]\n\n        # try to import by same name\n        try:\n            importlib.import_module(\"%s.%s\" % (self.namespace, typ))\n            if typ in self._class:\n                return self._class[typ]\n\n        except ImportError as e:\n            self.log.debug(\"ImportError \" + str(e))\n\n        raise ValueError(\"unknown plugin '%s'\" % typ)", "response": "get class by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters an error handler on the app instance for every type of exception code werkzeug is aware about.", "response": "def register_error_handler(app, handler=None):\n    \"\"\"\n    Register error handler\n    Registers an exception handler on the app instance for every type of\n    exception code werkzeug is aware about.\n\n    :param app: flask.Flask - flask application instance\n    :param handler: function - the handler\n    :return: None\n    \"\"\"\n    if not handler:\n        handler = default_error_handler\n\n    for code in exceptions.default_exceptions.keys():\n        app.register_error_handler(code, handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_error_handler(exception):\n    http_exception = isinstance(exception, exceptions.HTTPException)\n    code = exception.code if http_exception else 500\n\n    # log exceptions only (app debug should be off)\n    if code == 500:\n        current_app.logger.error(exception)\n\n    # jsonify error if json requested via accept header\n    if has_app_context() and has_request_context():\n        headers = request.headers\n        if 'Accept' in headers and headers['Accept'] == 'application/json':\n            return json_error_handler(exception)\n\n    # otherwise render template\n    return template_error_handler(exception)", "response": "Default error handler for userland templates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_error_handler(exception):\n    http_exception = isinstance(exception, exceptions.HTTPException)\n    code = exception.code if http_exception else 500\n\n    # log exceptions only (app debug should be off)\n    if code == 500:\n        current_app.logger.error(exception)\n\n    response = jsonify(dict(message=str(exception)))\n    response.status_code = code\n    return response", "response": "Json error handler\n    Returns a json message for th excepion with appripriate response code and\n    application/json content type.\n    :param exception:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntemplates error handler Renders a template for the error code if exception is know by werkzeug. Will attempt to load a template from userland app templates and then fall back to boiler templates if not found. :param exception: Exception :return:", "response": "def template_error_handler(exception):\n    \"\"\"\n    Template error handler\n    Renders a template for the error code if exception is know by werkzeug.\n    Will attempt to load a template from userland app templates and then\n    fall back to boiler templates if not found.\n    :param exception: Exception\n    :return:\n    \"\"\"\n    http_exception = isinstance(exception, exceptions.HTTPException)\n    code = exception.code if http_exception else 500\n\n    # log exceptions only (app debug should be off)\n    if code == 500:\n        current_app.logger.error(exception)\n\n    template = 'errors/{}.j2'.format(code)\n    return render_template(template, error=exception), code"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_url_error_handler(urls=()):\n    if type(urls) is str:\n        urls = [urls]\n\n    # the handler itself\n    def handler(exception):\n        http_exception = isinstance(exception, exceptions.HTTPException)\n        code = exception.code if http_exception else 500\n\n        # log exceptions only (app debug should be off)\n        if code == 500:\n            current_app.logger.error(exception)\n\n        # if matches one of urls, return json\n        if has_app_context() and has_request_context():\n            for prefix in urls:\n                prefix = prefix.strip('/')\n                prefix = '/' + prefix + '/' if len(prefix) else '/'\n                if request.path.startswith(prefix):\n                    return json_error_handler(exception)\n\n        # otherwise fall back to error page handler\n        return template_error_handler(exception)\n\n    return handler", "response": "Json URL error handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a unique ID for the request", "response": "def _make_nonce(self):\n        '''\n        Generate a unique ID for the request, 25 chars in length\n\n        Returns:\n            - str: Cryptographic nonce\n        '''\n\n        chars = string.digits + string.ascii_letters\n        nonce = ''.join(random.choice(chars) for i in range(25))\n\n        if self._logging:\n            utils.log('nonce created: %s' % nonce)\n\n        return nonce"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_auth(self, method, date, nonce, path, query={}, ctype='application/json'):\n        '''\n        Create the request signature to authenticate\n\n        Args:\n            - method (str): HTTP method\n            - date (str): HTTP date header string\n            - nonce (str): Cryptographic nonce\n            - path (str): URL pathname\n            - query (dict, default={}): URL query string in key-value pairs\n            - ctype (str, default='application/json'): HTTP Content-Type\n        '''\n\n        query = urlencode(query)\n\n        hmac_str = (method + '\\n' + nonce + '\\n' + date + '\\n' + ctype + '\\n' + path +\n                    '\\n' + query + '\\n').lower().encode('utf-8')\n\n        signature = base64.b64encode(hmac.new(self._secret_key, hmac_str, digestmod=hashlib.sha256).digest())\n        auth = 'On ' + self._access_key.decode('utf-8') + ':HmacSHA256:' + signature.decode('utf-8')\n\n        if self._logging:\n            utils.log({\n                'query': query,\n                'hmac_str': hmac_str,\n                'signature': signature,\n                'auth': auth\n            })\n\n        return auth", "response": "Create the request signature to authenticate the user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_headers(self, method, path, query={}, headers={}):\n        '''\n        Creates a headers object to sign the request\n\n        Args:\n            - method (str): HTTP method\n            - path (str): Request path, e.g. /api/documents. No query string\n            - query (dict, default={}): Query string in key-value format\n            - headers (dict, default={}): Other headers to pass in\n\n        Returns:\n            - dict: Dictionary containing all headers\n        '''\n\n        date = datetime.datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')\n        nonce = self._make_nonce()\n        ctype = headers.get('Content-Type') if headers.get('Content-Type') else 'application/json'\n\n        auth = self._make_auth(method, date, nonce, path, query=query, ctype=ctype)\n\n        req_headers = {\n            'Content-Type': 'application/json',\n            'Date': date,\n            'On-Nonce': nonce,\n            'Authorization': auth,\n            'User-Agent': 'Onshape Python Sample App',\n            'Accept': 'application/json'\n        }\n\n        # add in user-defined headers\n        for h in headers:\n            req_headers[h] = headers[h]\n\n        return req_headers", "response": "Creates a headers object to sign the request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, method, path, query={}, headers={}, body={}, base_url=None):\n        '''\n        Issues a request to Onshape\n\n        Args:\n            - method (str): HTTP method\n            - path (str): Path  e.g. /api/documents/:id\n            - query (dict, default={}): Query params in key-value pairs\n            - headers (dict, default={}): Key-value pairs of headers\n            - body (dict, default={}): Body for POST request\n            - base_url (str, default=None): Host, including scheme and port (if different from creds file)\n\n        Returns:\n            - requests.Response: Object containing the response from Onshape\n        '''\n\n        req_headers = self._make_headers(method, path, query, headers)\n        if base_url is None:\n            base_url = self._url\n        url = base_url + path + '?' + urlencode(query)\n\n        if self._logging:\n            utils.log(body)\n            utils.log(req_headers)\n            utils.log('request url: ' + url)\n\n        # only parse as json string if we have to\n        body = json.dumps(body) if type(body) == dict else body\n\n        res = requests.request(method, url, headers=req_headers, data=body, allow_redirects=False, stream=True)\n\n        if res.status_code == 307:\n            location = urlparse(res.headers[\"Location\"])\n            querystring = parse_qs(location.query)\n\n            if self._logging:\n                utils.log('request redirected to: ' + location.geturl())\n\n            new_query = {}\n            new_base_url = location.scheme + '://' + location.netloc\n\n            for key in querystring:\n                new_query[key] = querystring[key][0]  # won't work for repeated query params\n\n            return self.request(method, location.path, query=new_query, headers=headers, base_url=new_base_url)\n        elif not 200 <= res.status_code <= 206:\n            if self._logging:\n                utils.log('request failed, details: ' + res.text, level=1)\n        else:\n            if self._logging:\n                utils.log('request succeeded, details: ' + res.text)\n\n        return res", "response": "Issues a request to Onshape s API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tuple_type_compare(types0, types1):\n    compares = [single_type_compare(types0[0], types1[0]),\n                single_type_compare(types0[1], types1[1])]\n    if compares[0] != 0:\n        return compares[0]\n    if compares[1] != 0:\n        return compares[1]\n    if types0[0] is types1[0] and types0[1] is types1[1]:\n        return 0\n    return hash(types1) - hash(types0)", "response": "doufo. tuple_type_compare - compare two types  \n articles"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_converters_keys(self):\n        keys = sorted(self.converters.keys(),\n                      key=cmp_to_key(tuple_type_compare))\n        return {k: self.converters[k] for k in keys}", "response": "doufo. ConvertDict. sorted_converters_key - sort converters keys  \n            self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(self, src: type, tar: type) -> Callable[[T], B]:\n        return self.converters[(src, tar)]", "response": "Returns a converter function that converts from source to target type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gen_sentences(self, tokens, aliases=None):\n        if aliases is None:\n            aliases = {}\n        for sentence in self._gen_sentences(tokens):\n            try:\n                alias = aliases[str(sentence[0])]\n            except KeyError:\n                # do nothing if no alias is found\n                pass\n            except IndexError:\n                pass\n            else:\n                sentence[0:1] = list(Program(alias).gen_tokens())\n            yield transform(Sentence(sentence), self.transforms)", "response": "Generate a sequence of sentences from a stream of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_timezone(new_tz=None):\n    global tz\n    if new_tz:\n        tz = pytz.timezone(new_tz)\n    else:\n        tz = tzlocal.get_localzone()", "response": "Set the timezone for datetime fields."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(method, uri, params_prefix=None, **params):\n    params = _prepare_params(params, params_prefix)\n\n    if method == \"POST\" or method == \"PUT\":\n        r_data = {\"data\": params}\n    else:\n        r_data = {\"params\": params}\n\n    # build the HTTP request and use basic authentication\n    url = \"https://%s/%s.json\" % (CHALLONGE_API_URL, uri)\n\n    try:\n        response = request(\n            method,\n            url,\n            auth=get_credentials(),\n            **r_data)\n        response.raise_for_status()\n    except HTTPError:\n        if response.status_code != 422:\n            response.raise_for_status()\n        # wrap up application-level errors\n        doc = response.json()\n        if doc.get(\"errors\"):\n            raise ChallongeException(*doc['errors'])\n\n    return response", "response": "Fetch the given uri and return the contents of the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_and_parse(method, uri, params_prefix=None, **params):\n    response = fetch(method, uri, params_prefix, **params)\n    return _parse(json.loads(response.text))", "response": "Fetch the given uri and return python dictionary with parsed data - types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing parameters to be sent to challonge. com.", "response": "def _prepare_params(dirty_params, prefix=None):\n    \"\"\"Prepares parameters to be sent to challonge.com.\n\n    The `prefix` can be used to convert parameters with keys that\n    look like (\"name\", \"url\", \"tournament_type\") into something like\n    (\"tournament[name]\", \"tournament[url]\", \"tournament[tournament_type]\"),\n    which is how challonge.com expects parameters describing specific\n    objects.\n\n    \"\"\"\n    if prefix and prefix.endswith('[]'):\n        keys = []\n        values = []\n        for k, v in dirty_params.items():\n            if isinstance(v, (tuple, list)):\n                keys.append(k)\n                values.append(v)\n        firstiter = ((k, v) for vals in zip(*values) for k, v in zip(keys, vals))\n        lastiter = ((k, v) for k, v in dirty_params.items() if k not in keys)\n        dpiter = itertools.chain(firstiter, lastiter)\n    else:\n        dpiter = dirty_params.items()\n\n    params = []\n    for k, v in dpiter:\n        if isinstance(v, (tuple, list)):\n            for val in v:\n                val = _prepare_value(val)\n                if prefix:\n                    params.append((\"%s[%s][]\" % (prefix, k), val))\n                else:\n                    params.append((k + \"[]\", val))\n        else:\n            v = _prepare_value(v)\n            if prefix:\n                params.append((\"%s[%s]\" % (prefix, k), v))\n            else:\n                params.append((k, v))\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of restclients. Department models for the passed College model.", "response": "def get_departments_by_college(college):\n    \"\"\"\n    Returns a list of restclients.Department models, for the passed\n    College model.\n    \"\"\"\n    url = \"{}?{}\".format(\n        dept_search_url_prefix,\n        urlencode({\"college_abbreviation\": college.label}))\n    return _json_to_departments(get_resource(url), college)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scoped_session_decorator(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        from wallace.db import session as wallace_session\n        with sessions_scope(wallace_session) as session:\n            from psiturk.db import db_session as psi_session\n            with sessions_scope(psi_session) as session_psiturk:\n                # The sessions used in func come from the funcs globals, but\n                # they will be proxied thread locals vars from the session\n                # registry, and will therefore be identical to those returned\n                # by the context managers above.\n                logger.debug('Running worker %s in scoped DB sessions',\n                             func.__name__)\n                return func(*args, **kwargs)\n    return wrapper", "response": "Manage contexts and add debugging to psiTurk sessions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the database optionally dropping existing tables.", "response": "def init_db(drop_all=False):\n    \"\"\"Initialize the database, optionally dropping existing tables.\"\"\"\n    if drop_all:\n        Base.metadata.drop_all(bind=engine)\n    Base.metadata.create_all(bind=engine)\n\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef readline(self, continuation=False):\n        prompt = (self.secondary_prompt_string if continuation else\n                  self.primary_prompt_string)\n        try:\n            line = raw_input(prompt)\n            while line.endswith(\"\\\\\"):\n                line = line[:-1] + raw_input(self.secondary_prompt_string)\n        except EOFError:\n            raise SystemExit()\n        else:\n            return line", "response": "Read a line from the terminal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef readlines(self):\n        continuation = False\n        while True:\n            yield self.readline(continuation)\n            continuation = True", "response": "Read a command from the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_bytes(self, inst_data, encoding=None):\n        selected = encoding or self.default_encoding\n        content_type = '{0}; charset=\"{1}\"'.format(self.content_type, selected)\n        dumped = self._dumps(escape.recursive_unicode(inst_data))\n        return content_type, dumped.encode(selected)", "response": "Transform an object into bytes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_bytes(self, data, encoding=None):\n        return self._loads(data.decode(encoding or self.default_encoding))", "response": "Returns an object from the bytes data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_pdb(self):\n        '''A function to fix fatal errors in PDB files when they can be automatically fixed. At present, this only runs if\n           self.strict is False. We may want a separate property for this since we may want to keep strict mode but still\n           allow PDBs to be fixed.\n\n           The only fixes at the moment are for missing chain IDs which get filled in with a valid PDB ID, if possible.'''\n\n        if self.strict:\n            return\n\n        # Get the list of chains\n        chains = set()\n        for l in self.lines:\n            if l.startswith('ATOM  ') or l.startswith('HETATM'):\n                chains.add(l[21])\n\n        # If there is a chain with a blank ID, change that ID to a valid unused ID\n        if ' ' in chains:\n            fresh_id = None\n            allowed_chain_ids = list(string.uppercase) + list(string.lowercase) + map(str, range(10))\n            for c in chains:\n                try: allowed_chain_ids.remove(c)\n                except: pass\n            if allowed_chain_ids:\n                fresh_id = allowed_chain_ids[0]\n\n            # Rewrite the lines\n            new_lines = []\n            if fresh_id:\n                for l in self.lines:\n                    if (l.startswith('ATOM  ') or l.startswith('HETATM')) and l[21] == ' ':\n                        new_lines.append('%s%s%s' % (l[:21], fresh_id, l[22:]))\n                    else:\n                        new_lines.append(l)\n                self.lines = new_lines", "response": "A function to fix fatal errors in PDB files when they can be automatically fixed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_headers(source_pdb_content, target_pdb_content):\n        '''Takes the headers from source_pdb_content and adds them to target_pdb_content, removing any headers that\n           target_pdb_content had.\n           Only the content up to the first structural line are taken from source_pdb_content and only the content from\n           the first structural line in target_pdb_content are taken.\n           '''\n        s = PDB(source_pdb_content)\n        t = PDB(target_pdb_content)\n\n        source_headers = []\n        for l in s.lines:\n            if l[:6].strip() in non_header_records:\n                break\n            else:\n                source_headers.append(l)\n\n        target_body = []\n        in_header = True\n        for l in t.lines:\n            if l[:6].strip() in non_header_records:\n                in_header = False\n            if not in_header:\n                target_body.append(l)\n\n        return '\\n'.join(source_headers + target_body)", "response": "Takes the headers from source_pdb_content and adds them to target_pdb_content removing any headers that were not present in the target_pdb_content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_filepath(filepath, strict = True, parse_ligands = False):\n        '''A function to replace the old constructor call where a filename was passed in.'''\n        return PDB(read_file(filepath), strict = strict, parse_ligands = parse_ligands)", "response": "A function to replace the old constructor call where a filename was passed in."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a PDB object by using a cached copy of the file if it exists or by retrieving the file from the RCSB.", "response": "def retrieve(pdb_id, cache_dir = None, strict = True, parse_ligands = False):\n        '''Creates a PDB object by using a cached copy of the file if it exists or by retrieving the file from the RCSB.'''\n\n        # Check to see whether we have a cached copy\n        pdb_id = pdb_id.upper()\n        if cache_dir:\n            filename = os.path.join(cache_dir, \"%s.pdb\" % pdb_id)\n            if os.path.exists(filename):\n                return PDB(read_file(filename), strict = strict, parse_ligands = parse_ligands)\n\n        # Get a copy from the RCSB\n        contents = rcsb.retrieve_pdb(pdb_id)\n\n        # Create a cached copy if appropriate\n        if cache_dir:\n            write_file(os.path.join(cache_dir, \"%s.pdb\" % pdb_id), contents)\n\n        # Return the object\n        return PDB(contents, strict = strict, parse_ligands = parse_ligands)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the parsed_lines dict which keeps all record data in document order indexed by the record type.", "response": "def _split_lines(self):\n        '''Creates the parsed_lines dict which keeps all record data in document order indexed by the record type.'''\n        parsed_lines = {}\n        for rt in all_record_types:\n            parsed_lines[rt] = []\n        parsed_lines[0] = []\n\n        for line in self.lines:\n            linetype = line[0:6]\n            if linetype in all_record_types:\n                parsed_lines[linetype].append(line)\n            else:\n                parsed_lines[0].append(line)\n\n        self.parsed_lines = parsed_lines\n        self._update_structure_lines()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate self. structure_lines and self. atom_chain_order.", "response": "def _update_structure_lines(self):\n        '''ATOM and HETATM lines may be altered by function calls. When this happens, this function should be called to keep self.structure_lines up to date.'''\n        structure_lines = []\n        atom_chain_order = []\n        chain_atoms = {}\n\n        for line in self.lines:\n            linetype = line[0:6]\n            if linetype == 'ATOM  ' or linetype == 'HETATM' or linetype == 'TER   ':\n                chain_id = line[21]\n                self.residue_types.add(line[17:20].strip())\n                if missing_chain_ids.get(self.pdb_id):\n                    chain_id = missing_chain_ids[self.pdb_id]\n                structure_lines.append(line)\n                if (chain_id not in atom_chain_order) and (chain_id != ' '):\n                    atom_chain_order.append(chain_id)\n                if linetype == 'ATOM  ':\n                    atom_type = line[12:16].strip()\n                    if atom_type:\n                        chain_atoms[chain_id] = chain_atoms.get(chain_id, set())\n                        chain_atoms[chain_id].add(atom_type)\n            if linetype == 'ENDMDL':\n                colortext.warning(\"ENDMDL detected: Breaking out early. We do not currently handle NMR structures properly.\")\n                break\n\n        self.structure_lines = structure_lines\n        self.atom_chain_order = atom_chain_order\n        self.chain_atoms = chain_atoms"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pdb_id(self):\n        '''Return the PDB ID. If one was passed in to the constructor, this takes precedence, otherwise the header is\n           parsed to try to find an ID. The header does not always contain a PDB ID in regular PDB files and appears to\n           always have an ID of 'XXXX' in biological units so the constructor override is useful.'''\n        if self.pdb_id:\n            return self.pdb_id\n        else:\n            header = self.parsed_lines[\"HEADER\"]\n            assert(len(header) <= 1)\n            if header:\n                self.pdb_id = header[0][62:66]\n                return self.pdb_id\n        return None", "response": "Return the PDB ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_replacement_pdb_id(self):\n        '''Checks to see if the PDB file has been deprecated and, if so, what the new ID is.'''\n        deprecation_lines = self.parsed_lines['OBSLTE']\n        date_regex = re.compile('(\\d+)-(\\w{3})-(\\d+)')\n        if deprecation_lines:\n            assert(len(deprecation_lines) == 1)\n            tokens = deprecation_lines[0].split()[1:]\n            if tokens[1].upper() in obsolete_pdb_ids_with_no_replacement_entries:\n                assert(len(tokens) == 2)\n            else:\n                assert(len(tokens) == 3)\n            if self.pdb_id:\n                mtchs = date_regex.match(tokens[0])\n                assert(mtchs)\n                _day = int(mtchs.group(1))\n                _month = mtchs.group(2)\n                _year = int(mtchs.group(3)) # only two characters?\n                assert(tokens[1] == self.pdb_id)\n                self.deprecation_date = (_day, _month, _year) # no need to do anything fancier unless this is ever needed\n                self.deprecated = True\n                if len(tokens) == 3:\n                    assert(len(tokens[2]) == 4)\n                    self.replacement_pdb_id = tokens[2]", "response": "Checks to see if the PDB file has been deprecated and if so what the new ID is."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_to_chains(self, chains, break_at_endmdl = True):\n        '''Throw away all ATOM/HETATM/ANISOU/TER lines for chains that are not in the chains list.'''\n        if chains:\n            chains = set(chains)\n\n            # Remove any structure lines not associated with the chains\n            self.lines = [l for l in self.lines if not(l.startswith('ATOM  ') or l.startswith('HETATM') or l.startswith('ANISOU') or l.startswith('TER')) or l[21] in chains]\n\n            # For some Rosetta protocols, only one NMR model should be kept\n            if break_at_endmdl:\n                new_lines = []\n                for l in self.lines:\n                    if l.startswith('ENDMDL'):\n                        new_lines.append(l)\n                        break\n                    new_lines.append(l)\n                self.lines = new_lines\n\n            self._update_structure_lines()\n            # todo: this logic should be fine if no other member elements rely on these lines e.g. residue mappings otherwise we need to update or clear those elements here\n        else:\n            raise Exception('The chains argument needs to be supplied.')", "response": "Throw away all ATOM HETATM and ANISOU lines for chains that are not in the chains list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strip_HETATMs(self, only_strip_these_chains = []):\n        '''Throw away all HETATM lines. If only_strip_these_chains is specified then only strip HETATMs lines for those chains.'''\n        if only_strip_these_chains:\n            self.lines = [l for l in self.lines if not(l.startswith('HETATM')) or l[21] not in only_strip_these_chains]\n        else:\n            self.lines = [l for l in self.lines if not(l.startswith('HETATM'))]\n        self._update_structure_lines()", "response": "Throw away all HETATMs lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_all_paired_mutations_for_position(self, chain_ids, chain_sequence_mappings = {}, residue_ids_to_ignore = [], typed_residue_ids_to_ignore = [], silent = True):\n        '''Generates a set of mutations for the chains in chain_ids where each set corresponds to the \"same\" residue (see\n           below) in both chains and where the wildtype residues match.\n             e.g. if chain A and B both have K19 then the set of mutations K19A, ... K19I, K19L, K19Y will be included in\n                  in the returned results unless 19 is in residue_ids_to_ignore or typed_residue_ids_to_ignore.\n           residue_ids_to_ignore should be a list/set of residue IDs.\n           typed_residue_ids_to_ignore should be a dict residue ID -> residue AA. It is used similarly to residue_ids_to_ignore\n           but we also assert that the residue types match the sequences in the chains.\n\n           By default, \"same residue\" is inferred by residue ID i.e. the generation assumes that a residue with some ID\n           in one chain corresponds to the residue with the same ID in another chain. If this is not true then a mapping\n           between chain residues is necessary and should be provided using the chain_sequence_mappings parameter.\n           chain_sequence_mappings should be a dict from pairs of chain IDs to SequenceMap objects. As all sequences are\n           compared with the first chain in chain_ids, only mappings from that first chain to any other chain are used.\n\n           This function is useful in certain cases e.g. generating a set of mutations where we make the same mutation in\n           both chains of a homodimer or a quasi-homodimer (where we only mutate the positions which agree).\n           '''\n\n        residue_ids_to_ignore = set([str(r).strip() for r in residue_ids_to_ignore])\n        for k, v in typed_residue_ids_to_ignore.iteritems():\n            typed_residue_ids_to_ignore[k] = v.strip()\n\n        assert(len(chain_ids) > 0)\n        first_chain = chain_ids[0]\n        mutations = []\n        if sorted(set(self.atom_sequences.keys()).intersection(set(chain_ids))) == sorted(chain_ids):\n            aas = sorted(residue_type_3to1_map.values())\n            aas.remove('X')\n            sequence = self.atom_sequences[first_chain]\n            for res_id in sequence.order:\n                chain_res_ids = {}\n                for c in chain_ids:\n                    chain_res_ids[c] = c + res_id[1:]\n                    if c != first_chain and chain_sequence_mappings.get((first_chain, c)):\n                        chain_res_ids[c] = chain_sequence_mappings[(first_chain, c)][res_id]\n\n                sres_id = str(res_id)[1:].strip()\n                skip = sres_id in residue_ids_to_ignore\n\n                if not skip and sres_id in typed_residue_ids_to_ignore:\n                    for c in chain_ids:\n                        if chain_res_ids[c] in self.atom_sequences[c].sequence:\n                            if not typed_residue_ids_to_ignore[sres_id] == self.atom_sequences[c][chain_res_ids[c]].ResidueAA:\n                                raise Exception('Expected to find {0} at residue {1} but found {2} in chain {3} at this position.'.format(typed_residue_ids_to_ignore[sres_id], sres_id, self.atom_sequences[c][chain_res_id].ResidueAA, c))\n                            skip = True\n                if skip:\n                    if not silent:\n                        print('Skipping residue {0} as requested.'.format(res_id))\n                    continue\n\n                for c in chain_ids:\n                    if (chain_res_ids[c]) not in self.atom_sequences[c].sequence:\n                        if not silent:\n                            print('Skipping residue {0} as it is missing from chain {1}.'.format(res_id, c))\n                            skip = True\n                if skip:\n                    continue\n\n                chain_res_aas = set([self.atom_sequences[c][chain_res_ids[c]].ResidueAA for c in chain_ids if chain_res_ids[c] in self.atom_sequences[c].sequence])\n                if len(chain_res_aas) > 1:\n                    if not silent:\n                        colortext.warning('Skipping residue {0} as the amino acid type differs between the specified chains.'.format(res_id))\n                    continue\n                wt_aa = chain_res_aas.pop()\n                for mut_aa in aas:\n                    if mut_aa != wt_aa:\n                        mutations.append([ChainMutation(wt_aa, str(chain_res_ids[c])[1:].strip(), mut_aa, Chain = c) for c in chain_ids])\n            return mutations\n        else:\n            raise Exception('Chain(s) {0} could not be found in the PDB file.'.format(', '.join(sorted(set(chain_ids).difference(set(self.atom_sequences.keys()))))))", "response": "Generates a set of mutations for all chains in chain_ids that are paired with the same residue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the version of the PDB File Format used to generate the file.", "response": "def _get_pdb_format_version(self):\n        '''Remark 4 indicates the version of the PDB File Format used to generate the file.'''\n        if not self.format_version:\n            version = None\n            version_lines = None\n            try:\n                version_lines = [line for line in self.parsed_lines['REMARK'] if int(line[7:10]) == 4 and line[10:].strip()]\n            except: pass\n            if version_lines:\n                assert(len(version_lines) == 1)\n                version_line = version_lines[0]\n                version_regex = re.compile('.*?FORMAT V.(.*),')\n                mtch = version_regex.match(version_line)\n                if mtch and mtch.groups(0):\n                    try:\n                        version = float(mtch.groups(0)[0])\n                    except:\n                        pass\n            self.format_version = version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_DB_references(self):\n        ''' \"The DBREF record provides cross-reference links between PDB sequences (what appears in SEQRES record) and\n                a corresponding database sequence.\" - http://www.wwpdb.org/documentation/format33/sect3.html#DBREF\n        '''\n\n        _database_names = {\n            'GB'    :  'GenBank',\n            'PDB'   :  'Protein Data Bank',\n            'UNP'   :  'UNIPROT',\n            'NORINE':  'Norine',\n            'TREMBL': 'UNIPROT',\n        }\n\n        DBref = {}\n        for l in self.parsed_lines[\"DBREF \"]: # [l for l in self.lines if l.startswith('DBREF')]\n            pdb_id = l[7:11]\n            chain_id = l[12]\n            seqBegin = int(l[14:18])\n            insertBegin = l[18]\n            seqEnd = int(l[20:24])\n            insertEnd = l[24]\n            database = _database_names[l[26:32].strip()]\n            dbAccession = l[33:41].strip()\n            dbIdCode = l[42:54].strip()\n            dbseqBegin = int(l[55:60])\n            idbnsBeg = l[60]\n            dbseqEnd = int(l[62:67])\n            dbinsEnd = l[67]\n\n            DBref[pdb_id] = DBref.get(pdb_id, {})\n            DBref[pdb_id][database] = DBref[pdb_id].get(database, {})\n            if DBref[pdb_id][database].get(chain_id):\n                if not(DBref[pdb_id][database][chain_id]['dbAccession'] == dbAccession and DBref[pdb_id][database][chain_id]['dbIdCode'] == dbIdCode):\n                    raise PDBParsingException('This code needs to be generalized. dbIdCode should really be a list to handle chimera cases.')\n            else:\n                DBref[pdb_id][database][chain_id] = {'dbAccession'   :   dbAccession, 'dbIdCode'      :   dbIdCode, 'PDBtoDB_mapping' : []}\n\n            DBref[pdb_id][database][chain_id]['PDBtoDB_mapping'].append(\n                {'PDBRange'      :   (\"%d%s\" % (seqBegin,  insertBegin), \"%d%s\" % (seqEnd,  insertEnd)),\n                'dbRange'       :   (\"%d%s\" % (dbseqBegin, idbnsBeg), \"%d%s\" % (dbseqEnd, dbinsEnd)),\n                }\n            )\n        return DBref", "response": "The DBREF record provides cross - reference links between PDB sequences ( what appears in SEQRES record ) and\n            a corresponding database sequence. - http://www. wwwpdb. org / documentation / format33. html#DBREF\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the SEQRES Sequences and stores the chains in order of their appearance in the ATOM records.", "response": "def _get_SEQRES_sequences(self):\n        '''Creates the SEQRES Sequences and stores the chains in order of their appearance in the SEQRES records. This order of chains\n           in the SEQRES sequences does not always agree with the order in the ATOM records.'''\n\n        pdb_id = self.get_pdb_id()\n        SEQRES_lines = self.parsed_lines[\"SEQRES\"]\n\n        modified_residue_mapping_3 = self.modified_residue_mapping_3\n        # I commented this out since we do not need it for my current test cases\n        #for k, v in self.modified_residues.iteritems():\n        #    assert(v['modified_residue'] not in modified_residues)\n        #    modified_residues[v['modified_residue']] = v['original_residue_3']\n\n        for x in range(0, len(SEQRES_lines)):\n            assert(SEQRES_lines[x][7:10].strip().isdigit())\n\n        if not SEQRES_lines:\n            #colortext.warning(\"WARNING: No SEQRES records were found. Kyle is trying to handle this gracefully, but Shane may need to fix it\")\n            return\n\n        seqres_chain_order = []\n        SEQRES_lines = [line[11:].rstrip() for line in SEQRES_lines] # we cannot strip the left characters as some cases e.g. 2MBP are missing chain identifiers\n\n        # Collect all residues for all chains, remembering the chain order\n        chain_tokens = {}\n        for line in SEQRES_lines:\n            chainID = line[0]\n            if missing_chain_ids.get(self.pdb_id):\n                chainID = missing_chain_ids[self.pdb_id]\n            if chainID not in seqres_chain_order:\n                seqres_chain_order.append(chainID)\n            chain_tokens[chainID] = chain_tokens.get(chainID, [])\n            chain_tokens[chainID].extend(line[6:].strip().split())\n\n        sequences = {}\n        self.chain_types = {}\n\n        canonical_acid_types = set(residue_type_3to1_map.keys())\n        canonical_acid_types.remove('UNK')\n        assert(len(canonical_acid_types) == 20)\n\n        for chain_id, tokens in chain_tokens.iteritems():\n\n            # Determine whether the chain is DNA, RNA, or a protein chain\n            # 1H38 is a good test for this - it contains DNA (chains E and G and repeated by H, K, N, J, M, P), RNA (chain F, repeated by I, L, O) and protein (chain D, repeated by A,B,C) sequences\n            # 1ZC8 is similar but also has examples of DU\n            # 4IHY has examples of DI (I is inosine)\n            # 2GRB has RNA examples of I and U\n            # 1LRP has protein chains with only CA atoms\n            # This will throw an exception when a non-canonical is found which is not listed in basics.py. In that case, the list in basics.py should be updated.\n\n            chain_type = None\n            set_of_tokens = set(tokens)\n            if (set_of_tokens.union(all_recognized_dna) == all_recognized_dna):# or (len(set_of_tokens) <= 5 and len(set_of_tokens.union(dna_nucleotides)) == len(set_of_tokens) + 1): # allow one unknown DNA residue\n                chain_type = 'DNA'\n            elif (set_of_tokens.union(all_recognized_rna) == all_recognized_rna):# or (len(set_of_tokens) <= 5 and len(set_of_tokens.union(dna_nucleotides)) == len(set_of_tokens) + 1): # allow one unknown DNA residue\n                chain_type = 'RNA'\n            elif len(set_of_tokens) == 1 and 'UNK' in set_of_tokens:\n                chain_type = 'Unknown'\n            elif not(set_of_tokens.intersection(canonical_acid_types)):\n                # Zero canonical residues may imply a ligand or a heterogen chain\n                chain_type = PDB._determine_heterogen_chain_type(set_of_tokens)\n            else:\n                assert(len(set(tokens).intersection(dna_nucleotides)) == 0)\n                assert(len(set(tokens).intersection(rna_nucleotides)) == 0)\n                assert(len(set(tokens).intersection(rna_nucleotides)) == 0)\n                chain_type = 'Protein'\n                if not self.chain_atoms.get(chain_id):\n                    # possible for biological unit files\n                    continue\n                if self.chain_atoms[chain_id] == set(['CA']):\n                    chain_type = 'Protein skeleton'\n\n            # Get the sequence, mapping non-canonicals to the appropriate letter\n            self.chain_types[chain_id] = chain_type\n\n            sequence = []\n            if chain_type == 'DNA':\n                for r in tokens:\n                    if dna_nucleotides_2to1_map.get(r):\n                        sequence.append(dna_nucleotides_2to1_map[r])\n                    else:\n                        if non_canonical_dna.get(r):\n                            sequence.append(non_canonical_dna[r])\n                        else:\n                            raise Exception(\"Unknown DNA residue %s.\" % r)\n            elif chain_type == 'RNA':\n                for r in tokens:\n                    if r in rna_nucleotides:\n                        sequence.append(r)\n                    else:\n                        if non_canonical_rna.get(r):\n                            sequence.append(non_canonical_rna[r])\n                        else:\n                            raise Exception(\"Unknown RNA residue %s.\" % r)\n            else:\n                token_counter = 0\n                for r in tokens:\n                    token_counter += 1\n                    if residue_type_3to1_map.get(r):\n                        sequence.append(residue_type_3to1_map[r])\n                    else:\n\n                        if self.modified_residue_mapping_3.get(r):\n                            sequence.append(residue_type_3to1_map[self.modified_residue_mapping_3.get(r)])\n                        elif non_canonical_amino_acids.get(r):\n                            #print('Mapping non-canonical residue %s to %s.' % (r, non_canonical_amino_acids[r]))\n                            #print(SEQRES_lines)\n                            #print(line)\n                            sequence.append(non_canonical_amino_acids[r])\n                        elif r == 'UNK':\n                            continue\n                        # Skip these residues\n                        elif r == 'ACE' and token_counter == 1:\n                            # Always allow ACE as the first residue of a chain\n                            sequence.append('X')\n                        elif r == 'ACE' and pdb_id in cases_with_ACE_residues_we_can_ignore:\n                            sequence.append('X')\n                            #continue\n                        # End of skipped residues\n                        else:\n                            #print(modified_residue_mapping_3)\n                            if modified_residue_mapping_3.get(r):\n                                if modified_residue_mapping_3[r] == 'UNK':\n                                    sequence.append('X')\n                                else:\n                                    assert(modified_residue_mapping_3[r] in residue_types_3)\n                                    sequence.append(residue_type_3to1_map[modified_residue_mapping_3[r]])\n                            else:\n                                raise Exception(\"Unknown protein residue %s in chain %s.\" % (r, chain_id))\n            sequences[chain_id] = \"\".join(sequence)\n\n        self.seqres_chain_order = seqres_chain_order\n\n        # Create Sequence objects for the SEQRES sequences\n        for chain_id, sequence in sequences.iteritems():\n            self.seqres_sequences[chain_id] = Sequence.from_sequence(chain_id, sequence, self.chain_types[chain_id])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_ATOM_sequences(self):\n        '''Creates the ATOM Sequences.'''\n\n        # Get a list of all residues with ATOM or HETATM records\n        atom_sequences = {}\n        structural_residue_IDs_set = set() # use a set for a quicker lookup\n        ignore_HETATMs = True # todo: fix this if we need to deal with HETATMs\n\n        residue_lines_by_chain = []\n        structural_residue_IDs_set = []\n\n        present_chain_ids = {}\n        for l in self.structure_lines:\n            if len(l) > 21 and l[:3] != 'TER':\n                present_chain_ids[l[21]] = present_chain_ids.get(l[21], set())\n                present_chain_ids[l[21]].add(l[:6])\n\n        model_index = 0\n        residue_lines_by_chain.append([])\n        structural_residue_IDs_set.append(set())\n        full_code_map = {}\n        hetatm_map = {}\n        full_atom_map = {}\n        for l in self.structure_lines:\n            chain_id = None\n            if l.startswith(\"TER   \"):\n                model_index += 1\n                residue_lines_by_chain.append([])\n                structural_residue_IDs_set.append(set())\n            else:\n                residue_id = l[21:27]\n                if residue_id not in structural_residue_IDs_set[model_index]:\n                    residue_lines_by_chain[model_index].append(l)\n                    structural_residue_IDs_set[model_index].add(residue_id)\n                if l.startswith('ATOM'):\n                    chain_id = l[21]\n                    # Only use ATOM records to build the code map as chains can have ligands HETATMs\n                    full_code_map[chain_id] = full_code_map.get(chain_id, set())\n                    full_code_map[chain_id].add(l[17:20].strip())\n\n                    # Only use ATOM records to build the atom map as CA-only chains can have ligands described in full as HETATMs\n                    full_atom_map[chain_id] = full_atom_map.get(chain_id, set())\n                    full_atom_map[chain_id].add(l[12:16].strip())\n                elif l.startswith('HETATM'):\n                    chain_id = l[21]\n                    hetatm_map[chain_id] = hetatm_map.get(chain_id, set())\n                    hetatm_map[chain_id].add(l[17:20].strip())\n\n        # Get the residues used by the residue lines. These can be used to determine the chain type if the header is missing.\n        for chain_id in self.atom_chain_order:\n            if full_code_map.get(chain_id):\n                # The chains may contain other molecules e.g. MG or HOH so before we decide their type based on residue types alone,\n                # we subtract out those non-canonicals\n                canonical_molecules = full_code_map[chain_id].intersection(dna_nucleotides.union(rna_nucleotides).union(residue_types_3))\n\n                determined_chain_type = None\n                if canonical_molecules.union(dna_nucleotides) == dna_nucleotides:\n                    determined_chain_type = 'DNA'\n                elif canonical_molecules.union(rna_nucleotides) == rna_nucleotides:\n                    determined_chain_type = 'RNA'\n                elif len(full_code_map[chain_id]) == 1 and 'UNK' in full_code_map[chain_id]:\n                    determined_chain_type = 'Unknown'\n                elif canonical_molecules:\n                    if len(full_atom_map[chain_id]) == 1 and 'CA' in full_atom_map[chain_id]:\n                        determined_chain_type = 'Protein skeleton'\n                    else:\n                        determined_chain_type = 'Protein'\n                else:\n                    determined_chain_type = PDB._determine_heterogen_chain_type(canonical_molecules)\n\n                if self.chain_types.get(chain_id):\n                    assert(self.chain_types[chain_id] == determined_chain_type)\n                else:\n                    self.chain_types[chain_id] = determined_chain_type\n\n        line_types_by_chain = []\n        chain_ids = []\n        for model_index in range(len(residue_lines_by_chain)):\n            line_types = set()\n            if residue_lines_by_chain[model_index]:\n                if missing_chain_ids.get(self.pdb_id):\n                    chain_ids.append(missing_chain_ids[self.pdb_id])\n                else:\n                    chain_ids.append(residue_lines_by_chain[model_index][0][21])\n            for l in residue_lines_by_chain[model_index]:\n                line_types.add(l[0:6])\n            if line_types == set(['ATOM']):\n                line_types_by_chain.append('ATOM')\n            elif line_types == set(['HETATM']):\n                line_types_by_chain.append('HETATM')\n            else:\n                line_types_by_chain.append('Mixed')\n\n        for x in range(0, len(residue_lines_by_chain)):\n            residue_lines = residue_lines_by_chain[x]\n            line_types = line_types_by_chain[x]\n            if ignore_HETATMs and line_types == 'HETATM':\n                continue\n\n            for y in range(len(residue_lines)):\n                l = residue_lines[y]\n                residue_type = l[17:20].strip()\n                if l.startswith(\"HETATM\"):\n                    if self.modified_residue_mapping_3.get(residue_type):\n                        residue_type = self.modified_residue_mapping_3[residue_type]\n                    elif y == (len(residue_lines) - 1):\n                        # last residue in the chain\n                        if residue_type == 'NH2':\n                            residue_type = 'UNK' # fixes a few cases e.g. 1MBG, 1K9Q, 1KA6\n                        elif ignore_HETATMs:\n                            continue\n\n                    elif ignore_HETATMs:\n                        continue\n\n                residue_id = l[21:27]\n                chain_id = l[21]\n                if missing_chain_ids.get(self.pdb_id):\n                    chain_id = missing_chain_ids[self.pdb_id]\n\n                if chain_id in self.chain_types:\n                    # This means the pdb had SEQRES and we constructed atom_sequences\n                    chain_type = self.chain_types[chain_id]\n                else:\n                    # Otherwise assume this is protein\n                    chain_type = 'Protein'\n\n                atom_sequences[chain_id] = atom_sequences.get(chain_id, Sequence(chain_type))\n\n                residue_type = self.modified_residue_mapping_3.get(residue_type, residue_type)\n\n                short_residue_type = None\n                if residue_type == 'UNK':\n                    short_residue_type = 'X'\n                elif chain_type == 'Unknown':\n                    assert(False) # we should not reach here - Unknown chains should only contain UNK records\n                elif chain_type == 'Protein' or chain_type == 'Protein skeleton':\n                    short_residue_type = residue_type_3to1_map.get(residue_type) or protonated_residue_type_3to1_map.get(residue_type) or non_canonical_amino_acids.get(residue_type)\n                elif chain_type == 'DNA':\n                    short_residue_type = dna_nucleotides_2to1_map.get(residue_type) or non_canonical_dna.get(residue_type)\n                elif chain_type == 'RNA':\n                    short_residue_type = non_canonical_rna.get(residue_type) or residue_type\n\n                if not short_residue_type:\n                    if l.startswith(\"ATOM\") and l[12:16] == ' OH2' and l[17:20] == 'TIP':\n                        continue\n                    elif not self.strict:\n                        short_residue_type = 'X'\n                    else:\n                        raise NonCanonicalResidueException(\"Unrecognized residue type %s in PDB file '%s', residue ID '%s'.\" % (residue_type, str(self.pdb_id), str(residue_id)))\n\n                #structural_residue_IDs.append((residue_id, short_residue_type))\n                # KAB - way to allow for multiresidue noncanonical AA's\n                if len(short_residue_type) == 1:\n                    atom_sequences[chain_id].add(PDBResidue(residue_id[0], residue_id[1:], short_residue_type, chain_type))\n                else:\n                    for char in short_residue_type:\n                        atom_sequences[chain_id].add(PDBResidue(residue_id[0], residue_id[1:], char, chain_type))\n\n        # Assign 'Ligand' or 'Heterogen' to all HETATM-only chains\n        for chain_id in present_chain_ids.keys():\n            if chain_id not in self.chain_types:\n                assert('ATOM  ' not in present_chain_ids[chain_id])\n                self.chain_types[chain_id] = PDB._determine_heterogen_chain_type(hetatm_map.get(chain_id, set()))\n        self.atom_sequences = atom_sequences", "response": "Creates the ATOM Sequences."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_ATOM_sequences_2(self):\n        '''Creates the ATOM Sequences.'''\n\n        # Get a list of all residues with ATOM or HETATM records\n        atom_sequences = {}\n        structural_residue_IDs_set = set() # use a set for a quicker lookup\n        ignore_HETATMs = True # todo: fix this if we need to deal with HETATMs\n        for l in self.structure_lines:\n            residue_type = l[17:20].strip()\n            if l.startswith(\"HETATM\"):\n                if self.modified_residue_mapping_3.get(residue_type):\n                    residue_type = self.modified_residue_mapping_3[residue_type]\n                elif ignore_HETATMs:\n                    continue\n\n            residue_id = l[21:27]\n            if residue_id not in structural_residue_IDs_set:\n                chain_id = l[21]\n                chain_type = self.chain_types[chain_id]\n                atom_sequences[chain_id] = atom_sequences.get(chain_id, Sequence(chain_type))\n                residue_type = l[17:20].strip()\n\n                residue_type = self.modified_residue_mapping_3.get(residue_type, residue_type)\n                short_residue_type = None\n                if residue_type == 'UNK':\n                    short_residue_type = 'X'\n                elif chain_type == 'Unknown':\n                    assert(False) # we should not reach here - Unknown chains should only contain UNK records\n                elif chain_type == 'Protein' or chain_type == 'Protein skeleton':\n                    short_residue_type = residue_type_3to1_map.get(residue_type) or protonated_residue_type_3to1_map.get(residue_type)\n                elif chain_type == 'DNA':\n                    short_residue_type = dna_nucleotides_2to1_map.get(residue_type) or non_canonical_dna.get(residue_type)\n                elif chain_type == 'RNA':\n                    short_residue_type = non_canonical_rna.get(residue_type) or residue_type\n                elif not self.strict:\n                    short_residue_type = 'X'\n                else:\n                    raise NonCanonicalResidueException(\"Unrecognized residue type %s in PDB file '%s', residue ID '%s'.\" % (residue_type, str(self.pdb_id), str(residue_id)))\n\n                #structural_residue_IDs.append((residue_id, short_residue_type))\n                atom_sequences[chain_id].add(PDBResidue(residue_id[0], residue_id[1:], short_residue_type, chain_type))\n                structural_residue_IDs_set.add(residue_id)\n\n        self.atom_sequences = atom_sequences", "response": "Creates the ATOM Sequences."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef construct_seqres_to_atom_residue_map(self):\n        '''Uses the SequenceAligner to align the SEQRES and ATOM sequences and return the mappings.\n           If the SEQRES sequence does not exist for a chain, the mappings are None.\n           Note: The ResidueRelatrix is better equipped for this job since it can use the SIFTS mappings. This function\n           is provided for cases where it is not possible to use the ResidueRelatrix.'''\n        from klab.bio.clustalo import SequenceAligner\n\n        seqres_to_atom_maps = {}\n        atom_to_seqres_maps = {}\n        for c in self.seqres_chain_order:\n            if c in self.atom_chain_order:\n\n                # Get the sequences for chain c\n                seqres_sequence = self.seqres_sequences[c]\n                atom_sequence = self.atom_sequences[c]\n\n                # Align the sequences. mapping will be a mapping between the sequence *strings* (1-indexed)\n                sa = SequenceAligner()\n                sa.add_sequence('seqres_%s' % c, str(seqres_sequence))\n                sa.add_sequence('atom_%s' % c, str(atom_sequence))\n                mapping, match_mapping = sa.get_residue_mapping()\n\n                # Use the mapping from the sequence strings to look up the residue IDs and then create a mapping between these residue IDs\n                seqres_to_atom_maps[c] = {}\n                atom_to_seqres_maps[c] = {}\n                for seqres_residue_index, atom_residue_index in mapping.iteritems():\n                    seqres_residue_id = seqres_sequence.order[seqres_residue_index - 1] # order is a 0-based list\n                    atom_residue_id = atom_sequence.order[atom_residue_index - 1] # order is a 0-based list\n                    seqres_to_atom_maps[c][seqres_residue_id] = atom_residue_id\n                    atom_to_seqres_maps[c][atom_residue_id] = seqres_residue_id\n\n        return seqres_to_atom_maps, atom_to_seqres_maps", "response": "Uses the SequenceAligner to align the SEQRES and ATOM sequences and return the mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_pdb_to_rosetta_residue_map(self, rosetta_scripts_path, rosetta_database_path = None, extra_command_flags = None, cache_dir = None):\n        ''' Uses the features database to create a mapping from Rosetta-numbered residues to PDB ATOM residues.\n            Next, the object's rosetta_sequences (a dict of Sequences) element is created.\n            Finally, a SequenceMap object is created mapping the Rosetta Sequences to the ATOM Sequences.\n\n            The extra_command_flags parameter expects a string e.g. \"-ignore_zero_occupancy false\".\n\n            If cache_dir is passed then the file <self.pdb_id>.\n        '''\n\n        ## Create a mapping from Rosetta-numbered residues to PDB ATOM residues\n\n        import json\n\n        # Apply any PDB-specific hacks\n        specific_flag_hacks = None\n        if self.pdb_id and HACKS_pdb_specific_hacks.get(self.pdb_id):\n            specific_flag_hacks = HACKS_pdb_specific_hacks[self.pdb_id]\n\n        skeletal_chains = sorted([k for k in self.chain_types.keys() if self.chain_types[k] == 'Protein skeleton'])\n        if skeletal_chains:\n            raise PDBMissingMainchainAtomsException('The PDB to Rosetta residue map could not be created as chains %s only have CA atoms present.' % \", \".join(skeletal_chains))\n\n        # Get the residue mapping using the features database\n        mapping = None\n        cached_json_mapping_filepath = None\n        if cache_dir:\n            cached_json_mapping_filepath = os.path.join(cache_dir, '{0}.rosetta2pdb.rawmap.json'.format(self.pdb_id)) # note: the resmap.json file created by self.get_atom_sequence_to_rosetta_json_map is more involved - rawmap is simply what is returned by get_pdb_contents_to_pose_residue_map\n        if self.pdb_id and cache_dir and os.path.exists(cached_json_mapping_filepath):\n            # Read cached file\n            try:\n                mapping = json.loads(read_file(cached_json_mapping_filepath))\n            except: pass\n        if mapping == None:\n            pdb_file_contents = \"\\n\".join(self.structure_lines)\n            success, mapping = get_pdb_contents_to_pose_residue_map(pdb_file_contents, rosetta_scripts_path, rosetta_database_path = rosetta_database_path, pdb_id = self.pdb_id, extra_flags = ((specific_flag_hacks or '') + ' ' + (extra_command_flags or '')).strip())\n            if not success:\n                raise colortext.Exception(\"An error occurred mapping the PDB ATOM residue IDs to the Rosetta numbering.\\n%s\" % \"\\n\".join(mapping))\n            if self.pdb_id and cache_dir:\n                write_file(cached_json_mapping_filepath, json.dumps(mapping, indent = 4, sort_keys = True))\n\n        ## Create Sequences for the Rosetta residues (self.rosetta_sequences)\n\n        # Initialize maps\n        rosetta_residues = {}\n        rosetta_sequences = {}\n        for chain_id in self.atom_chain_order:\n            chain_type = self.chain_types[chain_id]\n            rosetta_residues[chain_id] = {}\n            rosetta_sequences[chain_id] = Sequence(chain_type)\n\n        # Create a map rosetta_residues, Chain -> Rosetta residue ID -> Rosetta residue information\n        rosetta_pdb_mappings = {}\n        for chain_id in self.atom_chain_order:\n            rosetta_pdb_mappings[chain_id] = {}\n        for k, v in mapping.iteritems():\n            rosetta_residues[k[0]][v['pose_residue_id']] = v\n            rosetta_pdb_mappings[k[0]][v['pose_residue_id']] = k\n\n        # Create rosetta_sequences map Chain -> Sequence(Residue)\n        for chain_id, v in sorted(rosetta_residues.iteritems()):\n            chain_type = self.chain_types[chain_id]\n            for rosetta_id, residue_info in sorted(v.iteritems()):\n                short_residue_type = None\n\n                residue_type = None\n                if chain_type == 'Protein':\n                    residue_type = residue_info['name3'].strip()\n                    short_residue_type = residue_type_3to1_map.get(residue_type, 'X') # some HETATMs can be passed here e.g. MG so we can not map those cases\n                else:\n                    residue_type = residue_info['res_type'].strip()\n                    if chain_type == 'DNA':\n                        if residue_type.find('UpperDNA') != -1 or residue_type.find('LowerDNA') != -1:\n                            residue_type = residue_type[:3]\n                        short_residue_type = dna_nucleotides_3to1_map.get(residue_type) # Commenting this out since Rosetta does not seem to handle these \"or non_canonical_dna.get(residue_type)\"\n                    else:\n                        assert(chain_type == 'RNA')\n                        if residue_type.find('UpperRNA') != -1 or residue_type.find('LowerRNA') != -1 or (len(residue_type) > 3 and residue_type[3] == ':'):\n                            residue_type = residue_type[:3]\n                        short_residue_type = rna_nucleotides_3to1_map.get(residue_type)\n\n                if short_residue_type == None:\n                    raise colortext.Exception('Could not determine the one-letter code of the residue: chain {0}, chain_type \"{1}\", residue \"{2}\", residue type \"{3}\".'.format(chain_id, chain_type, rosetta_id, residue_type))\n\n                rosetta_sequences[chain_id].add(Residue(chain_id, rosetta_id, short_residue_type, chain_type))\n\n\n        ## Create SequenceMap objects to map the Rosetta Sequences to the ATOM Sequences\n        rosetta_to_atom_sequence_maps = {}\n        for chain_id, rosetta_pdb_mapping in rosetta_pdb_mappings.iteritems():\n            rosetta_to_atom_sequence_maps[chain_id] = SequenceMap.from_dict(rosetta_pdb_mapping)\n\n        self.rosetta_to_atom_sequence_maps = rosetta_to_atom_sequence_maps\n        self.rosetta_sequences = rosetta_sequences", "response": "Constructs a mapping from the Rosetta - numbered residues to the ATOM Sequences."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a mapping from ATOM to Rosetta.", "response": "def get_atom_sequence_to_rosetta_map(self):\n        '''Uses the Rosetta->ATOM injective map to construct an injective mapping from ATOM->Rosetta.\n           We do not extend the injection to include ATOM residues which have no corresponding Rosetta residue.\n             e.g. atom_sequence_to_rosetta_mapping[c].map.get('A  45 ') will return None if there is no corresponding Rosetta residue\n           those residues to None.\n           Likewise, if a PDB chain c is not present in the Rosetta model then atom_sequence_to_rosetta_mapping[c].map.get(s) returns None.\n        '''\n        if not self.rosetta_to_atom_sequence_maps and self.rosetta_sequences:\n            raise Exception('The PDB to Rosetta mapping has not been determined. Please call construct_pdb_to_rosetta_residue_map first.')\n\n        atom_sequence_to_rosetta_mapping = {}\n        for chain_id, mapping in self.rosetta_to_atom_sequence_maps.iteritems():\n            chain_mapping = {}\n            for k in mapping:\n                chain_mapping[k[1]] = k[0]\n            atom_sequence_to_rosetta_mapping[chain_id] = SequenceMap.from_dict(chain_mapping)\n\n        # Add empty maps for missing chains\n        for chain_id, sequence in self.atom_sequences.iteritems():\n            if not atom_sequence_to_rosetta_mapping.get(chain_id):\n                atom_sequence_to_rosetta_mapping[chain_id] = SequenceMap()\n\n        return atom_sequence_to_rosetta_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_atom_sequence_to_rosetta_json_map(self):\n        '''Returns the mapping from PDB ATOM residue IDs to Rosetta residue IDs in JSON format.'''\n        import json\n        d = {}\n        atom_sequence_to_rosetta_mapping = self.get_atom_sequence_to_rosetta_map()\n        for c, sm in atom_sequence_to_rosetta_mapping.iteritems():\n            for k, v in sm.map.iteritems():\n                d[k] = v\n        return json.dumps(d, indent = 4, sort_keys = True)", "response": "Returns the mapping from PDB ATOM residue IDs to Rosetta residue IDs in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_rosetta_sequence_to_atom_json_map(self):\n        '''Returns the mapping from Rosetta residue IDs to PDB ATOM residue IDs in JSON format.'''\n        import json\n        if not self.rosetta_to_atom_sequence_maps and self.rosetta_sequences:\n            raise Exception('The PDB to Rosetta mapping has not been determined. Please call construct_pdb_to_rosetta_residue_map first.')\n\n        d = {}\n        for c, sm in self.rosetta_to_atom_sequence_maps.iteritems():\n            for k, v in sm.map.iteritems():\n                d[k] = v\n            #d[c] = sm.map\n        return json.dumps(d, indent = 4, sort_keys = True)", "response": "Returns the mapping from Rosetta residue IDs to PDB ATOM residue IDs in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_pdb_residues_to_rosetta_residues(self, mutations):\n        '''This function takes a list of ChainMutation objects and uses the PDB to Rosetta mapping to return the corresponding\n           list of SimpleMutation objects using Rosetta numbering.\n           e.g.\n              p = PDB(...)\n              p.construct_pdb_to_rosetta_residue_map()\n              rosetta_mutations = p.map_pdb_residues_to_rosetta_residues(pdb_mutations)\n        '''\n        if not self.rosetta_to_atom_sequence_maps and self.rosetta_sequences:\n            raise Exception('The PDB to Rosetta mapping has not been determined. Please call construct_pdb_to_rosetta_residue_map first.')\n\n        rosetta_mutations = []\n        atom_sequence_to_rosetta_mapping = self.get_atom_sequence_to_rosetta_map()\n        for m in mutations:\n            rosetta_residue_id = atom_sequence_to_rosetta_mapping[m.Chain].get('%s%s' % (m.Chain, m.ResidueID))\n            rosetta_mutations.append(SimpleMutation(m.WildTypeAA, rosetta_residue_id, m.MutantAA))\n        return rosetta_mutations", "response": "This function maps the Residues of a list of ChainMutation objects to the corresponding SimpleMutation objects using the Rosetta numbering."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that the wildtype of the Mutation object matches the PDB sequence.", "response": "def assert_wildtype_matches(self, mutation):\n        '''Check that the wildtype of the Mutation object matches the PDB sequence.'''\n        readwt = self.getAminoAcid(self.getAtomLine(mutation.Chain, mutation.ResidueID))\n        assert(mutation.WildTypeAA == residue_type_3to1_map[readwt])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the type of heterogen chain.", "response": "def _determine_heterogen_chain_type(residue_types):\n        '''We distinguish three types of heterogen chain: i) all solution; ii) all ligand; or iii) other (a mix of solution, ligand, and/or ions).\n           residue_types should be a Set of sequence identifers e.g. GTP, ZN, HOH.\n        '''\n        residue_type_id_lengths = set(map(len, residue_types))\n        if (len(residue_types) > 0):\n            if len(residue_types.difference(common_solution_ids)) == 0:\n                return 'Solution'\n            elif (len(residue_type_id_lengths) == 1) and (3 in residue_type_id_lengths) and (len(residue_types.difference(common_solution_ids)) > 0):\n                # The last expression discounts chains which only contain solution molecules e.g. HOH\n                return 'Ligand'\n        return 'Heterogen'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the HETATM lines to Hill notation.", "response": "def convert_hetatms_to_Hill_notation(lines, ignore_list = []):#['HOH']):\n        '''From the PDB site:\n           The elements of the chemical formula are given in the order following Hill ordering. The order of elements depends\n           on whether carbon is present or not. If carbon is present, the order should be: C, then H, then the other elements\n           in alphabetical order of their symbol. If carbon is not present, the elements are listed purely in alphabetic order\n           of their symbol. This is the 'Hill' system used by Chemical Abstracts.\n\n           WARNING: This assumes that all atoms are in the PDB. This is not usually the case so the formulae will be missing\n                    atoms in those cases. To account for some missing data, we merge the element counters to use the most\n                    amount of information we can.\n                    In general, the FORMUL lines should be used. This function can be used in files with missing headers.\n           '''\n\n        ignore_list = set(ignore_list)\n        hetatms = {}\n        for l in lines:\n            if l.startswith('HETATM'):\n                het_id = l[17:20].strip()\n                if het_id in ignore_list:\n                    continue\n                res_id = l[21:27]\n                atom_name = l[12:16]\n                alt_loc = l[16]\n                hetatms[het_id] = hetatms.get(het_id, {})\n                hetatms[het_id][res_id] = hetatms[het_id].get(res_id, {})\n                hetatms[het_id][res_id][alt_loc] = hetatms[het_id][res_id].get(alt_loc, ElementCounter())\n                hetatms[het_id][res_id][alt_loc].add(atom_name)\n\n        for het_id, res_atoms in hetatms.iteritems():\n            res_ids = res_atoms.keys()\n            for res_id in res_ids:\n                ecs = hetatms[het_id][res_id].values()\n                for x in range(1, len(ecs)):\n                    ecs[0].merge(ecs[x])\n                hetatms[het_id][res_id] = ecs[0]\n\n        str_mapping = {}\n        mapping = {}\n        for het_id, res_atoms in hetatms.iteritems():\n            res_ids = res_atoms.keys()\n            for res_id in res_ids:\n                Hill_notation = hetatms[het_id][res_id]\n                if str_mapping.get(het_id):\n                    if not str_mapping[het_id] == str(Hill_notation):\n                        mapping[het_id].merge(Hill_notation)\n                        str_mapping[het_id] = str(mapping[het_id])\n                else:\n                    str_mapping[het_id] = str(Hill_notation)\n                    mapping[het_id] = Hill_notation\n        return mapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetRosettaResidueMap(self, ConvertMSEToAtom = False, RemoveIncompleteFinalResidues = False, RemoveIncompleteResidues = False):\n        '''Note: This function ignores any DNA.'''\n        raise Exception('This code looks to be deprecated. Use construct_pdb_to_rosetta_residue_map instead.')\n        chain = None\n        sequences = {}\n        residue_map = {}\n        resid_set = set()\n        resid_list = []\n\n        DNA_residues = set([' DA', ' DC', ' DG', ' DT'])\n        chains = []\n        self.RAW_ATOM_SEQUENCE = []\n        essential_atoms_1 = set(['CA', 'C', 'N'])#, 'O'])\n        essential_atoms_2 = set(['CA', 'C', 'N'])#, 'OG'])\n        current_atoms = set()\n        atoms_read = {}\n        oldchainID = None\n        removed_residue = {}\n        for line in self.lines:\n            if line[0:4] == 'ATOM' or (ConvertMSEToAtom and (line[0:6] == 'HETATM') and (line[17:20] == 'MSE')):\n                chainID = line[21]\n                if missing_chain_ids.get(self.pdb_id):\n                    chainID = missing_chain_ids[self.pdb_id]\n                if chainID not in chains:\n                    chains.append(chainID)\n                residue_longname = line[17:20]\n                if residue_longname in DNA_residues:\n                    # Skip DNA\n                    continue\n                if residue_longname == 'UNK':\n                    # Skip unknown residues\n                    continue\n                if residue_longname not in allowed_PDB_residues_types and not(ConvertMSEToAtom and residue_longname == 'MSE'):\n                    if not self.strict:\n                        # Skip unknown residues\n                        continue\n                    else:\n                        raise NonCanonicalResidueException(\"Residue %s encountered: %s\" % (line[17:20], line))\n                else:\n                    resid = line[21:27]\n                    #print(chainID, residue_longname, resid)\n                    #print(line)\n                    #print(resid_list)\n                    if resid not in resid_set:\n                        removed_residue[chainID] = False\n                        add_residue = True\n                        if current_atoms:\n                            if RemoveIncompleteResidues and essential_atoms_1.intersection(current_atoms) != essential_atoms_1 and essential_atoms_2.intersection(current_atoms) != essential_atoms_2:\n                                oldChain = resid_list[-1][0]\n                                oldResidueID = resid_list[-1][1:]\n                                print(\"The last residue '%s', %s, in chain %s is missing these atoms: %s.\" % (resid_list[-1], residue_longname, oldChain, essential_atoms_1.difference(current_atoms) or essential_atoms_2.difference(current_atoms)))\n                                resid_set.remove(resid_list[-1])\n                                #print(\"\".join(resid_list))\n                                resid_list = resid_list[:-1]\n                                if oldchainID:\n                                    removed_residue[oldchainID] = True\n                                #print(\"\".join(resid_list))\n                                #print(sequences[oldChain])\n                                if sequences.get(oldChain):\n                                    sequences[oldChain] = sequences[oldChain][:-1]\n\n                                if residue_map.get(oldChain):\n                                    residue_map[oldChain] = residue_map[oldChain][:-1]\n\n                                #print(sequences[oldChain]\n                        else:\n                            assert(not(resid_set))\n                        current_atoms = set()\n                        atoms_read[chainID] = set()\n                        atoms_read[chainID].add(line[12:15].strip())\n                        resid_set.add(resid)\n                        resid_list.append(resid)\n                        chainID = line[21]\n\n                        sequences[chainID] = sequences.get(chainID, [])\n                        if residue_longname in non_canonical_amino_acids:\n                            sequences[chainID].append(non_canonical_amino_acids[residue_longname])\n                        else:\n                            sequences[chainID].append(residue_type_3to1_map[residue_longname])\n\n                        residue_map[chainID] = residue_map.get(chainID, [])\n                        if residue_longname in non_canonical_amino_acids:\n                            residue_map[chainID].append((resid, non_canonical_amino_acids[residue_longname]))\n                        else:\n                            residue_map[chainID].append((resid, residue_type_3to1_map[residue_longname]))\n\n                        oldchainID = chainID\n                    else:\n                        #atoms_read[chainID] = atoms_read.get(chainID, set())\n                        atoms_read[chainID].add(line[12:15].strip())\n                    current_atoms.add(line[12:15].strip())\n        if RemoveIncompleteFinalResidues:\n            # These are (probably) necessary for Rosetta to keep the residue. Rosetta does throw away residues where only the N atom is present if that residue is at the end of a chain.\n            for chainID, sequence_list in sequences.iteritems():\n                if not(removed_residue[chainID]):\n                    if essential_atoms_1.intersection(atoms_read[chainID]) != essential_atoms_1 and essential_atoms_2.intersection(atoms_read[chainID]) != essential_atoms_2:\n                        print(\"The last residue %s of chain %s is missing these atoms: %s.\" % (sequence_list[-1], chainID, essential_atoms_1.difference(atoms_read[chainID]) or essential_atoms_2.difference(atoms_read[chainID])))\n                        oldResidueID = sequence_list[-1][1:]\n                        residue_map[chainID] = residue_map[chainID][0:-1]\n                        sequences[chainID] = sequence_list[0:-1]\n\n\n        for chainID, sequence_list in sequences.iteritems():\n            sequences[chainID] = \"\".join(sequence_list)\n            assert(sequences[chainID] == \"\".join([res_details[1] for res_details in residue_map[chainID]]))\n        for chainID in chains:\n            for a_acid in sequences.get(chainID, \"\"):\n                self.RAW_ATOM_SEQUENCE.append((chainID, a_acid))\n\n        residue_objects = {}\n        for chainID in residue_map.keys():\n            residue_objects[chainID] = []\n        for chainID, residue_list in residue_map.iteritems():\n            for res_pair in residue_list:\n                resid = res_pair[0]\n                resaa = res_pair[1]\n                assert(resid[0] == chainID)\n                residue_objects[chainID].append((resid[1:].strip(), resaa))\n\n        return sequences, residue_objects", "response": "This function returns a dictionary of all the residue IDs that are used in the ROSetTA residue table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_mutations(self, mutations):\n        '''This function has been refactored to use the SimpleMutation class.\n           The parameter is a list of Mutation objects. The function has no return value but raises a PDBValidationException\n           if the wildtype in the Mutation m does not match the residue type corresponding to residue m.ResidueID in the PDB file.\n        '''\n        # Chain, ResidueID, WildTypeAA, MutantAA\n        resID2AA = self.get_residue_id_to_type_map()\n        badmutations = []\n        for m in mutations:\n            wildtype = resID2AA.get(PDB.ChainResidueID2String(m.Chain, m.ResidueID), \"\")\n            if m.WildTypeAA != wildtype:\n                badmutations.append(m)\n        if badmutations:\n            raise PDBValidationException(\"The mutation(s) %s could not be matched against the PDB %s.\" % (\", \".join(map(str, badmutations)), self.pdb_id))", "response": "This function is refactored to use the SimpleMutation class. It is called by the validate_mutations method in order to validate the list of mutations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling in missing chain identifier", "response": "def fix_chain_id(self):\n        \"\"\"fill in missing chain identifier\"\"\"\n\n        for i in xrange(len(self.lines)):\n            line = self.lines[i]\n            if line.startswith(\"ATOM\") and line[21] == ' ':\n                self.lines[i] = line[:21] + 'A' + line[22:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getAtomLinesForResidueInRosettaStructure(self, resid):\n        '''We assume a Rosetta-generated structure where residues are uniquely identified by number.'''\n        lines = [line for line in self.lines if line[0:4] == \"ATOM\" and resid == int(line[22:27])]\n        if not lines:\n            #print('Failed searching for residue %d.' % resid)\n            #print(\"\".join([line for line in self.lines if line[0:4] == \"ATOM\"]))\n            raise Exception(\"Could not find the ATOM/HETATM line corresponding to residue '%(resid)s'.\" % vars())\n        return lines", "response": "We assume a Rosetta - generated structure where residues are uniquely identified by number."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes in a list of mutation tuples and returns the list of mutated positions and the remapped residue IDs.", "response": "def remapMutations(self, mutations, pdbID = '?'):\n        '''Takes in a list of (Chain, ResidueID, WildTypeAA, MutantAA) mutation tuples and returns the remapped\n           mutations based on the ddGResmap (which must be previously instantiated).\n           This function checks that the mutated positions exist and that the wild-type matches the PDB.\n        '''\n        raise Exception('This code is deprecated. Please use map_pdb_residues_to_rosetta_residues instead.')\n\n        remappedMutations = []\n        ddGResmap = self.get_ddGResmap()\n\n        for m in mutations:\n            ns = (PDB.ChainResidueID2String(m['Chain'], str(ddGResmap['ATOM-%s' % PDB.ChainResidueID2String(m['Chain'], m['ResidueID'])])))\n            remappedMutations.append(Mutation(m['WildTypeAA'], ns[1:].strip(), m['MutantAA'], ns[0]))\n\n        # Validate the mutations against the Rosetta residues\n        sequences, residue_map = self.GetRosettaResidueMap()\n        for rm in remappedMutations:\n            offset = int(residue_map[rm.Chain][0][0])\n            pr = residue_map[rm.Chain][int(rm.ResidueID) - offset]\n            assert(pr[0] == rm.ResidueID)\n            assert(pr[1] == rm.WildTypeAA)\n        return remappedMutations"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stripForDDG(self, chains = True, keepHETATM = False, numberOfModels = None, raise_exception = True):\n        '''Strips a PDB to ATOM lines. If keepHETATM is True then also retain HETATM lines.\n           By default all PDB chains are kept. The chains parameter should be True or a list.\n           In the latter case, only those chains in the list are kept.\n           Unoccupied ATOM lines are discarded.\n           This function also builds maps from PDB numbering to Rosetta numbering and vice versa.\n           '''\n        if raise_exception:\n            raise Exception('This code is deprecated.')\n\n        from Bio.PDB import PDBParser\n        resmap = {}\n        iresmap = {}\n        newlines = []\n        residx = 0\n        oldres = None\n        model_number = 1\n        for line in self.lines:\n            fieldtype = line[0:6].strip()\n            if fieldtype == \"ENDMDL\":\n                model_number += 1\n                if numberOfModels and (model_number > numberOfModels):\n                    break\n                if not numberOfModels:\n                    raise Exception(\"The logic here does not handle multiple models yet.\")\n            if (fieldtype == \"ATOM\" or (fieldtype == \"HETATM\" and keepHETATM)) and (float(line[54:60]) != 0):\n                chain = line[21:22]\n                if (chains == True) or (chain in chains):\n                    resid = line[21:27] # Chain, residue sequence number, insertion code\n                    iCode = line[26:27]\n                    if resid != oldres:\n                        residx += 1\n                        newnumbering = \"%s%4.i \" % (chain, residx)\n                        assert(len(newnumbering) == 6)\n                        id = fieldtype + \"-\" + resid\n                        resmap[id] = residx\n                        iresmap[residx] = id\n                        oldres = resid\n                    oldlength = len(line)\n                    # Add the original line back including the chain [21] and inserting a blank for the insertion code\n                    line = \"%s%4.i %s\" % (line[0:22], resmap[fieldtype + \"-\" + resid], line[27:])\n                    assert(len(line) == oldlength)\n                    newlines.append(line)\n        self.lines = newlines\n        self.ddGresmap = resmap\n        self.ddGiresmap = iresmap\n\n        # Sanity check against a known library\n        tmpfile = \"/tmp/ddgtemp.pdb\"\n        self.lines = self.lines or [\"\\n\"] \t# necessary to avoid a crash in the Bio Python module\n        F = open(tmpfile,'w')\n        F.write(string.join(self.lines, \"\\n\"))\n        F.close()\n        parser=PDBParser()\n        structure=parser.get_structure('tmp', tmpfile)\n        os.remove(tmpfile)\n        count = 0\n        for residue in structure.get_residues():\n            count += 1\n        assert(count == residx)\n        assert(len(resmap) == len(iresmap))", "response": "Strips a PDB to ATOM lines. If keepHETATM is True then also retain HETATM lines."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary mapping 6 - character residue IDs to residue types corresponding one - letter amino acid.", "response": "def get_residue_id_to_type_map(self):\n        '''Returns a dictionary mapping 6-character residue IDs (Chain, residue number, insertion code e.g. \"A 123B\") to the\n           corresponding one-letter amino acid.\n\n           Caveat: This function ignores occupancy - this function should be called once occupancy has been dealt with appropriately.'''\n\n        resid2type = {}\n        atomlines = self.parsed_lines['ATOM  ']\n        for line in atomlines:\n            resname = line[17:20]\n            if resname in allowed_PDB_residues_types and line[13:16] == 'CA ':\n                resid2type[line[21:27]] = residue_type_3to1_map.get(resname) or protonated_residue_type_3to1_map.get(resname)\n        return resid2type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_residue_numbering(self):\n\n        resid_list = self.aa_resids()\n        resid_set  = set(resid_list)\n        resid_lst1 = list(resid_set)\n        resid_lst1.sort()\n        map_res_id = {}\n\n        x = 1\n        old_chain = resid_lst1[0][0]\n        for resid in resid_lst1:\n            map_res_id[resid] = resid[0] + '%4.i' % x\n            if resid[0] == old_chain:\n                x+=1\n            else:\n                x = 1\n                old_chain = resid[0]\n\n        atomlines = []\n        for line in self.lines:\n            if line[0:4] == \"ATOM\" and line[21:26] in resid_set and line[26] == ' ':\n                lst = [char for char in line]\n                #lst.remove('\\n')\n                lst[21:26] = map_res_id[line[21:26]]\n                atomlines.append( string.join(lst,'') )\n                #print string.join(lst,'')\n            else:\n                atomlines.append(line)\n\n        self.lines = atomlines\n        return map_res_id", "response": "this function renumbers the residue numbering in order to avoid strange behaviour of Rosetta"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_residue_mapping(self):\n\n        resid_list = self.aa_resids()\n        # resid_set  = set(resid_list)\n        # resid_lst1 = list(resid_set)\n        # resid_lst1.sort()\n        map_res_id = {}\n\n        x = 1\n        for resid in resid_list:\n            # map_res_id[ int(resid[1:].strip()) ] = x\n            map_res_id[ resid ] = x\n            x+=1\n        return map_res_id", "response": "this function maps the chain and res ids A 234 to values from [ 1 - N )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef neighbors2(self, distance, chain_residue, atom = None, resid_list = None):\n\n        #atom = \" CA \"\n        '''this one is more precise since it uses the chain identifier also'''\n\n        if atom == None:     # consider all atoms\n            lines = [line for line in self.atomlines(resid_list) if line[17:20] in allowed_PDB_residues_types]\n        else:                # consider only given atoms\n            lines = [line for line in self.atomlines(resid_list) if line[17:20] in allowed_PDB_residues_types and line[12:16] == atom]\n\n        shash = spatialhash.SpatialHash(distance)\n\n        for line in lines:\n            pos = (float(line[30:38]), float(line[38:46]), float(line[46:54]))\n            shash.insert(pos, line[21:26])\n\n        neighbor_list = []\n        for line in lines:\n            resid = line[21:26]\n            if resid == chain_residue:\n                pos = (float(line[30:38]), float(line[38:46]), float(line[46:54]))\n\n                for data in shash.nearby(pos, distance):\n                    if data[1] not in neighbor_list:\n                        neighbor_list.append(data[1])\n                neighbor_list.sort()\n        return neighbor_list", "response": "returns a list of all neighbors of a given residue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_xyz_matrix_from_chain(self, chain_id, atoms_of_interest = []):\n        '''Create a pandas coordinates dataframe from the lines in the specified chain.'''\n        chains = [l[21] for l in self.structure_lines if len(l) > 21]\n        chain_lines = [l for l in self.structure_lines if len(l) > 21 and l[21] == chain_id]\n        return PDB.extract_xyz_matrix_from_pdb(chain_lines, atoms_of_interest = atoms_of_interest, include_all_columns = True)", "response": "Create a pandas coordinates dataframe from the lines in the specified chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pandas dataframe of X Y Z coordinates for all chains in the PDB.", "response": "def extract_xyz_matrix_from_pdb(pdb_lines, atoms_of_interest = backbone_atoms, expected_num_residues = None, expected_num_residue_atoms = None, fail_on_model_records = True, include_all_columns = False):\n        '''Returns a pandas dataframe of X, Y, Z coordinates for all chains in the PDB.\n           Note: This function is not intended to handle structures with MODELs e.g. from NMR although the fail_on_model_records\n           check is optional for convenience in case the first model is to be parsed.\n           Otherwise, the file should be split apart and passed into this function model by model.'''\n\n        if fail_on_model_records and [l for l in pdb_lines if l.startswith('MODEL')]:\n            raise Exception('This function does not handle files with MODEL records. Please split those file by model first.')\n\n        chain_ids = set([l[21] for l in pdb_lines if l.startswith('ATOM  ')])\n        dataframes = []\n        for chain_id in chain_ids:\n            dataframes.append(PDB.extract_xyz_matrix_from_pdb_chain(pdb_lines, chain_id, atoms_of_interest = atoms_of_interest, expected_num_residues = expected_num_residues, expected_num_residue_atoms = expected_num_residue_atoms, include_all_columns = include_all_columns))\n        if dataframes:\n            return(pandas.concat(dataframes, verify_integrity = True))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a pandas dataframe of X Y Z coordinates for the given PDB chain.", "response": "def extract_xyz_matrix_from_pdb_chain(pdb_lines, chain_id, atoms_of_interest = backbone_atoms, expected_num_residues = None, expected_num_residue_atoms = None, fail_on_model_records = True, include_all_columns = False):\n        '''Returns a pandas dataframe of X, Y, Z coordinates for the PDB chain.\n           Note: This function is not intended to handle structures with MODELs e.g. from NMR although the fail_on_model_records\n           check is optional for convenience in case the chain of the first model is to be parsed.'''\n\n        if fail_on_model_records and [l for l in pdb_lines if l.startswith('MODEL')]:\n            raise Exception('This function does not handle files with MODEL records. Please split those file by model first.')\n\n        new_pdb_lines = []\n        found_chain = False\n        for l in pdb_lines:\n            if l.startswith('ATOM  '):\n                if l[21] == chain_id:\n                    found_chain = True\n                    if found_chain:\n                        new_pdb_lines.append(l)\n            if found_chain and (l.strip() == 'TER' or l.startswith('MODEL') or (len(l) > 21 and l[21] != chain_id)):\n                # Do not cross over into other chains or models\n                break\n        return PDB.extract_xyz_matrix_from_pdb_residue_range(new_pdb_lines, atoms_of_interest = atoms_of_interest, expected_num_residues = expected_num_residues, expected_num_residue_atoms = expected_num_residue_atoms, include_all_columns = include_all_columns)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a pandas dataframe of X Y Z coordinates for the residues identified in the range from start_pdb_residue_id to stop_pdb_residue_id inclusive.", "response": "def extract_xyz_matrix_from_pdb_residue_range(pdb_lines, start_pdb_residue_id = None, stop_pdb_residue_id = None, atoms_of_interest = backbone_atoms, expected_num_residues = None, expected_num_residue_atoms = None, break_on_chain_end = True, include_all_columns = False):\n        '''Creates a pandas dataframe of X, Y, Z coordinates for the residues identified in the range from\n           start_pdb_residue_id to stop_pdb_residue_id inclusive. The dataframe is indexed by a string identifying the\n           PDB residue and atom type.\n\n           pdb_lines should be an array of lines from a PDB file (only ATOM lines are currently considered).\n           The residue IDs should be 6-character strings correspond to columns 22-27 (inclusive where columns are 1-indexed)\n           of the PDB file. The start and stop residues are both optional - omitting either removes the lower and upper\n           bound of the residue range respectively.\n           The returned coordinates will be restricted to atoms_of_interest.\n           expected_num_residues can be set if the number of residues is known in advance and the user wishes to assert this.\n           If expected_num_residue_atoms is set then each residue will be checked to ensure that this number of atoms was read.\n\n           This method does not handle MODELs e.g. from PDB files determined via NMR. To handle those files, an intermediate\n           function should be written which identifies the lines for one MODEL and then calls this function.'''\n        atoms = {}\n        found_start, found_end = start_pdb_residue_id == None, None\n        res_id_list, x_list, y_list, z_list = [], [], [], []\n        if include_all_columns:\n            chain_id_list, plain_res_id_list, atom_type_list, loc_list, residue_aa_list = [], [], [], [], []\n        for l in pdb_lines:\n            res_id = None\n            atom_type = None\n            alt_loc = None\n\n            if (break_on_chain_end and l.strip() == 'TER') or l.startswith('MODEL'):\n                # Do not cross over into other chains (unless specified) or models\n                break\n\n            if l.startswith('ATOM  '):\n                res_id = l[21:27]\n                atom_type = l[12:16].strip()\n                alt_loc = l[16]\n                if res_id == start_pdb_residue_id:\n                    # Saw the first residue - enter parsing\n                    found_start = True\n                if (stop_pdb_residue_id != None) and (res_id == stop_pdb_residue_id):\n                    assert(found_start)\n                    found_end = True\n\n            if found_end and res_id != stop_pdb_residue_id:\n                # Passed the last residue - exit parsing\n                break\n\n            if found_start and l.startswith('ATOM  ') and (not(atoms_of_interest) or (atom_type in atoms_of_interest)):\n                if expected_num_residues or expected_num_residue_atoms:\n                    # Only build the atoms dict if the assertions are turned on\n                    assert(res_id and atom_type and not(atoms.get(res_id, {}).get(atom_type)))\n                    atoms[res_id] = atoms.get(res_id, {})\n                    atoms[res_id][atom_type] = True\n\n                # Add the dataframe elements\n                res_id_list.append('{0}_{1}_{2}'.format(res_id.strip(), atom_type, alt_loc))\n                x_list.append(float(l[30:38]))\n                y_list.append(float(l[38:46]))\n                z_list.append(float(l[46:54]))\n                if include_all_columns:\n                    chain_id_list.append(l[21])\n                    plain_res_id_list.append(l[22:27])\n                    atom_type_list.append(l[12:16])\n                    loc_list.append(l[16])\n                    residue_aa_list.append(l[17:20])\n\n        assert(found_start and ((stop_pdb_residue_id == None) or found_end))\n\n        if expected_num_residues != None:\n            assert(len(atoms) == expected_num_residues)\n        if expected_num_residue_atoms != None:\n            for res_id, atom_details in atoms.iteritems():\n                assert(len(atom_details) == expected_num_residue_atoms)\n\n        if include_all_columns:\n            return pandas.DataFrame(dict(chain = chain_id_list, res_id = plain_res_id_list, atom = atom_type_list, altloc = loc_list, AA = residue_aa_list, X = x_list, Y = y_list, Z = z_list), index = res_id_list)\n        else:\n            return pandas.DataFrame(dict(X = x_list, Y = y_list, Z = z_list), index = res_id_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the token file for the current user.", "response": "def create_token_file(username=id_generator(), password=id_generator()):\n    '''\n        Store the admins password for further retrieve\n    '''\n\n    cozy_ds_uid = helpers.get_uid('cozy-data-system')\n    if not os.path.isfile(LOGIN_FILENAME):\n        with open(LOGIN_FILENAME, 'w+') as token_file:\n            token_file.write(\"{0}\\n{1}\".format(username, password))\n\n    helpers.file_rights(LOGIN_FILENAME, mode=0400, uid=cozy_ds_uid, gid=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_admin():\n    '''\n        Return the actual admin from token file\n    '''\n    if os.path.isfile(LOGIN_FILENAME):\n        with open(LOGIN_FILENAME, 'r') as token_file:\n            old_login, old_password = token_file.read().splitlines()[:2]\n            return old_login, old_password\n    else:\n        return None, None", "response": "Return the actual admin from token file\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlaunches a curl on CouchDB instance", "response": "def curl_couchdb(url, method='GET', base_url=BASE_URL, data=None):\n    '''\n        Launch a curl on CouchDB instance\n    '''\n    (username, password) = get_admin()\n    if username is None:\n        auth = None\n    else:\n        auth = (username, password)\n\n    if method == 'PUT':\n        req = requests.put('{}{}'.format(base_url, url), auth=auth, data=data)\n    elif method == 'DELETE':\n        req = requests.delete('{}{}'.format(base_url, url), auth=auth)\n    else:\n        req = requests.get('{}{}'.format(base_url, url), auth=auth)\n\n    if req.status_code not in [200, 201]:\n        raise HTTPError('{}: {}'.format(req.status_code, req.text))\n    return req"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the actual CouchDB admins", "response": "def get_couchdb_admins():\n    '''\n        Return the actual CouchDB admins\n    '''\n    user_list = []\n    req = curl_couchdb('/_config/admins/')\n\n    for user in req.json().keys():\n        user_list.append(user)\n\n    return user_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a CouchDB user", "response": "def create_couchdb_admin(username, password):\n    '''\n        Create a CouchDB user\n    '''\n    curl_couchdb('/_config/admins/{}'.format(username),\n                 method='PUT',\n                 data='\"{}\"'.format(password))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a Cozy is registered", "response": "def is_cozy_registered():\n    '''\n        Check if a Cozy is registered\n    '''\n    req = curl_couchdb('/cozy/_design/user/_view/all')\n    users = req.json()['rows']\n\n    if len(users) > 0:\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes all CouchDB admins excluding current ones", "response": "def delete_all_couchdb_admins():\n    '''\n        Delete all CouchDB users\n    '''\n    # Get current cozy token\n    username = get_admin()[0]\n    # Get CouchDB admin list\n    admins = get_couchdb_admins()\n\n    # Delete all admin user excluding current\n    for admin in admins:\n        if admin == username:\n            print \"Delete {} later...\".format(admin)\n        else:\n            print \"Delete {}\".format(admin)\n            delete_couchdb_admin(admin)\n\n    # Delete current CouchDB admin\n    admin = username\n    print \"Delete {}\".format(admin)\n    delete_couchdb_admin(admin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_token():\n    '''\n        Create token file & create user\n    '''\n    username = id_generator()\n    password = id_generator()\n    create_couchdb_admin(username, password)\n    create_token_file(username, password)\n\n    return 'Token {} created'.format(username)", "response": "Create token file & create user\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npings CozyDB with existing credentials", "response": "def ping():\n    '''\n        Ping CozyDB with existing credentials\n    '''\n    try:\n        curl_couchdb('/cozy/')\n        ping = True\n    except requests.exceptions.ConnectionError, error:\n        print error\n        ping = False\n    return ping"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting parameter in Cozy configuration", "response": "def get_cozy_param(param):\n    '''\n        Get parameter in Cozy configuration\n    '''\n    try:\n        req = curl_couchdb('/cozy/_design/cozyinstance/_view/all')\n        rows = req.json()['rows']\n        if len(rows) == 0:\n            return None\n        else:\n            return rows[0].get('value', {}).get(param, None)\n    except:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef str2type(value):\n    if not isinstance(value, str):\n        return value\n    try:\n        return json.loads(value)\n    except JSONDecodeError:\n        return value", "response": "Take a string and convert it to a value of proper type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict(self):\n        data = dict()\n        data['api_url'] = self.api_url\n        data['api_key'] = self.api_key\n        data['verifySSL'] = self.verifySSL\n        data['client_id'] = self.client_id\n        data['client_secret'] = self.client_secret\n        data['redirect_url'] = self.redirect_url\n        data['token'] = self.token\n        data['state'] = self.state\n        data['auth_url'] = self.auth_url\n        return data", "response": "Returns a dict of all of the necessary components."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a pyalveo. OAuth2 given a json string built from the oauth. to_json method.", "response": "def from_json(json_data):\n        \"\"\"\n            Returns a pyalveo.OAuth2 given a json string built from the oauth.to_json() method.\n        \"\"\"\n        #If we have a string, then decode it, otherwise assume it's already decoded\n        if isinstance(json_data, str):\n            data = json.loads(json_data)\n        else:\n            data = json_data\n        oauth_dict = {\n                      'client_id':data.get('client_id',None),\n                      'client_secret':data.get('client_secret',None),\n                      'redirect_url':data.get('redirect_url',None),\n                      }\n        oauth = OAuth2(api_url=data.get('api_url',None), api_key=data.get('api_key',None),oauth=oauth_dict, verifySSL=data.get('verifySSL',True))\n        oauth.token = data.get('token',None)\n        oauth.state = data.get('state',None)\n        oauth.auth_url = data.get('auth_url',None)\n        return oauth"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_authorisation_url(self, reset=False):\n\n        if reset:\n            self.auth_url = None\n        if not self.auth_url:\n            try:\n                oauth = OAuth2Session(self.client_id,redirect_uri=self.redirect_url)\n                self.auth_url,self.state = oauth.authorization_url(self.auth_base_url)\n            except Exception:\n                #print(\"Unexpected error:\", sys.exc_info()[0])\n                #print(\"Could not get Authorisation Url!\")\n                return None\n\n        return self.auth_url", "response": "Initializes the OAuth2 Process by asking the auth server for a login URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_callback(self,auth_resp):\n        try:\n            oauth = OAuth2Session(self.client_id,state=self.state,redirect_uri=self.redirect_url)\n            self.token = oauth.fetch_token(self.token_url,\n                                           authorization_response=auth_resp,\n                                           client_secret=self.client_secret,\n                                           verify=self.verifySSL)\n            if not self.api_key and self.API_KEY_DEFAULT:\n                self.get_api_key()\n                if not self.api_key:\n                    self.API_KEY_DEFAULT = False\n        except Exception:\n            #print(\"Unexpected error:\", sys.exc_info()[0])\n            #print(\"Could not fetch token from OAuth Callback!\")\n            return False\n        return True", "response": "Called when the user has responded to the authorisation server and the user has requested a token. Returns True if a token was successfully retrieved False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self):\n\n        try:\n            resp = self.request().get(self.validate_url, verify=self.verifySSL).json()\n        except TokenExpiredError:\n            return False\n        except AttributeError:\n            return False\n\n        if 'error' in resp:\n            return False\n        return True", "response": "Checks if the current token is still valid. Returns True if it is valid False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh_token(self):\n\n        try:\n            if self.token:\n                self.token = self.request().refresh_token(self.refresh_url, self.token['refresh_token'])\n                return True\n        except Exception as e:\n            # TODO: what might go wrong here - handle this error properly\n            #print(\"Unexpected error:\\t\\t\", str(e))\n            #traceback.print_exc()\n            pass\n        return False", "response": "Refreshes the access token using the refresh token. Returns true if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revoke_access(self):\n        if self.token is None:\n            return True\n        #Don't try to revoke if token is invalid anyway, will cause an error response anyway.\n        if self.validate():\n            data = {}\n            data['token'] = self.token['access_token']\n            self.request().post(self.revoke_url, data=data, json=None,verify=self.verifySSL)\n        return True", "response": "Revoke access to the current user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an OAuth2 Session to be used to make requests. Returns None if no token has been received.", "response": "def request(self):\n        \"\"\" Returns an OAuth2 Session to be used to make requests.\n        Returns None if a token hasn't yet been received.\"\"\"\n\n        headers = {'Accept': 'application/json'}\n\n        # Use API Key if possible\n        if self.api_key:\n            headers['X-API-KEY'] = self.api_key\n            return requests,headers\n        else:\n            # Try to use OAuth\n            if self.token:\n                return OAuth2Session(self.client_id, token=self.token),headers\n            else:\n                raise APIError(\"No API key and no OAuth session available\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a json string containing all relevant data to recreate this pyalveo. Client.", "response": "def to_json(self):\n        \"\"\"\n            Returns a json string containing all relevant data to recreate this pyalveo.Client.\n        \"\"\"\n        data = dict(self.__dict__)\n        data.pop('context',None)\n        data['oauth'] = self.oauth.to_dict()\n        data['cache'] = self.cache.to_dict()\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_json(json_data):\n        # If we have a string, then decode it, otherwise assume it's already decoded\n        if isinstance(json_data, str):\n            data = json.loads(json_data)\n        else:\n            data = json_data\n        oauth_dict = {\n                      'client_id':data.get('oauth',{}).get('client_id',None),\n                      'client_secret':data.get('oauth',{}).get('client_secret',None),\n                      'redirect_url':data.get('oauth',{}).get('redirect_url',None),\n                      }\n        client = Client(api_key=data.get('api_key',None),\n                        api_url=data.get('api_url',None),\n                        oauth=oauth_dict,\n                        use_cache=data.get('use_cache',None),\n                        cache_dir=data.get('cache_dir',None),\n                        update_cache=data.get('update_cache',None),\n                        verifySSL=data.get('oauth',{}).get('verifySSL',None)\n                        )\n        client.cache = Cache.from_json(data.get('cache',None))\n        client.oauth = OAuth2.from_json(data.get('oauth',None))\n        return client", "response": "Returns a pyalveo. Client given a json string built from the client. to_json method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms an API request to the given URL optionally including the specified data.", "response": "def api_request(self, url, data=None, method='GET', raw=False, file=None):\n        \"\"\" Perform an API request to the given URL, optionally\n        including the specified data\n\n        :type url: String\n        :param url: the URL to which to make the request\n        :type data: String\n        :param data: the data to send with the request, if any\n        :type method: String\n        :param method: the HTTP request method\n        :type raw: Boolean\n        :para raw: if True, return the raw response, otherwise treat as JSON and return the parsed response\n        :type file: String\n        :param file: (Optional) full path to file to be uploaded in a POST request\n\n\n        :returns: the response from the server either as a raw response or a Python dictionary\n            generated by parsing the JSON response\n\n        :raises: APIError if the API request is not successful\n\n\n        \"\"\"\n\n        if method is 'GET':\n            response = self.oauth.get(url)\n        elif method is 'POST':\n            if file is not None:\n                response = self.oauth.post(url, data=data, file=file)\n            else:\n                response = self.oauth.post(url, data=data)\n        elif method is 'PUT':\n            response = self.oauth.put(url, data=data)\n        elif method is 'DELETE':\n            response = self.oauth.delete(url)\n        else:\n            raise APIError(\"Unknown request method: %s\" % (method,))\n\n        # check for error responses\n        if response.status_code >= 400:\n            raise APIError(response.status_code,\n                           '',\n                           \"Error accessing API (url: %s, method: %s)\\nData: %s\\nMessage: %s\" % (url, method, data, response.text))\n\n        if raw:\n            return response.content\n        else:\n            return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a list of the collection URLs for all collections hosted on the server.", "response": "def get_collections(self):\n        \"\"\"Retrieve a list of the collection URLs for all collections\n        hosted on the server.\n\n        :rtype: List\n        :returns: a List of tuples of (name, url) for each collection\n        \"\"\"\n        result = self.api_request('/catalog')\n\n        # get the collection name from the url\n        return [(os.path.split(x)[1], x) for x in result['collections']]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_item(self, item_url, force_download=False):\n        item_url = str(item_url)\n\n        if (self.use_cache and\n                not force_download and\n                self.cache.has_item(item_url)):\n            item_json = self.cache.get_item(item_url)\n        else:\n            item_json = self.api_request(item_url, raw=True)\n            if self.update_cache:\n                self.cache.add_item(item_url, item_json)\n\n        return Item(json.loads(item_json.decode('utf-8')), self)", "response": "Retrieve the item metadata from the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_document(self, doc_url, force_download=False):\n        doc_url = str(doc_url)\n        if (self.use_cache and\n                not force_download and\n                self.cache.has_document(doc_url)):\n            doc_data = self.cache.get_document(doc_url)\n        else:\n            doc_data = self.api_request(doc_url, raw=True)\n            if self.update_cache:\n                self.cache.add_document(doc_url, doc_data)\n\n        return doc_data", "response": "Retrieve the data for the given document from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the primary text for an item from the server", "response": "def get_primary_text(self, item_url, force_download=False):\n        \"\"\" Retrieve the primary text for an item from the server\n\n        :type item_url: String or Item\n        :param item_url: URL of the item, or an Item object\n        :type force_download: Boolean\n        :param force_download: True to download from the server\n            regardless of the cache's contents\n\n        :rtype: String\n        :returns: the item's primary text if it has one, otherwise None\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        item_url = str(item_url)\n        metadata = self.get_item(item_url).metadata()\n\n        try:\n            primary_text_url = metadata['alveo:primary_text_url']\n        except KeyError:\n            return None\n\n        if primary_text_url == 'No primary text found':\n            return None\n\n        if (self.use_cache and\n                not force_download and\n                self.cache.has_primary_text(item_url)):\n            primary_text = self.cache.get_primary_text(item_url)\n        else:\n            primary_text = self.api_request(primary_text_url, raw=True)\n            if self.update_cache:\n                self.cache.add_primary_text(item_url, primary_text)\n\n        return primary_text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the annotations for an item from the server", "response": "def get_item_annotations(self, item_url, annotation_type=None, label=None):\n        \"\"\" Retrieve the annotations for an item from the server\n\n        :type item_url: String or Item\n        :param item_url: URL of the item, or an Item object\n        :type annotation_type: String\n        :param annotation_type: return only results with a matching Type field\n        :type label: String\n        :param label: return only results with a matching Label field\n\n        :rtype: String\n        :returns: the annotations as a dictionary, if the item has\n            annotations, otherwise None\n            The annotation dictionary has keys:\n            commonProperties - properties common to all annotations\n            @context - the url of the JSON-LD annotation context definition\n            alveo:annotations - a list of annotations, each is a dictionary\n\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        # get the annotation URL from the item metadata, if not present then there are no annotations\n        item_url = str(item_url)\n        metadata = self.get_item(item_url).metadata()\n\n        try:\n            annotation_url = metadata['alveo:annotations_url']\n        except KeyError:\n            return None\n\n\n        req_url = annotation_url\n        if annotation_type is not None:\n            req_url += '?'\n            req_url += urlencode((('type', annotation_type),))\n        if label is not None:\n            if annotation_type is None:\n                req_url += '?'\n            else:\n                req_url += '&'\n            req_url += urlencode((('label',label),))\n        try:\n            return self.api_request(req_url)\n        except KeyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the annotation types for the given item from the server", "response": "def get_annotation_types(self, item_url):\n        \"\"\" Retrieve the annotation types for the given item from the server\n\n        :type item_url: String or Item\n        :param item_url: URL of the item, or an Item object\n\n        :rtype: List\n        :returns: a List specifying the annotation types\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        req_url = item_url + \"/annotations/types\"\n        resp = self.api_request(req_url)\n        return resp['annotation_types']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the given annotations to the given item", "response": "def add_annotations(self, item_url, annotations):\n        \"\"\"Add annotations to the given item\n\n        :type item_url: String or Item\n        :param item_url: the URL of the item corresponding to the annotation,\n            or an Item object\n        :type annotation: list\n        :param annotations: the annotations as a list of dictionaries, each with keys '@type', 'label', 'start', 'end' and 'type'\n\n        :rtype: String\n        :returns: the server's success message, if successful\n\n        :raises: APIError if the upload was not successful\n        :raises: Exception if the annotations are malformed (missing a required key)\n        \"\"\"\n        adict = {'@context': \"https://alveo-staging1.intersect.org.au/schema/json-ld\"}\n\n        for ann in annotations:\n            # verify that we have the required properties\n            for key in ('@type', 'label', 'start', 'end', 'type'):\n                if key not in ann.keys():\n                    raise Exception(\"required key '%s' not present in annotation\" % key)\n        adict['@graph'] = annotations\n\n        resp = self.api_request(str(item_url) + '/annotations', method='POST', data=json.dumps(adict))\n        return self.__check_success(resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_collection(self, name, metadata):\n\n        payload = {\n                    'collection_metadata': metadata,\n                    'name': name\n                   }\n\n        response = self.api_request('/catalog', method='POST', data=json.dumps(payload))\n\n        return self.__check_success(response)", "response": "Create a new collection with the given name and attach the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify the metadata for the given collection.", "response": "def modify_collection_metadata(self, collection_uri, metadata, replace=None, name=''):\n        \"\"\"Modify the metadata for the given collection.\n\n        :param collection_uri: The URI that references the collection\n        :type collection_uri: String\n\n        :param metadata: a dictionary of metadata values to add/modify\n        :type metadata: Dict\n\n        :rtype: String\n        :returns: a message confirming that the metadata is modified\n\n        :raises: APIError if the request was not successful\n        \"\"\"\n\n        payload = {\n                    'collection_metadata': metadata,\n                    'name': name\n                   }\n\n        if replace is not None:\n            payload['replace'] = replace\n\n        response = self.api_request(collection_uri, method='PUT', data=json.dumps(payload))\n\n        return self.__check_success(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_items(self, collection_uri):\n\n        cname = os.path.split(collection_uri)[1]\n        return self.search_metadata(\"collection_name:%s\" % cname)", "response": "Return all items in this collection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new item to a collection containing a single text document.", "response": "def add_text_item(self, collection_uri, name, metadata, text, title=None):\n        \"\"\"Add a new item to a collection containing a single\n        text document.\n\n        The full text of the text document is specified as the text\n        argument and will be stored with the same name as the\n        item and a .txt extension.\n\n        This is a shorthand for the more general add_item method.\n\n        :param collection_uri: The URI that references the collection\n        :type collection_uri: String\n\n        :param name: The item name, suitable for use in a URI (no spaces)\n        :type name: String\n\n        :param metadata: a dictionary of metadata values describing the item\n        :type metadata: Dict\n\n        :param text: the full text of the document associated with this item\n        :type text: String\n\n\n        :param title: document title, defaults to the item name\n        :type title: String\n\n        :rtype String\n        :returns: the URI of the created item\n\n        :raises: APIError if the request was not successful\n\n        \"\"\"\n\n        docname = name + \".txt\"\n        if title is None:\n            title = name\n\n        metadata['dcterms:identifier'] = name\n        metadata['@type'] = 'ausnc:AusNCObject'\n        metadata['hcsvlab:display_document'] = {'@id': docname}\n        metadata['hcsvlab:indexable_document'] = {'@id': docname}\n        metadata['ausnc:document'] =  [{ '@id': 'document1.txt',\n                                         '@type': 'foaf:Document',\n                                         'dcterms:extent': len(text),\n                                         'dcterms:identifier': docname,\n                                         'dcterms:title': title,\n                                         'dcterms:type': 'Text'}]\n\n        meta = {'items': [{'metadata': { '@context': self.context,\n                                         '@graph': [metadata]\n                                        },\n                            'documents': [{'content': text, 'identifier': docname}]\n                          }]\n                }\n\n        response = self.api_request(collection_uri, method='POST', data=json.dumps(meta))\n\n        # this will raise an exception if the request fails\n        self.__check_success(response)\n\n        item_uri = collection_uri + \"/\" + response['success'][0]\n\n        return item_uri"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_item(self, collection_uri, name, metadata):\n\n        metadata['dcterms:identifier'] = name\n        metadata['dc:identifier'] = name  # for backward compatability in Alveo SOLR store until bug fix\n        metadata['@type'] = 'ausnc:AusNCObject'\n\n        meta = {'items': [{'metadata': { '@context': self.context,\n                                         '@graph': [metadata]\n                                        }\n                          }]\n                }\n\n        response = self.api_request(collection_uri, method='POST', data=json.dumps(meta))\n\n        # this will raise an exception if the request fails\n        self.__check_success(response)\n\n        item_uri = collection_uri + \"/\" + response['success'][0]\n\n        return item_uri", "response": "Add a new item to a collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies the metadata on an item", "response": "def modify_item(self, item_uri, metadata):\n        \"\"\"Modify the metadata on an item\n\n        \"\"\"\n\n        md = json.dumps({'metadata': metadata})\n\n        response = self.api_request(item_uri, method='PUT', data=md)\n        return self.__check_success(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes an item from a collection", "response": "def delete_item(self, item_uri):\n        \"\"\"Delete an item from a collection\n\n        :param item_uri: the URI that references the item\n        :type item_uri: String\n\n        :rtype: String\n        :returns: a message confirming that the metadata is modified\n\n        :raises: APIError if the request was not successful\n        \"\"\"\n\n        response = self.api_request(item_uri, method='DELETE')\n        return self.__check_success(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a document to an existing item.", "response": "def add_document(self, item_uri, name, metadata,\n                     content=None, docurl=None, file=None,\n                     displaydoc=False, preferName=False,\n                     contrib_id=None):\n        \"\"\"Add a document to an existing item\n\n        :param item_uri: the URI that references the item\n        :type item_uri: String\n\n        :param name: The document name\n        :type name: String\n\n        :param metadata: a dictionary of metadata values describing the document\n        :type metadata: Dict\n\n        :param content: optional content of the document\n        :type content: byte array\n\n        :param docurl: optional url referencing the document\n        :type docurl: String\n\n        :param file: optional full path to file to be uploaded\n        :type file: String\n\n        :param displaydoc: if True, make this the display document for the item\n        :type displaydoc: Boolean\n        \n        :param preferName: if True, given document name will be the document id rather than\n            filename. Useful if you want to upload under a different filename.\n        :type preferName: Boolean\n\n        :param contrib_id: if present, add this document to this contribution as well as\n            associating it with the item\n        :type contrib_id: Integer\n\n        :rtype: String\n        :returns: The URL of the newly created document\n\n        \"\"\"\n        \n        if not preferName and file is not None:\n            docid = os.path.basename(file)\n        else:\n            docid = name\n\n        docmeta = {\"metadata\": {\"@context\": self.context,\n                                \"@type\": \"foaf:Document\",\n                                \"dcterms:identifier\": docid,\n                                }\n                  }\n        # add in metadata we are passed\n        docmeta[\"metadata\"].update(metadata)\n\n        if contrib_id:\n            docmeta['contribution_id'] = contrib_id\n\n        if content is not None:\n            docmeta['document_content'] = content\n        elif docurl is not None:\n            docmeta[\"metadata\"][\"dcterms:source\"] = { \"@id\": docurl }\n        elif file is not None:\n            # we only pass the metadata part of the dictionary\n            docmeta = docmeta['metadata']\n        else:\n            raise Exception(\"One of content, docurl or file must be specified in add_document\")\n\n        if file is not None:\n            result = self.api_request(item_uri, method='POST', data={'metadata': json.dumps(docmeta)}, file=file)\n        else:\n            result = self.api_request(item_uri, method='POST', data=json.dumps(docmeta))\n\n        self.__check_success(result)\n\n        if displaydoc:\n            itemmeta = {\"http://alveo.edu.org/vocabulary/display_document\": docid}\n\n            self.modify_item(item_uri, itemmeta)\n\n        doc_uri = item_uri + \"/document/\" + name\n        return doc_uri"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a document from an item node", "response": "def delete_document(self, doc_uri):\n        \"\"\"Delete a document from an item\n\n        :param doc_uri: the URI that references the document\n        :type doc_uri: String\n\n        :rtype: String\n        :returns: a message confirming that the document was deleted\n\n        :raises: APIError if the request was not successful\n        \"\"\"\n\n        result = self.api_request(doc_uri, method='DELETE')\n        return self.__check_success(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __check_success(resp):\n\n        if \"success\" not in resp.keys():\n            try:\n                raise APIError('200', 'Operation Failed', resp[\"error\"])\n            except KeyError:\n                raise APIError('200', 'Operation Failed', str(resp))\n        return resp[\"success\"]", "response": "Checks a JSON server response to see if it was successful and returns the success message if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload the items from the server and save it to the file_path", "response": "def download_items(self, items, file_path, file_format='zip'):\n        \"\"\" Retrieve a file from the server containing the metadata\n        and documents for the speficied items\n\n        :type items: List or ItemGroup\n        :param items: List of the the URLs of the items to download,\n            or an ItemGroup object\n        :type file_path: String\n        :param file_path: the path to which to save the file\n        :type file_format: String\n        :param file_format: the file format to request from the server: specify\n            either 'zip' or 'warc'\n\n        :rtype: String\n        :returns: the file path\n\n        :raises: APIError if the API request is not successful\n\n\n        \"\"\"\n        download_url = '/catalog/download_items'\n        download_url += '?' + urlencode((('format', file_format),))\n        item_data = {'items': list(items)}\n\n        data = self.api_request(download_url, method='POST', data=json.dumps(item_data), raw=True)\n\n        with open(file_path, 'w') as f:\n            f.write(data)\n\n        return file_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_metadata(self, query):\n        query_url = ('/catalog/search?' +\n                     urlencode((('metadata', query),)))\n\n        resp = self.api_request(query_url)\n        return ItemGroup(resp['items'], self)", "response": "Submit a search query to the server and retrieve the results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving an item list from the server as an ItemList object", "response": "def get_item_list(self, item_list_url):\n        \"\"\" Retrieve an item list from the server as an ItemList object\n\n        :type item_list_url: String or ItemList\n        :param item_list_url: URL of the item list to retrieve, or an\n            ItemList object\n\n        :rtype: ItemList\n        :returns: The ItemList\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        resp = self.api_request(str(item_list_url))\n        return ItemList(resp['items'], self, str(item_list_url), resp['name'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_item_list_by_name(self, item_list_name, category='own'):\n        resp = self.api_request('/item_lists')\n        for item_list in resp[category]:\n            if item_list['name'] == item_list_name:\n                return self.get_item_list(item_list['item_list_url'])\n        raise ValueError('List does not exist: ' + item_list_name)", "response": "This method returns an item list object by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_to_item_list(self, item_urls, item_list_url):\n        item_list_url = str(item_list_url)\n        name = self.get_item_list(item_list_url).name()\n        return self.add_to_item_list_by_name(item_urls, name)", "response": "Instructs the server to add the given items to the specified Item List"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_to_item_list_by_name(self, item_urls, item_list_name):\n        url_name = urlencode((('name', item_list_name),))\n        request_url = '/item_lists?' + url_name\n\n        data = json.dumps({'items': list(item_urls)})\n        resp = self.api_request(request_url,  method='POST', data=data)\n        return self.__check_success(resp)", "response": "Instructs the server to add the given items to the specified item list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenames an Item List on the server :type item_list_url: String or ItemList :param item_list_url: the URL of the list to which to add the items, or an ItemList object :type new_name: String :param new_name: the new name to give the Item List :rtype: ItemList :returns: the item list, if successful :raises: APIError if the request was not successful", "response": "def rename_item_list(self, item_list_url, new_name):\n        \"\"\" Rename an Item List on the server\n\n        :type item_list_url: String or ItemList\n        :param item_list_url: the URL of the list to which to add the items,\n            or an ItemList object\n        :type new_name: String\n        :param new_name: the new name to give the Item List\n\n        :rtype: ItemList\n        :returns: the item list, if successful\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        data = json.dumps({'name': new_name})\n        resp = self.api_request(str(item_list_url), data, method=\"PUT\")\n\n        try:\n            return ItemList(resp['items'], self, item_list_url, resp['name'])\n        except KeyError:\n            try:\n                raise APIError('200', 'Rename operation failed', resp['error'])\n            except KeyError:\n                raise APIError('200', 'Rename operation failed', resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_item_list(self, item_list_url):\n\n        try:\n            resp = self.api_request(str(item_list_url), method=\"DELETE\")\n\n            # all good if it says success\n            if 'success' in resp:\n                return True\n            else:\n                raise APIError('200', 'Operation Failed', 'Delete operation failed')\n        except APIError as e:\n            if e.http_status_code == 302:\n                return True\n            else:\n                raise e", "response": "Delete an Item List on the server"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of speaker URLs for the given collection_name", "response": "def get_speakers(self, collection_name):\n        \"\"\"Get a list of speaker URLs for this collection\n\n        :type collection_name: String\n        :param collection_name: the name of the collection to search\n\n        :rtype: List\n        :returns: a list of URLs for the speakers associated with\n            the given collection\n\n        \"\"\"\n\n        speakers_url = \"/speakers/\"+collection_name\n        resp = self.api_request(speakers_url)\n        if 'speakers' in resp:\n            return resp['speakers']\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_speaker(self, collection_name, metadata):\n\n        if 'dcterms:identifier' not in metadata:\n            raise APIError(msg=\"No identifier in speaker metadata\")\n\n        if '@context' not in metadata:\n            metadata['@context'] = CONTEXT\n\n        speakers_url = \"/speakers/\"+collection_name+\"/\"\n        resp = self.api_request(speakers_url, data=json.dumps(metadata), method=\"POST\")\n\n        if 'success' in resp:\n            return resp['success']['URI']\n        else:\n            return None", "response": "Add a new speaker to a collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_speaker(self, speaker_uri):\n\n        response = self.api_request(speaker_uri, method='DELETE')\n        return self.__check_success(response)", "response": "Delete an speaker from a collection\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubmit a sparql query to the server to search metadata and annotations.", "response": "def sparql_query(self, collection_name, query):\n        \"\"\" Submit a sparql query to the server to search metadata\n        and annotations.\n\n        :type collection_name: String\n        :param collection_name: the name of the collection to search\n        :type query: String\n        :param query: the sparql query\n\n        :rtype: Dict\n        :returns: the query result from the server as a Python dictionary\n            following the format of the SPARQL JSON result format documented\n            at http://www.w3.org/TR/rdf-sparql-json-res/\n\n        :raises: APIError if the request was not successful\n\n\n        \"\"\"\n        request_url = '/sparql/' + collection_name + '?'\n        request_url += urlencode((('query', query),))\n\n        return self.api_request(request_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_contribution(self, url):\n\n        result = self.api_request(url)\n\n        # add the contrib id into the metadata\n        result['id'] = os.path.split(result['url'])[1]\n\n        return result", "response": "Get the details of a particular contribution given it s\n         url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new contribution given a dictionary of metadata", "response": "def create_contribution(self, metadata):\n        \"\"\"Create a new contribution given a dictionary of metadata\n\n            {\n                \"contribution_name\": \"HelloWorld\",\n                \"contribution_collection\": \"Cooee\",\n                \"contribution_text\": \"This is contribution description\",\n                \"contribution_abstract\": \"This is contribution abstract\"\n            }\n\n        :rtype: dict\n        :returns: The metadata for the created contribution\n\n        \"\"\"\n\n        result = self.api_request('/contrib/', method='POST', data=json.dumps(metadata))\n\n        # add the contrib id into the metadata\n        result['id'] = os.path.split(result['url'])[1]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the contribution with this identifier", "response": "def delete_contribution(self, url):\n        \"\"\"Delete the contribution with this identifier\n\n        :rtype: bool\n        :returns: True if the contribution was deleted, False otherwise (eg. if it didn't exist)\n        \"\"\"\n\n        # first validate that this is a real contrib\n        try:\n            result = self.api_request(url)\n\n            if 'url' in result and 'documents' in result:\n                self.api_request(result['url'], method='DELETE')\n                return True\n        except:\n            pass\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lint():\n    path = os.path.realpath(os.getcwd())\n    cmd = 'flake8 %s' % path\n    opt = ''\n    print(\">>> Linting codebase with the following command: %s %s\" % (cmd, opt))\n\n    try:\n        return_code = call([cmd, opt], shell=True)\n        if return_code < 0:\n            print(\">>> Terminated by signal\", -return_code, file=sys.stderr)\n        elif return_code != 0:\n            sys.exit('>>> Lint checks failed')\n        else:\n            print(\">>> Lint checks passed\", return_code, file=sys.stderr)\n    except OSError as e:\n        print(\">>> Execution failed:\", e, file=sys.stderr)", "response": "run linter on our code base"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    parser = argparse.ArgumentParser()\n    sub_parser = parser.add_subparsers()\n\n    lint_parser = sub_parser.add_parser('lint')\n    lint_parser.set_defaults(func=lint)\n\n    unit_test_parser = sub_parser.add_parser('unit-test')\n    unit_test_parser.set_defaults(func=unit_test)\n\n    test_suite_parser = sub_parser.add_parser('test-suite')\n    test_suite_parser.set_defaults(func=test_suite)\n\n    args, extra_args = parser.parse_known_args()\n\n    if extra_args:\n        args.func(extra_args)\n    else:\n        args.func()", "response": "This is the main entry point for the\n    command line tool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the statement stmt to the terminal and wait for a Y or N answer. Returns True for Y False for N.", "response": "def prompt_yn(stmt):\n    '''Prints the statement stmt to the terminal and wait for a Y or N answer.\n       Returns True for 'Y', False for 'N'.'''\n    print(stmt)\n    answer = ''\n    while answer not in ['Y', 'N']:\n        sys.stdout.write(\"$ \")\n        answer = sys.stdin.readline().upper().strip()\n    return answer == 'Y'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_agents(self, addr=True, agent_cls=None, include_manager=False):\n        '''Get agents in the environment.\n\n        :param bool addr: If ``True``, returns only addresses of the agents.\n        :param agent_cls:\n            Optional, if specified returns only agents belonging to that\n            particular class.\n\n        :param bool include_manager:\n            If `True``` includes the environment's manager, i.e. the agent in\n            the address ``tcp://environment-host:port/0``, to the returned\n            list if the environment has attribute :attr:`manager`. If\n            environment does not have :attr:`manager`, then the parameter does\n            nothing.\n\n        :returns: A list of agents in the environment.\n        :rtype: list\n\n        .. note::\n            By design, manager agents are excluded from the returned lists of\n            agents by default.\n        '''\n        agents = list(self.agents.dict.values())\n        if hasattr(self, 'manager') and self.manager is not None:\n            if not include_manager:\n                agents = [a for a in agents if a.addr.rsplit('/', 1)[1] != '0']\n        if agent_cls is not None:\n            agents = [a for a in agents if type(a) is agent_cls]\n        if addr:\n            agents = [agent.addr for agent in agents]\n        return agents", "response": "Get agents in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntriggering an action to act.", "response": "async def trigger_act(self, *args, addr=None, agent=None, **kwargs):\n        '''Trigger agent to act.\n\n        If *agent* is None, then looks the agent by the address.\n\n        :raises ValueError: if both *agent* and *addr* are None.\n        '''\n        if agent is None and addr is None:\n            raise TypeError(\"Either addr or agent has to be defined.\")\n        if agent is None:\n            for a in self.get_agents(addr=False):\n                if addr == a.addr:\n                    agent = a\n        self._log(logging.DEBUG, \"Triggering agent in {}\".format(agent.addr))\n        ret = await agent.act(*args, **kwargs)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def trigger_all(self, *args, **kwargs):\n        '''Trigger all agents in the environment to act asynchronously.\n\n        :returns: A list of agents' :meth:`act` return values.\n\n        Given arguments and keyword arguments are passed down to each agent's\n        :meth:`creamas.core.agent.CreativeAgent.act`.\n\n        .. note::\n\n            By design, the environment's manager agent, i.e. if the environment\n            has :attr:`manager`, is excluded from acting.\n        '''\n        tasks = []\n        for a in self.get_agents(addr=False, include_manager=False):\n            task = asyncio.ensure_future(self.trigger_act\n                                         (*args, agent=a, **kwargs))\n            tasks.append(task)\n        rets = await asyncio.gather(*tasks)\n        return rets", "response": "Triggers all agents in the environment to act asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate random connections for all agents in the environment.", "response": "def create_random_connections(self, n=5):\n        '''Create random connections for all agents in the environment.\n\n        :param int n: the number of connections for each agent\n\n        Existing agent connections that would be created by chance are not\n        doubled in the agent's :attr:`connections`, but count towards\n        connections created.\n        '''\n        if type(n) != int:\n            raise TypeError(\"Argument 'n' must be of type int.\")\n        if n <= 0:\n            raise ValueError(\"Argument 'n' must be greater than zero.\")\n        for a in self.get_agents(addr=False):\n            others = self.get_agents(addr=False)[:]\n            others.remove(a)\n            shuffle(others)\n            for r_agent in others[:n]:\n                a.add_connection(r_agent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_connections(self, connection_map):\n        '''Create agent connections from a given connection map.\n\n        :param dict connection_map:\n            A map of connections to be created. Dictionary where keys are\n            agent addresses and values are lists of (addr, attitude)-tuples\n            suitable for\n            :meth:`~creamas.core.agent.CreativeAgent.add_connections`.\n\n        Only connections for agents in this environment are made.\n        '''\n        agents = self.get_agents(addr=False)\n        rets = []\n        for a in agents:\n            if a.addr in connection_map:\n                r = a.add_connections(connection_map[a.addr])\n                rets.append(r)\n        return rets", "response": "Create agent connections from a given connection map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_connections(self, data=True):\n        connections = []\n        for a in self.get_agents(addr=False):\n            c = (a.addr, a.get_connections(data=data))\n            connections.append(c)\n        return connections", "response": "Return connections from all the agents in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning random agent that is not the same as agent given as parameter.", "response": "def get_random_agent(self, agent):\n        '''Return random agent that is not the same as agent given as\n        parameter.\n\n        :param agent: Agent that is not wanted to return\n        :type agent: :py:class:`~creamas.core.agent.CreativeAgent`\n        :returns: random, non-connected, agent from the environment\n        :rtype: :py:class:`~creamas.core.agent.CreativeAgent`\n        '''\n        r_agent = choice(self.get_agents(addr=False))\n        while r_agent.addr == agent.addr:\n            r_agent = choice(self.get_agents(addr=False))\n        return r_agent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_artifact(self, artifact):\n        '''Add artifact with given framing to the environment.\n\n        :param object artifact: Artifact to be added.\n        '''\n        artifact.env_time = self.age\n        self.artifacts.append(artifact)\n        self._log(logging.DEBUG, \"ARTIFACTS appended: '{}', length={}\"\n                  .format(artifact, len(self.artifacts)))", "response": "Add an artifact to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_artifacts(self, agent=None):\n        '''Return artifacts published to the environment.\n\n        :param agent:\n            If not ``None``, then returns only artifacts created by the agent.\n\n        :returns: All artifacts published (by the agent).\n        :rtype: list\n\n        If environment has a :attr:`manager` agent, e.g. it is a slave\n        environment in a :class:`~creamas.mp.MultiEnvironment`, then the\n        manager's :meth:`~creamas.mp.EnvManager.get_artifacts` is called.\n        '''\n        # TODO: Figure better way for this\n        if hasattr(self, 'manager') and self.manager is not None:\n            artifacts = await self.manager.get_artifacts()\n        else:\n            artifacts = self.artifacts\n        if agent is not None:\n            artifacts = [a for a in artifacts if agent.name == a.creator]\n        return artifacts", "response": "Return all artifacts published to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndestroys the environment. Does the following: 1. calls :py:meth:`~creamas.core.Environment.save_info` 2. for each agent: calls :py:meth:`close` 3. Shuts down its RPC-service.", "response": "def destroy(self, folder=None, as_coro=False):\n        '''Destroy the environment.\n\n        Does the following:\n\n        1. calls :py:meth:`~creamas.core.Environment.save_info`\n        2. for each agent: calls :py:meth:`close`\n        3. Shuts down its RPC-service.\n        '''\n        async def _destroy(folder):\n            ret = self.save_info(folder)\n            for a in self.get_agents(addr=False):\n                a.close(folder=folder)\n            await self.shutdown(as_coro=True)\n            return ret\n\n        return run_or_coro(_destroy(folder), as_coro)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(self, resource_data=None):\n        if not self._populated:\n            params = {\n                \"Page\"      : self.page,\n                \"PageSize\"  : self.page_size,\n            }\n\n            params.update(self._filters)\n\n            if not resource_data:\n                self._resource_data = self._client._get(self._url + \".json\", params)\n            else:\n                self._resource_data = resource_data\n\n            self.total = self._resource_data[\"total\"]\n            self._page_start = self._resource_data[\"start\"]\n            self._page_end = self._resource_data[\"end\"]\n\n            self._populated = True", "response": "Populates this class with remote data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npopulates this class with remote data", "response": "def fetch(self, resource_data=None):\n        \"\"\"Populates this class with remote data\"\"\"\n        try:\n            if not resource_data:\n                resource_data = self._client._get(self._url + \".json\")\n\n            for name in self._allowed_attributes:\n                setattr(self, name, resource_data.get(name, None))\n\n            if 'sid' in self._allowed_attributes:\n                self._short_url = self.sid\n            else:\n                self._short_url = \"\"\n\n            self._populated = True\n            self._resource_data = resource_data\n        except exceptions.RequestError, e:\n            if not e.http_code == 405:\n                print e\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tee(*popenargs, **kwargs):\n\n    import subprocess, select, sys\n\n    process = subprocess.Popen(\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            *popenargs, **kwargs)\n\n    stdout, stderr = '', ''\n\n    def read_stream(input_callback, output_stream):   # (no fold)\n        read = input_callback()\n        output_stream.write(read)\n        output_stream.flush()\n        return read\n\n    while process.poll() is None:\n        watch = process.stdout.fileno(), process.stderr.fileno()\n        ready = select.select(watch, [], [])[0]\n\n        for fd in ready:\n            if fd == process.stdout.fileno():\n                stdout += read_stream(process.stdout.readline, sys.stdout)\n            if fd == process.stderr.fileno():\n                stderr += read_stream(process.stderr.readline, sys.stderr)\n\n    stdout += read_stream(process.stdout.read, sys.stdout)\n    stderr += read_stream(process.stderr.read, sys.stderr)\n\n    return stdout, stderr", "response": "Runs a command as if it were piped though tee. Returns a string that can be used to display the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        # Get the pid from the pidfile\n        try:\n            pf = file(self.pidfile,'r')\n            pid = int(pf.read().strip())\n            pf.close()\n        except IOError:\n            pid = None\n\n        if not pid:\n            message = \"pidfile %s does not exist. Daemon not running?\\n\"\n            sys.stderr.write(message % self.pidfile)\n            return # not an error in a restart\n\n        # Try killing the daemon process\n        try:\n            while 1:\n                pgid = os.getpgid(pid)\n                os.killpg(pgid, SIGTERM) # let's kill the whole process tree so that there are no zombies left\n                # os.kill(pid, SIGTERM)\n                time.sleep(0.1)\n        except OSError, err:\n            err = str(err)\n            if err.find(\"No such process\") > 0:\n                os.remove(self.pidfile)\n            else:\n                print str(err)\n                sys.exit(1)", "response": "Stop the daemon process"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(self, app):\n        cfg = app.config\n        self.welcome_message = cfg.get('USER_SEND_WELCOME_MESSAGE')\n        self.require_confirmation = cfg.get(\n            'USER_ACCOUNTS_REQUIRE_CONFIRMATION'\n        )\n\n        subjects = cfg.get('USER_EMAIL_SUBJECTS')\n        self.email_subjects = subjects if subjects else dict()\n\n        self.jwt_secret = cfg.get('USER_JWT_SECRET')\n        self.jwt_algo = cfg.get('USER_JWT_ALGO')\n        self.jwt_lifetime = cfg.get('USER_JWT_LIFETIME_SECONDS')\n        self.jwt_implementation = cfg.get('USER_JWT_IMPLEMENTATION')\n        self.jwt_loader_implementation = cfg.get(\n            'USER_JWT_LOADER_IMPLEMENTATION'\n        )", "response": "Initializes from flask app\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, user, commit=True):\n        self.is_instance(user)\n\n        schema = UpdateSchema()\n        valid = schema.process(user)\n        if not valid:\n            return valid\n\n        db.session.add(user)\n        if commit:\n            db.session.commit()\n\n        events.user_save_event.send(user)\n        return user", "response": "Persist user and emit event"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nauthenticating user and emit event.", "response": "def login(self, email=None, password=None, remember=False):\n        \"\"\" Authenticate user and emit event. \"\"\"\n        from flask_login import login_user\n        user = self.first(email=email)\n        if user is None:\n            events.login_failed_nonexistent_event.send()\n            return False\n\n        # check for account being locked\n        if user.is_locked():\n            raise x.AccountLocked(locked_until=user.locked_until)\n\n        # check for email being confirmed\n        is_new = user.email and not user.email_new\n        if is_new and not user.email_confirmed and self.require_confirmation:\n            raise x.EmailNotConfirmed(email=user.email_secure)\n\n        verified = user.verify_password(password)\n        if not verified:\n            user.increment_failed_logins()\n            self.save(user)\n            events.login_failed_event.send(user)\n            return False\n\n        # login otherwise\n        login_user(user=user, remember=remember)\n        user.reset_login_counter()\n        self.save(user)\n        events.login_event.send(user)\n\n        # notify principal\n        app = current_app._get_current_object()\n        identity_changed.send(app, identity=Identity(user.id))\n\n        # and return\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nforce login a user without credentials", "response": "def force_login(self, user):\n        \"\"\" Force login a user without credentials \"\"\"\n        from flask_login import login_user\n\n        # check for account being locked\n        if user.is_locked():\n            raise x.AccountLocked(locked_until=user.locked_until)\n\n        # check for email being confirmed\n        is_new = user.email and not user.email_new\n        if is_new and not user.email_confirmed and self.require_confirmation:\n            raise x.EmailNotConfirmed(email=user.email_secure)\n\n        # login\n        login_user(user=user, remember=True)\n        user.reset_login_counter()\n        self.save(user)\n\n        # notify principal\n        app = current_app._get_current_object()\n        identity_changed.send(app, identity=Identity(user.id))\n\n        # and return\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattempt social login and return boolean result", "response": "def attempt_social_login(self, provider, id):\n        \"\"\" Attempt social login and return boolean result \"\"\"\n        if not provider or not id:\n            return False\n\n        params = dict()\n        params[provider.lower() + '_id'] = id\n        user = self.first(**params)\n        if not user:\n            return False\n\n        self.force_login(user)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode a token into a dictionary.", "response": "def decode_token(self, token):\n        \"\"\"\n        Decode token\n        A shorthand method to decode JWT token. Will return the payload as a\n        dictionary\n        :return: str, token\n        :return: dict\n        \"\"\"\n        return jwt.decode(\n            token,\n            self.jwt_secret,\n            algorithms=[self.jwt_algo]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revoke_user_token(self, user_id):\n        user = self.get(user_id)\n        user._token = None\n        self.save(user)", "response": "Revoke user token on file and store it in the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_token(self, user_id):\n        if not self.jwt_implementation:\n            return self.default_token_implementation(user_id)\n\n        try:\n            implementation = import_string(self.jwt_implementation)\n        except ImportError:\n            msg = 'Failed to import custom JWT implementation. '\n            msg += 'Check that configured module exists [{}]'\n            raise x.ConfigurationException(msg.format(self.jwt_implementation))\n\n        # return custom token\n        return implementation(user_id)", "response": "Get user token from user id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_by_token(self, token):\n        if not self.jwt_loader_implementation:\n            return self.default_token_user_loader(token)\n\n        try:\n            implementation = import_string(self.jwt_loader_implementation)\n        except ImportError:\n            msg = 'Failed to import custom JWT user loader implementation. '\n            msg += 'Check that configured module exists [{}]'\n            raise x.ConfigurationException(\n                msg.format(self.jwt_loader_implementation)\n            )\n\n        # return user from custom loader\n        return implementation(token)", "response": "Get user by token using custom token user loader"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_token_implementation(self, user_id):\n        user = self.get(user_id)\n        if not user:\n            msg = 'No user with such id [{}]'\n            raise x.JwtNoUser(msg.format(user_id))\n\n        # return token if exists and valid\n        if user._token:\n            try:\n                self.decode_token(user._token)\n                return user._token\n            except jwt.exceptions.ExpiredSignatureError:\n                pass\n\n        from_now = datetime.timedelta(seconds=self.jwt_lifetime)\n        expires = datetime.datetime.utcnow() + from_now\n        issued = datetime.datetime.utcnow()\n        not_before = datetime.datetime.utcnow()\n        data = dict(\n            exp=expires,\n            nbf=not_before,\n            iat=issued,\n            user_id=user_id\n        )\n        token = jwt.encode(data, self.jwt_secret, algorithm=self.jwt_algo)\n        string_token = token.decode('utf-8')\n        user._token = string_token\n        self.save(user)\n        return string_token", "response": "Default JWT token implementation for user with given id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndefault token user loader", "response": "def default_token_user_loader(self, token):\n        \"\"\"\n        Default token user loader\n        Accepts a token and decodes it checking signature and expiration. Then\n        loads user by id from the token to see if account is not locked. If\n        all is good, returns user record, otherwise throws an exception.\n\n        :param token: str, token string\n        :return: boiler.user.models.User\n        \"\"\"\n        try:\n            data = self.decode_token(token)\n        except jwt.exceptions.DecodeError as e:\n            raise x.JwtDecodeError(str(e))\n        except jwt.ExpiredSignatureError as e:\n            raise x.JwtExpired(str(e))\n\n        user = self.get(data['user_id'])\n        if not user:\n            msg = 'No user with such id [{}]'\n            raise x.JwtNoUser(msg.format(data['user_id']))\n\n        if user.is_locked():\n            msg = 'This account is locked'\n            raise x.AccountLocked(msg, locked_until=user.locked_until)\n\n        if self.require_confirmation and not user.email_confirmed:\n            msg = 'Please confirm your email address [{}]'\n            raise x.EmailNotConfirmed(\n                msg.format(user.email_secure),\n                email=user.email\n            )\n\n        # test token matches the one on file\n        if not token == user._token:\n            raise x.JwtTokenMismatch('The token does not match our records')\n\n        # return on success\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a user with the database.", "response": "def register(self, user_data, base_confirm_url='', send_welcome=True):\n        \"\"\"\n        Register user\n        Accepts user data, validates it and performs registration. Will send\n        a welcome message with a confirmation link on success.\n\n        :param user_data: dic, populate user with data\n        :param send_welcome: bool, whether to send welcome or skip it (testing)\n        :param base_confirm_url: str, base confirmation link url\n        :return: boiler.user.models.User\n        \"\"\"\n        user = self.__model__(**user_data)\n        schema = RegisterSchema()\n        valid = schema.process(user)\n        if not valid:\n            return valid\n\n        db.session.add(user)\n        db.session.commit()\n        if not user.id:\n            return False\n\n        # send welcome message\n        if send_welcome:\n            self.send_welcome_message(user, base_confirm_url)\n\n        events.register_event.send(user)\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend welcome mail with email confirmation link", "response": "def send_welcome_message(self, user, base_url):\n        \"\"\" Send welcome mail with email confirmation link \"\"\"\n        if not self.require_confirmation and not self.welcome_message:\n            return\n\n        # get subject\n        subject = ''\n        subjects = self.email_subjects\n        if self.require_confirmation:\n            subject = 'Welcome, please activate your account!'\n            if 'welcome_confirm' in subjects.keys():\n                subject = subjects['welcome_confirm']\n        if not self.require_confirmation:\n            subject = 'Welcome to our site!'\n            if 'welcome' in subjects.keys():\n                subject = subjects['welcome']\n\n        # prepare data\n        sender = current_app.config['MAIL_DEFAULT_SENDER']\n        recipient = user.email\n        link = '{url}/{link}/'.format(\n            url=base_url.rstrip('/'),\n            link=user.email_link\n        )\n        data = dict(link=link)\n\n        # render message\n        if self.require_confirmation:\n            html = render_template('user/mail/account-confirm.html', **data)\n            txt = render_template('user/mail/account-confirm.txt', **data)\n        else:\n            html = render_template('user/mail/welcome.html', **data)\n            txt = render_template('user/mail/welcome.txt', **data)\n\n        # and send\n        mail.send(Message(\n            subject=subject,\n            recipients=[recipient],\n            body=txt,\n            html=html,\n            sender=sender\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregenerates email link and resend welcome message", "response": "def resend_welcome_message(self, user, base_url):\n        \"\"\" Regenerate email link and resend welcome \"\"\"\n        user.require_email_confirmation()\n        self.save(user)\n        self.send_welcome_message(user, base_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfirms email with link", "response": "def confirm_email_with_link(self, link):\n        \"\"\"\n        Confirm email with link\n        A universal method to confirm email. used for both initial\n        confirmation and when email is changed.\n        \"\"\"\n        user = self.first(email_link=link)\n        if not user:\n            return False\n        elif user and user.email_confirmed:\n            return True\n        elif user and user.email_link_expired():\n            raise x.EmailLinkExpired('Link expired, generate a new one')\n\n        # confirm otherwise\n        user.confirm_email()\n        db.session.add(user)\n        db.session.commit()\n        events.email_confirmed_event.send(user)\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_email(\n        self, user, new_email, base_confirm_url='', send_message=True):\n        \"\"\"\n        Change email\n        Saves new email and sends confirmation before doing the switch.\n        Can optionally skip sending out message for testing purposes.\n\n        The email will be sent to the new email address to verify the user has\n        access to it. Important: please be sure to password-protect this.\n\n        :param user: boiler.user.models.User\n        :param new_email: str, new email\n        :param base_confirm_url: str, base url for confirmation links\n        :param send_message: bool, send email or skip\n        :return: None\n        \"\"\"\n        from boiler.user.models import UpdateSchema\n        schema = UpdateSchema()\n        user.email = new_email\n        valid = schema.validate(user)\n        if not valid:\n            return valid\n\n        db.session.add(user)\n        db.session.commit()\n\n        # send confirmation link\n        if send_message:\n            self.send_email_changed_message(user, base_confirm_url)\n\n        events.email_update_requested_event.send(user)\n        return user", "response": "Changes the email address of a user s hasnac entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregenerate email confirmation link and resend email changed message", "response": "def resend_email_changed_message(self, user, base_url):\n        \"\"\" Regenerate email confirmation link and resend message \"\"\"\n        user.require_email_confirmation()\n        self.save(user)\n        self.send_email_changed_message(user, base_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request_password_reset(self, user, base_url):\n        user.generate_password_link()\n        db.session.add(user)\n        db.session.commit()\n        events.password_change_requested_event.send(user)\n        self.send_password_change_message(user, base_url)", "response": "Regenerate password link and send message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchanging user password and logout", "response": "def change_password(self, user, new_password):\n        \"\"\" Change user password and logout \"\"\"\n        from boiler.user.models import UpdateSchema\n        from flask_login import logout_user\n\n        schema = UpdateSchema()\n        user.password = new_password\n        user.password_link=None\n        user.password_link_expires=None\n        valid = schema.validate(user)\n\n        if not valid:\n            return valid\n\n        db.session.add(user)\n        db.session.commit()\n\n        # logout if a web request\n        if has_request_context():\n            logout_user()\n\n        events.password_changed_event.send(user)\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_password_change_message(self, user, base_url):\n        subject = 'Change your password here'\n        if 'password_change' in self.email_subjects.keys():\n            subject = self.email_subjects['password_change']\n\n        sender = current_app.config['MAIL_DEFAULT_SENDER']\n        recipient = user.email\n        link = '{url}/{link}/'.format(\n            url=base_url.rstrip('/'),\n            link=user.password_link\n        )\n        data = dict(link=link)\n        html = render_template('user/mail/password-change.html', **data)\n        txt = render_template('user/mail/password-change.txt', **data)\n\n        mail.send(Message(\n            subject=subject,\n            recipients=[recipient],\n            body=txt,\n            html=html,\n            sender=sender\n        ))", "response": "Send a password change message to the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a role to a user", "response": "def add_role_to_user(self, user, role):\n        \"\"\" Adds a role to user \"\"\"\n        user.add_role(role)\n        self.save(user)\n        events.user_got_role_event.send(user, role=role)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_role_from_user(self, user, role):\n        user.remove_role(role)\n        self.save(user)\n        events.user_lost_role_event.send(user, role=role)", "response": "Removes role from user"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a random walk from a source.", "response": "def random_walk(network):\n    \"\"\"Take a random walk from a source.\n\n    Start at a node randomly selected from those that receive input from a\n    source. At each step, transmit to a randomly-selected downstream node.\n    \"\"\"\n    latest = network.latest_transmission_recipient()\n\n    if (not network.transmissions() or latest is None):\n        sender = random.choice(network.nodes(type=Source))\n    else:\n        sender = latest\n\n    receiver = random.choice(sender.neighbors(direction=\"to\", type=Agent))\n\n    sender.transmit(to_whom=receiver)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngeneralize cultural Moran process.", "response": "def moran_cultural(network):\n    \"\"\"Generalized cultural Moran process.\n\n    At eachtime step, an individual is chosen to receive information from\n    another individual. Nobody dies, but perhaps their ideas do.\n    \"\"\"\n    if not network.transmissions():  # first step, replacer is a source\n        replacer = random.choice(network.nodes(type=Source))\n        replacer.transmit()\n    else:\n        replacer = random.choice(network.nodes(type=Agent))\n        replaced = random.choice(\n            replacer.neighbors(direction=\"to\", type=Agent))\n\n        from operator import attrgetter\n\n        replacer.transmit(\n            what=max(replacer.infos(), key=attrgetter('creation_time')),\n            to_whom=replaced)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef moran_sexual(network):\n    if not network.transmissions():\n        replacer = random.choice(network.nodes(type=Source))\n        replacer.transmit()\n    else:\n        from operator import attrgetter\n        agents = network.nodes(type=Agent)\n        baby = max(agents, key=attrgetter('creation_time'))\n        agents = [a for a in agents if a.id != baby.id]\n        replacer = random.choice(agents)\n        replaced = random.choice(\n            replacer.neighbors(direction=\"to\", type=Agent))\n\n        # Give the baby the same outgoing connections as the replaced.\n        for node in replaced.neighbors(direction=\"to\"):\n            baby.connect(direction=\"to\", whom=node)\n\n        # Give the baby the same incoming connections as the replaced.\n        for node in replaced.neighbors(direction=\"from\"):\n            node.connect(direction=\"to\", whom=baby)\n\n        # Kill the replaced agent.\n        replaced.fail()\n\n        # Endow the baby with the ome of the replacer.\n        replacer.transmit(to_whom=baby)", "response": "Generalized sexual Moran process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_object(self, obj):\n        if isinstance(obj, uuid.UUID):\n            return str(obj)\n        if hasattr(obj, 'isoformat'):\n            return obj.isoformat()\n        if isinstance(obj, (bytes, bytearray, memoryview)):\n            return base64.b64encode(obj).decode('ASCII')\n        raise TypeError('{!r} is not JSON serializable'.format(obj))", "response": "This method is called to encode unrecognized objects. It returns a string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize a datum into something that umsgpack likes.", "response": "def normalize_datum(self, datum):\n        \"\"\"\n        Convert `datum` into something that umsgpack likes.\n\n        :param datum: something that we want to process with umsgpack\n        :return: a packable version of `datum`\n        :raises TypeError: if `datum` cannot be packed\n\n        This message is called by :meth:`.packb` to recursively normalize\n        an input value before passing it to :func:`umsgpack.packb`.  Values\n        are normalized according to the following table.\n\n        +-------------------------------+-------------------------------+\n        | **Value**                     | **MsgPack Family**            |\n        +-------------------------------+-------------------------------+\n        | :data:`None`                  | `nil byte`_ (0xC0)            |\n        +-------------------------------+-------------------------------+\n        | :data:`True`                  | `true byte`_ (0xC3)           |\n        +-------------------------------+-------------------------------+\n        | :data:`False`                 | `false byte`_ (0xC2)          |\n        +-------------------------------+-------------------------------+\n        | :class:`int`                  | `integer family`_             |\n        +-------------------------------+-------------------------------+\n        | :class:`float`                | `float family`_               |\n        +-------------------------------+-------------------------------+\n        | String                        | `str family`_                 |\n        +-------------------------------+-------------------------------+\n        | :class:`bytes`                | `bin family`_                 |\n        +-------------------------------+-------------------------------+\n        | :class:`bytearray`            | `bin family`_                 |\n        +-------------------------------+-------------------------------+\n        | :class:`memoryview`           | `bin family`_                 |\n        +-------------------------------+-------------------------------+\n        | :class:`collections.Sequence` | `array family`_               |\n        +-------------------------------+-------------------------------+\n        | :class:`collections.Set`      | `array family`_               |\n        +-------------------------------+-------------------------------+\n        | :class:`collections.Mapping`  | `map family`_                 |\n        +-------------------------------+-------------------------------+\n        | :class:`uuid.UUID`            | Converted to String           |\n        +-------------------------------+-------------------------------+\n\n        .. _nil byte: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#formats-nil\n        .. _true byte: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#bool-format-family\n        .. _false byte: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#bool-format-family\n        .. _integer family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#int-format-family\n        .. _float family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#float-format-family\n        .. _str family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#str-format-family\n        .. _array family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#array-format-family\n        .. _map family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md\n           #mapping-format-family\n        .. _bin family: https://github.com/msgpack/msgpack/blob/\n           0b8f5ac67cdd130f4d4d4fe6afb839b989fdb86a/spec.md#bin-format-family\n\n        \"\"\"\n        if datum is None:\n            return datum\n\n        if isinstance(datum, self.PACKABLE_TYPES):\n            return datum\n\n        if isinstance(datum, uuid.UUID):\n            datum = str(datum)\n\n        if isinstance(datum, bytearray):\n            datum = bytes(datum)\n\n        if isinstance(datum, memoryview):\n            datum = datum.tobytes()\n\n        if hasattr(datum, 'isoformat'):\n            datum = datum.isoformat()\n\n        if isinstance(datum, (bytes, str)):\n            return datum\n\n        if isinstance(datum, (collections.Sequence, collections.Set)):\n            return [self.normalize_datum(item) for item in datum]\n\n        if isinstance(datum, collections.Mapping):\n            out = {}\n            for k, v in datum.items():\n                out[k] = self.normalize_datum(v)\n            return out\n\n        raise TypeError(\n            '{} is not msgpackable'.format(datum.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_pymol_selection_from_PDB_residue_ids(residue_list):\n    '''Elements of residue_list should be strings extracted from PDB lines from position 21-26 inclusive (zero-indexing)\n       i.e. the chain letter concatenated by the 5-character (including insertion code) residue ID.'''\n    residues_by_chain = {}\n    for residue_id in residue_list:\n        chain_id = residue_id[0]\n        pruned_residue_id = residue_id[1:]\n        residues_by_chain[chain_id] = residues_by_chain.get(chain_id, [])\n        residues_by_chain[chain_id].append(pruned_residue_id)\n\n    str = []\n    for chain_id, residue_list in sorted(residues_by_chain.iteritems()):\n        str.append('(chain %s and resi %s)' % (chain_id, '+'.join(map(string.strip, sorted(residue_list)))))\n    return ' or '.join(str)", "response": "Create a pymol selection string from a list of residue IDs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _offload(self, args, **extra_args):\n        if not isinstance(args, argparse.Namespace):\n            raise Exception(\"args should of an instance of argparse.Namespace\")\n\n        # create new freight forwarder object\n        freight_forwarder = FreightForwarder()\n\n        # create commercial invoice this is the contact given to freight forwarder dispatch containers and images\n        commercial_invoice = freight_forwarder.commercial_invoice(\n            'offload',\n            args.data_center,\n            args.environment,\n            args.service\n        )\n\n        # off load container and images.\n        bill_of_lading = freight_forwarder.offload(commercial_invoice)\n\n        # pretty lame... Need to work on return values through to app to make them consistent.\n        exit_code = 0 if bill_of_lading else 1\n\n        if exit_code != 0:\n            exit(exit_code)", "response": "This function is the entry point for exporting docker images."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmapping a value for a group id applying requested mapping.", "response": "def map_value(self, value, gid):\n        \"\"\"\n        Return the value for a group id, applying requested mapping.\n        Map only groups related to a filter, ie when the basename of\n        the group is identical to the name of a filter.\n        \"\"\"\n        base_gid = self.base_gid_pattern.search(gid).group(1)\n        if self.anonymyze:\n            try:\n                if value in self._maps[base_gid]:\n                    return self._maps[base_gid][value]\n                else:\n                    k = (len(self._maps[base_gid]) + 1) % self.mapmax\n                    new_item = u'{0}_{1:0{2}d}'.format(base_gid.upper(), k, self.mapexp)\n                    self._maps[base_gid][value] = new_item\n                    return new_item\n            except KeyError:\n                return value\n        elif base_gid in ['client', 'mail', 'from', 'rcpt', 'user'] and self.ip_lookup:\n            ip_match = self.ip_pattern.search(value)\n            if ip_match is None:\n                return value\n            host = self.gethost(ip_match.group(1))\n            if host == ip_match.group(1) or value.startswith(host):\n                return value\n            return u''.join([\n                value[:ip_match.start(1)],\n                self.gethost(ip_match.group(1)),\n                value[ip_match.end(1):]])\n        elif (base_gid == 'user' or base_gid == 'uid') and self.uid_lookup:\n            return self.getuname(value)\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_to_dict(self, match, gids):\n        values = {}\n        for gid in gids:\n            try:\n                values[gid] = self.map_value(match.group(gid), gid)\n            except IndexError:\n                pass\n        return values", "response": "Map values from match into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_to_string(self, match, gids, values=None):\n        s = match.string\n        parts = []\n        k = 0\n        for gid in sorted(gids, key=lambda x: gids[x]):\n            if values is None:\n                try:\n                    value = self.map_value(match.group(gid), gid)\n                    parts.append(s[k:match.start(gid)])\n                    parts.append(value)\n                    k = match.end(gid)\n                except IndexError:\n                    continue\n            elif gid in values:\n                parts.append(s[k:match.start(gid)])\n                parts.append(values[gid])\n                k = match.end(gid)\n        parts.append(s[k:])\n        return u\"\".join(parts)", "response": "Return the mapped string from a match object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gethost(self, ip_addr):\n        # Handle silly fake ipv6 addresses\n        try:\n            if ip_addr[:7] == '::ffff:':\n                ip_addr = ip_addr[7:]\n        except TypeError:\n            pass\n\n        if ip_addr[0] in string.letters:\n            return ip_addr\n\n        try:\n            return self.hostsmap[ip_addr]\n        except KeyError:\n            pass\n\n        try:\n            name = socket.gethostbyaddr(ip_addr)[0]\n        except socket.error:\n            name = ip_addr\n\n        self.hostsmap[ip_addr] = name\n        return name", "response": "Do reverse lookup on an ip address and return the host name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getuname(self, uid):\n        uid = int(uid)\n        try:\n            return self.uidsmap[uid]\n        except KeyError:\n            pass\n\n        try:\n            name = pwd.getpwuid(uid)[0]\n        except (KeyError, AttributeError):\n            name = \"uid=%d\" % uid\n\n        self.uidsmap[uid] = name\n        return name", "response": "Get the username of a given uid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naliases to register model", "response": "def register_models(**kwargs):\n    \"\"\"\n    Alias to register model\n    :param kwargs:\n    :return:\n    \"\"\"\n    [setattr(models, k, v) for k, v in kwargs.items()]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_env():\n    if not __ENV__:\n        env = os.environ[\"env\"] if \"env\" in os.environ else \"Dev\"\n        set_env(env)\n    return __ENV__", "response": "Returns the Capitalize environment name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the app and env from command line.", "response": "def get_app_env():\n    \"\"\"\n    if the app and the envi are passed in the command line as 'app=$app:$env'\n    :return: tuple app, env\n    \"\"\"\n    app, env = None, get_env()\n    if \"app\" in os.environ:\n        app = os.environ[\"app\"].lower()\n        if \":\" in app:\n            app, env = os.environ[\"app\"].split(\":\", 2)\n            set_env(env)\n    return app, env"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize a new app object", "response": "def init_app(kls):\n    \"\"\"\n    To bind middlewares, plugins that needs the 'app' object to init\n    Bound middlewares will be assigned on cls.init()\n    \"\"\"\n    if not hasattr(kls, \"__call__\"):\n        raise exceptions.MochaError(\"init_app: '%s' is not callable\" % kls)\n    Mocha._init_apps.add(kls)\n    return kls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a package with the Mocha.", "response": "def register_package(pkg, prefix=None):\n    \"\"\"\n    Allow to register an app packages by loading and exposing: templates, static,\n    and exceptions for abort()\n\n    Structure of package\n        root\n            | $package_name\n                | __init__.py\n                |\n                | /templates\n                    |\n                    |\n                |\n                | /static\n                    |\n                    | assets.yml\n\n    :param pkg: str - __package__\n                    or __name__\n                    or The root dir\n                    or the dotted resource package (package.path.path,\n                    usually __name__ of templates and static\n    :param prefix: str - to prefix the template path\n    \"\"\"\n\n    root_pkg_dir = pkg\n    if not os.path.isdir(pkg) and \".\" in pkg:\n        root_pkg_dir = pkg_resources.resource_filename(pkg, \"\")\n\n    template_path = os.path.join(root_pkg_dir, \"templates\")\n    static_path = os.path.join(root_pkg_dir, \"static\")\n\n    logging.info(\"Registering App: \" + pkg)\n    if os.path.isdir(template_path):\n        loader = jinja2.FileSystemLoader(template_path)\n        if prefix:\n            ploader = jinja2.PrefixLoader({\n                prefix: loader\n            })\n            loader = ploader\n        Mocha._template_paths.add(loader)\n\n    if os.path.isdir(static_path):\n        Mocha._static_paths.add(static_path)\n        Mocha._add_asset_bundle(static_path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config(key, default=None):\n    return Mocha._app.config.get(key, default) if Mocha._app else default", "response": "Shortcut to access the application s config in your class\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef page_attr(title=None, **kwargs):\n    default = dict(\n        title=\"\",\n        description=\"\",\n        url=\"\",\n        image=\"\",\n        site_name=\"\",\n        object_type=\"article\",\n        locale=\"\",\n        keywords=[],\n        use_opengraph=True,\n        use_googleplus=True,\n        use_twitter=True,\n        properties={}\n    )\n    meta = getattr(g, \"__META__\", default)\n    if title:\n        kwargs[\"title\"] = title\n    meta.update(**kwargs)\n    setattr(g, \"__META__\", meta)", "response": "Page Attr allows you to add meta data in the request g."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef local_datetime(utcdatetime, format=None, timezone=None):\n    if utcdatetime is None:\n        return None\n\n    timezone = timezone or config(\"DATETIME_TIMEZONE\", \"US/Eastern\")\n    dt = utcdatetime.to(timezone) \\\n        if isinstance(utcdatetime, arrow.Arrow) \\\n        else arrow.get(utcdatetime, timezone)\n    if format is False:\n        return dt\n\n    _ = config(\"DATETIME_FORMAT\")\n    format = _.get(\"default\") or \"MM/DD/YYYY\" if not format else _.get(format)\n    return dt.format(format)", "response": "Returns a datetime object based on the timezone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_for(endpoint, **kw):\n\n    _endpoint = None\n    if isinstance(endpoint, six.string_types):\n        return f_url_for(endpoint, **kw)\n    else:\n        # self, will refer the caller method, by getting the method name\n        if isinstance(endpoint, Mocha):\n            fn = sys._getframe().f_back.f_code.co_name\n            endpoint = getattr(endpoint, fn)\n\n        if is_method(endpoint):\n            _endpoint = _get_action_endpoint(endpoint)\n            if not _endpoint:\n                _endpoint = _build_endpoint_route_name(endpoint)\n    if _endpoint:\n        return f_url_for(_endpoint, **kw)\n    else:\n        raise exceptions.MochaError('Mocha `url_for` received an invalid endpoint')", "response": "Mocha url_for is an alias to the flask url_for function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nredirects to the right endpoint.", "response": "def redirect(endpoint, **kw):\n    \"\"\"\n    Redirect allow to redirect dynamically using the classes methods without\n    knowing the right endpoint.\n    Expecting all endpoint have GET as method, it will try to pick the first\n    match, based on the endpoint provided or the based on the Rule map_url\n\n    An endpoint can also be passed along with **kw\n\n    An http: or https: can also be passed, and will redirect to that site.\n\n    example:\n        redirect(self.hello_world)\n        redirect(self.other_page, name=\"x\", value=\"v\")\n        redirect(\"https://google.com\")\n        redirect(views.ContactPage.index)\n    :param endpoint:\n    :return: redirect url\n    \"\"\"\n\n    _endpoint = None\n\n    if isinstance(endpoint, six.string_types):\n        _endpoint = endpoint\n        # valid for https:// or /path/\n        # Endpoint should not have slashes. Use : (colon) to build endpoint\n        if \"/\" in endpoint:\n            return f_redirect(endpoint)\n        else:\n            for r in Mocha._app.url_map.iter_rules():\n                _endpoint = endpoint\n                if 'GET' in r.methods and endpoint in r.endpoint:\n                    _endpoint = r.endpoint\n                    break\n    else:\n        # self, will refer the caller method, by getting the method name\n        if isinstance(endpoint, Mocha):\n            fn = sys._getframe().f_back.f_code.co_name\n            endpoint = getattr(endpoint, fn)\n\n        if is_method(endpoint):\n            _endpoint = _get_action_endpoint(endpoint)\n            if not _endpoint:\n                _endpoint = _build_endpoint_route_name(endpoint)\n    if _endpoint:\n        return f_redirect(url_for(_endpoint, **kw))\n    else:\n        raise exceptions.MochaError(\"Invalid endpoint\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_action_endpoint(action):\n    _endpoint = None\n    if is_method(action):\n        if hasattr(action, \"_rule_cache\"):\n            rc = action._rule_cache\n            if rc:\n                k = list(rc.keys())[0]\n                rules = rc[k]\n                len_rules = len(rules)\n                if len_rules == 1:\n                    rc_kw = rules[0][1]\n                    _endpoint = rc_kw.get(\"endpoint\", None)\n                    if not _endpoint:\n                        _endpoint = _build_endpoint_route_name(action)\n                elif len_rules > 1:\n                    _prefix = _build_endpoint_route_name(action)\n                    for r in Mocha._app.url_map.iter_rules():\n                        if ('GET' in r.methods or 'POST' in r.methods) \\\n                                and _prefix in r.endpoint:\n                            _endpoint = r.endpoint\n                            break\n    return _endpoint", "response": "Return the endpoint base on the view s action\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_endpoint_route_name(cls, method_name, class_name=None):\n\n    module = cls.__module__.split(\"views.\")[1] if \".views.\" in cls.__module__ \\\n        else cls.__module__.split(\".\")[-1]\n    return \"%s.%s:%s\" % (module, class_name or cls.__name__, method_name)", "response": "Build the route name for the view"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a function to all the members of a class.", "response": "def apply_function_to_members(cls, fn):\n    \"\"\"\n    Apply a function to all the members of a class.\n    Used for decorators that is applied in a class and want all the members\n    to use it\n    :param cls: class\n    :param fn: function\n    :return: \n    \"\"\"\n    for name, method in get_interesting_members(Mocha, cls):\n        setattr(cls, name, fn(method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndrills through layers of decorators attempting to locate the actual argspec for the method.", "response": "def get_true_argspec(method):\n    \"\"\"Drills through layers of decorators attempting to locate the actual argspec for the method.\"\"\"\n\n    argspec = inspect.getargspec(method)\n    args = argspec[0]\n    if args and args[0] == 'self':\n        return argspec\n    if hasattr(method, '__func__'):\n        method = method.__func__\n    if not hasattr(method, '__closure__') or method.__closure__ is None:\n        raise DecoratorCompatibilityError\n\n    closure = method.__closure__\n    for cell in closure:\n        inner_method = cell.cell_contents\n        if inner_method is method:\n            continue\n        if not inspect.isfunction(inner_method) \\\n                and not inspect.ismethod(inner_method):\n            continue\n        true_argspec = get_true_argspec(inner_method)\n        if true_argspec:\n            return true_argspec"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_view_attr(view, key, value, cls_name=None):\n    ns = view_namespace(view, cls_name)\n    if ns:\n        if ns not in _views_attr:\n            _views_attr[ns] = {}\n        _views_attr[ns][key] = value", "response": "Set the view attributes for the navigable object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the attributes that were saved for the view.", "response": "def get_view_attr(view, key, default=None, cls_name=None):\n    \"\"\"\n    Get the attributes that was saved for the view\n    :param view: object (class or instance method)\n    :param key: string - the key\n    :param default: mixed - the default value\n    :param cls_name: str - To pass the class name associated to the view\n            in the case of decorators that may not give the real class name\n    :return: mixed\n    \"\"\"\n    ns = view_namespace(view, cls_name)\n    if ns:\n        if ns not in _views_attr:\n            return default\n        return _views_attr[ns].get(key, default)\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the namespace from the view object", "response": "def view_namespace(view, cls_name=None):\n    \"\"\"\n    Create the namespace from the view\n    :param view: object (class or instance method)\n    :param cls_name: str - To pass the class name associated to the view\n            in the case of decorators that may not give the real class name\n    :return: string or None\n    \"\"\"\n    ns = view.__module__\n    if inspect.isclass(view):\n        ns += \".%s\" % view.__name__\n    else:\n        if hasattr(view, \"im_class\") or hasattr(view, \"im_self\"):\n            if view.im_class is not None:\n                cls_name = view.im_class.__name__\n            elif view.im_self is not None:\n                cls_name = view.im_self.__name__\n        if cls_name is None:\n            return None\n        ns += \".%s.%s\" % (cls_name, view.__name__)\n    return ns"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the authorization token from the request headers.", "response": "def get_auth_token(cls):\n        \"\"\"\n        Return the authorization token\n        :return: string\n        \"\"\"\n        if 'Authorization' not in f_request.headers:\n            raise ValueError(\"Missing Authorization Bearer in headers\")\n        data = f_request.headers['Authorization'].encode('ascii', 'ignore')\n        return str.replace(str(data), 'Bearer ', '').strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_installed_apps(cls):\n\n        cls._installed_apps = cls._app.config.get(\"INSTALLED_APPS\", [])\n        if cls._installed_apps:\n            def import_app(module, props={}):\n                _ = werkzeug.import_string(module)\n                setattr(_, \"__options__\", utils.dict_dot(props))\n\n            for k in cls._installed_apps:\n                if isinstance(k, six.string_types):  # One string\n                    import_app(k, {})\n                elif isinstance(k, tuple):\n                    import_app(k[0], k[1])\n                elif isinstance(k, list):  # list of tuple[(module props), ...]\n                    for t in k:\n                        import_app(t[0], t[1])", "response": "This method sets up the installed 3rd party applications along with associated properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the view template based on the class and method being invoked.", "response": "def render(cls, data={}, _template=None, _layout=None, **kwargs):\n        \"\"\"\n        Render the view template based on the class and the method being invoked\n        :param data: The context data to pass to the template\n        :param _template: The file template to use. By default it will map the module/classname/action.html\n        :param _layout: The body layout, must contain {% include __template__ %}\n        \"\"\"\n\n        # Invoke the page meta so it can always be set\n        page_attr()\n\n        # Add some global Mocha data in g, along with APPLICATION DATA\n        vars = dict(\n            __NAME__=__title__,\n            __VERSION__=__version__,\n            __YEAR__=utc_now().year\n        )\n        for k, v in vars.items():\n            setattr(g, k, v)\n\n        # Build the template using the method name being called\n        if not _template:\n            stack = inspect.stack()[1]\n            action_name = stack[3]\n            _template = build_endpoint_route_name(cls, action_name)\n            _template = utils.list_replace([\".\", \":\"], \"/\", _template)\n            _template = \"%s.%s\" % (_template, cls.template_markup)\n\n        data = data or {}\n        data.update(kwargs)\n        data[\"__template__\"] = _template\n\n        return render_template(_layout or cls.base_layout, **data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a webassets bundle yml file", "response": "def _add_asset_bundle(cls, path):\n        \"\"\"\n        Add a webassets bundle yml file\n        \"\"\"\n        f = \"%s/assets.yml\" % path\n        if os.path.isfile(f):\n            cls._asset_bundles.add(f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister the models and assign them to models", "response": "def _expose_models(cls):\n        \"\"\"\n        Register the models and assign them to `models`\n        :return: \n        \"\"\"\n        if db._IS_OK_:\n            register_models(**{m.__name__: m\n                               for m in db.Model.__subclasses__()\n                               if not hasattr(models, m.__name__)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _register(cls,\n                  app,\n                  base_route=None,\n                  subdomain=None,\n                  route_prefix=None,\n                  trailing_slash=True):\n        \"\"\"Registers a Mocha class for use with a specific instance of a\n        Flask app. Any methods not prefixes with an underscore are candidates\n        to be routed and will have routes registered when this method is\n        called.\n\n        :param app: an instance of a Flask application\n\n        :param base_route: The base path to use for all routes registered for\n                           this class. Overrides the base_route attribute if\n                           it has been set.\n\n        :param subdomain:  A subdomain that this registration should use when\n                           configuring routes.\n\n        :param route_prefix: A prefix to be applied to all routes registered\n                             for this class. Precedes base_route. Overrides\n                             the class' route_prefix if it has been set.\n        \"\"\"\n\n        if cls is Mocha:\n            raise TypeError(\"cls must be a subclass of Mocha, not Mocha itself\")\n\n        # Create a unique namespaced key to access view.\n        # $module.$class_name.$Method\n        module = cls.__module__.split(\".\")[-1]\n\n        if not hasattr(views, module):\n            setattr(views, module, type('', (), {}))\n        mod = getattr(views, module)\n        setattr(mod, cls.__name__, cls)\n\n        if base_route:\n            cls.orig_base_route = cls.base_route\n            cls.base_route = base_route\n\n        if route_prefix:\n            cls.orig_route_prefix = cls.route_prefix\n            cls.route_prefix = route_prefix\n\n        if not subdomain:\n            if hasattr(app, \"subdomain\") and app.subdomain is not None:\n                subdomain = app.subdomain\n            elif hasattr(cls, \"subdomain\"):\n                subdomain = cls.subdomain\n\n        if trailing_slash is not None:\n            cls.orig_trailing_slash = cls.trailing_slash\n            cls.trailing_slash = trailing_slash\n\n        for name, value in get_interesting_members(Mocha, cls):\n            proxy = cls.make_proxy_method(name)\n            route_name = build_endpoint_route_name(cls, name)\n            try:\n                if hasattr(value, \"_rule_cache\") and name in value._rule_cache:\n                    for idx, cached_rule in enumerate(value._rule_cache[name]):\n                        rule, options = cached_rule\n                        rule = cls.build_rule(rule)\n                        sub, ep, options = cls.parse_options(options)\n\n                        if not subdomain and sub:\n                            subdomain = sub\n\n                        if ep:\n                            endpoint = ep\n                        elif len(value._rule_cache[name]) == 1:\n                            endpoint = route_name\n                        else:\n                            endpoint = \"%s_%d\" % (route_name, idx,)\n\n                        app.add_url_rule(rule, endpoint, proxy,\n                                         subdomain=subdomain,\n                                         **options)\n                elif name in cls.__special_methods:\n                    if name in [\"get\", \"index\"]:\n                        methods = [\"GET\"]\n                        if name == \"index\":\n                            if hasattr(value, \"_methods_cache\"):\n                                methods = value._methods_cache\n                    else:\n                        methods = [name.upper()]\n\n                    rule = cls.build_rule(\"/\", value)\n                    if not cls.trailing_slash:\n                        rule = rule.rstrip(\"/\")\n                    app.add_url_rule(rule, route_name, proxy,\n                                     methods=methods,\n                                     subdomain=subdomain)\n\n                else:\n                    methods = value._methods_cache \\\n                        if hasattr(value, \"_methods_cache\") \\\n                        else [\"GET\"]\n\n                    name = utils.dasherize(name)\n                    route_str = '/%s/' % name\n                    if not cls.trailing_slash:\n                        route_str = route_str.rstrip('/')\n                    rule = cls.build_rule(route_str, value)\n                    app.add_url_rule(rule, route_name, proxy,\n                                     subdomain=subdomain,\n                                     methods=methods)\n            except DecoratorCompatibilityError:\n                raise DecoratorCompatibilityError(\n                    \"Incompatible decorator detected on %s in class %s\" % (name, cls.__name__))\n\n        if hasattr(cls, \"orig_base_route\"):\n            cls.base_route = cls.orig_base_route\n            del cls.orig_base_route\n\n        if hasattr(cls, \"orig_route_prefix\"):\n            cls.route_prefix = cls.orig_route_prefix\n            del cls.orig_route_prefix\n\n        if hasattr(cls, \"orig_trailing_slash\"):\n            cls.trailing_slash = cls.orig_trailing_slash\n            del cls.orig_trailing_slash", "response": "Registers a Mocha class for use with a specific instance of app."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract subdomain endpoint and options from the options dict and returns them along with a new dict without those values.", "response": "def parse_options(cls, options):\n        \"\"\"Extracts subdomain and endpoint values from the options dict and returns\n           them along with a new dict without those values.\n        \"\"\"\n        options = options.copy()\n        subdomain = options.pop('subdomain', None)\n        endpoint = options.pop('endpoint', None)\n        return subdomain, endpoint, options,"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a proxy method that can be used by Flasks routing. The proxy method is called by the controller s methods.", "response": "def make_proxy_method(cls, name):\n        \"\"\"Creates a proxy function that can be used by Flasks routing. The\n        proxy instantiates the Mocha subclass and calls the appropriate\n        method.\n        :param name: the name of the method to create a proxy for\n        \"\"\"\n\n        i = cls()\n        view = getattr(i, name)\n\n        for decorator in cls.decorators:\n            view = decorator(view)\n\n        @functools.wraps(view)\n        def proxy(**forgettable_view_args):\n            # Always use the global request object's view_args, because they\n            # can be modified by intervening function before an endpoint or\n            # wrapper gets called. This matches Flask's behavior.\n            del forgettable_view_args\n\n            if hasattr(i, \"before_request\"):\n                response = i.before_request(name, **request.view_args)\n                if response is not None:\n                    return response\n\n            before_view_name = \"before_\" + name\n            if hasattr(i, before_view_name):\n                before_view = getattr(i, before_view_name)\n                response = before_view(**request.view_args)\n                if response is not None:\n                    return response\n\n            response = view(**request.view_args)\n\n            # You can also return a dict or None, it will pass it to render\n            if isinstance(response, dict) or response is None:\n                response = response or {}\n                if hasattr(i, \"_renderer\"):\n                    response = i._renderer(response)\n                else:\n                    _template = build_endpoint_route_name(cls, view.__name__)\n                    _template = utils.list_replace([\".\", \":\"], \"/\", _template)\n                    _template = \"%s.%s\" % (_template, cls.template_markup)\n\n                    # Set the title from the nav title, if not set\n                    _meta_title = getattr(g, \"__META__\", {}).get(\"title\")\n                    if (not _meta_title or _meta_title == \"\") and get_view_attr(view, \"title\"):\n                        page_attr(title=get_view_attr(view, \"title\"))\n\n                    response.setdefault(\"_template\", _template)\n                    response = i.render(**response)\n\n            if not isinstance(response, Response):\n                response = make_response(response)\n\n            for ext in cls._ext:\n                response = ext(response)\n\n            after_view_name = \"after_\" + name\n            if hasattr(i, after_view_name):\n                after_view = getattr(i, after_view_name)\n                response = after_view(response)\n\n            if hasattr(i, \"after_request\"):\n                response = i.after_request(name, response)\n\n            return response\n\n        return proxy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a routing rule based on the class name and the base_route attribute of the class.", "response": "def build_rule(cls, rule, method=None):\n        \"\"\"Creates a routing rule based on either the class name (minus the\n        'View' suffix) or the defined `base_route` attribute of the class\n\n        :param rule: the path portion that should be appended to the\n                     route base\n\n        :param method: if a method's arguments should be considered when\n                       constructing the rule, provide a reference to the\n                       method here. arguments named \"self\" will be ignored\n        \"\"\"\n\n        rule_parts = []\n\n        if cls.route_prefix:\n            rule_parts.append(cls.route_prefix)\n\n        base_route = cls.get_base_route()\n        if base_route:\n            rule_parts.append(base_route)\n\n        rule_parts.append(rule)\n        ignored_rule_args = ['self']\n        if hasattr(cls, 'base_args'):\n            ignored_rule_args += cls.base_args\n\n        if method:\n            args = get_true_argspec(method)[0]\n            for arg in args:\n                if arg not in ignored_rule_args:\n                    rule_parts.append(\"<%s>\" % arg)\n\n        result = \"/%s\" % \"/\".join(rule_parts)\n        return re.sub(r'(/)\\1+', r'\\1', result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_base_route(cls):\n        base_route = cls.__name__.lower()\n        if cls.base_route is not None:\n            base_route = cls.base_route\n            base_rule = parse_rule(base_route)\n            cls.base_args = [r[2] for r in base_rule]\n        return base_route.strip(\"/\")", "response": "Returns the base route to use for the current class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds and return a gene in the influence graph with the given name. Raise an AttributeError if there is no gene with the given name.", "response": "def find_gene_by_name(self, gene_name: str) -> Gene:\n        \"\"\" \n        Find and return a gene in the influence graph with the given name.\n        Raise an AttributeError if there is no gene in the graph with the given name.\n        \"\"\"\n        for gene in self.genes:\n            if gene.name == gene_name:\n                return gene\n        raise AttributeError(f'gene \"{gene_name}\" does not exist')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_multiplex_by_name(self, multiplex_name: str) -> Multiplex:\n        for multiplex in self.multiplexes:\n            if multiplex.name == multiplex_name:\n                return multiplex\n        raise AttributeError(f'multiplex \"{multiplex_name}\" does not exist')", "response": "Find and return a multiplex in the influence graph with the given name. Raise an AttributeError if there is no multiplex with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_states(self) -> Tuple[State, ...]:\n        return tuple(self._transform_list_of_states_to_state(states)\n                     for states in self._cartesian_product_of_every_states_of_each_genes())", "response": "Return all possible states of this influence graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the area of the triangles in this mesh in units of square degrees.", "response": "def area(\n            self):\n        \"\"\"*The mean area of triangles in this mesh in units of square degrees.*\n\n        **Usage:**\n\n            .. code-block:: python\n\n                mesh.area\n        \"\"\"\n        pi = numpy.pi\n        area0 = 4.0 * pi / 8.0\n        areadiv = 4.0 ** self.depth\n        area = area0 / areadiv * (180.0 / pi) ** 2\n        return area"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup_id(\n            self,\n            ra,\n            dec):\n        \"\"\"*Lookup the ID of HTM trixel that a coordinate or lists of coordinates lie on*\n\n        **Key Arguments:**\n            - ``ra`` -- list, numpy array or single ra value (first coordinate set)\n            - ``dec`` -- list, numpy array or single dec value (first coordinate set - must match ra1 array length)\n\n        **Return:**\n            - ``htmIds`` -- a list of HTM trixel ids the coordinates lie on\n\n        **Usage:**\n\n            To find the trixel IDs that a set of coordinate lie on:\n\n            .. code-block:: python\n\n                raList1 = [\"13:20:00.00\", 200.0, \"13:20:00.00\", 175.23, 21.36]\n                decList1 = [\"+24:18:00.00\",  24.3,  \"+24:18:00.00\",  -28.25, -15.32]\n\n                htmids = mesh.lookup_id(raList1, decList1)\n                for h, r, d in zip(htmids, raList1, decList1):\n                    print r, d, \" --> \", h\n\n        \"\"\"\n        self.log.debug('starting the ``lookup_id`` method')\n\n        from astrocalc.coords import coordinates_to_array\n        raArray, decArray = coordinates_to_array(\n            log=self.log,\n            ra=ra,\n            dec=dec\n        )\n\n        self.log.debug('completed the ``lookup_id`` method')\n        return super(HTM, self).lookup_id(raArray, decArray)", "response": "This method will return the ID of the HTM trixel that a set of coordinates lie on."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intersect(self, ra, dec, radius, inclusive=True, convertCoordinates=True):\n        # CONVERT RA AND DEC DECIMAL DEGREES\n\n        if convertCoordinates == True:\n            converter = unit_conversion(\n                log=self.log\n            )\n            ra = converter.ra_sexegesimal_to_decimal(\n                ra=ra\n            )\n            dec = converter.dec_sexegesimal_to_decimal(\n                dec=dec\n            )\n\n        if inclusive:\n            inc = 1\n        else:\n            inc = 0\n        return super(HTM, self).intersect(ra, dec, radius, inc)", "response": "Returns the set of trixels that intersect the given point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef match(self, ra1, dec1, ra2, dec2, radius, maxmatch=1, convertToArray=True):\n\n        # CONVERT LISTS AND SINGLE VALUES TO ARRAYS OF FLOATS\n        ra1 = numpy.array(ra1, dtype='f8', ndmin=1, copy=False)\n        dec1 = numpy.array(dec1, dtype='f8', ndmin=1, copy=False)\n        ra2 = numpy.array(ra2, dtype='f8', ndmin=1, copy=False)\n        dec2 = numpy.array(dec2, dtype='f8', ndmin=1, copy=False)\n        radius = numpy.array(radius, dtype='f8', ndmin=1, copy=False)\n\n        # CHECK ARRAY SIZES MATCH\n        if (ra1.size != dec1.size\n                or ra2.size != ra2.size):\n            stup = (ra1.size, dec1.size, ra2.size, dec2.size)\n            raise ValueError(\"ra1 must equal dec1 in size \"\n                             \"and ra2 must equal dec2 in size, \"\n                             \"got %d,%d and %d,%d\" % stup)\n\n        if radius.size != 1 and radius.size != ra2.size:\n            raise ValueError(\"radius size (%d) != 1 and\"\n                             \" != ra2,dec2 size (%d)\" % (radius.size, ra2.size))\n\n        # QUICK TRIMMING IN DEC SPACE OF BOTH SETS OF ARRAYS\n        decMatchIndices2 = (numpy.abs(dec1[:, None] - dec2) < radius).any(0)\n        decMatchIndices2 = numpy.where(decMatchIndices2)[0]\n        ra2a = ra2[decMatchIndices2]\n        dec2a = dec2[decMatchIndices2]\n\n        decMatchIndices1 = (numpy.abs(dec2[:, None] - dec1) < radius).any(0)\n        decMatchIndices1 = numpy.where(decMatchIndices1)[0]\n        ra1a = ra1[decMatchIndices1]\n        dec1a = dec1[decMatchIndices1]\n\n        # new way using a Matcher\n        depth = self.depth\n        matcher = Matcher(\n            log=self.log,\n            depth=depth,\n            ra=ra2a,\n            dec=dec2a,\n            convertToArray=convertToArray)\n        matchIndices1, matchIndices2, seps = matcher.match(\n            ra=ra1a,\n            dec=dec1a,\n            radius=radius,\n            maxmatch=maxmatch)\n\n        matchIndices1 = decMatchIndices1[matchIndices1]\n        matchIndices2 = decMatchIndices2[matchIndices2]\n\n        return matchIndices1, matchIndices2, seps", "response": "Match two lists of ra and dec points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a file and returns the sha1 hash of the data.", "response": "def read_sha1(\n    file_path,\n    buf_size = None,\n    start_byte = 0,\n    read_size = None,\n    extra_hashers = [], # update(data) will be called on all of these\n):\n    '''\n    Determines the sha1 hash of a file in chunks, to prevent loading the entire file at once into memory\n    '''\n    read_size = read_size or os.stat(file_path).st_size\n    buf_size = buf_size or DEFAULT_BUFFER_SIZE\n\n    data_read = 0\n    total_sha1 = hashlib.sha1()\n    while data_read < read_size:\n        with open( file_path, 'rb', buffering = 0 ) as f:\n            f.seek( start_byte )\n            data = f.read( min(buf_size, read_size - data_read) )\n            assert( len(data) > 0 )\n            total_sha1.update( data )\n            for hasher in extra_hashers:\n                hasher.update( data )\n            data_read += len(data)\n            start_byte += len(data)\n    assert( data_read == read_size )\n\n    return total_sha1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_file( self, folder_id, basename, limit = 500 ):\n        '''\n        Finds a file based on a box path\n        Returns a list of file IDs\n        Returns multiple file IDs if the file was split into parts with the extension '.partN' (where N is an integer)\n        '''\n        search_folder = self.client.folder( folder_id = folder_id )\n        offset = 0\n        search_items = search_folder.get_items( limit = limit, offset = offset )\n        found_files = []\n        while len(search_items) > 0:\n            files = [ (f['id'], f['name']) for f in search_items if f['name'].startswith( basename ) and f['type'] == 'file' ]\n            files.sort()\n            for f_id, f_name in files:\n                assert(\n                    f_name == basename\n                    or\n                    ( f_name.startswith( basename ) and f_name[len(basename):len(basename)+5] == '.part' )\n                )\n            found_files.extend( files )\n            offset += limit\n            search_items = search_folder.get_items( limit = limit, offset = offset )\n        return [f[0] for f in found_files]", "response": "Find a file based on a box path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_uploaded_file(\n            self,\n            destination_folder_id,\n            source_path,\n            verbose = True,\n    ):\n        '''\n        Verifies the integrity of a file uploaded to Box\n        '''\n        source_file_size = os.stat(source_path).st_size\n\n        total_part_size = 0\n        file_position = 0\n        uploaded_box_file_ids = self.find_file( destination_folder_id, os.path.basename( source_path ) )\n        total_sha1 = hashlib.sha1()\n        for i, file_id in enumerate(uploaded_box_file_ids):\n            file_info = self.client.file( file_id = file_id ).get()\n            uploaded_sha1 = file_info.response_object['sha1']\n            uploaded_size = file_info.response_object['size']\n\n            part_sha1 = read_sha1( source_path, start_byte = file_position, read_size = uploaded_size, extra_hashers = [total_sha1] )\n            if part_sha1.hexdigest() != uploaded_sha1:\n                print( '\\n' )\n                print( 'Part sha1: ' + part_sha1.hexdigest() )\n                print( 'Uploaded sha1: ' + uploaded_sha1 )\n                print('Sha1 hash of uploaded file {0} ({1}) does not match'.format(file_info.response_object['name'], file_id) )\n                return False\n\n            file_position += uploaded_size\n            total_part_size += uploaded_size\n            if len(uploaded_box_file_ids) > 1:\n                print( 'Finished verifying part {0} of {1} of {2}'.format( i+1, len(uploaded_box_file_ids), file_id ) )\n\n        assert( source_file_size == total_part_size )\n\n        if verbose:\n            print( 'Verified uploaded file {0} ({1}) with sha1: {2}'.format(source_path, file_id, total_sha1.hexdigest()) )\n\n        return True", "response": "Verifies the integrity of a file uploaded to Box\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _upload_in_splits( self, destination_folder_id, source_path, preflight_check, verbose = True, chunked_upload_threads = 5 ):\n        '''\n        Since Box has a maximum file size limit (15 GB at time of writing),\n        we need to split files larger than this into smaller parts, and chunk upload each part\n        '''\n        file_size = os.stat(source_path).st_size\n        split_size = BOX_MAX_FILE_SIZE\n\n        # Make sure that the last split piece is still big enough for a chunked upload\n        while file_size % split_size < BOX_MIN_CHUNK_UPLOAD_SIZE:\n            split_size -= 1000\n            if split_size < BOX_MIN_CHUNK_UPLOAD_SIZE:\n                raise Exception('Lazy programming error')\n\n        split_start_byte = 0\n        part_count = 0\n        uploaded_file_ids = []\n        while split_start_byte < file_size:\n            dest_file_name = '{0}.part{1}'.format( os.path.basename(source_path), part_count)\n            prev_uploaded_file_ids = self.find_file( destination_folder_id, dest_file_name )\n            if len( prev_uploaded_file_ids ) == 1:\n                if verbose:\n                    print ( '\\nSkipping upload of split {0} of {1}; already exists'.format( part_count + 1, math.ceil(file_size / split_size) ) )\n                uploaded_file_ids.extend( prev_uploaded_file_ids )\n            else:\n                if verbose:\n                    print ( '\\nUploading split {0} of {1}'.format( part_count + 1, math.ceil(file_size / split_size) ) )\n                uploaded_file_ids.append( self._chunked_upload(\n                    destination_folder_id, source_path,\n                    dest_file_name = dest_file_name,\n                    split_start_byte = split_start_byte,\n                    file_size = min(split_size, file_size - split_start_byte), # Take the min of file_size - split_start_byte so that the last part of a split doesn't read into the next split\n                    preflight_check = preflight_check,\n                    verbose = verbose,\n                    upload_threads = chunked_upload_threads,\n                ) )\n            part_count += 1\n            split_start_byte += split_size\n\n        return uploaded_file_ids", "response": "Uploads a file in a set of splits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the points that make up the mesh.", "response": "def getPoints(self, pared=False):\n        \"\"\"\n        Get the points that make up the mesh.\n        :param pared: use the pared down list of points\n        :return: A list of points\n        \"\"\"\n        points = self._points[:]\n        if pared:\n            np = NodePare()\n            np.addPoints(points)\n            np.parePoints()\n            points = np.getParedPoints()\n\n        return points"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the elements of the mesh as a list of point index lists.", "response": "def getElements(self, zero_based=True, pared=False):\n        \"\"\"\n        Get the elements of the mesh as a list of point index list.\n        :param zero_based: use zero based index of points if true otherwise use 1-based index of points.\n        :param pared: use the pared down list of points\n        :return: A list of point index lists\n        \"\"\"\n        points = self._points[:]\n        elements = self._elements[:]\n        offset = 0\n        if not zero_based:\n            offset = 1\n\n        np = None\n        if pared:\n            np = NodePare()\n            np.addPoints(points)\n            np.parePoints()\n\n        if pared or not zero_based:\n            modified_elements = []\n            for element in elements:\n                modified_element = [index + offset if np is None else np.getParedIndex(index) + offset\n                                    for index in element]\n                modified_elements.append(modified_element)\n\n            elements = modified_elements\n\n        return elements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefine the contents of new Infos.", "response": "def _contents(self):\n        \"\"\"Define the contents of new Infos.\n\n        transmit() -> _what() -> create_information() -> _contents().\n        \"\"\"\n        stories = [\n            \"ghosts.md\",\n            \"cricket.md\",\n            \"moochi.md\",\n            \"outwit.md\",\n            \"raid.md\",\n            \"species.md\",\n            \"tennis.md\",\n            \"vagabond.md\"\n        ]\n        story = random.choice(stories)\n        with open(\"static/stimuli/{}\".format(story), \"r\") as f:\n            return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_resourcelist(ltext, **kwargs):\n    '''\n    A helper that converts lists of resources from a textual format such as Markdown, including absolutizing relative IRIs\n    '''\n    base=kwargs.get('base', VERSA_BASEIRI)\n    model=kwargs.get('model')\n    iris = ltext.strip().split()\n    newlist = model.generate_resource()\n    for i in iris:\n        model.add(newlist, VERSA_BASEIRI + 'item', I(iri.absolutize(i, base)))\n    return newlist", "response": "A helper that converts a list of resources from a textual format such as Markdown including absolutizing relative IRIs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(md, model, encoding='utf-8', config=None):\n    #Set up configuration to interpret the conventions for the Markdown\n    config = config or {}\n    #This mapping takes syntactical elements such as the various header levels in Markdown and associates a resource type with the specified resources\n    syntaxtypemap = {}\n    if config.get('autotype-h1'): syntaxtypemap['h1'] = config.get('autotype-h1')\n    if config.get('autotype-h2'): syntaxtypemap['h2'] = config.get('autotype-h2')\n    if config.get('autotype-h3'): syntaxtypemap['h3'] = config.get('autotype-h3')\n    interp_stanza = config.get('interpretations', {})\n    interpretations = {}\n\n    def setup_interpretations(interp):\n        #Map the interpretation IRIs to functions to do the data prep\n        for prop, interp_key in interp.items():\n            if interp_key.startswith('@'):\n                interp_key = iri.absolutize(interp_key[1:], VERSA_BASEIRI)\n            if interp_key in PREP_METHODS:\n                interpretations[prop] = PREP_METHODS[interp_key]\n            else:\n                #just use the identity, i.e. no-op\n                interpretations[prop] = lambda x, **kwargs: x\n\n    setup_interpretations(interp_stanza)\n\n    #Prep ID generator, in case needed\n    idg = idgen(None)\n\n    #Parse the Markdown\n    #Alternately:\n    #from xml.sax.saxutils import escape, unescape\n    #h = markdown.markdown(escape(md.decode(encoding)), output_format='html5')\n    #Note: even using safe_mode this should not be presumed safe from tainted input\n    #h = markdown.markdown(md.decode(encoding), safe_mode='escape', output_format='html5')\n    comments = mkdcomments.CommentsExtension()\n    h = markdown.markdown(md, safe_mode='escape', output_format='html5', extensions=[comments])\n\n    #doc = html.markup_fragment(inputsource.text(h.encode('utf-8')))\n    tb = treebuilder()\n    h = '<html>' + h + '</html>'\n    root = tb.parse(h)\n    #Each section contains one resource description, but the special one named @docheader contains info to help interpret the rest\n    first_h1 = next(select_name(descendants(root), 'h1'))\n    #top_section_fields = itertools.takewhile(lambda x: x.xml_name != 'h1', select_name(following_siblings(first_h1), 'h2'))\n\n    #Extract header elements. Notice I use an empty element with an empty parent as the default result\n    docheader = next(select_value(select_name(descendants(root), 'h1'), '@docheader'), element('empty', parent=root)) # //h1[.=\"@docheader\"]\n    sections = filter(lambda x: x.xml_value != '@docheader', select_name_pattern(descendants(root), HEADER_PAT)) # //h1[not(.=\"@docheader\")]|h2[not(.=\"@docheader\")]|h3[not(.=\"@docheader\")]\n\n    def fields(sect):\n        '''\n        Each section represents a resource and contains a list with its properties\n        This generator parses the list and yields the key value pairs representing the properties\n        Some properties have attributes, expressed in markdown as a nested list. If present these attributes\n        Are yielded as well, else None is yielded\n        '''\n        #import logging; logging.debug(repr(sect))\n        #Pull all the list elements until the next header. This accommodates multiple lists in a section\n        sect_body_items = itertools.takewhile(lambda x: HEADER_PAT.match(x.xml_name) is None, select_elements(following_siblings(sect)))\n        #results_until(sect.xml_select('following-sibling::*'), 'self::h1|self::h2|self::h3')\n        #field_list = [ U(li) for ul in sect.xml_select('following-sibling::ul') for li in ul.xml_select('./li') ]\n        field_list = [ li for elem in select_name(sect_body_items, 'ul') for li in select_name(elem, 'li') ]\n\n        def parse_li(pair):\n            '''\n            Parse each list item into a property pair\n            '''\n            if pair.strip():\n                matched = REL_PAT.match(pair)\n                if not matched:\n                    raise ValueError(_('Syntax error in relationship expression: {0}'.format(pair)))\n                #print matched.groups()\n                if matched.group(3): prop = matched.group(3).strip()\n                if matched.group(4): prop = matched.group(4).strip()\n                if matched.group(7):\n                    val = matched.group(7).strip()\n                    typeindic = RES_VAL\n                elif matched.group(9):\n                    val = matched.group(9).strip()\n                    typeindic = TEXT_VAL\n                elif matched.group(11):\n                    val = matched.group(11).strip()\n                    typeindic = TEXT_VAL\n                elif matched.group(12):\n                    val = matched.group(12).strip()\n                    typeindic = UNKNOWN_VAL\n                else:\n                    val = ''\n                    typeindic = UNKNOWN_VAL\n                #prop, val = [ part.strip() for part in U(li.xml_select('string(.)')).split(':', 1) ]\n                #import logging; logging.debug(repr((prop, val)))\n                return prop, val, typeindic\n            return None, None, None\n\n        #Go through each list item\n        for li in field_list:\n            #Is there a nested list, which expresses attributes on a property\n            if list(select_name(li, 'ul')):\n                #main = ''.join([ node.xml_value\n                #        for node in itertools.takewhile(\n                #            lambda x: x.xml_name != 'ul', select_elements(li)\n                #            )\n                #    ])\n                main = ''.join(itertools.takewhile(\n                            lambda x: isinstance(x, text), li.xml_children\n                            ))\n                #main = li.xml_select('string(ul/preceding-sibling::node())')\n                prop, val, typeindic = parse_li(main)\n                subfield_list = [ parse_li(sli.xml_value) for e in select_name(li, 'ul') for sli in (\n                                select_name(e, 'li')\n                                ) ]\n                subfield_list = [ (p, v, t) for (p, v, t) in subfield_list if p is not None ]\n                #Support a special case for syntax such as in the @iri and @interpretations: stanza of @docheader\n                if val is None: val = ''\n                yield prop, val, typeindic, subfield_list\n            #Just a regular, unadorned property\n            else:\n                prop, val, typeindic = parse_li(li.xml_value)\n                if prop: yield prop, val, typeindic, None\n\n    iris = {}\n\n    #Gather the document-level metadata from the @docheader section\n    base = propbase = rtbase = document_iri = default_lang = None\n    for prop, val, typeindic, subfield_list in fields(docheader):\n        #The @iri section is where key IRI prefixes can be set\n        if prop == '@iri':\n            for (k, uri, typeindic) in subfield_list:\n                if k == '@base':\n                    base = propbase = rtbase = uri\n                elif k == '@property':\n                    propbase = uri\n                elif k == '@resource-type':\n                    rtbase = uri\n                else:\n                    iris[k] = uri\n        #The @interpretations section is where defaults can be set as to the primitive types of values from the Markdown, based on the relevant property/relationship\n        elif prop == '@interpretations':\n            #Iterate over items from the @docheader/@interpretations section to set up for further parsing\n            interp = {}\n            for k, v, x in subfield_list:\n                interp[I(iri.absolutize(k, propbase))] = v\n            setup_interpretations(interp)\n        #Setting an IRI for this very document being parsed\n        elif prop == '@document':\n            document_iri = val\n        elif prop == '@language':\n            default_lang = val\n        #If we have a resource to which to attach them, just attach all other properties\n        elif document_iri or base:\n            rid = document_iri or base\n            fullprop = I(iri.absolutize(prop, propbase or base))\n            if fullprop in interpretations:\n                val = interpretations[fullprop](val, rid=rid, fullprop=fullprop, base=base, model=model)\n                if val is not None: model.add(rid, fullprop, val)\n            else:\n                model.add(rid, fullprop, val)\n\n\n    #Default IRI prefixes if @iri/@base is set\n    if not propbase: propbase = base\n    if not rtbase: rtbase = base\n    if not document_iri: document_iri = base\n\n    #Go through the resources expressed in remaining sections\n    for sect in sections:\n        #if U(sect) == '@docheader': continue #Not needed because excluded by ss\n        #The header can take one of 4 forms: \"ResourceID\" \"ResourceID [ResourceType]\" \"[ResourceType]\" or \"[]\"\n        #The 3rd form is for an anonymous resource with specified type and the 4th an anonymous resource with unspecified type\n        matched = RESOURCE_PAT.match(sect.xml_value)\n        if not matched:\n            raise ValueError(_('Syntax error in resource header: {0}'.format(sect.xml_value)))\n        rid = matched.group(1)\n        rtype = matched.group(3)\n        if rtype:\n            rtype = I(iri.absolutize(rtype, base))\n\n        if rid:\n            rid = I(iri.absolutize(rid, base))\n        if not rid:\n            rid = next(idg)\n\n        #Resource type might be set by syntax config\n        if not rtype:\n            rtype = syntaxtypemap.get(sect.xml_name)\n        if rtype:\n            model.add(rid, TYPE_REL, rtype)\n        #Add the property\n        for prop, val, typeindic, subfield_list in fields(sect):\n            attrs = {}\n            for (aprop, aval, atype) in subfield_list or ():\n                if atype == RES_VAL:\n                    valmatch = URI_ABBR_PAT.match(aval)\n                    if valmatch:\n                        uri = iris[valmatch.group(1)]\n                        attrs[aprop] = URI_ABBR_PAT.sub(uri + '\\\\2\\\\3', aval)\n                    else:\n                        attrs[aprop] = I(iri.absolutize(aval, rtbase))\n                elif atype == TEXT_VAL:\n                    attrs[aprop] = aval\n                elif atype == UNKNOWN_VAL:\n                    attrs[aprop] = aval\n                    if aprop in interpretations:\n                        aval = interpretations[aprop](aval, rid=rid, fullprop=aprop, base=base, model=model)\n                        if aval is not None: attrs[aprop] = aval\n                    else:\n                        attrs[aprop] = aval\n            propmatch = URI_ABBR_PAT.match(prop)\n            if propmatch:\n                uri = iris[propmatch.group(1)]\n                fullprop = URI_ABBR_PAT.sub(uri + '\\\\2\\\\3', prop)\n            else:\n                fullprop = I(iri.absolutize(prop, propbase))\n            if typeindic == RES_VAL:\n                valmatch = URI_ABBR_PAT.match(aval)\n                if valmatch:\n                    uri = iris[valmatch.group(1)]\n                    val = URI_ABBR_PAT.sub(uri + '\\\\2\\\\3', val)\n                else:\n                    val = I(iri.absolutize(val, rtbase))\n                model.add(rid, fullprop, val, attrs)\n            elif typeindic == TEXT_VAL:\n                if '@lang' not in attrs: attrs['@lang'] = default_lang\n                model.add(rid, fullprop, val, attrs)\n            elif typeindic == UNKNOWN_VAL:\n                if fullprop in interpretations:\n                    val = interpretations[fullprop](val, rid=rid, fullprop=fullprop, base=base, model=model)\n                    if val is not None: model.add(rid, fullprop, val)\n                else:\n                    model.add(rid, fullprop, val, attrs)\n            #resinfo = AB_RESOURCE_PAT.match(val)\n            #if resinfo:\n            #    val = resinfo.group(1)\n            #    valtype = resinfo.group(3)\n            #    if not val: val = model.generate_resource()\n            #    if valtype: attrs[TYPE_REL] = valtype\n\n    return document_iri", "response": "Translate the Versa Markdown source text into Versa model relationships"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict of all of the necessary components.", "response": "def to_dict(self):\n        \"\"\" \n            Returns a dict of all of it's necessary components.\n            Not the same as the __dict__ method\n        \"\"\"\n        data = dict()\n        data['max_age'] = self.max_age\n        data['cache_dir'] = self.cache_dir\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a pyalveo. OAuth2 given a json string built from the oauth. to_json method.", "response": "def from_json(json_data):\n        \"\"\"\n            Returns a pyalveo.OAuth2 given a json string built from the oauth.to_json() method.\n        \"\"\"\n        #If we have a string, then decode it, otherwise assume it's already decoded\n        if isinstance(json_data, str):\n            data = json.loads(json_data)\n        else:\n            data = json_data\n        oauth = Cache(cache_dir=data.get('cache_dir',None), max_age=data.get('max_age',None))\n        return oauth"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a SQLite3 database for use with Cache objects", "response": "def create_cache_database(self):\n        \"\"\" Create a new SQLite3 database for use with Cache objects\n\n\n        :raises: IOError if there is a problem creating the database file\n\n        \"\"\"\n\n        conn = sqlite3.connect(self.database)\n        conn.text_factory = str\n\n        c = conn.cursor()\n        c.execute(\"\"\"CREATE TABLE items\n                     (url text, metadata text, datetime text)\"\"\")\n        c.execute(\"\"\"CREATE TABLE documents\n                     (url text, path text, datetime text)\"\"\")\n        c.execute(\"\"\"CREATE TABLE primary_texts\n                     (item_url text, primary_text text, datetime text)\"\"\")\n        conn.commit()\n        conn.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __exists_row_not_too_old(self, row):\n        if row is None:\n            return False\n        record_time = dateutil.parser.parse(row[2])\n        now = datetime.datetime.now(dateutil.tz.gettz())\n        age = (record_time - now).total_seconds()\n        if age > self.max_age:\n            return False\n\n        return True", "response": "Check if the given row exists and is not too old"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_item(self, item_url):\n        c = self.conn.cursor()\n        c.execute(\"SELECT * FROM items WHERE url=?\", (str(item_url),))\n        row = c.fetchone()\n        c.close()\n        return self.__exists_row_not_too_old(row)", "response": "Check if the item with the given URL is present in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the content of the given document is present in the cache.", "response": "def has_document(self, doc_url):\n        \"\"\" Check if the content of the given document is present\n        in the cache\n\n        If the max_age attribute of this Cache is set to a nonzero value,\n        entries older than the value of max_age in seconds will be ignored\n\n        :type doc_url: String or Document\n        :param doc_url: the URL of the document, or a Document object\n\n        :rtype: Boolean\n        :returns: True if the data is present, False otherwise\n\n\n        \"\"\"\n        c = self.conn.cursor()\n        c.execute(\"SELECT * FROM documents WHERE url=?\", (str(doc_url),))\n        row = c.fetchone()\n        c.close()\n        return self.__exists_row_not_too_old(row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the content for the given document from the cache.", "response": "def get_document(self, doc_url):\n        \"\"\" Retrieve the content for the given document from the cache.\n\n        :type doc_url: String or Document\n        :param doc_url: the URL of the document, or a Document object\n\n        :rtype: String\n        :returns: the document data\n\n        :raises: ValueError if the item is not in the cache\n\n\n        \"\"\"\n        c = self.conn.cursor()\n        c.execute(\"SELECT * FROM documents WHERE url=?\", (str(doc_url),))\n        row = c.fetchone()\n        c.close()\n        if row is None:\n            raise ValueError(\"Item not present in cache\")\n        file_path = row[1]\n        try:\n            with open(file_path, 'rb') as f:\n                return f.read()\n        except IOError as e:\n            raise IOError(\"Error reading file \" + file_path +\n                          \" to retrieve document \" + doc_url +\n                          \": \" + e.message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the primary text for the given item from the cache.", "response": "def get_primary_text(self, item_url):\n        \"\"\" Retrieve the primary text for the given item from the cache.\n\n        :type item_url: String or Item\n        :param item_url: the URL of the item, or an Item object\n\n        :rtype: String\n        :returns: the primary text\n\n        :raises: ValueError if the primary text is not in the cache\n\n\n        \"\"\"\n        c = self.conn.cursor()\n        c.execute(\"SELECT * FROM primary_texts WHERE item_url=?\",\n                      (str(item_url),))\n        row = c.fetchone()\n        c.close()\n        if row is None:\n            raise ValueError(\"Item not present in cache\")\n        return row[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_item(self, item_url, item_metadata):\n        c = self.conn.cursor()\n        c.execute(\"DELETE FROM items WHERE url=?\", (str(item_url),))\n        self.conn.commit()\n        c.execute(\"INSERT INTO items VALUES (?, ?, ?)\",\n                  (str(item_url), item_metadata, self.__now_iso_8601()))\n        self.conn.commit()\n        c.close()", "response": "Adds the given item to the cache database updating the existing metadata if the item is already present"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __generate_filepath(self):\n        file_path = os.path.join(self.file_dir, str(uuid.uuid4()))\n        if os.path.exists(file_path):\n            warnings.warn(\"something has almost certainly gone wrong\")\n            return self.__generate_filepath()\n        return file_path", "response": "Generate a unique file path within the file_dir directory containing the unique ID of the current class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_document(self, doc_url, data):\n        file_path = self.__generate_filepath()\n        with open(file_path, 'wb') as f:\n            f.write(data)\n\n        c = self.conn.cursor()\n        c.execute(\"SELECT * FROM documents WHERE url=?\", (str(doc_url),))\n        for row in c.fetchall():\n            old_file_path = row[1]\n            if os.path.isfile(old_file_path):\n                os.unlink(old_file_path)\n        c.execute(\"DELETE FROM documents WHERE url=?\", (str(doc_url),))\n        self.conn.commit()\n        c.execute(\"INSERT INTO documents VALUES (?, ?, ?)\",\n                  (str(doc_url), file_path, self.__now_iso_8601()))\n        self.conn.commit()\n        c.close()", "response": "Adds the given document to the cache updating the existing content data if the document is already present"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the given primary text to the cache database updating the existing record if the primary text is already present", "response": "def add_primary_text(self, item_url, primary_text):\n        \"\"\" Add the given primary text to the cache database, updating\n        the existing record if the primary text is already present\n\n        :type item_url: String or Item\n        :param item_url: the URL of the corresponding item, or an Item object\n        :type primary_text: String\n        :param primary_text: the item's primary text\n\n\n        \"\"\"\n        c = self.conn.cursor()\n        c.execute(\"DELETE FROM primary_texts WHERE item_url=?\",\n                      (str(item_url),))\n        self.conn.commit()\n        c.execute(\"INSERT INTO primary_texts VALUES (?, ?, ?)\",\n                  (str(item_url), primary_text, self.__now_iso_8601()))\n        self.conn.commit()\n        c.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def profile(self, ctx, tag):\n        '''Example command for use inside a discord bot cog.'''\n        if not self.check_valid_tag(tag):\n            return await ctx.send('Invalid tag!')\n\n        profile = await self.cr.get_profile(tag)\n\n        em = discord.Embed(color=0x00FFFFF)\n        em.set_author(name=str(profile), icon_url=profile.clan_badge_url)\n        em.set_thumbnail(url=profile.arena.badge_url)\n\n        # Example of adding data. (Bad)\n        for attr in self.cdir(profile):\n            value = getattr(profile, attr) \n            if not callable(value):\n                em.add_field(\n                    name=attr.replace('_').title(), \n                    value=str(value)\n                    )\n\n        await ctx.send(embed=em)", "response": "Example command for use inside a discord bot cog."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_item_metric_pair(item_lst, metric_lst, id_lst):\r\n    query_dic = {}  # key is qid, value is list, whose elements are tuple eg: count of words, bleu score pairs\r\n    for index in range(len(metric_lst)):\r\n        current_id = id_lst[index]\r\n        current_bleu = metric_lst[index]\r\n        current_rank_score = item_lst[index]\r\n        if current_id in query_dic:\r\n            query_dic[current_id].append((current_rank_score, current_bleu))\r\n        else:\r\n            query_dic[current_id] = []\r\n            query_dic[current_id].append((current_rank_score, current_bleu))\r\n    return query_dic", "response": "Returns a list of tuples where each element in the list is the score of the item in the list that is used to rank candidates and each element in the list is the score of the item in the list that is used to rank candidates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef top_x_bleu(query_dic, mark, x=1):\r\n    all_total = 0.0\r\n    with open(top_bleu_path + mark, 'w') as writer:\r\n        for k in query_dic:\r\n            candidate_lst = query_dic[k]\r\n            top_x = sorted(candidate_lst, key=lambda a: a[0], reverse=True)[:x]\r\n            total = 0\r\n            for t in top_x:\r\n                total += t[1]\r\n            ave_bleu = total / x\r\n            writer.write('%s\\tAverageBleu:%f\\tTop%d:%s\\n' % (k, ave_bleu, x, str(top_x)))\r\n\r\n            all_total += ave_bleu\r\n            if k in contrast_dic:\r\n                contrast_dic[k].append(str(ave_bleu))\r\n            else:\r\n                contrast_dic[k] = []\r\n                contrast_dic[k].append(str(ave_bleu))\r\n    result_string = '%s\\ttop%d_Bleu:\\t%f' % (mark, x, all_total / len(query_dic))\r\n    print result_string\r\n    # eval_result_dict['Bleu'].append(result_string)\r\n    return ['Bleu', result_string]", "response": "Calculates the top x average bleu value predictions ranking by item x default is set above"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kendall_tau(query_dic, mark):\r\n    total = 0.0\r\n    with open(kendall_tau_path + mark, 'w') as writer:\r\n        for k in query_dic:\r\n            candidate_lst = query_dic[k]\r\n            ordered_lst = sorted(candidate_lst, key=lambda a: a[0], reverse=True)\r\n            rank_lst = [can[1] for can in ordered_lst]\r\n            tau_value = calculate_lst_kendall(rank_lst)\r\n            writer.write('%s %f\\n' % (k, tau_value))\r\n            total += tau_value\r\n    result_string = '%s\\tkendall_tau:\\t%f' % (mark, total / len(query_dic))\r\n    print result_string\r\n    # eval_result_dict['Kendall'].append(result_string)\r\n    return ['Kendall', result_string]", "response": "Calculate kendall_tau metric result of a method\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the METEOR score of the top x meteor of the list of items in query_dic", "response": "def top_x_meteor(query_dic, mark, x=1):\r\n    \"\"\"\r\n    Calculate METEOR score of the top result\r\n    :param query_dic: dict, key is qid, value is (item, meteor) tuple list, which will be ranked by 'item' as key\r\n    :param mark: string, which indicates which method is evaluated, also used as output file name here.\r\n    :param x: int, define top x\r\n    :return: average meteor score\r\n    \"\"\"\r\n    all_total = 0.0\r\n    with open(top_meteor_path + mark, 'w') as writer:\r\n        for k in query_dic:\r\n            candidate_lst = query_dic[k]\r\n            top_x = sorted(candidate_lst, key=lambda a: a[0], reverse=True)[:x]\r\n            total = 0\r\n            for t in top_x:\r\n                total += t[1]\r\n            ave_value = total / x\r\n            writer.write('%s\\tAverageBleu:%f\\tTop%d:%s\\n' % (k, ave_value, x, str(top_x)))\r\n\r\n            all_total += ave_value\r\n\r\n            # for debug below here\r\n            if k in contrast_dic:\r\n                contrast_dic[k].append(str(ave_value))\r\n            else:\r\n                contrast_dic[k] = []\r\n                contrast_dic[k].append(str(ave_value))\r\n    result_string = '%s\\ttop%d_METEOR:\\t%f' % (mark, x, all_total / len(query_dic))\r\n    print result_string\r\n    # eval_result_dict['METEOR'].append(result_string)\r\n    return ['METEOR', result_string]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dict of container_ships that will be used to create the container_ships for the given hosts.", "response": "def _create_container_ships(self, hosts):\n        \"\"\"\n        :param hosts:\n        :return:\n        \"\"\"\n        container_ships = {}\n\n        if hosts:\n            if 'default' not in hosts:\n                default_container_ship     = self._create_container_ship(None)\n                container_ships['default'] = {default_container_ship.url.geturl(): default_container_ship}\n\n            for alias, hosts in six.iteritems(hosts):\n                if hosts is None:\n                    container_ships[alias] = hosts\n                elif isinstance(hosts, list):\n                    container_ships[alias] = {}\n\n                    for host in hosts:\n                        if not host or not isinstance(host, dict):\n                            raise ValueError(\"hosts: {0} is required to be a dict.\".format(alias))\n\n                        existing_container_ship = None\n\n                        for container_ship_dict in six.itervalues(container_ships):\n\n                            for address, container_ship in six.iteritems(container_ship_dict):\n                                if address == host.get('address') and address not in container_ships[alias]:\n                                    existing_container_ship = container_ship\n                                    break\n\n                        if existing_container_ship is None:\n                            container_ships[alias][host.get('address')] = self._create_container_ship(host)\n                        else:\n                            container_ships[alias][host.get('address')] = existing_container_ship\n                else:\n                    raise ValueError(logger.error(\"hosts is required to be a list or None. host: {0}\".format(hosts)))\n\n        else:\n            default_container_ship     = self._create_container_ship(None)\n            container_ships['default'] = {default_container_ship.url.geturl(): default_container_ship}\n\n        return container_ships"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new container ship object from the given host data.", "response": "def _create_container_ship(self, host_data=None):\n        \"\"\"\n            # docker env vars. We use them if nothing is supplied.\n            DOCKER_HOST=fqdn:port\n            DOCKER_TLS_VERIFY=false\n            DOCKER_CERT_PATH=/path/\n        \"\"\"\n        if not host_data:\n            host_data = {}\n            path = os.getenv('DOCKER_CERT_PATH')\n            host_data['address'] = os.getenv('DOCKER_HOST')\n\n            if not host_data:\n                raise LookupError(\n                    logger.error(\"Unable to find docker ENV var: DOCKER_HOST, DOCKER_CERT_PATH, and DOCKER_TLS_VERIFY are required.\")\n                )\n\n            if not host_data.get('address'):\n                raise LookupError(logger.error(\"Unable to find a value for DOCKER_HOST.\"))\n\n            if 'tcp://' in host_data['address']:\n                host_data['address'] = host_data['address'].replace('tcp://', 'https://')\n\n            host_data['ssl_cert_path'] = os.path.realpath(path)\n            host_data['verify']        = os.getenv('DOCKER_TLS_VERIFY')\n\n            if host_data['verify'] == 'yes':\n                host_data['verify'] = True\n            elif host_data['verify'] == 'no':\n                host_data['verify'] = False\n\n        return ContainerShip(\n            host_data.get('address'),\n            services=host_data.get('services'),\n            ssl_cert_path=host_data.get('ssl_cert_path'),\n            verify=host_data.get('verify')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dataframe_row(self, dataset_cases, predicted_data, pdb_data, record_id, additional_prediction_data_columns):\n        '''Create a dataframe row for a prediction.'''\n        record = dataset_cases[record_id]\n        for m in record['PDBMutations']:\n            assert('DSSPSimpleSSType' not in m)\n            m['DSSPSimpleSSType'] = dssp_elision.get(m['ComplexDSSP']) or dssp_elision.get(m['MonomericDSSP'])\n            m['DSSPType'] = m.get('ComplexDSSP') or m.get('MonomericDSSP')\n            m['DSSPExposure'] = m.get('ComplexExposure') or m.get('MonomericExposure')\n\n        dataframe_record = super(DBBenchmarkRun, self).get_dataframe_row(dataset_cases, predicted_data, pdb_data, record_id, additional_prediction_data_columns)\n        # add columns\n        return dataframe_record", "response": "Create a dataframe row for a prediction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes all required stats handling", "response": "def init_stats(output_dir, config):\n    \"\"\"Init all required ressources for stats handling\n    :param str output_dir: the output directory for the results\n    :param dict config: the project configuration\n    \"\"\"\n\n    try:\n        os.makedirs(output_dir, 0o755)\n    except OSError as e:\n        print(\"ERROR: Can not create output directory: %s\\n\" % e)\n        raise\n\n    db_uri = get_db_uri(config, output_dir)\n\n    set_database(db_uri, db, config)\n\n    tables_to_create = [t for t in [Result, Turret] if not t.table_exists()]\n\n    db.get_conn()\n    db.create_tables(tables_to_create)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_result(self, data):\n        data['custom_timers'] = ujson.dumps(data['custom_timers'])\n        self.results.append(data)\n\n        if len(self.results) >= 150:  # 150 rows for SQLite default limit\n            with db.execution_context():\n                with db.atomic():\n                    Result.insert_many(self.results).execute()\n                del self.results[:]", "response": "Write the results received to the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_remaining(self):\n        if not self.results:\n            return\n        with db.execution_context():\n            with db.atomic():\n                Result.insert_many(self.results).execute()\n        del self.results[:]", "response": "Write the remaining content to the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the configuration of the test and return it as a config object", "response": "def configure(project_path, config_file=None):\n    \"\"\"Get the configuration of the test and return it as a config object\n\n    :return: the configured config object\n    :rtype: Object\n    \"\"\"\n    if config_file is None:\n        config_file = os.path.join(project_path, 'config.json')\n    try:\n        with open(config_file, 'r') as f:\n            config = json.load(f)\n    except ValueError as e:\n        raise OctConfigurationError(\"Configuration setting failed with error: %s\" % e)\n    for key in REQUIRED_CONFIG_KEYS:\n        if key not in config:\n            raise OctConfigurationError(\"Error: the required configuration key %s is not define\" % key)\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure_for_turret(project_name, config_file):\n    config = configure(project_name, config_file)\n    for key in WARNING_CONFIG_KEYS:\n        if key not in config:\n            print(\"WARNING: %s configuration key not present, the value will be set to default value\" % key)\n    common_config = {\n        'hq_address': config.get('hq_address', '127.0.0.1'),\n        'hq_publisher': config.get('publish_port', 5000),\n        'hq_rc': config.get('rc_port', 5001),\n        'turrets_requirements': config.get('turrets_requirements', [])\n    }\n    configs = []\n    for turret in config['turrets']:\n        if isinstance(turret, six.string_types):\n            turret = load_turret_config(project_name, turret)\n        turret.update(common_config)\n        turret.update(config.get('extra_turret_config', {}))\n        configs.append(turret)\n    return configs", "response": "Load the configuration file and check for keys that will be set to default value if not present"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_db_uri(config, output_dir):\n    db_config = config.get(\"results_database\", {\"db_uri\": \"default\"})\n    if db_config['db_uri'] == 'default':\n        return os.path.join(output_dir, \"results.sqlite\")\n    return db_config['db_uri']", "response": "Process results_database parameters in config to format them for\n    set database"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds an element in the document with the given name.", "response": "def find_element(self, name, type=ElementType.ANY):\n        \"\"\"Find an elemnent in the document with the given name - could be a PartStudio, Assembly or blob.\n\n        Args:\n            name: str\n                the name of the element.\n\n        Returns:\n            - onshapepy.uri of the element\n        \"\"\"\n\n        for e in self.e_list:\n            # if a type is specified and this isn't it, move to the next loop.\n            if type.value and not e['elementType'] == type:\n                continue\n            if e[\"name\"] == name:\n                uri = self.uri\n                uri.eid = e[\"id\"]\n                return uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef beta(C, HIGHSCALE, newphys=True):\n\n    g = C[\"g\"]\n    gp = C[\"gp\"]\n    gs = C[\"gs\"]\n    m2 = C[\"m2\"]\n    Lambda = C[\"Lambda\"]\n    Gu = C[\"Gu\"]\n    Gd = C[\"Gd\"]\n    Ge = C[\"Ge\"]\n\n\n    Eta1 = (3*np.trace(C[\"uphi\"] @ Gu.conj().T) \\\n      + 3*np.trace(C[\"dphi\"] @ Gd.conj().T) \\\n      + np.trace(C[\"ephi\"] @ Ge.conj().T) \\\n      + 3*np.conj(np.trace(C[\"uphi\"] @ Gu.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"dphi\"] @ Gd.conj().T)) \\\n      + np.conj(np.trace(C[\"ephi\"] @ Ge.conj().T)))/2\n    Eta2 = -6*np.trace(C[\"phiq3\"] @ Gu @ Gu.conj().T) \\\n      - 6*np.trace(C[\"phiq3\"] @ Gd @ Gd.conj().T) \\\n      - 2*np.trace(C[\"phil3\"] @ Ge @ Ge.conj().T) \\\n      + 3*(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu) \\\n      + np.conj(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu)))\n    Eta3 = 3*np.trace(C[\"phiq1\"] @ Gd @ Gd.conj().T) \\\n      - 3*np.trace(C[\"phiq1\"] @ Gu @ Gu.conj().T) \\\n      + 9*np.trace(C[\"phiq3\"] @ Gd @ Gd.conj().T) \\\n      + 9*np.trace(C[\"phiq3\"] @ Gu @ Gu.conj().T) \\\n      + 3*np.trace(C[\"phiu\"] @ Gu.conj().T @ Gu) \\\n      - 3*np.trace(C[\"phid\"] @ Gd.conj().T @ Gd) \\\n      - 3*(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu) \\\n      + np.conj(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu))) \\\n      + np.trace(C[\"phil1\"] @ Ge @ Ge.conj().T) \\\n      + 3*np.trace(C[\"phil3\"] @ Ge @ Ge.conj().T) \\\n      - np.trace(C[\"phie\"] @ Ge.conj().T @ Ge)\n    Eta4 = 12*np.trace(C[\"phiq1\"] @ Gd @ Gd.conj().T) \\\n      - 12*np.trace(C[\"phiq1\"] @ Gu @ Gu.conj().T) \\\n      + 12*np.trace(C[\"phiu\"] @ Gu.conj().T @ Gu) \\\n      - 12*np.trace(C[\"phid\"] @ Gd.conj().T @ Gd) \\\n      + 6*(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu) \\\n      + np.conj(np.trace(C[\"phiud\"] @ Gd.conj().T @ Gu))) \\\n      + 4*np.trace(C[\"phil1\"] @ Ge @ Ge.conj().T) \\\n      - 4*np.trace(C[\"phie\"] @ Ge.conj().T @ Ge)\n    Eta5 = 1j*3/2*(np.trace(Gd @ C[\"dphi\"].conj().T) \\\n      - np.conj(np.trace(Gd @ C[\"dphi\"].conj().T))) \\\n      - 1j*3/2*(np.trace(Gu @ C[\"uphi\"].conj().T) \\\n      - np.conj(np.trace(Gu @ C[\"uphi\"].conj().T))) \\\n      + 1j*1/2*(np.trace(Ge @ C[\"ephi\"].conj().T) \\\n      - np.conj(np.trace(Ge @ C[\"ephi\"].conj().T)))\n\n    GammaH = np.trace(3*Gu @ Gu.conj().T + 3*Gd @ Gd.conj().T + Ge @ Ge.conj().T)\n    Gammaq = 1/2*(Gu @ Gu.conj().T + Gd @ Gd.conj().T)\n    Gammau = Gu.conj().T @ Gu\n    Gammad = Gd.conj().T @ Gd\n    Gammal = 1/2*Ge @ Ge.conj().T\n    Gammae = Ge.conj().T @ Ge\n\n    Beta = OrderedDict()\n\n    Beta[\"g\"] = -19/6*g**3 - 8*g*m2/HIGHSCALE**2*C[\"phiW\"]\n\n    Beta[\"gp\"] = 41/6*gp**3  - 8*gp*m2/HIGHSCALE**2*C[\"phiB\"]\n\n    Beta[\"gs\"] = -7*gs**3  - 8*gs*m2/HIGHSCALE**2*C[\"phiG\"]\n\n    Beta[\"Lambda\"] = 12*Lambda**2 \\\n      + 3/4*gp**4 + 3/2*g**2*gp**2 + 9/4*g**4 - 3*(gp**2 + 3*g**2)*Lambda \\\n      + 4*Lambda*GammaH \\\n      - 4*(3*np.trace(Gd @ Gd.conj().T @ Gd @ Gd.conj().T) \\\n      + 3*np.trace(Gu @ Gu.conj().T @ Gu @ Gu.conj().T) \\\n      + np.trace(Ge @ Ge.conj().T @ Ge @ Ge.conj().T)) \\\n      + 4*m2/HIGHSCALE**2*(12*C[\"phi\"] \\\n      + (-16*Lambda + 10/3*g**2)*C[\"phiBox\"] \\\n      + (6*Lambda + 3/2*(gp**2 - g**2))*C[\"phiD\"] \\\n      + 2*(Eta1 + Eta2) \\\n      + 9*g**2*C[\"phiW\"] \\\n      + 3*gp**2*C[\"phiB\"] \\\n      + 3*g*gp*C[\"phiWB\"] \\\n      + 4/3*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])))\n\n    Beta[\"m2\"] = m2*(6*Lambda - 9/2*g**2 - 3/2*gp**2 \\\n      + 2*GammaH + 4*m2/HIGHSCALE**2*(C[\"phiD\"] \\\n      - 2*C[\"phiBox\"]))\n\n    Beta[\"Gu\"] = 3/2*(Gu @ Gu.conj().T @ Gu - Gd @ Gd.conj().T @ Gu) \\\n      + (GammaH - 9/4*g**2 - 17/12*gp**2 - 8*gs**2)*Gu \\\n      + 2*m2/HIGHSCALE**2*(3*C[\"uphi\"] \\\n      + 1/2*(C[\"phiD\"] - 2*C[\"phiBox\"])*Gu \\\n      - C[\"phiq1\"].conj().T @ Gu \\\n      + 3*C[\"phiq3\"].conj().T @ Gu \\\n      + Gu @ C[\"phiu\"].conj().T \\\n      - Gd @ C[\"phiud\"].conj().T \\\n      - 2*(my_einsum(\"rpts,pt\", C[\"qu1\"], Gu) \\\n      + 4/3*my_einsum(\"rpts,pt\", C[\"qu8\"], Gu)) \\\n      - my_einsum(\"ptrs,pt\", C[\"lequ1\"], np.conj(Ge)) \\\n      + 3*my_einsum(\"rspt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 1/2*(my_einsum(\"psrt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 4/3*my_einsum(\"psrt,pt\", C[\"quqd8\"], np.conj(Gd))))\n\n    Beta[\"Gd\"] = 3/2*(Gd @ Gd.conj().T @ Gd - Gu @ Gu.conj().T @ Gd) \\\n      + (GammaH - 9/4*g**2 - 5/12*gp**2 - 8*gs**2)*Gd \\\n      + 2*m2/HIGHSCALE**2*(3*C[\"dphi\"] + 1/2*(C[\"phiD\"] \\\n      - 2*C[\"phiBox\"])*Gd \\\n      + C[\"phiq1\"].conj().T @ Gd \\\n      + 3*C[\"phiq3\"].conj().T @ Gd \\\n      - Gd @ C[\"phid\"].conj().T \\\n      - Gu @ C[\"phiud\"] \\\n      - 2*(my_einsum(\"rpts,pt\", C[\"qd1\"], Gd) \\\n      + 4/3*my_einsum(\"rpts,pt\", C[\"qd8\"], Gd)) \\\n      + my_einsum(\"ptsr,pt\", np.conj(C[\"ledq\"]), Ge) \\\n      + 3*my_einsum(\"ptrs,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 1/2*(my_einsum(\"rpts,tp\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 4/3*my_einsum(\"rpts,tp\", C[\"quqd8\"], np.conj(Gu))))\n\n    Beta[\"Ge\"] = 3/2*Ge @ Ge.conj().T @ Ge + (GammaH \\\n      - 3/4*(3*g**2 + 5*gp**2))*Ge + 2*m2/HIGHSCALE**2*(3*C[\"ephi\"] \\\n      + 1/2*(C[\"phiD\"] - 2*C[\"phiBox\"])*Ge \\\n      + C[\"phil1\"].conj().T @ Ge \\\n      + 3*C[\"phil3\"].conj().T @ Ge \\\n      - Ge @ C[\"phie\"].conj().T \\\n      - 2*my_einsum(\"rpts,pt\", C[\"le\"], Ge) \\\n      + 3*my_einsum(\"rspt,tp\", C[\"ledq\"], Gd) \\\n      - 3*my_einsum(\"rspt,pt\", C[\"lequ1\"], np.conj(Gu)))\n\n    Beta[\"Theta\"] = -128*np.pi**2/g**2*m2/HIGHSCALE**2*C[\"phiWtilde\"]\n\n    Beta[\"Thetap\"] = -128*np.pi**2/gp**2*m2/HIGHSCALE**2*C[\"phiBtilde\"]\n\n    Beta[\"Thetas\"] = -128*np.pi**2/gs**2*m2/HIGHSCALE**2*C[\"phiGtilde\"]\n\n    if not newphys:\n        # if there is no new physics, generate a dictionary with zero\n        # Wilson coefficients (i.e. zero beta functions)\n        BetaSM = C_array2dict(np.zeros(5000))\n        BetaSM.update(Beta)\n        return BetaSM\n\n\n    XiB = 2/3*(C[\"phiBox\"] + C[\"phiD\"]) \\\n      + 8/3*( - np.trace(C[\"phil1\"]) + np.trace(C[\"phiq1\"]) \\\n      - np.trace(C[\"phie\"]) \\\n      + 2*np.trace(C[\"phiu\"]) - np.trace(C[\"phid\"]))\n    Xie = 2*my_einsum(\"prst,rs\", C[\"le\"], Ge) \\\n      - 3*my_einsum(\"ptsr,rs\", C[\"ledq\"], Gd) \\\n      + 3*my_einsum(\"ptsr,sr\", C[\"lequ1\"], np.conj(Gu))\n    Xid = 2*(my_einsum(\"prst,rs\", C[\"qd1\"], Gd) \\\n      + 4/3*my_einsum(\"prst,rs\", C[\"qd8\"], Gd)) \\\n      - (3*my_einsum(\"srpt,sr\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 1/2*(my_einsum(\"prst,sr\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 4/3*my_einsum(\"prst,sr\", C[\"quqd8\"], np.conj(Gu)))) \\\n      - my_einsum(\"srtp,sr\", np.conj(C[\"ledq\"]), Ge)\n    Xiu = 2*(my_einsum(\"prst,rs\", C[\"qu1\"], Gu) \\\n      + 4/3*my_einsum(\"prst,rs\", C[\"qu8\"], Gu)) \\\n      - (3*my_einsum(\"ptsr,sr\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 1/2*(my_einsum(\"stpr,sr\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 4/3*my_einsum(\"stpr,sr\", C[\"quqd8\"], np.conj(Gd)))) \\\n      + my_einsum(\"srpt,sr\", C[\"lequ1\"], np.conj(Ge))\n\n    Beta[\"G\"] = 15*gs**2*C[\"G\"]\n\n    Beta[\"Gtilde\"] = 15*gs**2*C[\"Gtilde\"]\n\n    Beta[\"W\"] = 29/2*g**2*C[\"W\"]\n\n    Beta[\"Wtilde\"] = 29/2*g**2*C[\"Wtilde\"]\n\n    #c.c.\n    Beta[\"phi\"] = -9/2*(3*g**2 \\\n      + gp**2)*C[\"phi\"] \\\n      + Lambda*(20/3*g**2*C[\"phiBox\"] \\\n      + 3*(gp**2 \\\n      - g**2)*C[\"phiD\"]) \\\n      - 3/4*(g**2 \\\n      + gp**2)**2*C[\"phiD\"] \\\n      + 6*Lambda*(3*g**2*C[\"phiW\"] \\\n      + gp**2*C[\"phiB\"] \\\n      + g*gp*C[\"phiWB\"]) \\\n      - 3*(g**2*gp**2 \\\n      + 3*g**4)*C[\"phiW\"] \\\n      - 3*(gp**4 \\\n      + g**2*gp**2)*C[\"phiB\"] \\\n      - 3*(g*gp**3 \\\n      + g**3*gp)*C[\"phiWB\"] \\\n      + 8/3*Lambda*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])) \\\n      + 54*Lambda*C[\"phi\"] \\\n      - 40*Lambda**2*C[\"phiBox\"] \\\n      + 12*Lambda**2*C[\"phiD\"] \\\n      + 4*Lambda*(Eta1 \\\n      + Eta2) \\\n      - 4*(3*np.trace(C[\"uphi\"] @ Gu.conj().T @ Gu @ Gu.conj().T) \\\n      + 3*np.trace(C[\"dphi\"] @ Gd.conj().T @ Gd @ Gd.conj().T) \\\n      + np.trace(C[\"ephi\"] @ Ge.conj().T @ Ge @ Ge.conj().T) \\\n      + 3*np.conj(np.trace(C[\"uphi\"] @ Gu.conj().T @ Gu @ Gu.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"dphi\"] @ Gd.conj().T @ Gd @ Gd.conj().T)) \\\n      + np.conj(np.trace(C[\"ephi\"] @ Ge.conj().T @ Ge @ Ge.conj().T))) \\\n      + 6*GammaH*C[\"phi\"]\n\n    Beta[\"phiBox\"] = -(4*g**2 \\\n      + 4/3*gp**2)*C[\"phiBox\"] \\\n      + 5/3*gp**2*C[\"phiD\"] \\\n      + 2*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])) \\\n      + 2/3*gp**2*(2*np.trace(C[\"phiu\"]) \\\n      - np.trace(C[\"phid\"]) \\\n      - np.trace(C[\"phie\"]) \\\n      + np.trace(C[\"phiq1\"]) \\\n      - np.trace(C[\"phil1\"])) \\\n      + 12*Lambda*C[\"phiBox\"] \\\n      - 2*Eta3 \\\n      + 4*GammaH*C[\"phiBox\"]\n\n    Beta[\"phiD\"] = 20/3*gp**2*C[\"phiBox\"] \\\n      + (9/2*g**2 \\\n      - 5/6*gp**2)*C[\"phiD\"] \\\n      + 8/3*gp**2*(2*np.trace(C[\"phiu\"]) \\\n      - np.trace(C[\"phid\"]) \\\n      - np.trace(C[\"phie\"]) \\\n      + np.trace(C[\"phiq1\"]) \\\n      - np.trace(C[\"phil1\"])) \\\n      + 6*Lambda*C[\"phiD\"] \\\n      - 2*Eta4 \\\n      + 4*GammaH*C[\"phiD\"]\n\n    #c.c.\n    Beta[\"phiG\"] = (-3/2*gp**2 \\\n      - 9/2*g**2 \\\n      - 14*gs**2)*C[\"phiG\"] \\\n      + 6*Lambda*C[\"phiG\"] \\\n      - 2*gs*(np.trace(C[\"uG\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dG\"] @ Gd.conj().T) \\\n      + np.conj(np.trace(C[\"uG\"] @ Gu.conj().T)) \\\n      + np.conj(np.trace(C[\"dG\"] @ Gd.conj().T))) \\\n      + 2*GammaH*C[\"phiG\"]\n\n    #c.c.\n    Beta[\"phiB\"] = (85/6*gp**2 \\\n      - 9/2*g**2)*C[\"phiB\"] \\\n      + 3*g*gp*C[\"phiWB\"] \\\n      + 6*Lambda*C[\"phiB\"] \\\n      + gp*( \\\n      - 5*np.trace(C[\"uB\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dB\"] @ Gd.conj().T) \\\n      + 3*np.trace(C[\"eB\"] @ Ge.conj().T) \\\n      - 5*np.conj(np.trace(C[\"uB\"] @ Gu.conj().T)) \\\n      + np.conj(np.trace(C[\"dB\"] @ Gd.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"eB\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiB\"]\n\n    #c.c.\n    Beta[\"phiW\"] = (-3/2*gp**2 \\\n      - 53/6*g**2)*C[\"phiW\"] \\\n      + g*gp*C[\"phiWB\"] \\\n      - 15*g**3*C[\"W\"] \\\n      + 6*Lambda*C[\"phiW\"] \\\n      - g*(3*np.trace(C[\"uW\"] @ Gu.conj().T) \\\n      + 3*np.trace(C[\"dW\"] @ Gd.conj().T) \\\n      + np.trace(C[\"eW\"] @ Ge.conj().T) \\\n      + 3*np.conj(np.trace(C[\"uW\"] @ Gu.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"dW\"] @ Gd.conj().T)) \\\n      + np.conj(np.trace(C[\"eW\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiW\"]\n\n    #c.c.\n    Beta[\"phiWB\"] = (19/3*gp**2 \\\n      + 4/3*g**2)*C[\"phiWB\"] \\\n      + 2*g*gp*(C[\"phiB\"] \\\n      + C[\"phiW\"]) \\\n      + 3*g**2*gp*C[\"W\"] \\\n      + 2*Lambda*C[\"phiWB\"] \\\n      + g*(3*np.trace(C[\"uB\"] @ Gu.conj().T) \\\n      - 3*np.trace(C[\"dB\"] @ Gd.conj().T) \\\n      - np.trace(C[\"eB\"] @ Ge.conj().T) \\\n      + 3*np.conj(np.trace(C[\"uB\"] @ Gu.conj().T)) \\\n      - 3*np.conj(np.trace(C[\"dB\"] @ Gd.conj().T)) \\\n      - np.conj(np.trace(C[\"eB\"] @ Ge.conj().T))) \\\n      + gp*(5*np.trace(C[\"uW\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dW\"] @ Gd.conj().T) \\\n      + 3*np.trace(C[\"eW\"] @ Ge.conj().T) \\\n      + 5*np.conj(np.trace(C[\"uW\"] @ Gu.conj().T)) \\\n      + np.conj(np.trace(C[\"dW\"] @ Gd.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"eW\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiWB\"]\n\n    #problem with i as I*iCPV\n    Beta[\"phiGtilde\"] = (-3/2*gp**2 \\\n      - 9/2*g**2 \\\n      - 14*gs**2)*C[\"phiGtilde\"] \\\n      + 6*Lambda*C[\"phiGtilde\"] \\\n      + 2j*gs*(np.trace(C[\"uG\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dG\"] @ Gd.conj().T) \\\n      - np.conj(np.trace(C[\"uG\"] @ Gu.conj().T)) \\\n      - np.conj(np.trace(C[\"dG\"] @ Gd.conj().T))) \\\n      + 2*GammaH*C[\"phiGtilde\"]\n\n    #i\n    Beta[\"phiBtilde\"] = (85/6*gp**2 \\\n      - 9/2*g**2)*C[\"phiBtilde\"] \\\n      + 3*g*gp*C[\"phiWtildeB\"] \\\n      + 6*Lambda*C[\"phiBtilde\"] \\\n      - 1j*gp*( \\\n      - 5*np.trace(C[\"uB\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dB\"] @ Gd.conj().T) \\\n      + 3*np.trace(C[\"eB\"] @ Ge.conj().T) \\\n      + 5*np.conj(np.trace(C[\"uB\"] @ Gu.conj().T)) \\\n      - np.conj(np.trace(C[\"dB\"] @ Gd.conj().T)) \\\n      - 3*np.conj(np.trace(C[\"eB\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiBtilde\"]\n\n    #i\n    Beta[\"phiWtilde\"] = (-3/2*gp**2 \\\n      - 53/6*g**2)*C[\"phiWtilde\"] \\\n      + g*gp*C[\"phiWtildeB\"] \\\n      - 15*g**3*C[\"Wtilde\"] \\\n      + 6*Lambda*C[\"phiWtilde\"] \\\n      + 1j*g*(3*np.trace(C[\"uW\"] @ Gu.conj().T) \\\n      + 3*np.trace(C[\"dW\"] @ Gd.conj().T) \\\n      + np.trace(C[\"eW\"] @ Ge.conj().T) \\\n      - 3*np.conj(np.trace(C[\"uW\"] @ Gu.conj().T)) \\\n      - 3*np.conj(np.trace(C[\"dW\"] @ Gd.conj().T)) \\\n      - np.conj(np.trace(C[\"eW\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiWtilde\"]\n\n    #i\n    Beta[\"phiWtildeB\"] = (19/3*gp**2 \\\n      + 4/3*g**2)*C[\"phiWtildeB\"] \\\n      + 2*g*gp*(C[\"phiBtilde\"] \\\n      + C[\"phiWtilde\"]) \\\n      + 3*g**2*gp*C[\"Wtilde\"] \\\n      + 2*Lambda*C[\"phiWtildeB\"] \\\n      - 1j*g*(3*np.trace(C[\"uB\"] @ Gu.conj().T) \\\n      - 3*np.trace(C[\"dB\"] @ Gd.conj().T) \\\n      - np.trace(C[\"eB\"] @ Ge.conj().T) \\\n      - 3*np.conj(np.trace(C[\"uB\"] @ Gu.conj().T)) \\\n      + 3*np.conj(np.trace(C[\"dB\"] @ Gd.conj().T)) \\\n      + np.conj(np.trace(C[\"eB\"] @ Ge.conj().T))) \\\n      - 1j*gp*(5*np.trace(C[\"uW\"] @ Gu.conj().T) \\\n      + np.trace(C[\"dW\"] @ Gd.conj().T) \\\n      + 3*np.trace(C[\"eW\"] @ Ge.conj().T) \\\n      - 5*np.conj(np.trace(C[\"uW\"] @ Gu.conj().T)) \\\n      - np.conj(np.trace(C[\"dW\"] @ Gd.conj().T)) \\\n      - 3*np.conj(np.trace(C[\"eW\"] @ Ge.conj().T))) \\\n      + 2*GammaH*C[\"phiWtildeB\"]\n\n    \"\"\"(3,3)\"\"\"\n    #i  #the coefficients of Eta5 is not equal\n    Beta[\"uphi\"] = (10/3*g**2*C[\"phiBox\"] \\\n      + 3/2*(gp**2 \\\n      - g**2)*C[\"phiD\"] \\\n      + 32*gs**2*(C[\"phiG\"] \\\n      + 1j*C[\"phiGtilde\"]) \\\n      + 9*g**2*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      + 17/3*gp**2*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]) \\\n      - g*gp*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      + 4/3*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])))*Gu \\\n      - (35/12*gp**2 \\\n      + 27/4*g**2 \\\n      + 8*gs**2)*C[\"uphi\"] \\\n      - gp*(5*gp**2 \\\n      - 3*g**2)*C[\"uB\"] \\\n      + g*(5*gp**2 \\\n      - 9*g**2)*C[\"uW\"] \\\n      - (3*g**2 \\\n      - gp**2)*Gu @ C[\"phiu\"] \\\n      + 3*g**2*Gd @ C[\"phiud\"].conj().T \\\n      + 4*gp**2*C[\"phiq1\"] @ Gu \\\n      - 4*gp**2*C[\"phiq3\"] @ Gu \\\n      - 5*gp*(C[\"uB\"] @ Gu.conj().T @ Gu \\\n      + Gu @ Gu.conj().T @ C[\"uB\"]) \\\n      - 3*g*(C[\"uW\"] @ Gu.conj().T @ Gu \\\n      - Gu @ Gu.conj().T @ C[\"uW\"]) \\\n      - 16*gs*(C[\"uG\"] @ Gu.conj().T @ Gu \\\n      + Gu @ Gu.conj().T @ C[\"uG\"]) \\\n      - 12*g*Gd @ Gd.conj().T @ C[\"uW\"] \\\n      - 6*g*C[\"dW\"] @ Gd.conj().T @ Gu \\\n      + Lambda*(12*C[\"uphi\"] \\\n      - 2*C[\"phiq1\"] @ Gu \\\n      + 6*C[\"phiq3\"] @ Gu \\\n      + 2*Gu @ C[\"phiu\"] \\\n      - 2*Gd @ C[\"phiud\"].conj().T \\\n      - 2*C[\"phiBox\"]*Gu \\\n      + C[\"phiD\"]*Gu \\\n      - 4*my_einsum(\"rpts,pt\", C[\"qu1\"], Gu) \\\n      - 16/3*my_einsum(\"rpts,pt\", C[\"qu8\"], Gu) \\\n      - 2*my_einsum(\"ptrs,pt\", C[\"lequ1\"], np.conj(Ge)) \\\n      + 6*my_einsum(\"rspt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + my_einsum(\"psrt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 4/3*my_einsum(\"psrt,pt\", C[\"quqd8\"], np.conj(Gd))) \\\n      + 2*(Eta1 \\\n      + Eta2 \\\n      - 1j*Eta5)*Gu \\\n      + (C[\"phiD\"] \\\n      - 6*C[\"phiBox\"])*Gu @ Gu.conj().T @ Gu \\\n      - 2*C[\"phiq1\"] @ Gu @ Gu.conj().T @ Gu \\\n      + 6*C[\"phiq3\"] @ Gd @ Gd.conj().T @ Gu \\\n      + 2*Gu @ Gu.conj().T @ Gu @ C[\"phiu\"] \\\n      - 2*Gd @ Gd.conj().T @ Gd @ C[\"phiud\"].conj().T \\\n      + 8*(my_einsum(\"rpts,pt\", C[\"qu1\"], Gu @ Gu.conj().T @ Gu) \\\n      + 4/3*my_einsum(\"rpts,pt\", C[\"qu8\"], Gu @ Gu.conj().T @ Gu)) \\\n      - 2*(my_einsum(\"tsrp,pt\", C[\"quqd1\"], Gd.conj().T @ Gd @ Gd.conj().T) \\\n      + 4/3*my_einsum(\"tsrp,pt\", C[\"quqd8\"], Gd.conj().T @ Gd @ Gd.conj().T)) \\\n      - 12*my_einsum(\"rstp,pt\", C[\"quqd1\"], Gd.conj().T @ Gd @ Gd.conj().T) \\\n      + 4*my_einsum(\"tprs,pt\", C[\"lequ1\"], Ge.conj().T @ Ge @ Ge.conj().T) \\\n      + 4*C[\"uphi\"] @ Gu.conj().T @ Gu \\\n      + 5*Gu @ Gu.conj().T @ C[\"uphi\"] \\\n      - 2*Gd @ C[\"dphi\"].conj().T @ Gu \\\n      - C[\"dphi\"] @ Gd.conj().T @ Gu \\\n      - 2*Gd @ Gd.conj().T @ C[\"uphi\"] \\\n      + 3*GammaH*C[\"uphi\"] \\\n      + Gammaq @ C[\"uphi\"] \\\n      + C[\"uphi\"] @ Gammau\n\n    #i  #Eta5\n    Beta[\"dphi\"] = (10/3*g**2*C[\"phiBox\"] \\\n      + 3/2*(gp**2 \\\n      - g**2)*C[\"phiD\"] \\\n      + 32*gs**2*(C[\"phiG\"] \\\n      + 1j*C[\"phiGtilde\"]) \\\n      + 9*g**2*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      + 5/3*gp**2*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]) \\\n      + g*gp*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      + 4/3*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])))*Gd \\\n      - (23/12*gp**2 \\\n      + 27/4*g**2 \\\n      + 8*gs**2)*C[\"dphi\"] \\\n      - gp*(3*g**2 \\\n      - gp**2)*C[\"dB\"] \\\n      - g*(9*g**2 \\\n      - gp**2)*C[\"dW\"] \\\n      + (3*g**2 \\\n      + gp**2)*Gd @ C[\"phid\"] \\\n      + 3*g**2*Gu @ C[\"phiud\"] \\\n      - 2*gp**2*C[\"phiq1\"] @ Gd \\\n      - 2*gp**2*C[\"phiq3\"] @ Gd \\\n      + gp*(C[\"dB\"] @ Gd.conj().T @ Gd \\\n      + Gd @ Gd.conj().T @ C[\"dB\"]) \\\n      - 3*g*(C[\"dW\"] @ Gd.conj().T @ Gd \\\n      - Gd @ Gd.conj().T @ C[\"dW\"]) \\\n      - 16*gs*(C[\"dG\"] @ Gd.conj().T @ Gd \\\n      + Gd @ Gd.conj().T @ C[\"dG\"]) \\\n      - 12*g*Gu @ Gu.conj().T @ C[\"dW\"] \\\n      - 6*g*C[\"uW\"] @ Gu.conj().T @ Gd \\\n      + Lambda*(12*C[\"dphi\"] \\\n      + 2*C[\"phiq1\"] @ Gd \\\n      + 6*C[\"phiq3\"] @ Gd \\\n      - 2*Gd @ C[\"phid\"] \\\n      - 2*Gu @ C[\"phiud\"] \\\n      - 2*C[\"phiBox\"]*Gd \\\n      + C[\"phiD\"]*Gd \\\n      - 4*my_einsum(\"rpts,pt\", C[\"qd1\"], Gd) \\\n      - 16/3*my_einsum(\"rpts,pt\", C[\"qd8\"], Gd) \\\n      + 2*my_einsum(\"ptsr,pt\", np.conj(C[\"ledq\"]), Ge) \\\n      + 6*my_einsum(\"ptrs,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      + my_einsum(\"rtps,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 4/3*my_einsum(\"rtps,pt\", C[\"quqd8\"], np.conj(Gu))) \\\n      + 2*(Eta1 \\\n      + Eta2 \\\n      + 1j*Eta5)*Gd \\\n      + (C[\"phiD\"] \\\n      - 6*C[\"phiBox\"])*Gd @ Gd.conj().T @ Gd \\\n      + 2*C[\"phiq1\"] @ Gd @ Gd.conj().T @ Gd \\\n      + 6*C[\"phiq3\"] @ Gu @ Gu.conj().T @ Gd \\\n      - 2*Gd @ Gd.conj().T @ Gd @ C[\"phid\"] \\\n      - 2*Gu @ Gu.conj().T @ Gu @ C[\"phiud\"] \\\n      + 8*(my_einsum(\"rpts,pt\", C[\"qd1\"], Gd @ Gd.conj().T @ Gd) \\\n      + 4/3*my_einsum(\"rpts,pt\", C[\"qd8\"], Gd @ Gd.conj().T @ Gd)) \\\n      - 2*(my_einsum(\"rpts,pt\", C[\"quqd1\"], Gu.conj().T @ Gu @ Gu.conj().T) \\\n      + 4/3*my_einsum(\"rpts,pt\", C[\"quqd8\"], Gu.conj().T @ Gu @ Gu.conj().T)) \\\n      - 12*my_einsum(\"tprs,pt\", C[\"quqd1\"], Gu @ Gu.conj().T @ Gu) \\\n      - 4*my_einsum(\"ptsr,pt\", np.conj(C[\"ledq\"]), Ge @ Ge.conj().T @ Ge) \\\n      + 4*C[\"dphi\"] @ Gd.conj().T @ Gd \\\n      + 5*Gd @ Gd.conj().T @ C[\"dphi\"] \\\n      - 2*Gu @ C[\"uphi\"].conj().T @ Gd \\\n      - C[\"uphi\"] @ Gu.conj().T @ Gd \\\n      - 2*Gu @ Gu.conj().T @ C[\"dphi\"] \\\n      + 3*GammaH*C[\"dphi\"] \\\n      + Gammaq @ C[\"dphi\"] \\\n      + C[\"dphi\"] @ Gammad\n\n    #i\n    Beta[\"ephi\"] = (10/3*g**2*C[\"phiBox\"] \\\n      + 3/2*(gp**2 \\\n      - g**2)*C[\"phiD\"] \\\n      + 9*g**2*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      + 15*gp**2*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]) \\\n      - 3*g*gp*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      + 4/3*g**2*(np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"])))*Ge \\\n      - 3/4*(7*gp**2 \\\n      + 9*g**2)*C[\"ephi\"] \\\n      - 3*gp*(g**2 \\\n      - 3*gp**2)*C[\"eB\"] \\\n      - 9*g*(g**2 \\\n      - gp**2)*C[\"eW\"] \\\n      + 3*(g**2 \\\n      - gp**2)*Ge @ C[\"phie\"] \\\n      - 6*gp**2*C[\"phil1\"] @ Ge \\\n      - 6*gp**2*C[\"phil3\"] @ Ge \\\n      + 9*gp*(C[\"eB\"] @ Ge.conj().T @ Ge \\\n      + Ge @ Ge.conj().T @ C[\"eB\"]) \\\n      - 3*g*(C[\"eW\"] @ Ge.conj().T @ Ge \\\n      - Ge @ Ge.conj().T @ C[\"eW\"]) \\\n      + Lambda*(12*C[\"ephi\"] \\\n      + 2*C[\"phil1\"] @ Ge \\\n      + 6*C[\"phil3\"] @ Ge \\\n      - 2*Ge @ C[\"phie\"] \\\n      - 2*C[\"phiBox\"]*Ge \\\n      + C[\"phiD\"]*Ge \\\n      - 4*my_einsum(\"rpts,pt\", C[\"le\"], Ge) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"ledq\"], Gd) \\\n      - 6*my_einsum(\"rspt,pt\", C[\"lequ1\"], np.conj(Gu))) \\\n      + 2*(Eta1 \\\n      + Eta2 \\\n      + 1j*Eta5)*Ge \\\n      + (C[\"phiD\"] \\\n      - 6*C[\"phiBox\"])*Ge @ Ge.conj().T @ Ge \\\n      + 2*C[\"phil1\"] @ Ge @ Ge.conj().T @ Ge \\\n      - 2*Ge @ Ge.conj().T @ Ge @ C[\"phie\"] \\\n      + 8*my_einsum(\"rpts,pt\", C[\"le\"], Ge @ Ge.conj().T @ Ge) \\\n      - 12*my_einsum(\"rspt,tp\", C[\"ledq\"], Gd @ Gd.conj().T @ Gd) \\\n      + 12*my_einsum(\"rstp,pt\", C[\"lequ1\"], Gu.conj().T @ Gu @ Gu.conj().T) \\\n      + 4*C[\"ephi\"] @ Ge.conj().T @ Ge \\\n      + 5*Ge @ Ge.conj().T @ C[\"ephi\"] \\\n      + 3*GammaH*C[\"ephi\"] \\\n      + Gammal @ C[\"ephi\"] \\\n      + C[\"ephi\"] @ Gammae\n\n    #i\n    Beta[\"eW\"] = 1/12*(3*gp**2 \\\n      - 11*g**2)*C[\"eW\"] \\\n      - 1/2*g*gp*C[\"eB\"] \\\n      - (g*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      - 3/2*gp*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]))*Ge \\\n      - 6*g*my_einsum(\"rspt,pt\", C[\"lequ3\"], np.conj(Gu)) \\\n      + C[\"eW\"] @ Ge.conj().T @ Ge \\\n      + GammaH*C[\"eW\"] \\\n      + Gammal @ C[\"eW\"] \\\n      + C[\"eW\"] @ Gammae\n\n    #i\n    Beta[\"eB\"] = 1/4*(151/3*gp**2 \\\n      - 9*g**2)*C[\"eB\"] \\\n      - 3/2*g*gp*C[\"eW\"] \\\n      - (3/2*g*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      - 3*gp*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]))*Ge \\\n      + 10*gp*my_einsum(\"rspt,pt\", C[\"lequ3\"], np.conj(Gu)) \\\n      + C[\"eB\"] @ Ge.conj().T @ Ge \\\n      + 2*Ge @ Ge.conj().T @ C[\"eB\"] \\\n      + GammaH*C[\"eB\"] \\\n      + Gammal @ C[\"eB\"] \\\n      + C[\"eB\"] @ Gammae\n\n    #i\n    Beta[\"uG\"] = -1/36*(81*g**2 \\\n      + 19*gp**2 \\\n      + 204*gs**2)*C[\"uG\"] \\\n      + 6*g*gs*C[\"uW\"] \\\n      + 10/3*gp*gs*C[\"uB\"] \\\n      - gs*(4*(C[\"phiG\"] \\\n      + 1j*C[\"phiGtilde\"]) \\\n      - 9*gs*(C[\"G\"] \\\n      + 1j*C[\"Gtilde\"]))*Gu \\\n      - gs*(my_einsum(\"psrt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      - 1/6*my_einsum(\"psrt,pt\", C[\"quqd8\"], np.conj(Gd))) \\\n      + 2*Gu @ Gu.conj().T @ C[\"uG\"] \\\n      - 2*Gd @ Gd.conj().T @ C[\"uG\"] \\\n      - C[\"dG\"] @ Gd.conj().T @ Gu \\\n      + C[\"uG\"] @ Gu.conj().T @ Gu \\\n      + GammaH*C[\"uG\"] \\\n      + Gammaq @ C[\"uG\"] \\\n      + C[\"uG\"] @ Gammau\n\n    #i\n    Beta[\"uW\"] = -1/36*(33*g**2 \\\n      + 19*gp**2 \\\n      - 96*gs**2)*C[\"uW\"] \\\n      + 8/3*g*gs*C[\"uG\"] \\\n      - 1/6*g*gp*C[\"uB\"] \\\n      - (g*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      - 5/6*gp*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]))*Gu \\\n      + g/4*(my_einsum(\"psrt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 4/3*my_einsum(\"psrt,pt\", C[\"quqd8\"], np.conj(Gd))) \\\n      - 2*g*my_einsum(\"ptrs,pt\", C[\"lequ3\"], np.conj(Ge)) \\\n      + 2*Gd @ Gd.conj().T @ C[\"uW\"] \\\n      - C[\"dW\"] @ Gd.conj().T @ Gu \\\n      + C[\"uW\"] @ Gu.conj().T @ Gu \\\n      + GammaH*C[\"uW\"] \\\n      + Gammaq @ C[\"uW\"] \\\n      + C[\"uW\"] @ Gammau\n\n    #i\n    Beta[\"uB\"] = -1/36*(81*g**2 \\\n      - 313*gp**2 \\\n      - 96*gs**2)*C[\"uB\"] \\\n      + 40/9*gp*gs*C[\"uG\"] \\\n      - 1/2*g*gp*C[\"uW\"] \\\n      - (-3/2*g*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      + 5/3*gp*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]))*Gu \\\n      + gp/12*(my_einsum(\"psrt,pt\", C[\"quqd1\"], np.conj(Gd)) \\\n      + 4/3*my_einsum(\"psrt,pt\", C[\"quqd8\"], np.conj(Gd))) \\\n      - 6*gp*my_einsum(\"ptrs,pt\", C[\"lequ3\"], np.conj(Ge)) \\\n      + 2*Gu @ Gu.conj().T @ C[\"uB\"] \\\n      - 2*Gd @ Gd.conj().T @ C[\"uB\"] \\\n      - C[\"dB\"] @ Gd.conj().T @ Gu \\\n      + C[\"uB\"] @ Gu.conj().T @ Gu \\\n      + GammaH*C[\"uB\"] \\\n      + Gammaq @ C[\"uB\"] \\\n      + C[\"uB\"] @ Gammau\n\n    #i\n    Beta[\"dG\"] = -1/36*(81*g**2 \\\n      + 31*gp**2 \\\n      + 204*gs**2)*C[\"dG\"] \\\n      + 6*g*gs*C[\"dW\"] \\\n      - 2/3*gp*gs*C[\"dB\"] \\\n      - gs*(4*(C[\"phiG\"] \\\n      + 1j*C[\"phiGtilde\"]) \\\n      - 9*gs*(C[\"G\"] \\\n      + 1j*C[\"Gtilde\"]))*Gd \\\n      - gs*(my_einsum(\"rtps,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      - 1/6*my_einsum(\"rtps,pt\", C[\"quqd8\"], np.conj(Gu))) \\\n      - 2*Gu @ Gu.conj().T @ C[\"dG\"] \\\n      + 2*Gd @ Gd.conj().T @ C[\"dG\"] \\\n      - C[\"uG\"] @ Gu.conj().T @ Gd \\\n      + C[\"dG\"] @ Gd.conj().T @ Gd \\\n      + GammaH*C[\"dG\"] \\\n      + Gammaq @ C[\"dG\"] \\\n      + C[\"dG\"] @ Gammad\n\n    #i\n    Beta[\"dW\"] = -1/36*(33*g**2 \\\n      + 31*gp**2 \\\n      - 96*gs**2)*C[\"dW\"] \\\n      + 8/3*g*gs*C[\"dG\"] \\\n      + 5/6*g*gp*C[\"dB\"] \\\n      - (g*(C[\"phiW\"] \\\n      + 1j*C[\"phiWtilde\"]) \\\n      - gp/6*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]))*Gd \\\n      + g/4*(my_einsum(\"rtps,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 4/3*my_einsum(\"rtps,pt\", C[\"quqd8\"], np.conj(Gu))) \\\n      + 2*Gu @ Gu.conj().T @ C[\"dW\"] \\\n      - C[\"uW\"] @ Gu.conj().T @ Gd \\\n      + C[\"dW\"] @ Gd.conj().T @ Gd \\\n      + GammaH*C[\"dW\"] \\\n      + Gammaq @ C[\"dW\"] \\\n      + C[\"dW\"] @ Gammad\n\n    #i\n    Beta[\"dB\"] = -1/36*(81*g**2 \\\n      - 253*gp**2 \\\n      - 96*gs**2)*C[\"dB\"] \\\n      - 8/9*gp*gs*C[\"dG\"] \\\n      + 5/2*g*gp*C[\"dW\"] \\\n      - (3/2*g*(C[\"phiWB\"] \\\n      + 1j*C[\"phiWtildeB\"]) \\\n      - gp/3*(C[\"phiB\"] \\\n      + 1j*C[\"phiBtilde\"]))*Gd \\\n      - 5/12*gp*(my_einsum(\"rtps,pt\", C[\"quqd1\"], np.conj(Gu)) \\\n      + 4/3*my_einsum(\"rtps,pt\", C[\"quqd8\"], np.conj(Gu))) \\\n      - 2*Gu @ Gu.conj().T @ C[\"dB\"] \\\n      + 2*Gd @ Gd.conj().T @ C[\"dB\"] \\\n      - C[\"uB\"] @ Gu.conj().T @ Gd \\\n      + C[\"dB\"] @ Gd.conj().T @ Gd \\\n      + GammaH*C[\"dB\"] \\\n      + Gammaq @ C[\"dB\"] \\\n      + C[\"dB\"] @ Gammad\n\n    #I3 #coefficient not equal with manual!!!!!!\n    Beta[\"phil1\"] = -1/4*XiB*gp**2*I3 \\\n      + 1/3*gp**2*C[\"phil1\"] \\\n      - 2/3*gp**2*(my_einsum(\"rstt\", C[\"ld\"]) \\\n      + my_einsum(\"rstt\", C[\"le\"]) \\\n      + 2*my_einsum(\"rstt\", C[\"ll\"]) \\\n      + my_einsum(\"rtts\", C[\"ll\"]) \\\n      - my_einsum(\"rstt\", C[\"lq1\"]) \\\n      - 2*my_einsum(\"rstt\", C[\"lu\"])) \\\n      - 1/2*(C[\"phiBox\"] \\\n      + C[\"phiD\"])*Ge @ Ge.conj().T \\\n      - Ge @ C[\"phie\"] @ Ge.conj().T \\\n      + 3/2*(Ge @ Ge.conj().T @ C[\"phil1\"] \\\n      + C[\"phil1\"] @ Ge @ Ge.conj().T \\\n      + 3*Ge @ Ge.conj().T @ C[\"phil3\"] \\\n      + 3*C[\"phil3\"] @ Ge @ Ge.conj().T) \\\n      + 2*my_einsum(\"rspt,tp\", C[\"le\"], Ge.conj().T @ Ge) \\\n      - 2*(2*my_einsum(\"rspt,tp\", C[\"ll\"], Ge @ Ge.conj().T) \\\n      + my_einsum(\"rtps,tp\", C[\"ll\"], Ge @ Ge.conj().T)) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"lq1\"], Gd @ Gd.conj().T) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"lq1\"], Gu @ Gu.conj().T) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"lu\"], Gu.conj().T @ Gu) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"ld\"], Gd.conj().T @ Gd) \\\n      + 2*GammaH*C[\"phil1\"] \\\n      + Gammal @ C[\"phil1\"] \\\n      + C[\"phil1\"] @ Gammal\n\n    #I3 #coefficient\n    Beta[\"phil3\"] = 2/3*g**2*(1/4*C[\"phiBox\"] \\\n      + np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"]))*I3 \\\n      - 17/3*g**2*C[\"phil3\"] \\\n      + 2/3*g**2*my_einsum(\"rtts\", C[\"ll\"]) \\\n      + 2*g**2*my_einsum(\"rstt\", C[\"lq3\"]) \\\n      - 1/2*C[\"phiBox\"]*Ge @ Ge.conj().T \\\n      + 1/2*(3*Ge @ Ge.conj().T @ C[\"phil1\"] \\\n      + 3*C[\"phil1\"] @ Ge @ Ge.conj().T \\\n      + Ge @ Ge.conj().T @ C[\"phil3\"] \\\n      + C[\"phil3\"] @ Ge @ Ge.conj().T) \\\n      - 2*(my_einsum(\"rtps,tp\", C[\"ll\"], Ge @ Ge.conj().T)) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"lq3\"], Gd @ Gd.conj().T) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"lq3\"], Gu @ Gu.conj().T) \\\n      + 2*GammaH*C[\"phil3\"] \\\n      + Gammal @ C[\"phil3\"] \\\n      + C[\"phil3\"] @ Gammal\n\n    #I3  #coefficient even terms not equal...\n    Beta[\"phie\"] = -1/2*XiB*gp**2*I3 \\\n      + 1/3*gp**2*C[\"phie\"] \\\n      - 2/3*gp**2*(my_einsum(\"rstt\", C[\"ed\"]) \\\n      + 4*my_einsum(\"rstt\", C[\"ee\"]) \\\n      - 2*my_einsum(\"rstt\", C[\"eu\"]) \\\n      + my_einsum(\"ttrs\", C[\"le\"]) \\\n      - my_einsum(\"ttrs\", C[\"qe\"])) \\\n      + (C[\"phiBox\"] \\\n      + C[\"phiD\"])*Ge.conj().T @ Ge \\\n      - 2*Ge.conj().T @ C[\"phil1\"] @ Ge \\\n      + 3*(Ge.conj().T @ Ge @ C[\"phie\"] \\\n      + C[\"phie\"] @ Ge.conj().T @ Ge) \\\n      - 2*my_einsum(\"ptrs,tp\", C[\"le\"], Ge @ Ge.conj().T) \\\n      + 8*my_einsum(\"rspt,tp\", C[\"ee\"], Ge.conj().T @ Ge) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"eu\"], Gu.conj().T @ Gu) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"ed\"], Gd.conj().T @ Gd) \\\n      - 6*my_einsum(\"ptrs,tp\", C[\"qe\"], Gd @ Gd.conj().T) \\\n      + 6*my_einsum(\"ptrs,tp\", C[\"qe\"], Gu @ Gu.conj().T) \\\n      + 2*GammaH*C[\"phie\"] \\\n      + Gammae @ C[\"phie\"] \\\n      + C[\"phie\"] @ Gammae\n\n    #I3  #coefficient???\n    Beta[\"phiq1\"] = 1/12*XiB*gp**2*I3 \\\n      + 1/3*gp**2*C[\"phiq1\"] \\\n      - 2/3*gp**2*(my_einsum(\"ttrs\", C[\"lq1\"]) \\\n      + my_einsum(\"rstt\", C[\"qd1\"]) \\\n      - 2*my_einsum(\"rstt\", C[\"qu1\"]) \\\n      + my_einsum(\"rstt\", C[\"qe\"]) \\\n      - 2*my_einsum(\"rstt\", C[\"qq1\"]) \\\n      - 1/3*my_einsum(\"rtts\", C[\"qq1\"]) \\\n      - my_einsum(\"rtts\", C[\"qq3\"])) \\\n      + 1/2*(C[\"phiBox\"] \\\n      + C[\"phiD\"])*(Gu @ Gu.conj().T \\\n      - Gd @ Gd.conj().T) \\\n      - Gu @ C[\"phiu\"] @ Gu.conj().T \\\n      - Gd @ C[\"phid\"] @ Gd.conj().T \\\n      + 2*my_einsum(\"rspt,tp\", C[\"qe\"], Ge.conj().T @ Ge) \\\n      - 2*my_einsum(\"ptrs,tp\", C[\"lq1\"], Ge @ Ge.conj().T) \\\n      + 3/2*(Gd @ Gd.conj().T @ C[\"phiq1\"] \\\n      + Gu @ Gu.conj().T @ C[\"phiq1\"] \\\n      + C[\"phiq1\"] @ Gd @ Gd.conj().T \\\n      + C[\"phiq1\"] @ Gu @ Gu.conj().T \\\n      + 3*Gd @ Gd.conj().T @ C[\"phiq3\"] \\\n      - 3*Gu @ Gu.conj().T @ C[\"phiq3\"] \\\n      + 3*C[\"phiq3\"] @ Gd @ Gd.conj().T \\\n      - 3*C[\"phiq3\"] @ Gu @ Gu.conj().T) \\\n      - 2*(6*my_einsum(\"ptrs,tp\", C[\"qq1\"], Gd @ Gd.conj().T) \\\n      + my_einsum(\"psrt,tp\", C[\"qq1\"], Gd @ Gd.conj().T) \\\n      + 3*my_einsum(\"psrt,tp\", C[\"qq3\"], Gd @ Gd.conj().T) \\\n      - 6*my_einsum(\"ptrs,tp\", C[\"qq1\"], Gu @ Gu.conj().T) \\\n      - my_einsum(\"psrt,tp\", C[\"qq1\"], Gu @ Gu.conj().T) \\\n      - 3*my_einsum(\"psrt,tp\", C[\"qq3\"], Gu @ Gu.conj().T)) \\\n      - 6*my_einsum(\"rspt,tp\", C[\"qu1\"], Gu.conj().T @ Gu) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"qd1\"], Gd.conj().T @ Gd) \\\n      + 2*GammaH*C[\"phiq1\"] \\\n      + Gammaq @ C[\"phiq1\"] \\\n      + C[\"phiq1\"] @ Gammaq\n\n    #I3 #co\n    Beta[\"phiq3\"] = 2/3*g**2*(1/4*C[\"phiBox\"] \\\n      + np.trace(C[\"phil3\"]) \\\n      + 3*np.trace(C[\"phiq3\"]))*I3 \\\n      - 17/3*g**2*C[\"phiq3\"] \\\n      + 2/3*g**2*(my_einsum(\"ttrs\", C[\"lq3\"]) \\\n      + my_einsum(\"rtts\", C[\"qq1\"]) \\\n      + 6*my_einsum(\"rstt\", C[\"qq3\"]) \\\n      - my_einsum(\"rtts\", C[\"qq3\"])) \\\n      - 1/2*C[\"phiBox\"]*(Gu @ Gu.conj().T \\\n      + Gd @ Gd.conj().T) \\\n      + 1/2*(3*Gd @ Gd.conj().T @ C[\"phiq1\"] \\\n      - 3*Gu @ Gu.conj().T @ C[\"phiq1\"] \\\n      + 3*C[\"phiq1\"] @ Gd @ Gd.conj().T \\\n      - 3*C[\"phiq1\"] @ Gu @ Gu.conj().T \\\n      + Gd @ Gd.conj().T @ C[\"phiq3\"] \\\n      + Gu @ Gu.conj().T @ C[\"phiq3\"] \\\n      + C[\"phiq3\"] @ Gd @ Gd.conj().T \\\n      + C[\"phiq3\"] @ Gu @ Gu.conj().T) \\\n      - 2*(6*my_einsum(\"rspt,tp\", C[\"qq3\"], Gd @ Gd.conj().T) \\\n      + my_einsum(\"rtps,tp\", C[\"qq1\"], Gd @ Gd.conj().T) \\\n      - my_einsum(\"rtps,tp\", C[\"qq3\"], Gd @ Gd.conj().T) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"qq3\"], Gu @ Gu.conj().T) \\\n      + my_einsum(\"rtps,tp\", C[\"qq1\"], Gu @ Gu.conj().T) \\\n      - my_einsum(\"rtps,tp\", C[\"qq3\"], Gu @ Gu.conj().T)) \\\n      - 2*my_einsum(\"ptrs,tp\", C[\"lq3\"], Ge @ Ge.conj().T) \\\n      + 2*GammaH*C[\"phiq3\"] \\\n      + Gammaq @ C[\"phiq3\"] \\\n      + C[\"phiq3\"] @ Gammaq\n\n    #I3 #co\n    Beta[\"phiu\"] = 1/3*XiB*gp**2*I3 \\\n      + 1/3*gp**2*C[\"phiu\"] \\\n      - 2/3*gp**2*(my_einsum(\"ttrs\", C[\"eu\"]) \\\n      + my_einsum(\"ttrs\", C[\"lu\"]) \\\n      - my_einsum(\"ttrs\", C[\"qu1\"]) \\\n      + my_einsum(\"rstt\", C[\"ud1\"]) \\\n      - 4*my_einsum(\"rstt\", C[\"uu\"]) \\\n      - 4/3*my_einsum(\"rtts\", C[\"uu\"])) \\\n      - (C[\"phiBox\"] \\\n      + C[\"phiD\"])*Gu.conj().T @ Gu \\\n      - 2*Gu.conj().T @ C[\"phiq1\"] @ Gu \\\n      + 3*(Gu.conj().T @ Gu @ C[\"phiu\"] \\\n      + C[\"phiu\"] @ Gu.conj().T @ Gu) \\\n      + Gu.conj().T @ Gd @ C[\"phiud\"].conj().T \\\n      + C[\"phiud\"] @ Gd.conj().T @ Gu \\\n      - 4*(3*my_einsum(\"rspt,tp\", C[\"uu\"], Gu.conj().T @ Gu) \\\n      + my_einsum(\"rtps,tp\", C[\"uu\"], Gu.conj().T @ Gu)) \\\n      + 2*my_einsum(\"ptrs,tp\", C[\"eu\"], Ge.conj().T @ Ge) \\\n      - 2*my_einsum(\"ptrs,tp\", C[\"lu\"], Ge @ Ge.conj().T) \\\n      + 6*my_einsum(\"rspt,tp\", C[\"ud1\"], Gd.conj().T @ Gd) \\\n      - 6*my_einsum(\"ptrs,tp\", C[\"qu1\"], Gd @ Gd.conj().T) \\\n      + 6*my_einsum(\"ptrs,tp\", C[\"qu1\"], Gu @ Gu.conj().T) \\\n      + 2*GammaH*C[\"phiu\"] \\\n      + Gammau @ C[\"phiu\"] \\\n      + C[\"phiu\"] @ Gammau\n\n    #I3 #co\n    Beta[\"phid\"] = -1/6*XiB*gp**2*I3 \\\n      + 1/3*gp**2*C[\"phid\"] \\\n      - 2/3*gp**2*(2*my_einsum(\"rstt\", C[\"dd\"]) \\\n      + 2/3*my_einsum(\"rtts\", C[\"dd\"]) \\\n      + my_einsum(\"ttrs\", C[\"ed\"]) \\\n      + my_einsum(\"ttrs\", C[\"ld\"]) \\\n      - my_einsum(\"ttrs\", C[\"qd1\"]) \\\n      - 2*my_einsum(\"ttrs\", C[\"ud1\"])) \\\n      + (C[\"phiBox\"] \\\n      + C[\"phiD\"])*Gd.conj().T @ Gd \\\n      - 2*Gd.conj().T @ C[\"phiq1\"] @ Gd \\\n      + 3*(Gd.conj().T @ Gd @ C[\"phid\"] \\\n      + C[\"phid\"] @ Gd.conj().T @ Gd) \\\n      - Gd.conj().T @ Gu @ C[\"phiud\"] \\\n      - C[\"phiud\"].conj().T @ Gu.conj().T @ Gd \\\n      + 4*(3*my_einsum(\"rspt,tp\", C[\"dd\"], Gd.conj().T @ Gd) \\\n      + my_einsum(\"rtps,tp\", C[\"dd\"], Gd.conj().T @ Gd)) \\\n      + 2*my_einsum(\"ptrs,tp\", C[\"ed\"], Ge.conj().T @ Ge) \\\n      - 2*my_einsum(\"ptrs,tp\", C[\"ld\"], Ge @ Ge.conj().T) \\\n      - 6*my_einsum(\"ptrs,tp\", C[\"ud1\"], Gu.conj().T @ Gu) \\\n      - 6*my_einsum(\"ptrs,tp\", C[\"qd1\"], Gd @ Gd.conj().T) \\\n      + 6*my_einsum(\"ptrs,tp\", C[\"qd1\"], Gu @ Gu.conj().T) \\\n      + 2*GammaH*C[\"phid\"] \\\n      + Gammad @ C[\"phid\"] \\\n      + C[\"phid\"] @ Gammad\n\n        #co\n    Beta[\"phiud\"] = -3*gp**2*C[\"phiud\"] \\\n      + (2*C[\"phiBox\"] \\\n      - C[\"phiD\"])*Gu.conj().T @ Gd \\\n      - 2*Gu.conj().T @ Gd @ C[\"phid\"] \\\n      + 2*C[\"phiu\"] @ Gu.conj().T @ Gd \\\n      + 4*(my_einsum(\"rtps,tp\", C[\"ud1\"], Gu.conj().T @ Gd) \\\n      + 4/3*my_einsum(\"rtps,tp\", C[\"ud8\"], Gu.conj().T @ Gd)) \\\n      + 2*Gu.conj().T @ Gu @ C[\"phiud\"] \\\n      + 2*C[\"phiud\"] @ Gd.conj().T @ Gd \\\n      + 2*GammaH*C[\"phiud\"] \\\n      + Gammau @ C[\"phiud\"] \\\n      + C[\"phiud\"] @ Gammad\n\n    \"\"\"Dimension-5\"\"\"\n    Beta[\"llphiphi\"] = (2*Lambda \\\n      - 3*g**2 \\\n      + 2*GammaH)*C[\"llphiphi\"]-3/2*(C[\"llphiphi\"] @ Ge @ Ge.conj().T \\\n      + Ge.conj() @ Ge.T @ C[\"llphiphi\"])\n\n    \"\"\"(3,3,3,3)\"\"\"\n    # the einsum function is strong\n    Beta[\"ll\"] = -1/6*gp**2*my_einsum(\"st,pr\", C[\"phil1\"], I3) \\\n      - 1/6*g**2*(my_einsum(\"st,pr\", C[\"phil3\"], I3) \\\n      - 2*my_einsum(\"sr,pt\", C[\"phil3\"], I3)) \\\n      + 1/3*gp**2*(2*my_einsum(\"prww,st\", C[\"ll\"], I3) \\\n      + my_einsum(\"pwwr,st\", C[\"ll\"], I3)) \\\n      - 1/3*g**2*my_einsum(\"pwwr,st\", C[\"ll\"], I3) \\\n      + 2/3*g**2*my_einsum(\"swwr,pt\", C[\"ll\"], I3) \\\n      - 1/3*gp**2*my_einsum(\"prww,st\", C[\"lq1\"], I3) \\\n      - g**2*my_einsum(\"prww,st\", C[\"lq3\"], I3) \\\n      + 2*g**2*my_einsum(\"ptww,rs\", C[\"lq3\"], I3) \\\n      + 1/3*gp**2*( \\\n      - 2*my_einsum(\"prww,st\", C[\"lu\"], I3) \\\n      + my_einsum(\"prww,st\", C[\"ld\"], I3) \\\n      + my_einsum(\"prww,st\", C[\"le\"], I3)) \\\n      - 1/2*(my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phil1\"]) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phil3\"])) \\\n      - my_einsum(\"pt,sr\", Ge @ Ge.conj().T, C[\"phil3\"]) \\\n      - 1/2*my_einsum(\"sv,tw,prvw\", Ge, np.conj(Ge), C[\"le\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"ll\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ll\"], Gammal) \\\n      - 1/6*gp**2*my_einsum(\"pr,st\", C[\"phil1\"], I3) \\\n      - 1/6*g**2*(my_einsum(\"pr,st\", C[\"phil3\"], I3) \\\n      - 2*my_einsum(\"pt,sr\", C[\"phil3\"], I3)) \\\n      + 1/3*gp**2*(2*my_einsum(\"stww,pr\", C[\"ll\"], I3) \\\n      + my_einsum(\"swwt,pr\", C[\"ll\"], I3)) \\\n      - 1/3*g**2*my_einsum(\"swwt,pr\", C[\"ll\"], I3) \\\n      + 2/3*g**2*my_einsum(\"pwwt,sr\", C[\"ll\"], I3) \\\n      - 1/3*gp**2*my_einsum(\"stww,pr\", C[\"lq1\"], I3) \\\n      - g**2*my_einsum(\"stww,pr\", C[\"lq3\"], I3) \\\n      + 2*g**2*my_einsum(\"srww,tp\", C[\"lq3\"], I3) \\\n      + 1/3*gp**2*( \\\n      - 2*my_einsum(\"stww,pr\", C[\"lu\"], I3) \\\n      + my_einsum(\"stww,pr\", C[\"ld\"], I3) \\\n      + my_einsum(\"stww,pr\", C[\"le\"], I3)) \\\n      - 1/2*(my_einsum(\"st,pr\", Ge @ Ge.conj().T, C[\"phil1\"]) \\\n      - my_einsum(\"st,pr\", Ge @ Ge.conj().T, C[\"phil3\"])) \\\n      - my_einsum(\"sr,pt\", Ge @ Ge.conj().T, C[\"phil3\"]) \\\n      - 1/2*my_einsum(\"pv,rw,stvw\", Ge, np.conj(Ge), C[\"le\"]) \\\n      + my_einsum(\"sv,vtpr\", Gammal, C[\"ll\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"ll\"], Gammal) \\\n      + 6*g**2*my_einsum(\"ptsr\", C[\"ll\"]) \\\n      + 3*(gp**2 \\\n      - g**2)*my_einsum(\"prst\", C[\"ll\"])\n\n    Beta[\"qq1\"] = 1/18*gp**2*my_einsum(\"st,pr\", C[\"phiq1\"], I3) \\\n      - 1/9*gp**2*my_einsum(\"wwst,pr\", C[\"lq1\"], I3) \\\n      + 1/9*gp**2*(2*my_einsum(\"prww,st\", C[\"qq1\"], I3) \\\n      + 1/3*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3))) \\\n      + 1/3*gs**2*(my_einsum(\"swwr,pt\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"swwr,pt\", C[\"qq3\"], I3)) \\\n      - 2/9*gs**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 2/9*gp**2*my_einsum(\"prww,st\", C[\"qu1\"], I3) \\\n      - 1/9*gp**2*my_einsum(\"prww,st\", C[\"qd1\"], I3) \\\n      + 1/12*gs**2*(my_einsum(\"srww,pt\", C[\"qu8\"], I3) \\\n      + my_einsum(\"srww,pt\", C[\"qd8\"], I3)) \\\n      - 1/18*gs**2*(my_einsum(\"prww,st\", C[\"qu8\"], I3) \\\n      + my_einsum(\"prww,st\", C[\"qd8\"], I3)) \\\n      - 1/9*gp**2*my_einsum(\"prww,st\", C[\"qe\"], I3) \\\n      + 1/2*(my_einsum(\"pr,st\", Gu @ Gu.conj().T, C[\"phiq1\"]) \\\n      - my_einsum(\"pr,st\", Gd @ Gd.conj().T, C[\"phiq1\"])) \\\n      - 1/2*(my_einsum(\"pv,rw,stvw\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"pv,rw,stvw\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      - 1/2*(my_einsum(\"pv,rw,stvw\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"pv,rw,stvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/8*(my_einsum(\"pv,tw,srvw\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"pv,tw,srvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/8*(my_einsum(\"tw,rv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"tw,rv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      - 1/8*(my_einsum(\"sw,pv,rvtw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"sw,pv,rvtw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + 1/16*(my_einsum(\"tw,rv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"sw,pv,tvrw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qq1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qq1\"], Gammaq) \\\n      + 1/18*gp**2*my_einsum(\"pr,st\", C[\"phiq1\"], I3) \\\n      - 1/9*gp**2*my_einsum(\"wwpr,st\", C[\"lq1\"], I3) \\\n      + 1/9*gp**2*(2*my_einsum(\"stww,pr\", C[\"qq1\"], I3) \\\n      + 1/3*(my_einsum(\"swwt,pr\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"swwt,pr\", C[\"qq3\"], I3))) \\\n      + 1/3*gs**2*(my_einsum(\"pwwt,sr\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwt,sr\", C[\"qq3\"], I3)) \\\n      - 2/9*gs**2*(my_einsum(\"swwt,pr\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"swwt,pr\", C[\"qq3\"], I3)) \\\n      + 2/9*gp**2*my_einsum(\"stww,pr\", C[\"qu1\"], I3) \\\n      - 1/9*gp**2*my_einsum(\"stww,pr\", C[\"qd1\"], I3) \\\n      + 1/12*gs**2*(my_einsum(\"ptww,sr\", C[\"qu8\"], I3) \\\n      + my_einsum(\"ptww,sr\", C[\"qd8\"], I3)) \\\n      - 1/18*gs**2*(my_einsum(\"stww,pr\", C[\"qu8\"], I3) \\\n      + my_einsum(\"stww,pr\", C[\"qd8\"], I3)) \\\n      - 1/9*gp**2*my_einsum(\"stww,pr\", C[\"qe\"], I3) \\\n      + 1/2*(my_einsum(\"st,pr\", Gu @ Gu.conj().T, C[\"phiq1\"]) \\\n      - my_einsum(\"st,pr\", Gd @ Gd.conj().T, C[\"phiq1\"])) \\\n      - 1/2*(my_einsum(\"sv,tw,prvw\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"sv,tw,prvw\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      - 1/2*(my_einsum(\"sv,tw,prvw\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"sv,tw,prvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/8*(my_einsum(\"sv,rw,ptvw\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"sv,rw,ptvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/8*(my_einsum(\"rw,tv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"rw,tv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      - 1/8*(my_einsum(\"pw,sv,tvrw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"pw,sv,tvrw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + 1/16*(my_einsum(\"rw,tv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"pw,sv,rvtw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + my_einsum(\"sv,vtpr\", Gammaq, C[\"qq1\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"qq1\"], Gammaq) \\\n      + 9*g**2*my_einsum(\"prst\", C[\"qq3\"]) \\\n      - 2*(gs**2 \\\n      - 1/6*gp**2)*my_einsum(\"prst\", C[\"qq1\"]) \\\n      + 3*gs**2*(my_einsum(\"ptsr\", C[\"qq1\"]) \\\n      + 3*my_einsum(\"ptsr\", C[\"qq3\"]))\n\n    Beta[\"qq3\"] = 1/6*g**2*my_einsum(\"st,pr\", C[\"phiq3\"], I3) \\\n      + 1/3*g**2*my_einsum(\"wwst,pr\", C[\"lq3\"], I3) \\\n      + 1/3*g**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      - my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 2*g**2*my_einsum(\"prww,st\", C[\"qq3\"], I3) \\\n      + 1/3*gs**2*(my_einsum(\"swwr,pt\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"swwr,pt\", C[\"qq3\"], I3)) \\\n      + 1/12*gs**2*(my_einsum(\"srww,pt\", C[\"qu8\"], I3) \\\n      + my_einsum(\"srww,pt\", C[\"qd8\"], I3)) \\\n      - 1/2*(my_einsum(\"pr,st\", Gu @ Gu.conj().T, C[\"phiq3\"]) \\\n      + my_einsum(\"pr,st\", Gd @ Gd.conj().T, C[\"phiq3\"])) \\\n      - 1/8*(my_einsum(\"pv,tw,srvw\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"pv,tw,srvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 1/8*(my_einsum(\"tw,rv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"tw,rv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      + 1/8*(my_einsum(\"sw,pv,rvtw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"sw,pv,rvtw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      - 1/16*(my_einsum(\"tw,rv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"sw,pv,tvrw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qq3\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qq3\"], Gammaq) \\\n      + 1/6*g**2*my_einsum(\"pr,st\", C[\"phiq3\"], I3) \\\n      + 1/3*g**2*my_einsum(\"wwpr,st\", C[\"lq3\"], I3) \\\n      + 1/3*g**2*(my_einsum(\"swwt,pr\", C[\"qq1\"], I3) \\\n      - my_einsum(\"swwt,pr\", C[\"qq3\"], I3)) \\\n      + 2*g**2*my_einsum(\"stww,pr\", C[\"qq3\"], I3) \\\n      + 1/3*gs**2*(my_einsum(\"pwwt,sr\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwt,sr\", C[\"qq3\"], I3)) \\\n      + 1/12*gs**2*(my_einsum(\"ptww,sr\", C[\"qu8\"], I3) \\\n      + my_einsum(\"ptww,sr\", C[\"qd8\"], I3)) \\\n      - 1/2*(my_einsum(\"st,pr\", Gu @ Gu.conj().T, C[\"phiq3\"]) \\\n      + my_einsum(\"st,pr\", Gd @ Gd.conj().T, C[\"phiq3\"])) \\\n      - 1/8*(my_einsum(\"sv,rw,ptvw\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"sv,rw,ptvw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 1/8*(my_einsum(\"rw,tv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"rw,tv,svpw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      + 1/8*(my_einsum(\"pw,sv,tvrw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"pw,sv,tvrw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      - 1/16*(my_einsum(\"rw,tv,pvsw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"pw,sv,rvtw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + my_einsum(\"sv,vtpr\", Gammaq, C[\"qq3\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"qq3\"], Gammaq) \\\n      + 3*gs**2*(my_einsum(\"ptsr\", C[\"qq1\"]) \\\n      - my_einsum(\"ptsr\", C[\"qq3\"])) \\\n      - 2*(gs**2 \\\n      + 3*g**2 \\\n      - 1/6*gp**2)*my_einsum(\"prst\", C[\"qq3\"]) \\\n      + 3*g**2*my_einsum(\"prst\", C[\"qq1\"])\n\n    #the terms are equal, but the order is not. No wonder if you check some differences inside\n    Beta[\"lq1\"] = -1/3*gp**2*my_einsum(\"st,pr\", C[\"phiq1\"], I3) \\\n      + 1/9*gp**2*my_einsum(\"pr,st\", C[\"phil1\"], I3) \\\n      - 2/9*gp**2*(2*my_einsum(\"prww,st\", C[\"ll\"], I3) \\\n      + my_einsum(\"pwwr,st\", C[\"ll\"], I3)) \\\n      + 2/9*gp**2*my_einsum(\"prww,st\", C[\"lq1\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"lq1\"], I3) \\\n      - 2/9*gp**2*(6*my_einsum(\"stww,pr\", C[\"qq1\"], I3) \\\n      + my_einsum(\"swwt,pr\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"swwt,pr\", C[\"qq3\"], I3)) \\\n      - 2/3*gp**2*(2*my_einsum(\"stww,pr\", C[\"qu1\"], I3) \\\n      - my_einsum(\"stww,pr\", C[\"qd1\"], I3) \\\n      - my_einsum(\"stww,pr\", C[\"qe\"], I3)) \\\n      + 2/9*gp**2*(2*my_einsum(\"prww,st\", C[\"lu\"], I3) \\\n      - my_einsum(\"prww,st\", C[\"ld\"], I3) \\\n      - my_einsum(\"prww,st\", C[\"le\"], I3)) \\\n      - gp**2*my_einsum(\"prst\", C[\"lq1\"]) \\\n      + 9*g**2*my_einsum(\"prst\", C[\"lq3\"]) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phiq1\"]) \\\n      + my_einsum(\"st,pr\", Gu @ Gu.conj().T, C[\"phil1\"]) \\\n      - my_einsum(\"st,pr\", Gd @ Gd.conj().T, C[\"phil1\"]) \\\n      + 1/4*(my_einsum(\"tw,rv,pvsw\", np.conj(Gu), np.conj(Ge), C[\"lequ1\"]) \\\n      - 12*my_einsum(\"tw,rv,pvsw\", np.conj(Gu), np.conj(Ge), C[\"lequ3\"]) \\\n      + my_einsum(\"sw,pv,rvtw\", Gu, Ge, np.conj(C[\"lequ1\"])) \\\n      - 12*my_einsum(\"sw,pv,rvtw\", Gu, Ge, np.conj(C[\"lequ3\"]))) \\\n      - my_einsum(\"sv,tw,prvw\", Gu, np.conj(Gu), C[\"lu\"]) \\\n      - my_einsum(\"sv,tw,prvw\", Gd, np.conj(Gd), C[\"ld\"]) \\\n      - my_einsum(\"pv,rw,stvw\", Ge, np.conj(Ge), C[\"qe\"]) \\\n      + 1/4*(my_einsum(\"sw,rv,pvwt\", Gd, np.conj(Ge), C[\"ledq\"]) \\\n      + my_einsum(\"pv,tw,rvws\", Ge, np.conj(Gd), np.conj(C[\"ledq\"]))) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"lq1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"lq1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"lq1\"], Gammal) \\\n      + my_einsum(\"prsv,vt\", C[\"lq1\"], Gammaq)\n\n    Beta[\"lq3\"] = 1/3*g**2*(my_einsum(\"st,pr\", C[\"phiq3\"], I3) \\\n      + my_einsum(\"pr,st\", C[\"phil3\"], I3)) \\\n      + 2/3*g**2*(3*my_einsum(\"prww,st\", C[\"lq3\"], I3) \\\n      + my_einsum(\"wwst,pr\", C[\"lq3\"], I3)) \\\n      + 2/3*g**2*(6*my_einsum(\"stww,pr\", C[\"qq3\"], I3) \\\n      + my_einsum(\"swwt,pr\", C[\"qq1\"], I3) \\\n      - my_einsum(\"swwt,pr\", C[\"qq3\"], I3)) \\\n      + 2/3*g**2*my_einsum(\"pwwr,st\", C[\"ll\"], I3) \\\n      + 3*g**2*my_einsum(\"prst\", C[\"lq1\"]) \\\n      - (6*g**2 \\\n      + gp**2)*my_einsum(\"prst\", C[\"lq3\"]) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phiq3\"]) \\\n      - my_einsum(\"st,pr\", Gu @ Gu.conj().T, C[\"phil3\"]) \\\n      - my_einsum(\"st,pr\", Gd @ Gd.conj().T, C[\"phil3\"]) \\\n      - 1/4*(my_einsum(\"tw,rv,pvsw\", np.conj(Gu), np.conj(Ge), C[\"lequ1\"]) \\\n      - 12*my_einsum(\"tw,rv,pvsw\", np.conj(Gu), np.conj(Ge), C[\"lequ3\"]) \\\n      + my_einsum(\"sw,pv,rvtw\", Gu, Ge, np.conj(C[\"lequ1\"])) \\\n      - 12*my_einsum(\"sw,pv,rvtw\", Gu, Ge, np.conj(C[\"lequ3\"]))) \\\n      + 1/4*(my_einsum(\"sw,rv,pvwt\", Gd, np.conj(Ge), C[\"ledq\"]) \\\n      + my_einsum(\"pv,tw,rvws\", Ge, np.conj(Gd), np.conj(C[\"ledq\"]))) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"lq3\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"lq3\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"lq3\"], Gammal) \\\n      + my_einsum(\"prsv,vt\", C[\"lq3\"], Gammaq)\n\n    #order\n    Beta[\"ee\"] = -1/3*gp**2*my_einsum(\"st,pr\", C[\"phie\"], I3) \\\n      + 2/3*gp**2*(my_einsum(\"wwpr,st\", C[\"le\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"qe\"], I3) \\\n      - 2*my_einsum(\"prww,st\", C[\"eu\"], I3) \\\n      + my_einsum(\"prww,st\", C[\"ed\"], I3) \\\n      + 4*my_einsum(\"prww,st\", C[\"ee\"], I3)) \\\n      + my_einsum(\"pr,st\", Ge.conj().T @ Ge, C[\"phie\"]) \\\n      - my_einsum(\"wr,vp,vwst\", Ge, np.conj(Ge), C[\"le\"]) \\\n      + my_einsum(\"pv,vrst\", Gammae, C[\"ee\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ee\"], Gammae) \\\n      - 1/3*gp**2*my_einsum(\"pr,st\", C[\"phie\"], I3) \\\n      + 2/3*gp**2*(my_einsum(\"wwst,pr\", C[\"le\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"qe\"], I3) \\\n      - 2*my_einsum(\"stww,pr\", C[\"eu\"], I3) \\\n      + my_einsum(\"stww,pr\", C[\"ed\"], I3) \\\n      + 4*my_einsum(\"wwst,pr\", C[\"ee\"], I3)) \\\n      + my_einsum(\"st,pr\", Ge.conj().T @ Ge, C[\"phie\"]) \\\n      - my_einsum(\"wt,vs,vwpr\", Ge, np.conj(Ge), C[\"le\"]) \\\n      + my_einsum(\"sv,vtpr\", Gammae, C[\"ee\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"ee\"], Gammae) \\\n      + 12*gp**2*my_einsum(\"prst\", C[\"ee\"])\n\n    #order\n    Beta[\"uu\"] = 2/9*gp**2*my_einsum(\"st,pr\", C[\"phiu\"], I3) \\\n      - 4/9*gp**2*(my_einsum(\"wwst,pr\", C[\"eu\"], I3) \\\n      + my_einsum(\"wwst,pr\", C[\"lu\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"qu1\"], I3) \\\n      - 4*my_einsum(\"wwst,pr\", C[\"uu\"], I3) \\\n      - 4/3*my_einsum(\"swwt,pr\", C[\"uu\"], I3)) \\\n      - 1/9*gs**2*(my_einsum(\"wwst,pr\", C[\"qu8\"], I3) \\\n      - 3*my_einsum(\"wwsr,pt\", C[\"qu8\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"pwwt,rs\", C[\"uu\"], I3) \\\n      - 2/9*gs**2*my_einsum(\"swwt,pr\", C[\"uu\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"stww,pr\", C[\"ud1\"], I3) \\\n      - 1/18*gs**2*(my_einsum(\"stww,pr\", C[\"ud8\"], I3) \\\n      - 3*my_einsum(\"srww,pt\", C[\"ud8\"], I3)) \\\n      - my_einsum(\"pr,st\", Gu.conj().T @ Gu, C[\"phiu\"]) \\\n      - (my_einsum(\"wr,vp,vwst\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"wr,vp,vwst\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      - 1/2*my_einsum(\"wr,vs,vwpt\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"pv,vrst\", Gammau, C[\"uu\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"uu\"], Gammau) \\\n      + 2/9*gp**2*my_einsum(\"pr,st\", C[\"phiu\"], I3) \\\n      - 4/9*gp**2*(my_einsum(\"wwpr,st\", C[\"eu\"], I3) \\\n      + my_einsum(\"wwpr,st\", C[\"lu\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"qu1\"], I3) \\\n      - 4*my_einsum(\"wwpr,st\", C[\"uu\"], I3) \\\n      - 4/3*my_einsum(\"pwwr,st\", C[\"uu\"], I3)) \\\n      - 1/9*gs**2*(my_einsum(\"wwpr,st\", C[\"qu8\"], I3) \\\n      - 3*my_einsum(\"wwpt,sr\", C[\"qu8\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"swwr,tp\", C[\"uu\"], I3) \\\n      - 2/9*gs**2*my_einsum(\"pwwr,st\", C[\"uu\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"prww,st\", C[\"ud1\"], I3) \\\n      - 1/18*gs**2*(my_einsum(\"prww,st\", C[\"ud8\"], I3) \\\n      - 3*my_einsum(\"ptww,sr\", C[\"ud8\"], I3)) \\\n      - my_einsum(\"st,pr\", Gu.conj().T @ Gu, C[\"phiu\"]) \\\n      - (my_einsum(\"wt,vs,vwpr\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"wt,vs,vwpr\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      - 1/2*my_einsum(\"wt,vp,vwsr\", Gu, np.conj(Gu), C[\"qu8\"]) \\\n      + my_einsum(\"sv,vtpr\", Gammau, C[\"uu\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"uu\"], Gammau) \\\n      + 2*(8/3*gp**2 \\\n      - gs**2)*my_einsum(\"prst\", C[\"uu\"]) \\\n      + 6*gs**2*my_einsum(\"ptsr\", C[\"uu\"])\n\n    #order\n    Beta[\"dd\"] = -1/9*gp**2*my_einsum(\"st,pr\", C[\"phid\"], I3) \\\n      + 2/9*gp**2*(my_einsum(\"wwst,pr\", C[\"ed\"], I3) \\\n      + my_einsum(\"wwst,pr\", C[\"ld\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"qd1\"], I3) \\\n      + 2*my_einsum(\"wwst,pr\", C[\"dd\"], I3) \\\n      + 2/3*my_einsum(\"swwt,pr\", C[\"dd\"], I3)) \\\n      - 1/9*gs**2*(my_einsum(\"wwst,pr\", C[\"qd8\"], I3) \\\n      - 3*my_einsum(\"wwsr,pt\", C[\"qd8\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"pwwt,rs\", C[\"dd\"], I3) \\\n      - 2/9*gs**2*my_einsum(\"swwt,pr\", C[\"dd\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"wwst,pr\", C[\"ud1\"], I3) \\\n      - 1/18*gs**2*(my_einsum(\"wwst,pr\", C[\"ud8\"], I3) \\\n      - 3*my_einsum(\"wwsr,pt\", C[\"ud8\"], I3)) \\\n      + my_einsum(\"pr,st\", Gd.conj().T @ Gd, C[\"phid\"]) \\\n      - (my_einsum(\"wr,vp,vwst\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"wr,vp,vwst\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/2*my_einsum(\"wr,vs,vwpt\", Gd, np.conj(Gd), C[\"qd8\"]) \\\n      + my_einsum(\"pv,vrst\", Gammad, C[\"dd\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"dd\"], Gammad) \\\n      - 1/9*gp**2*my_einsum(\"pr,st\", C[\"phid\"], I3) \\\n      + 2/9*gp**2*(my_einsum(\"wwpr,st\", C[\"ed\"], I3) \\\n      + my_einsum(\"wwpr,st\", C[\"ld\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"qd1\"], I3) \\\n      + 2*my_einsum(\"wwpr,st\", C[\"dd\"], I3) \\\n      + 2/3*my_einsum(\"pwwr,st\", C[\"dd\"], I3)) \\\n      - 1/9*gs**2*(my_einsum(\"wwpr,st\", C[\"qd8\"], I3) \\\n      - 3*my_einsum(\"wwpt,sr\", C[\"qd8\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"swwr,tp\", C[\"dd\"], I3) \\\n      - 2/9*gs**2*my_einsum(\"pwwr,st\", C[\"dd\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"wwpr,st\", C[\"ud1\"], I3) \\\n      - 1/18*gs**2*(my_einsum(\"wwpr,st\", C[\"ud8\"], I3) \\\n      - 3*my_einsum(\"wwpt,sr\", C[\"ud8\"], I3)) \\\n      + my_einsum(\"st,pr\", Gd.conj().T @ Gd, C[\"phid\"]) \\\n      - (my_einsum(\"wt,vs,vwpr\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"wt,vs,vwpr\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      - 1/2*my_einsum(\"wt,vp,vwsr\", Gd, np.conj(Gd), C[\"qd8\"]) \\\n      + my_einsum(\"sv,vtpr\", Gammad, C[\"dd\"]) \\\n      + my_einsum(\"svpr,vt\", C[\"dd\"], Gammad) \\\n      + 2*(2/3*gp**2 \\\n      - gs**2)*my_einsum(\"prst\", C[\"dd\"]) \\\n      + 6*gs**2*my_einsum(\"ptsr\", C[\"dd\"])\n\n    Beta[\"eu\"] = -2/3*gp**2*(my_einsum(\"st,pr\", C[\"phiu\"], I3) \\\n      + 2*(my_einsum(\"wwst,pr\", C[\"qu1\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"lu\"], I3) \\\n      + 4*my_einsum(\"wwst,pr\", C[\"uu\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"eu\"], I3) \\\n      - my_einsum(\"stww,pr\", C[\"ud1\"], I3)) \\\n      + 8/3*my_einsum(\"swwt,pr\", C[\"uu\"], I3)) \\\n      + 4/9*gp**2*(my_einsum(\"pr,st\", C[\"phie\"], I3) \\\n      + 2*(my_einsum(\"wwpr,st\", C[\"qe\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"le\"], I3) \\\n      - 4*my_einsum(\"prww,st\", C[\"ee\"], I3) \\\n      + 2*my_einsum(\"prww,st\", C[\"eu\"], I3) \\\n      - my_einsum(\"prww,st\", C[\"ed\"], I3))) \\\n      - 8*gp**2*my_einsum(\"prst\", C[\"eu\"]) \\\n      + 2*my_einsum(\"pr,st\", Ge.conj().T @ Ge, C[\"phiu\"]) \\\n      - 2*my_einsum(\"st,pr\", Gu.conj().T @ Gu, C[\"phie\"]) \\\n      + my_einsum(\"vp,ws,vrwt\", np.conj(Ge), np.conj(Gu), C[\"lequ1\"]) \\\n      - 12*my_einsum(\"vp,ws,vrwt\", np.conj(Ge), np.conj(Gu), C[\"lequ3\"]) \\\n      + my_einsum(\"vr,wt,vpws\", Ge, Gu, np.conj(C[\"lequ1\"])) \\\n      - 12*my_einsum(\"vr,wt,vpws\", Ge, Gu, np.conj(C[\"lequ3\"])) \\\n      - 2*my_einsum(\"vp,wr,vwst\", np.conj(Ge), Ge, C[\"lu\"]) \\\n      - 2*my_einsum(\"vs,wt,vwpr\", np.conj(Gu), Gu, C[\"qe\"]) \\\n      + my_einsum(\"pv,vrst\", Gammae, C[\"eu\"]) \\\n      + my_einsum(\"sv,prvt\", Gammau, C[\"eu\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"eu\"], Gammae) \\\n      + my_einsum(\"prsv,vt\", C[\"eu\"], Gammau)\n\n    Beta[\"ed\"] = -2/3*gp**2*(my_einsum(\"st,pr\", C[\"phid\"], I3) \\\n      + 2*(my_einsum(\"wwst,pr\", C[\"qd1\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"ld\"], I3) \\\n      - 2*my_einsum(\"wwst,pr\", C[\"dd\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"ed\"], I3) \\\n      + 2*my_einsum(\"wwst,pr\", C[\"ud1\"], I3)) \\\n      - 4/3*my_einsum(\"swwt,pr\", C[\"dd\"], I3)) \\\n      - 2/9*gp**2*(my_einsum(\"pr,st\", C[\"phie\"], I3) \\\n      + 2*(my_einsum(\"wwpr,st\", C[\"qe\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"le\"], I3) \\\n      - 4*my_einsum(\"prww,st\", C[\"ee\"], I3) \\\n      - my_einsum(\"prww,st\", C[\"ed\"], I3) \\\n      + 2*my_einsum(\"prww,st\", C[\"eu\"], I3))) \\\n      + 4*gp**2*my_einsum(\"prst\", C[\"ed\"]) \\\n      + 2*my_einsum(\"pr,st\", Ge.conj().T @ Ge, C[\"phid\"]) \\\n      + 2*my_einsum(\"st,pr\", Gd.conj().T @ Gd, C[\"phie\"]) \\\n      - 2*my_einsum(\"vp,wr,vwst\", np.conj(Ge), Ge, C[\"ld\"]) \\\n      - 2*my_einsum(\"vs,wt,vwpr\", np.conj(Gd), Gd, C[\"qe\"]) \\\n      + my_einsum(\"vp,wt,vrsw\", np.conj(Ge), Gd, C[\"ledq\"]) \\\n      + my_einsum(\"vr,ws,vptw\", Ge, np.conj(Gd), np.conj(C[\"ledq\"])) \\\n      + my_einsum(\"pv,vrst\", Gammae, C[\"ed\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"ed\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ed\"], Gammae) \\\n      + my_einsum(\"prsv,vt\", C[\"ed\"], Gammad)\n\n    #order\n    Beta[\"ud1\"] = 4/9*gp**2*(my_einsum(\"st,pr\", C[\"phid\"], I3) \\\n      + 2*(my_einsum(\"wwst,pr\", C[\"qd1\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"ld\"], I3) \\\n      - 2*my_einsum(\"wwst,pr\", C[\"dd\"], I3) \\\n      + 2*my_einsum(\"wwst,pr\", C[\"ud1\"], I3) \\\n      - my_einsum(\"wwst,pr\", C[\"ed\"], I3)) \\\n      - 4/3*my_einsum(\"swwt,pr\", C[\"dd\"], I3)) \\\n      - 2/9*gp**2*(my_einsum(\"pr,st\", C[\"phiu\"], I3) \\\n      + 2*(my_einsum(\"wwpr,st\", C[\"qu1\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"lu\"], I3) \\\n      + 4*my_einsum(\"wwpr,st\", C[\"uu\"], I3) \\\n      - my_einsum(\"prww,st\", C[\"ud1\"], I3) \\\n      - my_einsum(\"wwpr,st\", C[\"eu\"], I3)) \\\n      + 8/3*my_einsum(\"pwwr,st\", C[\"uu\"], I3)) \\\n      - 8/3*(gp**2*my_einsum(\"prst\", C[\"ud1\"]) \\\n      - gs**2*my_einsum(\"prst\", C[\"ud8\"])) \\\n      - 2*my_einsum(\"pr,st\", Gu.conj().T @ Gu, C[\"phid\"]) \\\n      + 2*my_einsum(\"st,pr\", Gd.conj().T @ Gd, C[\"phiu\"]) \\\n      + 2/3*my_einsum(\"sr,pt\", Gd.conj().T @ Gu, C[\"phiud\"]) \\\n      + 2/3*my_einsum(\"pt,rs\", Gu.conj().T @ Gd, np.conj(C[\"phiud\"])) \\\n      + 1/3*(my_einsum(\"vs,wp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      + 4/3*my_einsum(\"vs,wp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"vt,wr,vpws\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      + 4/3*my_einsum(\"vt,wr,vpws\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      - my_einsum(\"ws,vp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - my_einsum(\"wt,vr,vpws\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 2*my_einsum(\"vp,wr,vwst\", np.conj(Gu), Gu, C[\"qd1\"]) \\\n      - 2*my_einsum(\"vs,wt,vwpr\", np.conj(Gd), Gd, C[\"qu1\"]) \\\n      + my_einsum(\"pv,vrst\", Gammau, C[\"ud1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"ud1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ud1\"], Gammau) \\\n      + my_einsum(\"prsv,vt\", C[\"ud1\"], Gammad)\n\n    #order\n    Beta[\"ud8\"] = 8/3*gs**2*my_einsum(\"pwwr,st\", C[\"uu\"], I3) \\\n      + 8/3*gs**2*my_einsum(\"swwt,pr\", C[\"dd\"], I3) \\\n      + 4/3*gs**2*my_einsum(\"wwpr,st\", C[\"qu8\"], I3) \\\n      + 4/3*gs**2*my_einsum(\"wwst,pr\", C[\"qd8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"prww,st\", C[\"ud8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"wwst,pr\", C[\"ud8\"], I3) \\\n      - 4*(2/3*gp**2 \\\n      + gs**2)*my_einsum(\"prst\", C[\"ud8\"]) \\\n      + 12*gs**2*my_einsum(\"prst\", C[\"ud1\"]) \\\n      + 4*my_einsum(\"sr,pt\", Gd.conj().T @ Gu, C[\"phiud\"]) \\\n      + 4*my_einsum(\"pt,rs\", Gu.conj().T @ Gd, np.conj(C[\"phiud\"])) \\\n      + 2*(my_einsum(\"vs,wp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"vs,wp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"vt,wr,vpws\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"vt,wr,vpws\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      - 2*my_einsum(\"vp,wr,vwst\", np.conj(Gu), Gu, C[\"qd8\"]) \\\n      - 2*my_einsum(\"vs,wt,vwpr\", np.conj(Gd), Gd, C[\"qu8\"]) \\\n      - (my_einsum(\"ws,vp,vrwt\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + my_einsum(\"wt,vr,vpws\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + my_einsum(\"pv,vrst\", Gammau, C[\"ud8\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"ud8\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ud8\"], Gammau) \\\n      + my_einsum(\"prsv,vt\", C[\"ud8\"], Gammad)\n\n    Beta[\"le\"] = -1/3*gp**2*my_einsum(\"st,pr\", C[\"phie\"], I3) \\\n      - 2/3*gp**2*my_einsum(\"pr,st\", C[\"phil1\"], I3) \\\n      + 8/3*gp**2*my_einsum(\"prww,st\", C[\"ll\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"pwwr,st\", C[\"ll\"], I3) \\\n      - 4/3*gp**2*my_einsum(\"prww,st\", C[\"lq1\"], I3) \\\n      - 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"qe\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"prww,st\", C[\"le\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"le\"], I3) \\\n      - 8/3*gp**2*my_einsum(\"prww,st\", C[\"lu\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"prww,st\", C[\"ld\"], I3) \\\n      - 4/3*gp**2*my_einsum(\"stww,pr\", C[\"eu\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"stww,pr\", C[\"ed\"], I3) \\\n      + 8/3*gp**2*my_einsum(\"wwst,pr\", C[\"ee\"], I3) \\\n      - 6*gp**2*my_einsum(\"prst\", C[\"le\"]) \\\n      + my_einsum(\"rs,pt\", np.conj(Ge), Xie) \\\n      + my_einsum(\"pt,rs\", Ge, np.conj(Xie)) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phie\"]) \\\n      + 2*my_einsum(\"st,pr\", Ge.conj().T @ Ge, C[\"phil1\"]) \\\n      - 4*my_einsum(\"pv,rw,vtsw\", Ge, np.conj(Ge), C[\"ee\"]) \\\n      + my_einsum(\"pw,vs,vrwt\", Ge, np.conj(Ge), C[\"le\"]) \\\n      - 2*my_einsum(\"wt,vs,pwvr\", Ge, np.conj(Ge), C[\"ll\"]) \\\n      - 4*my_einsum(\"wt,vs,prvw\", Ge, np.conj(Ge), C[\"ll\"]) \\\n      + my_einsum(\"vt,rw,pvsw\", Ge, np.conj(Ge), C[\"le\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"le\"]) \\\n      + my_einsum(\"sv,prvt\", Gammae, C[\"le\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"le\"], Gammal) \\\n      + my_einsum(\"prsv,vt\", C[\"le\"], Gammae)\n\n    #order\n    Beta[\"lu\"] = -1/3*gp**2*my_einsum(\"st,pr\", C[\"phiu\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"pr,st\", C[\"phil1\"], I3) \\\n      - 16/9*gp**2*my_einsum(\"prww,st\", C[\"ll\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"pwwr,st\", C[\"ll\"], I3) \\\n      + 8/9*gp**2*my_einsum(\"prww,st\", C[\"lq1\"], I3) \\\n      - 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"qu1\"], I3) \\\n      + 16/9*gp**2*my_einsum(\"prww,st\", C[\"lu\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"lu\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"ld\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"le\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"stww,pr\", C[\"ud1\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"eu\"], I3) \\\n      - 8/3*gp**2*my_einsum(\"stww,pr\", C[\"uu\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"swwt,pr\", C[\"uu\"], I3) \\\n      + 4*gp**2*my_einsum(\"prst\", C[\"lu\"]) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phiu\"]) \\\n      - 2*my_einsum(\"st,pr\", Gu.conj().T @ Gu, C[\"phil1\"]) \\\n      - 1/2*(my_einsum(\"rv,ws,pvwt\", np.conj(Ge), np.conj(Gu), C[\"lequ1\"]) \\\n      + 12*my_einsum(\"rv,ws,pvwt\", np.conj(Ge), np.conj(Gu), C[\"lequ3\"])) \\\n      - 1/2*(my_einsum(\"pv,wt,rvws\", Ge, Gu, np.conj(C[\"lequ1\"])) \\\n      + 12*my_einsum(\"pv,wt,rvws\", Ge, Gu, np.conj(C[\"lequ3\"]))) \\\n      - 2*my_einsum(\"vs,wt,prvw\", np.conj(Gu), Gu, C[\"lq1\"]) \\\n      - my_einsum(\"rw,pv,vwst\", np.conj(Ge), Ge, C[\"eu\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"lu\"]) \\\n      + my_einsum(\"sv,prvt\", Gammau, C[\"lu\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"lu\"], Gammal) \\\n      + my_einsum(\"prsv,vt\", C[\"lu\"], Gammau)\n\n    Beta[\"ld\"] = -1/3*gp**2*my_einsum(\"st,pr\", C[\"phid\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"pr,st\", C[\"phil1\"], I3) \\\n      + 8/9*gp**2*my_einsum(\"prww,st\", C[\"ll\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"pwwr,st\", C[\"ll\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"prww,st\", C[\"lq1\"], I3) \\\n      - 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"qd1\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"prww,st\", C[\"ld\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"ld\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"lu\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"prww,st\", C[\"le\"], I3) \\\n      - 4/3*gp**2*my_einsum(\"wwst,pr\", C[\"ud1\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"wwst,pr\", C[\"ed\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"stww,pr\", C[\"dd\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"swwt,pr\", C[\"dd\"], I3) \\\n      - 2*gp**2*my_einsum(\"prst\", C[\"ld\"]) \\\n      - my_einsum(\"pr,st\", Ge @ Ge.conj().T, C[\"phid\"]) \\\n      + 2*my_einsum(\"st,pr\", Gd.conj().T @ Gd, C[\"phil1\"]) \\\n      - 1/2*my_einsum(\"rv,wt,pvsw\", np.conj(Ge), Gd, C[\"ledq\"]) \\\n      - 1/2*my_einsum(\"pv,ws,rvtw\", Ge, np.conj(Gd), np.conj(C[\"ledq\"])) \\\n      - 2*my_einsum(\"vs,wt,prvw\", np.conj(Gd), Gd, C[\"lq1\"]) \\\n      - my_einsum(\"rw,pv,vwst\", np.conj(Ge), Ge, C[\"ed\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"ld\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"ld\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ld\"], Gammal) \\\n      + my_einsum(\"prsv,vt\", C[\"ld\"], Gammad)\n\n    Beta[\"qe\"] = 1/9*gp**2*my_einsum(\"st,pr\", C[\"phie\"], I3) \\\n      - 2/3*gp**2*my_einsum(\"pr,st\", C[\"phiq1\"], I3) \\\n      - 8/3*gp**2*my_einsum(\"prww,st\", C[\"qq1\"], I3) \\\n      - 4/9*gp**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 4/3*gp**2*my_einsum(\"wwpr,st\", C[\"lq1\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"le\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"prww,st\", C[\"qe\"], I3) \\\n      + 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"qe\"], I3) \\\n      - 8/3*gp**2*my_einsum(\"prww,st\", C[\"qu1\"], I3) \\\n      + 4/3*gp**2*my_einsum(\"prww,st\", C[\"qd1\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"stww,pr\", C[\"eu\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"stww,pr\", C[\"ed\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"wwst,pr\", C[\"ee\"], I3) \\\n      + 2*gp**2*my_einsum(\"prst\", C[\"qe\"]) \\\n      + my_einsum(\"pr,st\", Gu @ Gu.conj().T, C[\"phie\"]) \\\n      - my_einsum(\"pr,st\", Gd @ Gd.conj().T, C[\"phie\"]) \\\n      + 2*my_einsum(\"st,pr\", Ge.conj().T @ Ge, C[\"phiq1\"]) \\\n      - 1/2*my_einsum(\"pw,vs,vtwr\", Gd, np.conj(Ge), C[\"ledq\"]) \\\n      - 1/2*my_einsum(\"vt,rw,vswp\", Ge, np.conj(Gd), np.conj(C[\"ledq\"])) \\\n      - 2*my_einsum(\"vs,wt,vwpr\", np.conj(Ge), Ge, C[\"lq1\"]) \\\n      - 1/2*(my_einsum(\"rw,vs,vtpw\", np.conj(Gu), np.conj(Ge), C[\"lequ1\"]) \\\n      + 12*my_einsum(\"rw,vs,vtpw\", np.conj(Gu), np.conj(Ge), C[\"lequ3\"])) \\\n      - 1/2*(my_einsum(\"pw,vt,vsrw\", Gu, Ge, np.conj(C[\"lequ1\"])) \\\n      + 12*my_einsum(\"pw,vt,vsrw\", Gu, Ge, np.conj(C[\"lequ3\"]))) \\\n      - my_einsum(\"rw,pv,stvw\", np.conj(Gd), Gd, C[\"ed\"]) \\\n      - my_einsum(\"rw,pv,stvw\", np.conj(Gu), Gu, C[\"eu\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qe\"]) \\\n      + my_einsum(\"sv,prvt\", Gammae, C[\"qe\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qe\"], Gammaq) \\\n      + my_einsum(\"prsv,vt\", C[\"qe\"], Gammae)\n\n    Beta[\"qu1\"] = 1/9*gp**2*my_einsum(\"st,pr\", C[\"phiu\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"pr,st\", C[\"phiq1\"], I3) \\\n      + 16/9*gp**2*my_einsum(\"prww,st\", C[\"qq1\"], I3) \\\n      + 8/27*gp**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      - 8/9*gp**2*my_einsum(\"wwpr,st\", C[\"lq1\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"qe\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"qd1\"], I3) \\\n      + 16/9*gp**2*my_einsum(\"prww,st\", C[\"qu1\"], I3) \\\n      + 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"qu1\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"lu\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"eu\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"stww,pr\", C[\"ud1\"], I3) \\\n      + 8/9*gp**2*my_einsum(\"stww,pr\", C[\"uu\"], I3) \\\n      + 8/27*gp**2*my_einsum(\"swwt,pr\", C[\"uu\"], I3) \\\n      - 4/3*gp**2*my_einsum(\"prst\", C[\"qu1\"]) \\\n      - 8/3*gs**2*my_einsum(\"prst\", C[\"qu8\"]) \\\n      + 1/3*my_einsum(\"rs,pt\", np.conj(Gu), Xiu) \\\n      + 1/3*my_einsum(\"pt,rs\", Gu, np.conj(Xiu)) \\\n      + my_einsum(\"pr,st\", Gu @ Gu.conj().T, C[\"phiu\"]) \\\n      - my_einsum(\"pr,st\", Gd @ Gd.conj().T, C[\"phiu\"]) \\\n      - 2*my_einsum(\"st,pr\", Gu.conj().T @ Gu, C[\"phiq1\"]) \\\n      + 1/3*(my_einsum(\"pw,vs,vrwt\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      + 4/3*my_einsum(\"pw,vs,vrwt\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      + 1/3*(my_einsum(\"vt,rw,pvsw\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      + 4/3*my_einsum(\"vt,rw,pvsw\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      + 1/3*(my_einsum(\"rw,vs,ptvw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      + 4/3*my_einsum(\"rw,vs,ptvw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      + 1/3*(my_einsum(\"pw,vt,rsvw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      + 4/3*my_einsum(\"pw,vt,rsvw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + 1/2*my_einsum(\"rw,vs,vtpw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      + 1/2*my_einsum(\"pw,vt,vsrw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 2/3*(my_einsum(\"vt,ws,pvwr\", Gu, np.conj(Gu), C[\"qq1\"]) \\\n      + 3*my_einsum(\"vt,ws,pvwr\", Gu, np.conj(Gu), C[\"qq3\"])) \\\n      - 4*my_einsum(\"wt,vs,prvw\", Gu, np.conj(Gu), C[\"qq1\"]) \\\n      - 2/3*my_einsum(\"pv,rw,vtsw\", Gu, np.conj(Gu), C[\"uu\"]) \\\n      - 2*my_einsum(\"pv,rw,vwst\", Gu, np.conj(Gu), C[\"uu\"]) \\\n      - my_einsum(\"pv,rw,stvw\", Gd, np.conj(Gd), C[\"ud1\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qu1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammau, C[\"qu1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qu1\"], Gammaq) \\\n      + my_einsum(\"prsv,vt\", C[\"qu1\"], Gammau)\n\n    Beta[\"qd1\"] = 1/9*gp**2*my_einsum(\"st,pr\", C[\"phid\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"pr,st\", C[\"phiq1\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"qq1\"], I3) \\\n      - 4/27*gp**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 4/9*gp**2*my_einsum(\"wwpr,st\", C[\"lq1\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"prww,st\", C[\"qe\"], I3) \\\n      - 8/9*gp**2*my_einsum(\"prww,st\", C[\"qu1\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"prww,st\", C[\"qd1\"], I3) \\\n      + 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"qd1\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"ld\"], I3) \\\n      - 2/9*gp**2*my_einsum(\"wwst,pr\", C[\"ed\"], I3) \\\n      + 4/9*gp**2*my_einsum(\"wwst,pr\", C[\"ud1\"], I3) \\\n      - 4/9*gp**2*my_einsum(\"stww,pr\", C[\"dd\"], I3) \\\n      - 4/27*gp**2*my_einsum(\"swwt,pr\", C[\"dd\"], I3) \\\n      + 2/3*gp**2*my_einsum(\"prst\", C[\"qd1\"]) \\\n      - 8/3*gs**2*my_einsum(\"prst\", C[\"qd8\"]) \\\n      + 1/3*my_einsum(\"rs,pt\", np.conj(Gd), Xid) \\\n      + 1/3*my_einsum(\"pt,rs\", Gd, np.conj(Xid)) \\\n      + my_einsum(\"pr,st\", Gu @ Gu.conj().T, C[\"phid\"]) \\\n      - my_einsum(\"pr,st\", Gd @ Gd.conj().T, C[\"phid\"]) \\\n      + 2*my_einsum(\"st,pr\", Gd.conj().T @ Gd, C[\"phiq1\"]) \\\n      + 1/3*(my_einsum(\"pw,vs,vrwt\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      + 4/3*my_einsum(\"pw,vs,vrwt\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 1/3*(my_einsum(\"vt,rw,pvsw\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      + 4/3*my_einsum(\"vt,rw,pvsw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 1/3*(my_einsum(\"rw,vs,vwpt\", np.conj(Gu), np.conj(Gd), C[\"quqd1\"]) \\\n      + 4/3*my_einsum(\"rw,vs,vwpt\", np.conj(Gu), np.conj(Gd), C[\"quqd8\"])) \\\n      + 1/3*(my_einsum(\"pw,vt,vwrs\", Gu, Gd, np.conj(C[\"quqd1\"])) \\\n      + 4/3*my_einsum(\"pw,vt,vwrs\", Gu, Gd, np.conj(C[\"quqd8\"]))) \\\n      + 1/2*my_einsum(\"ws,rv,pvwt\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      + 1/2*my_einsum(\"pv,wt,rvws\", Gu, Gd, np.conj(C[\"quqd1\"])) \\\n      - 2/3*(my_einsum(\"vt,ws,pvwr\", Gd, np.conj(Gd), C[\"qq1\"]) \\\n      + 3*my_einsum(\"vt,ws,pvwr\", Gd, np.conj(Gd), C[\"qq3\"])) \\\n      - 4*my_einsum(\"wt,vs,prvw\", Gd, np.conj(Gd), C[\"qq1\"]) \\\n      - 2/3*my_einsum(\"pv,rw,vtsw\", Gd, np.conj(Gd), C[\"dd\"]) \\\n      - 2*my_einsum(\"pv,rw,vwst\", Gd, np.conj(Gd), C[\"dd\"]) \\\n      - my_einsum(\"pv,rw,vwst\", Gu, np.conj(Gu), C[\"ud1\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qd1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"qd1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qd1\"], Gammaq) \\\n      + my_einsum(\"prsv,vt\", C[\"qd1\"], Gammad)\n\n    Beta[\"qu8\"] = 8/3*gs**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"prww,st\", C[\"qu8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"prww,st\", C[\"qd8\"], I3) \\\n      + 4/3*gs**2*my_einsum(\"wwst,pr\", C[\"qu8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"stww,pr\", C[\"ud8\"], I3) \\\n      + 8/3*gs**2*my_einsum(\"swwt,pr\", C[\"uu\"], I3) \\\n      - (4/3*gp**2 \\\n      + 14*gs**2)*my_einsum(\"prst\", C[\"qu8\"]) \\\n      - 12*gs**2*my_einsum(\"prst\", C[\"qu1\"]) \\\n      + 2*my_einsum(\"rs,pt\", np.conj(Gu), Xiu) \\\n      + 2*my_einsum(\"pt,rs\", Gu, np.conj(Xiu)) \\\n      + 2*(my_einsum(\"pw,vs,vrwt\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"pw,vs,vrwt\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      + 2*(my_einsum(\"vt,rw,pvsw\", Gu, np.conj(Gu), C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"vt,rw,pvsw\", Gu, np.conj(Gu), C[\"qu8\"])) \\\n      + 2*(my_einsum(\"rw,vs,ptvw\", np.conj(Gd), np.conj(Gu), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"rw,vs,ptvw\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"])) \\\n      + 2*(my_einsum(\"pw,vt,rsvw\", Gd, Gu, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"pw,vt,rsvw\", Gd, Gu, np.conj(C[\"quqd8\"]))) \\\n      + 1/2*my_einsum(\"vs,rw,vtpw\", np.conj(Gu), np.conj(Gd), C[\"quqd8\"]) \\\n      + 1/2*my_einsum(\"vt,pw,vsrw\", Gu, Gd, np.conj(C[\"quqd8\"])) \\\n      - 4*(my_einsum(\"vt,ws,pvwr\", Gu, np.conj(Gu), C[\"qq1\"]) \\\n      + 3*my_einsum(\"vt,ws,pvwr\", Gu, np.conj(Gu), C[\"qq3\"])) \\\n      - 4*my_einsum(\"pv,rw,vtsw\", Gu, np.conj(Gu), C[\"uu\"]) \\\n      - my_einsum(\"pv,rw,stvw\", Gd, np.conj(Gd), C[\"ud8\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qu8\"]) \\\n      + my_einsum(\"sv,prvt\", Gammau, C[\"qu8\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qu8\"], Gammaq) \\\n      + my_einsum(\"prsv,vt\", C[\"qu8\"], Gammau)\n\n    Beta[\"qd8\"] = 8/3*gs**2*(my_einsum(\"pwwr,st\", C[\"qq1\"], I3) \\\n      + 3*my_einsum(\"pwwr,st\", C[\"qq3\"], I3)) \\\n      + 2/3*gs**2*my_einsum(\"prww,st\", C[\"qu8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"prww,st\", C[\"qd8\"], I3) \\\n      + 4/3*gs**2*my_einsum(\"wwst,pr\", C[\"qd8\"], I3) \\\n      + 2/3*gs**2*my_einsum(\"wwst,pr\", C[\"ud8\"], I3) \\\n      + 8/3*gs**2*my_einsum(\"swwt,pr\", C[\"dd\"], I3) \\\n      - (-2/3*gp**2 \\\n      + 14*gs**2)*my_einsum(\"prst\", C[\"qd8\"]) \\\n      - 12*gs**2*my_einsum(\"prst\", C[\"qd1\"]) \\\n      + 2*my_einsum(\"rs,pt\", np.conj(Gd), Xid) \\\n      + 2*my_einsum(\"pt,rs\", Gd, np.conj(Xid)) \\\n      + 2*(my_einsum(\"pw,vs,vrwt\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"pw,vs,vrwt\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 2*(my_einsum(\"vt,rw,pvsw\", Gd, np.conj(Gd), C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"vt,rw,pvsw\", Gd, np.conj(Gd), C[\"qd8\"])) \\\n      + 2*(my_einsum(\"rw,vs,vwpt\", np.conj(Gu), np.conj(Gd), C[\"quqd1\"]) \\\n      - 1/6*my_einsum(\"rw,vs,vwpt\", np.conj(Gu), np.conj(Gd), C[\"quqd8\"])) \\\n      + 2*(my_einsum(\"pw,vt,vwrs\", Gu, Gd, np.conj(C[\"quqd1\"])) \\\n      - 1/6*my_einsum(\"pw,vt,vwrs\", Gu, Gd, np.conj(C[\"quqd8\"]))) \\\n      + 1/2*my_einsum(\"vs,rw,pwvt\", np.conj(Gd), np.conj(Gu), C[\"quqd8\"]) \\\n      + 1/2*my_einsum(\"vt,pw,rwvs\", Gd, Gu, np.conj(C[\"quqd8\"])) \\\n      - 4*(my_einsum(\"vt,ws,pvwr\", Gd, np.conj(Gd), C[\"qq1\"]) \\\n      + 3*my_einsum(\"vt,ws,pvwr\", Gd, np.conj(Gd), C[\"qq3\"])) \\\n      - 4*my_einsum(\"pv,rw,vtsw\", Gd, np.conj(Gd), C[\"dd\"]) \\\n      - my_einsum(\"pv,rw,vwst\", Gu, np.conj(Gu), C[\"ud8\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"qd8\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"qd8\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"qd8\"], Gammaq) \\\n      + my_einsum(\"prsv,vt\", C[\"qd8\"], Gammad)\n\n    Beta[\"ledq\"] = -(8/3*gp**2 \\\n      + 8*gs**2)*my_einsum(\"prst\", C[\"ledq\"]) \\\n      - 2*my_einsum(\"ts,pr\", np.conj(Gd), Xie) \\\n      - 2*my_einsum(\"pr,ts\", Ge, np.conj(Xid)) \\\n      + 2*my_einsum(\"pv,tw,vrsw\", Ge, np.conj(Gd), C[\"ed\"]) \\\n      - 2*my_einsum(\"vr,tw,pvsw\", Ge, np.conj(Gd), C[\"ld\"]) \\\n      + 2*my_einsum(\"vr,ws,pvwt\", Ge, np.conj(Gd), C[\"lq1\"]) \\\n      + 6*my_einsum(\"vr,ws,pvwt\", Ge, np.conj(Gd), C[\"lq3\"]) \\\n      - 2*my_einsum(\"pw,vs,vtwr\", Ge, np.conj(Gd), C[\"qe\"]) \\\n      + 2*my_einsum(\"vs,tw,prvw\", np.conj(Gd), np.conj(Gu), C[\"lequ1\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"ledq\"]) \\\n      + my_einsum(\"sv,prvt\", Gammad, C[\"ledq\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"ledq\"], Gammae) \\\n      + my_einsum(\"prsv,vt\", C[\"ledq\"], Gammaq)\n\n    Beta[\"quqd1\"] = 10/3*gp*my_einsum(\"st,pr\", C[\"dB\"], Gu) \\\n      - 6*g*my_einsum(\"st,pr\", C[\"dW\"], Gu) \\\n      - 20/9*gp*my_einsum(\"pt,sr\", C[\"dB\"], Gu) \\\n      + 4*g*my_einsum(\"pt,sr\", C[\"dW\"], Gu) \\\n      - 64/9*gs*my_einsum(\"pt,sr\", C[\"dG\"], Gu) \\\n      - 2/3*gp*my_einsum(\"pr,st\", C[\"uB\"], Gd) \\\n      - 6*g*my_einsum(\"pr,st\", C[\"uW\"], Gd) \\\n      + 4/9*gp*my_einsum(\"sr,pt\", C[\"uB\"], Gd) \\\n      + 4*g*my_einsum(\"sr,pt\", C[\"uW\"], Gd) \\\n      - 64/9*gs*my_einsum(\"sr,pt\", C[\"uG\"], Gd) \\\n      - 1/2*(11/9*gp**2 + 3*g**2 + 32*gs**2)*my_einsum(\"prst\", C[\"quqd1\"]) \\\n      - 1/3*( - 5/9*gp**2 - 3*g**2 + 64/3*gs**2)*my_einsum(\"srpt\", C[\"quqd1\"]) \\\n      - 4/9*( - 5/9*gp**2 - 3*g**2 + 28/3*gs**2)*my_einsum(\"srpt\", C[\"quqd8\"]) \\\n      + 16/9*gs**2*my_einsum(\"prst\", C[\"quqd8\"]) \\\n      - 2*my_einsum(\"pr,st\", Gu, Xid) \\\n      - 2*my_einsum(\"st,pr\", Gd, Xiu) \\\n      + 4/3*(my_einsum(\"vr,pw,svwt\", Gu, Gd, C[\"qd1\"]) \\\n      + 4/3*my_einsum(\"vr,pw,svwt\", Gu, Gd, C[\"qd8\"]) \\\n      + my_einsum(\"vt,sw,pvwr\", Gd, Gu, C[\"qu1\"]) \\\n      + 4/3*my_einsum(\"vt,sw,pvwr\", Gd, Gu, C[\"qu8\"]) \\\n      + my_einsum(\"pw,sv,vrwt\", Gd, Gu, C[\"ud1\"]) \\\n      + 4/3*my_einsum(\"pw,sv,vrwt\", Gd, Gu, C[\"ud8\"])) \\\n      + 8/3*(my_einsum(\"wt,vr,svpw\", Gd, Gu, C[\"qq1\"]) \\\n      - 3*my_einsum(\"wt,vr,svpw\", Gd, Gu, C[\"qq3\"]) \\\n      - 3*my_einsum(\"wt,vr,swpv\", Gd, Gu, C[\"qq1\"]) \\\n      + 9*my_einsum(\"wt,vr,swpv\", Gd, Gu, C[\"qq3\"])) \\\n      - 4*my_einsum(\"sw,pv,vrwt\", Gd, Gu, C[\"ud1\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"quqd1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"quqd1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"quqd1\"], Gammau) \\\n      + my_einsum(\"prsv,vt\", C[\"quqd1\"], Gammad)\n\n    Beta[\"quqd8\"] = 8*gs*my_einsum(\"st,pr\", C[\"dG\"], Gu) \\\n      - 40/3*gp*my_einsum(\"pt,sr\", C[\"dB\"], Gu) \\\n      + 24*g*my_einsum(\"pt,sr\", C[\"dW\"], Gu) \\\n      + 16/3*gs*my_einsum(\"pt,sr\", C[\"dG\"], Gu) \\\n      + 8*gs*my_einsum(\"pr,st\", C[\"uG\"], Gd) \\\n      + 8/3*gp*my_einsum(\"sr,pt\", C[\"uB\"], Gd) \\\n      + 24*g*my_einsum(\"sr,pt\", C[\"uW\"], Gd) \\\n      + 16/3*gs*my_einsum(\"sr,pt\", C[\"uG\"], Gd) \\\n      + 8*gs**2*my_einsum(\"prst\", C[\"quqd1\"]) \\\n      + (10/9*gp**2 + 6*g**2 + 16/3*gs**2)*my_einsum(\"srpt\", C[\"quqd1\"]) \\\n      + (-11/18*gp**2 - 3/2*g**2 + 16/3*gs**2)*my_einsum(\"prst\", C[\"quqd8\"]) \\\n      - 1/3*(5/9*gp**2 + 3*g**2 \\\n      + 44/3*gs**2)*my_einsum(\"srpt\", C[\"quqd8\"]) \\\n      + 8*(my_einsum(\"vr,pw,svwt\", Gu, Gd, C[\"qd1\"]) \\\n      - 1/6*my_einsum(\"vr,pw,svwt\", Gu, Gd, C[\"qd8\"]) \\\n      + my_einsum(\"vt,sw,pvwr\", Gd, Gu, C[\"qu1\"]) \\\n      - 1/6*my_einsum(\"vt,sw,pvwr\", Gd, Gu, C[\"qu8\"]) \\\n      + my_einsum(\"pw,sv,vrwt\", Gd, Gu, C[\"ud1\"]) \\\n      - 1/6*my_einsum(\"pw,sv,vrwt\", Gd, Gu, C[\"ud8\"])) \\\n      + 16*(my_einsum(\"wt,vr,svpw\", Gd, Gu, C[\"qq1\"]) \\\n      - 3*my_einsum(\"wt,vr,svpw\", Gd, Gu, C[\"qq3\"])) \\\n      - 4*my_einsum(\"sw,pv,vrwt\", Gd, Gu, C[\"ud8\"]) \\\n      + my_einsum(\"pv,vrst\", Gammaq, C[\"quqd8\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"quqd8\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"quqd8\"], Gammau) \\\n      + my_einsum(\"prsv,vt\", C[\"quqd8\"], Gammad)\n\n    Beta[\"lequ1\"] = -(11/3*gp**2 + 8*gs**2)*my_einsum(\"prst\", C[\"lequ1\"]) \\\n      + (30*gp**2 + 18*g**2)*my_einsum(\"prst\", C[\"lequ3\"]) \\\n      + 2*my_einsum(\"st,pr\", Gu, Xie) \\\n      + 2*my_einsum(\"pr,st\", Ge, Xiu) \\\n      + 2*my_einsum(\"sv,wt,prvw\", Gd, Gu, C[\"ledq\"]) \\\n      + 2*my_einsum(\"pv,sw,vrwt\", Ge, Gu, C[\"eu\"]) \\\n      + 2*my_einsum(\"vr,wt,pvsw\", Ge, Gu, C[\"lq1\"]) \\\n      - 6*my_einsum(\"vr,wt,pvsw\", Ge, Gu, C[\"lq3\"]) \\\n      - 2*my_einsum(\"vr,sw,pvwt\", Ge, Gu, C[\"lu\"]) \\\n      - 2*my_einsum(\"pw,vt,svwr\", Ge, Gu, C[\"qe\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"lequ1\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"lequ1\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"lequ1\"], Gammae) \\\n      + my_einsum(\"prsv,vt\", C[\"lequ1\"], Gammau)\n\n    Beta[\"lequ3\"] = 5/6*gp*my_einsum(\"pr,st\", C[\"eB\"], Gu) \\\n      - 3/2*g*my_einsum(\"st,pr\", C[\"uW\"], Ge) \\\n      - 3/2*gp*my_einsum(\"st,pr\", C[\"uB\"], Ge) \\\n      - 3/2*g*my_einsum(\"pr,st\", C[\"eW\"], Gu) \\\n      + (2/9*gp**2 - 3*g**2 + 8/3*gs**2)*my_einsum(\"prst\", C[\"lequ3\"]) \\\n      + 1/8*(5*gp**2 + 3*g**2)*my_einsum(\"prst\", C[\"lequ1\"]) \\\n      - 1/2*my_einsum(\"sw,pv,vrwt\", Gu, Ge, C[\"eu\"]) \\\n      - 1/2*my_einsum(\"vr,wt,pvsw\", Ge, Gu, C[\"lq1\"]) \\\n      + 3/2*my_einsum(\"vr,wt,pvsw\", Ge, Gu, C[\"lq3\"]) \\\n      - 1/2*my_einsum(\"vr,sw,pvwt\", Ge, Gu, C[\"lu\"]) \\\n      - 1/2*my_einsum(\"pw,vt,svwr\", Ge, Gu, C[\"qe\"]) \\\n      + my_einsum(\"pv,vrst\", Gammal, C[\"lequ3\"]) \\\n      + my_einsum(\"sv,prvt\", Gammaq, C[\"lequ3\"]) \\\n      + my_einsum(\"pvst,vr\", C[\"lequ3\"], Gammae) \\\n      + my_einsum(\"prsv,vt\", C[\"lequ3\"], Gammau)\n\n    Beta[\"duql\"] = -(9/2*g**2 \\\n      + 11/6*gp**2 \\\n      + 4*gs**2)*my_einsum(\"prst\", C[\"duql\"]) \\\n      - my_einsum(\"sv,wp,vrwt\", np.conj(Gd), Gd, C[\"duql\"]) \\\n      - my_einsum(\"sv,wr,pvwt\", np.conj(Gu), Gu, C[\"duql\"]) \\\n      + 2*my_einsum(\"tv,sw,prwv\", np.conj(Ge), np.conj(Gu), C[\"duue\"]) \\\n      + my_einsum(\"tv,sw,pwrv\", np.conj(Ge), np.conj(Gu), C[\"duue\"]) \\\n      + 4*my_einsum(\"vp,wr,vwst\", Gd, Gu, C[\"qqql\"]) \\\n      + 4*my_einsum(\"vp,wr,wvst\", Gd, Gu, C[\"qqql\"]) \\\n      - my_einsum(\"vp,wr,vswt\", Gd, Gu, C[\"qqql\"]) \\\n      - my_einsum(\"vp,wr,wsvt\", Gd, Gu, C[\"qqql\"]) \\\n      + 2*my_einsum(\"wp,tv,wsrv\", Gd, np.conj(Ge), C[\"qque\"]) \\\n      + my_einsum(\"vp,vrst\", Gd.conj().T @ Gd, C[\"duql\"]) \\\n      + my_einsum(\"vr,pvst\", Gu.conj().T @ Gu, C[\"duql\"]) \\\n      + 1/2*(my_einsum(\"vs,prvt\", Gu @ Gu.conj().T, C[\"duql\"]) \\\n      + my_einsum(\"vs,prvt\", Gd @ Gd.conj().T, C[\"duql\"])) \\\n      + 1/2*my_einsum(\"vt,prsv\", Ge @ Ge.conj().T, C[\"duql\"])\n\n    Beta[\"qque\"] = -(9/2*g**2 \\\n      + 23/6*gp**2 + 4*gs**2)*my_einsum(\"prst\", C[\"qque\"]) \\\n      - my_einsum(\"rv,ws,pwvt\", np.conj(Gu), Gu, C[\"qque\"]) \\\n      + 1/2*my_einsum(\"wt,rv,vspw\", Ge, np.conj(Gd), C[\"duql\"]) \\\n      - 1/2*(2*my_einsum(\"pv,rw,vwst\", np.conj(Gd), np.conj(Gu), C[\"duue\"]) \\\n      + my_einsum(\"pv,rw,vswt\", np.conj(Gd), np.conj(Gu), C[\"duue\"])) \\\n      + 1/2*( \\\n      - 2*my_einsum(\"ws,vt,prwv\", Gu, Ge, C[\"qqql\"]) \\\n      + my_einsum(\"ws,vt,pwrv\", Gu, Ge, C[\"qqql\"]) \\\n      - 2*my_einsum(\"ws,vt,wprv\", Gu, Ge, C[\"qqql\"])) \\\n      + 1/2*(my_einsum(\"vp,vrst\", Gu @ Gu.conj().T, C[\"qque\"]) \\\n      + my_einsum(\"vp,vrst\", Gd @ Gd.conj().T, C[\"qque\"])) \\\n      - my_einsum(\"pv,ws,rwvt\", np.conj(Gu), Gu, C[\"qque\"]) \\\n      + 1/2*my_einsum(\"wt,pv,vsrw\", Ge, np.conj(Gd), C[\"duql\"]) \\\n      - 1/2*(2*my_einsum(\"rv,pw,vwst\", np.conj(Gd), np.conj(Gu), C[\"duue\"]) \\\n      + my_einsum(\"rv,pw,vswt\", np.conj(Gd), np.conj(Gu), C[\"duue\"])) \\\n      + 1/2*( \\\n      - 2*my_einsum(\"ws,vt,rpwv\", Gu, Ge, C[\"qqql\"]) \\\n      + my_einsum(\"ws,vt,rwpv\", Gu, Ge, C[\"qqql\"]) \\\n      - 2*my_einsum(\"ws,vt,wrpv\", Gu, Ge, C[\"qqql\"])) \\\n      + 1/2*(my_einsum(\"vr,vpst\", Gu @ Gu.conj().T, C[\"qque\"]) \\\n      + my_einsum(\"vr,vpst\", Gd @ Gd.conj().T, C[\"qque\"])) \\\n      + my_einsum(\"vs,prvt\", Gu.conj().T @ Gu, C[\"qque\"]) \\\n      + my_einsum(\"vt,prsv\", Ge.conj().T @ Ge, C[\"qque\"])\n\n    Beta[\"qqql\"] = -(3*g**2 \\\n      + 1/3*gp**2 + 4*gs**2)*my_einsum(\"prst\", C[\"qqql\"]) \\\n      - 4*g**2*(my_einsum(\"rpst\", C[\"qqql\"]) \\\n      + my_einsum(\"srpt\", C[\"qqql\"]) \\\n      + my_einsum(\"psrt\", C[\"qqql\"])) \\\n      - 4*my_einsum(\"tv,sw,prwv\", np.conj(Ge), np.conj(Gu), C[\"qque\"]) \\\n      + 2*(my_einsum(\"pv,rw,vwst\", np.conj(Gd), np.conj(Gu), C[\"duql\"]) \\\n      + my_einsum(\"rv,pw,vwst\", np.conj(Gd), np.conj(Gu), C[\"duql\"])) \\\n      + 1/2*(my_einsum(\"vp,vrst\", Gu @ Gu.conj().T, C[\"qqql\"]) \\\n      + my_einsum(\"vp,vrst\", Gd @ Gd.conj().T, C[\"qqql\"])) \\\n      + 1/2*(my_einsum(\"vr,pvst\", Gu @ Gu.conj().T, C[\"qqql\"]) \\\n      + my_einsum(\"vr,pvst\", Gd @ Gd.conj().T, C[\"qqql\"])) \\\n      + 1/2*(my_einsum(\"vs,prvt\", Gu @ Gu.conj().T, C[\"qqql\"]) \\\n      + my_einsum(\"vs,prvt\", Gd @ Gd.conj().T, C[\"qqql\"])) \\\n      + 1/2*my_einsum(\"vt,prsv\", Ge @ Ge.conj().T, C[\"qqql\"])\n\n    Beta[\"duue\"] = -(2*gp**2 + 4*gs**2)*my_einsum(\"prst\", C[\"duue\"]) \\\n      - 20/3*gp**2*my_einsum(\"psrt\", C[\"duue\"]) \\\n      + 4*my_einsum(\"ws,vt,prwv\", Gu, Ge, C[\"duql\"]) \\\n      - 8*my_einsum(\"vp,wr,vwst\", Gd, Gu, C[\"qque\"]) \\\n      + my_einsum(\"vp,vrst\", Gd.conj().T @ Gd, C[\"duue\"]) \\\n      + my_einsum(\"vr,pvst\", Gu.conj().T @ Gu, C[\"duue\"]) \\\n      + my_einsum(\"vs,prvt\", Gu.conj().T @ Gu, C[\"duue\"]) \\\n      + my_einsum(\"vt,prsv\", Ge.conj().T @ Ge, C[\"duue\"])\n\n    Beta[\"llphiphi\"] = (2*Lambda \\\n      - 3*g**2 \\\n      + 2*GammaH)*C[\"llphiphi\"]-3/2*(C[\"llphiphi\"] @ Ge @ Ge.conj().T \\\n      + Ge.conj() @ Ge.T @ C[\"llphiphi\"])\n\n    return Beta", "response": "Returns the beta functions of all SM parameters and SMEFT Wilson\n    coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef beta_array(C, HIGHSCALE, *args, **kwargs):\n    beta_odict = beta(C, HIGHSCALE, *args, **kwargs)\n    return np.hstack([np.asarray(b).ravel() for b in beta_odict.values()])", "response": "Return the beta functions of all SM parameters and SMEFT Wilson\n    coefficients as a 1D numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _search(self, query, search_term):\n        criterias = mongoengine.Q()\n        rel_criterias = mongoengine.Q()\n        terms = shlex.split(search_term)\n\n        # If an ObjectId pattern, see if we can get an instant lookup.\n        if len(terms) == 1 and re.match(RE_OBJECTID, terms[0]):\n            q = query.filter(id=bson.ObjectId(terms[0]))\n            if q.count() == 1:  # Note: .get doesn't work, they need a QuerySet\n                return q\n\n        for term in terms:\n            op, term = parse_like_term(term)\n\n            # Case insensitive by default\n            if op == 'contains':\n                op = 'icontains'\n\n            criteria = mongoengine.Q()\n\n            for field in self._search_fields:\n                if isinstance(field, mongoengine.fields.ReferenceField):\n                    rel_model = field.document_type\n                    rel_fields = (\n                        getattr(self, 'column_searchable_refs', {})\n                        .get(field.name, {})\n                        .get('fields', ['id'])\n                    )\n\n                    # If term isn't an ID, don't do an ID lookup\n                    if rel_fields == ['id'] and not re.match(RE_OBJECTID, term):\n                        continue\n\n                    ids = [\n                        o.id for o in search_relative_field(rel_model, rel_fields, term)\n                    ]\n                    rel_criterias |= mongoengine.Q(**{'%s__in' % field.name: ids})\n                elif isinstance(field, mongoengine.fields.ListField):\n                    if not isinstance(field.field, mongoengine.fields.ReferenceField):\n                        continue  # todo: support lists of other types\n                    rel_model = field.field.document_type_obj\n                    rel_fields = (\n                        getattr(self, 'column_searchable_refs', {})\n                        .get(field.name, {})\n                        .get('fields', 'id')\n                    )\n                    ids = [\n                        o.id for o in search_relative_field(rel_model, rel_fields, term)\n                    ]\n                    rel_criterias |= mongoengine.Q(**{'%s__in' % field.name: ids})\n                else:\n                    flt = {'%s__%s' % (field.name, op): term}\n                    q = mongoengine.Q(**flt)\n                    criteria |= q\n\n            criterias &= criteria\n\n        # import pprint\n        # pp = pprint.PrettyPrinter(indent=4).pprint\n        # print(pp(query.filter(criterias)._query))\n        return query.filter(criterias | rel_criterias)", "response": "Search between words and returns a QuerySet containing the set of entries that match the search_term."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_data_from_iterable(self, frames, values, labels=None):\n        if not isinstance(frames, collections.Iterable):\n            raise TypeError, \"frames must be an iterable\"\n        if not isinstance(values, collections.Iterable):\n            raise TypeError, \"values must be an iterable\"\n        assert(len(frames) == len(values))\n        self.frames = frames\n        self.values = values\n        if labels is None:\n            self.label2int['New Point'] = 0\n            self.int2label[0] = 'New Point'\n            self.labels = [0 for i in xrange(len(frames))]\n        else:\n            if not isinstance(labels, collections.Iterable):\n                raise TypeError, \"labels must be an iterable\"\n            for l in labels:\n                if l not in self.label2int:\n                    self.label2int[l] = len(self.label2int)\n                    self.int2label[len(self.int2label)] = l\n                self.labels.append(self.label2int[l])", "response": "Initialize a dataset structure from iterable parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        # dataset = self.data.appendChild(self.doc.createElement('dataset'))\n        # dataset.setAttribute('id', str(imodel))\n        # dataset.setAttribute('dimensions', '2')\n        writer.write('%s<dataset id=\"%s\" dimensions=\"%s\">%s' % (indent, self.datasetid, self.dimensions, newl))\n        indent2 = indent + addindent\n        for l, x, y in zip(self.labels, self.frames, self.values):\n            writer.write('%s<point label=\"%s\" frame=\"%d\" value=\"%f\"/>%s' % (indent2, self.int2label[l], x, y, newl))\n        writer.write('%s</dataset>%s' % (indent, newl))", "response": "Writes the continuous  dataset using sonic visualiser xml conventions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gaus_pdf(x, mean, std):\n    '''Gaussian distribution's probability density function.\n\n    See, e.g. `Wikipedia <https://en.wikipedia.org/wiki/Normal_distribution>`_.\n\n    :param x: point in x-axis\n    :type x: float or numpy.ndarray\n    :param float mean: mean or expectation\n    :param float str: standard deviation\n    :returns: pdf(s) in point **x**\n    :rtype: float or numpy.ndarray\n    '''\n    return exp(-((x - mean) / std)**2 / 2) / sqrt(2 * pi) / std", "response": "Gaussian distribution s probability density function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_grid_menv(addr, slave_addrs, grid_size, origin, logger=logger,\n                     extra_ser=None):\n    '''\n    :param addr: Address of the multi-environment\n    :param slave_addrs: Addresses for the slave environments.\n    :param tuple grid_size: Grid size for each slave environment, e.g. (4, 4)\n    :param origin:\n        Origin of the multi-environment (slave envs are stacked horizontally).\n\n    :param logger:\n        Root logger for the multi-environment.\n\n    :param extra_ser:\n        Extra serializers for the environments (used to communicate arbitrary\n        Python objects between the agents).\n\n    :returns: Instance of :py:class:`GridMultiEnvironment`\n    '''\n    env_kwargs = {'codec': aiomas.MsgPack, 'extra_serializers': extra_ser}\n    menv = GridMultiEnvironment(addr,\n                                env_cls=Environment,\n                                mgr_cls=GridMultiEnvManager,\n                                logger=logger,\n                                grid_size=grid_size,\n                                origin=origin,\n                                **env_kwargs)\n    slave_kwargs = [{'codec': aiomas.MsgPack, 'extra_serializers': extra_ser}\n                    for _ in range(len(slave_addrs))]\n    run(menv.spawn_slaves(slave_addrs=slave_addrs,\n                          slave_env_cls=GridEnvironment,\n                          slave_mgr_cls=GridEnvManager,\n                          slave_kwargs=slave_kwargs))\n    return menv", "response": "Creates a multi - environment with the given addresses and grid size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef populate_menv(menv, agent_cls_name, log_folder):\n    '''Populate given multiprocessing grid environment with agents.\n\n    :param menv: Instance of :py:class:`GridMultiEnvironment`\n    :param str agent_cls_name: Name of the agent class, e.g. 'grip_mp:GridAgent'\n    :param str log_folder: Root logging folder for the agents.\n    '''\n    gs = menv.gs\n    n_agents = gs[0] * gs[1]\n    n_slaves = len(menv.addrs)\n    logger.info(\"Populating {} with {} agents\".format(HOST, n_agents*n_slaves))\n    run(menv.populate(agent_cls_name, n_agents, log_folder=log_folder))\n    logger.info(\"Populating complete.\")", "response": "Populate given multiprocessing grid environment with agents."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_slave_addrs(mgr_addr, N):\n    '''Get ports for the slave environments.\n\n    Currently the ports are not checked for availability.\n    '''\n    return  [(HOST, p) for p in range(mgr_addr+1, mgr_addr+1+N)]", "response": "Get ports for the slave environments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate artifact s value to be weighted average of values returned by rule s subrules.", "response": "def weighted_average(rule, artifact):\n    \"\"\"Evaluate artifact's value to be weighted average of values returned by\n    rule's subrules.\n    \"\"\"\n    e = 0\n    w = 0\n    for i in range(len(rule.R)):\n        r = rule.R[i](artifact)\n        if r is not None:\n            e += r * rule.W[i]\n            w += abs(rule.W[i])\n    if w == 0.0:\n        return 0.0\n    return e / w"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef minimum(rule, artifact):\n    m = 1.0\n    for i in range(len(rule.R)):\n        e = rule.R[i](artifact)\n        if e is not None:\n            if e < m:\n                m = e\n    return m", "response": "Evaluate artifact s value to be minimum of values returned by rule s\n    subrules. This evaluation function ignores subrule weights."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_subrule(self, subrule, weight):\n        if not issubclass(subrule.__class__, (Rule, RuleLeaf)):\n            raise TypeError(\"Rule's class must be (subclass of) {} or {}, got \"\n                            \"{}.\".format(Rule, RuleLeaf, subrule.__class__))\n        self.__domains = set.union(self.__domains, subrule.domains)\n        self.R.append(subrule)\n        self.W.append(weight)", "response": "Add a subrule to the rule."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef omap(m):\n    '''\n    Create a nested mapping from origin to property to values/attributes covering an entire Versa model\n    '''\n    om = {}\n    for s, p, o, a in m.match():\n        om.setdefault(s, {})\n        om[s].setdefault(p, []).append((o, a))\n    return om", "response": "Create a nested mapping from origin to property to values / attributes covering an entire Versa model"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a list of Versa models to CSV.", "response": "def write(models, csvout, rulelist, write_header, base=None, logger=logging):\n    '''\n    models - one or more input Versa models from which output is generated.\n    '''\n    properties = [ k for (k, v) in rulelist ]\n    numprops = len(properties)\n    headers = [ v for (k, v) in rulelist ]\n    if write_header:\n        csvout.writerow(['id', 'type'] + headers)\n\n    rules = { k: v for (k, v) in rulelist }\n\n    if not isinstance(models, list): models = [models]\n    for m in models:\n        mapped = omap(m)\n        for o, props in mapped.items():\n            rtypes = list(map(operator.itemgetter(0), props.get(RDF_TYPE_REL, [])))\n            if not rtypes: continue\n            #print('RES TYPES:', rtypes)\n            row = [o, fromlist(rtypes)] + [None] * numprops\n            for ix, p in enumerate(properties):\n                v = list(map(operator.itemgetter(0), props.get(p, [])))\n                if v:\n                    row[ix + 2] = fromlist(v)\n                    csvout.writerow(row)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the SEQRES lines into the object", "response": "def parse_seqres(self, pdb):\n    \"\"\"Parse the SEQRES entries into the object\"\"\"\n    \n    seqresre = re.compile(\"SEQRES\")\n    \n    seqreslines = [line for line in pdb.lines if seqresre.match(line)]\n    \n    for line in seqreslines:\n      chain = line[11]\n      resnames = line[19:70].strip()\n      self.setdefault(chain, [])\n      self[chain] += resnames.split()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_atoms(self, pdb):\n    \n    atomre = re.compile(\"ATOM\")\n    \n    atomlines = [line for line in pdb.lines if atomre.match(line)]\n    \n    chainresnums = {}\n    \n    for line in atomlines:\n      chain = line[21]\n      resname = line[17:20]\n      resnum = line[22:27]\n      #print resnum\n      chainresnums.setdefault(chain, [])\n      \n      if resnum in chainresnums[chain]:\n        assert self[chain][chainresnums[chain].index(resnum)] == resname\n      else:\n        if resnum[-1] == ' ':\n          self.setdefault(chain, [])\n          self[chain] += [resname]\n          chainresnums[chain] += [resnum]\n    \n    return chainresnums", "response": "Parse the ATOM entries into the object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating SEQRES lines representing the contents of the sequence", "response": "def seqres_lines(self):\n    \"\"\"Generate SEQRES lines representing the contents\"\"\"\n  \n    lines = []\n  \n    for chain in self.keys():\n      seq = self[chain]\n      serNum = 1\n      startidx = 0\n      while startidx < len(seq):\n        endidx = min(startidx+13, len(seq))\n        lines += [\"SEQRES  %2i %s %4i  %s\\n\" % (serNum, chain, len(seq), \" \".join(seq[startidx:endidx]))]\n        serNum += 1\n        startidx += 13\n    \n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace SEQRES lines with a new sequence.", "response": "def replace_seqres(self, pdb, update_atoms = True):\n    \"\"\"Replace SEQRES lines with a new sequence, optionally removing \n    mutated sidechains\"\"\"\n  \n    newpdb = PDB()\n    inserted_seqres = False\n    entries_before_seqres = set([\"HEADER\", \"OBSLTE\", \"TITLE\",  \"CAVEAT\", \"COMPND\", \"SOURCE\", \n                                 \"KEYWDS\", \"EXPDTA\", \"AUTHOR\", \"REVDAT\", \"SPRSDE\", \"JRNL\", \n                                 \"REMARK\", \"DBREF\",  \"SEQADV\"])\n  \n    mutated_resids = {}\n    \n    if update_atoms:\n      old_seqs = ChainSequences()\n      chainresnums = old_seqs.parse_atoms(pdb)\n    \n      assert self.keys() == old_seqs.keys()\n      \n      for chain in self.keys():\n        assert len(self[chain]) == len(old_seqs[chain])\n        for i in xrange(len(self[chain])):\n          if self[chain][i] != old_seqs[chain][i]:\n            resid = chain + chainresnums[chain][i]\n            mutated_resids[resid] = self[chain][i]\n    \n    for line in pdb.lines:\n    \n      entry = line[0:6]\n      if (not inserted_seqres) and entry not in entries_before_seqres:\n        inserted_seqres = True\n        newpdb.lines += self.seqres_lines()\n      \n      if update_atoms and entry == \"ATOM  \":\n        resid = line[21:27]\n        atom = line[12:16].strip()\n        if not mutated_resids.has_key(resid):\n          newpdb.lines += [line]\n        else:\n          newpdb.lines += [line[:17] + mutated_resids[resid] + line[20:]]\n      elif entry != \"SEQRES\":\n        newpdb.lines += [line]\n    \n    if update_atoms:\n      newpdb.remove_nonbackbone_atoms(mutated_resids.keys())\n    \n    return newpdb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the log line matches the given list of hostname patterns.", "response": "def has_host_match(log_data, hosts):\n    \"\"\"\n    Match the data with a list of hostname patterns. If the log line data\n    doesn't include host information considers the line as matched.\n    \"\"\"\n    hostname = getattr(log_data, 'host', None)\n    if hostname and hostname not in host_cache:\n        for host_pattern in hosts:\n            if host_pattern.search(hostname) is not None:\n                host_cache.add(hostname)\n                return True\n        else:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_matcher(dispatcher, parsers, apptags, matcher='ruled', hosts=tuple(), time_range=None,\n                   time_period=(None, None), patterns=tuple(), invert=False, count=False,\n                   files_with_match=None, max_count=0, only_matching=False, quiet=False,\n                   thread=False, name_cache=None):\n    \"\"\"\n    Create a matcher engine.\n    :return: A matcher function.\n    \"\"\"\n    parsers = CycleParsers(parsers)\n    max_matches = 1 if quiet else max_count\n    use_app_rules = matcher != 'unruled'\n    select_unparsed = matcher == 'unparsed'\n    register_log_lines = not (quiet or count or files_with_match is not None)\n    start_dt, end_dt = get_mktime_period(time_period)\n    pattern_search = create_search_function(invert, only_matching)\n    dispatch_selected = dispatcher.dispatch_selected\n    dispatch_context = dispatcher.dispatch_context\n    display_progress_bar = sys.stdout.isatty() and all(c.name != 'stdout' for c in dispatcher.channels)\n\n    def process_logfile(source, apps, encoding='utf-8'):\n        log_parser = next(parsers)\n        first_event = None\n        last_event = None\n        app_thread = None\n        selected_data = None\n        line_counter = 0\n        unknown_counter = 0\n        selected_counter = 0\n        extra_tags = Counter()\n        dispatcher.reset()\n        read_size = 0\n        progress_bar = None\n\n        with open_resource(source) as logfile:\n            # Set counters and status\n            logfile_name = logfile.name\n\n            fstat = os.fstat(logfile.fileno())\n            file_mtime = datetime.datetime.fromtimestamp(fstat.st_mtime)\n            file_year = file_mtime.year\n            file_month = file_mtime.month\n            prev_year = file_year - 1\n\n            if display_progress_bar:\n                read_size = 0\n                progress_bar = ProgressBar(sys.stdout, fstat.st_size, logfile_name)\n\n            for line in logfile:\n                line = line.decode(encoding)\n                line_counter += 1\n                if line[-1] != '\\n':\n                    line += '\\n'\n\n                if display_progress_bar:\n                    read_size += len(line)\n                    if not line_counter % 100:\n                        progress_bar.redraw(read_size)\n\n                ###\n                # Parses the line and extracts the log data\n                log_match = log_parser.match(line)\n                if log_match is None:\n                    # The current parser doesn't match: try another available parser.\n                    next_parser, log_match = parsers.detect(line)\n                    if log_match is not None:\n                        log_parser = next_parser\n                    elif line_counter == 1:\n                        logger.warning(\"the file '{}' has an unknown format, skip ...\".format(logfile_name))\n                        break\n                    else:\n                        unknown_counter += 1\n                        continue\n                log_data = log_parser.get_data(log_match)\n\n                ###\n                # Process last event repetition (eg. 'last message repeated N times' RFC 3164's logs)\n                if getattr(log_data, 'repeat', None) is not None:\n                    if selected_data is not None:\n                        repeat = int(log_data.repeat)\n                        if not thread:\n                            selected_counter += repeat\n                        if use_app_rules:\n                            app = log_parser.app or get_app(selected_data, apps, apptags, extra_tags)\n                            app.increase_last(repeat)\n                            app.matches += 1\n                            dispatch_context(\n                                key=(app, app_thread),\n                                filename=logfile_name,\n                                line_number=line_counter,\n                                rawlog=line\n                            )\n                        selected_data = None\n                    continue\n                selected_data = None\n\n                ###\n                # Parse the log's timestamp and gets the event datetime\n                year = getattr(\n                    log_data, 'year',\n                    prev_year if MONTHMAP[log_data.month] != '01' and file_month == 1 else file_year\n                )\n                event_dt = get_mktime(\n                    year=year,\n                    month=log_data.month,\n                    day=log_data.day,\n                    ltime=log_data.ltime\n                )\n\n                ###\n                # Scope exclusions\n                if event_dt is None or event_dt < start_dt:\n                    # Excludes lines older than the start datetime\n                    continue\n                elif event_dt > end_dt:\n                    # Excludes lines newer than the end datetime\n                    if fstat.st_mtime < event_dt:\n                        logger.error(\"found anomaly with mtime of file %r at line %d\", logfile_name, line_counter)\n                    logger.warning(\"newer event at line %d: skip the rest of the file %r\", line_counter, logfile_name)\n                    break\n                elif time_range is not None and not time_range.between(log_data.ltime):\n                    # Excludes lines not in time range\n                    continue\n                elif hosts and not has_host_match(log_data, hosts):\n                    # Excludes lines with host restriction\n                    continue\n\n                ###\n                # Search log line with provided not-empty pattern(s)\n                pattern_matched, match, rawlog = pattern_search(line, patterns)\n                if not pattern_matched and not thread:\n                    dispatch_context(filename=logfile_name, line_number=line_counter, rawlog=rawlog)\n                    continue\n\n                ###\n                # App parsing: get the app from parser or from the log data\n                app = log_parser.app or get_app(log_data, apps, apptags, extra_tags)\n                if app is None:\n                    # Unmatchable tag --> skip the line\n                    continue\n                elif use_app_rules:\n                    # Parse the log message with app's rules\n                    app_matched, has_full_match, app_thread, output_data = app.match_rules(log_data)\n                    if not pattern_matched and app_matched and app_thread is None:\n                        continue\n                    if output_data:\n                        rawlog = name_cache.match_to_string(log_match, log_parser.parser.groupindex, output_data)\n\n                    if app_matched:\n                        app.matches += 1\n                        if not has_full_match or select_unparsed:\n                            dispatch_context(\n                                key=(app, app_thread),\n                                filename=logfile_name,\n                                line_number=line_counter,\n                                rawlog=rawlog\n                            )\n                            continue\n                    else:\n                        app.unparsed += 1\n                        if not select_unparsed:\n                            dispatch_context(\n                                key=(app, app_thread),\n                                filename=logfile_name,\n                                line_number=line_counter,\n                                rawlog=rawlog\n                            )\n                            continue\n\n                ###\n                # Event selected: register event's data and datetime\n                selected_data = log_data\n\n                if first_event is None:\n                    first_event = event_dt\n                    last_event = event_dt\n                else:\n                    if first_event > event_dt:\n                        first_event = event_dt\n                    if last_event < event_dt:\n                        last_event = event_dt\n\n                if pattern_matched:\n                    if max_matches and selected_counter >= max_matches:\n                        # Stops iteration if max_count matches is exceeded\n                        break\n                    selected_counter += 1\n                    if files_with_match:\n                        break\n                    if register_log_lines:\n                        dispatch_selected(\n                            key=(app, app_thread),\n                            filename=logfile_name,\n                            line_number=line_counter,\n                            log_data=log_data,\n                            rawlog=rawlog,\n                            match=match\n                        )\n                elif register_log_lines and not only_matching:\n                    # Thread matching\n                    dispatch_context(\n                        key=(app, app_thread),\n                        filename=logfile_name,\n                        line_number=line_counter,\n                        rawlog=rawlog\n                    )\n\n            if display_progress_bar:\n                progress_bar.redraw(fstat.st_size)\n\n        try:\n            for key in list(dispatcher.keys()):\n                dispatcher.flush(key)\n        except (NameError, AttributeError):\n            pass\n\n        # If count option is enabled then register only the number of matched lines.\n        if files_with_match and selected_counter or files_with_match is False and not selected_counter:\n            dispatch_selected(filename=logfile.name)\n        elif count:\n            dispatch_selected(filename=logfile.name, counter=selected_counter)\n\n        return MatcherResult(\n            lines=line_counter,\n            matches=selected_counter,\n            unknown=unknown_counter,\n            extra_tags=extra_tags,\n            first_event=first_event,\n            last_event=last_event\n        )\n\n    return process_logfile", "response": "Create a matcher engine."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dumb_relative_half_prime(n, divisor = None):\n    '''A dumb brute-force algorithm to find a relative prime for n which is approximately n/2 through n/5.\n       It is used for generating spaced colors.\n       Written on a Friday evening. Do not judge!\n    '''\n    if n < 1 or not isinstance(n, int):\n        raise Exception('n must be a positive non-zero integer.')\n    elif n < 7:\n        return dumb_relative_prime_const[n]\n    elif n < 10:\n        divisor = 2.0\n    if not divisor:\n        if n <= 20:\n            divisor = 3.0\n        elif n <= 30:\n            divisor = 4.0\n        else:\n            divisor = 5.0\n    m = int(n / divisor)\n    while m > 1:\n        if fractions.gcd(n, m) == 1:\n            return m\n        m -= 1\n    if divisor > 2.0:\n        return dumb_relative_half_prime(n, divisor - 1.0)", "response": "A dumb brute - force algorithm to find a relative prime for n which is approximately n through n / 2 through n / 5. Do not judge!"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, app):\n        project_path = os.getcwd()\n        if self.args.name is not None:\n            project_path = os.path.join(project_path, self.args.name)\n\n        proto_path = paths.PROTO_PATH\n\n        try:\n            copytree(proto_path, project_path)\n            print(colored('A new glim app created successfully! Happy coding :)', 'green'))\n        except FolderExistsError as e:\n            print(e)\n            print(colored('App already exists', 'red'))", "response": "Function copies the prototype folder into os. getcwd() path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, app):\n        GlimLog.info('Glim server started on %s environment' % self.args.env)\n        try:\n            kwargs = Config.get('app.server.options')\n            run(app.wsgi,\n                host=Config.get('app.server.host'),\n                port=Config.get('app.server.port'),\n                debug=Config.get('app.server.debugger'),\n                reloader=Config.get('app.server.reloader'),\n                server=Config.get('app.server.wsgi'),\n                **kwargs)\n        except Exception as e:\n            print(traceback.format_exc())\n            exit()", "response": "Function starts the web server given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the standard deviation of the positive or negative set of values.", "response": "def get_symmetrical_std_dev(values, take_positive_values, ignore_zeros = True):\n    \"\"\"Computes the standard deviation of either the positive or negative subset of values.\n       The subset is first converted into a symmetrical set of values by unioning it with its complemented/mirrored set\n       along the origin i.e. if x is a value in the subset then both x and -x are members of the symmetrical set.\n       The standard deviation is then computed on this symmetrical set.\n\n       Note: zeroes are generally ignored as they could be included into both sides of a distribution split.\n\n    :param values: A list of numerical values.\n    :param take_positive_values: If True then the subset of positive numbers in values is considered. Otherwise, the subset of negative values is considered.\n    :param ignore_zeros: Whether or not zeroes should be considered when determining the standard deviations.\n    :return:\n    \"\"\"\n    if take_positive_values:\n        if ignore_zeros:\n            temp_pos = np.array([value for value in values if value > 0.0])\n        else:\n            temp_pos = np.array([value for value in values if value >= 0.0])\n    else:\n        if ignore_zeros:\n            temp_pos = np.array([value for value in values if value < 0.0])\n        else:\n            temp_pos = np.array([value for value in values if value <= 0.0])\n\n    # Convert the subset into a symmetrical distribution\n    temp_pos = np.concatenate((temp_pos, -temp_pos))\n\n    # Calculate standard deviations for sigma-based significance cutoffs\n    std_dev = np.std(temp_pos)\n\n    if not take_positive_values:\n        # Return a negative standard deviation for the subset of negative values\n        std_dev = -std_dev\n    return std_dev"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a list of values and splits it into positive and negative values.", "response": "def get_symmetrical_std_devs(values, ignore_zeros = True):\n    \"\"\"Takes a list of values and splits it into positive and negative values. For both of these subsets, a symmetrical\n       distribution is created by mirroring each value along the origin and the standard deviation for both subsets is returned.\n\n    :param values: A list of numerical values.\n    :param ignore_zeros: Whether or not zeroes should be considered when determining the standard deviations.\n    :return: A pair of values - the standard deviations of the positive and negative subsets respectively.\n    \"\"\"\n    pos_stdeviation = get_symmetrical_std_dev(values, True, ignore_zeros = ignore_zeros)\n    neg_stdeviation = get_symmetrical_std_dev(values, False, ignore_zeros = ignore_zeros)\n    return pos_stdeviation, neg_stdeviation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_csv(csv_lines, expect_negative_correlation = False, STDev_cutoff = 1.0, headers_start_with = 'ID', comments_start_with = None, separator = ','):\n    data = {}\n    data['experimental'] = {}\n    data['experimental']['list'] = []\n    data['experimental']['dict'] = {}\n    data['predictions'] = {}\n\n    if comments_start_with != None:\n        lines = [l for l in csv_lines if l.strip() and not(l.strip().startswith(comments_start_with))]\n    else:\n        lines = [l for l in csv_lines if l.strip()]\n\n    headers = lines[0]\n    assert(headers.startswith(headers_start_with))\n    headers = headers.split(separator)\n    num_fields = len(headers)\n    prediction_names = headers[2:]\n\n    skipped_cases = []\n    for line in lines[1:]:\n\n        fields = [t.strip() for t in line.split(separator)]\n        assert(len(fields) == num_fields)\n\n        mut_name = fields[0]\n        expt_value = fields[1]\n\n        # The script as is requires values for all records. We skip any which are missing some data.\n        predicted_values = [t.strip() for t in fields[2:] if t.strip()]\n        if(len(predicted_values) != len(fields) - 2):\n            skipped_cases.append(fields[0])\n            continue\n\n        data['experimental']['dict'][mut_name] = float(expt_value)\n        data['experimental']['list'].append(float(expt_value))\n        predictions = fields[2:]\n        counter = 0\n        for value in predictions:\n            counter += 1\n            prediction_id = counter\n            prediction_name = prediction_names[counter - 1]\n\n            data['predictions'][prediction_id] = data['predictions'].get(prediction_id, dict(name = prediction_name, id = prediction_id))\n            prediction_cases = data['predictions'][prediction_id]\n\n            prediction_cases['list'] = prediction_cases.get('list', [])\n            prediction_cases['dict'] = prediction_cases.get('dict', {})\n\n            prediction_cases['dict']['mut_name'] = float(value)\n            prediction_cases['list'].append(float(value))\n\n    data['skipped_cases'] = skipped_cases\n    for prediction_id, prediction_cases in data['predictions'].iteritems():\n        prediction_cases['array'] = np.array(prediction_cases['list'])\n        pos_STDev, neg_STDev = get_symmetrical_std_devs(prediction_cases['array'])\n        prediction_cases['positive significance threshold'] = pos_STDev\n        prediction_cases['negative significance threshold'] = neg_STDev\n\n    data['experimental']['array'] = np.array(data['experimental']['list'])\n    pos_STDev, neg_STDev = get_symmetrical_std_devs(data['experimental']['array'])\n    data['experimental']['positive significance threshold'] = pos_STDev\n    data['experimental']['negative significance threshold'] = neg_STDev\n\n    for prediction_id, prediction_cases in sorted(data['predictions'].iteritems()):\n        slope_through_origin, r_value_through_origin = least_squares_fixed_origin(prediction_cases['array'], data['experimental']['array'])\n        slope, intercept, r_value, p_value, std_err = stats.linregress(prediction_cases['array'], data['experimental']['array'])\n\n        prediction_cases.update(dict(\n            prediction_id = prediction_id,\n            slope_through_origin = slope_through_origin,\n            R_value_through_origin = r_value_through_origin,\n            slope = slope,\n            R_value = r_value,\n        ))\n\n        warnings = []\n        mae, scaled_mae, warning = calculate_mae(prediction_cases, data['experimental'])\n        accuracy, specificity, sensitivity, significance_specificity, significance_sensitivity, significant_beneficient_sensitivity, significant_beneficient_specificity, significant_beneficient_sensitivity_n, significant_beneficient_specificity_n = determine_correct_sign(prediction_cases, data['experimental'], expect_negative_correlation, STDev_cutoff)\n        if warning:\n            warnings = [warning]\n\n        prediction_cases.update(dict(\n            STDev_cutoff = STDev_cutoff,\n            warnings = warnings,\n            MAE = mae,\n            scaled_MAE = scaled_mae,\n            accuracy = accuracy,\n            specificity = specificity,\n            sensitivity = sensitivity,\n            significance_specificity = significance_specificity,\n            significance_sensitivity = significance_sensitivity,\n            significant_beneficient_sensitivity = (significant_beneficient_sensitivity, significant_beneficient_sensitivity_n),\n            significant_beneficient_specificity = (significant_beneficient_specificity, significant_beneficient_specificity_n),\n        ))\n    return data", "response": "Parses a CSV file containing experimental and predicted data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_csv_file(csv_filepath, expect_negative_correlation = False, STDev_cutoff = 1.0, headers_start_with = 'ID', comments_start_with = None, separator = ','):\n    assert (os.path.exists(csv_filepath))\n    return parse_csv(get_file_lines(csv_filepath),\n                     expect_negative_correlation = expect_negative_correlation, STDev_cutoff = STDev_cutoff, headers_start_with = headers_start_with,\n                     comments_start_with = comments_start_with, separator = separator)", "response": "Parses a CSV file and returns a list of Record objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls parse_csv and returns the analysis in a format similar to get_xy_dataset_statistics in klab. stats. misc.", "response": "def get_std_xy_dataset_statistics(x_values, y_values, expect_negative_correlation = False, STDev_cutoff = 1.0):\n    '''Calls parse_csv and returns the analysis in a format similar to get_xy_dataset_statistics in klab.stats.misc.'''\n    assert(len(x_values) == len(y_values))\n    csv_lines = ['ID,X,Y'] + [','.join(map(str, [c + 1, x_values[c], y_values[c]])) for c in xrange(len(x_values))]\n    data = parse_csv(csv_lines, expect_negative_correlation = expect_negative_correlation, STDev_cutoff = STDev_cutoff)\n\n    assert(len(data['predictions']) == 1)\n    assert(1 in data['predictions'])\n    assert(data['predictions'][1]['name'] == 'Y')\n    summary_data = data['predictions'][1]\n\n    stats = {}\n    for spair in field_name_mapper:\n        stats[spair[1]] = summary_data[spair[0]]\n    if stats['std_warnings']:\n        stats['std_warnings'] = '\\n'.join(stats['std_warnings'])\n    else:\n        stats['std_warnings'] = None\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef active_multiplex(self, state: 'State') -> Tuple['Multiplex']:\n        return tuple(multiplex for multiplex in self.multiplexes if multiplex.is_active(state))", "response": "Return a tuple of all the active multiplexes in the given state."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sanitized_name(self):\n        a = re.split(\"[:/]\", self.name)\n        return \"_\".join([i for i in a if len(i) > 0])", "response": "Sanitize the name of the agent used for file and directory creation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_artifact(self, artifact):\n        if not issubclass(artifact.__class__, Artifact):\n            raise TypeError(\"Artifact to add ({}) is not {}.\"\n                            .format(artifact, Artifact))\n        self._A.append(artifact)", "response": "Adds an artifact to the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_connection(self, addr, **kwargs):\n        if addr not in self._connections:\n            self.connections[addr] = {}\n            for k, v in kwargs.items():\n                self.connections[addr][k] = v\n            return True\n        return False", "response": "Add an agent with given address to current : attr : connections with given information."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_connections(self, conns):\n        rets = []\n        for addr, kwargs in conns:\n            r = self.add_connection(addr, **kwargs)\n            rets.append(r)\n        return rets", "response": "Adds agents from conns to self. connections."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_connections(self, data=False):\n        if data:\n            return self._connections\n        return list(self._connections.keys())", "response": "Get agent s current connections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to random agent from current connections.", "response": "async def random_connection(self):\n        \"\"\"Connect to random agent from current :attr:`connections`.\n\n        :returns: :class:`aiomas.Proxy` object for the connected agent.\n        \"\"\"\n        addr = choice(list(self._connections.keys()))\n        return await self.env.connect(addr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npublish an artifact to the environment.", "response": "def publish(self, artifact):\n        \"\"\"Publish artifact to agent's environment.\n\n        :param artifact: artifact to be published\n        :type artifact: :py:class:`~creamas.core.artifact.Artifact`\n        \"\"\"\n        self.env.add_artifact(artifact)\n        self._log(logging.DEBUG, \"Published {} to domain.\".format(artifact))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasking an agent s opinion about an artifact.", "response": "async def ask_opinion(self, addr, artifact):\n        \"\"\"Ask an agent's opinion about an artifact.\n\n        :param str addr: Address of the agent which opinion is asked\n        :type addr: :py:class:`~creamas.core.agent.CreativeAgent`\n        :param object artifact: artifact to be evaluated\n        :returns: agent's evaluation of the artifact\n        :rtype: float\n\n        This is a shortcut to::\n\n            remote_agent = await self.env.connect(addr)\n            opinion = await remote_agent.evaluate(artifact)\n\n        .. note::\n\n            The artifact object should be serializable by the environment.\n        \"\"\"\n        remote_agent = await self.env.connect(addr)\n        return await remote_agent.evaluate(artifact)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts enrichment by object_type.", "response": "def enrich_json_objects_by_object_type(request, value):\n    \"\"\"\n    Take the given value and start enrichment by object_type. The va\n\n    Args:\n        request (django.http.request.HttpRequest): request which is currently processed\n        value (dict|list|django.db.models.Model):\n            in case of django.db.models.Model object (or list of these\n            objects), to_json method is invoked\n\n    Returns:\n        dict|list\n    \"\"\"\n    time_start_globally = time()\n    if isinstance(value, list):\n        json = [x.to_json() if hasattr(x, \"to_json\") else x for x in value]\n    else:\n        if isinstance(value, dict):\n            json = value\n        else:\n            json = value.to_json()\n    objects, nested = _collect_json_objects(json, by='object_type')\n    for enricher_info in _get_OBJECT_TYPE_ENRICHER_ORDER():\n        if len(enricher_info['object_types']) > 0:\n            enricher_objects = flatten([objects.get(object_type, []) for object_type in enricher_info['object_types']])\n            enricher_nested = any([nested.get(object_type, False) for object_type in enricher_info['object_types']])\n        else:\n            enricher_objects = flatten(objects.values())\n            enricher_nested = any(nested.values())\n        if len(enricher_objects) > 0:\n            time_start = time()\n            enricher_info['enricher'](request, enricher_objects, enricher_nested)\n            LOGGER.debug('enrichment \"{}\" took {} seconds'.format(enricher_info['enricher_name'], time() - time_start))\n            if not enricher_info['pure']:\n                # if the enricher modified object types we must collect objects\n                # again\n                objects, nested = _collect_json_objects(json, by='object_type')\n    LOGGER.debug('The whole enrichment of json objects by their object_type took {} seconds.'.format(time() - time_start_globally))\n    return json"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a request and a JSON object returns the JSON object that is then applied to all the objects in the JSON object and the function applied to those objects.", "response": "def enrich_by_predicate(request, json, fun, predicate, skip_nested=False, **kwargs):\n    \"\"\"\n    Take the JSON, find all its subparts satisfying the given condition and\n    them by the given function. Other key-word arguments are passed to the function.\n\n    .. testsetup::\n\n        from pprint import pprint\n        from proso.django.enrichment import enrich_by_predicate\n        request = None\n\n    .. testcode::\n\n        def enricher(request, json_list, nested):\n            for json_object in json_list:\n                json_object['enriched'] = True\n\n        enriched = enrich_by_predicate(\n            request,\n            [{'object_type': 'example_1'}, {'object_type': 'example_2'}],\n            enricher,\n            lambda x: True\n        )\n\n        pprint(enriched)\n\n    .. testoutput::\n\n        [{'enriched': True, 'object_type': 'example_1'},\n         {'enriched': True, 'object_type': 'example_2'}]\n\n\n    Args:\n        request (django.http.request.HttpRequest): request which is currently processed\n        json (list|dict): in-memory representation of JSON\n        fun: function which is be applied on found objects\n        predicate: function which is applied on all objects to determine which\n            objects should be processed further\n        skip_nested: ignore nested objects\n\n    Returns:\n        list|dict: transformed JSON\n    \"\"\"\n    time_start = time()\n    collected = []\n    memory = {'nested': False}\n\n    def _collect(json_inner, nested):\n        if nested and skip_nested:\n            return\n        if isinstance(json_inner, list):\n            list(map(lambda x: _collect(x, nested), json_inner))\n        elif isinstance(json_inner, dict):\n            if predicate(json_inner):\n                collected.append(json_inner)\n                if nested:\n                    memory['nested'] = True\n            list(map(lambda x: _collect(x, True), list(json_inner.values())))\n    _collect(json, False)\n    if len(collected) > 0:\n        fun(request, collected, memory['nested'], **kwargs)\n    LOGGER.debug(\"enrichment of JSON by predicate by '%s' function took %s seconds\", fun.__name__, (time() - time_start))\n    return json"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enrich_by_object_type(request, json, fun, object_type, skip_nested=False, **kwargs):\n    if not isinstance(object_type, list):\n        object_type = [object_type]\n    predicate = lambda x: 'object_type' in x and x['object_type'] in object_type\n    return enrich_by_predicate(request, json, fun, predicate, skip_nested=skip_nested, **kwargs)", "response": "Given a request and a function that returns a list of objects that are of the given object type and apply it to all the objects in the object type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retrieve(cls, pdb_id, cache_dir = None):\n        '''Creates a PDB object by using a cached copy of the file if it exists or by retrieving the file from the RCSB.'''\n\n        # Check to see whether we have a cached copy\n        pdb_id = pdb_id.upper()\n        if cache_dir:\n            filename = os.path.join(cache_dir, \"%s.pdb\" % pdb_id)\n            if os.path.exists(filename):\n                return cls(read_file(filename))\n\n        # Get a copy from the RCSB\n        contents = rcsb.retrieve_pdb(pdb_id)\n\n        # Create a cached copy if appropriate\n        if cache_dir:\n            write_file(os.path.join(cache_dir, \"%s.pdb\" % pdb_id), contents)\n\n        # Return the object\n        return cls(contents)", "response": "Creates a PDB object by using a cached copy of the file if it exists or by retrieving the file from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, lines = None):\n        '''Parses the PDB file into a indexed representation (a tagged list of lines, see constructor docstring).\n           A set of Atoms is created, including x, y, z coordinates when applicable. These atoms are grouped into Residues.\n           Finally, the limits of the 3D space are calculated to be used for Atom binning.\n\n           ATOM serial numbers appear to be sequential within a model regardless of alternate locations (altLoc, see 1ABE). This\n           code assumes that this holds as this serial number is used as an index.\n           If an ATOM has a corresponding ANISOU record, the latter record uses the same serial number.\n        '''\n        indexed_lines = []\n        MODEL_count = 0\n        records_types_with_atom_serial_numbers = set(['ATOM', 'HETATM', 'TER', 'ANISOU'])\n        removable_records_types_with_atom_serial_numbers = set(['ATOM', 'HETATM', 'ANISOU'])\n        removable_xyz_records_types_with_atom_serial_numbers = set(['ATOM', 'HETATM'])\n        xs, ys, zs = [], [], []\n\n        # atoms maps ATOM/HETATM serial numbers to Atom objects. Atom objects know which Residue object they belong to and Residue objects maintain a list of their Atoms.\n        atoms = {}\n\n        # atoms maps chain -> residue IDs to Residue objects. Residue objects remember which ATOM/HETATM/ANISOU records (stored as Atom objects) belong to them\n        residues = {}\n\n        atom_name_to_group = {}\n        for line in self.lines:\n            record_type = line[:6].strip()\n            if record_type in removable_records_types_with_atom_serial_numbers:\n\n                #altLoc = line[16]\n                atom_name = line[12:16].strip()\n                chain = line[21]\n                resid = line[22:27] # residue ID + insertion code\n                serial_number = int(line[6:11])\n                element_name = None\n                if record_type == 'ATOM':\n                    element_name = line[12:14].strip() # see the ATOM section of PDB format documentation. The element name is stored in these positions, right-justified.\n                    element_name = ''.join([w for w in element_name if w.isalpha()]) # e.g. 1\n                    if atom_name not in atom_name_to_group:\n                        atom_name_to_group[atom_name] = element_name\n                    else:\n                        assert(atom_name_to_group[atom_name] == element_name)\n\n                residues[chain] = residues.get(chain, {})\n                residues[chain][resid] = residues[chain].get(resid, Residue(chain, resid, line[17:20]))\n                new_atom = Atom(residues[chain][resid], atom_name, element_name, serial_number, line[16])\n                residues[chain][resid].add(record_type.strip(), new_atom)\n\n                if record_type in removable_xyz_records_types_with_atom_serial_numbers:\n                    x, y, z = float(line[30:38]), float(line[38:46]), float(line[46:54])\n                    xs.append(x)\n                    ys.append(y)\n                    zs.append(z)\n                    assert(serial_number not in atoms) # the logic of this class relies on this assertion - that placed records have a unique identifier\n                    atoms[serial_number] = new_atom\n                    atoms[serial_number].place(x, y, z, record_type)\n                    indexed_lines.append((record_type, serial_number, line, new_atom))\n                else:\n                    indexed_lines.append((record_type, serial_number, line))\n            else:\n                if record_type == 'MODEL ':\n                    MODEL_count += 1\n                    if MODEL_count > 1:\n                        raise Exception('This code needs to be updated to properly handle NMR structures.')\n                indexed_lines.append((None, line))\n\n        if not xs:\n            raise Exception('No coordinates found.')\n\n        # Calculate the side size needed for a cube to contain all of the points, with buffers to account for edge-cases\n        min_x, min_y, min_z, max_x, max_y, max_z = min(xs), min(ys), min(zs), max(xs), max(ys), max(zs)\n        self.min_x, self.min_y, self.min_z, self.max_x, self.max_y, self.max_z = min(xs)-self.buffer, min(ys)-self.buffer, min(zs)-self.buffer, max(xs)+self.buffer, max(ys)+self.buffer, max(zs)+self.buffer\n        self.max_dimension = (self.buffer * 4) + max(self.max_x - self.min_x, self.max_y - self.min_y, self.max_z - self.min_z)\n        self.residues = residues\n        self.atoms = atoms\n        self.indexed_lines = indexed_lines\n        self.atom_name_to_group = atom_name_to_group", "response": "Parses the PDB file into an indexed representation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bin_atoms(self):\n        '''This function bins the Atoms into fixed-size sections of the protein space in 3D.'''\n\n        # Create the atom bins\n        low_point = numpy.array([self.min_x, self.min_y, self.min_z])\n        high_point = numpy.array([self.max_x, self.max_y, self.max_z])\n        atom_bin_dimensions = numpy.ceil((high_point - low_point) / self.bin_size)\n        self.atom_bin_dimensions = (int(atom_bin_dimensions[0]) - 1, int(atom_bin_dimensions[1]) - 1, int(atom_bin_dimensions[2]) - 1)\n        atom_bins = []\n        for x in range(int(atom_bin_dimensions[0])):\n            atom_bins.append([])\n            for y in range(int(atom_bin_dimensions[1])):\n                atom_bins[x].append([])\n                for z in range(int(atom_bin_dimensions[2])):\n                    atom_bins[x][y].append(Bin(x, y, z))\n\n        # Assign each Atom to a bin\n        for serial_number, atom in self.atoms.iteritems():\n            bin_location = numpy.trunc((atom.point - low_point) / self.bin_size)\n            bin = atom_bins[int(bin_location[0])][int(bin_location[1])][int(bin_location[2])]\n            bin.append(atom)\n            atom.set_bin(bin)\n\n        # Sanity_check\n        if self.safe_mode:\n            num_atoms = 0\n            for x in range(int(atom_bin_dimensions[0])):\n                for y in range(int(atom_bin_dimensions[1])):\n                    for z in range(int(atom_bin_dimensions[2])):\n                        num_atoms += len(atom_bins[x][y][z])\n            assert(num_atoms == len(self.atoms))\n\n        # Snip empty sections (saves a little space after garbage collection - space savings increase with the number of empty arrays in the matrix)\n        blank_section = ()\n        for x in range(int(atom_bin_dimensions[0])):\n            for y in range(int(atom_bin_dimensions[1])):\n                for z in range(int(atom_bin_dimensions[2])):\n                    if not atom_bins[x][y][z]:\n                        atom_bins[x][y][z] = blank_section\n\n        self.atom_bins = atom_bins", "response": "This function bins the Atoms into fixed - size sections of the protein space in 3D."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking to make sure that each atom type is unique per residue.", "response": "def check_residues(self):\n        '''Checks to make sure that each atom type is unique per residue.'''\n        for chain, residue_ids in self.residues.iteritems():\n            for residue_id, residue in residue_ids.iteritems():\n                for record_type, atoms in residue.records.iteritems():\n                    freq = {}\n                    for atom in atoms:\n                        rec_id = atom.name + atom.conformation\n                        freq[rec_id] = freq.get(rec_id, 0)\n                        freq[rec_id] += 1\n                    for atom_type, count in freq.items():\n                        if count > 1:\n                            raise Exception('{0} occurrences of atom type {1} for record type {2} occur in residue {3} in chain {4}.'.format(count, atom_type, record_type, residue_id.strip(), chain))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_atom_serial_numbers_from_pdb_residue_ids(self, pdb_residue_ids, ignore_these_atoms = [], ignore_these_conformations = []):\n        '''Checks to make sure that each atom type is unique per residue.'''\n        atom_list = []\n        for pdb_residue_id in pdb_residue_ids:\n            chain = pdb_residue_id[0]\n            residue_id = pdb_residue_id[1:]\n            if chain in self.residues and residue_id in self.residues[chain]:\n                residue = self.residues[chain][residue_id]\n                for record_type, atoms in residue.records.iteritems():\n                    freq = {}\n                    for atom in atoms:\n                        if atom.name not in ignore_these_atoms and atom.conformation not in ignore_these_conformations:\n                            atom_list.append(atom.serial_number)\n        return atom_list", "response": "Checks to make sure that each atom type is unique per residue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_heavy_atoms_near_atom(self, source_atom, search_radius, atom_hit_cache = set(), restrict_to_CA = False):\n        '''atom_hit_cache is a set of atom serial numbers which have already been tested. We keep track of these to avoid recalculating the distance.\n        '''\n        #todo: Benchmark atom_hit_cache to see if it actually speeds up the search\n\n        non_heavy_atoms = self.get_atom_names_by_group(set(['H', 'D', 'T']))\n        return self.find_atoms_near_atom(source_atom, search_radius, atom_names_to_exclude = non_heavy_atoms, atom_hit_cache = atom_hit_cache, restrict_to_CA = restrict_to_CA)", "response": "Finds heavy atoms near a given atom."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_sidechain_atoms_within_radius_of_residue_objects(self, source_residues, search_radius, find_ATOM_atoms = True, find_HETATM_atoms = False, restrict_to_CA = False):\n        '''for residue in source_residues:\n             for all heavy atoms in residue\n               find all heavy atoms within radius which are within residues (ATOM records)\n           for all heavy atoms found\n             determing the associated residue\n           for all found residues not in source_residues\n             identify all non-backbone atoms\n           return the non-backbone atoms'''\n\n        atom_hit_cache = set()\n        for residue in source_residues:\n            if find_ATOM_atoms:\n                for aatom in residue.get('ATOM'):\n                    self.find_heavy_atoms_near_atom(aatom, search_radius, atom_hit_cache = atom_hit_cache, restrict_to_CA = restrict_to_CA)\n            if find_HETATM_atoms:\n                for hatom in residue.get('HETATM'):\n                    self.find_heavy_atoms_near_atom(hatom, search_radius, atom_hit_cache = atom_hit_cache, restrict_to_CA = restrict_to_CA)\n\n        # Get the list of source_residues\n        loop_residue_ids = set()\n        for sres in source_residues:\n            loop_residue_ids.add(sres.id())\n\n        # Get the list of atoms to be removed (all sidechain atoms - including non-heavy atoms - of the found residues which are not in source_residues)\n        sidechain_atom_serial_numbers = set()\n        nearby_residues = set()\n        nearby_residue_ids = set()\n        for a in atom_hit_cache:\n            residue_id = a.residue.id()\n            if residue_id not in loop_residue_ids:\n                nearby_residues.add(a.residue)\n                nearby_residue_ids.add(residue_id)\n        for nearby_residue in nearby_residues:\n            for aatom in nearby_residue.get('ATOM'):\n                if aatom.name not in backbone_atoms:\n                    sidechain_atom_serial_numbers.add(aatom.serial_number)\n        assert(len(nearby_residue_ids.intersection(loop_residue_ids)) == 0)\n        return sidechain_atom_serial_numbers", "response": "Finds all sidechain atoms within a radius of a residue object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prune_structure_according_to_loop_definitions(self, loops_segments, search_radius, expected_min_loop_length = None, expected_max_loop_length = None, generate_pymol_session = True, check_sequence = False, keep_Ca_buttress_atoms = True):\n        '''Removes the loop residues identified by the residues in loops_segments and all sidechains with heavy atoms\n           within 10A of any heavy atom of the loop.\n           If keep_Ca_buttress_atoms is set then the N and Ca backbone atoms of the first loop residue are kept and the\n             Ca and C backbone atoms of the last loop residue are kept. This is a useful option to use for Rosetta as\n             discarding those atoms can negatively affect some of the loop modeling protocols.\n        '''\n\n        # Extract the list of Residues defined in the loops definitions\n        loop_residues = []\n        loop_N_terminii = []\n        loop_C_terminii = []\n        parsed_sequences = []\n        for loop in loops_segments:\n\n            # Identify the Residues corresponding to the loops file definition\n            start_id = loop.StartResidueID\n            end_id = loop.EndResidueID\n            chain_id = loop.Chain\n            start_residue, end_residue = None, None\n\n            try:\n                start_residue = self.residues[chain_id][loop.StartResidueID]\n                end_residue = self.residues[chain_id][loop.EndResidueID]\n            except Exception, e:\n                raise Exception('Could not find the start or end residue in the chain.')\n\n            if start_residue in loop_residues or end_residue in loop_residues:\n                raise Exception('Error: The loops segments overlap.')\n\n            # We assume that the loops file identifies a range in document order\n            loop_residue_ids = []\n            loop_start = False\n            for l in self.indexed_lines:\n                if l[0] == 'ATOM' or l[0] == 'HETATM':\n                    atom_residue = l[3].residue\n                    if not loop_start:\n                        if atom_residue == start_residue:\n                            loop_start = True\n                            if atom_residue not in loop_residues:\n                                if atom_residue.residue_id not in loop_residue_ids:\n                                    loop_residue_ids.append(atom_residue.residue_id)\n                                loop_residues.append(atom_residue)\n                    else:\n                        if atom_residue not in loop_residues:\n                            if atom_residue.residue_id not in loop_residue_ids:\n                                loop_residue_ids.append(atom_residue.residue_id)\n                            loop_residues.append(atom_residue)\n                        if atom_residue == end_residue:\n                            break\n\n            parsed_sequence = ''.join([loop_residue.get_amino_acid_code() for loop_residue in loop_residues])\n            if check_sequence:\n                if not parsed_sequence == loop.Sequence:\n                    raise Exception('Expected to find sequence {0} but found sequence {1}.'.format(loop.Sequence, parsed_sequence))\n            parsed_sequences.append((parsed_sequence, ';'.join([chain_id + lrid.strip() for lrid in loop_residue_ids])))\n\n            # These parameters currently only makes sense for a single loop\n            if expected_min_loop_length != None and ((expected_min_loop_length > len(loop_residues)) or (expected_min_loop_length > len(loop_residue_ids))):\n                raise Exception('Expected to identify at least {0} residues but {1} were identified.'.format(expected_min_loop_length, len(loop_residues)))\n            if expected_max_loop_length != None and ((expected_max_loop_length < len(loop_residues)) or (expected_max_loop_length < len(loop_residue_ids))):\n                raise Exception('Expected to identify at most {0} residues but {1} were identified.'.format(expected_max_loop_length, len(loop_residues)))\n\n            # Keep track of the loop terminii\n            loop_N_terminii.append(start_residue)\n            loop_C_terminii.append(end_residue)\n\n        # Determine the sidechain atoms to be removed\n        sidechain_atom_serial_numbers = self.find_sidechain_atoms_within_radius_of_residue_objects(loop_residues, search_radius)\n\n        # Determine the loop residue atoms to be removed\n        loop_residues_ids = set()\n        loop_atom_serial_numbers = set()\n        atoms_serial_numbers_to_keep_in_cutting = set()\n        for loop_residue in loop_residues:\n            for aatom in loop_residue.get('ATOM'):\n                if keep_Ca_buttress_atoms:\n                    # Keep the N and CA atoms of the N-terminus side and the CA and C atoms of the C-terminus side\n                    if (loop_residue in loop_N_terminii) and (aatom.name == 'N' or aatom.name == 'CA'):\n                        atoms_serial_numbers_to_keep_in_cutting.add(aatom.serial_number)\n                        continue\n                    elif (loop_residue in loop_C_terminii) and (aatom.name == 'CA' or aatom.name == 'C'):\n                        atoms_serial_numbers_to_keep_in_cutting.add(aatom.serial_number)\n                        continue\n                loop_atom_serial_numbers.add(aatom.serial_number)\n        assert(len(sidechain_atom_serial_numbers.intersection(loop_atom_serial_numbers)) == 0)\n\n        # Create a FASTA file with the loops' sequences\n        FASTA = []\n        FASTA_line_length = self.FASTA_line_length\n        for x in range(len(parsed_sequences)):\n            parsed_sequence = parsed_sequences[x][0]\n            FASTA.append('>loop_{0}|Residues {1}'.format(x + 1, parsed_sequences[x][1].strip()))\n            for idx in range(0, len(parsed_sequence), FASTA_line_length):\n                FASTA.append(parsed_sequence[idx:idx + FASTA_line_length])\n        FASTA_file = '\\n'.join(FASTA)\n\n        bonsai_pdb_content, cutting_pdb_content, PSE_file, PSE_script = self.prune(loop_atom_serial_numbers, sidechain_atom_serial_numbers, atoms_serial_numbers_to_keep_in_cutting = atoms_serial_numbers_to_keep_in_cutting, generate_pymol_session = generate_pymol_session)\n        return bonsai_pdb_content, cutting_pdb_content, PSE_file, PSE_script, FASTA_file", "response": "Prune the structure according to the loops definitions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npruning the structure according to the loops file.", "response": "def prune_structure_according_to_loops_file(self, loops_file_content, search_radius, expected_loop_length = None, generate_pymol_session = True):\n        '''todo: this needs to be rewritten to include the logic in prune_structure_according_to_loop_definitions.'''\n        lf = LoopsFile(loops_file_content)\n        assert(len(lf.data) == 1) # todo: remove\n\n        # Extract the list of Residues defined in the loops file\n        loop_residues = []\n        for loop in lf.data:\n            # Identify the Residues corresponding to the loops file definition\n            start_id = str(loop['start'])\n            end_id = str(loop['end'])\n            start = []\n            end = []\n            for chain, chain_residues in self.residues.iteritems():\n                for res, residue_object in chain_residues.iteritems():\n                    if res.strip() == start_id:\n                        start.append((chain, res, residue_object))\n                    if res.strip() == end_id:\n                        end.append((chain, res, residue_object))\n            if len(start) != len(end) != 1:\n                raise Exception('The PDB is ambiguous with respect to the loops file i.e. more than one PDB residue corresponds to the start or end residue defined in the loops file.')\n            start, end = start[0], end[0]\n\n            # We assume that the loops file identifies a range in document order\n            loop_start = False\n            for l in self.indexed_lines:\n                if l[0] == 'ATOM' or l[0] == 'HETATM':\n                    atom_residue = l[3].residue\n                    if not loop_start:\n                        if atom_residue == start[2]:\n                            loop_start = True\n                            if atom_residue not in loop_residues:\n                                loop_residues.append(atom_residue)\n                    else:\n                        if atom_residue not in loop_residues:\n                            loop_residues.append(atom_residue)\n                        if atom_residue == end[2]:\n                            break\n        if expected_loop_length != None and expected_loop_length != len(loop_residues):\n            raise Exception('Expected to identify {0} residues but {1} were identified.'.format(expected_loop_length, len(loop_residues)))\n\n        # Determine the sidechain atoms to be removed\n        sidechain_atom_serial_numbers = self.find_sidechain_atoms_within_radius_of_residue_objects(loop_residues, search_radius)\n\n        # Determine the loop residue atoms to be removed\n        loop_residues_ids = set()\n        loop_atom_serial_numbers = set()\n        for loop_residue in loop_residues:\n            for aatom in loop_residue.get('ATOM'):\n                loop_atom_serial_numbers.add(aatom.serial_number)\n        assert(len(sidechain_atom_serial_numbers.intersection(loop_atom_serial_numbers)) == 0)\n\n        return self.prune(loop_atom_serial_numbers, sidechain_atom_serial_numbers, generate_pymol_session = generate_pymol_session)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npruning the set of atom serial numbers from the original PDB file.", "response": "def prune(self, arbitrary_atom_serial_numbers, sidechain_atom_serial_numbers = set(), atoms_serial_numbers_to_keep_in_cutting = set(), keep_CA_in_cutting = True, generate_pymol_session = True, bonsai_label = 'Bonsai', cutting_label = 'Cutting', pymol_executable = 'pymol'):\n        '''Returns the content of two PDB files and (optionally) a PyMOL session and associated script.\n           The first returned PDB file (\"bonsai\") is missing the ATOM (and any related ANISOU) and HETATM records identified by atom_serial_numbers.\n           The second returned PDB file (\"cutting\") only contains ATOM, ANISOU, and HETATM records which are identified by atom_serial_numbers.\n           Both PDB objects contain all records from the original PDB which are not ATOM, ANISOU, or HETATM records.\n\n           If keep_CA_in_cutting is set, the cutting will also contain the associated Calpha atoms. This is useful purely\n           to visualize the cutting in the PyMOL session. If a PyMOL session is not to be generated, this option should\n           be set to False.\n           '''\n        bonsai = []\n        cutting = []\n\n        # Determine the set of sidechain residues in case keep_CA_in_cutting is True and we wish to keep those atoms in the cutting\n        sidechain_residues = set()\n        if keep_CA_in_cutting and sidechain_atom_serial_numbers:\n            for line in self.indexed_lines:\n                if line[0] == 'ATOM' and line[1] in sidechain_atom_serial_numbers:\n                    residue_id = line[3].residue.id()\n                    sidechain_residues.add(residue_id[0] + residue_id[1])\n\n        atom_serial_numbers_to_remove = arbitrary_atom_serial_numbers.union(sidechain_atom_serial_numbers)\n        for line in self.indexed_lines:\n            if line[0]: # record type\n                PDB_line = line[2]\n                if line[1] in atom_serial_numbers_to_remove:\n                    cutting.append(PDB_line)\n                else:\n                    if atoms_serial_numbers_to_keep_in_cutting and int(PDB_line[6:11]) in atoms_serial_numbers_to_keep_in_cutting:\n                        cutting.append(PDB_line)\n                    elif keep_CA_in_cutting and PDB_line[21:27] in sidechain_residues and PDB_line[12:16] == ' CA ':\n                        cutting.append(PDB_line)\n                    bonsai.append(PDB_line)\n            else:\n                bonsai.append(line[1])\n                cutting.append(line[1])\n        bonsai_pdb_content = '\\n'.join(bonsai)\n        cutting_pdb_content = '\\n'.join(cutting)\n        PSE_file, PSE_script = None, None\n        try:\n            PSE_file, PSE_script = self.generate_pymol_session(bonsai_pdb_content, cutting_pdb_content, bonsai_label = bonsai_label, cutting_label = cutting_label, pymol_executable = pymol_executable, settings = {})\n        except Exception, e:\n            colortext.error('Failed to generate the PyMOL session: \"{0}\"'.format(e))\n        return bonsai_pdb_content, cutting_pdb_content, PSE_file, PSE_script"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the PyMOL session for the scaffold model and design structures.", "response": "def generate_pymol_session(self, bonsai_pdb_content, cutting_pdb_content, bonsai_label = 'Bonsai', cutting_label = 'Cutting', pymol_executable = 'pymol', settings = {}):\n        ''' Generates the PyMOL session for the scaffold, model, and design structures.\n            Returns this session and the script which generated it.'''\n        if not pymol_load_failed:\n            b = BatchBuilder(pymol_executable = pymol_executable)\n\n            loop_residues = set()\n            for l in cutting_pdb_content.split('\\n'):\n                if l.startswith('ATOM  ') and l[12:16] == ' C  ':\n                    loop_residues.add(l[21:27])\n            loop_residues = sorted(loop_residues)\n\n            structures_list = [\n                (bonsai_label, bonsai_pdb_content, set()),\n                (cutting_label, cutting_pdb_content, loop_residues),\n            ]\n            settings['Main'] = bonsai_label\n            settings['Loop'] = cutting_label\n            PSE_files = b.run(LoopRemovalBuilder, [PDBContainer.from_content_triple(structures_list)], settings = settings)\n            return PSE_files[0], b.PSE_scripts[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates command to inject a new entry point into the injector", "response": "def _generate_injection_cmd(self, meta_data):\n        \"\"\" example injector response:\n        [\n           {\n              \"config_path\":\"/configs/cli_config.py\",\n              \"path\":\"/opt/cia-cli/cia_sdk/config\",\n              \"user\":\"injector\",\n              \"status_code\":201,\n              \"chmod\":755,\n              \"checksum\":\"a4bcf3939dd3a6aa4e04ee9f92131df4\",\n              \"created\":\"2015-08-04T22:48:25Z\",\n              \"updated\":\"2015-08-04T22:48:25Z\",\n              \"group\":\"injector\"\n           }\n        ]\n\n        \"\"\"\n        cmd = []\n        self._validate_templates(meta_data)\n        for i, config_data in enumerate(meta_data):\n            container_path = os.path.join(config_data['path'], config_data['name'])\n\n            cmd.append(\"mkdir\")\n            cmd.append(\"-p\")\n            cmd.append(config_data['path'])\n            cmd.append(\"&&\")\n            cmd.append(\"cp\")\n            cmd.append(\"-f\")\n            cmd.append(config_data['config_path'])\n            cmd.append(container_path)\n            cmd.append(\"&&\")\n            cmd.append(\"chown\")\n            cmd.append(\"{0}:{1}\".format(config_data['user'], config_data['group']))\n            cmd.append(container_path)\n            cmd.append(\"&&\")\n            cmd.append(\"chmod\")\n            cmd.append(six.text_type(config_data['chmod']))\n            cmd.append(container_path)\n\n            if i + 1 < len(meta_data):\n                cmd.append(\"&&\")\n\n        cmd = [\"-c\", \" \".join(cmd)]\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_templates(self, templates):\n        if templates is None:\n            return templates\n\n        if not isinstance(templates, list):\n            raise TypeError(logger.error(\"templates should be a list.\"))\n\n        for template in templates:\n            if not isinstance(template, dict):\n                raise TypeError(logger.error(\"each item to be injected must be a dict.\"))\n\n            if template.get('notifications'):\n                for level, notification in six.iteritems(template.get('notifications')):\n                    if level == 'errors':\n                        logger.error(\n                            \"errors were returned during the injection process. errors: {0}\".format(notification),\n                            extra={\"container\": 'injector'}\n                        )\n                        raise Exception(notification)\n\n            for key in ('user', 'name', 'group', 'chmod', 'config_path', 'path', 'checksum'):\n                if key not in template:\n                    raise KeyError(logger.error(\"The injector didn't return a {0}.\".format(key)))\n\n        return templates", "response": "Validate the templates and return a list of the keys that are valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, attr_name, *args):\n        if not isinstance(attr_name, six.string_types):\n            raise TypeError('attr_name must be a str.')\n\n        # allow retrieval of data with alias or normalized name\n        if '-' in attr_name:\n            attr_name = attr_name.replace('-', '_')\n\n        parent_attr = self\n        attr = getattr(parent_attr, attr_name, None)\n\n        for arg in args:\n            if not isinstance(arg, six.string_types):\n                raise TypeError(\n                    'each additional argument must be a string. {0} was not a string'.format(arg)\n                )\n\n            if hasattr(parent_attr, arg):\n                parent_attr = getattr(parent_attr, arg)\n\n                if hasattr(parent_attr, attr_name):\n                    attr = getattr(parent_attr, attr_name)\n        else:\n            pass\n\n        return attr", "response": "This method will recursively look through the configuration file for the specified attribute name and return the last found value or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef service_references(self):\n        services_blue_print = self._scheme_references.get('services')\n        if services_blue_print is None:\n            raise LookupError('unable to find any services in the config.')\n\n        # TODO: this needs to be cleaned up and made solid. maybe when creating the blueprint ref normalize the damn keys\n        return {key.replace('-', '_'): key for key in services_blue_print['keys']}", "response": "returns a list of service names\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the contents of the configuration file. Will return None if validation is successful or raise an error if validation is not successful.", "response": "def validate(self):\n        \"\"\" Validate the contents of the configuration file. Will return None if validation is successful or\n        raise an error if not.\n        \"\"\"\n        if not isinstance(self._data, dict):\n            raise TypeError('freight forwarder configuration file must be a dict.')\n\n        current_log_level = logger.get_level()\n\n        if self._verbose:\n            logger.set_level('DEBUG')\n        else:\n            logger.set_level('ERROR')\n\n        logger.info('Starting configuration validation', extra={\"formatter\": 'config-start'})\n\n        # copy config dict to allow config data to stay in its original state.\n        config_data = self._data.copy()\n\n        try:\n            self._walk_tree(config_data, ROOT_SCHEME)\n        except ConfigValidationException as e:\n            e.log_error()\n            raise\n\n        logger.info(\"Config validation passed.\", extra={'formatter': 'config-success'})\n\n        logger.set_level(current_log_level)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load(self):\n        if os.path.isdir(self._path):\n            for file_ext in ('yml', 'yaml', 'json'):\n                test_path = os.path.join(self._path, 'freight-forwarder.{0}'.format(file_ext))\n\n                if os.path.isfile(test_path):\n                    self._path = test_path\n                    break\n\n        if os.path.isfile(self._path):\n            file_name, file_extension = os.path.splitext(self._path)\n\n            with open(self._path, 'r') as config_file:\n                if file_extension in ('.yaml', '.yml'):\n                    self._load_yml_config(config_file.read())\n                elif file_extension == '.json':\n                    try:\n                        config_data = json.loads(config_file.read())\n                        self._data  = normalize_keys(config_data)\n                    except Exception:\n                        raise SyntaxError(\"There is a syntax error in your freight-forwarder config.\")\n                else:\n                    raise TypeError(\"Configuration file most be yaml or json.\")\n        else:\n            raise LookupError(\"Was unable to find a freight-forwarder configuration file.\")", "response": "Loads a configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_yml_config(self, config_file):\n        if not isinstance(config_file, six.string_types):\n            raise TypeError('config_file must be a str.')\n\n        try:\n            def construct_yaml_int(self, node):\n                obj  = SafeConstructor.construct_yaml_int(self, node)\n                data = ConfigInt(\n                    obj,\n                    node.start_mark,\n                    node.end_mark\n                )\n\n                return data\n\n            def construct_yaml_float(self, node):\n                obj, = SafeConstructor.construct_yaml_float(self, node)\n                data = ConfigFloat(\n                    obj,\n                    node.start_mark,\n                    node.end_mark\n                )\n\n                return data\n\n            def construct_yaml_str(self, node):\n                # Override the default string handling function\n                # to always return unicode objects\n                obj = SafeConstructor.construct_scalar(self, node)\n\n                assert isinstance(obj, six.string_types)\n                data = ConfigUnicode(\n                    obj,\n                    node.start_mark,\n                    node.end_mark\n                )\n\n                return data\n\n            def construct_yaml_mapping(self, node):\n                obj, = SafeConstructor.construct_yaml_map(self, node)\n                data = ConfigDict(\n                    obj,\n                    node.start_mark,\n                    node.end_mark\n                )\n\n                return data\n\n            def construct_yaml_seq(self, node):\n                obj, = SafeConstructor.construct_yaml_seq(self, node)\n                data = ConfigSeq(\n                    obj,\n                    node.start_mark,\n                    node.end_mark\n                )\n\n                return data\n\n            # SafeConstructor.add_constructor(u'tag:yaml.org,2002:bool',  construct_yaml_bool)\n            SafeConstructor.add_constructor(u'tag:yaml.org,2002:float', construct_yaml_float)\n            SafeConstructor.add_constructor(u'tag:yaml.org,2002:int', construct_yaml_int)\n            SafeConstructor.add_constructor(u'tag:yaml.org,2002:map', construct_yaml_mapping)\n            SafeConstructor.add_constructor(u'tag:yaml.org,2002:seq', construct_yaml_seq)\n            SafeConstructor.add_constructor(u'tag:yaml.org,2002:str', construct_yaml_str)\n\n            data = SafeLoader(config_file).get_data()\n            if data is None:\n                raise AttributeError('The configuration file needs to have data in it.')\n\n            self._data = normalize_keys(data, snake_case=False)\n        except YAMLError as e:\n            if hasattr(e, 'problem_mark'):\n                mark = e.problem_mark\n                raise SyntaxError(\n                    \"There is a syntax error in your freight-forwarder config file line: {0} column: {1}\".format(\n                        mark.line + 1,\n                        mark.column + 1\n                    )\n                )\n            else:\n                raise SyntaxError(\"There is a syntax error in your freight-forwarder config.\")", "response": "Loads a yaml file and assigns the config data to self. _data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge the current configuration file with the given data.", "response": "def _merge_config(self, config_override):\n        \"\"\" overrides and/or adds data to the current configuration file.\n\n        ** This has not been implemented yet.\n\n        :param config_override: A :string: config data to add to or override the current config.\n        \"\"\"\n        if not isinstance(config_override, dict):\n            raise TypeError(\"config override must be a dict\")\n\n        def recursion(config_value, override_value):\n            for key, value in override_value.items():\n                if key in config_value:\n                    if isinstance(value, dict) and isinstance(config_value[key], dict):\n                        recursion(config_value[key], value)\n                    else:\n                        config_value[key] = value\n                else:\n                    config_value[key] = value\n\n        for key, value in config_override.items():\n            if key in self._data:\n                recursion(self._data[key], value)\n            else:\n                self._data[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncollecting unrecognized values from the user supplied for this specific property.", "response": "def _collect_unrecognized_values(self, scheme, data, ancestors):\n        \"\"\" Looks for values that aren't defined in the scheme and returns a dict with any unrecognized values found.\n\n        :param scheme: A :dict:, The scheme defining the validations.\n        :param data: A :dict: user supplied for this specific property.\n        :param ancestors: A :OrderedDict: that provides a history of its ancestors.\n        :rtype: A :dict: of unrecognized configuration properties.\n        \"\"\"\n        if not isinstance(ancestors, OrderedDict):\n            raise TypeError(\"ancestors must be an OrderedDict. type: {0} was passed.\".format(type(ancestors)))\n\n        if not isinstance(scheme, dict):\n            raise TypeError('scheme must be a dict. type: {0} was passed'.format(type(scheme)))\n\n        unrecognized_values = {}\n        if isinstance(data, dict):\n            pruned_scheme = [key for key in scheme.keys() if key not in RESERVED_SCHEME_KEYS and key[0] not in RESERVED_SCHEME_KEYS]\n\n            for key, value in six.iteritems(data):\n                if key in pruned_scheme:\n                    continue\n\n                unrecognized_values[key] = value\n\n            validations = scheme.get('is')\n            if validations and 'one_of' in validations:\n                for nested_scheme in validations['one_of']:\n                    if isinstance(nested_scheme, dict):\n\n                        updated_scheme = self._update_scheme(nested_scheme, ancestors)\n                        pruned_scheme = [key for key in updated_scheme.keys() if key not in RESERVED_SCHEME_KEYS and key[0] not in RESERVED_SCHEME_KEYS]\n                        for key in pruned_scheme:\n                            if key in unrecognized_values:\n                                del unrecognized_values[key]\n        else:\n            # TODO: maybe return an error?\n            pass\n\n        return unrecognized_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the current scheme based off special pre - defined keys and retruns a new updated scheme.", "response": "def _update_scheme(self, scheme, ancestors):\n        \"\"\" Updates the current scheme based off special pre-defined keys and retruns a new updated scheme.\n\n        :param scheme: A :dict:, The scheme defining the validations.\n        :param ancestors: A :OrderedDict: that provides a history of its ancestors.\n        :rtype: A new :dict: with updated scheme values.\n        \"\"\"\n        if not isinstance(ancestors, OrderedDict):\n            raise TypeError(\"ancestors must be an OrderedDict. type: {0} was passed.\".format(type(ancestors)))\n\n        if not isinstance(scheme, dict):\n            raise TypeError('scheme must be a dict. type: {0} was passed'.format(type(scheme)))\n\n        # TODO: what if we have more than one scheme :P need to fix this.\n        definitions = ROOT_SCHEME.get('_')\n        if 'inherit' in scheme:\n            scheme = self._scheme_propagation(scheme, definitions)\n\n        updated_scheme = {}\n        for scheme_key in six.iterkeys(scheme):\n            if not isinstance(scheme_key, six.string_types):\n                raise TypeError('scheme keys are required to be strings. type: {0} was passed.'.format(scheme_key))\n\n            if '@' in scheme_key:\n                ref = scheme_key[1:]\n\n                scheme_reference = self._scheme_references.get(ref)\n                if not scheme_reference:\n                    raise ConfigValidationException(ancestors, ref, scheme_reference, 'required', scheme)\n\n                for reference_key in scheme_reference['keys']:\n                    scheme_reference['scheme'].update(scheme[scheme_key])\n                    updated_scheme[reference_key] = scheme_reference['scheme']\n\n            elif '~' in scheme_key:\n                ref = scheme_key[1:]\n\n                scheme_reference = self._scheme_references.get(ref)\n                if not scheme_reference:\n                    raise LookupError(\"was unable to find {0} in scheme reference.\".format(ref))\n\n                for reference_key in scheme_reference['keys']:\n                    updated_scheme[reference_key] = scheme[scheme_key]\n\n        scheme.update(updated_scheme)\n        return scheme"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_cascading_attr(self, attr_name, *args):\n        attr = self._data.get(attr_name, None)\n        if isinstance(attr, ConfigDict):\n            attr = ConfigDict(attr, attr.start_mark, attr.end_mark)\n        elif isinstance(attr, dict):\n            attr = attr.copy()\n\n        cascading = self._data\n        if args:\n\n            for key in args:\n                if not isinstance(key, six.string_types):\n                    raise TypeError('Every key in args must be a string.')\n\n                if key in cascading:\n                    config_object = cascading.get(key)\n\n                    if config_object:\n                        if attr_name in config_object:\n                            if isinstance(attr, dict):\n                                value = config_object[attr_name]\n\n                                if value is None:\n                                    attr = value\n                                elif isinstance(value, dict):\n                                    attr.update(config_object[attr_name])\n                                else:\n                                    raise LookupError(\n                                        \"Unable to find '{0}'. Obj structure: {1}\".format(\n                                            attr_name, \" -> \".join(args)\n                                        )\n                                    )\n                            else:\n                                attr = config_object[attr_name]\n\n                        cascading = config_object\n                        continue\n                else:\n                    break\n\n        return attr", "response": "This method will traverse the configuration data looking for the specified attribute name and returns the value of that attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _walk_tree(self, data, scheme, ancestors=None, property_name=None, prefix=None):\n        if property_name is None:\n            property_name = 'root'\n            # hack until i add this to references\n            # reorder validates putting required first.  If the data doesn't exist there is no need to continue.\n            order = ['registries'] + [key for key in scheme.keys() if key not in ('registries',)]\n            scheme = OrderedDict(sorted(scheme.items(), key=lambda x: order.index(x[0])))\n\n        if data is None:\n            return\n\n        elif not isinstance(property_name, six.string_types):\n            raise TypeError('property_name must be a string.')\n\n        ancestors = self._update_ancestors(data, property_name, ancestors)\n        if isinstance(ancestors, OrderedDict):\n            if list(ancestors)[0] != 'root':\n                raise LookupError('root must be the first item in ancestors.')\n        else:\n            raise TypeError('ancestors must be an OrderedDict. {0} was passed'.format(type(ancestors)))\n\n        if not isinstance(scheme, dict):\n            raise TypeError('scheme must be a dict. {0} was passed.'.format(type(scheme)))\n        scheme = self._update_scheme(scheme, ancestors)\n\n        if property_name is not None and data:\n            data = self._get_cascading_attr(\n                property_name, *list(ancestors)[1:]\n            ) if scheme.get('cascading', False) else data\n\n        for err in self.__execute_validations(scheme.get('is', {}), data, property_name, ancestors, prefix=prefix):\n            if err:\n                raise err\n            else:\n                self._create_attr(property_name, data, ancestors)\n\n        self.__validate_unrecognized_values(scheme, data, ancestors, prefix)\n\n        self.__populate_scheme_references(scheme, property_name)\n\n        self.__validate_config_properties(scheme, data, ancestors, prefix)", "response": "This function walks the configuration tree validating the data and the validation scheme\n            then updates the data with the data that is validated."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the ancestors of a specific property.", "response": "def _update_ancestors(self, config_data, property_name, ancestors=None):\n        \"\"\" Update ancestors for a specific property.\n\n        :param ancestors: A :OrderedDict:, representing the ancestors of a property.\n        :param config_data: The data that needs to be validated agents the scheme.\n        :param property_name: A :string: of the properties name.\n        :rtype: A :OrderDict: that has been updated with new parents.\n        \"\"\"\n        if not isinstance(property_name, six.string_types):\n            raise TypeError(\"property_key must be a string. type: {0} was passed.\".format(type(property_name)))\n\n        if ancestors is None:\n            ancestors = OrderedDict([('root', config_data)])\n\n        elif not isinstance(ancestors, OrderedDict):\n            raise TypeError(\"ancestors must be an OrderedDict. type: {0} was passed.\".format(type(ancestors)))\n\n        elif 'root' not in ancestors:\n            raise LookupError(\n                'root must be in ancestors. currently in the ancestors chain {0}'.format(', '.join(ancestors.keys()))\n            )\n\n        ancestors = ancestors.copy()\n\n        for previous_key in list(ancestors)[::-1]:\n            previous_item = ancestors[previous_key]\n\n            if isinstance(config_data, dict):\n                if property_name in previous_item:\n                    ancestors[property_name] = config_data\n                    break\n\n        return ancestors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reference_keys(self, reference):\n        if not isinstance(reference, six.string_types):\n            raise TypeError(\n                'When using ~ to reference dynamic attributes ref must be a str. a {0} was provided.'.format(type(reference).__name__)\n            )\n\n        if '~' in reference:\n            reference = reference[1:]\n\n            scheme = self._scheme_references.get(reference)\n            if not scheme:\n                # TODO: need to create nice error here as well and print pretty message.\n                raise LookupError(\n                    \"Was unable to find {0} in the scheme references. \"\n                    \"available references {1}\".format(reference, ', '.join(self._scheme_references.keys()))\n                )\n\n            return scheme['keys']\n        else:\n            raise AttributeError('references must start with ~. Please update {0} and retry.'.format(reference))", "response": "Returns a list of all of the keys for a given reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the validations for a specific configuration value.", "response": "def __execute_validations(self, validations, data, property_name, ancestors, negation=False, prefix=None):\n        \"\"\" Validate the data for a specific configuration value. This method will look up all of the validations provided\n        and dynamically call any validation methods. If a validation fails a error will be thrown.  If no errors are found\n        a attributes will be dynamically created on the Config object for the configuration value.\n\n        :param validations: A :dict: with any required validations and expected values.\n        :param data: the data to validate.\n        :param property_name: A :string:, the properties name.\n        :param ancestors: A :OrderedDict:, representing the ancestors of a property.\n        \"\"\"\n        if not isinstance(ancestors, OrderedDict):\n            raise TypeError(\"ancestors must be an OrderedDict. type: {0} was passed.\".format(type(ancestors)))\n\n        if not isinstance(validations, dict):\n            raise TypeError('validations is required to be a dict. type: {1} was passed.'.format(type(validations)))\n\n        if not isinstance(property_name, six.string_types):\n            raise TypeError(\"property_key must be a string. type: {0} was passed.\".format(type(property_name)))\n\n        # reorder validates putting required first.  If the data doesn't exist there is no need to continue.\n        order = ['type', 'required'] + [key for key in validations.keys() if key not in ('required', 'type')]\n        ordered_validations = OrderedDict(sorted(validations.items(), key=lambda x: order.index(x[0])))\n\n        for validation, value in six.iteritems(ordered_validations):\n            if validation in VALIDATORS:\n\n                if validation == 'not':\n                    # TODO: need to test to make sure this works\n                    for err in self.__execute_validations(value, data, property_name, ancestors, negation, prefix):\n                        yield err\n\n                    continue\n\n                for err in getattr(self, '_{0}'.format(validation))(value, data, property_name, ancestors, negation, prefix):\n                    yield err\n\n            else:\n                raise LookupError(\"{0} isn't a validator or reserved scheme key.\".format(validation))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(name, url, tournament_type=\"single elimination\", **params):\n    params.update({\n        \"name\": name,\n        \"url\": url,\n        \"tournament_type\": tournament_type,\n    })\n\n    return api.fetch_and_parse(\"POST\", \"tournaments\", \"tournament\", **params)", "response": "Create a new tournament."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap_star_digger(item, type_str, data_name='Value'):\n    ret = []\n    if type(item) == dict:\n        if 'Type' in item and item['Type'] == type_str and data_name in item:  # 'Business.Consumer_Product.Description'\n            if len(item[data_name]) > 1:\n                # print 'length error!!!!!!!!!!!'\n                pass\n            return item[data_name]\n        else:\n            for k in item:\n                sub_ret = wrap_star_digger(item[k], type_str, data_name)\n                if sub_ret:\n                    ret.extend(sub_ret)\n    elif type(item) == list:\n        for i in item:\n            sub_ret = wrap_star_digger(i, type_str, data_name)\n            if sub_ret:\n                ret.extend(sub_ret)\n    return ret", "response": "This function will extract all matched target from a Bing s wrap star obj and return a list of all matched target in occurance\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a date from the SWS response object and attempts to parse it using one of the several date formats used by the SWS response object .", "response": "def parse_sws_date(date_string):\n    \"\"\"\n    Takes a date from the SWS response object\n    and attempts to parse it using one of the several\n    datetime formats used by the SWS\n    :param date_string:\n    :return: date object\n    \"\"\"\n    if date_string is None:\n        return None\n    date_formats = [\"%m/%d/%Y\", \"%Y-%m-%d\", \"%Y%m%d\"]\n    datetime_obj = None\n    for fmt in date_formats:\n        try:\n            datetime_obj = datetime.strptime(date_string, fmt)\n        except ValueError:\n            continue\n        break\n    if datetime_obj is None:\n        raise ValueError(\"Unknown SWS date format\")\n    return datetime_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resource(url):\n    response = DAO.getURL(url, {'Accept': 'application/json',\n                                'Connection': 'keep-alive'})\n    if response.status != 200:\n        raise DataFailureException(url, response.status, response.data)\n    return json.loads(response.data)", "response": "Issue a GET request to SWS with the given url and return a response in json format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef users_feature(app):\n\n    # check we have jwt secret configures\n    if not app.config.get('USER_JWT_SECRET', None):\n        raise x.JwtSecretMissing('Please set USER_JWT_SECRET in config')\n\n    # use custom session interface\n    app.session_interface = BoilerSessionInterface()\n\n    # init user service\n    user_service.init(app)\n\n    # init login manager\n    login_manager.init_app(app)\n    login_manager.login_view = 'user.login'\n    login_manager.login_message = None\n\n    @login_manager.user_loader\n    def load_user(id):\n        return user_service.get(id)\n\n    # init OAuth\n    oauth.init_app(app)\n    registry = OauthProviders(app)\n    providers = registry.get_providers()\n    with app.app_context():\n        for provider in providers:\n            if provider not in oauth.remote_apps:\n                oauth.remote_app(provider, **providers[provider])\n                registry.register_token_getter(provider)\n\n    # init principal\n    principal.init_app(app)\n\n    @principal.identity_loader\n    def load_identity():\n        if current_user.is_authenticated:\n            return Identity(current_user.id)\n        session.pop('identity.name', None)\n        session.pop('identity.auth_type', None)\n        return AnonymousIdentity()\n\n    @identity_loaded.connect_via(app)\n    def on_identity_loaded(sender, identity):\n        identity.user = current_user\n        if not current_user.is_authenticated:\n            return\n\n        identity.provides.add(UserNeed(current_user.id))\n        for role in current_user.roles:\n            identity.provides.add(RoleNeed(role.handle))", "response": "Add users feature to the application."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenables request loader based on incomin request object.", "response": "def enable_request_loader():\n    \"\"\"\n    Enable request loader\n    Optional user loader based on incomin request object. This is useful to\n    enable on top of default user loader if you want to authenticate API\n    requests via bearer token header.\n    :return:\n    \"\"\"\n    @login_manager.request_loader\n    def load_user_from_request(request):\n        user = None\n        auth = request.headers.get('Authorization')\n        if auth and auth.startswith('Bearer'):\n            try:\n                token = auth[7:]\n                user = user_service.get_user_by_token(token)\n            except x.UserException as exception:\n                msg = 'JWT token login failed for [{ip}] with message: [{msg}]'\n                msg = msg.format(\n                    ip=request.environ['REMOTE_ADDR'],\n                    msg=str(exception)\n                )\n                current_app.logger.log(msg=msg, level=logging.INFO)\n                abort(401, description=str(exception))\n\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_document(self, name='Test Document', owner_type=0, public=True):\n        '''\n        Create a new document.\n\n        Args:\n            - name (str, default='Test Document'): The doc name\n            - owner_type (int, default=0): 0 for user, 1 for company, 2 for team\n            - public (bool, default=False): Whether or not to make doc public\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n            'name': name,\n            'ownerType': owner_type,\n            'isPublic': public\n        }\n\n        return self._api.request('post', '/api/documents', body=payload)", "response": "Create a new document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename_document(self, did, name):\n        '''\n        Renames the specified document.\n\n        Args:\n            - did (str): Document ID\n            - name (str): New document name\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n            'name': name\n        }\n\n        return self._api.request('post', '/api/documents/' + did, body=payload)", "response": "Renames the specified document."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy the current workspace.", "response": "def copy_workspace(self, uri, new_name):\n        '''\n        Copy the current workspace.\n\n        Args:\n            - uri (dict): the uri of the workspace being copied. Needs to have a did and wid key.\n            - new_name (str): the new name of the copied workspace.\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n            'isPublic': True,\n            'newName': new_name\n        }\n\n        return self._api.request('post', '/api/documents/' + uri['did'] + '/workspaces/' + uri['wvm'] + '/copy', body=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_workspace(self, did, name, version_id=None):\n        '''\n        Create a workspace in the specified document.\n\n        Args:\n            - did (str): the document id of where to create the new workspace\n            - name (str): the new name of the copied workspace.\n            - version_id (str): the ID of the version to be copied into a new workspace\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n            'isPublic': True,\n            'name': name,\n        }\n\n        if version_id:\n            payload['versionId'] = version_id\n\n        return self._api.request('post', '/api/documents/d/' + did + '/workspaces', body=payload)", "response": "Create a workspace in the specified document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_assembly(self, did, wid, name='My Assembly'):\n        '''\n        Creates a new assembly element in the specified document / workspace.\n\n        Args:\n            - did (str): Document ID\n            - wid (str): Workspace ID\n            - name (str, default='My Assembly')\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n            'name': name\n        }\n\n        return self._api.request('post', '/api/assemblies/d/' + did + '/w/' + wid, body=payload)", "response": "Creates a new assembly element in the specified document / workspace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_features(self, did, wid, eid):\n        '''\n        Gets the feature list for specified document / workspace / part studio.\n\n        Args:\n            - did (str): Document ID\n            - wid (str): Workspace ID\n            - eid (str): Element ID\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        return self._api.request('get', '/api/partstudios/d/' + did + '/w/' + wid + '/e/' + eid + '/features')", "response": "Gets the feature list for a specified document workspace and element ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the tessellation of the edges of all parts in a part studio.", "response": "def get_partstudio_tessellatededges(self, did, wid, eid):\n        '''\n        Gets the tessellation of the edges of all parts in a part studio.\n\n        Args:\n            - did (str): Document ID\n            - wid (str): Workspace ID\n            - eid (str): Element ID\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        return self._api.request('get', '/api/partstudios/d/' + did + '/w/' + wid + '/e/' + eid + '/tessellatededges')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a file to a new blob element in a workspace.", "response": "def upload_blob(self, did, wid, filepath='./blob.json'):\n        '''\n        Uploads a file to a new blob element in the specified doc.\n\n        Args:\n            - did (str): Document ID\n            - wid (str): Workspace ID\n            - filepath (str, default='./blob.json'): Blob element location\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        chars = string.ascii_letters + string.digits\n        boundary_key = ''.join(random.choice(chars) for i in range(8))\n\n        mimetype = mimetypes.guess_type(filepath)[0]\n        encoded_filename = os.path.basename(filepath)\n        file_content_length = str(os.path.getsize(filepath))\n        blob = open(filepath)\n\n        req_headers = {\n            'Content-Type': 'multipart/form-data; boundary=\"%s\"' % boundary_key\n        }\n\n        # build request body\n        payload = '--' + boundary_key + '\\r\\nContent-Disposition: form-data; name=\"encodedFilename\"\\r\\n\\r\\n' + encoded_filename + '\\r\\n'\n        payload += '--' + boundary_key + '\\r\\nContent-Disposition: form-data; name=\"fileContentLength\"\\r\\n\\r\\n' + file_content_length + '\\r\\n'\n        payload += '--' + boundary_key + '\\r\\nContent-Disposition: form-data; name=\"file\"; filename=\"' + encoded_filename + '\"\\r\\n'\n        payload += 'Content-Type: ' + mimetype + '\\r\\n\\r\\n'\n        payload += blob.read()\n        payload += '\\r\\n--' + boundary_key + '--'\n\n        return self._api.request('post', '/api/blobelements/d/' + did + '/w/' + wid, headers=req_headers, body=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef part_studio_stl(self, did, wid, eid):\n        '''\n        Exports STL export from a part studio\n\n        Args:\n            - did (str): Document ID\n            - wid (str): Workspace ID\n            - eid (str): Element ID\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        req_headers = {\n            'Accept': 'application/vnd.onshape.v1+octet-stream'\n        }\n        return self._api.request('get', '/api/partstudios/d/' + did + '/w/' + wid + '/e/' + eid + '/stl', headers=req_headers)", "response": "Exports STL export from a part studio"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an assembly instance.", "response": "def create_assembly_instance(self, assembly_uri, part_uri, configuration):\n        '''\n        Insert a configurable part into an assembly.\n\n        Args:\n            - assembly (dict): eid, wid, and did of the assembly into which will be inserted\n            - part (dict): eid and did of the configurable part\n            - configuration (dict): the configuration\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        payload = {\n          \"documentId\": part_uri[\"did\"],\n          \"elementId\": part_uri[\"eid\"],\n          # could be added if needed:\n          # \"partId\": \"String\",\n          # \"featureId\": \"String\",\n          # \"microversionId\": \"String\",\n          \"versionId\": part_uri[\"wvm\"],\n          # \"microversionId\": \"String\",\n          \"isAssembly\": False,\n          \"isWholePartStudio\": True,\n          \"configuration\": self.encode_configuration(part_uri[\"did\"], part_uri[\"eid\"], configuration)\n        }\n        return self._api.request('post', '/api/assemblies/d/' + assembly_uri[\"did\"] + '/' + assembly_uri[\"wvm_type\"] +\n                                 '/' + assembly_uri[\"wvm\"] + '/e/' + assembly_uri[\"eid\"] + '/instances', body=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode_configuration(self, did, eid, parameters):\n        '''\n        Encode parameters as a URL-ready string\n\n        Args:\n            - did (str): Document ID\n            - eid (str): Element ID\n            - parameters (dict): key-value pairs of the parameters to be encoded\n        Returns:\n            - configuration (str): the url-ready configuration string.\n        '''\n        # change to the type of list the API is expecting\n        parameters = [{\"parameterId\": k, \"parameterValue\": v} for (k,v) in parameters.items()]\n\n        payload = {\n            'parameters':parameters\n\n        }\n        req_headers = {\n            'Accept': 'application/vnd.onshape.v1+json',\n            'Content-Type': 'application/json'\n        }\n\n        res = self._api.request('post', '/api/elements/d/' + did  + '/e/' + eid + '/configurationencodings', body=payload, headers=req_headers)\n\n        return json.loads(res.content.decode(\"utf-8\"))[\"encodedId\"]", "response": "Encode parameters as a URL - ready string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_configuration(self, uri):\n        '''\n        get the configuration of a PartStudio\n\n        Args:\n            - uri (dict): points to a particular element\n\n        Returns:\n            - requests.Response: Onshape response data\n        '''\n\n        req_headers = {\n            'Accept': 'application/vnd.onshape.v1+json',\n            'Content-Type': 'application/json'\n        }\n        return self._api.request('get', '/api/partstudios/d/' + uri[\"did\"] + '/' + uri[\"wvm_type\"] + '/' + uri[\"wvm\"] + '/e/' + uri[\"eid\"] + '/configuration', headers=req_headers)", "response": "This method is used to get the configuration of a PartStudio\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the configuration of the specified in the payload", "response": "def update_configuration(self, did, wid, eid, payload):\n        '''\n        Update the configuration specified in the payload\n\n        Args:\n            - did (str): Document ID\n            - eid (str): Element ID\n            - payload (json): the request body\n        Returns:\n            - configuration (str): the url-ready configuration string.\n        '''\n\n        req_headers = {\n            'Accept': 'application/vnd.onshape.v1+json',\n            'Content-Type': 'application/json'\n        }\n\n        res = self._api.request('post', '/api/partstudios/d/' + did + '/w/' + wid + '/e/' + eid + '/configuration', body=payload, headers=req_headers)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_routing(app, view_data):\n\n    routing_modules = convert_routing_module(view_data)\n\n    for module in routing_modules:\n        view = import_string(module.import_path)\n        app.add_url_rule(module.url, view_func=view.as_view(module.endpoint))", "response": "This function applies the routing configuration you ve described in the routing module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retrieve_commands(self, module):\n        commands = []\n\n        for name, obj in inspect.getmembers(module):\n            if name != 'Command' and 'Command' in name:\n                if name != 'GlimCommand':\n                    cobject = getattr(module, name)\n                    commands.append(cobject)\n\n        return commands", "response": "Function smartly imports Command type classes given a module and returns a list of Command instances."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, module):\n        if module is not None:\n            cmds = self.retrieve_commands(module)\n\n            for c in cmds:\n                if self.valid_name(c.name):\n                    cmd = c(self.subparsers)\n                    self.commands.append(cmd)\n                else:\n                    print(colored(\"Warning: Command %s has empty name. It won't be registered\"\n                                  % c, 'yellow'))", "response": "Function registers into self. commands from module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_extension(self, module, extension):\n        if module is not None:\n            cmds = self.retrieve_commands(module)\n            commands = []\n\n            for c in cmds:\n                if self.valid_name(c.name):\n                    name = '%s:%s' % (extension, c.name)\n                    cmd = c(self.subparsers, name)\n                    self.commands.append(cmd)", "response": "Function registers into self. commands from module extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning dispatches the active command line utility. Args ---- args (argparse.parse_args()): The parsed arguments using parser.parse_args() function. Returns ------- command (glim.command.Command): the active command object.", "response": "def match(self, args):\n        \"\"\"\n        Function dispatches the active command line utility.\n\n        Args\n        ----\n          args (argparse.parse_args()):\n            The parsed arguments using parser.parse_args() function.\n\n        Returns\n        -------\n          command (glim.command.Command): the active command object.\n        \"\"\"\n        command = None\n        for c in self.commands:\n            if c.name == args.which:\n                c.args = args\n                command = c\n                break\n        return command"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction runs the active command.", "response": "def dispatch(self, command, app):\n        \"\"\"\n        Function runs the active command.\n\n        Args\n        ----\n          command (glim.command.Command): the command object.\n          app (glim.app.App): the glim app object.\n\n        Note:\n          Exception handling should be done in Command class\n          itself. If not, an unhandled exception may result\n          in app crash!\n        \"\"\"\n        if self.is_glimcommand(command):\n            command.run(app)\n        else:\n            command.run()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_sequence(self, pdb_ID, chain_id, replacement_sequence):\n        '''Replaces a sequence with another. Typically not useful but I use it in the ResidueRelatrix to make sure that the FASTA and SEQRES sequences match.'''\n        old_sequences = self.sequences\n        old_unique_sequences = self.unique_sequences\n        self.sequences = []\n        self.unique_sequences = {}\n        for s in old_sequences:\n            if s[0] == pdb_ID and s[1] == chain_id:\n                self._add_sequence(pdb_ID, chain_id, replacement_sequence)\n            else:\n                self._add_sequence(s[0], s[1], s[2])\n\n        self._find_identical_sequences()", "response": "Replaces a sequence with another. Typically not useful but I use it in the ResidueRelatrix to make sure that the FASTA and SEQRES sequences match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a FASTA object by using a cached copy of the file if it exists or by retrieving the file from the RCSB.", "response": "def retrieve(pdb_id, cache_dir = None, bio_cache = None):\n        '''Creates a FASTA object by using a cached copy of the file if it exists or by retrieving the file from the RCSB.'''\n\n        pdb_id = pdb_id.upper()\n\n        if bio_cache:\n            return FASTA(bio_cache.get_fasta_contents(pdb_id))\n\n        # Check to see whether we have a cached copy\n        if cache_dir:\n            filename = os.path.join(cache_dir, \"%s.fasta\" % pdb_id)\n            if os.path.exists(filename):\n                return FASTA(read_file(filename))\n            else:\n                filename += \".txt\"\n                if os.path.exists(filename):\n                    return FASTA(read_file(filename))\n\n        # Get a copy from the RCSB\n        contents = rcsb.retrieve_fasta(pdb_id)\n\n        # Create a cached copy if appropriate\n        if cache_dir:\n            write_file(os.path.join(cache_dir, \"%s.fasta\" % pdb_id), contents)\n\n        # Return the object\n        return FASTA(contents)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_sequence(self, pdbID, chainID, sequence):\n        '''This is a 'private' function. If you call it directly, call _find_identical_sequences() afterwards to update identical_sequences.'''\n        pdbID = pdbID.upper()\n        self[pdbID] = self.get(pdbID, {})\n        self[pdbID][chainID] = sequence\n        self.sequences.append((pdbID, chainID, sequence))\n        if not self.unique_sequences.get(sequence):\n            self.unique_sequences[sequence] = visible_colors[len(self.unique_sequences) % len(visible_colors)]\n        self.identical_sequences = None", "response": "This is a private function. This is a private function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the identical sequences in the database.", "response": "def _find_identical_sequences(self):\n        ''' Stores the identical sequences in a map with the structure pdb_id -> chain_id -> List(identical chains)\n            where the identical chains have the format 'pdb_id:chain_id'\n            e.g. for 1A2P, we get {'1A2P': {'A': ['1A2P:B', '1A2P:C'], 'C': ['1A2P:A', '1A2P:B'], 'B': ['1A2P:A', '1A2P:C']}}\n        '''\n\n        sequences = self.sequences\n        identical_sequences = {}\n        numseq = len(self.sequences)\n        for x in range(numseq):\n            for y in range(x + 1, numseq):\n                pdbID1 = sequences[x][0]\n                pdbID2 = sequences[y][0]\n                chain1 = sequences[x][1]\n                chain2 = sequences[y][1]\n                if sequences[x][2] == sequences[y][2]:\n                    identical_sequences[pdbID1] = identical_sequences.get(pdbID1, {})\n                    identical_sequences[pdbID1][chain1]=identical_sequences[pdbID1].get(chain1, [])\n                    identical_sequences[pdbID1][chain1].append(\"%s:%s\" % (pdbID2, chain2))\n                    identical_sequences[pdbID2] = identical_sequences.get(pdbID2, {})\n                    identical_sequences[pdbID2][chain2]=identical_sequences[pdbID2].get(chain2, [])\n                    identical_sequences[pdbID2][chain2].append(\"%s:%s\" % (pdbID1, chain1))\n        self.identical_sequences = identical_sequences"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating Sequence objects for each FASTA sequence.", "response": "def get_sequences(self, pdb_id = None):\n        '''Create Sequence objects for each FASTA sequence.'''\n        sequences = {}\n        if pdb_id:\n            for chain_id, sequence in self.get(pdb_id, {}).iteritems():\n                sequences[chain_id] = Sequence.from_sequence(chain_id, sequence)\n        else:\n            for pdb_id, v in self.iteritems():\n                sequences[pdb_id] = {}\n                for chain_id, sequence in v.iteritems():\n                    sequences[pdb_id][chain_id] = Sequence.from_sequence(chain_id, sequence)\n        return sequences"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of chains identifiers for the given PDB ID. If the FASTA file only has one PDB ID the list of chains identifiers for pdb_id is returned. Otherwise the list of chains identifiers for pdb_id is returned.", "response": "def get_chain_ids(self, pdb_id = None, safe_call = False):\n        '''If the FASTA file only has one PDB ID, pdb_id does not need to be specified. Otherwise, the list of chains identifiers for pdb_id is returned.'''\n\n        if pdb_id == None and len(self.keys()) == 1:\n            return self[self.keys()[0]].keys()\n\n        pdbID = pdbID.upper()\n        if not self.get(pdbID):\n            if not safe_call:\n                raise Exception(\"FASTA object does not contain sequences for PDB %s.\" % pdbID)\n            else:\n                return []\n        return self[pdbID].keys()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_json_data(person_data):\n    person = SwsPerson()\n    if person_data[\"BirthDate\"]:\n        person.birth_date = parse(person_data[\"BirthDate\"]).date()\n    person.directory_release = person_data[\"DirectoryRelease\"]\n    person.email = person_data[\"Email\"]\n    person.employee_id = person_data[\"EmployeeID\"]\n    person.first_name = person_data[\"FirstName\"]\n    person.gender = person_data[\"Gender\"]\n    person.last_name = person_data[\"LastName\"]\n    person.student_name = person_data[\"StudentName\"]\n\n    if person_data[\"LastEnrolled\"] is not None:\n        last_enrolled = LastEnrolled()\n        last_enrolled.href = person_data[\"LastEnrolled\"][\"Href\"]\n        last_enrolled.quarter = person_data[\"LastEnrolled\"][\"Quarter\"]\n        last_enrolled.year = person_data[\"LastEnrolled\"][\"Year\"]\n        person.last_enrolled = last_enrolled\n\n    if person_data[\"LocalAddress\"] is not None:\n        address_data = person_data[\"LocalAddress\"]\n        local_address = StudentAddress()\n        local_address.city = address_data[\"City\"]\n        local_address.country = address_data[\"Country\"]\n        local_address.street_line1 = address_data[\"Line1\"]\n        local_address.street_line2 = address_data[\"Line2\"]\n        local_address.postal_code = address_data[\"PostalCode\"]\n        local_address.state = address_data[\"State\"]\n        local_address.zip_code = address_data[\"Zip\"]\n        person.local_address = local_address\n\n    person.local_phone = person_data[\"LocalPhone\"]\n\n    if person_data[\"PermanentAddress\"] is not None:\n        perm_address_data = person_data[\"PermanentAddress\"]\n        permanent_address = StudentAddress()\n        permanent_address.city = perm_address_data[\"City\"]\n        permanent_address.country = perm_address_data[\"Country\"]\n        permanent_address.street_line1 = perm_address_data[\"Line1\"]\n        permanent_address.street_line2 = perm_address_data[\"Line2\"]\n        permanent_address.postal_code = perm_address_data[\"PostalCode\"]\n        permanent_address.state = perm_address_data[\"State\"]\n        permanent_address.zip_code = perm_address_data[\"Zip\"]\n        person.permanent_address = permanent_address\n\n    person.permanent_phone = person_data[\"PermanentPhone\"]\n    person.uwregid = person_data[\"RegID\"]\n    person.student_number = person_data[\"StudentNumber\"]\n    person.student_system_key = person_data[\"StudentSystemKey\"]\n    person.uwnetid = person_data[\"UWNetID\"]\n    person.visa_type = person_data[\"VisaType\"]\n\n    return person", "response": "Processes the JSON data returned by the API call into a uw_sws. models. SwsPerson object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_notice_date(self, response):\n        today = date.today()\n        yesterday = today - timedelta(days=1)\n        tomorrow = today + timedelta(days=1)\n        week = today + timedelta(days=2)\n        next_week = today + timedelta(weeks=1)\n        future = today + timedelta(weeks=3)\n        future_end = today + timedelta(weeks=5)\n\n        json_data = json.loads(response.data)\n        for notice in json_data[\"Notices\"]:\n            if notice[\"NoticeAttributes\"] and\\\n                    len(notice[\"NoticeAttributes\"]) > 0:\n                for attr in notice[\"NoticeAttributes\"]:\n                    if attr[\"DataType\"] == \"date\":\n                        if attr[\"Value\"] == \"yesterday\":\n                            attr[\"Value\"] = yesterday.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"today\":\n                            attr[\"Value\"] = today.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"tomorrow\":\n                            attr[\"Value\"] = tomorrow.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"future\":\n                            attr[\"Value\"] = future.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"future_end\":\n                            attr[\"Value\"] = future_end.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"next_week\":\n                            attr[\"Value\"] = next_week.strftime(\"%Y%m%d\")\n                        elif attr[\"Value\"] == \"week\":\n                            attr[\"Value\"] = week.strftime(\"%Y%m%d\")\n                        else:\n                            pass   # use original\n\n        response.data = json.dumps(json_data)", "response": "Make the date attribte value in the notice mock data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the value and returns the value as latex string", "response": "def ticks_format(value, index):\n    \"\"\"\n    get the value and returns the value as:\n       integer: [0,99]\n       1 digit float: [0.1, 0.99]\n       n*10^m: otherwise\n    To have all the number of the same size they are all returned as latex strings\n\n    http://stackoverflow.com/questions/17165435/matplotlib-show-labels-for-minor-ticks-also\n    \"\"\"\n    exp = np.floor(np.log10(value))\n    base = value/10**exp\n    if exp == 0 or exp == 1:\n        return '${0:d}$'.format(int(value))\n    if exp == -1:\n        return '${0:.1f}$'.format(value)\n    else:\n        return '${0:d}\\\\times10^{{{1:d}}}$'.format(int(base), int(exp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef relative_symlink(target, link_name):\n    link_name = os.path.abspath(link_name)\n    abs_target = os.path.abspath(target)\n    rel_target = os.path.relpath(target, os.path.dirname(link_name))\n\n    if os.path.exists(link_name):\n        os.remove(link_name)\n    os.symlink(rel_target, link_name)", "response": "Make a symlink to target using the shortest possible relative path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, infile):\n        '''Replace: \u4efb\u610f\u306e\u7b87\u6240\u306e\u30d0\u30a4\u30c8\u5217\u3068 \u540c\u30b5\u30a4\u30ba\u306e\u4efb\u610f\u306e\u30d0\u30a4\u30c8\u5217\u3092\u5165\u308c\u63db\u3048\u308b\n        '''\n        gf = infile[31:]\n        same_size_index = []\n        while len(same_size_index) <= 1:\n            index = random.randint(0,len(gf)-1)\n            index_len = len(gf[index])\n            same_size_index = [i for (i,g) in enumerate(gf) if len(g) == index_len]\n        else:\n            same_size_index = random.choice(same_size_index[:])\n        gf[index], gf[same_size_index] = gf[same_size_index], gf[index]\n        return infile[:31] + gf", "response": "Replace the file with a random entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nincrease the file name by one random number.", "response": "def increase(self, infile):\n        '''Increase: \u4efb\u610f\u306e\u7b87\u6240\u306e\u30d0\u30a4\u30c8\u5217\u3068 \u305d\u308c\u3088\u308a\u5927\u304d\u306a\u30b5\u30a4\u30ba\u306e\u4efb\u610f\u306e\u30d0\u30a4\u30c8\u5217\u3068\u5165\u308c\u63db\u3048\u308b\n        '''\n        gf = infile[31:]\n        index = gf.index(random.choice(gf))\n        index_len = len(gf[index])\n        large_size_index = random.choice([gf.index(g) for g in gf if len(g) > index_len])\n        gf[index], gf[large_size_index] = gf[large_size_index], gf[index]\n        return infile[:31] + gf"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrease(self, infile):\n        '''Decrease: \u4efb\u610f\u306e\u7b87\u6240\u306e\u30d0\u30a4\u30c8\u5217\u3092 \u524a\u9664\u3059\u308b\n        '''\n        gf = infile[31:]\n        try:\n            index = random.randint(len(gf)-1, 31)\n        except ValueError:\n            return infile\n        gf = gf[:index] + gf[index+1:]\n        return infile[:31] + gf", "response": "Decrease the file name by one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef swap(self, infile):\n        '''Swap: \u4efb\u610f\u306e\u7b87\u6240\u306e\u30d0\u30a4\u30c8\u5217\u3068 \u4ed6\u306e\u4efb\u610f\u306e\u7b87\u6240\u306e\u30d0\u30a4\u30c8\u5217\u3092\u5165\u308c\u63db\u3048\u308b\n        '''\n        gf = infile[31:]\n        index = gf.index(random.choice(gf))\n        another = gf.index(random.choice(gf))\n        gf[index], gf[another] = gf[another], gf[index]\n        return infile[:31] + gf", "response": "Swap file with random entry"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef params(self, dict):\n        self._configuration.update(dict)\n        self._measurements.update()", "response": "Set the configuration variables for an OnShape part."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing params to OnShape and synchronize the local copy", "response": "def update(self, params=None, client=c):\n        \"\"\"Push params to OnShape and synchronize the local copy\n        \"\"\"\n        uri = self.parent.uri\n        if not params or not self.res:\n            self.get_params()\n            return\n        d = self.payload\n        for k, v in params.items():\n            m = d[\"currentConfiguration\"][self.parameter_map[k]][\"message\"]\n            if isinstance(v, bool) or isinstance(v, str):\n                m[\"value\"] = v\n            else:\n                try:\n                    m[\"expression\"] = str(v)\n                except KeyError:\n                    m[\"value\"] = str(v)\n\n        res = client.update_configuration(uri.did, uri.wvm, uri.eid, json.dumps(d))\n\n        # If it was a good request, update config to be consistent with online.\n        if res.status_code == 200:\n            self.res = res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_params(self):\n        self.res = c.get_configuration(self.parent.uri.as_dict())", "response": "Manually pull params defined in config from OnShape and return a python representation of the params."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the params of response data from the API.", "response": "def params(self):\n        \"\"\"Get the params of response data from the API.\n\n        Returns:\n            - d (dict): Dictionary mapping of all configuration values\n        \"\"\"\n        payload = self.payload\n        d = {}\n        for i, p in enumerate(payload[\"currentConfiguration\"]):\n            type_name = p[\"typeName\"]\n            cp = payload[\"configurationParameters\"][i][\"message\"]\n            name = cp[\"parameterName\"]\n            if type_name == \"BTMParameterQuantity\":\n                try:\n                    v = q(p[\"message\"][\"expression\"])\n                except:\n                    v = q(p[\"message\"][\"value\"], p[\"message\"][\"units\"])\n            elif type_name == \"BTMParameterBoolean\":\n                v = p[\"message\"][\"value\"]\n            elif type_name == \"BTMParameterEnum\":\n                enum = p[\"message\"][\"value\"]\n                enum_map = {d['message']['option']: i for i, d in enumerate(cp['options'])}\n                v = cp['options'][enum_map[enum]]['message']['optionName']\n            d[name] = v\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all local variable names to match OnShape.", "response": "def update(self):\n        \"\"\" Update all local variable names to match OnShape. \"\"\"\n        uri = self.parent.uri\n        script = r\"\"\"\n        function(context, queries) {\n            return getVariable(context, \"measurements\");\n        }\n        \"\"\"\n\n        self.res = c.evaluate_featurescript(uri.as_dict(), script)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(self):\n        if not self.networks():\n            super(FunctionLearning, self).setup()\n            for net in self.networks():\n                self.source(network=net)", "response": "This is a method that is called by the experiment once at the start of the experiment. It does stuff only if there are no networks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake in a set list or tuple scriptnames and returns the symmetric difference of scriptnames and the stored names.", "response": "def SymmetricDifference(self, scriptnames):\n\t\t'''Takes in a set, list, or tuple scriptnames and returns the symmetric difference (as a list)\n\t\tof scriptnames and the stored names.'''\n\t\tscriptnames = set(scriptnames)\n\t\tmyscripts = set(self.scripts.keys())\n\t\treturn list(scriptnames.difference(myscripts).union(myscripts.difference(scriptnames)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of which identify failed jobs in the scriptsRun table.", "response": "def getFailedJobIDs(self, extraLapse = TYPICAL_LAPSE):\n\t\t'''Returns a list of which identify failed jobs in the scriptsRun table.\n\t\t\tIf a time stamp for a job can be found, we return this. The time stamp can be used to index the log.\n\t\t\tIf no time stamp was found, return the name of the script instead.\n\t\t''' \n\t\tscriptsRun = self.scriptsRun\n\t\t\n\t\tfailedJobTimestamps = []\n\t\tnodata = []\n\t\tfor name, details in sorted(scriptsRun.iteritems()):\n\t\t\tif details[\"lastSuccess\"] and expectedScripts.get(name):\n\t\t\t\tif not expectedScripts.check(name, details[\"lastSuccess\"], extraLapse): \n\t\t\t\t\tif details[\"lastRun\"]:\n\t\t\t\t\t\tfailedJobTimestamps.append(details[\"lastRun\"])\n\t\t\t\t\telse:\n\t\t\t\t\t\tnodata.append(name)\n\t\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tif details[\"lastRun\"]:\n\t\t\t\t\tfailedJobTimestamps.append(details[\"lastRun\"])\n\t\t\t\telse:\n\t\t\t\t\tnodata.append(name)\n\t\t\t\tcontinue\n\t\t\t\n\t\t\tif details[\"status\"] & RETROSPECT_FAIL:\n\t\t\t\tfailedJobTimestamps.append(details[\"lastRun\"])\n\t\t\telif details[\"status\"] & RETROSPECT_WARNING:\n\t\t\t\tfailedJobTimestamps.append(details[\"lastRun\"])\n\t\t\n\t\treturn failedJobTimestamps, nodata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generateSummary(self, extraLapse = TYPICAL_LAPSE):\n\t\t'''Generates a summary of the status of the expected scripts broken based on the log.\n\t\t\tThis summary (a list of strings) is returned as well as a list with the dates (which\n\t\t\tcan be used to index the log)of the most recent attempts at the failed jobs. \n\t\t'''\n\t\tscriptsRun = self.scriptsRun\n\t\t\n\t\tbody = []\n\t\t\n\t\tnumberOfFailed = 0\n\t\tnumberWithWarnings = 0\n\t\tfailedList = []\n\t\tsuccessList = []\n\t\twarningsList = []\n\t\t\n\t\tfor name, details in sorted(scriptsRun.iteritems()):\n\t\t\tstatus = None\n\t\t\tdaysSinceSuccess = None\n\t\t\t\n\t\t\tif details[\"lastSuccess\"] and expectedScripts.get(name):\n\t\t\t\tdaysSinceSuccess = expectedScripts.get(name).getDaysSinceLastSuccess(details[\"lastSuccess\"])\n\t\t\t\tif not expectedScripts.check(name, details[\"lastSuccess\"], extraLapse): \n\t\t\t\t\tstatus = \"FAILED\"\n\t\t\telse:\n\t\t\t\tstatus = \"FAILED\"\n\t\t\t\n\t\t\tif not status:\n\t\t\t\tif details[\"status\"] & RETROSPECT_FAIL:\n\t\t\t\t\tstatus = \"FAILED\"\n\t\t\t\telif details[\"status\"] & RETROSPECT_WARNING:\n\t\t\t\t\tstatus = \"WARNINGS\"\n\t\t\t\telif status != \"FAILED\":\n\t\t\t\t\tstatus = \"OK\"\n\t\t\t\n\t\t\tif details[\"lastSuccess\"] and daysSinceSuccess:\n\t\t\t\tlastSuccessDetails = \"Last successful run on %s (%0.1f days ago)\" % (details[\"lastSuccess\"], daysSinceSuccess)\n\t\t\telse:\n\t\t\t\tlastSuccessDetails = \"No recent successful run.\"\n\t\t\t\n\t\t\tif details[\"lastRun\"]:\n\t\t\t\tlastRunDetails = \"Last run on %s (%s)\" % (details[\"lastRun\"], status)\n\t\t\telse:\n\t\t\t\tlastRunDetails = \"No recent run (%s)\" % status\n\t\t\t\t \n\t\t\tif status == \"FAILED\":\n\t\t\t\tnumberOfFailed += 1\n\t\t\t\tfailedList.append(\"%s: %s. %s\" % (name, lastRunDetails, lastSuccessDetails))\n\t\t\telif status == \"WARNINGS\":\n\t\t\t\tnumberWithWarnings += 1\n\t\t\t\twarningsList.append(\"%s: %s. %s\" % (name, lastRunDetails, lastSuccessDetails))\n\t\t\telse:\n\t\t\t\tsuccessList.append(\"%s: %s. %s\" % (name, lastRunDetails, lastSuccessDetails))\n\t\t\n\t\tbody = []\n\t\tif failedList:\n\t\t\tbody.append(\"FAILED JOBS (%d)\" % numberOfFailed)\n\t\t\tbody.append(\"****************\")\n\t\t\tfor j in failedList:\n\t\t\t\tbody.append(j)\n\t\t\tbody.append(\"\\n\")\n\t\tif warningsList:\n\t\t\tbody.append(\"JOBS WITH WARNINGS (%d)\" % numberWithWarnings)\n\t\t\tbody.append(\"***********************\")\n\t\t\tfor j in warningsList:\n\t\t\t\tbody.append(j)\n\t\t\tbody.append(\"\\n\")\n\t\tif successList:\n\t\t\tbody.append(\"SUCCESSFUL JOBS\")\n\t\t\tbody.append(\"***************\")\n\t\t\tfor j in successList:\n\t\t\t\tbody.append(j)\n\t\t\n\t\treturn body, failedList", "response": "Generates a summary of the status of the expected scripts broken based on the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a summary HTML table of the expected scripts broken based on the log.", "response": "def generateSummaryHTMLTable(self, extraLapse = TYPICAL_LAPSE):\n\t\t'''Generates a summary in HTML of the status of the expected scripts broken based on the log.\n\t\t\tThis summary is returned as a list of strings. \n\t\t'''\n\t\tscriptsRun = self.scriptsRun\n\t\t\n\t\thtml = []\n\t\thtml.append(\"<table style='text-align:center;border:1px solid black;margin-left: auto;margin-right: auto;'>\\n\") # Start summary table\n\t\thtml.append('\t<tr><td colspan=\"4\" style=\"text-align:center\"></td></tr>\\n')\n\t\thtml.append('\t<tr style=\"font-weight:bold;background-color:#cccccc;text-align:center\"><td>Script</td><td>Last status</td><td>Last run</td><td>Last success</td></tr>\\n')\n\t\t\n\t\t# Alternate shades between rows\n\t\ttablestyle = ['background-color:#33dd33;', 'background-color:#33ff33;']\n\t\twarningstyle = ['background-color:#EA8737;', 'background-color:#f5b767;']\n\t\tfailstyle = ['background-color:#dd3333;', 'background-color:#ff3333;']\n\t\t\n\t\tcount = 0\n\t\tfor name, details in sorted(scriptsRun.iteritems()):\n\t\t\tstatus = None\n\t\t\t\n\t\t\trowstyle = tablestyle[count % 2]\n\t\t\tif details[\"lastSuccess\"] and expectedScripts.get(name):\n\t\t\t\tif not expectedScripts.check(name, details[\"lastSuccess\"], extraLapse): \n\t\t\t\t\tstatus = \"STOPPED\"\n\t\t\telse:\n\t\t\t\trowstyle = failstyle[count % 2]\n\t\t\t\tstatus = \"FAIL\"\n\t\t\t\t\n\t\t\tlaststatusstyle = tablestyle[count % 2]\n\t\t\tif details[\"status\"] & RETROSPECT_FAIL:\n\t\t\t\tlaststatusstyle = failstyle[count % 2]\n\t\t\t\tstatus = \"FAIL\"\n\t\t\telif status != \"STOPPED\" and details[\"status\"] & RETROSPECT_WARNING:\n\t\t\t\tlaststatusstyle = warningstyle[count % 2]\n\t\t\t\tstatus = \"WARNINGS\"\n\t\t\telif status != \"FAIL\" and status != \"STOPPED\":\n\t\t\t\tstatus = \"OK\"\n\t\t\t\t\n\t\t\t# Start a row\t\n\t\t\thtml.append('<tr style=\"text-align:left;%s\">\\n' % rowstyle)\n\t\t\t\n\t\t\t# Script name field\n\t\t\tif status == \"STOPPED\":\n\t\t\t\thtml.append('\\t<td style=\"%s\">%s</td>\\n' % (failstyle[count % 2], name))\n\t\t\telse:\n\t\t\t\thtml.append('\\t<td style=\"%s\">%s</td>' % (tablestyle[count % 2], name))\n\t\t\t\n\t\t\t\t\n\t\t\t# Last status field\n\t\t\tif details[\"lastRun\"]:\n\t\t\t\tif status == \"STOPPED\":\n\t\t\t\t\thtml.append('\\t<td style=\"%s\"><a href=\"#%s\">%s</a></td>\\n' % (failstyle[count % 2], self.createAnchorID(name, details[\"lastRun\"]), status))\n\t\t\t\telse:\n\t\t\t\t\thtml.append('\\t<td style=\"%s\"><a href=\"#%s\">%s</a></td>\\n' % (laststatusstyle, self.createAnchorID(name, details[\"lastRun\"]), status))\n\t\t\telse:\n\t\t\t\thtml.append('\\t<td style=\"%s\">%s</td>\\n' % (laststatusstyle, status))\n\t\t\t\n\t\t\t# Last run field\n\t\t\tif details[\"lastRun\"]:\n\t\t\t\thtml.append('\\t<td style=\"%s\"><a href=\"#%s\">%s</a></td>\\n' % (laststatusstyle, self.createAnchorID(name, details[\"lastRun\"]), details[\"lastRun\"]))\n\t\t\telse:\n\t\t\t\thtml.append('\\t<td style=\"%s\">none found</td>\\n' % laststatusstyle)\n\t\t\t\n\t\t\t# Last success field\n\t\t\tif details[\"lastSuccess\"]:\n\t\t\t\thtml.append('\\t<td><a href=\"#%s\">%s</a></td>\\n' % (self.createAnchorID(name, details[\"lastSuccess\"]), details[\"lastSuccess\"]))\n\t\t\telse:\n\t\t\t\thtml.append('\\t<td>none found</td>\\n')\n\t\t\thtml.append('</tr>\\n')\n\t\t\tcount += 1\n\t\thtml.append(\"</table>\")\n\t\treturn html"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_mail(template, to, **kwargs):\n\n    def cb():\n        return mail.send(to=to, template=template, **kwargs)\n\n    return signals.send_mail(cb, data={\"to\": to, \"template\": template, \"kwargs\": kwargs})", "response": "Send a mail to a specific recipient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_cors_config(app):\n    if \"CORS\" in app.config:\n        for k, v in app.config[\"CORS\"].items():\n            _ = \"CORS_\" + k.upper()\n            if _ not in app.config:\n                app.config[_] = v", "response": "This function will set the config as CORS_* and the value of the application s config as CORS_*."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap around storage. upload to upload a file conveniently by using set properties.", "response": "def upload_file(_props_key, file, **kw):\n    \"\"\"\n    Wrapper around storage.upload to upload a file conveniently by using set \n    properties, so no need to keep rewriting the same code.\n    config file must have STORAGE_UPLOAD_FILE_PROPS where it contains k/v, ie:\n\n    STORAGE_UPLOAD_FILE_PROPS = {\n        \"profile-image\": {\n            \"extensions\": [\"jpg\", \"jpeg\", \"gif\", \"png\"],\n            \"prefix\": \"/profile-image/\",\n            \"public\": True\n        }, \n        ...\n    }\n\n    upload_file(\"profile-image\", my_file)\n    :param _props_key: (str) a key available in config.STORAGE_UPLOAD_FILE_PROPS\n    :param file: FileStorage object or string location\n    :param kw: extra **kw for \n    :return: Storage object\n    \"\"\"\n    kwargs = {}\n    if _props_key is not None:\n        conf = config(\"STORAGE_UPLOAD_FILE_PROPS\")\n        if not conf:\n            raise ValueError(\"Missing STORAGE_UPLOAD_FILE_PROPS in config\")\n        if _props_key not in conf:\n            raise ValueError(\"Missing '%s' in config STORAGE_UPLOAD_FILE_PROPS\" % _props_key)\n        kwargs.update(conf.get(_props_key))\n    kwargs.update(kw)\n\n    return signals.upload_file(lambda: storage.upload(file, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nalias to delete a file from storage", "response": "def delete_file(fileobj):\n    \"\"\"\n    Alias to delete a file from storage\n    :param fileobj: \n    :return: \n    \"\"\"\n    if not isinstance(fileobj, (flask_cloudy.Object, mocha_db.StorageObject)):\n        raise TypeError(\"Invalid file type. Must be of flask_cloudy.Object\")\n    return signals.delete_file(lambda: fileobj.delete())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a file from the Cloud object.", "response": "def download_file(filename, object_name=None, content=None, as_attachment=True, timeout=60):\n    \"\"\"\n    Alias to download a file object as attachment, or convert some text as . \n    :param filename: the filename with extension.\n        If the file to download is an StorageOject, filename doesn't need to have an extension. \n            It will automatically put it\n        If the file to download is a `content` text, extension is required.\n    :param object_name: the file storage object name\n    :param content: string/bytes of text\n    :param as_attachment: to download as attachment\n    :param timeout: the timeout to download file from the cloud\n    :return: \n    \"\"\"\n    if object_name:\n        file = get_file(object_name)\n        if not isinstance(file, (flask_cloudy.Object, mocha_db.StorageObject)):\n            raise TypeError(\"Can't download file. It must be of StorageObject type\")\n        return file.download_url(timeout=timeout, name=filename)\n    elif content:\n        buff = six.BytesIO()\n        buff.write(content)\n        buff.seek(0)\n        return send_file(buff,\n                         attachment_filename=filename,\n                         as_attachment=as_attachment)\n    raise TypeError(\"`file` object or `content` text must be provided\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paginate(iter, **kwargs):\n    kwargs.setdefault(\"page\", int(request.args.get('page', 1)))\n    kwargs.setdefault(\"per_page\", int(config(\"PAGINATION_PER_PAGE\", 1)))\n    kwargs.setdefault(\"padding\", int(config(\"PAGINATION_PADDING\", 0)))\n    return Paginator(iter, **kwargs)", "response": "A wrapper around the Paginator that takes config data\n    and returns a Paginator object with the pagination options set to the default values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a sqlite filled database of results and return a csv file", "response": "def to_csv(args):\n    \"\"\"Take a sqlite filled database of results and return a csv file\n\n    :param str result_file: the path of the sqlite database\n    :param str output_file: the path of the csv output file\n    :param str delimiter: the desired delimiter for the output csv file\n    \"\"\"\n    result_file = args.result_file\n    output_file = args.output_file\n    delimiter = args.delimiter\n    if not os.path.isfile(result_file):\n        raise OSError(\"Results file does not exists\")\n    headers = ['elapsed', 'epoch', 'turret_name', 'scriptrun_time', 'error']\n    headers_row = {}\n\n    set_database(result_file, db, {})\n\n    results = Result.select()\n\n    for item in results:\n        result_item = item.to_dict()\n        for k in result_item['custom_timers'].keys():\n            if k not in headers:\n                headers.append(k)\n                headers_row[k] = k\n\n    with open(output_file, \"w+\") as f:\n        writer = csv.DictWriter(f, fieldnames=headers, delimiter=delimiter)\n        headers_row.update({\n            'elapsed': 'elapsed time',\n            'epoch': 'epoch (in seconds)',\n            'turret_name': 'turret name',\n            'scriptrun_time': 'transaction time',\n            'error': 'error'\n        })\n        writer.writerow(headers_row)\n        for result_item in results:\n            line = result_item.to_dict()\n            for key, value in line['custom_timers'].items():\n                line[key] = value\n            del line['custom_timers']\n            writer.writerow(line)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fraction_correct(x_values, y_values, x_cutoff = 1.0, y_cutoff = 1.0, ignore_null_values = False):\n    '''My version of the metric used in the Kellogg et al. paper.\n       \"Role of conformational sampling in computing mutation-induced changes in protein structure and stability\", Proteins, Volume 79, Issue 3, pages 830\u2013838, March 2011.\n       http://dx.doi.org/10.1002/prot.22921\n       Description: \"The fraction correct is defined as the number of mutations categorized correctly divided by the total number of mutations in the benchmark set.\"\n    '''\n\n    expected_types, xtypes, ytypes = set([type(None), type(1.0), numpy.float64]), set(map(type, x_values)), set(map(type, x_values))\n    assert(not(xtypes.difference(expected_types)) and not(ytypes.difference(expected_types)))\n\n    num_points = len(x_values)\n    considered_points = num_points\n    assert(num_points == len(y_values))\n    correct = 0.0\n    for i in range(num_points):\n        x = x_values[i]\n        y = y_values[i]\n        if (x == None or y == None or numpy.isnan(x) or numpy.isnan(y)) and ignore_null_values: # If we are missing values then we either discount the case or consider it as incorrect depending on ignore_null_values\n            considered_points -= 1\n        elif (x >= x_cutoff) and (y >= y_cutoff): # both positive\n            correct += 1.0\n        elif (x <= -x_cutoff) and (y <= -y_cutoff): # both negative\n            correct += 1.0\n        elif (-x_cutoff < x < x_cutoff) and (-y_cutoff < y < y_cutoff): # both neutral\n            correct += 1.0\n    return correct / float(considered_points)", "response": "This function calculates the fraction of mutations in a single file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_fraction_correct_values_to_dataframe(dataframe, x_series, y_series, new_label, x_cutoff = 1.0, y_cutoff = 1.0, ignore_null_values = False):\n    '''Adds a new column (new_label) to the dataframe with the fraction correct computed over X and Y values.'''\n    new_series_values = fraction_correct_values(dataframe.index.values.tolist(), dataframe[x_series].values.tolist(), dataframe[y_series].values.tolist(), x_cutoff = x_cutoff, y_cutoff = y_cutoff, ignore_null_values = ignore_null_values)\n    if new_label in dataframe.columns.values:\n        del dataframe[new_label]\n    dataframe.insert(len(dataframe.columns), new_label, new_series_values)", "response": "Adds a new column to the dataframe with the fraction correct computed over X and Y values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fraction_correct_fuzzy_linear(x_values, y_values, x_cutoff = 1.0, x_fuzzy_range = 0.1, y_scalar = 1.0, y_cutoff = None):\n    '''A version of fraction_correct which is more forgiving at the boundary positions.\n       In fraction_correct, if the x value is 1.01 and the y value is 0.99 (with cutoffs of 1.0) then that pair evaluates\n       to zero despite the results being very close to each other.\n       This function corrects for the boundary by overlapping the ranges and attenuating the endpoints.\n       This version of the function uses a linear approach - a classification (positive, negative, neutral resp. P, N, X)\n       is 1 for some range of values, 0 for a separate range, and between 0 and 1 for the in-between range i.e.\n           N       X        P\n          ----\\  /----\\  /-----\n               \\/      \\/\n               /\\      /\\\n          ----/  \\----/  \\----\n       This approach was suggested by Kale Kundert.\n    '''\n    num_points = len(x_values)\n    assert(num_points == len(y_values))\n    correct = 0.0\n    considered_points = 0\n    y_fuzzy_range = x_fuzzy_range * y_scalar\n    if y_cutoff == None:\n        y_cutoff = x_cutoff * y_scalar\n    for i in range(num_points):\n        x = x_values[i]\n        y = y_values[i]\n        xvec = fraction_correct_fuzzy_linear_create_vector(x, x_cutoff, x_fuzzy_range)\n        yvec = fraction_correct_fuzzy_linear_create_vector(y, y_cutoff, y_fuzzy_range)\n        if not(isinstance(xvec, NoneType)) and not(isinstance(yvec, NoneType)):\n            correct += numpy.dot(xvec, yvec)\n            considered_points += 1\n    return correct / float(considered_points)", "response": "A version of fraction_correct which is more forgiving at the boundary positions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmeans absolute / unsigned error.", "response": "def mae(x_values, y_values, drop_missing = True):\n    '''Mean absolute/unsigned error.'''\n    num_points = len(x_values)\n    assert(num_points == len(y_values) and num_points > 0)\n    return numpy.sum(numpy.apply_along_axis(numpy.abs, 0, numpy.subtract(x_values, y_values))) / float(num_points)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunzip a list of values and returns the first value of the function func.", "response": "def error_unzip_helper(values, func, func_kwargs):\n    '''Splits [(x1, y1), (x2, y2), ...] and gives to func'''\n    x_values = [x for x, y in values]\n    y_values = [y for x, y in values]\n    result = func(x_values, y_values, **func_kwargs)\n    if isinstance(result, float):\n        return result\n    else:\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_xy_dataset_statistics(x_values, y_values,\n                               fcorrect_x_cutoff = 1.0, fcorrect_y_cutoff = 1.0, x_fuzzy_range = 0.1, y_scalar = 1.0,\n                               ignore_null_values = False, bootstrap_data = False,\n                               expect_negative_correlation = False, STDev_cutoff = 1.0,\n                               run_standardized_analysis = True,\n                               check_multiple_analysis_for_consistency = True):\n    '''\n    A function which takes two lists of values of equal length with corresponding entries and returns a dict containing\n    a variety of metrics.\n    :param x_values: A list of values for the X-axis (experimental values).\n    :param y_values: A list of values for the X-axis (predicted values).\n    :param fcorrect_x_cutoff: See get_xy_dataset_statistics.\n    :param fcorrect_y_cutoff: See get_xy_dataset_statistics.\n    :param x_fuzzy_range: See get_xy_dataset_statistics.\n    :param y_scalar: See get_xy_dataset_statistics.\n    :param ignore_null_values: Remove records with missing data before running analysis.\n    :param bootstrap_data: Set to True to enable bootstrapping. Bootstrapping data to estimate errors is an expensive operation so is disabled by default.\n    :param expect_negative_correlation: See klab.benchmarking.analysis.ssm::parse_csv().\n    :param STDev_cutoff: See klab.benchmarking.analysis.ssm::parse_csv().\n    :return: A table of statistics.\n    '''\n    assert(len(x_values) == len(y_values))\n\n    num_null_cases = 0\n    if ignore_null_values:\n        truncated_x_values, truncated_y_values = [], []\n        for i in xrange(len(x_values)):\n            if (x_values[i] == None) or (numpy.isnan(x_values[i])):\n                num_null_cases += 1\n            elif (y_values[i] == None) or (numpy.isnan(y_values[i])):\n                num_null_cases += 1\n            else:\n                truncated_x_values.append(x_values[i])\n                truncated_y_values.append(y_values[i])\n        x_values = truncated_x_values\n        y_values = truncated_y_values\n\n    stats = dict(\n        pearsonr = pearsonr(x_values, y_values),\n        spearmanr = spearmanr(x_values, y_values),\n        gamma_CC = gamma_CC(x_values, y_values),\n        MAE = mae(x_values, y_values),\n        normaltestx = normaltest_check(x_values),\n        normaltesty = normaltest_check(y_values),\n        kstestx = kstest(x_values, 'norm'),\n        kstesty = kstest(y_values, 'norm'),\n        ks_2samp = ks_2samp(x_values, y_values),\n        fraction_correct = fraction_correct(x_values, y_values, x_cutoff = fcorrect_x_cutoff, y_cutoff = fcorrect_y_cutoff, ignore_null_values = ignore_null_values),\n        fraction_correct_fuzzy_linear = fraction_correct_fuzzy_linear(x_values, y_values, x_cutoff = fcorrect_x_cutoff, y_cutoff = fcorrect_y_cutoff, x_fuzzy_range = x_fuzzy_range, y_scalar = y_scalar),\n        n = len(x_values),\n        num_null_cases = num_null_cases,\n    )\n    if bootstrap_data:\n        stats.update(dict(\n            pearsonr_error = bootstrap_xy_stat(x_values, y_values, pearsonr),\n            MAE_error = bootstrap_xy_stat(x_values, y_values, mae),\n            fraction_correct_error = bootstrap_xy_stat(x_values, y_values, fraction_correct, func_kwargs = {'x_cutoff' : fcorrect_x_cutoff, 'y_cutoff' : fcorrect_y_cutoff, 'ignore_null_values' : ignore_null_values}),\n        ))\n\n    # Call Samuel Thompson's analysis which uses confidence intervals when considering fraction correct-like metrics\n    if run_standardized_analysis:\n        std_stats = get_std_xy_dataset_statistics(x_values, y_values, expect_negative_correlation = expect_negative_correlation, STDev_cutoff = STDev_cutoff)\n        fields_to_remove = []\n        if check_multiple_analysis_for_consistency:\n            # Make sure that any common analysis agrees\n            fields_to_remove = sorted(set(std_stats.keys()).intersection(stats.keys()))\n            for common_stat in fields_to_remove:\n                s1, s2 = std_stats[common_stat], stats[common_stat]\n                if isinstance(s1, tuple):\n                    s1 = s1[0]\n                if isinstance(s2, tuple):\n                    s2 = s2[0]\n                assert(abs(s1 - s2) < 0.001)\n            for f in fields_to_remove:\n                del std_stats[f]\n\n        stats.update(std_stats)\n\n    return stats", "response": "A function which takes two lists of values of equal length with corresponding entries and returns a dict containing the statistics of the X - axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_xy_dataset_statistics_pandas(dataframe, x_series, y_series, fcorrect_x_cutoff = 1.0, fcorrect_y_cutoff = 1.0, x_fuzzy_range = 0.1, y_scalar = 1.0, ignore_null_values = False,\n                                    bootstrap_data = False,\n                                    expect_negative_correlation = False, STDev_cutoff = 1.0,\n                                    run_standardized_analysis = True,\n                                    check_multiple_analysis_for_consistency = True):\n    '''\n    A version of _get_xy_dataset_statistics which accepts a pandas dataframe rather than X- and Y-value lists.\n    :param dataframe: A pandas dataframe\n    :param x_series: The column name of the X-axis series\n    :param y_series: The column name of the Y-axis series\n    :param fcorrect_x_cutoff: The X-axis cutoff value for the fraction correct metric.\n    :param fcorrect_y_cutoff: The Y-axis cutoff value for the fraction correct metric.\n    :param x_fuzzy_range: The X-axis fuzzy range value for the fuzzy fraction correct metric.\n    :param y_scalar: The Y-axis scalar multiplier for the fuzzy fraction correct metric (used to calculate y_cutoff and y_fuzzy_range in that metric)\n    :return: A table of statistics.\n    '''\n\n    x_values = dataframe[x_series].tolist()\n    y_values = dataframe[y_series].tolist()\n    return _get_xy_dataset_statistics(x_values, y_values,\n                                      fcorrect_x_cutoff = fcorrect_x_cutoff, fcorrect_y_cutoff = fcorrect_y_cutoff, x_fuzzy_range = x_fuzzy_range,\n                                      y_scalar = y_scalar, ignore_null_values = ignore_null_values,\n                                      bootstrap_data = bootstrap_data,\n                                      expect_negative_correlation = expect_negative_correlation,\n                                      STDev_cutoff = STDev_cutoff,\n                                      run_standardized_analysis = run_standardized_analysis,\n                                      check_multiple_analysis_for_consistency = check_multiple_analysis_for_consistency)", "response": "A version of _get_xy_dataset_statistics which accepts a pandas dataframe rather than X - and Y - values lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply quality control checks to the given sequence.", "response": "def apply_quality_control_checks(\n        seq,\n        check_gen9_seqs=True,\n        check_short_length=True,\n        check_local_gc_content=True,\n        check_global_gc_content=True):\n    \"\"\"\n    Raise a ValueError if the given sequence doesn't pass all of the Gen9 \n    quality control design guidelines.  Certain checks can be enabled or \n    disabled via the command line.\n    \"\"\"\n\n    seq = seq.upper()\n    failure_reasons = []\n    \n    # Minimum length\n    if check_short_length:\n        if len(seq) < min_gene_length:\n            failure_reasons.append('minimum_length: Sequence is %d bp long and needs to be at least %d bp'%(len(seq),min_gene_length))\n\n    # Maximum length\n    if len(seq) > max_gene_length:\n        failure_reasons.append('maximum_length: Sequence is %d bp long and needs to be shorter than %d bp'%(len(seq),max_gene_length))\n\n    # Gen9 restricted sequences\n    if check_gen9_seqs:\n        for site in reserved_restriction_sites:\n            pattern = dna.dna_to_re(site)\n            reverse_site = dna.reverse_complement(site)\n            reverse_pattern = dna.dna_to_re(reverse_site)\n\n            if pattern.match(seq):\n                failure_reasons.append('gen9_restricted_sequences: Reserved sequence %s is present'%(site))\n            if reverse_pattern.match(seq):\n                failure_reasons.append('gen9_restricted_sequences: Reverse-complement of reserved sequence %s is present'%(site))\n\n    # Global GC content\n    if check_global_gc_content:\n        gc_content = dna.gc_content(seq)\n\n        if gc_content < global_gc_content_min:\n            failure_reasons.append('global_gc_content_min: Global GC content is %.3f%% and must be at least %.3f%%'%(gc_content,global_gc_content_min))\n\n        if gc_content > global_gc_content_max:\n            failure_reasons.append('global_gc_content_max: Global GC content is %.3f%% and must be less than %.3f%%'%(gc_content,global_gc_content_max))\n\n    # Local GC content (windows)\n    if check_local_gc_content:\n        windows = [seq]\n\n        if local_gc_window_size < len(seq):\n            windows = dna.sliding_window(seq, local_gc_window_size)\n\n        for seq_window in windows:\n            lgc_content = dna.gc_content(seq_window)\n\n            if lgc_content < local_gc_content_min:\n                failure_reasons.append('local_gc_content_min: Local GC content is %.3f%% and must be at least %.3f%%'%(lgc_content,local_gc_content_min))\n                break\n            if lgc_content > local_gc_content_max:\n                failure_reasons.append('local_gc_content_max: Local GC content is %.3f%% and must be less than %.3f%%'%(lgc_content,local_gc_content_max))\n                break\n\n    # Homopolymers\n    for base in dna.dna_bases:\n        homopolymer = base * homopolymer_max_lengths[base]\n        if homopolymer in seq:\n            failure_reasons.append('max_%s_homopolymer: %s'%(\n                base.lower(), dna.case_highlight(seq,a_homopolymer)))\n\n    # Make sure all the checks passed.\n    if failure_reasons:\n        intro = \"The given sequence fails following Gen9 design guidelines:\"\n        raise ValueError('\\n'.join([intro] + failure_reasons))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a dict A -> B and returns another dict A -> B where A is a list where all values are original keys pointing to the same value.", "response": "def group_keys_by_values(d):\n    \"\"\"\n    Take a dict (A -> B( and return another one (B -> [A]). It groups keys\n    from the original dict by their values.\n\n    .. testsetup::\n\n        from proso.dict import group_keys_by_values\n        from pprint import pprint\n\n    .. doctest::\n\n        >>> pprint(group_keys_by_values({1: True, 2: False, 3: True, 4: True}))\n        {False: [2], True: [1, 3, 4]}\n\n    Args:\n        d (dict): original dictionary which will be transformed.\n    Returns:\n        dict: new keys are taken from original values, each new key points to a\n            list where all values are original keys pointing to the same value\n    \"\"\"\n    result = {}\n    for k, v in d.items():\n        saved = result.get(v, [])\n        saved.append(k)\n        result[v] = saved\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef group_keys_by_value_lists(d):\n    result = {}\n    for k, values in d.items():\n        for v in values:\n            saved = result.get(v, [])\n            saved.append(k)\n            result[v] = saved\n    return result", "response": "This function takes a dict and returns another dict where each key points to the same value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the default values for the current species.", "response": "def get_default_values(self):\n        \"\"\"\n        Make a crude estimation of the alignment using the center of mass\n        and general C->N orientation.\n        \"\"\"\n        out = dict(dx=0, dy=0, dz=0, theta=0, phi=0, psi=0)\n        dx, dy, dz, _ = np.mean(self.coord1 - self.coord2, axis=1)\n        out['dx'] = dx\n        out['dy'] = dy\n        out['dz'] = dz\n\n        # C->N vector\n        vec1 = self.coord1[:-1, 1] - self.coord1[:-1, -1]\n        vec2 = self.coord2[:-1, 1] - self.coord2[:-1, -1]\n        vec1 /= np.linalg.norm(vec1)\n        vec2 /= np.linalg.norm(vec2)\n\n        # Find the rotation matrix that converts vec1 to vec2:\n        # http://math.stackexchange.com/questions/180418/#476311\n        v = np.cross(vec1, vec2)\n        s = np.linalg.norm(v) + np.finfo(DTYPE).eps\n\n        c = vec1.dot(vec2)\n        vx = np.array([[0, -v[2], v[1]],\n                       [v[2], 0, -v[0]],\n                       [-v[1], v[0], 0]], dtype=DTYPE)\n        rotation_matrix = np.eye(3) + vx + vx.dot(vx) * (1 - c) / (s * s)\n\n        # Recover the angles from the matrix as seen here:\n        # http://nghiaho.com/?page_id=846\n        out['theta'] = math.atan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n        out['phi'] = math.atan2(-rotation_matrix[2, 0],\n                                math.hypot(rotation_matrix[2, 1],\n                                           rotation_matrix[2, 2]))\n        out['psi'] = math.atan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the rotation - translation matrix for the current language.", "response": "def get_matrix(theta, phi, psi, dx, dy, dz,\n                   matrix=np.zeros((4, 4), dtype=DTYPE),\n                   angles=np.zeros(3, dtype=DTYPE)):\n        \"\"\"\n        Build the rotation-translation matrix.\n\n        It has the form:\n\n        [         | dx ]\n        [    R    | dy ]\n        [         | dz ]\n        [ 0  0  0 | 1  ]\n        \"\"\"\n        # NB!: matrix and angles by default are being overwritten on each call\n        # thus, only created once at compile time.\n\n        angles[0] = theta\n        angles[1] = phi\n        angles[2] = psi\n\n        cx, cy, cz = np.cos(angles)\n        sx, sy, sz = np.sin(angles)\n\n        rotation = matrix[:3, :3]\n        rotation.flat = (cx * cz - sx * cy * sz,\n                         cx * sz + sx * cy * cz, sx * sy,\n                         -sx * cz - cx * cy * sz,\n                         -sx * sz + cx * cy * cz, cx * sy,\n                         sy * sz,\n                         -sy * cz, cy)\n\n        # Translation component\n        matrix[:3, 3] = dx, dy, dz\n        matrix[3, 3] = 1.\n        return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the minimisation target not normalised.", "response": "def _tm(self, theta, phi, psi, dx, dy, dz):\n        \"\"\"\n        Compute the minimisation target, not normalised.\n        \"\"\"\n        matrix = self.get_matrix(theta, phi, psi, dx, dy, dz)\n        coord = matrix.dot(self.coord2)\n        dist = coord - self.coord1\n\n        d_i2 = (dist * dist).sum(axis=0)\n\n        tm = -(1 / (1 + (d_i2 / self.d02)))\n\n        return tm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, outputfile='out.pdb', appended=False):\n        # FIXME some cases don't work.\n        matrix = self.get_matrix(**self.get_current_values())\n\n        out = open(outputfile, 'w')\n        atomid = 1\n        if appended:\n            for line in open(self.pdb1):\n                if not line.startswith('ATOM') or (line[21] != self.chain_1 and line[21] != ' '):\n                    continue\n                out.write(line[:7])\n                out.write('{: >4}'.format(atomid))\n                atomid += 1\n                out.write(line[11:21])\n                out.write('A')\n                out.write(line[22:])\n\n        for line in open(self.pdb2):\n            if not line.startswith('ATOM') or (line[21] != self.chain_2 and line[21] != ' '):\n                continue\n\n            x = float(line[32:38])\n            y = float(line[39:46])\n            z = float(line[48:54])\n            vec = np.array([x, y, z, 1])\n            x, y, z, _ = matrix.dot(vec)\n\n            out.write(line[:7])\n            out.write('{: >4}'.format(atomid))\n            atomid += 1\n            out.write(line[11:21])\n            out.write('B')\n            out.write(line[22:30])\n            out.write('{:>8.3f}{:>8.3f}{:>8.3f}'.format(x, y, z))\n            out.write(line[54:])\n\n        out.close()", "response": "Write the current set of current entries to a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the alignment parameters from the first and second chains of the common residues.", "response": "def _load_data_alignment(self, chain1, chain2):\n        \"\"\"\n        Extract the sequences from the PDB file, perform the alignment,\n        and load the coordinates of the CA of the common residues.\n        \"\"\"\n        parser = PDB.PDBParser(QUIET=True)\n        ppb = PDB.PPBuilder()\n\n        structure1 = parser.get_structure(chain1, self.pdb1)\n        structure2 = parser.get_structure(chain2, self.pdb2)\n\n        seq1 = str(ppb.build_peptides(structure1)[0].get_sequence())\n        seq2 = str(ppb.build_peptides(structure2)[0].get_sequence())\n\n        # Alignment parameters taken from PconsFold renumbering script.\n        align = pairwise2.align.globalms(seq1, seq2, 2, -1, -0.5, -0.1)[0]\n        indexes = set(i for i, (s1, s2) in enumerate(zip(align[0], align[1]))\n                      if s1 != '-' and s2 != '-')\n        coord1 = np.hstack([np.concatenate((r['CA'].get_coord(), (1,)))[:, None]\n                            for i, r in enumerate(structure1.get_residues())\n                            if i in indexes and 'CA' in r]).astype(DTYPE,\n                                                                   copy=False)\n        coord2 = np.hstack([np.concatenate((r['CA'].get_coord(), (1,)))[:, None]\n                            for i, r in enumerate(structure2.get_residues())\n                            if i in indexes and 'CA' in r]).astype(DTYPE,\n                                                                   copy=False)\n\n        self.coord1 = coord1\n        self.coord2 = coord2\n        self.N = len(seq1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_data_index(self, chain1, chain2):\n        parser = PDB.PDBParser(QUIET=True)\n\n        structure1 = parser.get_structure(chain1, self.pdb1)\n        structure2 = parser.get_structure(chain2, self.pdb2)\n\n        residues1 = list(structure1.get_residues())\n        residues2 = list(structure2.get_residues())\n\n        indexes1 = set(r.id[1] for r in residues1)\n        indexes2 = set(r.id[1] for r in residues2)\n\n        indexes = indexes1.intersection(indexes2)\n        self.indexes = indexes.copy()\n        self.N = len(indexes)\n\n        coord1 = []\n        indexes1 = indexes.copy()\n        for r in residues1:\n            if r.id[1] in indexes1 and 'CA' in r:\n                coord1.append(np.concatenate((r['CA'].get_coord(), (1,)))[:, None])\n                # Remove from index to avoid repeated residues\n                indexes1.remove(r.id[1])\n        coord1 = np.hstack(coord1).astype(DTYPE, copy=False)\n\n        coord2 = []\n        for r in residues2:\n            if r.id[1] in indexes and 'CA' in r:\n                coord2.append(np.concatenate((r['CA'].get_coord(), (1,)))[:, None])\n                indexes.remove(r.id[1])\n        coord2 = np.hstack(coord2).astype(DTYPE, copy=False)\n\n        self.coord1 = coord1\n        self.coord2 = coord2", "response": "Load the coordinates of the CA of the common residues."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _json_to_sectionstatus(section_data):\n    section_status = SectionStatus()\n    if section_data[\"AddCodeRequired\"] == 'true':\n        section_status.add_code_required = True\n    else:\n        section_status.add_code_required = False\n    section_status.current_enrollment = int(section_data[\"CurrentEnrollment\"])\n    current_period = int(section_data[\"CurrentRegistrationPeriod\"])\n    section_status.current_registration_period = current_period\n    if section_data[\"FacultyCodeRequired\"] == 'true':\n        section_status.faculty_code_required = True\n    else:\n        section_status.faculty_code_required = False\n\n    limit_estimate = int(section_data[\"LimitEstimateEnrollment\"])\n    section_status.limit_estimated_enrollment = limit_estimate\n\n    indicator = section_data[\"LimitEstimateEnrollmentIndicator\"]\n    section_status.limit_estimate_enrollment_indicator = indicator\n    section_status.room_capacity = int(section_data[\"RoomCapacity\"])\n    section_status.sln = int(section_data[\"SLN\"])\n    section_status.space_available = int(section_data[\"SpaceAvailable\"])\n    if section_data[\"Status\"] == \"open\":\n        section_status.is_open = True\n    else:\n        section_status.is_open = False\n\n    return section_status", "response": "Convert the passed json to a uw_sws. models. SectionStatus object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_script(job_name, job_directory,\n                  job_data_arrays = '', job_setup_commands = '', job_execution_commands = '', job_post_processing_commands = '',\n                  architecture = 'linux-x64', num_tasks = 1, memory_in_GB = 2, scratch_space_in_GB = 1,\n                  runtime_string = '24:00:00', queues = ['long.q'], cluster = 'QB3'):\n    '''This function uses python_script_template to create a script that can execute on the cluster. The template has\n       useful boiler-plate functionality and contains Genshi-style substitution syntax - strings of the form ${varname}\n       inside the template (typically syntax errors) are meant to be replaced with valid code. This function performs\n       the substitutions and returns a hopefully valid cluster script.\n\n       Note that we do not use standard Python-style subsitution syntax as this breaks if you use curly braces in another\n       context e.g. dict definition (even though you can define dicts without braces).\n       '''\n\n    allowed_queues = available_queues[cluster]\n\n    # Check inputs\n    try: assert(int(num_tasks) > 0 and str(num_tasks).isdigit())\n    except: raise JobInitializationException('numtasks should be a non-zero integer.')\n\n    try: assert(int(memory_in_GB) > 0 and str(memory_in_GB).isdigit())\n    except: raise JobInitializationException('memory_in_GB should be a non-zero integer.')\n\n    try: assert(int(scratch_space_in_GB) > 0 and str(scratch_space_in_GB).isdigit())\n    except: raise JobInitializationException('scratch_space_in_GB should be a non-zero integer.')\n\n    mtches = re.match('(\\d{1,2}):(\\d{1,2}):(\\d{1,2})', runtime_string)\n    try:\n        assert(mtches != None)\n        assert(int(mtches.group(2)) < 60)\n        assert(int(mtches.group(3)) < 60)\n    except:\n        raise JobInitializationException('The runtime parameter should be given in the format HH:MM:SS.')\n\n    if not queues:\n        raise JobInitializationException(\"A cluster queue must be specified.\")\n    if 'short.q' in queues:\n        # NOTE: This if/elif block is specific to the QB3 cluster system and is only included for the benefit of QB3 users. Delete this line or alter it to fit your SGE cluster queue names.\n        if not len(queues) == 1:\n            raise JobInitializationException(\"The short queue cannot be specified if any other queue is specified.\")\n    for q in queues:\n        if not (q in allowed_queues):\n            raise JobInitializationException(\"The queue you specified (%s) is invalid. Please use any or either of %.\" % (options['queue'], ', '.join(allowed_queues)))\n\n    # Create the script\n    header = '''\n#!/usr/bin/python\n#$ -S /usr/bin/python\n#$ -N {job_name}\n#$ -o {job_directory}\n#$ -e {job_directory}\n#$ -cwd\n#$ -r y\n#$ -t 1-{num_tasks}\n#$ -l arch={architecture}\n#$ -l mem_free={memory_in_GB}G\n#$ -l scratch={scratch_space_in_GB}G\n#$ -l h_rt={runtime_string}\n    '''.format(**locals())\n    if queues:\n        queues = ','.join(queues)\n        header = header.strip() + '\\n#$ -q {queues}'.format(**locals())\n\n    template_file = os.path.join(os.path.split(os.path.realpath(__file__))[0], 'python_script_template.py')\n    template = read_file(template_file)\n    template = template.replace('${JOB_NAME}', job_name)\n    template = template.replace('${JOB_DATA_ARRAYS}', '%s' % job_data_arrays.strip())\n    template = template.replace('${JOB_SETUP_COMMANDS}', '%s' % job_setup_commands.strip())\n    template = template.replace('${JOB_EXECUTION_COMMANDS}', '%s' % job_execution_commands.strip())\n    template = template.replace('${JOB_POST_PROCESSING_COMMANDS}', '%s' % job_post_processing_commands.strip())\n    return '\\n\\n'.join(map(string.strip, [header, template]))", "response": "This function creates a script that can be used to execute a cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef submit(command_filename, workingdir, send_mail = False, username = None):\n    '''Submit the given command filename to the queue. Adapted from the qb3 example.'''\n\n    # Open streams\n    command_filename = command_filename\n    outfile = command_filename + \".out\"\n    file_stdout = open(outfile, 'w')\n\n    # Form command\n    command = ['qsub']\n\n    if send_mail and username:\n        #username = 'Shane.OConnor@ucsf.edu'\n        command.extend(['-m', 'eas', '-M', '%s@chef.compbio.ucsf.edu' % username])\n    command.append(command_filename)\n\n    # Submit the job and capture output.\n    try:\n        subp = subprocess.Popen(command, stdout=file_stdout, stderr=file_stdout, cwd=workingdir)\n    except Exception, e:\n        colortext.error('Failed running qsub command: %s in cwd %s.' % (command, workingdir))\n        raise\n\n    waitfor = 0\n    errorcode = subp.wait()\n    file_stdout.close()\n\n    file_stdout = open(outfile, 'r')\n    output = file_stdout.read().strip()\n    file_stdout.close()\n\n    if errorcode != 0:\n        colortext.error('Failed running qsub command: %s in cwd %s.' % (command, workingdir))\n        raise Exception(output)\n\n    # Match job id\n    # This part of the script may be error-prone as it depends on the server message.\n    matches = re.match('Your job-array (\\d+).(\\d+)-(\\d+):(\\d+)', output)\n    if not matches:\n        matches = re.match('Your job (\\d+) \\(\".*\"\\) has been submitted.*', output)\n\n    if matches:\n        jobid = int(matches.group(1))\n    else:\n        jobid = -1\n\n    output = output.replace('\"', \"'\")\n    if output.startswith(\"qsub: ERROR\"):\n        raise Exception(output)\n\n    os.remove(outfile)\n    #os.remove(command_filename)\n\n    return jobid, output", "response": "Submit the given command filename to the queue. Adapted from the qb3 example."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake in a list of PDB lines and renumbers the atoms appropriately", "response": "def renumber_atoms(lines):\n    '''\n    Takes in a list of PDB lines and renumbers the atoms appropriately\n    '''\n    new_lines = []\n    current_number = 1\n    for line in lines:\n        if line.startswith('ATOM') or line.startswith('HETATM'):\n            new_lines.append(\n                line[:6] + string.rjust('%d' % current_number, 5) + line[11:]\n            )\n            current_number += 1\n        else:\n            if line.startswith('TER'):\n                current_number += 1\n            new_lines.append(line)\n    return new_lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving alternate location identifiers from the list of lines.", "response": "def clean_alternate_location_indicators(lines):\n    '''\n    Keeps only the first atom, if alternated location identifiers are being used\n    Removes alternate location ID charactor\n    '''\n    new_lines = []\n    previously_seen_alt_atoms = set()\n    for line in lines:\n        if line.startswith('ATOM'):\n            alt_loc_id = line[16]\n            if alt_loc_id != ' ':\n                atom_name = line[12:16].strip()\n                res_name = line[17:20].strip()\n                chain = line[21]\n                resnum = long( line[22:26].strip() )\n                loc_tup = (atom_name, res_name, chain, resnum)\n                if loc_tup in previously_seen_alt_atoms:\n                    # Continue main for loop\n                    continue\n                else:\n                    previously_seen_alt_atoms.add( loc_tup )\n                    line = line[:16] + ' ' + line[17:]\n        new_lines.append(line)\n    return new_lines"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_up(self):\n        if self.auth_type == 'registry_rubber' and self.user:\n            self._registry_rubber_uonce('delete')\n\n        # clean up old docker configs.\n        user_home = os.environ.get('HOME')\n        for file_name in os.listdir(user_home):\n            if 'dockercfg' in file_name:\n                if file_name.count('.') is 2:\n                    try:\n                        parts = file_name.split('.')\n                        delta = int(time.time()) - int(parts[1])\n\n                        # default to 30 seconds?\n                        if delta > 30:\n                            os.remove(os.path.realpath(os.path.join(user_home, file_name)))\n                    except Exception:\n                        pass", "response": "Clean up old docker configs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the dockercfg file and set the user and password.", "response": "def load_dockercfg(self):\n        \"\"\"\n        :return:\n        \"\"\"\n        if self.ssl_cert_path:\n            self._validate_ssl_certs()\n\n        if self.auth_type == 'registry_rubber':\n            self.user, self.passwd = self._registry_rubber_uonce('add')\n            self._config_path = self._create_dockercfg(\n                self.user,\n                self.passwd,\n                os.path.join(os.environ.get('HOME'), '.{0}.dockercfg'.format(self.user))\n            )\n        else:\n            if not os.path.isfile(self.config_path):\n                raise ValueError(\"Couldn't find dockercfg file: {0}\".format(self.config_path))\n\n            with open(self.config_path, 'r') as f:\n                try:\n                    config = json.loads(f.read())\n                except Exception:\n                    raise SyntaxError(\"{0} doesn't container valid json.\".format(self.config_path))\n\n            if self.registry not in config:\n                raise LookupError(\"Was unable to find {0} in {1}\".format(self.registry, self.config_path))\n\n            registry_config = config[self.registry]\n            if 'auth' not in registry_config:\n                raise LookupError(\"Was unable to find 'auth' obj for {0} in {1}\".format(self.registry, self.config_path))\n\n            credentials = base64.decodestring(registry_config['auth'])\n\n            self.user = credentials.get('user')\n            self.user = credentials.get('password')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_data_from_rcsb(cls, ligand_code, pdb_id = None, silent = True, cached_dir = None):\n        '''Retrieve a file from the RCSB.'''\n        if not silent:\n            colortext.printf(\"Retrieving data from RCSB\")\n        if cached_dir:\n            assert(os.path.exists(cached_dir))\n\n        ligand_info_path, ligand_info, pdb_ligand_info, pdb_ligand_info_path = None, None, None, None\n        if cached_dir:\n            ligand_info_path = os.path.join(cached_dir, '{0}.cif'.format(ligand_code))\n            if os.path.exists(ligand_info_path):\n                ligand_info = read_file(ligand_info_path)\n        if not ligand_info:\n            ligand_info = retrieve_ligand_cif(ligand_code)\n            if cached_dir:\n                write_file(ligand_info_path, ligand_info)\n\n        # Parse .cif\n        l = cls(ligand_code)\n        l.parse_cif(ligand_info)\n        l.pdb_id = pdb_id or l.pdb_id\n        has_pdb_id = l.pdb_id and (len(l.pdb_id) == 4) and (l.pdb_id != '?')  # the last case is unnecessary and will be short-cut but I included it to show possible values\n\n        # Parse PDB XML\n        if has_pdb_id:\n            if cached_dir:\n                pdb_ligand_info_path = os.path.join(cached_dir, '{0}.pdb.ligandinfo'.format(l.pdb_id.lower()))\n                if os.path.exists(pdb_ligand_info_path):\n                    pdb_ligand_info = read_file(pdb_ligand_info_path)\n                else:\n                    pdb_ligand_info = retrieve_pdb_ligand_info(l.pdb_id)\n                    write_file(pdb_ligand_info_path, pdb_ligand_info)\n            else:\n                pdb_ligand_info = retrieve_pdb_ligand_info(l.pdb_id)\n        if pdb_ligand_info:\n            l.parse_pdb_ligand_info(pdb_ligand_info)\n\n        # Retrive the diagram image\n        l.get_diagram()\n\n        return l", "response": "Retrieve a file from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_cif(self, cif):\n        '''See http://www.iucr.org/__data/iucr/cif/standard/cifstd4.html, Acta Cryst. (1991). A47, 655-685.'''\n        found_cif_header = False\n        found_cif_descriptors = False\n        found_cif_identifiers = False\n\n        blocks = []\n        blocklines = []\n        for l in cif.split('\\n'):\n            if l.strip() == '#':\n                if blocklines:\n                    blocks.append('\\n'.join(blocklines))\n                    blocklines = []\n            else:\n                blocklines.append(l)\n        if blocklines:\n            blocks.append('\\n'.join(blocklines))\n\n        for block in blocks:\n            if block.find('_chem_comp.id') != -1:\n                assert(not found_cif_header)\n                self.parse_cif_header(block)\n                found_cif_header = True\n            elif block.find('_chem_comp_atom.model_Cartn_x') != -1:\n                continue\n            elif block.find('_chem_comp_atom.pdbx_stereo_config') != -1:\n                continue\n            elif block.find('_pdbx_chem_comp_descriptor.comp_id') != -1:\n                assert(not found_cif_descriptors)\n                self.parse_cif_descriptor(block)\n                found_cif_descriptors = True\n            elif block.find('_pdbx_chem_comp_identifier.comp_id') != -1:\n                assert(not found_cif_identifiers)\n                self.parse_cif_identifier(block)\n                found_cif_identifiers = True\n            elif block.find('_pdbx_chem_comp_audit.comp_id') != -1:\n                continue\n            else:\n                continue", "response": "Parses a CIF file into a set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_tuples_dict(pair_dict):\n        '''pair_dict should be a dict mapping tuple (HET code, residue ID) -> (HET code, residue ID) e.g. {('MG ', 'A 204 ') : ('MG ', 'C 221 '), ...}.\n           HET codes and residue IDs should respectively correspond to columns 17:20 and 21:27 of the PDB file.\n        '''\n        lm = LigandMap()\n        for k, v in pair_dict.iteritems():\n            lm.add(k[0], k[1], v[0], v[1])\n        return lm", "response": "Convert a dictionary mapping HET codes residue IDs to LigandMap."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a code mapping without a given instance.", "response": "def add_code_mapping(self, from_pdb_code, to_pdb_code):\n        '''Add a code mapping without a given instance.'''\n\n        # Consistency check - make sure that we always map the same code e.g. 'LIG' to the same code e.g. 'GTP'\n        if from_pdb_code in self.code_map:\n            assert(self.code_map[from_pdb_code] == to_pdb_code)\n        else:\n            self.code_map[from_pdb_code] = to_pdb_code"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the mapping is injective ( 1 - to - 1.", "response": "def is_injective(self):\n        '''Returns True if the mapping is injective (1-to-1).'''\n        codomain_residues = [v.to_pdb_residue_id for k, v in self.mapping.iteritems()]\n        return(len(codomain_residues) == len(set(codomain_residues)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that all ligands in the source PDB file are in the mapping.", "response": "def is_complete(self, all_domain_residue_ids):\n        '''Check that all ligands (specified via the set or list all_domain_residue_ids containing columns 21:27 of the\n           HETATM records) in the source PDB file are considered in the mapping.'''\n        mapped_domain_residues = sorted([v.from_pdb_residue_id for k, v in self.mapping.iteritems()])\n        assert(len(all_domain_residue_ids) == len(set(all_domain_residue_ids)))\n        return mapped_domain_residues == sorted(all_domain_residue_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function from function f", "response": "def fmap(self, f: Callable[[T], B]) -> 'Maybe[B]':\n        \"\"\"doufo.maybe.fmap: map a `Maybe` object with a function  \n        Args:  \n            `self`  \n            f (`Callable[[T], B]`): a function    \n        Returns:  \n            return (`Maybe[B]`): returned `Maybe` objects from function `f`    \n        Raises:\n        \"\"\"\n        return Maybe(None) if self.unbox() is None else Maybe(f(self.unbox()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind(self, f: Callable[[T], 'Maybe[B]']) -> 'Maybe[B]':\n        return self.fmap(lambda x: f(x).unbox())", "response": "Returns a copy of the current Maybe with the result of applying f to the current Maybe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nroute is a shorthand for route declaration", "response": "def route(view, endpoint=None, methods=None, defaults=None, **options):\n    \"\"\"\n    Route: a shorthand for route declaration\n    Import and use it in your app.urls file by calling:\n        url['/path/to/view'] = route('module.views.view', 'route_name')\n    \"\"\"\n    if not endpoint:\n        endpoint = view\n    if not methods:\n        methods = ['GET']\n    return dict(\n        view_func=LazyView(view),\n        endpoint=endpoint,\n        methods=methods,\n        defaults=defaults,\n        **options\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_config():\n    app_module = os.getenv('APP_MODULE')\n    if not app_module:\n        err = 'Unable to bootstrap application APP_MODULE is not defined'\n        raise x.BootstrapException(err)\n\n    app_config = os.getenv('APP_CONFIG')\n    if not app_module:\n        err = 'Unable to bootstrap application APP_CONFIG is not defined'\n        raise x.BootstrapException(err)\n\n    try:\n        config_class = import_string(app_config)\n    except ImportError:\n        err = 'Failed imported config file [{}]'\n        raise x.BootstrapException(err.format(app_config))\n\n    # and return\n    config = config_class()\n    return config", "response": "Imports config based on environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_app(name, config=None, flask_params=None):\n    from boiler.config import DefaultConfig\n    if config is None:\n        config = DefaultConfig()\n\n    # get flask parameters\n    options = dict(import_name=name)\n    if flask_params is not None:\n        options.update(flask_params)\n    if config.get('FLASK_STATIC_URL') is not None:\n        options['static_url_path'] = config.get('FLASK_STATIC_URL')\n    if config.get('FLASK_STATIC_PATH') is not None:\n        options['static_folder'] = config.get('FLASK_STATIC_PATH')\n\n    # create an app\n    app = Flask(**options)\n\n    # configure app\n    if config.__class__ is type:\n        raise Exception('Config must be an object, got class instead.')\n\n    app.config.from_object(DefaultConfig())\n    app.config.from_object(config)\n\n    # register error handler\n    register_error_handler(app)\n\n    # use kernel templates\n    kernel_templates_path = path.realpath(path.dirname(__file__)+'/templates')\n    fallback_loader = FileSystemLoader([kernel_templates_path])\n    custom_loader = ChoiceLoader([app.jinja_loader, fallback_loader])\n    app.jinja_loader = custom_loader\n\n    # time restarts?\n    if app.config.get('TIME_RESTARTS'):\n        restart_timer.time_restarts(os.path.join(os.getcwd(), 'var', 'data'))\n\n    # detect browsersync proxy\n    @app.before_request\n    def detect_browsersync():\n        g.dev_proxy = False\n        proxy_header = app.config.get('DEV_PROXY_HEADER')\n        if proxy_header:\n            g.dev_proxy = bool(request.headers.get(proxy_header))\n\n    return app", "response": "Create a new app with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self):\n\n        if not __options__.get(\"allow_registration\"):\n            abort(403, \"Registration is not allowed. Contact admin if it's a mistake\")\n\n        page_attr(\"Register\")\n\n        if request.method == \"POST\":\n            try:\n                if not recaptcha.verify():\n                    raise mocha_exc.AppError(\"Invalid Security code\")\n\n                email = request.form.get(\"email\", \"\").strip()\n                username = request.form.get(\"username\", \"\").strip()\n                password = request.form.get(\"password\", \"\").strip()\n                password_confirm = request.form.get(\"password_confirm\", \"\").strip()\n                first_name = request.form.get(\"first_name\", \"\").strip()\n                last_name = request.form.get(\"last_name\", \"\").strip()\n\n                with_oauth = request.form.get(\"with_oauth\") == \"1\"\n                oauth_provider = request.form.get(\"oauth_provider\")\n                oauth_user_id = request.form.get(\"oauth_user_id\")\n\n                login_method = None\n\n                # Require username and email\n                if __options__.get(\"registration_username\"):\n                    if \"@\" in username:\n                        raise exceptions.AuthError(_(\"Username can't be an email\"))\n                    if not utils.is_email_valid(email):\n                        raise exceptions.AuthError(_(\"Invalid email address\"))\n                    login_method = \"username\"\n\n                # Require only email. Email will be used as username and email\n                elif __options__.get(\"registration_email\"):\n                    if not utils.is_email_valid(username):\n                        raise exceptions.AuthError(_(\"Invalid email address\"))\n                    email = username\n                    login_method = \"email\"\n\n                if not first_name:\n                    raise mocha_exc.AppError(\n                        _(\"First Name or Name is required\"))\n                elif not password or password != password_confirm:\n                    raise mocha_exc.AppError(_(\"Passwords don't match\"))\n\n                if not login_method:\n                    raise exceptions.AuthError(_(\"Registration is disabled\"))\n\n                user = create_user(username=username,\n                                   password=password,\n                                   email=email,\n                                   first_name=first_name,\n                                   last_name=last_name,\n                                   login_method=login_method)\n\n                # WITH OAUTH, we can straight up login user\n                if with_oauth and oauth_provider and oauth_user_id:\n                    user.add_federation(oauth_provider, oauth_user_id)\n                    create_session(user)\n                    return redirect(request.form.get(\n                        \"next\") or views.auth.Account.account_settings)\n\n                if __options__.get(\"require_email_verification\"):\n                    user.send_welcome_email(view_class=self)\n                    flash_success(_(\"Please check your email. We've sent you a message\"))\n\n                return redirect(\n                    request.form.get(\"next\") or __options__.get(\"login_view\"))\n\n            except (mocha_exc.AppError, exceptions.AuthError) as ex:\n                flash_error(str(ex))\n            except Exception as e:\n                logging.exception(e)\n                flash_error(\"Unable to register\")\n            return redirect(self.register, next=request.form.get(\"next\"))\n\n        return {\n            \"reg_email\": __options__.get(\"registration_email\"),\n            \"reg_username\": __options__.get(\"registration_username\"),\n            \"reg_social\": __options__.get(\"registration_social\"),\n            \"reg_full_name\": __options__.get(\"registration_full_name\"),\n            \"login_url_next\": request.args.get(\"next\", \"\"),\n\n            \"with_oauth\": has_oauth_request(),\n            \"oauth_provider\": get_oauth_session().get(\"provider\"),\n            \"oauth_user_id\": get_oauth_session().get(\"user_id\"),\n            \"email\": get_oauth_session().get(\"email\") or \"\",\n            \"name\": get_oauth_session().get(\"name\") or \"\",\n        }", "response": "Register a new user in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the user to the user s oauth session.", "response": "def _register_oauth_session_user(self, user):\n        \"\"\"\n        Add the\n        :param user:\n        :return:\n        \"\"\"\n        oauth_session = get_oauth_session()\n        if oauth_session:\n            if \"provider\" in oauth_session and \"user_id\" in oauth_session:\n                user.add_federated_login(provider=oauth_session.get(\"provider\"),\n                                      federated_id=oauth_session.get(\"user_id\"))\n        delete_oauth_session()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_password(self, action_token, signed_data):\n        try:\n            action = \"reset-password\"\n            user = get_user_by_action_token(action, action_token)\n            if not user or not user.signed_data_match(signed_data, action):\n                raise mocha_exc.AppError(\"Verification Invalid!\")\n\n            if request.method == \"POST\":\n                password = request.form.get(\"password\", \"\").strip()\n                password_confirm = request.form.get(\"password_confirm\",\n                                                    \"\").strip()\n                if not password or password != password_confirm:\n                    raise exceptions.AuthError(\n                        \"Password is missing or passwords don't match\")\n\n                user.change_password(password)\n                user.set_email_verified(True)\n                session_set_require_password_change(False)\n                flash_success(\"Password updated successfully!\")\n                return redirect(__options__.get(\"login_view\") or self.login)\n\n            return {\"action_token\": action_token, \"signed_data\": signed_data}\n\n        except (mocha_exc.AppError, exceptions.AuthError) as ex:\n            flash_error(str(ex))\n        except Exception as e:\n            logging.exception(e)\n            flash_error(\"Unable to reset password\")\n        return redirect(self.login)", "response": "Reset the user password."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_email(self, action_token, signed_data):\n        try:\n            action = \"verify-email\"\n            user = get_user_by_action_token(action, action_token)\n            if not user or not user.signed_data_match(signed_data, action):\n                raise mocha_exc.AppError(\"Verification Invalid!\")\n            else:\n                user.set_email_verified(True)\n                flash_success(\"Account verified. You can now login\")\n                username = user.username\n                if user.login_method == \"email\":\n                    username = user.email\n\n                return redirect(self.login, username=username)\n        except Exception as e:\n            logging.exception(e)\n            flash_error(\"Verification Failed!\")\n        return redirect(self.login)", "response": "Verify email account in which a link was sent to"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef oauth_connect(self, provider, action):\n        valid_actions = [\"connect\", \"authorized\", \"test\"]\n\n        _redirect = views.auth.Account.account_settings if is_authenticated() else self.login\n\n        if action not in valid_actions \\\n                or \"oauth\" not in __options__.get(\"registration_methods\") \\\n                or not __options__.get(\"allow_registration\") \\\n                or not hasattr(oauth, provider):\n            return redirect(_redirect)\n\n        client = getattr(oauth, provider)\n        params = client.__params__\n        me_args = params.get(\"me\")\n        user_id = params.get(\"user_id\")\n        oauth_user_id = None\n        oauth_name = None\n        oauth_email = None\n\n        if action == \"test\":\n            session_data = {\n                \"provider\": \"ensure\",\n                \"user_id\": \"1234\",\n                \"name\": \"Mardix\",\n                \"email\": \"mardix@email.com\",\n            }\n            set_oauth_session(session_data)\n            return redirect(url_for(self.register, oauth=1))\n\n        if action == \"connect\":\n            _next = request.args.get('next')\n            authorized_url = url_for(self,\n                                     provider=provider,\n                                     action=\"authorized\",\n                                     next=_next or request.referrer or None,\n                                     _external=True)\n            return client.authorize(callback=authorized_url)\n        elif action == \"authorized\":\n            resp = client.authorized_response()\n            if resp is None:\n                pass\n            elif isinstance(resp, OAuthException):\n                flash_error(\"Access Denied\")\n            else:\n                if not me_args:\n                    oauth_user_id = resp.get(user_id)\n                else:\n                    me = client.get(me_args)\n\n        if action == \"authorized\" and oauth_user_id:\n            if is_authenticated():\n                try:\n                    # Add federated login to current_user\n                    current_user.add_federated_login(provider=provider,\n                                                  federated_id=oauth_user_id)\n                    flash_success(\n                        \"You can now login with your %s account\" % provider.upper())\n                except Exception as e:\n                    logging.exception(e)\n                return redirect(views.auth.Account.account_settings)\n\n            # User not logged in\n            else:\n                # Existing user\n                user = with_federation(provider, oauth_user_id)\n                if user:\n                    create_session(user)\n                    return redirect(request.args.get(\"next\") or __options__.get(\n                        \"login_view\"))\n\n                # New User\n                else:\n                    session_data = {\n                        \"provider\": provider,\n                        \"user_id\": oauth_user_id,\n                        \"name\": oauth_name,\n                        \"email\": oauth_email,\n                    }\n                    set_oauth_session(session_data)\n\n        else:\n            return redirect(_redirect)\n\n        return {\n            \"action\": action,\n            \"provider\": provider,\n            \"authorized_url\": \"\"\n\n        }\n\n        return redirect(_redirect)", "response": "This endpoint does not check if user is logged in and if it is authorized to connect to the endpoint"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a message to log", "response": "def log(self, message, level=None):\n        \"\"\" Write a message to log \"\"\"\n        if level is None:\n            level = logging.INFO\n\n        current_app.logger.log(msg=message, level=level)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if provided object is instance of this service s model.", "response": "def is_instance(self, model):\n        \"\"\"\n        Is instance?\n        Checks if provided object is instance of this service's model.\n\n        :param model:           object\n        :return:                bool\n        \"\"\"\n        result = isinstance(model, self.__model__)\n        if result is True:\n            return True\n\n        err = 'Object {} is not of type {}'\n        raise ValueError(err.format(model, self.__model__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new object populated from provided data and persists it", "response": "def create(self, **kwargs):\n        \"\"\"\n        Create\n        Instantiates and persists new model populated from provided\n        arguments\n\n        :param kwargs:          varargs, data to populate with\n        :return:                object, persisted new instance of model\n        \"\"\"\n        model = self.new(**kwargs)\n        return self.save(model)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, model, commit=True):\n        self.is_instance(model)\n        db.session.add(model)\n        if commit:\n            db.session.commit()\n\n        return model", "response": "Save a record into the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes the specified object from the database.", "response": "def delete(self, model, commit=True):\n        \"\"\"\n        Delete\n        Puts model for deletion into unit of work and optionall commits\n        transaction\n\n        :param model:           object, model to delete\n        :param commit:          bool, commit?\n        :return:                object, deleted model\n        \"\"\"\n        self.is_instance(model)\n        db.session.delete(model)\n        if commit:\n            db.session.commit()\n\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_connectable(host: str, port: Union[int, str]) -> bool:\n    socket_ = None\n    try:\n        socket_ = socket.create_connection((host, port), 1)\n        result = True\n    except socket.timeout:\n        result = False\n    finally:\n        if socket_:\n            socket_.close()\n    return result", "response": "Tries to connect to the device to see if it is connectable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict(self):\n        collection = super().dict()\n        serialized_items = []\n        for item in collection['items']:\n            serialized_items.append(self.serializer(item))\n\n        collection['items'] = serialized_items\n        return collection", "response": "Returns current collection as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute init tasks for all components of virtualenv.", "response": "def init():\n    \"\"\"Execute init tasks for all components (virtualenv, pip).\"\"\"\n    print(yellow(\"# Setting up development environment...\\n\", True))\n    virtualenv.init()\n    virtualenv.update()\n    print(green(\"\\n# DONE.\", True))\n    print(green(\"Type \") + green(\"activate\", True) + green(\" to enable your dev virtual environment.\"))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_lines(lines):\n    groups = []\n    group = []\n\n    for line in lines:\n        if line.strip() == \"\":\n            groups.append(group[:])\n            group = []\n            continue\n        group.append(line)\n\n    if group:\n        groups.append(group[:])\n\n    return groups", "response": "Split a list of lines using empty lines as separators."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset neighbors for multi - environments their slave environments and agents.", "response": "async def set_neighbors(self):\n        '''Set neighbors for multi-environments, their slave environments,\n        and agents.\n        '''\n        t = time.time()\n        self.logger.debug(\"Settings grid neighbors for the multi-environments.\")\n        tasks = []\n        for i in range(len(self.grid)):\n            for j in range(len(self.grid[0])):\n                addr = self.grid[i][j]\n                N, E, S, W = None, None, None, None\n                if i != 0:\n                    W = self.grid[i-1][j]\n                if i != len(self.grid) - 1:\n                    E = self.grid[i+1][j]\n                if j != 0:\n                    N = self.grid[i][j-1]\n                if j != len(self.grid[0]) - 1:\n                    S = self.grid[i][j+1]\n                task = asyncio.ensure_future(self._set_node_neighbors(addr, N, E, S, W))\n                tasks.append(task)\n        await asyncio.gather(*tasks)\n\n        self.logger.debug(\"Setting grid neighbors for the slave environments \"\n                          \"and their agents.\")\n        tasks = []\n        for addr in self.addrs:\n            task = asyncio.ensure_future(self._set_neighbors(addr))\n            tasks.append(task)\n        await asyncio.gather(*tasks)\n        self.logger.debug(\"All grid neighbors set in {} seconds.\"\n                          .format(time.time() - t))\n        x = self._ngs[0] * self._gs[0] * self._n_slaves\n        y = self._ngs[1] * self._gs[1]\n        self.logger.info(\"Initialized a distributed grid with overall size \"\n                         \"({}, {}). Total of {} agents.\".format(x, y, x*y))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def ssh_exec(server, cmd, timeout=10, **ssh_kwargs):\n    conn = await asyncio.wait_for(asyncssh.connect(server, **ssh_kwargs),\n                                  timeout=timeout)\n    ret = await conn.run(cmd)\n    conn.close()\n    return ret", "response": "Execute a command on a given server using asynchronous SSH - connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ssh_exec_in_new_loop(server, cmd, timeout=10, **ssh_kwargs):\n    task = ssh_exec(server, cmd, timeout=timeout, **ssh_kwargs)\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n    return loop.run_until_complete(task)", "response": "Same as ssh_exec but creates a new event loop and executes it in that event loop."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def run_node(menv, log_folder):\n    try:\n        await menv.manager.stop_received\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ret = await menv.destroy(log_folder, as_coro=True)\n        return ret", "response": "Runs the node in the multi - environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait until all nodes are online or timeout expires. Should be called after spawn_nodes.", "response": "async def wait_nodes(self, timeout, check_ready=True):\n        \"\"\"Wait until all nodes are online (their managers accept connections)\n        or timeout expires. Should be called after :meth:`spawn_nodes`.\n\n        This is an alias for :meth:`~creamas.mp.MultiEnvironment.wait_slaves`.\n        \"\"\"\n        return await self.wait_slaves(timeout, check_ready=check_ready)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nspawning nodes on the local machine.", "response": "async def spawn_nodes(self, spawn_cmd, ports=None, **ssh_kwargs):\n        \"\"\"An alias for :meth:`creamas.ds.DistributedEnvironment.spawn_slaves`.\n        \"\"\"\n        return await self.spawn_slaves(spawn_cmd, ports=ports, **ssh_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nspawn multi - environments on the nodes through SSH - connections.", "response": "async def spawn_slaves(self, spawn_cmd, ports=None, **ssh_kwargs):\n        \"\"\"Spawn multi-environments on the nodes through SSH-connections.\n\n        :param spawn_cmd:\n            str or list, command(s) used to spawn the environment on each node.\n            If *list*, it must contain one command for each node in\n            :attr:`nodes`. If *str*, the same command is used for each node.\n\n        :param ports:\n            Optional. If not ``None``, must be a mapping from nodes\n            (``(server, port)``-tuples) to ports which are used for the spawned\n            multi-environments' master manager environments. If ``None``, then\n            the same port is used to derive the master manager addresses as was\n            used to initialize this distributed environment's managing\n            environment (port in :attr:`addr`).\n\n        :param ssh_kwargs:\n            Any additional SSH-connection arguments, as specified by\n            :meth:`asyncssh.connect`. See `asyncssh documentation\n            <http://asyncssh.readthedocs.io/en/latest/api.html#connect>`_ for\n            details.\n\n        Nodes are spawned by creating a multiprocessing pool where each node\n        has its own subprocess. These subprocesses then use SSH-connections\n        to spawn the multi-environments on the nodes. The SSH-connections in\n        the pool are kept alive until the nodes are stopped, i.e. this\n        distributed environment is destroyed.\n        \"\"\"\n        pool = multiprocessing.Pool(len(self.nodes))\n        rets = []\n        for i, node in enumerate(self.nodes):\n            server, server_port = node\n            port = ports[node] if ports is not None else self.port\n            mgr_addr = \"tcp://{}:{}/0\".format(server, port)\n            self._manager_addrs.append(mgr_addr)\n            if type(spawn_cmd) in [list, tuple]:\n                cmd = spawn_cmd[i]\n            else:\n                cmd = spawn_cmd\n            args = [server, cmd]\n            ssh_kwargs_cp = ssh_kwargs.copy()\n            ssh_kwargs_cp['port'] = server_port\n            ret = pool.apply_async(ssh_exec_in_new_loop,\n                                   args=args,\n                                   kwds=ssh_kwargs_cp,\n                                   error_callback=logger.warning)\n            rets.append(ret)\n        self._pool = pool\n        self._r = rets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_slave_managers(self, as_coro=False):\n        async def slave_task(addr):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.get_slave_managers()\n\n        tasks = create_tasks(slave_task, self.addrs)\n        return run_or_coro(tasks, as_coro)", "response": "Return all slave environment manager addresses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nodes(self, type=None, failed=False):\n        if type is None:\n            type = Node\n\n        if not issubclass(type, Node):\n            raise(TypeError(\"{} is not a valid node type.\".format(type)))\n\n        if failed not in [\"all\", False, True]:\n            raise ValueError(\"{} is not a valid node failed\".format(failed))\n\n        if failed == \"all\":\n            return type\\\n                .query\\\n                .filter_by(participant_id=self.id)\\\n                .all()\n        else:\n            return type\\\n                .query\\\n                .filter_by(failed=failed, participant_id=self.id)\\\n                .all()", "response": "Get a list of nodes associated with this participant."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_verbose(self):\n        print \"Nodes: \"\n        for a in (self.nodes(failed=\"all\")):\n            print a\n\n        print \"\\nVectors: \"\n        for v in (self.vectors(failed=\"all\")):\n            print v\n\n        print \"\\nInfos: \"\n        for i in (self.infos(failed=\"all\")):\n            print i\n\n        print \"\\nTransmissions: \"\n        for t in (self.transmissions(failed=\"all\")):\n            print t\n\n        print \"\\nTransformations: \"\n        for t in (self.transformations(failed=\"all\")):\n            print t", "response": "Print a verbose representation of a network."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vectors(self, direction=\"all\", failed=False):\n        # check direction\n        if direction not in [\"all\", \"incoming\", \"outgoing\"]:\n            raise ValueError(\n                \"{} is not a valid vector direction. \"\n                \"Must be all, incoming or outgoing.\".format(direction))\n\n        if failed not in [\"all\", False, True]:\n            raise ValueError(\"{} is not a valid vector failed\".format(failed))\n\n        # get the vectors\n        if failed == \"all\":\n            if direction == \"all\":\n                return Vector.query\\\n                    .filter(or_(Vector.destination_id == self.id,\n                                Vector.origin_id == self.id))\\\n                    .all()\n\n            if direction == \"incoming\":\n                return Vector.query\\\n                    .filter_by(destination_id=self.id)\\\n                    .all()\n\n            if direction == \"outgoing\":\n                return Vector.query\\\n                    .filter_by(origin_id=self.id)\\\n                    .all()\n        else:\n            if direction == \"all\":\n                return Vector.query\\\n                    .filter(and_(Vector.failed == failed,\n                            or_(Vector.destination_id == self.id,\n                                Vector.origin_id == self.id)))\\\n                    .all()\n\n            if direction == \"incoming\":\n                return Vector.query\\\n                    .filter_by(destination_id=self.id, failed=failed)\\\n                    .all()\n\n            if direction == \"outgoing\":\n                return Vector.query\\\n                    .filter_by(origin_id=self.id, failed=failed)\\\n                    .all()", "response": "Get the vectors that connect at this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all transmissions from this node.", "response": "def transmissions(self, direction=\"outgoing\", status=\"all\", failed=False):\n        \"\"\"Get transmissions sent to or from this node.\n\n        Direction can be \"all\", \"incoming\" or \"outgoing\" (default).\n        Status can be \"all\" (default), \"pending\", or \"received\".\n        failed can be True, False or \"all\"\n        \"\"\"\n        # check parameters\n        if direction not in [\"incoming\", \"outgoing\", \"all\"]:\n            raise(ValueError(\"You cannot get transmissions of direction {}.\"\n                             .format(direction) +\n                  \"Type can only be incoming, outgoing or all.\"))\n\n        if status not in [\"all\", \"pending\", \"received\"]:\n            raise(ValueError(\"You cannot get transmission of status {}.\"\n                             .format(status) +\n                  \"Status can only be pending, received or all\"))\n\n        if failed not in [\"all\", False, True]:\n            raise ValueError(\"{} is not a valid transmission failed\"\n                             .format(failed))\n\n        # get transmissions\n        if direction == \"all\":\n            if status == \"all\":\n                return Transmission.query\\\n                    .filter(and_(Transmission.failed == False,\n                                 or_(Transmission.destination_id == self.id,\n                                     Transmission.origin_id == self.id)))\\\n                    .all()\n            else:\n                return Transmission.query\\\n                    .filter(and_(Transmission.failed == False,\n                                 Transmission.status == status,\n                                 or_(Transmission.destination_id == self.id,\n                                     Transmission.origin_id == self.id)))\\\n                    .all()\n        if direction == \"incoming\":\n            if status == \"all\":\n                return Transmission.query\\\n                    .filter_by(failed=False, destination_id=self.id)\\\n                    .all()\n            else:\n                return Transmission.query\\\n                    .filter(and_(Transmission.failed == False,\n                                 Transmission.destination_id == self.id,\n                                 Transmission.status == status))\\\n                    .all()\n        if direction == \"outgoing\":\n            if status == \"all\":\n                return Transmission.query\\\n                    .filter_by(failed=False, origin_id=self.id)\\\n                    .all()\n            else:\n                return Transmission.query\\\n                    .filter(and_(Transmission.failed == False,\n                                 Transmission.origin_id == self.id,\n                                 Transmission.status == status))\\\n                    .all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns a list of lists into a list.", "response": "def flatten(self, l):\n        \"\"\"Turn a list of lists into a list.\"\"\"\n        if l == []:\n            return l\n        if isinstance(l[0], list):\n            return self.flatten(l[0]) + self.flatten(l[1:])\n        return l[:1] + self.flatten(l[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transmit(self, what=None, to_whom=None):\n        # make the list of what\n        what = self.flatten([what])\n        for i in range(len(what)):\n            if what[i] is None:\n                what[i] = self._what()\n            elif inspect.isclass(what[i]) and issubclass(what[i], Info):\n                what[i] = self.infos(type=what[i])\n        what = self.flatten(what)\n        for i in range(len(what)):\n            if inspect.isclass(what[i]) and issubclass(what[i], Info):\n                what[i] = self.infos(type=what[i])\n        what = list(set(self.flatten(what)))\n\n        # make the list of to_whom\n        to_whom = self.flatten([to_whom])\n        for i in range(len(to_whom)):\n            if to_whom[i] is None:\n                to_whom[i] = self._to_whom()\n            elif inspect.isclass(to_whom[i]) and issubclass(to_whom[i], Node):\n                to_whom[i] = self.neighbors(direction=\"to\", type=to_whom[i])\n        to_whom = self.flatten(to_whom)\n        for i in range(len(to_whom)):\n            if inspect.isclass(to_whom[i]) and issubclass(to_whom[i], Node):\n                to_whom[i] = self.neighbors(direction=\"to\", type=to_whom[i])\n        to_whom = list(set(self.flatten(to_whom)))\n\n        transmissions = []\n        vectors = self.vectors(direction=\"outgoing\")\n        for w in what:\n            for tw in to_whom:\n                try:\n                    vector = [v for v in vectors\n                              if v.destination_id == tw.id][0]\n                except:\n                    raise ValueError(\n                        \"{} cannot transmit to {} as it does not have \"\n                        \"a connection to them\".format(self, tw))\n                t = Transmission(info=w, vector=vector)\n                transmissions.append(t)\n        if len(transmissions) == 1:\n            return transmissions[0]\n        else:\n            return transmissions", "response": "Transmit one or more infos from one node to another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreceive some transmissions and update the node s info.", "response": "def receive(self, what=None):\n        \"\"\"Receive some transmissions.\n\n        Received transmissions are marked as received, then their infos are\n        passed to update().\n\n        \"what\" can be:\n\n            1. None (the default) in which case all pending transmissions are\n               received.\n            2. a specific transmission.\n\n        Will raise an error if the node is told to receive a transmission it has\n        not been sent.\n\n        \"\"\"\n        # check self is not failed\n        if self.failed:\n            raise ValueError(\"{} cannot receive as it has failed.\"\n                             .format(self))\n\n        received_transmissions = []\n        if what is None:\n            pending_transmissions = self.transmissions(direction=\"incoming\",\n                                                       status=\"pending\")\n            for transmission in pending_transmissions:\n                transmission.status = \"received\"\n                transmission.receive_time = timenow()\n                received_transmissions.append(transmission)\n\n        elif isinstance(what, Transmission):\n            if what in self.transmissions(direction=\"incoming\",\n                                          status=\"pending\"):\n                transmission.status = \"received\"\n                what.receive_time = timenow()\n                received_transmissions.append(what)\n            else:\n                raise(ValueError(\"{} cannot receive {} as it is not \"\n                                 \"in its pending_transmissions\"\n                                 .format(self, what)))\n        else:\n            raise ValueError(\"Nodes cannot receive {}\".format(what))\n\n        self.update([t.info for t in received_transmissions])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mutate(self, info_in):\n        # check self is not failed\n        if self.failed:\n            raise ValueError(\"{} cannot mutate as it has failed.\".format(self))\n\n        from transformations import Mutation\n        info_out = type(info_in)(origin=self,\n                                 contents=info_in._mutated_contents())\n        Mutation(info_in=info_in, info_out=info_out)", "response": "Replicate an info + mutation.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transmissions(self, status=\"all\"):\n        if status not in [\"all\", \"pending\", \"received\"]:\n            raise(ValueError(\"You cannot get {} transmissions.\"\n                             .format(status) +\n                             \"Status can only be pending, received or all\"))\n\n        if status == \"all\":\n            return Transmission\\\n                .query\\\n                .filter_by(vector_id=self.id,\n                           failed=False)\\\n                .all()\n        else:\n            return Transmission\\\n                .query\\\n                .filter_by(vector_id=self.id,\n                           status=status,\n                           failed=False)\\\n                .all()", "response": "Get all transmissions sent along this Vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serve_forever(self, banner=None):\n        if hasattr(readline, \"read_history_file\"):\n            try:\n                readline.read_history_file(self.histfile)\n            except IOError:\n                pass\n            atexit.register(self._save_history)\n        super(Shell, self).serve_forever(banner)", "response": "Interact with the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef complete(self, word, state):\n        try:\n            import rl\n            # TODO: doing this manually right now, but may make sense to\n            # exploit\n            rl.completion.suppress_append = True\n        except ImportError:\n            pass\n        word = transform(word, self.transforms, word=True)\n\n        if state == 0:\n            self.matches = self.get_matches(word)\n\n        try:\n            match = self.matches[state]\n        except IndexError:\n            return None\n        else:\n            return transform(match, self.transforms, word=True, inverse=True)", "response": "Return the next possible completion for word."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exclude_matches(self, matches):\n        for match in matches:\n            for exclude_pattern in self.exclude_patterns:\n                if re.match(exclude_pattern, match) is not None:\n                    break\n            else:\n                yield match", "response": "Filter any matches that match an exclude pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gen_filename_completions(self, word, filenames):\n        if not word:\n            return filenames\n        else:\n            trie = pygtrie.CharTrie()\n            for filename in filenames:\n                trie[filename] = filename\n            return trie.iterkeys(prefix=word)", "response": "Generate a sequence of filenames that match word."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a sequence of possible completions for word.", "response": "def gen_matches(self, word):\n        \"\"\"Generate a sequence of possible completions for ``word``.\n\n        :param word: the word to complete\n        \"\"\"\n\n        if word.startswith(\"$\"):\n            for match in self.gen_variable_completions(word, os.environ):\n                yield match\n        else:\n            head, tail = os.path.split(word)\n            filenames = os.listdir(head or '.')\n            completions = self.gen_filename_completions(tail, filenames)\n            for match in completions:\n                yield os.path.join(head, match)\n        for extension in self.extensions:\n            for match in extension(word):\n                yield match"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a sequence of possible variable completions for word.", "response": "def gen_variable_completions(self, word, env):\n        \"\"\"Generate a sequence of possible variable completions for ``word``.\n\n        :param word: the word to complete\n        :param env: the environment\n        \"\"\"\n        # ignore the first character, which is a dollar sign\n        var = word[1:]\n        for k in env:\n            if k.startswith(var):\n                yield \"$\" + k"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of filenames with match word.", "response": "def get_matches(self, word):\n        \"\"\"\n        Get a list of filenames with match *word*.\n        \"\"\"\n        matches = self.gen_matches(word)\n        # defend this against bad user input for regular expression patterns\n        try:\n            matches = self.exclude_matches(matches)\n        except Exception:\n            sys.stderr.write(traceback.format_exc())\n            return None\n        else:\n            if self.use_suffix:\n                matches = [self.inflect(match) for match in matches]\n            return list(matches)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inflect(self, filename):\n        suffix = (\"/\" if os.path.isdir(filename) else \" \")\n        return self._escape(filename) + suffix", "response": "Inflect a filename to indicate its type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef state(self, time=None):\n        if time is None:\n            return max(self.infos(type=State), key=attrgetter('creation_time'))\n        else:\n            states = [\n                s for s in self.infos(type=State) if s.creation_time < time]\n            return max(states, key=attrgetter('creation_time'))", "response": "Returns the most recently - created info of type State at the specified time."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an instance of a node from the config", "response": "def get_instance(self, node, *args, **kwargs):\n        \"\"\"\n        get plugin instance from config node\n        *NOTE* returns an uninitialized instance if one isn't there\n        *NOTE* instantiated plugins without names remain anonymous\n               FIXME - why would instantiate() even process them\n        \"\"\"\n        # string is a ref to an existing plugin instance\n        if isinstance(node, basestring):\n            if node in self._instance:\n                return self._instance[node]\n            # if not an instance, try for init with empty config\n            return self.new_plugin({'type': node}, *args, **kwargs)\n\n        if isinstance(node, collections.Mapping):\n            if \"type\" in node:\n                # node was a plugin config passed directly\n                name = node.get(\"name\", node.get(\"type\"))\n            elif len(node) == 1:\n                # node was a container with a single plugin config keyed\n                # to it\n                typ, config = list(node.items())[0]\n                name = config.get(\"name\", config.get(\"type\", typ))\n\n            # retrieve existing instance if it exists\n            if name in self._instance:\n                return self._instance[name]\n\n            # otherwise spawn new plugin\n            return self.new_plugin(node, *args, **kwargs)\n\n        raise ValueError(\"unable to parse plugin for output %s\" % str(node))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake plugin config (list under 'plugin') and instantiates defined plugins", "response": "def instantiate(self, config, *args, **kwargs):\n        \"\"\"\n        takes plugin config (list under 'plugin') and instantiates defined\n        plugins\n        \"\"\"\n        for plugin_config in config:\n            self.new_plugin(plugin_config, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_practice_counts(request):\n    data = None\n    if request.method == \"POST\":\n        data = json.loads(request.body.decode(\"utf-8\"))[\"filters\"]\n    if \"filters\" in request.GET:\n        data = load_query_json(request.GET, \"filters\")\n    if data is None or len(data) == 0:\n        return render_json(request, {}, template='models_json.html', help_text=to_practice_counts.__doc__)\n    language = get_language(request)\n    timer('to_practice_counts')\n    filter_names, filter_filters = list(zip(*sorted(data.items())))\n    reachable_leaves = Item.objects.filter_all_reachable_leaves_many(filter_filters, language)\n    response = {\n        group_id: {\n            'filter': data[group_id],\n            'number_of_items': len(items),\n        }\n        for group_id, items in zip(filter_names, reachable_leaves)\n    }\n    LOGGER.debug(\"to_practice_counts - getting items in groups took %s seconds\", (timer('to_practice_counts')))\n    return render_json(request, response, template='models_json.html', help_text=to_practice_counts.__doc__)", "response": "Returns a list of items available to practice."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the answer. GET parameters: html: turn on the HTML version of the API BODY json in following format: { \"answer\": #answer, -- for one answer \"answers\": [#answer, #answer, #answer ...] -- for multiple answers } answer = { \"answer_class\": str, -- class of answer to save (e.g., flashcard_answer) \"response_time\": int, -- response time in milliseconds \"meta\": \"str\" -- optional information \"time_gap\": int -- waiting time in frontend in seconds ... -- other fields depending on aswer type (see from_json method of Django model class) }", "response": "def answer(request):\n    \"\"\"\n    Save the answer.\n\n    GET parameters:\n        html:\n            turn on the HTML version of the API\n\n    BODY\n    json in following format:\n    {\n        \"answer\": #answer,                          -- for one answer\n        \"answers\": [#answer, #answer, #answer ...]  -- for multiple answers\n    }\n\n    answer = {\n        \"answer_class\": str,            -- class of answer to save (e.g., flashcard_answer)\n        \"response_time\": int,           -- response time in milliseconds\n        \"meta\": \"str\"                   -- optional information\n        \"time_gap\": int                 -- waiting time in frontend in seconds\n        ...                             -- other fields depending on aswer type\n                                          (see from_json method of Django model class)\n    }\n    \"\"\"\n    if request.method == 'GET':\n        return render(request, 'models_answer.html', {}, help_text=answer.__doc__)\n    elif request.method == 'POST':\n        practice_filter = get_filter(request)\n        practice_context = PracticeContext.objects.from_content(practice_filter)\n        saved_answers = _save_answers(request, practice_context, True)\n        return render_json(request, saved_answers, status=200, template='models_answer.html')\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_stats(request):\n    timer('user_stats')\n    response = {}\n    data = None\n    if request.method == \"POST\":\n        data = json.loads(request.body.decode(\"utf-8\"))[\"filters\"]\n    if \"filters\" in request.GET:\n        data = load_query_json(request.GET, \"filters\")\n    if data is None:\n        return render_json(request, {}, template='models_user_stats.html', help_text=user_stats.__doc__)\n    environment = get_environment()\n    if is_time_overridden(request):\n        environment.shift_time(get_time(request))\n    user_id = get_user_id(request)\n    language = get_language(request)\n    filter_names, filter_filters = list(zip(*sorted(data.items())))\n    reachable_leaves = Item.objects.filter_all_reachable_leaves_many(filter_filters, language)\n    all_leaves = sorted(list(set(flatten(reachable_leaves))))\n    answers = environment.number_of_answers_more_items(all_leaves, user_id)\n    correct_answers = environment.number_of_correct_answers_more_items(all_leaves, user_id)\n    if request.GET.get(\"mastered\"):\n        timer('user_stats_mastered')\n        mastery_threshold = get_mastery_trashold()\n        predictions = Item.objects.predict_for_overview(environment, user_id, all_leaves)\n        mastered = dict(list(zip(all_leaves, [p >= mastery_threshold for p in predictions])))\n        LOGGER.debug(\"user_stats - getting predictions for items took %s seconds\", (timer('user_stats_mastered')))\n    for identifier, items in zip(filter_names, reachable_leaves):\n        if len(items) == 0:\n            response[identifier] = {\n                \"filter\": data[identifier],\n                \"number_of_items\": 0,\n            }\n        else:\n            response[identifier] = {\n                \"filter\": data[identifier],\n                \"number_of_items\": len(items),\n                \"number_of_practiced_items\": sum(answers[i] > 0 for i in items),\n                \"number_of_answers\": sum(answers[i] for i in items),\n                \"number_of_correct_answers\": sum(correct_answers[i] for i in items),\n            }\n            if request.GET.get(\"mastered\"):\n                response[identifier][\"number_of_mastered_items\"]= sum(mastered[i] for i in items)\n    return render_json(request, response, template='models_user_stats.html', help_text=user_stats.__doc__)", "response": "Get user statistics for selected items in a single order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_loops_file(self, contents, ignore_whitespace = True, ignore_errors = False):\n        '''This parser is forgiving and allows leading whitespace.'''\n        for l in [l for l in contents.strip().split('\\n') if l]:\n            try:\n                if ignore_whitespace:\n                    l = l.strip()\n                tokens = l.split()\n                if len(tokens) < 3:\n                    raise RosettaFileParsingException('Lines in a loops file must have at least three entries.')\n                if len(tokens) < 4:\n                    tokens.append(None)\n                self.data.append(self.parse_loop_line(tokens))\n            except:\n                if ignore_errors:\n                    continue\n                else:\n                    raise", "response": "This parser is forgiving and allows leading whitespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new loop definition.", "response": "def add(self, start, end, cut_point = None, skip_rate = None, extend_loop = None):\n        '''Add a new loop definition.'''\n        self.data.append(self.parse_loop_line(['LOOP', start, end, cut_point, skip_rate, extend_loop]))\n        assert(start <= end)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_distinct_segments(self, left_offset = 0, right_offset = 0, sequence_length = None):\n        '''Returns a list of segments (pairs of start and end positions) based on the loop definitions. The returned segments\n            merge overlapping loops e.g. if the loops file contains sections 32-40, 23-30, 28-33, and 43-46 then the returned\n            segments will be [(23, 40), (43, 46)].\n            This may not be the fastest way to calculate this (numpy?) but that is probably not an issue.\n\n            The offsets are used to select the residues surrounding the loop regions. For example, i.e. if a sequence segment\n            is 7 residues long at positions 13-19 and we require 9-mers, we must consider the segment from positions 5-27 so\n            that all possible 9-mers are considered.\n        '''\n\n        # Create a unique, sorted list of all loop terminus positions\n        positions = set()\n        for l in self.data:\n            assert(l['start'] <= l['end'])\n            if sequence_length:\n                # If we know the sequence length then we can return valid positions\n                positions = positions.union(range(max(1, l['start'] - left_offset + 1), min(sequence_length + 1, l['end'] + 1 + right_offset - 1))) # For clarity, I did not simplify the expressions. The left_offset requires a +1 to be added, the right_offset requires a -1 to be added. The right offset also requires a +1 due to the way Python splicing works.\n            else:\n                # Otherwise, we may return positions outside the sequence length however Python splicing can handle this gracefully\n                positions = positions.union(range(max(1, l['start'] - left_offset + 1), l['end'] + 1 + right_offset - 1)) # For clarity, I did not simplify the expressions. The left_offset requires a +1 to be added, the right_offset requires a -1 to be added. The right offset also requires a +1 due to the way Python splicing works.\n        positions = sorted(positions)\n\n        # Iterate through the list to define the segments\n        segments = []\n        current_start = None\n        last_position = None\n        for p in positions:\n            if current_start == None:\n                current_start = p\n                last_position = p\n            else:\n                if p == last_position + 1:\n                    last_position = p\n                else:\n                    segments.append((current_start, last_position))\n                    current_start = p\n                    last_position = p\n        if current_start and last_position:\n            segments.append((current_start, last_position))\n        return segments", "response": "Returns a list of segments based on the loop definitions. The returned list is sorted by start and end positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a string to the logs.", "response": "def log(self, text, key=\"?????\", force=False):\n        \"\"\"Print a string to the logs.\"\"\"\n        if force or self.verbose:\n            print \">>>> {} {}\".format(key, text)\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef input_yes_no(msg=''):\n    print '\\n'+msg\n    while(True):\n        i=raw_input('Input yes or no: ')\n        i=i.lower()\n        if i=='y' or i=='yes':\n            return True\n        elif i=='n' or i=='no':\n            return False\n        else:\n            print 'ERROR: Bad input. Must enter y/n/yes/no'", "response": "Simple helper function to input yes or no"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_arguments(self):\n        # TODO: add tests to confirm deployments\n        self._parser.add_argument(\n            '-t', '--tag',\n            required=False,\n            type=six.text_type,\n            default=None,\n            help='This tag will override image tag provided in the configuration file.'\n        )\n\n        self._parser.add_argument(\n            '-e', '--env',\n            required=False,\n            type=six.text_type,\n            action='append',\n            default=None,\n            help='environment variables to create in the container at run time.'\n        )", "response": "Build command line arguments for the\n            command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy(self, args, **extra_args):\n        if not isinstance(args, argparse.Namespace):\n            raise TypeError(logger.error(\"args should of an instance of argparse.Namespace\"))\n\n        # create new freight forwarder\n        freight_forwarder = FreightForwarder()\n\n        # create commercial invoice this is the contact given to freight forwarder to dispatch containers and images\n        commercial_invoice = freight_forwarder.commercial_invoice(\n            'deploy',\n            args.data_center,\n            args.environment,\n            args.service\n        )\n\n        # deploy containers.\n        bill_of_lading = freight_forwarder.deploy_containers(commercial_invoice, args.tag, args.env)\n\n        # pretty lame... Need to work on return values through to app to make them consistent.\n        exit_code = 0 if bill_of_lading else 1\n\n        if exit_code != 0:\n            exit(exit_code)", "response": "Deploy a docker container to a specific container ship"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_relation_type_config(value):\n    relation_types = current_app.config['PIDRELATIONS_RELATION_TYPES']\n    if isinstance(value, six.string_types):\n        try:\n            obj = next(rt for rt in relation_types if rt.name == value)\n        except StopIteration:\n            raise ValueError(\"Relation name '{0}' is not configured.\".format(\n                value))\n\n    elif isinstance(value, int):\n        try:\n            obj = next(rt for rt in relation_types if rt.id == value)\n        except StopIteration:\n            raise ValueError(\"Relation ID {0} is not configured.\".format(\n                value))\n    else:\n        raise ValueError(\"Type of value '{0}' is not supported for resolving.\".\n                         format(value))\n    api_class = obj_or_import_string(obj.api)\n    schema_class = obj_or_import_string(obj.schema)\n    return obj.__class__(obj.id, obj.name, obj.label, api_class, schema_class)", "response": "Resolve the relation type to config object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nalign two PDB files returning a mapping from the chains of pdb1 to the chains of pdb2.", "response": "def match_pdb_chains(pdb1, pdb1_name, pdb2, pdb2_name, cut_off = 60.0, allow_multiple_matches = False, multiple_match_error_margin = 3.0, use_seqres_sequences_if_possible = True):\n    '''Aligns two PDB files, returning a mapping from the chains in pdb1 to the chains of pdb2.\n       If allow_multiple_matches is False, we return the best match for each chain in pdb1 if a match exists. The return\n        value is a dict mapping\n            chain_id_in_pdb1 -> None or a list with a single tuple (chain_id_in_pdb_2, percentage_identity_score)\n       where percentage_identity_score is a float. e.g. 'A' -> [('B', 100)]. We return a list to keep the return type\n       consistent with the allow_multiple_matches case. Use the match_best_pdb_chains wrapper is you only want one match.\n\n       If allow_multiple_matches is True, we return multiple matches for each chain in pdb1 if any matches exists. The return\n        value is a dict mapping\n            chain_id_in_pdb1 -> None or a list of tuples of the form (chain_id_in_pdb_2, percentage_identity_score)\n       where percentage_identity_score is a float. multiple_match_error_margin is the amount of percentage identity difference\n       from the best match that we allow for e.g. a chain may map to chain_id1_in_pdb2 with 78% identity and chain_id2_in_pdb2\n       with 76% identity. If chain_id1_in_pdb2 is the best match and multiple_match_error_margin >= 2, chain_id2_in_pdb2 will\n       also be returned.\n\n       Parameters: pdb1 and pdb2 are PDB objects from klab.bio.pdb. pdb1_name and pdb2_name are strings describing the\n        structures e.g. 'Model' and 'Scaffold'. cut_off is used in the matching to discard low-matching chains.\n\n       If use_seqres_sequences_if_possible is set, we will use the SEQRES sequences for the mapping when those sequences\n       exist. At present, it is possible to match a SEQRES sequence in pdb1 against an ATOM sequence in pdb2 if pdb1 has\n       a SEQRES sequence for that chain in question and pdb2 does not. We may want to change this behavior in the future\n       i.e. only match SEQRES to SEQRES and ATOM to ATOM.\n       If use_seqres_sequences_if_possible and a SEQRES sequence does not exist for a chain, we fall back to the ATOM\n       sequence.\n       '''\n\n    try:\n        pdb1_chains = [c for c in pdb1.atom_chain_order]\n        pdb2_chains = [c for c in pdb2.atom_chain_order]\n        unrecognized_residues = set(['X'])\n\n        # Extend the list of chains by the SEQRES chain IDs. These will typically be the same list but, just in case, we take\n        # the set union.\n        if use_seqres_sequences_if_possible:\n            pdb1_chains.extend(pdb1.seqres_chain_order)\n            pdb1_chains = sorted(set(pdb1_chains))\n            pdb2_chains.extend(pdb2.seqres_chain_order)\n            pdb2_chains = sorted(set(pdb2_chains))\n\n        sa = SequenceAligner()\n\n        # This is a hack to ensure that the assertions below hold. The alternative is to fix the logic below (maybe allow the separator character to be a parameter).\n        pdb1_name = pdb1_name.replace('_', chr(254))\n        pdb2_name = pdb2_name.replace('_', chr(254))\n\n        assert(pdb1_name.find('_') == -1)\n        assert(pdb2_name.find('_') == -1)\n\n        kept_chains = []\n        for c in pdb1_chains:\n            # We do not handle chains with all HETATMs (and not ATOMs) well, generally. These conditions allow for those chains\n            seq1 = pdb1.get_chain_sequence_string(c, use_seqres_sequences_if_possible, raise_Exception_if_not_found = False)\n\n            if seq1 and str(seq1) and set(str(seq1)) != unrecognized_residues:\n                sa.add_sequence('%s_%s' % (pdb1_name, c), str(seq1))\n                kept_chains.append(c)\n        pdb1_chains = kept_chains\n\n        kept_chains = []\n        for c in pdb2_chains:\n            # We do not handle chains with all HETATMs (and not ATOMs) well, generally. These conditions allow for those chains\n            seq2 = pdb2.get_chain_sequence_string(c, use_seqres_sequences_if_possible, raise_Exception_if_not_found = False)\n\n            if seq2 and str(seq2) and set(str(seq2)) != unrecognized_residues:\n                sa.add_sequence('%s_%s' % (pdb2_name, c), str(seq2))\n                kept_chains.append(c)\n        pdb2_chains = kept_chains\n\n        if not(pdb1_chains):\n            raise ChainMatchingException('No valid sequences were found in %s. Alignment failed.' % pdb1_name)\n        elif not(pdb2_chains):\n            raise ChainMatchingException('No valid sequences were found in %s. Alignment failed.' % pdb2_name)\n        else:\n            sa.align()\n\n        chain_matches = dict.fromkeys(pdb1_chains, None)\n        for c in pdb1_chains:\n            best_matches_by_id = sa.get_best_matches_by_id('%s_%s' % (pdb1_name, c), cut_off = cut_off)\n            if best_matches_by_id:\n                t = []\n                for k, v in best_matches_by_id.iteritems():\n                    if k.startswith(pdb2_name + '_'):\n                        t.append((v, k))\n                if t:\n                    # We may have multiple best matches here. Instead of just returning one\n                    if allow_multiple_matches:\n                        best_matches = sorted(t)\n                        best_match_identity = best_matches[0][0]\n                        allowed_cutoff = max(cut_off, best_match_identity - multiple_match_error_margin)\n                        chain_matches[c] = []\n                        for best_match in best_matches:\n                            if best_match[0] >= allowed_cutoff:\n                                chain_matches[c].append((best_match[1].split('_')[1], best_match[0]))\n                        assert(len(chain_matches[c]) > 0)\n                    else:\n                        best_match = sorted(t)[0]\n                        chain_matches[c] = [(best_match[1].split('_')[1], best_match[0])]\n\n        return chain_matches\n    except ChainMatchingException, e:\n        raise\n    except Exception, e:\n        raise ChainMatchingException()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_RCSB_pdb_chains(pdb_id1, pdb_id2, cut_off = 60.0, allow_multiple_matches = False, multiple_match_error_margin = 3.0, use_seqres_sequences_if_possible = True, strict = True):\n    '''A convenience function for match_pdb_chains. The required arguments are two PDB IDs from the RCSB.'''\n    try:\n        stage = pdb_id1\n        pdb_1 = PDB(retrieve_pdb(pdb_id1), strict = strict)\n        stage = pdb_id2\n        pdb_2 = PDB(retrieve_pdb(pdb_id2), strict = strict)\n    except (PDBParsingException, NonCanonicalResidueException, PDBValidationException), e:\n        raise PDBParsingException(\"An error occurred while loading %s: '%s'\" % (stage, str(e)))\n\n    return match_pdb_chains(pdb_1, pdb_id1, pdb_2, pdb_id2, cut_off = cut_off, allow_multiple_matches = allow_multiple_matches, multiple_match_error_margin = multiple_match_error_margin, use_seqres_sequences_if_possible = use_seqres_sequences_if_possible)", "response": "A convenience function for match_pdb_chains. The required arguments are two PDB IDs from the RCSB. The required arguments are two PDB IDs from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_best_pdb_chains(pdb1, pdb1_name, pdb2, pdb2_name, cut_off = 60.0, use_seqres_sequences_if_possible = True):\n    '''A wrapper function for match_pdb_chains. This function only takes the best match. The return\n        value is a dict mapping\n            chain_id_in_pdb1 -> None or a tuple (chain_id_in_pdb_2, percentage_identity_score)\n       where percentage_identity_score is a float. e.g. 'A' -> ('B', 100).'''\n    d = match_pdb_chains(pdb1, pdb1_name, pdb2, pdb2_name, cut_off = cut_off, allow_multiple_matches = False, use_seqres_sequences_if_possible = use_seqres_sequences_if_possible)\n    for k, v in d.iteritems():\n        if v:\n            d[k] = v[0]\n    return d", "response": "A wrapper function for match_pdb_chains. This function only takes the best match. The return\nMimeType is a dict mapping\n            chain_id_in_pdb1 -> None or a tuple mapping\n            chain_id_in_pdb2 -> 100."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping the residues of a single PDB file to the residues of the appropriate chains in the second class.", "response": "def _map_residues(self):\n        '''For each pair of equivalence classes, match the residues of a chain in the first class to the residues of appropriate chains in the second class.\n\n            Note: we do a lot of repeated work here. Some of the lookups e.g. atom_sequences/seqres_sequences here could be cached.'''\n\n        pdbs = self.pdbs\n        pdb_names = self.pdb_names\n        partition_by_sequence = self.partition_by_sequence\n        representative_pdbs = self.representative_pdbs\n        representative_ids = sorted(representative_pdbs.keys())\n\n        # Map the SEQRES sequences to the ATOM sequences\n        # Note: The correct way to do this for RCSB files would be to use the SIFTS information like the ResidueRelatrix\n        # does. However, we have to consider the case where users upload PDB files which have not yet been deposited in\n        # the PDB so we have to resort to automatic sequence alignments. Ideally, we would store these alignments in a\n        # database and then do a lookup at this point. This would not only speed up the computation here but also allow\n        # us to manually fix misalignments (which will probably only occur due to gaps rather than mismatches).\n        seqres_to_atom_maps = {}\n        atom_to_seqres_maps = {}\n        for x in range(len(representative_ids)):\n            representative_id = representative_ids[x]\n            pdb_object = representative_pdbs[representative_id]\n            seqres_to_atom_map, atom_to_seqres_map = pdb_object.construct_seqres_to_atom_residue_map()\n\n            # todo: I tested the remainder of this class on PDBs with no SEQRES records so any code related to these maps is untested\n            #       when these assertions fail, remove them and fix the code below accordingly\n\n            seqres_to_atom_maps[representative_id] = seqres_to_atom_map\n            atom_to_seqres_maps[representative_id] = atom_to_seqres_map\n\n\n        # Iterate over all pairs of representative PDBs and determine the residue mapping and sets of differing ATOM residues\n\n        # self.residue_id_mapping maps tuples of representative ids e.g. (0, 1) to residue_id_mapping where\n        #            residue_id_mapping is a mapping: 'ATOM' -> chain_1_id -> residue_1_id -> tuple(chain_2_id, residue_2_id)\n        # where chain_x_id and residue_x_id are associated to representative_id_x\n\n        # self.differing_atom_residue_ids maps tuples of representative ids e.g. (0, 1) to PDB residues IDs which differ between\n        # the two representatives\n        for x in range(len(representative_ids) - 1):\n            for y in range(x + 1, len(representative_ids)):\n                representative_pdb_id_1 = representative_ids[x]\n                representative_pdb_id_2 = representative_ids[y]\n                rpdb_object_1 = representative_pdbs[representative_pdb_id_1]\n                rpdb_object_2 = representative_pdbs[representative_pdb_id_2]\n\n                mapping_key = (representative_pdb_id_1, representative_pdb_id_2)\n                reverse_mapping_key = mapping_key[::-1]\n\n                residue_id_mapping = {'ATOM' : {}, 'SEQRES' : {}} # todo: add the other types of mapping here e.g. FASTA and Rosetta\n                pdb1_differing_atom_residue_ids = []\n                pdb2_differing_atom_residue_ids = []\n\n                for pdb1_chain, pdb2_chains in self.get_representative_chain_mapping(mapping_key[0], mapping_key[1]).iteritems():\n                    # e.g. pdb1_chain = 'A', pdb2_chains = ['A', 'E']\n\n                    residue_id_mapping['ATOM'][pdb1_chain] = {}\n                    residue_id_mapping['SEQRES'][pdb1_chain] = {}\n\n                    # Use the SEQRES or ATOM sequence appropriately\n                    pdb1_chain_sequence_type, pdb1_chain_sequence = rpdb_object_1.get_annotated_chain_sequence_string(pdb1_chain, self.use_seqres_sequences_if_possible)\n\n                    for pdb2_chain in pdb2_chains:\n                        # Get the mapping between the sequences\n                        # Note: sequences and mappings are 1-based following the UniProt convention\n                        # The mapping returned from sa.get_residue_mapping is an abstract mapping between *sequences of characters*\n                        # and knows nothing about residue identifiers e.g. ATOM residue IDs or whether the sequences are\n                        # SEQRES or ATOM sequences\n\n                        sa = SequenceAligner()\n                        pdb2_chain_sequence_type, pdb2_chain_sequence = rpdb_object_2.get_annotated_chain_sequence_string(pdb2_chain, self.use_seqres_sequences_if_possible)\n\n                        sa.add_sequence('%s_%s' % (representative_pdb_id_1, pdb1_chain), str(pdb1_chain_sequence))\n                        sa.add_sequence('%s_%s' % (representative_pdb_id_2, pdb2_chain), str(pdb2_chain_sequence))\n                        mapping, match_mapping = sa.get_residue_mapping()\n\n                        # Since the mapping is only between sequences and we wish to use the original residue identifiers of\n                        # the sequence e.g. the PDB/ATOM residue ID, we look this information up in the order mapping of the\n                        # Sequence objects\n                        for pdb1_residue_index, pdb2_residue_index in mapping.iteritems():\n                            pdb1_residue_id = pdb1_chain_sequence.order[pdb1_residue_index - 1] # order is a 0-based list\n                            pdb2_residue_id = pdb2_chain_sequence.order[pdb2_residue_index - 1] # order is a 0-based list\n                            pdb1_atom_residue_id, pdb2_atom_residue_id = None, None\n\n                            if pdb1_chain_sequence_type == 'SEQRES' and pdb2_chain_sequence_type == 'SEQRES':\n                                residue_id_mapping['SEQRES'][pdb1_chain][pdb1_residue_id] = residue_id_mapping['SEQRES'][pdb1_chain].get(pdb1_residue_id, [])\n                                residue_id_mapping['SEQRES'][pdb1_chain][pdb1_residue_id].append((pdb2_chain, pdb2_residue_id))\n\n                                pdb1_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_1, {}).get(pdb1_chain, {}).get(pdb1_residue_id)\n                                pdb2_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_2, {}).get(pdb2_chain, {}).get(pdb2_residue_id)\n                                if pdb1_atom_residue_id != None and pdb2_atom_residue_id != None:\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_atom_residue_id] = residue_id_mapping['ATOM'][pdb1_chain].get(pdb1_atom_residue_id, [])\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_atom_residue_id].append(pdb2_atom_residue_id)\n\n                            elif pdb1_chain_sequence_type == 'SEQRES' and pdb2_chain_sequence_type == 'ATOM':\n                                pdb1_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_1, {}).get(pdb1_chain, {}).get(pdb1_residue_id)\n                                if pdb1_atom_residue_id != None:\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_atom_residue_id] = residue_id_mapping['ATOM'][pdb1_chain].get(pdb1_atom_residue_id, [])\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_atom_residue_id].append(pdb2_residue_id)\n\n                            elif pdb1_chain_sequence_type == 'ATOM' and pdb2_chain_sequence_type == 'SEQRES':\n                                pdb2_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_2, {}).get(pdb2_chain, {}).get(pdb2_residue_id)\n                                if pdb2_atom_residue_id != None:\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_residue_id] = residue_id_mapping['ATOM'][pdb1_chain].get(pdb1_residue_id, [])\n                                    residue_id_mapping['ATOM'][pdb1_chain][pdb1_residue_id].append(pdb2_atom_residue_id)\n\n                            elif pdb1_chain_sequence_type == 'ATOM' and pdb2_chain_sequence_type == 'ATOM':\n                                residue_id_mapping['ATOM'][pdb1_chain][pdb1_residue_id] = residue_id_mapping['ATOM'][pdb1_chain].get(pdb1_residue_id, [])\n                                residue_id_mapping['ATOM'][pdb1_chain][pdb1_residue_id].append(pdb2_residue_id)\n                            else:\n                                raise Exception('An exception occurred.') # this should not happen\n\n                            # We store a *list* of corresponding residues i.e. if pdb1_chain matches pdb2_chain_1 and pdb2_chain_2\n                            # then we may map a residue in pdb1_chain to a residue in each of those chains\n                            #residue_id_mapping[pdb1_chain][pdb1_residue_id] = residue_id_mapping[pdb1_chain].get(pdb1_residue_id, [])\n                            #residue_id_mapping[pdb1_chain][pdb1_residue_id].append(pdb2_residue_id)\n\n                        # Determine which residues of each sequence differ between the sequences\n                        # We ignore leading and trailing residues from both sequences\n                        pdb1_residue_indices = mapping.keys()\n                        pdb2_residue_indices = mapping.values()\n                        differing_pdb1_indices = []\n                        differing_pdb2_indices = []\n                        for pdb1_residue_index, match_details in match_mapping.iteritems():\n                            if match_details.clustal == 0 or match_details.clustal == -1 or match_details.clustal == -2:\n                                # The residues differed\n                                differing_pdb1_indices.append(pdb1_residue_index)\n                                differing_pdb2_indices.append(mapping[pdb1_residue_index])\n\n                        # Convert the different sequence indices into PDB ATOM residue IDs. Sometimes there may not be a\n                        # mapping from SEQRES residues to the ATOM residues e.g. missing density\n                        for idx in differing_pdb1_indices:\n                            if pdb1_chain_sequence_type == 'SEQRES':\n                                pdb1_seqres_residue_id = pdb1_chain_sequence.order[idx - 1]\n                                pdb1_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_1, {}).get(pdb1_chain, {}).get(pdb1_seqres_residue_id)\n                                if pdb1_atom_residue_id != None:\n                                    pdb1_differing_atom_residue_ids.append(pdb1_atom_residue_id)\n                            elif pdb1_chain_sequence_type == 'ATOM':\n                                pdb1_differing_atom_residue_ids.append(pdb1_chain_sequence.order[idx - 1])\n                        for idx in differing_pdb2_indices:\n                            if pdb2_chain_sequence_type == 'SEQRES':\n                                pdb2_seqres_residue_id = pdb2_chain_sequence.order[idx - 1]\n                                pdb2_atom_residue_id = seqres_to_atom_maps.get(representative_pdb_id_2, {}).get(pdb2_chain, {}).get(pdb2_seqres_residue_id)\n                                if pdb2_atom_residue_id != None:\n                                    pdb2_differing_atom_residue_ids.append(pdb2_atom_residue_id)\n                            elif pdb2_chain_sequence_type == 'ATOM':\n                                pdb2_differing_atom_residue_ids.append(pdb2_chain_sequence.order[idx - 1])\n\n                self.residue_id_mapping[mapping_key] = residue_id_mapping\n                self.differing_atom_residue_ids[mapping_key] = pdb1_differing_atom_residue_ids\n                self.differing_atom_residue_ids[reverse_mapping_key] = pdb2_differing_atom_residue_ids\n\n        for k, v in sorted(self.differing_atom_residue_ids.iteritems()):\n            self.differing_atom_residue_ids[k] = sorted(set(v)) # the list of residues may not be unique in general so we make it unique here\n\n        self.seqres_to_atom_maps = seqres_to_atom_maps\n        self.atom_to_seqres_maps = atom_to_seqres_maps"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_representative_chain_mapping(self, representative_id_1, representative_id_2):\n        '''This replaces the old mapping member by constructing it from self.chain_mapping. This function returns a mapping from\n        chain IDs in pdb_name1 to chain IDs in pdb_name2.'''\n        d = {}\n        for pdb1_chain_id, matched_chain_list in self.chain_mapping[(representative_id_1, representative_id_2)].iteritems():\n            d[pdb1_chain_id] = matched_chain_list.get_related_chains_ids('EC{0}'.format(representative_id_2))\n        return d", "response": "This replaces the old mapping member by constructing it from self. chain_mapping. This function returns a mapping from pdb1_chain_id to pdb2_chain_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_chain_mapping(self, pdb_name1, pdb_name2):\n        '''This replaces the old mapping member by constructing it from self.chain_mapping. This function returns a mapping from\n        chain IDs in pdb_name1 to chain IDs in pdb_name2.'''\n        raise Exception('Implement. Map pdb_namex to its equivalence class, call get_representative_chain_mapping, and something something.')\n        pprint.pprint(self.chain_mapping)\n\n        d = {}\n        for pdb1_chain_id, matched_chain_list in self.chain_mapping[(pdb_name1, pdb_name2)].iteritems():\n            d[pdb1_chain_id] = matched_chain_list.get_related_chains_ids(pdb_name2)\n        return d", "response": "This function returns a mapping from pdb_name1 to pdb_name2. This function replaces the old mapping member by constructing it from self. chain_mapping. This function returns a mapping from pdb_name1 to pdb_name2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_differing_atom_residue_ids(self, pdb_name, pdb_list = []):\n        '''Returns a list of residues in pdb_name which differ from the pdbs corresponding to the names in pdb_list.'''\n\n        # partition_by_sequence is a map pdb_name -> Int where two pdb names in the same equivalence class map to the same integer (i.e. it is a partition)\n        # representative_pdbs is a map Int -> pdb_object mapping the equivalence classes (represented by an integer) to a representative PDB file\n        # self.pdb_name_to_structure_mapping : pdb_name -> pdb_object\n\n        # Sanity checks\n        assert(pdb_name in self.pdb_names)\n        assert(set(pdb_list).intersection(set(self.pdb_names)) == set(pdb_list)) # the names in pdb_list must be in pdb_names\n\n        # 1. Get the representative structure for pdb_name\n        representative_pdb_id = self.partition_by_sequence[pdb_name]\n        representative_pdb = self.representative_pdbs[representative_pdb_id]\n\n        # 2. Get the other representative structures as dictated by pdb_list\n        other_representative_pdbs = set()\n        other_representative_pdb_ids = set()\n        if not pdb_list:\n            pdb_list = self.pdb_names\n        for opdb_name in pdb_list:\n            orepresentative_pdb_id = self.partition_by_sequence[opdb_name]\n            other_representative_pdb_ids.add(orepresentative_pdb_id)\n            other_representative_pdbs.add(self.representative_pdbs[orepresentative_pdb_id])\n        other_representative_pdbs.discard(representative_pdb)\n        other_representative_pdb_ids.discard(representative_pdb_id)\n\n        # Early out if pdb_list was empty (or all pdbs were in the same equivalence class)\n        if not other_representative_pdbs:\n            return []\n\n        # 3. Return all residues of pdb_name's representative which differ from all the other representatives\n        differing_atom_residue_ids = set()\n        for other_representative_pdb_id in other_representative_pdb_ids:\n            differing_atom_residue_ids = differing_atom_residue_ids.union(set(self.differing_atom_residue_ids[(representative_pdb_id, other_representative_pdb_id)]))\n\n        return sorted(differing_atom_residue_ids)", "response": "Returns a list of residues in pdb_name which differ from the names in pdb_list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_sequence_tooltips(self, pdb_object, pdb_sequence, pdb_sequence_type, pdb_name, pdb_chain, pdb_alignment_lines):\n        '''pdb_sequence is a Sequence object. pdb_sequence_type is a type returned by PDB.get_annotated_chain_sequence_string,\n           pdb_name is the name of the PDB used throughout this object e.g. 'Scaffold', pdb_chain is the chain of interest,\n           pdb_alignment_lines are the lines returned by SequenceAligner._get_alignment_lines.\n\n           This function returns a set of tooltips corresponding to the residues in the sequence. The tooltips are the ATOM\n           residue IDs. These tooltips can be used to generate useful (and/or interactive using JavaScript) sequence alignments\n           in HTML.\n           '''\n\n        raise Exception('Re-implement using the equivalence classes.')\n\n        tooltips = None\n        atom_sequence = pdb_object.atom_sequences.get(pdb_chain)\n\n        try:\n            if pdb_sequence_type == 'SEQRES':\n                seqres_to_atom_map = self.seqres_to_atom_maps.get(pdb_name, {}).get(pdb_chain, {})\n                tooltips = []\n                if seqres_to_atom_map:\n                    idx = 1\n                    for aligned_residue in pdb_alignment_lines.strip():\n                        if aligned_residue != '-':\n                            atom_residue = seqres_to_atom_map.get(idx)\n                            if atom_residue:\n                                # This is a sanity check to make sure that the tooltips are mapping the correct residues types to\n                                # the correct residues types\n                                assert(aligned_residue == atom_sequence.sequence[atom_residue].ResidueAA)\n                            tooltips.append(atom_residue)\n                            idx += 1\n                    assert(len(tooltips) == len(str(pdb_sequence)))\n            elif pdb_sequence_type == 'ATOM':\n                tooltips = []\n                idx = 0\n                for aligned_residue in pdb_alignment_lines.strip():\n                    if aligned_residue != '-':\n                        # This is a sanity check to make sure that the tooltips are mapping the correct residues types to\n                        # the correct residues types\n                        assert(aligned_residue == pdb_sequence.sequence[pdb_sequence.order[idx]].ResidueAA)\n                        tooltips.append(pdb_sequence.order[idx])\n                        idx += 1\n                assert(len(tooltips) == len(str(pdb_sequence)))\n        except:\n            raise Exception('An error occurred during HTML tooltip creation for the multiple sequence alignment.')\n\n        return tooltips", "response": "This function returns a set of tooltips corresponding to the residues in the given PDB sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sequence_alignment_strings(self, pdb_list = [], reversed = True, width = 80, line_separator = '\\n'):\n        '''Takes a list, pdb_list, of pdb names e.g. ['Model', 'Scaffold', ...] with which the object was created.\n            Using the first element of this list as a base, get the sequence alignments with chains in other members\n            of the list. For simplicity, if a chain in the first PDB matches multiple chains in another PDB, we only\n            return the alignment for one of the chains. If pdb_list is empty then the function defaults to the object's\n            members.\n\n            Returns one sequence alignment string for each chain mapping. Each line is a concatenation of lines of the\n            specified width, separated by the specified line separator.'''\n\n        raise Exception('Re-implement using the equivalence classes.')\n\n        sequence_alignment_printer_tuples = self.get_sequence_alignment_printer_objects(pdb_list = pdb_list, reversed = reversed, width = width, line_separator = line_separator)\n        alignment_strings = []\n        for sequence_alignment_printer_tuple in sequence_alignment_printer_tuples:\n            primary_pdb_chain = sequence_alignment_printer_tuple[0]\n            sap = sequence_alignment_printer_tuple[1]\n            alignment_strings.append(sap.to_lines(reversed = reversed, width = width, line_separator = line_separator))\n\n        return alignment_strings", "response": "Takes a list of pdb names e. g. Model Scaffold... Returns a list of strings each one containing the alignment for each chain mapping."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sequence_alignment_strings_as_html(self, pdb_list = [], reversed = False, width = 80, line_separator = '\\n', extra_tooltip_class = ''):\n        '''Takes a list, pdb_list, of pdb names e.g. ['Model', 'Scaffold', ...] with which the object was created.\n            Using the first element of this list as a base, get the sequence alignments with chains in other members\n            of the list. For simplicity, if a chain in the first PDB matches multiple chains in another PDB, we only\n            return the alignment for one of the chains. If pdb_list is empty then the function defaults to the object's\n            members.\n\n            Returns HTML for the sequence alignments and an empty string if no alignments were made.'''\n\n        raise Exception('Re-implement using the equivalence classes.')\n\n        sequence_alignment_printer_tuples = self.get_sequence_alignment_printer_objects(pdb_list = pdb_list, reversed = reversed, width = width, line_separator = line_separator)\n        if not sequence_alignment_printer_tuples:\n            return ''\n        html = []\n        for sequence_alignment_printer_tuple in sequence_alignment_printer_tuples:\n            primary_pdb_chain = sequence_alignment_printer_tuple[0]\n            sap = sequence_alignment_printer_tuple[1]\n            html.append(sap.to_html(reversed = reversed, width = width, line_separator = line_separator, extra_tooltip_class = extra_tooltip_class))\n\n        return '\\n'.join(html)", "response": "Takes a list of pdb names e. g. Model Scaffold... Returns an HTML string for the sequence alignments and an empty string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_pymol_session(self, pymol_executable = 'pymol', settings = {}):\n        ''' Generates the PyMOL session for the scaffold, model, and design structures.\n            Returns this session and the script which generated it.'''\n        b = BatchBuilder(pymol_executable = pymol_executable)\n\n        structures_list = [\n            (self.structure_1_name, self.scaffold_pdb.pdb_content, self.get_differing_scaffold_residue_ids()),\n            (self.structure_2_name, self.model_pdb.pdb_content, self.get_differing_model_residue_ids()),\n        ]\n\n        PSE_files = b.run(ScaffoldModelDesignBuilder, [PDBContainer.from_content_triple(structures_list)], settings = settings)\n\n        return PSE_files[0], b.PSE_scripts[0]", "response": "Generates the PyMOL session for the scaffold model and design structures. Returns this session and the script which generated it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the PyMOL session for the scaffold model and design structures. Returns this session and the script which generated it.", "response": "def generate_pymol_session(self, pymol_executable = 'pymol', settings = {}):\n        ''' Generates the PyMOL session for the scaffold, model, and design structures.\n            Returns this session and the script which generated it.'''\n        b = BatchBuilder(pymol_executable = pymol_executable)\n\n        if self.scaffold_pdb:\n            structures_list = [\n                ('Scaffold', self.scaffold_pdb.pdb_content, self.get_differing_scaffold_residue_ids()),\n                ('Model', self.model_pdb.pdb_content, self.get_differing_model_residue_ids()),\n                ('ExpStructure', self.design_pdb.pdb_content, self.get_differing_design_residue_ids ()),\n            ]\n        else:\n            structures_list = [\n                ('Model', self.model_pdb.pdb_content, self.get_differing_model_residue_ids()),\n                ('ExpStructure', self.design_pdb.pdb_content, self.get_differing_design_residue_ids ()),\n            ]\n\n        PSE_files = b.run(ScaffoldModelDesignBuilder, [PDBContainer.from_content_triple(structures_list)], settings = settings)\n\n        return PSE_files[0], b.PSE_scripts[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_pymol_session(self, pymol_executable = 'pymol', settings = {}):\n        ''' Generates the PyMOL session for the scaffold, model, and design structures.\n            Returns this session and the script which generated it.'''\n\n        if not self.fixed:\n            self.fix()\n\n        b = BatchBuilder(pymol_executable = pymol_executable)\n\n        for s in self.structures:\n            s.add_residues_of_interest(self.get_differing_atom_residue_ids(s.structure_name))\n\n        PSE_files = b.run(MultiStructureBuilder, [self.structures], settings = settings)\n\n        return PSE_files[0], b.PSE_scripts[0]", "response": "Generates the PyMOL session for the scaffold model and design structures. This method will automatically generate the PyMOL session for the scaffold model and design structures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of residues in pdb_name which differ from the pdbs corresponding to the names in pdb_list.", "response": "def get_differing_atom_residue_ids(self, pdb_name, pdb_list):\n        '''Returns a list of residues in pdb_name which differ from the pdbs corresponding to the names in pdb_list.'''\n\n        assert(pdb_name in self.pdb_names)\n        assert(set(pdb_list).intersection(set(self.pdb_names)) == set(pdb_list)) # the names in pdb_list must be in pdb_names\n\n        differing_atom_residue_ids = set()\n        for other_pdb in pdb_list:\n            differing_atom_residue_ids = differing_atom_residue_ids.union(set(self.differing_atom_residue_ids[(pdb_name, other_pdb)]))\n\n        return sorted(differing_atom_residue_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a list of pdb names e. g. Model Scaffold... Returns a list of tuples each containing the ID of the sequence alignment object and each other containing the object s sequence alignment.", "response": "def get_sequence_alignment_printer_objects(self, pdb_list = [], reversed = True, width = 80, line_separator = '\\n'):\n        '''Takes a list, pdb_list, of pdb names e.g. ['Model', 'Scaffold', ...] with which the object was created.\n            Using the first element of this list as a base, get the sequence alignments with chains in other members\n            of the list. For simplicity, if a chain in the first PDB matches multiple chains in another PDB, we only\n            return the alignment for one of the chains. If pdb_list is empty then the function defaults to the object's\n            members.\n\n            Returns a list of tuples (chain_id, sequence_alignment_printer_object). Each sequence_alignment_printer_object\n            can be used to generate a printable version of the sequence alignment. '''\n\n        if not pdb_list:\n            pdb_list = self.pdb_names\n\n        assert(len(set(pdb_list)) == len(pdb_list) and (len(pdb_list) > 1))\n        assert(sorted(set(pdb_list).intersection(set(self.pdb_names))) == sorted(set(pdb_list)))\n\n        primary_pdb = self.pdb_name_to_structure_mapping[pdb_list[0]]\n        primary_pdb_name = pdb_list[0]\n        primary_pdb_chains = sorted(primary_pdb.chain_atoms.keys())\n\n        sequence_alignment_printer_objects = []\n        for primary_pdb_chain in primary_pdb_chains:\n\n            sa = SequenceAligner()\n\n            # Add the primary PDB's sequence for the chain\n            primary_pdb_sequence_type, primary_pdb_sequence = primary_pdb.get_annotated_chain_sequence_string(primary_pdb_chain, self.use_seqres_sequences_if_possible)\n            sa.add_sequence('%s_%s' % (primary_pdb_name, primary_pdb_chain), str(primary_pdb_sequence))\n            other_chain_types_and_sequences = {}\n            for other_pdb_name in pdb_list[1:]:\n                other_pdb = self.pdb_name_to_structure_mapping[other_pdb_name]\n                other_chains = self.get_chain_mapping(primary_pdb_name, other_pdb_name).get(primary_pdb_chain)\n                #other_chain = self.mapping[(primary_pdb_name, other_pdb_name)].get(primary_pdb_chain)\n                if other_chains:\n                    other_chain = sorted(other_chains)[0]\n                    other_pdb_sequence_type, other_pdb_sequence = other_pdb.get_annotated_chain_sequence_string(other_chain, self.use_seqres_sequences_if_possible)\n                    other_chain_types_and_sequences[other_pdb_name] = (other_pdb_sequence_type, other_pdb_sequence)\n                    sa.add_sequence('%s_%s' % (other_pdb_name, other_chain), str(other_pdb_sequence))\n\n            if len(sa.records) > 1:\n                # If there are no corresponding sequences in any other PDB, do not return the non-alignment\n                sa.align()\n\n                #pdb1_alignment_str = sa._get_alignment_lines()['%s:%s' % (primary_pdb_name, pdb1_chain)]\n                #pdb2_alignment_str = sa._get_alignment_lines()['%s:%s' % (pdb2_name, pdb2_chain)]\n\n                sequence_names, sequences, sequence_tooltips = [], [], []\n\n                sequence_names.append('%s_%s' % (primary_pdb_name, primary_pdb_chain))\n                primary_pdb_alignment_lines = sa._get_alignment_lines()['%s_%s' % (primary_pdb_name, primary_pdb_chain)]\n                sequences.append(primary_pdb_alignment_lines)\n                sequence_tooltips.append(self.get_sequence_tooltips(primary_pdb, primary_pdb_sequence, primary_pdb_sequence_type, primary_pdb_name, primary_pdb_chain, primary_pdb_alignment_lines))\n                for other_pdb_name in pdb_list[1:]:\n                    #other_chain = self.mapping[(primary_pdb_name, other_pdb_name)].get(primary_pdb_chain)\n                    other_pdb = self.pdb_name_to_structure_mapping[other_pdb_name]\n                    other_chains = self.get_chain_mapping(primary_pdb_name, other_pdb_name).get(primary_pdb_chain)\n                    if other_chains:\n                        other_chain = sorted(other_chains)[0]\n                        sequence_names.append('%s_%s' % (other_pdb_name, other_chain))\n                        other_pdb_alignment_lines = sa._get_alignment_lines()['%s_%s' % (other_pdb_name, other_chain)]\n                        sequences.append(other_pdb_alignment_lines)\n                        other_pdb_sequence_type, other_pdb_sequence = other_chain_types_and_sequences[other_pdb_name]\n                        sequence_tooltips.append(self.get_sequence_tooltips(other_pdb, other_pdb_sequence, other_pdb_sequence_type, other_pdb_name, other_chain, other_pdb_alignment_lines))\n\n                sap = MultipleSequenceAlignmentPrinter(sequence_names, sequences, sequence_tooltips)\n                sequence_alignment_printer_objects.append((primary_pdb_chain, sap))\n\n        return sequence_alignment_printer_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef materialize_entity(ctx, etype, unique=None):\n    '''\n    Low-level routine for creating a BIBFRAME resource. Takes the entity (resource) type and a data mapping\n    according to the resource type. Implements the Libhub Resource Hash Convention\n    As a convenience, if a vocabulary base is provided in the context, concatenate it to etype and the data keys\n\n    ctx - context information governing creation of the new entity\n    etype - type IRI for th enew entity\n    unique - list of key/value tuples of data to use in generating its unique ID, or None in which case one is just randomly generated\n    '''\n    params = {}\n    if ctx.base:\n        etype = ctx.base + etype\n\n    unique_computed = []\n    for k, v in unique:\n        k = k if iri.is_absolute(k) else iri.absolutize(k, ctx.base)\n        v = v(ctx) if callable(v) else v\n        unique_computed.append((k, v))\n\n    if unique_computed:\n        plaintext = json.dumps([etype, unique_computed], cls=OrderedJsonEncoder)\n        eid = ctx.idgen.send(plaintext)\n    else:\n        #We only have a type; no other distinguishing data. Generate a random hash\n        eid = next(ctx.idgen)\n    return eid", "response": "Materialize a resource into a new entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self):\n        for validator in self.validators:\n            try:\n                validator(self.obj)\n            except ValidationError as e:\n                self.errors.append(e.error)\n\n        if not self.errors and self._has_unvalidated_prefix():\n            self._move_to_validated()\n\n        return not self.errors", "response": "Validates the given Amazon S3 file with the given validator list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the database for missing notifications.", "response": "def check_db_for_missing_notifications():\n    \"\"\"Check the database for missing notifications.\"\"\"\n    aws_access_key_id = os.environ['aws_access_key_id']\n    aws_secret_access_key = os.environ['aws_secret_access_key']\n    if config.getboolean('Shell Parameters', 'launch_in_sandbox_mode'):\n        conn = MTurkConnection(\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            host='mechanicalturk.sandbox.amazonaws.com')\n    else:\n        conn = MTurkConnection(\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key)\n\n    # get all participants with status < 100\n    participants = Participant.query.filter_by(status=\"working\").all()\n\n    # get current time\n    current_time = datetime.now()\n\n    # get experiment duration in seconds\n    duration = float(config.get('HIT Configuration', 'duration')) * 60 * 60\n\n    # for each participant, if current_time - start_time > duration + 5 mins\n    for p in participants:\n        p_time = (current_time - p.creation_time).total_seconds()\n\n        if p_time > (duration + 120):\n            print (\"Error: participant {} with status {} has been playing for too \"\n                   \"long and no notification has arrived - \"\n                   \"running emergency code\".format(p.id, p.status))\n\n            # get their assignment\n            assignment_id = p.assignment_id\n\n            # ask amazon for the status of the assignment\n            try:\n                assignment = conn.get_assignment(assignment_id)[0]\n                status = assignment.AssignmentStatus\n            except:\n                status = None\n            print \"assignment status from AWS is {}\".format(status)\n            hit_id = p.hit_id\n\n            # general email settings:\n            username = os.getenv('wallace_email_username')\n            fromaddr = username + \"@gmail.com\"\n            email_password = os.getenv(\"wallace_email_key\")\n            toaddr = config.get('HIT Configuration', 'contact_email_on_error')\n            whimsical = os.getenv(\"whimsical\")\n\n            if status == \"Approved\":\n                # if its been approved, set the status accordingly\n                print \"status set to approved\"\n                p.status = \"approved\"\n                session.commit()\n            elif status == \"Rejected\":\n                print \"status set to rejected\"\n                # if its been rejected, set the status accordingly\n                p.status = \"rejected\"\n                session.commit()\n            elif status == \"Submitted\":\n                # if it has been submitted then resend a submitted notification\n                args = {\n                    'Event.1.EventType': 'AssignmentSubmitted',\n                    'Event.1.AssignmentId': assignment_id\n                }\n                requests.post(\n                    \"http://\" + os.environ['HOST'] + '/notifications',\n                    data=args)\n\n                # send the researcher an email to let them know\n                if whimsical:\n                    msg = MIMEText(\n                        \"\"\"Dearest Friend,\\n\\nI am writing to let you know that at\n {}, during my regular (and thoroughly enjoyable) perousal of the most charming\n  participant data table, I happened to notice that assignment {} has been\n taking longer than we were expecting. I recall you had suggested {} minutes as\n an upper limit for what was an acceptable length of time for each assignement\n , however this assignment had been underway for a shocking {} minutes, a full\n {} minutes over your allowance. I immediately dispatched a telegram to our\n mutual friends at AWS and they were able to assure me that although the\n notification had failed to be correctly processed, the assignment had in fact\n been completed. Rather than trouble you, I dealt with this myself and I can\n assure you there is no immediate cause for concern. Nonetheless, for my own\n peace of mind, I would appreciate you taking the time to look into this matter\n at your earliest convenience.\\n\\nI remain your faithful and obedient servant,\n\\nAlfred R. Wallace\\n\\n P.S. Please do not respond to this message, I am busy\n with other matters.\"\"\".format(\n                        datetime.now(),\n                        assignment_id,\n                        round(duration/60),\n                        round(p_time/60),\n                        round((p_time-duration)/60)))\n                    msg['Subject'] = \"A matter of minor concern.\"\n                else:\n                    msg = MIMEText(\n                        \"\"\"Dear experimenter,\\n\\nThis is an automated email from\n Wallace. You are receiving this email because the Wallace platform has\n discovered evidence that a notification from Amazon Web Services failed to\n arrive at the server. Wallace has automatically contacted AWS and has\n determined the dropped notification was a submitted notification (i.e. the\n participant has finished the experiment). This is a non-fatal error and so\n Wallace has auto-corrected the problem. Nonetheless you may wish to check the\n database.\\n\\nBest,\\nThe Wallace dev. team.\\n\\n Error details:\\nAssignment: {}\n\\nAllowed time: {}\\nTime since participant started: {}\"\"\").format(\n                        assignment_id,\n                        round(duration/60),\n                        round(p_time/60))\n                    msg['Subject'] = \"Wallace automated email - minor error.\"\n\n                # This method commented out as gmail now blocks emails from\n                # new locations\n                # server = smtplib.SMTP('smtp.gmail.com:587')\n                # server.starttls()\n                # server.login(username, email_password)\n                # server.sendmail(fromaddr, toaddr, msg.as_string())\n                # server.quit()\n                print (\"Error - submitted notification for participant {} missed. \"\n                       \"Database automatically corrected, but proceed with caution.\"\n                       .format(p.id))\n            else:\n                # if it has not been submitted shut everything down\n                # first turn off autorecruit\n                host = os.environ['HOST']\n                host = host[:-len(\".herokuapp.com\")]\n                args = json.dumps({\"auto_recruit\": \"false\"})\n                headers = {\n                    \"Accept\": \"application/vnd.heroku+json; version=3\",\n                    \"Content-Type\": \"application/json\"\n                }\n                heroku_email_address = os.getenv('heroku_email_address')\n                heroku_password = os.getenv('heroku_password')\n                requests.patch(\n                    \"https://api.heroku.com/apps/{}/config-vars\".format(host),\n                    data=args,\n                    auth=(heroku_email_address, heroku_password),\n                    headers=headers)\n\n                # then force expire the hit via boto\n                conn.expire_hit(hit_id)\n\n                # send the researcher an email to let them know\n                if whimsical:\n                    msg = MIMEText(\n                        \"\"\"Dearest Friend,\\n\\nI am afraid I write to you with most\n grave tidings. At {}, during a routine check of the usually most delightful\n participant data table, I happened to notice that assignment {} has been\n taking longer than we were expecting. I recall you had suggested {} minutes as\n an upper limit for what was an acceptable length of time for each assignment,\n however this assignment had been underway for a shocking {} minutes, a full {}\n minutes over your allowance. I immediately dispatched a telegram to our mutual\n friends at AWS and they infact informed me that they had already sent us a\n notification which we must have failed to process, implying that the\n assignment had not been successfully completed. Of course when the seriousness\n of this scenario dawned on me I had to depend on my trusting walking stick for\n support: without the notification I didn't know to remove the old assignment's\n data from the tables and AWS will have already sent their replacement, meaning\n that the tables may already be in a most unsound state!\\n\\nI am sorry to\n trouble you with this, however, I do not know how to proceed so rather than\n trying to remedy the scenario myself, I have instead temporarily ceased\n operations by expiring the HIT with the fellows at AWS and have refrained from\n posting any further invitations myself. Once you see fit I would be most\n appreciative if you could attend to this issue with the caution, sensitivity\n and intelligence for which I know you so well.\\n\\nI remain your faithful and\n obedient servant,\\nAlfred R. Wallace\\n\\nP.S. Please do not respond to this\n message, I am busy with other matters.\"\"\".format(\n                        datetime.now(),\n                        assignment_id,\n                        round(duration/60),\n                        round(p_time/60),\n                        round((p_time-duration)/60)))\n                    msg['Subject'] = \"Most troubling news.\"\n                else:\n                    msg = MIMEText(\n                        \"\"\"Dear experimenter,\\n\\nThis is an automated email from\n Wallace. You are receiving this email because the Wallace platform has\n discovered evidence that a notification from Amazon Web Services failed to\n arrive at the server. Wallace has automatically contacted AWS and has\n determined the dropped notification was an abandoned/returned notification\n (i.e. the participant had returned the experiment or had run out of time).\n This is a serious error and so Wallace has paused the experiment - expiring\n the HIT on MTurk and setting auto_recruit to false. Participants currently\n playing will be able to finish, however no further participants will be\n recruited until you do so manually. We strongly suggest you use the details\n below to check the database to make sure the missing notification has not caused\n additional problems before resuming.\\nIf you are receiving a lot of these\n emails this suggests something is wrong with your experiment code.\\n\\nBest,\n\\nThe Wallace dev. team.\\n\\n Error details:\\nAssignment: {}\n\\nAllowed time: {}\\nTime since participant started: {}\"\"\").format(\n                        assignment_id,\n                        round(duration/60),\n                        round(p_time/60))\n                    msg['Subject'] = \"Wallace automated email - major error.\"\n\n                # This method commented out as gmail now blocks emails from\n                # new locations\n                # server = smtplib.SMTP('smtp.gmail.com:587')\n                # server.starttls()\n                # server.login(username, email_password)\n                # server.sendmail(fromaddr, toaddr, msg.as_string())\n                # server.quit()\n\n                # send a notificationmissing notification\n                args = {\n                    'Event.1.EventType': 'NotificationMissing',\n                    'Event.1.AssignmentId': assignment_id\n                }\n                requests.post(\n                    \"http://\" + os.environ['HOST'] + '/notifications',\n                    data=args)\n\n                print (\"Error - abandoned/returned notification for participant {} missed. \"\n                       \"Experiment shut down. Please check database and then manually \"\n                       \"resume experiment.\"\n                       .format(p.id))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_apps(self):\n        apps = {}\n        for cfgfile in glob.iglob(os.path.join(self.confdir, '*.conf')):\n            name = os.path.basename(cfgfile)[0:-5]\n            try:\n                app = AppLogParser(name, cfgfile, self.args, self.logdir,\n                                   self.fields, self.name_cache, self.report)\n            except (LogRaptorOptionError, LogRaptorConfigError, LogFormatError) as err:\n                logger.error('cannot add app %r: %s', name, err)\n            else:\n                apps[name] = app\n\n        if not apps:\n            raise LogRaptorConfigError('no configured application in %r!' % self.confdir)\n        return apps", "response": "Read the configuration of applications returning a dictionary with application names as keys and configuration \\\n objects as values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple with re. RegexObject objects created from regex pattern arguments.", "response": "def patterns(self):\n        \"\"\"\n        A tuple with re.RegexObject objects created from regex pattern arguments.\n        \"\"\"\n        # No explicit argument for patterns ==> consider the first source argument as pattern.\n        if not self.args.patterns and not self.args.pattern_files:\n            try:\n                self.args.patterns.append(self.args.files.pop(0))\n            except IndexError:\n                raise LogRaptorArgumentError('PATTERN', 'no search pattern')\n\n        # Get the patterns from arguments and files\n        patterns = set()\n        if self.args.pattern_files:\n            patterns.update([p.rstrip('\\n') for p in fileinput.input(self.args.pattern_files)])\n        patterns.update(self.args.patterns)\n        logger.debug(\"search patterns to be processed: %r\", patterns)\n\n        # If one pattern is empty then skip the other patterns\n        if '' in patterns:\n            logger.info(\"an empty pattern provided: match all strings!\")\n            return tuple()\n\n        try:\n            flags = re.IGNORECASE if self.args.case else 0 | re.UNICODE\n            return tuple([\n                re.compile(r'(\\b%s\\b)' % pat if self.args.word else '(%s)' % pat, flags=flags)\n                for pat in patterns if pat\n            ])\n        except re.error as err:\n            raise LogRaptorArgumentError('wrong regex syntax for pattern: %r' % err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef files(self):\n        # If no files but a recursion option ==> use the current directory\n        if not self.args.files and self.recursive:\n            return ['.']\n        else:\n            return self.args.files", "response": "A list of input sources. Each item can be a file path a glob path or URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the matcher engine for the log raptor.", "response": "def matcher(self):\n        \"\"\"\n        Matcher engine: ruled, unruled, unparsed.\n        \"\"\"\n        if self.args.matcher is None:\n            return 'ruled'\n        elif self.args.matcher.startswith('-'):\n            matcher = self.args.matcher.strip('-').replace('-', '_')\n        else:\n            matcher = self.args.matcher\n\n        if matcher not in ['ruled', 'unruled', 'unparsed']:\n            raise LogRaptorArgumentError('matcher', 'unknown matcher argument %r' % matcher)\n        return matcher"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef time_period(self):\n        if self.args.time_period is None:\n            if self.args.files or is_pipe(STDIN_FILENO) or is_redirected(STDIN_FILENO):\n                time_period = (None, None)\n            else:\n                diff = 86400  # 24h = 86400 seconds\n                time_period = get_datetime_interval(int(time.time()), diff, 3600)\n        else:\n            time_period = self.args.time_period\n\n        logger.debug('time period to be processed: %r', time_period)\n        return time_period", "response": "Return the time period that is determined from the arguments date and last."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary mapping from log app - name to application.", "response": "def apptags(self):\n        \"\"\"\n        Map from log app-name to an application.\n        \"\"\"\n        logger.debug(\"populate tags map ...\")\n        apps = self._apps.keys()\n        unknown = set(apps)\n        unknown.difference_update(self._config_apps.keys())\n        if unknown:\n            raise ValueError(\"unknown apps: %r\" % list(unknown))\n\n        apps = [v for v in self._config_apps.values() if v.name in apps]\n        tagmap = {}\n        for app in sorted(apps, key=lambda x: (x.priority, x.name)):\n            for tag in app.tags:\n                if not tag:\n                    raise LogRaptorConfigError('found an empty tag for app %r' % app.name)\n                try:\n                    tagmap[tag].append(app)\n                except KeyError:\n                    tagmap[tag] = [app]\n        return tagmap"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all available channels.", "response": "def channels(self):\n        \"\"\"Output channels\"\"\"\n        try:\n            return self._channels\n        except AttributeError:\n            logger.debug(\"initialize output channels ...\")\n\n        channels = self.args.channels\n        config_channels = [sec.rpartition('_')[0] for sec in self.config.sections(suffix='_channel')]\n        unknown = set(channels) - set(config_channels)\n        if unknown:\n            raise ValueError(\"undefined channel %r\" % list(unknown))\n\n        output_channels = []\n        for channel in set(channels):\n            channel_type = self.config.get('%s_channel' % channel, 'type')\n            if channel_type == 'tty':\n                output_channels.append(TermChannel(channel, self.args, self.config))\n            elif channel_type == 'file':\n                output_channels.append(FileChannel(channel, self.args, self.config))\n            elif channel_type == 'mail':\n                output_channels.append(MailChannel(channel, self.args, self.config))\n            else:\n                raise LogRaptorConfigError('unknown channel type %r' % channel_type)\n        return output_channels"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_dispatcher(self):\n        before_context = max(self.args.before_context, self.args.context)\n        after_context = max(self.args.after_context, self.args.context)\n\n        if self.args.files_with_match is not None or self.args.count or self.args.only_matching or self.args.quiet:\n            # Sending of log lines disabled by arguments\n            return UnbufferedDispatcher(self._channels)\n        elif before_context == 0 and after_context == 0:\n            # Don't need line buffering\n            return UnbufferedDispatcher(self._channels)\n        elif self.args.thread:\n            return ThreadedDispatcher(self._channels, before_context, after_context)\n        else:\n            return LineBufferDispatcher(self._channels, before_context, after_context)", "response": "Create a dispatcher for configured channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_config(self):\n        # Create a dummy report object if necessary\n        channels = [sect.rsplit('_')[0] for sect in self.config.sections(suffix='_channel')]\n        channels.sort()\n        disabled_apps = [app for app in self._config_apps.keys() if app not in self._apps]\n        return u''.join([\n            u\"\\n--- %s configuration ---\" % __package__,\n            u\"\\nConfiguration file: %s\" % self.config.cfgfile,\n            u\"\\nConfiguration directory: %s\" % self.confdir,\n            u\"\\nConfigured applications: %s\" % ', '.join(self._config_apps.keys()),\n            u\"\\nDisabled applications: %s\" % ', '.join(disabled_apps) if disabled_apps else '',\n            u\"\\nFilter fields: %s\" % ', '.join(self.config.options('fields')),\n            u\"\\nOutput channels: %s\" % ', '.join(channels) if channels else u'No channels defined',\n            u\"\\nReports: %s\\n\" % ', '.join(\n                [section[:-7] for section in self.config.sections(suffix='_report')]\n            ),\n            ''\n        ])", "response": "Return a formatted text with main configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing a text summary from run statistics.", "response": "def get_run_summary(self, run_stats):\n        \"\"\"\n        Produce a text summary from run statistics.\n\n        :param run_stats: A dictionary containing run stats\n        :return: Formatted multiline string\n        \"\"\"\n        run_stats = run_stats.copy()\n        run_stats['files'] = len(run_stats['files'])\n        summary = [\n            u'\\n--- %s run summary ---' % __package__,\n            u'Number of processed files: %(files)d',\n            u'Total lines read: %(lines)d',\n            u'Total log events matched: %(matches)d',\n        ]\n        if any([app.matches or app.unparsed for app in self.apps.values()]):\n            if self.matcher == 'unruled':\n                summary.append(\"Applications found (application rules not used):\")\n                for app in filter(lambda x: x.matches, self.apps.values()):\n                    summary.append(u'  %s(matches=%d)' % (app.name, app.matches))\n            else:\n                summary.append(\"Applications found:\")\n                for app in filter(lambda x: x.matches or x.unparsed, self.apps.values()):\n                    summary.append(u'  %s(matches=%d, unparsed=%s)' % (app.name, app.matches, app.unparsed))\n        summary.append('\\n')\n        return '\\n'.join(summary) % run_stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_template_dirs(app):\n    template_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')\n\n    app.jinja_loader = jinja2.ChoiceLoader(\n        [app.jinja_loader, jinja2.FileSystemLoader(template_dir)]\n    )", "response": "Add flask_mongo_profiler s template directories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwalking the user though the Wallace setup.", "response": "def setup():\n    \"\"\"Walk the user though the Wallace setup.\"\"\"\n    # Create the Wallace config file if it does not already exist.\n    config_name = \".wallaceconfig\"\n    config_path = os.path.join(os.path.expanduser(\"~\"), config_name)\n\n    if os.path.isfile(config_path):\n        log(\"Wallace config file already exists.\", chevrons=False)\n\n    else:\n        log(\"Creating Wallace config file at ~/.wallaceconfig...\",\n            chevrons=False)\n        wallace_module_path = os.path.dirname(os.path.realpath(__file__))\n        src = os.path.join(wallace_module_path, \"config\", config_name)\n        shutil.copyfile(src, config_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the app and, if it's compatible with Wallace, freeze its state.", "response": "def setup_experiment(debug=True, verbose=False, app=None):\n    \"\"\"Check the app and, if it's compatible with Wallace, freeze its state.\"\"\"\n    print_header()\n\n    # Verify that the package is usable.\n    log(\"Verifying that directory is compatible with Wallace...\")\n    if not verify_package(verbose=verbose):\n        raise AssertionError(\n            \"This is not a valid Wallace app. \" +\n            \"Fix the errors and then try running 'wallace verify'.\")\n\n    # Verify that the Postgres server is running.\n    try:\n        psycopg2.connect(database=\"x\", user=\"postgres\", password=\"nada\")\n    except psycopg2.OperationalError, e:\n        if \"could not connect to server\" in str(e):\n            raise RuntimeError(\"The Postgres server isn't running.\")\n\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    # Check that the demo-specific requirements are satisfied.\n    try:\n        with open(\"requirements.txt\", \"r\") as f:\n            dependencies = f.readlines()\n    except:\n        dependencies = []\n\n    pkg_resources.require(dependencies)\n\n    # Generate a unique id for this experiment.\n    id = \"w\" + str(uuid.uuid4())[0:28]\n\n    # If the user provided an app name, use it everywhere that's user-facing.\n    if app:\n        id_long = id\n        id = str(app)\n\n    log(\"Running as experiment \" + id + \"...\")\n\n    # Copy this directory into a temporary folder, ignoring .git\n    dst = os.path.join(tempfile.mkdtemp(), id)\n    to_ignore = shutil.ignore_patterns(\n        \".git/*\",\n        \"*.db\",\n        \"snapshots\",\n        \"data\",\n        \"server.log\"\n    )\n    shutil.copytree(os.getcwd(), dst, ignore=to_ignore)\n\n    click.echo(dst)\n\n    # Save the experiment id\n    with open(os.path.join(dst, \"experiment_id.txt\"), \"w\") as file:\n        if app:\n            file.write(id_long)\n        else:\n            file.write(id)\n\n    # Zip up the temporary directory and place it in the cwd.\n    if not debug:\n        log(\"Freezing the experiment package...\")\n        shutil.make_archive(\n            os.path.join(\"snapshots\", id + \"-code\"), \"zip\", dst)\n\n    # Change directory to the temporary folder.\n    cwd = os.getcwd()\n    os.chdir(dst)\n\n    # Check directories.\n    if not os.path.exists(\"static/scripts\"):\n        os.makedirs(\"static/scripts\")\n    if not os.path.exists(\"templates\"):\n        os.makedirs(\"templates\")\n    if not os.path.exists(\"static/css\"):\n        os.makedirs(\"static/css\")\n\n    # Rename experiment.py to wallace_experiment.py to aviod psiTurk conflict.\n    os.rename(\n        os.path.join(dst, \"experiment.py\"),\n        os.path.join(dst, \"wallace_experiment.py\"))\n\n    # Copy files into this experiment package.\n    src = os.path.join(\n        os.path.dirname(os.path.realpath(__file__)),\n        \"custom.py\")\n    shutil.copy(src, os.path.join(dst, \"custom.py\"))\n\n    heroku_files = [\n        \"Procfile\",\n        \"requirements.txt\",\n        \"psiturkapp.py\",\n        \"worker.py\",\n        \"clock.py\",\n    ]\n\n    for filename in heroku_files:\n        src = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            \"heroku\",\n            filename)\n        shutil.copy(src, os.path.join(dst, filename))\n\n    clock_on = config.getboolean('Server Parameters', 'clock_on')\n\n    # If the clock process has been disabled, overwrite the Procfile.\n    if not clock_on:\n        src = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            \"heroku\",\n            \"Procfile_no_clock\")\n        shutil.copy(src, os.path.join(dst, \"Procfile\"))\n\n    frontend_files = [\n        \"static/css/wallace.css\",\n        \"static/scripts/wallace.js\",\n        \"static/scripts/reqwest.min.js\",\n        \"templates/error_wallace.html\",\n        \"templates/launch.html\",\n        \"templates/complete.html\",\n        \"static/robots.txt\"\n    ]\n\n    for filename in frontend_files:\n        src = os.path.join(\n            os.path.dirname(os.path.realpath(__file__)),\n            \"frontend\",\n            filename)\n        shutil.copy(src, os.path.join(dst, filename))\n\n    time.sleep(0.25)\n\n    os.chdir(cwd)\n\n    return (id, dst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a summary of a deployed app s status.", "response": "def summary(app):\n    \"\"\"Print a summary of a deployed app's status.\"\"\"\n    r = requests.get('https://{}.herokuapp.com/summary'.format(app))\n    summary = r.json()['summary']\n    click.echo(\"\\nstatus \\t| count\")\n    click.echo(\"----------------\")\n    for s in summary:\n        click.echo(\"{}\\t| {}\".format(s[0], s[1]))\n    num_101s = sum([s[1] for s in summary if s[0] == 101])\n    num_10xs = sum([s[1] for s in summary if s[0] >= 100])\n    if num_10xs > 0:\n        click.echo(\"\\nYield: {:.2%}\".format(1.0 * num_101s / num_10xs))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef debug(verbose):\n    (id, tmp) = setup_experiment(debug=True, verbose=verbose)\n\n    # Drop all the tables from the database.\n    db.init_db(drop_all=True)\n\n    # Switch to the temporary directory.\n    cwd = os.getcwd()\n    os.chdir(tmp)\n\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    # Set the mode to debug.\n    config.set(\"Experiment Configuration\", \"mode\", \"debug\")\n    config.set(\"Shell Parameters\", \"launch_in_sandbox_mode\", \"true\")\n    config.set(\n        \"Server Parameters\",\n        \"logfile\",\n        os.path.join(cwd, config.get(\"Server Parameters\", \"logfile\")))\n\n    # Swap in the HotAirRecruiter\n    os.rename(\"wallace_experiment.py\", \"wallace_experiment_tmp.py\")\n    with open(\"wallace_experiment_tmp.py\", \"r+\") as f:\n        with open(\"wallace_experiment.py\", \"w+\") as f2:\n            f2.write(\"from wallace.recruiters import HotAirRecruiter\\n\")\n            for idx, line in enumerate(f):\n                if re.search(\"\\s*self.recruiter = (.*)\", line):\n                    p = line.partition(\"self.recruiter =\")\n                    f2.write(p[0] + p[1] + ' HotAirRecruiter\\n')\n                else:\n                    f2.write(line)\n\n    os.remove(\"wallace_experiment_tmp.py\")\n\n    # Set environment variables.\n    aws_vars = ['aws_access_key_id', 'aws_secret_access_key', 'aws_region']\n    for var in aws_vars:\n        if var not in os.environ:\n            os.environ[var] = config.get('AWS Access', var)\n\n    pt_vars = ['psiturk_access_key_id', 'psiturk_secret_access_id']\n    for var in pt_vars:\n        if var not in os.environ:\n            os.environ[var] = config.get('psiTurk Access', var)\n\n    if \"HOST\" not in os.environ:\n        os.environ[\"HOST\"] = config.get('Server Parameters', 'host')\n\n    # Start up the local server\n    log(\"Starting up the server...\")\n\n    # Try opening the psiTurk shell.\n    try:\n        p = pexpect.spawn(\"psiturk\")\n        p.expect_exact(\"]$\")\n        p.sendline(\"server on\")\n        p.expect_exact(\"Experiment server launching...\")\n\n        # Launche the experiment.\n        time.sleep(4)\n\n        host = config.get(\"Server Parameters\", \"host\")\n        port = config.get(\"Server Parameters\", \"port\")\n\n        subprocess.call(\n            'curl --data \"\" http://{}:{}/launch'.format(host, port),\n            shell=True)\n\n        log(\"Here's the psiTurk shell...\")\n        p.interact()\n\n    except Exception:\n        click.echo(\"\\nCouldn't open psiTurk shell. Internet connection okay?\")\n\n    log(\"Completed debugging of experiment \" + id + \".\")\n    os.chdir(cwd)", "response": "Run the experiment locally."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scale_up_dynos(id):\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    dyno_type = config.get('Server Parameters', 'dyno_type')\n    num_dynos_web = config.get('Server Parameters', 'num_dynos_web')\n    num_dynos_worker = config.get('Server Parameters', 'num_dynos_worker')\n\n    log(\"Scaling up the dynos...\")\n    subprocess.call(\n        \"heroku ps:scale web=\" + str(num_dynos_web) + \":\" +\n        str(dyno_type) + \" --app \" + id, shell=True)\n\n    subprocess.call(\n        \"heroku ps:scale worker=\" + str(num_dynos_worker) + \":\" +\n        str(dyno_type) + \" --app \" + id, shell=True)\n\n    clock_on = config.getboolean('Server Parameters', 'clock_on')\n    if clock_on:\n        subprocess.call(\n            \"heroku ps:scale clock=1:\" + dyno_type + \" --app \" + id,\n            shell=True)", "response": "Scale up the Heroku dynos."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy_sandbox_shared_setup(verbose=True, app=None, web_procs=1):\n    if verbose:\n        out = None\n    else:\n        out = open(os.devnull, 'w')\n\n    (id, tmp) = setup_experiment(debug=False, verbose=verbose, app=app)\n\n    # Log in to Heroku if we aren't already.\n    log(\"Making sure that you are logged in to Heroku.\")\n    ensure_heroku_logged_in()\n\n    # Change to temporary directory.\n    cwd = os.getcwd()\n    os.chdir(tmp)\n\n    # Commit Heroku-specific files to tmp folder's git repo.\n    cmds = [\"git init\",\n            \"git add --all\",\n            'git commit -m \"Experiment ' + id + '\"']\n    for cmd in cmds:\n        subprocess.call(cmd, stdout=out, shell=True)\n        time.sleep(0.5)\n\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    # Initialize the app on Heroku.\n    log(\"Initializing app on Heroku...\")\n    subprocess.call(\n        \"heroku apps:create \" + id +\n        \" --buildpack https://github.com/thenovices/heroku-buildpack-scipy\",\n        stdout=out,\n        shell=True)\n\n    database_size = config.get('Database Parameters', 'database_size')\n\n    try:\n        if config.getboolean('Easter eggs', 'whimsical'):\n            whimsical = \"true\"\n        else:\n            whimsical = \"false\"\n    except:\n        whimsical = \"false\"\n\n    # Set up postgres database and AWS/psiTurk environment variables.\n    cmds = [\n        \"heroku addons:create heroku-postgresql:{}\".format(database_size),\n\n        \"heroku pg:wait\",\n\n        \"heroku addons:create rediscloud:250\",\n\n        \"heroku addons:create papertrail\",\n\n        \"heroku config:set HOST=\" +\n        id + \".herokuapp.com\",\n\n        \"heroku config:set aws_access_key_id=\" +\n        config.get('AWS Access', 'aws_access_key_id'),\n\n        \"heroku config:set aws_secret_access_key=\" +\n        config.get('AWS Access', 'aws_secret_access_key'),\n\n        \"heroku config:set aws_region=\" +\n        config.get('AWS Access', 'aws_region'),\n\n        \"heroku config:set psiturk_access_key_id=\" +\n        config.get('psiTurk Access', 'psiturk_access_key_id'),\n\n        \"heroku config:set psiturk_secret_access_id=\" +\n        config.get('psiTurk Access', 'psiturk_secret_access_id'),\n\n        \"heroku config:set auto_recruit=\" +\n        config.get('Experiment Configuration', 'auto_recruit'),\n\n        \"heroku config:set wallace_email_username=\" +\n        config.get('Email Access', 'wallace_email_address'),\n\n        \"heroku config:set wallace_email_key=\" +\n        config.get('Email Access', 'wallace_email_password'),\n\n        \"heroku config:set heroku_email_address=\" +\n        config.get('Heroku Access', 'heroku_email_address'),\n\n        \"heroku config:set heroku_password=\" +\n        config.get('Heroku Access', 'heroku_password'),\n\n        \"heroku config:set whimsical=\" + whimsical,\n    ]\n    for cmd in cmds:\n        subprocess.call(cmd + \" --app \" + id, stdout=out, shell=True)\n\n    # Set the notification URL in the cofig file to the notifications URL.\n    config.set(\n        \"Server Parameters\",\n        \"notification_url\",\n        \"http://\" + id + \".herokuapp.com/notifications\")\n\n    # Set the database URL in the config file to the newly generated one.\n    log(\"Saving the URL of the postgres database...\")\n    db_url = subprocess.check_output(\n        \"heroku config:get DATABASE_URL --app \" + id, shell=True)\n    config.set(\"Database Parameters\", \"database_url\", db_url.rstrip())\n    subprocess.call(\"git add config.txt\", stdout=out, shell=True),\n    time.sleep(0.25)\n    subprocess.call(\n        'git commit -m \"Save URLs for database and notifications\"',\n        stdout=out,\n        shell=True)\n    time.sleep(0.25)\n\n    # Launch the Heroku app.\n    log(\"Pushing code to Heroku...\")\n    subprocess.call(\"git push heroku HEAD:master\", stdout=out,\n                    stderr=out, shell=True)\n\n    scale_up_dynos(id)\n\n    time.sleep(8)\n\n    # Launch the experiment.\n    log(\"Launching the experiment on MTurk...\")\n    subprocess.call(\n        'curl --data \"\" http://{}.herokuapp.com/launch'.format(id),\n        shell=True)\n\n    time.sleep(8)\n\n    url = subprocess.check_output(\"heroku logs --app \" + id + \" | sort | \" +\n                                  \"sed -n 's|.*URL:||p'\", shell=True)\n\n    log(\"URLs:\")\n    click.echo(url)\n\n    # Return to the branch whence we came.\n    os.chdir(cwd)\n\n    log(\"Completed deployment of experiment \" + id + \".\")", "response": "Deploy the sandbox to Heroku and launch the app."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sandbox(verbose, app):\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    # Set the mode.\n    config.set(\"Experiment Configuration\", \"mode\", \"sandbox\")\n    config.set(\"Server Parameters\", \"logfile\", \"-\")\n\n    # Ensure that psiTurk is in sandbox mode.\n    config.set(\"Shell Parameters\", \"launch_in_sandbox_mode\", \"true\")\n\n    # Do shared setup.\n    deploy_sandbox_shared_setup(verbose=verbose, app=app)", "response": "Deploy app using Heroku to the MTurk Sandbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeploys app using Heroku to MTurk.", "response": "def deploy(verbose, app):\n    \"\"\"Deploy app using Heroku to MTurk.\"\"\"\n    # Load psiTurk configuration.\n    config = PsiturkConfig()\n    config.load_config()\n\n    # Set the mode.\n    config.set(\"Experiment Configuration\", \"mode\", \"deploy\")\n    config.set(\"Server Parameters\", \"logfile\", \"-\")\n\n    # Ensure that psiTurk is not in sandbox mode.\n    config.set(\"Shell Parameters\", \"launch_in_sandbox_mode\", \"false\")\n\n    # Do shared setup.\n    deploy_sandbox_shared_setup(verbose=verbose, app=app)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning a qualification to a worker.", "response": "def qualify(qualification, value, worker):\n    \"\"\"Assign a qualification to a worker.\"\"\"\n    # create connection to AWS\n    from boto.mturk.connection import MTurkConnection\n    config = PsiturkConfig()\n    config.load_config()\n    aws_access_key_id = config.get('AWS Access', 'aws_access_key_id')\n    aws_secret_access_key = config.get('AWS Access', 'aws_secret_access_key')\n    conn = MTurkConnection(aws_access_key_id, aws_secret_access_key)\n\n    def get_workers_with_qualification(qualification):\n        \"\"\"Get workers with the given qualification.\"\"\"\n        results = []\n        continue_flag = True\n        page = 1\n        while(continue_flag):\n            new_results = conn.get_qualifications_for_qualification_type(\n                qualification,\n                page_size=100,\n                page_number=page)\n\n            if(len(new_results) == 0):\n                continue_flag = False\n            else:\n                results.extend(new_results)\n                page = page + 1\n\n        return results\n\n    results = get_workers_with_qualification(qualification)\n    workers = [x.SubjectId for x in results]\n\n    # assign the qualification\n    click.echo(\n        \"Assigning qualification {} with value {} to worker {}\".format(\n            qualification,\n            value,\n            worker))\n\n    if worker in workers:\n        result = conn.update_qualification_score(qualification, worker, value)\n    else:\n        result = conn.assign_qualification(qualification, worker, value)\n\n    if result:\n        click.echo(result)\n\n    # print out the current set of workers with the qualification\n    results = get_workers_with_qualification(qualification)\n\n    click.echo(\"{} workers with qualification {}:\".format(\n        len(results),\n        qualification))\n\n    values = [r.IntegerValue for r in results]\n    unique_values = list(set([r.IntegerValue for r in results]))\n    for v in unique_values:\n        click.echo(\"{} with value {}\".format(\n            len([val for val in values if val == v]),\n            v))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_database(id):\n    log(\"Generating a backup of the database on Heroku...\")\n\n    dump_filename = \"data.dump\"\n    data_directory = \"data\"\n    dump_dir = os.path.join(data_directory, id)\n    if not os.path.exists(dump_dir):\n        os.makedirs(dump_dir)\n\n    subprocess.call(\"heroku pg:backups capture --app \" + id, shell=True)\n\n    backup_url = subprocess.check_output(\n        \"heroku pg:backups public-url --app \" + id, shell=True)\n    backup_url = backup_url.replace('\"', '').rstrip()\n    backup_url = re.search(\"https:.*\", backup_url).group(0)\n    print(backup_url)\n\n    log(\"Downloading the backup...\")\n    dump_path = os.path.join(dump_dir, dump_filename)\n    with open(dump_path, 'wb') as file:\n        subprocess.call(['curl', '-o', dump_path, backup_url], stdout=file)\n\n    return dump_path", "response": "Backup the Postgres database locally."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npauses an experiment and remove costly resources.", "response": "def hibernate(app):\n    \"\"\"Pause an experiment and remove costly resources.\"\"\"\n    backup(app)\n\n    log(\"Scaling down the web servers...\")\n    subprocess.call(\"heroku ps:scale web=0\" + \" --app \" + app, shell=True)\n    subprocess.call(\"heroku ps:scale worker=0\" + \" --app \" + app, shell=True)\n    subprocess.call(\"heroku ps:scale clock=0\" + \" --app \" + app, shell=True)\n\n    log(\"Removing addons...\")\n    addons = [\n        \"heroku-postgresql\",\n        # \"papertrail\",\n        \"rediscloud\",\n    ]\n    for addon in addons:\n        subprocess.call(\n            \"heroku addons:destroy {} --app {} --confirm {}\".format(\n                addon,\n                app,\n                app\n            ),\n            shell=True,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrestoring the database from a given url.", "response": "def awaken(app, databaseurl):\n    \"\"\"Restore the database from a given url.\"\"\"\n    config = PsiturkConfig()\n    config.load_config()\n\n    database_size = config.get('Database Parameters', 'database_size')\n\n    subprocess.call(\n        \"heroku addons:create heroku-postgresql:{} --app {}\".format(\n            database_size,\n            app),\n        shell=True)\n\n    subprocess.call(\"heroku pg:wait --app {}\".format(app), shell=True)\n\n    conn = boto.connect_s3(\n        config.get('AWS Access', 'aws_access_key_id'),\n        config.get('AWS Access', 'aws_secret_access_key'),\n    )\n\n    bucket = conn.get_bucket(app)\n    key = bucket.lookup('database.dump')\n    url = key.generate_url(expires_in=300)\n\n    cmd = \"heroku pg:backups restore\"\n    subprocess.call(\n        \"{} '{}' DATABASE_URL --app {} --confirm {}\".format(\n            cmd,\n            url,\n            app,\n            app),\n        shell=True)\n\n    subprocess.call(\n        \"heroku addons:create rediscloud:250 --app {}\".format(app),\n        shell=True)\n\n    # Scale up the dynos.\n    scale_up_dynos(app)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a copy of the given example.", "response": "def create(example):\n    \"\"\"Create a copy of the given example.\"\"\"\n    try:\n        this_dir = os.path.dirname(os.path.realpath(__file__))\n        example_dir = os.path.join(this_dir, os.pardir, \"examples\", example)\n        shutil.copytree(example_dir, os.path.join(os.getcwd(), example))\n        log(\"Example created.\", delay=0)\n    except TypeError:\n        click.echo(\"Example '{}' does not exist.\".format(example))\n    except OSError:\n        click.echo(\"Example '{}' already exists here.\".format(example))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the package has a config file and a valid experiment file.", "response": "def verify_package(verbose=True):\n    \"\"\"Ensure the package has a config file and a valid experiment file.\"\"\"\n    is_passing = True\n\n    # Check the config file.\n    if os.path.exists(\"config.txt\"):\n        log(\"\u2713 config.txt is OK\",\n            delay=0, chevrons=False, verbose=verbose)\n    else:\n        log(\"\u2717 config.txt is MISSING\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n\n    # Check the experiment file.\n    if os.path.exists(\"experiment.py\"):\n\n        # Check if the experiment file has exactly one Experiment class.\n        tmp = tempfile.mkdtemp()\n        for f in [\"experiment.py\", \"config.txt\"]:\n            shutil.copyfile(f, os.path.join(tmp, f))\n\n        cwd = os.getcwd()\n        os.chdir(tmp)\n\n        open(\"__init__.py\", \"a\").close()\n        exp = imp.load_source('experiment', os.path.join(tmp, \"experiment.py\"))\n\n        classes = inspect.getmembers(exp, inspect.isclass)\n        exps = [c for c in classes\n                if (c[1].__bases__[0].__name__ in \"Experiment\")]\n\n        if len(exps) == 0:\n            log(\"\u2717 experiment.py does not define an experiment class.\",\n                delay=0, chevrons=False, verbose=verbose)\n            is_passing = False\n        elif len(exps) == 1:\n            log(\"\u2713 experiment.py is OK\",\n                delay=0, chevrons=False, verbose=verbose)\n        else:\n            log(\"\u2717 experiment.py defines more than one experiment class.\",\n                delay=0, chevrons=False, verbose=verbose)\n        os.chdir(cwd)\n\n    else:\n        log(\"\u2717 experiment.py is MISSING\",\n            delay=0, chevrons=False, verbose=verbose)\n        is_passing = False\n\n    # Make sure there's a help file.\n    is_txt_readme = os.path.exists(\"README.md\")\n    is_md_readme = os.path.exists(\"README.txt\")\n    if (not is_md_readme) and (not is_txt_readme):\n        is_passing = False\n        log(\"\u2717 README.txt or README.md is MISSING.\",\n            delay=0, chevrons=False, verbose=verbose)\n    else:\n        log(\"\u2713 README is OK\",\n            delay=0, chevrons=False, verbose=verbose)\n\n    # Check front-end files do not exist\n    if os.path.exists(\"templates/complete.html\"):\n        log(\"\u2717 templates/complete.html will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"templates/error_wallace.html\"):\n        log(\"\u2717 templates/error_wallace.html will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"templates/launch.html\"):\n        log(\"\u2717 templates/launch.html will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"static/css/wallace.css\"):\n        log(\"\u2717 static/css/wallace.css will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"static/scripts/wallace.js\"):\n        log(\"\u2717 static/scripts/wallace.js will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"static/scripts/reqwest.min.js\"):\n        log(\"\u2717 static/scripts/reqwest.min.js will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    elif os.path.exists(\"static/robots.txt\"):\n        log(\"\u2717 static/robots.txt will CONFLICT with shared front-end files inserted at run-time, please delete or rename.\",\n            delay=0, chevrons=False, verbose=verbose)\n        return False\n    else:\n        log(\"\u2713 no file conflicts\",\n            delay=0, chevrons=False, verbose=verbose)\n\n    return is_passing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_last_period(last):\n    \n    wordmap = {\n        'hour': '1h',\n        'day': '1d',\n        'week': '1w',\n        'month': '1m'\n    }\n\n    # seconds\n    multmap = {\n        'h': 3600,\n        'd': 86400,\n        'w': 604800,\n        'm': 2592000\n    }\n\n    if last in wordmap:\n        last = wordmap[last]\n\n    cat = last[-1:].lower()\n\n    if cat not in multmap:\n        raise TypeError\n\n    try: \n        num = int(last[:-1])\n        if num <= 0:\n            raise TypeError\n    except ValueError: \n        raise TypeError\n    \n    diff = num * multmap[cat]    \n    return diff", "response": "Parse the last value and return the time difference in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_datetime_interval(timestamp, diff, offset=0):\n    fin_datetime = datetime.datetime.fromtimestamp(timestamp + offset)\n    ini_datetime = datetime.datetime.fromtimestamp(timestamp - diff)\n    return ini_datetime, fin_datetime", "response": "Returns datetime interval from timestamp backward in the past"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the date parameter and return a couple of datetime object.", "response": "def parse_date_period(date):\n    \"\"\"\n    Parse the --date value and return a couple of datetime object.\n    The format is [YYYY]MMDD[,[YYYY]MMDD].\n    \"\"\"\n    import datetime\n    \n    now = datetime.datetime.today()\n    date_len = len(date)\n    \n    if date_len == 4:\n        date1 = str(now.year) + date\n        date2 = str(now.year) + date + \"235959\"\n    elif date_len == 8:\n        date1 = date\n        date2 = date + \"235959\"\n    elif date_len == 9:\n        if date[4] != ',':\n            raise TypeError\n        date1 = str(now.year) + date[0:4]\n        date2 = str(now.year) + date[5:9] + \"235959\"\n    elif date_len == 17:\n        if date[8] != ',':\n            raise TypeError\n        date1 = date[0:8]\n        date2 = date[9:17] + \"235959\"\n    else:\n        raise TypeError\n\n    try:\n        date1 = datetime.datetime.strptime(date1, \"%Y%m%d\")\n    except ValueError:\n        if date_len < 9:\n            raise ValueError(\"Error of date value in --date parameter, use --date=[YYYY]MMDD\")\n        else:\n            raise ValueError(\"Error in the first date value in --date parameter, \"\n                             \"use --date=[YYYY]MMDD,[YYYY]MMDD\")\n    try:\n        date2 = datetime.datetime.strptime(date2, \"%Y%m%d%H%M%S\")        \n    except ValueError:\n        raise ValueError(\"Error in the second date value in --date parameter, \"\n                         \"use --date=[YYYY]MMDD,[YYYY]MMDD\")\n        \n    if date1 > date2:\n        raise ValueError(\"Wrong parameter --date: the first date is after the second!\")\n\n    return date1, date2"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef strftimegen(start_dt, end_dt):\n    if start_dt > end_dt:\n        raise ValueError(\"the start datetime is after the end datetime: (%r,%r)\" % (start_dt, end_dt))\n\n    def iterftime(string):\n        date_subs = [i for i in DATE_FORMATS if i[1].search(string) is not None]\n        if not date_subs:\n            yield string\n        else:\n            dt = start_dt\n            date_path = string\n            while end_dt >= dt:\n                for item in date_subs:\n                    date_path = item[1].sub(dt.strftime(item[0]), date_path)\n                yield date_path\n                dt = dt + datetime.timedelta(days=1)\n\n    return iterftime", "response": "Return a generator function for datetime format strings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef between(self, time_):\n        hour = int(time_[0:2])\n        minute = int(time_[3:5])\n        return not (\n            hour < self.h1 or hour > self.h2 or\n            (hour == self.h1 and minute < self.m1) or\n            (hour == self.h2 and minute > self.m2)\n        )", "response": "Compare if the parameter HH : MM is in the time range."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sequences(options, fasta_file_contents):\n    ''' This function returns a dict mapping (pdbid, chain, file_name) tuples to sequences:\n          - options is the OptionParser member;\n          - fasta_file_contents is a map from input filenames to the associated FASTA file contents.\n    '''\n    errors = []\n    fasta_files_str = \", \".join(fasta_file_contents.keys())\n    fasta_records = None\n    reverse_mapping = {}\n\n    try:\n        fasta_records, reverse_mapping = parse_FASTA_files(options, fasta_file_contents)\n        if not fasta_records:\n            errors.append(\"No protein sequences found in the FASTA file(s) %s.\" % fasta_files_str)\n    except Exception, e:\n        e = '\\n'.join([l for l in traceback.format_exc(), str('e') if l.strip()])\n        errors.append(\"Error parsing FASTA file(s) %s:\\n%s\" % (fasta_files_str, str(e)))\n\n    if not fasta_records:\n        return None, {}, errors\n\n    colorprinter.message('Found %d protein sequence(s).' % len(fasta_records))\n    return fasta_records, reverse_mapping, errors", "response": "This function returns a dict mapping PDBID chain file_name to sequence records."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_FASTA_files(options, fasta_file_contents):\n    ''' This function iterates through each filepath in fasta_file_contents and returns a dict mapping (pdbid, chain, file_name) tuples to sequences:\n          - options is the OptionParser member;\n          - fasta_file_contents is a map from input filenames to the associated FASTA file contents.\n    '''\n    records = {}\n    reverse_mapping = {}\n    original_segment_list = []\n    key_location = {}\n    sequenceLine = re.compile(\"^[A-Z]+\\n?$\")\n    sequence_offsets = {}\n\n    for fasta_file_name, tagged_fasta in sorted(fasta_file_contents.iteritems()):\n\n        # Check the tagged pair\n        fasta = tagged_fasta[0].strip().split('\\n')\n        file_type = tagged_fasta[1]\n        assert(file_type == 'PDB' or file_type == 'FASTA')\n        if not fasta:\n            raise Exception(\"Empty FASTA file.\")\n\n        first_line = [line for line in fasta if line.strip()][0]\n        if first_line[0] != '>':\n            raise Exception(\"The FASTA file %s is not formatted properly - the first non-blank line is not a description line (does not start with '>').\" % fasta_file_name)\n\n        key = None\n        line_count = 0\n        record_count = 0\n        file_keys = []\n        unique_keys = {}\n        for line in fasta:\n            line_count += 1\n            line = line.strip()\n            if line:\n                if line[0] == '>':\n                    record_count += 1\n                    tokens = [t.strip() for t in line[1:].split('|') if t.strip()]\n                    if len(tokens) < 2:\n                        raise Exception(\"The description line ('%s') of record %d of %s is invalid. It must contain both a protein description and a chain identifier, separated by a pipe ('|') symbol.\" % (line, record_count, fasta_file_name))\n                    if len(tokens[0]) < 4:\n                        raise Exception(\"The protein description in the description line ('%s') of record %d of %s is too short. It must be at least four characters long.\" % (line, record_count, fasta_file_name))\n                    if len(tokens[1]) != 1:\n                        raise Exception(\"The chain identifier in the description line ('%s') of record %d of %s is the wrong length. It must be exactky one character long.\" % (line, record_count, fasta_file_name))\n\n                    # Note: We store the PDB ID as lower-case so that the user does not have to worry about case-sensitivity here (we convert the user's PDB ID argument to lower-case as well)\n                    key = (tokens[0][0:4].lower(), tokens[1], fasta_file_name)\n                    sub_key = (key[0], key[1]) # this is the part of the key that we expect to be unique (the actual key)\n                    key_location[key] = fasta_file_name\n                    if sub_key in unique_keys:\n                        # todo: we include the fasta_file_name in the key - should we not be checking for uniqueness w.r.t. just tokens[0][0:4].lower() and tokens[1] i.e. omitting the fasta_file_name as part of the check for a more stringent check?\n                        raise Exception(\"Duplicate protein/chain identifier pair. The key %s was generated from both %s and %s. Remember that the first four characters of the protein description are concatenated with the chain letter to generate a 5-character ID which must be unique.\" % (key, key_location[key], fasta_file_name))\n                    records[key] = [line]\n                    unique_keys[sub_key] = True\n                    file_keys.append(key)\n                else:\n                    mtchs = sequenceLine.match(line)\n                    if not mtchs:\n                        raise FastaException(\"Expected a record header or sequence line at line %d.\" % line_count)\n                    records[key].append(line)\n\n        offset = 0\n        if file_type == 'PDB':\n            for key in file_keys:\n                sequence_length = len(''.join(records[key][1:]))\n                sequence_offsets[key[0] + key[1]] = (offset, offset + 1, offset + sequence_length) # storing the sequence start and end residue IDs here is redundant but simplifies code later on\n                offset += sequence_length\n\n    # We remove non-protein chains from fragment generation although we did consider them above when determining the offsets\n    # as we expect them to be used in predictions\n    non_protein_records = []\n    set_of_rna_dna_codes = set(('A', 'C', 'G', 'T', 'U', 'X', 'Z'))\n    for key, content_lines in records.iteritems():\n        mm_sequence = ''.join(content_lines[1:])\n        assert(re.match('^[A-Z]+$', mm_sequence)) # Allow X or Z because these may exist (X from the RCSB, Z from our input files)\n        if set(mm_sequence).union(set_of_rna_dna_codes) == set_of_rna_dna_codes:\n            non_protein_records.append(key)\n    for non_protein_record in non_protein_records:\n        del records[non_protein_record]\n\n    # If a loops file was passed in, use that to cut up the sequences and concatenate these subsequences to generate a\n    # shorter sequence to process. This should save a lot of time when the total length of the subsequences is considerably\n    # shorter than the length of the total sequence e.g. in cases where the protein has @1000 residues but we only care about\n    # 100 residues in particular loop regions.\n\n    # We need to sample all sequences around a loop i.e. if a sequence segment is 7 residues long at positions 13-19 and we\n    # require 9-mers, we must consider the segment from positions 5-27 so that all possible 9-mers are considered.\n    residue_offset = max(options.frag_sizes)\n\n    if options.loops_file or options.indices:\n        loops_definition = None\n        if options.loops_file:\n            loops_definition = LoopsFile.from_filepath(options.loops_file, ignore_whitespace = True, ignore_errors = False)\n\n        # If the user supplied more ranges of residues, use those as well\n        if options.indices:\n            if not loops_definition:\n                loops_definition = LoopsFile('')\n            for p in options.indices:\n                if loops_definition:\n                    loops_definition.add(p[0], p[1])\n\n        segment_list = loops_definition.get_distinct_segments(residue_offset, residue_offset)\n        original_segment_list = loops_definition.get_distinct_segments(1, 1) # We are looking for 1-mers so the offset is 1 rather than 0\n\n        # Sanity checks\n        assert(sorted(segment_list) == segment_list) # sanity check\n        for x in range(len(segment_list)):\n            segment = segment_list[x]\n            if x < len(segment_list) - 1:\n                assert(segment[1] < segment_list[x+1][0]) # sanity check\n\n        # Create the generic reverse_mapping from the indices in the sequences defined by the segment_list to the indices in the original sequences.\n        # This will be used in FASTA sequences to rewrite the fragments files to make them compatible with the original sequences.\n        # Note that this mapping ignores the length of the sequences (which may vary in length) so it may be mapping residues indices\n        # which are outside of the length of some of the sequences.\n        # Create a sorted list of residues of the chain that we will be including in the sequence for fragment generation\n        # then turn that into a 1-indexed mapping from the order of the residue in the sequence to the original residue ID in the PDB\n        residues_for_generation = []\n        for s in segment_list:\n            residues_for_generation += range(s[0], s[1] + 1)\n        reverse_mapping['FASTA'] = dict((key, value) for (key, value) in zip(range(1, len(residues_for_generation) + 1), residues_for_generation))\n\n        # Create the reverse_mappings from the indices in the PDB sequences defined by the segment_list to the indices in the original sequences.\n        # Membership in sequence_offsets implies a PDB sequence.\n        for k, v in sorted(sequence_offsets.iteritems()):\n            # For each PDB chain, we consider the set of segments (ignoring extra residues due to nmerage for now so that\n            # we do not include chains by accident e.g. if the user specified the first residues of chain C but none in chain B,\n            # they probably do not wish to generate fragments for chain B)\n            chain_residues = range(v[1], v[2] + 1)\n            residues_for_generation = []\n            for s in original_segment_list:\n                # If the original segment lists lie inside the chain residues then we extend the range w.r.t. the nmers\n                if (chain_residues[0] <= s[0] <= chain_residues[-1]) or (chain_residues[0] <= s[1] <= chain_residues[-1]):\n                    residues_for_generation += range(s[0] - residue_offset + 1, s[1] + residue_offset - 1 + 1)\n\n            # Create a sorted list of residues of the chain that we will be including in the sequence for fragment generation\n            # then turn that into a 1-indexed mapping from the order of the residue in the sequence to the original residue ID in the PDB\n            chain_residues_for_generation = sorted(set(chain_residues).intersection(set(residues_for_generation)))\n            reverse_mapping[k] = dict((key, value) for (key, value) in zip(range(1, len(chain_residues_for_generation) + 1), chain_residues_for_generation))\n\n        found_at_least_one_sequence = False\n        for k, v in sorted(records.iteritems()):\n            assert(v[0].startswith('>'))\n            subkey = k[0] + k[1]\n            sequence = ''.join([s.strip() for s in v[1:]])\n            assert(sequenceLine.match(sequence) != None) # sanity check\n            cropped_sequence = None\n            if sequence_offsets.get(subkey):\n                # PDB chain case\n                first_residue_id = sequence_offsets[subkey][1]\n                cropped_sequence = ''.join([sequence[rmv - first_residue_id] for rmk, rmv in sorted(reverse_mapping[subkey].iteritems())])\n                # Sanity check - check that the remapping from the cropped sequence to the original sequence will work in postprocessing\n                for x in range(0, len(cropped_sequence)):\n                    assert(cropped_sequence[x] == sequence[reverse_mapping[subkey][x + 1] - sequence_offsets[subkey][0] - 1])\n                records[k] = [v[0]] + [cropped_sequence[i:i+60] for i in range(0, len(cropped_sequence), 60)] # update the record to only use the truncated sequence\n            else:\n                # FASTA chain case\n                cropped_sequence = ''.join([sequence[rmv - 1] for rmk, rmv in sorted(reverse_mapping['FASTA'].iteritems()) if rmv <= len(sequence)])\n                # Sanity check - check that the remapping from the cropped sequence to the original sequence will work in postprocessing\n                for x in range(0, len(cropped_sequence)):\n                    assert(cropped_sequence[x] == sequence[reverse_mapping['FASTA'][x + 1] - 1])\n\n            found_at_least_one_sequence = found_at_least_one_sequence or (not not cropped_sequence)\n            if cropped_sequence:\n                records[k] = [v[0]] + [cropped_sequence[i:i+60] for i in range(0, len(cropped_sequence), 60)]\n            else:\n                del records[k] # delete the chain. todo: test that this works\n\n        if not found_at_least_one_sequence:\n            raise Exception('No sequences were created from the loops/indices and the input sequences. This may be an input error so the job is being terminated.')\n\n    if reverse_mapping:\n        return records, dict(reverse_mapping = reverse_mapping, segment_list = original_segment_list, sequence_offsets = sequence_offsets)\n    else:\n        return records, None", "response": "This function parses the FASTA files and returns a dictionary mapping from PDB IDs to sequences."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reformat(found_sequences):\n    '''Truncate the FASTA headers so that the first field is a 4-character ID.'''\n    for (pdb_id, chain, file_name), sequence in sorted(found_sequences.iteritems()):\n        header = sequence[0]\n        assert(header[0] == '>')\n        tokens = header.split('|')\n        tokens[0] = tokens[0][:5]\n        assert(len(tokens[0]) == 5)\n        sequence[0] = \"|\".join(tokens)", "response": "Truncate the FASTA headers so that the first field is a 4 - character ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_local_ip_address(target):\n    ip_adr = ''\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.connect((target, 8000))\n        ip_adr = s.getsockname()[0]\n        s.close()\n    except:\n        pass\n\n    return ip_adr", "response": "Get the local ip address to access one specific target."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(self):\n        try:\n            self.sock.connect((self.host, self.port))\n            return self.sock\n        except socket.error as ex:\n            logging.error('Exception while connecting socket on %s:%s - Error %s' % (self.host, self.port, ex))\n            raise\n        except Exception as ex:\n            logging.exception('Exception while connecting socket on %s:%s - Error %s' % (self.host, self.port, ex))\n            raise", "response": "Connect to server and return the server s ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending data by packet on socket.", "response": "def send_by_packet(self, data):\n        \"\"\"\n        Send data by packet on socket\n        \"\"\"\n        total_sent = 0\n        while total_sent < PACKET_SIZE:\n            sent = self.sock.send(data[total_sent:])\n            if sent == 0:\n                raise RuntimeError(\"socket connection broken\")\n            total_sent += sent\n        return total_sent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive(self, siz):\n        result = bytearray()\n        data = 'x'\n        while len(data) > 0:\n            data = self.sock.recv(siz - len(result))\n            result += data\n            if len(result) == siz:\n                return result\n            if len(result) > siz:\n                raise Exception('Received more bytes than expected')\n        raise Exception('Error receiving data. %d bytes received'%len(result))", "response": "Receive a known length of bytes from a socket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nspawning a new environment in a given address as a coroutine.", "response": "def spawn_container(addr, env_cls=Environment,\n                    mgr_cls=EnvManager, set_seed=True, *args, **kwargs):\n    \"\"\"Spawn a new environment in a given address as a coroutine.\n\n    Arguments and keyword arguments are passed down to the created environment\n    at initialization time.\n\n    If `setproctitle <https://pypi.python.org/pypi/setproctitle>`_ is\n    installed, this function renames the title of the process to start with\n    'creamas' so that the process is easily identifiable, e.g. with\n    ``ps -x | grep creamas``.\n    \"\"\"\n    # Try setting the process name to easily recognize the spawned\n    # environments with 'ps -x' or 'top'\n    try:\n        import setproctitle as spt\n        title = 'creamas: {}({})'.format(env_cls.__class__.__name__,\n                                         _get_base_url(addr))\n        spt.setproctitle(title)\n    except:\n        pass\n\n    if set_seed:\n        _set_random_seeds()\n\n    # kwargs['codec'] = aiomas.MsgPack\n    task = start(addr, env_cls, mgr_cls, *args, **kwargs)\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n    loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spawn_containers(addrs, env_cls=Environment,\n                     env_params=None,\n                     mgr_cls=EnvManager, *args, **kwargs):\n    \"\"\"Spawn environments in a multiprocessing :class:`multiprocessing.Pool`.\n\n    Arguments and keyword arguments are passed down to the created environments\n    at initialization time if *env_params* is None. If *env_params* is not\n    None, then it is assumed to contain individual initialization parameters\n    for each environment in *addrs*.\n\n    :param addrs:\n        List of (HOST, PORT) addresses for the environments.\n\n    :param env_cls:\n        Callable for the environments. Must be a subclass of\n        :py:class:`~creamas.core.environment.Environment`.\n\n    :param env_params: Initialization parameters for the environments.\n    :type env_params: Iterable of same length as *addrs* or None.\n\n    :param mgr_cls:\n        Callable for the managers. Must be a subclass of\n        :py:class:`~creamas.mp.EnvManager`.s\n\n    :returns:\n        The created process pool and the *ApplyAsync* results for the spawned\n        environments.\n    \"\"\"\n    pool = multiprocessing.Pool(len(addrs))\n    kwargs['env_cls'] = env_cls\n    kwargs['mgr_cls'] = mgr_cls\n    r = []\n    for i, addr in enumerate(addrs):\n        if env_params is not None:\n            k = env_params[i]\n            k['env_cls'] = env_cls\n            k['mgr_cls'] = mgr_cls\n        # Copy kwargs so that we can apply different address to different\n        # containers.\n        else:\n            k = kwargs.copy()\n        k['addr'] = addr\n        ret = pool.apply_async(spawn_container,\n                               args=args,\n                               kwds=k,\n                               error_callback=logger.warning)\n        r.append(ret)\n    return pool, r", "response": "Spawn environments in a multiprocessing. Pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def start(addr, env_cls, mgr_cls, *env_args, **env_kwargs):\n    env_kwargs.update(as_coro=True)\n    log_folder = env_kwargs.get('log_folder', None)\n    env = await env_cls.create(addr, *env_args, **env_kwargs)\n    try:\n        manager = mgr_cls(env)\n        env.manager = manager\n        await manager.stop_received\n    except KeyboardInterrupt:\n        logger.info('Execution interrupted by user')\n    finally:\n        await env.destroy(folder=log_folder, as_coro=True)", "response": "Coroutine that starts an environment with the given manager agent."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset new random seeds for the process.", "response": "def _set_random_seeds():\n    \"\"\"Set new random seeds for the process.\n    \"\"\"\n    try:\n        import numpy as np\n        np.random.seed()\n    except:\n        pass\n\n    try:\n        import scipy as sp\n        sp.random.seed()\n    except:\n        pass\n\n    import random\n    random.seed()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def report(self, msg, timeout=5):\n        try:\n            host_manager = await self.env.connect(self.host_manager,\n                                                  timeout=timeout)\n        except:\n            raise ConnectionError(\"Could not reach host manager ({}).\"\n                                  .format(self.host_manager))\n        ret = await host_manager.handle(msg)\n        return ret", "response": "Report a message to the host manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget agents from the environment.", "response": "def get_agents(self, addr=True, agent_cls=None, as_coro=False):\n        \"\"\"Get agents from the managed environment.\n\n        This is a managing function for the\n        :py:meth:`~creamas.environment.Environment.get_agents`. Returned\n        agent list excludes the environment's manager agent (this agent) by\n        design.\n        \"\"\"\n        return self.env.get_agents(addr=addr, agent_cls=agent_cls)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_artifacts(self):\n        host_manager = await self.env.connect(self._host_manager,\n                                              timeout=TIMEOUT)\n        artifacts = await host_manager.get_artifacts()\n        return artifacts", "response": "Get all the artifacts from the host environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def spawn(self, agent_cls, *args, addr=None, **kwargs):\n        _, addr = await self.menv.spawn(agent_cls, *args, addr=addr, **kwargs)\n        return addr", "response": "Spawn an agent to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns agents with same initialization parameters.", "response": "async def spawn_n(self, agent_cls, n, *args, addr=None, **kwargs):\n        \"\"\"Same as :meth:`~creamas.mp.MultiEnvManager.spawn`, but spawn\n        :attr:`n` agents with same initialization parameters.\n\n        This is a managing function for\n        :meth:`~creamas.mp.MultiEnvironment.spawn_n`.\n\n        .. note::\n\n            Since :class:`aiomas.rpc.Proxy` objects do not seem to handle\n            (re)serialization, only the addresses of the spawned agents are\n            returned.\n        \"\"\"\n        ret = await self.menv.spawn_n(agent_cls, n, *args, addr=addr, **kwargs)\n        return [r[1] for r in ret]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all agents in all the slave environments.", "response": "async def get_agents(self, addr=True, agent_cls=None):\n        \"\"\"Get addresses of all agents in all the slave environments.\n\n        This is a managing function for\n        :meth:`creamas.mp.MultiEnvironment.get_agents`.\n\n        .. note::\n\n            Since :class:`aiomas.rpc.Proxy` objects do not seem to handle\n            (re)serialization, ``addr`` and ``agent_cls`` parameters are\n            omitted from the call to underlying multi-environment's\n            :meth:`get_agents`.\n\n            If :class:`aiomas.rpc.Proxy` objects from all the agents are\n            needed, call each slave environment manager's :meth:`get_agents`\n            directly.\n        \"\"\"\n        return await self.menv.get_agents(addr=True, agent_cls=None,\n                                          as_coro=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_connections(self, data=True):\n        return await self.menv.get_connections(data=data, as_coro=True)", "response": "Return all the agents in the slave environments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets this manager as a host manager for the manager in addr.", "response": "async def set_as_host_manager(self, addr, timeout=5):\n        \"\"\"Set the this manager as a host manager for the manager in *addr*.\n\n        This is a managing function for\n        :py:meth:`~creamas.mp.MultiEnvironment.set_host_manager`.\n        \"\"\"\n        return await self.menv.set_host_manager(addr, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_agents(self, addr=True, agent_cls=None, as_coro=False):\n        async def slave_task(mgr_addr, addr=True, agent_cls=None):\n            r_manager = await self.env.connect(mgr_addr, timeout=TIMEOUT)\n            return await r_manager.get_agents(addr=addr, agent_cls=agent_cls)\n\n        tasks = create_tasks(slave_task, self.addrs, addr, agent_cls)\n        return run_or_coro(tasks, as_coro)", "response": "Get agents from the slave environments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def is_ready(self):\n        async def slave_task(addr, timeout):\n            try:\n                r_manager = await self.env.connect(addr, timeout=timeout)\n                ready = await r_manager.is_ready()\n                if not ready:\n                    return False\n            except:\n                return False\n            return True\n\n        if not self.env.is_ready():\n            return False\n        if not self.check_ready():\n            return False\n        rets = await create_tasks(slave_task, self.addrs, 0.5)\n        if not all(rets):\n            return False\n        return True", "response": "Check if the multi - environment is fully initialized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def spawn_slaves(self, slave_addrs, slave_env_cls, slave_mgr_cls,\n                           slave_kwargs=None):\n        \"\"\"Spawn slave environments.\n\n        :param slave_addrs:\n            List of (HOST, PORT) addresses for the slave-environments.\n\n        :param slave_env_cls: Class for the slave environments.\n\n        :param slave_kwargs:\n            If not None, must be a list of the same size as *addrs*. Each item\n            in the list containing parameter values for one slave environment.\n\n        :param slave_mgr_cls:\n            Class of the slave environment managers.\n        \"\"\"\n        pool, r = spawn_containers(slave_addrs, env_cls=slave_env_cls,\n                                   env_params=slave_kwargs,\n                                   mgr_cls=slave_mgr_cls)\n        self._pool = pool\n        self._r = r\n        self._manager_addrs = [\"{}{}\".format(_get_base_url(a), 0) for\n                               a in slave_addrs]", "response": "Spawn all the slaves."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting until all slaves are online.", "response": "async def wait_slaves(self, timeout, check_ready=False):\n        \"\"\"Wait until all slaves are online (their managers accept connections)\n        or timeout expires.\n\n        :param int timeout:\n            Timeout (in seconds) after which the method will return even though\n            all the slaves are not online yet.\n\n        :param bool check_ready:\n            If ``True`` also checks if all slave environment's are ready.\n            A slave environment is assumed to be ready when its manager's\n            :meth:`is_ready`-method returns ``True``.\n\n        .. seealso::\n\n            :meth:`creamas.core.environment.Environment.is_ready`,\n            :meth:`creamas.mp.EnvManager.is_ready`,\n            :meth:`creamas.mp.MultiEnvManager.is_ready`\n\n        \"\"\"\n        status = 'ready' if check_ready else 'online'\n        self._log(logging.DEBUG,\n                  \"Waiting for slaves to become {}...\".format(status))\n        t = time.monotonic()\n        online = []\n        while len(online) < len(self.addrs):\n            for addr in self.addrs:\n                if time.monotonic() - t > timeout:\n                    self._log(logging.DEBUG, \"Timeout while waiting for the \"\n                              \"slaves to become {}.\".format(status))\n                    return False\n                if addr not in online:\n                    try:\n                        r_manager = await self.env.connect(addr, timeout)\n                        ready = True\n                        if check_ready:\n                            ready = await r_manager.is_ready()\n                        if ready:\n                            online.append(addr)\n                            self._log(logging.DEBUG, \"Slave {}/{} {}: {}\"\n                                      .format(len(online),\n                                              len(self.addrs),\n                                              status,\n                                              addr))\n                    except:\n                        pass\n            asyncio.sleep(0.5)\n        self._log(logging.DEBUG, \"All slaves {} in {} seconds!\"\n                  .format(status, time.monotonic() - t))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset this multi - environment s manager as the host manager for the manager agent in addr", "response": "async def set_host_manager(self, addr, timeout=TIMEOUT):\n        \"\"\"Set this multi-environment's manager as the host manager for\n        a manager agent in *addr*\n        \"\"\"\n        r_manager = await self.env.connect(addr, timeout=timeout)\n        return await r_manager.set_host_manager(self.manager.addr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntriggering an agent in addr to act.", "response": "async def trigger_act(self, addr):\n        \"\"\"Trigger agent in :attr:`addr` to act.\n\n        This method is quite inefficient if used repeatedly for a large number\n        of agents.\n\n        .. seealso::\n\n            :py:meth:`creamas.mp.MultiEnvironment.trigger_all`\n        \"\"\"\n        r_agent = await self.env.connect(addr, timeout=TIMEOUT)\n        return await r_agent.act()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def trigger_all(self, *args, **kwargs):\n        async def slave_task(addr, *args, **kwargs):\n            r_manager = await self.env.connect(addr, timeout=TIMEOUT)\n            return await r_manager.trigger_all(*args, **kwargs)\n\n        return await create_tasks(slave_task, self.addrs, *args, **kwargs)", "response": "Trigger all agents in all the slave environments to act asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _get_smallest_env(self):\n        async def slave_task(mgr_addr):\n            r_manager = await self.env.connect(mgr_addr, timeout=TIMEOUT)\n            ret = await r_manager.get_agents(addr=True)\n            return mgr_addr, len(ret)\n\n        sizes = await create_tasks(slave_task, self.addrs, flatten=False)\n        return sorted(sizes, key=lambda x: x[1])[0][0]", "response": "Get the address of the slave environment manager with the smallest\n        number of agents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nspawn a new agent in a slave environment.", "response": "async def spawn(self, agent_cls, *args, addr=None, **kwargs):\n        \"\"\"Spawn a new agent in a slave environment.\n\n        :param str agent_cls:\n            `qualname`` of the agent class.\n            That is, the name should be in the form ``pkg.mod:cls``, e.g.\n            ``creamas.core.agent:CreativeAgent``.\n        :param str addr:\n            Optional. Address for the slave enviroment's manager.\n            If :attr:`addr` is None, spawns the agent in the slave environment\n            with currently smallest number of agents.\n\n        :returns: :class:`aiomas.rpc.Proxy` and address for the created agent.\n\n        The ``*args`` and ``**kwargs`` are passed down to the agent's\n        :meth:`__init__`.\n\n        .. note::\n\n            Use :meth:`~creamas.mp.MultiEnvironment.spawn_n` to spawn large\n            number of agents with identical initialization parameters.\n        \"\"\"\n        if addr is None:\n            addr = await self._get_smallest_env()\n        r_manager = await self.env.connect(addr)\n        return await r_manager.spawn(agent_cls, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nspawns agents in the slave environment with the given agent class and number of agents.", "response": "async def spawn_n(self, agent_cls, n, *args, addr=None, **kwargs):\n        \"\"\"Same as :meth:`~creamas.mp.MultiEnvironment.spawn`, but allows\n        spawning multiple agents with the same initialization parameters\n        simultaneously into **one** slave environment.\n\n        :param str agent_cls:\n            ``qualname`` of the agent class. That is, the name should be in the\n            form of ``pkg.mod:cls``, e.g. ``creamas.core.agent:CreativeAgent``.\n        :param int n: Number of agents to spawn\n        :param str addr:\n            Optional. Address for the slave enviroment's manager.\n            If :attr:`addr` is None, spawns the agents in the slave environment\n            with currently smallest number of agents.\n\n        :returns:\n            A list of (:class:`aiomas.rpc.Proxy`, address)-tuples for the\n            spawned agents.\n\n        The ``*args`` and ``**kwargs`` are passed down to each agent's\n        :meth:`__init__`.\n        \"\"\"\n        if addr is None:\n            addr = await self._get_smallest_env()\n        r_manager = await self.env.connect(addr)\n        return await r_manager.spawn_n(agent_cls, n, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning connections from all the agents in the slave environments.", "response": "def get_connections(self, data=True, as_coro=False):\n        \"\"\"Return connections from all the agents in the slave environments.\n\n        :param bool data:\n            If ``True``, returns also the data stored for each connection.\n\n        :param bool as_coro:\n            If ``True`` returns a coroutine, otherwise runs the asynchronous\n            calls to the slave environment managers in the event loop.\n\n        .. seealso::\n\n            :meth:`creamas.core.environment.Environment.get_connections`\n        \"\"\"\n        async def slave_task(addr, data):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.get_connections(data)\n\n        tasks = create_tasks(slave_task, self.addrs, data)\n        return run_or_coro(tasks, as_coro)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_artifacts(self, agent_name=None):\n        if agent_name is not None:\n            return [a for a in self.artifacts if agent_name == a.creator]\n        return self.artifacts", "response": "Get all artifacts or all artifacts published by a specific agent."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def stop_slaves(self, timeout=1):\n        for addr in self.addrs:\n            try:\n                r_manager = await self.env.connect(addr, timeout=timeout)\n                await r_manager.stop()\n            except:\n                self._log(logging.WARNING, \"Could not stop {}\".format(addr))", "response": "Stop all the slaves by sending a stop - message to each manager."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndestroys the multiprocessing environment and its slave environments.", "response": "def destroy(self, folder=None, as_coro=False):\n        \"\"\"Destroy the multiprocessing environment and its slave environments.\n        \"\"\"\n        async def _destroy(folder):\n            ret = self.save_info(folder)\n            await self.stop_slaves()\n            # Terminate and join the process pool when we are destroyed.\n            # Do not wait for unfinished processed with pool.close(),\n            # the slaves should be anyway already stopped.\n            if self._pool is not None:\n                self._pool.terminate()\n                self._pool.join()\n            await self._env.shutdown(as_coro=True)\n            return ret\n\n        return run_or_coro(_destroy(folder), as_coro)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump the next child of a PID.", "response": "def dump_next(self, obj):\n        \"\"\"Dump the parent of a PID.\"\"\"\n        if self._is_child(obj) and not obj.is_last_child(self.context['pid']):\n            return self._dump_relative(obj.next_child(self.context['pid']))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump_previous(self, obj):\n        if self._is_child(obj) and obj.index(self.context['pid']) > 0:\n            return self._dump_relative(obj.previous_child(self.context['pid']))", "response": "Dump the previous child of a PID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump the index of the child in the relation.", "response": "def dump_index(self, obj):\n        \"\"\"Dump the index of the child in the relation.\"\"\"\n        if isinstance(obj, PIDNodeOrdered) and self._is_child(obj):\n            return obj.index(self.context['pid'])\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the boolean stating if the child in the relation is last.", "response": "def dump_is_last(self, obj):\n        \"\"\"Dump the boolean stating if the child in the relation is last.\n\n        Dumps `None` for parent serialization.\n        \"\"\"\n        if self._is_child(obj) and isinstance(obj, PIDNodeOrdered):\n            if obj.children.count() > 0:\n                return obj.children.ordered('asc').all()[-1] == \\\n                    self.context['pid']\n            elif obj.draft_child:\n                return obj.draft_child == self.context['pid']\n            else:\n                return True\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the text name of the relation.", "response": "def dump_type(self, obj):\n        \"\"\"Dump the text name of the relation.\"\"\"\n        if not isinstance(obj.relation_type, RelationType):\n            return resolve_relation_type_config(obj.relation_type).name\n        else:\n            return obj.relation_type.name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_parent(self, obj):\n        if not self._is_parent(obj):\n            return self._dump_relative(obj.pid)\n        return None", "response": "Dump the parent of a PID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the siblings of a PID.", "response": "def dump_children(self, obj):\n        \"\"\"Dump the siblings of a PID.\"\"\"\n        data, errors = PIDSchema(many=True).dump(\n            obj.children.ordered('asc').all())\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_dotenvs():\n    if not os.getenv('DOTENVS_LOADED'):\n        envs = ['.env', '.flaskenv']\n        for env in envs:\n            path = os.path.join(os.getcwd(), env)\n            if os.path.isfile(path):\n                dotenvs(path)\n        os.environ['DOTENVS_LOADED'] = 'yes'", "response": "Load dotenvs from project root directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nidentify the app associated with a window.", "response": "def identify_window(pid, text):\n    \"\"\"Identify the app associated with a window.\"\"\"\n    proc = None\n    path = None\n    uas = Session.query(UserApp).filter(UserApp.window_text == text)\n    nontext = Session.query(UserApp).filter(UserApp.window_text == None)\n    if uas.count():\n        proc = psutil.Process(pid)\n        try:\n            path = proc.exe()\n        except psutil.AccessDenied:\n            path = proc.name()\n        logger.debug(\"Trying to identify app, path=%s\", path)\n        app = uas.filter(UserApp.path == path).first()\n        if app:\n            return app, proc\n    if nontext.count():\n        if proc == None:\n            proc = psutil.Process(pid)\n            path = proc.exe()\n            app = nontext.filter(UserApp.path == path).first()\n            if app:\n                return app, proc\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _assertCALL(self, url, *, allow_empty=False, check_headers=True, check_status=True,\n                    expect_errors=False, name=None, method='get', data=None):\n        \"\"\"\n        check url for response changes\n\n        :param url: url to check\n        :param allow_empty: if True ignore empty response and 404 errors\n        :param check_headers: check response headers\n        :param check_status: check response status code\n        :raises: ValueError\n        :raises: AssertionError\n        \"\"\"\n        self.view = resolve(url).func.cls\n        m = getattr(self.client, method.lower())\n        self.filename = self.get_response_filename(method, name or url)\n        response = m(url, data=data)\n        assert response.accepted_renderer\n        payload = response.data\n        if not allow_empty and not payload:\n            raise ValueError(f\"View {self.view} returned and empty json. Check your test\")\n\n        if response.status_code > 299 and not expect_errors:\n            raise ValueError(f\"View {self.view} unexpected response. {response.status_code} - {response.content}\")\n\n        if not allow_empty and response.status_code == 404:\n            raise ValueError(f\"View {self.view} returned 404 status code. Check your test\")\n\n        if not os.path.exists(self.filename) or os.environ.get('API_CHECKER_RESET', False):\n            _write(self.filename, serialize_response(response))\n\n        stored = load_response(self.filename)\n        if (check_status) and response.status_code != stored.status_code:\n            raise StatusCodeError(self.view, response.status_code, stored.status_code)\n        if check_headers:\n            self._assert_headers(response, stored)\n        self.compare(payload, stored.data, self.filename, view=self.view)", "response": "Check that the response from the API is OK."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def reboot():\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = DeviceSettings(LOOP, session, IPADDRESS)\n        result = await ghlocalapi.reboot()\n\n        print(\"Reboot info:\", result)", "response": "Reboot a Google Home unit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd user and remote_addr to the record.", "response": "def filter(self, record):\n        \"\"\"\n        Adds user and remote_addr to the record.\n        \"\"\"\n        request = get_request()\n        if request:\n            user = getattr(request, 'user', None)\n            if user and not user.is_anonymous():\n                record.username = user.username\n            else:\n                record.username = '-'\n            meta = getattr(request, 'META', {})\n            record.remote_addr = meta.get('REMOTE_ADDR', '-')\n            record.http_user_agent = meta.get('HTTP_USER_AGENT', '-')\n            if not hasattr(record, 'request'):\n                record.request = request\n        else:\n            record.username = '-'\n            record.remote_addr = '-'\n            record.http_user_agent = '-'\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_agent(self):\n        if not self._user_agent:\n            session = requests.Session()\n            user_agent = session.headers['User-Agent']\n            self._user_agent = '%s %s' % (self.base_user_agent, user_agent)\n        return self._user_agent", "response": "Return a user - agent string para as requisi\u00e7\u00f5es feitas para o Postmon."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef status(self):\n        try:\n            r = self._response\n        except AttributeError:\n            return None\n        else:\n            return r.status_code, r.reason", "response": "Status da resposta recebida do Postmon."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npackages resources and templates for a multi - tier environment.", "response": "def package_theme(app_name, build_dir,\n                  excludes=None, includes=None, path_prefix=None,\n                  template_dirs=None):\n    \"\"\"\n    Package resources and templates for a multi-tier environment\n    into a zip file.\n\n    Templates are pre-compiled into ``*build_dir*/*app_name*/templates``.\n    Compilation means {% assets '*path*' %} and {% static '*path*' %} tags\n    are replaced by their compiled expression.\n    \"\"\"\n    #pylint:disable=too-many-locals,too-many-arguments\n    templates_dest = os.path.join(build_dir, 'templates')\n    # override STATIC_URL to prefix APP_NAME.\n    orig_static_url = django_settings.STATIC_URL\n    if (app_name != settings.APP_NAME\n        and not django_settings.STATIC_URL.startswith('/' + app_name)):\n        django_settings.STATIC_URL = '/' + app_name + orig_static_url\n    if not os.path.exists(templates_dest):\n        os.makedirs(templates_dest)\n    if template_dirs is None:\n        template_dirs = get_template_search_path(app_name)\n    for template_dir in template_dirs:\n        # The first of template_dirs usually contains the most specialized\n        # templates (ie. the ones we truely want to install).\n        if (templates_dest\n            and not os.path.samefile(template_dir, templates_dest)):\n            install_templates(template_dir, templates_dest,\n                excludes=excludes, includes=includes, path_prefix=path_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the theme package. zip from templates and optionally a theme package.", "response": "def fill_package(app_name, build_dir=None, install_dir=None):\n    \"\"\"\n    Creates the theme package (.zip) from templates and optionally\n    assets installed in the ``build_dir``.\n    \"\"\"\n    zip_path = os.path.join(install_dir, '%s.zip' % app_name)\n    with zipfile.ZipFile(zip_path, 'w') as zip_file:\n        fill_package_zip(zip_file, os.path.dirname(build_dir), prefix=app_name)\n    return zip_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_templates(srcroot, destroot, prefix='', excludes=None,\n                      includes=None, path_prefix=None):\n    #pylint:disable=too-many-arguments,too-many-statements\n    \"\"\"\n    Expand link to compiled assets all templates in *srcroot*\n    and its subdirectories.\n    \"\"\"\n    #pylint: disable=too-many-locals\n    if excludes is None:\n        excludes = []\n    if includes is None:\n        includes = []\n    if not os.path.exists(os.path.join(prefix, destroot)):\n        os.makedirs(os.path.join(prefix, destroot))\n    for pathname in os.listdir(os.path.join(srcroot, prefix)):\n        pathname = os.path.join(prefix, pathname)\n        excluded = False\n        for pat in excludes:\n            if re.match(pat, pathname):\n                excluded = True\n                break\n        if excluded:\n            for pat in includes:\n                if re.match(pat, pathname):\n                    excluded = False\n                    break\n        if excluded:\n            LOGGER.debug(\"skip %s\", pathname)\n            continue\n        source_name = os.path.join(srcroot, pathname)\n        dest_name = os.path.join(destroot, pathname)\n        if os.path.isfile(source_name) and not os.path.exists(dest_name):\n            # We don't want to overwrite specific theme files by generic ones.\n            with open(source_name) as source:\n                template_string = source.read()\n            try:\n                template_string = force_text(template_string)\n                lexer = DebugLexer(template_string)\n                tokens = lexer.tokenize()\n                if not os.path.isdir(os.path.dirname(dest_name)):\n                    os.makedirs(os.path.dirname(dest_name))\n                engine, libraries, builtins = get_html_engine()\n                if isinstance(engine, DjangoTemplates):\n                    with open(dest_name, 'w') as dest:\n                        parser = AssetsParser(tokens,\n                            URLRewriteWrapper(dest, path_prefix),\n                            libraries=libraries,\n                            builtins=builtins,\n                            origin=None)\n                        parser.parse_through()\n                else:\n                    template_name = None\n                    tokens = Lexer(engine.env).tokeniter(template_string,\n                        template_name, filename=source_name)\n                    buffered_tokens = []\n                    state = None\n                    with open(dest_name, 'w') as dest:\n                        for token in tokens:\n                            if state is None:\n                                if token[1] == 'block_begin':\n                                    state = STATE_BLOCK_BEGIN\n                            elif state == STATE_BLOCK_BEGIN:\n                                if token[1] == 'name':\n                                    if token[2] == 'assets':\n                                        state = STATE_ASSETS_BEGIN\n                                    else:\n                                        buffered_tokens += [token]\n                                        state = None\n                            elif state == STATE_ASSETS_BEGIN:\n                                if (token[1] == 'name'\n                                    and token[2] == 'endassets'):\n                                    state = STATE_ASSETS_END\n                            elif state == STATE_ASSETS_END:\n                                if token[1] == 'block_end':\n                                    buffered_tokens += [token]\n                                    state = None\n                            if state is None:\n                                if buffered_tokens:\n                                    for tok in buffered_tokens:\n                                        if (tok[1] == 'name' and\n                                            tok[2] == 'assets'):\n                                            dest.write(_render_assets(\n                                                buffered_tokens,\n                                                engine.env.assets_environment))\n                                            buffered_tokens = []\n                                            break\n                                    if buffered_tokens:\n                                        dest.write(\"%s\" % ''.join([token[2]\n                                            for token in buffered_tokens]))\n                                    buffered_tokens = []\n                                else:\n                                    dest.write(\"%s\" % str(token[2]))\n                            else:\n                                buffered_tokens += [token]\n                        if buffered_tokens:\n                            dest.write(\"%s\" % ''.join([\n                                token[2] for token in buffered_tokens]))\n                            buffered_tokens = []\n                        dest.write(\"\\n\")\n\n                cmdline = ['diff', '-u', source_name, dest_name]\n                cmd = subprocess.Popen(cmdline, stdout=subprocess.PIPE)\n                lines = cmd.stdout.readlines()\n                cmd.wait()\n                # Non-zero error codes are ok here. That's how diff\n                # indicates the files are different.\n                if lines:\n                    verb = 'compile'\n                else:\n                    verb = 'install'\n                dest_multitier_name = dest_name.replace(destroot,\n                        '*MULTITIER_TEMPLATES_ROOT*')\n                LOGGER.debug(\"%s %s to %s\", verb,\n                    source_name.replace(\n                        django_settings.BASE_DIR, '*APP_ROOT*'),\n                    dest_multitier_name)\n            except UnicodeDecodeError:\n                LOGGER.warning(\"%s: Templates can only be constructed \"\n                    \"from unicode or UTF-8 strings.\", source_name)\n        elif os.path.isdir(source_name):\n            install_templates(srcroot, destroot, prefix=pathname,\n                excludes=excludes, includes=includes, path_prefix=path_prefix)", "response": "Installs all templates in srcroot to destroot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nredirecting to the inserted_url before going to the orginal request path.", "response": "def _insert_url(request, redirect_field_name=REDIRECT_FIELD_NAME,\n                inserted_url=None):\n    '''Redirects to the *inserted_url* before going to the orginal\n    request path.'''\n    # This code is pretty much straightforward\n    # from contrib.auth.user_passes_test\n    path = request.build_absolute_uri()\n    # If the login url is the same scheme and net location then just\n    # use the path as the \"next\" url.\n    login_scheme, login_netloc = six.moves.urllib.parse.urlparse(\n        inserted_url)[:2]\n    current_scheme, current_netloc = six.moves.urllib.parse.urlparse(path)[:2]\n    if ((not login_scheme or login_scheme == current_scheme) and\n        (not login_netloc or login_netloc == current_netloc)):\n        path = request.get_full_path()\n    # As long as *inserted_url* is not None, this call will redirect\n    # anything (i.e. inserted_url), not just the login.\n    from django.contrib.auth.views import redirect_to_login\n    return redirect_to_login(path, inserted_url, redirect_field_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a JsonResponse object with the JSON data.", "response": "def json_to_response(self, action=None, json_status=None, success_url=None,\n                         json_data=None, **response_kwargs):\n        \"\"\" Valid response with next action to be followed by the JS \"\"\"\n        data = {\n            \"status\": self.get_status(json_status),\n            \"action\": self.get_action(action),\n            \"extra_data\": self.get_json_data(json_data or {})\n        }\n\n        if self.action == AjaxResponseAction.REDIRECT:\n            data[\"action_url\"] = success_url or self.get_success_url()\n        return JsonResponse(data, **response_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_action(self, action=None):\n        if action:\n            self.action = action\n\n        if self.action not in AjaxResponseAction.choices:\n            raise ValueError(\n                \"Invalid action selected: '{}'\".format(self.action))\n\n        return self.action", "response": "Returns the action to take after call"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning status of for json", "response": "def get_status(self, json_status=None):\n        \"\"\" Returns status of for json \"\"\"\n        if json_status:\n            self.json_status = json_status\n\n        if self.json_status not in AjaxResponseStatus.choices:\n            raise ValueError(\n                \"Invalid status selected: '{}'\".format(self.json_status))\n\n        return self.json_status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_invalid(self, form, prefix=None):\n        response = super(FormAjaxMixin, self).form_invalid(form)\n        if self.request.is_ajax():\n            data = {\n                \"errors_list\": self.add_prefix(form.errors, prefix),\n            }\n            return self.json_to_response(status=400, json_data=data,\n                                         json_status=AjaxResponseStatus.ERROR)\n        return response", "response": "Return error list in JSON response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns response with action if form valid", "response": "def form_valid(self, form):\n        \"\"\" If form valid return response with action \"\"\"\n        response = super(FormAjaxMixin, self).form_valid(form)\n        if self.request.is_ajax():\n            return self.json_to_response()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds form prefix to errors", "response": "def add_prefix(self, errors, prefix):\n        \"\"\"Add form prefix to errors\"\"\"\n        if not prefix:\n            prefix = self.get_prefix()\n        if prefix:\n            return {\"%s-%s\" % (prefix, k): v for k, v in errors.items()}\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the rendered template in JSON format", "response": "def render_to_response(self, context, **response_kwargs):\n        \"\"\" Returns the rendered template in JSON format \"\"\"\n        if self.request.is_ajax():\n            data = {\n                \"content\": render_to_string(\n                    self.get_template_names(), context, request=self.request)\n            }\n            return JsonResponse(data)\n        if settings.DEBUG:\n            return super(PartialAjaxMixin, self).render_to_response(\n                context, **response_kwargs)\n        raise Http404()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_init_map(interface, state, label, inp):\n    import random\n    out = interface.output(0)\n    centers = {}\n\n    for row in inp:\n        row = row.strip().split(state[\"delimiter\"])\n        if len(row) > 1:\n            x = [(0 if row[i] in state[\"missing_vals\"] else float(row[i])) for i in state[\"X_indices\"]]\n            cluster = random.randint(0, state['k'] - 1)\n            vertex = state['create'](x, 1.0)\n            centers[cluster] = vertex if cluster not in centers else state[\"update\"](centers[cluster], vertex)\n    for cluster, values in centers.iteritems():\n        out.add(cluster, values)", "response": "Assign datapoint e randomly to one of the k clusters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates the map of the i - th cluster that is closest to the datapoint e.", "response": "def estimate_map(interface, state, label, inp):\n    \"\"\"Find the cluster `i` that is closest to the datapoint `e`.\"\"\"\n    out = interface.output(0)\n    centers = {}\n    for row in inp:\n        row = row.strip().split(state[\"delimiter\"])\n        if len(row) > 1:\n            x = [(0 if row[i] in state[\"missing_vals\"] else float(row[i])) for i in state[\"X_indices\"]]\n            cluster = min((state['dist'](c, x), i) for i, c in state['centers'])[1]\n            vertex = state['create'](x, 1.0)\n            centers[cluster] = vertex if cluster not in centers else state[\"update\"](centers[cluster], vertex)\n\n    for cluster, values in centers.iteritems():\n        out.add(cluster, values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef estimate_reduce(interface, state, label, inp):\n    centers = {}\n    for i, c in inp:\n        centers[i] = c if i not in centers else state['update'](centers[i], c)\n\n    out = interface.output(0)\n    for i, c in centers.items():\n        out.add(i, state['finalize'](c))", "response": "Estimate the cluster centers for each cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict_map(interface, state, label, inp):\n    out = interface.output(0)\n    for row in inp:\n        if len(row) > 1:\n            row = row.strip().split(state[\"delimiter\"])\n            x_id = \"\" if state[\"id_index\"] == -1 else row[state[\"id_index\"]]\n            x = [(0 if row[i] in state[\"missing_vals\"] else float(row[i])) for i in state[\"X_indices\"]]\n            out.add(x_id, min([(i, state[\"dist\"](c, x)) for i, c in state[\"centers\"]], key=lambda t: t[1]))", "response": "Determine the closest cluster for the datapoint e."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(dataset, n_clusters=5, max_iterations=10, random_state=None, save_results=True, show=False):\n    from disco.job import Job\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import result_iterator\n\n    try:\n        n_clusters = int(n_clusters)\n        max_iterations = int(max_iterations)\n        if n_clusters < 2:\n            raise Exception(\"Parameter n_clusters should be greater than 1.\")\n        if max_iterations < 1:\n            raise Exception(\"Parameter max_iterations should be greater than 0.\")\n    except ValueError:\n        raise Exception(\"Parameters should be numerical.\")\n\n    job = Job(worker=Worker(save_results=save_results))\n    job.pipeline = [(\"split\",\n                     Stage(\"kmeans_init_map\", input_chain=dataset.params[\"input_chain\"], init=map_init,\n                           process=random_init_map)),\n                    ('group_label',\n                     Stage(\"kmeans_init_reduce\", process=estimate_reduce, init=simple_init, combine=True))]\n    job.params = dict(dataset.params.items() + mean_point_center.items())\n    job.params['seed'] = random_state\n    job.params['k'] = n_clusters\n\n    job.run(input=dataset.params[\"data_tag\"], name=\"kmeans_init\")\n    init = job.wait(show=show)\n    centers = [(i, c) for i, c in result_iterator(init)]\n\n    for j in range(max_iterations):\n        job = Job(worker=Worker(save_results=save_results))\n        job.params = dict(dataset.params.items() + mean_point_center.items())\n        job.params['k'] = n_clusters\n        job.params['centers'] = centers\n\n        job.pipeline = [('split', Stage(\"kmeans_map_iter_%s\" % (j + 1,),\n                                        input_chain=dataset.params[\"input_chain\"],\n                                        process=estimate_map, init=simple_init)),\n                        ('group_label', Stage(\"kmeans_reduce_iter_%s\" % (j + 1,),\n                                              process=estimate_reduce, init=simple_init, combine=True))]\n\n        job.run(input=dataset.params[\"data_tag\"], name='kmeans_iter_%d' % (j + 1,))\n        fitmodel_url = job.wait(show=show)\n        centers = [(i, c) for i, c in result_iterator(fitmodel_url)]\n\n    return {\"kmeans_fitmodel\": fitmodel_url}", "response": "Optimize k - clustering for iterations with k - clustering for max_iterations iterations with cluster\n    center definitions as given in center."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef predict(dataset, fitmodel_url, save_results=True, show=False):\n\n    from disco.job import Job\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import result_iterator\n\n    if \"kmeans_fitmodel\" not in fitmodel_url:\n        raise Exception(\"Incorrect fit model.\")\n\n    job = Job(worker=Worker(save_results=save_results))\n    job.params = dict(dataset.params.items() + mean_point_center.items())\n    job.params[\"centers\"] = [(i, c) for i, c in result_iterator(fitmodel_url[\"kmeans_fitmodel\"])]\n\n    job.pipeline = [(\"split\", Stage(\"kmeans_predict\", input_chain=dataset.params[\"input_chain\"], init=simple_init,\n                                    process=predict_map))]\n\n    job.run(input=dataset.params[\"data_tag\"], name=\"kmeans_predict\")\n\n    return job.wait(show=show)", "response": "Predict closest clusters for the datapoints in input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscan sys. path for standard library modules.", "response": "def load_stdlib():\n    '''Scans sys.path for standard library modules.\n    '''\n    if _stdlib:\n        return _stdlib\n\n    prefixes = tuple({os.path.abspath(p) for p in (\n        sys.prefix,\n        getattr(sys, 'real_prefix', sys.prefix),\n        getattr(sys, 'base_prefix', sys.prefix),\n    )})\n\n    for sp in sys.path:\n        if not sp:\n            continue\n        _import_paths.append(os.path.abspath(sp))\n\n    stdpaths = tuple({p for p in _import_paths\n                      if p.startswith(prefixes) and 'site-packages' not in p})\n\n    _stdlib.update(sys.builtin_module_names)\n\n    for stdpath in stdpaths:\n        if not os.path.isdir(stdpath):\n            continue\n\n        for item in os.listdir(stdpath):\n            if item.startswith('.') or item == 'site-packages':\n                continue\n\n            p = os.path.join(stdpath, item)\n            if not os.path.isdir(p) and not item.endswith(('.py', '.so')):\n                continue\n\n            _stdlib.add(item.split('.', 1)[0])\n\n    return _stdlib"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_path_from_file(filename, as_list=False):\n    '''Returns a tuple of the import path and root module directory for the\n    supplied file.\n    '''\n    module_path = []\n    basename = os.path.splitext(os.path.basename(filename))[0]\n    if basename != '__init__':\n        module_path.append(basename)\n\n    dirname = os.path.dirname(filename)\n    while os.path.isfile(os.path.join(dirname, '__init__.py')):\n        dirname, tail = os.path.split(dirname)\n        module_path.insert(0, tail)\n\n    if as_list:\n        return module_path, dirname\n    return '.'.join(module_path), dirname", "response": "Returns a tuple of the import path and root module directory for the\n    supplied file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the file that might contain the import_path.", "response": "def file_containing_import(import_path, import_root):\n    '''Finds the file that might contain the import_path.\n    '''\n    if not _import_paths:\n        load_stdlib()\n\n    if os.path.isfile(import_root):\n        import_root = os.path.dirname(import_root)\n\n    search_paths = [import_root] + _import_paths\n    module_parts = import_path.split('.')\n    for i in range(len(module_parts), 0, -1):\n        module_path = os.path.join(*module_parts[:i])\n        for sp in search_paths:\n            p = os.path.join(sp, module_path)\n            if os.path.isdir(p):\n                return os.path.join(p, '__init__.py')\n            elif os.path.isfile(p + '.py'):\n                return p + '.py'\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_import(import_path, from_module):\n    '''Resolves relative imports from a module.\n    '''\n    if not import_path or not import_path.startswith('.'):\n        return import_path\n\n    from_module = from_module.split('.')\n    dots = 0\n    for c in import_path:\n        if c == '.':\n            dots += 1\n        else:\n            break\n\n    if dots:\n        from_module = from_module[:-dots]\n        import_path = import_path[dots:]\n\n    if import_path:\n        from_module.append(import_path)\n\n    return '.'.join(from_module)", "response": "Resolves relative imports from a module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_package(name, installed, package=False):\n    '''Finds a package in the installed list.\n\n    If `package` is true, match package names, otherwise, match import paths.\n    '''\n    if package:\n        name = name.lower()\n        tests = (\n            lambda x: x.user and name == x.name.lower(),\n            lambda x: x.local and name == x.name.lower(),\n            lambda x: name == x.name.lower(),\n        )\n    else:\n        tests = (\n            lambda x: x.user and name in x.import_names,\n            lambda x: x.local and name in x.import_names,\n            lambda x: name in x.import_names,\n        )\n\n    for t in tests:\n        try:\n            found = list(filter(t, installed))\n            if found and not found[0].is_scan:\n                return found[0]\n        except StopIteration:\n            pass\n    return None", "response": "Finds a package in the installed list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a file has a hashbang.", "response": "def is_script(filename):\n    '''Checks if a file has a hashbang.\n    '''\n    if not os.path.isfile(filename):\n        return False\n\n    try:\n        with open(filename, 'rb') as fp:\n            return fp.read(2) == b'#!'\n    except IOError:\n        pass\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks a file to see if it s a python script of some sort.", "response": "def is_python_script(filename):\n    '''Checks a file to see if it's a python script of some sort.\n    '''\n    if filename.lower().endswith('.py'):\n        return True\n\n    if not os.path.isfile(filename):\n        return False\n\n    try:\n        with open(filename, 'rb') as fp:\n            if fp.read(2) != b'#!':\n                return False\n            return re.match(r'.*python', str_(fp.readline()))\n    except IOError:\n        pass\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch database for given key and user pattern.", "response": "def search(self, key_pattern: str, user_pattern: str) -> List[Entry]:\n        \"\"\"Search database for given key and user pattern.\"\"\"\n        # normalize key\n        key_pattern = _normalized_key(key_pattern)\n\n        # search\n        results = []\n        for entry in self.entries:\n            if key_pattern in entry.key and user_pattern in entry.user:\n                results.append(entry)\n\n        # sort results according to key (stability of sorted() ensures that the order of accounts for any given key remains untouched)\n        return sorted(results, key=lambda e: e.key)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(path: str) -> \"Store\":\n        # load source (decrypting if necessary)\n        if _gpg.is_encrypted(path):\n            src_bytes = _gpg.decrypt(path)\n        else:\n            src_bytes = open(path, \"rb\").read()\n        src = src_bytes.decode(\"utf-8\")\n\n        # parse database source\n        ext = _gpg.unencrypted_ext(path)\n        assert ext not in [\n            \".yml\",\n            \".yaml\",\n        ], \"YAML support was removed in version 0.12.0\"\n        entries = _parse_entries(src)\n\n        return Store(path, entries)", "response": "Load a password store from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns PASS and WAIT results only skips everything else.", "response": "def only_passed_and_wait(result):\n    \"\"\"Returns PASS and WAIT results only, skips everything else.\"\"\"\n    verdict = result.get(\"verdict\", \"\").strip().lower()\n    if verdict in Verdicts.PASS + Verdicts.WAIT:\n        return result\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_source_info(result):\n    comment = result.get(\"comment\")\n    # don't change comment if it already exists\n    if comment:\n        return\n\n    source = result.get(\"source\")\n    job_name = result.get(\"job_name\")\n    run = result.get(\"run\")\n    source_list = [source, job_name, run]\n    if not all(source_list):\n        return\n\n    source_note = \"/\".join(source_list)\n    source_note = \"Source: {}\".format(source_note)\n    result[\"comment\"] = source_note", "response": "Adds info about source of test result if available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_parametrization(result, parametrize):\n    if parametrize:\n        # remove parameters from title\n        title = result.get(\"title\")\n        if title:\n            result[\"title\"] = TEST_PARAM_RE.sub(\"\", title)\n    else:\n        # don't parametrize if not specifically configured\n        if \"params\" in result:\n            del result[\"params\"]", "response": "Modifies the result s data according to the parametrization settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef include_class_in_title(result):\n    classname = result.get(\"classname\", \"\")\n    if classname:\n        filepath = result.get(\"file\", \"\")\n        title = result.get(\"title\")\n        if title and \"/\" in filepath and \".\" in classname:\n            fname = filepath.split(\"/\")[-1].replace(\".py\", \"\")\n            last_classname = classname.split(\".\")[-1]\n            # last part of classname is not file name\n            if fname != last_classname and last_classname not in title:\n                result[\"title\"] = \"{}.{}\".format(last_classname, title)\n        # we don't need to pass classnames?\n        del result[\"classname\"]", "response": "Makes sure that test class is included in title."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_rst_description(testcase):\n    description = testcase.get(\"description\")\n\n    if not description:\n        return\n\n    try:\n        with open(os.devnull, \"w\") as devnull:\n            testcase[\"description\"] = publish_parts(\n                description,\n                writer_name=\"html\",\n                settings_overrides={\"report_level\": 2, \"halt_level\": 2, \"warning_stream\": devnull},\n            )[\"html_body\"]\n    # pylint: disable=broad-except\n    except Exception as exp:\n        testcase_id = testcase.get(\"nodeid\") or testcase.get(\"id\") or testcase.get(\"title\")\n        logger.error(\"%s: description: %s\", str(exp), testcase_id)", "response": "Creates an HTML version of the RST formatted description."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preformat_plain_description(testcase):\n    description = testcase.get(\"description\")\n\n    if not description:\n        return\n\n    # naive approach to removing indent from pytest docstrings\n    nodeid = testcase.get(\"nodeid\") or \"\"\n    indent = None\n    if \"::Test\" in nodeid:\n        indent = 8 * \" \"\n    elif \"::test_\" in nodeid:\n        indent = 4 * \" \"\n\n    if indent:\n        orig_lines = description.split(\"\\n\")\n        new_lines = []\n        for line in orig_lines:\n            if line.startswith(indent):\n                line = line.replace(indent, \"\", 1)\n            new_lines.append(line)\n        description = \"\\n\".join(new_lines)\n\n    testcase[\"description\"] = \"<pre>\\n{}\\n</pre>\".format(description)", "response": "Creates a preformatted HTML version of the description."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_unique_runid(testcase, run_id=None):\n    testcase[\"description\"] = '{}<br id=\"{}\"/>'.format(\n        testcase.get(\"description\") or \"\", run_id or id(add_unique_runid)\n    )", "response": "Adds run id to the test description."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_automation_link(testcase):\n    automation_link = (\n        '<a href=\"{}\">Test Source</a>'.format(testcase[\"automation_script\"])\n        if testcase.get(\"automation_script\")\n        else \"\"\n    )\n    testcase[\"description\"] = \"{}<br/>{}\".format(testcase.get(\"description\") or \"\", automation_link)", "response": "Appends link to automation script to the test description."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image(self):\n        '''Return an image of the structure of the compound'''\n        r = requests.get(self.image_url, stream=True)\n        r.raise_for_status()\n        return r.raw.read()", "response": "Return an image of the structure of the compound"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_numbers():\n    a = request.params.get('a', 0, type=int)\n    b = request.params.get('b', 0, type=int)\n    return json.dumps({'result': a+b})", "response": "Add two numbers server side ridiculous but well..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef db_putString(self, db_name, key, value):\n        warnings.warn('deprecated', DeprecationWarning)\n        return (yield from self.rpc_call('db_putString',\n                                         [db_name, key, value]))", "response": "Store a string value in the specified database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef db_getString(self, db_name, key):\n        warnings.warn('deprecated', DeprecationWarning)\n        return (yield from self.rpc_call('db_getString', [db_name, key]))", "response": "Get a string from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db_putHex(self, db_name, key, value):\n        warnings.warn('deprecated', DeprecationWarning)\n        if not value.startswith('0x'):\n            value = add_0x(value)\n        return (yield from self.rpc_call('db_putHex', [db_name, key, value]))", "response": "Put a hex key in the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef db_getHex(self, db_name, key):\n        warnings.warn('deprecated', DeprecationWarning)\n        return (yield from self.rpc_call('db_getHex', [db_name, key]))", "response": "Get a hex value from a database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves the problem with the given set of entries.", "response": "def solve(self, b):\n        \"\"\"\n        LUx = b:\n           Ly = b\n           Ux = y\n        \"\"\"\n        #b = self.permute_vec(b)\n        y = []\n        for bri in range(self.N):  # block row index\n            for li in range(self.n):  # local row index\n                s = 0.0\n                for lci in range(li): # local column index\n                    s += self.lu[bri][li, lci]*y[bri*self.n+lci]\n                for di in range(1, self.ndiag+1):\n                    if bri >= di:\n                        # di:th sub diagonal (counted as distance from main diag)\n                        ci = self.colbyrow[bri][li]\n                        s += self.sub[di-1][(bri-di)*self.n+ci]*y[\n                            (bri-di)*self.n + ci]\n                y.append(b[bri*self.n+self.rowbycol[bri][li]]-s) # Doolittle: L[i, i] == 1\n        x = [0]*len(y)\n        for bri in range(self.N-1, -1, -1):\n            for li in range(self.n - 1, -1, -1):\n                s = 0.0\n                for ci in range(li+1, self.n):\n                    s += self.lu[bri][li, ci]*x[bri*self.n + ci]\n                for di in range(1, self.ndiag+1):\n                    if bri < self.N-di:\n                        ci = self.colbyrow[bri][li]\n                        s += self.sup[di-1][bri*self.n+ci]*x[(bri+di)*self.n + ci]\n                x[bri*self.n+li] = (y[bri*self.n + li] - s)/self.lu[bri][li, li]\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef entry_archive_year_url():\n    entry = Entry.objects.filter(published=True).latest()\n    arg_list = [entry.published_on.strftime(\"%Y\")]\n    return reverse('blargg:entry_archive_year', args=arg_list)", "response": "Renders the entry_archive_year URL for the latest Entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract parameters from properties.", "response": "def _extract_parameters_from_properties(properties):\n    \"\"\"Extracts parameters from properties.\"\"\"\n    new_properties = {}\n    parameters = []\n    for key, value in six.iteritems(properties):\n        if key.startswith(_PARAMETER_PREFIX):\n            parameters.append((key.replace(_PARAMETER_PREFIX, \"\"), value))\n        else:\n            new_properties[key] = value\n\n    return new_properties, sorted(parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_junit(junit_file, **kwargs):\n    xml_root = _get_xml_root(junit_file)\n\n    results = []\n    for test_data in xml_root:\n        if test_data.tag != \"testcase\":\n            continue\n\n        verdict, comment, properties = _parse_testcase_record(test_data)\n        properties, parameters = _extract_parameters_from_properties(properties)\n\n        title = test_data.get(\"name\")\n        classname = test_data.get(\"classname\")\n        time = test_data.get(\"time\", 0)\n        filepath = test_data.get(\"file\")\n\n        data = [\n            (\"title\", title),\n            (\"classname\", classname),\n            (\"verdict\", verdict),\n            (\"comment\", comment),\n            (\"time\", time),\n            (\"file\", filepath),\n        ]\n        for key in sorted(properties):\n            data.append((key, properties[key]))\n        if parameters:\n            data.append((\"params\", OrderedDict(parameters)))\n\n        results.append(OrderedDict(data))\n\n    return xunit_exporter.ImportedData(results=results, testrun=None)", "response": "Reads the content of the junit - results file produced by pytest and returns imported data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef watch(args):\n    \" Watch directory for changes and auto pack sources \"\n    assert op.isdir(args.source), \"Watch mode allowed only for directories.\"\n    print 'Zeta-library v. %s watch mode' % VERSION\n    print '================================'\n    print 'Ctrl+C for exit\\n'\n    observer = Observer()\n    handler = ZetaTrick(args=args)\n    observer.schedule(handler, args.source, recursive=True)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n        print \"\\nWatch mode stoped.\"\n    observer.join()", "response": "Watch directory for changes and auto pack sources"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse file or dir import css js code and save with prefix", "response": "def pack(args):\n    \" Parse file or dir, import css, js code and save with prefix \"\n    assert op.exists(args.source), \"Does not exists: %s\" % args.source\n    zeta_pack(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncasts a set of keys and an array to a Matrix object.", "response": "def cast(keys, data):\n        \"\"\"Cast a set of keys and an array to a Matrix object.\"\"\"\n        matrix = Matrix()\n        matrix.keys = keys\n        matrix.data = data\n        return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_to(self, vertex, weight=1):\n        for edge in self.edges_out:\n            if vertex == edge.vertex_in:\n                return edge\n        return Edge(self, vertex, weight)", "response": "Connect this edge to another edge."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect_from(self, vertex, weight=1):\n        for edge in self.edges_in:\n            if vertex == edge.vertex_out:\n                return edge\n        return Edge(vertex, self, weight)", "response": "Connect another vertex to this one."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef go_from(self, vertex):\n        if self.vertex_out:\n            self.vertex_out.edges_out.remove(self)\n        self.vertex_out = vertex\n        vertex.edges_out.add(self)", "response": "Tells the edge to go out from this one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntell the edge to go into this vertex.", "response": "def go_in(self, vertex):\n        \"\"\"\n        Tell the edge to go into this vertex.\n\n        Args:\n            vertex (Vertex): vertex to go into.\n        \"\"\"\n        if self.vertex_in:\n            self.vertex_in.edges_in.remove(self)\n        self.vertex_in = vertex\n        vertex.edges_in.add(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the device type from a device_type list.", "response": "def get_device_type(device_type=0):\n    \"\"\"Return the device type from a device_type list.\"\"\"\n    device_types = {\n        0: \"Unknown\",\n        1: \"Classic - BR/EDR devices\",\n        2: \"Low Energy - LE-only\",\n        3: \"Dual Mode - BR/EDR/LE\"\n    }\n    if device_type in [0, 1, 2, 3]:\n        return_value = device_types[device_type]\n    else:\n        return_value = device_types[0]\n    return return_value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef site_prefixed(path):\n    if path is None:\n        path = ''\n    if settings.DEBUG and hasattr(settings, 'APP_NAME'):\n        path_prefix = '/%s' % settings.APP_NAME\n    else:\n        path_prefix = ''\n    if path:\n        # We have an actual path instead of generating a prefix that will\n        # be placed in front of static urls (ie. {{'pricing'|site_prefixed}}\n        # insted of {{''|site_prefixed}}{{ASSET_URL}}).\n        path_prefix += '/'\n        if path.startswith('/'):\n            path = path[1:]\n    return urljoin(path_prefix, path)", "response": "Returns the path prefix for the current site."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_fit(interface, state, label, inp):\n    import numpy as np\n    out = interface.output(0)\n\n    H, J, grad = 0, 0, 0\n    for row in inp:\n        row = row.strip().split(state[\"delimiter\"])  # split row\n        if len(row) > 1:  # check if row is empty\n            # add intercept term to every sample\n            x = np.array([1] + [(0 if v in state[\"missing_vals\"] else float(v)) for i, v in enumerate(row) if\n                                i in state[\"X_indices\"]])\n            # map label value to 0 or 1. If label does not match set error\n            y = 0 if state[\"y_map\"][0] == row[state[\"y_index\"]] else 1 if state[\"y_map\"][1] == row[\n                state[\"y_index\"]] else \"Error\"\n\n            g = 1. / (1 + np.exp(-np.dot(x, state[\"thetas\"])))  # sigmoid function\n            grad += x * (g - y)  # gradient\n            H += np.multiply(np.outer(x, x), g * (1 - g))  # Hessian matrix\n            J -= np.log(g) if y == 1 else np.log(1 - g)  # J cost function\n    out.add(\"grad\", grad)\n    out.add(\"J\", J)\n    for i, row in enumerate(H):\n        out.add(i, row)", "response": "Function calculates sigmoid function for every sample and calculates gradient for each sample."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions for fitting a logistic regression model on a single dataset object.", "response": "def fit(dataset, alpha=1e-8, max_iterations=10, save_results=True, show=False):\n    \"\"\"\n    Function starts a job for calculation of theta parameters\n\n    Parameters\n    ----------\n    input - dataset object with input urls and other parameters\n    alpha - convergence value\n    max_iterations - define maximum number of iterations\n    save_results - save results to ddfs\n    show - show info about job execution\n\n    Returns\n    -------\n    Urls of fit model results on ddfs\n    \"\"\"\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import Job, result_iterator\n    import numpy as np\n\n    if dataset.params[\"y_map\"] == []:\n        raise Exception(\"Logistic regression requires a target label mapping parameter.\")\n    try:\n        alpha = float(alpha)\n        max_iterations = int(max_iterations)\n        if max_iterations < 1:\n            raise Exception(\"Parameter max_iterations should be greater than 0.\")\n    except ValueError:\n        raise Exception(\"Parameters should be numerical.\")\n\n    # initialize thetas to 0 and add intercept term\n    thetas = np.zeros(len(dataset.params[\"X_indices\"]) + 1)\n\n    J = [0]  # J cost function values for every iteration\n    for i in range(max_iterations):\n        job = Job(worker=Worker(save_results=save_results))\n        # job parallelizes mappers and joins them with one reducer\n        job.pipeline = [\n            (\"split\", Stage(\"map\", input_chain=dataset.params[\"input_chain\"], init=simple_init, process=map_fit)),\n            ('group_all', Stage(\"reduce\", init=simple_init, process=reduce_fit, combine=True))]\n\n        job.params = dataset.params  # job parameters (dataset object)\n        job.params[\"thetas\"] = thetas  # every iteration set new thetas\n        job.run(name=\"logreg_fit_iter_%d\" % (i + 1), input=dataset.params[\"data_tag\"])\n\n        fitmodel_url = job.wait(show=show)\n        for k, v in result_iterator(fitmodel_url):\n            if k == \"J\":  #\n                J.append(v)  # save value of J cost function\n            else:\n                thetas = v  # save new thetas\n        if np.abs(J[-2] - J[-1]) < alpha:  # check for convergence\n            if show:\n                print(\"Converged at iteration %d\" % (i + 1))\n            break\n\n    return {\"logreg_fitmodel\": fitmodel_url}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the plot using a template.", "response": "def render(self, template=None):\n        \"\"\"Render the plot using a template.\n\n        Once the plot is complete, it needs to be rendered.  Artist uses\n        the Jinja2 templating engine.  The default template results in a\n        LaTeX file which can be included in your document.\n\n        :param template: a user-supplied template or None.\n        :type template: string or None.\n        :returns: the rendered template as string.\n\n        This is a very minimal implementation.  Override this method to\n        include variables in the template.render call.\n\n        \"\"\"\n        if not template:\n            template = self.template\n\n        response = template.render()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, dest_path):\n        self.save_assets(dest_path)\n        self.external_filename = 'externalized-%s' % \\\n                                 os.path.basename(dest_path).replace(' ', '_')\n        dest_path = self._add_extension('tex', dest_path)\n        with open(dest_path, 'w') as f:\n            f.write(self.render())", "response": "r Save the plot as a LaTeX file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_as_pdf(self, dest_path):\n        dest_path = self._add_extension('pdf', dest_path)\n        build_dir = tempfile.mkdtemp()\n        build_path = os.path.join(build_dir, 'document.tex')\n        self.save_assets(build_path)\n        with open(build_path, 'w') as f:\n            f.write(self.render())\n        pdf_path = self._build_document(build_path)\n        shutil.copyfile(pdf_path, dest_path)\n        shutil.rmtree(build_dir)", "response": "Save the plot as a PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a data series to the plot.", "response": "def plot(self, x, y, xerr=[], yerr=[], mark='o',\n             linestyle='solid', use_steps=False, markstyle=None, legend=None):\n        \"\"\"Add a data series to the plot.\n\n        :param x: array containing x-values.\n        :param y: array containing y-values.\n        :param xerr: (optional) array containing errors on the x-values.\n        :param yerr: (optional) array containing errors on the y-values.\n        :param mark: the symbol used to mark the data point.  May be None,\n            or any plot mark accepted by TikZ (e.g. ``*, x, +, o, square,\n            triangle``).\n        :param linestyle: the line style used to connect the data points.\n            May be None, or any line style accepted by TikZ (e.g. solid,\n            dashed, dotted, thick, or even combinations like\n            \"red,thick,dashed\").\n        :param use_steps: if True, draw a stepped plot.\n        :param markstyle: the style of the plot marks (e.g. 'mark\n            size=.75pt')\n\n        The dimensions of x, y, xerr and yerr should be equal.  However,\n        xerr and yerr may be empty lists.  Each element in xerr and yerr\n        may be a single value for symmetric error bars, or a tuple of\n        two values for assymetric errors.\n\n        \"\"\"\n        if len(x) != len(y):\n            raise RuntimeError(\n                'The length of the x and y coordinates should be equal')\n        if (len(xerr) and len(xerr) != len(x) or\n                len(yerr) and len(yerr) != len(y)):\n            raise RuntimeError(\n                'The length of the errors and coordinates should be equal')\n\n        # clear the background of the marks\n        self._clear_plot_mark_background(x, y, mark, markstyle)\n        # draw the plot series over the background\n        options = self._parse_plot_options(mark, linestyle, use_steps,\n                                           markstyle)\n        plot_series = self._create_plot_series_object(x, y, xerr, yerr,\n                                                      options, legend)\n        self.plot_series_list.append(plot_series)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef histogram(self, counts, bin_edges, linestyle='solid'):\n        if len(bin_edges) - 1 != len(counts):\n            raise RuntimeError(\n                'The length of bin_edges should be length of counts + 1')\n        x = bin_edges\n        y = list(counts) + [counts[-1]]\n        self.plot(x, y, mark=None, linestyle=linestyle, use_steps=True)", "response": "Plots a histogram of the count values and bin edges."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a two - dimensional histogram of the count values.", "response": "def histogram2d(self, counts, x_edges, y_edges, type='bw', style=None,\n                    bitmap=False, colormap=None):\n        \"\"\"Plot a two-dimensional histogram.\n\n        The user needs to supply the histogram.  This method only plots\n        the results.  You can use NumPy's histogram2d function.\n\n        :param counts: array containing the count values.\n        :param x_edges: array containing the x-axis bin edges.\n        :param y_edges: array containing the y-axis bin edges.\n        :param type: the type of histogram.  Allowed values are 'bw' for\n            filled squares with shades from black (minimum value) to white\n            (maximum value), 'reverse_bw' for filled squares with the\n            shades reversed and, 'color' for color mapped histogram\n            which uses the 'coolwarm' colormap by default, but can be\n            overwritten with the colormap keyword, and 'area' for\n            squares where the area of the square is a measure of the\n            count in the bin.\n        :param style: optional TikZ styles to apply (e.g. 'red').  Note\n            that many color styles are overridden by the 'bw' and\n            'reverse_bw' types.\n        :param bitmap: Export the histogram as an image for better\n            performance. This does expect all bins along an axis to have\n            equal width. Can not be used in combination with type 'area'.\n        :param colormap: A colormap for the 'color' type, as expected by\n            the `Image.putpalette` method.\n\n        Example::\n\n            >>> x = np.random.uniform(low=1, high=1000, size=2000)\n            >>> y = np.random.uniform(low=0, high=50, size=2000)\n            >>> plot = artist.Plot()\n            >>> n, xbins, ybins = np.histogram2d(x, y)\n            >>> plot.histogram2d(n, xbins, ybins)\n\n        When you desire logarithmic axes and bitmap is set to True special\n        care has to be taken with the binning. This is because the bins along\n        an axis have to be equal size in the final result. So use logarithmic\n        binning for logarithmic axes.\n\n        Example::\n\n            >>> plot = artist.Plot(axis='semilogx')\n            >>> xbins = np.logspace(0, 3, 20)\n            >>> ybins = np.linspace(-5, 10, 10)\n            >>> n, xbins, ybins = np.histogram2d(x, y, bins=[xbins, ybins])\n            >>> plot.histogram2d(n, xbins, ybins, bitmap=True)\n\n        For each bin where the counts are nan the value will be set to the\n        minimum value (i.e. `np.nanmin(counts)`).\n\n        \"\"\"\n        if counts.shape != (len(x_edges) - 1, len(y_edges) - 1):\n            raise RuntimeError(\n                'The length of x_edges and y_edges should match counts')\n\n        if type not in ['bw', 'reverse_bw', 'area', 'color']:\n            raise RuntimeError('Histogram type %s not supported' % type)\n        if type == 'area' and bitmap:\n            raise RuntimeError('Histogram type %s not supported for bitmap '\n                               'output' % type)\n        if type == 'color' and not bitmap:\n            raise RuntimeError('Histogram type %s not supported for '\n                               'non-bitmapped output' % type)\n\n        if bitmap:\n            normed_counts = self._normalize_histogram2d(counts, type)\n            img = Image.fromarray(np.flipud(normed_counts.T))\n            if type == 'color':\n                if colormap == 'viridis':\n                    img.putpalette(VIRIDIS)\n                elif colormap in [None, 'coolwarm']:\n                    img.putpalette(COOLWARM)\n                else:\n                    img.putpalette(colormap)\n            self.bitmap_list.append({'image': img,\n                                     'xmin': min(x_edges),\n                                     'xmax': max(x_edges),\n                                     'ymin': min(y_edges),\n                                     'ymax': max(y_edges)})\n        else:\n            x_centers = (x_edges[:-1] + x_edges[1:]) / 2\n            y_centers = (y_edges[:-1] + y_edges[1:]) / 2\n\n            self.histogram2d_list.append({'x_edges': x_edges,\n                                          'y_edges': y_edges,\n                                          'x_centers': x_centers,\n                                          'y_centers': y_centers,\n                                          'counts': counts,\n                                          'max': np.nanmax(counts),\n                                          'min': np.nanmin(counts),\n                                          'type': type,\n                                          'style': style})\n        # Set limits unless lower/higher limits are already set.\n        xmin = min(x for x in (min(x_edges), self.limits['xmin'])\n                   if x is not None)\n        ymin = min(y for y in (min(y_edges), self.limits['ymin'])\n                   if y is not None)\n        xmax = max(x for x in (max(x_edges), self.limits['xmax'])\n                   if x is not None)\n        ymax = max(y for y in (max(y_edges), self.limits['ymax'])\n                   if y is not None)\n        self.set_xlimits(xmin, xmax)\n        self.set_ylimits(ymin, ymax)\n        if type != 'area':\n            self.set_mlimits(np.nanmin(counts), np.nanmax(counts))\n        if type == 'bw':\n            self.set_colormap('blackwhite')\n        elif type == 'reverse_bw':\n            self.set_colormap('whiteblack')\n        elif type == 'color':\n            if colormap == 'viridis':\n                self.set_colormap('viridis')\n            elif colormap in [None, 'coolwarm']:\n                self.set_colormap('coolwarm')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scatter(self, x, y, xerr=[], yerr=[], mark='o', markstyle=None):\n        self.plot(x, y, xerr=xerr, yerr=yerr, mark=mark, linestyle=None,\n                  markstyle=markstyle)", "response": "Plot a series of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scatter_table(self, x, y, c, s, mark='*'):\n        # clear the background of the marks\n        # self._clear_plot_mark_background(x, y, mark, markstyle)\n        # draw the plot series over the background\n        options = self._parse_plot_options(mark)\n        s = [sqrt(si) for si in s]\n        plot_series = self._create_plot_tables_object(x, y, c, s, options)\n        self.plot_table_list.append(plot_series)", "response": "Add a data series to the plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_label(self, text, location='upper right', style=None):\n        if location in RELATIVE_NODE_LOCATIONS:\n            label = RELATIVE_NODE_LOCATIONS[location].copy()\n            label['text'] = text\n            label['style'] = style\n            self.label = label\n        else:\n            raise RuntimeError('Unknown label location: %s' % location)", "response": "Set the label for the current plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a pin to the most recent data series.", "response": "def add_pin(self, text, location='left', x=None, use_arrow=False,\n                relative_position=None, style=None):\n        \"\"\"Add pin to most recent data series.\n\n        The location of the pin is interpolated if necessary, while correcting\n        for logarithmic x and/or y axes.\n\n        :param text: the text of the pin label.\n        :param location: the location of the pin relative to the data\n            point.  Any location accepted by TikZ is allowed.\n        :type location: string\n        :param x: the x location of the data point (in the most recent\n            data series) at which to place the label.  This is\n            interpolated between the actual data points.  If None, only\n            the relative_position parameter is used.\n        :param use_arrow: specifies whether to draw an arrow between the\n            data point and the pin label text.\n        :type use_arrow: boolean\n        :param relative_position: location of the data point as a relative\n            number between 0 and 1.\n        :param style: optional TikZ styles to apply (e.g. 'red').\n\n        \"\"\"\n        try:\n            series = self.plot_series_list[-1]\n        except IndexError:\n            raise RuntimeError(\n                'First plot a data series, before using this function')\n\n        data = series['data']\n        series_x, series_y = list(zip(*data))[:2]\n\n        if x is not None:\n            if self.xmode == 'log':\n                series_x = np.log10(np.array(series_x))\n                xp = np.log10(x)\n            else:\n                xp = x\n\n            if self.ymode == 'log':\n                series_y = np.log10(np.array(series_y))\n                y = 10 ** np.interp(xp, series_x, series_y)\n            else:\n                y = np.interp(xp, series_x, series_y)\n        else:\n            x, y = series_x, series_y\n\n        self.add_pin_at_xy(x, y, text, location, relative_position,\n                           use_arrow, style)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a pin at x y location.", "response": "def add_pin_at_xy(self, x, y, text, location='above right',\n                      relative_position=.9, use_arrow=True, style=None):\n        \"\"\"Add pin at x, y location.\n\n        :param x: array, list or float, specifying the location of the\n            pin.\n        :param y: array, list or float, specifying the location of the\n            pin.\n        :param text: the text of the pin label.\n        :param location: the location of the pin relative to the data\n            point.  Any location accepted by TikZ is allowed.\n        :param relative_position: location of the data point as a relative\n            number between 0 and 1.\n        :param use_arrow: specifies whether to draw an arrow between the\n            data point and the pin label text.\n        :type use_arrow: boolean\n        :param style: optional TikZ styles to apply (e.g. 'red').\n\n        If x, y are arrays or lists, relative position is used to pick a\n        point from the arrays.  A relative position of 0.0 will be the\n        first point from the series, while 1.0 will be the last point.\n\n        \"\"\"\n        if relative_position is None:\n            if location == 'left':\n                relative_position = 0.\n            elif location == 'right':\n                relative_position = 1.\n            else:\n                relative_position = .8\n\n        x, y = self._calc_position_for_pin(x, y, relative_position)\n        self.pin_list.append({'x': x, 'y': y, 'text': text,\n                              'location': location,\n                              'use_arrow': use_arrow,\n                              'options': style})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shade_region(self, x, lower, upper, color='lightgray'):\n        self.shaded_regions_list.append({'data': list(zip(x, lower, upper)),\n                                         'color': color})", "response": "Shade a region between upper and lower bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw_image(self, image, xmin=0, ymin=0, xmax=None, ymax=None):\n        if xmax is None:\n            xmax = xmin + image.size[0]\n        if ymax is None:\n            ymax = ymin + image.size[1]\n        self.bitmap_list.append({'image': image,\n                                 'xmin': xmin,\n                                 'xmax': xmax,\n                                 'ymin': ymin,\n                                 'ymax': ymax})\n        # Set limits unless lower/higher limits are already set.\n        xmin = min(x for x in (xmin, self.limits['xmin'])\n                   if x is not None)\n        ymin = min(y for y in (ymin, self.limits['ymin'])\n                   if y is not None)\n        xmax = max(x for x in (xmax, self.limits['xmax'])\n                   if x is not None)\n        ymax = max(y for y in (ymax, self.limits['ymax'])\n                   if y is not None)\n        self.set_xlimits(xmin, xmax)\n        self.set_ylimits(ymin, ymax)", "response": "Draw an image.\n\n        Do not forget to use :meth:`set_axis_equal` to preserve the\n        aspect ratio of the image, or change the aspect ratio of the\n        plot to the aspect ratio of the image.\n\n        :param image: Pillow Image object.\n        :param xmin,ymin,xmax,ymax: the x, y image bounds.\n\n        Example::\n\n            >>> from PIL import Image\n            >>> image = Image.open('background.png')\n            >>> plot = artist.Plot()\n            >>> plot.set_axis_equal()\n            >>> plot.draw_image(image)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting limits for the x - axis.", "response": "def set_xlimits(self, min=None, max=None):\n        \"\"\"Set limits for the x-axis.\n\n        :param min: minimum value to be displayed.  If None, it will be\n            calculated.\n        :param max: maximum value to be displayed.  If None, it will be\n            calculated.\n\n        \"\"\"\n        self.limits['xmin'] = min\n        self.limits['xmax'] = max"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting limits for the y - axis.", "response": "def set_ylimits(self, min=None, max=None):\n        \"\"\"Set limits for the y-axis.\n\n        :param min: minimum value to be displayed.  If None, it will be\n            calculated.\n        :param max: maximum value to be displayed.  If None, it will be\n            calculated.\n\n        \"\"\"\n        self.limits['ymin'] = min\n        self.limits['ymax'] = max"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_mlimits(self, min=None, max=None):\n        self.limits['mmin'] = min\n        self.limits['mmax'] = max", "response": "Set limits for the point meta values outside this range will be clipped."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_slimits(self, min, max):\n        self.limits['smin'] = sqrt(min)\n        self.limits['smax'] = sqrt(max)", "response": "Set limits for the size of points in scatter table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the tick labels for the x - axis.", "response": "def set_xtick_labels(self, labels, style=None):\n        \"\"\"Set tick labels for the x-axis.\n\n        Also set the x-ticks positions to ensure the labels end up on\n        the correct place.\n\n        :param labels: list of labels for the ticks along the axis.\n\n        \"\"\"\n        self.ticks['xlabels'] = labels\n        self.ticks['xlabel_style'] = style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_ytick_labels(self, labels, style=None):\n        self.ticks['ylabels'] = labels\n        self.ticks['ylabel_style'] = style", "response": "Set the tick labels for the y - axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the suffix for the ticks of the x - axis.", "response": "def set_xtick_suffix(self, suffix):\n        \"\"\"Set the suffix for the ticks of the x-axis.\n\n        :param suffix: string added after each tick. If the value is\n                       `degree` or `precent` the corresponding symbols\n                       will be added.\n\n        \"\"\"\n        if suffix == 'degree':\n            suffix = r'^\\circ'\n        elif suffix == 'percent':\n            suffix = r'\\%'\n\n        self.ticks['xsuffix'] = suffix"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the ticks for the y - axis.", "response": "def set_ytick_suffix(self, suffix):\n        \"\"\"Set ticks for the y-axis.\n\n        :param suffix: string added after each tick. If the value is\n                       `degree` or `precent` the corresponding symbols\n                       will be added.\n\n        \"\"\"\n        if suffix == 'degree':\n            suffix = r'^\\circ'\n        elif suffix == 'percent':\n            suffix = r'\\%'\n\n        self.ticks['ysuffix'] = suffix"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_scalebar(self, location='lower right'):\n        if location in RELATIVE_NODE_LOCATIONS:\n            scalebar = RELATIVE_NODE_LOCATIONS[location].copy()\n            self.scalebar = scalebar\n        else:\n            raise RuntimeError('Unknown scalebar location: %s' % location)", "response": "Set marker area scale."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calc_position_for_pin(self, x, y, relative_position):\n        try:\n            max_idx_x = len(x) - 1\n            max_idx_y = len(y) - 1\n        except TypeError:\n            return x, y\n        else:\n            assert max_idx_x == max_idx_y, \\\n                'If x and y are iterables, they must be the same length'\n\n        if relative_position == 0:\n            xs, ys = x[0], y[0]\n        elif relative_position == 1:\n            xs, ys = x[max_idx_x], y[max_idx_y]\n        else:\n            if self.xmode == 'log':\n                x = np.log10(np.array(x))\n            if self.ymode == 'log':\n                y = np.log10(np.array(y))\n            rel_length = [0]\n            rel_length.extend(self._calc_relative_path_lengths(x, y))\n            idx = np.interp(relative_position, rel_length,\n                            range(len(rel_length)))\n            frac, idx = modf(idx)\n            idx = int(idx)\n            if self.xmode == 'log':\n                xs = 10 ** (x[idx] + (x[idx + 1] - x[idx]) * frac)\n            else:\n                xs = x[idx] + (x[idx + 1] - x[idx]) * frac\n            if self.ymode == 'log':\n                ys = 10 ** (y[idx] + (y[idx + 1] - y[idx]) * frac)\n            else:\n                ys = y[idx] + (y[idx + 1] - y[idx]) * frac\n        return xs, ys", "response": "Calculates the position at fraction of x y for pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _calc_relative_path_lengths(self, x, y):\n\n        path_lengths = np.sqrt(np.diff(x) ** 2 + np.diff(y) ** 2)\n        total_length = np.sum(path_lengths)\n        cummulative_lengths = np.cumsum(path_lengths)\n        relative_path_lengths = cummulative_lengths / total_length\n        return relative_path_lengths", "response": "Determine the relative path length at each x y position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _normalize_histogram2d(self, counts, type):\n        counts = (255 * (counts - np.nanmin(counts)) /\n                  (np.nanmax(counts) - np.nanmin(counts)))\n\n        if type == 'reverse_bw':\n            counts = 255 - counts\n\n        return counts.astype(np.uint8)", "response": "Normalize the values of the counts for a 2D histogram."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_bitmaps(self, path, suffix=''):\n        dir, prefix = os.path.split(path)\n        if '.' in prefix:\n            prefix = prefix.split('.')[0]\n        if prefix == '':\n            prefix = 'figure'\n        for i, bitmap in enumerate(self.bitmap_list):\n            name = '%s%s_%d.png' % (prefix, suffix, i)\n            bitmap['name'] = name\n            img = bitmap['image']\n            # Make the bitmap at least 1000x1000 pixels\n            size0 = int(np.ceil(1000. / img.size[0]) * img.size[0])\n            size1 = int(np.ceil(1000. / img.size[1]) * img.size[1])\n            large_img = img.resize((size0, size1))\n            large_img.save(os.path.join(dir, name))", "response": "Write bitmap file assets.\n\n        :param path: path of the plot file.\n        :param suffix: optional suffix to add to asset names.\n\n        The path parameter is used for the dirname, and the filename.\n        So if :meth:`save` is called with '/foo/myplot.tex', you can call\n        this method with that same path. The assets will then be saved in\n        the /foo directory, and have a name like 'myplot_0.png'."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prepare_data(self):\n        xmin, xmax = self.limits['xmin'], self.limits['xmax']\n\n        self.prepared_plot_series_list = []\n        for series in self.plot_series_list:\n            prepared_series = series.copy()\n            data = prepared_series['data']\n\n            x, _, _, _ = zip(*data)\n            # only limit data when the data is sorted\n            if sorted(x) == list(x):\n                x = np.array(x)\n                if xmin is not None:\n                    min_idx = x.searchsorted(xmin)\n                    if min_idx > 0:\n                        min_idx -= 1\n                else:\n                    min_idx = None\n                if xmax is not None:\n                    max_idx = x.searchsorted(xmax) + 1\n                else:\n                    max_idx = None\n\n                prepared_series['data'] = data[min_idx:max_idx]\n            self.prepared_plot_series_list.append(prepared_series)\n\n        self.prepared_shaded_regions_list = []\n        for series in self.shaded_regions_list:\n            prepared_series = series.copy()\n            data = prepared_series['data']\n\n            x, _, _ = zip(*data)\n            # only limit data when the data is sorted\n            if sorted(x) == list(x):\n                x = np.array(x)\n                if xmin is not None:\n                    min_idx = x.searchsorted(xmin)\n                    if min_idx > 0:\n                        min_idx -= 1\n                else:\n                    min_idx = None\n                if xmax is not None:\n                    max_idx = x.searchsorted(xmax) + 1\n                else:\n                    max_idx = None\n\n                prepared_series['data'] = data[min_idx:max_idx]\n            self.prepared_shaded_regions_list.append(prepared_series)", "response": "Prepare data before rendering a new object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, template=None):\n        if not template:\n            template = self.template\n\n        self._prepare_data()\n\n        response = template.render(\n            axis_background=self.axis_background,\n            xmode=self.xmode,\n            ymode=self.ymode,\n            title=self.title,\n            width=self.width,\n            height=self.height,\n            xlabel=self.xlabel,\n            ylabel=self.ylabel,\n            limits=self.limits,\n            xscale=self.xscale,\n            yscale=self.yscale,\n            ticks=self.ticks,\n            axis_equal=self.axis_equal,\n            scalebar=self.scalebar,\n            colorbar=self.colorbar,\n            colormap=self.colormap,\n            external_filename=self.external_filename,\n            font_options=self.font_options,\n            axis_options=self.axis_options,\n            has_graph_paper=self.has_graph_paper,\n            plot=self,\n            plot_template=self.template)\n        return response", "response": "Render the plot using a Jinja2 template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a data series to the plot.", "response": "def plot(self, phi, r, **kwargs):\n        \"\"\"Add a data series to the plot.\n\n        :param phi: array containing phi-values, should be in degrees\n                    (or radians).\n        :param r: array containing r-values.\n\n        For further options see the plot function of the super class.\n\n        \"\"\"\n        if self.use_radians:\n            phi = np.degrees(phi)\n        super(PolarPlot, self).plot(phi, r, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef histogram(self, counts, bin_edges, linestyle='solid'):\n        if len(bin_edges) - 1 != len(counts):\n            raise RuntimeError(\n                'The length of bin_edges should be length of counts + 1')\n\n        x = []\n        y = []\n\n        if self.use_radians:\n            circle = 2 * np.pi\n        else:\n            circle = 360.\n\n        step = circle / 1800.\n\n        for i in range(len(bin_edges) - 1):\n            for bin_edge in np.arange(bin_edges[i], bin_edges[i + 1],\n                                      step=step):\n                x.append(bin_edge)\n                y.append(counts[i])\n            x.append(bin_edges[i + 1])\n            y.append(counts[i])\n\n        # If last edge is same as first bin edge, connect the ends.\n        if bin_edges[-1] % circle == bin_edges[0] % circle:\n            x.append(bin_edges[0])\n            y.append(counts[0])\n\n        self.plot(x, y, mark=None, linestyle=linestyle)", "response": "This method plots a polar histogram."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _override_payload(self, payload):\n        if self.override_payload:\n            old_payload = payload\n\n            def get_value(data, key):\n                try:\n                    parent_key, nested_key = key.split(\".\", 1)\n                    return get_value(data.get(parent_key, {}), nested_key)\n                except ValueError:\n                    return data.get(key, key)\n\n            def set_values(data):\n                for key, value in data.items():\n                    if isinstance(value, dict):\n                        set_values(value)\n                    else:\n                        data[key] = get_value(old_payload, value)\n\n            payload = deepcopy(self.override_payload)\n            set_values(payload)\n\n        return payload", "response": "This function transforms the payload into a new format using the self. override_payload property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiring a webhook in the event of a failed WhatsApp contact lookup.", "response": "def fire_failed_contact_lookup(self, msisdn):\n        \"\"\"\n        Fires a webhook in the event of a failed WhatsApp contact lookup.\n        \"\"\"\n        payload = {\"address\": msisdn}\n        # We cannot user the raw_hook_event here, because we don't have a user, so we\n        # manually filter and send the hooks for all users\n        hooks = Hook.objects.filter(event=\"whatsapp.failed_contact_check\")\n        for hook in hooks:\n            hook.deliver_hook(\n                None, payload_override={\"hook\": hook.dict(), \"data\": payload}\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the WhatsApp ID for the given MSISDN.", "response": "def get_contact(self, msisdn):\n        \"\"\"\n        Returns the WhatsApp ID for the given MSISDN\n        \"\"\"\n        response = self.session.post(\n            urllib_parse.urljoin(self.api_url, \"/v1/contacts\"),\n            json={\"blocking\": \"wait\", \"contacts\": [msisdn]},\n        )\n        response.raise_for_status()\n        whatsapp_id = response.json()[\"contacts\"][0].get(\"wa_id\")\n        if not whatsapp_id:\n            self.fire_failed_contact_lookup(msisdn)\n        return whatsapp_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a custom HSM with more customizable fields than the send_hsm function.", "response": "def send_custom_hsm(self, whatsapp_id, template_name, language, variables):\n        \"\"\"\n        Sends an HSM with more customizable fields than the send_hsm function\n        \"\"\"\n        data = {\n            \"to\": whatsapp_id,\n            \"type\": \"hsm\",\n            \"hsm\": {\n                \"namespace\": self.hsm_namespace,\n                \"element_name\": template_name,\n                \"language\": {\"policy\": \"deterministic\", \"code\": language},\n                \"localizable_params\": [{\"default\": variable} for variable in variables],\n            },\n        }\n\n        if self.ttl is not None:\n            data[\"ttl\"] = self.ttl\n        response = self.session.post(\n            urllib_parse.urljoin(self.api_url, \"/v1/messages\"), json=data\n        )\n        return self.return_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_data(self):\n        try:\n            df = self.live_quote_arg_func(self.tickers)\n            for index, ticker in enumerate(self.tickers):\n                ticker_info = df.loc[index]\n                self.ticker_dict[ticker].append(ticker_info['price'],\n                                                ticker_info['volume'],\n                                                ticker_info['amount'],\n                                                ticker_info['time'])\n        except Exception:\n            raise ValueError('Polling thread exception')", "response": "Load data from live quote"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_departures(self, stop_id, route, destination, api_key):\n        self.stop_id = stop_id\n        self.route = route\n        self.destination = destination\n        self.api_key = api_key\n\n        # Build the URL including the STOP_ID and the API key\n        url = \\\n            'https://api.transport.nsw.gov.au/v1/tp/departure_mon?' \\\n            'outputFormat=rapidJSON&coordOutputFormat=EPSG%3A4326&' \\\n            'mode=direct&type_dm=stop&name_dm=' \\\n            + self.stop_id \\\n            + '&departureMonitorMacro=true&TfNSWDM=true&version=10.2.1.42'\n        auth = 'apikey ' + self.api_key\n        header = {'Accept': 'application/json', 'Authorization': auth}\n\n        # Send query or return error\n        try:\n            response = requests.get(url, headers=header, timeout=10)\n        except:\n            logger.warning(\"Network or Timeout error\")\n            return self.info\n\n        # If there is no valid request\n        if response.status_code != 200:\n            logger.warning(\"Error with the request sent; check api key\")\n            return self.info\n\n        # Parse the result as a JSON object\n        result = response.json()\n\n        # If there is no stop events for the query\n        try:\n            result['stopEvents']\n        except KeyError:\n            logger.warning(\"No stop events for this query\")\n            return self.info\n\n        # Set variables\n        maxresults = 1\n        monitor = []\n        if self.destination != '':\n            for i in range(len(result['stopEvents'])):\n                destination = result['stopEvents'][i]['transportation']['destination']['name']\n                if destination == self.destination:\n                    event = self.parseEvent(result, i)\n                    if event != None:\n                        monitor.append(event)\n                    if len(monitor) >= maxresults:\n                        # We found enough results, lets stop\n                        break\n        elif self.route != '':\n            # Find the next stop events for a specific route\n            for i in range(len(result['stopEvents'])):\n                number = result['stopEvents'][i]['transportation']['number']\n                if number == self.route:\n                    event = self.parseEvent(result, i)\n                    if event != None:\n                        monitor.append(event)\n                    if len(monitor) >= maxresults:\n                        # We found enough results, lets stop\n                        break\n        else:\n            # No route defined, find any route leaving next\n            for i in range(0, maxresults):\n                event = self.parseEvent(result, i)\n                if event != None:\n                    monitor.append(event)\n        if monitor:\n            self.info = {\n                ATTR_STOP_ID: self.stop_id,\n                ATTR_ROUTE: monitor[0][0],\n                ATTR_DUE_IN: monitor[0][1],\n                ATTR_DELAY: monitor[0][2],\n                ATTR_REALTIME: monitor[0][5],\n                ATTR_DESTINATION: monitor[0][6],\n                ATTR_MODE: monitor[0][7]\n                }\n        return self.info", "response": "Get the latest data from Transport NSW."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseEvent(self, result, i):\n        fmt = '%Y-%m-%dT%H:%M:%SZ'\n        due = 0\n        delay = 0\n        real_time = 'n'\n        number = result['stopEvents'][i]['transportation']['number']\n        planned = datetime.strptime(result['stopEvents'][i]\n            ['departureTimePlanned'], fmt)\n        destination = result['stopEvents'][i]['transportation']['destination']['name']\n        mode = self.get_mode(result['stopEvents'][i]['transportation']['product']['class'])\n        estimated = planned\n        if 'isRealtimeControlled' in result['stopEvents'][i]:\n            real_time = 'y'\n            estimated = datetime.strptime(result['stopEvents'][i]\n                ['departureTimeEstimated'], fmt)\n        # Only deal with future leave times\n        if estimated > datetime.utcnow():\n            due = self.get_due(estimated)\n            delay = self.get_delay(planned, estimated)\n            return[\n                number,\n                due,\n                delay,\n                planned,\n                estimated,\n                real_time,\n                destination,\n                mode\n                ]\n        else:\n            return None", "response": "Parse the current event and extract data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_delay(self, planned, estimated):\n        delay = 0                   # default is no delay\n        if estimated >= planned:    # there is a delay\n            delay = round((estimated - planned).seconds / 60)\n        else:                       # leaving earlier\n            delay = round((planned - estimated).seconds / 60) * -1\n        return delay", "response": "Get the minimum delay on planned departure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_ethereum_client(uri, timeout=60, *, loop=None):\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    presult = urlparse(uri)\n    if presult.scheme in ('ipc', 'unix'):\n        reader, writer = yield from asyncio.open_unix_connection(presult.path,\n                                                                 loop=loop)\n        return AsyncIOIPCClient(reader, writer, uri, timeout, loop=loop)\n    elif presult.scheme in ('http', 'https'):\n        tls = presult.scheme[-1] == 's'\n        netloc = presult.netloc.split(':')\n        host = netloc.pop(0)\n        port = netloc.pop(0) if netloc else (443 if tls else 80)\n        return AsyncIOHTTPClient(host, port, tls, timeout, loop=loop)\n    else:\n        raise RuntimeError('This scheme does not supported.')", "response": "Create client to ethereum node based on schema."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_alarms():\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = Alarms(LOOP, session, IPADDRESS)\n        await ghlocalapi.get_alarms()\n\n        print(\"Alarms:\", ghlocalapi.alarms)", "response": "Get alarms and timers from GH."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_0x(string):\n    if isinstance(string, bytes):\n        string = string.decode('utf-8')\n    return '0x' + str(string)", "response": "Add 0x to string at start."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nguesses the optimal depth to use for the given packages.", "response": "def guess_depth(packages):\n    \"\"\"\n    Guess the optimal depth to use for the given list of arguments.\n\n    Args:\n        packages (list of str): list of packages.\n\n    Returns:\n        int: guessed depth to use.\n    \"\"\"\n    if len(packages) == 1:\n        return packages[0].count('.') + 2\n    return min(p.count('.') for p in packages) + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print(self, format=TEXT, output=sys.stdout, **kwargs):\n        if format is None:\n            format = TEXT\n        if format == TEXT:\n            print(self._to_text(**kwargs), file=output)\n        elif format == CSV:\n            print(self._to_csv(**kwargs), file=output)\n        elif format == JSON:\n            print(self._to_json(**kwargs), file=output)", "response": "Print the object in a file or on standard output by default."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_training_data(self,\n            positive_corpus_file=os.path.join(os.path.dirname(__file__),\n                \"positive.txt\"),\n            negative_corpus_file=os.path.join(os.path.dirname(__file__),\n                \"negative.txt\")\n            ):\n        \"\"\"\n        This method imports the positive and negative training data from the\n        two corpus files and creates the training data list. \n        \"\"\"\n\n        positive_corpus = open(positive_corpus_file)\n        negative_corpus = open(negative_corpus_file)\n\n        # for line in positive_corpus: \n        #     self.training_data.append((line, True))\n\n        # for line in negative_corpus: \n        #     self.training_data.append((line, False))\n\n        # The following code works. Need to profile this to see if this is an\n        # improvement over the code above. \n        positive_training_data = list(map(lambda x: (x, True), positive_corpus))\n        negative_training_data = list(map(lambda x: (x, False), negative_corpus))\n        self.training_data = positive_training_data + negative_training_data", "response": "This method imports the positive and negative training data from the two corpus files and creates the training data list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef train(self): \n        if not self.training_data: \n            self.import_training_data()\n        training_feature_set = [(self.extract_features(line), label) \n                                    for (line, label) in self.training_data]\n        self.classifier = nltk.NaiveBayesClassifier.train(training_feature_set)", "response": "This method generates the classifier for the current nltk. NaiveBayesClassifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_features(self, phrase):\n        \n        words = nltk.word_tokenize(phrase)\n        features = {}\n        for word in words:\n            features['contains(%s)' % word] = (word in words)\n        return features", "response": "This function will extract features from the phrase being used. It will extract the unigrams of the text corpus."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the classifier to a file.", "response": "def save(self, filename='classifier.dump'):\n        \"\"\"\n        Pickles the classifier and dumps it into a file\n        \"\"\"\n        ofile = open(filename,'w+')\n        pickle.dump(self.classifier, ofile)\n        ofile.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the classifier used by this instance", "response": "def load(self, filename='classifier.dump'):\n        \"\"\"\n        Unpickles the classifier used\n        \"\"\"\n        ifile = open(filename, 'r+')\n        self.classifier = pickle.load(ifile)\n        ifile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pw(\n    ctx,\n    key_pattern,\n    user_pattern,\n    mode,\n    strict_flag,\n    user_flag,\n    file,\n    edit_subcommand,\n    gen_subcommand,\n):\n    \"\"\"Search for USER and KEY in GPG-encrypted password file.\"\"\"\n\n    # install silent Ctrl-C handler\n    def handle_sigint(*_):\n        click.echo()\n        ctx.exit(1)\n\n    signal.signal(signal.SIGINT, handle_sigint)\n\n    # invoke a subcommand?\n    if gen_subcommand:\n        length = int(key_pattern) if key_pattern else None\n        generate_password(mode, length)\n        return\n    elif edit_subcommand:\n        launch_editor(ctx, file)\n        return\n\n    # verify that database file is present\n    if not os.path.exists(file):\n        click.echo(\"error: password store not found at '%s'\" % file, err=True)\n        ctx.exit(1)\n\n    # load database\n    store = Store.load(file)\n\n    # if no user query provided, split key query according to right-most \"@\" sign (since usernames are typically email addresses)\n    if not user_pattern:\n        user_pattern, _, key_pattern = key_pattern.rpartition(\"@\")\n\n    # search database\n    results = store.search(key_pattern, user_pattern)\n    results = list(results)\n\n    # if strict flag is enabled, check that precisely a single record was found\n    if strict_flag and len(results) != 1:\n        click.echo(\n            \"error: multiple or no records found (but using --strict flag)\", err=True\n        )\n        ctx.exit(2)\n\n    # raw mode?\n    if mode == Mode.RAW:\n        for entry in results:\n            click.echo(entry.user if user_flag else entry.password)\n        return\n\n    # print results\n    for idx, entry in enumerate(results):\n        # start with key and user\n        line = highlight_match(key_pattern, entry.key)\n        if entry.user:\n            line += \": \" + highlight_match(user_pattern, entry.user)\n\n        # add password or copy&paste sucess message\n        if mode == Mode.ECHO and not user_flag:\n            line += \" | \" + style_password(entry.password)\n        elif mode == Mode.COPY and idx == 0:\n            try:\n                import pyperclip\n\n                pyperclip.copy(entry.user if user_flag else entry.password)\n                result = style_success(\n                    \"*** %s COPIED TO CLIPBOARD ***\"\n                    % (\"USERNAME\" if user_flag else \"PASSWORD\")\n                )\n            except ImportError:\n                result = style_error('*** PYTHON PACKAGE \"PYPERCLIP\" NOT FOUND ***')\n            line += \" | \" + result\n\n        # add notes\n        if entry.notes:\n            if idx == 0:\n                line += \"\\n\"\n                line += \"\\n\".join(\"   \" + line for line in entry.notes.splitlines())\n            else:\n                lines = entry.notes.splitlines()\n                line += \" | \" + lines[0]\n                if len(lines) > 1:\n                    line += \" (...)\"\n        click.echo(line)", "response": "Search for USER and KEY in GPG - encrypted password file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef launch_editor(ctx, file):\n    # do not use EDITOR environment variable (rather force user to make a concious choice)\n    editor = os.environ.get(\"PW_EDITOR\")\n    if not editor:\n        click.echo(\"error: no editor set in PW_EDITOR environment variables\")\n        ctx.exit(1)\n\n    # verify that database file is present\n    if not os.path.exists(file):\n        click.echo(\"error: password store not found at '%s'\" % file, err=True)\n        ctx.exit(1)\n\n    # load source (decrypting if necessary)\n    is_encrypted = _gpg.is_encrypted(file)\n    if is_encrypted:\n        original = _gpg.decrypt(file)\n    else:\n        original = open(file, \"rb\").read()\n\n    # if encrypted, determine recipient\n    if is_encrypted:\n        recipient = os.environ.get(\"PW_GPG_RECIPIENT\")\n        if not recipient:\n            click.echo(\n                \"error: no recipient set in PW_GPG_RECIPIENT environment variables\"\n            )\n            ctx.exit(1)\n\n    # launch the editor\n    ext = _gpg.unencrypted_ext(file)\n    modified = click.edit(\n        original.decode(\"utf-8\"), editor=editor, require_save=True, extension=ext\n    )\n    if modified is None:\n        click.echo(\"not modified\")\n        return\n    modified = modified.encode(\"utf-8\")\n\n    # not encrypted? simply overwrite file\n    if not is_encrypted:\n        with open(file, \"wb\") as fp:\n            fp.write(modified)\n        return\n\n    # otherwise, the process is somewhat more complicated\n    _gpg.encrypt(recipient=recipient, dest_path=file, content=modified)", "response": "launch editor with decrypted password database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_password(mode, length):\n    # generate random password\n    r = random.SystemRandom()\n    length = length or RANDOM_PASSWORD_DEFAULT_LENGTH\n    password = \"\".join(r.choice(RANDOM_PASSWORD_ALPHABET) for _ in range(length))\n\n    # copy or echo generated password\n    if mode == Mode.ECHO:\n        click.echo(style_password(password))\n    elif mode == Mode.COPY:\n        try:\n            import pyperclip\n\n            pyperclip.copy(password)\n            result = style_success(\"*** PASSWORD COPIED TO CLIPBOARD ***\")\n        except ImportError:\n            result = style_error('*** PYTHON PACKAGE \"PYPERCLIP\" NOT FOUND ***')\n        click.echo(result)\n    elif mode == Mode.RAW:\n        click.echo(password)", "response": "generate a random password"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_argv_schema(data, arg_names=None, arg_abbrevs=None, filters=None, defaults=None):\n    '''\n    to_argv_schema(instructions) yields a valid tuple of CommandLineParser instructions for the\n      given instructions tuple; by itself, this will only return the instructions as they are, but\n      optional arguments (below) will override the values in the instructions if provided.\n    to_argv_schema(plan) yields a valid tuple of CommandLineParser instructions for the given plan\n      object.\n\n    These schema returned by this function will parse a command-line list (sys.argv) for parameters\n    either listed in the instructions (see help(CommandLineParser)) or the afferent parameters of\n    the plan. Generally, this should be called by the argv_parse() function and not directly.\n\n    If a plan is given as the first argument, then the following rules are used to determine how\n    arguments are parsed:\n      * An argument that begins with -- (e.g., --quux-factor=10) is checked for a matching\n        plan parameter; the argument name \"quux-factor\" will match either a parameter called\n        \"quux-factor\" or \"quux_factor\" (dashes in command-line arguments are auto-translated\n        into underscores).\n      * If \"quux_factor\" is a parameter to the plan and is the only parameter that starts with a\n        'q', then -q10 or -q 10 are both equivalent to --quux-factor=10. If other parameters\n        also start with a 'q' then neither \"quux_factor\" or the other parameter(s) will be\n        matched with the -q flag unless it is specified explicitly via the arg_abbrevs option.\n      * Argument values are parsed using Python's ast.literal_eval(); if this raises an\n        exception then the value is left as a string.\n      * If an argument or flag is provided without an argument (e.g. \"--quuxztize\" or \"-q\") then\n        it is interpreted as a boolean flag and is given the value True.\n      * Arguments that come after the flag \"--\" are never processed.\n\n    The following options may be given:\n      * arg_names (default: None) may be a dictionary that specifies explicity command-line\n        argument names for the plan parameters; plan parameters should be keys and the argument\n        names should be values. Any parameter not listed in this option will be interpreted\n        according to the above rules. If a parameter is mapped to None then it will not be\n        filled from the command-line arguments.\n      * arg_abbrevs (default:None) may be a dictionary that is handled identically to that of\n        arg_names except that its values must be single letters, which are used for the\n        abbreviated flag names.\n      * defaults (default: None) may specify the default values for the plan parameters; this\n        dictionary overrides the default values of the plan itself.\n    '''\n    if is_plan(data):\n        # First we must convert it to a valid instruction list\n        (plan, data) = (data, {})\n        # we go through the afferent parameters...\n        for aff in plan.afferents:\n            # these are provided by the parsing mechanism and shouldn't be processed\n            if aff in ['argv', 'argv_parsed', 'stdout', 'stderr', 'stdin']: continue\n            # we ignore defaults for now\n            data[aff] = (None, aff.replace('_', '-'), aff)\n        # and let's try to guess at abbreviation names\n        entries = sorted(data.keys())\n        n = len(entries)\n        for (ii,entry) in enumerate(entries):\n            if ii > 0   and entry[0] == entries[ii-1][0]: continue\n            if ii < n-1 and entry[0] == entries[ii+1][0]: continue\n            r = data[entry]\n            data[entry] = (entry[0], r[1], entry, r[3]) if len(r) == 4 else (entry[0], r[1], entry)\n        # now go through and fix defaults...\n        for (entry,dflt) in six.iteritems(plan.defaults):\n            if entry not in data: continue\n            r = data[entry]\n            data[entry] = (r[0], r[1], r[2], dflt)\n    elif arg_names is None and arg_abbrevs is None and defaults is None:\n        # return the same object if there are no changes to a schema\n        return data\n    else:\n        data = {r[2]:r for r in data}\n    # Now we go through and make updates based on the optional arguments\n    if arg_names is None: arg_names = {}\n    for (entry,arg_name) in six.iteritems(arg_names):\n        if entry not in data: continue\n        r = data[entry]\n        data[entry] = (r[0], arg_name, entry) if len(r) == 3 else (r[0], arg_name, entry, r[3])\n    if arg_abbrevs is None: arg_abbrevs = {}\n    for (entry,arg_abbrev) in six.iteritems(arg_abbrevs):\n        if entry not in data: continue\n        r = data[entry]\n        data[entry] = (arg_abbrev, r[1], entry) if len(r) == 3 else (arg_abbrev, r[1], entry, r[3])\n    if defaults is None: defaults = {}\n    for (entry,dflt) in six.iteritems(defaults):\n        if entry not in data: continue\n        r = data[entry]\n        data[entry] = (r[0], r[1], entry, dflt)\n    # return the list-ified version of this\n    return [tuple(row) for row in six.itervalues(data)]", "response": "Parse the given data into a tuple of CommandLineParser arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef argv_parser(instructs,\n                arg_names=None, arg_abbrevs=None, defaults=None,\n                value_parser=True, filters=None):\n    '''\n    argv_parser(instructions) is equivalent to CommandLineParser(instructions).\n    argv_parser(plan) is equivalent to CommandLineParser(plan_to_argv_instructions(plan)).\n\n    See also help(CommandLineParser) and help(to_argv_schema); all optional arguments accepted by\n    these functions are passed along by argv_parser.\n\n    See also help(argv_parse), which is the recommended interface for parsing command-line\n    arguments.\n    '''\n    schema = to_argv_schema(instructs,\n                            arg_names=arg_names, arg_abbrevs=arg_abbrevs, defaults=defaults)\n    return CommandLineParser(schema, value_parser=value_parser, filters=filters)", "response": "A wrapper around to_argv_schema that takes a list of INDRA IN D IN D IN D IN D IN DAGS and a list of INDRA INDRA"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef argv_parse(schema, argv, init=None,\n               arg_names=None, arg_abbrevs=None, value_parser=True, defaults=None, filters=None):\n    '''\n    argv_parse(schema, argv) yields the tuple (unparsed_argv, params) where unparsed_argv is a list\n      subset of argv that contains only those command line arguments that were not understood by\n      the given argument schema and params is a dictionary of parameters as parsed by the given \n      schema. It is equivalent to argv_parser(schema)(argv). See also help(CommandLineParser) for\n      information about the instructions format.\n    argv_parse(plan, argv) yields a pimms IMap object whose parameters have been initialized from\n      the arguments in argv using the given pimms calculation plan as a template for the argument\n      schema; see help(to_argv_schema) for information about the way plans are interpreted as argv\n      schemas. The plan is initialized with the additional parameters 'argv' and 'argv_parsed'. The\n      'argv' parameter contains the command-line arguments in argv that were not interpreted by the\n      command-line parser; the 'argv_parsed' parameter contains the parsed command-line parameters.\n      To avoid the plan-specific behavior and instead only parse the arguments from a plan, use\n      argv_parse(to_argv_schema(plan), argv).\n\n    The following options may be given:\n      * init (default: None) specifies that the given dictionary should be merged into either the\n        resulting options dictionary (if schema is a schema and not a plan) or into the parameters\n        initially provided to the plan (if schema is a plan).\n      * arg_names (default: None) may be a dictionary that specifies explicity command-line\n        argument names for the plan parameters; plan parameters should be keys and the argument\n        names should be values. Any parameter not listed in this option will be interpreted\n        according to the above rules. If a parameter is mapped to None then it will not be\n        filled from the command-line arguments.\n      * arg_abbrevs (default:None) may be a dictionary that is handled identically to that of\n        arg_names except that its values must be single letters, which are used for the\n        abbreviated flag names.\n      * defaults (default: None) may specify the default values for the plan parameters; this\n        dictionary overrides the default values of the plan itself.\n      * value_parse (default: True) specifies whether the values are interpreted via the\n        ast.literal_eval() function. This may be set to False to leave the values as strings or it\n        may be set to a function that takes one argument and performs the parsing itself; such a\n        function f must obey the syntax `parsed_val = f(string_val)`. The value_parse function is\n        only called on arguments that have string values included. Note that by default the\n        value_parse function interprets the string '...' as Ellipsis in addition to the typical\n        ast.literal_eval() behavior.\n      * filters (default: None) optionally specifies a dictionary of filter functions, each of which\n        is passed the parsed value of the associated argument. Each filter function f must obey the\n        syntax `final_value = f(parsed_value)`. The keys of this dictionary must be the entry names\n        of the arguments. Note that filter functions are called on provided default values but the\n        value_parse function is not called on these.\n    '''\n    parser = argv_parser(schema,\n                         arg_names=arg_names, arg_abbrevs=arg_abbrevs, defaults=defaults,\n                         value_parser=value_parser, filters=filters)\n    res = parser(argv)\n    if is_plan(schema):\n        init = {} if init is None else init\n        init = pyr.pmap(init) if not is_pmap(init) else init\n        return schema({'argv': tuple(res[0]), 'argv_parsed': pyr.pmap(res[1])}, res[1], init)\n    else:\n        return res if init is None else (res[0], dict(merge(res[1], init)))", "response": "Parses the given command - line arguments into a pimms IMap object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a WorkLog object that formats output to a number of columns.", "response": "def worklog(columns=None, bullet='  * ', stdout=Ellipsis, stderr=Ellipsis, verbose=False):\n    '''\n    worklog() yields a worklog object using sys.stdout and sys.stderr as the outputs.\n    worklog(n) yields a worklog that formats output to n columns.\n\n    The following options may be give:\n      * bullet (default: '  * ') the bullet-text to print for each bullet.\n      * stdout (default: Ellipsis) the file to use in place of stdout; if None, no stdout is\n        printed; if Ellipsis, then is set to sys.stdout if verbose is True and None otherwise.\n      * stderr (default: Ellipsis) the file to use in place of stderr; if None, no stderr is\n        printed; if Ellipsis, then is set to sys.stderr.\n      * verbose (default: False) specifies whether to use verbose output. This only has an effect\n        if the stdout option is Ellipsis.\n    '''\n    if columns is None:\n        try: columns = int(os.environ['COLUMNS'])\n        except: columns = 80\n    if stdout is Ellipsis:\n        if verbose: stdout = sys.stdout\n        else: stdout = None\n    return WorkLog(columns=columns, bullet=bullet, stdout=stdout, stderr=stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new WorkLog with the same columns and indentation.", "response": "def indent(self, n=1):\n        '''\n        worklog.indent() yields a duplicate worklog that is indented relative to worklog.\n        worklog.indent(x) indents x times.\n        '''\n        return WorkLog(columns=self.columns,\n                       bullet=(self.blanks + self.bullet),\n                       stdout=self.stdout, stderr=self.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump2sqlite(records, output_file):\n    results_keys = list(records.results[0].keys())\n    pad_data = []\n\n    for key in REQUIRED_KEYS:\n        if key not in results_keys:\n            results_keys.append(key)\n            pad_data.append(\"\")\n\n    conn = sqlite3.connect(os.path.expanduser(output_file), detect_types=sqlite3.PARSE_DECLTYPES)\n\n    # in each row there needs to be data for every column\n    # last column is current time\n    pad_data.append(datetime.datetime.utcnow())\n\n    to_db = [list(row.values()) + pad_data for row in records.results]\n\n    cur = conn.cursor()\n    cur.execute(\n        \"CREATE TABLE testcases ({},sqltime TIMESTAMP)\".format(\n            \",\".join(\"{} TEXT\".format(key) for key in results_keys)\n        )\n    )\n    cur.executemany(\n        \"INSERT INTO testcases VALUES ({},?)\".format(\",\".join([\"?\"] * len(results_keys))), to_db\n    )\n\n    if records.testrun:\n        cur.execute(\"CREATE TABLE testrun (testrun TEXT)\")\n        cur.execute(\"INSERT INTO testrun VALUES (?)\", (records.testrun,))\n\n    conn.commit()\n    conn.close()\n\n    logger.info(\"Data written to '%s'\", output_file)", "response": "Dumps testcases results to database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(args=None):\n    args = get_args(args)\n\n    utils.init_log(args.log_level)\n\n    if \".csv\" not in args.input_file.lower():\n        logger.warning(\"Make sure the input file '%s' is in CSV format\", args.input_file)\n\n    try:\n        records = csvtools.get_imported_data(args.input_file)\n    except (EnvironmentError, Dump2PolarionException) as err:\n        logger.fatal(err)\n        return 1\n\n    # check if all columns required by `pytest_polarion_cfme` are there\n    required_columns = {\"id\": \"ID\", \"title\": \"Title\"}\n    missing_columns = [required_columns[k] for k in required_columns if k not in records.results[0]]\n    if missing_columns:\n        logger.fatal(\n            \"The input file '%s' is missing following columns: %s\",\n            args.input_file,\n            \", \".join(missing_columns),\n        )\n        return 1\n\n    try:\n        dump2sqlite(records, args.output_file)\n    # pylint: disable=broad-except\n    except Exception as err:\n        logger.exception(err)\n        return 1\n\n    return 0", "response": "Main function for cli."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit the algorithm to find the minimum energy between k clusters.", "response": "def fit(sim_mat, D_len, cidx):\n    \"\"\"\n    Algorithm maximizes energy between clusters, which is distinction in this algorithm. Distance matrix contains mostly 0, which are overlooked due to search of maximal distances. Algorithm does not try to retain k clusters.\n\n    D: numpy array - Symmetric distance matrix\n    k: int - number of clusters\n    \"\"\"\n\n    min_energy = np.inf\n    for j in range(3):\n        # select indices in each sample that maximizes its dimension\n        inds = [np.argmin([sim_mat[idy].get(idx, 0) for idx in cidx]) for idy in range(D_len) if idy in sim_mat]\n\n        cidx = []\n        energy = 0  # current enengy\n        for i in np.unique(inds):\n            indsi = np.where(inds == i)[0]  # find indices for every cluster\n\n            minind, min_value = 0, 0\n            for index, idy in enumerate(indsi):\n                if idy in sim_mat:\n                    # value = sum([sim_mat[idy].get(idx,0) for idx in indsi])\n                    value = 0\n                    for idx in indsi:\n                        value += sim_mat[idy].get(idx, 0)\n                    if value < min_value:\n                        minind, min_value = index, value\n            energy += min_value\n            cidx.append(indsi[minind])  # new centers\n\n        if energy < min_energy:\n            min_energy, inds_min, cidx_min = energy, inds, cidx\n\n    return inds_min, cidx_min"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output(*args, **kwargs):\n    '''Analog of print() but with an indent option\n    '''\n    indent = kwargs.pop('indent', 0)\n    sep = kwargs.pop('sep', None)\n    kwargs['sep'] = u''  # Sanity\n    if sep is None:\n        sep = u' '\n    indent_str = u' ' * (indent * tab_width)\n    text = sep.join(map(str_, args))\n    color = kwargs.pop('color', None)\n    if color:\n        color.bright = kwargs.pop('bright', None)\n        text = ColorText(text, color)\n    print(indent_str + text, **kwargs)", "response": "Analog of print but with an indent option\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calc_theta(self):\n        if self.decaying_prior:\n            n_sampled = np.clip(self.alpha_ + self.beta_, 1, np.inf)\n            prior_weight = 1/n_sampled\n            alpha = self.alpha_ + prior_weight * self.alpha_0\n            beta = self.beta_ + prior_weight * self.beta_0\n        else:\n            alpha = self.alpha_ + self.alpha_0\n            beta = self.beta_ + self.beta_0\n\n        # Mean of Beta-distributed rv\n        self.theta_ = alpha / (alpha + beta)\n\n        # NEW: calculate theta assuming weak prior\n        if self.store_wp:\n            alpha = self.alpha_ + self._wp_weight * self.alpha_0\n            beta = self.beta_ + self._wp_weight * self.beta_0\n            self.theta_wp_ = alpha / (alpha + beta)", "response": "Calculate an estimate of theta"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calc_var_theta(self):\n        if self.decaying_prior:\n            n_sampled = np.clip(self.alpha_ + self.beta_, 1, np.inf)\n            prior_weight = 1/n_sampled\n            alpha = self.alpha_ + prior_weight * self.alpha_0\n            beta = self.beta_ + prior_weight * self.beta_0\n        else:\n            alpha = self.alpha_ + self.alpha_0\n            beta = self.beta_ + self.beta_0\n        # Variance of Beta-distributed rv\n        self.var_theta_ = ( alpha * beta /\n                            ((alpha + beta)**2 * (alpha + beta + 1)) )", "response": "Calculate an estimate of the var ( theta )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, ell, k):\n        self.alpha_[k] += ell\n        self.beta_[k] += 1 - ell\n\n        self._calc_theta()\n        if self.store_variance:\n            self._calc_var_theta()", "response": "Update the posterior and estimates after a label is sampled\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self):\n        self.alpha_ = np.zeros(self._size, dtype=int)\n        self.beta_ = np.zeros(self._size, dtype=int)\n        self.theta_ = np.empty(self._size, dtype=float)\n        if self.store_variance:\n            self.var_theta_ = np.empty(self._size, dtype=float)\n        if self.store_wp:\n            self.theta_wp_ = np.empty(self._size, dtype=float)\n\n        self._calc_theta()\n        if self.store_variance:\n            self._calc_var_theta()", "response": "Reset the instance to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sample_item(self, **kwargs):\n        t = self.t_\n\n        # Update instrumental distribution\n        self._calc_inst_pmf()\n\n        if self.record_inst_hist:\n            inst_pmf = self._inst_pmf[:,t]\n        else:\n            inst_pmf = self._inst_pmf\n\n        # Sample label and record weight\n        loc, stratum_idx = self.strata.sample(pmf = inst_pmf)\n        weight = self.strata.weights_[stratum_idx]/inst_pmf[stratum_idx]\n\n        return loc, weight, {'stratum': stratum_idx}", "response": "Sample an item from the pool according to the instrumental distribution\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate a prior for the BB model.", "response": "def _calc_BB_prior(self, theta_0):\n        \"\"\"Generate a prior for the BB model\n\n        Parameters\n        ----------\n        theta_0 : array-like, shape=(n_strata,)\n            array of oracle probabilities (probability of a \"1\" label)\n            for each stratum. This is just a guess.\n\n        Returns\n        -------\n        alpha_0 : numpy.ndarray, shape=(n_strata,)\n            \"alpha\" hyperparameters for an ensemble of Beta-distributed rvs\n\n        beta_0 : numpy.ndarray, shape=(n_strata,)\n            \"beta\" hyperparameters for an ensemble of Beta-distributed rvs\n        \"\"\"\n        #: Easy vars\n        prior_strength = self.prior_strength\n\n        #weighted_strength = self.weights * strength\n        n_strata = len(theta_0)\n        weighted_strength = prior_strength / n_strata\n        alpha_0 = theta_0 * weighted_strength\n        beta_0 = (1 - theta_0) * weighted_strength\n        return alpha_0, beta_0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates an estimate of the F - measure based on the scores", "response": "def _calc_F_guess(self, alpha, predictions, theta, weights):\n        \"\"\"Calculate an estimate of the F-measure based on the scores\"\"\"\n        num = np.sum(predictions.T * theta * weights, axis=1)\n        den = np.sum((1 - alpha) * theta * weights + \\\n                     alpha * predictions.T * weights, axis=1)\n        F_guess = num/den\n        # Ensure guess is not undefined\n        F_guess[den==0] = 0.5\n        return F_guess"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the epsilon - greedy instrumental distribution of the classifiers of the current object.", "response": "def _calc_inst_pmf(self):\n        \"\"\"Calculate the epsilon-greedy instrumental distribution\"\"\"\n        # Easy vars\n        t = self.t_\n        epsilon = self.epsilon\n        alpha = self.alpha\n        preds = self._preds_avg_in_strata\n        weights = self.strata.weights_[:,np.newaxis]\n        p1 = self._BB_model.theta_[:,np.newaxis]\n        p0 = 1 - p1\n        if t==0:\n            F = self._F_guess[self.opt_class]\n        else:\n            F = self._estimate[t - 1, self.opt_class]\n            # Fill in non-finite estimates with the initial guess\n            nonfinite = ~np.isfinite(F)\n            F[nonfinite] = self._F_guess[self.opt_class][nonfinite]\n\n        # Calculate optimal instrumental pmf\n        sqrt_arg = np.sum(preds * (alpha**2 * F**2 * p0 + (1 - F)**2 * p1) + \\\n                          (1 - preds) * (1 - alpha)**2 * F**2 * p1, \\\n                          axis=1, keepdims=True) #: sum is over classifiers\n        inst_pmf = weights * np.sqrt(sqrt_arg)\n        # Normalize\n        inst_pmf /= np.sum(inst_pmf)\n        # Epsilon-greedy: (1 - epsilon) q + epsilon * p\n        inst_pmf *= (1 - epsilon)\n        inst_pmf += epsilon * weights\n\n        if self.record_inst_hist:\n            self._inst_pmf[:,t] = inst_pmf.ravel()\n        else:\n            self._inst_pmf = inst_pmf.ravel()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the sampler to its initial state", "response": "def reset(self):\n        \"\"\"Resets the sampler to its initial state\n\n        Note\n        ----\n        This will destroy the label cache, instrumental distribution and\n        history of estimates.\n        \"\"\"\n        super(OASISSampler, self).reset()\n        self.strata.reset()\n        self._BB_model.reset()\n\n        # Array to record history of instrumental distributions\n        if self.record_inst_hist:\n            self._inst_pmf = np.zeros([self.strata.n_strata_, self._max_iter],\n                                      dtype=float)\n        else:\n            self._inst_pmf = np.zeros(self.strata.n_strata_, dtype=float)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the numerical value of token. value if it is a number", "response": "def numval(token):\n    \"\"\"Return the numerical value of token.value if it is a number\"\"\"\n    if token.type == 'INTEGER':\n        return int(token.value)\n    elif token.type == 'FLOAT':\n        return float(token.value)\n    else:\n        return token.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tokenize(code):\n    tok_regex = '|'.join('(?P<{}>{})'.format(*pair) for pair in _tokens)\n    tok_regex = re.compile(tok_regex, re.IGNORECASE|re.M)\n    line_num = 1\n    line_start = 0\n    for mo in re.finditer(tok_regex, code):\n        kind = mo.lastgroup\n        value = mo.group(kind)\n        if kind == 'NEWLINE':\n            line_start = mo.end()\n            line_num += 1\n        elif kind == 'SKIP' or value=='':\n            pass\n        else:\n            column = mo.start() - line_start\n            yield Token(kind, value, line_num, column)", "response": "Tokenize the string code"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(tokens):\n    d = collections.OrderedDict()\n    prev_line = 0\n    blockname = None\n    blockline = None\n    for token in tokens:\n        if token.type == 'COMMENT':\n            continue\n        elif token.type == 'BLOCK':\n            block = token\n            blockline = token.line\n            blocktype = token.value.upper()\n            blockname = None\n            if blocktype not in d:\n                d[blocktype] = collections.OrderedDict()\n        elif token.line == blockline:\n            if blockname is None:\n                blockname = token.value\n                d[blocktype][blockname] = collections.defaultdict(list)\n            else:\n                d[blocktype][blockname]['info'].append(numval(token))\n        elif token.line != prev_line:\n            if blockname is None:\n                raise ParseError(\"Found value outside block!\")\n            d[blocktype][blockname]['values'].append([numval(token)])\n        else:\n            if blockname is None:\n                raise ParseError(\"Found value outside block!\")\n            d[blocktype][blockname]['values'][-1].append(numval(token))\n        prev_line = token.line\n    return d", "response": "Parse the token list into a hierarchical data structure"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(stream):\n    if isinstance(stream, str):\n        string = stream\n    else:\n        string = stream.read()\n    tokens = tokenize(string)\n    return parse(tokens)", "response": "Parse the LHA document and produce the corresponding Python object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a parser for the subcommands defined in the module.", "response": "def build_subcommands_parser(parser, module):\n    \"\"\"\n    Returns a parser for the subcommands defined in the *module*\n    (i.e. commands starting with a 'pub_' prefix).\n    \"\"\"\n    mdefs = module.__dict__\n    keys = list(mdefs.keys())\n    keys.sort()\n    subparsers = parser.add_subparsers(help='sub-command help')\n    for command in keys:\n        if command.startswith('pub_'):\n            func = module.__dict__[command]\n            parser = subparsers.add_parser(command[4:], help=func.__doc__)\n            parser.set_defaults(func=func)\n            argspec = inspect.getargspec(func)\n            flags = len(argspec.args)\n            if argspec.defaults:\n                flags = len(argspec.args) - len(argspec.defaults)\n            if flags >= 1:\n                for arg in argspec.args[:flags - 1]:\n                    parser.add_argument(arg)\n                parser.add_argument(argspec.args[flags - 1], nargs='*')\n            short_opts = set([])\n            for idx, arg in enumerate(argspec.args[flags:]):\n                arg = arg.replace('_', '-')\n                short_opt = arg[0]\n                if not (arg.startswith('no') or (short_opt in short_opts)):\n                    opts = ['-%s' % short_opt, '--%s' % arg]\n                else:\n                    opts = ['--%s' % arg]\n                short_opts |= set([short_opt])\n                if isinstance(argspec.defaults[idx], list):\n                    parser.add_argument(*opts, action='append')\n                elif isinstance(argspec.defaults[idx], dict):\n                    parser.add_argument(*opts, type=json.loads)\n                elif argspec.defaults[idx] is False:\n                    parser.add_argument(*opts, action='store_true')\n                elif argspec.defaults[idx] is not None:\n                    parser.add_argument(*opts, default=argspec.defaults[idx])\n                else:\n                    parser.add_argument(*opts)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_subcommand_args(func, options):\n    kwargs = {}\n    argspec = inspect.getargspec(func)\n    for arg in argspec.args:\n        if arg in options:\n            kwargs.update({arg: getattr(options, arg)})\n    return kwargs", "response": "Filter out all options which are not part of the function func * func* and returns a set that can be used as kwargs for calling func."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pub_download(args, location=None, prefix=\"\"):\n    download(location, remotes=args, prefix=prefix)", "response": "Download theme packages from the stage location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pub_upload(args, location=None, prefix=\"\"):\n    upload(location, remotes=args, prefix=prefix)", "response": "Upload theme packages to the stage location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(args):\n    try:\n        import __main__\n        parser = argparse.ArgumentParser(\n            usage='%(prog)s [options] command\\n\\nVersion\\n  %(prog)s version '\n            + str(__version__),\n            formatter_class=argparse.RawTextHelpFormatter)\n        parser.add_argument('--version', action='version',\n                            version='%(prog)s ' + str(__version__))\n        build_subcommands_parser(parser, __main__)\n\n        if len(args) <= 1:\n            parser.print_help()\n            return 1\n\n        options = parser.parse_args(args[1:])\n        # Filter out options with are not part of the function prototype.\n        func_args = filter_subcommand_args(options.func, options)\n        options.func(**func_args)\n\n    except RuntimeError as err:\n        LOGGER.error(err)\n        return err.code", "response": "Main entry point for the\n Arc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_assets():\n    cwd = os.getcwd()\n    try:\n        from webassets.script import GenericArgparseImplementation\n        from django_assets.env import get_env\n        prog = \"%s assets\" % os.path.basename(sys.argv[0])\n        impl = GenericArgparseImplementation(\n            env=get_env(), log=LOGGER, no_global_options=True, prog=prog)\n        impl.run_with_argv([\"build\"])\n    except ImportError:\n        pass\n    os.chdir(cwd)", "response": "Call django_assets. manage. py assets build if the app is present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sample_item(self, **kwargs):\n        if 'fixed_stratum' in kwargs:\n            stratum_idx = kwargs['fixed_stratum']\n        else:\n            stratum_idx = None\n        if stratum_idx is not None:\n            #: Sample in given stratum\n            loc = self.strata._sample_in_stratum(stratum_idx,\n                                                 replace=self.replace)\n        else:\n            loc, stratum_idx = self.strata.sample(pmf = self.strata.weights_,\n                                                  replace=self.replace)\n\n        return loc, 1, {'stratum': stratum_idx}", "response": "Sample an item from the strata"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_estimate_and_sampler(self, ell, ell_hat, weight, extra_info,\n                                     **kwargs):\n        \"\"\"Update the estimate after querying the label for an item\"\"\"\n\n        stratum_idx = extra_info['stratum']\n\n        if 'calc_rates' in kwargs:\n            calc_rates = kwargs['calc_rates']\n        else:\n            calc_rates = True\n\n        self._TP_st[stratum_idx,:] += ell_hat * ell * weight\n        self._PP_st[stratum_idx,:] += ell_hat * weight\n        self._P_st[stratum_idx,:] += ell * weight\n\n        if calc_rates:\n            self._P_rates = self._P_st/self.strata._n_sampled[:,np.newaxis]\n            self._TP_rates = self._TP_st/self.strata._n_sampled[:,np.newaxis]\n            self._PP_rates = self._PP_st/self.strata._n_sampled[:,np.newaxis]\n\n        #: Update model estimate (with prior)\n        self._estimate[self.t_], self._F_num, self._F_den = \\\n            self._calc_estimate(self._TP_rates, self._PP_rates, \\\n                                self._P_rates, return_num_den=True)", "response": "Update the estimate of the model with the new values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self):\n        super(DruckSampler, self).reset()\n        self.strata.reset()\n        self._TP_st = np.zeros([self.strata.n_strata_, self._n_class])\n        self._PP_st = np.zeros([self.strata.n_strata_, self._n_class])\n        self._P_st = np.zeros([self.strata.n_strata_, self._n_class])\n        self._TP_rates = np.zeros([self.strata.n_strata_, self._n_class])\n        self._PP_rates = np.zeros([self.strata.n_strata_, self._n_class])\n        self._P_rates = np.zeros([self.strata.n_strata_, self._n_class])\n\n        for k in self.strata.indices_:\n            for i in range(2):\n                self._iterate(fixed_stratum = k, calc_rates = False)", "response": "Resets the sampler to its initial state"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a checksum based on the IDL that ignores comments and ordering and parameter order and enum values.", "response": "def get_checksum(self):\n        \"\"\"\n        Returns a checksum based on the IDL that ignores comments and \n        ordering, but detects changes to types, parameter order, \n        and enum values.\n        \"\"\"\n        arr = [ ]\n        for elem in self.parsed:\n            s = elem_checksum(elem)\n            if s:\n                arr.append(s)\n        arr.sort()\n        #print arr\n        return md5(json.dumps(arr))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsampling an item from the pool according to the instrumental distribution", "response": "def _sample_item(self, **kwargs):\n        \"\"\"Sample an item from the pool according to the instrumental\n        distribution\n        \"\"\"\n        t = self.t_\n        if 'fixed_stratum' in kwargs:\n            stratum_idx = kwargs['fixed_stratum']\n        else:\n            stratum_idx = None\n        if stratum_idx is not None:\n            # Sample in given stratum\n            loc = self.strata._sample_in_stratum(stratum_idx, replace=False)\n            # Record instrumental distribution\n            if self.record_inst_hist:\n                self.inst_pmf_[stratum_idx,t] = 1\n        else:\n            # Choose stratum based on instrumental distribution\n            self._calc_inst_pmf()\n\n            if self.record_inst_hist:\n                inst_pmf = self.inst_pmf_[:,t]\n            else:\n                inst_pmf = self.inst_pmf_\n\n            loc, stratum_idx = self.strata.sample(pmf = inst_pmf, replace=False)\n\n        return loc, 1, {'stratum': stratum_idx}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_estimate_and_sampler(self, ell, ell_hat, weight, extra_info,\n                                     **kwargs):\n        \"\"\"Update the BB models and the estimates\"\"\"\n        stratum_idx = extra_info['stratum']\n        self._BB_TP.update(ell*ell_hat, stratum_idx)\n        self._BB_PP.update(ell_hat, stratum_idx)\n        self._BB_P.update(ell, stratum_idx)\n\n        # Update model covariance matrix for stratum_idx\n        self._update_cov_model(strata_to_update = [stratum_idx])\n\n        # Update F-measure estimate, estimator variance, exp. variance decrease\n        self._update_estimates()", "response": "Update the BB models P and F - measure estimates and Samples."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_cov_model(self, strata_to_update='all'):\n        if strata_to_update == 'all':\n            strata_to_update = self.strata.indices_\n        #: Otherwise assume strata_to_update is valid (no duplicates etc.)\n\n        #: Update covariance matrices\n        #: We usually update only one stratum at a time, so for loop is ok\n        n_sampled = np.clip(self.strata._n_sampled, 2, np.inf) #: adding 2 avoids undef. cov\n        factor = n_sampled/(n_sampled - 1)\n        for k in strata_to_update:\n            TP = self._BB_TP.theta_[k]\n            PP = self._BB_PP.theta_[k]\n            P = self._BB_P.theta_[k]\n\n            self.cov_model_[k,0,0] = factor[k] * TP * (1 - TP)\n            self.cov_model_[k,0,1] = factor[k] * TP * (1 - PP)\n            self.cov_model_[k,0,2] = factor[k] * TP * (1 - P)\n            self.cov_model_[k,1,1] = factor[k] * PP * (1 - PP)\n            self.cov_model_[k,1,2] = factor[k] * (TP - PP * P)\n            self.cov_model_[k,2,2] = factor[k] * P * (1 - P)\n            self.cov_model_[k,1,0] = self.cov_model_[k,0,1]\n            self.cov_model_[k,2,0] = self.cov_model_[k,0,2]\n            self.cov_model_[k,2,1] = self.cov_model_[k,1,2]", "response": "Update the covariance matrix of the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_path(num):\n        num = int(num)\n        dig_len = len(str(num))\n        paths = []\n        for i in range(dig_len - 2):\n            divisor = 10 ** (dig_len - i - 1)\n            paths.append(\n                \"{}-{}\".format((num // divisor) * divisor, (((num // divisor) + 1) * divisor) - 1)\n            )\n        return \"/\".join(paths)", "response": "Gets a path from the workitem number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget XML tree of the workitem.", "response": "def get_tree(self, work_item_id):\n        \"\"\"Gets XML tree of the workitem.\"\"\"\n        try:\n            __, tcid = work_item_id.split(\"-\")\n        except ValueError:\n            logger.warning(\"Couldn't load workitem %s, bad format\", work_item_id)\n            self._cache[work_item_id] = InvalidObject()\n            return None\n\n        path = os.path.join(self.test_case_dir, self.get_path(tcid), work_item_id, \"workitem.xml\")\n        try:\n            tree = etree.parse(path)\n        # pylint: disable=broad-except\n        except Exception:\n            logger.warning(\"Couldn't load workitem %s\", work_item_id)\n            self._cache[work_item_id] = InvalidObject()\n            return None\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwalking the repo and returns work items.", "response": "def get_all_items(self):\n        \"\"\"Walks the repo and returns work items.\"\"\"\n        for item in os.walk(self.test_case_dir):\n            if \"workitem.xml\" not in item[2]:\n                continue\n            case_id = os.path.split(item[0])[-1]\n            if not (case_id and \"*\" not in case_id):\n                continue\n            item_cache = self[case_id]\n            if not item_cache:\n                continue\n            if not item_cache.get(\"title\"):\n                continue\n            yield item_cache"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all files matching the pattern in the directory", "response": "def _remove_files(self, directory, pattern):\n        '''\n        Removes all files matching the search path\n\n        Arguments:\n        search_path -- The path you would like to remove, can contain wildcards\n\n        Example:\n        self._remove_files(\"output/*.html\")\n        '''\n        for root, dirnames, file_names in os.walk(directory):\n            for file_name in fnmatch.filter(file_names, pattern):\n                os.remove(os.path.join(root, file_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mail2blogger(entry, **kwargs):\n    enabled = blargg_settings.get('mail2blogger', False)\n    recipient = blargg_settings.get('mail2blogger_email', None)\n    if enabled and recipient:\n\n        # Send HTML (and text-only) email\n        msg = EmailMultiAlternatives(\n            entry.title,  # Subject\n            striptags(entry.crossposted_content),  # Text-only\n            settings.DEFAULT_FROM_EMAIL,  # From\n            [recipient]  # List of Recipients\n        )\n        msg.attach_alternative(entry.crossposted_content, \"text/html\")\n        msg.send(fail_silently=True)", "response": "This signal handler sends cross - posts published Entry s to Blogger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_event(message_id, event_type, event_detail, timestamp):\n    # Load message\n    try:\n        message = Outbound.objects.select_related(\"channel\").get(\n            vumi_message_id=message_id\n        )\n    except ObjectDoesNotExist:\n        return (False, \"Cannot find message for ID {}\".format(message_id))\n\n    if event_type == \"ack\":\n        message.delivered = True\n        message.to_addr = \"\"\n        message.metadata[\"ack_timestamp\"] = timestamp\n        message.metadata[\"ack_reason\"] = event_detail\n        message.save(update_fields=[\"delivered\", \"to_addr\", \"metadata\"])\n    elif event_type == \"nack\":\n        message.metadata[\"nack_timestamp\"] = timestamp\n        message.metadata[\"nack_reason\"] = event_detail\n        message.save(update_fields=[\"metadata\"])\n\n        decr_message_count(message)\n\n        send_message.delay(str(message.id))\n    elif event_type == \"delivery_succeeded\":\n        message.delivered = True\n        message.to_addr = \"\"\n        message.metadata[\"delivery_timestamp\"] = timestamp\n        message.metadata[\"delivery_reason\"] = event_detail\n        message.save(update_fields=[\"delivered\", \"metadata\", \"to_addr\"])\n    elif event_type == \"delivery_failed\":\n        message.metadata[\"delivery_failed_reason\"] = event_detail\n        message.metadata[\"delivery_failed_timestamp\"] = timestamp\n        message.save(update_fields=[\"metadata\"])\n\n        decr_message_count(message)\n\n        send_message.delay(str(message.id))\n    elif event_type == \"read\":\n        message.delivered = True\n        message.to_addr = \"\"\n        message.metadata[\"read_timestamp\"] = timestamp\n        message.save(update_fields=[\"delivered\", \"to_addr\", \"metadata\"])\n\n    outbound_event_total.labels(event_type, message.channel_id).inc()\n    fire_delivery_hook(message)\n\n    return (True, \"Event processed\")", "response": "Processes an event of the given details returning a tuple containing a success and message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck for expect event types before continuing", "response": "def post(self, request, *args, **kwargs):\n        \"\"\"\n        Checks for expect event types before continuing\n        \"\"\"\n        serializer = EventSerializer(data=request.data)\n\n        if not serializer.is_valid():\n            return Response(\n                {\"accepted\": False, \"reason\": serializer.errors}, status=400\n            )\n\n        data = serializer.validated_data\n\n        event_type = {\n            \"ack\": \"ack\",\n            \"nack\": \"nack\",\n            \"delivery_report\": \"delivery_succeeded\",\n        }.get(data[\"event_type\"])\n\n        accepted, reason = process_event(\n            data[\"user_message_id\"], event_type, data[\"nack_reason\"], data[\"timestamp\"]\n        )\n\n        return Response(\n            {\"accepted\": accepted, \"reason\": reason}, status=200 if accepted else 400\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an LDAP Group.", "response": "def create(self, group, grouptype):\n        \"\"\"\n        Create an LDAP Group.\n\n        Raises:\n            ldap3.core.exceptions.LDAPNoSuchObjectResult:\n                an object involved with the request is missing\n\n            ldap3.core.exceptions.LDAPEntryAlreadyExistsResult:\n                the entity being created already exists\n\n        \"\"\"\n        try:\n            self.client.add(\n                self.__distinguished_name(group), API.__object_class(),\n                self.__ldap_attr(group, grouptype))\n        except ldap3.core.exceptions.LDAPNoSuchObjectResult:  # pragma: no cover\n            print(\n                \"Error creating LDAP Group.\\nRequest: \",\n                self.__ldap_attr(group, grouptype),\n                \"\\nDistinguished Name: \",\n                self.__distinguished_name(group),\n                file=sys.stderr)\n        except ldap3.core.exceptions.LDAPEntryAlreadyExistsResult:  # pragma: no cover\n            print(\n                \"Error creating LDAP Group. Group already exists. \\nRequest: \",\n                self.__ldap_attr(group, grouptype),\n                \"\\nDistinguished Name: \",\n                self.__distinguished_name(group),\n                file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a user to the specified LDAP group.", "response": "def add_user(self, group, username):\n        \"\"\"\n        Add a user to the specified LDAP group.\n\n        Args:\n            group: Name of group to update\n            username: Username of user to add\n\n        Raises:\n            ldap_tools.exceptions.InvalidResult:\n                Results of the query were invalid.  The actual exception raised\n                inherits from InvalidResult.  See #lookup_id for more info.\n\n        \"\"\"\n        try:\n            self.lookup_id(group)\n        except ldap_tools.exceptions.InvalidResult as err:  # pragma: no cover\n            raise err from None\n\n        operation = {'memberUid': [(ldap3.MODIFY_ADD, [username])]}\n        self.client.modify(self.__distinguished_name(group), operation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a user from an LDAP group.", "response": "def remove_user(self, group, username):\n        \"\"\"\n        Remove a user from the specified LDAP group.\n\n        Args:\n            group: Name of group to update\n            username: Username of user to remove\n\n        Raises:\n            ldap_tools.exceptions.InvalidResult:\n                Results of the query were invalid.  The actual exception raised\n                inherits from InvalidResult.  See #lookup_id for more info.\n\n        \"\"\"\n        try:\n            self.lookup_id(group)\n        except ldap_tools.exceptions.InvalidResult as err:  # pragma: no cover\n            raise err from None\n\n        operation = {'memberUid': [(ldap3.MODIFY_DELETE, [username])]}\n        self.client.modify(self.__distinguished_name(group), operation)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lookup_id(self, group):\n        filter = [\"(cn={})\".format(group), \"(objectclass=posixGroup)\"]\n        results = self.client.search(filter, ['gidNumber'])\n\n        if len(results) < 1:\n            raise ldap_tools.exceptions.NoGroupsFound(\n                'No Groups Returned by LDAP')\n        elif len(results) > 1:\n            raise ldap_tools.exceptions.TooManyResults(\n                'Multiple groups found. Please narrow your search.')\n        else:\n            return results[0].gidNumber.value", "response": "Lookup the ID of the group specified by group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an LDAP group.", "response": "def create(config, group, type):\n        \"\"\"Create an LDAP group.\"\"\"\n        if type not in ('user', 'service'):\n            raise click.BadOptionUsage(  # pragma: no cover\n                \"--grouptype must be 'user' or 'service'\")\n\n        client = Client()\n        client.prepare_connection()\n        group_api = API(client)\n        group_api.create(group, type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(config, group, force):\n        if not force:\n            if not click.confirm(\n                    'Confirm that you want to delete group {}'.format(group)):\n                sys.exit(\"Deletion of {} aborted\".format(group))\n\n        client = Client()\n        client.prepare_connection()\n        group_api = API(client)\n        group_api.delete(group)", "response": "Delete an LDAP group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_user(config, group, username):\n        client = Client()\n        client.prepare_connection()\n        group_api = API(client)\n        try:\n            group_api.add_user(group, username)\n        except ldap_tools.exceptions.NoGroupsFound:  # pragma: no cover\n            print(\"Group ({}) not found\".format(group))\n        except ldap_tools.exceptions.TooManyResults:  # pragma: no cover\n            print(\"Query for group ({}) returned multiple results.\".format(\n                group))\n        except ldap3.TYPE_OR_VALUE_EXISTS:  # pragma: no cover\n            print(\"{} already exists in {}\".format(username, group))", "response": "Add specified user to specified group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove specified user from specified group.", "response": "def remove_user(config, group, username):\n        \"\"\"Remove specified user from specified group.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        group_api = API(client)\n        try:\n            group_api.remove_user(group, username)\n        except ldap_tools.exceptions.NoGroupsFound:  # pragma: no cover\n            print(\"Group ({}) not found\".format(group))\n        except ldap_tools.exceptions.TooManyResults:  # pragma: no cover\n            print(\"Query for group ({}) returned multiple results.\".format(\n                group))\n        except ldap3.NO_SUCH_ATTRIBUTE:  # pragma: no cover\n            print(\"{} does not exist in {}\".format(username, group))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying group info in raw format.", "response": "def index(config):  # pragma: no cover\n        \"\"\"Display group info in raw format.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        group_api = API(client)\n        print(group_api.index())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect importer based on input file type.", "response": "def _get_importer(input_file):\n    \"\"\"Selects importer based on input file type.\"\"\"\n    __, ext = os.path.splitext(input_file)\n    ext = ext.lower()\n\n    if \"ostriz\" in input_file:\n        from dump2polarion.results import ostriztools\n\n        importer = ostriztools.import_ostriz\n    elif ext == \".xml\":\n        # expect junit-report from pytest\n        from dump2polarion.results import junittools\n\n        importer = junittools.import_junit\n    elif ext == \".csv\":\n        from dump2polarion.results import csvtools\n\n        importer = csvtools.import_csv\n    elif ext in dbtools.SQLITE_EXT:\n        importer = dbtools.import_sqlite\n    elif ext == \".json\":\n        from dump2polarion.results import jsontools\n\n        importer = jsontools.import_json\n    else:\n        raise Dump2PolarionException(\"Cannot recognize type of input data, add file extension.\")\n\n    return importer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a db url and return a dict with connection properties", "response": "def parse_db_url(db_url):\n    \"\"\"provided a db url, return a dict with connection properties\n    \"\"\"\n    u = urlparse(db_url)\n    db = {}\n    db[\"database\"] = u.path[1:]\n    db[\"user\"] = u.username\n    db[\"password\"] = u.password\n    db[\"host\"] = u.hostname\n    db[\"port\"] = u.port\n    return db"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_like_context(ctx, param, value):\n    if ctx.obj and ctx.obj.get(\"like\") and (value == \"like\" or ctx.obj.get(\"all_like\")):\n        return ctx.obj[\"like\"][param.name]\n    else:\n        return None", "response": "Return the value for an option from the context if the option\n    or all_like is given else return None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bounds_handler(ctx, param, value):\n    retval = from_like_context(ctx, param, value)\n    if retval is None and value is not None:\n        try:\n            value = value.strip(\", []\")\n            retval = tuple(float(x) for x in re.split(r\"[,\\s]+\", value))\n            assert len(retval) == 4\n            return retval\n        except Exception:\n            raise click.BadParameter(\n                \"{0!r} is not a valid bounding box representation\".format(value)\n            )\n    else:  # pragma: no cover\n        return retval", "response": "Handle different forms of bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints basic metadata about a DataBC WFS layer as JSON.", "response": "def info(dataset, indent, meta_member):\n    \"\"\"Print basic metadata about a DataBC WFS layer as JSON.\n\n    Optionally print a single metadata item as a string.\n    \"\"\"\n    table = bcdata.validate_name(dataset)\n    wfs = WebFeatureService(url=bcdata.OWS_URL, version=\"2.0.0\")\n    info = {}\n    info[\"name\"] = table\n    info[\"count\"] = bcdata.get_count(table)\n    info[\"schema\"] = wfs.get_schema(\"pub:\" + table)\n    if meta_member:\n        click.echo(info[meta_member])\n    else:\n        click.echo(json.dumps(info, indent=indent))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping BC DEM to TIFF", "response": "def dem(bounds, src_crs, dst_crs, out_file, resolution):\n    \"\"\"Dump BC DEM to TIFF\n    \"\"\"\n    if not dst_crs:\n        dst_crs = \"EPSG:3005\"\n    bcdata.get_dem(bounds, out_file=out_file, src_crs=src_crs, dst_crs=dst_crs, resolution=resolution)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(dataset, query, out_file, bounds):\n    table = bcdata.validate_name(dataset)\n    data = bcdata.get_data(table, query=query, bounds=bounds)\n    if out_file:\n        with open(out_file, \"w\") as f:\n            json.dump(data.json(), f)\n    else:\n        sink = click.get_text_stream(\"stdout\")\n        sink.write(json.dumps(data))", "response": "Dump DataBC features to stdout as GeoJSON feature collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cat(dataset, query, bounds, indent, compact, dst_crs, pagesize, sortby):\n    # Note that cat does not concatenate!\n    dump_kwds = {\"sort_keys\": True}\n    if indent:\n        dump_kwds[\"indent\"] = indent\n    if compact:\n        dump_kwds[\"separators\"] = (\",\", \":\")\n    table = bcdata.validate_name(dataset)\n    for feat in bcdata.get_features(\n        table, query=query, bounds=bounds, sortby=sortby, crs=dst_crs\n    ):\n        click.echo(json.dumps(feat, **dump_kwds))", "response": "Write DataBC features to stdout as GeoJSON feature objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bc2pg(dataset, db_url, table, schema, query, append, pagesize, sortby, max_workers):\n    src = bcdata.validate_name(dataset)\n    src_schema, src_table = [i.lower() for i in src.split(\".\")]\n    if not schema:\n        schema = src_schema\n    if not table:\n        table = src_table\n\n    # create schema if it does not exist\n    conn = pgdata.connect(db_url)\n    if schema not in conn.schemas:\n        click.echo(\"Schema {} does not exist, creating it\".format(schema))\n        conn.create_schema(schema)\n\n    # build parameters for each required request\n    param_dicts = bcdata.define_request(\n        dataset, query=query, sortby=sortby, pagesize=pagesize\n    )\n    try:\n        # run the first request / load\n        payload = urlencode(param_dicts[0], doseq=True)\n        url = bcdata.WFS_URL + \"?\" + payload\n        db = parse_db_url(db_url)\n        db_string = \"PG:host={h} user={u} dbname={db} password={pwd}\".format(\n            h=db[\"host\"], u=db[\"user\"], db=db[\"database\"], pwd=db[\"password\"]\n        )\n\n        # create the table\n        if not append:\n            command = [\n                \"ogr2ogr\",\n                \"-lco\",\n                \"OVERWRITE=YES\",\n                \"-lco\",\n                \"SCHEMA={}\".format(schema),\n                \"-lco\",\n                \"GEOMETRY_NAME=geom\",\n                \"-f\",\n                \"PostgreSQL\",\n                db_string,\n                \"-t_srs\",\n                \"EPSG:3005\",\n                \"-nln\",\n                table,\n                url,\n            ]\n            click.echo(\" \".join(command))\n            subprocess.run(command)\n\n        # append to table when append specified or processing many chunks\n        if len(param_dicts) > 1 or append:\n            # define starting index in list of requests\n            if append:\n                idx = 0\n            else:\n                idx = 1\n            commands = []\n            for chunk, paramdict in enumerate(param_dicts[idx:]):\n                payload = urlencode(paramdict, doseq=True)\n                url = bcdata.WFS_URL + \"?\" + payload\n                command = [\n                    \"ogr2ogr\",\n                    \"-update\",\n                    \"-append\",\n                    \"-f\",\n                    \"PostgreSQL\",\n                    db_string + \" active_schema=\" + schema,\n                    \"-t_srs\",\n                    \"EPSG:3005\",\n                    \"-nln\",\n                    table,\n                    url,\n                ]\n                commands.append(command)\n\n            # https://stackoverflow.com/questions/14533458\n            pool = Pool(max_workers)\n            with click.progressbar(\n                pool.imap(partial(call), commands), length=len(param_dicts)\n            ) as bar:\n                for returncode in bar:\n                    if returncode != 0:\n                        click.echo(\"Command failed: {}\".format(returncode))\n\n        click.echo(\n            \"Load of {} to {} in {} complete\".format(src, schema + \".\" + table, db_url)\n        )\n    except Exception:\n        click.echo(\"Data load failed\")\n        raise click.Abort()", "response": "Download a DataBC WFS layer to postgres"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __parseFormat(self, fmt, content, fps = 25):\n        '''Actual parser. Please note that time_to is not required to process as not all subtitles\n        provide it.'''\n\n        headerFound = False\n        subSection = ''\n        for lineNo, line in enumerate(content):\n            line = self._initialLinePrepare(line, lineNo)\n            if not fmt.WITH_HEADER and not self._formatFound and lineNo > self._maxFmtSearch:\n                return\n\n            subSection = ''.join([subSection, line])\n            if fmt.WITH_HEADER and not headerFound:\n                if lineNo > self._maxHeaderLen:\n                    return\n                headerFound = fmt.addHeaderInfo(subSection, self._subtitles.header())\n                if headerFound:\n                    self._formatFound = True\n                    subSection = ''\n            elif fmt.subtitleEnds(line) or (lineNo + 1) == len(content):\n                subtitle = fmt.createSubtitle(fps, subSection)\n                if subtitle is None:\n                    if subSection in ('\\n', '\\r\\n', '\\r'):\n                        subSection = ''\n                        continue\n                    elif self._subtitles.size() > 0:\n                        raise SubParsingError(_(\"Parsing error\"), lineNo)\n                    else:\n                        return\n\n                # store parsing result if new end marker occurred, then clear results\n                if subtitle.start and subtitle.text:\n                    self._formatFound = True\n                    try:\n                        self._subtitles.append(subtitle)\n                    except SubException as msg:\n                        raise SubParsingError(msg, lineNo)\n                elif subtitle.start and not subtitle.text:\n                    pass\n                else:\n                    return\n                subSection = ''", "response": "Internal method for parsing a format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_args(args=None):\n    parser = argparse.ArgumentParser(description=\"dump2polarion\")\n    parser.add_argument(\n        \"-i\",\n        \"--input_file\",\n        required=True,\n        help=\"Path to CSV, SQLite or JUnit reports file or importers XML file\",\n    )\n    parser.add_argument(\n        \"-o\", \"--output_file\", help=\"Where to save the XML output file (default: not saved)\"\n    )\n    parser.add_argument(\"-t\", \"--testrun-id\", help=\"Polarion test run id\")\n    parser.add_argument(\"-c\", \"--config-file\", help=\"Path to config YAML\")\n    parser.add_argument(\n        \"-n\", \"--no-submit\", action=\"store_true\", help=\"Don't submit results to Polarion\"\n    )\n    parser.add_argument(\"--user\", help=\"Username to use to submit results to Polarion\")\n    parser.add_argument(\"--password\", help=\"Password to use to submit results to Polarion\")\n    parser.add_argument(\"--polarion-url\", help=\"Base Polarion URL\")\n    parser.add_argument(\"-f\", \"--force\", action=\"store_true\", help=\"Don't validate test run id\")\n    parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Dry run, don't update anything\")\n    parser.add_argument(\"--no-verify\", action=\"store_true\", help=\"Don't verify import success\")\n    parser.add_argument(\n        \"--verify-timeout\",\n        type=int,\n        default=300,\n        metavar=\"SEC\",\n        help=\"How long to wait (in seconds) for verification of results submission\"\n        \" (default: %(default)s)\",\n    )\n    parser.add_argument(\n        \"--job-log\", help=\"Where to save the log file produced by the Importer (default: not saved)\"\n    )\n    parser.add_argument(\"--log-level\", help=\"Set logging to specified level\")\n    return parser.parse_args(args)", "response": "Get command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets arguments for the submit_and_verify method.", "response": "def get_submit_args(args):\n    \"\"\"Gets arguments for the `submit_and_verify` method.\"\"\"\n    submit_args = dict(\n        testrun_id=args.testrun_id,\n        user=args.user,\n        password=args.password,\n        no_verify=args.no_verify,\n        verify_timeout=args.verify_timeout,\n        log_file=args.job_log,\n        dry_run=args.dry_run,\n    )\n    submit_args = {k: v for k, v in submit_args.items() if v is not None}\n    return Box(submit_args, frozen_box=True, default_box=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubmitting the input XML file if it s already in the expected format.", "response": "def submit_if_ready(args, submit_args, config):\n    \"\"\"Submits the input XML file if it's already in the expected format.\"\"\"\n    __, ext = os.path.splitext(args.input_file)\n    if ext.lower() != \".xml\":\n        return None\n\n    with io.open(args.input_file, encoding=\"utf-8\") as input_file:\n        xml = input_file.read(1024)\n\n    if not (\"<testsuites\" in xml or \"<testcases\" in xml or \"<requirements\" in xml):\n        return None\n\n    if args.no_submit:\n        logger.info(\"Nothing to do\")\n        return 0\n\n    # expect importer xml and just submit it\n    response = dump2polarion.submit_and_verify(\n        xml_file=args.input_file, config=config, **submit_args\n    )\n    return 0 if response else 2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(args=None, transform_func=None):\n    args = get_args(args)\n\n    utils.init_log(args.log_level)\n\n    try:\n        config = _get_config(args)\n    except Dump2PolarionException as err:\n        logger.fatal(err)\n        return 1\n\n    return dumper(args, config, transform_func=transform_func)", "response": "Main function for cli."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_ldap_config(self):  # pragma: no cover\n        try:\n            with open('{}/ldap_info.yaml'.format(self.config_dir),\n                      'r') as FILE:\n                config = yaml.load(FILE)\n                self.host = config['server']\n                self.user_dn = config['user_dn']\n                self.port = config['port']\n                self.basedn = config['basedn']\n                self.mail_domain = config['mail_domain']\n                self.service_ou = config['service_ou']\n        except OSError as err:\n            print('{}: Config file ({}/ldap_info.yaml) not found'.format(\n                type(err), self.config_dir))", "response": "Load LDAP Client settings from a config file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_ldap_password(self):  # pragma: no cover\n        with open('{}/ldap.secret'.format(self.config_dir), 'r') as FILE:\n            secure_config = FILE.read()\n            self.user_pw = base64.b64decode(secure_config.encode())", "response": "Import LDAP password from file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, distinguished_name, object_class, attributes):\n        self.conn.add(distinguished_name, object_class, attributes)", "response": "Adds an object to the LDAP record store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching LDAP for records.", "response": "def search(self, filter, attributes=None):\n        \"\"\"Search LDAP for records.\"\"\"\n        if attributes is None:\n            attributes = ['*']\n\n        if filter is None:\n            filter = [\"(objectclass=*)\"]\n\n        # Convert filter list into an LDAP-consumable format\n        filterstr = \"(&{})\".format(''.join(filter))\n        self.conn.search(\n            search_base=self.basedn,\n            search_filter=filterstr,\n            search_scope=ldap3.SUBTREE,\n            attributes=attributes)\n        return self.conn.entries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_max_id(self, object_type, role):\n        if object_type == 'user':\n            objectclass = 'posixAccount'\n            ldap_attr = 'uidNumber'\n        elif object_type == 'group':  # pragma: no cover\n            objectclass = 'posixGroup'\n            ldap_attr = 'gidNumber'\n        else:\n            raise ldap_tools.exceptions.InvalidResult('Unknown object type')\n\n        minID, maxID = Client.__set_id_boundary(role)\n\n        filter = [\n            \"(objectclass={})\".format(objectclass), \"({}>={})\".format(ldap_attr, minID)\n        ]\n\n        if maxID is not None:\n            filter.append(\"({}<={})\".format(ldap_attr, maxID))\n\n        id_list = self.search(filter, [ldap_attr])\n\n        if id_list == []:\n            id = minID\n        else:\n            if object_type == 'user':\n                id = max([i.uidNumber.value for i in id_list]) + 1\n            elif object_type == 'group':\n                id = max([i.gidNumber.value for i in id_list]) + 1\n            else:\n                raise ldap_tools.exceptions.InvalidResult('Unknown object')\n\n        return id", "response": "Get the highest used ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dem(bounds, out_file=\"dem.tif\", src_crs=\"EPSG:3005\", dst_crs=\"EPSG:3005\", resolution=25):\n    bbox = \",\".join([str(b) for b in bounds])\n    # todo: validate resolution units are equivalent to src_crs units\n    # build request\n    payload = {\n        \"service\": \"WCS\",\n        \"version\": \"1.0.0\",\n        \"request\": \"GetCoverage\",\n        \"coverage\": \"pub:bc_elevation_25m_bcalb\",\n        \"Format\": \"GeoTIFF\",\n        \"bbox\": bbox,\n        \"CRS\": src_crs,\n        \"RESPONSE_CRS\": dst_crs,\n        \"resx\": str(resolution),\n        \"resy\": str(resolution),\n    }\n    # request data from WCS\n    r = requests.get(bcdata.WCS_URL, params=payload)\n    # save to tiff\n    if r.status_code == 200:\n        with open(out_file, \"wb\") as file:\n            file.write(r.content)\n        return out_file\n    else:\n        raise RuntimeError(\n            \"WCS request failed with status code {}\".format(str(r.status_code))\n        )", "response": "Get 25m DEM for provided bounds write to GeoTIFF\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecorating a function so that print arguments before calling it. Args: output: writable to print args. (Default: sys.stdout)", "response": "def print_args(output=sys.stdout):\n    \"\"\"Decorate a function so that print arguments before calling it.\n\n    Args:\n      output: writable to print args. (Default: sys.stdout)\n    \"\"\"\n    def decorator(func):\n        \"\"\"The decorator function.\n        \"\"\"\n        @wraps(func)\n        def _(*args, **kwargs):\n            \"\"\"The decorated function.\n            \"\"\"\n            output.write(\n                \"Args: {0}, KwArgs: {1}\\n\".format(str(args), str(kwargs)))\n            return func(*args, **kwargs)\n        return _\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef constant(func):\n    @wraps(func)\n    def _(*args, **kwargs):\n        \"\"\"The decorated function.\n        \"\"\"\n        if not _.res:\n            _.res = func(*args, **kwargs)\n        return _.res\n    _.res = None\n    return _", "response": "Decorator to make a function return a constant value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef memoized(func):\n    cache = {}\n    @wraps(func)\n    def memoized_function(*args):\n        \"\"\"The decorated function.\n        \"\"\"\n        try:\n            return cache[args]\n        except KeyError:\n            value = func(*args)\n            try:\n                cache[args] = value\n            except MemoryError:\n                cache.clear()\n                gc.collect()\n            return value\n    return memoized_function", "response": "Decorator to memoize results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the content of the database file and returns imported data.", "response": "def import_sqlite(db_file, older_than=None, **kwargs):\n    \"\"\"Reads the content of the database file and returns imported data.\"\"\"\n    conn = _open_sqlite(db_file)\n    cur = conn.cursor()\n    # get rows that were not exported yet\n    select = \"SELECT * FROM testcases WHERE exported != 'yes'\"\n    if older_than:\n        cur.execute(\" \".join((select, \"AND sqltime < ?\")), (older_than,))\n    else:\n        cur.execute(select)\n    columns = [description[0] for description in cur.description]\n    rows = cur.fetchall()\n\n    # map data to columns\n    results = []\n    for row in rows:\n        record = OrderedDict(list(zip(columns, row)))\n        results.append(record)\n\n    testrun = _get_testrun_from_sqlite(conn)\n\n    conn.close()\n\n    return xunit_exporter.ImportedData(results=results, testrun=testrun)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mark_exported_sqlite(db_file, older_than=None):\n    logger.debug(\"Marking rows in database as exported\")\n    conn = _open_sqlite(db_file)\n    cur = conn.cursor()\n    update = \"UPDATE testcases SET exported = 'yes' WHERE verdict IS NOT null AND verdict != ''\"\n    if older_than:\n        cur.execute(\" \".join((update, \"AND sqltime < ?\")), (older_than,))\n    else:\n        cur.execute(update)\n    conn.commit()\n    conn.close()", "response": "Marks rows with verdict as exported."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createSubtitle(self, fps, section):\n        matched = self._pattern.search(section)\n        if matched is not None:\n            matchedDict = matched.groupdict()\n            return Subtitle(\n                self.frametime(fps, matchedDict.get(\"time_from\")),\n                self.frametime(fps, matchedDict.get(\"time_to\")),\n                self.formatSub(matchedDict.get(\"text\"))\n            )\n        return None", "response": "Returns a correct Subtitle object from a text given in section."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formatSub(self, string):\n        string = string.strip()\n        string = string.replace('{', '{{').replace('}', '}}')\n        string = self._formatWithTags(\"gsp_b_\", \"_gsp_b\", string)\n        string = self._formatWithTags(\"gsp_i_\", \"_gsp_i\", string)\n        string = self._formatWithTags(\"gsp_u_\", \"_gsp_u\", string)\n        string = self._formatLinesep(string)\n        return string", "response": "Convert sub - type specific formatting to GSP formatting."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts FrameTime object to properly formatted string that describes subtitle start or end time.", "response": "def convertTime(self, frametime, which):\n        \"\"\"Convert FrameTime object to properly formatted string that describes subtitle start or\n        end time.\"\"\"\n        SubAssert(frametime.frame >= 0, _(\"Negative time present.\"))\n        return frametime.frame"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def device_info():\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = NetworkScan(LOOP, session)\n        result = await ghlocalapi.scan_for_units(IPRANGE)\n        print(result)", "response": "Get device info from GH."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nduplicate arr to a writeable array sets arr2 [ k ] = v returns arr2", "response": "def _ndarray_assoc(arr, k, v):\n    '_ndarray_assoc(arr, k, v) duplicates arr to a writeable array, sets arr2[k]=v, returns arr2'\n    arr = np.array(arr)\n    arr[k] = v\n    arr.setflags(write=False)\n    return arr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef itable(*args, **kwargs):\n    '''\n    itable(...) yields a new immutable table object from the given set of arguments. The arguments\n      may be any number of maps or itables followed by any number of keyword arguments. All the\n      entries from the arguments and keywords are collapsed left-to-right (respecting laziness),\n      and the resulting column set is returned as the itable. Arguments and maps may contain\n      values that are functions of zero arguments; these are considered lazy values and are not\n      evaluated by the itable function.\n    '''\n    # a couple things we want to check first... does our argument list reduce to just an empty\n    # itable or just a single itable?\n    if len(args) == 0 and len(kwargs) == 0:\n        return ITable({}, n=0)\n    elif len(args) == 1 and len(kwargs) == 0 and isinstance(args[0], ITable):\n        return args[0]\n    # we want to try to convert any arguments we can from datatables into maps\n    try:\n        import pandas\n        args = [{k:a[k].values for k in a.keys()} if isinstance(a, pandas.DataFrame) else a\n                for a in args]\n    except: pass\n    # now we want to merge these together and make them one lazy map\n    m0 = lazy_map(merge(args, kwargs))\n    # see if we can deduce the row size from a non-lazy argument:\n    v = next((m0[k] for k in six.iterkeys(m0) if not m0.is_lazy(k)), None) if is_lazy_map(m0) else \\\n        None\n    if v is None:\n        k = next((u for u in six.iterkeys(m0)), m0)\n        if k is m0: v = None\n        else: v = m0[k]\n    return ITable(m0, n=(None if v is None else len(v)))", "response": "Yields a new immutable table object from the given set of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raise_201(instance, location):\n    _set_location(instance, location)\n    instance.response.status = 201\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 201 response code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raise_204(instance):\n    instance.response.status = 204\n    instance.response.body = ''\n    instance.response.body_raw = None\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 204 response code. Clears the body of the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raise_205(instance):\n    instance.response.status = 205\n    instance.response.body = ''\n    instance.response.body_raw = None\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 205 response code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naborts the current request with a 301 ( Moved Permanentlyly response code.", "response": "def raise_301(instance, location):\n    \"\"\"Abort the current request with a 301 (Moved Permanently) response code.\n    Sets the Location header correctly. If the location does not start with a\n    slash, the path of the current request is prepended.\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 301\n    \"\"\"\n    _set_location(instance, location)\n    instance.response.status = 301\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nabort the current request with a 302 response code.", "response": "def raise_302(instance, location):\n    \"\"\"Abort the current request with a 302 (Found) response code. Sets the\n    Location header correctly. If the location does not start with a slash,\n    the path of the current request is prepended.\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 302\n    \"\"\"\n    _set_location(instance, location)\n    instance.response.status = 302\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raise_303(instance, location):\n    _set_location(instance, location)\n    instance.response.status = 303\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 303 response code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raise_304(instance):\n    instance.response.status = 304\n    instance.response.body = ''\n    instance.response.body_raw = None\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 304 response code."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naborts the current request with a 305 response code.", "response": "def raise_305(instance, location):\n    \"\"\"Abort the current request with a 305 (Use Proxy) response code. Sets\n    the Location header correctly. If the location does not start with a\n    slash, the path of the current request is prepended.\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 305\n    \"\"\"\n    _set_location(instance, location)\n    instance.response.status = 305\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naborts the current request with a 307 response.", "response": "def raise_307(instance, location):\n    \"\"\"Abort the current request with a 307 (Temporary Redirect) response\n    code. Sets the Location header correctly. If the location does not start\n    with a slash, the path of the current request is prepended.\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 307\n    \"\"\"\n    _set_location(instance, location)\n    instance.response.status = 307\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nabort the current request with a 400 response code.", "response": "def raise_400(instance, msg=None):\n    \"\"\"Abort the current request with a 400 (Bad Request) response code. If\n    the message is given it's output as an error message in the response body\n    (correctly converted to the requested MIME type).\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 400\n    \"\"\"\n    instance.response.status = 400\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raise_401(instance, authenticate, msg=None):\n    instance.response.status = 401\n    instance.response.headers['WWW-Authenticate'] = authenticate\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 401 response code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raise_402(instance, msg=None):\n    instance.response.status = 402\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 402 response code."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nabort the current request with a 403 response code.", "response": "def raise_403(instance, msg=None):\n    \"\"\"Abort the current request with a 403 (Forbidden) response code. If the\n    message is given it's output as an error message in the response body\n    (correctly converted to the requested MIME type).\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 403\n    \"\"\"\n    instance.response.status = 403\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nabort the current request with a 405 response.", "response": "def raise_405(instance):\n    \"\"\"Abort the current request with a 405 (Method Not Allowed) response\n    code. Sets the ``Allow`` response header to the return value of the\n    :func:`Resource.get_allowed_methods` function.\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 405\n    \"\"\"\n    instance.response.status = 405\n    instance.response.headers['Allow'] = instance.get_allowed_methods()\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nabort the current request with a 412 response.", "response": "def raise_412(instance, msg=None):\n    \"\"\"Abort the current request with a 412 (Precondition Failed) response\n    code. If the message is given it's output as an error message in the\n    response body (correctly converted to the requested MIME type).\n\n    :param instance: Resource instance (used to access the response)\n    :type instance: :class:`webob.resource.Resource`\n    :raises: :class:`webob.exceptions.ResponseException` of status 412\n    \"\"\"\n    instance.response.status = 412\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raise_415(instance, msg=None):\n    instance.response.status = 415\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 415 response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef raise_500(instance, msg=None):\n    instance.response.status = 500\n    if msg:\n        instance.response.body_raw = {'error': msg}\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 500 response code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raise_501(instance):\n    instance.response.status = 501\n    instance.response.headers['Allow'] = instance.get_allowed_methods()\n    raise ResponseException(instance.response)", "response": "Abort the current request with a 501 response code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_location(instance, location):\n    location = str(location)\n    if not location.startswith('/'):\n        location = urljoin(instance.request_path.rstrip('/') + '/', location)\n    instance.response.location = location", "response": "Sets a Location response header."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves query parameters from the url and returns the asset_url without caching it.", "response": "def no_cache(asset_url):\n    \"\"\"\n    Removes query parameters\n    \"\"\"\n    pos = asset_url.rfind('?')\n    if pos > 0:\n        asset_url = asset_url[:pos]\n    return asset_url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __ngrams(s, n=3):\n    return list(zip(*[s[i:] for i in range(n)]))", "response": "Returns a list of n - grams from a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of n - grams in a string.", "response": "def word_ngrams(s, n=3, token_fn=tokens.on_whitespace):\n    \"\"\"\n        Word-level n-grams in a string\n\n        By default, whitespace is assumed to be a word boundary.\n\n        >>> ng.word_ngrams('This is not a test!')\n        [('This', 'is', 'not'), ('is', 'not', 'a'), ('not', 'a', 'test!')]\n\n        If the sequence's length is less than or equal to n, the n-grams are\n        simply the sequence itself.\n\n        >>> ng.word_ngrams('Test!')\n        [('Test!')]\n\n        Args:\n            s: a string\n\n        Returns:\n            list: tuples of word-level n-grams\n    \"\"\"\n    tokens = token_fn(s)\n    return __ngrams(tokens, n=min(len(tokens), n))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef char_ngrams(s, n=3, token_fn=tokens.on_whitespace):\n    tokens = token_fn(s)\n    ngram_tuples = [__ngrams(t, n=min(len(t), n)) for t in tokens]\n    def unpack(l):\n        return sum(l, [])\n    def untuple(l):\n        return [''.join(t) for t in l]\n    return untuple(unpack(ngram_tuples))", "response": "Returns a list of n - grams from within the words in a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the n - grams that match between two sequences s1 and s2.", "response": "def __matches(s1, s2, ngrams_fn, n=3):\n    \"\"\"\n        Returns the n-grams that match between two sequences\n\n        See also: SequenceMatcher.get_matching_blocks\n\n        Args:\n            s1: a string\n            s2: another string\n            n: an int for the n in n-gram\n\n        Returns:\n            set:\n    \"\"\"\n    ngrams1, ngrams2 = set(ngrams_fn(s1, n=n)), set(ngrams_fn(s2, n=n))\n    return ngrams1.intersection(ngrams2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef char_matches(s1, s2, n=3):\n    return __matches(s1, s2, char_ngrams, n=n)", "response": "Returns the n - grams that match between two strings"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef word_matches(s1, s2, n=3):\n    return __matches(s1, s2, word_ngrams, n=n)", "response": "Word - level n - grams that match between two strings\n            s1 and s2 are the n - grams that match between two strings\n            s2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __similarity(s1, s2, ngrams_fn, n=3):\n    ngrams1, ngrams2 = set(ngrams_fn(s1, n=n)), set(ngrams_fn(s2, n=n))\n    matches = ngrams1.intersection(ngrams2)\n    return 2 * len(matches) / (len(ngrams1) + len(ngrams2))", "response": "Calculates the fraction of n - grams matching between two sequences\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_json(self, model, space=None, rel_path=None, extra_params=None, get_all=None):\n        # Only API.spaces and API.event should not provide\n        # the `space argument\n        if space is None and model not in (Space, Event):\n            raise Exception(\n                'In general, `API._get_json` should always '\n                'be called with a `space` argument.'\n            )\n\n        if not extra_params:\n            extra_params = {}\n\n        # Handle pagination for requests carrying large amounts of data\n        extra_params['page'] = extra_params.get('page', 1)\n\n        # Generate the url to hit\n        url = '{0}/{1}/{2}.json?{3}'.format(\n            settings.API_ROOT_PATH,\n            settings.API_VERSION,\n            rel_path or model.rel_path,\n            urllib.urlencode(extra_params),\n        )\n\n        # If the cache is being used and the url has been hit already\n        if self.cache_responses and url in self.cache:\n            response = self.cache[url]\n        else:\n            # Fetch the data\n            headers = {\n                'X-Api-Key': self.key,\n                'X-Api-Secret': self.secret,\n            }\n            response = self.session.get(url=url, headers=headers)\n            # If the cache is being used, update it\n            if self.cache_responses:\n                self.cache[url] = response\n\n        if response.status_code == 200:  # OK\n            results = []\n            json_response = response.json()\n            for obj in json_response:\n                instance = model(data=obj)\n                instance.api = self\n                if space:\n                    instance.space = space\n                results.append(instance)\n            # If it looks like there are more pages to fetch,\n            # try and fetch the next one\n            per_page = extra_params.get('per_page', None)\n            if (\n                get_all\n                and per_page\n                and len(json_response)\n                and per_page == len(json_response)\n            ):\n                extra_params['page'] += 1\n                results = results + self._get_json(model, space, rel_path, extra_params, get_all=get_all)\n            return results\n        elif response.status_code == 204:  # No Content\n            return []\n        else:  # Most likely a 404 Not Found\n            raise Exception(\n                'Code {0} returned from `{1}`. Response text: \"{2}\".'.format(\n                    response.status_code,\n                    url,\n                    response.text\n                )\n            )", "response": "Internal method for fetching the JSON data from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbases level method for updating data via the API.", "response": "def _post_json(self, instance, space=None, rel_path=None, extra_params=None):\n        \"\"\"\n        Base level method for updating data via the API\n        \"\"\"\n\n        model = type(instance)\n\n        # Only API.spaces and API.event should not provide\n        # the `space argument\n        if space is None and model not in (Space, Event):\n            raise Exception(\n                'In general, `API._post_json` should always '\n                'be called with a `space` argument.'\n            )\n\n        if 'number' in instance.data:\n            raise AttributeError(\n                'You cannot create a ticket which already has a number'\n            )\n\n        if not extra_params:\n            extra_params = {}\n\n        # Generate the url to hit\n        url = '{0}/{1}/{2}?{3}'.format(\n            settings.API_ROOT_PATH,\n            settings.API_VERSION,\n            rel_path or model.rel_path,\n            urllib.urlencode(extra_params),\n        )\n\n        # Fetch the data\n        response = requests.post(\n            url=url,\n            data=json.dumps(instance.data),\n            headers={\n                'X-Api-Key': self.key,\n                'X-Api-Secret': self.secret,\n                'Content-type': \"application/json\",\n            },\n        )\n\n        if response.status_code == 201:  # OK\n            instance = model(data=response.json())\n            instance.api = self\n            if space:\n                instance.space = space\n            return instance\n        else:  # Most likely a 404 Not Found\n            raise Exception(\n                'Code {0} returned from `{1}`. Response text: \"{2}\".'.format(\n                    response.status_code,\n                    url,\n                    response.text\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbase level method for adding new data to the API.", "response": "def _put_json(self, instance, space=None, rel_path=None, extra_params=None, id_field=None):\n        \"\"\"\n        Base level method for adding new data to the API\n        \"\"\"\n\n        model = type(instance)\n\n        # Only API.spaces and API.event should not provide\n        # the `space argument\n        if space is None and model not in (Space, Event):\n            raise Exception(\n                'In general, `API._put_json` should always '\n                'be called with a `space` argument.'\n            )\n\n        if not extra_params:\n            extra_params = {}\n\n        if not id_field:\n            id_field = 'number'\n\n        # Generate the url to hit\n        url = '{0}/{1}/{2}/{3}.json?{4}'.format(\n            settings.API_ROOT_PATH,\n            settings.API_VERSION,\n            rel_path or model.rel_path,\n            instance[id_field],\n            urllib.urlencode(extra_params),\n        )\n\n        # Fetch the data\n        response = requests.put(\n            url=url,\n            data=json.dumps(instance.data),\n            headers={\n                'X-Api-Key': self.key,\n                'X-Api-Secret': self.secret,\n                'Content-type': \"application/json\",\n            },\n        )\n\n        if response.status_code == 204:  # OK\n            return instance\n        else:  # Most likely a 404 Not Found\n            raise Exception(\n                'Code {0} returned from `{1}`. Response text: \"{2}\".'.format(\n                    response.status_code,\n                    url,\n                    response.text\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbase level method for removing data from the API", "response": "def _delete_json(self, instance, space=None, rel_path=None, extra_params=None, id_field=None, append_to_path=None):\n        \"\"\"\n        Base level method for removing data from the API\n        \"\"\"\n\n        model = type(instance)\n\n        # Only API.spaces and API.event should not provide\n        # the `space argument\n        if space is None and model not in (Space, Event):\n            raise Exception(\n                'In general, `API._delete_json` should always '\n                'be called with a `space` argument.'\n            )\n\n        if not extra_params:\n            extra_params = {}\n\n        if not id_field:\n            id_field = 'number'\n\n        if not instance.get(id_field, None):\n            raise AttributeError(\n                '%s does not have a value for the id field \\'%s\\'' % (\n                    instance.__class__.__name__,\n                    id_field\n                )\n            )\n\n        # Generate the url to hit\n        url = '{0}/{1}/{2}/{3}{4}.json?{5}'.format(\n            settings.API_ROOT_PATH,\n            settings.API_VERSION,\n            rel_path or model.rel_path,\n            instance[id_field],\n            append_to_path or '',\n            urllib.urlencode(extra_params),\n        )\n\n        # Fetch the data\n        response = requests.delete(\n            url=url,\n            headers={\n                'X-Api-Key': self.key,\n                'X-Api-Secret': self.secret,\n                'Content-type': \"application/json\",\n            },\n        )\n\n        if response.status_code == 204:  # OK\n            return True\n        else:  # Most likely a 404 Not Found\n            raise Exception(\n                'Code {0} returned from `{1}`. Response text: \"{2}\".'.format(\n                    response.status_code,\n                    url,\n                    response.text\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _bind_variables(self, instance, space):\n        instance.api = self\n        if space:\n            instance.space = space\n        return instance", "response": "Bind related variables to the instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving all Tickets in this Space", "response": "def tickets(self, extra_params=None):\n        \"\"\"\n        All Tickets in this Space\n        \"\"\"\n\n        # Default params\n        params = {\n            'per_page': settings.MAX_PER_PAGE,\n            'report': 0,  # Report 0 is all tickets\n        }\n\n        if extra_params:\n            params.update(extra_params)\n\n        return self.api._get_json(\n            Ticket,\n            space=self,\n            rel_path=self._build_rel_path('tickets'),\n            extra_params=params,\n            get_all=True,  # Retrieve all tickets in the space\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve all milestones in this Space", "response": "def milestones(self, extra_params=None):\n        \"\"\"\n        All Milestones in this Space\n        \"\"\"\n        \n        # Default params\n        params = {\n            'per_page': settings.MAX_PER_PAGE,\n        }\n\n        if extra_params:\n            params.update(extra_params)\n            \n        return self.api._get_json(\n            Milestone,\n            space=self,\n            rel_path=self._build_rel_path('milestones/all'),\n            extra_params=params,\n            get_all=True,  # Retrieve all milestones in the space\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tools(self, extra_params=None):\n        return self.api._get_json(\n            SpaceTool,\n            space=self,\n            rel_path=self._build_rel_path('space_tools'),\n            extra_params=extra_params,\n        )", "response": "All Tools in this Space"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all components in this Space", "response": "def components(self, extra_params=None):\n        \"\"\"\"\n        All components in this Space\n        \"\"\"\n        return self.api._get_json(\n            Component,\n            space=self,\n            rel_path=self._build_rel_path('ticket_components'),\n            extra_params=extra_params,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all Users with access to this Space.", "response": "def users(self, extra_params=None):\n        \"\"\"\n        All Users with access to this Space\n        \"\"\"\n        return self.api._get_json(\n            User,\n            space=self,\n            rel_path=self._build_rel_path('users'),\n            extra_params=extra_params,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tags(self, extra_params=None):\n        return self.api._get_json(\n            Tag,\n            space=self,\n            rel_path=self._build_rel_path('tags'),\n            extra_params=extra_params,\n        )", "response": "All Tags in this Space"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wiki_pages(self, extra_params=None):\n        return self.api._get_json(\n            WikiPage,\n            space=self,\n            rel_path=self._build_rel_path('wiki_pages'),\n            extra_params=extra_params,\n        )", "response": "Get all Wiki Pages with access to this Space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of Tickets which are part of this Milestone.", "response": "def tickets(self, extra_params=None):\n        \"\"\"\n        All Tickets which are a part of this Milestone\n        \"\"\"\n        return filter(\n            lambda ticket: ticket.get('milestone_id', None) == self['id'],\n            self.space.tickets(extra_params=extra_params)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tags(self, extra_params=None):\n\n        # Default params\n        params = {\n            'per_page': settings.MAX_PER_PAGE,\n        }\n\n        if extra_params:\n            params.update(extra_params)\n\n        return self.api._get_json(\n            Tag,\n            space=self,\n            rel_path=self.space._build_rel_path(\n                'tickets/%s/tags' % self['number']\n            ),\n            extra_params=params,\n            get_all=True,  # Retrieve all tags in the ticket\n        )", "response": "Retrieve all Tags in this Ticket"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef milestone(self, extra_params=None):\n        if self.get('milestone_id', None):\n            milestones = self.space.milestones(id=self['milestone_id'], extra_params=extra_params)\n            if milestones:\n                return milestones[0]", "response": "Returns the Milestone that the Ticket is part of."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the User currently assigned to the Ticket.", "response": "def user(self, extra_params=None):\n        \"\"\"\n        The User currently assigned to the Ticket\n        \"\"\"\n        if self.get('assigned_to_id', None):\n            users = self.space.users(\n                id=self['assigned_to_id'],\n                extra_params=extra_params\n            )\n            if users:\n                return users[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Component currently assigned to the Ticket.", "response": "def component(self, extra_params=None):\n        \"\"\"\n        The Component currently assigned to the Ticket\n        \"\"\"\n        if self.get('component_id', None):\n            components = self.space.components(id=self['component_id'], extra_params=extra_params)\n            if components:\n                return components[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comments(self, extra_params=None):\n\n        # Default params\n        params = {\n            'per_page': settings.MAX_PER_PAGE,\n        }\n\n        if extra_params:\n            params.update(extra_params)\n\n        return self.api._get_json(\n            TicketComment,\n            space=self,\n            rel_path=self.space._build_rel_path(\n                'tickets/%s/ticket_comments' % self['number']\n            ),\n            extra_params=params,\n            get_all=True,  # Retrieve all comments in the ticket\n        )", "response": "Retrieve all Comments in this Ticket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the Ticket to Assembla.", "response": "def write(self):\n        \"\"\"\n        Create or update the Ticket on Assembla\n        \"\"\"\n        if not hasattr(self, 'space'):\n            raise AttributeError(\"A ticket must have a 'space' attribute before you can write it to Assembla.\")\n\n        if self.get('number'):  # Modifying an existing ticket\n            method = self.space.api._put_json\n        else:  # Creating a new ticket\n            method = self.space.api._post_json\n\n        return method(\n            self,\n            space=self.space,\n            rel_path=self.space._build_rel_path('tickets'),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the Ticket from Assembla.", "response": "def delete(self):\n        \"\"\"\n        Remove the Ticket from Assembla\n        \"\"\"\n        if not hasattr(self, 'space'):\n            raise AttributeError(\"A ticket must have a 'space' attribute before you can remove it from Assembla.\")\n\n        return self.space.api._delete_json(\n            self,\n            space=self.space,\n            rel_path=self.space._build_rel_path('tickets'),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates or updates a Wiki Page on Assembla.", "response": "def write(self):\n        \"\"\"\n        Create or update a Wiki Page on Assembla\n        \"\"\"\n        if not hasattr(self, 'space'):\n            raise AttributeError(\"A WikiPage must have a 'space' attribute before you can write it to Assembla.\")\n\n        self.api = self.space.api\n\n        if self.get('id'):  # We are modifying an existing wiki page\n            return self.api._put_json(\n                self,\n                space=self.space,\n                rel_path=self.space._build_rel_path('wiki_pages'),\n                id_field='id'\n            )\n        else:  # Creating a new wiki page\n            return self.api._post_json(\n                self,\n                space=self.space,\n                rel_path=self.space._build_rel_path('wiki_pages'),\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, spec):\n        for limit in spec.limit_to:\n            if limit not in self.limit_to:\n                self.limit_to.append(limit)", "response": "Add limitations of given spec to self. limit_to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining package specifications with limitations.", "response": "def combine(specs):\n        \"\"\"\n        Combine package specifications' limitations.\n\n        Args:\n            specs (list of PackageSpec): the package specifications.\n\n        Returns:\n            list of PackageSpec: the new, merged list of PackageSpec.\n        \"\"\"\n        new_specs = {}\n        for spec in specs:\n            if new_specs.get(spec, None) is None:\n                new_specs[spec] = spec\n            else:\n                new_specs[spec].add(spec)\n        return list(new_specs.values())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding method. Returns the packageSpec corresponding to the package.", "response": "def find(self, package, **kwargs):\n        \"\"\"\n        Find method.\n\n        Args:\n            package (str): package to find.\n            **kwargs (): additional keyword arguments.\n\n        Returns:\n            PackageSpec: the PackageSpec corresponding to the package, or None.\n        \"\"\"\n        if not exists(package):\n            return None\n        name, path = None, None\n        enforce_init = kwargs.pop('enforce_init', True)\n        if isdir(package):\n            if isfile(join(package, '__init__.py')) or not enforce_init:\n                name, path = basename(package), package\n        elif isfile(package) and package.endswith('.py'):\n            name, path = splitext(basename(package))[0], package\n        if name and path:\n            return PackageSpec(name, path)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, package, **kwargs):\n        spec = find_spec(package)\n        if spec is None:\n            return None\n        limit = []\n        if '.' in package:\n            package, limit = package.split('.', 1)\n            limit = [limit]\n            spec = find_spec(package)\n        if spec is not None:\n            if spec.submodule_search_locations:\n                path = spec.submodule_search_locations[0]\n            elif spec.origin and spec.origin != 'built-in':\n                path = spec.origin\n            else:\n                return None\n            return PackageSpec(spec.name, path, limit)\n        return None", "response": "Find method. Returns the corresponding PackageSpec object or None if no such PackageSpec is found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, package, **kwargs):\n        for finder in self.finders:\n            package_spec = finder.find(package, **kwargs)\n            if package_spec:\n                return package_spec\n        return None", "response": "Find a package using package finders."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if q is a pint quantity or a tuple and False otherwise.", "response": "def is_quantity(q):\n    '''\n    is_quantity(q) yields True if q is a pint quantity or a tuple (scalar, unit) and False\n      otherwise.\n    '''\n    if isinstance(q, tuple):\n        return len(q) == 2 and is_unit(q[1])\n    else:\n        cls = type(q)\n        return cls.__module__.startswith('pint.') and cls.__name__ == 'Quantity'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unit(u):\n    '''\n    unit(u) yields the pimms-library unit object for the given unit object u (which may be from a\n      separate pint.UnitRegistry instance).\n    unit(uname) yields the unit object for the given unit name uname.\n    unit(None) yields None.\n    unit(q) yields the unit of the given quantity q.\n    '''\n    if u is None:    return None\n    elif is_unit(u): return getattr(units, str(u))\n    elif is_quantity(u):\n        if isinstance(u, tuple): return getattr(units, str(u[1]))\n        else: return getattr(units, str(u.u))\n    else:\n        raise ValueError('unrecotnized unit argument')", "response": "Returns the pimms - library unit object for the given unit object u."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mag(val, u=Ellipsis):\n    '''\n    mag(scalar) yields scalar for the given scalar (numeric value without a unit).\n    mag(quant) yields the scalar magnitude of the quantity quant.\n    mag(scalar, u=u) yields scalar.\n    mag(quant, u=u) yields the given magnitude of the given quant after being translated into the\n      given unit u.\n\n    The quant arguments in the above list may be replaced with (scalar, unit) as in (10, 'degrees')\n    or (14, 'mm'). Note that mag always translates all lists and tuples into numpy ndarrays.\n    '''\n    if not is_quantity(val): return val\n    if isinstance(val, tuple):\n        val = units.Quantity(val[0], val[1])\n    return val.m if u is Ellipsis else val.to(unit(u)).m", "response": "Returns the magnitude of the object in the order of the given value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef imm_array(q):\n    '''\n    imm_array(val) yields a version of val that is wrapped in numpy's ndarray class. If val is a\n      read-only numpy array, then it is returned as-is; if it is not, then it is cast copied to a\n      numpy array, duplicated, the read-only flag is set on the new object, and then it is returned.\n    '''\n    if is_quantity(q):\n        m = mag(q)\n        mm = imm_array(m)\n        return q if mm is m else units.Quantity(mm, unit(q))\n    elif not isinstance(q, np.ndarray) or q.flags['WRITEABLE']:\n        q = np.array(q)\n        q.setflags(write=False)\n    return q", "response": "Returns a copy of the array q with the same magnitude as the input object q."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new avec of avec of avec of avec of avec of avec of avec of avec of avec of avec", "response": "def quant(val, u=Ellipsis):\n    '''\n    quant(scalar) yields a dimensionless quantity with the magnitude given by scalar.\n    quant(q) yields q for any quantity q; if q is not part of the pimms units registry, then a\n      version of q registered to pimms.units is yielded. Note that q is a quantity if\n      pimms.is_quantity(q) is True.\n    quant(x, u) yields the given scalar or quantity x converted to the given unit u; if x is a\n      scalar or a dimensionless quantity, then the unit u is given to the new quantity with no\n      conversion; otherwise, x must be a quantity whose unit can be converted into the unit u.\n    '''\n    if is_quantity(val):\n        if isinstance(val, tuple) or val._REGISTRY is not units:\n            val = units.Quantity(mag(val), unit(val))\n        return val if u is Ellipsis or u is None else val.to(unit(u))\n    else:\n        return units.Quantity(val, units.dimensionless if u is Ellipsis or u is None else unit(u))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if a and b can be cast to each other in terms of units and False otherwise.", "response": "def like_units(a, b):\n    '''\n    like_units(a,b) yields True if a and b can be cast to each other in terms of units and False\n      otherwise. Non-united units are considered dimensionless units.\n    '''\n    a = quant(0.0, a) if is_unit(a) else a if is_quantity(a) else quant(a, units.dimensionless)\n    b = quant(0.0, b) if is_unit(b) else b if is_quantity(b) else quant(b, units.dimensionless)\n    if a == b: return True\n    try:\n        c = a.to(b.u)\n        return True\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef qhashform(o):\n    '''\n    qhashform(o) yields a version of o, if possible, that yields a hash that can be reproduced\n      across instances. This correctly handles quantities and numpy arrays, among other things.\n    '''\n    if is_quantity(o): return ('__#quant', qhashform(mag(o)), str(o.u))\n    elif isinstance(o, np.ndarray) and np.issubdtype(o.dtype, np.dtype(np.number).type):\n        return ('__#ndarray', o.tobytes())\n    elif isinstance(o, (set, frozenset)): return ('__#set', tuple([qhashform(x) for x in o]))\n    elif is_map(o): return ps.pmap({qhashform(k):qhashform(v) for (k,v) in six.iteritems(o)})\n    elif is_str(o): return o\n    elif hasattr(o, '__iter__'): return tuple([qhashform(u) for u in o])\n    else: return o", "response": "Returns a version of o that yields a hash that can be reproduced\n      across instances."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(filename, obj, overwrite=False, create_directories=False):\n    '''\n    pimms.save(filename, obj) attempts to pickle the given object obj in the filename (or stream,\n      if given). An error is raised when this cannot be accomplished; the first argument is always\n      returned; though if the argument is a filename, it may be a differet string that refers to\n      the same file.\n\n    The save/load protocol uses pickle for all saving/loading except when the object is a numpy\n    object, in which case it is written using obj.tofile(). The save function writes meta-data\n    into the file so cannot simply be unpickled, but must be loaded using the pimms.load()\n    function. Fundamentally, however, if an object can be picled, it can be saved/loaded.\n\n    Options:\n      * overwrite (False) The optional parameter overwrite indicates whether an error should be\n        raised before opening the file if the file already exists.\n      * create_directories (False) The optional parameter create_directories indicates whether the\n        function should attempt to create the directories in which the filename exists if they do\n        not already exist.\n    '''\n    if isinstance(filename, six.string_types):\n        filename = os.path.expanduser(filename)\n        if not overwrite and os.path.exists(filename):\n            raise ValueError('save would overwrite file %s' % filename)\n        if create_directories:\n            dname = os.path.dirname(os.path.realpath(filename))\n            if not os.path.isdir(dname): os.makedirs(dname)\n        with open(filename, 'wb') as f:\n            _save_stream(f, obj)\n    else:\n        _save_stream(filename, obj)\n    return filename", "response": "Save the object obj to the file filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a pimms - formatted save - file from the given filename", "response": "def load(filename, ureg='pimms'):\n    '''\n    pimms.load(filename) loads a pimms-formatted save-file from the given filename, which may\n      optionaly be a string. By default, this function forces all quantities (via the pint\n      module) to be loaded using the pimms.units unit registry; the option ureg can change\n      this.\n\n    If the filename is not a correctly formatted pimms save-file, an error is raised.\n\n    Options:\n      * ureg ('pimms') specifies the unit-registry to use for ping module units that are loaded\n        from the files; 'pimms' is equivalent to pimms.units. None is equivalent to using the\n        pint._APP_REGISTRY unit registry.\n    '''\n    if ureg is not None:\n        if ureg == 'pimms': ureg = units\n        orig_app_ureg = pint._APP_REGISTRY\n        orig_dfl_ureg = pint._DEFAULT_REGISTRY\n        pint._APP_REGISTRY = ureg\n        pint._DEFAULT_REGISTRY = ureg\n        try:    return load(filename, ureg=None)\n        except: raise\n        finally:\n            pint._APP_REGISTRY     = orig_app_ureg\n            pint._DEFAULT_REGISTRY = orig_dfl_ureg\n    if isinstance(filename, six.string_types):\n        filename = os.path.expanduser(filename)\n        with open(filename, 'rb') as f:\n            return _load_stream(f)\n    else:\n        return _load_stream(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_str(arg):\n    '''\n    is_str(x) yields True if x is a string object or a 0-dim numpy array of a string and yields\n      False otherwise. \n    '''\n    return (isinstance(arg, six.string_types) or\n            is_npscalar(arg, 'string') or\n            is_npvalue(arg, 'string'))", "response": "Returns True if the argument is a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef numpy_type(type_id):\n    '''\n    numpy_type(type) yields a tuple of valid numpy types that can represent the type specified in\n      the given type argument. The type argument may be a numpy type such as numpy.signedinteger, in\n      which case a tuple containing only it is returned. Alternately, it may be a string that labels\n      a numpy type or a builtin type that should be translated to a numpy type (see below).\n\n    Note that numpy_types() does note intend to reproduce the numpy type hierarchy! If you want to\n    perform comparisons on the numpy hierarchy, use numpy's functions. Rather, numpy_type()\n    represents types in a mathematical hierarchy, so, for example, numpy_type('real') yields the\n    tuple (numpy.floating, numpy.integer, numpy.bool_) because all of these are valid real numbers.\n\n    Valid numpy type strings include:\n      * 'bool'\n      * 'int' / 'integer' (integers and booleans)\n      * 'float' / 'real' (integers, booleans, or floating-point)\n      * 'complex' / 'number' (integers, booleans, reals, or complex numbers)\n      * 'string' ('unicode' in Python 3, 'bytes' in Python 2)\n      * 'unicode'\n      * 'bytes'\n      * 'chars' (numpy.character)\n      * 'object'\n      * 'any'\n    Valid builtin types include:\n      * int (also long in Python 2), like 'int'\n      * float, like 'float'\n      * complex, like 'complex'\n      * str, like 'string'\n      * bytes, like 'bytes',\n      * unicode, like 'unicode'\n      * object, like 'object'\n      * None, like 'any'\n    '''\n    if is_str(type_id):\n        return _numpy_type_names[type_id.lower()]\n    elif isinstance(type_id, (list, tuple)):\n        return tuple([dt for s in type_id for dt in numpy_type(s)])\n    elif type_id is None:\n        return _numpy_type_names['any']\n    elif type_id in six.integer_types:       return _numpy_type_names['int']\n    elif type_id is float:                   return _numpy_type_names['float']\n    elif type_id is numbers.Real:            return _numpy_type_names['real']\n    elif type_id is complex:                 return _numpy_type_names['complex']\n    elif type_id is numbers.Complex:         return _numpy_type_names['complex']\n    elif type_id is bool:                    return _numpy_type_names['bool']\n    elif type_id is str:                     return _numpy_type_names['string']\n    elif type_id is unicode:                 return _numpy_type_names['unicode']\n    elif type_id is bytes:                   return _numpy_type_names['bytes']\n    elif type_id is object:                  return _numpy_type_names['object']\n    elif np.issubdtype(type_id, np.generic): return (type_id,)\n    else: raise ValueError('Could not deduce numpy type for %s' % type_id)", "response": "Returns a tuple of numpy types that can be represented by the given type argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_npvalue(u, dtype):\n    '''\n    is_npvalue(u, dtype) yields True if u is a member of the given dtype according to numpy. The\n      dtype may be specified as a string (see numpy_type) or a type. Note that dtype may be None,\n      'any', or np.generic, but this will always return True if so.\n\n    Note that is_npvalue(1, 'int') will yield True, while is_npvalue(np.array(1), 'int'),\n    is_npvalue(np.array([1]), 'int'), and is_npvalue([1], 'int') will yield False (because lists\n    and numpy arrays of ints aren't ints).\n\n    See also is_nparray, is_npscalar, is_scalar.\n    '''\n    if is_quantity(u): return is_npvalue(mag(u), dtype=dtype)\n    return any(np.issubdtype(type(u), np.generic if d is None else d) for d in numpy_type(dtype))", "response": "Returns True if u is a member of the given dtype."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_seq(arg):\n    '''\n    is_seq(arg) yields True if arg is a sequential collection otherwise False; i.e., it must be a\n      list, tuple, persistent vector, persistent list, or numpy array.\n    \n    Note that strings are not considered sequences.\n    '''\n    return isinstance(arg, (list_type, tuple_type, pyr.PVector, pyr.PList)) or is_nparray(arg)", "response": "Returns True if arg is a sequential collection otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_pseq(arg):\n    '''\n    is_pseq(arg) yields True if arg is a persistent vector, a persistent list, a tuple, or a numpy\n      array with its writeable flag off.\n    '''\n    if is_nparray(arg): return arg.flags['WRITEABLE'] == False\n    return isinstance(arg, (tuple_type, pyr.PVector, pyr.PList))", "response": "Returns True if arg is a persistent sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_int(arg):\n    '''\n    is_int(x) yields True if x is an integer object and False otherwise; integer objects include the\n      standard Python integer types as well as numpy single integer arrays (i.e., where\n      x.shape == ()) and quantities with integer magnitudes.\n    '''\n    return (is_int(mag(arg)) if is_quantity(arg)                   else\n            True             if isinstance(arg, six.integer_types) else\n            is_npscalar(arg, 'int') or is_npvalue(arg, 'int'))", "response": "Returns True if the argument is an integer object and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_real(arg):\n    '''\n    is_real(x) yields True if x is a non-complex numeric object and False otherwise.\n\n    Note that is_real(i) will yield True for an integer or bool i; to check for floating-point\n    representations of numbers, use is_array(x, numpy.floating) or similar.\n    '''\n    return (is_real(mag(arg)) if is_quantity(arg)       else\n            True              if isinstance(arg, float) else\n            is_npscalar(arg, 'real') or is_npvalue(arg, 'real'))", "response": "Returns True if the argument is real."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if x is an inexact number.", "response": "def is_inexact(arg):\n    '''\n    is_inexact(x) yields True if x is a number represented by floating-point data (i.e., either a\n      non-integer real number or a complex number) and False otherwise.\n    '''\n    return (is_inexact(mag(arg)) if is_quantity(arg) else\n            is_npscalar(u, np.inexact) or is_npvalue(arg, np.inexact))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_complex(arg):\n    '''\n    is_complex(x) yields True if x is a complex numeric object and False otherwise. Note that this\n      includes anything representable as as a complex number such as an integer or a boolean value.\n      In effect, this makes this function an alias for is_number(arg).\n    '''\n    return (is_complex(mag(arg)) if is_quantity(arg)                 else\n            True                 if isinstance(arg, numbers.Complex) else\n            is_npscalar(arg, 'complex') or is_npvalue(arg, 'complex'))", "response": "Returns True if the argument is a complex number and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if x is a numeric object and False otherwise.", "response": "def is_number(arg):\n    '''\n    is_number(x) yields True if x is a numeric object and False otherwise.\n    '''\n    return (is_number(mag(arg)) if is_quantity(arg)              else\n            is_npscalar(arg, 'number') or is_npvalue(arg, 'number'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a lazy map whose keys are the same as those of the given dict or mapping object.", "response": "def lazy_value_map(f, m, *args, **kwargs):\n    '''\n    lazy_value_map(f, mapping) yields a lazy map whose keys are the same as those of the given dict\n      or mapping object and whose values, for each key k are f(mapping[k]).\n    lazy_value_map(f, mapping, *args, **kw) additionally passes the given arguments to the function\n      f, so in the resulting map, each key k is mapped to f(mapping[k], *args, **kw).\n\n    If a dict object that is not persistent is passed to lazy_value_map, then a persistent copy of\n    it is made for use with the lazy-map; accordingly, it's not necessary to worry about the \n    persistence of the map you pass to this function. It is, however, important to worry about the\n    persistence of the values in the map you pass. If these values are mutated in-place, then the\n    lazy map returned from this function could change as well.\n\n    If the given mapping object is an ITable object, then an ITable object is returned.\n    '''\n    if not is_map(m): raise ValueError('Non-mapping object passed to lazy_value_map')\n    if not is_lazy_map(m) and not is_pmap(m): m = ps.pmap(m)\n    def curry_fn(k): return lambda:f(m[k], *args, **kwargs)\n    m0 = {k:curry_fn(k) for k in six.iterkeys(m)}\n    from .table import (is_itable, itable)\n    return itable(m0) if is_itable(m) else lazy_map(m0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value_map(f, m, *args, **kwargs):\n    '''\n    value_map(f, mapping) yields a persistent map whose keys are the same as those of the given dict\n      or mapping object and whose values, for each key k are f(mapping[k]).\n    value_map(f, mapping, *args, **kw) additionally passes the given arguments to the function\n      f, so in the resulting map, each key k is mapped to f(mapping[k], *args, **kw).\n\n    Unlike lazy_value_map, this function yields either a persistent or a lazy map depending on the\n    input argument mapping. If mapping is a lazy map, then a lazy map is returned; otherwise, a\n    persistent non-lazy map is returned.\n    '''\n    if is_lazy_map(m): return lazy_value_map(f, m, *args, **kwargs)\n    else:              return ps.pmap({k:f(v, *args, **kwargs) for (k,v) in six.iteritems(m)})", "response": "A value_map implementation that uses a function to map values to persistent dicts."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a persistent map containing all the given keys in the given order.", "response": "def collect(*args, **kwargs):\n    '''\n    collect(m1, m2, ...) yields a persistent map whose keys are the union of all keys in the given\n      maps m1, m2, etc. and whose values are tuples containing each of the given maps (in provided\n      order) that contain the given key. This function never evaluates the values in the maps so it\n      implicitly supports laziness.\n\n    The collect function fist passes its arguments to flatten_maps, so it is fine to pass lists or\n    nested lists of maps to this function; all will be collected.\n    '''\n    args = flatten_maps(args, **kwargs)\n    if len(args) == 0: return ps.m()\n    m = {}\n    for arg in args:\n        for k in six.iterkeys(arg):\n            if k in m: m[k].append(arg)\n            else: m[k] = [arg]\n    return ps.pmap({k:tuple(v) for (k,v) in six.iteritems(m)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(*args, **kwargs):\n    '''\n    merge(...) lazily collapses all arguments, which must be python Mapping objects of some kind,\n      into a single mapping from left-to-right. The mapping that is returned is a lazy persistent\n      object that does not request the value of a key from any of the maps provided until they are\n      requested of it; in this fashion it preserves the laziness of immutable map objects that are\n      passed to it. Arguments may be mappings or lists/tuples of mappings.\n\n    If all of the arguments passed to merge are pimms itables with the same row_count, then an\n    itable object is returned instead of a lazy map.\n\n    The following options are accepted:\n    * choose (default None) specifies a function that chooses from which map, of those maps given\n      to merge, the value should be drawn when keys overlap. The function is always passed two\n      arguments: the key for which the conflict occurs and a list of maps containing that key; it\n      should return the value to which the key should be mapped. The default uses the first map.\n    '''\n    from .table import (is_itable, ITable)\n    # figure out the choose-fn\n    choose_fn = None\n    if 'choose' in kwargs:\n        choose_fn = kwargs['choose']\n    if len(kwargs) > 1 or (len(kwargs) > 0 and 'choose' not in kwargs):\n        raise ValueError('Unidentified options given to merge: %s' (kwargs.keys(),))\n    # collect the maps...\n    maps = flatten_maps(*args)\n    if len(maps) == 0: return ps.m()\n    elif len(maps) == 1: return maps[0]\n    coll = collect(maps)\n    if choose_fn is None: choose_fn = _choose_last\n    def curry_choice(k, args): return lambda:choose_fn(k, args)\n    resmap = lazy_map({k:curry_choice(k, v) for (k,v) in six.iteritems(coll)})\n    # if they're all itables of the same size, return an itable\n    if is_itable(maps[0]):\n        n = maps[0].row_count\n        if all(is_itable(m) and m.row_count == n for m in maps):\n            return ITable(resmap, n)\n    # otherwise return the lazy map\n    return resmap", "response": "Merge two or more maps into a single lazy persistent object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the argument is a persistent object and False otherwise.", "response": "def is_persistent(arg):\n    '''\n    is_persistent(x) yields True if x is a persistent object and False if not.\n\n    Note that this persistence can only be checked by the pimms library, so immutable/persistent\n    structures not known to pimms or defined in terms of pimms's immutables library cannot be\n    evaluated correctly.\n\n    Additionally, is_persistent(x) checks only x; if x is a tuple of mutable objects, it is still\n    considered a persistent object.\n    '''\n    from .immutable import (is_imm, imm_is_persistent)\n    if is_imm(arg): return imm_is_persistent(arg)\n    elif isinstance(arg, (np.generic, np.ndarray)): return not arg.flags.writeable\n    elif is_quantity(arg) and isinstance(mag(arg), (np.generic, np.ndarray)):\n        return not mag(arg).flags.writable\n    elif is_str(arg): return True\n    elif is_number(arg): return True\n    elif is_pmap(arg): return True\n    elif isinstance(arg, frozenset): return True\n    elif isinstance(arg, (ps.PVector, ps.PSet, ps.PList, ps.PRecord)): return True\n    else: return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a persistent version of the given argument.", "response": "def persist(arg, depth=Ellipsis, on_mutable=None):\n    '''\n    persist(x) yields a persistent version of x if possible, or yields x itself.\n\n    The transformations performed by persist(x) are as follows:\n      * If x is an immutable object, yields x.persist()\n      * If x is a set, yield a frozenset of of persist(u) for all u in x.\n      * If x is a numpy array, yield imm_array(x).\n      * If x is a map, yields a persistent version of x with all keys and values replaced with their\n        persist()'ed form; note that this respects laziness and itables.\n      * If x is a list/tuple type, yields a tuple of persist()'ed contents.\n      * Otherwise, if the type of x is not recognized, yields x.\n\n    The depth to which persist() searches the argument's elements is controlled by the depth option;\n    the default behavior is to persist objects down to the point that a persistent object is found,\n    at which its elements are not checked for persistence.\n\n    Note that persist() is not guaranteed to recognize a particular object; it is intended as a\n    utility function for basic functional-style and immutable data code in Python. In particular,\n    it is usefl for pimms's immutable objects; dicts and mappings; pimms's lazy-maps and itables;\n    pyrsistent's sets, vectors, and maps; sets and frozensets (which are both communted to\n    frozensets); and anything implementing __iter__ (which are commuted to tuples). Objects that are\n    not numbers or strings are considered potentially-mutable and will trigger the on_mutable case.\n\n    The optional arguments may be passed to persist:\n      * depth (default: Ellipsis) specifies the depth to which toe persist() function should search\n        when persisting objects. The given argument is considered depth 0, so persist(arg, 0) will\n        persist only arg and not its contents, if it is a collection. If None is given, then goes to\n        any depth; if Ellipsis is given, then searches until a persistent object is found, but does\n        not attempt to persist the elements of already-persistent containers (this is the default).\n      * on_mutable (default: None) specifies what to do when a non-persistable object is encountered\n        in the search. If None, then the object is left; if 'error', then an error is raised;\n        otherwise, this must be a function that is passed the object--the return value of this\n        function is the replacement used in the object returned from persist().\n    '''\n    from .immutable import (is_imm, imm_copy)\n    # Parse the on_mutable argument\n    if on_mutable is None: on_mutable = lambda x:x\n    elif on_mutable == 'error':\n        def _raise(x):\n            raise ValueError('non-persistable: %s' % x)\n        on_mutable = _raise\n    if depth in (None, Ellipsis): depth_next = depth\n    elif depth < 0: return arg\n    else: depth_next = depth - 1\n    precur = lambda x:persist(x, depth=depth_next, on_mutable=on_mutable)\n    # See if we have an easy type to handle\n    if is_imm(arg): return imm_copy(arg)\n    if is_quantity(arg):\n        (m,u) = (mag(arg), unit(arg))\n        mm = precur(m)\n        if mm is m: return arg\n        else: return quant(mm, u)\n    elif isinstance(arg, np.ndarray): return imm_array(arg)\n    elif isinstance(arg, np.generic):\n        x = type(arg)(arg)\n        x.setflags(write=False)\n        return x\n    elif is_str(arg) or is_number(arg): return arg\n    elif isinstance(arg, ps.PVector):\n        if depth is Ellipsis or depth == 0: return arg\n        for (k,v0) in zip(range(len(arg)), arg):\n            v = precur(v0)\n            if v0 is not v: arg = arg.set(k,v)\n        return arg\n    elif isinstance(arg, ps.PSet):\n        if depth is Ellipsis or depth == 0: return arg\n        for v0 in arg:\n            v = precur(v0)\n            if v0 is not v: arg = arg.discard(v0).add(v)\n        return arg\n    elif is_pmap(arg):\n        if depth is Ellipsis or depth == 0: return arg\n        return key_map(precur, value_map(precur, arg))\n    elif is_map(arg):\n        if not is_pmap(arg): arg = ps.pmap(arg)\n        if depth == 0: return arg\n        return key_map(precur, value_map(precur, arg))\n    elif isinstance(arg, frozenset):\n        if depth is Ellipsis or depth == 0: return frozenset(arg)\n        a = [x for x in arg]\n        q = [precur(x) for x in a]\n        if all(ai is qi for (ai,qi) in zip(a,q)): return arg\n        return frozenset(q)\n    elif isinstance(arg, set):\n        if depth == 0: return frozenset(arg)\n        a = [x for x in arg]\n        q = [precur(x) for x in a]\n        if isinstance(arg, frozenset) and all(ai is qi for (ai,qi) in zip(a,q)): return arg\n        return frozenset(q)\n    elif hasattr(arg, '__iter__'):\n        if depth == 0 or (depth is Ellipsis and isinstance(arg, tuple)): return tuple(arg)\n        q = tuple(precur(x) for x in arg)\n        if isinstance(arg, tuple) and all(ai is qi for (ai,qi) in zip(arg,q)): return arg\n        else: return q\n    elif isinstance(arg, (types.FunctionType, partial)):\n        return arg\n    else: return on_mutable(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a mutable pythin dictionary with the arguments k1 k2... etc.", "response": "def dissoc(m, *args, **kw):\n    '''\n    dissoc(m, k1, k2...) yields a map equivalent to m without the arguments k1, k2, etc. If m is a\n      mutable pythin dictionary, this is equivalent to using del m[k] for k in [k1, k2...] then\n      returning m itself. If m is a persistent map, this is equivalent to calling m = m.discard(k)\n      for all the keys then returning m.\n\n    If m is not a map but is instead a list or persistent vector, this operates as if the\n    list/vector is a map whose keys are integers. If an item not at the end of the vector is deleted\n    then it is replaced with None instead of pop'ed.\n\n    The optional argument error (default: False) specifies whether an error should be raised when\n    one of the keys is not found; this applies to mutable or immutable arguments.\n    '''\n    if   len(kw) == 0: err = False\n    elif len(kw) == 1: err = kw['error']\n    else:              raise ValueError('unrecognized optional arguments')\n    if is_pmap(m):\n        if err:\n            for k in args: m = m.remove(k)\n        else:\n            for k in args: m = m.discard(k)\n        return m\n    elif is_map(m):\n        if err:\n            for k in args: del m[k]\n        else:\n            for k in args:\n                if k in m: del m[k]\n        return m\n    elif isinstance(m, tuple_type):\n        return m if len(args) == 0 else tuple(dissoc(list(m), *args, error=err))\n    elif isinstance(m, list_type):\n        if len(args) == 0: return m\n        n = len(m)\n        if err:\n            for k in args:\n                if not is_int(k) or k < 0 or k >= n: raise KeyError(k)\n        else: args = [k for k in args if is_int(k)]\n        args = sorted(list(set(k if k >= 0 else n + k for k in args)))\n        if err:\n            for k in args:\n                if k < 0 or k >= n: raise KeyError(k)\n        else: args = [k for k in args if k < n and k >= 0]\n        n -= 1 # just for eliminating the == n-1 in the next line\n        while len(args) > 0 and args[-1] == n:\n            m.pop()\n            args.pop()\n            n -= 1\n        for k in args: m[k] = None\n        return m\n    elif is_nparray(m):\n        args = list(args)\n        if len(args) == 0: return m\n        return np.asarray(dissoc(m.tolist(), *args, error=err))\n    else: raise ValueError('Cannot dissoc from given type: %s' % type(m))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _examine_val(self, k, val):\n        'should only be called internally'\n        if not isinstance(val, (types.FunctionType, partial)): return val\n        vid = id(val)\n        if vid in self._memoized:\n            return self._memoized[vid]\n        elif [] != getargspec_py27like(val)[0]:\n            return val\n        else:\n            val = val()\n            object.__setattr__(self, '_memoized', self._memoized.set(vid, val))\n            return val", "response": "should only be called internally"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_lazy(self, k):\n        '''\n        lmap.is_lazy(k) yields True if the given k is lazy and unmemoized in the given lazy map,\n        lmap, otherwise False.\n        '''\n        v = ps.PMap.__getitem__(self, k)\n        if not isinstance(v, (types.FunctionType, partial)) or \\\n           id(v) in self._memoized or \\\n           [] != getargspec_py27like(v)[0]:\n            return False\n        else:\n            return True", "response": "Returns True if the given key is lazy and unmemoized in the given lazy map otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_memoized(self, k):\n        '''\n        lmap.is_memoized(k) yields True if k is a key in the given lazy map lmap that is both lazy\n        and already memoized.\n        '''\n        v = ps.PMap.__getitem__(self, k)\n        if not isinstance(v, (types.FunctionType, partial)):\n            return False\n        else:\n            return id(v) in self._memoized", "response": "Returns True if k is a key in the given lazy map lmap that is already memoized."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef psh_fire_msg_action_if_new(sender, instance, created, **kwargs):\n    if created:\n        from message_sender.tasks import send_message\n\n        send_message.apply_async(kwargs={\"message_id\": str(instance.id)})", "response": "Post save hook to fire message send task\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nposts save hook to ensure that there is only one default channel", "response": "def update_default_channels(sender, instance, created, **kwargs):\n    \"\"\" Post save hook to ensure that there is only one default\n    \"\"\"\n    if instance.default:\n        Channel.objects.filter(default=True).exclude(\n            channel_id=instance.channel_id\n        ).update(default=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mktree(newdir):\n    if os.path.isdir(newdir):\n        pass\n    elif os.path.isfile(newdir):\n        raise OSError(\"a file with the same name as the desired \"\n                      \"dir, '%s', already exists.\" % newdir)\n    else:\n        os.makedirs(newdir)", "response": "Make a tree of the tree of files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a message to the set of topics and payload.", "response": "def shh_post(self, from_=None, to=None, *, topics, payload, priority, ttl):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#shh_post\n        \"\"\"\n        # FIXME: Not working\n        obj = {\n            'from': from_,\n            'to': to,\n            'topics': topics,\n            'payload': payload,\n            'priority': hex(priority),\n            'ttl': hex(ttl),\n        }\n        return float((yield from self.rpc_call('shh_post', [obj])))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_fit(interface, state, label, inp):\n    import numpy as np\n    ete, etde = 0, 0\n    out = interface.output(0)\n\n    for row in inp:\n        row = row.strip().split(state[\"delimiter\"])  # split row\n        if len(row) > 1:  # check if row is empty\n            # intercept term is added to every sample\n            x = np.array([(0 if v in state[\"missing_vals\"] else float(v)) for i, v in enumerate(row) if\n                          i in state[\"X_indices\"]] + [-1])\n            # map label value to 1 or -1. If label does not match set error\n            y = 1 if state[\"y_map\"][0] == row[state[\"y_index\"]] else -1 if state[\"y_map\"][1] == row[\n                state[\"y_index\"]] else \"Error\"\n            ete += np.outer(x, x)\n            etde += x * y\n    out.add(\"etde\", etde)\n    for i, row in enumerate(ete):\n        out.add(i, row)", "response": "Function calculates matrices ete etde for every sample aggregates and outputs them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction joins all partially calculated matrices ETE and ETDe aggregates them and calculates final parameters.", "response": "def reduce_fit(interface, state, label, inp):\n    \"\"\"\n    Function joins all partially calculated matrices ETE and ETDe, aggregates them and it calculates final parameters.\n    \"\"\"\n    import numpy as np\n\n    out = interface.output(0)\n    sum_etde = 0\n    sum_ete = [0 for _ in range(len(state[\"X_indices\"]) + 1)]\n    for key, value in inp:\n        if key == \"etde\":\n            sum_etde += value\n        else:\n            sum_ete[key] += value\n\n    sum_ete += np.true_divide(np.eye(len(sum_ete)), state[\"nu\"])\n    out.add(\"params\", np.linalg.lstsq(sum_ete, sum_etde)[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(dataset, nu=0.1, save_results=True, show=False):\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import Job\n\n    if dataset.params[\"y_map\"] == []:\n        raise Exception(\"Linear proximal SVM requires a target label mapping parameter.\")\n    try:\n        nu = float(nu)\n        if nu <= 0:\n            raise Exception(\"Parameter nu should be greater than 0\")\n    except ValueError:\n        raise Exception(\"Parameter should be numerical.\")\n\n    job = Job(worker=Worker(save_results=save_results))\n\n    # job parallelizes mappers and joins them with one reducer\n    job.pipeline = [\n        (\"split\", Stage(\"map\", input_chain=dataset.params[\"input_chain\"], init=simple_init, process=map_fit)),\n        ('group_all', Stage(\"reduce\", init=simple_init, process=reduce_fit, combine=True))]\n\n    job.params = dataset.params\n    job.params[\"nu\"] = nu\n    job.run(name=\"linearsvm_fit\", input=dataset.params[\"data_tag\"])\n    fitmodel_url = job.wait(show=show)\n    return {\"linsvm_fitmodel\": fitmodel_url}", "response": "Function starts a job for calculation of model parameters on the classifier and returns the url of the fit model on the classifier"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions starts a job that makes predictions to input data with a given model.", "response": "def predict(dataset, fitmodel_url, save_results=True, show=False):\n    \"\"\"\n    Function starts a job that makes predictions to input data with a given model.\n\n    Parameters\n    ----------\n    input - dataset object with input urls and other parameters\n    fitmodel_url - model created in fit phase\n    save_results - save results to ddfs\n    show - show info about job execution\n\n    Returns\n    -------\n    Urls with predictions on ddfs\n    \"\"\"\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import Job, result_iterator\n\n    if \"linsvm_fitmodel\" not in fitmodel_url:\n        raise Exception(\"Incorrect fit model.\")\n\n    job = Job(worker=Worker(save_results=save_results))\n    # job parallelizes execution of mappers\n    job.pipeline = [\n        (\"split\", Stage(\"map\", input_chain=dataset.params[\"input_chain\"], init=simple_init, process=map_predict))]\n\n    job.params = dataset.params\n    job.params[\"fit_params\"] = [v for _, v in result_iterator(fitmodel_url[\"linsvm_fitmodel\"])][0]\n    job.run(name=\"linsvm_predict\", input=dataset.params[\"data_tag\"])\n\n    return job.wait(show=show)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of paths available from a directory.", "response": "def fingerprint(dirnames, prefix=None, previous=[]):\n    #pylint:disable=dangerous-default-value\n    \"\"\"\n    Returns a list of paths available from *dirname*. When previous\n    is specified, returns a list of additional files only.\n\n    Example:\n    [{ \"Key\": \"abc.txt\",\n       \"LastModified\": \"Mon, 05 Jan 2015 12:00:00 UTC\"},\n     { \"Key\": \"def.txt\",\n       \"LastModified\": \"Mon, 05 Jan 2015 12:00:001 UTC\"},\n    ]\n    \"\"\"\n    results = []\n    for dirname in dirnames:\n        for filename in os.listdir(dirname):\n            fullpath = os.path.join(dirname, filename)\n            if os.path.isdir(fullpath):\n                results += fingerprint(\n                    [fullpath], prefix=filename, previous=previous)\n            else:\n                fullname = fullpath\n                if prefix and fullname.startswith(prefix):\n                    fullname = fullname[len(prefix):]\n                found = False\n                for prevpath in previous:\n                    if fullname == prevpath['Key']:\n                        found = True\n                        break\n                if not found:\n                    mtime = datetime.datetime.fromtimestamp(\n                        os.path.getmtime(fullpath), tz=utc)\n                    results += [{\"Key\": fullname,\n                                 \"LastModified\": mtime.strftime(\n                                     '%a, %d %b %Y %H:%M:%S %Z')}]\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all files present in a directory and with their timestamp.", "response": "def list_local(paths, prefix=None):\n    \"\"\"\n    Returns a list of all files (recursively) present in a directory\n    with their timestamp.\n\n    Example:\n    [{ \"Key\": \"abc.txt\",\n       \"LastModified\": \"Mon, 05 Jan 2015 12:00:00 UTC\"},\n     { \"Key\": \"def.txt\",\n       \"LastModified\": \"Mon, 05 Jan 2015 12:00:001 UTC\"},\n    ]\n    \"\"\"\n    results = []\n    for path in paths:\n        if os.path.isdir(path):\n            for filename in os.listdir(path):\n                fullpath = os.path.join(path, filename)\n                if os.path.isdir(fullpath):\n                    results += list_local([fullpath], prefix)\n                else:\n                    fullname = fullpath\n                    if prefix and fullname.startswith(prefix):\n                        fullname = fullname[len(prefix):]\n                    mtime = datetime.datetime.fromtimestamp(\n                        os.path.getmtime(fullpath), tz=utc)\n                    results += [{\"Key\": fullname,\n                        \"LastModified\": mtime.strftime(\n                                '%a, %d %b %Y %H:%M:%S %Z')}]\n        else:\n            fullpath = path\n            fullname = fullpath\n            if prefix and fullname.startswith(prefix):\n                fullname = fullname[len(prefix):]\n            mtime = datetime.datetime.fromtimestamp(\n                os.path.getmtime(fullpath), tz=utc)\n            results += [{\"Key\": fullname,\n                \"LastModified\": mtime.strftime(\n                        '%a, %d %b %Y %H:%M:%S %Z')}]\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the next_url against the allowed hosts.", "response": "def validate_redirect_url(next_url):\n        \"\"\"\n        Returns the next_url path if next_url matches allowed hosts.\n        \"\"\"\n        if not next_url:\n            return None\n        parts = urlparse(next_url)\n        if parts.netloc:\n            domain, _ = split_domain_port(parts.netloc)\n            allowed_hosts = (['*'] if django_settings.DEBUG\n                else django_settings.ALLOWED_HOSTS)\n            if not (domain and validate_host(domain, allowed_hosts)):\n                return None\n        return urlunparse((\"\", \"\", parts.path,\n            parts.params, parts.query, parts.fragment))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_currency(amount, from_currency, to_currency):\n    '''\n    Converts currencies.\n\n    Example:\n    {% convert_currency 2 'EUR' 'SGD' as amount %}\n\n    '''\n    try:\n        rate = CurrencyRate.objects.get(\n            from_currency__iso_code=from_currency,\n            to_currency__iso_code=to_currency)\n    except CurrencyRate.DoesNotExist:\n        return _('n/a')\n    try:\n        history = rate.history.all()[0]\n    except IndexError:\n        return _('n/a')\n    return amount * history.value", "response": "Converts amount from one currency to another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the next row of the reader s iterable object.", "response": "def next(self):\n        \"\"\"Returns the next row of the reader\u2019s iterable object.\"\"\"\n        row = self.reader.next()\n        return [s.decode(\"utf-8\") for s in row]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef url_prefixed(regex, view, name=None):\n    return url(r'^%(app_prefix)s%(regex)s' % {\n        'app_prefix': APP_PREFIX, 'regex': regex}, view, name=name)", "response": "Returns a urlpattern prefixed with the APP_NAME in debug mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a list of output lines and return a list of events.", "response": "def simple_parse_process(\n        parser: Parser[A, B],\n        node: str,\n        output: List[str],\n        result: List[OutputEvent[A, B]],\n        current: List[OutputLine[A]],\n) -> List[OutputEvent[A, B]]:\n    '''\n    Parse a list of output lines.\n    The algorithm starts at the graph node 'start'\n    1. detach the first output line into *line* and *rest* and call\n        *parse_line*\n    2. find an edge that matches to current line\n    a) if a match was found\n        3. construct an *OutputLine*\n        4. set the current node to the target node of the edge\n        5. add the entry to the list *current*\n        6. recurse with *rest* as new *output*\n    b) if no match was found\n        7. construct an *OutputEvent* from *current*\n        8. if the current node is 'start', set *output* to *rest*\n            else, keep *output* to try again with 'start'\n        9. recurse with 'start'\n    10. add the last event and exit the recursion\n    '''\n    def add_event() -> List[OutputEvent[A, B]]:\n        new = Nil if current.empty else parser.cons_events(current)\n        return result + new\n    def parse_line(line: str, rest: List[str]) -> Tuple[bool, tuple]:\n        log.debug2(lambda: f'parsing line: {line}')\n        @do(Either[str, Tuple[OutputLine[A], str]])\n        def match(step: Step) -> Do:\n            match = yield step.data.regex.match(line)\n            log.debug2(lambda: f'matched edge to {step.node}')\n            output_line = yield cons_output_line(step.data.cons_output_line)(match)\n            return output_line, step.node\n        def cont(entry: OutputLine[A], next_node: str) -> Tuple[bool, tuple]:\n            return True, (parser, next_node, rest, result, current.cat(entry))\n        def next_event() -> Tuple[bool, tuple]:\n            new_output = rest if node == 'start' and current.empty else output\n            return True, (parser, 'start', new_output, add_event(), List())\n        return match_edge(parser.graph, node, match).map2(cont) | next_event\n    quit = lambda: (False, add_event())\n    return output.detach_head.map2(parse_line) | quit"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_polygon_from_postgis(conn, schema, table, gcol='geom', union=False):\n    # TODO@G\u00fcnni\n    logging.debug('Getting polygon from DB table')\n    if union:\n        geo_string = 'st_union({0})'.format(gcol)\n    else:\n        geo_string = '{0}'.format(gcol)\n\n    sql = '''\n        SELECT st_astext(ST_Transform({geo_string}, 4326))\n        FROM {schema}.{table};\n    '''.format(**{'geo_string': geo_string, 'schema': schema, 'table': table})\n    return wkt_loads(conn.execute(sql).fetchone()[0])", "response": "r Returns a polygon that can be used in a postgis table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind windzone from map.", "response": "def get_windzone(conn, geometry):\n    'Find windzone from map.'\n    # TODO@G\u00fcnni\n    if geometry.geom_type in ['Polygon', 'MultiPolygon']:\n        coords = geometry.centroid\n    else:\n        coords = geometry\n    sql = \"\"\"\n        SELECT zone FROM oemof_test.windzones\n        WHERE st_contains(geom, ST_PointFromText('{wkt}', 4326));\n        \"\"\".format(wkt=coords.wkt)\n    zone = conn.execute(sql).fetchone()\n    if zone is not None:\n        zone = zone[0]\n    else:\n        zone = 0\n    return zone"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_empty_table_serial_primary(conn, schema, table, columns=None,\n                                      id_col='id'):\n    r\"\"\"New database table with primary key type serial and empty columns\n\n    Parameters\n    ----------\n    conn : sqlalchemy connection object\n        A valid connection to a database\n    schema : str\n        The database schema\n    table : str\n        The database table\n    columns : list, optional\n        Columns that are to be created\n    id_col : str, optional\n        Name of index column of database table\n\n    Notes\n    -------\n    Currently all created table columns will be of type `double precision`.\n    Feel free to enhance this function by\n    by generalizing this aspect.\n    \"\"\"\n\n    sql_str = \"\"\"CREATE TABLE {schema}.{table} ({id_col} SERIAL PRIMARY KEY\n        NOT NULL)\n        \"\"\".format(schema=schema, table=table, id_col=id_col)\n\n    conn.execute(sql_str)\n\n    # define more columns\n    if columns is not None:\n        for col in columns:\n            col_str = \"\"\"alter table {schema}.{table} add column {col}\n                double precision;\n                \"\"\".format(schema=schema, table=table, col=col)\n            conn.execute(col_str)", "response": "r Creates an empty table with serial primary key and empty columns."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grant_db_access(conn, schema, table, role):\n    grant_str = \"\"\"GRANT ALL ON TABLE {schema}.{table}\n    TO {role} WITH GRANT OPTION;\"\"\".format(schema=schema, table=table,\n                                           role=role)\n\n    conn.execute(grant_str)", "response": "r Gives access to database users and groups of the object holding the specified role"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_primary_key(conn, schema, table, pk_col):\n    sql_str = \"\"\"alter table {schema}.{table} add primary key ({col})\"\"\".format(\n        schema=schema, table=table, col=pk_col)\n\n    conn.execute(sql_str)", "response": "r Adds a primary key to the database table\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch a given filePath and parse its contents.", "response": "def createDataFromFile(self, filePath, inputEncoding = None, defaultFps = None):\n        \"\"\"Fetch a given filePath and parse its contents.\n\n        May raise the following exceptions:\n        * RuntimeError - generic exception telling that parsing was unsuccessfull\n        * IOError - failed to open a file at given filePath\n\n        @return SubtitleData filled with non-empty, default datafields. Client should modify them\n                and then perform an add/update operation\"\"\"\n\n        file_ = File(filePath)\n        if inputEncoding is None:\n            inputEncoding = file_.detectEncoding()\n        inputEncoding = inputEncoding.lower()\n\n        videoInfo = VideoInfo(defaultFps) if defaultFps is not None else file_.detectFps()\n\n        subtitles = self._parseFile(file_, inputEncoding, videoInfo.fps)\n\n        data = SubtitleData()\n        data.subtitles = subtitles\n        data.fps = videoInfo.fps\n        data.inputEncoding = inputEncoding\n        data.outputEncoding = inputEncoding\n        data.outputFormat = self._parser.parsedFormat()\n        data.videoPath = videoInfo.videoPath\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, cmd):\n        if not cmd.filePath in self._history.keys():\n            self._history[cmd.filePath] = SubtitleUndoStack(self)\n            try:\n                self._history[cmd.filePath].push(cmd)\n            except:\n                self._history[cmd.filePath].deleteLater()\n                del self._history[cmd.filePath]\n                raise\n            else:\n                self._history[cmd.filePath].clear()\n        else:\n            self._history[cmd.filePath].push(cmd)", "response": "Execute a command to modify storage [ cmd. filePath ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_property(xml_root, name, value, properties=None):\n    if properties is None:\n        properties = xml_root.find(\"properties\")\n\n    for prop in properties:\n        if prop.get(\"name\") == name:\n            prop.set(\"value\", utils.get_unicode_str(value))\n            break\n    else:\n        etree.SubElement(\n            properties, \"property\", {\"name\": name, \"value\": utils.get_unicode_str(value)}\n        )", "response": "Sets property to specified value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fill_response_property(xml_root, name=None, value=None):\n    name, value = generate_response_property(name, value)\n    response_property = None\n\n    if xml_root.tag == \"testsuites\":\n        response_property = _fill_testsuites_response_property(xml_root, name, value)\n    elif xml_root.tag in (\"testcases\", \"requirements\"):\n        response_property = _fill_non_testsuites_response_property(xml_root, name, value)\n    else:\n        raise Dump2PolarionException(_NOT_EXPECTED_FORMAT_MSG)\n\n    return response_property", "response": "Returns response property and fills it if missing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving response properties if exist.", "response": "def remove_response_property(xml_root):\n    \"\"\"Removes response properties if exist.\"\"\"\n    if xml_root.tag == \"testsuites\":\n        properties = xml_root.find(\"properties\")\n        resp_properties = []\n        for prop in properties:\n            prop_name = prop.get(\"name\", \"\")\n            if \"polarion-response-\" in prop_name:\n                resp_properties.append(prop)\n        for resp_property in resp_properties:\n            properties.remove(resp_property)\n    elif xml_root.tag in (\"testcases\", \"requirements\"):\n        resp_properties = xml_root.find(\"response-properties\")\n        if resp_properties is not None:\n            xml_root.remove(resp_properties)\n    else:\n        raise Dump2PolarionException(_NOT_EXPECTED_FORMAT_MSG)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_property(xml_root, partial_name):\n    if xml_root.tag in (\"testsuites\", \"testcases\", \"requirements\"):\n        properties = xml_root.find(\"properties\")\n        remove_properties = []\n        for prop in properties:\n            prop_name = prop.get(\"name\", \"\")\n            if partial_name in prop_name:\n                remove_properties.append(prop)\n        for rem_prop in remove_properties:\n            properties.remove(rem_prop)\n    else:\n        raise Dump2PolarionException(_NOT_EXPECTED_FORMAT_MSG)", "response": "Removes properties if exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_dry_run(xml_root, value=True):\n    value_str = str(value).lower()\n    assert value_str in (\"true\", \"false\")\n    if xml_root.tag == \"testsuites\":\n        _set_property(xml_root, \"polarion-dry-run\", value_str)\n    elif xml_root.tag in (\"testcases\", \"requirements\"):\n        _set_property(xml_root, \"dry-run\", value_str)\n    else:\n        raise Dump2PolarionException(_NOT_EXPECTED_FORMAT_MSG)", "response": "Sets dry - run so records are not updated only log file is produced."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving environment variables from a namespace.", "response": "def get_environ(cls, prefix):\n        \"\"\"Retrieves environment variables from a namespace.\n\n        Args:\n            prefix (str): The prefix, without a trailing underscore.\n\n        Returns:\n            list: A list of environment variable keys and values.\n\n        \"\"\"\n        return ((key[len(prefix) + 1:], value)\n                for key, value in os.environ.items()\n                if key.startswith('%s_' % prefix))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bool(self, name, default=None):\n        if name not in self:\n            if default is not None:\n                return default\n            raise EnvironmentError.not_found(self._prefix, name)\n        return bool(self.get_int(name))", "response": "Retrieves an environment variable value as a bool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dict(self, name, default=None):\n        if name not in self:\n            if default is not None:\n                return default\n            raise EnvironmentError.not_found(self._prefix, name)\n        return dict(**self.get(name))", "response": "Retrieves an environment variable value as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_int(self, name, default=None):\n        if name not in self:\n            if default is not None:\n                return default\n            raise EnvironmentError.not_found(self._prefix, name)\n        return int(self[name])", "response": "Retrieves an environment variable as an integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_list(self, name, default=None):\n        if name not in self:\n            if default is not None:\n                return default\n            raise EnvironmentError.not_found(self._prefix, name)\n        return list(self[name])", "response": "Retrieves an environment variable as a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_path(self, name, default=None):\n        if name not in self:\n            if default is not None:\n                return default\n            raise EnvironmentError.not_found(self._prefix, name)\n        return pathlib.Path(self[name])", "response": "Retrieves an environment variable as a filesystem path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates all environment variables from os. environ.", "response": "def refresh(self):\n        \"\"\"Update all environment variables from ``os.environ``.\n\n        Use if ``os.environ`` was modified dynamically *after* you\n        accessed an environment namespace with ``biome``.\n\n        \"\"\"\n        super(Habitat, self).update(self.get_environ(self._prefix))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _top_element(self):\n        top = etree.Element(\"testsuites\")\n        comment = etree.Comment(\"Generated for testrun {}\".format(self.testrun_id))\n        top.append(comment)\n        return top", "response": "Returns the top XML element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _properties_element(self, parent_element):\n        testsuites_properties = etree.SubElement(parent_element, \"properties\")\n\n        etree.SubElement(\n            testsuites_properties,\n            \"property\",\n            {\"name\": \"polarion-testrun-id\", \"value\": str(self.testrun_id)},\n        )\n        etree.SubElement(\n            testsuites_properties,\n            \"property\",\n            {\"name\": \"polarion-project-id\", \"value\": str(self.config[\"polarion-project-id\"])},\n        )\n\n        for name, value in sorted(self.config[\"xunit_import_properties\"].items()):\n            if name == \"polarion-lookup-method\":\n                lookup_prop = str(value).lower()\n                if lookup_prop not in (\"id\", \"name\", \"custom\"):\n                    raise Dump2PolarionException(\n                        \"Invalid value '{}' for the 'polarion-lookup-method' property\".format(\n                            str(value)\n                        )\n                    )\n                self._lookup_prop = lookup_prop\n            elif name in (\"polarion-testrun-id\", \"polarion-project-id\"):\n                # this was already set\n                continue\n            else:\n                etree.SubElement(\n                    testsuites_properties, \"property\", {\"name\": name, \"value\": str(value)}\n                )\n\n        return testsuites_properties", "response": "Returns properties XML element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfills the polarion - lookup - method property.", "response": "def _fill_lookup_prop(self, testsuites_properties):\n        \"\"\"Fills the polarion-lookup-method property.\"\"\"\n        if not self._lookup_prop:\n            raise Dump2PolarionException(\"Failed to set the 'polarion-lookup-method' property\")\n\n        etree.SubElement(\n            testsuites_properties,\n            \"property\",\n            {\"name\": \"polarion-lookup-method\", \"value\": self._lookup_prop},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _transform_result(self, result):\n        if self._transform_func:\n            result = self._transform_func(result)\n        return result or None", "response": "Calls transform function on result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_verdict(result):\n        verdict = result.get(\"verdict\")\n        if not verdict:\n            return None\n        verdict = verdict.strip().lower()\n        if verdict not in Verdicts.PASS + Verdicts.FAIL + Verdicts.SKIP + Verdicts.WAIT:\n            return None\n        return verdict", "response": "Gets verdict of the testcase."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_lookup_prop(self, result_data):\n        if self._lookup_prop:\n            return\n\n        if result_data.get(\"id\"):\n            self._lookup_prop = \"id\"\n        elif result_data.get(\"title\"):\n            self._lookup_prop = \"name\"\n        else:\n            return\n\n        logger.debug(\"Setting lookup method for xunit to `%s`\", self._lookup_prop)", "response": "Set lookup property based on processed testcases if not configured."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_lookup_prop(self, result_data):\n        if not self._lookup_prop:\n            return False\n\n        if not result_data.get(\"id\") and self._lookup_prop != \"name\":\n            return False\n        if not result_data.get(\"title\") and self._lookup_prop == \"name\":\n            return False\n        return True", "response": "Checks that the selected lookup property can be used for this testcase."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd stdout and stderr if present.", "response": "def _fill_out_err(result, testcase):\n        \"\"\"Adds stdout and stderr if present.\"\"\"\n        if result.get(\"stdout\"):\n            system_out = etree.SubElement(testcase, \"system-out\")\n            system_out.text = utils.get_unicode_str(result[\"stdout\"])\n\n        if result.get(\"stderr\"):\n            system_err = etree.SubElement(testcase, \"system-err\")\n            system_err.text = utils.get_unicode_str(result[\"stderr\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fill_properties(verdict, result, testcase, testcase_id, testcase_title):\n        properties = etree.SubElement(testcase, \"properties\")\n        etree.SubElement(\n            properties,\n            \"property\",\n            {\"name\": \"polarion-testcase-id\", \"value\": testcase_id or testcase_title},\n        )\n        if verdict in Verdicts.PASS and result.get(\"comment\"):\n            etree.SubElement(\n                properties,\n                \"property\",\n                {\n                    \"name\": \"polarion-testcase-comment\",\n                    \"value\": utils.get_unicode_str(result[\"comment\"]),\n                },\n            )\n\n        for param, value in six.iteritems(result.get(\"params\") or {}):\n            etree.SubElement(\n                properties,\n                \"property\",\n                {\n                    \"name\": \"polarion-parameter-{}\".format(param),\n                    \"value\": utils.get_unicode_str(value),\n                },\n            )", "response": "Adds properties into the testcase element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the balance of an account", "response": "def eth_getBalance(self, address, block=BLOCK_TAG_LATEST):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getbalance\n\n        :param address: Account address\n        :type address: str\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :return: wei\n        :rtype: int\n        \"\"\"\n        block = validate_block(block)\n        return hex_to_dec((yield from self.rpc_call('eth_getBalance',\n                                                    [address, block])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eth_getStorageAt(self, address, position=0, block=BLOCK_TAG_LATEST):\n        block = validate_block(block)\n        return hex_to_dec((yield from self.rpc_call('eth_getStorageAt',\n                                                    [address,\n                                                     hex(position),\n                                                     block])))", "response": "Get the storage at the specified position in the specified block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of transactions in the specified block.", "response": "def eth_getTransactionCount(self, address, block=BLOCK_TAG_LATEST):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_gettransactioncount\n\n        :param address: Account address\n        :type address: str\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :return: count\n        :rtype: int\n        \"\"\"\n        block = validate_block(block)\n        return hex_to_dec((yield from self.rpc_call('eth_getTransactionCount',\n                                                    [address, block])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eth_getBlockTransactionCountByHash(self, bhash):\n        response = yield from self.rpc_call('eth_getBlockTransactionCountByHash',\n                                            [bhash])\n        if response:\n            return hex_to_dec(response)\n        return response", "response": "This interface is used to get the number of transactions in a specific block."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eth_getBlockTransactionCountByNumber(self, block=BLOCK_TAG_LATEST):\n        block = validate_block(block)\n        return hex_to_dec((yield from self.rpc_call('eth_getBlockTransactionCountByNumber',\n                                                    [block])))", "response": "Get the number of transactions in a specific block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eth_getUncleCountByBlockHash(self, bhash):\n        response = yield from self.rpc_call('eth_getUncleCountByBlockHash',\n                                            [bhash])\n        if response:\n            return hex_to_dec(response)\n        return response", "response": "This interface is used to get the uncle count of a specific block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the code of a specific block.", "response": "def eth_getCode(self, address, block=BLOCK_TAG_LATEST):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getcode\n\n        :param address: Address of contract\n        :type address: str\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :return: code\n        :rtype: str\n        \"\"\"\n        block = validate_block(block)\n        return (yield from self.rpc_call('eth_getCode', [address, block]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eth_sendTransaction(self, from_, to=None, gas=None,\n                            gas_price=None, value=None, data=None,\n                            nonce=None):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_sendtransaction\n\n        :param from_: From account address\n        :type from_: str\n\n        :param to: To account address (optional)\n        :type to: str\n\n        :param gas: Gas amount for current transaction (optional)\n        :type gas: int\n\n        :param gas_price: Gas price for current transaction (optional)\n        :type gas_price: int\n\n        :param value: Amount of ether to send (optional)\n        :type value: int\n\n        :param data: Additional data for transaction (optional)\n        :type data: hex\n\n        :param nonce: Unique nonce for transaction (optional)\n        :type nonce: int\n\n        :return: txhash\n        :rtype: str\n        \"\"\"\n        obj = {}\n        obj['from'] = from_\n        if to is not None:\n            obj['to'] = to\n        if gas is not None:\n            obj['gas'] = hex(gas)\n        if gas_price is not None:\n            obj['gasPrice'] = hex(gas_price)\n        if value is not None:\n            obj['value'] = hex(ether_to_wei(value))\n        if data is not None:\n            obj['data'] = data\n        if nonce is not None:\n            obj['nonce'] = hex(nonce)\n\n        return (yield from self.rpc_call('eth_sendTransaction', [obj]))", "response": "Send a transaction to the specified account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eth_call(self, from_, to=None, gas=None,\n                 gas_price=None, value=None, data=None,\n                 block=BLOCK_TAG_LATEST):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_call\n\n        :param from_: From account address\n        :type from_: str\n\n        :param to: To account address (optional)\n        :type to: str\n\n        :param gas: Gas amount for current transaction (optional)\n        :type gas: int\n\n        :param gas_price: Gas price for current transaction (optional)\n        :type gas_price: int\n\n        :param value: Amount of ether to send (optional)\n        :type value: int\n\n        :param data: Additional data for transaction (optional)\n        :type data: hex\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :rtype: str\n        \"\"\"\n        block = validate_block(block)\n        obj = {}\n        obj['from'] = from_\n        if to is not None:\n            obj['to'] = to\n        if gas is not None:\n            obj['gas'] = hex(gas)\n        if gas_price is not None:\n            obj['gasPrice'] = hex(gas_price)\n        if value is not None:\n            obj['value'] = hex(ether_to_wei(value))\n        if data is not None:\n            obj['data'] = data\n\n        return (yield from self.rpc_call('eth_call', [obj, block]))", "response": "Send a call to Ethernet."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eth_estimateGas(self, from_, to=None, gas=None,\n                        gas_price=None, value=None, data=None):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_estimategas\n\n        :param from_: From account address\n        :type from_: str\n\n        :param to: To account address (optional)\n        :type to: str\n\n        :param gas: Gas amount for current transaction (optional)\n        :type gas: int\n\n        :param gas_price: Gas price for current transaction (optional)\n        :type gas_price: int\n\n        :param value: Amount of ether to send (optional)\n        :type value: int\n\n        :param data: Additional data for transaction (optional)\n        :type data: hex\n\n        :return: gas amount\n        :rtype: int\n        \"\"\"\n        obj = {}\n        obj['from'] = from_\n        if to is not None:\n            obj['to'] = to\n        if gas is not None:\n            obj['gas'] = hex(gas)\n        if gas_price is not None:\n            obj['gasPrice'] = hex(gas_price)\n        if value is not None:\n            obj['value'] = hex(ether_to_wei(value))\n        if data is not None:\n            obj['data'] = data\n\n        return hex_to_dec((yield from self.rpc_call('eth_estimateGas', [obj])))", "response": "Estimate gas amount for current transaction"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eth_getBlockByHash(self, bhash, tx_objects=True):\n        result = yield from self.rpc_call('eth_getBlockByHash',\n                                          [bhash, tx_objects])\n        # TODO: Update result response\n        return result", "response": "Get the block with the given hash."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting block by number.", "response": "def eth_getBlockByNumber(self, block=BLOCK_TAG_LATEST, tx_objects=True):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getblockbynumber\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :param tx_objects: Return txs full object (optional)\n        :type tx_objects: bool\n\n        :return: block\n        :rtype: dict or None\n        \"\"\"\n        block = validate_block(block)\n        result = yield from self.rpc_call('eth_getBlockByNumber',\n                                          [block, tx_objects])\n        # TODO: Update result response\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eth_getTransactionByBlockHashAndIndex(self, bhash, index=0):\n        result = yield from self.rpc_call('eth_getTransactionByBlockHashAndIndex',\n                                          [bhash, hex(index)])\n        # TODO: Update result response\n        return result", "response": "Get the transaction by block hash and index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eth_getTransactionByBlockNumberAndIndex(self, block=BLOCK_TAG_LATEST,\n                                                index=0):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_gettransactionbyblocknumberandindex\n\n        :param block: Block tag or number (optional)\n        :type block: int or BLOCK_TAGS\n\n        :param index: Index position (optional)\n        :type index: int\n\n        :return: transaction\n        :rtype: dict or None\n        \"\"\"\n        block = validate_block(block)\n        result = yield from self.rpc_call('eth_getTransactionByBlockNumberAndIndex',\n                                          [block, hex(index)])\n        # TODO: Update result response\n        return result", "response": "Get transaction by block number and index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting uncle by block hash and index.", "response": "def eth_getUncleByBlockHashAndIndex(self, bhash, index=0):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getunclebyblockhashandindex\n\n        :param bhash: Block hash\n        :type bhash: str\n\n        :param index: Index position (optional)\n        :type index: int\n\n        :return: block\n        :rtype: dict or None\n        \"\"\"\n        result = yield from self.rpc_call('eth_getUncleByBlockHashAndIndex',\n                                          [bhash, hex(index)])\n        # TODO: Update result response\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eth_getLogs(self, from_block=BLOCK_TAG_LATEST,\n                    to_block=BLOCK_TAG_LATEST, address=None, topics=None):\n        \"\"\"https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getlogs\n\n        :param from_block: Block tag or number (optional)\n        :type from_block: int or BLOCK_TAGS\n\n        :param to_block: Block tag or number (optional)\n        :type to_block: int or BLOCK_TAGS\n\n        :param address: Contract address (optional)\n        :type address: str\n\n        :param topics: Topics (optional)\n        :type topics: list\n\n        :return: logs\n        :rtype: list\n        \"\"\"\n        obj = {\n            'fromBlock': validate_block(from_block),\n            'toBlock': validate_block(to_block),\n            'address': address,\n            'topics': topics\n        }\n        result = yield from self.rpc_call('eth_getLogs', [obj])\n        return result", "response": "Get the logs from the network."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eth_submitWork(self, nonce, header, mix_digest):\n        return (yield from self.rpc_call('eth_submitWork',\n                                         [nonce, header, mix_digest]))", "response": "Submit a work to the blockchain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_within_hour_range(ref_time, start_time, end_time):\n    str_ref_time = ref_time.strftime('%Y%m%d')\n    start_time_ = mktime(strptime(str_ref_time + '-' + start_time, '%Y%m%d-%H:%M'))\n    end_time_ = mktime(strptime(str_ref_time + '-' + end_time, '%Y%m%d-%H:%M'))\n    ref_time_ = mktime(ref_time.timetuple())\n    if start_time_ <= ref_time_ <= end_time_:\n        return True\n    else:\n        return False", "response": "Check if a date is within a given hour range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all products unique relationship with POS s Storage", "response": "def get_value_product_unique(self, pos):\n        \"\"\"\n        Return all products unique relationship with POS's Storage (only salable zones)\n        \"\"\"\n        qs = ProductUnique.objects.filter(\n            box__box_structure__zone__storage__in=pos.storage_stock.filter(storage_zones__salable=True),\n            product_final=self\n        )\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the log file and return a list of the testcases and requirements.", "response": "def parse(log_file):\n    \"\"\"Parse log file.\"\"\"\n    with io.open(os.path.expanduser(log_file), encoding=\"utf-8\") as input_file:\n        for line in input_file:\n            if \"Starting import of XUnit results\" in line:\n                obj = XUnitParser\n                break\n            elif \"Starting import of test cases\" in line:\n                obj = TestcasesParser\n                break\n            elif \"Starting import of requirements\" in line:\n                obj = RequirementsParser\n                break\n        else:\n            raise Dump2PolarionException(\n                \"No valid data found in the log file '{}'\".format(log_file)\n            )\n\n        return obj(input_file, log_file).parse()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_result(self, line):\n        res = self.RESULT_SEARCH.search(line)\n        try:\n            name, ids = res.group(1), res.group(2)\n        except (AttributeError, IndexError):\n            return None\n\n        ids = ids.split(\"/\")\n        tc_id = ids[0]\n        try:\n            custom_id = ids[1]\n        except IndexError:\n            custom_id = None\n        return LogItem(name, tc_id, custom_id)", "response": "Gets work item name and id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_result_warn(self, line):\n        res = self.RESULT_WARN_SEARCH.search(line)\n        try:\n            return LogItem(res.group(1), None, None)\n        except (AttributeError, IndexError):\n            pass\n\n        # try again with custom ID\n        res = self.RESULT_WARN_SEARCH_CUSTOM.search(line)\n        try:\n            return LogItem(res.group(1), None, res.group(2))\n        except (AttributeError, IndexError):\n            return None", "response": "Gets work item name of item that was not successfully imported."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_requirement(self, line):\n        res = self.REQ_SEARCH.search(line)\n        try:\n            name, tc_id = res.group(1), res.group(2)\n        except (AttributeError, IndexError):\n            return None\n\n        return LogItem(name, tc_id, None)", "response": "Gets requirement name and id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget name of test case that was not successfully imported.", "response": "def get_requirement_warn(self, line):\n        \"\"\"Gets name of test case that was not successfully imported.\"\"\"\n        res = self.REQ_WARN_SEARCH.search(line)\n        try:\n            return LogItem(res.group(1), None, None)\n        except (AttributeError, IndexError):\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfilters :data for the objects in it which possess attributes equal in name/value to a key/value in kwargs. Each key/value combination in kwargs is compared against the object, so multiple keyword arguments can be passed in to constrain the filtering.", "response": "def assembla_filter(func):\n    \"\"\"\n    Filters :data for the objects in it which possess attributes equal in\n    name/value to a key/value in kwargs.\n\n    Each key/value combination in kwargs is compared against the object, so\n    multiple keyword arguments can be passed in to constrain the filtering.\n    \"\"\"\n    @wraps(func)\n    def wrapper(class_instance, **kwargs):\n\n        # Get the result\n        extra_params = kwargs.get('extra_params', None)\n        if extra_params:\n            del kwargs['extra_params']\n        results = func(class_instance, extra_params)\n\n        # Filter the result\n        if kwargs:\n            results = filter(\n                # Find the objects who have an equal number of matching attr/value\n                # combinations as `len(kwargs)`\n                lambda obj: len(kwargs) == len(\n                    filter(\n                        lambda boolean: boolean,\n                        [obj.get(attr_name) == value\n                            for attr_name, value in kwargs.iteritems()]\n                    )\n                ),\n                results\n            )\n\n        return results\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_app(self, app):\n        '''Initalizes the application with the extension.\n        \n        :param app: The Flask application object.\n        '''\n        self.app = app\n        self._session_conf = app.config.get('BEAKER_SESSION', {\n            'session.type': 'file',\n            'session.data_dir': '/tmp/session/data',\n            'session.lock_dir': '/tmp/session/lock'\n        })\n        app.wsgi_app = SessionMiddleware(app.wsgi_app, self._session_conf)\n        app.session_interface = BeakerSessionInterface()", "response": "Initalizes the application with the extension.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate a config file in the system.", "response": "def locate_config(confname, app_name,\n                  location=None, prefix='etc', verbose=False):\n    \"\"\"\n    Returns absolute path on the filesystem to a config file named *confname*.\n    \"\"\"\n    candidates = []\n    if location:\n        candidate = os.path.normpath(os.path.join(location, confname))\n        if os.path.isfile(candidate):\n            candidates += [candidate]\n    candidate = os.path.normpath(os.path.join(\n        os.path.dirname(os.path.dirname(sys.executable)),\n        prefix, app_name, confname))\n    if os.path.isfile(candidate):\n        candidates += [candidate]\n    candidate = os.path.normpath('/%s/%s/%s' % (prefix, app_name, confname))\n    if os.path.isfile(candidate):\n        candidates += [candidate]\n    candidate = os.path.normpath(os.path.join(os.getcwd(), confname))\n    if os.path.isfile(candidate):\n        candidates += [candidate]\n    if candidates:\n        if verbose:\n            LOGGER.info(\"config loaded from '%s'\", candidates[0])\n        return candidates[0]\n    else:\n        LOGGER.warning(\"config '%s' was not found.\", confname)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a config file from a path to a file and set it in the current namespace.", "response": "def load_config(app_name, *args, **kwargs):\n    \"\"\"\n    Given a path to a file, parse its lines in ini-like format, and then\n    set them in the current namespace.\n\n    Quiet by default. Set verbose to True to see the absolute path to the config\n    files printed on stderr.\n    \"\"\"\n    configure_logging()\n\n    # compatible with Python 2 and 3.\n    prefix = kwargs.get('prefix', 'etc')\n    verbose = kwargs.get('verbose', False)\n    location = kwargs.get('location', None)\n    passphrase = kwargs.get('passphrase',\n        os.getenv(\"%s_SETTINGS_CRYPT_KEY\" % app_name.upper(),\n            os.getenv(\"SETTINGS_CRYPT_KEY\", None)))\n    confnames = args\n\n    if not location:\n        location = os.getenv(\"%s_SETTINGS_LOCATION\" % app_name.upper(), None)\n    if not location:\n        location = os.getenv(\"SETTINGS_LOCATION\", None)\n        if location:\n            location = \"%s/%s\" % (location, app_name)\n\n    config = {}\n    for confname in confnames:\n        content = None\n        if location and location.startswith('s3://'):\n            try:\n                import boto\n                _, bucket_name, prefix = urlparse(location)[:3]\n                try:\n                    conn = boto.connect_s3()\n                    bucket = conn.get_bucket(bucket_name)\n                    key_name = '%s/%s' % (prefix, confname)\n                    key = bucket.get_key(key_name)\n                    content = key.get_contents_as_string()\n                    if verbose:\n                        LOGGER.info(\"config loaded from 's3://%s/%s'\",\n                            bucket_name, key_name)\n                except (boto.exception.NoAuthHandlerFound,\n                        boto.exception.S3ResponseError) as _:\n                    pass\n            except ImportError:\n                pass\n\n        # We cannot find a deployutils S3 bucket. Let's look on the filesystem.\n        if not content:\n            confpath = locate_config(\n                confname, app_name, location=location,\n                prefix=prefix, verbose=verbose)\n            if confpath:\n                with open(confpath, 'rb') as conffile:\n                    content = conffile.read()\n\n        if content:\n            if passphrase:\n                content = crypt.decrypt(content, passphrase)\n            if hasattr(content, 'decode'):\n                content = content.decode('utf-8')\n            for line in content.split('\\n'):\n                if not line.startswith('#'):\n                    look = re.match(r'(\\w+)\\s*=\\s*(.*)', line)\n                    if look:\n                        try:\n                            # We used to parse the file line by line.\n                            # Once Django 1.5 introduced ALLOWED_HOSTS\n                            # (a tuple that definitely belongs to the site.conf\n                            # set), we had no choice other than resort\n                            # to eval(value, {}, {}).\n                            # We are not resorting to import conf module yet\n                            # but that might be necessary once we use\n                            # dictionary configs for some of the apps...\n                            # TODO: consider using something like ConfigObj\n                            # for this:\n                            # http://www.voidspace.org.uk/python/configobj.html\n                            #pylint:disable=eval-used\n                            config.update({look.group(1).upper():\n                                eval(look.group(2), {}, {})})\n                        except Exception:\n                            raise\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the account. :param account_id: the account to close :return: Nothing", "response": "def close(account_id: str) -> None:\n    \"\"\"\n    Closes the account.\n\n    :param account_id: the account to close\n    :return: Nothing\n    \"\"\"\n    logger.info('closing-account', account_id=account_id)\n    with transaction.atomic():\n        account = Account.objects.get(pk=account_id)\n        account.close()\n        account.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_invoices(account_id: str, due_date: date) -> Sequence[Invoice]:\n    invoices = []\n    with transaction.atomic():\n        due_charges = Charge.objects \\\n            .uninvoiced(account_id=account_id) \\\n            .charges()\n        total = total_amount(due_charges)\n        for amount_due in total.monies():\n            if amount_due.amount > 0:\n                invoice = Invoice.objects.create(account_id=account_id, due_date=due_date)\n                Charge.objects \\\n                    .uninvoiced(account_id=account_id) \\\n                    .charges() \\\n                    .in_currency(currency=amount_due.currency) \\\n                    .update(invoice=invoice)\n                invoices.append(invoice)\n    logger.info('created-invoices', account_id=str(account_id), invoice_ids=[i.pk for i in invoices])\n    for invoice in invoices:\n        invoice_ready.send(sender=create_invoices, invoice=invoice)\n    return invoices", "response": "Creates the invoices for any due positive charges in the account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a charge to the account.", "response": "def add_charge(account_id: str,\n               amount: Money,\n               reverses_id: Optional[str] = None,\n               product_code: Optional[str] = None,\n               product_properties: Optional[Dict[str, str]] = None) -> Charge:\n    \"\"\"\n    Add a charge to the account.\n\n    :param account_id: The account on which to add the charge\n    :param amount:  The amount of the charge\n    :param reverses_id: Set this if this charge reverses another one\n    :param product_code: A code identifying the type of product cnarged\n    :param product_properties: A dict of hames and values.\n    :return: The newly created charge.\n    \"\"\"\n    logger.info('adding-charge', account_id=account_id, amount=amount, product_code=product_code,\n                product_properties=product_properties)\n\n    with transaction.atomic():\n        charge = Charge(account_id=account_id,\n                        amount=amount)\n        if reverses_id:\n            charge.reverses_id = reverses_id\n        if product_code:\n            charge.product_code = product_code\n        charge.full_clean(exclude=['id', 'account'])  # Exclude to avoid unnecessary db queries\n        charge.save(force_insert=True)\n\n        if product_properties:\n            objs = [ProductProperty(charge=charge, name=k, value=v) for k, v in product_properties.items()]\n            for o in objs:\n                o.full_clean(exclude=['id', 'charge'])  # Exclude to avoid unnecessary db queries\n            ProductProperty.objects.bulk_create(objs)\n\n    return charge"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to pay pending invoices starting from the oldest with available funds.", "response": "def assign_funds_to_account_pending_invoices(account_id: str) -> Sequence[str]:\n    \"\"\"\n    Tries to pay pending account invoices (starting from the oldest) with available funds.\n    :param account_id: the account on which to perform the operation\n    :return: The ids of the invoices that were paid (possibly empty list).\n    \"\"\"\n    logger.info('assign-funds-to-pending-invoices', account_id=str(account_id))\n\n    paid_invoice_ids = []\n    for invoice in Invoice.objects.filter(status=Invoice.PENDING, account_id=account_id).order_by('due_date'):\n        invoice_was_paid = assign_funds_to_invoice(invoice.pk)\n        if invoice_was_paid:\n            paid_invoice_ids.append(invoice.id)\n        else:\n            break  # Bail even though there may be funds in another currency to pay more recent invoices.\n    logger.info('assign-funds-to-pending-invoices.end', account_id=str(account_id),\n                paid_invoice_count=len(paid_invoice_ids))\n    return paid_invoice_ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assign_funds_to_invoice(invoice_id: str) -> bool:\n\n    logger.info('assign-funds-to-invoice', invoice_id=invoice_id)\n    invoice = Invoice.objects.get(pk=invoice_id)\n    account_id = invoice.account_id\n\n    #\n    # Precondition. Don't touch invoices that are not PENDING\n    #\n    if invoice.status != Invoice.PENDING:\n        logger.info('assign-funds-to-invoice.status-is-not-pending', invoice_id=invoice_id)\n        return False\n\n    #\n    # Precondition: Only handle invoices in a single currency\n    #\n    invoice_due_monies = invoice.due().monies()\n    if len(invoice_due_monies) != 1:\n        logger.info('assign-funds-to-invoice.more-than-one-currency', invoice_id=invoice_id)\n        return False\n    invoice_due_amount = invoice_due_monies[0].amount\n    invoice_due_currency = invoice_due_monies[0].currency\n\n    #\n    # 1. Collect funds as long as long as we need them\n    #\n    if invoice_due_amount > 0:\n\n        payments = Transaction.successful \\\n            .payments() \\\n            .uninvoiced(account_id=account_id) \\\n            .in_currency(invoice_due_currency) \\\n            .order_by('created')\n\n        credits = Charge.objects \\\n            .credits() \\\n            .uninvoiced(account_id=account_id) \\\n            .in_currency(invoice_due_currency) \\\n            .order_by('created')\n\n        funds = list(credits) + list(payments)\n        for fund in funds:\n            contributed_amount = abs(fund.amount.amount)  # 'abs' because credits have a negative value\n            logger.info('assign-funds-to-invoice.assigning-fund',\n                        invoice_id=invoice_id,\n                        fund_type=type(fund).__name__,\n                        fund_id=str(fund.pk),\n                        contributed_amount=contributed_amount)\n            fund.invoice_id = invoice_id\n            fund.save()\n            invoice_due_amount -= contributed_amount\n            if invoice_due_amount <= 0:\n                break\n\n    #\n    # 2. Mark invoice paid if nothing is due.\n    #\n    if invoice_due_amount <= 0:\n        logger.info('assign-funds-to-invoice.mark-paid', invoice_id=invoice_id, invoice_due_amount=invoice_due_amount)\n        invoice.status = Invoice.PAID\n        invoice.save()\n\n    #\n    # 3. Carry forward any overpaid money.\n    #\n    if invoice_due_amount < 0:\n        overpayment = Money(abs(invoice_due_amount), invoice_due_currency)\n        logger.info('assign-funds-to-invoice.handling-overpayment',\n                    invoice_id=invoice_id,\n                    overpayment=overpayment)\n        with transaction.atomic():\n            Charge.objects.create(account_id=account_id, amount=overpayment, product_code=CARRIED_FORWARD,\n                                  invoice_id=invoice_id)\n            Charge.objects.create(account_id=account_id, amount=-overpayment, product_code=CREDIT_REMAINING)\n\n    return invoice.status == Invoice.PAID", "response": "Assigns funds to an invoice."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_tree(self):\n        for spec in self.specs:\n            if spec.ismodule:\n                self.modules.append(Module(spec.name, spec.path, dsm=self))\n            else:\n                self.packages.append(Package(\n                    spec.name, spec.path,\n                    dsm=self, limit_to=spec.limit_to,\n                    build_tree=True,\n                    build_dependencies=False,\n                    enforce_init=self.enforce_init))", "response": "Build the Python packages tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning first parts of dot - separated strings and rest of strings.", "response": "def split_limits_heads(self):\n        \"\"\"\n        Return first parts of dot-separated strings, and rest of strings.\n\n        Returns:\n            (list of str, list of str): the heads and rest of the strings.\n        \"\"\"\n        heads = []\n        new_limit_to = []\n        for limit in self.limit_to:\n            if '.' in limit:\n                name, limit = limit.split('.', 1)\n                heads.append(name)\n                new_limit_to.append(limit)\n            else:\n                heads.append(limit)\n        return heads, new_limit_to"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the tree for this package.", "response": "def build_tree(self):\n        \"\"\"Build the tree for this package.\"\"\"\n        for m in listdir(self.path):\n            abs_m = join(self.path, m)\n            if isfile(abs_m) and m.endswith('.py'):\n                name = splitext(m)[0]\n                if not self.limit_to or name in self.limit_to:\n                    self.modules.append(Module(name, abs_m, self.dsm, self))\n            elif isdir(abs_m):\n                if isfile(join(abs_m, '__init__.py')) or not self.enforce_init:\n                    heads, new_limit_to = self.split_limits_heads()\n                    if not heads or m in heads:\n                        self.packages.append(\n                            Package(m, abs_m, self.dsm, self, new_limit_to,\n                                    build_tree=True,\n                                    build_dependencies=False,\n                                    enforce_init=self.enforce_init))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of dependencies of this package to the given node.", "response": "def cardinal(self, to):\n        \"\"\"\n        Return the number of dependencies of this package to the given node.\n\n        Args:\n            to (Package/Module): target node.\n\n        Returns:\n            int: number of dependencies.\n        \"\"\"\n        return sum(m.cardinal(to) for m in self.submodules)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_dict(self, absolute=False):\n        return {\n            'name': self.absolute_name() if absolute else self.name,\n            'path': self.path,\n            'dependencies': [{\n                # 'source': d.source.absolute_name(),  # redundant\n                'target': d.target if d.external else d.target.absolute_name(),\n                'lineno': d.lineno,\n                'what': d.what,\n                'external': d.external\n            } for d in self.dependencies]\n        }", "response": "Return the dependencies as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_dependencies(self):\n        highest = self.dsm or self.root\n        if self is highest:\n            highest = LeafNode()\n        for _import in self.parse_code():\n            target = highest.get_target(_import['target'])\n            if target:\n                what = _import['target'].split('.')[-1]\n                if what != target.name:\n                    _import['what'] = what\n                _import['target'] = target\n            self.dependencies.append(Dependency(source=self, **_import))", "response": "Build the dependencies for this module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_code(self):\n        code = open(self.path, encoding='utf-8').read()\n        try:\n            body = ast.parse(code).body\n        except SyntaxError:\n            try:\n                code = code.encode('utf-8')\n                body = ast.parse(code).body\n            except SyntaxError:\n                return []\n        return self.get_imports(body)", "response": "Read the source code and return all the import statements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_imports(self, ast_body):\n        imports = []\n        for node in ast_body:\n            if isinstance(node, ast.Import):\n                imports.extend({'target': name.name, 'lineno': node.lineno}\n                               for name in node.names)\n            elif isinstance(node, ast.ImportFrom):\n                for name in node.names:\n                    name = (\n                        self.absolute_name(self.depth - node.level) + '.'\n                        if node.level > 0 else ''\n                    ) + (\n                        node.module + '.' if node.module else ''\n                    ) + name.name\n                    imports.append({'target': name, 'lineno': node.lineno})\n            elif isinstance(node, Module.RECURSIVE_NODES):\n                imports.extend(self.get_imports(node.body))\n                if isinstance(node, ast.Try):\n                    imports.extend(self.get_imports(node.finalbody))\n        return imports", "response": "Returns all the import statements given an AST body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cardinal(self, to):\n        return sum(1 for _ in filter(\n            lambda d: not d.external and d.target in to, self.dependencies))", "response": "Returns the number of dependencies of this module to the given node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning generates URLs in split command fashion.", "response": "def generate_urls(self, first_url, last_url):\n        \"\"\"\n        Function generates URLs in split command fashion. If first_url is xaaaaa and last_url is xaaaac, it will automatically generate xaaaab.\n        \"\"\"\n        first_url = first_url.split(\"/\")\n        last_url = last_url.split(\"/\")\n        if first_url[0].lower() != \"http:\" or last_url[0].lower() != \"http:\":\n            raise Exception(\"URLs should be accessible via HTTP.\")\n\n        url_base = \"/\".join(first_url[:-1])\n        start_index = first_url[-1].index(\"a\")\n        file_name = first_url[-1][0:start_index]\n        url_base += \"/\" + file_name\n\n        start = first_url[-1][start_index:]\n        finish = last_url[-1][start_index:]\n\n        if start.count(\".\") == 1 and finish.count(\".\") == 1:\n            start, file_extension = start.split(\".\")\n            finish, _ = finish.split(\".\")\n            if len(start) != len(finish):\n                raise Exception(\"Filenames in url should have the same length.\")\n            file_extension = \".\" + file_extension\n        else:\n            raise Exception(\"URLs does not have the same pattern.\")\n\n        alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n        product = itertools.product(alphabet, repeat=len(start))\n\n        urls = []\n        for p in product:\n            urls.append([url_base + \"\".join(p) + file_extension])\n            if \"\".join(p) == finish:\n                break\n        return urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_raw_data(sql, connection, geometry):\n    tmp_dc = {}\n    weather_df = pd.DataFrame(\n        connection.execute(sql).fetchall(), columns=[\n            'gid', 'geom_point', 'geom_polygon', 'data_id', 'time_series',\n            'dat_id', 'type_id', 'type', 'height', 'year', 'leap_year']).drop(\n        'dat_id', 1)\n\n    # Get the timezone of the geometry\n    tz = tools.tz_from_geom(connection, geometry)\n\n    for ix in weather_df.index:\n        # Convert the point of the weather location to a shapely object\n        weather_df.loc[ix, 'geom_point'] = wkt_loads(\n            weather_df['geom_point'][ix])\n\n        # Roll the dataset forward according to the timezone, because the\n        # dataset is based on utc (Berlin +1, Kiev +2, London +0)\n        utc = timezone('utc')\n        offset = int(utc.localize(datetime(2002, 1, 1)).astimezone(\n            timezone(tz)).strftime(\"%z\")[:-2])\n\n        # Get the year and the length of the data array\n        db_year = weather_df.loc[ix, 'year']\n        db_len = len(weather_df['time_series'][ix])\n\n        # Set absolute time index for the data sets to avoid errors.\n        tmp_dc[ix] = pd.Series(\n            np.roll(np.array(weather_df['time_series'][ix]), offset),\n            index=pd.date_range(pd.datetime(db_year, 1, 1, 0),\n                                periods=db_len, freq='H', tz=tz))\n    weather_df['time_series'] = pd.Series(tmp_dc)\n    return weather_df", "response": "Fetch the coastdat2 from the database adapt it to the local time zone\n    and create a time index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_single_weather(df, rename_dc):\n    my_weather = weather.FeedinWeather()\n    data_height = {}\n    name = None\n    # Create a pandas.DataFrame with the time series of the weather data set\n    weather_df = pd.DataFrame(index=df.time_series.iloc[0].index)\n    for row in df.iterrows():\n        key = rename_dc[row[1].type]\n        weather_df[key] = row[1].time_series\n        data_height[key] = row[1].height if not np.isnan(row[1].height) else 0\n        name = row[1].gid\n    my_weather.data = weather_df\n    my_weather.timezone = weather_df.index.tz\n    my_weather.longitude = df.geom_point.iloc[0].x\n    my_weather.latitude = df.geom_point.iloc[0].y\n    my_weather.geometry = df.geom_point.iloc[0]\n    my_weather.data_height = data_height\n    my_weather.name = name\n    return my_weather", "response": "Create an oemof weather object for the given geometry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_multi_weather(df, rename_dc):\n    weather_list = []\n    # Create a pandas.DataFrame with the time series of the weather data set\n    # for each data set and append them to a list.\n    for gid in df.gid.unique():\n        gid_df = df[df.gid == gid]\n        obj = create_single_weather(gid_df, rename_dc)\n        weather_list.append(obj)\n    return weather_list", "response": "Create a list of oemof weather objects if the given geometry is a polygon\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _openssl_key_iv(passphrase, salt):\n    def _openssl_kdf(req):\n        if hasattr(passphrase, 'encode'):\n            passwd = passphrase.encode('ascii', 'ignore')\n        else:\n            passwd = passphrase\n        prev = b''\n        while req > 0:\n            digest = hashes.Hash(hashes.MD5(), backend=default_backend())\n            digest.update(prev + passwd + salt)\n            prev = digest.finalize()\n            req -= IV_BLOCK_SIZE\n            yield prev\n    assert passphrase is not None\n    assert salt is not None\n    # AES key: 32 bytes, IV: 16 bytes\n    mat = b''.join([x for x in _openssl_kdf(32 + IV_BLOCK_SIZE)])\n    return mat[0:32], mat[32:32 + IV_BLOCK_SIZE]", "response": "Generate a key and IV tuple from a passphrase and a salt."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(source_text, passphrase, debug_stmt=None):\n    if debug_stmt is None:\n        debug_stmt = \"decrypt\"\n    full_encrypted = b64decode(source_text)\n    salt = full_encrypted[8:IV_BLOCK_SIZE]\n    encrypted_text = full_encrypted[IV_BLOCK_SIZE:]\n    key, iv_ = _openssl_key_iv(passphrase, salt)\n    cipher = Cipher(\n        algorithms.AES(key), modes.CBC(iv_), default_backend()\n    ).decryptor()\n    plain_text = cipher.update(encrypted_text)\n    plain_text += cipher.finalize()\n    # PKCS#7 padding\n    if six.PY2:\n        padding = ord(plain_text[-1])\n    else:\n        padding = plain_text[-1]\n    plain_text = plain_text[:-padding]\n    if hasattr(plain_text, 'decode'):\n        plain_text = plain_text.decode('utf-8')\n    _log_debug(salt, key, iv_, source_text, plain_text,\n        passphrase=passphrase, debug_stmt=debug_stmt)\n    return plain_text", "response": "Decrypt a base64 - encoded string of source_text using the given passphrase."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt(source_text, passphrase, debug_stmt=None):\n    if debug_stmt is None:\n        debug_stmt = \"encrypt\"\n    prefix = b'Salted__'\n    salt = os.urandom(IV_BLOCK_SIZE - len(prefix))\n    key, iv_ = _openssl_key_iv(passphrase, salt)\n    cipher = Cipher(\n        algorithms.AES(key), modes.CBC(iv_), default_backend()\n    ).encryptor()\n\n    # PKCS#7 padding\n    if hasattr(source_text, 'encode'):\n        source_utf8 = source_text.encode('utf-8')\n    else:\n        source_utf8 = str(source_text)\n    padding = (IV_BLOCK_SIZE - len(source_utf8) % IV_BLOCK_SIZE)\n    if six.PY2:\n        padding = chr(padding) * padding\n    else:\n        padding = bytes([padding for _ in range(padding)])\n    plain_text = source_utf8 + padding\n    encrypted_text = cipher.update(plain_text) + cipher.finalize()\n    full_encrypted = b64encode(prefix + salt + encrypted_text)\n    _log_debug(salt, key, iv_, full_encrypted, source_text,\n        passphrase=passphrase, debug_stmt=debug_stmt)\n    return full_encrypted", "response": "Encrypt a string of source_text with a passphrase."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction randomly selects features without replacement. It used with random forest.", "response": "def rand_indices(x, rand_attr):\n    \"\"\"\n    Function randomly selects features without replacement. It used with random forest. Selected features must have more\n    than one distinct value.\n    x: numpy array - dataset\n    rand_attr - parameter defines number of randomly selected features\n    \"\"\"\n    loop = True\n    indices = range(len(x[0]))\n\n    while loop:\n        loop = False\n        # randomly selected features without replacement\n        rand_list = random.sample(indices, rand_attr)\n        for i in rand_list:\n            if len(np.unique(x[:, i])) == 1:\n                loop = True\n                indices.remove(i)\n                if len(indices) == rand_attr - 1:\n                    return -1  # all features in dataset have one distinct value\n                break\n    return rand_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit(x, y, t, randomized, max_tree_nodes, min_samples_leaf, min_samples_split, class_majority, measure, accuracy,\n        separate_max):\n    \"\"\"\n    Function builds a binary decision tree with given dataset and it expand tree nodes in priority order. Tree model is\n    stored in a dictionary and it has following structure:\n    {parent_identifier: [(child_identifier, highest_estimated_feature_index , split_value, distribution_of_labels,\n    depth, feature_type)]}\n\n    x: numpy array - dataset with features\n    y: numpy array - dataset with labels\n    t: list - features types\n    randomized: boolean - if True, algorithm estimates sqrt(num_of_features)+1 randomly selected features each\n    iteration.\n    If False, it estimates all features in each iteration.\n    max_tree_nodes: integer - number of tree nodes to expand.\n    min_samples_leaf: float - minimal number of samples in leafs.\n    class_majority: float - purity of the classes in leafs.\n    measure: measure function - information gain or mdl.\n    split_fun: split function - discretization of continuous features can be made randomly or with equal label frequency.\n    \"\"\"\n\n    depth = 0  # depth of the tree\n    node_id = 1  # node identifier\n\n    # conditions of continuous and discrete features.\n    operation = {\"c\": (np.less_equal, np.greater), \"d\": (np.in1d, np.in1d)}\n    tree = {0: [(node_id, -1, \"\", dict(Counter(y)), depth, \"\")]}  # initialize tree model\n    mapping = range(len(x[0]))  # global features indices\n\n    # sqrt(num_of_features) is estimated if randomized == True.\n    # If randomized == False, all indices are estimated at each node.\n    rand_attr = int(np.ceil(np.sqrt(len(x[0]))))\n    recalculate = True\n    while recalculate:\n        recalculate = False\n        est_indices = rand_indices(x, rand_attr) if randomized else range(len(x[0]))\n        # estimate indices with given measure\n        est = [measure(x[:, i], y, t[i], accuracy, separate_max) for i in est_indices]\n        try:\n            max_est, split = max(est)  # find highest estimated split\n        except:\n            recalculate = True\n\n    best = est_indices[est.index((max_est, split))]  # select feature index with highest estimate\n\n    queue = Queue.PriorityQueue()  # initialize priority queue\n    # put datasets in the queue\n    queue.put((max_est, (node_id, x, y, mapping, best, split, depth)))\n\n    while not queue.empty() and len(tree) * 2 < max_tree_nodes:\n        _, (parent_id, x, y, mapping, best, split, depth) = queue.get()\n\n        # features indices are mapped due to constantly changing subsets of data\n        best_map = mapping[best]\n\n        for j in range(2):  # for left and right branch of the tree\n            selection = range(len(x[0]))  # select all indices for the new subset\n            new_mapping = [i for i in mapping]  # create a mapping of indices for a new subset\n\n            if t[best_map] == \"d\" and len(split[j]) == 1:\n                # if feature is discrete with one value in split, we cannot split it further.\n                selection.remove(best)  # remove feature from new dataset\n                new_mapping.remove(best_map)  # remove mapping of feature\n\n            # select rows of new dataset that satisfy condition (less than, greater than or in)\n            indices = operation[t[best_map]][j](x[:, best], split[j]).nonzero()[0]\n            # create new subsets of data\n            sub_x, sub_y = x[indices.reshape(len(indices), 1), selection], y[indices]\n            if j == 0 and (len(sub_y) < min_samples_leaf or len(x) - len(sub_y) < min_samples_leaf):\n                break\n\n            node_id += 1  # increase node identifier\n            y_dist = Counter(sub_y)  # distribution of labels in the new node\n\n            # connect child node with its parent and update tree model\n            tree[parent_id] = tree.get(parent_id, []) + [(node_id, best_map,\n                                                          set(split[j]) if t[best_map] == \"d\" else split[j],\n                                                          dict(y_dist), depth + 1, t[best_map])]\n\n            # select new indices for estimation\n            est_indices = rand_indices(sub_x, rand_attr) if randomized and len(sub_x[0]) > rand_attr else range(\n                len(sub_x[0]))\n            # check label majority\n            current_majority = y_dist[max(y_dist, key=y_dist.get)] / float(len(sub_y))\n\n            # if new node satisfies following conditions it can be further split\n            if current_majority < class_majority and len(sub_y) > min_samples_split and est_indices != -1:\n                # estimate selected indices\n                est = [measure(sub_x[:, i], sub_y, t[new_mapping[i]], accuracy, separate_max) for i in est_indices]\n                try:\n                    max_est, new_split = max(est)  # find highest estimated split\n                except:\n                    continue\n                # select feature index with highest estimate\n                new_best = est_indices[est.index((max_est, new_split))]\n                # put new datasets in the queue with inverse value of estimate (priority order)\n                queue.put(\n                    (max_est * -1 * len(sub_y), (node_id, sub_x, sub_y, new_mapping, new_best, new_split, depth + 1)))\n    return tree", "response": "Function builds a binary decision tree with given dataset and it expands tree nodes in priority order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(tree, x, y=[], dist=False):\n\n    # conditions of continuous and discrete features\n    node_id = 1  # initialize node identifier as first node under the root\n    while 1:\n        nodes = tree[node_id]\n\n        if nodes[0][5] == \"c\":\n            if x[nodes[0][1]] <= nodes[0][2]:\n                index, node_id = 0, nodes[0][0]  # set identifier of child node\n            else:\n                index, node_id = 1, nodes[1][0]  # set identifier of child node\n        else:\n            if x[nodes[0][1]] in nodes[0][2]:\n                index, node_id = 0, nodes[0][0]  # set identifier of child node\n\n            elif x[nodes[1][1]] in nodes[1][2]:\n                index, node_id = 1, nodes[1][0]  # set identifier of child node\n\n            else:\n                # value is not in left or right branch. Get label distributions of left and right child\n                # sum labels distribution to get parent label distribution\n                node_id = str(nodes[0][0]) + \",\" + str(nodes[1][0])\n                index, nodes = 0, [[0, 0, 0, {k: nodes[0][3].get(k, 0) + nodes[1][3].get(k, 0) for k in\n                                              set(nodes[0][3]) | set(nodes[1][3])}]]\n\n        if node_id in tree.keys():  # check if tree can be traversed further\n            continue\n\n        if dist:\n            suma = sum(nodes[index][3].values())\n            return Counter({k: v / float(suma) for k, v in nodes[index][3].iteritems()})\n\n        prediction = max(nodes[index][3], key=nodes[index][3].get)\n        if y == []:\n            return prediction\n\n        probs = sorted(\n            zip(nodes[index][3].keys(), np.true_divide(nodes[index][3].values(), np.sum(nodes[index][3].values()))),\n            key=itemgetter(1), reverse=True)\n        if prediction == y:\n            margin = probs[0][1] - probs[1][1] if len(probs) > 1 else 1\n        else:\n            margin = dict(probs).get(y, 0) - probs[0][1]\n        return node_id, margin", "response": "Function makes a prediction of one sample with a tree model. If y is not defined it returns node identifier and margin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new tab index. Creates a new one if it isn t opened and returns its index otherwise.", "response": "def __addTab(self, filePath):\n        \"\"\"Returns existing tab index. Creates a new one if it isn't opened and returns its index\n        otherwise.\"\"\"\n        for i in range(self.tabBar.count()):\n            widget = self.pages.widget(i)\n            if not widget.isStatic and filePath == widget.filePath:\n                return i\n        tab = SubtitleEditor(filePath, self._subtitleData, self)\n        newIndex = self.tabBar.addTab(self._createTabName(tab.name, tab.history.isClean()))\n        tab.history.cleanChanged.connect(\n            lambda clean: self._cleanStateForFileChanged(filePath, clean))\n        self.pages.addWidget(tab)\n        return newIndex"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges two configuration dictionaries by overwriting values with the priority on values given on the left side of the database.", "response": "def merge_configs(to_be_merged, default):\n    \"\"\"Merges two configuration dictionaries by overwriting values with\n    same keys, with the priority on values given on the 'left' side, so\n    the to_be_merged dict.\n    Notice that with lists in the configuration, it skips from the default\n    (right side) the tuples in that which already exist in the left side\n    to_be_merged list. This is used to be able to override time intervals for\n    default values in the configuration.\n    Example:\n    In [1]: x = [[\"get_stats_disk_usage_for_database\", 180],\n                 [\"get_stats_tx_rate_for_database\", 500]]\n    In [2]: y = [[\"get_stats_seconds_since_last_vacuum_per_table\", 60],\n                 [\"get_stats_tx_rate_for_database\", 60]]\n    In [3]: merge_configs(x, y)\n    Out[3]:\n    [['get_stats_disk_usage_for_database', 180],\n     ['get_stats_tx_rate_for_database', 500],\n     ['get_stats_seconds_since_last_vacuum_per_table', 60]]\n    \"\"\"\n    if isinstance(to_be_merged, dict) and isinstance(default, dict):\n        for k, v in default.items():\n            if k not in to_be_merged:\n                to_be_merged[k] = v\n            else:\n                to_be_merged[k] = merge_configs(to_be_merged[k], v)\n    elif isinstance(to_be_merged, list) and isinstance(default, list):\n        same_keys = set()\n        for x in to_be_merged:\n            for y in default:\n                if isinstance(x, (list, set, tuple)) and isinstance(y, (list, set, tuple)) and len(\n                        x) > 0 and len(y) > 0 and x[0] == y[0]:\n                    same_keys.add(x[0])\n        for y in default:\n            if not isinstance(y, (list, set, tuple)) or y[0] not in same_keys:\n                to_be_merged.append(y)\n    return to_be_merged"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the service configuration file and parses it.", "response": "def find_and_parse_config(config, default_config='default.yaml'):\n    \"\"\"Finds the service configuration file and parses it.\n    Checks also a directory called default, to check for default configuration values,\n    that will be overwritten by the actual configuration found on given path.\n    \"\"\"\n\n    def load_config(path):\n        if os.path.isfile(path):\n            with open(path, 'r') as f:\n                config_dict_ = yaml.load(f)\n            return config_dict_\n\n    config_path = find_file(config)\n    default_path = find_file(default_config)\n    config = load_config(config_path)\n    default_config = load_config(default_path)\n    if config is None and default_config is None:\n        raise ValueError('Both config and default_config return None')\n    if config is None:\n        config_dict = default_config\n    elif default_config is None:\n        config_dict = config\n    else:\n        config_dict = merge(default_config, config)\n\n    return config_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(s, subs):\n    if len(subs) == 0:\n        return []\n\n    points = []\n    requests = _tokenize_request(s)\n\n    if len(requests) == 1 and requests[0].type_ == _Request.Type.OFFSET:\n        return _offset_subtitles(requests[0], subs)\n    return _sync_subtitles(requests, subs)", "response": "Parses a given string and creates a list of SyncPoints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef full_name_natural_split(full_name):\n    parts = full_name.strip().split(' ')\n    first_name = \"\"\n    if parts:\n        first_name = parts.pop(0)\n    if first_name.lower() == \"el\" and parts:\n        first_name += \" \" + parts.pop(0)\n    last_name = \"\"\n    if parts:\n        last_name = parts.pop()\n    if (last_name.lower() == 'i' or last_name.lower() == 'ii'\n        or last_name.lower() == 'iii' and parts):\n        last_name = parts.pop() + \" \" + last_name\n    middle_initials = \"\"\n    for middle_name in parts:\n        if middle_name:\n            middle_initials += middle_name[0]\n    return first_name, middle_initials, last_name", "response": "This function splits a full name into a natural first name last name and middle initials."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the local time that s the user s start of day for a given datetime", "response": "def start_of_day(dtime_at=None):\n    \"\"\"\n    Returns the local (user timezone) start of day, that's,\n    time 00:00:00 for a given datetime\n    \"\"\"\n    dtime_at = datetime_or_now(dtime_at)\n    return datetime.datetime(dtime_at.year, dtime_at.month,\n        dtime_at.day, tzinfo=tzlocal())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dumps(obj, root_tag):\n    xml = _get_xml_value(obj)\n    if xml:\n        # Remove invalid XML\n        xml = RE_ILLEGAL_XML.sub('', xml)\n    if root_tag is None:\n        return xml\n    else:\n        root = root_tag\n        return '<' + root + '>' + xml + '</' + root + '>'", "response": "Serialize obj to an XML."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an individual value to an XML string.", "response": "def _get_xml_value(value):\n    \"\"\"Convert an individual value to an XML string. Calls itself\n    recursively for dictionaries and lists.\n\n    Uses some heuristics to convert the data to XML:\n        - In dictionaries, the keys become the tag name.\n        - In lists the tag name is 'child' with an order-attribute giving\n          the list index.\n        - All other values are included as is.\n\n    All values are escaped to fit into the XML document.\n\n    :param value: The value to convert to XML.\n    :type value: Any valid Python value\n    :rtype: string\n    \"\"\"\n    retval = []\n    if isinstance(value, dict):\n        for key, value in value.iteritems():\n            retval.append('<' + xml_escape(str(key)) + '>')\n            retval.append(_get_xml_value(value))\n            retval.append('</' + xml_escape(str(key)) + '>')\n    elif isinstance(value, list):\n        for key, value in enumerate(value):\n            retval.append('<child order=\"' + xml_escape(str(key)) + '\">')\n            retval.append(_get_xml_value(value))\n            retval.append('</child>')\n    elif isinstance(value, bool):\n        retval.append(xml_escape(str(value).lower()))\n    elif isinstance(value, unicode):\n        retval.append(xml_escape(value.encode('utf-8')))\n    else:\n        retval.append(xml_escape(str(value)))\n    return \"\".join(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch latest changes from stage and touch. timestamp if any python sources have been modified.", "response": "def fetch_changes(repo_path, up_commit='master'):\n    \"\"\"\n    Fetch latest changes from stage and touch .timestamp\n    if any python sources have been modified.\n    \"\"\"\n    last_up_commit = None\n    prevcwd = os.getcwd()\n    try:\n        gitexe = 'git'\n        os.chdir(repo_path)\n        old_sources_timestamp = sources_latest_timestamp('.')\n        shell_command([gitexe, 'pull'])\n        last_up_commit = subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n        shell_command([gitexe, 'checkout', up_commit])\n        up_commit = subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n        new_sources_timestamp = sources_latest_timestamp('.')\n        if old_sources_timestamp < new_sources_timestamp:\n            with open('.timestamp', 'w') as up_commit_file:\n                up_commit_file.write(up_commit)\n    finally:\n        os.chdir(prevcwd)\n    return last_up_commit, up_commit"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef migrate_all():\n    if 'south' in settings.INSTALLED_APPS:\n        return _south_migrate_all()\n    from django.core.management.commands import makemigrations, migrate\n    schema_args = [sys.executable, 'makemigrations']\n    for app in settings.INSTALLED_APPS:\n        if not app.startswith('django'):\n            schema_args += [app]\n    schema_cmd = makemigrations.Command()\n    schema_cmd.run_from_argv(schema_args)\n\n    migrate_cmd = migrate.Command()\n    sys.stderr.write(\"MIGRATE ALL!\\n\")\n    return migrate_cmd.run_from_argv([sys.executable, 'migrate'])", "response": "Create schema migrations for all apps specified in INSTALLED_APPS then run a migrate command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, username, user_api, filename=None):\n        keys = API.__get_keys(filename)\n        user = user_api.find(username)[0]\n        distinguished_name = user.entry_dn\n        if 'ldapPublicKey' not in user.objectClass:\n            raise ldap3.core.exceptions.LDAPNoSuchAttributeResult(\n                'LDAP Public Key Object Class not found. ' +\n                'Please ensure user was created correctly.')\n        else:\n            for key in list(set(keys)):  # prevents duplicate insertion\n                print(key)\n                try:\n                    SSHKey(key).parse()\n                except Exception as err:\n                    raise err from None\n                else:\n                    operation = {'sshPublicKey': [(ldap3.MODIFY_ADD, [key])]}\n                    self.client.modify(distinguished_name, operation)", "response": "Adds an SSH public key to a user s profile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, username, user_api, filename=None, force=False):\n        self.keys = API.__get_keys(filename)\n        self.username = username\n        user = user_api.find(username)[0]\n\n        if not force:  # pragma: no cover\n            self.__confirm()\n\n        for key in self.__delete_keys():\n            operation = {'sshPublicKey': [(ldap3.MODIFY_DELETE, [key])]}\n            self.client.modify(user.entry_dn, operation)", "response": "Remove specified SSH public key from specified user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall SSH keys from LDAP for consumption by SSH.", "response": "def install(self):  # pragma: no cover\n        \"\"\"Install/download ssh keys from LDAP for consumption by SSH.\"\"\"\n        keys = self.get_keys_from_ldap()\n        for user, ssh_keys in keys.items():\n            user_dir = API.__authorized_keys_path(user)\n            if not os.path.isdir(user_dir):\n                os.makedirs(user_dir)\n            authorized_keys_file = os.path.join(user_dir, 'authorized_keys')\n            with open(authorized_keys_file, 'w') as FILE:\n                print(\"\\n\".join([k.decode() for k in ssh_keys]), file=FILE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches keys from ldap.", "response": "def get_keys_from_ldap(self, username=None):\n        \"\"\"\n        Fetch keys from ldap.\n\n        Args:\n            username Username associated with keys to fetch (optional)\n\n        Returns:\n            Array of dictionaries in '{username: [public keys]}' format\n\n        \"\"\"\n        result_dict = {}\n        filter = ['(sshPublicKey=*)']\n        if username is not None:\n            filter.append('(uid={})'.format(username))\n        attributes = ['uid', 'sshPublicKey']\n        results = self.client.search(filter, attributes)\n        for result in results:\n            result_dict[result.uid.value] = result.sshPublicKey.values\n        return result_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(config, username, filename):\n        try:\n            client = Client()\n            client.prepare_connection()\n            user_api = UserApi(client)\n            key_api = API(client)\n            key_api.add(username, user_api, filename)\n        except (ldap3.core.exceptions.LDAPNoSuchAttributeResult,\n                ldap_tools.exceptions.InvalidResult,\n                ldap3.core.exceptions.LDAPAttributeOrValueExistsResult\n                ) as err:  # pragma: no cover\n            print('{}: {}'.format(type(err), err.args[0]))\n        except Exception as err:  # pragma: no cover\n            raise err from None", "response": "Add user s SSH public key to their LDAP entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(config, username, filename, force):\n        client = Client()\n        client.prepare_connection()\n        user_api = UserApi(client)\n        key_api = API(client)\n        key_api.remove(username, user_api, filename, force)", "response": "Remove user s SSH public key from their LDAP entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls user s SSH public key to the local system.", "response": "def install(config):  # pragma: no cover\n        \"\"\"Install user's SSH public key to the local system.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        key_api = API(client)\n        key_api.install()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(config):  # pragma: no cover\n        client = Client()\n        client.prepare_connection()\n        key_api = API(client)\n        for key, values in key_api.get_keys_from_ldap().items():\n            print(\"{}: \".format(key))\n            for value in [v.decode() for v in values]:\n                print(\"\\t - {}\".format(value))", "response": "List SSH public key from LDAP."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows a user s SSH public key from their LDAP entry.", "response": "def show(config, username):  # pragma: no cover\n        \"\"\"Show a user's SSH public key from their LDAP entry.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        key_api = API(client)\n        for key, value in key_api.get_keys_from_ldap(username).items():\n            print(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns mmi - runner", "response": "def main():\n    \"\"\"run mmi runner\"\"\"\n    logging.basicConfig()\n    logger.info(\"mmi-runner\")\n    warnings.warn(\n        \"You are using the mmi-runner script, please switch to `mmi runner`\",\n        DeprecationWarning\n    )\n    arguments = docopt.docopt(__doc__)\n    kwargs = parse_args(arguments)\n    runner = mmi.runner.Runner(\n        **kwargs\n    )\n    runner.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args(arguments, wrapper_kwargs={}):\n    # make a socket that replies to message with the grid\n\n    # if we are running mpi we want to know the rank\n    args = {}\n    positional = [\n        'engine',\n        'configfile',\n    ]\n    for key in positional:\n        args[key] = arguments['<' + key + '>']\n\n    #  integer if not 'random'\n    port = arguments['--port']\n    args['port'] = port if port == 'random' else int(port)\n\n    # integer, default 1\n    interval = arguments['--interval']\n    args['interval'] = int(interval) if interval else 1\n    # boolean\n    args['pause'] = bool(arguments['--pause'])\n    args['bmi_class'] = arguments['--bmi-class']\n    args['output_vars'] = arguments['-o']\n    args['tracker'] = arguments['--track']\n\n    return args", "response": "parse the arguments for the MMI"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a list of package names from a given file path.", "response": "def load_requires_from_file(filepath):\n    \"\"\"Read a package list from a given file path.\n\n    Args:\n      filepath: file path of the package list.\n\n    Returns:\n      a list of package names.\n    \"\"\"\n    with open(filepath) as fp:\n        return [pkg_name.strip() for pkg_name in fp.readlines()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last(self):\n        if len(self._range) == 0:\n            raise IndexError(\"range is empty\")\n        if self._idx == -1:\n            return self._range[0]\n        return self._get(self._idx)", "response": "Returns the last element accessed via next or prev."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tour_list(self):\n        resp = json.loads(urlopen(self.tour_list_url.format(1)).read().decode('utf-8'))\n        total_count = resp['response']['body']['totalCount']\n        # Get total count\n\n        resp = json.loads(urlopen(self.tour_list_url.format(total_count)).read().decode('utf-8'))\n        data = resp['response']['body']['items']['item']\n        # Extract data list\n\n        keychain = {\n            'contentid': ('content_id', None),\n            'contenttypeid': ('content_type_id', None),\n            'title': ('title', None),\n            'addr1': ('address', None),\n            'zipcode': ('zipcode', None),\n            'sigungucode': ('municipality', None),\n            'mapx': ('x', None),\n            'mapy': ('y', None),\n            'cat1': ('main_category', None),\n            'cat2': ('middle_category', None),\n            'cat3': ('small_category', None),\n            'readcount': ('views', 0),\n            'tel': ('tel', None),\n            'firstimage': ('image', None),\n        }\n\n        for tour in data:\n            _dict_key_changer(tour, keychain)\n\n            tour['creation_date'] = str(tour.pop('createdtime'))[:8] if 'createdtime' in tour else None\n            tour['modified_date'] = str(tour.pop('modifiedtime'))[:8] if 'modifiedtime' in tour else None\n\n            tour.pop('areacode', None)\n            tour.pop('addr2', None)\n            tour.pop('mlevel', None)\n            # Manufacture\n\n        return data", "response": "Get all tour list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_detail_common(self, content_id):\n        resp = json.loads(urlopen(self.detail_common_url.format(str(content_id))).read().decode('utf-8'))\n        data = resp['response']['body']['items']['item']\n        # Extract data\n\n        keychain = {\n            'contenttypeid': ('content_type_id', None),\n            'overview': ('overview', None),\n            'tel': ('tel', None),\n            'telname': ('tel_owner', None),\n            'booktour': ('in_book', 0)\n        }\n        _dict_key_changer(data, keychain)\n\n        try:\n            data['homepage'] = re.findall('http\\w?://[\\w|.]+', data.pop('homepage'))[0] if 'homepage' in data else None\n        except IndexError:\n            data['homepage'] = None\n\n        data.pop('contentid', None)\n        data.pop('title', None)\n        data.pop('createdtime', None)\n        data.pop('modifiedtime', None)\n        # Manufacture\n\n        return data", "response": "Get common detail data for a specific content_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets detail introduction for a specific content_id.", "response": "def get_detail_intro(self, content_id):\n        \"\"\"\n        Inquire detail introduction\n\n        :param content_id: Content ID to inquire\n        :type content_id: str\n\n        :rtype: dict\n        \"\"\"\n        content_type_id = self.get_detail_common(content_id)['content_type_id']\n        # Get content type id\n\n        resp = json.loads(urlopen(self.detail_intro_url.format(content_id, content_type_id)).read().decode('utf-8'))\n        data = resp['response']['body']['items']['item']\n        # Extract data\n\n        del data['contentid']\n        del data['contenttypeid']\n\n        if content_type_id == 12:\n            # \uad00\uad11\uc9c0\n            keychain = {\n                'accomcount': ('capacity', None),\n                'chkbabycarriage': ('baby_carriage', None),\n                'chkcreditcard': ('credit_card', None),\n                'chkpet': ('pet', None),\n                'expagerange': ('age_range', None),\n                'expguide': ('guide', None),\n                'infocenter': ('info_center', None),\n                'opendate': ('open_date', None),\n                'parking': ('parking', None),\n                'restdate': ('rest_date', None),\n                'useseason': ('season', None),\n                'usetime': ('use_time', None)\n            }\n            _dict_key_changer(data, keychain)\n\n            data['cultural_heritage'] = data.pop('heritage1', None) == 1\n            data['natural_heritage'] = data.pop('heritage2', None) == 1\n            data['archival_heritage'] = data.pop('heritage3', None) == 1\n        elif content_type_id == 14:\n            # \ubb38\ud654\uc2dc\uc124\n            keychain = {\n                'accomcountculture': ('capacity', None),\n                'chkbabycarriageculture': ('baby_carriage', None),\n                'chkcreditcardculture': ('credit_card', None),\n                'chkpetculture': ('pet', None),\n                'discountinfo': ('discount_info', None),\n                'infocenterculture': ('info_center', None),\n                'parkingculture': ('parking', None),\n                'parkingfee': ('parking_fee', None),\n                'restdateculture': ('rest_date', None),\n                'usefee': ('use_fee', None),\n                'usetimeculture': ('use_time', None),\n                # \uc774\uc6a9\uc2dc\uac04\n                'scale': ('scale', None),\n                'spendtime': ('spend_time', None)\n                # \uad00\ub78c \uc18c\uc694\uc2dc\uac04\n            }\n            _dict_key_changer(data, keychain)\n        elif content_type_id == 15:\n            # \ucd95\uc81c/\uacf5\uc5f0/\ud589\uc0ac\n            keychain = {\n                'agelimit': ('age_limit', None),\n                'bookingplace': ('reservation_place', None),\n                'eventstartdate': ('start_date', None),\n                'eventenddate': ('end_date', None),\n                'eventplace': ('place', None),\n                'festivalgrade': ('festival_grade', None),\n                'placeinfo': ('place_guide', None),\n                'spendtimefestival': ('spend_time', None),\n                'sponsor1': ('organizer', None),\n                'sponsor2': ('host', None),\n                'subevent': ('sub_event', None),\n                'usetimefestival': ('use_fee', None)\n            }\n            _dict_key_changer(data, keychain)\n\n            data.pop('eventhomepage', None)\n        elif content_type_id == 25:\n            # \uc5ec\ud589\ucf54\uc2a4\n            keychain = {\n                'distance': ('distance', None),\n                'infocentertourcourse': ('info_center', None),\n                'schedule': ('schedule', None),\n                'taketime': ('spend_time', None),\n                'theme': ('theme', None)\n            }\n            _dict_key_changer(data, keychain)\n        elif content_type_id == 28:\n            # \ub808\ud3ec\uce20\n            keychain = {\n                'accomcountleports': ('capacity', None),\n                'chkbabycarriageleports': ('baby_carriage', None),\n                'chkcreditcardleports': ('credit_card', None),\n                'chkpetleports': ('pet', None),\n                'expagerangeleports': ('age_range', None),\n                'infocenterleports': ('info_center', None),\n                'openperiod': ('open_period', None),\n                'parkingleports': ('parking', None),\n                'parkingfeeleports': ('parking_fee', None),\n                'reservation': ('reservation_info', None),\n                'restdateleports': ('rest_date', None),\n                'scaleleports': ('scale', None),\n                'usetimeleports': ('use_time', None),\n                'usefeeleports': ('use_fee', None),\n            }\n            _dict_key_changer(data, keychain)\n        elif content_type_id == 32:\n            # \uc219\ubc15\n            keychain = {\n                'accomcountlodging': ('capacity', None),\n                'checkintime': ('checkin_time', None),\n                'checkouttime': ('checkout_time', None),\n                'foodplace': ('food_field', None),\n                'infocenterlodging': ('info_center', None),\n                'parkinglodging': ('parking', None),\n                'pickup': ('pickup_service', None),\n                'reservationlodging': ('reservation_info', None),\n                'roomtype': ('room_type', None),\n                'scalelodging': ('scale', None),\n                'subfacility': ('sub_facility', None)\n            }\n            _dict_key_changer(data, keychain)\n\n            data['benikia'] = data.pop('benikia', False) == 1\n            data['cooking'] = data.pop('chkcooking', False) == 1\n            data['goodstay'] = data.pop('goodstay', False) == 1\n            data['korean_house'] = data.pop('hanok', False) == 1\n            data['barbecue'] = data.pop('barbecue', False) == 1\n            data['beauty'] = data.pop('beauty', False) == 1\n            data['beverage'] = data.pop('beverage', False) == 1\n            data['bicycle'] = data.pop('bicycle', False) == 1\n            data['campfire'] = data.pop('campfire', False) == 1\n            data['fitness'] = data.pop('fitness', False) == 1\n            data['karaoke'] = data.pop('karaoke', False) == 1\n            data['public_bath'] = data.pop('publicbath', False) == 1\n            data['public_pc'] = data.pop('publicpc', False) == 1\n            data['sauna'] = data.pop('sauna', False) == 1\n            data['seminar'] = data.pop('seminar', False) == 1\n            data['sports'] = data.pop('sports', False) == 1\n        elif content_type_id == 38:\n            # \uc1fc\ud551\n            keychain = {\n                'chkbabycarriageshopping': ('baby_carriage', None),\n                'chkcreditcardshopping': ('credit_card', None),\n                'chkpetshopping': ('pet', None),\n                'fairday': ('fair_day', None),\n                'infocentershopping': ('info_center', None),\n                'opendateshopping': ('open_date', None),\n                'opentime': ('use_time', None),\n                'parkingshopping': ('parking', None),\n                'restdateshopping': ('rest_date', None),\n                'restroom': ('restroom_info', None),\n                'saleitem': ('sale_item', None),\n                'saleitemcost': ('sale_item_cost', None),\n                'scaleshopping': ('scale', None),\n                'shopguide': ('guide', None)\n            }\n            _dict_key_changer(data, keychain)\n        elif content_type_id == 39:\n            # \uc74c\uc2dd\n            keychain = {\n                'chkcreditcardfood': ('credit_card', None),\n                'discountinfofodd': ('discount_info', None),\n                'firstmenu': ('rep_menu', None),\n                'infocenterfood': ('info_center', None),\n                'kidsfacility': ('kids_facility', None),\n                'opendatefood': ('open_date', None),\n                'opentimefood': ('open_time', None),\n                'packing': ('packing', None),\n                'parkingfood': ('parking', None),\n                'reservationfood': ('reservation_info', None),\n                'restdatefood': ('rest_date', None),\n                'scalefood': ('scale', None),\n                'seat': ('seat', None),\n                'smoking': ('smoking', None),\n                'treatmenu': ('treat_menus', None)\n            }\n            _dict_key_changer(data, keychain)\n\n            data['kids_facility'] = data.pop('kidsfacility') == 1 if 'kidsfacility' in data else False\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the detail images for a specific content_id.", "response": "def get_detail_images(self, content_id):\n        \"\"\"\n        Inquire detail images\n\n        :param content_id: Content ID to inquire\n        :type content_id: str\n\n        :rtype: list\n        \"\"\"\n        resp = json.loads(urlopen(self.additional_images_url.format(content_id, 1)).read().decode('utf-8'))\n        total_count = resp['response']['body']['totalCount']\n        # Get total count\n\n        resp = json.loads(urlopen(self.additional_images_url.format(content_id, total_count)).read().decode('utf-8'))\n        try:\n            data = resp['response']['body']['items']['item']\n            # Extract data list\n            if type(data) is dict:\n                data.pop('contentid', None)\n                data.pop('serialnum', None)\n                data['origin'] = data.pop('originimgurl', None)\n                data['small'] = data.pop('smallimageurl', None)\n                # Manufacture\n            else:\n                for img in data:\n                    if type(img) is dict:\n                        img.pop('contentid', None)\n                        img.pop('serialnum', None)\n                        img['origin'] = img.pop('originimgurl', None)\n                        img['small'] = img.pop('smallimageurl', None)\n                        # Manufacture\n                    else:\n                        del img\n\n            return data if type(data) is list else [data]\n        except TypeError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsafing file writing. Most common mistakes are checked against and reported before write operation. After that, if anything unexpected happens, user won't be left without data or with corrupted one as this method writes to a temporary file and then simply renames it (which should be atomic operation according to POSIX but who knows how Ext4 really works. @see: http://lwn.net/Articles/322823/).", "response": "def _writeFile(cls, filePath, content, encoding = None):\n        \"\"\"Safe file writing. Most common mistakes are checked against and reported before write\n        operation. After that, if anything unexpected happens, user won't be left without data or\n        with corrupted one as this method writes to a temporary file and then simply renames it\n        (which should be atomic operation according to POSIX but who knows how Ext4 really works.\n        @see: http://lwn.net/Articles/322823/).\"\"\"\n\n        filePath = os.path.realpath(filePath)\n        log.debug(_(\"Real file path to write: %s\" % filePath))\n\n        if encoding is None:\n            encoding = File.DEFAULT_ENCODING\n\n        try:\n            encodedContent = ''.join(content).encode(encoding)\n        except LookupError as msg:\n            raise SubFileError(_(\"Unknown encoding name: '%s'.\") % encoding)\n        except UnicodeEncodeError:\n            raise SubFileError(\n                _(\"There are some characters in '%(file)s' that cannot be encoded to '%(enc)s'.\")\n                % {\"file\": filePath, \"enc\": encoding})\n\n        tmpFilePath = \"%s.tmp\" % filePath\n        bakFilePath = \"%s.bak\" % filePath\n        with open(tmpFilePath, 'wb') as f:\n            f.write(encodedContent)\n            # ensure that all data is on disk.\n            # for performance reasons, we skip os.fsync(f.fileno())\n            f.flush()\n\n        try:\n            os.rename(filePath, bakFilePath)\n        except FileNotFoundError:\n            # there's nothing to move when filePath doesn't exist\n            # note the Python bug: http://bugs.python.org/issue16074\n            pass\n\n        os.rename(tmpFilePath, filePath)\n\n        try:\n            os.unlink(bakFilePath)\n        except FileNotFoundError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detectFps(self, movieFile = None, default = 23.976):\n\n        if movieFile is None:\n            movieFile = self._searchForMovieFile()\n        return File.detectFpsFromMovie(movieFile, default)", "response": "Fetch movie FPS from MPlayer output or return given default."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detectFpsFromMovie(cls, movieFile, default = 23.976):\n\n        # initialize with a default FPS value, but not with a movieFile\n        videoInfo = VideoInfo(float(default))\n\n        command = ['mplayer',\n            '-really-quiet', '-vo', 'null', '-ao', 'null', '-frames', '0', '-identify', movieFile]\n\n        try:\n            mpOut, mpErr = Popen(command, stdout=PIPE, stderr=PIPE).communicate()\n            log.debug(mpOut)\n            log.debug(mpErr)\n\n            # Overwrite default (not fetched from video) values.\n            # If there's any error on changing videoInfo.fps, whole videoInfo won't be changed at\n            # all.\n            videoInfo.fps = float(re.search(r'ID_VIDEO_FPS=([\\w/.]+)\\s?', str(mpOut)).group(1))\n            videoInfo.videoPath = movieFile\n        except OSError:\n            log.warning(_(\"Couldn't run mplayer. It has to be installed and placed in your $PATH \"\n                \"to detect FPS.\"))\n        except AttributeError:\n            log.warning(_(\"Couldn't get FPS from %(movie)s. Using default value: %(fps)s.\") %\n                {\"movie\": movieFile, \"fps\": videoInfo.fps})\n        else:\n            pass\n            log.debug(P_(\n                \"Got %(fps)s FPS from '%(movie)s'.\",\n                \"Got %(fps)s FPS from '%(movie)s'.\",\n                int(videoInfo.fps)) % {\"fps\": videoInfo.fps, \"movie\": videoInfo.videoPath})\n\n        return videoInfo", "response": "Detect FPS from a movie file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pay_with_account_credit_cards(invoice_id) -> Optional[Transaction]:\n    logger.debug('invoice-payment-started', invoice_id=invoice_id)\n    with transaction.atomic():\n        invoice = Invoice.objects.select_for_update().get(pk=invoice_id)\n\n        #\n        # Precondition: Invoice should be in a state that allows payment\n        #\n        if not invoice.in_payable_state:\n            raise PreconditionError('Cannot pay invoice with status {}.'.format(invoice.status))\n\n        #\n        # Precondition: The due amount must be positive, in a single currency\n        #\n        due = invoice.due().monies()\n        if len(due) == 0:\n            raise PreconditionError('Cannot pay empty invoice.')\n        if len(due) > 1:\n            raise PreconditionError('Cannot pay invoice with more than one currency.')\n        amount = due[0]\n        if amount.amount <= 0:\n            raise PreconditionError('Cannot pay invoice with non-positive amount.')\n\n        #\n        # Try valid credit cards until one works. Start with the active ones\n        #\n        valid_credit_cards = CreditCard.objects.valid().filter(account=invoice.account).order_by('status')\n        if not valid_credit_cards:\n            raise PreconditionError('No valid credit card on account.')\n\n        for credit_card in valid_credit_cards:\n            try:\n                success, payment_psp_object = psp.charge_credit_card(\n                    credit_card_psp_object=credit_card.psp_object,\n                    amount=amount,\n                    client_ref=str(invoice_id))\n                payment = Transaction.objects.create(\n                    account=invoice.account,\n                    invoice=invoice,\n                    amount=amount,\n                    success=success,\n                    payment_method=credit_card.type,\n                    credit_card_number=credit_card.number,\n                    psp_object=payment_psp_object)\n                if success:\n                    invoice.pay()\n                    invoice.save()\n                    logger.info('invoice-payment-success', invoice=invoice_id, payment=payment)\n                    return payment\n                else:\n                    logger.info('invoice-payment-failure', invoice=invoice_id, payment=payment)\n            except Exception as e:\n                logger.error('invoice-payment-error', invoice_id=invoice_id, credit_card=credit_card, exc_info=e)\n        return None", "response": "Get paid for the invoice and try the valid credit cards on the account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smooth(x, y, degree=1, logx=False, logy=False):\n    if degree == 0:\n        return x, y\n    else:\n        if logx:\n            x = np.log10(x)\n        if logy:\n            y = np.log10(y)\n\n        if degree == 1:\n            # generate new linearly spaced x-points\n            smoothed_x = np.linspace(min(x), max(x), len(x))\n            # generate new y-points using linear interpolation\n            smoothed_y = np.interp(smoothed_x, x, y)\n        else:\n            # smooth data by linear interpolation\n            x, y = smooth(x, y, degree - 1)\n            smoothed_x = (x[:-1] + x[1:]) / 2\n            smoothed_y = np.interp(smoothed_x, x, y)\n\n        if logx:\n            smoothed_x = 10 ** smoothed_x\n        if logy:\n            smoothed_y = 10 ** smoothed_y\n\n        return smoothed_x, smoothed_y", "response": "Smooth y - values and return new x y pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating toolbox contents with a data corresponding to a given tab.", "response": "def setContentFor(self, widget):\n        \"\"\"Updates toolbox contents with a data corresponding to a given tab.\"\"\"\n        for i in range(self.count()):\n            item = self.widget(i)\n            if widget.isStatic:\n                item.setStaticContent(widget)\n            else:\n                item.setContent(widget)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear(self):\n        layout = self.layout()\n        for index in reversed(range(layout.count())):\n            item = layout.takeAt(index)\n            try:\n                item.widget().deleteLater()\n            except AttributeError:\n                item = None", "response": "Removes all child widgets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting content for static widget.", "response": "def setStaticContent(self, widget=None):\n        \"\"\"Set content for static widget (FileList).\"\"\"\n        self.clear()\n        self.addTitle(_(\"No subtitle data\"))\n        self.addLabel(_(\"Open subtitles in a new tab to see their details.\"))\n        self.addStretch()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _abort_http(method, http_resp):\n    exc_template = \"\"\"POST {method} {0.status_code} {0.reason}\nHeaders:\n{headers}\nContent:\n{0.content!r}\nSummary: POST {method} {0.status_code} {0.reason}\"\"\"\n\n    headers = _pp.pformat(dict(http_resp.headers))\n\n    message = exc_template.format(\n        http_resp,\n        method=method,\n        headers=headers,\n    )\n    raise _exc.FastbillResponseError(message, http_resp)", "response": "Abort the HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _request(self, service, **kw):\n        fb_request = {\n            'service': service,\n        }\n        for key in ['limit', 'offset', 'filter', 'data']:\n            fb_request[key] = kw.pop(key, None)\n\n        if kw:\n            raise _exc.FastbillRequestError(\"Unknown arguments: %s\" %\n                                            \", \".join(kw.keys()))\n\n        data = _jsonencoder.dumps(fb_request)\n        _logger.debug(\"Sending data: %r\", data)\n\n        self._pre_request_callback(service, fb_request)\n        # TODO: Retry when we hit a 404 (api not found). Probably a deploy.\n        http_resp = self.session.post(self.SERVICE_URL,\n                                      auth=self.auth,\n                                      headers=self.headers,\n                                      timeout=self.timeout,\n                                      data=data)\n        self._post_request_callback(service, fb_request, http_resp)\n\n        try:\n            json_resp = http_resp.json()\n        except ValueError:\n            _logger.debug(\"Got data: %r\", http_resp.content)\n            _abort_http(service, http_resp)\n            return  # to make PyCharm happy\n        else:\n            _logger.debug(\"Got data: %r\", json_resp)\n\n        errors = json_resp['RESPONSE'].get('ERRORS')\n        if errors:\n            _abort_api(service, json_resp, errors)\n\n        # If Fastbill should ever remove the REQUEST or SERVICE section\n        # from their responses, just remove the checks.\n        if json_resp['REQUEST']['SERVICE'] != service:\n            raise _exc.FastbillError(\n                \"API Error: Got response from wrong service.\")\n\n        return _response.FastbillResponse(json_resp['RESPONSE'], self)", "response": "Perform the actual request to Fastbill s API server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattaching node to its parent.", "response": "def set_parent(self, node):\n        \"\"\"\n        Attach node to its parent.\n\n        Args:\n            node: Parent node.\n\n        Note:\n            ``node`` can be ``None``. In that case, the node is detached from its previous parent.\n\n        \"\"\"\n        self._parent = node\n\n        if node is None:\n            # detach from parent\n            self._depth = 0\n        else:\n            self._depth = node.get_depth() + 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd one child node to this node.", "response": "def set_child_node(self, name, node):\n        \"\"\"\n        Add one child node to this node.\n\n        Args:\n            name (str): Name of the child.\n            node (TreeMapNode): Node to add.\n\n        Warning:\n            No test is done to see whether or not a node was already attached with that name. If this is the case, the\n            new node takes the place of the old one that is now unreachable. See :meth:`set_unique_child_node`.\n        \"\"\"\n        assert isinstance(node, TreeMapNode)\n        self._nodes[name] = node\n        node.set_parent(self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding one child node to this node.", "response": "def set_unique_child_node(self, name, node):\n        \"\"\"\n        Add one child node to this node.\n\n        Args:\n            name (str): Name of the child.\n            node (TreeMapNode): Node to add.\n\n        Note:\n            The name must **not** be in use.\n        \"\"\"\n        try:\n            temp = self._nodes[name]\n            raise RuntimeError(\"Name '%s' is already used for child node\" % name)\n        except KeyError:\n            pass\n\n        self.set_child_node(name, node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_child_leaf_nodes(self):\n\n        def _yield_child_leaf_nodes(node):\n            \"\"\"\n\n            Args:\n                node:\n\n            Yields:\n            \"\"\"\n            if not node.has_children():\n                yield node\n            else:\n                for child_node in node.generate_child_nodes():\n                    # recursivity is not compatible with yield in Python2.x: you have to re-yield results\n                    for child in _yield_child_leaf_nodes(child_node):\n                        yield child\n\n        return _yield_child_leaf_nodes(self)", "response": "Generate leaf nodes of this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetaches all children from the current node.", "response": "def detach_children(self):\n        \"\"\"\n        Erase references to children without deleting them.\n\n        These children might be used somewhere else, otherwise they will be taken care by ``Python``'s garbage collector.\n        \"\"\"\n        for node in self.get_child_nodes():\n            node.set_parent(None)\n        self._nodes = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_expt(h5_path, inmemory = True, ignorenan = False):\n\n    logging.info(\"Reading file at {}\".format(h5_path))\n    h5_file = tables.open_file(h5_path, mode = 'r')\n\n    F = h5_file.root.F_measure\n\n    n_expt, n_labels, n_class = F.shape\n    mean_n_iterations = np.sum(h5_file.root.n_iterations)/n_expt\n\n    if hasattr(h5_file.root, 'CPU_time'):\n        CPU_time = h5_file.root.CPU_time\n        mean_CPU_time = np.mean(CPU_time)\n        var_CPU_time = np.var(CPU_time)\n    else:\n        mean_CPU_time = None\n        var_CPU_time = None\n        mean_CPU_time_per_iteration = None\n\n    F_mean = np.empty([n_labels, n_class], dtype='float')\n    F_var = np.empty([n_labels, n_class], dtype='float')\n    F_stderr = np.empty([n_labels, n_class], dtype='float')\n    n_sample = np.empty(n_labels, dtype='int')\n    if inmemory:\n        F_mem = F[:,:,:]\n\n    logging.info(\"Beginning processing\".format())\n    for t in range(n_labels):\n\n        if t%np.ceil(n_labels/10).astype(int) == 0:\n            logging.info(\"Processed {} of {} experiments\".format(t, n_labels))\n        if inmemory:\n            temp = F_mem[:,t,:]\n        else:\n            temp = F[:,t,:]\n        if ignorenan:\n            n_sample[t] = np.sum(~np.isnan(temp))\n            # Expect to see RuntimeWarnings if array contains all NaNs\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n                F_mean[t] = np.nanmean(temp, axis=0)\n                F_var[t] = np.nanvar(temp, axis=0)\n                F_stderr[t] = np.sqrt(F_var[t]/n_sample[t])\n        else:\n            n_sample[t] = len(temp)\n            F_mean[t] = np.mean(temp, axis=0)\n            F_var[t] = np.var(temp, axis=0)\n            F_stderr[t] = np.sqrt(F_var[t]/n_sample[t])\n\n    logging.info(\"Processing complete\".format())\n\n    h5_file.close()\n\n    return {'mean': F_mean,\n            'variance': F_var,\n            'std_error': F_stderr,\n            'n_samples': n_sample,\n            'n_expts': n_expt,\n            'n_labels': n_labels,\n            'mean_CPU_time': mean_CPU_time,\n            'var_CPU_time': var_CPU_time,\n            'mean_n_iterations': mean_n_iterations,\n            'h5_path': h5_path}", "response": "This function processes the experimental data in the HDF5 file and returns a dictionary containing the mean and variance of the experiments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scores_to_preds(self, threshold, use_probs = True):\n        self.threshold = threshold\n\n        if use_probs:\n            if self.probs is None:\n                raise DataError(\"Probabilities are not available to make \"\n                                \"predictions.\")\n            else:\n                word = \"probabilities\"\n                scores = self.probs\n        else:\n            if self.scores is None:\n                raise DataError(\"Scores are not available to make predictions.\")\n            else:\n                word = \"scores\"\n                scores = self.scores\n\n        if threshold > np.max(scores) or threshold < np.min(scores):\n            warnings.warn(\"Threshold {} is outside the range of the \"\n                          \"{}.\".format(self.threshold, word))\n\n        if self.preds is not None:\n            warnings.warn(\"Overwriting predictions\")\n        self.preds = (scores >= threshold)*1", "response": "Set self. scores to predictions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_confusion_matrix(self, printout = False):\n        if self.labels is None:\n            raise DataError(\"Cannot calculate confusion matrix before data \"\n                            \"has been read.\")\n\n        if self.preds is None:\n            raise DataError(\"Predictions not available. Please run \"\n                            \"`scores_to_preds` before calculating confusion \"\n                            \"matrix\")\n\n        self.TP = np.sum(np.logical_and(self.preds == 1, self.labels == 1))\n        self.TN = np.sum(np.logical_and(self.preds == 0, self.labels == 0))\n        self.FP = np.sum(np.logical_and(self.preds == 1, self.labels == 0))\n        self.FN = np.sum(np.logical_and(self.preds == 0, self.labels == 1))\n\n        if printout:\n            print(\"Contingency matrix is:\")\n            print(\"----------------------\")\n            print(\"TP: {} \\t FN: {}\".format(self.TP,self.FN))\n            print(\"FP: {} \\t TN: {}\".format(self.FP,self.TN))\n            print(\"\\n\")", "response": "Calculates the confusion matrix for the current class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating precision recall and balanced F - measure and calculate true performance.", "response": "def calc_true_performance(self, printout = False):\n        \"\"\"\n        Evaluate precision, recall and balanced F-measure\n        \"\"\"\n        try:\n            self.calc_confusion_matrix(printout = False)\n        except DataError as e:\n            print(e.msg)\n            raise\n\n        if self.TP + self.FP == 0:\n            self.precision = np.nan\n        else:\n            self.precision = self.TP / (self.TP + self.FP)\n\n        if self.TP + self.FN == 0:\n            self.recall = np.nan\n        else:\n            self.recall = self.TP / (self.TP + self.FN)\n\n        if self.precision + self.recall == 0:\n            self.F1_measure = np.nan\n        else:\n            self.F1_measure = ( 2 * self.precision * self.recall /\n                                 (self.precision + self.recall) )\n\n        if printout:\n            print(\"True performance is:\")\n            print(\"--------------------\")\n            print(\"Precision: {} \\t Recall: {} \\t F1 measure: {}\".format(self.precision, self.recall, self.F1_measure))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying the foreign key constraint on the outbound field.", "response": "def modify_fk_constraint(apps, schema_editor):\n    \"\"\"\n    Delete's the current foreign key contraint on the outbound field, and adds\n    it again, but this time with an ON DELETE clause\n    \"\"\"\n    model = apps.get_model(\"message_sender\", \"OutboundSendFailure\")\n    table = model._meta.db_table\n\n    with schema_editor.connection.cursor() as cursor:\n        constraints = schema_editor.connection.introspection.get_constraints(\n            cursor, table\n        )\n        [constraint] = filter(lambda c: c[1][\"foreign_key\"], constraints.items())\n        [name, _] = constraint\n    sql_delete_fk = (\n        \"SET CONSTRAINTS {name} IMMEDIATE; \"\n        \"ALTER TABLE {table} DROP CONSTRAINT {name}\"\n    ).format(table=schema_editor.quote_name(table), name=schema_editor.quote_name(name))\n    schema_editor.execute(sql_delete_fk)\n\n    field = model.outbound.field\n    to_table = field.remote_field.model._meta.db_table\n    to_column = field.remote_field.model._meta.get_field(\n        field.remote_field.field_name\n    ).column\n    sql_create_fk = (\n        \"ALTER TABLE {table} ADD CONSTRAINT {name} FOREIGN KEY \"\n        \"({column}) REFERENCES {to_table} ({to_column}) \"\n        \"ON DELETE CASCADE {deferrable};\"\n    ).format(\n        table=schema_editor.quote_name(table),\n        name=schema_editor.quote_name(name),\n        column=schema_editor.quote_name(field.column),\n        to_table=schema_editor.quote_name(to_table),\n        to_column=schema_editor.quote_name(to_column),\n        deferrable=schema_editor.connection.ops.deferrable_sql(),\n    )\n    schema_editor.execute(sql_create_fk)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_generator_action(self, action):\n        if not isinstance(action, GeneratorAction):\n            raise RuntimeError('Can not add a none GeneratorAction object.')\n\n        self.__generator_actions.append(action)", "response": "Add a generator action."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_compatible_generator_action(self, filename):\n        # find first compatible generator action\n        for action in self.__generator_actions:\n            if action.act_on_file(filename):\n                return action\n\n        return None", "response": "Returns the first compatible generator action for a given filename."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog a warning if logger exists.", "response": "def log_warning(self, msg):\n        \"\"\"\n        Log a warning if ``logger`` exists.\n\n        Args:\n            msg: Warning to log.\n\n        Warning:\n            Can raise a ``RuntimeError`` if this was asked in the constructor.\n\n        \"\"\"\n        if self.__logger:\n            self.__logger.warning(msg)\n\n        if self.__raise_exception_on_warning:\n            raise RuntimeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_error(self, msg):\n        if self.__logger:\n            self.__logger.error(msg)\n\n        raise RuntimeError(msg)", "response": "Log an error and raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a filter in the Jinja2 environment.", "response": "def register_filter(self, filter_name, filter_ref, force=False):\n        \"\"\"\n        Add/register one filter.\n\n        Args:\n            filter_name (str): Filter name used inside :program:`Jinja2` tags.\n            filter_ref: Reference to the filter itself, i.e. the corresponding :program:`Python` function.\n            force (bool): If set to ``True``, forces the registration of a filter no matter if it already exists or not.\n\n        Note:\n            The list of user added/registered filters can be retrieve with :mth:`registered_filters_list`\n        \"\"\"\n        if not force and (filter_name in self.filters_list()):\n            self.log_warning(\"Extension %s already exist, ignore redefinition.\" % ext_in)\n            return\n\n        self.__jinja2_environment.filters[filter_name] = filter_ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_filters(self, filters, force=False):\n        for filter_name, filter_ref in filters.items():\n            self.register_filter(filter_name, filter_ref, force)", "response": "Add or register filters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef registered_filters_list(self):\n        return [filter_name for filter_name in self.__jinja2_environment.filters.keys() if filter_name not in self.__jinja2_predefined_filters ]", "response": "Return the list of registered filters as a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds common type filters for the CysParse project.", "response": "def register_common_type_filters(self):\n        \"\"\"\n        Add/register common type filters for the :program:`CySparse` project.\n\n        \"\"\"\n        self.register_filter('type2enum', type2enum)\n        self.register_filter('cysparse_type_to_numpy_c_type', cysparse_type_to_numpy_c_type)\n        self.register_filter('cysparse_type_to_numpy_type', cysparse_type_to_numpy_type)\n        self.register_filter('cysparse_type_to_numpy_enum_type', cysparse_type_to_numpy_enum_type)\n        self.register_filter('cysparse_type_to_real_sum_cysparse_type', cysparse_type_to_real_sum_cysparse_type)\n        self.register_filter('cysparse_real_type_from_real_cysparse_complex_type', cysparse_real_type_from_real_cysparse_complex_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds or register a file extension.", "response": "def register_extension(self, ext_in, ext_out, force=False):\n        \"\"\"\n        Add/register a file extension.\n\n\n        Args:\n            ext_in (str): Extension of input files.\n            ext_out (str): Extension of corresponding output files.\n            force (bool): If ``force`` is set to ``True``, simply overwrite existing extensions, otherwise do nothing.\n                If the ``logger`` is set, log a warning about the duplicate extension if ``force == False``.\n\n\n        \"\"\"\n        if not force and (ext_in in self.__extensions.keys()):\n            self.log_warning(\"Extension %s already exist, ignore redefinition.\" % ext_in)\n            return\n\n        self.__extensions[ext_in] = ext_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_extensions(self, exts, force=False):\n        for ext_in, ext_out in exts.items():\n            self.register_extension(ext_in, ext_out, force)", "response": "Add or register extensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds action into the dictionary of actions.", "response": "def __add_action(self, relative_directory, action):\n        \"\"\"\n        Add action into the dictionary of actions.\n\n        Args:\n            relative_directory:\n            action:\n\n        \"\"\"\n        generator_action_container = self.__actions.retrieve_element_or_default(relative_directory, None)\n\n        if generator_action_container is None:\n            generator_action_container = GeneratorActionContainer()\n            generator_action_container.add_generator_action(action)\n            self.__actions.add_element(location=relative_directory, element=generator_action_container)\n        else:\n            generator_action_container.add_generator_action(action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __is_function_action(self, action_function):\n        # test if function returns a couple of values\n        is_function_action = True\n\n        if not hasattr(action_function, '__call__'):\n            return False\n\n        # OK, callable. Do we receive the right arguments?\n        try:\n            for end_string, context in action_function():\n                if not isinstance(end_string, basestring):\n                    self.log_error(\"Action function must return end of filename as a string as first argument\")\n                if not isinstance(context, dict):\n                    self.log_error(\"Action function must return context as a dict as second argument\")\n                break\n        except Exception:\n            is_function_action = False\n\n        return is_function_action", "response": "Test if given function is really an action function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_action(self, relative_directory, file_pattern, action_function):\n        # test if directory exists\n        if not os.path.isdir(os.path.join(self.__root_directory, relative_directory)):\n            self.log_error('Relative directory \\'%s\\' does not exist.' % relative_directory)\n            return\n\n        if not self.__is_function_action(action_function):\n                self.log_error('Attached function is not an action function.')\n\n        self.__add_action(relative_directory, GeneratorAction(file_pattern, action_function))", "response": "Add an action to the list of available modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_default_action(self, file_pattern,  action_function):\n        if self.__default_action is not None:\n            self.log_error('Default action function already exist.')\n\n        if not self.__is_function_action(action_function):\n            self.log_error('Attached default function is not an action function.')\n\n        self.__default_action = GeneratorAction(file_pattern=file_pattern, action_function=action_function)", "response": "Register a default action for the given file pattern."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __generate_file(self, template_filename, context, generated_filename, force=False):\n        # TODO: maybe avoid reading same template file again and again... i.e. parse it once and generate all needed files without reparsing the template.\n        # test if file is non existing or needs to be regenerated\n        if force or (not os.path.isfile(generated_filename) or os.stat(template_filename).st_mtime - os.stat(generated_filename).st_mtime > 1):\n            self.log_info('   Parsing file %s' % template_filename)\n            code_generated = self.__jinja2_environment.get_template(template_filename).render(context)\n\n            with open(generated_filename, 'w') as f:\n                self.log_info('   Generating file %s' % generated_filename)\n                f.write(code_generated.encode('utf8'))", "response": "Generate one file from a template file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_page(self, *args, **kwargs):\n        '''\n        This is called after the page has been loaded, good time to do extra polishing\n        '''\n        super(BaseBackend, self).prepare_page(*args, **kwargs)", "response": "This is called before the page has been loaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, pattern):\n        def wrap(f):\n            self.functions.append((f, pattern))\n            return f\n\n        return wrap", "response": "Decorator to add new dispatch functions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_method(self, pattern):\n        def wrap(f):\n            def frozen_function(class_instance, f):\n                def _(pattern, *args, **kwargs):\n                    return f(class_instance, pattern, *args, **kwargs)\n\n                return _\n\n            self.functions.append((frozen_function(self, f), pattern))\n            return f\n\n        return wrap", "response": "Decorator to add new dispatch functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dispatch(self, stream, *args, **kwargs):\n        for f, pat in self.functions:\n            matched, matched_stream = self._match(stream, pat, {}, {})\n            if matched:\n                return f(matched_stream, *args, **kwargs)\n\n        raise DispatchFailed()", "response": "Dispatch to functions held internally depending upon the value of stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndispatch to function held internally depending upon the value of stream.", "response": "def dispatch_strict(self, stream, *args, **kwargs):\n        \"\"\"\n        Dispatch to function held internally depending upon the value of stream.\n\n        Matching on directories is strict. This means dictionaries will\n        match if they are exactly the same.\n\n        \"\"\"\n        for f, pat in self.functions:\n            matched, matched_stream = self._match(stream, pat, \n                                                  {'strict': True}, {})\n            if matched:\n                return f(matched_stream, *args, **kwargs)\n\n        raise DispatchFailed()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the current status of the current txpool.", "response": "def txpool_status(self):\n        \"\"\"https://github.com/ethereum/go-ethereum/wiki/Management-APIs#txpool_status\n\n        :rtype: dict\n        \"\"\"\n        result = yield from self.rpc_call('txpool_status')\n        return {k: hex_to_dec(v) for k, v in result.items()}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecide if this decorator was called with arguments", "response": "def is_wrapped_arg(self, *args, **kwargs):\n        \"\"\"decide if this decorator was called with arguments (eg, @dec(...)) or\n        without (eg, @dec) so we can take the correct path when the decorator is\n        invoked\n\n        for the most part this works except for the case where you have one callback\n        or class as the only passed in method to the decorator (eg, @dec(lambda x: x)),\n        you can get around it by using named arguments (eg, @dec(callback=lambda x: x))\n        or by setting required_args class property to True in your child decorator,\n        otherwise this will try and autodiscover and have to recover when the\n        decorator is actually invoked. I wracked my brain trying to figure out a\n        better way to do this and I couldn't come up with anything and after the\n        hours I've spent on it I'm just not sure there is a way to really know\n\n        :param *args: any positional values passed into __new__ or __call__\n        :param **kwargs: any named values passed into __new__ or __call__\n        :returns: boolean\n        \"\"\"\n        ret = False\n        if len(args) == 1 and len(kwargs) == 0:\n            #pout.v(args, self, isinstance(args[0], type), isinstance(args[0], FuncDecorator))\n            ret = inspect.isfunction(args[0]) \\\n                or isinstance(args[0], type) \\\n                or isinstance(args[0], Decorator)\n            if ret:\n                ret = not self.required_args\n#                 if ret:\n#                     frames = inspect.getouterframes(inspect.currentframe())\n#                     if len(frames) >= 3:\n#                         dec_frame = frames[2]\n#                         lines = \"\".join(dec_frame[4]).strip()\n#                         # we have 3 possibilities here:\n#                         # 1) @dec\n#                         # 2) @dec(...)\n#                         # 3) something else\n#                         # this will return True for 1 and 3\n#                         if re.match(r\"^@\", lines):\n#                             ret = \"(\" not in lines\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride this in a child class with your own logic, it must return a function that calls self.func :param func: callback -- the function being decorated :param decorator_args: tuple -- the arguments passed into the decorator (eg, @dec(1, 2)) :param decorator_kwargs: dict -- the named args passed into the decorator (eg, @dec(foo=1)) :returns: the wrapped func with our decorator func", "response": "def decorate_func(self, func, *decorator_args, **decorator_kwargs):\n        \"\"\"override this in a child class with your own logic, it must return a\n        function that calls self.func\n\n        :param func: callback -- the function being decorated\n        :param decorator_args: tuple -- the arguments passed into the decorator (eg, @dec(1, 2))\n        :param decorator_kwargs: dict -- the named args passed into the decorator (eg, @dec(foo=1))\n        :returns: the wrapped func with our decorator func\n        \"\"\"\n        raise RuntimeError(\"decorator {} does not support function decoration\".format(self.__class__.__name__))\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decorate_class(self, klass, *decorator_args, **decorator_kwargs):\n        raise RuntimeError(\"decorator {} does not support class decoration\".format(self.__class__.__name__))\n        return klass", "response": "override this in a child class with your own logic it must return a\n        function that returns klass or the like\n        function that returns klass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decorate(self, func, *decorator_args, **decorator_kwargs):\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        return wrapper", "response": "Decorator for the a\n        method"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget device info from GH.", "response": "async def device_info():\n    \"\"\"Get device info from GH.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = DeviceInfo(LOOP, session, IPADDRESS)\n        await ghlocalapi.get_device_info()\n\n        print(\"Device info:\", ghlocalapi.device_info)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plan(*args, **kwargs):\n    '''\n    plan(name1=calcs1, name2=calc2...) yields a new calculation plan (object of type\n      Plan) that is itself a constructor for the calculation dictionary that is implied by\n      the given calc functionss given. The names that are given are used as identifiers for\n      updating the calc plan (using the without and using methods).\n    plan(arg1, arg2..., name1=calc1, name2=calc2...) additionally initializes the dictionary\n      of calculations and names with the calculation plans or dictionaries given as arguments. These\n      are collapsed left-to-right.\n    plan(imap) yields the plan object for the given IMap imap.\n    '''\n    if len(args) == 1 and len(kwargs) == 0 and is_imap(args[0]):\n        return args[0].plan\n    adict = merge(tuple(arg.nodes if isinstance(arg, Plan) else arg for arg in args),\n                  kwargs)\n    return Plan(**adict)", "response": "Returns a new calculation plan object that is a constructor for the given calculation dictionary and the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef imap(p, *args, **kwargs):\n    '''\n    imap(p, args...) yields an immutable map object made from the plan object p and the given\n    arguments, which may be any number of mappings followed by any number of keyword arguments,\n    all of which are merged left-to-right then interpreted as the parameters of the given plan p.\n    '''\n    p = p if is_plan(p) else plan(p)\n    params = merge(args, kwargs)\n    return p(params)", "response": "Returns an immutable map object made from a plan object p and the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_tr(calc_fn, *args, **kwargs):\n    '''\n    calc_tr(calc_fn, ...) yields a copy of calc_fn in which the afferent and efferent values of the\n      function have been translated. The translation is found from merging the list of 0 or more\n      dictionary arguments given left-to-right followed by the keyword arguments. If the calc_fn\n      that is given is not a @calc function explicitly, calc_tr will attempt to coerce it to one.\n    '''\n    if not is_calc(calc_fn):\n        calc_fn = calc(calc_fn)\n    return calc_fn.tr(*args, **kwargs)", "response": "A function that returns a copy of the given calc_fn with the given arguments translated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of a plan p with the given arguments translated.", "response": "def plan_tr(p, *args, **kwargs):\n    '''\n    plan_tr(p, ...) yields a copy of plan p in which the afferent and efferent values of its\n      functions have been translated. The translation is found from merging the list of 0 or more\n      dictionary arguments given left-to-right followed by the keyword arguments. If the plan that\n      is given is not a plan object explicitly, calc_tr will attempt to coerce it to one.\n    '''\n    if not is_plan(p):\n        p = plan(p)\n    return p.tr(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the immutable map m with the given arguments translated.", "response": "def imap_tr(imap, *args, **kwargs):\n    '''\n    imap_tr(m, ...) yields a copy of the immutable map m in which the keywords have been translated\n      according to the given arguments. Arguments may be any number of dictionaries followed by any\n      number of keyword arguments, all of which are merged left-to-right then used as the\n      translation.\n    '''\n    if not is_imap(imap):\n        raise TypeError('IMap object required of imap_tr')\n    return imap.tr(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_meta(self, meta_data):\n        '''\n        node.set_meta(meta) yields a calculation node identical to the given node except that its\n        meta_data attribute has been set to the given dictionary meta. If meta is not persistent,\n        it is cast to a persistent dictionary first.\n        '''\n        if not (isinstance(meta_data, ps.PMap) or isinstance(meta_data, IMap)):\n            meta_data = ps.pmap(meta_data)\n        new_cnode = copy.copy(self)\n        object.__setattr__(new_cnode, 'meta_data', meta_data)\n        return new_cnode", "response": "Sets the meta_data attribute of the current node to the given dictionary meta."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_defaults(self, *args, **kwargs):\n        '''\n        node.set_defaults(a=b...) yields a new calculation node identical to the given node except\n        with the default values matching the given key-value pairs. Arguments are collapsed left-to\n        right with later arguments overwriting earlier arguments.\n        '''\n        args = merge(self.defaults, args, kwargs)\n        new_cnode = copy.copy(self)\n        object.__setattr__(new_cnode, 'defaults', ps.pmap(args))\n        return new_cnode", "response": "A method that sets the default values of the given key - value pairs for the given node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discard_defaults(self, *args):\n        '''\n        node.discard_defaults(a, b...) yields a new calculation node identical to the given node\n        except that the default values for the given afferent parameters named by the arguments a,\n        b, etc. have been removed. In the new node that is returned, these parameters will be\n        required.\n        '''\n        rms = set(arg for aa in args for arg in ([aa] if isinstance(aa, six.string_types) else aa))\n        new_defaults = ps.pmap({k:v for (k,v) in six.iteritems(args) if k not in rms})\n        new_cnode = copy.copy(self)\n        object.__setattr__(new_cnode, 'defaults', new_defaults)\n        return new_cnode", "response": "Returns a new node with the given defaults removed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_defaults(self, *args):\n        '''\n        node.remove_defaults(a, b...) is identical to node.discard_defaults(a, b...) except that\n        it raises a KeyError if any of the given arguments are not already defaults.\n        '''\n        rms = set(arg for aa in args for arg in ([aa] if isinstance(aa, six.string_types) else aa))\n        for arg in rms:\n            if arg not in self.defaults:\n                raise KeyError('{0}'.format(arg))\n        return self.discard_defaults(*args)", "response": "This method is identical to node. remove_defaults except that it raises a KeyError if any of the given arguments are not already defaults."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tr(self, *args, **kwargs):\n        '''\n        calc_fn.tr(...) yields a copy of calc_fn in which the afferent and efferent values of the\n        function have been translated. The translation is found from merging the list of 0 or more\n        dictionary arguments given left-to-right followed by the keyword arguments. \n        '''\n        d = merge(args, kwargs)\n        # make a copy\n        translation = copy.copy(self)\n        object.__setattr__(translation, 'afferents',\n                           tuple(d[af] if af in d else af for af in self.afferents))\n        object.__setattr__(translation, 'efferents',\n                           tuple(d[ef] if ef in d else ef for ef in self.efferents))\n        object.__setattr__(translation, 'afferent_docs',\n                           ps.pmap({kk:ps.pmap({(d[k] if k in d else k):v\n                                                for (k,v) in six.iteritems(vv)})\n                                    for (kk,vv) in six.iteritems(self.afferent_docs)}))\n        object.__setattr__(translation, 'efferent_docs',\n                           ps.pmap({kk:ps.pmap({(d[k] if k in d else k):v\n                                                for (k,v) in six.iteritems(vv)})\n                                    for (kk,vv) in six.iteritems(self.efferent_docs)}))\n        fn = self.function\n        def _tr_fn_wrapper(*args, **kwargs):\n            res = fn(*args, **kwargs)\n            if isinstance(res, colls.Mapping):\n                return {(d[k] if k in d else k):v for (k,v) in six.iteritems(res)}\n            else:\n                return res\n        object.__setattr__(translation, 'function', _tr_fn_wrapper)\n        return translation", "response": "This method returns a copy of calc_fn in which the afferent and efferent values of the function have been translated. The function is called by the function\n        method with the given arguments and keyword arguments. The function is called by the function\n        method with the same arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check(self, calc_dict, changes=None):\n        '''\n        cplan._check(calc_dict) should be called only by the calc_dict object itself.\n        The check method makes sure that all of the proactive methods on the calc_dict are run; if\n        the optional keyword argument changes is given, then checks are only run for the list of\n        changes given.\n        '''\n        if changes is None:\n            changes = self.afferents\n            # run the zero-reqs\n            for req in self.initializers:\n                calc_dict._run_node(req)\n        else:\n            # invalidate these data if needed\n            dpts = set(dpt for aff in changes for dpt in self.dependants[aff])\n            for dpt in dpts: del calc_dict[dpt]\n        # now, make sure that proactive dependants get run\n        proactives = set(node for change in changes for node in self.proactive_dependants[change])\n        for node in proactives:\n            calc_dict._run_node(node)", "response": "This method is called by the cplan. _check method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, **kwargs):\n        '''\n        cplan.set(a=b...) yields a new caclulation plan identical to cplan except such that the\n        calculation pieces specified by the arguments have been replaced with the given\n        calculations instead.\n        '''\n        return Plan(reduce(lambda m,u: m.set(u[0],u[1]), six.iteritems(kwargs), self.nodes))", "response": "Returns a new caclulation plan with the given set parameters replaced with the given\n        calculations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new calculation plan with all the elements in the given list discarded.", "response": "def discard(self, *args):\n        '''\n        cplan.discard(...) yields a new calculation plan identical to cplan except without any of\n        the calculation steps listed in the arguments.\n        '''\n        return Plan(reduce(lambda m,k: m.discard(k), args, self.nodes))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new calculation plan with all of the given keys removed.", "response": "def remove(self, *args):\n        '''\n        cplan.remove(...) yields a new calculation plan identical to cplan except without any of\n        the calculation steps listed in the arguments. An exception is raised if any keys are not\n        found in the calc-plan.\n        '''\n        return Plan(reduce(lambda m,k: m.remove(k), args, self.nodes))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_defaults(self, *args, **kwargs):\n        '''\n        cplan.set_defaults(a=b...) yields a new caclulation plan identical to cplan except such\n        that the calculation default values specified by the arguments have been replaced with the\n        given values instead. E.g., cplan.set_defaults(a=1) would return a new plan with a default\n        value for a=1.\n        '''\n        d = merge(args, kwargs)\n        # make a copy of this object's nodes with translations...\n        nodes = ps.pmap({k:v.set_defaults(d) for (k,v) in six.iteritems(self.nodes)})\n        # make a new plan with that!\n        return Plan(nodes)", "response": "Set the default values of the caclulation plan to the given values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discard_defaults(self, *args):\n        '''\n        cplan.discard_defaults(a, b...) yields a new caclulation plan identical to cplan except \n        without default values for any of the given parameter names.\n        '''\n        # make a copy of this object's nodes with translations...\n        nodes = ps.pmap({k:v.discard_defaults(*args) for (k,v) in six.iteritems(self.nodes)})\n        # make a new plan with that!\n        return Plan(nodes)", "response": "Returns a new caclulation plan with no default values for any of the given parameter names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forget(self, node=None, cache_directory=None):\n        '''\n        plan.forget() clears the in-memory memoized cache for the plan and returns the cache dict\n          prior to clearing.\n        '''\n        #plan.forget(node) clears only the cache for the given node (which may be a node name) and\n        #  all nodes that depend on it; plan.forget(None) is equivalent to plan.forget()\n        #plan.forget(node, cache_directory) additionally deletes all directories in the given cache\n        #  directory that correspond to the nodes downstream of node. The node may be None to delete\n        #  all relevant cache directories.\n        m = self._memoized_data\n        self._memoized_data = {}\n        return m", "response": "Forget the cache for a given node and delete all directories that depend on it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _cache(cpath, arg):\n        '''\n        IMap._cache(cpath, arg) is an internally-called method that saves the dict of arguments to\n          cache files in the given cpath directory.\n        '''\n        if not os.path.isdir(cpath): os.makedirs(cpath)\n        for (k,v) in six.iteritems(arg):\n            save(os.path.join(cpath, k + '.pp'), v, create_directories=True, overwrite=True)\n        return True", "response": "IMap. _cache method saves the dict of arguments to\n          cache files in the given cpath directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_node(self, node):\n        '''\n        calc_dict._run_node(node) calculates the results of the given calculation node in the\n        calc_dict's calculation plan and caches the results in the calc_dict. This should only\n        be called by calc_dict itself internally.\n        '''\n        #print IMap.indent, ('Node: %s' % node.name) #dbg\n        #IMap.indent = '  ' + IMap.indent #dbg\n        #\n        # We need to pause here and handle caching, if needed.\n        res = None\n        if ('memoize' in self.afferents and self.afferents['memoize']) and node.memoize:\n            memdat = self.plan._memoized_data\n            try:\n                h = qhash({k:self.afferents[k] for k in self.plan.afferent_dependencies[node.name]})\n                ho = (node.name, h)\n                if ho in memdat:\n                    # memoization success; no need to memoize the result after processing it\n                    res = memdat[ho]\n                    h = None\n                    ho = None\n                    #print(IMap.indent, 'retrieved') #dbg\n                else:\n                    cpath = self.afferents['cache_directory'] \\\n                            if node.cache and 'cache_directory' in self.afferents else \\\n                            None\n                    if cpath is not None:\n                        ureg = self.afferents['unit_registry'] \\\n                               if 'unit_registry' in self.afferents else \\\n                               'pimms'\n                        cpath = os.path.join(cpath, node.name, ('0' + str(-h)) if h < 0 else str(h))\n                        try:\n                            res = self._uncache(cpath, node, ureg)\n                            cpath = None\n                            #print(IMap.indent, 'loaded cache') #dbg\n                        except: pass\n            except:\n                # memoization failure, must run the node normally (don't memoize/cache)\n                h = None\n                ho = None\n                res = None\n        else:\n            h = None\n            ho = None\n        # ensure we have a result\n        if res is None: res = node(self)\n        # process the result:\n        effs = reduce(lambda m,v: m.set(v[0],v[1]), six.iteritems(res), self.efferents)\n        object.__setattr__(self, 'efferents', effs)\n        # Handle the caching if needed:\n        if h is not None:\n            memdat[ho] = res\n            #if cpath is None: print IMap.indent, 'hashed' #dbg\n            if cpath is not None:\n                try:\n                    self._cache(cpath, res)\n                    #print IMap.indent, 'saved cache' #dbg\n                except: pass", "response": "This method is called by calc_dict. _run_node to calculate the results of the given calculation node in the calc_dict and caches the results in the calc_dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the values of the keys in the current object to the values of the given keys.", "response": "def set(self, *args, **kwargs):\n        '''\n        d.set(...) yields a copy of the IMap object d; the ... may be replaced with either\n        nothing (in which case d is returned) or a list of 0 or more dictionaries followed by a lsit\n        of zero or more keyword arguments. These dictionaries and keywords arguments are merged\n        left-to-right; the result may contain only afferent parameters of d and replaces the values\n        of d in the newly returned calc dictionary.\n        '''\n        args = merge(args, kwargs)\n        if len(args) == 0: return self\n        affs = self.afferents\n        pln = self.plan\n        # make sure these are all valid parameters\n        if any(k not in affs for k in six.iterkeys(args)):\n            raise TypeError(\n                'The given key \\'%s\\' is not an afferent parameter of IMap object')\n        # okay, we can make the change...\n        new_calc_dict = copy.copy(self)\n        new_affs = reduce(lambda m,v: m.set(v[0],v[1]), six.iteritems(args), affs)\n        object.__setattr__(new_calc_dict, 'afferents', new_affs)\n        # we need to run checks and delete any cache that has been invalidated.\n        # The calculation's check method does this; it raises an exception if there is an error\n        pln._check(new_calc_dict, changes=args)\n        return new_calc_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a copy of the immutable map plan with the keys of translated according to the given arguments.", "response": "def tr(self, *args, **kwargs):\n        '''\n        imap.tr(...) yields a copy of the immutable map imap in which both the plan and the keys of\n        the new map have been translated according to the translation given in the arguments list.\n        The translation is found from merging the list of 0 or more dictionary arguments given\n        left-to-right followed by the keyword arguments.\n        '''\n        d = merge_args(args, kwargs)\n        # make a copy of the plan first:\n        new_plan = self.plan.tr(d)\n        # now use that plan to re-initialize ourself\n        return new_plan(**{(d[k] if k in d else k):v for (k,v) in six.iteritems(self.afferents)})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the M2M Tag s for an Entry right after it has been saved.", "response": "def generate_entry_tags(sender, instance, created, raw, using, **kwargs):\n    \"\"\"Generate the M2M ``Tag``s for an ``Entry`` right after it has\n    been saved.\"\"\"\n    Tag.objects.create_tags(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates stats for the given QuerySet of Entry s.", "response": "def entry_stats(entries, top_n=10):\n    \"\"\"Calculates stats for the given ``QuerySet`` of ``Entry``s.\"\"\"\n\n    wc = Counter()  # A Word counter\n    for content in entries.values_list(\"rendered_content\", flat=True):\n        # Do a little cleanup\n        content = strip_tags(content)  # remove all html tags\n        content = re.sub('\\s+', ' ', content)  # condense all whitespace\n        content = re.sub('[^A-Za-z ]+', '', content)  # remove non-alpha chars\n\n        words = [w.lower() for w in content.split()]\n        wc.update([w for w in words if w not in IGNORE_WORDS])\n\n    return {\n        \"total_words\": len(wc.values()),\n        \"most_common\": wc.most_common(top_n),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_tags(self, entry):\n        tag_list = [t.lower().strip() for t in entry.tag_string.split(',')]\n        for t in tag_list:\n            tag, created = self.get_or_create(name=t)\n            entry.tags.add(tag)", "response": "Inspects an Entry instance and builds associates Tag objects based on the values in the entry s tag_string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_date_slug(self):\n        if not self.pk:\n            # haven't saved this yet, so use today's date\n            d = utc_now()\n        elif self.published and self.published_on:\n            # use the actual published on date\n            d = self.published_on\n        elif self.updated_on:\n            # default to the last-updated date\n            d = self.updated_on\n        self.date_slug = u\"{0}/{1}\".format(d.strftime(\"%Y/%m/%d\"), self.slug)", "response": "Create the date_slug attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the content according to the content_format.", "response": "def _render_content(self):\n        \"\"\"Renders the content according to the ``content_format``.\"\"\"\n        if self.content_format == \"rst\" and docutils_publish is not None:\n            doc_parts = docutils_publish(\n                source=self.raw_content,\n                writer_name=\"html4css1\"\n            )\n            self.rendered_content = doc_parts['fragment']\n        elif self.content_format == \"rs\" and docutils_publish is None:\n            raise RuntimeError(\"Install docutils to pubilsh reStructuredText\")\n        elif self.content_format == \"md\" and markdown is not None:\n            self.rendered_content = markdown(self.raw_content)\n        elif self.content_format == \"md\" and markdown is None:\n            raise RuntimeError(\"Install Markdown to pubilsh markdown\")\n        else:  # Assume we've got html\n            self.rendered_content = self.raw_content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the absolute URL based on the entry s date & slug.", "response": "def get_absolute_url_with_date(self):\n        \"\"\"URL based on the entry's date & slug.\"\"\"\n        pub_date = self.published_on\n\n        if pub_date and settings.USE_TZ:\n            # If TZ is enabled, convert all of these dates from UTC to whatever\n            # the project's timezone is set as. Ideally, we'd pull this form\n            # some user settings, but the *canonical* publish time is that of\n            # the author (asssuming author == owner of this project).\n            pub_date = make_naive(pub_date, pytz.utc)  # Make naive\n            pub_date = pytz.timezone(settings.TIME_ZONE).localize(pub_date)\n        if pub_date:\n            args = [\n                pub_date.strftime(\"%Y\"),\n                pub_date.strftime(\"%m\"),\n                pub_date.strftime(\"%d\"),\n                self.slug\n            ]\n        else:\n            args = [self.slug]\n        return reverse('blargg:entry_detail', args=args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tag_list(self):\n        tags = [tag.strip() for tag in self.tag_string.split(\",\")]\n        return sorted(filter(None, tags))", "response": "Return a plain python list containing all of this Entry s tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncontenting to be cross - posted on other sites.", "response": "def crossposted_content(self):\n        \"\"\"Content to be cross-posted on other sites. This method adds an\n        additional line of content with a link back to the original site as\n        well as the `#end` tag. This signals the end blog content according\n        to: https://support.google.com/blogger/answer/41452?hl=en\n\n        \"\"\"\n        url = \"http://{0}{1}\".format(self.site.domain, self.get_absolute_url())\n        origin = (\n            '<p><em>This entry was originally published at: '\n            '<a href=\"{0}\">{1}</a>.</em></p>#end'.format(url, url)\n        )\n        return mark_safe(u\"{0}{1}\".format(self.content, origin))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef personal_unlockAccount(self, address, passphrase=None, duration=None):\n        return (yield from self.rpc_call('personal_unlockAccount',\n                                         [address, passphrase, duration]))", "response": "Unlocks the personal account with the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsigns a message for the specified account.", "response": "def personal_sign(self, message, account, password=None):\n        \"\"\"https://github.com/ethereum/go-ethereum/wiki/Management-APIs#personal_sign\n\n        :param message: Message for sign\n        :type message: str\n\n        :param account: Account address\n        :type account: str\n\n        :param password: Password of account (optional)\n        :type password: str\n\n        :return: signature\n        :rtype: str\n        \"\"\"\n        return (yield from self.rpc_call('personal_sign',\n                                         [message, account, password]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef heartbeat(self):\n        url = urljoin(self.base_url, 'heartbeat')\n        return self.session.get(url).json()['ok']", "response": "Check The API Is Up.\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck A Venue Is Up.", "response": "def venue_healthcheck(self):\n        \"\"\"Check A Venue Is Up.\n\n        https://starfighter.readme.io/docs/venue-healthcheck\n        \"\"\"\n        url = urljoin(self.base_url, 'venues/TESTEX/heartbeat')\n        return self.session.get(url).json()['ok']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist the stocks available for trading on the venue.", "response": "def venue_stocks(self):\n        \"\"\"List the stocks available for trading on the venue.\n\n        https://starfighter.readme.io/docs/list-stocks-on-venue\n        \"\"\"\n        url = urljoin(self.base_url, 'venues/{0}/stocks'.format(self.venue))\n        return self.session.get(url).json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the orderbook for a particular stock.", "response": "def orderbook_for_stock(self, stock):\n        \"\"\"Get the orderbook for a particular stock.\n\n        https://starfighter.readme.io/docs/get-orderbook-for-stock\n        \"\"\"\n        url_fragment = 'venues/{venue}/stocks/{stock}'.format(\n            venue=self.venue,\n            stock=stock,\n        )\n        url = urljoin(self.base_url, url_fragment)\n        return self.session.get(url).json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef place_new_order(self, stock, price, qty, direction, order_type):\n        url_fragment = 'venues/{venue}/stocks/{stock}/orders'.format(\n            venue=self.venue,\n            stock=stock,\n        )\n        data = {\n          \"stock\": stock,\n          \"price\": price,\n          \"venue\": self.venue,\n          \"account\": self.account,\n          \"qty\": qty,\n          \"direction\": direction,\n          \"orderType\": order_type,\n        }\n        url = urljoin(self.base_url, url_fragment)\n        resp = self.session.post(url, json=data)\n        return resp.json()", "response": "Place a new order for a stock."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cancel_order(self, order_id, stock):\n        url_fragment = 'venues/{venue}/stocks/{stock}/orders/{order_id}'.format(\n            venue=self.venue,\n            stock=stock,\n            order_id=order_id,\n        )\n        url = urljoin(self.base_url, url_fragment)\n        return self.session.delete(url).json()", "response": "Cancel an order in a given stock"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scan_django_settings(values, imports):\n    '''Recursively scans Django settings for values that appear to be\n    imported modules.\n    '''\n    if isinstance(values, (str, bytes)):\n        if utils.is_import_str(values):\n            imports.add(values)\n    elif isinstance(values, dict):\n        for k, v in values.items():\n            scan_django_settings(k, imports)\n            scan_django_settings(v, imports)\n    elif hasattr(values, '__file__') and getattr(values, '__file__'):\n        imp, _ = utils.import_path_from_file(getattr(values, '__file__'))\n        imports.add(imp)\n    elif hasattr(values, '__iter__'):\n        for item in values:\n            scan_django_settings(item, imports)", "response": "Recursively scans Django settings for values that appear to be\n    imported modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_django_settings(filename):\n    '''Attempts to load a Django project and get package dependencies from\n    settings.\n\n    Tested using Django 1.4 and 1.8. Not sure if some nuances are missed in\n    the other versions.\n    '''\n    old_sys_path = sys.path[:]\n    dirpath = os.path.dirname(filename)\n    project = os.path.basename(dirpath)\n    cwd = os.getcwd()\n    project_path = os.path.normpath(os.path.join(dirpath, '..'))\n    if project_path not in sys.path:\n        sys.path.insert(0, project_path)\n    os.chdir(project_path)\n\n    project_settings = '{}.settings'.format(project)\n    os.environ['DJANGO_SETTINGS_MODULE'] = project_settings\n\n    try:\n        import django\n        # Sanity\n        django.setup = lambda: False\n    except ImportError:\n        log.error('Found Django settings, but Django is not installed.')\n        return\n\n    log.warn('Loading Django Settings (Using {}): {}'\n                    .format(django.get_version(), filename))\n\n    from django.conf import LazySettings\n\n    installed_apps = set()\n    settings_imports = set()\n\n    try:\n        settings = LazySettings()\n        settings._setup()\n        for k, v in vars(settings._wrapped).items():\n            if k not in _excluded_settings and re.match(r'^[A-Z_]+$', k):\n                # log.debug('Scanning Django setting: %s', k)\n                scan_django_settings(v, settings_imports)\n\n        # Manually scan INSTALLED_APPS since the broad scan won't include\n        # strings without a period in it .\n        for app in getattr(settings, 'INSTALLED_APPS', []):\n            if hasattr(app, '__file__') and getattr(app, '__file__'):\n                imp, _ = utils.import_path_from_file(getattr(app, '__file__'))\n                installed_apps.add(imp)\n            else:\n                installed_apps.add(app)\n    except Exception as e:\n        log.error('Could not load Django settings: %s', e)\n        log.debug('', exc_info=True)\n        return\n\n    if not installed_apps or not settings_imports:\n        log.error('Got empty settings values from Django settings.')\n\n    try:\n        from django.apps.registry import apps, Apps, AppRegistryNotReady\n        # Django doesn't like it when the initial instance of `apps` is reused,\n        # but it has to be populated before other instances can be created.\n        if not apps.apps_ready:\n            apps.populate(installed_apps)\n        else:\n            apps = Apps(installed_apps)\n\n        start = time.time()\n        while True:\n            try:\n                for app in apps.get_app_configs():\n                    installed_apps.add(app.name)\n            except AppRegistryNotReady:\n                if time.time() - start > 10:\n                    raise Exception('Bail out of waiting for Django')\n                log.debug('Waiting for apps to load...')\n                continue\n            break\n    except Exception as e:\n        log.debug('Could not use AppConfig: {}'.format(e))\n\n    # Restore before sub scans can occur\n    sys.path[:] = old_sys_path\n    os.chdir(cwd)\n\n    for item in settings_imports:\n        need_scan = item.startswith(_filescan_modules)\n        yield ('django', item, project_path if need_scan else None)\n\n    for app in installed_apps:\n        need_scan = app.startswith(project)\n        yield ('django', app, project_path if need_scan else None)", "response": "Attempts to load a Django project and get package dependencies from django. conf."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _url(endpoint: str, sandbox: bool=False) -> str:\n    if sandbox is True:\n        url = BASE_URL_SANDBOX\n    else:\n        url = BASE_URL\n    return \"{0}{1}\".format(url, endpoint)", "response": "Build a URL from the API s base URLs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a single savings goals data.", "response": "def update(self, goal: Dict=None) -> None:\n        \"\"\"Update a single savings goals data.\"\"\"\n        if goal is None:\n            endpoint = \"/account/{0}/savings-goals/{1}\".format(\n                self._account_uid,\n                self.uid\n            )\n\n            response = get(\n                _url(endpoint, self._sandbox),\n                headers=self._auth_headers\n            )\n            response.raise_for_status()\n            goal = response.json()\n\n        self.uid = goal.get('savingsGoalUid')\n        self.name = goal.get('name')\n\n        target = goal.get('target', {})\n        self.target_currency = target.get('currency')\n        self.target_minor_units = target.get('minorUnits')\n\n        total_saved = goal.get('totalSaved', {})\n        self.total_saved_currency = total_saved.get('currency')\n        self.total_saved_minor_units = total_saved.get('minorUnits')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deposit(self, deposit_minor_units: int) -> None:\n        endpoint = \"/account/{0}/savings-goals/{1}/add-money/{2}\".format(\n            self._account_uid,\n            self.uid,\n            uuid4()\n        )\n\n        body = {\n            \"amount\": {\n                \"currency\": self.total_saved_currency,\n                \"minorUnits\": deposit_minor_units\n            }\n        }\n\n        response = put(\n            _url(endpoint, self._sandbox),\n            headers=self._auth_headers,\n            data=json_dumps(body)\n        )\n        response.raise_for_status()\n\n        self.update()", "response": "Add funds to a savings goal."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_image(self, filename: str=None) -> None:\n        if filename is None:\n            filename = \"{0}.png\".format(self.name)\n\n        endpoint = \"/account/{0}/savings-goals/{1}/photo\".format(\n            self._account_uid,\n            self.uid\n        )\n\n        response = get(\n            _url(endpoint, self._sandbox),\n            headers=self._auth_headers\n        )\n        response.raise_for_status()\n\n        base64_image = response.json()['base64EncodedPhoto']\n        with open(filename, 'wb') as file:\n            file.write(b64decode(base64_image))", "response": "Download the photo associated with a Savings Goal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the account data with the account information.", "response": "def update_account_data(self) -> None:\n        \"\"\"Get basic information for the account.\"\"\"\n        response = get(\n            _url(\n                \"/accounts/{0}/identifiers\".format(self._account_uid),\n                self._sandbox\n            ),\n            headers=self._auth_headers\n        )\n        response.raise_for_status()\n\n        response = response.json()\n\n        self.account_identifier = response.get('accountIdentifier')\n        self.bank_identifier = response.get('bankIdentifier')\n        self.iban = response.get('iban')\n        self.bic = response.get('bic')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the internal state of the object with the latest balance information.", "response": "def update_balance_data(self) -> None:\n        \"\"\"Get the latest balance information for the account.\"\"\"\n        response = get(\n            _url(\n                \"/accounts/{0}/balance\".format(self._account_uid),\n                self._sandbox\n            ),\n            headers=self._auth_headers\n        )\n        response.raise_for_status()\n\n        response = response.json()\n        self.cleared_balance = response['clearedBalance']['minorUnits']\n        self.effective_balance = response['effectiveBalance']['minorUnits']\n        self.pending_transactions \\\n            = response['pendingTransactions']['minorUnits']\n        self.available_to_spend = response['availableToSpend']['minorUnits']\n        self.accepted_overdraft = response['acceptedOverdraft']['minorUnits']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_savings_goal_data(self) -> None:\n        response = get(\n            _url(\n                \"/account/{0}/savings-goals\".format(self._account_uid),\n                self._sandbox\n            ),\n            headers=self._auth_headers\n        )\n        response.raise_for_status()\n\n        response = response.json()\n        response_savings_goals = response.get('savingsGoalList', {})\n\n        returned_uids = []\n\n        # New / Update\n        for goal in response_savings_goals:\n            uid = goal.get('savingsGoalUid')\n            returned_uids.append(uid)\n\n            # Intiialise new _SavingsGoal object if new\n            if uid not in self.savings_goals:\n                self.savings_goals[uid] = SavingsGoal(\n                    self._auth_headers,\n                    self._sandbox,\n                    self._account_uid\n                )\n\n            self.savings_goals[uid].update(goal)\n\n        # Forget about savings goals if the UID isn't returned by Starling\n        for uid in list(self.savings_goals):\n            if uid not in returned_uids:\n                self.savings_goals.pop(uid)", "response": "Update the savings goal data for the account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the inlines of the content of the current page.", "response": "def process_inlines(parser, token):\n    \"\"\"\n    Searches through the provided content and applies inlines where ever they\n    are found.\n\n    Syntax::\n\n        {% process_inlines entry.body [in template_dir] [as varname] }\n\n    Examples::\n\n        {% process_inlines entry.body %}\n\n        {% process_inlines entry.body as body %}\n\n        {% process_inlines entry.body in 'inlines/sidebar' %}\n\n        {% process_inlines entry.body in 'inlines/sidebar' as body %}\n\n    \"\"\"\n\n    args = token.split_contents()\n\n    if not len(args) in (2, 4, 6):\n        raise template.TemplateSyntaxError(\"%r tag requires either 1, 3 or 5 arguments.\" % args[0])\n\n    var_name = args[1]\n\n    ALLOWED_ARGS = ['as', 'in']\n    kwargs = { 'template_directory': None }\n    if len(args) > 2:\n        tuples = zip(*[args[2:][i::2] for i in range(2)])\n        for k,v in tuples:\n            if not k in ALLOWED_ARGS:\n                raise template.TemplateSyntaxError(\"%r tag options arguments must be one of %s.\" % (args[0], ', '.join(ALLOWED_ARGS)))\n            if k == 'in':\n                kwargs['template_directory'] = v\n            if k == 'as':\n                kwargs['asvar'] = v\n\n    return InlinesNode(var_name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart an admin_startRPC RPC.", "response": "def admin_startRPC(self, host='localhost', port=8545, cors=None, apis=None):\n        \"\"\"https://github.com/ethereum/go-ethereum/wiki/Management-APIs#admin_startrpc\n\n        :param host: Network interface to open the listener socket (optional)\n        :type host: str\n\n        :param port: Network port to open the listener socket (optional)\n        :type port: int\n\n        :param cors: Cross-origin resource sharing header to use (optional)\n        :type cors: str\n\n        :param apis: API modules to offer over this interface (optional)\n        :type apis: str\n\n        :rtype: bool\n        \"\"\"\n        if cors is None:\n            cors = []\n        if apis is None:\n            apis = ['eth', 'net', 'web3']\n\n        return (yield from self.rpc_call('admin_startRPC',\n                                         [host, port,\n                                          ','.join(cors), ','.join(apis)]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef admin_startWS(self, host='localhost', port=8546, cors=None, apis=None):\n        if cors is None:\n            cors = []\n        if apis is None:\n            apis = ['eth', 'net', 'web3']\n\n        return (yield from self.rpc_call('admin_startWS',\n                                         [host, port,\n                                          ','.join(cors), ','.join(apis)]))", "response": "Open the listener socket and start the admin session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the current state of SQL items from the current project state.", "response": "def build_current_graph():\n    \"\"\"\n    Read current state of SQL items from the current project state.\n\n    Returns:\n        (SQLStateGraph) Current project state graph.\n    \"\"\"\n    graph = SQLStateGraph()\n    for app_name, config in apps.app_configs.items():\n        try:\n            module = import_module(\n                '.'.join((config.module.__name__, SQL_CONFIG_MODULE)))\n            sql_items = module.sql_items\n        except (ImportError, AttributeError):\n            continue\n        for sql_item in sql_items:\n            graph.add_node((app_name, sql_item.name), sql_item)\n\n            for dep in sql_item.dependencies:\n                graph.add_lazy_dependency((app_name, sql_item.name), dep)\n\n    graph.build_graph()\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread lazy dependency list and build graph.", "response": "def build_graph(self):\n        \"\"\"\n        Read lazy dependency list and build graph.\n        \"\"\"\n        for child, parents in self.dependencies.items():\n            if child not in self.nodes:\n                raise NodeNotFoundError(\n                    \"App %s SQL item dependencies reference nonexistent child node %r\" % (\n                        child[0], child),\n                    child\n                )\n            for parent in parents:\n                if parent not in self.nodes:\n                    raise NodeNotFoundError(\n                        \"App %s SQL item dependencies reference nonexistent parent node %r\" % (\n                            child[0], parent),\n                        parent\n                    )\n                self.node_map[child].add_parent(self.node_map[parent])\n                self.node_map[parent].add_child(self.node_map[child])\n\n        for node in self.nodes:\n            self.ensure_not_cyclic(node,\n                                   lambda x: (parent.key for parent in self.node_map[x].parents))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the sampler to its initial state.", "response": "def reset(self):\n        \"\"\"Resets the sampler to its initial state\n\n        Note\n        ----\n        This will destroy the label cache and history of estimates.\n        \"\"\"\n        self._TP = np.zeros(self._n_class)\n        self._FP = np.zeros(self._n_class)\n        self._FN = np.zeros(self._n_class)\n        self._TN = np.zeros(self._n_class)\n        self.t_ = 0\n        self._queried_oracle = np.repeat(False, self._max_iter)\n        self.cached_labels_ = np.repeat(np.nan, self._n_items)\n        self._estimate = np.tile(np.nan, [self._max_iter, self._n_class])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _iterate(self, **kwargs):\n        # Sample item\n        loc, weight, extra_info = self._sample_item(**kwargs)\n        # Query label\n        ell = self._query_label(loc)\n        # Get predictions\n        ell_hat = self.predictions[loc,:]\n\n        if self.debug == True:\n            print(\"Sampled label {} for item {}.\".format(ell,loc))\n\n        # Update\n        self._update_estimate_and_sampler(ell, ell_hat, weight, extra_info, **kwargs)\n\n        self.t_ = self.t_ + 1", "response": "Procedure for a single iteration ( sampling and updating"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsample a sequence of items from the pool.", "response": "def sample(self, n_to_sample, **kwargs):\n        \"\"\"Sample a sequence of items from the pool\n\n        Parameters\n        ----------\n        n_to_sample : int\n            number of items to sample\n        \"\"\"\n        n_to_sample = verify_positive(int(n_to_sample))\n\n        n_remaining = self._max_iter - self.t_\n\n        if n_remaining == 0:\n            if (not self.replace) and (self._n_items == self._max_iter):\n                raise Exception(\"All items have already been sampled\")\n            else:\n                raise Exception(\"No more space available to continue sampling. \"\n                                \"Consider re-initialising with a larger value \"\n                                \"of max_iter.\")\n\n        if n_to_sample > n_remaining:\n            warnings.warn(\"Space only remains for {} more iteration(s). \"\n                          \"Setting n_to_sample = {}.\".format(n_remaining, \\\n                          n_remaining))\n            n_to_sample = n_remaining\n\n        for _ in range(n_to_sample):\n            self._iterate(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsample a sequence of items from the pool until a minimum number of distinct items are queried.", "response": "def sample_distinct(self, n_to_sample, **kwargs):\n        \"\"\"Sample a sequence of items from the pool until a minimum number of\n        distinct items are queried\n\n        Parameters\n        ----------\n        n_to_sample : int\n            number of distinct items to sample. If sampling with replacement,\n            this number is not necessarily the same as the number of\n            iterations.\n        \"\"\"\n        # Record how many distinct items have not yet been sampled\n        n_notsampled = np.sum(np.isnan(self.cached_labels_))\n\n        if n_notsampled == 0:\n            raise Exception(\"All distinct items have already been sampled.\")\n\n        if n_to_sample > n_notsampled:\n            warnings.warn(\"Only {} distinct item(s) have not yet been sampled.\"\n                          \" Setting n_to_sample = {}.\".format(n_notsampled, \\\n                          n_notsampled))\n            n_to_sample = n_notsampled\n\n        n_sampled = 0 # number of distinct items sampled this round\n        while n_sampled < n_to_sample:\n            self.sample(1,**kwargs)\n            n_sampled += self._queried_oracle[self.t_ - 1]*1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sample_item(self, **kwargs):\n        if self.replace:\n            # Can sample from any of the items\n            loc = np.random.choice(self._n_items)\n        else:\n            # Can only sample from items that have not been seen\n            # Find ids that haven't been seen yet\n            not_seen_ids = np.where(np.isnan(self.cached_labels_))[0]\n            loc = np.random.choice(not_seen_ids)\n        return loc, 1, {}", "response": "Sample an item from the pool"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the label for the item with index loc.", "response": "def _query_label(self, loc):\n        \"\"\"Query the label for the item with index `loc`. Preferentially\n        queries the label from the cache, but if not yet cached, queries the\n        oracle.\n\n        Returns\n        -------\n        int\n            the true label \"0\" or \"1\".\n        \"\"\"\n        # Try to get label from cache\n        ell = self.cached_labels_[loc]\n\n        if np.isnan(ell):\n            # Label has not been cached. Need to query oracle\n            oracle_arg = self.identifiers[loc]\n            ell = self.oracle(oracle_arg)\n            if ell not in [0, 1]:\n                raise Exception(\"Oracle provided an invalid label.\")\n            #TODO Gracefully handle errors from oracle?\n            self._queried_oracle[self.t_] = True\n            self.cached_labels_[loc] = ell\n\n        return ell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the weighted F - measure of a set of TPs FP FN.", "response": "def _F_measure(self, alpha, TP, FP, FN, return_num_den=False):\n        \"\"\"Calculate the weighted F-measure\"\"\"\n        num = np.float64(TP)\n        den = np.float64(alpha * (TP + FP) + (1 - alpha) * (TP + FN))\n        with np.errstate(divide='ignore', invalid='ignore'):\n            F_measure = num/den\n        #F_measure = num/den\n\n        if return_num_den:\n            return F_measure, num, den\n        else:\n            return F_measure"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the estimate after querying the label for an item", "response": "def _update_estimate_and_sampler(self, ell, ell_hat, weight, extra_info,\n                                     **kwargs):\n        \"\"\"Update the estimate after querying the label for an item\"\"\"\n        self._TP += ell_hat * ell * weight\n        self._FP += ell_hat * (1 - ell) * weight\n        self._FN += (1 - ell_hat) * ell * weight\n        self._TN += (1 - ell_hat) * (1 - ell) * weight\n\n        self._estimate[self.t_] = \\\n                self._F_measure(self.alpha, self._TP, self._FP, self._FN)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_occurrence(self, key, update=True):\n        if update:\n            self.update()\n        result = {}\n        for k, v in self.database.items():\n            if key in v:\n                result[str(v[key])] = k\n        return result", "response": "Return a dict containing the value of the provided key and its uuid as\n        value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zmq_address(self, key):\n        zmq_address = \"tcp://\" + self.database[key]['node'] + \":\" + str(self.database[key]['ports']['REQ'])\n        return zmq_address", "response": "Return a ZeroMQ address to the module with the provided key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_json(location):\n    location = os.path.expanduser(location)\n    try:\n        if os.path.isfile(location):\n            with io.open(location, encoding=\"utf-8\") as json_data:\n                return json.load(json_data, object_pairs_hook=OrderedDict).get(\"tests\")\n        elif \"http\" in location:\n            json_data = requests.get(location)\n            if not json_data:\n                raise Dump2PolarionException(\"Failed to download\")\n            return json.loads(json_data.text, object_pairs_hook=OrderedDict).get(\"tests\")\n        else:\n            raise Dump2PolarionException(\"Invalid location\")\n    except Exception as err:\n        raise Dump2PolarionException(\"Failed to parse JSON from {}: {}\".format(location, err))", "response": "Reads JSON data from file or URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate how long it took to execute the testcase.", "response": "def _calculate_duration(start_time, finish_time):\n    \"\"\"Calculates how long it took to execute the testcase.\"\"\"\n    if not (start_time and finish_time):\n        return 0\n    start = datetime.datetime.fromtimestamp(start_time)\n    finish = datetime.datetime.fromtimestamp(finish_time)\n    duration = finish - start\n\n    decimals = float((\"0.\" + str(duration.microseconds)))\n    return duration.seconds + decimals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _filter_parameters(parameters):\n    if not parameters:\n        return None\n    return OrderedDict(\n        (param, value) for param, value in six.iteritems(parameters) if param not in IGNORED_PARAMS\n    )", "response": "Filters the ignored parameters out."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds data of single testcase results to results database.", "response": "def _append_record(test_data, results, test_path):\n    \"\"\"Adds data of single testcase results to results database.\"\"\"\n    statuses = test_data.get(\"statuses\")\n    jenkins_data = test_data.get(\"jenkins\") or {}\n\n    data = [\n        (\"title\", test_data.get(\"test_name\") or _get_testname(test_path)),\n        (\"verdict\", statuses.get(\"overall\")),\n        (\"source\", test_data.get(\"source\")),\n        (\"job_name\", jenkins_data.get(\"job_name\")),\n        (\"run\", jenkins_data.get(\"build_number\")),\n        (\"params\", _filter_parameters(test_data.get(\"params\"))),\n        (\n            \"time\",\n            _calculate_duration(test_data.get(\"start_time\"), test_data.get(\"finish_time\")) or 0,\n        ),\n    ]\n    test_id = test_data.get(\"polarion\")\n    if test_id:\n        if isinstance(test_id, list):\n            test_id = test_id[0]\n        data.append((\"test_id\", test_id))\n\n    results.append(OrderedDict(data))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the content of the input JSON and returns testcases results.", "response": "def _parse_ostriz(ostriz_data):\n    \"\"\"Reads the content of the input JSON and returns testcases results.\"\"\"\n    if not ostriz_data:\n        raise NothingToDoException(\"No data to import\")\n\n    results = []\n    found_build = None\n    last_finish_time = [0]\n    for test_path, test_data in six.iteritems(ostriz_data):\n        curr_build = test_data.get(\"build\")\n        if not curr_build:\n            continue\n\n        # set `found_build` from first record where it's present\n        if not found_build:\n            found_build = curr_build\n\n        # make sure we are collecting data for the same build\n        if found_build != curr_build:\n            continue\n\n        if not test_data.get(\"statuses\"):\n            continue\n\n        _append_record(test_data, results, test_path)\n        _comp_finish_time(test_data, last_finish_time)\n\n    if last_finish_time[0]:\n        logger.info(\"Last result finished at %s\", last_finish_time[0])\n\n    testrun_id = _get_testrun_id(found_build)\n    return xunit_exporter.ImportedData(results=results, testrun=testrun_id)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_array(\n        socket, A=None, metadata=None, flags=0,\n        copy=False, track=False, compress=None,\n        chunksize=50 * 1000 * 1000\n):\n    \"\"\"send a numpy array with metadata over zmq\n\n    message is mostly multipart:\n    metadata | array part 1 | array part 2, etc\n\n    only metadata:\n    metadata\n\n    the chunksize roughly determines the size of the parts being sent\n    if the chunksize is too big, you get an error like:\n        zmq.error.Again: Resource temporarily unavailable\n    \"\"\"\n\n    # create a metadata dictionary for the message\n    md = {}\n    # always add a timestamp\n    md['timestamp'] = datetime.datetime.now().isoformat()\n\n    # copy extra metadata\n    if metadata:\n        md.update(metadata)\n\n    # if we don't have an array\n    if A is None:\n        # send only json\n        md['parts'] = 0\n        socket.send_json(md, flags)\n        # and we're done\n        return\n\n    # support single values (empty shape)\n    if isinstance(A, float) or isinstance(A, int):\n        A = np.asarray(A)\n\n    # add array metadata\n    md['dtype'] = str(A.dtype)\n    md['shape'] = A.shape\n    # determine number of parts\n    md['parts'] = int(np.prod(A.shape) // chunksize + 1)\n    try:\n        # If an array has a fill value assume it's an array with missings\n        # store the fill_Value in the metadata and fill the array before sending.\n        # asscalar should work for scalar, 0d array or nd array of size 1\n        md['fill_value'] = np.asscalar(A.fill_value)\n        A = A.filled()\n    except AttributeError:\n        # no masked array, nothing to do\n        pass\n\n    # send json, followed by array (in x parts)\n    socket.send_json(md, flags | zmq.SNDMORE)\n\n    # although the check is not strictly necessary, we try to maintain fast\n    # pointer transfer when there is only 1 part\n    if md['parts'] == 1:\n        msg = memoryview(np.ascontiguousarray(A))\n        socket.send(msg, flags, copy=copy, track=track)\n    else:\n        # split array at first dimension and send parts\n        for i, a in enumerate(np.array_split(A, md['parts'])):\n            # Make a copy if required and pass along the memoryview\n            msg = memoryview(np.ascontiguousarray(a))\n            flags_ = flags\n            if i != md['parts'] - 1:\n                flags_ |= zmq.SNDMORE\n            socket.send(msg, flags_, copy=copy, track=track)\n    return", "response": "send a numpy array over zmq socket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recv_array(\n        socket,\n        flags=0,\n        copy=False,\n        track=False,\n        poll=None,\n        poll_timeout=10000\n):\n    \"\"\"recv a metadata and an optional numpy array from a zmq socket\n\n    Optionally provide poll object to use recv_array with timeout\n\n    poll_timeout is in millis\n    \"\"\"\n    if poll is None:\n        md = socket.recv_json(flags=flags)\n    else:\n        # one-try \"Lazy Pirate\" method: http://zguide.zeromq.org/php:chapter4\n        socks = dict(poll.poll(poll_timeout))\n        if socks.get(socket) == zmq.POLLIN:\n            reply = socket.recv_json(flags=flags)\n            # note that reply can be an empty array\n            md = reply\n        else:\n            raise NoResponseException(\n                \"Recv_array got no response within timeout (1)\")\n\n    if md['parts'] == 0:\n        # No array expected\n        A = None\n    elif md['parts'] == 1:\n        # although the check is not strictly necessary, we try to maintain fast\n        # pointer transfer when there is only 1 part\n\n        if poll is None:\n            msg = socket.recv(flags=flags, copy=copy, track=track)\n        else:\n            # one-try \"Lazy Pirate\" method: http://zguide.zeromq.org/php:chapter4\n            socks = dict(poll.poll(poll_timeout))\n            if socks.get(socket) == zmq.POLLIN:\n                reply = socket.recv(flags=flags, copy=copy, track=track)\n                # note that reply can be an empty array\n                msg = reply\n            else:\n                raise NoResponseException(\n                    \"Recv_array got no response within timeout (2)\")\n        buf = buffer(msg)\n        A = np.frombuffer(buf, dtype=md['dtype'])\n        A = A.reshape(md['shape'])\n\n        if 'fill_value' in md:\n            A = np.ma.masked_equal(A, md['fill_value'])\n\n    else:\n        # multi part array\n        A = np.zeros(np.prod(md['shape']), dtype=md['dtype'])\n        arr_position = 0\n        for i in range(md['parts']):\n            if poll is None:\n                msg = socket.recv(flags=flags, copy=copy, track=track)\n            else:\n                # one-try \"Lazy Pirate\" method: http://zguide.zeromq.org/php:chapter4\n                socks = dict(poll.poll(poll_timeout))\n                if socks.get(socket) == zmq.POLLIN:\n                    reply = socket.recv(flags=flags, copy=copy, track=track)\n                    if not reply:\n                        raise EmptyResponseException(\n                            \"Recv_array got an empty response (2)\")\n                    msg = reply\n                else:\n                    raise NoResponseException(\n                        \"Recv_array got no response within timeout (2)\")\n            buf = buffer(msg)\n            a = np.frombuffer(buf, dtype=md['dtype'])\n            A[arr_position:arr_position + a.shape[0]] = a[:]\n            arr_position += a.shape[0]\n        A = A.reshape(md['shape'])\n\n        if 'fill_value' in md:\n            A = np.ma.masked_equal(A, md['fill_value'])\n\n    return A, md", "response": "recv a metadata and an optional numpy array from a zmq socket"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(name, re=None, convert=None, doc=None):\n\n    def wrap(cls_or_func):\n        if not hasattr(cls_or_func, '_validations'):\n            cls_or_func._validations = {}\n        cls_or_func._validations[name] = {'re': re, 'convert': convert, 'doc': doc}\n        return cls_or_func\n    return wrap", "response": "Decorator to add validation methods to a resource or any of its sisers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expires(duration, vary=None, currtime=time.time):\n    if isinstance(duration, timedelta):\n        duration = timedelta_to_seconds(duration)\n\n    @decorator\n    def _expires(func, *args, **kwargs):\n        \"Sets the expirations header to the given duration.\"\n        res = args[0].response\n\n        res.cache_control.max_age = duration\n        res.expires = currtime() + duration\n\n        if vary:\n            if res.vary is None:\n                res.vary = vary\n            else:\n                # A bit completed because res.vary is usually a tuple.\n                res.vary = list(set(list(res.vary) + list(vary)))\n\n        return func(*args, **kwargs)\n    return _expires", "response": "Decorator that applies on a resource method to set the expirations header to the given duration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nidentify sql as either SQL string or 2 - tuple of SQL and params.", "response": "def _sql_params(sql):\n    \"\"\"\n    Identify `sql` as either SQL string or 2-tuple of SQL and params.\n    Same format as supported by Django's RunSQL operation for sql/reverse_sql.\n    \"\"\"\n    params = None\n    if isinstance(sql, (list, tuple)):\n        elements = len(sql)\n        if elements == 2:\n            sql, params = sql\n        else:\n            raise ValueError(\"Expected a 2-tuple but got %d\" % elements)\n    return sql, params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the SQL items are equal.", "response": "def is_sql_equal(sqls1, sqls2):\n    \"\"\"\n    Find out equality of two SQL items.\n\n    See https://docs.djangoproject.com/en/1.8/ref/migration-operations/#runsql.\n    Args:\n        sqls1, sqls2: SQL items, have the same format as supported by Django's RunSQL operation.\n    Returns:\n        (bool) `True` if equal, otherwise `False`.\n    \"\"\"\n    is_seq1 = isinstance(sqls1, (list, tuple))\n    is_seq2 = isinstance(sqls2, (list, tuple))\n\n    if not is_seq1:\n        sqls1 = (sqls1,)\n    if not is_seq2:\n        sqls2 = (sqls2,)\n\n    if len(sqls1) != len(sqls2):\n        return False\n\n    for sql1, sql2 in zip(sqls1, sqls2):\n        sql1, params1 = _sql_params(sql1)\n        sql2, params2 = _sql_params(sql2)\n        if sql1 != sql2 or params1 != params2:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassemble changes for a set of items.", "response": "def assemble_changes(self, keys, resolve_keys, sql_state):\n        \"\"\"\n        Accepts keys of SQL items available, sorts them and adds additional dependencies.\n        Uses graph of `sql_state` nodes to build `keys` and `resolve_keys` into sequence that\n        starts with leaves (items that have not dependents) and ends with roots.\n\n        Changes `resolve_keys` argument as dependencies are added to the result.\n\n        Args:\n            keys (list): List of migration keys, that are one of create/delete operations, and\n                dont require respective reverse operations.\n            resolve_keys (list): List of migration keys, that are changing existing items,\n                and may require respective reverse operations.\n            sql_sate (graph.SQLStateGraph): State of SQL items.\n        Returns:\n            (list) Sorted sequence of migration keys, enriched with dependencies.\n        \"\"\"\n        result_keys = []\n        all_keys = keys | resolve_keys\n        for key in all_keys:\n            node = sql_state.node_map[key]\n            sql_item = sql_state.nodes[key]\n            ancs = node.ancestors()[:-1]\n            ancs.reverse()\n            pos = next((i for i, k in enumerate(result_keys) if k in ancs), len(result_keys))\n            result_keys.insert(pos, key)\n\n            if key in resolve_keys and not sql_item.replace:\n                # ancestors() and descendants() include key itself, need to cut it out.\n                descs = reversed(node.descendants()[:-1])\n                for desc in descs:\n                    if desc not in all_keys and desc not in result_keys:\n                        result_keys.insert(pos, desc)\n                        # these items added may also need reverse operations.\n                        resolve_keys.add(desc)\n        return result_keys"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd SQL operation and register it to be used as dependency for further sequential operations.", "response": "def add_sql_operation(self, app_label, sql_name, operation, dependencies):\n        \"\"\"\n        Add SQL operation and register it to be used as dependency for further\n        sequential operations.\n        \"\"\"\n        deps = [(dp[0], SQL_BLOB, dp[1], self._sql_operations.get(dp)) for dp in dependencies]\n\n        self.add_operation(app_label, operation, dependencies=deps)\n        self._sql_operations[(app_label, sql_name)] = operation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_reversed_sql(self, keys, changed_keys):\n        for key in keys:\n            if key not in changed_keys:\n                continue\n            app_label, sql_name = key\n            old_item = self.from_sql_graph.nodes[key]\n            new_item = self.to_sql_graph.nodes[key]\n            if not old_item.reverse_sql or old_item.reverse_sql == RunSQL.noop or new_item.replace:\n                continue\n\n            # migrate backwards\n            operation = ReverseAlterSQL(sql_name, old_item.reverse_sql, reverse_sql=old_item.sql)\n            sql_deps = [n.key for n in self.from_sql_graph.node_map[key].children]\n            sql_deps.append(key)\n            self.add_sql_operation(app_label, sql_name, operation, sql_deps)", "response": "Generate reversed operations for changes that require full rollback and creation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate SQL operations for changing or creating items.", "response": "def _generate_sql(self, keys, changed_keys):\n        \"\"\"\n        Generate forward operations for changing/creating SQL items.\n        \"\"\"\n        for key in reversed(keys):\n            app_label, sql_name = key\n            new_item = self.to_sql_graph.nodes[key]\n            sql_deps = [n.key for n in self.to_sql_graph.node_map[key].parents]\n            reverse_sql = new_item.reverse_sql\n\n            if key in changed_keys:\n                operation_cls = AlterSQL\n                kwargs = {}\n                # in case of replace mode, AlterSQL will hold sql, reverse_sql and\n                # state_reverse_sql, the latter one will be used for building state forward\n                # instead of reverse_sql.\n                if new_item.replace:\n                    kwargs['state_reverse_sql'] = reverse_sql\n                    reverse_sql = self.from_sql_graph.nodes[key].sql\n            else:\n                operation_cls = CreateSQL\n                kwargs = {'dependencies': list(sql_deps)}\n\n            operation = operation_cls(\n                sql_name, new_item.sql, reverse_sql=reverse_sql, **kwargs)\n            sql_deps.append(key)\n            self.add_sql_operation(app_label, sql_name, operation, sql_deps)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _generate_altered_sql_dependencies(self, dep_changed_keys):\n        for key, removed_deps, added_deps in dep_changed_keys:\n            app_label, sql_name = key\n            operation = AlterSQLState(sql_name, add_dependencies=tuple(added_deps),\n                                      remove_dependencies=tuple(removed_deps))\n            sql_deps = [key]\n            self.add_sql_operation(app_label, sql_name, operation, sql_deps)", "response": "Generates forward operations for changing or creating SQL item dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate forward delete operations for SQL items.", "response": "def _generate_delete_sql(self, delete_keys):\n        \"\"\"\n        Generate forward delete operations for SQL items.\n        \"\"\"\n        for key in delete_keys:\n            app_label, sql_name = key\n            old_node = self.from_sql_graph.nodes[key]\n            operation = DeleteSQL(sql_name, old_node.reverse_sql, reverse_sql=old_node.sql)\n            sql_deps = [n.key for n in self.from_sql_graph.node_map[key].children]\n            sql_deps.append(key)\n            self.add_sql_operation(app_label, sql_name, operation, sql_deps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_sql_changes(self):\n        from_keys = set(self.from_sql_graph.nodes.keys())\n        to_keys = set(self.to_sql_graph.nodes.keys())\n        new_keys = to_keys - from_keys\n        delete_keys = from_keys - to_keys\n        changed_keys = set()\n        dep_changed_keys = []\n\n        for key in from_keys & to_keys:\n            old_node = self.from_sql_graph.nodes[key]\n            new_node = self.to_sql_graph.nodes[key]\n\n            # identify SQL changes -- these will alter database.\n            if not is_sql_equal(old_node.sql, new_node.sql):\n                changed_keys.add(key)\n\n            # identify dependencies change\n            old_deps = self.from_sql_graph.dependencies[key]\n            new_deps = self.to_sql_graph.dependencies[key]\n            removed_deps = old_deps - new_deps\n            added_deps = new_deps - old_deps\n            if removed_deps or added_deps:\n                dep_changed_keys.append((key, removed_deps, added_deps))\n\n        # we do basic sort here and inject dependency keys here.\n        # operations built using these keys will properly set operation dependencies which will\n        # enforce django to build/keep a correct order of operations (stable_topological_sort).\n        keys = self.assemble_changes(new_keys, changed_keys, self.to_sql_graph)\n        delete_keys = self.assemble_changes(delete_keys, set(), self.from_sql_graph)\n\n        self._sql_operations = {}\n        self._generate_reversed_sql(keys, changed_keys)\n        self._generate_sql(keys, changed_keys)\n        self._generate_delete_sql(delete_keys)\n        self._generate_altered_sql_dependencies(dep_changed_keys)", "response": "Generate the SQL changes for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_dependency(self, operation, dependency):\n        if isinstance(dependency[1], SQLBlob):\n            # NOTE: we follow the sort order created by `assemble_changes` so we build a fixed chain\n            # of operations. thus we should match exact operation here.\n            return dependency[3] == operation\n        return super(MigrationAutodetector, self).check_dependency(operation, dependency)", "response": "Check if dependency for a migration operation is correct."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_altered_fields(self):\n        result = super(MigrationAutodetector, self).generate_altered_fields()\n        self.generate_sql_changes()\n        return result", "response": "This method is used to generate the altered fields of the migration object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreactivate a credit card.", "response": "def reactivate(credit_card_id: str) -> None:\n    \"\"\"\n    Reactivates a credit card.\n    \"\"\"\n    logger.info('reactivating-credit-card', credit_card_id=credit_card_id)\n    with transaction.atomic():\n        cc = CreditCard.objects.get(pk=credit_card_id)\n        cc.reactivate()\n        cc.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync(self, syncPointList):\n\n        if len(syncPointList) == 0:\n            return\n\n        subsCopy = self._subs.clone()\n\n        syncPointList.sort()\n\n        SubAssert(syncPointList[0].subNo >= 0)\n        SubAssert(syncPointList[0].subNo < subsCopy.size())\n        SubAssert(syncPointList[-1].subNo < subsCopy.size())\n\n        # Always start from the first subtitle.\n        firstSyncPoint = self._getLowestSyncPoint(syncPointList, subsCopy)\n        if firstSyncPoint != syncPointList[0]:\n            syncPointList.insert(0, firstSyncPoint)\n\n        for i, syncPoint in enumerate(syncPointList):\n\n            # Algorithm:\n            # 1. Calculate time deltas between sync points and between subs:\n            #        DE_OLD = subTime[secondSyncSubNo] - subTime[firstSyncSubNo]\n            #        DE_NEW = secondSyncTime - firstSyncTime\n            # 2. Calculate proportional sub position within DE_OLD:\n            #        d = (subTime - subTime[firstSubNo]) / DE_OLD\n            # 3. \"d\" is constant within deltas, so we can now calculate newSubTime:\n            #        newSubTime = DE_NEW * d + firstSyncTime\n\n            firstSyncPoint = syncPointList[i]\n            secondSyncPoint = self._getSyncPointOrEnd(i + 1, syncPointList, subsCopy)\n\n            log.debug(_(\"Syncing times for sync points:\"))\n            log.debug(\"  %s\" % firstSyncPoint)\n            log.debug(\"  %s\" % secondSyncPoint)\n\n            # A case for the last one syncPoint\n            if firstSyncPoint == secondSyncPoint:\n                continue\n\n            secondSubNo = secondSyncPoint.subNo\n            firstSubNo = firstSyncPoint.subNo\n\n            firstOldSub = subsCopy[firstSubNo]\n            secondOldSub = subsCopy[secondSubNo]\n\n            oldStartDelta, oldEndDelta = self._getDeltas(firstOldSub, secondOldSub)\n            newStartDelta, newEndDelta = self._getDeltas(firstSyncPoint, secondSyncPoint)\n\n            for subNo in range(firstSubNo, secondSubNo + 1):\n                sub = subsCopy[subNo]\n                newStartTime = self._calculateTime(sub.start, firstOldSub.start,\n                    firstSyncPoint.start, oldStartDelta, newStartDelta)\n                newEndTime = self._calculateTime(sub.end, firstOldSub.end,\n                    firstSyncPoint.end, oldEndDelta, newEndDelta)\n\n                self._subs.changeSubStart(subNo, newStartTime)\n                self._subs.changeSubEnd(subNo, newEndTime)", "response": "Synchronise subtitles using a given list of SyncPoints."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getDeltas(self, firstSub, secondSub):\n        startDelta = max(firstSub.start, secondSub.start) - min(firstSub.start, secondSub.start)\n        endDelta = max(firstSub.end, secondSub.end) - min(firstSub.end, secondSub.end)\n        return (startDelta, endDelta)", "response": "Get the delta between two FrameTimes objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getLowestSyncPoint(self, syncPointList, subs):\n        if syncPointList[0].subNo == 0:\n            return syncPointList[0]\n        return SyncPoint(0, subs[0].start, subs[0].end)", "response": "Get the lowest possible sync point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_location_descriptor(self, location):\n        loc_descriptor = None\n        if isinstance(location, basestring):\n            loc_descriptor = LocationDescriptor(location)\n        elif isinstance(location, LocationDescriptor):\n            loc_descriptor = location\n        else:\n            raise RuntimeError(\"Argument is neither a string nor a self._nbr_of_nodes\")\n\n        return loc_descriptor", "response": "Returns a corresponding LocationDescriptor object from a string or a LocationDescriptor itself."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_node(self, loc_descriptor, create_non_existing_nodes=False):\n        node = self._root_node\n\n        for location in loc_descriptor.generate_all_sub_locations():\n            child = node.get_child_node_or_default(location, None)\n            if child is None:\n                if not create_non_existing_nodes:\n                    raise RuntimeError(\"Node at location '%s' in '%s' does not exist!\" % (location, loc_descriptor.to_string()))\n                else:\n                    # create empty node\n                    child = TreeMapNode(None)\n                    node.set_child_node(location, child)\n                    self._nbr_of_nodes += 1\n            node = child\n\n        return node", "response": "Returns a node corresponding to the last location in a LocationDescriptor object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an entry located at ``location``. Args: location: String or :class:`LocationDescriptor` to describe a \"separator location\" (i.e. dir1/dir2/dir3 for instance). element: Element to store at the location. unique: ``True`` means that the element to store **must** be unique and that the corresponding node doesn't already exist. delete_element: In case the element must not be unique, delete or not the existing element at the ``location`` if it exist? Returns: The created node with the element. Raises: A ``RuntimeError`` is raised if leaf node already exists and ``unique`` is set to ``True``. Note: Non existing linking node (i.e. non leaf nodes) are created on the fly.", "response": "def _create_entry(self, location, element, unique=True, delete_element=False):\n        \"\"\"\n        Create an entry located at ``location``.\n        \n        Args:\n            location: String or :class:`LocationDescriptor` to describe a \"separator location\" (i.e. dir1/dir2/dir3 for\n                instance).\n            element: Element to store at the location.\n            unique: ``True`` means that the element to store **must** be unique and that the corresponding node doesn't already exist.\n            delete_element: In case the element must not be unique, delete or not the existing element at\n                the ``location`` if it exist?\n        \n        Returns:\n            The created node with the element.\n            \n        Raises:\n            A ``RuntimeError`` is raised if leaf node already exists and ``unique`` is set to ``True``.\n\n        Note:\n            Non existing linking node (i.e. non leaf nodes) are created on the fly.\n        \"\"\"\n        loc_descriptor = self._get_location_descriptor(location)\n\n        # find parent node\n        parent_node = self._root_node\n        if loc_descriptor.nbr_of_sub_locations() > 1:\n            parent_node = self._get_node(loc_descriptor.get_sub_location_descriptor(), create_non_existing_nodes=True)\n\n        # find child node if it exist\n        last_location = loc_descriptor.last_sub_location()\n        child_node = parent_node.get_child_node_or_default(last_location, None)\n        if child_node is None:\n            # create node\n            child_node = TreeMapNode(element)\n            parent_node.set_child_node(last_location, child_node)\n            self._nbr_of_nodes += 1\n        else:\n            # child node exist\n            if unique:\n                raise RuntimeError(\"Node corresponding to the location '%s' already exist!\" % loc_descriptor.to_string())\n            elif delete_element:\n                child_node.delete_element()\n            child_node.set_element(element)\n\n        return child_node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_unique_element(self, location, element):\n        return self._create_entry(location, element, unique=True)", "response": "Create an entry located at location and add an element to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an entry located at location.", "response": "def add_element(self, location, element, delete_elem=False):\n        \"\"\"\n        Create an entry located at ``location``.\n        \n        Args:\n            location: String or :class:`LocationDescriptor` to describe a \"separator location\" (i.e. dir1/dir2/dir3 for\n                instance).\n            element: Element to store.\n            delete_elem: Delete old element or not if it exist?\n        \n        Returns:\n            The created node with the element.\n            \n        Notes:\n            The different sub locations entries **must** exist and the last may or may not already exist.\n            Use the more strict :meth:`add_unique_element` method if needed.\n            \n            You don't need to have a common root node. We internally use a dummy root node.\n        \"\"\"\n        return self._create_entry(location, element, unique=False, delete_element=delete_elem)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the element from the node identified by location.", "response": "def retrieve_element(self, location):\n        \"\"\"\n        \n        Args:\n            location:\n        \n        Returns:\n        \"\"\"\n        loc_descriptor = self._get_location_descriptor(location)\n        # find node\n        node = self._get_node(loc_descriptor)\n        return node.get_element()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_element_or_default(self, location, default=None):\n        loc_descriptor = self._get_location_descriptor(location)\n        # find node\n        node = None\n        try:\n            node = self._get_node(loc_descriptor)\n        except Exception as e:\n            return default\n\n        return node.get_element()", "response": "Retrieve an element from the node with the specified location or return the default if it s not found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscan local network for GH units.", "response": "async def scan_for_units(self, iprange):\n        \"\"\"Scan local network for GH units.\"\"\"\n        units = []\n        for ip_address in ipaddress.IPv4Network(iprange):\n            sock = socket.socket()\n            sock.settimeout(0.02)\n            host = str(ip_address)\n            try:\n                scan_result = sock.connect((host, PORT))\n            except socket.error:\n                scan_result = 1\n            _LOGGER.debug('Checking port connectivity on %s:%s',\n                          host, (str(PORT)))\n            if scan_result is None:\n                ghlocalapi = DeviceInfo(self._loop, self._session, host)\n                await ghlocalapi.get_device_info()\n                data = ghlocalapi.device_info\n                if data is not None:\n                    cap = data['device_info']['capabilities']\n                    units.append({\n                        'host': host,\n                        'name': data['name'],\n                        'model': data['device_info']['model_name'],\n                        'assistant_supported': cap.get('assistant_supported',\n                                                       False)\n                    })\n            sock.close()\n        return units"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets nearby bluetooth devices.", "response": "async def bluetooth_scan():\n    \"\"\"Get nearby bluetooth devices.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = Bluetooth(LOOP, session, IPADDRESS)\n        await ghlocalapi.scan_for_devices()  # Start device scan\n        await ghlocalapi.get_scan_result()  # Returns the result\n\n        print(\"Device info:\", ghlocalapi.devices)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning that calculates the mean and variance of every feature in a data chunk. It returns the number of elements and the variance of the feature in each row in inp.", "response": "def map_fit(interface, state, label, inp):\n    \"\"\"\n    Function counts occurrences of feature values for every row in given data chunk. For continuous features it returns\n    number of values and it calculates mean and variance for every feature.\n    For discrete features it counts occurrences of labels and values for every feature. It returns occurrences of pairs:\n    label, feature index, feature values.\n    \"\"\"\n    import numpy as np\n    combiner = {}  # combiner used for joining of intermediate pairs\n    out = interface.output(0)  # all outputted pairs have the same output label\n\n    for row in inp:  # for every row in data chunk\n        row = row.strip().split(state[\"delimiter\"])  # split row\n        if len(row) > 1:  # check if row is empty\n            for i, j in enumerate(state[\"X_indices\"]):  # for defined features\n                if row[j] not in state[\"missing_vals\"]:  # check missing values\n                    # creates a pair - label, feature index\n                    pair = row[state[\"y_index\"]] + state[\"delimiter\"] + str(j)\n\n                    if state[\"X_meta\"][i] == \"c\":  # continuous features\n                        if pair in combiner:\n                            # convert to float and store value\n                            combiner[pair].append(np.float32(row[j]))\n                        else:\n                            combiner[pair] = [np.float32(row[j])]\n\n                    else:  # discrete features\n                        # add feature value to pair\n                        pair += state[\"delimiter\"] + row[j]\n                        # increase counts of current pair\n                        combiner[pair] = combiner.get(pair, 0) + 1\n\n                    # increase label counts\n                    combiner[row[state[\"y_index\"]]] = combiner.get(row[state[\"y_index\"]], 0) + 1\n\n    for k, v in combiner.iteritems():  # all pairs in combiner are output\n        if len(k.split(state[\"delimiter\"])) == 2:  # continous features\n            # number of elements, partial mean and variance\n            out.add(k, (np.size(v), np.mean(v, dtype=np.float32), np.var(v, dtype=np.float32)))\n        else:  # discrete features and labels\n            out.add(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction that calculates the mean and variance of a single node in a naive Bayes dataset.", "response": "def reduce_fit(interface, state, label, inp):\n    \"\"\"\n    Function separates aggregation of continuous and discrete features.\n    For continuous features it aggregates partially calculated means and variances and returns them. For discrete\n    features it aggregates pairs and returns them. Pairs with label occurrences are used to calculate prior probabilities\n    \"\"\"\n    from disco.util import kvgroup  # function for grouping values by key\n    import numpy as np\n\n    out = interface.output(0)  # all outputted pairs have the same output label\n\n    # model of naive Bayes stores label names, sum of all label occurrences and pairs\n    # (feature index, feature values) for discrete features which are needed to optimize predict phase.\n    fit_model = {\"y_labels\": [], \"y_sum\": 0, \"iv\": set()}\n    combiner = {}  # combiner maintains correct order of means and variances.\n    means, variances = [], []\n    k_prev = \"\"\n\n    for key, value in kvgroup(inp):  # input pairs are sorted and grouped by key\n        k_split = key.split(state[\"delimiter\"])  # pair is split\n\n        if len(k_split) == 3:  # discrete features\n            # store pair (feature index, feature value)\n            fit_model[\"iv\"].add(tuple(k_split[1:]))\n            # aggregate and output occurrences of a pair\n            out.add(tuple(k_split), sum(value))\n\n        elif len(k_split) == 2:  # continuous features\n\n            # if label is different than previous.\n            # This enables calculation of all variances and means for every feature for current label.\n            if k_split[0] != k_prev and k_prev != \"\":\n                mean, var = zip(*[combiner[key] for key in sorted(combiner.keys())])\n                means.append(mean)\n                variances.append(var)\n\n            # number of elements, partial mean, partial variance.\n            n_a = mean_a = var_a = 0\n            # code aggregates partially calculated means and variances\n            for n_b, mean_b, var_b in value:\n                n_ab = n_a + n_b\n                var_a = ((n_a * var_a + n_b * var_b) / float(n_ab)) + (\n                    n_a * n_b * ((mean_b - mean_a) / float(n_ab)) ** 2)\n                mean_a = (n_a * mean_a + n_b * mean_b) / float(n_ab)\n                n_a = n_ab\n\n            # maintains correct order of statistics for every feature\n            combiner[int(k_split[1])] = (mean_a, var_a + 1e-9)\n            k_prev = k_split[0]\n\n        else:  # aggregates label occurrences\n            fit_model[key] = np.sum(value)\n            fit_model[\"y_sum\"] += fit_model[key]  # sum of all label occurrences\n            fit_model[\"y_labels\"].append(key)\n\n    # if statistics for continuous features were not output in last iteration\n    if len(means) > 0:\n        mean, var = zip(*[combiner[key] for key in sorted(combiner.keys())])\n        out.add(\"mean\", np.array(means + [mean], dtype=np.float32))\n        variances = np.array(variances + [var], dtype=np.float32)\n        out.add(\"var\", variances)\n        out.add(\"var_log\", np.log(np.pi * variances))\n\n    # calculation of prior probabilities\n    prior = [fit_model[y_label] / float(fit_model[\"y_sum\"]) for y_label in fit_model[\"y_labels\"]]\n    out.add(\"prior\", np.array(prior, dtype=np.float32))\n    out.add(\"prior_log\", np.log(prior))\n    out.add(\"iv\", list(fit_model[\"iv\"]))\n    out.add(\"y_labels\", fit_model[\"y_labels\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction makes a predictions of samples with given model. It calculates probabilities with multinomial and Gaussian distribution.", "response": "def map_predict(interface, state, label, inp):\n    \"\"\"\n    Function makes a predictions of samples with given model. It calculates probabilities with multinomial and Gaussian distribution.\n    \"\"\"\n    import numpy as np\n    out = interface.output(0)\n\n    continuous = [j for i, j in enumerate(state[\"X_indices\"]) if\n                  state[\"X_meta\"][i] == \"c\"]  # indices of continuous features\n    discrete = [j for i, j in enumerate(state[\"X_indices\"]) if\n                state[\"X_meta\"][i] == \"d\"]  # indices of discrete features\n\n    cont = True if len(continuous) > 0 else False  # enables calculation of Gaussian probabilities\n    disc = True if len(discrete) > 0 else False  # enables calculation of multinomial probabilities.\n\n    for row in inp:\n        row = row.strip().split(state[\"delimiter\"])\n        if len(row) > 1:  # if row is empty\n            # set id of a sample\n            x_id = \"\" if state[\"id_index\"] == -1 else row[state[\"id_index\"]]\n            # initialize prior probability for all labels\n            probs = state[\"fit_model\"][\"prior_log\"]\n\n            if cont:  # continuous features\n                x = np.array([(0 if row[j] in state[\"missing_vals\"] else float(row[j])) for j in\n                              continuous])  # sets selected features of the sample\n                # Gaussian distribution\n                probs = probs - 0.5 * np.sum(\n                    np.true_divide((x - state[\"fit_model\"][\"mean\"]) ** 2, state[\"fit_model\"][\"var\"]) +\n                    state[\"fit_model\"][\"var_log\"], axis=1)\n\n            if disc:  # discrete features\n                # multinomial distribution\n                probs = probs + np.sum(\n                    [(0 if row[i] in state[\"missing_vals\"] else state[\"fit_model\"].get((str(i), row[i]), np.zeros(1)))\n                     for i in discrete], axis=0)\n\n            # normalize by P(x) = P(f_1, ..., f_n)\n            log_prob_x = np.log(np.sum(np.exp(probs)))\n            probs = np.exp(np.array(probs) - log_prob_x)\n            # Predicted label is the one with highest probability\n            y_predicted = max(zip(probs, state[\"fit_model\"][\"y_labels\"]))[1]\n            out.add(x_id, (y_predicted, probs.tolist()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef predict(dataset, fitmodel_url, m=1, save_results=True, show=False):\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import Job, result_iterator\n    import numpy as np\n\n    try:\n        m = float(m)\n    except ValueError:\n        raise Exception(\"Parameter m should be numerical.\")\n\n    if \"naivebayes_fitmodel\" in fitmodel_url:\n        # fit model is loaded from ddfs\n        fit_model = dict((k, v) for k, v in result_iterator(fitmodel_url[\"naivebayes_fitmodel\"]))\n        if len(fit_model[\"y_labels\"]) < 2:\n            print \"There is only one class in training data.\"\n            return []\n    else:\n        raise Exception(\"Incorrect fit model.\")\n\n    if dataset.params[\"X_meta\"].count(\"d\") > 0:  # if there are discrete features in the model\n        # code calculates logarithms to optimize predict phase as opposed to calculation by every mapped.\n        np.seterr(divide='ignore')\n        for iv in fit_model[\"iv\"]:\n            dist = [fit_model.pop((y,) + iv, 0) for y in fit_model[\"y_labels\"]]\n            fit_model[iv] = np.nan_to_num(\n                np.log(np.true_divide(np.array(dist) + m * fit_model[\"prior\"], np.sum(dist) + m))) - fit_model[\n                                \"prior_log\"]\n        del (fit_model[\"iv\"])\n\n    # define a job and set save of results to ddfs\n    job = Job(worker=Worker(save_results=save_results))\n\n    # job parallelizes execution of mappers\n    job.pipeline = [\n        (\"split\", Stage(\"map\", input_chain=dataset.params[\"input_chain\"], init=simple_init, process=map_predict))]\n\n    job.params = dataset.params  # job parameters (dataset object)\n    job.params[\"fit_model\"] = fit_model\n    # define name of a job and input data urls\n    job.run(name=\"naivebayes_predict\", input=dataset.params[\"data_tag\"])\n    results = job.wait(show=show)\n    return results", "response": "Function that makes predictions to input data with a given model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data(self):\n        if self._data:\n            return self._data\n\n        retval = {}\n        data = self.get_request_data()\n        for subdata in data:\n            for key, value in subdata.iteritems():\n                if not key in retval:\n                    retval[key] = value\n\n        self._data = retval\n        return retval", "response": "Returns the request data as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource(self, resource, **kwargs):\n        return resource(request=self.request, response=self.response,\n            path_params=self.path_params, application=self.application,\n            **kwargs)", "response": "Returns a new instance of the resource class passed in as resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_method(self, method=None):\n        if method is None:\n            method = self.request.method\n        if hasattr(self, method) and callable(getattr(self, method)):\n            return method\n        elif method == 'HEAD':\n            return self.get_method('GET')\n        # Error: did not find any method, raise a 405 or 501 exception\n        elif method in self.KNOWN_METHODS:\n            # Known HTTP methods => 405 Method Not Allowed\n            raise_405(self)\n        else:\n            # Unknown HTTP methods => 501 Not Implemented\n            raise_501(self)", "response": "Returns the method to call on this instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_content_type(self):\n        extension = self.path_params.get('_extension')\n        for ext, mime in self.EXTENSION_MAP:\n            if ext == extension:\n                return mime\n        # Else: use the Accept headers\n        if self.response.vary is None:\n            self.response.vary = ['Accept']\n        else:\n            self.response.vary.append('Accept')\n        types = [mime for ext, mime in self.EXTENSION_MAP]\n        ct = self.request.accept.best_match(types)\n        # No best match found. The specification allows us to either return a\n        # 406 or just use another format in this case.\n        # We pick the default format, though that may become a configurable\n        # behavior in the future.\n        if not ct:\n            ct = types[0]\n        return ct", "response": "Returns the Content Type to serve from either the extension or the Accept headers. Uses the extension_map list for all the the\n        Accept headers. Uses the HTTP Accept header to determine the content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_ignored_resources(self):\n        if (self.method in ('GET', 'HEAD') and\n                self.request.path_qs in self.IGNORED_PATHS):\n            raise_404(self)", "response": "Handle the ignore requests for the resource that we are not interested in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_conditions(self):\n        self.assert_condition_md5()\n        etag = self.clean_etag(self.call_method('get_etag'))\n        self.response.last_modified = self.call_method('get_last_modified')\n        self.assert_condition_etag()\n        self.assert_condition_last_modified()", "response": "Checks the HTTP conditions and raises HTTP exceptions to the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the MD5 hash of the request body matches the MD5 hash of the request body.", "response": "def assert_condition_md5(self):\n        \"\"\"If the ``Content-MD5`` request header is present in the request\n        it's verified against the MD5 hash of the request body. If they don't\n        match, a 400 HTTP response is returned.\n\n        :raises: :class:`webob.exceptions.ResponseException` of status 400 if\n                 the MD5 hash does not match the body.\n        \"\"\"\n        if 'Content-MD5' in self.request.headers:\n            body_md5 = hashlib.md5(self.request.body).hexdigest()\n            if body_md5 != self.request.headers['Content-MD5']:\n                raise_400(self, msg='Invalid Content-MD5 request header.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_condition_etag(self):\n        if self.response.etag:\n            etag = self.response.etag.replace('\"', '')\n            if not etag in self.request.if_match:\n                raise_412(self,\n                    'If-Match request header does not the resource ETag.')\n            if etag in self.request.if_none_match:\n                if self.request.method in ('GET', 'HEAD'):\n                    raise_304(self)\n                else:\n                    raise_412(self,\n                        'If-None-Match request header matches resource ETag.')", "response": "Checks whether the ETag of the resource matches the ETag in the request headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_condition_last_modified(self):\n        rq = self.request\n        rs = self.response\n        if rs.last_modified:\n            rsl = rs.last_modified\n            if rq.if_modified_since and rsl <= rq.if_modified_since:\n                raise_304(self)\n            if rq.if_unmodified_since and rsl > rq.if_unmodified_since:\n                raise_412(self, 'Resource is newer than the '\n                    'If-Unmodified-Since request header.')", "response": "Checks if the resource has a last modified date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_etag(self, etag):\n        if etag:\n            etag = etag.replace('\"', '')\n            extension = None\n            for ext, mime in self.EXTENSION_MAP:\n                if mime == self.type:\n                    extension = ext[1:]\n                    break\n            if extension:\n                etag += '_' + extension\n            self.response.etag = etag", "response": "Cleans the ETag as returned by get_etag. Will wrap it in\n            quotes and append the extension for the current MIME type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a coma - separated list of method names that are allowed on this instance. Useful to set the Allowed response header.", "response": "def get_allowed_methods(self):\n        \"\"\"Returns a coma-separated list of method names that are allowed on\n        this instance. Useful to set the ``Allowed`` response header.\n        \"\"\"\n        return \", \".join([method for method in dir(self)\n            if method.upper() == method\n            and callable(getattr(self, method))])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the specified method on the current instance.", "response": "def call_method(self, method_name):\n        \"\"\"Call an instance method filling in all the method parameters based\n        on their names. The parameters are filled in from the following\n        locations (in that order of precedence):\n\n            1. Path parameters from routing\n            2. GET parameters\n            3. POST parameters\n\n        All values are validated using the method :func:`validate_param`. The\n        return value of the method is returned unaltered.\n\n        :param method_name: Name of the method on the current instance to\n                            call.\n        :type method_name: str\n        \"\"\"\n        params = []\n        method = getattr(self, method_name)\n\n        method_params, varargs, varkw, defaults = inspect.getargspec(method)\n        if method_params and len(method_params) > 1:\n            method_params.pop(0)  # pop the self off\n            data = self._merge_defaults(self.data, method_params, defaults)\n            for param in method_params:\n                value = data.get(param)\n                self.validate_param(method, param, value)\n                value = self.convert_param(method, param, value)\n                params.append(value)\n\n        return method(*params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the parameter according to the rules in the validation dictionary of the method and the instance.", "response": "def validate_param(self, method, param, value):\n        \"\"\"Validates the parameter according to the configurations in the\n        _validations dictionary of either the method or the instance. This\n        dictionaries are written by the decorator\n        :func:`wsgiservice.decorators.validate`.\n\n        .. todo:: Allow validation by type (e.g. header, post, query, etc.)\n\n        :param method: A function to get the validation information from (done\n                       using :func:`_get_validation`).\n        :type method: Python function\n        :param param: Name of the parameter to validate the value for.\n        :type param: str\n        :param value: Value passed in for the given parameter.\n        :type value: Any valid Python value\n\n        :raises: :class:`wsgiservice.exceptions.ValidationException` if the\n            value is invalid for the given method and parameter.\n        \"\"\"\n        rules = self._get_validation(method, param)\n        if not rules:\n            return\n        if value is None or (isinstance(value, basestring) and len(value) == 0):\n            raise ValidationException(\n                \"Value for {0} must not be empty.\".format(param))\n        elif rules.get('re'):\n            if not re.search('^' + rules['re'] + '$', value):\n                raise ValidationException(\n                    \"{0} value {1} does not validate.\".format(param, value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_param(self, method, param, value):\n        rules = self._get_validation(method, param)\n        if not rules or not rules.get('convert'):\n            return value\n        try:\n            return rules['convert'](value)\n        except ValueError:\n            raise ValidationException(\n                \"{0} value {1} does not validate.\".format(param, value))", "response": "Converts the parameter using the function convert function of the validation rules."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_validation(self, method, param):\n        if hasattr(method, '_validations') and param in method._validations:\n            return method._validations[param]\n        elif (hasattr(method.im_class, '_validations') and\n                param in method.im_class._validations):\n            return method.im_class._validations[param]\n        else:\n            return None", "response": "Returns the correct validations dictionary for this parameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfinish filling the instance s response object so it s ready to be a new object.", "response": "def convert_response(self):\n        \"\"\"Finish filling the instance's response object so it's ready to be\n        served to the client. This includes converting the body_raw property\n        to the content type requested by the user if necessary.\n        \"\"\"\n        if hasattr(self.response, 'body_raw'):\n            if self.response.body_raw is not None:\n                to_type = re.sub('[^a-zA-Z_]', '_', self.type)\n                to_type_method = 'to_' + to_type\n                if hasattr(self, to_type_method):\n                    self.response.body = getattr(self, to_type_method)(\n                        self.response.body_raw)\n            del self.response.body_raw"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog the given exception and set the response code and status to the status code.", "response": "def handle_exception(self, e, status=500):\n        \"\"\"Handle the given exception. Log, sets the response code and\n        output the exception message as an error message.\n\n        :param e: Exception which is being handled.\n        :type e: :class:`Exception`\n        :param status: Status code to set.\n        :type status: int\n        \"\"\"\n        logger.exception(\n            \"An exception occurred while handling the request: %s\", e)\n        self.response.body_raw = {'error': str(e)}\n        self.response.status = status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_exception_404(self, e):\n        logger.debug(\"A 404 Not Found exception occurred while handling \"\n                     \"the request.\")\n        self.response.body_raw = {'error': 'Not Found'}\n        self.response.status = 404", "response": "Handle the given exception and set the response code to 404 and the response body_raw to be a string containing the error message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_response_content_type(self):\n        if self.response.body:\n            ct = self.type\n            if self.charset:\n                ct += '; charset=' + self.charset\n            self.response.headers['Content-Type'] = ct\n        elif 'Content-Type' in self.response.headers:\n            del self.response.headers['Content-Type']", "response": "Sets the Content - Type in the response. Uses the type and charset attributes which were set by get_content_type. Also uses the charset attribute which was set by get_content_type. Also uses the charset attribute which was set by get_content_type. Also uses the charset attribute which was set by get_content_type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_response_content_md5(self):\n        self.response.content_md5 = hashlib.md5(self.response.body).hexdigest()", "response": "Set the Content - MD5 response header. Calculated from the the\n response body by creating the MD5 hash from it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_request_data(self):\n        request_data = [self.path_params, self.request.GET]\n\n        if self.request.headers.get('Content-Type') == 'application/json' \\\n           and self.request.body:\n            try:\n                post = json.loads(self.request.body)\n            except ValueError:\n                raise_400(self, msg='Invalid JSON content data')\n            if isinstance(post, dict):\n                request_data.append(post)\n        else:\n            request_data.append(self.request.POST)\n\n        return request_data", "response": "Read the input values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _merge_defaults(self, data, method_params, defaults):\n        if defaults:\n            optional_args = method_params[-len(defaults):]\n            for key, value in zip(optional_args, defaults):\n                if not key in data:\n                    data[key] = value\n        return data", "response": "Helper method for adding default values to the data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a new model from the database.", "response": "def get(self, key=None, view=None):\n        \"\"\"Register a new model (models)\"\"\"\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.set_header(\"Content-Type\", \"application/json\")\n        if key is not None:\n            value = {}\n            value.update(self.database[key])\n            if view is not None:\n                # generate a context with the relevant variables\n                context = {}\n                context[\"value\"] = value\n                context[\"ctx\"] = self.ctx\n                result = json.dumps(getattr(views, view)(context))\n            else:\n                result = json.dumps(value)\n        else:\n            result = json.dumps(self.database.values())\n\n        self.write(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post(self):\n        self.set_header(\"Content-Type\", \"application/json\")\n        key = uuid.uuid4().hex\n        metadata = json.loads(self.request.body.decode())\n        metadata[\"uuid\"] = key\n        self.database[key] = metadata\n        result = json.dumps({\"uuid\": key})\n        self.write(result)", "response": "Register a new model ( models"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a data_frame. columns.", "response": "def get_columns(self, usage, columns=None):\n        \"\"\"\n        Returns a `data_frame.columns`.\n        :param usage (str): should be a value from [ALL, INCLUDE, EXCLUDE].\n                            this value only makes sense if attr `columns` is also set.\n                            otherwise, should be used with default value ALL.\n        :param columns: * if `usage` is all, this value is not used.\n                        * if `usage` is INCLUDE, the `df` is restricted to the intersection\n                          between `columns` and the `df.columns`\n                        * if usage is EXCLUDE, returns the `df.columns` excluding these `columns`\n        :return: `data_frame` columns, excluding `target_column` and `id_column` if given.\n                 `data_frame` columns, including/excluding the `columns` depending on `usage`.\n        \"\"\"\n        columns_excluded = pd.Index([])\n        columns_included = self.df.columns\n\n        if self.has_target():\n            columns_excluded = pd.Index([self.target_column])\n\n        if self.has_id():\n            columns_excluded = columns_excluded.union(pd.Index([self.id_column]))\n\n        if usage == self.INCLUDE:\n            try:\n                columns_included = columns_included.intersection(pd.Index(columns))\n            except TypeError:\n                pass\n        elif usage == self.EXCLUDE:\n            try:\n                columns_excluded = columns_excluded.union(pd.Index(columns))\n            except TypeError:\n                pass\n\n        columns_included = columns_included.difference(columns_excluded)\n        return columns_included.intersection(self.df.columns)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a python dict from a pandas dataframe with columns as keys", "response": "def to_dict(self, columns=None):\n        \"\"\"\n        Return a python dict from a pandas dataframe, with columns as keys\n        :return: dict\n        \"\"\"\n        if columns:\n            assert len(columns) == len(self.feature_names)\n        d = [\n            dict([\n                (columns[i] if columns else col_name, row[i])\n                for i, col_name in enumerate(self.feature_names)\n            ])\n            for row in self.data\n        ]\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a subset of columns from the given table X", "response": "def _get_columns(self, X, cols):\n        \"\"\"\n        Get a subset of columns from the given table X.\n        X       a Pandas dataframe; the table to select columns from\n        cols    a string or list of strings representing the columns\n                to select\n        Returns a numpy array with the data from the selected columns\n        \"\"\"\n        if isinstance(X, DataSet):\n            X = X[cols]\n\n        return_vector = False\n        if isinstance(cols, basestring):\n            return_vector = True\n            cols = [cols]\n\n        if isinstance(X, list):\n            X = [x[cols] for x in X]\n            X = pd.DataFrame(X)\n\n        if return_vector:\n            t = X[cols[0]]\n        else:\n            t = X.as_matrix(cols)\n\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, X, y=None):\n        for columns, transformer in self.mapping:\n            if transformer is not None:\n                transformer.fit(self._get_columns(X, columns))\n        return self", "response": "Fit a transformation from the pipeline to the data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, X):\n\n        extracted = []\n        for columns, transformer in self.mapping:\n            if transformer is not None:\n                feature = transformer.transform(self._get_columns(X, columns))\n            else:\n                feature = self._get_columns(X, columns)\n\n            if hasattr(feature, 'toarray'):\n                # sparse arrays should be converted to regular arrays for hstack.\n                feature = feature.toarray()\n\n            if len(feature.shape) == 1:\n                feature = np.array([feature]).T\n            extracted.append(feature)\n\n        # combine the feature outputs into one array.\n        # at this point we lose track of which features\n        # were created from which input columns, so it's\n        # assumed that that doesn't matter to the model.\n        return np.hstack(extracted)", "response": "Transform the given data. Assumes that fit has already been called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _top_element(self):\n        attrs = {\"project-id\": self.config[\"polarion-project-id\"]}\n        document_relative_path = self.config.get(\"requirements-document-relative-path\")\n        if document_relative_path:\n            attrs[\"document-relative-path\"] = document_relative_path\n        top = etree.Element(\"requirements\", attrs)\n        return top", "response": "Returns the top XML element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _properties_element(self, parent_element):\n        requirements_properties = etree.SubElement(parent_element, \"properties\")\n\n        req_properties_conf = self.config.get(\"requirements_import_properties\") or {}\n        for name, value in sorted(six.iteritems(req_properties_conf)):\n            if name == \"lookup-method\":\n                lookup_prop = str(value).lower()\n                if lookup_prop not in (\"id\", \"name\"):\n                    raise Dump2PolarionException(\n                        \"Invalid value '{}' for the 'lookup-method' property\".format(str(value))\n                    )\n                self._lookup_prop = lookup_prop\n            else:\n                etree.SubElement(\n                    requirements_properties, \"property\", {\"name\": name, \"value\": str(value)}\n                )\n\n        return requirements_properties", "response": "Returns properties XML element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fill_lookup_prop(self, requirements_properties):\n        if not self._lookup_prop:\n            raise Dump2PolarionException(\"Failed to set the 'polarion-lookup-method' property\")\n\n        etree.SubElement(\n            requirements_properties,\n            \"property\",\n            {\"name\": \"lookup-method\", \"value\": self._lookup_prop},\n        )", "response": "Fills the polarion - lookup - method property."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_lookup_prop(self, req_id):\n        if self._lookup_prop:\n            if not req_id and self._lookup_prop == \"id\":\n                return False\n        else:\n            if req_id:\n                self._lookup_prop = \"id\"\n            else:\n                self._lookup_prop = \"name\"\n        return True", "response": "Checks that the selected lookup property can be used for this testcase."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _requirement_element(self, parent_element, req_data):\n        req_data = self._transform_result(req_data)\n        if not req_data:\n            return\n\n        title = req_data.get(\"title\")\n        if not title:\n            logger.warning(\"Skipping requirement, title is missing\")\n            return\n        req_id = req_data.get(\"id\")\n\n        if not self._check_lookup_prop(req_id):\n            logger.warning(\n                \"Skipping requirement `%s`, data missing for selected lookup method\", title\n            )\n            return\n\n        attrs, custom_fields = self._classify_data(req_data)\n        attrs, custom_fields = self._fill_defaults(attrs, custom_fields)\n\n        # For testing purposes, the order of fields in resulting XML\n        # needs to be always the same.\n        attrs = OrderedDict(sorted(attrs.items()))\n        custom_fields = OrderedDict(sorted(custom_fields.items()))\n\n        requirement = etree.SubElement(parent_element, \"requirement\", attrs)\n\n        title_el = etree.SubElement(requirement, \"title\")\n        title_el.text = title\n\n        description = req_data.get(\"description\")\n        if description:\n            description_el = etree.SubElement(requirement, \"description\")\n            description_el.text = description\n\n        self._fill_custom_fields(requirement, custom_fields)", "response": "Adds requirement XML element."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_xml(xml, output_file=None):\n        gen_filename = \"requirements-{:%Y%m%d%H%M%S}.xml\".format(datetime.datetime.now())\n        utils.write_xml(xml, output_loc=output_file, filename=gen_filename)", "response": "Outputs the XML content into a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _client(self, id, secret):\n        url = self.api_url + self.auth_token_url\n        auth_string = '%s:%s' % (id, secret)\n        authorization = base64.b64encode(auth_string.encode()).decode()\n        headers = {\n            'Authorization': \"Basic \" + authorization,\n            'Content-Type': \"application/x-www-form-urlencoded\"\n        }\n        params = {\n            'grant_type': 'client_credentials',\n            'response_type': 'token'\n        }\n        return self.session.post(url, params=params, headers=headers)", "response": "Performs client login with the provided credentials"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform login with the provided credentials", "response": "def _login(self, username, password, client_id, client_secret):\n        \"\"\"Performs login with the provided credentials\"\"\"\n        url = self.api_url + self.auth_token_url\n        auth_string = '%s:%s' % (client_id, client_secret)\n        authorization = base64.b64encode(auth_string.encode()).decode()\n        headers = {\n            'Authorization': \"Basic \" + authorization,\n            'Content-Type': \"application/x-www-form-urlencoded\"\n        }\n        params = {\n            'username': str(username),\n            'password': str(password),\n            # 'client_id': client_id,\n            'grant_type': 'password',\n            'response_type': 'token'\n        }\n        return self.session.post(url, params=params, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login(self, username=None, password=''):\n        auth = None\n        if username is not None:\n            # User login\n            resp = self._login(username, password, self.client_id, self.client_secret)\n            msg = \"User Login\"\n        else:\n            # client credentials\n            resp = self._client(self.client_id, self.client_secret)\n            msg = \"Client credentials\"\n        if resp.status_code == requests.codes.ok:\n            auth = resp.json()\n            self.session.headers.update({\n                'Authorization':\n                    (\"%s %s\" % (auth['token_type'], auth['access_token']))\n            })\n        else:\n            error = {'description': \"%s not valid\" % msg }\n            raise UAAException(error, resp.status_code)\n        return auth", "response": "Performs login with the provided credentials"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the normalised feedin profile and installed capacity for the given object - store the data in a single dataframe.", "response": "def aggregate_cap_val(self, conn, **kwargs):\n        '''\n        Returns the normalised feedin profile and installed capacity for\n        a given region.\n\n        Parameters\n        ----------\n        region : Region instance\n        region.geom : shapely.geometry object\n            Geo-spatial data with information for location/region-shape. The\n            geometry can be a polygon/multi-polygon or a point.\n\n        Returns\n        -------\n        feedin_df : pandas dataframe\n            Dataframe containing the normalised feedin profile of the given\n            region. Index of the dataframe is the hour of the year; columns\n            are 'pv_pwr' and 'wind_pwr'.\n        cap : pandas series\n            Series containing the installed capacity (in W) of PV and wind\n            turbines of the given region.\n        '''\n        region = kwargs['region']\n        [pv_df, wind_df, cap] = self.get_timeseries(\n            conn,\n            geometry=region.geom,\n            **kwargs)\n\n        if kwargs.get('store', False):\n            self.store_full_df(pv_df, wind_df, **kwargs)\n\n        # Summerize the results to one column for pv and one for wind\n        cap = cap.sum()\n        df = pd.concat([pv_df.sum(axis=1) / cap['pv_pwr'],\n            wind_df.sum(axis=1) / cap['wind_pwr']], axis=1)\n        feedin_df = df.rename(columns={0: 'pv_pwr', 1: 'wind_pwr'})\n\n        return feedin_df, cap"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_assets(self, dest_path):\n        for idx, subplot in enumerate(self.subplots):\n            subplot.save_assets(dest_path, suffix='_%d' % idx)", "response": "Save plot assets alongside dest_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_empty(self, row, column):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_empty()", "response": "Keep one of the subplots completely empty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nkeeping all specified subplots completely empty.", "response": "def set_empty_for_all(self, row_column_list):\n        \"\"\"Keep all specified subplots completely empty.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :type row_column_list: list or None\n\n        \"\"\"\n        for row, column in row_column_list:\n            self.set_empty(row, column)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a title text.", "response": "def set_title(self, row, column, text):\n        \"\"\"Set a title text.\n\n        :param row,column: specify the subplot.\n        :param text: title text.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_title(text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_label(self, row, column, text, location='upper right',\n                  style=None):\n        \"\"\"Set a label for the subplot.\n\n        :param row,column: specify the subplot.\n        :param text: the label text.\n        :param location: the location of the label inside the plot.  May\n            be one of 'center', 'upper right', 'lower right', 'upper\n            left', 'lower left'.\n        :param style: any TikZ style to style the text.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_label(text, location, style)", "response": "Set a label for the current subplot."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the x - axis tick labels for a specific subplot.", "response": "def show_xticklabels(self, row, column):\n        \"\"\"Show the x-axis tick labels for a subplot.\n\n        :param row,column: specify the subplot.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.show_xticklabels()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the x - axis tick labels for all specified subplots.", "response": "def show_xticklabels_for_all(self, row_column_list=None):\n        \"\"\"Show the x-axis tick labels for all specified subplots.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :type row_column_list: list or None\n\n        \"\"\"\n        if row_column_list is None:\n            for subplot in self.subplots:\n                subplot.show_xticklabels()\n        else:\n            for row, column in row_column_list:\n                self.show_xticklabels(row, column)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_yticklabels(self, row, column):\n        subplot = self.get_subplot_at(row, column)\n        subplot.show_yticklabels()", "response": "Show the y - axis tick labels for a specific subplot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_yticklabels_for_all(self, row_column_list=None):\n        if row_column_list is None:\n            for subplot in self.subplots:\n                subplot.show_yticklabels()\n        else:\n            for row, column in row_column_list:\n                self.show_yticklabels(row, column)", "response": "Show the y - axis tick labels for all specified subplots."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_xticklabels_position(self, row, column, position):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xticklabels_position(position)", "response": "Set the position of the x - axis tick labels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the position of the y - axis tick labels.", "response": "def set_yticklabels_position(self, row, column, position):\n        \"\"\"Specify the position of the axis tick labels.\n\n        This is generally only useful for multiplots containing only one\n        column.  This can be used to e.g. alternatively draw the tick\n        labels on the left or the right of the subplot.\n\n        :param row,column: specify the subplot.\n        :param position: 'left' or 'right' to specify the position of the\n            tick labels.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_yticklabels_position(position)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_xlimits(self, row, column, min=None, max=None):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xlimits(min, max)", "response": "Set x - axis limits of a subplot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_xlimits_for_all(self, row_column_list=None, min=None, max=None):\n        if row_column_list is None:\n            self.limits['xmin'] = min\n            self.limits['xmax'] = max\n        else:\n            for row, column in row_column_list:\n                self.set_xlimits(row, column, min, max)", "response": "Set x - axis limits of all the specified subplots."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_ylimits(self, row, column, min=None, max=None):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_ylimits(min, max)", "response": "Set y - axis limits of a subplot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_ylimits_for_all(self, row_column_list=None, min=None, max=None):\n        if row_column_list is None:\n            self.limits['ymin'] = min\n            self.limits['ymax'] = max\n        else:\n            for row, column in row_column_list:\n                self.set_ylimits(row, column, min, max)", "response": "Set y - axis limits of all the available base cDNA resources."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting limits for the point meta values outside this range will be clipped.", "response": "def set_mlimits(self, row, column, min=None, max=None):\n        \"\"\"Set limits for the point meta (colormap).\n\n        Point meta values outside this range will be clipped.\n\n        :param min: value for start of the colormap.\n        :param max: value for end of the colormap.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_mlimits(min, max)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets limits for all the point meta data for all the subplots.", "response": "def set_mlimits_for_all(self, row_column_list=None, min=None, max=None):\n        \"\"\"Set limits for point meta (colormap) for specified subplots.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :type row_column_list: list or None\n        :param min: value for start of the colormap.\n        :param max: value for end of the colormap.\n\n        \"\"\"\n        if row_column_list is None:\n            self.limits['mmin'] = min\n            self.limits['mmax'] = max\n        else:\n            for row, column in row_column_list:\n                self.set_mlimits(row, column, min, max)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset limits for the point sizes.", "response": "def set_slimits(self, row, column, min, max):\n        \"\"\"Set limits for the point sizes.\n\n        :param min: point size for the lowest value.\n        :param max: point size for the highest value.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_slimits(min, max)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset point size limits for all the specified subplots.", "response": "def set_slimits_for_all(self, row_column_list=None, min=None, max=None):\n        \"\"\"Set point size limits of specified subplots.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :type row_column_list: list or None\n        :param min: point size for the lowest value.\n        :param max: point size for the highest value.\n\n        \"\"\"\n        if min is None or max is None:\n            raise Exception('Both min and max are required.')\n        if row_column_list is None:\n            self.limits['smin'] = sqrt(min)\n            self.limits['smax'] = sqrt(max)\n        else:\n            for row, column in row_column_list:\n                self.set_slimits(row, column, min, max)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_xticks(self, row, column, ticks):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xticks(ticks)", "response": "Manually specify the x - axis tick values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_xticks_for_all(self, row_column_list=None, ticks=None):\n        if row_column_list is None:\n            self.ticks['x'] = ticks\n        else:\n            for row, column in row_column_list:\n                self.set_xticks(row, column, ticks)", "response": "Manually specify the x - axis tick values for all subplots."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_logxticks_for_all(self, row_column_list=None, logticks=None):\n        if row_column_list is None:\n            self.ticks['x'] = ['1e%d' % u for u in logticks]\n        else:\n            for row, column in row_column_list:\n                self.set_logxticks(row, column, logticks)", "response": "Manually specify the x - axis log tick values for all the available base classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_yticks_for_all(self, row_column_list=None, ticks=None):\n        if row_column_list is None:\n            self.ticks['y'] = ticks\n        else:\n            for row, column in row_column_list:\n                self.set_yticks(row, column, ticks)", "response": "Manually specify the y - axis tick values for all subplots."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_xtick_labels(self, row, column, labels):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xtick_labels(labels)", "response": "Manually specify the x - axis tick labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_xtick_labels_for_all(self, row_column_list=None, labels=None):\n        if row_column_list is None:\n            for subplot in self.subplots:\n                self.set_xtick_labels(subplot.row, subplot.column, labels)\n        else:\n            for row, column in row_column_list:\n                self.set_xtick_labels(row, column, labels)", "response": "Manually specify the x - axis tick labels for all subplots."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_ytick_labels(self, row, column, labels):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_ytick_labels(labels)", "response": "Manually specify the y - axis tick labels."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_subplot_at(self, row, column):\n        idx = row * self.columns + column\n        return self.subplots[idx]", "response": "Return the subplot at row column position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the plot using a template.", "response": "def render(self, template=None):\n        \"\"\"Render the plot using a template.\n\n        Once the plot is complete, it needs to be rendered.  Artist uses\n        the Jinja2 templating engine.  The default template results in a\n        LaTeX file which can be included in your document.\n\n        :param template: a user-supplied template or None.\n        :type template: string or None.\n        :returns: the rendered template as string.\n\n        \"\"\"\n        if not template:\n            template = self.template\n\n        for subplot in self.subplots:\n            subplot._prepare_data()\n\n        response = template.render(rows=self.rows, columns=self.columns,\n                                   xmode=self.xmode, ymode=self.ymode,\n                                   width=self.width, height=self.height,\n                                   xlabel=self.xlabel, ylabel=self.ylabel,\n                                   limits=self.limits, ticks=self.ticks,\n                                   colorbar=self.colorbar,\n                                   colormap=self.colormap,\n                                   external_filename=self.external_filename,\n                                   font_options=self.font_options,\n                                   axis_options=self.axis_options,\n                                   subplots=self.subplots,\n                                   plot_template=self.template)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_subplot_xlabel(self, row, column, text):\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xlabel(text)", "response": "Set a label for the x - axis of a subplot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset a label for the y - axis of a subplot.", "response": "def set_subplot_ylabel(self, row, column, text):\n        \"\"\"Set a label for the y-axis of a subplot.\n\n        :param row,column: specify the subplot.\n        :param text: text of the label.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_ylabel(text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing marker area scale for all subplots.", "response": "def set_scalebar_for_all(self, row_column_list=None,\n                             location='lower right'):\n        \"\"\"Show marker area scale for subplots.\n\n        :param row_column_list: a list containing (row, column) tuples to\n            specify the subplots, or None to indicate *all* subplots.\n        :param location: the location of the label inside the plot.  May\n            be one of 'center', 'upper right', 'lower right', 'upper\n            left', 'lower left'.\n\n        \"\"\"\n        if row_column_list is None:\n            for subplot in self.subplots:\n                subplot.set_scalebar(location)\n        else:\n            for row, column in row_column_list:\n                subplot = self.get_subplot_at(row, column)\n                subplot.set_scalebar(location)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_colorbar(self, label='', horizontal=False):\n        if self.limits['mmin'] is None or self.limits['mmax'] is None:\n            warnings.warn('Set (only) global point meta limits to ensure the '\n                          'colorbar is correct for all subplots.')\n        self.colorbar = {'label': label,\n                         'horizontal': horizontal}", "response": "Show the colorbar for the last plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_axis_options(self, row, column, text):\n\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_axis_options(text)", "response": "Set additionnal options as plain text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_axis_options_for_all(self, row_column_list=None, text=''):\n        if row_column_list is None:\n            self.axis_options = text\n        else:\n            for row, column in row_column_list:\n                self.set_axis_options(row, column, text)", "response": "Set point size limits for all subplots."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the position of the x - axis tick labels.", "response": "def set_xticklabels_position(self, position):\n        \"\"\"Specify the position of the axis tick labels.\n\n        This is generally only useful for multiplots containing only one\n        row.  This can be used to e.g. alternatively draw the tick labels\n        on the bottom or the top of the subplot.\n\n        :param position: 'top' or 'bottom' to specify the position of the\n            tick labels.\n\n        \"\"\"\n        pgfplots_translation = {'top': 'right', 'bottom': 'left'}\n        fixed_position = pgfplots_translation[position]\n\n        self.xticklabel_pos = fixed_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize(self, configfile=None):\n\n        method = \"initialize\"\n\n        A = None\n        metadata = {method: configfile}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)", "response": "Initialize the module with the given configfile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget variable name from the object.", "response": "def get_var_name(self, i):\n        \"\"\"\n        Return variable name\n        \"\"\"\n\n        method = \"get_var_name\"\n\n        A = None\n        metadata = {method: i}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)\n\n        return metadata[method]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_var_type(self, name):\n\n        method = \"get_var_type\"\n\n        A = None\n        metadata = {method: name}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)\n\n        return metadata[method]", "response": "Get the type of a variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_current_time(self, t):\n\n        method = \"set_current_time\"\n\n        A = None\n        metadata = {method: t}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)", "response": "Set current time of simulation\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_var_slice(self, name, start, count, var):\n\n        method = \"set_var_slice\"\n\n        A = var\n        metadata = {\n            method: name,\n            \"start\": start,\n            \"count\": count\n        }\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)", "response": "Set the variable name with the values of var"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, dt):\n\n        method = \"update\"\n\n        A = None\n        metadata = {method: dt}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)", "response": "Advance the module with timestep dt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remote(self, action):\n        method = \"remote\"\n\n        A = None\n        metadata = {method: action}\n\n        send_array(self.socket, A, metadata)\n        A, metadata = recv_array(\n            self.socket, poll=self.poll, poll_timeout=self.poll_timeout,\n            flags=self.zmq_flags)\n\n        return metadata[method]", "response": "Function specific for MMI not BMI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubscribe to the SUB socket to listen for incomming variables return a stream that can be listened to. topic is the topic to listen for incomming variables return a stream that can be listened to.", "response": "def subscribe(self, topic=b''):\n        \"\"\"subscribe to the SUB socket, to listen for incomming variables, return a stream that can be listened to.\"\"\"\n        self.sockets[zmq.SUB].setsockopt(zmq.SUBSCRIBE, topic)\n        poller = self.pollers[zmq.SUB]\n        return poller"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads resources from a stage server.", "response": "def download(remote_location, remotes=None, prefix=\"\", dry_run=False):\n    \"\"\"\n    Download resources from a stage server.\n    \"\"\"\n    if remotes is None:\n        remotes, _ = _resources_files(\n            abs_paths=remote_location.startswith('s3://'))\n    if remote_location.startswith('s3://'):\n        from .s3 import S3Backend\n        backend = S3Backend(remote_location, dry_run=dry_run)\n        backend.download(list_local(remotes, prefix), prefix)\n    else:\n        dest_root = '.'\n        shell_command([\n                '/usr/bin/rsync',\n                '-thrRvz', '--rsync-path', '/usr/bin/rsync',\n                '%s/./' % remote_location, dest_root], dry_run=dry_run)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shell_command(cmd, dry_run=False):\n    if cmd[0] == '/usr/bin/rsync':\n        if dry_run:\n            cmd = [cmd[0], '-n'] + cmd[1:]\n        LOGGER.info('run: %s', ' '.join(cmd))\n        subprocess.check_call(cmd)\n    else:\n        LOGGER.info('run: %s', ' '.join(cmd))\n        if not dry_run:\n            subprocess.check_call(cmd)", "response": "Run a shell command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload(remote_location, remotes=None, ignores=None,\n           static_root=\"/static/\", prefix=\"\", dry_run=False):\n    # pylint:disable=too-many-arguments\n    \"\"\"\n    Upload resources to a stage server.\n    \"\"\"\n    if remotes is None:\n        remotes, ignores = _resources_files(\n            abs_paths=remote_location.startswith('s3://'))\n    if remote_location.startswith('s3://'):\n        from deployutils.s3 import S3Backend\n        backend = S3Backend(remote_location,\n            static_root=static_root, dry_run=dry_run)\n        backend.upload(list_local(remotes, prefix), prefix)\n    else:\n        excludes = []\n        if ignores:\n            for ignore in ignores:\n                excludes += ['--exclude', ignore]\n        # -O omit to set mod times on directories to avoid permissions error.\n        shell_command(['/usr/bin/rsync']\n            + excludes + ['-pOthrRvz', '--rsync-path', '/usr/bin/rsync']\n            + remotes + [remote_location], dry_run=dry_run)", "response": "Uploads resources to a stage server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_dumps(obj):\n    try:\n        return json.dumps(obj, indent=2, sort_keys=True, allow_nan=False)\n    except ValueError:\n        pass\n    # we don't want to call do_map on the original object since it can\n    # contain objects that need to be converted for JSON. after reading\n    # in the created JSON we get a limited set of possible types we\n    # can encounter\n    json_str = json.dumps(obj, indent=2, sort_keys=True, allow_nan=True)\n    json_obj = json.loads(json_str)\n\n    def do_map(obj):\n        if obj is None:\n            return None\n        if isinstance(obj, basestring):\n            return obj\n        if isinstance(obj, dict):\n            res = {}\n            for (key, value) in obj.items():\n                res[key] = do_map(value)\n            return res\n        if isinstance(obj, collections.Iterable):\n            res = []\n            for el in obj:\n                res.append(do_map(el))\n            return res\n        # diverging numbers need to be passed as strings otherwise it\n        # will throw a parsing error on the ECMAscript consumer side\n        if math.isnan(obj):\n            return \"NaN\"\n        if math.isinf(obj):\n            return \"Infinity\" if obj > 0 else \"-Infinity\"\n        return obj\n\n    return json.dumps(\n        do_map(json_obj), indent=2, sort_keys=True, allow_nan=False)", "response": "A safe JSON dump function that provides correct diverging numbers for ECMAscript consumer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a message from the server to the log file.", "response": "def msg(message, *args, **kwargs):\n    \"\"\"Prints a message from the server to the log file.\"\"\"\n    global log_file\n    if log_file is None:\n        log_file = sys.stderr\n    if long_msg:\n        file_name, line = caller_trace()\n        file_name, file_type = os.path.splitext(file_name)\n        if file_name.endswith('/__init__'):\n            file_name = os.path.basename(os.path.dirname(file_name))\n        elif file_name.endswith('/__main__'):\n            file_name = \"(-m) {0}\".format(\n                os.path.basename(os.path.dirname(file_name)))\n        else:\n            file_name = os.path.basename(file_name)\n        head = '{0}{1} ({2}): '.format(file_name, file_type, line)\n    else:\n        head = '[SERVER] '\n    out = StringIO()\n    for line in message.format(*args, **kwargs).split('\\n'):\n        out.write('{0}{1}\\n'.format(head, line))\n    out.flush()\n    out.seek(0)\n    if _msg_stderr:\n        sys.stderr.write(out.read())\n        sys.stderr.flush()\n    else:\n        log_file.write(out.read())\n        log_file.flush()\n    out.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_restart():\n    exit_code = os.environ.get('QUICK_SERVER_RESTART', None)\n    if exit_code is None:\n        try:\n            atexit.unregister(_on_exit)\n        except AttributeError:\n            atexit._exithandlers = filter(\n                lambda exit_hnd: exit_hnd[0] != _on_exit, atexit._exithandlers)\n        _start_restart_loop(None, in_atexit=False)", "response": "Sets up restart functionality that doesn t keep the first process alive."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the query string of an URL to a map.", "response": "def convert_argmap(self, query):\n        \"\"\"Converts the query string of an URL to a map.\n\n        Parameters\n        ----------\n        query : string\n            The URL to parse.\n\n        Returns\n        -------\n        A map object containing all fields as keys with their value. Fields\n        without '=' in the URL are interpreted as flags and the value is set\n        to True.\n        \"\"\"\n        res = {}\n        if isinstance(query, bytes):\n            query = query.decode('utf8')\n        for section in query.split('&'):\n            eqs = section.split('=', 1)\n            name = urlparse_unquote(eqs[0])\n            if len(eqs) > 1:\n                res[name] = urlparse_unquote(eqs[1])\n            else:\n                res[name] = True\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_args(self, rem_path, args):\n        fragment_split = rem_path.split('#', 1)\n        query_split = fragment_split[0].split('?', 1)\n        segs = filter(\n            lambda p: len(p) and p != '.',\n            os.path.normpath(query_split[0]).split('/'))\n        paths = [urlparse_unquote(p) for p in segs]\n        query = self.convert_argmap(query_split[1]) \\\n            if len(query_split) > 1 else {}\n        args['paths'] = paths\n        args['query'] = query\n        args['fragment'] = urlparse_unquote(fragment_split[1]).decode('utf8') \\\n            if len(fragment_split) > 1 else ''\n        return args", "response": "Splits the rest of a URL into its argument parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_post_file(self, hdr, f_in, clen, post, files):\n        lens = {\n            'clen': clen,\n            'push': [],\n        }\n        prefix = \"boundary=\"\n        if not hdr.startswith(prefix):\n            return None\n        boundary = hdr[len(prefix):].strip().encode('utf8')\n        if not boundary:\n            return None\n        boundary = b'--' + boundary\n        raw_boundary = b'\\r\\n' + boundary\n        end_boundary = boundary + b'--'\n\n        def push_back(line):\n            ln = BytesIO()\n            ln.write(line)\n            ln.flush()\n            ln.seek(0)\n            lens['clen'] += len(line)\n            lens['push'].append(ln)\n\n        def read_line():\n            line = b''\n            while not line.endswith(b'\\n') and lens['push']:\n                br = lens['push'].pop()\n                line += br.readline()\n                tmp = br.read(1)\n                if tmp != b'':\n                    br.seek(br.tell() - 1)\n                    lens['push'].append(br)\n            if not line.endswith(b'\\n'):\n                line += f_in.readline(lens['clen'])\n            lens['clen'] -= len(line)\n            if line == b'' or lens['clen'] < 0:\n                raise ValueError(\"Unexpected EOF\")\n            return line.strip()\n\n        def read(length):\n            res = b''\n            while len(res) < length and lens['push']:\n                br = lens['push'].pop()\n                res += br.read(length - len(res))\n                tmp = br.read(1)\n                if tmp != b'':\n                    br.seek(br.tell() - 1)\n                    lens['push'].append(br)\n            if len(res) < length:\n                res += f_in.read(length - len(res))\n            lens['clen'] -= len(res)\n            if res == b'' or lens['clen'] < 0:\n                raise ValueError(\"Unexpected EOF\")\n            return res\n\n        def parse_file():\n            f = BytesIO()\n            buff_size = 10 * 1024\n\n            def write_buff(buff):\n                if f.tell() + len(buff) > self.server.max_file_size:\n                    raise PreventDefaultResponse(\n                        413, \"Uploaded file is too large! {0} > {1}\".format(\n                            f.tell() + len(buff), self.server.max_file_size))\n                f.write(buff)\n                f.flush()\n\n            buff = b\"\"\n            while True:\n                buff += read(min(lens['clen'], buff_size))\n                bix = buff.find(raw_boundary)\n                if bix >= 0:\n                    write_buff(buff[:bix])\n                    push_back(buff[bix + len(raw_boundary) - len(boundary):])\n                    break\n                out_split = max(len(buff) - len(raw_boundary), 0)\n                if out_split > 0:\n                    write_buff(buff[:out_split])\n                    buff = buff[out_split:]\n            f.seek(0)\n            return f\n\n        def parse_field():\n            return parse_file().read().decode('utf8')\n\n        while True:\n            line = read_line()\n            if line == end_boundary:\n                if lens['clen'] > 0:\n                    raise ValueError(\n                        \"Expected EOF got: {0}\".format(\n                            repr(f_in.read(lens['clen']))))\n                return\n            if line != boundary:\n                raise ValueError(\n                    \"Expected boundary got: {0}\".format(repr(line)))\n            headers = {}\n            while True:\n                line = read_line()\n                if not line:\n                    break\n                key, value = line.split(b':', 1)\n                headers[key.lower()] = value.strip()\n            name = None\n            if b'content-disposition' in headers:\n                cdis = headers[b'content-disposition']\n                if not cdis.startswith(b'form-data'):\n                    raise ValueError(\n                        \"Unknown content-disposition: {0}\".format(repr(cdis)))\n                name_field = b'name=\"'\n                ix = cdis.find(name_field)\n                if ix >= 0:\n                    name = cdis[ix + len(name_field):]\n                    name = name[:name.index(b'\"')].decode('utf8')\n            ctype = None\n            if b'content-type' in headers:\n                ctype = headers[b'content-type']\n            # b'application/octet-stream': # we treat all files the same\n            if ctype is not None:\n                files[name] = parse_file()\n            else:\n                post[name] = parse_field()", "response": "Reads a single file from a multipart - form - data file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a special request.", "response": "def handle_special(self, send_body, method_str):\n        \"\"\"Handles a dynamic request. If this method returns False the request\n           is interpreted as static file request. Methods can be registered\n           using the `add_TYPE_METHOD_mask` methods of QuickServer.\n\n        Parameters\n        ----------\n        send_body : bool\n            Whether to actually send the result body. This is False if the URL\n            was requested as HEAD.\n\n        method_str : string\n            The method as string: POST, GET, or HEAD.\n\n        Returns\n        -------\n        A bool whether the request was handled. If it was not handled the\n        requested URL is interpreted as static file.\n        \"\"\"\n        ongoing = True\n        if self.server.report_slow_requests:\n            path = self.path\n\n            def do_report():\n                if not ongoing:\n                    return\n                msg(\"request takes longer than expected: \\\"{0} {1}\\\"\",\n                    method_str, path)\n\n            alarm = threading.Timer(5.0, do_report)\n            alarm.start()\n        else:\n            alarm = None\n        try:\n            return self._handle_special(send_body, method_str)\n        finally:\n            if alarm is not None:\n                alarm.cancel()\n            ongoing = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef translate_path(self, orig_path):\n        init_path = orig_path\n        orig_path = urlparse.urlparse(orig_path)[2]\n        needs_redirect = False\n        is_folder = len(orig_path) <= 1 or orig_path[-1] == '/'\n        orig_path = posixpath.normpath(urlparse_unquote(orig_path))\n        if is_folder:\n            orig_path += '/'\n        path = None\n        for (name, fm) in self.server._folder_masks:\n            if not orig_path.startswith(name):\n                continue\n            cur_base = os.path.abspath(os.path.join(self.server.base_path, fm))\n            path = cur_base\n            words = orig_path[len(name):].split('/')\n            words = filter(None, words)\n            for word in words:\n                _drive, word = os.path.splitdrive(word)\n                _head, word = os.path.split(word)\n                if word in (os.curdir, os.pardir):\n                    continue\n                if word.startswith('.'):  # don't ever allow any hidden files\n                    raise PreventDefaultResponse(404, \"File not found\")\n                path = os.path.join(path, word)\n            # make path absolute and check if it exists\n            path = os.path.abspath(path)\n            if os.path.exists(path):\n                break\n        # if pass is still None here the file cannot be found\n        if path is None:\n            # try proxies\n            for (name, pxy) in self.server._folder_proxys:\n                if not orig_path.startswith(name):\n                    continue\n                remain = orig_path[len(name) - 1:]\n                proxy = urlparse.urlparse(pxy)\n                reala = urlparse.urlparse(init_path)\n                pxya = urlparse.urlunparse((\n                    proxy[0],  # scheme\n                    proxy[1],  # netloc\n                    \"{0}{1}\".format(proxy[2], remain),  # path\n                    reala[3],  # params\n                    reala[4],  # query\n                    reala[5],  # fragment\n                ))\n                self.send_to_proxy(pxya)  # raises PreventDefaultResponse\n            msg(\"no matching folder alias: {0}\".format(orig_path))\n            raise PreventDefaultResponse(404, \"File not found\")\n        if os.path.isdir(path):\n            if not is_folder:\n                needs_redirect = True\n            else:\n                for orig_index in [\"index.html\", \"index.htm\"]:\n                    index = os.path.join(path, orig_index)\n                    if os.path.isfile(index):\n                        path = index\n                        break\n        if os.path.isdir(path):\n            # no black-/white-list for directories\n            is_white = True\n        else:\n            # match agains black- and white-list\n            is_white = len(self.server._pattern_white) == 0\n            for pattern in self.server._pattern_white:\n                if fnmatch.fnmatch(path, pattern):\n                    is_white = True\n                    break\n            for pattern in self.server._pattern_black:\n                if fnmatch.fnmatch(path, pattern):\n                    is_white = False\n                    break\n        if not is_white:\n            raise PreventDefaultResponse(404, \"File not found\")\n        # make sure to not accept any trickery to get away from the base path\n        if not path.startswith(cur_base):\n            raise ValueError(\"WARNING: attempt to access {0}\".format(path))\n        # favicon handling\n        if self.server.favicon_everywhere and \\\n                os.path.basename(path) == 'favicon.ico' and \\\n                not os.path.exists(path):\n            for (name, fm) in self.server._folder_masks:\n                fav_base = os.path.abspath(\n                    os.path.join(self.server.base_path, fm))\n                favicon = os.path.join(fav_base, 'favicon.ico')\n                if os.path.exists(favicon):\n                    path = favicon\n                    break\n                if self.server.favicon_fallback is not None and \\\n                        os.path.exists(self.server.favicon_fallback):\n                    path = os.path.join(\n                        self.server.base_path, self.server.favicon_fallback)\n                    break\n        # redirect improper index requests\n        if needs_redirect:\n            self.send_response(301, \"Use index page with slash\")\n            location = urlparse.urlunparse(tuple([\n                seg if ix != 2 else seg + '/'\n                for (ix, seg) in enumerate(urlparse.urlparse(init_path))\n            ]))\n            self.send_header(\"Location\", location)\n            self.end_headers()\n            raise PreventDefaultResponse()\n        # handle ETag caching\n        if self.request_version >= \"HTTP/1.1\" and os.path.isfile(path):\n            e_tag = None\n            with open(path, 'rb') as input_f:\n                e_tag = \"{0:x}\".format(zlib.crc32(input_f.read()) & 0xFFFFFFFF)\n                thread_local.size = input_f.tell()\n            if e_tag is not None:\n                match = _getheader(self.headers, 'if-none-match')\n                if match is not None:\n                    if self.check_cache(e_tag, match):\n                        raise PreventDefaultResponse()\n                self.send_header(\"ETag\", e_tag, end_header=True)\n                self.send_header(\"Cache-Control\",\n                                 \"max-age={0}\".format(self.server.max_age),\n                                 end_header=True)\n        return path", "response": "Translates a path for a static file request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the ETag and sends a cache match response if it matches.", "response": "def check_cache(self, e_tag, match):\n        \"\"\"Checks the ETag and sends a cache match response if it matches.\"\"\"\n        if e_tag != match:\n            return False\n        self.send_response(304)\n        self.send_header(\"ETag\", e_tag)\n        self.send_header(\"Cache-Control\",\n                         \"max-age={0}\".format(self.server.max_age))\n        self.end_headers()\n        thread_local.size = 0\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to send an 500 error after encountering an exception.", "response": "def handle_error(self):\n        \"\"\"Tries to send an 500 error after encountering an exception.\"\"\"\n        if self.server.can_ignore_error(self):\n            return\n        if thread_local.status_code is None:\n            msg(\"ERROR: Cannot send error status code! \" +\n                \"Header already sent!\\n{0}\", traceback.format_exc())\n        else:\n            msg(\"ERROR: Error while processing request:\\n{0}\",\n                traceback.format_exc())\n            try:\n                self.send_error(500, \"Internal Error\")\n            except:  # nopep8\n                if self.server.can_ignore_error(self):\n                    return\n                msg(\"ERROR: Cannot send error status code:\\n{0}\",\n                    traceback.format_exc())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cross_origin_headers(self):\n        if not self.is_cross_origin():\n            return False\n        # we allow everything\n        self.send_header(\"Access-Control-Allow-Methods\",\n                         \"GET, POST, PUT, DELETE, HEAD\")\n        allow_headers = _getheader(self.headers,\n                                   'access-control-request-headers')\n        if allow_headers is not None:\n            self.send_header(\"Access-Control-Allow-Headers\", allow_headers)\n        self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.send_header(\"Access-Control-Allow-Credentials\", \"true\")\n        return allow_headers is not None", "response": "Sends cross origin headers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle an OPTIONS request.", "response": "def do_OPTIONS(self):\n        \"\"\"Handles an OPTIONS request.\"\"\"\n        thread_local.clock_start = get_time()\n        thread_local.status_code = 200\n        thread_local.message = None\n        thread_local.headers = []\n        thread_local.end_headers = []\n        thread_local.size = -1\n        thread_local.method = 'OPTIONS'\n        self.send_response(200)\n        if self.is_cross_origin():\n            no_caching = self.cross_origin_headers()\n            # ten minutes if no custom headers requested\n            self.send_header(\"Access-Control-Max-Age\",\n                             0 if no_caching else 10*60)\n        self.send_header(\"Content-Length\", 0)\n        self.end_headers()\n        thread_local.size = 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a GET request.", "response": "def do_GET(self):\n        \"\"\"Handles a GET request.\"\"\"\n        thread_local.clock_start = get_time()\n        thread_local.status_code = 200\n        thread_local.message = None\n        thread_local.headers = []\n        thread_local.end_headers = []\n        thread_local.size = -1\n        thread_local.method = 'GET'\n        try:\n            self.cross_origin_headers()\n            if self.handle_special(True, 'GET'):\n                return\n            SimpleHTTPRequestHandler.do_GET(self)\n        except PreventDefaultResponse as pdr:\n            if pdr.code:\n                self.send_error(pdr.code, pdr.msg)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except Exception:\n            self.handle_error()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_message(self, format, *args):\n        clock_start = getattr(thread_local, 'clock_start', None)\n        thread_local.clock_start = None\n        timing = self.log_elapsed_time_string(\n            get_time() - clock_start) if clock_start is not None else ''\n        msg(\"%s[%s] %s\" % (\n            timing + ' ' if len(timing) else '', self.log_date_time_string(),\n            format % args))", "response": "Logs a message. All messages get prefixed with '[SERVER]'\n           and the arguments act like `format`."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs the current request.", "response": "def log_request(self, code='-', size='-'):\n        \"\"\"Logs the current request.\"\"\"\n        print_size = getattr(thread_local, 'size', -1)\n        if size != '-':\n            size_str = ' (%s)' % size\n        elif print_size >= 0:\n            size_str = self.log_size_string(print_size) + ' '\n        else:\n            size_str = ''\n        if not self.server.suppress_noise or (code != 200 and code != 304):\n            self.log_message(\n                '%s\"%s\" %s', size_str, self.requestline, str(code))\n        if print_size >= 0:\n            thread_local.size = -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_request(self, request, client_address):\n        try:\n            self.finish_request(request, client_address)\n        except Exception:\n            self.handle_error(request, client_address)\n        finally:\n            self.shutdown_request(request)", "response": "Actually processes the request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_request(self, request, client_address):\n        if not self._parallel:\n            self._process_request(request, client_address)\n            return\n        t = self._thread_factory(\n            target=self._process_request, args=(request, client_address))\n        t.daemon = True\n        t.start()", "response": "Processes the request by delegating to _process_request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_file_patterns(self, patterns, blacklist):\n        bl = self._pattern_black if blacklist else self._pattern_white\n        for pattern in patterns:\n            bl.append(pattern)", "response": "Adds a list of file patterns to either the black - list or white - list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a mask that maps to a given folder relative to base_path.", "response": "def bind_path(self, name, folder):\n        \"\"\"Adds a mask that maps to a given folder relative to `base_path`.\"\"\"\n        if not len(name) or name[0] != '/' or name[-1] != '/':\n            raise ValueError(\n                \"name must start and end with '/': {0}\".format(name))\n        self._folder_masks.insert(0, (name, folder))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a fallback for a given folder relative to base_path.", "response": "def bind_path_fallback(self, name, folder):\n        \"\"\"Adds a fallback for a given folder relative to `base_path`.\"\"\"\n        if not len(name) or name[0] != '/' or name[-1] != '/':\n            raise ValueError(\n                \"name must start and end with '/': {0}\".format(name))\n        self._folder_masks.append((name, folder))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a mask that maps to a given proxy.", "response": "def bind_proxy(self, name, proxy):\n        \"\"\"Adds a mask that maps to a given proxy.\"\"\"\n        if not len(name) or name[0] != '/' or name[-1] != '/':\n            raise ValueError(\n                \"name must start and end with '/': {0}\".format(name))\n        self._folder_proxys.insert(0, (name, proxy))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_cmd_method(self, name, method, argc=None, complete=None):\n        if ' ' in name:\n            raise ValueError(\"' ' cannot be in command name {0}\".format(name))\n        self._cmd_methods[name] = method\n        self._cmd_argc[name] = argc\n        self._cmd_complete[name] = complete", "response": "Adds a command to the command line interface loop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a raw file mask for dynamic requests.", "response": "def _add_file_mask(self, start, method_str, method):\n        \"\"\"Adds a raw file mask for dynamic requests.\n\n        Parameters\n        ----------\n        start : string\n            The URL prefix that must be matched to perform this request.\n\n        method_str : string\n            The HTTP method for which to trigger the request.\n\n        method : function(esrh, args)\n            The function to execute to perform the request. The function takes\n            two arguments. esrh is the QuickServerRequestHandler object that\n            called the function. args is a map containing the arguments to the\n            request (i.e., the rest of the URL as path segment array 'paths', a\n            map of all query fields / flags 'query', the fragment string\n            'fragment', and if the method was a POST the JSON form content\n            'post'). The function must return a file object containing the\n            response (preferably BytesIO). If the result is None no response\n            body is sent. In this case make sure to send an appropriate error\n            code.\n        \"\"\"\n        fm = self._f_mask.get(method_str, [])\n        fm.append((start, method))\n        fm.sort(key=lambda k: len(k[0]), reverse=True)\n        self._f_mask[method_str] = fm\n        self._f_argc[method_str] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_json_mask(self, start, method_str, json_producer):\n        def send_json(drh, rem_path):\n            obj = json_producer(drh, rem_path)\n            if not isinstance(obj, Response):\n                obj = Response(obj)\n            ctype = obj.get_ctype(\"application/json\")\n            code = obj.code\n            obj = obj.response\n            if obj is None:\n                drh.send_error(404, \"File not found\")\n                return None\n            f = BytesIO()\n            json_str = json_dumps(obj)\n            if isinstance(json_str, (str, unicode)):\n                try:\n                    json_str = json_str.decode('utf8')\n                except AttributeError:\n                    pass\n                json_str = json_str.encode('utf8')\n            f.write(json_str)\n            f.flush()\n            size = f.tell()\n            f.seek(0)\n            # handle ETag caching\n            if drh.request_version >= \"HTTP/1.1\":\n                e_tag = \"{0:x}\".format(zlib.crc32(f.read()) & 0xFFFFFFFF)\n                f.seek(0)\n                match = _getheader(drh.headers, 'if-none-match')\n                if match is not None:\n                    if drh.check_cache(e_tag, match):\n                        f.close()\n                        return None\n                drh.send_header(\"ETag\", e_tag, end_header=True)\n                drh.send_header(\"Cache-Control\",\n                                \"max-age={0}\".format(self.max_age),\n                                end_header=True)\n            drh.send_response(code)\n            drh.send_header(\"Content-Type\", ctype)\n            drh.send_header(\"Content-Length\", size)\n            drh.end_headers()\n            return f\n        self._add_file_mask(start, method_str, send_json)", "response": "Adds a handler that produces a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a handler that produces a plain text response.", "response": "def add_text_mask(self, start, method_str, text_producer):\n        \"\"\"Adds a handler that produces a plain text response.\n\n        Parameters\n        ----------\n        start : string\n            The URL prefix that must be matched to perform this request.\n\n        method_str : string\n            The HTTP method for which to trigger the request.\n\n        text_producer : function(esrh, args)\n            A function returning a string. The function takes two arguments.\n            esrh is the QuickServerRequestHandler object that called the\n            function. args is a map containing the arguments to the request\n            (i.e., the rest of the URL as path segment array 'paths', a map of\n            all query fields / flags 'query', the fragment string 'fragment',\n            and if the method was a POST the JSON form content 'post'). If the\n            result is None a 404 error is sent.\n        \"\"\"\n        def send_text(drh, rem_path):\n            text = text_producer(drh, rem_path)\n            if not isinstance(text, Response):\n                text = Response(text)\n            ctype = text.get_ctype(\"text/plain\")\n            code = text.code\n            text = text.response\n            if text is None:\n                drh.send_error(404, \"File not found\")\n                return None\n            f = BytesIO()\n            if isinstance(text, (str, unicode)):\n                try:\n                    text = text.decode('utf8')\n                except AttributeError:\n                    pass\n                text = text.encode('utf8')\n            f.write(text)\n            f.flush()\n            size = f.tell()\n            f.seek(0)\n            # handle ETag caching\n            if drh.request_version >= \"HTTP/1.1\":\n                e_tag = \"{0:x}\".format(zlib.crc32(f.read()) & 0xFFFFFFFF)\n                f.seek(0)\n                match = _getheader(drh.headers, 'if-none-match')\n                if match is not None:\n                    if drh.check_cache(e_tag, match):\n                        f.close()\n                        return None\n                drh.send_header(\"ETag\", e_tag, end_header=True)\n                drh.send_header(\"Cache-Control\",\n                                \"max-age={0}\".format(self.max_age),\n                                end_header=True)\n            drh.send_response(code)\n            drh.send_header(\"Content-Type\", ctype)\n            drh.send_header(\"Content-Length\", size)\n            drh.end_headers()\n            return f\n        self._add_file_mask(start, method_str, send_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_special_file(self, mask, path, from_quick_server, ctype=None):\n        full_path = path if not from_quick_server else os.path.join(\n            os.path.dirname(__file__), path)\n\n        def read_file(_req, _args):\n            with open(full_path, 'rb') as f_out:\n                return Response(f_out.read(), ctype=ctype)\n\n        self.add_text_get_mask(mask, read_file)\n        self.set_file_argc(mask, 0)", "response": "Adds a special file that might have a different actual path than the original path than the original path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmirroring a file to a different location.", "response": "def mirror_file(self, path_to, path_from, from_quick_server=True):\n        \"\"\"Mirrors a file to a different location. Each time the file changes\n           while the process is running it will be copied to 'path_to',\n           overwriting the destination.\n\n        Parameters\n        ----------\n        path_to : string\n            The mirror destination.\n\n        path_from : string\n            The mirror origin.\n\n        from_quick_server : bool\n            If set the origin path is relative to *this* script otherwise it is\n            relative to the process.\n        \"\"\"\n        full_path = path_from if not from_quick_server else os.path.join(\n            os.path.dirname(__file__), path_from)\n        if self._mirror is None:\n            if not self._symlink_mirror(path_to, full_path, init=True):\n                self._poll_mirror(path_to, full_path, init=True)\n            return\n        impl = self._mirror[\"impl\"]\n        if impl == \"symlink\":\n            self._symlink_mirror(path_to, full_path, init=False)\n        elif impl == \"poll\":\n            self._poll_mirror(path_to, full_path, init=False)\n        else:\n            raise ValueError(\"unknown mirror implementation: {0}\".format(impl))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef link_empty_favicon_fallback(self):\n        self.favicon_fallback = os.path.join(\n            os.path.dirname(__file__), 'favicon.ico')", "response": "Links the empty favicon as default favicon."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_worker(self, mask, cache_id=None, cache_method=\"string\",\n                    cache_section=\"www\"):\n        \"\"\"A function annotation that adds a worker request. A worker request\n           is a POST request that is computed asynchronously. That is, the\n           actual task is performed in a different thread and the network\n           request returns immediately. The client side uses polling to fetch\n           the result and can also cancel the task. The worker javascript\n           client side must be linked and used for accessing the request.\n\n        Parameters\n        ----------\n        mask : string\n            The URL that must be matched to perform this request.\n\n        cache_id : function(args) or None\n            Optional function for caching the result. If set the worker must be\n            idempotent. Requires a `cache` object for the server. The function\n            needs to return an object constructed from the function arguments\n            to uniquely identify the result. Results are cached verbatim.\n\n        cache_method : string or None\n            Optional cache method string. Gets passed to get_hnd() of the\n            cache. Defaults to \"string\" which requires a JSON serializable\n            cache_id.\n\n        cache_section : string or None\n            Optional cache section string. Gets passed to get_hnd() of the\n            cache. Defaults to \"www\".\n\n        fun : function(args); (The annotated function)\n            A function returning a (JSON-able) object. The function takes one\n            argument which is the dictionary containing the payload from the\n            client side. If the result is None a 404 error is sent.\n        \"\"\"\n        use_cache = cache_id is not None\n\n        def wrapper(fun):\n            lock = threading.RLock()\n            tasks = {}\n            cargo = {}\n            cargo_cleaner = [None]\n\n            def is_done(cur_key):\n                with lock:\n                    if cur_key not in tasks:\n                        return True\n                    if \"running\" not in tasks[cur_key]:\n                        return False\n                    return not tasks[cur_key][\"running\"]\n\n            def start_cargo_cleaner():\n\n                def get_next_cargo():\n                    with lock:\n                        next_ttl = None\n                        for value in cargo.values():\n                            ttl, _ = value\n                            if next_ttl is None or ttl < next_ttl:\n                                next_ttl = ttl\n                        return next_ttl\n\n                def clean_for(timestamp):\n                    with lock:\n                        keys = []\n                        for (key, value) in cargo.items():\n                            ttl, _ = value\n                            if ttl > timestamp:\n                                continue\n                            keys.append(key)\n                        for k in keys:\n                            cargo.pop(k)\n                            msg(\"purged cargo that was never read ({0})\", k)\n\n                def remove_cleaner():\n                    with lock:\n                        if get_next_cargo() is not None:\n                            return False\n                        cargo_cleaner[0] = None\n                        return True\n\n                def clean():\n                    while True:\n                        next_ttl = get_next_cargo()\n                        if next_ttl is None:\n                            if remove_cleaner():\n                                break\n                            else:\n                                continue\n                        time_until = next_ttl - time.time()\n                        if time_until > 0:\n                            time.sleep(time_until)\n                        clean_for(time.time())\n\n                with lock:\n                    if cargo_cleaner[0] is not None:\n                        return\n                    cleaner = self._thread_factory(\n                        target=clean,\n                        name=\"{0}-Cargo-Cleaner\".format(self.__class__))\n                    cleaner.daemon = True\n                    cargo_cleaner[0] = cleaner\n                    cleaner.start()\n\n            def add_cargo(content):\n                with lock:\n                    mcs = self.max_chunk_size\n                    if mcs < 1:\n                        raise ValueError(\"invalid chunk size: {0}\".format(mcs))\n                    ttl = time.time() + 10 * 60  # 10 minutes\n                    chunks = []\n                    while len(content) > 0:\n                        chunk = content[:mcs]\n                        content = content[mcs:]\n                        cur_key = get_key()\n                        cargo[cur_key] = (ttl, chunk)\n                        chunks.append(cur_key)\n                    start_cargo_cleaner()\n                    return chunks\n\n            def remove_cargo(cur_key):\n                with lock:\n                    _, result = cargo.pop(cur_key)\n                    return result\n\n            def remove_worker(cur_key):\n                with lock:\n                    task = tasks.pop(cur_key, None)\n                    if task is None:\n                        err_msg = \"Task {0} not found!\".format(cur_key)\n                        return None, (ValueError(err_msg), None)\n                    if task[\"running\"]:\n                        th = task[\"thread\"]\n                        if th.is_alive():\n                            # kill the thread\n                            tid = None\n                            for tk, tobj in threading._active.items():\n                                if tobj is th:\n                                    tid = tk\n                                    break\n                            if tid is not None:\n                                papi = ctypes.pythonapi\n                                pts_sae = papi.PyThreadState_SetAsyncExc\n                                res = pts_sae(ctypes.c_long(tid),\n                                              ctypes.py_object(WorkerDeath))\n                                if res == 0:\n                                    # invalid thread id -- the thread might\n                                    # be done already\n                                    msg(\"invalid thread id for \" +\n                                        \"killing worker {0}\", cur_key)\n                                elif res != 1:\n                                    # roll back\n                                    pts_sae(ctypes.c_long(tid), None)\n                                    msg(\"killed too many ({0}) workers? {1}\",\n                                        res, cur_key)\n                                else:\n                                    if self.verbose_workers:\n                                        msg(\"killed worker {0}\", cur_key)\n                        err_msg = \"Task {0} is still running!\".format(cur_key)\n                        return None, (ValueError(err_msg), None)\n                    return task[\"result\"], task[\"exception\"]\n\n            def start_worker(args, cur_key, get_thread):\n                try:\n                    with lock:\n                        task = {\n                            \"running\": True,\n                            \"result\": None,\n                            \"exception\": None,\n                            \"thread\": get_thread(),\n                        }\n                        tasks[cur_key] = task\n                    if use_cache:\n                        cache_obj = cache_id(args)\n                        if cache_obj is not None and self.cache is not None:\n                            with self.cache.get_hnd(\n                                    cache_obj,\n                                    section=cache_section,\n                                    method=cache_method) as hnd:\n                                if hnd.has():\n                                    result = hnd.read()\n                                else:\n                                    result = hnd.write(json_dumps(fun(args)))\n                        else:\n                            result = json_dumps(fun(args))\n                    else:\n                        result = json_dumps(fun(args))\n                    with lock:\n                        task[\"running\"] = False\n                        task[\"result\"] = result\n                except (KeyboardInterrupt, SystemExit):\n                    raise\n                except Exception as e:\n                    with lock:\n                        task[\"running\"] = False\n                        task[\"exception\"] = (e, traceback.format_exc())\n                    return\n                # make sure the result does not get stored forever\n                try:\n                    # remove 2 minutes after not reading the result\n                    time.sleep(120)\n                finally:\n                    _result, err = remove_worker(cur_key)\n                    if err is not None:\n                        e, tb = err\n                        if tb is not None:\n                            msg(\"Error in purged worker for {0}: {1}\\n{2}\",\n                                cur_key, e, tb)\n                        return\n                    msg(\"purged result that was never read ({0})\", cur_key)\n\n            def get_key():\n                with lock:\n                    crc32 = zlib.crc32(repr(get_time()).encode('utf8'))\n                    cur_key = int(crc32 & 0xFFFFFFFF)\n                    while cur_key in tasks or cur_key in cargo:\n                        key = int(cur_key + 1)\n                        if key == cur_key:\n                            key = 0\n                        cur_key = key\n                    return cur_key\n\n            def reserve_worker():\n                with lock:\n                    cur_key = get_key()\n                    tasks[cur_key] = {}  # put marker\n                    return cur_key\n\n            def run_worker(req, args):\n                post = args[\"post\"]\n                try:\n                    action = post[\"action\"]\n                    cur_key = None\n                    if action == \"stop\":\n                        cur_key = post[\"token\"]\n                        remove_worker(cur_key)  # throw away the result\n                        return {\n                            \"token\": cur_key,\n                            \"done\": True,\n                            \"result\": None,\n                            \"continue\": False,\n                        }\n                    if action == \"start\":\n                        cur_key = reserve_worker()\n                        inner_post = post.get(\"payload\", {})\n                        th = []\n                        wname = \"{0}-Worker-{1}\".format(self.__class__,\n                                                        cur_key)\n                        worker = self._thread_factory(\n                            target=start_worker,\n                            name=wname,\n                            args=(inner_post, cur_key, lambda: th[0]))\n                        th.append(worker)\n                        worker.start()\n                        # give fast tasks a way to immediately return results\n                        time.sleep(0.1)\n                    if action == \"cargo\":\n                        cur_key = post[\"token\"]\n                        result = remove_cargo(cur_key)\n                        return {\n                            \"token\": cur_key,\n                            \"result\": result,\n                        }\n                    if action == \"get\":\n                        cur_key = post[\"token\"]\n                    if cur_key is None:\n                        raise ValueError(\"invalid action: {0}\".format(action))\n                    if is_done(cur_key):\n                        result, exception = remove_worker(cur_key)\n                        if exception is not None:\n                            e, tb = exception\n                            if tb is None:\n                                # token does not exist anymore\n                                return {\n                                    \"token\": cur_key,\n                                    \"done\": False,\n                                    \"result\": None,\n                                    \"continue\": False,\n                                }\n                            if isinstance(e, PreventDefaultResponse):\n                                raise e\n                            msg(\"Error in worker for {0}: {1}\\n{2}\",\n                                cur_key, e, tb)\n                            raise PreventDefaultResponse(500, \"worker error\")\n                        if len(result) > self.max_chunk_size:\n                            cargo_keys = add_cargo(result)\n                            return {\n                                \"token\": cur_key,\n                                \"done\": True,\n                                \"result\": cargo_keys,\n                                \"continue\": True,\n                            }\n                        return {\n                            \"token\": cur_key,\n                            \"done\": True,\n                            \"result\": result,\n                            \"continue\": False,\n                        }\n                    return {\n                        \"token\": cur_key,\n                        \"done\": False,\n                        \"result\": None,\n                        \"continue\": True,\n                    }\n                except:  # nopep8\n                    msg(\"Error processing worker command: {0}\", post)\n                    raise\n\n            self.add_json_post_mask(mask, run_worker)\n            self.set_file_argc(mask, 0)\n            return fun\n        return wrapper", "response": "A worker function that adds a request to the network and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_token_obj(self, token, expire=_token_default):\n        if expire == _token_default:\n            expire = self.get_default_token_expiration()\n        now = get_time()\n        until = now + expire if expire is not None else None\n        with self._token_lock:\n            # _token_timings is keys sorted by time\n            first_valid = None\n            for (pos, k) in enumerate(self._token_timings):\n                t = self._token_map[k][0]\n                if t is None or t > now:\n                    first_valid = pos\n                    break\n            if first_valid is None:\n                self._token_map = {}\n                self._token_timings = []\n            else:\n                for k in self._token_timings[:first_valid]:\n                    del self._token_map[k]\n                self._token_timings = self._token_timings[first_valid:]\n            if until is None or until > now:\n                if token not in self._token_map:\n                    self._token_map[token] = (until, {})\n                    self._token_timings.append(token)\n                else:\n                    self._token_map[token] = (until, self._token_map[token][1])\n                self._token_timings.sort(key=lambda k: (\n                    1 if self._token_map[k][0] is None else 0,\n                    self._token_map[k][0]\n                ))\n                return self._token_map[token][1]\n            else:\n                if token in self._token_map:\n                    self._token_timings = [\n                        k for k in self._token_timings if k != token\n                    ]\n                    del self._token_map[token]\n                return {}", "response": "Returns or creates the object associated with the given token."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a single server command.", "response": "def handle_cmd(self, cmd):\n        \"\"\"Handles a single server command.\"\"\"\n        cmd = cmd.strip()\n        segments = []\n        for s in cmd.split():\n            # remove bash-like comments\n            if s.startswith('#'):\n                break\n            # TODO implement escape sequences (also for \\#)\n            segments.append(s)\n        args = []\n        if not len(segments):\n            return\n        # process more specific commands first\n        while segments:\n            cur_cmd = \"_\".join(segments)\n            if cur_cmd in self._cmd_methods:\n                argc = self._cmd_argc[cur_cmd]\n                if argc is not None and len(args) != argc:\n                    msg('command {0} expects {1} argument(s), got {2}',\n                        \" \".join(segments), argc, len(args))\n                    return\n                self._cmd_methods[cur_cmd](args)\n                return\n            args.insert(0, segments.pop())\n        # invalid command\n        prefix = '_'.join(args) + '_'\n        matches = filter(\n            lambda cmd: cmd.startswith(prefix), self._cmd_methods.keys())\n        candidates = set([])\n        for m in matches:\n            if len(m) <= len(prefix):\n                continue\n            m = m[len(prefix):]\n            if '_' in m:\n                m = m[:m.index('_')]\n            candidates.add(m)\n        if len(candidates):\n            msg('command \"{0}\" needs more arguments:', ' '.join(args))\n            for c in candidates:\n                msg('    {0}', c)\n        else:\n            msg('command \"{0}\" invalid; type ' +\n                'help or use <TAB> for a list of commands',\n                ' '.join(args))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the command line loop.", "response": "def start_cmd_loop(self):\n        \"\"\"Starts the command line loop. This method is called automatically by\n           the serve_forever method. The function call is idempotent so you can\n           call the method before or after that without worrying or extra\n           side-effect. An EOF terminates the loop but does not close the\n           server. A `KeyboardInterrupt` terminates the server as well.\n        \"\"\"\n        # thread-safe check if the loop is already running\n        with self._cmd_lock:\n            cmd_start = self._cmd_start\n            self._cmd_start = True\n\n        if cmd_start:\n            return\n\n        cmd_state = {\n            'suggestions': [],\n            'clean_up_lock': threading.Lock(),\n            'clean': False,\n            'line': '',\n        }\n\n        # setup internal commands (no replace)\n        @self.cmd(argc=0, no_replace=True)\n        def help(args):  # pylint: disable=unused-variable\n            msg('available commands:')\n            for key in self._cmd_methods.keys():\n                msg('    {0}', key.replace('_', ' '))\n\n        @self.cmd(argc=0, no_replace=True)\n        def restart(args):  # pylint: disable=unused-variable\n            global _do_restart\n            _do_restart = True\n            self.done = True\n\n        @self.cmd(argc=0, no_replace=True)\n        def quit(args):  # pylint: disable=unused-variable\n            self.done = True\n\n        # loading the history\n        hfile = self.history_file\n        try:\n            readline.read_history_file(hfile)\n        except IOError:\n            pass\n\n        # set up command completion\n        def complete(text, state):\n            if state == 0:\n                origline = readline.get_line_buffer()\n                line = origline.lstrip()\n                stripped = len(origline) - len(line)\n                begidx = readline.get_begidx() - stripped\n                endidx = readline.get_endidx() - stripped\n                prefix = line[:begidx].replace(' ', '_')\n\n                def match_cmd(cmd):\n                    return cmd.startswith(prefix) and \\\n                           cmd[begidx:].startswith(text)\n\n                matches = filter(match_cmd, self._cmd_methods.keys())\n\n                def _endidx(m):\n                    eix = m.find('_', endidx)\n                    return eix + 1 if eix >= 0 else len(m)\n\n                candidates = [\n                    m[begidx:_endidx(m)].replace('_', ' ') for m in matches\n                ]\n                rest_cmd = line[:begidx].split()\n                args = []\n                while rest_cmd:\n                    cur_cmd = '_'.join(rest_cmd)\n                    if cur_cmd in self._cmd_complete and \\\n                            self._cmd_complete[cur_cmd] is not None:\n                        cc = self._cmd_complete[cur_cmd](args, text)\n                        if cc is not None:\n                            candidates.extend(cc)\n                    args.insert(0, rest_cmd.pop())\n                cmd_state['suggestions'] = sorted(set(candidates))\n                cmd_state['line'] = line\n            suggestions = cmd_state['suggestions']\n            if len(suggestions) == 1 and text == suggestions[0]:\n                probe_cmd = cmd_state['line'].replace(' ', '_')\n                if probe_cmd in self._cmd_argc and \\\n                        self._cmd_argc[probe_cmd] != 0:\n                    cmd_state['line'] = \"\"\n                    return text + ' '\n                return None\n            if state < len(suggestions):\n                return suggestions[state]\n            return None\n\n        old_completer = readline.get_completer()\n        readline.set_completer(complete)\n        # be mac compatible\n        if readline.__doc__ is not None and 'libedit' in readline.__doc__:\n            readline.parse_and_bind(\"bind ^I rl_complete\")\n        else:\n            readline.parse_and_bind(\"tab: complete\")\n\n        # remember to clean up before exit -- the call must be idempotent!\n        def clean_up():\n            with cmd_state['clean_up_lock']:\n                clean = cmd_state['clean']\n                cmd_state['clean'] = True\n\n            if clean:\n                return\n\n            readline.write_history_file(hfile)\n            readline.set_completer(old_completer)\n        atexit.register(clean_up)\n        self._clean_up_call = clean_up\n\n        def cmd_loop():\n            close = False\n            kill = True\n            try:\n                while not self.done and not close and not self.no_command_loop:\n                    line = \"\"\n                    try:\n                        try:\n                            line = input(self.prompt)\n                        except IOError as e:\n                            if e.errno == errno.EBADF:\n                                close = True\n                                kill = False\n                            elif (e.errno == errno.EWOULDBLOCK or\n                                  e.errno == errno.EAGAIN or\n                                  e.errno == errno.EINTR):\n                                continue\n                            else:\n                                raise e\n                        self.handle_cmd(line)\n                    except EOFError:\n                        close = True\n                        kill = False\n                    except KeyboardInterrupt:\n                        close = True\n                    except Exception:\n                        msg(\"{0}\", traceback.format_exc())\n                        msg(\"^ exception executing command {0} ^\", line)\n            finally:\n                if kill:\n                    self.done = True\n                else:\n                    msg(\"no command loop - use CTRL-C to terminate\")\n                    self.no_command_loop = True\n                clean_up()\n\n        if not self.no_command_loop:\n            t = self._thread_factory(target=cmd_loop)\n            t.daemon = True\n            t.start()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling an HTTP request.", "response": "def handle_request(self):\n        \"\"\"Handles an HTTP request.The actual HTTP request is handled using a\n           different thread.\n        \"\"\"\n        timeout = self.socket.gettimeout()\n        if timeout is None:\n            timeout = self.timeout\n        elif self.timeout is not None:\n            timeout = min(timeout, self.timeout)\n        ctime = get_time()\n        done_req = False\n        shutdown_latency = self.shutdown_latency\n        if timeout is not None:\n            shutdown_latency = min(shutdown_latency, timeout) \\\n                if shutdown_latency is not None else timeout\n        while not (self.done or done_req) and (timeout is None or\n                                               timeout == 0 or\n                                               (get_time() - ctime) < timeout):\n            try:\n                fd_sets = select.select([self], [], [], shutdown_latency)\n            except (OSError, select.error) as e:\n                if e.args[0] != errno.EINTR:\n                    raise\n                # treat EINTR as shutdown_latency timeout\n                fd_sets = [[], [], []]\n            for _fd in fd_sets[0]:\n                done_req = True\n                self._handle_request_noblock()\n            if timeout == 0:\n                break\n        if not (self.done or done_req):\n            # don't handle timeouts if we should shut down the server instead\n            self.handle_timeout()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serve_forever(self):\n        self.start_cmd_loop()\n        try:\n            while not self.done:\n                self.handle_request()\n        except KeyboardInterrupt:\n            # clean error output if log file is STD_ERR\n            if log_file == sys.stderr:\n                log_file.write(\"\\n\")\n        finally:\n            if self._clean_up_call is not None:\n                self._clean_up_call()\n            self.done = True", "response": "Starts the server handling commands and HTTP requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef can_ignore_error(self, reqhnd=None):\n        value = sys.exc_info()[1]\n        try:\n            if isinstance(value, BrokenPipeError) or \\\n                    isinstance(value, ConnectionResetError):\n                return True\n        except NameError:\n            pass\n        if not self.done:\n            return False\n        if not isinstance(value, socket.error):\n            return False\n        need_close = value.errno == 9\n        if need_close and reqhnd is not None:\n            reqhnd.close_connection = 1\n        return need_close", "response": "Tests if the error is worth reporting."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_error(self, request, client_address):\n        if self.can_ignore_error():\n            return\n        thread = threading.current_thread()\n        msg(\"Error in request ({0}): {1} in {2}\\n{3}\",\n            client_address, repr(request), thread.name, traceback.format_exc())", "response": "Handle an error gracefully."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _findRow(subNo, model):\n    items = model.findItems(str(subNo))\n    if len(items) == 0:\n        return None\n    if len(items) > 1:\n        raise IndexError(\"Too many items with sub number %s\" % subNo)\n    return items[0].row()", "response": "Finds a row in a given model which has a column with a given\n    number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _subtitlesAdded(self, path, subNos):\n        def action(current, count, model, row):\n            _setSubNo(current + count, model, row)\n\n        def count(current, nos):\n            ret = 0\n            for no in nos:\n                if current >= no:\n                    ret += 1\n                    # consider: current = 0, nos = [0, 1, 2, 3]\n                    # in that case, current should be prepended by all nos\n                    current += 1\n            return ret\n\n        self._changeSubNos(path, subNos, count, action)", "response": "When subtitle is added all syncPoints greater than a new\n        are incremented."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _subtitlesRemoved(self, path, subNos):\n        def action(current, count, model, row):\n            if count.equal > 0:\n                model.removeRow(row)\n            else:\n                _setSubNo(current - count.greater_equal, model, row)\n\n        def count(current, nos):\n            return _GtEqCount(current, nos)\n\n        self._changeSubNos(path, subNos, count, action)", "response": "When subtitle is removed all syncPoints greater than removed\n        subtitle are decremented. SyncPoint equal to removed\n        subtitle is also removed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _changeSubNos(self, path, subNos, count, action, reverse=False):\n        model = self._models.get(path)\n        if model is None:\n            return\n\n        syncPoints = _syncPoints(model)\n        syncSubNos = [p.subNo for p in syncPoints]\n        syncSubNos.sort()\n\n        if len(syncSubNos) == 0:\n            return\n\n        for current in syncSubNos:\n            row = _findRow(current, model)\n            action(current, count(current, subNos), model, row)", "response": "Implementation of subs add removal handling."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds fieldnames in Polarion exported csv file.", "response": "def _get_csv_fieldnames(csv_reader):\n    \"\"\"Finds fieldnames in Polarion exported csv file.\"\"\"\n    fieldnames = []\n    for row in csv_reader:\n        for col in row:\n            field = (\n                col.strip()\n                .replace('\"', \"\")\n                .replace(\" \", \"\")\n                .replace(\"(\", \"\")\n                .replace(\")\", \"\")\n                .lower()\n            )\n            fieldnames.append(field)\n        if \"id\" in fieldnames:\n            break\n        else:\n            # this is not a row with fieldnames\n            del fieldnames[:]\n    if not fieldnames:\n        return None\n    # remove trailing unannotated fields\n    while True:\n        field = fieldnames.pop()\n        if field:\n            fieldnames.append(field)\n            break\n    # name unannotated fields\n    suffix = 1\n    for index, field in enumerate(fieldnames):\n        if not field:\n            fieldnames[index] = \"field{}\".format(suffix)\n            suffix += 1\n\n    return fieldnames"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping data to fieldnames.", "response": "def _get_results(csv_reader, fieldnames):\n    \"\"\"Maps data to fieldnames.\n\n    The reader needs to be at position after fieldnames, before the results data.\n    \"\"\"\n    fieldnames_count = len(fieldnames)\n    results = []\n    for row in csv_reader:\n        for col in row:\n            if col:\n                break\n        else:\n            # empty row, skip it\n            continue\n        record = OrderedDict(list(zip(fieldnames, row)))\n        # skip rows that were already exported\n        if record.get(\"exported\") == \"yes\":\n            continue\n        row_len = len(row)\n        if fieldnames_count > row_len:\n            for key in fieldnames[row_len:]:\n                record[key] = None\n        results.append(record)\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the content of the Polarion exported csv file and returns imported data.", "response": "def get_imported_data(csv_file, **kwargs):\n    \"\"\"Reads the content of the Polarion exported csv file and returns imported data.\"\"\"\n    open_args = []\n    open_kwargs = {}\n    try:\n        # pylint: disable=pointless-statement\n        unicode\n        open_args.append(\"rb\")\n    except NameError:\n        open_kwargs[\"encoding\"] = \"utf-8\"\n    with open(os.path.expanduser(csv_file), *open_args, **open_kwargs) as input_file:\n        reader = _get_csv_reader(input_file)\n\n        fieldnames = _get_csv_fieldnames(reader)\n        if not fieldnames:\n            raise Dump2PolarionException(\n                \"Cannot find field names in CSV file '{}'\".format(csv_file)\n            )\n\n        results = _get_results(reader, fieldnames)\n        if not results:\n            raise Dump2PolarionException(\"No results read from CSV file '{}'\".format(csv_file))\n\n        testrun = _get_testrun_from_csv(input_file, reader)\n\n    return xunit_exporter.ImportedData(results=results, testrun=testrun)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_csv(csv_file, **kwargs):\n    records = get_imported_data(csv_file, **kwargs)\n    _check_required_columns(csv_file, records.results)\n    return records", "response": "Imports data and checks that all required columns are there."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config(filename):\n\n    if filename is None:\n        filename = ''\n\n    abs_filename = os.path.join(os.getcwd(), filename)\n\n    global FILE\n\n    # find the config file\n    if os.path.isfile(filename):\n        FILE = filename\n    elif os.path.isfile(abs_filename):\n        FILE = abs_filename\n    elif os.path.isfile(FILE):\n        pass\n    else:\n        if os.path.dirname(filename):\n            file_not_found = filename\n        else:\n            file_not_found = abs_filename\n        file_not_found_message(file_not_found)\n\n    # load config\n    init(FILE)", "response": "Load data from config file to cfg that can be accessed by get set\n    afterwards."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading config file and initialize the object", "response": "def init(FILE):\n    \"\"\"\n    Read config file\n\n    :param FILE: Absolute path to config file (incl. filename)\n    :type FILE: str\n    \"\"\"\n    try:\n        cfg.read(FILE)\n        global _loaded\n        _loaded = True\n    except:\n        file_not_found_message(FILE)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value of a given key of a given section of the main config file.", "response": "def get(section, key):\n    \"\"\"\n    returns the value of a given key of a given section of the main\n    config file.\n\n    :param section: the section.\n    :type section: str.\n    :param key: the key.\n    :type key: str.\n\n    :returns: the value which will be casted to float, int or boolean.\n    if no cast is successfull, the raw string will be returned.\n\n    \"\"\"\n    # FILE = 'config_misc'\n    if not _loaded:\n        init(FILE)\n    try:\n        return cfg.getfloat(section, key)\n    except Exception:\n        try:\n            return cfg.getint(section, key)\n        except:\n            try:\n                return cfg.getboolean(section, key)\n            except:\n                return cfg.get(section, key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompress and minify assets for a single item", "response": "def bundle_assets():\n    \"\"\"Compress and minify assets\"\"\"\n    YUI_COMPRESSOR_BIN = current_app.config.get('YUI_COMPRESSOR_BIN')\n\n    path_to_jar = YUI_COMPRESSOR_BIN\n\n    tmp_files = []\n\n    def get_path(item):\n        \"\"\"Get the static path of an item\"\"\"\n        return os.path.join(current_app.static_folder, item)\n\n    def fix_urls(filename, compressed_file):\n        \"\"\"Fix relative paths in URLs for bundles\"\"\"\n        print(\"Fixing URL's in %s\" % filename)\n\n        def fix_urls_regex(url, relpath):\n            \"\"\"Callback to fix relative path\"\"\"\n            url = url.group(1).strip('\"\\'')\n            if url.startswith(('data:', 'http:', 'https:', 'attr(')):\n                return url\n            else:\n                url = os.path.relpath(url, relpath)\n                return 'url(%s)' % url\n\n        css_content = ''\n        with open(get_path(filename), 'r') as css_in:\n            css_content = css_in.read()\n\n        relpath = os.path.relpath(os.path.dirname(compressed_file),\n                                  get_path(os.path.dirname(filename)))\n\n        parse = lambda url: fix_urls_regex(url, relpath)\n\n        css_parsed = re.sub('url\\(([^)]*?)\\)', parse, css_content)\n\n        out_file = get_path(os.path.join(current_app.config.get('BUNDLES_DIR'),\n                                         'tmp', '%s.tmp' % filename))\n\n        if not os.path.exists(os.path.dirname(out_file)):\n            os.makedirs(os.path.dirname(out_file))\n\n        with open(out_file, 'w') as css_out:\n            css_out.write(css_parsed)\n\n        return os.path.relpath(out_file, get_path('.'))\n\n    def preprocess_file(filename, compressed_file):\n        \"\"\"Preprocess the file\"\"\"\n        if filename.startswith('//'):\n            url = 'http:%s' % filename\n        elif filename.startswith(('http:', 'https:')):\n            url = filename\n        else:\n            url = None\n\n        if url:\n            ext_media_path = get_path('external')\n\n            if not os.path.exists(ext_media_path):\n                os.makedirs(ext_media_path)\n\n            filename = os.path.basename(url)\n            if filename.endswith(('.js', '.css', '.less')):\n                fp = get_path(filename.lstrip('/'))\n                file_path = os.path.join(ext_media_path, fp)\n\n                try:\n                    req = urlopen(url)\n                    print(' - Fetching %s ...' % url)\n                except HTTPError as e:\n                    print(' - HTTP Error %s for %s, %s' % (url, filename,\n                                                           str(e.code)))\n                    return None\n                except URLError as e:\n                    print(' - Invalid URL %s for %s, %s' % (url, filename,\n                                                            str(e.reason)))\n                    return None\n\n                with open(file_path, 'w+') as fp:\n                    try:\n                        shutil.copyfileobj(req, fp)\n                    except shutil.Error:\n                        print(' - Could not copy file %s' % filename)\n                filename = os.path.join('external', filename)\n            else:\n                print(' - Not a valid remote file %s' % filename)\n                return None\n\n        filename = preprocess(filename.lstrip('/'))\n\n        if url is None and filename.endswith('.css'):\n            filename = fix_urls(filename, compressed_file)\n            tmp_files.append(filename)\n\n        return get_path(filename.lstrip('/'))\n\n    def minify(ftype, file_in, file_out):\n        \"\"\"Minify the file\"\"\"\n        if ftype == 'js' and 'UGLIFY_BIN' in current_app.config:\n            o = {'method': 'UglifyJS',\n                 'bin': current_app.config.get('UGLIFY_BIN')}\n            subprocess.call(\"%s -o %s %s\" % (o['bin'], file_out, file_in),\n                            shell=True, stdout=subprocess.PIPE)\n        elif ftype == 'css' and 'CLEANCSS_BIN' in current_app.config:\n            o = {'method': 'clean-css',\n                 'bin': current_app.config.get('CLEANCSS_BIN')}\n            subprocess.call(\"%s -o %s %s\" % (o['bin'], file_out, file_in),\n                            shell=True, stdout=subprocess.PIPE)\n        else:\n            o = {'method': 'YUI Compressor',\n                 'bin': current_app.config.get('JAVA_BIN')}\n            variables = (o['bin'], path_to_jar, file_in, file_out)\n            subprocess.call(\"%s -jar %s %s -o %s\" % variables,\n                            shell=True, stdout=subprocess.PIPE)\n\n        print(\"Minifying %s (using %s)\" % (file_in, o['method']))\n\n    # Assemble bundles and process\n    bundles = {\n        'css': current_app.config.get('CSS_BUNDLES'),\n        'js': current_app.config.get('JS_BUNDLES'),\n    }\n\n    for ftype, bundle in bundles.items():\n        for name, files in bundle.items():\n            concatenated_file = get_path(os.path.join(\n                current_app.config.get('BUNDLES_DIR'), ftype,\n                '%s-all.%s' % (name, ftype,)))\n            compressed_file = get_path(os.path.join(\n                current_app.config.get('BUNDLES_DIR'), ftype,\n                '%s-min.%s' % (name, ftype,)))\n\n            if not os.path.exists(os.path.dirname(concatenated_file)):\n                os.makedirs(os.path.dirname(concatenated_file))\n\n            all_files = []\n            for fn in files:\n                processed = preprocess_file(fn, compressed_file)\n                print('Processed: %s' % processed)\n                if processed is not None:\n                    all_files.append(processed)\n\n            # Concatenate\n            if len(all_files) == 0:\n                print(\"Warning: '%s' is an empty bundle.\" % bundle)\n\n            all_files = ' '.join(all_files)\n\n            subprocess.call(\"cat %s > %s\" % (all_files, concatenated_file),\n                            shell=True)\n\n            # Minify\n            minify(ftype, concatenated_file, compressed_file)\n\n            # Post process\n            postprocess(compressed_file, fix_path=False)\n\n            # Remove concatenated file\n            print('Remove concatenated file')\n            os.remove(concatenated_file)\n\n    # Cleanup\n    print('Clean up temporary files')\n    for file in tmp_files:\n        try:\n            os.remove(get_path(file))\n            os.rmdir(os.path.dirname(get_path(file)))\n        except OSError:\n            pass\n\n    try:\n        os.rmdir(get_path(os.path.join(current_app.config.get('BUNDLES_DIR'),\n                                       'tmp')))\n    except OSError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds extra data to the helper_metadata field.", "response": "def to_internal_value(self, data):\n        \"\"\"\n        Adds extra data to the helper_metadata field.\n        \"\"\"\n        if \"session_event\" in data:\n            data[\"helper_metadata\"][\"session_event\"] = data[\"session_event\"]\n\n        return super(InboundSerializer, self).to_internal_value(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef acceptAlias(decoratedFunction):\n    def wrapper(self, *args, **kwargs):\n        SubAssert(isinstance(self, AliasBase))\n\n        if len(args) > 0:\n            key = args[0]\n            if args[0] in self._aliases.keys():\n                key = self._aliases[args[0]]\n            return decoratedFunction(self, key, *args[1:], **kwargs)\n        return decoratedFunction(self, *args, **kwargs)\n    return wrapper", "response": "This is a decorator that can be used as a decorator. Each class method that is decorated will be able\n    to accept alias or original names as first function positional parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nominal_splits(x, y, x_vals, y_dist, separate_max):\n    # select a label with least samples\n    y_val = max(y_dist, key=y_dist.get) if separate_max else min(y_dist, key=y_dist.get)\n\n    prior = y_dist[y_val] / float(len(y))  # prior distribution of selected label\n\n    values, dist, splits = [], [], []\n    for x_val in x_vals:  # for every unique nominal value\n        dist.append(Counter(y[x == x_val]))  # distribution of labels at selected nominal value\n        splits.append(x_val)\n        suma = sum([prior * dist[-1][y_key] for y_key in y_dist.keys()])\n        # estimate probability\n        values.append(prior * dist[-1][y_val] / float(suma))\n    indices = np.array(values).argsort()[::-1]\n\n    # distributions and splits are sorted according to probabilities\n    return np.array(dist)[indices], np.array(splits)[indices].tolist()", "response": "Function uses heuristic to find best binary split of nominal values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef h(values):\n    ent = np.true_divide(values, np.sum(values))\n    return -np.sum(np.multiply(ent, np.log2(ent)))", "response": "Function calculates entropy.\n\n    values: list of integers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info_gain_nominal(x, y, separate_max):\n    x_vals = np.unique(x)  # unique values\n    if len(x_vals) < 3:  # if there is just one unique value\n        return None\n    y_dist = Counter(y)  # label distribution\n    h_y = h(y_dist.values())  # class entropy\n\n    # calculate distributions and splits in accordance with feature type\n\n    dist, splits = nominal_splits(x, y, x_vals, y_dist, separate_max)\n\n    indices, repeat = (range(1, len(dist)), 1) if len(dist) < 50 else (range(1, len(dist), len(dist) / 10), 3)\n    interval = len(dist) / 10\n\n    max_ig, max_i, iteration = 0, 1, 0\n    while iteration < repeat:\n        for i in indices:\n            dist0 = np.sum([el for el in dist[:i]])  # iter 0: take first distribution\n            dist1 = np.sum([el for el in dist[i:]])  # iter 0: take the other distributions without first\n            coef = np.true_divide([np.sum(dist0.values()), np.sum(dist1.values())], len(y))\n            ig = h_y - np.dot(coef, [h(dist0.values()), h(dist1.values())])  # calculate information gain\n            if ig > max_ig:\n                max_ig, max_i = ig, i  # store index and value of maximal information gain\n        iteration += 1\n        if repeat > 1:\n            interval = int(interval * 0.5)\n            if max_i in indices and interval > 0:\n                middle_index = indices.index(max_i)\n            else:\n                break\n            min_index = middle_index if middle_index == 0 else middle_index - 1\n            max_index = middle_index if middle_index == len(indices) - 1 else middle_index + 1\n            indices = range(indices[min_index], indices[max_index], interval)\n\n    # store splits of maximal information gain in accordance with feature type\n    return float(max_ig), [splits[:max_i], splits[max_i:]]", "response": "Function calculates information gain for discrete features."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multinomLog2(selectors):\n\n    ln2 = 0.69314718055994528622\n    noAll = sum(selectors)\n    lgNf = math.lgamma(noAll + 1.0) / ln2  # log2(N!)\n\n    lgnFac = []\n    for selector in selectors:\n        if selector == 0 or selector == 1:\n            lgnFac.append(0.0)\n        elif selector == 2:\n            lgnFac.append(1.0)\n        elif selector == noAll:\n            lgnFac.append(lgNf)\n        else:\n            lgnFac.append(math.lgamma(selector + 1.0) / ln2)\n    return lgNf - sum(lgnFac)", "response": "Function calculates logarithm 2 of a kind of multinom."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_mdl(yx_dist, y_dist):\n    prior = multinomLog2(y_dist.values())\n    prior += multinomLog2([len(y_dist.keys()) - 1, sum(y_dist.values())])\n\n    post = 0\n    for x_val in yx_dist:\n        post += multinomLog2([x_val.get(c, 0) for c in y_dist.keys()])\n        post += multinomLog2([len(y_dist.keys()) - 1, sum(x_val.values())])\n    return (prior - post) / float(sum(y_dist.values()))", "response": "Function calculates mdl with given label distributions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mdl_nominal(x, y, separate_max):\n    x_vals = np.unique(x)  # unique values\n    if len(x_vals) == 1:  # if there is just one unique value\n        return None\n\n    y_dist = Counter(y)  # label distribution\n    # calculate distributions and splits in accordance with feature type\n    dist, splits = nominal_splits(x, y, x_vals, y_dist, separate_max)\n    prior_mdl = calc_mdl(dist, y_dist)\n\n    max_mdl, max_i = 0, 1\n    for i in range(1, len(dist)):\n        # iter 0: take first distribution\n        dist0_x = [el for el in dist[:i]]\n        dist0_y = np.sum(dist0_x)\n        post_mdl0 = calc_mdl(dist0_x, dist0_y)\n\n        # iter 0: take the other distributions without first\n        dist1_x = [el for el in dist[i:]]\n        dist1_y = np.sum(dist1_x)\n        post_mdl1 = calc_mdl(dist1_x, dist1_y)\n\n        coef = np.true_divide([sum(dist0_y.values()), sum(dist1_y.values())], len(x))\n        mdl_val = prior_mdl - np.dot(coef, [post_mdl0, post_mdl1])  # calculate mdl\n        if mdl_val > max_mdl:\n            max_mdl, max_i = mdl_val, i\n\n            # store splits of maximal mdl in accordance with feature type\n    split = [splits[:max_i], splits[max_i:]]\n    return (max_mdl, split)", "response": "Function calculates minimum description length for discrete features."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the URL used to connect to the database.", "response": "def url(section=\"postGIS\", config_file=None):\n    \"\"\" Retrieve the URL used to connect to the database.\n\n    Use this if you have your own means of accessing the database and do not\n    want to use :func:`engine` or :func:`connection`.\n\n    Parameters\n    ----------\n    section : str, optional\n        The `config.ini` section corresponding to the targeted database.\n        It should contain all the details that needed to set up a connection.\n\n    Returns\n    -------\n    database URL : str\n        The URL with which one can connect to the database. Be careful as this\n        will probably contain sensitive data like the username/password\n        combination.\n    config_file : str, optional\n        Relative of absolute of config.ini. If not specified, it tries to read\n        from .oemof/config.ini in your HOME dir\n\n    Notes\n    -----\n\n    For documentation on config.ini see the README section on\n    :ref:`configuring <readme#configuration>` :mod:`oemof.db`.\n    \"\"\"\n\n    cfg.load_config(config_file)\n\n    try:\n        pw = keyring.get_password(cfg.get(section, \"database\"),\n                                  cfg.get(section, \"username\"))\n    except NoSectionError as e:\n        print(\"There is no section {section} in your config file. Please \"\n              \"choose one available section from your config file or \"\n              \"specify a new one!\".format(\n            section=section))\n        exit(-1)\n\n\n    if pw is None:\n        try:\n            pw = cfg.get(section, \"pw\")\n        except option:\n            pw = getpass.getpass(prompt=\"No password available in your \"\\\n                                        \"keyring for database {database}. \"\n                                        \"\\n\\nEnter your password to \" \\\n                                        \"store it in \"\n                                        \"keyring:\".format(database=section))\n            keyring.set_password(section, cfg.get(section, \"username\"), pw)\n        except NoSectionError:\n            print(\"Unable to find the 'postGIS' section in oemof's config.\" +\n                  \"\\nExiting.\")\n            exit(-1)\n\n    return \"postgresql+psycopg2://{user}:{passwd}@{host}:{port}/{db}\".format(\n            user=cfg.get(section, \"username\"),\n            passwd=pw,\n            host=cfg.get(section, \"host\"),\n            db=cfg.get(section, \"database\"),\n            port=int(cfg.get(section, \"port\")))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimplement a raw HTTP GET against the entire Socrata portal for the domain in question. This method uses the first of the two ways of getting this information, the raw JSON endpoint. Parameters ---------- domain: str A Socrata data portal domain. \"data.seattle.gov\" or \"data.cityofnewyork.us\" for example. Returns ------- Portal dataset metadata from the JSON endpoint.", "response": "def get_endpoints_using_raw_json_emission(domain):\n    \"\"\"\n    Implements a raw HTTP GET against the entire Socrata portal for the domain in question. This method uses the\n    first of the two ways of getting this information, the raw JSON endpoint.\n\n    Parameters\n    ----------\n    domain: str\n        A Socrata data portal domain. \"data.seattle.gov\" or \"data.cityofnewyork.us\" for example.\n\n    Returns\n    -------\n    Portal dataset metadata from the JSON endpoint.\n    \"\"\"\n    uri = \"http://{0}/data.json\".format(domain)\n    r = requests.get(uri)\n    r.raise_for_status()\n    return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimplement a raw HTTP GET against the entire Socrata portal for the domain in question. This method uses the second of the two ways of getting this information, the catalog API. Parameters ---------- domain: str A Socrata data portal domain. \"data.seattle.gov\" or \"data.cityofnewyork.us\" for example. token: str A Socrata application token. Application tokens can be registered by going onto the Socrata portal in question, creating an account, logging in, going to developer tools, and spawning a token. Returns ------- Portal dataset metadata from the catalog API.", "response": "def get_endpoints_using_catalog_api(domain, token):\n    \"\"\"\n    Implements a raw HTTP GET against the entire Socrata portal for the domain in question. This method uses the\n    second of the two ways of getting this information, the catalog API.\n\n    Parameters\n    ----------\n    domain: str\n        A Socrata data portal domain. \"data.seattle.gov\" or \"data.cityofnewyork.us\" for example.\n    token: str\n        A Socrata application token. Application tokens can be registered by going onto the Socrata portal in\n        question, creating an account, logging in, going to developer tools, and spawning a token.\n\n    Returns\n    -------\n    Portal dataset metadata from the catalog API.\n    \"\"\"\n    # Token required for all requests. Providing login info instead is also possible but I didn't implement it.\n    headers = {\"X-App-Token\": token}\n\n    # The API will return only 100 requests at a time by default. We can ask for more, but the server seems to start\n    # to lag after a certain N requested. Instead, let's pick a less conservative pagination limit and spool up with\n    # offsets.\n    #\n    # At the time this library was written, Socrata would return all of its results in a contiguous list. Once you\n    # maxed out, you wouldn't get any more list items. Later on this was changed so that now if you exhaust portal\n    # entities, it will actually take you back to the beginning of the list again!\n    #\n    # As a result we need to perform our own set-wise check to make sure that what we get isn't just a bit of the\n    # same list all over again.\n    uri = \"http://api.us.socrata.com/api/catalog/v1?domains={0}&offset={1}&limit=1000\"\n    ret = []\n    endpoints_thus_far = set()\n    offset = 0\n\n    while True:\n        try:\n            r = requests.get(uri.format(domain, offset), headers=headers)\n            r.raise_for_status()\n        except requests.HTTPError:\n            raise requests.HTTPError(\"An HTTP error was raised during Socrata API ingestion.\".format(domain))\n        data = r.json()\n\n        endpoints_returned = {r['resource']['id'] for r in data['results']}\n        new_endpoints = endpoints_returned.difference(endpoints_thus_far)\n\n        if len(new_endpoints) >= 999:  # we are continuing to stream\n            # TODO: 999 not 1000 b/c the API suffers off-by-one errors. Can also do worse, however. Compensate?\n            # cf. https://github.com/ResidentMario/pysocrata/issues/1\n            ret += data['results']\n            endpoints_thus_far.update(new_endpoints)\n            offset += 1000\n            continue\n        else:  # we are ending on a stream with some old endpoints on it\n            ret += [r for r in data['results'] if r['resource']['id'] in new_endpoints]\n            break\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resources(domain, token):\n    json_endpoints = get_endpoints_using_raw_json_emission(domain)\n    catalog_api_output = get_endpoints_using_catalog_api(domain, token)\n    catalog_endpoints = [d['permalink'].split(\"/\")[-1] for d in catalog_api_output]\n    json_endpoints = [d['landingPage'].split(\"/\")[-1] for d in json_endpoints['dataset']]\n    resources = []\n    for i, endpoint in enumerate(json_endpoints):\n        try:\n            catalog_ind = catalog_endpoints.index(json_endpoints[i])\n        except ValueError:  # The catalog does not contain this dataset. Skip it.\n            pass\n        else:\n            resources.append(catalog_api_output[catalog_ind])\n\n    # Exclude stories, which are remixed, not published, data.\n    resources = [d for d in resources if d['resource']['type'] != 'story']\n\n    return resources", "response": "Returns a list of resources on a Socrata domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_resources(domain, token):\n    resources = get_resources(domain, token)\n    return dict(Counter([r['resource']['type'] for r in resources if r['resource']['type'] != 'story']))", "response": "Given a domain in question generates counts for each of the different endpoint types classifiable as published public datasets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsample an item from the pool according to the instrumental distribution", "response": "def _sample_item(self, **kwargs):\n        \"\"\"Sample an item from the pool according to the instrumental\n        distribution\n        \"\"\"\n        loc = np.random.choice(self._n_items, p = self._inst_pmf)\n        weight = (1/self._n_items)/self._inst_pmf[loc]\n        return loc, weight, {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates an estimate of the F - measure based on the scores", "response": "def _calc_F_guess(self, alpha, predictions, probabilities):\n        \"\"\"Calculate an estimate of the F-measure based on the scores\"\"\"\n        num = np.sum(predictions.T * probabilities, axis=1)\n        den = np.sum((1 - alpha) * probabilities + \\\n                     alpha * predictions.T, axis=1)\n        F_guess = num/den\n        # Ensure guess is not undefined\n        F_guess[den==0] = 0.5\n        return F_guess"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitialises the optimal instrumental distribution for the current class entry.", "response": "def _initialise_pmf(self):\n        \"\"\"Calculate the epsilon-greedy instrumental distribution\"\"\"\n        # Easy vars\n        epsilon = self.epsilon\n        alpha = self.alpha\n        preds = self.predictions\n        p1 = self._probs_avg_opt_class\n        p0 = 1 - p1\n        n_items = self._n_items\n        F = self._F_guess\n\n        # Calculate optimal instrumental pmf\n        sqrt_arg = np.sum(preds * (alpha**2 * F**2 * p0 + (1 - F)**2 * p1) + \\\n                          (1 - preds) * (1 - alpha)**2 * F**2 * p1, \\\n                          axis=1) #: sum is over classifiers\n        self._inst_pmf = np.sqrt(sqrt_arg)\n        # Normalize\n        self._inst_pmf /= np.sum(self._inst_pmf)\n        # Epsilon-greedy: (1 - epsilon) q + epsilon * p\n        self._inst_pmf *= (1 - epsilon)\n        self._inst_pmf += epsilon * 1/n_items"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the current time is a tradetime.", "response": "def is_tradetime_now():\n    \"\"\"\n    \u5224\u65ad\u76ee\u524d\u662f\u4e0d\u662f\u4ea4\u6613\u65f6\u95f4, \u540c\u65f6\u8003\u8651\u8282\u5047\u65e5\n    :return: bool\n    \"\"\"\n    cal = Calendar('china.sse')\n    now_time = time.localtime()\n    today = Date(now_time[0], now_time[1], now_time[2])\n    if not cal.isBizDay(today):\n        return False\n    now = (now_time.tm_hour, now_time.tm_min, now_time.tm_sec)\n    if (9, 15, 0) <= now <= (11, 30, 0) or (13, 0, 0) <= now <= (15, 0, 0):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstratify by clustering the items in feature space.", "response": "def stratify_by_features(features, n_strata, **kwargs):\n    \"\"\"Stratify by clustering the items in feature space\n\n    Parameters\n    ----------\n    features : array-like, shape=(n_items,n_features)\n        feature matrix for the pool, where rows correspond to items and columns\n        correspond to features.\n\n    n_strata : int\n        number of strata to create.\n\n    **kwargs :\n        passed to sklearn.cluster.KMeans\n\n    Returns\n    -------\n    Strata instance\n    \"\"\"\n    n_items = features.shape[0]\n    km = KMeans(n_clusters=n_strata, **kwargs)\n    allocations = km.fit_predict(X=features)\n    return Strata(allocations)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _heuristic_bin_width(obs):\n    IQR = sp.percentile(obs, 75) - sp.percentile(obs, 25)\n    N = len(obs)\n    return 2*IQR*N**(-1/3)", "response": "Optimal histogram bin width based on the Freedman - Diaconis rule"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stratify_by_scores(scores, goal_n_strata='auto', method='cum_sqrt_F',\n                       n_bins = 'auto'):\n    \"\"\"Stratify by binning the items based on their scores\n\n    Parameters\n    ----------\n    scores : array-like, shape=(n_items,)\n        ordered array of scores which quantify the classifier confidence for\n        the items in the pool. High scores indicate a high confidence that\n        the true label is a \"1\" (and vice versa for label \"0\").\n\n    goal_n_strata : int or 'auto', optional, default 'auto'\n        desired number of strata. If set to 'auto', the number is selected\n        using the Freedman-Diaconis rule. Note that for the 'cum_sqrt_F' method\n        this number is a goal -- the actual number of strata created may be\n        less than the goal.\n\n    method : {'cum_sqrt_F' or 'equal_size'}, optional, default 'cum_sqrt_F'\n        stratification method to use. 'equal_size' aims to create s\n\n    Other Parameters\n    ----------------\n    n_bins : int or 'auto', optional, default 'auto'\n        specify the number of bins to use when estimating the distribution of\n        the score function. This is used when ``goal_n_strata = 'auto'``\n        and/or when ``method = 'cum_sqrt_F'``. If set to 'auto', the number is\n        selected using the Freedman-Diaconis rule.\n\n    Returns\n    -------\n    Strata instance\n    \"\"\"\n\n    available_methods = ['equal_size', 'cum_sqrt_F']\n    if method not in available_methods:\n        raise ValueError(\"method argument is invalid\")\n\n    if (method == 'cum_sqrt_F') or (goal_n_strata == 'auto'):\n        # computation below is needed for cum_sqrt_F method OR if we need to\n        # determine the number of strata for equal_size method automatically\n        if n_bins == 'auto':\n            # choose n_bins heuristically\n            width_score = _heuristic_bin_width(scores)\n            n_bins = np.ceil(sp.ptp(scores)/width_score).astype(int)\n            print(\"Automatically setting n_bins = {}.\".format(n_bins))\n\n        # approx distribution of scores -- called F\n        counts, score_bins = np.histogram(scores, bins=n_bins)\n\n        # generate cumulative dist of sqrt(F)\n        sqrt_counts = np.sqrt(counts)\n        csf = np.cumsum(sqrt_counts)\n\n        if goal_n_strata == 'auto':\n            # choose heuristically\n            width_csf = _heuristic_bin_width(csf)\n            goal_n_strata = np.ceil(sp.ptp(csf)/width_csf).astype(int)\n            print(\"Automatically setting goal_n_strata = {}.\".format(goal_n_strata))\n        elif method == 'cum_sqrt_F':\n            width_csf = csf[-1]/goal_n_strata\n\n    # goal_n_strata is now guaranteed to have a valid integer value\n\n    if method == 'equal_size':\n        sorted_ids = scores.argsort()\n        n_items = len(sorted_ids)\n        quotient = n_items // goal_n_strata\n        remainder = n_items % goal_n_strata\n        allocations = np.empty(n_items, dtype='int')\n\n        st_pops = [quotient for i in range(goal_n_strata)]\n        for i in range(remainder):\n            st_pops[i] += 1\n\n        j = 0\n        for k,nk in enumerate(st_pops):\n            start = j\n            end = j + nk\n            allocations[sorted_ids[start:end]] = k\n            j = end\n\n    if method == 'cum_sqrt_F':\n        if goal_n_strata > n_bins:\n            warnings.warn(\"goal_n_strata > n_bins. \"\n                          \"Consider increasing n_bins.\")\n        # calculate roughly equal bins on cum sqrt(F) scale\n        csf_bins = [x * width_csf for x in np.arange(goal_n_strata + 1)]\n\n        # map cum sqrt(F) bins to score bins\n        j = 0\n        new_bins = []\n        for (idx,value) in enumerate(csf):\n            if j == (len(csf_bins) - 1) or idx == (len(csf) - 1):\n                new_bins.append(score_bins[-1])\n                break\n            if value >= csf_bins[j]:\n                new_bins.append(score_bins[idx])\n                j += 1\n        new_bins[0] -= 0.01\n        new_bins[-1] += 0.01\n\n        # bin scores based on new_bins\n        allocations = np.digitize(scores, bins=new_bins, right=True) - 1\n\n        # remove empty strata\n        nonempty_ids = np.unique(allocations)\n        n_strata = len(nonempty_ids)\n        indices = np.arange(n_strata)\n        allocations = np.digitize(allocations, nonempty_ids, right=True)\n\n        if n_strata < goal_n_strata:\n            warnings.warn(\"Failed to create {} strata\".format(goal_n_strata))\n\n    return Strata(allocations)", "response": "Stratify the items in the hierarchy based on their scores."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto_stratify(scores, **kwargs):\n    if 'stratification_method' in kwargs:\n        method = kwargs['stratification_method']\n    else:\n        method = 'cum_sqrt_F'\n    if 'stratification_n_strata' in kwargs:\n        n_strata = kwargs['stratification_n_strata']\n    else:\n        n_strata = 'auto'\n    if 'stratification_n_bins' in kwargs:\n        n_bins = kwargs['stratification_n_bins']\n        strata = stratify_by_scores(scores, n_strata, method = method, \\\n                                         n_bins = n_bins)\n    else:\n        strata = stratify_by_scores(scores, n_strata, method = method)\n    return strata", "response": "Generate a Strata instance automatically based on scores."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples a stratum from the strata.", "response": "def _sample_stratum(self, pmf=None, replace=True):\n        \"\"\"Sample a stratum\n\n        Parameters\n        ----------\n        pmf : array-like, shape=(n_strata,), optional, default None\n            probability distribution to use when sampling from the strata. If\n            not given, use the stratum weights.\n\n        replace : bool, optional, default True\n            whether to sample with replacement\n\n        Returns\n        -------\n        int\n            a randomly selected stratum index\n        \"\"\"\n        if pmf is None:\n            # Use weights\n            pmf = self.weights_\n\n        if not replace:\n            # Find strata which have been fully sampled (i.e. are now empty)\n            empty = (self._n_sampled >= self.sizes_)\n            if np.any(empty):\n                pmf = copy.copy(pmf)\n                pmf[empty] = 0\n                if np.sum(pmf) == 0:\n                    raise(RuntimeError)\n                pmf /= np.sum(pmf)\n\n        return np.random.choice(self.indices_, p = pmf)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsample an item uniformly from a stratum.", "response": "def _sample_in_stratum(self, stratum_idx, replace = True):\n        \"\"\"Sample an item uniformly from a stratum\n\n        Parameters\n        ----------\n        stratum_idx : int\n            stratum index to sample from\n\n        replace : bool, optional, default True\n            whether to sample with replacement\n\n        Returns\n        -------\n        int\n            location of the randomly selected item in the original input array\n        \"\"\"\n        if replace:\n            stratum_loc = np.random.choice(self.sizes_[stratum_idx])\n        else:\n            # Extract only the unsampled items\n            stratum_locs = np.where(~self._sampled[stratum_idx])[0]\n            stratum_loc = np.random.choice(stratum_locs)\n\n        # Record that item has been sampled\n        self._sampled[stratum_idx][stratum_loc] = True\n        self._n_sampled[stratum_idx] += 1\n        # Get generic location\n        loc = self.allocations_[stratum_idx][stratum_loc]\n        return loc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample(self, pmf=None, replace=True):\n        stratum_idx = self._sample_stratum(pmf, replace=replace)\n        loc = self._sample_in_stratum(stratum_idx, replace=replace)\n        return loc, stratum_idx", "response": "Sample an item from the strata and return the location and index of the sample in the stratum."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intra_mean(self, values):\n        # TODO Check that quantity is valid\n        if values.ndim > 1:\n            return np.array([np.mean(values[x,:], axis=0) for x in self.allocations_])\n        else:\n            return np.array([np.mean(values[x]) for x in self.allocations_])", "response": "Calculate the mean of a quantity within a strata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self):\n        self._sampled = [np.repeat(False, x) for x in self.sizes_]\n        self._n_sampled = np.zeros(self.n_strata_, dtype=int)", "response": "Reset the instance to begin sampling from scratch"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smooth(x, y, degree=3):\n\n    if degree == 1:\n        return x, y\n    elif not isodd(degree):\n        raise ValueError(\"Degree must be an odd number\")\n    else:\n        window_width = int(degree / 2)\n        data_size = len(y) - degree + 1\n\n        smoothed_y = np.zeros(data_size)\n        for idx in range(degree):\n            smoothed_y += y[idx:idx + data_size]\n        smoothed_y /= degree\n\n        smoothed_x = x[window_width:-window_width]\n\n        return smoothed_x, smoothed_y", "response": "Smooth y - values and return new x y pair."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning for GH units on the network and return a list of all devices that have been added to the network.", "response": "async def bluetooth_scan():\n    \"\"\"\n    Get devices from all GH units on the network.\n\n    This will scan the IPRANGE defined above for GH units.\n    Then do a multirun scan on each unit.\n    Compiling all devices from all units so you can see which unit has\n    the stronges signal to the device.\n    \"\"\"\n    devices = {}\n    async with aiohttp.ClientSession() as session:\n        ghlocalapi = NetworkScan(LOOP, session)\n        result = await ghlocalapi.scan_for_units(IPRANGE)\n    for host in result:\n        if host['assistant_supported']:\n            async with aiohttp.ClientSession() as session:\n                ghlocalapi = DeviceInfo(LOOP, session, host['host'])\n                await ghlocalapi.get_device_info()\n                ghname = ghlocalapi.device_info.get('name')\n            async with aiohttp.ClientSession() as session:\n                ghlocalapi = Bluetooth(LOOP, session, host['host'])\n                await ghlocalapi.scan_for_devices_multi_run()\n                await ghlocalapi.get_scan_result()\n                for device in ghlocalapi.devices:\n                    mac = device['mac_address']\n                    if not devices.get(mac, False):\n                        # New device\n                        devices[mac] = {}\n                        devices[mac]['rssi'] = device['rssi']\n                        devices[mac]['ghunit'] = ghname\n                    elif devices[mac]['rssi'] < device['rssi']:\n                        # Better RSSI value on this device\n                        devices[mac]['rssi'] = device['rssi']\n                        devices[mac]['ghunit'] = ghname\n    print(devices)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that all the data that is needed for submit verification is available.", "response": "def get_queue_obj(session, queue_url, log_url):\n    \"\"\"Checks that all the data that is needed for submit verification is available.\"\"\"\n    skip = False\n    if not queue_url:\n        logger.error(\"The queue url is not configured, skipping submit verification\")\n        skip = True\n\n    if not session:\n        logger.error(\"Missing requests session, skipping submit verification\")\n        skip = True\n    queue = QueueSearch(session=session, queue_url=queue_url, log_url=log_url)\n    queue.skip = skip\n    return queue"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies that the results were successfully submitted.", "response": "def verify_submit(\n    session, queue_url, log_url, job_ids, timeout=_DEFAULT_TIMEOUT, delay=_DEFAULT_DELAY, **kwargs\n):\n    \"\"\"Verifies that the results were successfully submitted.\"\"\"\n    verification_queue = get_queue_obj(session=session, queue_url=queue_url, log_url=log_url)\n    return verification_queue.verify_submit(job_ids, timeout, delay, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading data of completed jobs.", "response": "def download_queue(self, job_ids):\n        \"\"\"Downloads data of completed jobs.\"\"\"\n        if self.skip:\n            return None\n\n        url = \"{}?jobtype=completed&jobIds={}\".format(\n            self.queue_url, \",\".join(str(x) for x in job_ids)\n        )\n        try:\n            response = self.session.get(url, headers={\"Accept\": \"application/json\"})\n            if response:\n                response = response.json()\n            else:\n                response = None\n        # pylint: disable=broad-except\n        except Exception as err:\n            logger.error(err)\n            response = None\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_jobs(self, job_ids):\n        matched_jobs = []\n        if self.skip:\n            return matched_jobs\n\n        json_data = self.download_queue(job_ids)\n        if not json_data:\n            return matched_jobs\n\n        jobs = json_data[\"jobs\"]\n        for job in jobs:\n            if (\n                job.get(\"id\") in job_ids\n                and job.get(\"status\", \"\").lower() not in _NOT_FINISHED_STATUSES\n            ):\n                matched_jobs.append(job)\n\n        return matched_jobs", "response": "Finds the jobs in the completed job queue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_jobs(self, job_ids, timeout, delay):\n        if self.skip:\n            return\n\n        logger.debug(\"Waiting up to %d sec for completion of the job IDs %s\", timeout, job_ids)\n\n        remaining_job_ids = set(job_ids)\n        found_jobs = []\n\n        countdown = timeout\n        while countdown > 0:\n            matched_jobs = self.find_jobs(remaining_job_ids)\n            if matched_jobs:\n                remaining_job_ids.difference_update({job[\"id\"] for job in matched_jobs})\n                found_jobs.extend(matched_jobs)\n            if not remaining_job_ids:\n                return found_jobs\n            time.sleep(delay)\n            countdown -= delay\n\n        logger.error(\n            \"Timed out while waiting for completion of the job IDs %s. Results not updated.\",\n            list(remaining_job_ids),\n        )", "response": "Waits up to delay seconds for the jobs in the completed job queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses returned messages and checks submit outcome.", "response": "def _check_outcome(self, jobs):\n        \"\"\"Parses returned messages and checks submit outcome.\"\"\"\n        if self.skip:\n            return False\n\n        if not jobs:\n            logger.error(\"Import failed!\")\n            return False\n\n        failed_jobs = []\n        for job in jobs:\n            status = job.get(\"status\")\n            if not status:\n                failed_jobs.append(job)\n                continue\n\n            if status.lower() != \"success\":\n                failed_jobs.append(job)\n\n        for job in failed_jobs:\n            logger.error(\"job: %s; status: %s\", job.get(\"id\"), job.get(\"status\"))\n        if len(failed_jobs) == len(jobs):\n            logger.error(\"Import failed!\")\n        elif failed_jobs:\n            logger.error(\"Some import jobs failed!\")\n        else:\n            logger.info(\"Results successfully updated!\")\n\n        return not failed_jobs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _download_log(self, url, output_file):\n        logger.info(\"Saving log %s to %s\", url, output_file)\n\n        def _do_log_download():\n            try:\n                return self.session.get(url)\n            # pylint: disable=broad-except\n            except Exception as err:\n                logger.error(err)\n\n        # log file may not be ready yet, wait a bit\n        for __ in range(5):\n            log_data = _do_log_download()\n            if log_data or log_data is None:\n                break\n            time.sleep(2)\n\n        if not (log_data and log_data.content):\n            logger.error(\"Failed to download log file %s.\", url)\n            return\n        with open(os.path.expanduser(output_file), \"ab\") as out:\n            out.write(log_data.content)", "response": "Downloads log from the specified url and saves it to the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_logs(self, jobs, log_file=None):\n        if not (jobs and self.log_url):\n            return\n\n        for job in jobs:\n            url = \"{}?jobId={}\".format(self.log_url, job.get(\"id\"))\n            if log_file:\n                self._download_log(\"{}&download\".format(url), log_file)\n            else:\n                logger.info(\"Submit log for job %s: %s\", job.get(\"id\"), url)", "response": "Get log url of the jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that the results were successfully submitted.", "response": "def verify_submit(self, job_ids, timeout, delay, **kwargs):\n        \"\"\"Verifies that the results were successfully submitted.\"\"\"\n        if self.skip:\n            return False\n\n        jobs = self.wait_for_jobs(job_ids, timeout, delay)\n        self.get_logs(jobs, log_file=kwargs.get(\"log_file\"))\n\n        return self._check_outcome(jobs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if given item is contained inside the node modules or packages.", "response": "def _contains(self, item):\n        \"\"\"\n        Whether given item is contained inside the node modules/packages.\n\n        Args:\n            item (Package/Module): a package or module.\n\n        Returns:\n            bool: True if self is item or item in self's packages/modules.\n        \"\"\"\n        if self is item:\n            return True\n        for m in self.modules:\n            if item in m:\n                return True\n        for p in self.packages:\n            if item in p:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting item through the __getitem__ and cache the result.", "response": "def get(self, item):\n        \"\"\"\n        Get item through ``__getitem__`` and cache the result.\n\n        Args:\n            item (str): name of package or module.\n\n        Returns:\n            Package/Module: the corresponding object.\n        \"\"\"\n        if item not in self._item_cache:\n            try:\n                item = self.__getitem__(item)\n            except KeyError:\n                item = None\n            self._item_cache[item] = item\n        return self._item_cache[item]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_target(self, target):\n        if target not in self._target_cache:\n            self._target_cache[target] = self._get_target(target)\n        return self._target_cache[target]", "response": "Get the result of _get_target cache it and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_target(self, target):\n        depth = target.count('.') + 1\n        parts = target.split('.', 1)\n        for m in self.modules:\n            if parts[0] == m.name:\n                if depth < 3:\n                    return m\n        for p in self.packages:\n            if parts[0] == p.name:\n                if depth == 1:\n                    return p\n                # pylama:ignore=W0212\n                target = p._get_target(parts[1])\n                if target:\n                    return target\n                # FIXME: can lead to internal dep instead of external\n                # see example with django.contrib.auth.forms\n                # importing forms from django\n                # Idea: when parsing files with ast, record what objects\n                # are defined in the module. Then check here if the given\n                # part is one of these objects.\n                if depth < 3:\n                    return p\n        return None", "response": "Get the Package or Module related to a given target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_graph(self, format=None, output=sys.stdout, depth=0, **kwargs):\n        graph = self.as_graph(depth=depth)\n        graph.print(format=format, output=output, **kwargs)", "response": "Print the graph of the node s nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_matrix(self, format=None, output=sys.stdout, depth=0, **kwargs):\n        matrix = self.as_matrix(depth=depth)\n        matrix.print(format=format, output=output, **kwargs)", "response": "Print the matrix for this node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_treemap(self, format=None, output=sys.stdout, **kwargs):\n        treemap = self.as_treemap()\n        treemap.print(format=format, output=output, **kwargs)", "response": "Print the matrix for this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_dict(self):\n        return {\n            'name': str(self),\n            'modules': [m.as_dict() for m in self.modules],\n            'packages': [p.as_dict() for p in self.packages]\n        }", "response": "Return the dependencies as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a graph with self as node cache it and return it.", "response": "def as_graph(self, depth=0):\n        \"\"\"\n        Create a graph with self as node, cache it, return it.\n\n        Args:\n            depth (int): depth of the graph.\n\n        Returns:\n            Graph: an instance of Graph.\n        \"\"\"\n        if depth in self._graph_cache:\n            return self._graph_cache[depth]\n        self._graph_cache[depth] = graph = Graph(self, depth=depth)\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_matrix(self, depth=0):\n        if depth in self._matrix_cache:\n            return self._matrix_cache[depth]\n        self._matrix_cache[depth] = matrix = Matrix(self, depth=depth)\n        return matrix", "response": "Create a matrix with self as node cache it return it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_treemap(self):\n        if self._treemap_cache:\n            return self._treemap_cache\n        self._treemap_cache = treemap = TreeMap(self)\n        return treemap", "response": "Return the dependencies as a TreeMap."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the root node of the hierarchy.", "response": "def root(self):\n        \"\"\"\n        Property to return the root of this node.\n\n        Returns:\n            Package: this node's root package.\n        \"\"\"\n        node = self\n        while node.package is not None:\n            node = node.package\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef depth(self):\n        if self._depth_cache is not None:\n            return self._depth_cache\n        depth, node = 1, self\n        while node.package is not None:\n            depth += 1\n            node = node.package\n        self._depth_cache = depth\n        return depth", "response": "Return the depth of the node in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the absolute name of the node.", "response": "def absolute_name(self, depth=0):\n        \"\"\"\n        Return the absolute name of the node.\n\n        Concatenate names from root to self within depth.\n\n        Args:\n            depth (int): maximum depth to go to.\n\n        Returns:\n            str: absolute name of the node (until given depth is reached).\n        \"\"\"\n        node, node_depth = self, self.depth\n        if depth < 1:\n            depth = node_depth\n        while node_depth > depth and node.package is not None:\n            node = node.package\n            node_depth -= 1\n        names = []\n        while node is not None:\n            names.append(node.name)\n            node = node.package\n        return '.'.join(reversed(names))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nonzero_monies(self):\n        return [copy.copy(m) for m in self._money_obs if m.amount != 0]", "response": "Returns a list of the underlying Money instances that are not zero"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index(pc):\n    click.echo(\"Format Version: {0}\".format(pc.idx['formatVersion']))\n    click.echo(\"Publication Date: {0}\".format(pc.idx['publicationDate']))\n    olist = ''\n    for i,o in enumerate(pc.idx['offers']):\n        if i < len(pc.idx['offers']) - 1:\n            olist += o + \", \"\n        else:\n            olist += o\n\n    click.echo(\"Services Offered: {0}\".format(olist))", "response": "Show details about the Pricing API Index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef product(pc, service, attrib, sku):\n    pc.service = service.lower()\n    pc.sku = sku\n    pc.add_attributes(attribs=attrib)\n    click.echo(\"Service Alias: {0}\".format(pc.service_alias))\n    click.echo(\"URL: {0}\".format(pc.service_url))\n    click.echo(\"Region: {0}\".format(pc.region))\n    click.echo(\"Product Terms: {0}\".format(pc.terms))\n    click.echo(\"Filtering Attributes: {0}\".format(pc.attributes))\n\n    prods = pyutu.find_products(pc)\n    for p in prods:\n        click.echo(\"Product SKU: {0} product: {1}\".format(\n            p, json.dumps(prods[p], indent=2, sort_keys=True))\n        )\n\n    click.echo(\"Total Products Found: {0}\".format(len(prods)))\n    click.echo(\"Time: {0} secs\".format(time.process_time()))", "response": "Get a list of a service s products."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of a service s prices.", "response": "def price(pc, service, attrib, sku):\n    \"\"\"\n    Get a list of a service's prices.\n    The list will be in the given region, matching the specific terms and\n    any given attribute filters or a SKU.\n    \"\"\"\n    pc.service = service.lower()\n    pc.sku = sku\n    pc.add_attributes(attribs=attrib)\n    click.echo(\"Service Alias: {0}\".format(pc.service_alias))\n    click.echo(\"URL: {0}\".format(pc.service_url))\n    click.echo(\"Region: {0}\".format(pc.region))\n    click.echo(\"Product Terms: {0}\".format(pc.terms))\n    click.echo(\"Filtering Attributes: {0}\".format(pc.attributes))\n\n    prices = pyutu.get_prices(pc)\n    for p in prices:\n        click.echo(\"Rate Code: {0} price: {1}\".format(\n            p, json.dumps(prices[p], indent=2, sort_keys=True))\n        )\n\n    click.echo(\"Total Prices Found: {0}\".format(len(prices)))\n    if sys.version_info >= (3, 3):\n        click.echo(\"Time: {0} secs\".format(time.process_time()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a graph name using the name of the caller.", "response": "def create_graph_name(suffix='', dirname=None):\n    \"\"\"Create a graph name using the name of the caller.\n\n    :param suffix: optional suffix to add to name\n    :param dirname: optional directory name\n\n    :return: path for the named graph\n    :rtype: string\n\n    \"\"\"\n    if suffix:\n        suffix = '-%s' % suffix\n    caller = get_callers_name(level=3)\n    name = '%s%s%s%s' % (__prefix, caller, suffix, __suffix)\n    if dirname:\n        name = os.path.join(dirname, name)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a graph as LaTeX file.", "response": "def save_graph(graph, suffix='', dirname=None, pdf=False):\n    \"\"\"Save a graph using caller's name.\n\n    :type graph: GraphArtist instance\n    :param suffix: optional suffix to add to name\n    :param dirname: optional directory name\n    :param pdf: if True, the saved graph is additionally rendered and\n        saved as a pdf, alongside the LaTeX file.\n\n    \"\"\"\n    name = create_graph_name(suffix, dirname)\n    graph.save(name)\n    if pdf:\n        graph.save_as_pdf(name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_data(data, suffix='', dirname=None):\n    if type(data) == list:\n        data = np.array(data).T\n\n    name = create_graph_name(suffix, dirname) + '.txt'\n    np.savetxt(name, data)", "response": "Save a dataset using caller s name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cysparse_type_to_real_sum_cysparse_type(cysparse_type):\n\n    r_type = None\n\n    if cysparse_type in ['INT32_t', 'UINT32_t', 'INT64_t', 'UINT64_t']:\n        r_type = 'FLOAT64_t'\n    elif cysparse_type in ['FLOAT32_t', 'FLOAT64_t']:\n        r_type = 'FLOAT64_t'\n    elif cysparse_type in ['FLOAT128_t']:\n        r_type = 'FLOAT128_t'\n    elif cysparse_type in ['COMPLEX64_t', 'COMPLEX128_t']:\n        r_type = 'FLOAT64_t'\n    elif cysparse_type in ['COMPLEX256_t']:\n        r_type = 'FLOAT128_t'\n    else:\n        raise TypeError(\"Not a recognized type\")\n\n    assert r_type in ['FLOAT64_t', 'FLOAT128_t']\n\n    return r_type", "response": "Returns the best real type for a given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cysparse_real_type_from_real_cysparse_complex_type(cysparse_type):\n    r_type = None\n\n    if cysparse_type in ['COMPLEX64_t']:\n        r_type = 'FLOAT32_t'\n    elif cysparse_type in ['COMPLEX128_t']:\n        r_type = 'FLOAT64_t'\n    elif cysparse_type in ['COMPLEX256_t']:\n        r_type = 'FLOAT128_t'\n    else:\n        raise TypeError(\"Not a recognized complex type\")\n\n    return r_type", "response": "Returns the real type for the real or imaginary part of a complex type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread file from path", "response": "def read(path, savedir):\n        \" Read file from path \"\n        if path.startswith('http://'):\n            name = op.basename(path)\n            save_path = op.join(savedir, name)\n            if not op.exists(save_path):\n                src = urllib2.urlopen(path).read()\n                try:\n                    open(save_path, 'w').write(src)\n                except IOError:\n                    return src\n            path = save_path\n        return open(path, 'r').read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_imports(self, src):\n        \" Parse imports from source. \"\n        result = []\n\n        def child(obj):\n            result.append(obj.group(1))\n        src = self.import_re.sub(child, src)\n        return src, result", "response": "Parse imports from source."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef by_user(self):  # pragma: no cover\n        users = [i for i in self.__get_users()]\n        user_groups = {}\n        group_results = {\n            tuple(value): key\n            for (key, value) in self.by_group().items()\n        }\n        for user in users:\n            user_groups[user] = []\n            for user_list, group in group_results.items():\n                if user in user_list:\n                    user_groups[user].append(group)\n\n        return user_groups", "response": "Display group membership sorted by group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_group(self):  # pragma: no cover\n        group_membership = {}\n        for record in self.__get_groups_with_membership():\n            group_membership[record.cn.value] = [\n                i for i in record.memberUid.values\n            ]\n        return group_membership", "response": "Display group membership sorted by group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_user(config):\n        client = Client()\n        client.prepare_connection()\n        audit_api = API(client)\n        CLI.parse_membership('Groups by User', audit_api.by_user())", "response": "Display LDAP group membership sorted by user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the contents of LDAP to console in raw format.", "response": "def raw(config):  # pragma: no cover\n        \"\"\"Dump the contents of LDAP to console in raw format.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        audit_api = API(client)\n        print(audit_api.raw())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_membership(header_string, membership):  # pragma: no cover\n        print(header_string, \"\\n{}\".format('=' * len(header_string)))\n        for key, values in membership.items():\n            if values is None:\n                continue\n            print('- ', key)\n            for value in values:\n                print(\"\\t- {}\".format(value))", "response": "Print membership for by_group and by_user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the session_data as a base64 encrypted json string.", "response": "def prepare(session_data={}, #pylint: disable=dangerous-default-value\n                passphrase=None):\n        \"\"\"\n        Returns *session_dict* as a base64 encrypted json string.\n\n        \"\"\"\n        if passphrase is None:\n            passphrase = settings.DJAODJIN_SECRET_KEY\n        return encode(session_data, passphrase,\n            json_encoder=crypt.JSONEncoder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self):\n        session_data = {}\n        try:\n            session_data = decode(self.session_key,\n                settings.DJAODJIN_SECRET_KEY)\n            self._session_key_data.update(session_data)\n            LOGGER.debug(\"session data (from proxy): %s\", session_data)\n            # We have been able to decode the session data, let's\n            # create Users and session keys expected by Django\n            # contrib.auth backend.\n            if 'username' in session_data:\n                user = authenticate(\n                    request=session_data, remote_user=session_data['username'])\n                if not user:\n                    raise ValueError(\"Cannot authenticate user.\")\n                session_data[SESSION_KEY] = user.id\n                session_data[BACKEND_SESSION_KEY] = user.backend\n                session_data[HASH_SESSION_KEY] = user.get_session_auth_hash()\n                if self._local:\n                    session_data_local = self._local.load()\n                    LOGGER.debug(\"session data (local): %s\", session_data_local)\n                    session_data.update(session_data_local)\n        except Exception as err: #pylint:disable=broad-except\n            LOGGER.debug(\"error: while loading session, %s\", err)\n            return {}\n        return session_data", "response": "Load the session data from the key itself if it exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncharge a credit card in a psp", "response": "def charge_credit_card(credit_card_psp_object: Model, amount: Money, client_ref: str) -> Tuple[bool, Model]:\n    \"\"\"\n    :param credit_card_psp_object: an instance representing the credit card in the psp\n    :param amount: the amount to charge\n    :param client_ref: a reference that will appear on the customer's credit card report\n    :return: a tuple (success, payment_psp_object)\n    \"\"\"\n    logger.debug('charge-credit-card', credit_card_psp_object=credit_card_psp_object, amount=amount,\n                 client_ref=client_ref)\n    if amount.amount <= 0:\n        raise PreconditionError('Can only charge positive amounts')\n    psp = psp_for_model_instance(credit_card_psp_object)\n    return psp.charge_credit_card(credit_card_psp_object, amount, client_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrefunds a payment in the psp using the given amount.", "response": "def refund_payment(payment_psp_object: Model, amount: Money, client_ref: str) -> Tuple[bool, Model]:\n    \"\"\"\n    :param payment_psp_object: an instance representing the original payment in the psp\n    :param amount: the amount to refund\n    :param client_ref: a reference that will appear on the customer's credit card statement\n    :return: a tuple (success, refund_psp_object)\n    \"\"\"\n    logger.debug('refund-payment', payment_psp_object=payment_psp_object, amount=amount, client_ref=client_ref)\n    if amount.amount <= 0:\n        raise PreconditionError('Can only refund positive amounts')\n    psp = psp_for_model_instance(payment_psp_object)\n    return psp.refund_payment(payment_psp_object, amount, client_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncharging credit card in the psp to the amount", "response": "def charge_credit_card(self, credit_card_psp_object: Model, amount: Money, client_ref: str) -> Tuple[bool, Model]:\n        \"\"\"\n        :param credit_card_psp_object: an instance representing the credit card in the psp\n        :param amount: the amount to charge\n        :param client_ref: a reference that will appear on the customer's credit card report\n        :return: a tuple (success, payment_psp_object)\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefund a payment in the psp and return the refund_psp_object", "response": "def refund_payment(self, payment_psp_object: Model, amount: Money, client_ref: str) -> Tuple[bool, Model]:\n        \"\"\"\n        :param payment_psp_object: an instance representing the original payment in the psp\n        :param amount: the amount to refund\n        :param client_ref: a reference that will appear on the customer's credit card statement\n        :return: a tuple (success, refund_psp_object)\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_parser():\n    parser = argparse.ArgumentParser(\n        add_help=False,\n        description='Command line tool for dependenpy Python package.')\n    mxg = parser.add_mutually_exclusive_group(required=False)\n\n    parser.add_argument(\n        'packages', metavar='PACKAGES', nargs=argparse.ONE_OR_MORE,\n        help='The package list. Can be a comma-separated list. Each package '\n             'must be either a valid path or a package in PYTHONPATH.')\n    parser.add_argument(\n        '-d', '--depth', default=None, type=int, dest='depth',\n        help='Specify matrix or graph depth. Default: best guess.')\n    parser.add_argument(\n        '-f', '--format', choices=FORMAT, default='text',\n        dest='format', help='Output format. Default: text.')\n    mxg.add_argument(\n        '-g', '--show-graph', action='store_true', dest='graph', default=False,\n        help='Show the graph (no text format). Default: false.')\n    parser.add_argument(\n        '-G', '--greedy', action='store_true', dest='greedy', default=False,\n        help='Explore subdirectories even if they do not contain an '\n             '__init__.py file. Can make execution slower. Default: false.')\n    parser.add_argument(\n        '-h', '--help', action='help', default=argparse.SUPPRESS,\n        help='Show this help message and exit.')\n    parser.add_argument(\n        '-i', '--indent', default=None, type=int, dest='indent',\n        help='Specify output indentation. CSV will never be indented. '\n             'Text will always have new-lines. JSON can be minified with '\n             'a negative value. Default: best guess.')\n    mxg.add_argument(\n        '-l', '--show-dependencies-list', action='store_true',\n        dest='dependencies', default=False,\n        help='Show the dependencies list. Default: false.')\n    mxg.add_argument(\n        '-m', '--show-matrix', action='store_true',\n        dest='matrix', default=False,\n        help='Show the matrix. Default: true unless -g, -l or -t.')\n    parser.add_argument(\n        '-o', '--output', action='store', dest='output', default=sys.stdout,\n        help='Output to given file. Default: stdout.')\n    mxg.add_argument(\n        '-t', '--show-treemap', action='store_true',\n        dest='treemap', default=False,\n        help='Show the treemap (work in progress). Default: false.')\n    parser.add_argument(\n        '-v', '--version', action='version',\n        version='dependenpy %s' % __version__,\n        help='Show the current version of the program and exit.')\n    return parser", "response": "Return a parser for the command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(args=None):\n    parser = get_parser()\n    args = parser.parse_args(args=args)\n\n    if not (args.matrix or args.dependencies or args.treemap or args.graph):\n        args.matrix = True\n\n    # split comma-separated args\n    packages = []\n    for arg in args.packages:\n        if ',' in arg:\n            for package in arg.split(','):\n                if package not in packages:\n                    packages.append(package)\n        elif arg not in packages:\n            packages.append(arg)\n\n    # guess convenient depth\n    depth = args.depth\n    if depth is None:\n        depth = guess_depth(packages)\n\n    # open file if not stdout\n    output = args.output\n    if isinstance(output, str):\n        output = open(output, 'w')\n\n    dsm = DSM(*packages, build_tree=True, build_dependencies=True,\n              enforce_init=not args.greedy)\n\n    if dsm.empty:\n        return 1\n\n    indent = args.indent\n    if indent is None:\n        if args.format == CSV:\n            indent = 0\n        else:\n            indent = 2\n    elif indent < 0 and args.format == JSON:\n        # special case for json.dumps indent argument\n        indent = None\n\n    try:\n        if args.dependencies:\n            dsm.print(format=args.format, output=output, indent=indent)\n        elif args.matrix:\n            dsm.print_matrix(format=args.format, output=output,\n                             depth=depth, indent=indent)\n        elif args.treemap:\n            dsm.print_treemap(format=args.format, output=output)\n        elif args.graph:\n            dsm.print_graph(format=args.format, output=output,\n                            depth=depth, indent=indent)\n    except BrokenPipeError:\n        # avoid traceback\n        return 2\n\n    return 0", "response": "This function is the main function of the DSM command line entry point. It is the main function of the DSM command line interface. It is the main function of the DSM command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sql_state(self, state):\n        if not hasattr(state, 'sql_state'):\n            setattr(state, 'sql_state', SQLStateGraph())\n        return state.sql_state", "response": "Get SQLStateGraph from state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a field to sort by", "response": "def get_sortkey(table):\n    \"\"\"Get a field to sort by\n    \"\"\"\n    # Just pick the first column in the table in alphabetical order.\n    # Ideally we would get the primary key from bcdc api, but it doesn't\n    # seem to be available\n    wfs = WebFeatureService(url=bcdata.OWS_URL, version=\"2.0.0\")\n    return sorted(wfs.get_schema(\"pub:\" + table)[\"properties\"].keys())[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning true if the cache file holding list of all datasets does not exist or is older than 30 days", "response": "def check_cache(path):\n    \"\"\"Return true if the cache file holding list of all datasets\n    does not exist or is older than 30 days\n    \"\"\"\n    if not os.path.exists(path):\n        return True\n    else:\n        # check the age\n        mod_date = datetime.fromtimestamp(os.path.getmtime(path))\n        if mod_date < (datetime.now() - timedelta(days=30)):\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery DataBC Catalogue API about given package", "response": "def bcdc_package_show(package):\n    \"\"\"Query DataBC Catalogue API about given package\n    \"\"\"\n    params = {\"id\": package}\n    r = requests.get(bcdata.BCDC_API_URL + \"package_show\", params=params)\n    if r.status_code != 200:\n        raise ValueError(\"{d} is not present in DataBC API list\".format(d=package))\n    return r.json()[\"result\"]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all datasets available via WFS", "response": "def list_tables(refresh=False, cache_file=None):\n    \"\"\"Return a list of all datasets available via WFS\n    \"\"\"\n    # default cache listing all objects available is\n    # ~/.bcdata\n    if not cache_file:\n        cache_file = os.path.join(str(Path.home()), \".bcdata\")\n\n    # regenerate the cache if:\n    # - the cache file doesn't exist\n    # - we force a refresh\n    # - the cache is older than 1 month\n    if refresh or check_cache(cache_file):\n        wfs = WebFeatureService(url=bcdata.OWS_URL, version=\"2.0.0\")\n        bcdata_objects = [i.strip(\"pub:\") for i in list(wfs.contents)]\n        with open(cache_file, \"w\") as outfile:\n            json.dump(sorted(bcdata_objects), outfile)\n    else:\n        with open(cache_file, \"r\") as infile:\n            bcdata_objects = json.load(infile)\n\n    return bcdata_objects"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nask DataBC WFS how many features there are in a table", "response": "def get_count(dataset, query=None):\n    \"\"\"Ask DataBC WFS how many features there are in a table/query\n    \"\"\"\n    # https://gis.stackexchange.com/questions/45101/only-return-the-numberoffeatures-in-a-wfs-query\n    table = validate_name(dataset)\n    payload = {\n        \"service\": \"WFS\",\n        \"version\": \"2.0.0\",\n        \"request\": \"GetFeature\",\n        \"typeName\": table,\n        \"resultType\": \"hits\",\n        \"outputFormat\": \"json\",\n    }\n    if query:\n        payload[\"CQL_FILTER\"] = query\n    r = requests.get(bcdata.WFS_URL, params=payload)\n    return int(ET.fromstring(r.text).attrib[\"numberMatched\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubmits a getfeature request to DataBC WFS and return features", "response": "def make_request(parameters):\n    \"\"\"Submit a getfeature request to DataBC WFS and return features\n    \"\"\"\n    r = requests.get(bcdata.WFS_URL, params=parameters)\n    return r.json()[\"features\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef define_request(\n    dataset, query=None, crs=\"epsg:4326\", bounds=None, sortby=None, pagesize=10000\n):\n    \"\"\"Define the getfeature request parameters required to download a dataset\n\n    References:\n    - http://www.opengeospatial.org/standards/wfs\n    - http://docs.geoserver.org/stable/en/user/services/wfs/vendor.html\n    - http://docs.geoserver.org/latest/en/user/tutorials/cql/cql_tutorial.html\n    \"\"\"\n    # validate the table name and find out how many features it holds\n    table = validate_name(dataset)\n    n = bcdata.get_count(table, query=query)\n\n    # DataBC WFS getcapabilities says that it supports paging,\n    # and the spec says that responses should include 'next URI'\n    # (section 7.7.4.4.1)....\n    # But I do not see any next uri in the responses. Instead of following\n    # the paged urls, for datasets with >10k records, just generate urls\n    # based on number of features in the dataset.\n    chunks = math.ceil(n / pagesize)\n\n    # if making several requests, we need to sort by something\n    if chunks > 1 and not sortby:\n        sortby = get_sortkey(table)\n\n    # build the request parameters for each chunk\n    param_dicts = []\n    for i in range(chunks):\n        request = {\n            \"service\": \"WFS\",\n            \"version\": \"2.0.0\",\n            \"request\": \"GetFeature\",\n            \"typeName\": table,\n            \"outputFormat\": \"json\",\n            \"SRSNAME\": crs,\n        }\n        if sortby:\n            request[\"sortby\"] = sortby\n        if query:\n            request[\"CQL_FILTER\"] = query\n        if bounds:\n            request[\"bbox\"] = \",\".join([str(b) for b in bounds])\n        if chunks > 1:\n            request[\"startIndex\"] = i * pagesize\n            request[\"count\"] = pagesize\n        param_dicts.append(request)\n    return param_dicts", "response": "Define the getfeature request parameters required to download a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_data(\n    dataset,\n    query=None,\n    crs=\"epsg:4326\",\n    bounds=None,\n    sortby=None,\n    pagesize=10000,\n    max_workers=5,\n):\n    \"\"\"Get GeoJSON featurecollection from DataBC WFS\n    \"\"\"\n    param_dicts = define_request(dataset, query, crs, bounds, sortby, pagesize)\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = executor.map(make_request, param_dicts)\n\n    outjson = dict(type=\"FeatureCollection\", features=[])\n    for result in results:\n        outjson[\"features\"] += result\n    return outjson", "response": "Get GeoJSON featurecollection from DataBC WFS\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield features from DataBC WFS", "response": "def get_features(\n    dataset,\n    query=None,\n    crs=\"epsg:4326\",\n    bounds=None,\n    sortby=None,\n    pagesize=10000,\n    max_workers=5,\n):\n    \"\"\"Yield features from DataBC WFS\n    \"\"\"\n    param_dicts = define_request(dataset, query, crs, bounds, sortby, pagesize)\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        for result in executor.map(make_request, param_dicts):\n            for feature in result:\n                yield feature"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_sorted(self, resources):\n        tmp = []\n        for resource in resources:\n            path = resource._path\n            # Each slash counts as 10 priority, each variable takes one away\n            priority = path.count('/') * 10 - path.count('{')\n            tmp.append((priority, resource))\n        return [resource for prio, resource in reversed(sorted(tmp))]", "response": "Order the resources by priority - the most specific paths come\nAttributeNames first."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compile(self, resources):\n        routes = []\n        search_vars = re.compile(r'\\{(\\w+)\\}').finditer\n        for resource in resources:\n            # Compile regular expression for each path\n            path, regexp, prev_pos = resource._path, '^', 0\n            for match in search_vars(path):\n                regexp += re.escape(path[prev_pos:match.start()])\n                # .+? - match any character but non-greedy\n                regexp += '(?P<{0}>.+?)'.format(match.group(1))\n                prev_pos = match.end()\n            regexp += re.escape(path[prev_pos:])\n            # Allow an extension to overwrite the mime type\n            extensions = \"|\".join([ext for ext, _ in resource.EXTENSION_MAP])\n            regexp += '(?P<_extension>' + extensions + ')?$'\n            routes.append((re.compile(regexp).match, resource))\n        return routes", "response": "Compiles a list of match functions using regular expressions for the paths. Returns a list of two - item tuples consisting of the match function and the resource class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts tier to caselevel.", "response": "def set_cfme_caselevel(testcase, caselevels):\n    \"\"\"Converts tier to caselevel.\"\"\"\n    tier = testcase.get(\"caselevel\")\n    if tier is None:\n        return\n\n    try:\n        caselevel = caselevels[int(tier)]\n    except IndexError:\n        # invalid value\n        caselevel = \"component\"\n    except ValueError:\n        # there's already string value\n        return\n\n    testcase[\"caselevel\"] = caselevel"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_xunit_transform_cfme(config):\n    skip_searches = [\n        \"SKIPME:\",\n        \"Skipping due to these blockers\",\n        \"BZ ?[0-9]+\",\n        \"GH ?#?[0-9]+\",\n        \"GH#ManageIQ\",\n    ]\n    skips = re.compile(\"(\" + \")|(\".join(skip_searches) + \")\")\n\n    parametrize = config.get(\"cfme_parametrize\", False)\n\n    def results_transform(result):\n        \"\"\"Results transform for CFME.\"\"\"\n        verdict = result.get(\"verdict\")\n        if not verdict:\n            return None\n\n        result = copy.deepcopy(result)\n\n        transform.setup_parametrization(result, parametrize)\n        transform.include_class_in_title(result)\n        transform.insert_source_info(result)\n\n        verdict = verdict.strip().lower()\n        # we want to submit PASS and WAIT results\n        if verdict in Verdicts.PASS + Verdicts.WAIT:\n            return result\n        comment = result.get(\"comment\")\n        # ... and SKIP results where there is a good reason (blocker etc.)\n        if verdict in Verdicts.SKIP and comment and skips.search(comment):\n            # found reason for skip\n            result[\"comment\"] = comment.replace(\"SKIPME: \", \"\").replace(\"SKIPME\", \"\")\n            return result\n        if verdict in Verdicts.FAIL and comment and \"FAILME\" in comment:\n            result[\"comment\"] = comment.replace(\"FAILME: \", \"\").replace(\"FAILME\", \"\")\n            return result\n        # we don't want to report this result if here\n        return None\n\n    return results_transform", "response": "Return a function that transforms the CFME result into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a function that returns a copy of the requirements dict for CFME.", "response": "def get_requirements_transform_cfme(config):\n    \"\"\"Return requirement transformation function for CFME.\"\"\"\n\n    def requirement_transform(requirement):\n        \"\"\"Requirements transform for CFME.\"\"\"\n        requirement = copy.deepcopy(requirement)\n\n        if \"id\" in requirement:\n            del requirement[\"id\"]\n\n        return requirement\n\n    return requirement_transform"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_xunit_transform_cmp(config):\n    skip_searches = [\n        \"SKIPME:\",\n        \"Skipping due to these blockers\",\n        \"BZ ?[0-9]+\",\n        \"GH ?#?[0-9]+\",\n        \"GH#ManageIQ\",\n    ]\n    skips = re.compile(\"(\" + \")|(\".join(skip_searches) + \")\")\n\n    def results_transform(result):\n        \"\"\"Results transform for CMP.\"\"\"\n        verdict = result.get(\"verdict\")\n        if not verdict:\n            return None\n\n        result = copy.deepcopy(result)\n\n        # don't parametrize if not specifically configured\n        if result.get(\"params\"):\n            del result[\"params\"]\n\n        classname = result.get(\"classname\", \"\")\n        if classname:\n            # we don't need to pass classnames?\n            del result[\"classname\"]\n\n        # if the \"test_id\" property is present, use it as test case ID\n        test_id = result.get(\"test_id\", \"\")\n        if test_id:\n            result[\"id\"] = test_id\n\n        verdict = verdict.strip().lower()\n        # we want to submit PASS and WAIT results\n        if verdict in Verdicts.PASS + Verdicts.WAIT:\n            return result\n        comment = result.get(\"comment\")\n        # ... and SKIP results where there is a good reason (blocker etc.)\n        if verdict in Verdicts.SKIP and comment and skips.search(comment):\n            # found reason for skip\n            result[\"comment\"] = comment.replace(\"SKIPME: \", \"\").replace(\"SKIPME\", \"\")\n            return result\n        if verdict in Verdicts.FAIL and comment and \"FAILME\" in comment:\n            result[\"comment\"] = comment.replace(\"FAILME: \", \"\").replace(\"FAILME\", \"\")\n            return result\n        # we don't want to report this result if here\n        return None\n\n    return results_transform", "response": "Return a function that transforms the result of CFME to XUnit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a function that transforms the given requirements dictionary into CLOUDTP.", "response": "def get_requirements_transform_cloudtp(config):\n    \"\"\"Return requirement transformation function for CLOUDTP.\"\"\"\n\n    def requirement_transform(requirement):\n        \"\"\"Requirements transform for CLOUDTP.\"\"\"\n        requirement = copy.deepcopy(requirement)\n\n        if \"id\" in requirement:\n            del requirement[\"id\"]\n        # TODO: testing purposes, remove once ready\n        if not requirement.get(\"assignee-id\"):\n            requirement[\"assignee-id\"] = \"mkourim\"\n        if not requirement.get(\"approver-ids\"):\n            requirement[\"approver-ids\"] = \"mkourim:approved\"\n\n        return requirement\n\n    return requirement_transform"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the archive page", "response": "def render_archive(entries):\n    \"\"\"Creates the archive page\"\"\"\n    context = GLOBAL_TEMPLATE_CONTEXT.copy()\n    context['entries'] = entries\n    _render(context, 'archive_index.html',\n            os.path.join(CONFIG['output_to'], 'archive/index.html')),"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_new_posts_and_pages(db):\n\n    Q = Query()\n    for root, dirs, files in os.walk(CONFIG['content_root']):\n        for filename in sorted([f for f in files if\n                               f.endswith(('md', 'markdown'))]):\n            fullpath = os.path.join(root, filename)\n            _p = fullpath.split(CONFIG['content_root'])[-1].lstrip('/')\n            new_mtime = int(os.path.getmtime(fullpath))\n            e, item = None, None\n\n            for collection in ['posts', 'pages']:\n                item = db[collection].get(Q.filename == _p)\n                if item:\n                    if new_mtime > item['mtime']:\n                        db[collection].update({'mtime': new_mtime},\n                                              doc_ids=[item.doc_id])\n                        e = Entry(fullpath, doc_id=item.doc_id)\n                    break\n\n            if not item:\n                e = Entry(fullpath)\n            if e:\n                yield e, e.id", "response": "Walk content dir and put each post and page in the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all entries and the last qty entries", "response": "def _get_last_entries(db, qty):\n    \"\"\"get all entries and the last qty entries\"\"\"\n    doc_ids = [post.doc_id for post in db.posts.all()]\n    doc_ids = sorted(doc_ids, reverse=True)\n    # bug: here we shoud only render doc_ids[:qty]\n    # but we can't use mtimes for sorting. We'll need to add ptime for the\n    # database (publish time)\n    entries = [Entry(os.path.join(CONFIG['content_root'],\n                     db.posts.get(doc_id=doc_id)['filename']), doc_id)\n               for doc_id in doc_ids]\n    # return _sort_entries(entries)[:qty]\n    entries.sort(key=operator.attrgetter('date'), reverse=True)\n    return entries[:qty], entries"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the index with the last 10 entries in the database", "response": "def update_index(entries):\n    \"\"\"find the last 10 entries in the database and create the main\n    page.\n    Each entry in has an doc_id, so we only get the last 10 doc_ids.\n\n    This method also updates the ATOM feed.\n    \"\"\"\n    context = GLOBAL_TEMPLATE_CONTEXT.copy()\n    context['entries'] = entries\n    context['last_build'] = datetime.datetime.now().strftime(\n        \"%Y-%m-%dT%H:%M:%SZ\")\n\n    list(map(lambda x: _render(context, x[0],\n                               os.path.join(CONFIG['output_to'], x[1])),\n             (('entry_index.html', 'index.html'), ('atom.xml', 'atom.xml'))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlaunches an HTTP to preview the website", "response": "def preview():  # pragma: no coverage\n    \"\"\"launch an HTTP to preview the website\"\"\"\n    Handler = http.server.SimpleHTTPRequestHandler\n    socketserver.TCPServer.allow_reuse_address = True\n    port = CONFIG['http_port']\n    httpd = socketserver.TCPServer((\"\", port), Handler)\n    os.chdir(CONFIG['output_to'])\n    try:\n        logger.info(\"and ready to test at \"\n                    \"http://127.0.0.1:%d\" % CONFIG['http_port'])\n        logger.info(\"Hit Ctrl+C to exit\")\n        httpd.serve_forever()\n    except KeyboardInterrupt:\n        httpd.shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_post(GITDIRECTORY=CONFIG['output_to'], kind=KINDS['writing']):  # pragma: no coverage # noqa\n\n    title = input(\"Give the title of the post: \")\n    while ':' in title:\n        title = input(\"Give the title of the post (':' not allowed): \")\n\n    author = CONFIG['author']\n    date = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')\n    tags = input(\"Give the tags, separated by ', ':\")\n    published = 'yes'\n    chronological = 'yes'\n    summary = (\"summary: Type your summary here.\")\n\n    # make file name\n    fname = os.path.join(os.getcwd(), 'content', kind['name_plural'],\n                         datetime.datetime.strftime(datetime.datetime.now(),\n                                                    '%Y'),\n                         date + '-' + title.replace(' ', '-') + '.markdown')\n    # first post every year need to create a new directory\n    if not os.path.exists(os.path.dirname(fname)):\n        os.makedirs(os.path.dirname(fname))\n\n    with open(fname, 'w') as npost:\n        npost.write('---\\n')\n        npost.write('title: %s\\n' % title)\n        npost.write('author: %s\\n' % author)\n        npost.write('published: %s\\n' % date)\n        npost.write('tags: %s\\n' % tags)\n        npost.write('public: %s\\n' % published)\n        npost.write('chronological: %s\\n' % chronological)\n        npost.write('kind: %s\\n' % kind['name'])\n        npost.write('%s\\n' % summary)\n        npost.write('---\\n')\n\n    os.system('%s %s' % (CONFIG['editor'], fname))", "response": "Create a new post with the given title author and date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the actual lists of entries tagged with", "response": "def entries(self):\n        \"\"\"return the actual lists of entries tagged with\"\"\"\n        Tags = Query()\n        tag = self.table.get(Tags.name == self.name)\n        posts = tag['post_ids']\n\n        for id in posts:\n            post = self.db.posts.get(doc_id=id)\n            if not post:  # pragma: no coverage\n                raise ValueError(\"No post found for doc_id %s\" % id)\n            yield Entry(os.path.join(CONFIG['content_root'], post['filename']), id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self):\n        context = GLOBAL_TEMPLATE_CONTEXT.copy()\n        context['tag'] = self\n        entries = list(self.entries)\n        entries.sort(key=operator.attrgetter('date'), reverse=True)\n        context['entries'] = entries\n\n        # render html page\n        render_to = os.path.join(CONFIG['output_to'], 'tags', self.slug)\n        if not os.path.exists(render_to):  # pragma: no coverage\n            os.makedirs(render_to)\n        _render(context, 'tag_index.html', os.path.join(render_to, 'index.html'))  # noqa\n\n        # render atom.xml\n        context['entries'] = context['entries'][:10]\n        context['last_build'] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")  # noqa\n\n        _render(context, 'atom.xml', os.path.join(render_to, 'atom.xml'))\n        return True", "response": "Render the html page and atom feed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the object for use in the blog.", "response": "def prepare(self):\n\n        self.body_html = markdown(\n            codecs.open(self.abspath, 'r').read(),\n            extras=['fenced-code-blocks', 'hilite', 'tables', 'metadata'])\n\n        self.header = self.body_html.metadata\n        \"\"\"a blog post without tags causes an error ...\"\"\"\n        if 'tags' in self.header:  # pages can lack tags\n            self.header['tags'] = [t.strip().lower() for t in\n                                   self.header['tags'].split(',')]\n\n        else:\n            self.header['tags'] = (\"\",)\n\n        self.date = self.header.get('published', datetime.datetime.now())\n\n        if isinstance(self.date, str):\n            self.date = datetime.datetime.strptime(self.date, \"%Y-%m-%d\")\n\n        for k, v in self.header.items():\n            try:\n                setattr(self, k, v)\n            except AttributeError:\n                pass\n\n        if self.id:\n            return\n\n        rec = {'filename': self.path,\n               'mtime': int(os.path.getmtime(self.abspath))}\n\n        if self.header['kind'] == 'writing':\n            _id = Entry.db.posts.insert(rec)\n\n        elif self.header['kind'] == 'page':\n            _id = Entry.db.pages.insert(rec)\n\n        self.id = _id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tracker():\n    application = mmi.tracker.app()\n    application.listen(22222)\n    logger.info('serving at port 22222')\n    tornado.ioloop.IOLoop.instance().start()", "response": "start a tracker to register running models"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef runner(\n        engine,\n        configfile,\n        output_vars,\n        interval,\n        pause,\n        mpi,\n        tracker,\n        port,\n        bmi_class\n):\n    \"\"\"\n    run a BMI compatible model\n    \"\"\"\n    # keep track of info\n    # update mpi information or use rank 0\n    runner = mmi.runner.Runner(\n        engine=engine,\n        configfile=configfile,\n        output_vars=output_vars,\n        interval=interval,\n        pause=pause,\n        mpi=mpi,\n        tracker=tracker,\n        port=port,\n        bmi_class=bmi_class\n    )\n    runner.run()", "response": "run a BMI compatible model\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall EXTRA_POLISH_FUNCTIONS to see if they applies to this page and if so calls it", "response": "def do_extra_polishing(self):\n        '''\n        Goes over each EXTRA_POLISH_FUNCTION to see if it applies to this page, if so, calls it\n        '''\n        for f in self.EXTRA_POLISH_FUNCTIONS:\n            if not hasattr(f, 'polish_commit_indexes'):\n                if hasattr(f, 'polish_urls') and self.URL in f.polish_urls:\n                    f()\n\n            if not hasattr(f, 'polish_urls'):\n                if hasattr(f, 'polish_commit_indexes') and self.CURRENT_COMMIT_INDEX in f.polish_commit_indexes:\n                    f()\n\n            if hasattr(f, 'polish_commit_indexes') and hasattr(f, 'polish_urls'):\n                if self.URL in f.polish_urls and self.CURRENT_COMMIT_INDEX in f.polish_commit_indexes:\n                    f()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef total_amount(qs) -> Total:\n    aggregate = qs.values('amount_currency').annotate(sum=Sum('amount'))\n    return Total(Money(amount=r['sum'], currency=r['amount_currency']) for r in aggregate)", "response": "Sums the amounts of the objects in the queryset keeping each currency separate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef total_charges(self):\n        selected_charges = Charge.objects \\\n            .filter(invoice=self) \\\n            .charges() \\\n            .exclude(product_code=CARRIED_FORWARD)\n        return total_amount(selected_charges)", "response": "Returns the total amount of charges acquired in the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef due(self):\n        invoice_charges = Charge.objects.filter(invoice=self)\n        invoice_transactions = Transaction.successful.filter(invoice=self)\n        return total_amount(invoice_charges) - total_amount(invoice_transactions)", "response": "Returns the amount of due for this invoice."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup():\n    install_requirements = [\"attrdict\"]\n    if sys.version_info[:2] < (3, 4):\n        install_requirements.append(\"pathlib\")\n    setup_requirements = ['six', 'setuptools>=17.1', 'setuptools_scm']\n    needs_sphinx = {\n        'build_sphinx',\n        'docs',\n        'upload_docs',\n    }.intersection(sys.argv)\n    if needs_sphinx:\n        setup_requirements.append('sphinx')\n    setuptools.setup(\n        author=\"David Gidwani\",\n        author_email=\"david.gidwani@gmail.com\",\n        classifiers=[\n            \"Development Status :: 4 - Beta\",\n            \"Intended Audience :: Developers\",\n            \"License :: OSI Approved :: BSD License\",\n            \"Operating System :: OS Independent\",\n            \"Programming Language :: Python\",\n            \"Programming Language :: Python :: 2\",\n            \"Programming Language :: Python :: 2.7\",\n            \"Programming Language :: Python :: 3\",\n            \"Programming Language :: Python :: 3.3\",\n            \"Programming Language :: Python :: 3.4\",\n            \"Topic :: Software Development\",\n            \"Topic :: Software Development :: Libraries :: Python Modules\",\n        ],\n        description=\"Painless access to namespaced environment variables\",\n        download_url=\"https://github.com/darvid/biome/tarball/0.1\",\n        install_requires=install_requirements,\n        keywords=\"conf config configuration environment\",\n        license=\"BSD\",\n        long_description=readme(),\n        name=\"biome\",\n        package_dir={'': 'src'},\n        packages=setuptools.find_packages('./src'),\n        setup_requires=setup_requirements,\n        tests_require=[\"pytest\"],\n        url=\"https://github.com/darvid/biome\",\n        use_scm_version=True,\n    )", "response": "A function that sets up the package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing Stylus (.styl) files", "response": "def stylus(input, output, **kw):\n    \"\"\"Process Stylus (.styl) files\"\"\"\n    stdin = open(input, 'r')\n    stdout = open(output, 'w')\n    cmd = '%s --include %s' % (current_app.config.get('STYLUS_BIN'),\n                               os.path.abspath(os.path.dirname(input)))\n    subprocess.call(cmd, shell=True, stdin=stdin, stdout=stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning autoprefixer on the input", "response": "def autoprefixer(input, **kw):\n    \"\"\"Run autoprefixer\"\"\"\n    cmd = '%s -b \"%s\" %s' % (current_app.config.get('AUTOPREFIXER_BIN'),\n                             current_app.config.get('AUTOPREFIXER_BROWSERS'),\n                             input)\n    subprocess.call(cmd, shell=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncancel an existing charge.", "response": "def cancel_charge(charge_id: str) -> None:\n    \"\"\"\n    Cancels an existing charge.\n\n    If the charge was already cancelled then an Exception is raised.\n\n    If it is not in an invoice then the charge is deleted,\n    otherwise a Credit object is created to reverse the Charge.\n\n    :param charge_id: The id of the charge to cancel.\n    \"\"\"\n    logger.info('cancelling-charge', charge_id=charge_id)\n\n    with transaction.atomic():\n        charge = Charge.all_charges.get(pk=charge_id)\n\n        if charge.deleted:\n            raise ChargeAlreadyCancelledError(\"Cannot cancel deleted charge.\")\n\n        if Charge.all_charges.filter(reverses=charge_id).exists():\n            raise ChargeAlreadyCancelledError(\"Cannot cancel reversed charge.\")\n\n        if charge.invoice is None:\n            charge.deleted = True\n            charge.save()\n        else:\n            add_charge(\n                account_id=charge.account_id,\n                reverses_id=charge_id,\n                amount=-charge.amount,\n                product_code=REVERSAL_PRODUCT_CODE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_app(defs, add_help=True):\n    def is_resource(d):\n        try:\n            if issubclass(d, wsgiservice.Resource) and hasattr(d, '_path'):\n                return True\n        except TypeError:\n            pass  # d wasn't a class\n\n        return False\n\n    resources = [d for d in defs.values() if is_resource(d)]\n    if add_help:\n        resources.append(wsgiservice.resource.Help)\n    return Application(resources)", "response": "Small wrapper function to return an instance of WSGI application which serves all resources in the defs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog the most important parts of this request.", "response": "def _log_request(self, request):\n        \"\"\"Log the most important parts of this request.\n\n        :param request: Object representing the current request.\n        :type request: :class:`webob.Request`\n        \"\"\"\n        msg = []\n        for d in self.LOG_DATA:\n            val = getattr(request, d)\n            if val:\n                msg.append(d + ': ' + repr(val))\n        for d in self.LOG_HEADERS:\n            if d in request.headers and request.headers[d]:\n                msg.append(d + ': ' + repr(request.headers[d]))\n        logger.info(\"Request information: %s\", ', '.join(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_request(self, request):\n        response = webob.Response(request=request)\n        path = request.path_info\n        parsed = self._urlmap(path)\n        if parsed:\n            path_params, resource = parsed\n        else:\n            path_params, resource = {}, self.NOT_FOUND_RESOURCE\n        instance = resource(request=request, response=response,\n            path_params=path_params, application=self)\n        response = instance()\n        if request.method == 'HEAD':\n            response.body = ''\n        return response", "response": "Finds the resource to which a request maps and then calls it.\n        Instantiates, fills and returns a :class:`webob.Response` object. If\n        no resource matches the request, a 404 status is set on the response\n        object.\n\n        :param request: Object representing the current request.\n        :type request: :class:`webob.Request`"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_mortgage_payment_per_payment_frequency(self):\n        # Calculate the interest rate per the payment parameters:\n        r = self.get_interest_rate_per_payment_frequency()\n\n        # Calculate the total number of payments given the parameters:\n        n = self.get_total_number_of_payments_per_frequency()\n\n        # Variables used as number holders.\n        p = self._loan_amount\n        mortgage = None\n        top = None\n        bottom = None\n\n        top = r + 1\n        top = math.pow(top, n)\n        top = r * top\n\n        bottom = r + 1\n        bottom = math.pow(bottom, n)\n        bottom = bottom - 1\n\n        if bottom == 0:\n            return Money(amount=0.00, currency=self._currency)\n\n        mortgage = (top / bottom)\n        mortgage = mortgage * p\n\n        return mortgage", "response": "Function will return the amount paid per payment based on the frequency of the payment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info(self):\n        url = self.api_url + self.info_url\n        resp = self.session.get(url)\n        if resp.status_code != 200:\n            error = {'description': \"Info HTTP response not valid\"}\n            raise CFException(error, resp.status_code)\n        try:\n            info = resp.json()\n        except ValueError as e:\n            error = {'description': \"Info HTTP response not valid, %s\" % str(e)}\n            raise CFException(error, resp.status_code)\n        return info", "response": "Gets info endpoint. Used to perform login auth."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login(self, username=None, password=''):\n        self.username = username\n        self.password = password\n        return self._login()", "response": "Performs a login with the provided credentials"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete all buildpack caches in the blobstore", "response": "def clean_blobstore_cache(self):\n        \"\"\"Deletes all of the existing buildpack caches in the blobstore\"\"\"\n        url = self.api_url + self.blobstores_builpack_cache_url\n        resp, rcode = self.request('DELETE', url)\n        if rcode != 202:\n            raise CFException(resp, rcode)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, query, locations: list=None):\n        '''Search using the CAS number, barcode or chemical name\n        '''\n        cas_number = re.search(r\"\\b[1-9]{1}[0-9]{1,5}-\\d{2}-\\d\\b\", str(query))\n        if cas_number:\n            query = cas_number[0]\n            search_type = 'cas'   \n        else:\n            try:\n                query = int(query)\n                search_type = 'barcode'\n            except ValueError:\n                query = f\"%{query}%\"\n                search_type = 'name'\n        if not locations:\n            locations = self.get_locations(filter_to_my_group=True)\n            locations = [loc.inventory_id for loc in locations]\n        data = {\n            'groupid': self.groupid,\n            'searchtype': search_type,\n            'searchterm':  query,\n            'limitlocations': locations.append(1)\n        }\n        r = self._post('search-search', referer_path='search', data=data)\n        \n        #return a list of container objects\n        if r['searchresults']['containers']:\n            containers = []\n            for container in r['searchresults']['containers']:\n                loc = Location(name=container.get('location'))\n                ct = Container(\n                    inventory_id = container.get('id'), \n                    compound_id = container.get('sid'),\n                    name=container.get('containername'),\n                    location=loc,\n                    size=container.get('size'),\n                    smiles=container.get('smiles'),\n                    cas=container.get('cas'),\n                    comments=container.get('comments'),\n                    barcode=container.get('barcode'),\n                    supplier=container.get('supplier'),\n                    date_acquired=container.get('dateacquired'),\n                    owner=container.get('owner'))\n                containers.append(ct)\n            return containers\n        else:\n            return []", "response": "Search using the CAS number barcode or chemical name\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve groups listed in ChemInventory", "response": "def get_groups(self):\n        '''Retrieve groups listed in ChemInventory'''\n        resp = self._post('general-retrievelocations', 'locations')\n        final_resp = []\n        if resp['groupinfo']:\n            for group in resp['groupinfo']:\n                final_resp.append(Group(\n                    name=group.get('name'),\n                    inventory_id=group.get('id')\n                ))\n        return final_resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_locations(self, filter_to_my_group=False):\n        resp = self._post('general-retrievelocations', 'locations')\n        groups = {}\n        if resp['groupinfo']:\n            for group in resp['groupinfo']:\n                groups[group['id']] = Group(\n                                            name=group.get('name'),\n                                            inventory_id=group.get('id')\n                                            )\n        final_resp = []\n        if resp['data']:\n            if filter_to_my_group:\n                resp['data'] = {self.groupid: resp['data'][self.groupid]}\n            for groupid, sublocation in resp['data'].items():\n                if type(sublocation) is dict:\n                    sublocation = [loc for _, loc in sublocation.items()]\n                    sublocation = flatten_list(sublocation)\n                if type(sublocation) is list:\n                    sublocation = flatten_list(sublocation)\n                for location in sublocation:\n                    group = groups[groupid]\n                    final_resp.append(Location(\n                                            name=location.get('name'),\n                                            inventory_id=location.get('id'),\n                                            parent=location.get('parent'),\n                                            group=group,\n                                            barcode=location.get('barcode')\n                                      ))\n        return final_resp", "response": "Retrieve Locations listed in ChemInventory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_containers(self, include_only=[]):\n        locations = self.get_locations() \n        if len(locations) == 0:\n            raise ValueError(\"No locations for containers exist in Cheminventory\")\n\n        final_locations = []\n        if include_only:\n            for location in locations:\n                check = location in include_only or location.group in include_only\n                if check:\n                    final_locations.append(location)\n            if len(final_locations)==0: raise ValueError(f\"Location(s) or group(s) {include_only} is/are not in the database.\")\n        else:\n            final_locations = locations\n\n        containers = []\n        for location in final_locations:\n            containers += self._get_location_containers(location.inventory_id)\n\n        return containers", "response": "Download all the containers owned by a group or location"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_unicode_str(obj):\n    if isinstance(obj, six.text_type):\n        return obj\n    if isinstance(obj, six.binary_type):\n        return obj.decode(\"utf-8\", errors=\"ignore\")\n    return six.text_type(obj)", "response": "Makes sure obj is a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_xml(xml_str, output_loc=None, filename=None):\n    if not xml_str:\n        raise Dump2PolarionException(\"No data to write.\")\n    filename_fin = _get_filename(output_loc=output_loc, filename=filename)\n\n    with io.open(filename_fin, \"w\", encoding=\"utf-8\") as xml_file:\n        xml_file.write(get_unicode_str(xml_str))\n    logger.info(\"Data written to '%s'\", filename_fin)", "response": "Outputs the XML content into a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noutputting the XML content from XML element to a file.", "response": "def write_xml_root(xml_root, output_loc=None, filename=None):\n    \"\"\"Outputs the XML content (from XML element) into a file.\n\n    If `output_loc` is supplied and it's a file (not directory), the output\n    will be saved there and the `filename` is ignored.\n\n    Args:\n        xml_root: root element ot the XML document\n        output_loc: file or directory for saving the file\n        filename: file name that will be used if `output_loc` is directory\n            If it is needed and is not supplied, it will be generated\n    \"\"\"\n    if xml_root is None:\n        raise Dump2PolarionException(\"No data to write.\")\n    filename_fin = _get_filename(output_loc=output_loc, filename=filename)\n\n    et = etree.ElementTree(xml_root)\n    et.write(filename_fin, xml_declaration=True, pretty_print=True, encoding=\"utf-8\")\n    logger.info(\"Data written to '%s'\", filename_fin)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_xml_root_from_str(xml_str):\n    try:\n        xml_root = etree.fromstring(xml_str.encode(\"utf-8\"), NO_BLANKS_PARSER)\n    # pylint: disable=broad-except\n    except Exception as err:\n        raise Dump2PolarionException(\"Failed to parse XML string: {}\".format(err))\n    return xml_root", "response": "Returns XML root from string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prettify_xml(xml_root):\n    xml_string = etree.tostring(xml_root, encoding=\"utf-8\", xml_declaration=True, pretty_print=True)\n    return get_unicode_str(xml_string)", "response": "Returns pretty - printed string representation of element tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches up from a given path to find the project root.", "response": "def find_vcs_root(path, dirs=(\".git\",)):\n    \"\"\"Searches up from a given path to find the project root.\"\"\"\n    prev, path = None, os.path.abspath(path)\n    while prev != path:\n        if any(os.path.exists(os.path.join(path, d)) for d in dirs):\n            return path\n        prev, path = path, os.path.abspath(os.path.join(path, os.pardir))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npack and save file", "response": "def pack(self):\n        \" Pack and save file \"\n        pack_name = self.args.prefix + op.basename(self.path)\n        pack_path = op.join(self.args.output or self.basedir, pack_name)\n\n        self.out(\"Packing: %s\" % self.path)\n        self.out(\"Output: %s\" % pack_path)\n\n        if self.args.format:\n            ext = self.get_ext(self.path)\n            self.parsers[ext] = self.args.format\n\n        out = \"\".join(self.merge(self.parse(self.path)))\n        try:\n            open(pack_path, 'w').write(out)\n            self.out(\"Linked file saved as: '%s'.\" % pack_path)\n        except IOError, ex:\n            raise ZetaError(ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends message to shell", "response": "def out(msg, error=False):\n        \" Send message to shell \"\n        pipe = stdout\n        if error:\n            pipe = stderr\n            msg = color_msg(msg, \"warning\")\n\n        pipe.write(\"%s\\n\" % msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the inverse (negative) of a color. The red, green, and blue values are inverted, while the opacity is left alone.", "response": "def _invert(color):\n    \"\"\"\n    Returns the inverse (negative) of a color.\n    The red, green, and blue values are inverted, while the opacity is left alone.\n    \"\"\"\n    col = ColorValue(color)\n    c = col.value\n    c[0] = 255.0 - c[0]\n    c[1] = 255.0 - c[1]\n    c[2] = 255.0 - c[2]\n    return col"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _mix(color1, color2, weight=None):\n    # This algorithm factors in both the user-provided weight\n    # and the difference between the alpha values of the two colors\n    # to decide how to perform the weighted average of the two RGB values.\n    #\n    # It works by first normalizing both parameters to be within [-1, 1],\n    # where 1 indicates \"only use color1\", -1 indicates \"only use color 0\",\n    # and all values in between indicated a proportionately weighted average.\n    #\n    # Once we have the normalized variables w and a,\n    # we apply the formula (w + a)/(1 + w*a)\n    # to get the combined weight (in [-1, 1]) of color1.\n    # This formula has two especially nice properties:\n    #\n    # * When either w or a are -1 or 1, the combined weight is also that number\n    # (cases where w * a == -1 are undefined, and handled as a special case).\n    #\n    #   * When a is 0, the combined weight is w, and vice versa\n    #\n    # Finally, the weight of color1 is renormalized to be within [0, 1]\n    # and the weight of color2 is given by 1 minus the weight of color1.\n    #\n    # Algorithm from the Sass project: http://sass-lang.com/\n\n    c1 = ColorValue(color1).value\n    c2 = ColorValue(color2).value\n    p = NumberValue(weight).value if weight is not None else 0.5\n    p = 0.0 if p < 0 else 1.0 if p > 1 else p\n\n    w = p * 2 - 1\n    a = c1[3] - c2[3]\n\n    w1 = ((w if (w * a == -1) else (w + a) / (1 + w * a)) + 1) / 2.0\n\n    w2 = 1 - w1\n    q = [w1, w1, w1, p]\n    r = [w2, w2, w2, 1 - p]\n\n    color = ColorValue(None).merge(c1).merge(c2)\n    color.value = [c1[i] * q[i] + c2[i] * r[i] for i in range(4)]\n\n    return color", "response": "This function takes two colors and returns the combined color of color1 and color2."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a sprite map from the files matching the glob pattern.", "response": "def _sprite_map(g, **kwargs):\n    \"\"\"\n    Generates a sprite map from the files matching the glob pattern.\n    Uses the keyword-style arguments passed in to control the placement.\n    \"\"\"\n    g = StringValue(g).value\n\n    if not Image:\n        raise Exception(\"Images manipulation require PIL\")\n\n    if g in sprite_maps:\n        sprite_maps[glob]['*'] = datetime.datetime.now()\n    elif '..' not in g:  # Protect against going to prohibited places...\n        vertical = (kwargs.get('direction', 'vertical') == 'vertical')\n        offset_x = NumberValue(kwargs.get('offset_x', 0))\n        offset_y = NumberValue(kwargs.get('offset_y', 0))\n        repeat = StringValue(kwargs.get('repeat', 'no-repeat'))\n        position = NumberValue(kwargs.get('position', 0))\n        dst_color = kwargs.get('dst_color')\n        src_color = kwargs.get('src_color')\n        if position and position > -1 and position < 1:\n            position.units = {'%': _units_weights.get('%', 1), '_': '%'}\n        spacing = kwargs.get('spacing', 0)\n        if isinstance(spacing, ListValue):\n            spacing = [int(NumberValue(v).value) for n, v in spacing.items()]\n        else:\n            spacing = [int(NumberValue(spacing).value)]\n        spacing = (spacing * 4)[:4]\n\n        if callable(STATIC_ROOT):\n            rfiles = files = sorted(STATIC_ROOT(g))\n        else:\n            glob_path = os.path.join(STATIC_ROOT, g)\n            files = glob.glob(glob_path)\n            files = sorted((f, None) for f in files)\n            rfiles = [(f[len(STATIC_ROOT):], s) for f, s in files]\n\n        if not files:\n            log.error(\"Nothing found at '%s'\", glob_path)\n            return StringValue(None)\n\n        times = []\n        for file, storage in files:\n            try:\n                d_obj = storage.modified_time(file)\n                times.append(int(time.mktime(d_obj.timetuple())))\n            except:\n                times.append(int(os.path.getmtime(file)))\n\n        map_name = os.path.normpath(\n            os.path.dirname(g)).replace('\\\\', '_').replace('/', '_')\n        key = list(zip(*files)[0]) + times + [repr(kwargs)]\n        key = map_name + '-' + base64.urlsafe_b64encode(\n            hashlib.md5(repr(key)).digest()).rstrip('=').replace('-', '_')\n        asset_file = key + '.png'\n        asset_path = os.path.join(ASSETS_ROOT, asset_file)\n\n        if os.path.exists(asset_path + '.cache'):\n            asset, map, sizes = pickle.load(open(asset_path + '.cache'))\n            sprite_maps[asset] = map\n        else:\n            images = tuple(Image.open(storage.open(file)) if storage is not None else Image.open(file) for file, storage in files)\n            names = tuple(os.path.splitext(\n                os.path.basename(file))[0] for file, storage in files)\n            positions = []\n            spacings = []\n            tot_spacings = []\n            for name in names:\n                name = name.replace('-', '_')\n                _position = kwargs.get(name + '_position')\n                if _position is None:\n                    _position = position\n                else:\n                    _position = NumberValue(_position)\n                    if _position and _position > -1 and _position < 1:\n                        _position.units = {'%':\n                                           _units_weights.get('%', 1), '_': '%'}\n                positions.append(_position)\n                _spacing = kwargs.get(name + '_spacing')\n                if _spacing is None:\n                    _spacing = spacing\n                else:\n                    if isinstance(_spacing, ListValue):\n                        _spacing = [int(NumberValue(\n                            v).value) for n, v in _spacing.items()]\n                    else:\n                        _spacing = [int(NumberValue(_spacing).value)]\n                    _spacing = (_spacing * 4)[:4]\n                spacings.append(_spacing)\n                if _position and _position.unit != '%':\n                    if vertical:\n                        if _position > 0:\n                            tot_spacings.append((_spacing[0], _spacing[\n                                1], _spacing[2], _spacing[3] + _position))\n                    else:\n                        if _position > 0:\n                            tot_spacings.append((_spacing[0] + _position,\n                                                 _spacing[1], _spacing[2], _spacing[3]))\n                else:\n                    tot_spacings.append(_spacing)\n            sizes = tuple(image.size for image in images)\n\n            _spacings = zip(*tot_spacings)\n            if vertical:\n                width = max(\n                    zip(*sizes)[0]) + max(_spacings[1]) + max(_spacings[3])\n                height = sum(\n                    zip(*sizes)[1]) + sum(_spacings[0]) + sum(_spacings[2])\n            else:\n                width = sum(\n                    zip(*sizes)[0]) + sum(_spacings[1]) + sum(_spacings[3])\n                height = max(\n                    zip(*sizes)[1]) + max(_spacings[0]) + max(_spacings[2])\n\n            new_image = Image.new(\n                mode='RGBA',\n                size=(width, height),\n                color=(0, 0, 0, 0)\n            )\n\n            offsets_x = []\n            offsets_y = []\n            offset = 0\n            for i, image in enumerate(images):\n                spacing = spacings[i]\n                position = positions[i]\n                if vertical:\n                    if position and position.unit == '%':\n                        x = width * position.value - \\\n                            (spacing[3] + sizes[i][1] + spacing[1])\n                    elif position.value < 0:\n                        x = width + position.value - \\\n                            (spacing[3] + sizes[i][1] + spacing[1])\n                    else:\n                        x = position.value\n                    offset += spacing[0]\n                    new_image.paste(image, (int(x + spacing[3]), offset))\n                    offsets_x.append(x)\n                    offsets_y.append(offset - spacing[0])\n                    offset += sizes[i][1] + spacing[2]\n                else:\n                    if position and position.unit == '%':\n                        y = height * position.value - \\\n                            (spacing[0] + sizes[i][1] + spacing[2])\n                    elif position.value < 0:\n                        y = height + position.value - \\\n                            (spacing[0] + sizes[i][1] + spacing[2])\n                    else:\n                        y = position.value\n                    offset += spacing[3]\n                    new_image.paste(image, (offset, int(y + spacing[0])))\n                    offsets_x.append(offset - spacing[3])\n                    offsets_y.append(y)\n                    offset += sizes[i][0] + spacing[1]\n\n            if dst_color:\n                src_color = ColorValue(\n                    src_color).value[:3] if src_color else (0, 0, 0)\n                dst_color = list(ColorValue(dst_color).value[:3])\n                pixdata = new_image.load()\n                for y in xrange(new_image.size[1]):\n                    for x in xrange(new_image.size[0]):\n                        if pixdata[x, y][:3] == src_color:\n                            pixdata[x,\n                                    y] = tuple(dst_color + [pixdata[x, y][3]])\n\n            try:\n                new_image.save(asset_path)\n            except IOError:\n                log.exception(\"Error while saving image\")\n            filetime = int(time.mktime(datetime.datetime.now().timetuple()))\n\n            url = '%s%s?_=%s' % (ASSETS_URL, asset_file, filetime)\n            asset = 'url(\"%s\") %s' % (escape(url), repeat)\n            # Use the sorted list to remove older elements (keep only 500\n            # objects):\n            if len(sprite_maps) > 1000:\n                for a in sorted(sprite_maps, key=lambda a: sprite_maps[a]['*'], reverse=True)[500:]:\n                    del sprite_maps[a]\n            # Add the new object:\n            map = dict(zip(names, zip(sizes, rfiles, offsets_x, offsets_y)))\n            map['*'] = datetime.datetime.now()\n            map['*f*'] = asset_file\n            map['*k*'] = key\n            map['*n*'] = map_name\n            map['*t*'] = filetime\n            pickle.dump((asset, map, zip(files, sizes)), open(\n                asset_path + '.cache', 'w'))\n            sprite_maps[asset] = map\n        for file, size in sizes:\n            sprite_images[file] = size\n    ret = StringValue(asset)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of a sprite map", "response": "def _sprite_map_name(map):\n    \"\"\"\n    Returns the name of a sprite map The name is derived from the folder than\n    contains the sprites.\n    \"\"\"\n    map = StringValue(map).value\n    sprite_map = sprite_maps.get(map)\n    if not sprite_map:\n        log.error(\"No sprite map found: %s\", map)\n    if sprite_map:\n        return StringValue(sprite_map['*n*'])\n    return StringValue(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sprite_file(map, sprite):\n    map = StringValue(map).value\n    sprite_name = StringValue(sprite).value\n    sprite_map = sprite_maps.get(map)\n    sprite = sprite_map and sprite_map.get(sprite_name)\n    if not sprite_map:\n        log.error(\"No sprite map found: %s\", map)\n    elif not sprite:\n        log.error(\"No sprite found: %s in %s\", sprite_name, sprite_map['*n*'])\n    if sprite:\n        return QuotedStringValue(sprite[1][0])\n    return StringValue(None)", "response": "Returns the relative path to the original file that is used when construction the sprite."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the image and background position for use in a single shorthand property", "response": "def _sprite(map, sprite, offset_x=None, offset_y=None):\n    \"\"\"\n    Returns the image and background position for use in a single shorthand\n    property\n    \"\"\"\n    map = StringValue(map).value\n    sprite_name = StringValue(sprite).value\n    sprite_map = sprite_maps.get(map)\n    sprite = sprite_map and sprite_map.get(sprite_name)\n    if not sprite_map:\n        log.error(\"No sprite map found: %s\", map)\n    elif not sprite:\n        log.error(\"No sprite found: %s in %s\", sprite_name, sprite_map['*n*'])\n    if sprite:\n        url = '%s%s?_=%s' % (ASSETS_URL, sprite_map['*f*'], sprite_map['*t*'])\n        x = NumberValue(offset_x or 0, 'px')\n        y = NumberValue(offset_y or 0, 'px')\n        if not x or (x <= -1 or x >= 1) and x.unit != '%':\n            x -= sprite[2]\n        if not y or (y <= -1 or y >= 1) and y.unit != '%':\n            y -= sprite[3]\n        pos = \"url(%s) %s %s\" % (escape(url), x, y)\n        return StringValue(pos)\n    return StringValue('0 0')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sprite_url(map):\n    map = StringValue(map).value\n    sprite_map = sprite_maps.get(map)\n    if not sprite_map:\n        log.error(\"No sprite map found: %s\", map)\n    if sprite_map:\n        url = '%s%s?_=%s' % (ASSETS_URL, sprite_map['*f*'], sprite_map['*t*'])\n        url = \"url(%s)\" % escape(url)\n        return StringValue(url)\n    return StringValue(None)", "response": "Returns a url to the sprite image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sprite_position(map, sprite, offset_x=None, offset_y=None):\n    map = StringValue(map).value\n    sprite_name = StringValue(sprite).value\n    sprite_map = sprite_maps.get(map)\n    sprite = sprite_map and sprite_map.get(sprite_name)\n    if not sprite_map:\n        log.error(\"No sprite map found: %s\", map)\n    elif not sprite:\n        log.error(\"No sprite found: %s in %s\", sprite_name, sprite_map['*n*'])\n    if sprite:\n        x = None\n        if offset_x is not None and not isinstance(offset_x, NumberValue):\n            x = str(offset_x)\n        if x not in ('left', 'right', 'center'):\n            if x:\n                offset_x = None\n            x = NumberValue(offset_x or 0, 'px')\n            if not x or (x <= -1 or x >= 1) and x.unit != '%':\n                x -= sprite[2]\n        y = None\n        if offset_y is not None and not isinstance(offset_y, NumberValue):\n            y = str(offset_y)\n        if y not in ('top', 'bottom', 'center'):\n            if y:\n                offset_y = None\n            y = NumberValue(offset_y or 0, 'px')\n            if not y or (y <= -1 or y >= 1) and y.unit != '%':\n                y -= sprite[3]\n        pos = '%s %s' % (x, y)\n        return StringValue(pos)\n    return StringValue('0 0')", "response": "Returns the position of the original image in the sprite."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the contents of an image in a CSS stylesheet.", "response": "def _inline_image(image, mime_type=None):\n    \"\"\"\n    Embeds the contents of a file directly inside your stylesheet, eliminating\n    the need for another HTTP request. For small files such images or fonts,\n    this can be a performance benefit at the cost of a larger generated CSS\n    file.\n    \"\"\"\n    file = StringValue(image).value\n    mime_type = StringValue(mime_type).value or mimetypes.guess_type(file)[0]\n    path = None\n    if callable(STATIC_ROOT):\n        try:\n            _file, _storage = list(STATIC_ROOT(file))[0]\n            path = _storage.open(_file)\n        except:\n            pass\n    else:\n        _path = os.path.join(STATIC_ROOT, file)\n        if os.path.exists(_path):\n            path = open(_path, 'rb')\n    if path:\n        url = 'data:' + mime_type + ';base64,' + base64.b64encode(path.read())\n    url = url = '%s%s?_=%s' % (STATIC_URL, file, 'NA')\n    inline = 'url(\"%s\")' % escape(url)\n    return StringValue(inline)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _image_url(image, dst_color=None, src_color=None):\n    if src_color and dst_color:\n        if not Image:\n            raise Exception(\"Images manipulation require PIL\")\n    file = StringValue(image).value\n    path = None\n    if callable(STATIC_ROOT):\n        try:\n            _file, _storage = list(STATIC_ROOT(file))[0]\n            d_obj = _storage.modified_time(_file)\n            filetime = int(time.mktime(d_obj.timetuple()))\n            if dst_color:\n                path = _storage.open(_file)\n        except:\n            filetime = 'NA'\n    else:\n        _path = os.path.join(STATIC_ROOT, file)\n        if os.path.exists(_path):\n            filetime = int(os.path.getmtime(_path))\n            if dst_color:\n                path = open(_path, 'rb')\n        else:\n            filetime = 'NA'\n    BASE_URL = STATIC_URL\n    if path:\n        src_color = tuple(int(round(c)) for c in ColorValue(\n            src_color).value[:3]) if src_color else (0, 0, 0)\n        dst_color = [int(round(c)) for c in ColorValue(dst_color).value[:3]]\n\n        file_name, file_ext = os.path.splitext(\n            os.path.normpath(file).replace('\\\\', '_').replace('/', '_'))\n        key = (filetime, src_color, dst_color)\n        key = file_name + '-' + base64.urlsafe_b64encode(\n            hashlib.md5(repr(key)).digest()).rstrip('=').replace('-', '_')\n        asset_file = key + file_ext\n        asset_path = os.path.join(ASSETS_ROOT, asset_file)\n\n        if os.path.exists(asset_path):\n            file = asset_file\n            BASE_URL = ASSETS_URL\n            filetime = int(os.path.getmtime(asset_path))\n        else:\n            image = Image.open(path)\n            image = image.convert(\"RGBA\")\n            pixdata = image.load()\n            for y in xrange(image.size[1]):\n                for x in xrange(image.size[0]):\n                    if pixdata[x, y][:3] == src_color:\n                        new_color = tuple(dst_color + [pixdata[x, y][3]])\n                        pixdata[x, y] = new_color\n            try:\n                image.save(asset_path)\n                file = asset_file\n                BASE_URL = ASSETS_URL\n            except IOError:\n                log.exception(\"Error while saving image\")\n    url = 'url(\"%s%s?_=%s\")' % (BASE_URL, file, filetime)\n    return StringValue(url)", "response": "Generates a path to an image found relative to the project s images\n    directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the width of the image found at the path supplied by image.", "response": "def _image_width(image):\n    \"\"\"\n    Returns the width of the image found at the path supplied by `image`\n    relative to your project's images directory.\n    \"\"\"\n    if not Image:\n        raise Exception(\"Images manipulation require PIL\")\n    file = StringValue(image).value\n    path = None\n    try:\n        width = sprite_images[file][0]\n    except KeyError:\n        width = 0\n        if callable(STATIC_ROOT):\n            try:\n                _file, _storage = list(STATIC_ROOT(file))[0]\n                path = _storage.open(_file)\n            except:\n                pass\n        else:\n            _path = os.path.join(STATIC_ROOT, file)\n            if os.path.exists(_path):\n                path = open(_path, 'rb')\n        if path:\n            image = Image.open(path)\n            size = image.size\n            width = size[0]\n            sprite_images[file] = size\n    return NumberValue(width, 'px')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _blank(*objs):\n    for o in objs:\n        if bool(o):\n            return BooleanValue(False)\n    return BooleanValue(True)", "response": "Returns true when the object is false an empty string or an empty list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compact(*args):\n    ret = {}\n    if len(args) == 1:\n        args = args[0]\n        if isinstance(args, ListValue):\n            args = args.value\n        if isinstance(args, dict):\n            for i, item in args.items():\n                if bool(item):\n                    ret[i] = item\n        elif bool(args):\n            ret[0] = args\n    else:\n        for i, item in enumerate(args):\n            if bool(item):\n                ret[i] = item\n    return ListValue(ret)", "response": "Returns a new list after removing any non - true values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nth(lst, n=1):\n    n = StringValue(n).value\n    lst = ListValue(lst).value\n    try:\n        n = int(float(n)) - 1\n        n = n % len(lst)\n    except:\n        if n.lower() == 'first':\n            n = 0\n        elif n.lower() == 'last':\n            n = -1\n    try:\n        ret = lst[n]\n    except KeyError:\n        lst = [v for k, v in sorted(lst.items()) if isinstance(k, int)]\n        try:\n            ret = lst[n]\n        except:\n            ret = ''\n    return ret.__class__(ret)", "response": "Return the Nth item in the string\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef locate_blocks(self, codestr):\n        def _strip_selprop(selprop, lineno):\n            _lineno, _sep, selprop = selprop.partition(SEPARATOR)\n            if _sep == SEPARATOR:\n                lineno = _lineno.strip()\n                lineno = int(lineno) if lineno else 0\n            else:\n                selprop = _lineno\n            selprop = _nl_num_re.sub('\\n', selprop)\n            selprop = selprop.strip()\n            return selprop, lineno\n\n        def _strip(selprop):\n            selprop, _ = _strip_selprop(selprop, 0)\n            return selprop\n\n        lineno = 0\n\n        par = 0\n        instr = None\n        depth = 0\n        skip = False\n        thin = None\n        i = init = safe = lose = 0\n        start = end = None\n\n        for m in _blocks_re.finditer(codestr):\n            _s = m.start(0)\n            _e = m.end(0)\n            i = _e - 1\n            if _s == _e:\n                break\n            if instr is not None:\n                if codestr[i] == instr:\n                    instr = None\n            elif codestr[i] in ('\"', \"'\"):\n                instr = codestr[i]\n            elif codestr[i] == '(':\n                par += 1\n                thin = None\n                safe = i + 1\n            elif codestr[i] == ')':\n                par -= 1\n            elif not par and not instr:\n                if codestr[i] == '{':\n                    if depth == 0:\n                        if i > 0 and codestr[i - 1] == '#':\n                            skip = True\n                        else:\n                            start = i\n                            if thin is not None and _strip(codestr[thin:i - 1]):\n                                init = thin\n                            if lose < init:\n                                losestr = codestr[lose:init]\n                                for _property in losestr.split(';'):\n                                    _property, lineno = _strip_selprop(\n                                        _property, lineno)\n                                    if _property:\n                                        yield lineno, _property, None\n                                lose = init\n                            thin = None\n                    depth += 1\n                elif codestr[i] == '}':\n                    if depth > 0:\n                        depth -= 1\n                        if depth == 0:\n                            if not skip:\n                                end = i\n                                _selectors, lineno = _strip_selprop(\n                                    codestr[init:start], lineno)\n                                _codestr = codestr[start + 1:end].strip()\n                                if _selectors:\n                                    yield lineno, _selectors, _codestr\n                                init = safe = lose = end + 1\n                                thin = None\n                            skip = False\n                elif depth == 0:\n                    if codestr[i] == ';':\n                        init = safe = i + 1\n                        thin = None\n                    elif codestr[i] == ',':\n                        if thin is not None and _strip(codestr[thin:i - 1]):\n                            init = thin\n                        thin = None\n                        safe = i + 1\n                    elif codestr[i] == '\\n':\n                        if thin is None and _strip(codestr[safe:i - 1]):\n                            thin = i + 1\n                        elif thin is not None and _strip(codestr[thin:i - 1]):\n                            init = i + 1\n                            thin = None\n        if depth > 0:\n            if not skip:\n                _selectors, lineno = _strip_selprop(\n                    codestr[init:start], lineno)\n                _codestr = codestr[start + 1:].strip()\n                if _selectors:\n                    yield lineno, _selectors, _codestr\n                if par:\n                    raise Exception(\"Missing closing parenthesis somewhere in block: '%s'\" %\n                                    _selectors)\n                elif instr:\n                    raise Exception(\"Missing closing string somewhere in block: '%s'\" %\n                                    _selectors)\n                else:\n                    raise Exception(\"Block never closed: '%s'\" % _selectors)\n        losestr = codestr[lose:]\n        for _property in losestr.split(';'):\n            _property, lineno = _strip_selprop(_property, lineno)\n            if _property:\n                yield lineno, _property, None", "response": "Locate all code blocks between a proper keycoat and a proper keycoat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize_selectors(self, _selectors, extra_selectors=None, extra_parents=None):\n        # Fixe tabs and spaces in selectors\n        _selectors = _spaces_re.sub(' ', _selectors)\n\n        if isinstance(extra_selectors, basestring):\n            extra_selectors = extra_selectors.split(',')\n\n        if isinstance(extra_parents, basestring):\n            extra_parents = extra_parents.split('&')\n\n        parents = set()\n        if ' extends ' in _selectors:\n            selectors = set()\n            for key in _selectors.split(','):\n                child, _, parent = key.partition(' extends ')\n                child = child.strip()\n                parent = parent.strip()\n                selectors.add(child)\n                parents.update(\n                    s.strip() for s in parent.split('&') if s.strip())\n        else:\n            selectors = set(\n                s.strip() for s in _selectors.split(',') if s.strip())\n        if extra_selectors:\n            selectors.update(s.strip() for s in extra_selectors if s.strip())\n        selectors.discard('')\n        if not selectors:\n            return ''\n        if extra_parents:\n            parents.update(s.strip() for s in extra_parents if s.strip())\n        parents.discard('')\n        if parents:\n            return ','.join(sorted(selectors)) + ' extends ' + '&'.join(sorted(parents))\n        return ','.join(sorted(selectors))", "response": "Normalizes or extends selectors in a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _do_functions(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        if name:\n            funct, params, _ = name.partition('(')\n            funct = funct.strip()\n            params = split_params(depar(params + _))\n            defaults = {}\n            new_params = []\n            for param in params:\n                param, _, default = param.partition(':')\n                param = param.strip()\n                default = default.strip()\n                if param:\n                    new_params.append(param)\n                    if default:\n                        default = self.apply_vars(\n                            default, rule[CONTEXT], None, rule)\n                        defaults[param] = default\n            context = rule[CONTEXT].copy()\n            for p in new_params:\n                context.pop(p, None)\n            mixin = [list(new_params), defaults, self.\n                     apply_vars(c_codestr, context, None, rule)]\n            if code == '@function':\n                def _call(mixin):\n                    def __call(R, *args, **kwargs):\n                        m_params = mixin[0]\n                        m_vars = rule[CONTEXT].copy()\n                        m_vars.update(mixin[1])\n                        m_codestr = mixin[2]\n                        for i, a in enumerate(args):\n                            m_vars[m_params[i]] = a\n                        m_vars.update(kwargs)\n                        _options = rule[OPTIONS].copy()\n                        _rule = spawn_rule(R, codestr=m_codestr, context=m_vars, options=_options, deps=set(), properties=[], final=False, lineno=c_lineno)\n                        self.manage_children(_rule, p_selectors, p_parents,\n                                             p_children, (scope or '') + '', R[MEDIA])\n                        ret = _rule[OPTIONS].pop('@return', '')\n                        return ret\n                    return __call\n                _mixin = _call(mixin)\n                _mixin.mixin = mixin\n                mixin = _mixin\n            # Insert as many @mixin options as the default parameters:\n            while len(new_params):\n                rule[OPTIONS]['%s %s:%d' % (code, funct,\n                                            len(new_params))] = mixin\n                param = new_params.pop()\n                if param not in defaults:\n                    break\n            if not new_params:\n                rule[OPTIONS][code + ' ' + funct + ':0'] = mixin", "response": "Handles functions in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimplementing include for include rule", "response": "def _do_include(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        \"\"\"\n        Implements @include, for @mixins\n        \"\"\"\n        funct, params, _ = name.partition('(')\n        funct = funct.strip()\n        funct = self.do_glob_math(\n            funct, rule[CONTEXT], rule[OPTIONS], rule, True)\n        params = split_params(depar(params + _))\n        new_params = {}\n        num_args = 0\n        for param in params:\n            varname, _, param = param.partition(':')\n            if param:\n                param = param.strip()\n                varname = varname.strip()\n            else:\n                param = varname.strip()\n                varname = num_args\n                if param:\n                    num_args += 1\n            if param:\n                new_params[varname] = param\n        mixin = rule[OPTIONS].get('@mixin %s:%s' % (funct, num_args))\n        if not mixin:\n            # Fallback to single parmeter:\n            mixin = rule[OPTIONS].get('@mixin %s:1' % (funct,))\n            if mixin and all(map(lambda o: isinstance(o, int), new_params.keys())):\n                new_params = {0: ', '.join(new_params.values())}\n        if mixin:\n            m_params = mixin[0]\n            m_vars = mixin[1].copy()\n            m_codestr = mixin[2]\n            for varname, value in new_params.items():\n                try:\n                    m_param = m_params[varname]\n                except:\n                    m_param = varname\n                value = self.calculate(\n                    value, rule[CONTEXT], rule[OPTIONS], rule)\n                m_vars[m_param] = value\n            for p in m_vars:\n                if p not in new_params:\n                    if isinstance(m_vars[p], basestring):\n                        value = self.calculate(\n                            m_vars[p], m_vars, rule[OPTIONS], rule)\n                        m_vars[p] = value\n            _context = rule[CONTEXT].copy()\n            _context.update(m_vars)\n            _rule = spawn_rule(\n                rule, codestr=m_codestr, context=_context, lineno=c_lineno)\n            self.manage_children(\n                _rule, p_selectors, p_parents, p_children, scope, media)\n        else:\n            log.error(\"Required mixin not found: %s:%d (%s)\",\n                      funct, num_args, rule[INDEX][rule[LINENO]])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement @import Load and import mixins and functions and rules", "response": "def _do_import(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        \"\"\"\n        Implements @import\n        Load and import mixins and functions and rules\n        \"\"\"\n        i_codestr = None\n        if '..' not in name and '://' not in name and 'url(' not in name:  # Protect against going to prohibited places...\n            names = name.split(',')\n            for name in names:\n                name = dequote(name.strip())\n                if '@import ' + name not in rule[OPTIONS]:  # If already imported in this scope, skip...\n                    try:\n                        raise KeyError\n                        i_codestr = self._scss_files[name]\n                    except KeyError:\n                        filename = os.path.basename(name)\n                        dirname = os.path.dirname(name)\n                        load_paths = []\n                        i_codestr = None\n                        for path in ['./'] + LOAD_PATHS.split(','):\n                            for basepath in ['./', os.path.dirname(rule[PATH])]:\n                                i_codestr = None\n                                full_path = os.path.realpath(\n                                    os.path.join(path, basepath, dirname))\n                                if full_path not in load_paths:\n                                    try:\n                                        full_filename = os.path.join(full_path,\n                                                                     '_' + filename + '.scss')\n                                        i_codestr = open(full_filename).read()\n                                    except:\n                                        try:\n                                            full_filename = os.path.join(\n                                                full_path, filename + '.scss')\n                                            i_codestr = open(\n                                                full_filename).read()\n                                        except:\n                                            try:\n                                                full_filename = os.path.join(\n                                                    full_path, '_' + filename)\n                                                i_codestr = open(\n                                                    full_filename).read()\n                                            except:\n                                                try:\n                                                    full_filename = os.path.join(\n                                                        full_path, filename)\n                                                    i_codestr = open(\n                                                        full_filename).read()\n                                                except:\n                                                    pass\n                                    if i_codestr is not None:\n                                        break\n                                    else:\n                                        load_paths.append(full_path)\n                            if i_codestr is not None:\n                                break\n                        if i_codestr is None:\n                            i_codestr = self._do_magic_import(rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name)\n                        i_codestr = self._scss_files[name] = i_codestr and self.load_string(\n                            i_codestr, full_filename)\n                    if i_codestr is None:\n                        log.warn(\"File to import not found or unreadable: '%s'\\nLoad paths:\\n\\t%s\",\n                                 filename, \"\\n\\t\".join(load_paths))\n                    else:\n                        _rule = spawn_rule(rule, codestr=i_codestr,\n                                           path=full_filename, lineno=c_lineno)\n                        self.manage_children(_rule,\n                                             p_selectors, p_parents, p_children, scope, media)\n                        rule[OPTIONS]['@import ' + name] = True\n        else:\n            rule[PROPERTIES].append((c_lineno, c_property, None))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimplements @import for sprite - maps directories", "response": "def _do_magic_import(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        \"\"\"\n        Implements @import for sprite-maps\n        Imports magic sprite map directories\n        \"\"\"\n        if callable(STATIC_ROOT):\n            files = sorted(STATIC_ROOT(name))\n        else:\n            glob_path = os.path.join(STATIC_ROOT, name)\n            files = glob.glob(glob_path)\n            files = sorted((file[len(STATIC_ROOT):], None) for file in files)\n\n        if files:\n            # Build magic context\n            map_name = os.path.normpath(\n                os.path.dirname(name)).replace('\\\\', '_').replace('/', '_')\n            kwargs = {}\n\n            def setdefault(var, val):\n                _var = '$' + map_name + '-' + var\n                if _var in rule[CONTEXT]:\n                    kwargs[var] = interpolate(rule[CONTEXT][_var], rule)\n                else:\n                    rule[CONTEXT][_var] = val\n                    kwargs[var] = interpolate(val, rule)\n                return rule[CONTEXT][_var]\n\n            setdefault(\n                'sprite-base-class', StringValue('.' + map_name + '-sprite'))\n            setdefault('sprite-dimensions', BooleanValue(False))\n            position = setdefault('position', NumberValue(0, '%'))\n            spacing = setdefault('spacing', NumberValue(0))\n            repeat = setdefault('repeat', StringValue('no-repeat'))\n            names = tuple(os.path.splitext(\n                os.path.basename(file))[0] for file, storage in files)\n            for n in names:\n                setdefault(n + '-position', position)\n                setdefault(n + '-spacing', spacing)\n                setdefault(n + '-repeat', repeat)\n            sprite_map = _sprite_map(name, **kwargs)\n            rule[CONTEXT]['$' + map_name + '-' + 'sprites'] = sprite_map\n            ret = '''\n                @import \"compass/utilities/sprites/base\";\n\n                // All sprites should extend this class\n                // The %(map_name)s-sprite mixin will do so for you.\n                #{$%(map_name)s-sprite-base-class} {\n                    background: $%(map_name)s-sprites;\n                }\n\n                // Use this to set the dimensions of an element\n                // based on the size of the original image.\n                @mixin %(map_name)s-sprite-dimensions($name) {\n                    @include sprite-dimensions($%(map_name)s-sprites, $name);\n                }\n\n                // Move the background position to display the sprite.\n                @mixin %(map_name)s-sprite-position($name, $offset-x: 0, $offset-y: 0) {\n                    @include sprite-position($%(map_name)s-sprites, $name, $offset-x, $offset-y);\n                }\n\n                // Extends the sprite base class and set the background position for the desired sprite.\n                // It will also apply the image dimensions if $dimensions is true.\n                @mixin %(map_name)s-sprite($name, $dimensions: $%(map_name)s-sprite-dimensions, $offset-x: 0, $offset-y: 0) {\n                    @extend #{$%(map_name)s-sprite-base-class};\n                    @include sprite($%(map_name)s-sprites, $name, $dimensions, $offset-x, $offset-y);\n                }\n\n                @mixin %(map_name)s-sprites($sprite-names, $dimensions: $%(map_name)s-sprite-dimensions) {\n                    @include sprites($%(map_name)s-sprites, $sprite-names, $%(map_name)s-sprite-base-class, $dimensions);\n                }\n\n                // Generates a class for each sprited image.\n                @mixin all-%(map_name)s-sprites($dimensions: $%(map_name)s-sprite-dimensions) {\n                    @include %(map_name)s-sprites(%(sprites)s, $dimensions);\n                }\n            ''' % {'map_name': map_name, 'sprites': ' '.join(names)}\n            return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the if - rule.", "response": "def _do_if(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        \"\"\"\n        Implements @if and @else if\n        \"\"\"\n        if code != '@if':\n            if '@if' not in rule[OPTIONS]:\n                log.error(\"@else with no @if (%s)\", rule[INDEX][rule[LINENO]])\n            val = not rule[OPTIONS].get('@if', True)\n            name = c_property[9:].strip()\n        else:\n            val = True\n        if val:\n            val = self.calculate(name, rule[CONTEXT], rule[OPTIONS], rule)\n            val = bool(False if not val or val in('0', 'false',) or (isinstance(\n                val, basestring) and _variable_re.match(val)) else val)\n            if val:\n                rule[CODESTR] = c_codestr\n                self.manage_children(\n                    rule, p_selectors, p_parents, p_children, scope, media)\n            rule[OPTIONS]['@if'] = val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the else rule.", "response": "def _do_else(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr, code, name):\n        \"\"\"\n        Implements @else\n        \"\"\"\n        if '@if' not in rule[OPTIONS]:\n            log.error(\"@else with no @if (%s\", rule[INDEX][rule[LINENO]])\n        val = rule[OPTIONS].pop('@if', True)\n        if not val:\n            rule[CODESTR] = c_codestr\n            self.manage_children(\n                rule, p_selectors, p_parents, p_children, scope, media)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets variables from a rule.", "response": "def _get_variables(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr):\n        \"\"\"\n        Implements @variables and @vars\n        \"\"\"\n        _rule = list(rule)\n        _rule[CODESTR] = c_codestr\n        _rule[PROPERTIES] = rule[CONTEXT]\n        self.manage_children(\n            _rule, p_selectors, p_parents, p_children, scope, media)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_properties(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr):\n        prop, value = (_prop_split_re.split(c_property, 1) + [None])[:2]\n        try:\n            is_var = (c_property[len(prop)] == '=')\n        except IndexError:\n            is_var = False\n        prop = prop.strip()\n        prop = self.do_glob_math(\n            prop, rule[CONTEXT], rule[OPTIONS], rule, True)\n        if prop:\n            if value:\n                value = value.strip()\n                value = self.calculate(\n                    value, rule[CONTEXT], rule[OPTIONS], rule)\n            _prop = (scope or '') + prop\n            if is_var or prop.startswith('$') and value is not None:\n                if isinstance(value, basestring):\n                    if '!default' in value:\n                        if _prop in rule[CONTEXT]:\n                            value = None\n                        else:\n                            value = value.replace(\n                                '!default', '').replace('  ', ' ').strip()\n                elif isinstance(value, ListValue):\n                    value = ListValue(value)\n                    for k, v in value.value.items():\n                        if v == '!default':\n                            if _prop in rule[CONTEXT]:\n                                value = None\n                            else:\n                                del value.value[k]\n                                value = value.first(\n                                ) if len(value) == 1 else value\n                            break\n                if value is not None:\n                    rule[CONTEXT][_prop] = value\n            else:\n                _prop = self.apply_vars(\n                    _prop, rule[CONTEXT], rule[OPTIONS], rule, True)\n                rule[PROPERTIES].append((c_lineno, _prop,\n                                         to_str(value) if value is not None else None))", "response": "Implements properties and variables extraction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement Nested CSS rules", "response": "def _nest_rules(self, rule, p_selectors, p_parents, p_children, scope, media, c_lineno, c_property, c_codestr):\n        \"\"\"\n        Implements Nested CSS rules\n        \"\"\"\n        if c_property == self.construct and rule[MEDIA] == media:\n            rule[CODESTR] = c_codestr\n            self.manage_children(\n                rule, p_selectors, p_parents, p_children, scope, media)\n        else:\n            c_property = self.apply_vars(\n                c_property, rule[CONTEXT], rule[OPTIONS], rule, True)\n\n            c_selectors = self.normalize_selectors(c_property)\n            c_selectors, _, c_parents = c_selectors.partition(' extends ')\n\n            better_selectors = set()\n            c_selectors = c_selectors.split(',')\n            for c_selector in c_selectors:\n                for p_selector in p_selectors:\n                    if c_selector == self.construct:\n                        better_selectors.add(p_selector)\n                    elif '&' in c_selector:  # Parent References\n                        better_selectors.add(\n                            c_selector.replace('&', p_selector))\n                    elif p_selector:\n                        better_selectors.add(p_selector + ' ' + c_selector)\n                    else:\n                        better_selectors.add(c_selector)\n            better_selectors = ','.join(sorted(better_selectors))\n\n            if c_parents:\n                parents = set(p.strip() for p in c_parents.split('&'))\n                parents.discard('')\n                if parents:\n                    better_selectors += ' extends ' + '&'.join(sorted(parents))\n\n            _rule = spawn_rule(rule, codestr=c_codestr, deps=set(), context=rule[CONTEXT].copy(), options=rule[OPTIONS].copy(), selectors=better_selectors, properties=[], final=False, media=media, lineno=c_lineno)\n\n            p_children.appendleft(_rule)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef link_with_parents(self, parent, c_selectors, c_rules):\n        parent_found = None\n        for p_selectors, p_rules in self.parts.items():\n            _p_selectors, _, _ = p_selectors.partition(' extends ')\n            _p_selectors = _p_selectors.split(',')\n\n            new_selectors = set()\n            found = False\n\n            # Finds all the parent selectors and parent selectors with another\n            # bind selectors behind. For example, if `.specialClass extends\n            # .baseClass`,\n            # and there is a `.baseClass` selector, the extension should create\n            # `.specialClass` for that rule, but if there's also a `.baseClass\n            # a`\n            # it also should create `.specialClass a`\n            for p_selector in _p_selectors:\n                if parent in p_selector:\n                    # get the new child selector to add (same as the parent\n                    # selector but with the child name)\n                    # since selectors can be together, separated with # or .\n                    # (i.e. something.parent) check that too:\n                    for c_selector in c_selectors.split(','):\n                        # Get whatever is different between the two selectors:\n                        _c_selector, _parent = c_selector, parent\n                        lcp = self.longest_common_prefix(_c_selector, _parent)\n                        if lcp:\n                            _c_selector = _c_selector[lcp:]\n                            _parent = _parent[lcp:]\n                        lcs = self.longest_common_suffix(_c_selector, _parent)\n                        if lcs:\n                            _c_selector = _c_selector[:-lcs]\n                            _parent = _parent[:-lcs]\n                        if _c_selector and _parent:\n                            # Get the new selectors:\n                            prev_symbol = '(?<![#.:])' if _parent[\n                                0] in ('#', '.', ':') else r'(?<![-\\w#.:])'\n                            post_symbol = r'(?![-\\w])'\n                            new_parent = re.sub(prev_symbol + _parent +\n                                                post_symbol, _c_selector, p_selector)\n                            if p_selector != new_parent:\n                                new_selectors.add(new_parent)\n                                found = True\n\n            if found:\n                # add parent:\n                parent_found = parent_found or []\n                parent_found.extend(p_rules)\n\n            if new_selectors:\n                new_selectors = self.normalize_selectors(\n                    p_selectors, new_selectors)\n                # rename node:\n                if new_selectors != p_selectors:\n                    del self.parts[p_selectors]\n                    self.parts.setdefault(new_selectors, [])\n                    self.parts[new_selectors].extend(p_rules)\n\n                deps = set()\n                # save child dependencies:\n                for c_rule in c_rules or []:\n                    c_rule[SELECTORS] = c_selectors  # re-set the SELECTORS for the rules\n                    deps.add(c_rule[POSITION])\n\n                for p_rule in p_rules:\n                    p_rule[SELECTORS] = new_selectors  # re-set the SELECTORS for the rules\n                    p_rule[DEPS].update(\n                        deps)  # position is the \"index\" of the object\n\n        return parent_found", "response": "Link with a parent for the current child rule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_extends(self):\n        # To be able to manage multiple extends, you need to\n        # destroy the actual node and create many nodes that have\n        # mono extend. The first one gets all the css rules\n        for _selectors, rules in self.parts.items():\n            if ' extends ' in _selectors:\n                selectors, _, parent = _selectors.partition(' extends ')\n                parents = parent.split('&')\n                del self.parts[_selectors]\n                for parent in parents:\n                    new_selectors = selectors + ' extends ' + parent\n                    self.parts.setdefault(new_selectors, [])\n                    self.parts[new_selectors].extend(rules)\n                    rules = []\n                        # further rules extending other parents will be empty\n\n        cnt = 0\n        parents_left = True\n        while parents_left and cnt < 10:\n            cnt += 1\n            parents_left = False\n            for _selectors in self.parts.keys():\n                selectors, _, parent = _selectors.partition(' extends ')\n                if parent:\n                    parents_left = True\n                    if _selectors not in self.parts:\n                        continue  # Nodes might have been renamed while linking parents...\n\n                    rules = self.parts[_selectors]\n\n                    del self.parts[_selectors]\n                    self.parts.setdefault(selectors, [])\n                    self.parts[selectors].extend(rules)\n\n                    parents = self.link_with_parents(parent, selectors, rules)\n\n                    if parents is None:\n                        log.warn(\"Parent rule not found: %s\", parent)\n                    else:\n                        # from the parent, inherit the context and the options:\n                        new_context = {}\n                        new_options = {}\n                        for parent in parents:\n                            new_context.update(parent[CONTEXT])\n                            new_options.update(parent[OPTIONS])\n                        for rule in rules:\n                            _new_context = new_context.copy()\n                            _new_context.update(rule[CONTEXT])\n                            rule[CONTEXT] = _new_context\n                            _new_options = new_options.copy()\n                            _new_options.update(rule[OPTIONS])\n                            rule[OPTIONS] = _new_options", "response": "Parse the extends part of the css file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_css(self, fileid=None):\n        if fileid:\n            rules = self._rules.get(fileid) or []\n        else:\n            rules = self.rules\n\n        compress = self._scss_opts.get('compress', True)\n        if compress:\n            sc, sp, tb, nl = False, '', '', ''\n        else:\n            sc, sp, tb, nl = True, ' ', '  ', '\\n'\n\n        scope = set()\n        return self._create_css(rules, scope, sc, sp, tb, nl, not compress and self._scss_opts.get('debug_info', False))", "response": "Generate the final CSS string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps a function to allow calling any function with any arguments as parameters.", "response": "def _wrap(fn):\n        \"\"\"\n        Wrapper function to allow calling any function\n        using Value objects as parameters.\n        \"\"\"\n        def _func(*args):\n            merged = None\n            _args = []\n            for arg in args:\n                if merged.__class__ != arg.__class__:\n                    if merged is None:\n                        merged = arg.__class__(None)\n                    else:\n                        merged = Value._merge_type(merged, arg)(None)\n                merged.merge(arg)\n                if isinstance(arg, Value):\n                    arg = arg.value\n                _args.append(arg)\n            merged.value = fn(*_args)\n            return merged\n        return _func"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the i'th token and return it.", "response": "def token(self, i, restrict=None):\n        \"\"\"\n        Get the i'th token, and if i is one past the end, then scan\n        for another token; restrict is a list of tokens that\n        are allowed, or 0 for any token.\n        \"\"\"\n        tokens_len = len(self.tokens)\n        if i == tokens_len:  # We are at the end, ge the next...\n            tokens_len += self.scan(restrict)\n        if i < tokens_len:\n            if restrict and self.restrictions[i] and restrict > self.restrictions[i]:\n                raise NotImplementedError(\n                    \"Unimplemented: restriction set changed\")\n            return self.tokens[i]\n        raise NoMoreTokens()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scan(self, restrict):\n        # Keep looking for a token, ignoring any in self.ignore\n        while True:\n            # Search the patterns for a match, with earlier\n            # tokens in the list having preference\n            best_pat = None\n            best_pat_len = 0\n            for p, regexp in self.patterns:\n                # First check to see if we're restricting to this token\n                if restrict and p not in restrict and p not in self.ignore:\n                    continue\n                m = regexp.match(self.input, self.pos)\n                if m:\n                    # We got a match\n                    best_pat = p\n                    best_pat_len = len(m.group(0))\n                    break\n\n            # If we didn't find anything, raise an error\n            if best_pat is None:\n                msg = \"Bad Token\"\n                if restrict:\n                    msg = \"Trying to find one of \" + \", \".join(restrict)\n                raise SyntaxError(self.pos, msg)\n\n            # If we found something that isn't to be ignored, return it\n            if best_pat in self.ignore:\n                # This token should be ignored ..\n                self.pos += best_pat_len\n            else:\n                end_pos = self.pos + best_pat_len\n                # Create a token with this data\n                token = (\n                    self.pos,\n                    end_pos,\n                    best_pat,\n                    self.input[self.pos:end_pos]\n                )\n                self.pos = end_pos\n                # Only add this token if it's not in the list\n                # (to prevent looping)\n                if not self.tokens or token != self.tokens[-1]:\n                    self.tokens.append(token)\n                    self.restrictions.append(restrict)\n                    return 1\n                break\n        return 0", "response": "Scan another token and add it to the list self. tokens self. restrictions and self. restrictions\n        Returns 1 if the token was found and 0 if not found"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _scan(self, type):\n        tok = self._scanner.token(self._pos, set([type]))\n        if tok[2] != type:\n            raise SyntaxError(tok[0], \"Trying to find \" + type)\n        self._pos += 1\n        return tok[3]", "response": "Scan for a specific type of entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding files in a directory and return their base directories recursively or not.", "response": "def find_files(directory, pattern, recursively=True):\n    \"\"\"\n    Yield a list of files with their base directories, recursively or not.\n\n    Returns:\n        A list of (base_directory, filename)\n\n    Args:\n        directory: base directory to start the search.\n        pattern: fnmatch pattern for filenames.\n        complete_filename: return complete filename or not?\n        recursively: do we recurse or not?\n    \"\"\"\n\n    for root, dirs, files in os.walk(directory):\n        for basename in files:\n            if fnmatch.fnmatch(basename, pattern):\n                yield root, basename\n        if not recursively:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the form value.", "response": "def validate(self):\n        \"\"\"Run the form value through the validators, and update the error field if needed\"\"\"\n        if self.error:\n            return False\n\n        for v in self.validators:\n            self.error = v(self.value)\n            if self.error:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the value of the attribute from the request.", "response": "def extract_value(self, data):\n        \"\"\"\n        Extract the data from the request\n        :param data: A mult-dict with either the post or get query\n        \"\"\"\n        if self.name not in data and not self.allow_missing:\n            raise exceptions.FieldNotFound('Field {} is missing from request'.format(self.name))\n        \n        if self.multiple_inputs:\n            self.value = []\n            for value in data.getlist(self.name):\n                if self.strip_value:\n                    value = value.strip()\n                if value == '' and self.convert_empty_to_none:\n                    value = None\n\n                self.value.append(value)\n        else:\n            self.value = data.get(self.name)\n            if self.value is not None:\n                if self.strip_value:\n                    self.value = self.value.strip()\n                if self.value == '' and self.convert_empty_to_none:\n                    self.value = None\n\n        # Convert the value to the correct data type\n        self.convert_value()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the input column attributes.", "response": "def get_input_column_attributes(self, extra_classes=None):\n        \"\"\"\n        :param extra_classes: String with space separated list of classes or None\n        \"\"\"\n        all_classes = []\n        css_class = self.input_column_class\n        if css_class:\n            all_classes.append(css_class)\n        if extra_classes:\n            all_classes.append(extra_classes)\n\n        style = self.input_column_style\n        parts = []\n\n        if all_classes:\n            parts.append('class=\"{}\"'.format(' '.join(all_classes)))\n\n        if style:\n            parts.append('style=\"{}\"'.format(style))\n\n        return Markup(' '.join(parts))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef form_group_classes(self):\n        classes = ['form-group']\n        if self.style == styles.BOOTSTRAP_4 and self.form_type == formtype.HORIZONTAL:\n            classes.append('row')\n        if self.error and self.style == styles.BOOTSTRAP_3:\n            classes.append('has-error')\n        if self.form_group_css_class:\n            classes.append(self.form_group_css_class)\n\n        return ' '.join(classes)", "response": "Returns the full list of classes for the form group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the full list of classes for the class attribute of the input.", "response": "def input_classes(self):\n        \"\"\"\n        Full list of classes for the class attribute of the input, returned as a string with\n        spaces separating each class.\n        \"\"\"\n        classes = [self.base_input_css_class]\n        if self.css_class:\n            classes.append(self.css_class)\n\n        if self.style == styles.BOOTSTRAP_4 and self.error:\n            classes.append('is-invalid')\n\n        return ' '.join(classes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender the form and all sections to HTML", "response": "def render(self):\n        \"\"\"Render the form and all sections to HTML\"\"\"\n        return Markup(env.get_template('form.html').render(form=self,\n                                                           render_open_tag=True,\n                                                           render_close_tag=True,\n                                                           render_before=True,\n                                                           render_sections=True,\n                                                           render_after=True,\n                                                           generate_csrf_token=None if self.disable_csrf else _csrf_generation_function))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the form up to the first section.", "response": "def render_before_sections(self):\n        \"\"\"Render the form up to the first section.  This will open the form tag but not close it.\"\"\"\n        return Markup(env.get_template('form.html').render(form=self,\n                                                           render_open_tag=True,\n                                                           render_close_tag=False,\n                                                           render_before=True,\n                                                           render_sections=False,\n                                                           render_after=False,\n                                                           generate_csrf_token=None if self.action else _csrf_generation_function))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_form_data(self):\n        if self.processed_data:\n            raise exceptions.AlreadyProcessed('The data has already been processed for this form')\n        \n        if self.readonly:\n            return\n\n        if request.method == self.method:\n            if self.method == 'POST':\n                data = request.form\n            else:\n                data = request.args\n\n            if self.submitted_hidden_input_name in data:\n                # The form has been submitted\n                self.processed_data = True\n\n                for field in self.all_fields:\n                    # We need to skip readonly fields\n                    if field.readonly:\n                        pass\n                    else:\n                        field.extract_value(data)\n\n                        # Validate the field\n                        if not field.validate():\n                            log.debug('Validation error in field \\'%s\\': %s' % (field.name, field.error))\n                            self.has_errors = True", "response": "Attempt to read the form data from the request"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value for a field if it exists otherwise returns default", "response": "def get_if_present(self, name, default=None):\n        \"\"\"\n        Returns the value for a field, but if the field doesn't exist will return default instead\n        \"\"\"\n        if not self.processed_data:\n            raise exceptions.FormNotProcessed('The form data has not been processed yet')\n\n        if name in self.field_dict:\n            return self[name]\n\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisable the validation rules for a field", "response": "def disable_validation(self, field_name):\n        \"\"\"Disable the validation rules for a field\"\"\"\n        field = self.field_dict.get(field_name)\n\n        if not field:\n            raise exceptions.FieldNotFound('Field not found: \\'%s\\' when trying to disable validation' % field_name)\n        \n        field.validators = []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_type(self, form_type, css_class=None):\n        self.form_type = form_type\n        \n        if css_class is None:\n            self.css_class = self.get_default_css_class(form_type)\n        else:\n            self.css_class = css_class\n        \n        return ''", "response": "This function is used to set the form type and css class for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying certain behaviors to commits or URLs that need polishing before they are ready for screenshots For example, if you have 10 commits in a row where static file links were broken, you could re-write the html in memory as it is interpreted. Keyword arguments: commit_indexes -- A list of indexes to apply the wrapped function to url -- A list of URLs to apply the wrapped function to", "response": "def polish(commit_indexes=None, urls=None):\n    '''\n    Apply certain behaviors to commits or URLs that need polishing before they are ready for screenshots\n\n    For example, if you have 10 commits in a row where static file links were broken, you could re-write the html\n    in memory as it is interpreted.\n\n    Keyword arguments:\n    commit_indexes -- A list of indexes to apply the wrapped function to\n    url -- A list of URLs to apply the wrapped function to\n    '''\n    def decorator(f):\n        if commit_indexes:\n            f.polish_commit_indexes = commit_indexes\n        if urls:\n            f.polish_urls = urls\n\n        @wraps(f)\n        def wrappee(*args, **kwargs):\n            return f(*args, **kwargs)\n\n        return wrappee\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef localize(date_time, time_zone):\n\n    if datetime_is_naive(date_time):\n        ret = time_zone.localize(date_time)\n    else:\n        ret = date_time.astimezone(time_zone)\n    return ret", "response": "Returns a datetime adjusted to a timezone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timestamp_to_datetime(cls, time_stamp, localized=True):\n        ret = datetime.datetime.utcfromtimestamp(time_stamp)\n        if localized:\n            ret = localize(ret, pytz.utc)\n        return ret", "response": "Converts a UTC timestamp to a datetime. datetime."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _imm_init_getattribute(self, name):\n    '''\n    During the initial transient state, getattribute works on params; as soon as a non-param is\n    requested, all checks are forced and the getattr switches to standard transient form.\n    '''\n    values = _imm_value_data(self)\n    params = _imm_param_data(self)\n    if name in values:\n        _imm_init_to_trans(self)\n        return getattr(self, name)\n    elif name in params:\n        dd = object.__getattribute__(self, '__dict__')\n        if name in dd: return dd[name]\n        else: raise RuntimeError('Required immutable parameter %s requested before set' % name)\n    else:\n        # if they request a required param before it's set, raise an exception; that's fine\n        return object.__getattribute__(self, name)", "response": "Internal method to perform getattribute on immutable parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _imm_delattr(self, name):\n    '''\n    A persistent immutable's delattr allows the object's value-caches to be invalidated, otherwise\n    raises an exception.\n    '''\n    if _imm_is_persist(self):\n        values = _imm_value_data(self)\n        if name in values:\n            dd = object.__getattribute__(self, '__dict__')\n            if name in dd:\n                del dd[name]\n                if name in _imm_const_data(self): _imm_check(imm, [name])\n        else:\n            raise TypeError('Attempt to reset parameter \\'%s\\' of non-transient immutable' % name)\n    else:\n        return _imm_trans_delattr(self, name)", "response": "A persistent immutable s delattr allows the object s value - caches to be invalidated otherwise an exception is raised."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the default representation function for an immutable object.", "response": "def _imm_repr(self):\n    '''\n    The default representation function for an immutable object.\n    '''\n    return (type(self).__name__\n            + ('(' if _imm_is_persist(self) else '*(')\n            + ', '.join([k + '=' + str(v) for (k,v) in six.iteritems(imm_params(self))])\n            + ')')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _imm_new(cls):\n    '''\n    All immutable new classes use a hack to make sure the post-init cleanup occurs.\n    '''\n    imm = object.__new__(cls)\n    # Note that right now imm has a normal setattr method;\n    # Give any parameter that has one a default value\n    params = cls._pimms_immutable_data_['params']\n    for (p,dat) in six.iteritems(params):\n        dat = dat[0]\n        if dat: object.__setattr__(imm, p, dat[0])\n    # Clear any values; they are not allowed yet\n    _imm_clear(imm)\n    # Note that we are initializing...\n    dd = object.__getattribute__(imm, '__dict__')\n    dd['_pimms_immutable_is_init'] = True\n    # That should do it!\n    return imm", "response": "Create immutable new object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn immutable if it is transient and not persistent.", "response": "def imm_persist(imm):\n    '''\n    imm_persist(imm) turns imm from a transient into a persistent immutable and returns imm. If imm\n    is already persistent, then it is simply returned.\n    '''\n    if not is_imm(imm):\n        raise ValueError('imm_persist given non-immutable')\n    if not _imm_is_persist(imm):\n        _imm_trans_to_persist(imm)\n    return imm"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a persistent copy of the immutable object imm with the same parameters as the given object imm.", "response": "def imm_copy(imm, **kwargs):\n    '''\n    imm_copy(imm, a=b, c=d...) yields a persisent copy of the immutable object imm that differs from\n    imm only in that the parameters a, c, etc. have been changed to have the values b, d, etc.\n    If the object imm is persistent and no changes are made, imm is returned. If imm is transient,\n    a persistent copy of imm is always made.\n    '''\n    if not is_imm(imm):\n        raise ValueError('Non-immutable given to imm_copy')\n    if imm_is_persistent(imm) and len(kwargs) == 0:\n        # no changes and copy risk\n        return imm\n    dup = copy.copy(imm)\n    if _imm_is_trans(dup): dup = dup.persist()\n    dd = object.__getattribute__(dup, '__dict__')\n    if _imm_is_persist(dup):\n        # we update values directly then recompute checks and invalidate cache\n        all_checks = set([])\n        all_deps = set([])\n        params = _imm_param_data(imm)\n        for (p,v) in six.iteritems(kwargs):\n            if p not in params:\n                raise ValueError('attempt to set non-parameter \\'%s\\' in imm_copy()' % p)\n            (_, tx_fn, arg_lists, check_fns, deps) = params[p]\n            for (arg_list, check_fn) in zip(arg_lists, check_fns):\n                all_checks.add((tuple(arg_list), check_fn))\n            all_deps |= set(deps)\n            dd[p] = v if tx_fn is None else tx_fn(v)\n        # now invalidate the deps\n        for dep in all_deps:\n            if dep in dd:\n                del dd[dep]\n        # now run the tests\n        for (arg_list, check_fn) in all_checks:\n            if not check_fn(*[getattr(dup, arg) for arg in arg_list]):\n                raise ValueError(\n                    'Requirement \\'%s%s\\' failed when copying immutable' % (check_fn, arg_list))\n    else:\n        # this is an initial-state immutable...\n        for (p,v) in six.iteritems(kwargs): object.__setattr__(dup, p, v)\n        _imm_init_to_trans(dup)\n        _imm_trans_to_persist(dup)\n    return dup"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of the parameters of the immutable object imm.", "response": "def imm_params(imm):\n    '''\n    imm_params(imm) yields a dictionary of the parameters of the immutable object imm.\n    '''\n    return {p: getattr(imm, p) for p in six.iterkeys(_imm_param_data(imm))}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary of the values of the immutable object imm.", "response": "def imm_values(imm):\n    '''\n    imm_values(imm) yields a dictionary of the values of the immutable object imm. Note that this\n    forces all of the values to be reified, so only use it if you want to force execution of all\n    lazy values.\n    '''\n    return {p: getattr(imm, p) for p in six.iterkeys(_imm_value_data(imm))}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imm_dict(imm):\n    '''\n    imm_dict(imm) yields a persistent dictionary of the params and values of the immutable\n    object im. Note that this forces all of the values to be reified, so only use it if you want to\n    force execution of all lazy values.\n    '''\n    immd = dict(**imm_params(imm))\n    for (k,v) in six.iteritems(imm_values(imm)):\n        immd[k] = v\n    return immd", "response": "Returns a persistent dictionary of the params and values of immutable\n    object im."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef require(f):\n    '''\n    The @require decorator, usable in an immutable class (see immutable), specifies that the\n    following function is actually a validation check on the immutable class. These functions\n    will appear as static members of the class and get called automatically when the relevant\n    data change. Daughter classes can overload requirements to change them, or may add new\n    requirements with different function names.\n    '''\n    (args, varargs, kwargs, dflts) = getargspec_py27like(f)\n    if varargs is not None or kwargs is not None or dflts:\n        raise ValueError(\n            'Requirements may not accept variable, variadic keyword, or default arguments')\n    f._pimms_immutable_data_ = {}\n    f._pimms_immutable_data_['is_check'] = True\n    f._pimms_immutable_data_['inputs'] = args\n    f._pimms_immutable_data_['name'] = f.__name__\n    f = staticmethod(f)\n    return f", "response": "Decorator for a immutable class that validates the immutable data of a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _imm_merge_class(cls, parent):\n    '''\n    _imm_merge_class(imm_class, parent) updates the given immutable class imm_class to have the\n    appropriate attributes of its given parent class. The parents should be passed through this\n    function in method-resolution order.\n    '''\n    # If this is not an immutable parent, ignore it\n    if not hasattr(parent, '_pimms_immutable_data_'): return cls\n    # otherwise, let's look at the data\n    cdat = cls._pimms_immutable_data_\n    pdat = parent._pimms_immutable_data_\n    # for params, values, and checks, we add them to cls only if they do not already exist in cls\n    cparams = cdat['params']\n    cvalues = cdat['values']\n    cconsts = cdat['consts']\n    for (param, (dflt, tx_fn, arg_lists, check_fns, deps)) in six.iteritems(pdat['params']):\n        if param not in cparams and param not in cvalues:\n            cparams[param] = (dflt, tx_fn, [], [], [])\n    for (value, (arg_list, calc_fn, deps)) in six.iteritems(pdat['values']):\n        if value in cparams:\n            raise ValueError('cannot convert value into parameter: %s' % value)\n        if value not in cvalues:\n            cvalues[value] = (arg_list, calc_fn, [])\n            if len(arg_list) == 0:\n                cconsts[value] = ([], [])\n    cchecks = cdat['checks']\n    for (check, (arg_list, check_fn)) in six.iteritems(pdat['checks']):\n        if check not in cchecks:\n            cchecks[check] = (arg_list, check_fn)\n    # That's it for now\n    return cls", "response": "Internal method to merge the given immutable class into the given parent class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scan_directory(pym, directory, sentinel, installed, depth=0):\n    '''Entry point scan that creates a PyModule instance if needed.\n    '''\n    if not pym:\n        d = os.path.abspath(directory)\n        basename = os.path.basename(d)\n        pym = utils.find_package(basename, installed)\n        if not pym:\n            version = 'DIRECTORY'\n            if os.path.isfile(os.path.join(d, '__init__.py')):\n                version = 'MODULE'\n            pym = PyModule(basename, version, d)\n            installed.insert(0, pym)\n        else:\n            pym.is_scan = True\n\n    # Keep track of how many file scans resulted in nothing\n    bad_scans = 0\n\n    for item in _scan_directory(directory, sentinel, depth):\n        if os.path.isfile(item):\n            if bad_scans > 100:\n                # Keep in mind this counter resets if it a good scan happens\n                # in *this* directory. If you have a module with more than 100\n                # files in a single directory, you should probably refactor it.\n                log.debug('Stopping scan of directory since it looks like a data dump: %s', directory)\n                break\n\n            if not scan_file(pym, item, sentinel, installed):\n                bad_scans += 1\n            else:\n                bad_scans = 0\n        elif os.path.isdir(item):\n            scan_directory(pym, item, sentinel, installed, depth + 1)\n\n    return pym", "response": "Entry point scan that creates a PyModule instance if needed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading configuration from project config file.", "response": "def _get_project_conf():\n    \"\"\"Loads configuration from project config file.\"\"\"\n    config_settings = {}\n\n    project_root = find_vcs_root(\".\")\n    if project_root is None:\n        return config_settings\n\n    for conf_dir in PROJECT_CONF_DIRS:\n        conf_dir = conf_dir.lstrip(\"./\")\n        joined_dir = os.path.join(project_root, conf_dir) if conf_dir else project_root\n        joined_glob = os.path.join(joined_dir, PROJECT_CONF)\n        conf_files = glob.glob(joined_glob)\n        # config files found, not trying other directories\n        if conf_files:\n            break\n    else:\n        conf_files = []\n\n    for conf_file in conf_files:\n        try:\n            with io.open(conf_file, encoding=\"utf-8\") as input_file:\n                loaded_settings = yaml.safe_load(input_file)\n        except EnvironmentError:\n            logger.warning(\"Failed to load config from %s\", conf_file)\n        else:\n            logger.info(\"Config loaded from %s\", conf_file)\n            config_settings.update(loaded_settings)\n\n    return config_settings"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading config file and returns its content.", "response": "def get_config(config_file=None, config_values=None, load_project_conf=True):\n    \"\"\"Loads config file and returns its content.\"\"\"\n    config_values = config_values or {}\n    config_settings = {}\n\n    default_conf = _get_default_conf()\n    user_conf = _get_user_conf(config_file) if config_file else {}\n    # load project configuration only when user configuration was not specified\n    project_conf = {} if user_conf or not load_project_conf else _get_project_conf()\n\n    if not (user_conf or project_conf or config_values):\n        if load_project_conf:\n            raise Dump2PolarionException(\n                \"Failed to find configuration file for the project \"\n                \"and no configuration file or values passed.\"\n            )\n        raise Dump2PolarionException(\"No configuration file or values passed.\")\n\n    # merge configuration\n    config_settings.update(default_conf)\n    config_settings.update(user_conf)\n    config_settings.update(project_conf)\n    config_settings.update(config_values)\n\n    _populate_urls(config_settings)\n    _set_legacy_project_id(config_settings)\n    _set_legacy_custom_fields(config_settings)\n    _check_config(config_settings)\n\n    return config_settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures that predictions is stored as a numpy array and checks that all values are either 0 or 1.", "response": "def verify_predictions(predictions):\n    \"\"\"Ensures that predictions is stored as a numpy array and checks that\n    all values are either 0 or 1.\n    \"\"\"\n    # Check that it contains only zeros and ones\n    predictions = np.array(predictions, copy=False)\n    if not np.array_equal(predictions, predictions.astype(bool)):\n        raise ValueError(\"predictions contains invalid values. \" +\n                         \"The only permitted values are 0 or 1.\")\n    if predictions.ndim == 1:\n        predictions = predictions[:,np.newaxis]\n    return predictions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_scores(scores):\n    scores = np.array(scores, copy=False)\n    if np.any(~np.isfinite(scores)):\n        raise ValueError(\"scores contains invalid values. \" +\n                         \"Please check that all values are finite.\")\n    if scores.ndim == 1:\n        scores = scores[:,np.newaxis]\n    return scores", "response": "Ensures that scores is stored as a numpy array and checks that all values are finite."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_consistency(predictions, scores, proba, opt_class):\n    if predictions.shape != scores.shape:\n        raise ValueError(\"predictions and scores arrays have inconsistent \" +\n                         \"dimensions.\")\n\n    n_class = scores.shape[1] if scores.ndim > 1 else 1\n\n    # If proba not given, default to False for all classifiers\n    if proba is None:\n        proba = np.repeat(False, n_class)\n\n    # If opt_class is not given, default to True for all classifiers\n    if opt_class is None:\n        opt_class = np.repeat(True, n_class)\n\n    # Convert to numpy arrays if necessary\n    proba = np.array(proba, dtype=bool, ndmin=1)\n    opt_class = np.array(opt_class, dtype=bool, ndmin=1)\n\n    if np.sum(opt_class) < 1:\n        raise ValueError(\"opt_class should contain at least one True value.\")\n\n    if predictions.shape[1] != len(proba):\n        raise ValueError(\"mismatch in shape of proba and predictions.\")\n    if predictions.shape[1] != len(opt_class):\n        raise ValueError(\"mismatch in shape of opt_class and predictions.\")\n\n    for m in range(n_class):\n        if (np.any(np.logical_or(scores[:,m] < 0, scores[:,m] > 1)) and proba[m]):\n            warnings.warn(\"scores fall outside the [0,1] interval for \" +\n                          \"classifier {}. Setting proba[m]=False.\".format(m))\n            proba[m] = False\n\n    return proba, opt_class", "response": "Verifies that all arrays have consistent dimensions. Also verifies that the scores are consistent with proba. Also verifies that the predictions and scores arrays have consistent dimensions. Also verifies that the proba and opt_class arrays are consistent with proba. Also verifies that the scores are consistent with opt_class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that identifiers has a compatible length and that its elements are unique.", "response": "def verify_identifiers(identifiers, n_items):\n    \"\"\"Ensure that identifiers has a compatible length and that its elements\n    are unique\"\"\"\n    if identifiers is None:\n        return identifiers\n\n    identifiers = np.array(identifiers, copy=False)\n\n    # Check length for consistency\n    if len(identifiers) != n_items:\n        raise ValueError(\"identifiers has inconsistent dimension.\")\n\n    # Check that identifiers are unique\n    if len(np.unique(identifiers)) != n_items:\n        raise ValueError(\"identifiers contains duplicate values.\")\n\n    return identifiers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scores_to_probs(scores, proba, eps=0.01):\n    if np.any(~proba):\n        # Need to convert some of the scores into probabilities\n        probs = copy.deepcopy(scores)\n        n_class = len(proba)\n        for m in range(n_class):\n            if not proba[m]:\n                #TODO: incorporate threshold (currently assuming zero)\n                # find most extreme absolute score\n                max_extreme_score = max(np.abs(np.min(scores[:,m])),\\\n                                    np.abs(np.max(scores[:,m])))\n                k = np.log((1-eps)/eps)/max_extreme_score # scale factor\n                self._probs[:,m] = expit(k * self.scores[:,m])\n        return probs\n    else:\n        return scores", "response": "Transforms scores to probabilities by applying the logistic function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deliver_hook(target, payload, instance_id=None, hook_id=None, **kwargs):\n    r = requests.post(\n        url=target,\n        data=json.dumps(payload),\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": \"Token %s\" % settings.HOOK_AUTH_TOKEN,\n        },\n    )\n    r.raise_for_status()\n    return r.text", "response": "deliver a hook to a specific instance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiring a metric using the MetricsApiClient", "response": "def fire_metric(metric_name, metric_value):\n    \"\"\" Fires a metric using the MetricsApiClient\n    \"\"\"\n    metric_value = float(metric_value)\n    metric = {metric_name: metric_value}\n    metric_client.fire_metrics(**metric)\n    return \"Fired metric <{}> with value <{}>\".format(metric_name, metric_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfires a webhook in the event of a None to_addr.", "response": "def fire_failed_msisdn_lookup(self, to_identity):\n        \"\"\"\n        Fires a webhook in the event of a None to_addr.\n        \"\"\"\n        payload = {\"to_identity\": to_identity}\n        hooks = Hook.objects.filter(event=\"identity.no_address\")\n        for hook in hooks:\n            hook.deliver_hook(\n                None, payload_override={\"hook\": hook.dict(), \"data\": payload}\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, message_id, **kwargs):\n        log = self.get_logger(**kwargs)\n\n        error_retry_count = kwargs.get(\"error_retry_count\", 0)\n        if error_retry_count >= self.max_error_retries:\n            raise MaxRetriesExceededError(\n                \"Can't retry {0}[{1}] args:{2} kwargs:{3}\".format(\n                    self.name, self.request.id, self.request.args, kwargs\n                )\n            )\n\n        log.info(\"Loading Outbound Message <%s>\" % message_id)\n        try:\n            message = Outbound.objects.select_related(\"channel\").get(id=message_id)\n        except ObjectDoesNotExist:\n            logger.error(\"Missing Outbound message\", exc_info=True)\n            return\n\n        if message.attempts < settings.MESSAGE_SENDER_MAX_RETRIES:\n            if error_retry_count > 0:\n                retry_delay = calculate_retry_delay(error_retry_count)\n            else:\n                retry_delay = self.default_retry_delay\n            log.info(\"Attempts: %s\" % message.attempts)\n            # send or resend\n            try:\n                if not message.channel:\n                    channel = Channel.objects.get(default=True)\n                else:\n                    channel = message.channel\n\n                sender = self.get_client(channel)\n                ConcurrencyLimiter.manage_limit(self, channel)\n\n                if not message.to_addr and message.to_identity:\n                    message.to_addr = get_identity_address(\n                        message.to_identity, use_communicate_through=True\n                    )\n                    if not message.to_addr:\n                        self.fire_failed_msisdn_lookup(message.to_identity)\n                        return\n\n                if message.to_addr and not message.to_identity:\n                    result = get_identity_by_address(message.to_addr)\n\n                    if result:\n                        message.to_identity = result[0][\"id\"]\n                    else:\n                        identity = {\n                            \"details\": {\n                                \"default_addr_type\": \"msisdn\",\n                                \"addresses\": {\n                                    \"msisdn\": {message.to_addr: {\"default\": True}}\n                                },\n                            }\n                        }\n                        identity = create_identity(identity)\n                        message.to_identity = identity[\"id\"]\n\n                if \"voice_speech_url\" in message.metadata:\n                    # OBD number of tries metric\n                    fire_metric.apply_async(\n                        kwargs={\n                            \"metric_name\": \"vumimessage.obd.tries.sum\",\n                            \"metric_value\": 1.0,\n                        }\n                    )\n\n                    # Voice message\n                    speech_url = message.metadata[\"voice_speech_url\"]\n                    vumiresponse = sender.send_voice(\n                        voice_to_addr_formatter(message.to_addr),\n                        message.content,\n                        speech_url=speech_url,\n                        session_event=\"new\",\n                    )\n                    log.info(\"Sent voice message to <%s>\" % message.to_addr)\n\n                elif \"image_url\" in message.metadata:\n                    # Image message\n                    image_url = message.metadata[\"image_url\"]\n                    vumiresponse = sender.send_image(\n                        text_to_addr_formatter(message.to_addr),\n                        message.content,\n                        image_url=image_url,\n                    )\n                    log.info(\"Sent image message to <%s>\" % (message.to_addr,))\n\n                else:\n                    # Plain content\n                    vumiresponse = sender.send_text(\n                        text_to_addr_formatter(message.to_addr),\n                        message.content,\n                        metadata=message.metadata,\n                        session_event=\"new\",\n                    )\n                    log.info(\"Sent text message to <%s>\" % (message.to_addr,))\n\n                message.last_sent_time = timezone.now()\n                message.attempts += 1\n                message.vumi_message_id = vumiresponse[\"message_id\"]\n                message.save()\n                fire_metric.apply_async(\n                    kwargs={\"metric_name\": \"vumimessage.tries.sum\", \"metric_value\": 1.0}\n                )\n            except requests_exceptions.ConnectionError as exc:\n                log.info(\"Connection Error sending message\")\n                fire_metric.delay(\"sender.send_message.connection_error.sum\", 1)\n                kwargs[\"error_retry_count\"] = error_retry_count + 1\n                self.retry(\n                    exc=exc, countdown=retry_delay, args=(message_id,), kwargs=kwargs\n                )\n            except requests_exceptions.Timeout as exc:\n                log.info(\"Sending message failed due to timeout\")\n                fire_metric.delay(\"sender.send_message.timeout.sum\", 1)\n                kwargs[\"error_retry_count\"] = error_retry_count + 1\n                self.retry(\n                    exc=exc, countdown=retry_delay, args=(message_id,), kwargs=kwargs\n                )\n            except (requests_exceptions.HTTPError, HTTPServiceError) as exc:\n                # retry message sending if in 500 range (3 default\n                # retries)\n                log.info(\n                    \"Sending message failed due to status: %s\"\n                    % exc.response.status_code\n                )\n                metric_name = (\n                    \"sender.send_message.http_error.%s.sum\" % exc.response.status_code\n                )\n                fire_metric.delay(metric_name, 1)\n                kwargs[\"error_retry_count\"] = error_retry_count + 1\n                self.retry(\n                    exc=exc, countdown=retry_delay, args=(message_id,), kwargs=kwargs\n                )\n\n            # If we've gotten this far the message send was successful.\n            fire_metric.apply_async(\n                kwargs={\"metric_name\": \"message.sent.sum\", \"metric_value\": 1.0}\n            )\n            return vumiresponse\n\n        else:\n            # This is for retries based on async nacks from the transport.\n            log.info(\"Message <%s> at max retries.\" % str(message_id))\n            message.to_addr = \"\"\n            message.save(update_fields=[\"to_addr\"])\n            fire_metric.apply_async(\n                kwargs={\n                    \"metric_name\": \"vumimessage.maxretries.sum\",\n                    \"metric_value\": 1.0,\n                }\n            )\n            # Count failures on exhausted tries.\n            fire_metric.apply_async(\n                kwargs={\"metric_name\": \"message.failures.sum\", \"metric_value\": 1.0}\n            )", "response": "Load and contruct message and send them off"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_data(self, filename, queryset):\n        with gzip.open(filename, \"wb\") as f:\n            for outbound in queryset.iterator():\n                data = OutboundArchiveSerializer(outbound).data\n                data = JSONRenderer().render(data)\n                f.write(data)\n                f.write(\"\\n\".encode(\"utf-8\"))", "response": "Dumps the data of the queryset into a gzipped file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_archived_outbound(self, date, filename):\n        with open(filename, \"rb\") as f:\n            f = File(f)\n            ArchivedOutbounds.objects.create(date=date, archive=f)", "response": "Creates the required ArchivedOutbound entry with the file specified\n            at filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef valid_dict(d, keys=None):\n\n    if keys is None:\n        d_ = d\n    else:\n        d_ = itemfilter(lambda item: item[0] in keys, d)\n        if len(d_) != len(keys):\n            return False\n    values = list(itervalues(d_))\n    return False if None in values else True", "response": "Check if a dictionary is valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the list of all the accessibles for the current user filtered by roles.", "response": "def accessibles(self, roles=None):\n        \"\"\"\n        Returns the list of *slugs* for which the accounts are accessibles\n        by ``request.user`` filtered by ``roles`` if present.\n        \"\"\"\n        return [org['slug']\n                for org in self.get_accessibles(self.request, roles=roles)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of accessibles for the user in the current session.", "response": "def get_accessibles(request, roles=None):\n        \"\"\"\n        Returns the list of *dictionnaries* for which the accounts are\n        accessibles by ``request.user`` filtered by ``roles`` if present.\n        \"\"\"\n        results = []\n        for role_name, organizations in six.iteritems(request.session.get(\n                'roles', {})):\n            if roles is None or role_name in roles:\n                results += organizations\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the user is a manager for account.", "response": "def manages(self, account):\n        \"\"\"\n        Returns ``True`` if the ``request.user`` is a manager for ``account``.\n        ``account`` will be converted to a string and compared\n        to an organization slug.\n        \"\"\"\n        account_slug = str(account)\n        for organization in self.request.session.get(\n                'roles', {}).get('manager', []):\n            if account_slug == organization['slug']:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimplement before date filtering on date_field", "response": "def get_queryset(self):\n        \"\"\"\n        Implements before date filtering on ``date_field``\n        \"\"\"\n        kwargs = {}\n        if self.ends_at:\n            kwargs.update({'%s__lt' % self.date_field: self.ends_at})\n        return super(BeforeMixin, self).get_queryset().filter(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimplements date range filtering on created_at", "response": "def get_queryset(self):\n        \"\"\"\n        Implements date range filtering on ``created_at``\n        \"\"\"\n        kwargs = {}\n        if self.start_at:\n            kwargs.update({'%s__gte' % self.date_field: self.start_at})\n        return super(DateRangeMixin, self).get_queryset().filter(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, fname, lname, group, type, group_api):\n        self.__username(fname, lname)\n        self.client.add(\n            self.__distinguished_name(type, fname=fname, lname=lname),\n            API.__object_class(),\n            self.__ldap_attr(fname, lname, type, group, group_api))", "response": "Create an LDAP User."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, username, type):\n        self.client.delete(self.__distinguished_name(type, username=username))", "response": "Delete an LDAP user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a specific user s info in LDIF format.", "response": "def show(self, username):\n        \"\"\"Return a specific user's info in LDIF format.\"\"\"\n        filter = ['(objectclass=posixAccount)', \"(uid={})\".format(username)]\n        return self.client.search(filter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding user with given username.", "response": "def find(self, username):\n        \"\"\"\n        Find user with given username.\n\n        Args:\n            username Username of the user to search for\n\n        Raises:\n            ldap_tools.exceptions.NoUserFound: No users returned by LDAP\n            ldap_tools.exceptions.TooManyResults:\n                Multiple users returned by LDAP\n\n        \"\"\"\n        filter = ['(uid={})'.format(username)]\n        results = self.client.search(filter)\n\n        if len(results) < 1:\n            raise ldap_tools.exceptions.NoUserFound(\n                'User ({}) not found'.format(username))\n            return  # pragma: no cover\n        elif len(results) > 1:\n            raise ldap_tools.exceptions.TooManyResults(\n                'Multiple users found. Please narrow your search.')\n            return  # pragma: no cover\n        else:\n            return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting first name + last name into first. last style username.", "response": "def __username(self, fname, lname):  # pragma: no cover\n        \"\"\"Convert first name + last name into first.last style username.\"\"\"\n        self.username = '.'.join([i.lower() for i in [fname, lname]])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassemble the DN of the user.", "response": "def __distinguished_name(self, type, fname=None, lname=None,\n                             username=None):  # pragma: no cover\n        \"\"\"Assemble the DN of the user.\"\"\"\n        if username is None:\n            uid = \"uid={}\".format(self.username)\n        else:\n            uid = \"uid={}\".format(username)\n\n        dn_list = [\n            uid,\n            \"ou={}\".format(self.__organizational_unit(type)),\n            self.client.basedn,\n        ]\n\n        return ','.join(dn_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a password for the user.", "response": "def __create_password():  # pragma: no cover\n        \"\"\"Create a password for the user.\"\"\"\n        salt = b64encode(API.__generate_string(32))\n        password = b64encode(API.__generate_string(64))\n        return b64encode(sha1(password + salt).digest())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __generate_string(length):  # pragma: no cover\n        return ''.join(\n            SystemRandom().choice(string.ascii_letters + string.digits)\n            for x in range(length)).encode()", "response": "Generate a string for password creation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an LDAP user.", "response": "def create(config, name, group, type):\n        \"\"\"Create an LDAP user.\"\"\"\n        if type not in ('user', 'service'):\n            raise click.BadOptionUsage(\"--type must be 'user' or 'service'\")\n        client = Client()\n        client.prepare_connection()\n        user_api = API(client)\n        group_api = GroupApi(client)\n        user_api.create(name[0], name[1], group, type, group_api)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes an LDAP user.", "response": "def delete(config, username, type):\n        \"\"\"Delete an LDAP user.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        user_api = API(client)\n        user_api.delete(username, type)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay user info in LDIF format.", "response": "def index(config):\n        \"\"\"Display user info in LDIF format.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        user_api = API(client)\n        CLI.show_user(user_api.index())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays a specific user.", "response": "def show(config, username):\n        \"\"\"Display a specific user.\"\"\"\n        client = Client()\n        client.prepare_connection()\n        user_api = API(client)\n        CLI.show_user(user_api.show(username))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning for bluetooth devices.", "response": "async def get_scan_result(self):\n        \"\"\"Scan for bluetooth devices.\"\"\"\n        endpoint = '/setup/bluetooth/scan_results'\n        url = API.format(ip=self._ipaddress, endpoint=endpoint)\n        try:\n            async with async_timeout.timeout(5, loop=self._loop):\n                response = await self._session.get(url)\n                self._devices = await response.json()\n                _LOGGER.debug(self._devices)\n        except (asyncio.TimeoutError,\n                aiohttp.ClientError, socket.gaierror) as error:\n            _LOGGER.error('Error connecting to %s - %s', self._ipaddress, error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def scan_for_devices_multi_run(self, runs=2):\n        run = 1\n        master = {}\n        while run < runs + 1:\n            await self.scan_for_devices()\n            await self.get_scan_result()\n            if master is None:\n                for device in self._devices:\n                    mac = device['mac_address']\n                    master[mac] = {}\n                    master[mac]['rssi'] = device['rssi']\n                    master[mac]['device_class'] = device['device_class']\n                    master[mac]['name'] = device['name']\n                    master[mac]['device_type'] = device['device_type']\n                    master[mac]['count'] = 1\n            else:\n                for device in self._devices:\n                    mac = device['mac_address']\n                    if master.get(mac, False):\n                        master[mac]['rssi'] = device['rssi']\n                        master[mac]['count'] = str(1 + 1)\n                    else:\n                        master[mac] = {}\n                        master[mac]['rssi'] = device['rssi']\n                        master[mac]['device_class'] = device['device_class']\n                        master[mac]['name'] = device['name']\n                        master[mac]['device_type'] = device['device_type']\n                        master[mac]['count'] = 1\n            run = run + 1\n            result = []\n            for device in master:\n                if int(master[device]['count']) > 1:\n                    result.append(master[device])\n        self._devices = result", "response": "Scan for devices multiple times."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a Barrister IDL JSON file and returns a Contract class", "response": "def contract_from_file(fname):\n    \"\"\"\n    Loads a Barrister IDL JSON from the given file and returns a Contract class\n\n    :Parameters:\n      fname\n        Filename containing Barrister IDL JSON to load\n    \"\"\"\n    f = open(fname)\n    j = f.read()\n    f.close()\n    return Contract(json.loads(j))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a JSON - RPC method in the interface. [ function notation returns a tuple of the interface name and function name.", "response": "def unpack_method(method):\n    \"\"\"\n    Given a JSON-RPC method in:  [interface].[function] notation, returns a tuple of the interface\n    name and function.\n\n    For example, unpack_method(\"MyService.LoadUser\") would return: (\"MyService\", \"LoadUser\")\n\n    :Parameters:\n      method\n        String method name\n    \"\"\"\n    pos = method.find(\".\")\n    if pos == -1:\n        raise RpcException(ERR_METHOD_NOT_FOUND, \"Method not found: %s\" % method)\n\n    iface_name = method[:pos]\n    func_name  = method[pos+1:]\n    return iface_name, func_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a JSON - RPC error as a dict with keys : jsonrpc id error message data", "response": "def err_response(reqid, code, msg, data=None):\n    \"\"\"\n    Formats a JSON-RPC error as a dict with keys: 'jsonrpc', 'id', 'error'\n    \"\"\"\n    err = { \"code\": code, \"message\": msg }\n    if data:\n        err[\"data\"] = data\n    return { \"jsonrpc\": \"2.0\", \"id\": reqid, \"error\": err }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef safe_get(d, key, def_val=None):\n    if d.has_key(key):\n        return d[key]\n    else:\n        return def_val", "response": "Helper function to fetch a value from a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a property set on the context.", "response": "def get_prop(self, key, default_val=None):\n        \"\"\"\n        Returns a property set on the context.\n\n        :Parameters:\n          key\n            String key to lookup in the context props dict\n          default_val\n            Value to return if key is not set on the context props\n        \"\"\"\n        if self.props.has_key(key):\n            return self.props[key]\n        else:\n            return default_val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_error(self, code, msg, data=None):\n        self.error = err_response(self.request[\"id\"], code, msg, data)", "response": "Set an error on this request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the given handler to the set of handlers for the given interface.", "response": "def add_handler(self, iface_name, handler):\n        \"\"\"\n        Associates the given handler with the interface name.  If the interface does not exist in\n        the Contract, an RpcException is raised.\n\n        :Parameters:\n          iface_name\n            Name of interface that this handler implements\n          handler\n            Instance of a class that implements all functions defined on the interface\n        \"\"\"\n        if self.contract.has_interface(iface_name):\n            self.handlers[iface_name] = handler\n        else:\n            raise RpcException(ERR_INVALID_REQ, \"Unknown interface: '%s'\", iface_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the filters for the server.", "response": "def set_filters(self, filters):\n        \"\"\"\n        Sets the filters for the server.\n\n        :Parameters:\n          filters\n            List of filters to set on this server, or None to remove all filters.\n            Elements in list should subclass Filter\n        \"\"\"\n        if filters == None or isinstance(filters, (tuple, list)):\n            self.filters = filters\n        else:\n            self.filters = [ filters ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a Barrister request and returns a response.", "response": "def call(self, req, props=None):\n        \"\"\"\n        Executes a Barrister request and returns a response.  If the request is a list, then the\n        response will also be a list.  If the request is an empty list, a RpcException is raised.\n\n        :Parameters:\n          req\n            The request. Either a list of dicts, or a single dict.\n          props\n            Application defined properties to set on RequestContext for use with filters. \n            For example: authentication headers.  Must be a dict.\n        \"\"\"\n        resp = None\n\n        if self.log.isEnabledFor(logging.DEBUG):\n            self.log.debug(\"Request: %s\" % str(req))\n\n        if isinstance(req, list):\n            if len(req) < 1:\n                resp = err_response(None, ERR_INVALID_REQ, \"Invalid Request. Empty batch.\")\n            else:\n                resp = [ ]\n                for r in req:\n                    resp.append(self._call_and_format(r, props))\n        else:\n            resp = self._call_and_format(req, props)\n\n        if self.log.isEnabledFor(logging.DEBUG):\n            self.log.debug(\"Response: %s\" % str(resp))\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call_and_format(self, req, props=None):\n        if not isinstance(req, dict):\n            return err_response(None, ERR_INVALID_REQ, \n                             \"Invalid Request. %s is not an object.\" % str(req))\n\n        reqid = None\n        if req.has_key(\"id\"):\n            reqid = req[\"id\"]\n\n        if props == None:\n            props = { }\n        context = RequestContext(props, req)\n\n        if self.filters:\n            for f in self.filters:\n                f.pre(context)\n\n        if context.error:\n            return context.error\n\n        resp = None\n        try:\n            result = self._call(context)\n            resp = { \"jsonrpc\": \"2.0\", \"id\": reqid, \"result\": result }\n        except RpcException, e:\n            resp = err_response(reqid, e.code, e.msg, e.data)\n        except:\n            self.log.exception(\"Error processing request: %s\" % str(req))\n            resp = err_response(reqid, ERR_UNKNOWN, \"Server error. Check logs for details.\")\n        \n        if self.filters:\n            context.response = resp\n            for f in self.filters:\n                f.post(context)\n\n        return resp", "response": "Calls the _call method and formats the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a single request against a specific handler.", "response": "def _call(self, context):\n        \"\"\"\n        Executes a single request against a handler.  If the req.method == 'barrister-idl', the\n        Contract IDL JSON structure is returned.  Otherwise the method is resolved to a handler\n        based on the interface name, and the appropriate function is called on the handler.\n\n        :Parameter:\n          req\n            A dict representing a valid JSON-RPC 2.0 request.  'method' must be provided.\n        \"\"\"\n        req = context.request\n        if not req.has_key(\"method\"):\n            raise RpcException(ERR_INVALID_REQ, \"Invalid Request. No 'method'.\")\n\n        method = req[\"method\"]\n\n        if method == \"barrister-idl\":\n            return self.contract.idl_parsed\n\n        iface_name, func_name = unpack_method(method)\n\n        if self.handlers.has_key(iface_name):\n            iface_impl = self.handlers[iface_name]\n            func = getattr(iface_impl, func_name)\n            if func:\n                if req.has_key(\"params\"):\n                    params = req[\"params\"]\n                else:\n                    params = [ ]\n\n                if self.validate_req:\n                    self.contract.validate_request(iface_name, func_name, params)\n\n                if hasattr(iface_impl, \"barrister_pre\"):\n                    pre_hook = getattr(iface_impl, \"barrister_pre\")\n                    pre_hook(context, params)\n\n                if params:\n                    result = func(*params)\n                else:\n                    result = func()\n\n                if self.validate_resp:\n                    self.contract.validate_response(iface_name, func_name, result)\n                return result\n            else:\n                msg = \"Method '%s' not found\" % (method)\n                raise RpcException(ERR_METHOD_NOT_FOUND, msg)\n        else:\n            msg = \"No implementation of '%s' found\" % (iface_name)\n            raise RpcException(ERR_METHOD_NOT_FOUND, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, req):\n        data = json.dumps(req)\n        req = urllib2.Request(self.url, data, self.headers)\n        f = self.opener.open(req)\n        resp = f.read()\n        f.close()\n        return json.loads(resp)", "response": "Makes a request against the server and returns the deserialized result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a single RPC request and returns the result.", "response": "def call(self, iface_name, func_name, params):\n        \"\"\"\n        Makes a single RPC request and returns the result.\n\n        :Parameters:\n          iface_name\n            Interface name to call\n          func_name\n            Function to call on the interface\n          params\n            List of parameters to pass to the function\n        \"\"\"\n        req  = self.to_request(iface_name, func_name, params)\n        if self.log.isEnabledFor(logging.DEBUG):\n            self.log.debug(\"Request: %s\" % str(req))\n        resp = self.transport.request(req)\n        if self.log.isEnabledFor(logging.DEBUG):\n            self.log.debug(\"Response: %s\" % str(resp))\n        return self.to_result(iface_name, func_name, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_request(self, iface_name, func_name, params):\n        if self.validate_req:\n            self.contract.validate_request(iface_name, func_name, params)\n            \n        method = \"%s.%s\" % (iface_name, func_name)\n        reqid = self.id_gen()\n        return { \"jsonrpc\": \"2.0\", \"id\": reqid, \"method\": method, \"params\": params }", "response": "Converts the arguments to a JSON - RPC request dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_result(self, iface_name, func_name, resp):\n        if resp.has_key(\"error\"):\n            e = resp[\"error\"]\n            data = None\n            if e.has_key(\"data\"):\n                data = e[\"data\"]\n            raise RpcException(e[\"code\"], e[\"message\"], data)\n            \n        result = resp[\"result\"]\n        \n        if self.validate_resp:\n            self.contract.validate_response(iface_name, func_name, result)\n        return result", "response": "Takes a JSON - RPC response and returns a result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _caller(self, iface_name, func_name):\n        def caller(*params):\n            return self.client.call(iface_name, func_name, params)\n        return caller", "response": "Returns a function that calls client. call with the correct arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call(self, iface_name, func_name, params):\n        if self.sent:\n            raise Exception(\"Batch already sent. Cannot add more calls.\")\n        else:\n            req = self.client.to_request(iface_name, func_name, params)\n            self.req_list.append(req)", "response": "Implements the call method with same signature as Client. call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self):\n        if self.sent:\n            raise Exception(\"Batch already sent. Cannot send() again.\")\n        else:\n            self.sent = True\n            results = self.client.transport.request(self.req_list)\n            \n            id_to_method = { }\n            by_id = { }\n            for res in results:\n                reqid = res[\"id\"]\n                by_id[reqid] = res\n\n            in_req_order = [ ]\n            for req in self.req_list:\n                reqid  = req[\"id\"]\n                result = None\n                error  = None\n                resp   = safe_get(by_id, reqid)\n                if resp == None:\n                    msg = \"Batch response missing result for request id: %s\" % reqid\n                    error = RpcException(ERR_INVALID_RESP, msg)\n                else:\n                    r_err = safe_get(resp, \"error\")\n                    if r_err == None:\n                        result = resp[\"result\"]\n                    else:\n                        error = RpcException(r_err[\"code\"], r_err[\"message\"], safe_get(r_err, \"data\"))\n                in_req_order.append(RpcResponse(req, result, error))\n            return in_req_order", "response": "Sends the request to the server and returns a list of RpcResponse objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the given params match the expected length and types for this interface and function. Returns a 2 element tuple that is True if valid False if not valid None if not valid", "response": "def validate_request(self, iface_name, func_name, params):\n        \"\"\"\n        Validates that the given params match the expected length and types for this \n        interface and function.  \n\n        Returns two element tuple: (bool, string)\n\n        - `bool` - True if valid, False if not\n        - `string` - Description of validation error, or None if valid\n\n        :Parameters:\n          iface_name\n            Name of interface\n          func_name\n            Name of function\n          params\n            List of params to validate against this function\n        \"\"\"\n        self.interface(iface_name).function(func_name).validate_params(params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_response(self, iface_name, func_name, resp):\n        self.interface(iface_name).function(func_name).validate_response(resp)", "response": "Validates that the response for the function  \n\n            is valid for the interfaceunused."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the struct enum or interface with the given name or raises RpcException if no such element is found.", "response": "def get(self, name):\n        \"\"\"\n        Returns the struct, enum, or interface with the given name, or raises RpcException if\n        no elements match that name.\n\n        :Parameters:\n          name\n            Name of struct/enum/interface to return\n        \"\"\"\n        if self.structs.has_key(name):\n            return self.structs[name]\n        elif self.enums.has_key(name):\n            return self.enums[name]\n        elif self.interfaces.has_key(name):\n            return self.interfaces[name]\n        else:\n            raise RpcException(ERR_INVALID_PARAMS, \"Unknown entity: '%s'\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the struct with the given name or raises RpcException if no struct matches the given name.", "response": "def struct(self, struct_name):\n        \"\"\"\n        Returns the struct with the given name, or raises RpcException if no struct matches\n        \"\"\"\n        if self.structs.has_key(struct_name):\n            return self.structs[struct_name]\n        else:\n            raise RpcException(ERR_INVALID_PARAMS, \"Unknown struct: '%s'\", struct_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the interface with the given name or raises RpcException if no interface with the given name exists.", "response": "def interface(self, iface_name):\n        \"\"\"\n        Returns the interface with the given name, or raises RpcException if no interface matches\n        \"\"\"\n        if self.has_interface(iface_name):\n            return self.interfaces[iface_name]\n        else:\n            raise RpcException(ERR_INVALID_PARAMS, \"Unknown interface: '%s'\", iface_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, expected_type, is_array, val):\n        if val == None:\n            if expected_type.optional:\n                return True, None\n            else:\n                return False, \"Value cannot be null\"\n        elif is_array:\n            if not isinstance(val, list):\n                return self._type_err(val, \"list\")\n            else:\n                for v in val:\n                    ok, msg = self.validate(expected_type, False, v)\n                    if not ok:\n                        return ok, msg\n        elif expected_type.type == \"int\":\n            if not isinstance(val, (long, int)):\n                return self._type_err(val, \"int\")\n        elif expected_type.type == \"float\":\n            if not isinstance(val, (float, int, long)):\n                return self._type_err(val, \"float\")\n        elif expected_type.type == \"bool\":\n            if not isinstance(val, bool):\n                return self._type_err(val, \"bool\")\n        elif expected_type.type == \"string\":\n            if not isinstance(val, (str, unicode)):\n                return self._type_err(val, \"string\")\n        else:\n            return self.get(expected_type.type).validate(val)\n        return True, None", "response": "Validates that the value is of the expected type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef function(self, func_name):\n        if self.functions.has_key(func_name):\n            return self.functions[func_name]\n        else:\n            raise RpcException(ERR_METHOD_NOT_FOUND, \n                               \"%s: Unknown function: '%s'\", self.name, func_name)", "response": "Returns the Function instance associated with the given func_name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that the val is in the list of values for this Enum.", "response": "def validate(self, val):\n        \"\"\"\n        Validates that the val is in the list of values for this Enum.\n\n        Returns two element tuple: (bool, string)\n\n        - `bool` - True if valid, False if not\n        - `string` - Description of validation error, or None if valid\n\n        :Parameters:\n          val\n            Value to validate.  Should be a string.\n        \"\"\"\n        if val in self.values:\n            return True, None\n        else:\n            return False, \"'%s' is not in enum: %s\" % (val, str(self.values))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the field on this struct with the given name. Will try to find this name on all ancestors and return None if no such field exists.", "response": "def field(self, name):\n        \"\"\"\n        Returns the field on this struct with the given name. Will try to find this \n        name on all ancestors if this struct extends another.\n\n        If found, returns a dict with keys: 'name', 'comment', 'type', 'is_array'\n        If not found, returns None\n\n        :Parameters:\n          name\n            string name of field to lookup\n        \"\"\"\n        if self.fields.has_key(name):\n            return self.fields[name]\n        elif self.extends:\n            if not self.parent:\n                self.parent = self.contract.struct(self.extends)\n            return self.parent.field(name)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the val matches the expected fields for this struct.", "response": "def validate(self, val):\n        \"\"\"\n        Validates that the val matches the expected fields for this struct.\n        val must be a dict, and must contain only fields represented by this struct and its\n        ancestors.\n\n        Returns two element tuple: (bool, string)\n\n        - `bool` - True if valid, False if not\n        - `string` - Description of validation error, or None if valid\n\n        :Parameters:\n          val\n            Value to validate.  Must be a dict\n        \"\"\"\n        if type(val) is not dict:\n            return False, \"%s is not a dict\" % (str(val))\n\n        for k, v in val.items():\n            field = self.field(k)\n            if field:\n                ok, msg = self.contract.validate(field, field.is_array, v)\n                if not ok:\n                    return False, \"field '%s': %s\" % (field.name, msg)\n            else:\n                return False, \"field '%s' not found in struct %s\" % (k, self.name)\n\n        all_fields = self.get_all_fields([])\n        for field in all_fields:\n            if not val.has_key(field.name) and not field.optional:\n                return False, \"field '%s' missing from: %s\" % (field.name, str(val))\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_fields(self, arr):\n        for k, v in self.fields.items():\n            arr.append(v)\n            \n        if self.extends:\n            parent = self.contract.get(self.extends)\n            if parent:\n                return parent.get_all_fields(arr)\n\n        return arr", "response": "Returns a list containing this struct s fields and all the fields of\n            s ancestors. Used during validation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_params(self, params):\n        plen = 0\n        if params != None:\n            plen = len(params)\n\n        if len(self.params) != plen:\n            vals = (self.full_name, len(self.params), plen)\n            msg = \"Function '%s' expects %d param(s). %d given.\" % vals\n            raise RpcException(ERR_INVALID_PARAMS, msg)\n        \n        if params != None:\n            i = 0\n            for p in self.params:\n                self._validate_param(p, params[i])\n                i += 1", "response": "Validates the params against expected types for this function. Raises RpcException if the params are invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the response against expected return type for this function. Raises RpcException if the response is invalid.", "response": "def validate_response(self, resp):\n        \"\"\"\n        Validates resp against expected return type for this function.  \n        Raises RpcException if the response is invalid.\n        \"\"\"\n        ok, msg = self.contract.validate(self.returns, \n                                         self.returns.is_array, resp)\n        if not ok:\n            vals = (self.full_name, str(resp), msg)\n            msg = \"Function '%s' invalid response: '%s'. %s\" % vals\n            raise RpcException(ERR_INVALID_RESP, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate a single parameter against its expected type.", "response": "def _validate_param(self, expected, param):\n        \"\"\"\n        Validates a single param against its expected type.\n        Raises RpcException if the param is invalid\n        \n        :Parameters:\n          expected\n            Type instance\n          param\n            Parameter value to validate\n        \"\"\"\n        ok, msg = self.contract.validate(expected, expected.is_array, param)\n        if not ok:\n            vals = (self.full_name, expected.name, msg)\n            msg = \"Function '%s' invalid param '%s'. %s\" % vals\n            raise RpcException(ERR_INVALID_PARAMS, msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubmit data to Polarion Importer.", "response": "def submit(xml_root, submit_config, session, dry_run=None, **kwargs):\n    \"\"\"Submits data to the Polarion Importer.\"\"\"\n    properties.xunit_fill_testrun_id(xml_root, kwargs.get(\"testrun_id\"))\n    if dry_run is not None:\n        properties.set_dry_run(xml_root, dry_run)\n    xml_input = utils.etree_to_string(xml_root)\n\n    logger.info(\"Submitting data to %s\", submit_config.submit_target)\n    files = {\"file\": (\"results.xml\", xml_input)}\n    try:\n        response = session.post(submit_config.submit_target, files=files)\n    # pylint: disable=broad-except\n    except Exception as err:\n        logger.error(err)\n        response = None\n\n    return SubmitResponse(response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubmitting data to the Polarion Importer and checks that it was imported.", "response": "def submit_and_verify(\n    xml_str=None, xml_file=None, xml_root=None, config=None, session=None, dry_run=None, **kwargs\n):\n    \"\"\"Submits data to the Polarion Importer and checks that it was imported.\"\"\"\n    try:\n        config = config or configuration.get_config()\n        xml_root = _get_xml_root(xml_root, xml_str, xml_file)\n        submit_config = SubmitConfig(xml_root, config, **kwargs)\n        session = session or utils.get_session(submit_config.credentials, config)\n        submit_response = submit(xml_root, submit_config, session, dry_run=dry_run, **kwargs)\n    except Dump2PolarionException as err:\n        logger.error(err)\n        return None\n\n    valid_response = submit_response.validate_response()\n    if not valid_response or kwargs.get(\"no_verify\"):\n        return submit_response.response\n\n    response = verify_submit(\n        session,\n        submit_config.queue_url,\n        submit_config.log_url,\n        submit_response.job_ids,\n        timeout=kwargs.get(\"verify_timeout\"),\n        log_file=kwargs.get(\"log_file\"),\n    )\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the job IDs of the import.", "response": "def get_job_ids(self):\n        \"\"\"Returns job IDs of the import.\"\"\"\n        if not self.parsed_response:\n            return None\n        try:\n            job_ids = self.parsed_response[\"files\"][\"results.xml\"][\"job-ids\"]\n        except KeyError:\n            return None\n        if not job_ids or job_ids == [0]:\n            return None\n        return job_ids"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_response(self):\n        if self.response is None:\n            logger.error(\"Failed to submit\")\n            return False\n\n        if not self.response:\n            logger.error(\n                \"HTTP status %d: failed to submit to %s\",\n                self.response.status_code,\n                self.response.url,\n            )\n            return False\n\n        if not self.parsed_response:\n            logger.error(\"Submit to %s failed, invalid response received\", self.response.url)\n            return False\n\n        error_message = self.get_error_message()\n        if error_message:\n            logger.error(\"Submit to %s failed with error\", self.response.url)\n            logger.debug(\"Error message: %s\", error_message)\n            return False\n\n        if not self.job_ids:\n            logger.error(\"Submit to %s failed to get job id\", self.response.url)\n            return False\n\n        logger.info(\"Results received by the Importer (HTTP status %d)\", self.response.status_code)\n        logger.info(\"Job IDs: %s\", self.job_ids)\n\n        return True", "response": "Checks that the response is valid and import succeeded."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the msisdn in E. 164 international format.", "response": "def e_164(msisdn: str) -> str:\n    \"\"\"\n    Returns the msisdn in E.164 international format.\n    \"\"\"\n    # Phonenumbers library requires the + to identify the country, so we add it if it\n    # does not already exist\n    number = phonenumbers.parse(\"+{}\".format(msisdn.lstrip(\"+\")), None)\n    return phonenumbers.format_number(number, phonenumbers.PhoneNumberFormat.E164)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadFile(self, filePath):\n        self._filePath = filePath\n\n        if self._proc.state() != QProcess.Running:\n            self._kill()\n            self._run(self._filePath)\n        else:\n            self._execute(\"pausing_keep_force pt_step 1\")\n            self._execute(\"get_property pause\")\n            self._execute(\"loadfile \\\"%s\\\"\" % self._filePath)\n\n        self._data.reset()\n        self.videoDataChanged.emit(False)\n        self._changePlayingState(True)", "response": "Loads a file into the internal data structures."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setVolume(self, volume):\n        val = float(val)\n        cmd = \"volume %s\" % val\n        self._execute(cmd)", "response": "Changes the volume of the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef square(x):\n\n    def H(x):\n        \"\"\"Heaveside step function\"\"\"\n\n        if x < 0.:\n            return 0.\n        if x == 0.:\n            return 0.5\n        if x > 0.:\n            return 1.\n    return 2 * (H(x / L) - H(x / L - 1)) - 1", "response": "Square wave of period 2L"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a custom pin at the maximum value of a data series.", "response": "def add_custom_pin(plot, x, y, label, distance='3ex'):\n    \"\"\"Add a pin at the maximum value of a data series (sort of)\"\"\"\n\n    # only use the second quarter, for cosmetic reasons\n    q = int(0.25 * len(y))\n    y = y[q:2*q]\n    max_index = q + np.argmax(y)\n    max_x = x[max_index]\n    plot.add_pin(label, x=max_x, location='above', use_arrow=True,\n                 style='pin distance=%s' % distance)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_type(t, includeOptional=True):\n    s = \"\"\n    if t.has_key('is_array') and t['is_array']:\n        s = \"[]%s\" % t['type']\n    else:\n        s = t['type']\n    if includeOptional and t.has_key('optional') and t['optional'] == True:\n        s += \" [optional]\"\n    return s", "response": "Formats the type as a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef docco_html(title, idl_parsed, diagram_fname=None):\n    sections = to_sections(idl_parsed)\n    s = \"\"\"<!DOCTYPE html>\n<html>\n<head>\n  <title>%s</title>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n  <style type=\"text/css\">\n  %s\n  </style>\n</head>\n<body>\n  <div id=\"container\">\n    <div id=\"background\"></div>\n    <table cellpadding=\"0\" cellspacing=\"0\">\n      <thead>\n        <tr>\n          <th class=\"docs\">\n            <h1>\n               %s\n            </h1>\n          </th>\n          <th class=\"code\">\n          </th>\n        </tr>\n      </thead>\n      <tbody>\"\"\" % (title, DOCCO_CSS, title)\n    \n    i = 0\n    for sec in sections:\n        i += 1\n        s += \"\"\"<tr id=\"section-%d\">\n            <td class=\"docs\">\n              <div class=\"pilwrap\">\n                <a class=\"pilcrow\" href=\"#section-%d\">&#182;</a>\n              </div>\n              %s\n            </td>\n            <td class=\"code\">\n              %s\n            </td>\n          </tr>\"\"\" % (i, i, sec['docs'], sec['code'])\n\n    s += \"\"\"</tbody>\n    </table>\n  </div>\n</body>\n</html>\"\"\"\n    if diagram_fname:\n        diagram_link = \"\"\"<a href=\"%s\"><img src=\"%s\" height=\"120\" width=\"120\" border=\"0\" /></a>\"\"\" % (diagram_fname, diagram_fname)\n        s = s.replace(\"[[diagram]]\", diagram_link)\n    return s", "response": "Returns a string containing the HTML representation of the IDL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_enum(enum):\n    docs = enum['comment']\n    code = '<span class=\"k\">enum</span> <span class=\"gs\">%s</span> {\\n' % enum['name']\n    for v in enum[\"values\"]:\n        if v['comment']:\n            for line in v['comment'].split(\"\\n\"):\n                code += '    <span class=\"c1\">// %s</span>\\n' % line\n        code += '    <span class=\"nv\">%s</span>\\n' % v['value']\n    code += \"}\"\n\n    return to_section(docs, code)", "response": "Parses an IDL enum dict and returns a docco section for the given enum."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the IDL struct and returns a docco section for the given struct.", "response": "def parse_struct(s):\n    \"\"\"\n    Returns a docco section for the given struct.\n\n    :Parameters:\n      s\n        Parsed IDL struct dict. Keys: 'comment', 'name', 'extends', 'fields'\n    \"\"\"\n    docs = s['comment']\n    code = '<span class=\"k\">struct</span> <span class=\"gs\">%s</span>' % s['name']\n    if s['extends']:\n        code += ' extends <span class=\"gs\">%s</span>' % s['extends']\n    code += ' {\\n'\n    namelen = 0\n    typelen = 0\n    for v in s[\"fields\"]:\n        tlen = len(format_type(v, includeOptional=False))\n        if len(v['name']) > namelen:\n            namelen = len(v['name'])\n        if tlen > typelen:\n          typelen = tlen\n\n    namelen += 1\n    typelen += 1\n\n    formatstr = '    <span class=\"nv\">%s</span><span class=\"kt\">%s %s</span>\\n'\n\n    i = 0\n    for v in s[\"fields\"]:\n        if v.has_key('comment') and v['comment']:\n            if i > 0: code += \"\\n\"\n            for line in v['comment'].split(\"\\n\"):\n                code += '    <span class=\"c1\">// %s</span>\\n' % line\n        opt = \"\"\n        if v.has_key('optional') and v['optional'] == True:\n          opt = \" [optional]\"\n        code += formatstr % (string.ljust(v['name'], namelen), string.ljust(format_type(v, includeOptional=False), typelen), opt)\n        i += 1\n    code += \"}\"\n\n    return to_section(docs, code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_interface(iface):\n    sections = [ ]\n    docs = iface['comment']\n    code = '<span class=\"k\">interface</span> <span class=\"gs\">%s</span> {\\n' % iface['name']\n    for v in iface[\"functions\"]:\n        func_code = '    <span class=\"nf\">%s</span>(' % v['name']\n        i = 0\n        for p in v[\"params\"]:\n            if i == 0: i = 1\n            else: func_code += \", \"\n            func_code += '<span class=\"na\">%s</span> <span class=\"kt\">%s</span>' % (p['name'], format_type(p))\n        func_code += ') <span class=\"kt\">%s</span>\\n' % format_type(v['returns'])\n        if v.has_key('comment') and v['comment']:\n            if code:\n                sections.append(to_section(docs, code))\n            docs = v['comment']\n            code = func_code\n        else:\n            code += func_code\n    code += \"}\"\n\n    sections.append(to_section(docs, code))\n    return sections", "response": "Parses the IDL interface dict and returns a list of docco sections for the given interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating through elements in idl_parsed list and returns a list of section dicts.", "response": "def to_sections(idl_parsed):\n    \"\"\"\n    Iterates through elements in idl_parsed list and returns a list of section dicts.\n    Currently elements of type \"comment\", \"enum\", \"struct\", and \"interface\" are processed.\n\n    :Parameters:\n      idl_parsed\n        Barrister parsed IDL\n    \"\"\"\n    sections = []\n    for entity in idl_parsed:\n        if entity[\"type\"] == \"comment\":\n            sections.append(to_section(entity[\"value\"], \"\"))\n        elif entity[\"type\"] == \"enum\":\n            sections.append(parse_enum(entity))\n        elif entity[\"type\"] == \"struct\":\n            sections.append(parse_struct(entity))\n        elif entity[\"type\"] == \"interface\":\n            sections.extend(parse_interface(entity))\n    return sections"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sub_location(self, nbr):\n        assert nbr > -1, \"Sub location number must be greater or equal to 0!\"\n        assert nbr < self.nbr_of_sub_locations() - 1, \"Sub location number must be lower than %d!\" % self.nbr_of_sub_locations() - 1\n        return self._locations_list[nbr]", "response": "Returns a given sub location 0 - based."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_locations_list(self, lower_bound=0, upper_bound=None):\n        real_upper_bound = upper_bound\n        if upper_bound is None:\n            real_upper_bound = self.nbr_of_sub_locations()\n\n        try:\n            return self._locations_list[lower_bound:real_upper_bound]\n        except:\n            return list()", "response": "Return the internal location list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_string(self, other_separation_char=None):\n        separation_char = self._separation_char\n        if other_separation_char is not None:\n            separation_char = other_separation_char\n        return separation_char.join(self._locations_list)", "response": "Returns a string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_args(args, kwargs, arg_names):\n    '''Get arguments as a dict.\n    '''\n    n_args = len(arg_names)\n    if len(args) + len(kwargs) > n_args:\n        raise MoultScannerError('Too many arguments supplied. Expected: {}'.format(n_args))\n\n    out_args = {}\n    for i, a in enumerate(args):\n        out_args[arg_names[i]] = a\n\n    for a in arg_names:\n        if a not in out_args:\n            out_args[a] = None\n\n    out_args.update(kwargs)\n    return out_args", "response": "Get arguments as a dict.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ast_scan_file(filename, re_fallback=True):\n    '''Scans a file for imports using AST.\n\n    In addition to normal imports, try to get imports via `__import__`\n    or `import_module` calls. The AST parser should be able to resolve\n    simple variable assignments in cases where these functions are called\n    with variables instead of strings.\n    '''\n    try:\n        with io.open(filename, 'rb') as fp:\n            try:\n                root = ast.parse(fp.read(), filename=filename)\n            except (SyntaxError, IndentationError):\n                if re_fallback:\n                    log.debug('Falling back to regex scanner')\n                    return _ast_scan_file_re(filename)\n                else:\n                    log.error('Could not parse file: %s', filename)\n                    log.info('Exception:', exc_info=True)\n                return None, None\n            log.debug('Starting AST Scan: %s', filename)\n            ast_visitor.reset(filename)\n            ast_visitor.visit(root)\n            log.debug('Project path: %s', ast_visitor.import_root)\n            return ast_visitor.scope, ast_visitor.imports\n    except IOError:\n        log.warn('Could not open file: %s', filename)\n\n    return None, None", "response": "Scans a file for imports using AST."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the session_data to be used in the cookie.", "response": "def prepare(session_data={}, #pylint: disable=dangerous-default-value\n                passphrase=None):\n        \"\"\"\n        Returns *session_dict* as a base64 encrypted json string.\n\n        The full encrypted text is special crafted to be compatible\n        with openssl. It can be decrypted with:\n\n          $ echo _full_encypted_ | openssl aes-256-cbc -d -a -k _passphrase_ -p\n          salt=...\n          key=...\n          iv=...\n          _json_formatted_\n        \"\"\"\n        if passphrase is None:\n            passphrase = settings.DJAODJIN_SECRET_KEY\n        encrypted = crypt.encrypt(\n            json.dumps(session_data, cls=crypt.JSONEncoder),\n            passphrase=passphrase,\n            debug_stmt=\"encrypted_cookies.SessionStore.prepare\")\n        # b64encode will return `bytes` (Py3) but Django 2.0 is expecting\n        # a `str` to add to the cookie header, otherwise it wraps those\n        # `bytes` into a b'***' and adds that to the cookie.\n        # Note that Django 1.11 will add those `bytes` to the cookie \"as-is\".\n        if not isinstance(encrypted, six.string_types):\n            as_text = encrypted.decode('ascii')\n        else:\n            as_text = encrypted\n        return as_text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self):\n        session_data = {}\n        try:\n            session_text = crypt.decrypt(self.session_key,\n                passphrase=settings.DJAODJIN_SECRET_KEY,\n                debug_stmt=\"encrypted_cookies.SessionStore.load\")\n            session_data = json.loads(session_text)\n            self._session_key_data.update(session_data)\n            LOGGER.debug(\"session data (from proxy): %s\", session_data)\n            # We have been able to decode the session data, let's\n            # create Users and session keys expected by Django\n            # contrib.auth backend.\n            if 'username' in session_data:\n                user = authenticate(\n                    request=session_data, remote_user=session_data['username'])\n                if not user:\n                    raise ValueError(\"Cannot authenticate user.\")\n                session_data[SESSION_KEY] = user.id\n                session_data[BACKEND_SESSION_KEY] = user.backend\n                session_data[HASH_SESSION_KEY] = user.get_session_auth_hash()\n                if self._local:\n                    session_data_local = self._local.load()\n                    LOGGER.debug(\"session data (local): %s\", session_data_local)\n                    session_data.update(session_data_local)\n        except (IndexError, TypeError, ValueError) as err:\n            # Incorrect padding in b64decode, incorrect block size in AES,\n            # incorrect PKCS#5 padding or malformed json will end-up here.\n            LOGGER.debug(\"error: while loading session, %s\", err)\n            return {}\n        return session_data", "response": "Load the session data from the key itself if it is not already there."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen the session from the key itself.", "response": "def open_session(self, app, request):\n        \"\"\"\n        We load the data from the key itself instead of fetching from\n        some external data store. Opposite of _get_session_key(),\n        raises BadSignature if signature fails.\n\n          $ echo '_json_formatted_' | openssl aes-256-cbc -a -k _passphrase_ -p\n          salt=...\n          key=...\n          iv=...\n          _full_encrypted_\n        \"\"\"\n        session_key = request.cookies.get(app.session_cookie_name)\n        if not session_key:\n            found = False\n            for path in self.allowed_no_session:\n                if request.path.startswith(str(path)):\n                    found = True\n                    break\n            if not found:\n                app.logger.debug(\"%s not found in %s\", request.path,\n                    [str(url) for url in self.allowed_no_session])\n                raise PermissionDenied(\"No DjaoDjin session key\")\n\n        session_data = {}\n        try:\n            session_data = json.loads(crypt.decrypt(\n                session_key, passphrase=self.secret_key))\n        except (IndexError, TypeError, ValueError) as _:\n            # Incorrect padding in b64decode, incorrect block size in AES,\n            # incorrect PKCS#5 padding or malformed json will end-up here.\n            pass\n        return self.session_class(initial=session_data, session_key=session_key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize structured data into a stream in JSON YAML or LHA format.", "response": "def dump(d, fmt='json', stream=None):\n    \"\"\"Serialize structured data into a stream in JSON, YAML, or LHA format.\n    If stream is None, return the produced string instead.\n\n    Parameters:\n    - fmt: should be 'json' (default), 'yaml', or 'lha'\n    - stream: if None, return string\n    \"\"\"\n    if fmt == 'json':\n        return _dump_json(d, stream=stream)\n    elif fmt == 'yaml':\n        return yaml.dump(d, stream)\n    elif fmt == 'lha':\n        s = _dump_lha(d)\n        if stream is None:\n            return s\n        else:\n            return stream.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a string of text from a text inline and returns a 3 tuple of name value kwargs.", "response": "def parse_inline(text):\n    \"\"\"\n    Takes a string of text from a text inline and returns a 3 tuple of\n    (name, value, **kwargs).\n    \"\"\"\n\n    m = INLINE_SPLITTER.match(text)\n    if not m:\n        raise InlineUnparsableError\n    args = m.group('args')\n    name = m.group('name')\n    value = \"\"\n    kwtxt = \"\"\n    kwargs = {}\n    if args:\n        kwtxt = INLINE_KWARG_PARSER.search(args).group('kwargs')\n        value = re.sub(\"%s\\Z\" % kwtxt, \"\", args)\n        value = value.strip()\n    if m.group('variant'):\n        kwargs['variant'] = m.group('variant')\n    if kwtxt:\n        for kws in kwtxt.split():\n            k, v = kws.split('=')\n            kwargs[str(k)] = v\n    return (name, value, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inline_for_model(model, variants=[], inline_args={}):\n\n    if not isinstance(model, ModelBase):\n        raise ValueError(\"inline_for_model requires it's argument to be a Django Model\")\n    d = dict(model=model)\n    if variants:\n        d['variants'] = variants\n    if inline_args:\n        d['args'] = inline_args\n    class_name = \"%sInline\" % model._meta.module_name.capitalize()\n    return type(class_name, (ModelInline,), d)", "response": "A shortcut function to produce ModelInlines for django models"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_predict(training_data, fitting_data, tau=1, samples_per_job=0, save_results=True, show=False):\n    from disco.worker.pipeline.worker import Worker, Stage\n    from disco.core import Job, result_iterator\n    from disco.core import Disco\n\n    \"\"\"\n    training_data - training samples\n    fitting_data - dataset to be fitted to training data.\n    tau - controls how quickly the weight of a training sample falls off with distance of its x(i) from the query point x.\n    samples_per_job - define a number of samples that will be processed in single mapreduce job. If 0, algorithm will calculate number of samples per job.\n    \"\"\"\n\n    try:\n        tau = float(tau)\n        if tau <= 0:\n            raise Exception(\"Parameter tau should be >= 0.\")\n    except ValueError:\n        raise Exception(\"Parameter tau should be numerical.\")\n\n    if fitting_data.params[\"id_index\"] == -1:\n        raise Exception(\"Predict data should have id_index set.\")\n\n    job = Job(worker=Worker(save_results=save_results))\n    job.pipeline = [\n        (\"split\", Stage(\"map\", input_chain=fitting_data.params[\"input_chain\"], init=simple_init, process=map_predict))]\n    job.params = fitting_data.params\n    job.run(name=\"lwlr_read_data\", input=fitting_data.params[\"data_tag\"])\n\n    samples = {}\n    results = []\n    tau = float(2 * tau ** 2)  # calculate tau once\n    counter = 0\n\n    for test_id, x in result_iterator(job.wait(show=show)):\n        if samples_per_job == 0:\n            # calculate number of samples per job\n            if len(x) <= 100:  # if there is less than 100 attributes\n                samples_per_job = 100  # 100 samples is max per on job\n            else:\n                # there is more than 100 attributes\n                samples_per_job = len(x) * -25 / 900. + 53  # linear function\n\n        samples[test_id] = x\n        if counter == samples_per_job:\n            results.append(_fit_predict(training_data, samples, tau, save_results, show))\n            counter = 0\n            samples = {}\n        counter += 1\n\n    if len(samples) > 0:  # if there is some samples left in the the dictionary\n        results.append(_fit_predict(training_data, samples, tau, save_results, show))\n\n    # merge results of every iteration into a single tag\n    ddfs = Disco().ddfs\n    ddfs.tag(job.name, [[list(ddfs.blobs(tag))[0][0]] for tag in results])\n\n    return [\"tag://\" + job.name]", "response": "Fit a predict on the training data and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a list of ports for the current rank", "response": "def create_ports(port, mpi, rank):\n        \"\"\"create a list of ports for the current rank\"\"\"\n        if port == \"random\" or port is None:\n            # ports will be filled in using random binding\n            ports = {}\n        else:\n            port = int(port)\n            ports = {\n                \"REQ\": port + 0,\n                \"PUSH\": port + 1,\n                \"SUB\": port + 2\n            }\n        # if we want to communicate with separate domains\n        # we have to setup a socket for each of them\n        if mpi == 'all':\n            # use a socket for each rank rank\n            for port in ports:\n                ports[port] += (rank * 3)\n        return ports"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_from_string(full_class_name):\n        s = full_class_name.split('.')\n        class_name = s[-1]\n        module_name = full_class_name[:-len(class_name)-1]\n        module = importlib.import_module(module_name)\n        # the class, it's common to spell with k as class is reserved\n        klass = getattr(module, class_name)\n        return klass", "response": "import a class based on it s full class name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a bmi model using an optional class", "response": "def create_bmi_model(self, engine, bmi_class=None, wrapper_kwargs=None):\n        \"\"\"initialize a bmi mode using an optional class\"\"\"\n        if wrapper_kwargs is None:\n            wrapper_kwargs = {}\n        if bmi_class is None:\n            wrapper_class = bmi.wrapper.BMIWrapper\n        else:\n            wrapper_class = self.import_from_string(bmi_class)\n        try:\n            \"\"\"most models use engine as a first argument\"\"\"\n            model = wrapper_class(\n                engine,\n                **wrapper_kwargs\n            )\n        except TypeError as e:\n            \"\"\"but old python engines are engines, so they don't, but they should \"\"\"\n            logger.warn(\n                'Model wrapper %s does not accept engine as a first argument',\n                wrapper_class\n            )\n            model = wrapper_class(\n                **wrapper_kwargs\n            )\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self):\n        # connect to tracker\n        result = requests.post(urljoin(self.tracker, 'models'), data=json.dumps(self.metadata))\n        logger.debug(\"registered at server %s: %s\", self.tracker, result)\n        self.metadata[\"tracker\"] = result.json()", "response": "register model at tracking server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_incoming(self):\n\n        model = self.model\n        sockets = self.sockets\n\n        # Check for new messages\n        if not sockets:\n            return\n        # unpack sockets\n        poller = sockets['poller']\n        rep = sockets['rep']\n        # pull = sockets['pull']\n        pub = sockets['pub']\n        items = poller.poll(10)\n        for sock, n in items:\n            for i in range(n):\n\n                A, metadata = recv_array(sock)\n                var = None\n\n                # bmi actions\n                if \"update\" in metadata:\n                    dt = float(metadata[\"update\"])\n                    model.update(dt)\n                    metadata[\"dt\"] = dt\n                elif \"get_var\" in metadata:\n                    name = metadata[\"get_var\"]\n                    # temporary implementation\n                    if metadata.get(\"copy\", False):\n                        var = model.get_var(name).copy()\n                    else:\n                        var = model.get_var(name)\n                    if var is None:\n                        logger.warning(\"Get_var returns None for %s\" % name)\n                    metadata['name'] = name\n                    # assert socket is req socket\n                elif \"get_var_count\" in metadata:\n                    # temporary implementation\n                    n = model.get_var_count()\n                    metadata['get_var_count'] = n\n                    # assert socket is req socket\n                elif \"get_var_rank\" in metadata:\n                    # temporary implementation\n                    var_name = metadata['get_var_rank']\n                    n = model.get_var_rank(var_name)\n                    metadata['get_var_rank'] = n\n                    # assert socket is req socket\n                elif \"get_var_shape\" in metadata:\n                    # temporary implementation\n                    var_name = metadata['get_var_shape']\n                    n = model.get_var_shape(var_name)\n                    metadata['get_var_shape'] = tuple([int(item) for item in n])\n                    # assert socket is req socket\n                elif \"get_var_type\" in metadata:\n                    # temporary implementation\n                    var_name = metadata['get_var_type']\n                    n = model.get_var_type(var_name)\n                    metadata['get_var_type'] = n\n                    # assert socket is req socket\n                elif \"get_var_name\" in metadata:\n                    i = int(metadata[\"get_var_name\"])\n                    name = model.get_var_name(i)\n                    metadata['get_var_name'] = name\n                    # assert socket is req socket\n                elif \"set_current_time\" in metadata:\n                    t = float(metadata[\"set_current_time\"])\n                    model.set_current_time(t)\n                elif \"set_var\" in metadata:\n                    name = metadata[\"set_var\"]\n                    # logger.debug(\"setting variable %s\", name)\n                    model.set_var(name, A)\n                    metadata[\"name\"] = name  # !?\n                elif \"set_var_slice\" in metadata:\n                    name = metadata[\"set_var_slice\"]\n                    logger.debug(\"setting variable %s\", name)\n                    start = metadata[\"start\"]\n                    count = metadata[\"count\"]\n                    model.set_var_slice(name, start, count, A)\n                    metadata[\"name\"] = name  # !?\n                elif \"set_var_index\" in metadata:\n                    name = metadata[\"set_var_index\"]\n                    logger.debug(\"setting variable %s using index index\", name)\n                    index = metadata[\"index\"]\n                    # TODO: test if this is fast enough.\n                    # Otherwise move to BMI ++ but that is\n                    # a bit of a burden on implementers\n                    var = model.get_var(name).copy()\n                    var.flat[index] = A\n                    model.set_var(name, var)\n                    metadata[\"name\"] = name  # !?\n                elif \"get_current_time\" in metadata:\n                    metadata[\"get_current_time\"]\n                    t = model.get_current_time()\n                    metadata['get_current_time'] = t\n                elif \"get_time_step\" in metadata:\n                    metadata[\"get_time_step\"]\n                    dt = model.get_time_step()\n                    metadata['get_time_step'] = dt\n                elif \"get_end_time\" in metadata:\n                    metadata[\"get_end_time\"]\n                    t = model.get_end_time()\n                    metadata['get_end_time'] = t\n                elif \"get_start_time\" in metadata:\n                    metadata[\"get_start_time\"]\n                    t = model.get_start_time()\n                    metadata['get_start_time'] = t\n                    # assert socket is req socket\n                # custom actions\n                elif \"remote\" in metadata:\n                    assert metadata[\"remote\"] in {\n                        \"play\", \"stop\", \"pause\", \"rewind\", \"quit\"}\n                    model.state = metadata[\"remote\"]\n                elif \"operator\" in metadata:\n                    # TODO: support same operators as MPI_ops here....,\n                    # TODO: reduce before apply\n                    # TODO: assert pull socket\n                    pass\n                    # S = tuple(slice(*x) for x in action['slice'])\n                    # print(repr(arr[S]))\n                    # if action['operator'] == 'setitem':\n                    #     arr[S] = data\n                    # elif action['operator'] == 'add':\n                    #     arr[S] += data\n                elif \"initialize\" in metadata:\n                    config_file = metadata[\"initialize\"]\n                    model.initialize(str(config_file))\n                elif \"finalize\" in metadata:\n                    model.finalize()\n                else:\n                    logger.warn(\"got unknown message {} from socket {}\".format(str(metadata), sock))\n                if sock.socket_type == zmq.REP:\n                    # reply\n                    send_array(rep, var, metadata=metadata)\n                # any getter requested through the pull socket?\n                elif any(x.startswith(\"get_\") for x in metadata) and sock.socket_type == zmq.PULL:\n                    # return through the pub socket\n                    send_array(pub, var, metadata=metadata)", "response": "process incoming messages and return a dict with the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates various aspects of the structure", "response": "def calc_basics(width=-1, length=-1, height=2.4, prevailing_wind=2.8):   \n    \"\"\"\n    calculate various aspects of the structure \n    \"\"\"\n    if width == -1:\n        width = int(input('enter building width : '))\n    if length == -1:\n        length = int(input('enter building length : '))\n    res = {}\n    \n    res['area'] = width * length\n    res['perim'] =  2 * width + 2 * length\n    res['roof_cladding'] = res['area']\n    res['wall_cladding'] = res['perim'] * height\n    pprint(res)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates rafter deflections - see test_calc_building_design.py for Sample values for equations below from Structures II course", "response": "def bld_rafter_deflection(length=-9, force=-9, E_mod_elasticity=-9, I_moment_of_intertia=-9):\n    \"\"\"\n    calculate rafter deflections - see test_calc_building_design.py for \n    Sample values for equations below from Structures II course\n    \"\"\"\n    \n    \n    if length == -9:\n        length = float(input('enter rafter length : '))\n        \n    if force == -9:\n        force = float(input('enter Force or weight applied to roof : '))\n    \n    if E_mod_elasticity == -9:\n        E_mod_elasticity = float(input('enter modulus of elasticity x10**5 (Steel beam example=2.1) : '))\n    \n    if I_moment_of_intertia == -9:\n        I_moment_of_intertia = float(input('enter members \"moment of intertia x10**6\" (for Steel beam 410UB53.7=188 ) :'))\n        \n    res = {}\n    \n    res['max deflection - centre load'] =  (1 * force * (length ** 3)) / (48  * (E_mod_elasticity * 10**5) * (I_moment_of_intertia * 10**6))\n    res['max deflection - distrib load'] = (5 * force * (length ** 4)) / (384 * (E_mod_elasticity * 10**5) * (I_moment_of_intertia * 10**6))\n    \n    pprint(res)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all the states in the division.", "response": "def get_division(self, obj):\n        \"\"\"Division.\"\"\"\n        if self.context.get(\"division\"):\n            return DivisionSerializer(self.context.get(\"division\")).data\n        else:\n            if obj.slug == \"senate\":\n                return DivisionSerializer(obj.jurisdiction.division).data\n            else:\n                us = DivisionSerializer(obj.jurisdiction.division).data\n\n                us[\"children\"] = [\n                    DivisionSerializer(\n                        state,\n                        context={\"children_level\": DivisionLevel.DISTRICT},\n                    ).data\n                    for state in obj.jurisdiction.division.children.all()\n                ]\n\n                return us"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_parties(self, obj):\n        return PartySerializer(Party.objects.all(), many=True).data", "response": "Get all parties for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_elections(self, obj):\n        election_day = ElectionDay.objects.get(\n            date=self.context[\"election_date\"]\n        )\n\n        kwargs = {\"race__office__body\": obj, \"election_day\": election_day}\n        if self.context.get(\"division\") and obj.slug == \"senate\":\n            kwargs[\"division\"] = self.context[\"division\"]\n        elif self.context.get(\"division\") and obj.slug == \"house\":\n            kwargs[\"division__parent\"] = self.context[\"division\"]\n\n        if obj.slug == \"house\" and not self.context.get(\"division\"):\n            kwargs[\"race__special\"] = False\n\n        elections = Election.objects.filter(**kwargs)\n        return ElectionSerializer(elections, many=True).data", "response": "All elections held on an election day."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef accuracy_score(y, y_pred):\n\n    y, y_pred = convert_assert(y, y_pred)\n    return np.count_nonzero(y == y_pred) / y.size", "response": "Calculates the fraction of the correctly classified samples over all."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef true_positives(y, y_pred):\n\n    y, y_pred = convert_assert(y, y_pred)\n    assert_binary_problem(y)\n\n    return np.count_nonzero(y_pred[y == 1] == 1)", "response": "Returns the number of true positives in the base node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of false positives in the base node.", "response": "def false_positives(y, y_pred):\n    \"\"\"False-positives\n    \n    Parameters:\n    -----------\n    y : vector, shape (n_samples,)\n    The target labels.\n\n    y_pred : vector, shape (n_samples,)\n    The predicted labels.\n    \n    Returns:\n    --------\n    fp : integer, the number of false-positives\n    \n    \"\"\"\n\n    y, y_pred = convert_assert(y, y_pred)\n    assert_binary_problem(y)\n\n    return np.count_nonzero(y_pred[y == 0] == 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the number of true negatives in the base node.", "response": "def true_negatives(y, y_pred):\n    \"\"\"True-negatives\n    \n    Parameters:\n    -----------\n    y : vector, shape (n_samples,)\n    The target labels.\n\n    y_pred : vector, shape (n_samples,)\n    The predicted labels.\n    \n    Returns:\n    --------\n    tn : integer, the number of true-negatives\n    \n    \"\"\"\n\n    y, y_pred = convert_assert(y, y_pred)\n    assert_binary_problem(y)\n\n    return np.count_nonzero(y_pred[y == 0] == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef false_negatives(y, y_pred):\n\n    y, y_pred = convert_assert(y, y_pred)\n    assert_binary_problem(y)\n\n    return np.count_nonzero(y_pred[y == 1] == 0)", "response": "Returns the number of false negatives in the base node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recall(y, y_pred):\n\n    tp = true_positives(y, y_pred)\n    fn = false_negatives(y, y_pred)\n    return  tp / (tp + fn)", "response": "Recall score of a target and predicted labels."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef f1_score(y, y_pred):\n\n    p = precision(y, y_pred)\n    r = recall(y, y_pred)\n\n    return 2*p*r / (p+r)", "response": "F1 score of a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('speaker', nargs='?', default=args['config']['core']['channel'])\n    parser.add_argument('--length', type=int, choices=[1, 2], default=2)\n    parser.add_argument('--start', nargs='*')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if args['db'].query(Babble).count():\n        send(build_msg(args['db'], cmdargs.speaker, cmdargs.length, cmdargs.start))\n    else:\n        send(\"Please run ./scripts/gen_babble.py to initialize the babble cache\")", "response": "Babbles like a user\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naligning queries to genome and gets SAM file for each sequence in dqueries", "response": "def dqueries2queriessam(cfg,dqueries):    \n    \"\"\"\n    Aligns queries to genome and gets SAM file\n    step#1\n\n    :param cfg: configuration dict\n    :param dqueries: dataframe of queries\n    \"\"\"\n    datatmpd=cfg['datatmpd']\n    dqueries=set_index(dqueries,'query id')\n    queryls=dqueries.loc[:,'query sequence'].apply(len).unique()\n    for queryl in queryls:\n        logging.debug(f\"now aligning queries of length {queryl}\")\n        queriesfap = f'{datatmpd}/01_queries_queryl{queryl:02}.fa'\n        logging.info(basename(queriesfap))\n        if not exists(queriesfap) or cfg['force']:\n            with open(queriesfap,'w') as f:\n                for gi in dqueries.index:\n                    f.write('>{}\\n{}\\n'.format(gi.replace(' ','_'),dqueries.loc[gi,'query sequence']))\n        ## BWA alignment command is adapted from cripror \n        ## https://github.com/rraadd88/crisporWebsite/blob/master/crispor.py\n        # BWA allow up to X mismatches\n        # maximum number of occurences in the genome to get flagged as repeats. \n        # This is used in bwa samse, when converting the sam file\n        # and for warnings in the table output.\n        MAXOCC = 60000\n\n        # the BWA queue size is 2M by default. We derive the queue size from MAXOCC\n        MFAC = 2000000/MAXOCC\n\n        genomep=cfg['genomep']\n        genomed = dirname(genomep) # make var local, see below\n        genomegffp=cfg['genomegffp']\n\n        # increase MAXOCC if there is only a single query, but only in CGI mode\n        bwaM = MFAC*MAXOCC # -m is queue size in bwa\n        queriessap = f'{datatmpd}/01_queries_queryl{queryl:02}.sa'\n        logging.info(basename(queriessap))\n        if not exists(queriessap) or cfg['force']:\n            cmd=f\"{cfg['bwa']} aln -t 1 -o 0 -m {bwaM} -n {cfg['mismatches_max']} -k {cfg['mismatches_max']} -N -l {queryl} {genomep} {queriesfap} > {queriessap} 2> {queriessap}.log\"\n            runbashcmd(cmd)\n\n        queriessamp = f'{datatmpd}/01_queries_queryl{queryl:02}.sam'\n        logging.info(basename(queriessamp))        \n        if not exists(queriessamp) or cfg['force']:\n            cmd=f\"{cfg['bwa']} samse -n {MAXOCC} {genomep} {queriessap} {queriesfap} > {queriessamp} 2> {queriessamp}.log\"\n            runbashcmd(cmd)\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the alignmentbed file and returns a pandas. DataFrame with the genomic coordinates in BED format.", "response": "def queriessam2dalignbed(cfg):\n    \"\"\"\n    Processes SAM file to get the genomic coordinates in BED format\n    step#2\n\n    :param cfg: configuration dict\n    \"\"\"\n    datatmpd=cfg['datatmpd']\n    alignmentbedp=cfg['alignmentbedp']\n    dalignbedp=cfg['dalignbedp']\n    logging.info(basename(dalignbedp))\n    if not exists(alignmentbedp) or cfg['force']:\n        #input/s\n        queriessamps=glob(f'{datatmpd}/01_queries_queryl*.sam')\n        for queriessamp in queriessamps:\n            if stat(queriessamp).st_size != 0:\n                samfile=pysam.AlignmentFile(queriessamp, \"rb\")\n                dalignbed=pd.DataFrame(columns=bed_colns)\n                for read in samfile.fetch():\n                    algnids=[]\n                    \n#                     read_position=read.positions[0]\n#                     tag_NM=read.get_tag('NM')                    \n                    if len(read.positions)!=0:\n                        read_position=read.positions[0]\n                    else:\n                        logging.error('no alignments found')\n                        print(read)\n                        continue\n#                         read_position=[None]\n                    try: \n                        tag_NM=read.get_tag('NM')\n                    except: \n                        logging.error('no NM tag found')\n                        print(read)\n                        continue\n#                         tag_NM=None\n                    algnids.append(f\"{read.reference_name}|{'-' if read.is_reverse else '+'}{read_position}|{read.cigarstring}|{tag_NM}\")\n                    if read.has_tag('XA'):\n                        algnids+=['|'.join(s.split(',')) for s in read.get_tag('XA').split(';') if len(s.split(','))>1]\n#                     print(len(algnids))\n                    chroms=[]\n                    starts=[]\n                    ends=[]\n                    algnids=algnids[:20]\n                    NMs=[]\n                    strands=[]\n                    for a in algnids:\n                        strand=a.split('|')[1][0]\n                        chroms.append(a.split('|')[0])\n                        if strand=='+':\n                            offset=0\n                        elif strand=='-':\n                            offset=0                    \n                        starts.append(int(a.split('|')[1][1:])+offset)\n                        ends.append(int(a.split('|')[1][1:])+str2num(a.split('|')[2])+offset)\n                        NMs.append(a.split('|')[3])\n                        strands.append(strand)\n                        del strand,offset\n                    col2dalignbed={'chromosome':chroms,\n                                   'start':starts,\n                                   'end':ends,\n                                   'id':algnids,\n                                   'NM':NMs,\n                                   'strand':strands}\n                #     col2dalignbed=dict(zip(cols,[a.split('|')[0],a.split('|')[1],a.split('|')[2],a,a.split('|')[3],a.split('|')[4] for a in algnids]))\n                    dalignbed_=pd.DataFrame(col2dalignbed)\n                    dalignbed_['query id']=read.qname.replace('_',' ')\n                    dalignbed = dalignbed.append(dalignbed_,ignore_index=True,sort=True)\n                #     break\n                samfile.close()\n            else:\n                logging.warning(f\"file is empty: {queriessamp}\")\n        dalignbed.to_csv(dalignbedp,sep='\\t')\n        from rohan.dandage.io_nums import str2numorstr\n        dalignbed['chromosome']=dalignbed.apply(lambda x : str2numorstr(x['chromosome']),axis=1)\n        dalignbed=dalignbed.sort_values(['chromosome','start','end'], ascending=[True, True, True])\n        dalignbed.loc[:,bed_colns].to_csv(alignmentbedp,sep='\\t',\n                        header=False,index=False,\n                        chunksize=5000)\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dalignbed2annotationsbed(cfg):\n    datatmpd=cfg['datatmpd']\n    alignmentbedp=cfg['alignmentbedp']    \n    alignmentbedsortedp=alignmentbedp+'.sorted.bed'\n    logging.info(basename(alignmentbedsortedp))\n    if not exists(alignmentbedsortedp) or cfg['force']:\n        cmd=f\"{cfg['bedtools']} sort -i {alignmentbedp} > {alignmentbedsortedp}\"\n        runbashcmd(cmd)\n    \n    genomegffsortedp=cfg['genomegffp']+'.sorted.gff3.gz'\n    logging.info(basename(genomegffsortedp))\n    if not exists(genomegffsortedp):    \n        cmd=f\"{cfg['bedtools']} sort -i {cfg['genomegffp']} > {genomegffsortedp}\"\n        runbashcmd(cmd)\n\n    annotationsbedp=f'{datatmpd}/03_annotations.bed'\n    cfg['annotationsbedp']=annotationsbedp\n    logging.info(basename(annotationsbedp))\n    if not exists(annotationsbedp) or cfg['force']:    \n        cmd=f\"{cfg['bedtools']} intersect -wa -wb -loj -a {alignmentbedsortedp} -b {genomegffsortedp} > {annotationsbedp}\"\n        runbashcmd(cmd)\n    return cfg", "response": "Get the annotations from the aligned BED file\n    step#3"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dalignbed2dalignbedqueries(cfg):\n    datatmpd=cfg['datatmpd']\n    dalignbed=del_Unnamed(pd.read_csv(cfg['dalignbedp'],sep='\\t'))\n    dqueries=set_index(del_Unnamed(pd.read_csv(cfg['dqueriesp'],sep='\\t')),'query id')\n    \n#     if the error in human, use: `cut -f 1 data/alignment.bed.sorted.bed | sort| uniq -c | grep -v CHR | grep -v GL | grep -v KI`\n    dalignbedqueriesp=cfg['dalignbedqueriesp']\n    logging.info(basename(dalignbedqueriesp))\n    if not exists(dalignbedqueriesp) or cfg['force']:\n        dalignbed=pd.merge(dalignbed,dqueries,on='query id',suffixes=('', '.1'))\n        dalignbed.to_csv(dalignbedqueriesp,'\\t')\n    return cfg", "response": "Get query seqeunces from the BED file\n    step#4\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget sequences in FASTA format from BED file and write to daligned FASTA file", "response": "def alignmentbed2dalignedfasta(cfg):\n    \"\"\"\n    Get sequences in FASTA format from BED file\n    step#5\n\n    :param cfg: configuration dict\n    \"\"\"    \n    datatmpd=cfg['datatmpd']\n    alignmentbedp=cfg['alignmentbedp']    \n    dalignedfastap=cfg['dalignedfastap']\n    logging.info(basename(dalignedfastap))\n    if not exists(dalignedfastap) or cfg['force']:\n        alignedfastap='{}/05_alignment.fa'.format(datatmpd)\n        if not exists(alignedfastap) or cfg['force']:\n            cmd=f\"{cfg['bedtools']} getfasta -s -name -fi {cfg['genomep']} -bed {alignmentbedp} -fo {alignedfastap}\"\n            runbashcmd(cmd)\n\n        dalignedfasta=fa2df(alignedfastap)\n        dalignedfasta.columns=['aligned sequence']\n        dalignedfasta=dalignedfasta.loc[(dalignedfasta.apply(lambda x: not 'N' in x['aligned sequence'],axis=1)),:] #FIXME bwa aligns to NNNNNs\n        dalignedfasta.index=[i.split('(')[0] for i in dalignedfasta.index] # for bedtools 2.27, the fasta header now has hanging (+) or (-)\n        dalignedfasta.index.name='id'\n        dalignedfasta.to_csv(dalignedfastap,sep='\\t')\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting sequences from BED file step 6", "response": "def dalignbed2dalignbedqueriesseq(cfg):\n    \"\"\"\n    Get sequences from BED file\n    step#6\n\n    :param cfg: configuration dict\n    \"\"\"\n    datatmpd=cfg['datatmpd']\n    dalignbedqueries=del_Unnamed(pd.read_csv(cfg['dalignbedqueriesp'],sep='\\t'))\n    dalignedfasta=del_Unnamed(pd.read_csv(cfg['dalignedfastap'],sep='\\t'))\n    dalignbedqueriesseqp=cfg['dalignbedqueriesseqp']\n    logging.info(basename(dalignbedqueriesseqp))\n    if not exists(dalignbedqueriesseqp) or cfg['force']:        \n        dalignbedqueriesseq=pd.merge(dalignbedqueries,dalignedfasta,on='id',suffixes=('', '.2'))\n        dalignbedqueriesseq=dalignbedqueriesseq.dropna(subset=['aligned sequence'],axis=0)\n\n        # dalignbed.index.name='id'\n        dalignbedqueriesseq=dalignbedqueriesseq.drop_duplicates()\n        dalignbedqueriesseq.to_csv(dalignbedqueriesseqp,sep='\\t')\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget scores for queries step#7 Gets scores for queries step#7 Gets scores for queries step#7 Gets scores for queries step#7 Gets scores for queries step#7 Gets scores for queries step#7 Gets scores for queries step#7 Gets Gets TTS scores for queries step#7 Gets TTS TTS TTS TTSTTS", "response": "def dalignbedqueriesseq2dalignbedstats(cfg):\n    \"\"\"\n    Gets scores for queries\n    step#7\n\n    :param cfg: configuration dict\n    \"\"\"\n    datatmpd=cfg['datatmpd']\n    dalignbedqueriesseq=del_Unnamed(pd.read_csv(cfg['dalignbedqueriesseqp'],sep='\\t'))\n    \n    dalignbedstatsp=cfg['dalignbedstatsp']  \n    logging.info(basename(dalignbedstatsp))\n    if not exists(dalignbedstatsp) or cfg['force']:\n        df=dalignbedqueriesseq.apply(lambda x: align(x['query sequence'],x['aligned sequence'],\n                                                    psm=2,pmm=0.5,pgo=-3,pge=-1,),\n                           axis=1).apply(pd.Series)\n        print(df.head())\n        df.columns=['alignment','alignment: score']\n        dalignbedstats=dalignbedqueriesseq.join(df)\n        del df\n        dalignbedstats.to_csv(dalignbedstatsp,sep='\\t')\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dannots2dalignbed2dannotsagg(cfg):\n    datatmpd=cfg['datatmpd']\n    \n    daannotp=f'{datatmpd}/08_dannot.tsv'\n    cfg['daannotp']=daannotp\n    dannotsaggp=cfg['dannotsaggp']\n    logging.info(basename(daannotp))\n    if ((not exists(daannotp)) and (not exists(dannotsaggp))) or cfg['force']:\n        gff_renamed_cols=[c+' annotation' if c in set(bed_colns).intersection(gff_colns) else c for c in gff_colns]\n        dannots=pd.read_csv(cfg['annotationsbedp'],sep='\\t',\n                   names=bed_colns+gff_renamed_cols,\n                           low_memory=False)\n        dannots=del_Unnamed(dannots)\n\n        dannots=dannots.set_index('id')\n        dannots['annotations count']=1\n        # separate ids from attribute columns\n        dannots=lambda2cols(dannots,lambdaf=gffatributes2ids,\n                    in_coln='attributes',\n                to_colns=['gene name','gene id','transcript id','protein id','exon id'])\n        dannots=dannots.drop(['attributes']+[c for c in gff_renamed_cols if 'annotation' in c],axis=1)\n        logging.debug('or this step takes more time?')\n        to_table(dannots,daannotp)\n#         to_table_pqt(dannots,daannotp)\n    else:\n#         dannots=read_table_pqt(daannotp)\n        dannots=read_table(daannotp)\n        dannots=del_Unnamed(dannots)\n        \n    logging.info(basename(dannotsaggp))\n    if not exists(dannotsaggp) or cfg['force']:\n        if not 'dannots' in locals():\n#             dannots=read_table_pqt(daannotp)\n            dannots=pd.read_table(daannotp,low_memory=False)\n        dannots=del_Unnamed(dannots)\n        dannots=dannots.reset_index()\n        logging.debug('aggregating the annotations')\n        from rohan.dandage.io_sets import unique \n        cols2aggf={'annotations count':np.sum,\n                  'type': unique,\n                  'gene name': unique,\n                  'gene id': unique,\n                  'transcript id': unique,\n                  'protein id': unique,\n                  'exon id': unique}\n        dannotsagg=dannots.groupby('id').agg(cols2aggf)\n        dannotsagg['annotations count']=dannotsagg['annotations count']-1\n        dannotsagg.loc[dannotsagg['annotations count']==0,'region']='intergenic'\n        dannotsagg.loc[dannotsagg['annotations count']!=0,'region']='genic'\n        logging.debug('end of the slowest step')            \n        del dannots    \n        dannotsagg=dannotsagg.reset_index()\n#         to_table_pqt(dannotsagg,dannotsaggp)\n        dannotsagg.to_csv(dannotsaggp,sep='\\t')        \n    return cfg", "response": "reads annotations from annotationsbedp and aggregates them into one single record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmap aggregated annotations to queries step 9", "response": "def dannotsagg2dannots2dalignbedannot(cfg):\n    \"\"\"\n    Map aggregated annotations to queries\n    step#9\n\n    :param cfg: configuration dict\n    \"\"\"\n    datatmpd=cfg['datatmpd']\n    \n    dannotsagg=del_Unnamed(pd.read_csv(cfg['dannotsaggp'],sep='\\t'))\n    dalignbedstats=del_Unnamed(pd.read_csv(cfg['dalignbedstatsp'],sep='\\t'))\n    dalignbedannotp=cfg['dalignbedannotp']\n    logging.info(basename(dalignbedannotp))\n    if not exists(dalignbedannotp) or cfg['force']:\n        # df2info(dalignbed)\n        # df2info(dannotsagg)\n        dalignbedannot=dalignbedstats.set_index('id').join(set_index(dannotsagg,'id'),\n                                              rsuffix=' annotation')\n        dalignbedannot['NM']=dalignbedannot['NM'].apply(int)\n#         from rohan.dandage.get_scores import get_beditorscore_per_alignment,get_cfdscore\n#         dalignbedannot['beditor score']=dalignbedannot.apply(lambda x : get_beditorscore_per_alignment(NM=x['NM'],\n#                                genic=True if x['region']=='genic' else False,\n#                                alignment=x['alignment'],\n#                                pam_length=len(x['PAM']),\n#                                pam_position=x['original position'],\n#                                # test=cfg['test'],\n#                                 ),axis=1) \n#         dalignbedannot['CFD score']=dalignbedannot.apply(lambda x : get_cfdscore(x['query sequence'].upper(), x['aligned sequence'].upper()), axis=1)            \n        dalignbedannot.to_csv(dalignbedannotp,sep='\\t')\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dalignbedannot2daggbyquery(cfg):\n    datatmpd=cfg['datatmpd']\n\n    dalignbedannot=del_Unnamed(pd.read_csv(cfg['dalignbedannotp'],sep='\\t',low_memory=False))\n    \n    daggbyqueryp=f'{datatmpd}/10_daggbyquery.tsv'      \n    logging.info(basename(daggbyqueryp))\n    if not exists(daggbyqueryp) or cfg['force']:\n        dalignbedannot=dfliststr2dflist(dalignbedannot,\n                                ['type', 'gene name', 'gene id', 'transcript id', 'protein id', 'exon id'],\n                                colfmt='tuple')    \n        dalignbedannot['alternate alignments count']=1\n        import itertools\n        from rohan.dandage.io_sets import unique\n        def unique_dropna(l): return unique(l,drop='nan')\n        def merge_unique_dropna(l): return unique(list(itertools.chain(*l)),drop='nan')\n        cols2aggf={'id':unique_dropna,\n         'type':merge_unique_dropna,\n         'gene name':merge_unique_dropna,\n         'gene id':merge_unique_dropna,\n         'transcript id':merge_unique_dropna,\n         'protein id':merge_unique_dropna,\n         'exon id':merge_unique_dropna,\n         'region':unique_dropna,\n         'alternate alignments count':sum,\n        }\n        daggbyquery=dalignbedannot.groupby('query id').agg(cols2aggf)\n        daggbyquery.to_csv(daggbyqueryp,sep='\\t')\n        daggbyquery.to_csv(cfg['dalignannotedp'],sep='\\t')\n    return cfg", "response": "step 10 - alignbed annotations per alignment to annotations per query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef queries2alignments(cfg):\n    from rohan.dandage.align import get_genomes\n    get_genomes(cfg)\n    \n    cfg['datad']=cfg['prjd']\n    cfg['plotd']=cfg['datad']\n    dalignannotedp=f\"{cfg['datad']}/dalignannoted.tsv\"  \n    \n#     stepn='04_alignannoteds'\n#     logging.info(stepn)\n    \n    cfg['datatmpd']=f\"{cfg['datad']}/tmp\"\n    for dp in [cfg['datatmpd']]:\n        if not exists(dp):\n            makedirs(dp)\n            \n    step2doutp={\n    1:'01_queries_queryl*.fa',\n    2:'02_dalignbed.tsv',\n    3:'03_annotations.bed',\n    4:'04_dalignbedqueries.tsv',\n    5:'05_dalignedfasta.tsv',\n    6:'06_dalignbedqueriesseq.tsv',\n    7:'07_dalignbedstats.tsv',\n    8:'08_dannotsagg.tsv',\n    9:'09_dalignbedannot.tsv',\n    10:'10_daggbyquery.tsv',\n    }\n    cfg['dqueriesp']=cfg['dinp']\n    cfg['alignmentbedp']=f\"{cfg['datatmpd']}/02_alignment.bed\"\n    cfg['dalignbedp']=f\"{cfg['datatmpd']}/02_dalignbed.tsv\"\n    cfg['dalignbedqueriesp']=f\"{cfg['datatmpd']}/04_dalignbedqueries.tsv\"\n    cfg['dalignedfastap']=f\"{cfg['datatmpd']}/05_dalignedfasta.tsv\"\n    cfg['dalignbedqueriesseqp']=f\"{cfg['datatmpd']}/06_dalignbedqueriesseq.tsv\"\n    cfg['dalignbedstatsp']=f\"{cfg['datatmpd']}/07_dalignbedstats.tsv\"\n    cfg['dannotsaggp']=f\"{cfg['datatmpd']}/08_dannotsagg.tsv\"\n    cfg['dalignbedannotp']=f\"{cfg['datatmpd']}/09_dalignbedannot.tsv\"\n    cfg['daggbyqueryp']=f\"{cfg['datatmpd']}/10_daggbyquery.tsv\"\n\n    annotationsbedp=f\"{cfg['datatmpd']}/03_annotations.bed\"\n    cfg['annotationsbedp']=annotationsbedp\n    \n    dqueries=read_table(cfg['dqueriesp'])\n    print(dqueries.head())\n    #check which step to process\n    for step in range(2,10+1,1):\n        if not exists(f\"{cfg['datatmpd']}/{step2doutp[step]}\"):\n            if step==2:\n                step=-1\n            break\n    logging.info(f'process from step:{step}')\n    cfg['dalignannotedp']='{}/dalignannoted.tsv'.format(cfg['datad'])\n    if not exists(cfg['dalignannotedp']) or cfg['force']:\n        if step<=1:\n            cfg=dqueries2queriessam(cfg,dqueries)\n        if step<=2:\n            cfg=queriessam2dalignbed(cfg)\n        if step<=3:\n            cfg=dalignbed2annotationsbed(cfg)\n        if step<=4:\n            cfg=dalignbed2dalignbedqueries(cfg)\n        if step<=5:\n            cfg=alignmentbed2dalignedfasta(cfg)\n        if step<=6:\n            cfg=dalignbed2dalignbedqueriesseq(cfg)\n        if step<=7:\n            cfg=dalignbedqueriesseq2dalignbedstats(cfg)\n        if step<=8:\n            cfg=dannots2dalignbed2dannotsagg(cfg)\n        if step<=9:\n            cfg=dannotsagg2dannots2dalignbedannot(cfg)\n        if step<=10:\n            cfg=dalignbedannot2daggbyquery(cfg)\n\n        if cfg is None:        \n            logging.warning(f\"no alignment found\")\n            cfg['step']=4\n            return saveemptytable(cfg,cfg['dalignannotedp'])\n        import gc\n        gc.collect()", "response": "This function takes in a configuration file and returns a list of all the processes in alignannoted detection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_channels(self):\n        channels = []\n        for channel in self._project_dict[\"channels\"]:\n            channels.append(Channel(channel, self._is_sixteen_bit, self._ignore_list))\n        return channels", "response": "Creates an array of Channel objects from the project"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the dictionary of the project", "response": "def update(self):\n        \"\"\"Updates the dictionary of the project\"\"\"\n        for channel in self.channels:\n            channel.update()\n        for i in range(len(self._project_dict[\"channels\"])):\n            channel_dict = self._project_dict[\"channels\"][i]\n            for channel in self.channels:\n                if channel.name == channel_dict[\"common.ALLTYPES_NAME\"]:\n                    self._project_dict[\"channels\"][i] = channel.as_dict()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, *_):\n    url = get('http://distrowatch.com/random.php').url\n    match = re.search('=(.*)', url)\n    if match:\n        send(match.group(1))\n    else:\n        send(\"no distro found\")", "response": "Gets a random distro.\n    Syntax: {command}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef should_skip_file(name):\n    if name.endswith(('~', '.bak')):\n        return 'Skipping backup file %(filename)s'\n    if name.endswith(('.pyc', '.pyo')):\n        return 'Skipping %s file ' % os.path.splitext(name)[1] + '%(filename)s'\n    if name.endswith('$py.class'):\n        return 'Skipping $py.class file %(filename)s'\n    return None", "response": "Checks if a file should be skipped based on its name. Returns the reason if it should be skipped otherwise returns None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the license name is a private license.", "response": "def _parse_license_name(long_name):\n    ''' Check if the license name on the PyPI licenses list. Prepends 'OSI\n    Approved :: ' if required. If the license is 'Other/Proprietary License' or\n    unknow, asummes that is a private license.\n    '''\n    licenses_path = utils.get_data_dir() / 'license_list.txt'\n    with licenses_path.open('rt') as f:\n        licenses = [line.strip() for line in f.readlines()]\n\n    if long_name in licenses:\n        return long_name, long_name == PRIVATE_LICENSE_NAME\n\n    osi_name = 'OSI Approved :: {}'.format(long_name)\n    if osi_name in licenses:\n        return osi_name, False\n\n    logging.warn('License \"{}\" is not a valid PyPI classifier'.format(long_name))\n\n    return long_name, True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, *_):\n    try:\n        output = subprocess.check_output(['ddate'], universal_newlines=True)\n    except subprocess.CalledProcessError:\n        output = 'Today is the day you install ddate!'\n    for line in output.splitlines():\n        send(line)", "response": "Returns the Discordian date."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--chan', '--channel', action=arguments.ChanParser)\n    try:\n        cmdargs, extra = parser.parse_known_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    target = cmdargs.channels[0] if hasattr(cmdargs, 'channels') else args['target']\n    mode = \" \".join(extra)\n    if not mode:\n        send('Please specify a mode.')\n    elif target == 'private':\n        send(\"Modes don't work in a PM!\")\n    else:\n        with args['handler'].data_lock:\n            if target not in args['handler'].channels:\n                send(\"Bot not in channel %s\" % target)\n            elif args['botnick'] not in args['handler'].opers[target]:\n                send(\"Bot must be opped in channel %s\" % target)\n            else:\n                args['handler'].connection.mode(target, mode)\n                if args['target'] != args['config']['core']['ctrlchan']:\n                    send(\"Mode \\\"%s\\\" on %s by %s\" % (mode, target, args['nick']), target=args['config']['core']['ctrlchan'])", "response": "Sets a mode.\n\n    Syntax: {command} [--chan <chan>] <mode>"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef df2plotshape(dlen,xlabel_unit,ylabel_unit,\n                 suptitle='',fix='h',xlabel_skip=[],\n                 test=False):\n    \"\"\"\n    _xlen: \n    _ylen:\n    title:\n    \"\"\"\n    dlen['xlabel']=dlen.apply(lambda x : f\"{x['_xlen']}\" if not x['title'] in xlabel_skip else '',axis=1)\n    dlen['ylabel']=dlen.apply(lambda x : \"\",axis=1)\n    ylen=dlen['_ylen'].unique()[0]\n    \n    if test: print(dlen.columns)\n    if fix=='h':    \n        dlen['xlen']=dlen['_xlen']/dlen['_xlen'].max()/len(dlen)*0.8\n        dlen['ylen']=0.8\n        subsets=[]\n        for subset in [c for c in dlen if c.startswith('_ylen ')]:\n            subsetcol=subset.replace('_ylen','ylen')\n            dlen[subsetcol]=0.25\n            subsets.append(subsetcol)\n        subsets2cols=dict(zip([subsetcol.replace('ylen ','') for s in subsets],subsets))\n        if test: print(dlen.columns)\n        if test: print(subsets2cols)\n    elif fix=='w':    \n        dlen['xlen']=0.8\n        dlen['ylen']=dlen['_ylen']/dlen['_ylen'].max()/len(dlen)*0.85\n   \n    dlen=dlen.drop([c for c in dlen if c.startswith('_')],axis=1)    \n    if test: print(dlen.columns)\n    if fig is None:fig = plt.figure(figsize=[4,4])\n    for idx in dlen.index:\n        if idx==0:x_=0\n        kws_plot_rect=makekws_plot_rect(dlen,fig,idx,x_)\n        if test: print(kws_plot_rect)\n        kws_plot_rect_big={k:kws_plot_rect[k] for k in kws_plot_rect if not 'ylen ' in k}\n        kws_plot_rect_big['color']='gray'\n        ax=plot_rect(**kws_plot_rect_big)\n        for subset in subsets2cols:\n            kws_plot_rect=makekws_plot_rect(dlen.drop('ylen',axis=1).rename(columns={subsets2cols[subset]:'ylen'}),fig,idx,x_)\n            kws_plot_rect['title']=''\n            kws_plot_rect['xlabel']=''\n            kws_plot_rect['ylabel']=subset\n            if idx!=0:kws_plot_rect['ylabel']=''\n            if test: print(kws_plot_rect)\n            ax=plot_rect(**kws_plot_rect)            \n        x_=kws_plot_rect['x']+dlen.loc[idx,'xlen']+0.1  \n    \n    ax.text(x_/2.3,-0.1,xlabel_unit,ha='center')\n    ax.text(x_/2.3,0.9,suptitle,ha='center')\n    ax.text(-0.1,0.4,f\"total ~{ylen}{ylabel_unit}\",va='center',rotation=90)\n    if fig is not None:\n        return fig,ax\n    else:\n        return ax", "response": "Plot the shape of a single cell."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_json(context):\n    info = {\n        'info': cgi.escape(pprint.pformat(context.context)),\n    }\n    return Response(content_type='application/json', body=json.dumps(info))", "response": "Return an object s representation as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning info about an object s members as JSON", "response": "def as_tree(context):\n    \"\"\"Return info about an object's members as JSON\"\"\"\n\n    tree = _build_tree(context, 2, 1)\n    if type(tree) == dict:\n        tree = [tree] \n    \n    return Response(content_type='application/json', body=json.dumps(tree))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprototyping to see how an RPG simulation might be used in the AIKIF framework. The idea is to build a simple character and run a simulation to see how it succeeds in a random world against another players character character stats world locations", "response": "def main():\n    \"\"\"\n    Prototype to see how an RPG simulation might be used\n    in the AIKIF framework.\n    The idea is to build a simple character and run a simulation\n    to see how it succeeds in a random world against another players\n    character\n    character\n        stats\n    world\n        locations\n    \n    \"\"\"\n     \n    character1 = Character('Albogh', str=4,int=7,sta=50)\n    character2 = Character('Zoltor', str=6,int=6,sta=70)\n    print('PLAYER1 [start]:', character1)\n    print('PLAYER2 [start]:', character2)\n    b = Battle(character1, character2)\n    print(b)\n    print('PLAYER1 [end]:', character1)\n    print('PLAYER2 [end]:', character2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a timedelta for this build.", "response": "def duration(self):\n        \"\"\"\n        Return a timedelta for this build.\n\n        Measure the time between this build's start and end time, or \"now\"\n        if the build has not yet finished.\n\n        :returns: timedelta object\n        \"\"\"\n        if self.completion_ts:\n            end = self.completed\n        else:\n            end = datetime.utcnow()\n        return end - self.started"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url(self):\n        endpoint = 'buildinfo?buildID=%d' % self.build_id\n        return posixpath.join(self.connection.weburl, endpoint)", "response": "Return a kojiweb URL for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nestimate the completion time for a build.", "response": "def estimate_completion(self):\n        \"\"\"\n        Estimate completion time for a build.\n\n        This calls getAverageBuildDuration on the hub for this package. This\n        value is a very rough guess, an average for all completed builds in the\n        system.\n\n        For now this is better than nothing, but I'm recording a few thoughts\n        here for posterity:\n\n        A more advanced implementation of for estimating build times would\n        track unique averages per build target. Early releases of Ceph \"Hammer\"\n        versions would build much more quickly than newer Ceph releases like\n        \"Mimic\", and the current method simply averages all of them.\n\n        Also, different Koji build targets can have different arches. When we\n        build ceph in \"newarch\" side tags, those build times are wildly beyond\n        the average, but they influence this average too, subtly throwing it\n        off for the x86-only builds that I care about.\n\n        :returns: deferred that when fired returns a datetime object for the\n                  estimated or actual datetime.\n        \"\"\"\n        if self.state != build_states.BUILDING:\n            # Build is already complete. Return the exact completion time:\n            defer.returnValue(self.completed)\n        avg_delta = yield self.connection.getAverageBuildDuration(self.name)\n        est_completion = self.started + avg_delta\n        defer.returnValue(est_completion)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef target(self):\n        task = yield self.task()\n        if not task:\n            yield defer.succeed(None)\n            defer.returnValue(None)\n        defer.returnValue(task.target)", "response": "Find the target name for this build."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef task(self):\n        # If we have no .task_id, this is a no-op to return None.\n        if not self.task_id:\n            return defer.succeed(None)\n        return self.connection.getTaskInfo(self.task_id)", "response": "Returns the Task object that this build was created for."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the task ID for this build.", "response": "def task_id(self):\n        \"\"\"\n        Hack to return a task ID for a build, including container CG builds.\n\n        We have something for this in Brewweb, but not yet for upstream Koji:\n        https://pagure.io/koji/issue/215\n        \"\"\"\n        if self['task_id']:\n            return self['task_id']\n        if self.extra and 'container_koji_task_id' in self.extra:\n            return self.extra['container_koji_task_id']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_images(self, obj):\n        return {str(i.tag): i.image.url for i in obj.images.all()}", "response": "Object of images serialized by tag name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_override_winner(self, obj):\n        if obj.election.division.level.name == DivisionLevel.DISTRICT:\n            division = obj.election.division.parent\n        else:\n            division = obj.election.division\n\n        vote = obj.votes.filter(division=division).first()\n        return vote.winning if vote else False", "response": "Returns True if the user has already set the override winning attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_override_votes(self, obj):\n        if hasattr(obj, \"meta\"):  # TODO: REVISIT THIS\n            if obj.meta.override_ap_votes:\n                all_votes = None\n                for ce in obj.candidate_elections.all():\n                    if all_votes:\n                        all_votes = all_votes | ce.votes.all()\n                    else:\n                        all_votes = ce.votes.all()\n                return VotesSerializer(all_votes, many=True).data\n        return False", "response": "Returns a list of all votes that have been set in the backend."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all CandidateElections for the given object.", "response": "def get_candidates(self, obj):\n        \"\"\"\n        CandidateElections.\n        \"\"\"\n        return CandidateElectionSerializer(\n            obj.candidate_elections.all(), many=True\n        ).data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the object to the database.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Before saving, if slide is for a publication, use publication info\n        for slide's title, subtitle, description.\n        \"\"\"\n        if self.publication:\n            publication = self.publication\n\n            if not self.title:\n                self.title = publication.title\n\n            if not self.subtitle:\n                first_author = publication.first_author\n\n                if first_author == publication.last_author:\n                    authors = first_author\n                else:\n                    authors = '{} et al.'.format(first_author)\n\n                self.subtitle = '{}, {} ({})'.format(authors,\n                    publication.journal, publication.year)\n\n            if not self.description:\n                self.description = publication.abstract\n\n            if self.publication.year and not self.pk:\n                delta = timezone.now() - self.publish_datetime\n\n                if self.publish_datetime <= timezone.now() and delta.days == 0:\n                    self.publish_datetime = datetime.datetime(\n                        year=int(self.publication.year),\n                        month=int(self.publication.month or 1),\n                        day=int(self.publication.day or 1),\n                    )\n\n        super().save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, context=None, stdout=None, stderr=None):\n        total_benchmark = Benchmark()\n        self.context = context or Context()\n        if self._is_collection():\n            self.stdout = sys.stdout\n            self.stderr = sys.stderr\n        else:\n            self.stdout = stdout or StringIO()\n            self.stderr = stderr or StringIO()\n        self._record_start_example(self.formatter)\n        try:\n            with total_benchmark, Replace(sys, 'stdout', self.stdout), Replace(sys, 'stderr', self.stderr):\n                self._setup()\n                self._execute()\n                self._teardown()\n        except Exception as e:\n            self.example.error = e\n            self.example.traceback = sys.exc_info()[2] #traceback.format_exc()\n        finally:\n            self.example.real_time = total_benchmark.total_time\n            self._record_end_example(self.formatter)\n            self.context = None\n            self.example.stdout = self.stdout\n            self.example.stderr = self.stderr\n        return self.example.error is None", "response": "Does all the work of running an example.\n\n        This includes:\n        - building up the context.\n        - capturing stdout & stderr\n        - execute before functions\n        - run example, catching any exceptions\n        - execute after functions\n        - record the results & timings to formatter and original example object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nliking execute but records a skip if the should_skip method returns True.", "response": "def run(self, context=None, stdout=None, stderr=None):\n        \"Like execute, but records a skip if the should_skip method returns True.\"\n        if self.should_skip():\n            self._record_skipped_example(self.formatter)\n            self.num_skipped += 1\n        else:\n            self.execute(context, stdout, stderr)\n        return self.num_successes, self.num_failures, self.num_skipped"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset the state and prepares for running the example.", "response": "def _setup(self):\n        \"Resets the state and prepares for running the example.\"\n        self.example.error = None\n        self.example.traceback = ''\n        # inject function contexts from parent functions\n        c = Context(parent=self.context)\n        #for parent in reversed(self.example.parents):\n        #    c._update_properties(locals_from_function(parent))\n        self.context = c\n        if self.is_root_runner:\n            run.before_all.execute(self.context)\n        self.example.before(self.context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _execute_example_group(self):\n        \"Handles the execution of Example Group\"\n        for example in self.example:\n            runner = self.__class__(example, self.formatter)\n            runner.is_root_runner = False\n            successes, failures, skipped = runner.run(self.context)\n            self.num_successes += successes\n            self.num_failures += failures\n            self.num_skipped += skipped", "response": "Handles the execution of Example Group"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the execution of the Example", "response": "def _execute_example(self):\n        \"Handles the execution of the Example\"\n        test_benchmark = Benchmark()\n        try:\n            with Registry(), test_benchmark:\n                if accepts_arg(self.example.testfn):\n                    self.example.testfn(self.context)\n                else:\n                    self.context.inject_into_self(self.example.testfn)\n                    self.example.testfn()\n                self.num_successes += 1\n        except KeyboardInterrupt:\n            # bubble interrupt for canceling spec execution\n            raise\n        except:\n            raise\n            self.num_failures += 1\n        finally:\n            self.example.user_time = test_benchmark.total_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _teardown(self):\n        \"Handles the restoration of any potential global state set.\"\n        self.example.after(self.context)\n        if self.is_root_runner:\n            run.after_all.execute(self.context)\n        #self.context = self.context._parent\n        self.has_ran = True", "response": "Handles the restoration of any potential global state set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nannotate a boxplot with the given data metrics", "response": "def annot_boxplot(ax,dmetrics,xoffwithin=0.85,xoff=1.6,\n                  yoff=0,annotby='xs',\n                  test=False):\n    \"\"\"\n    :param dmetrics: hue in index, x in columns\n    \n    #todos\n    #x|y off in %\n    xmin,xmax=ax.get_xlim()\n    (xmax-xmin)+(xmax-xmin)*0.35+xmin\n    \"\"\"\n    xlabel=ax.get_xlabel()\n    ylabel=ax.get_ylabel()\n    if test:\n        dmetrics.index.name='index'\n        dmetrics.columns.name='columns'\n        dm=dmetrics.melt()\n        dm['value']=1\n        ax=sns.boxplot(data=dm,x='columns',y='value')\n    for huei,hue in enumerate(dmetrics.index):  \n        for xi,x in enumerate(dmetrics.columns):\n            if not pd.isnull(dmetrics.loc[hue,x]):\n                xco=xi+(huei*xoffwithin/len(dmetrics.index)+(xoff/len(dmetrics.index)))\n                yco=ax.get_ylim()[1]+yoff\n                if annotby=='ys':\n                    xco,yco=yco,xco\n                ax.text(xco,yco,dmetrics.loc[hue,x],ha='center')\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nannotate the tables of the tables", "response": "def annot_heatmap(ax,dannot,\n                  xoff=0,yoff=0,\n                  kws_text={},# zip\n                  annot_left='(',annot_right=')',\n                  annothalf='upper',\n                ):\n    \"\"\"\n    kws_text={'marker','s','linewidth','facecolors','edgecolors'}\n    \"\"\"\n    for xtli,xtl in enumerate(ax.get_xticklabels()):\n        xtl=xtl.get_text()\n        for ytli,ytl in enumerate(ax.get_yticklabels()):\n            ytl=ytl.get_text()\n            if annothalf=='upper':\n                ax.text(xtli+0.5+xoff,ytli+0.5+yoff,dannot.loc[xtl,ytl],**kws_text,ha='center')\n            else:\n                ax.text(ytli+0.5+yoff,xtli+0.5+xoff,dannot.loc[xtl,ytl],**kws_text,ha='center')                \n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pval2annot(pval,alternative=None,alpha=None,fmt='*',#swarm=False\n               linebreak=True,\n              ):\n    \"\"\"\n    fmt: *|<|'num'\n    \"\"\"\n    if alternative is None and alpha is None:\n        ValueError('both alternative and alpha are None')\n    if alpha is None:\n        alpha=0.025 if alternative=='two-sided' else alternative if is_numeric(alternative) else 0.05\n    if pd.isnull(pval):\n        return ''\n    elif pval < 0.0001:\n        return \"****\" if fmt=='*' else f\"P<\\n{0.0001:.0e}\" if fmt=='<' else f\"P={pval:.1g}\" if len(f\"P={pval:.1g}\")<6 else f\"P=\\n{pval:.1g}\"  if linebreak else f\"P={pval:.1g}\"\n    elif (pval < 0.001):\n        return \"***\"  if fmt=='*' else f\"P<\\n{0.001:.0e}\" if fmt=='<' else f\"P={pval:.1g}\" if len(f\"P={pval:.1g}\")<6 else f\"P=\\n{pval:.1g}\" if linebreak else f\"P={pval:.1g}\"\n    elif (pval < 0.01):\n        return \"**\" if fmt=='*' else f\"P<\\n{0.01:.0e}\" if fmt=='<' else f\"P={pval:.1g}\" if len(f\"P={pval:.1g}\")<6 else f\"P=\\n{pval:.1g}\" if linebreak else f\"P={pval:.1g}\"\n    elif (pval < alpha):\n        return \"*\" if fmt=='*' else f\"P<\\n{alpha:.0e}\" if fmt=='<' else f\"P={pval:.1g}\" if len(f\"P={pval:.1g}\")<6 else f\"P=\\n{pval:.1g}\" if linebreak else f\"P={pval:.1g}\"\n    else:\n        return \"ns\" if fmt=='*' else f\"P=\\n{pval:.0e}\" if fmt=='<' else f\"P={pval:.1g}\" if len(f\"P={pval:.1g}\")<6 else f\"P=\\n{pval:.1g}\" if linebreak else f\"P={pval:.1g}\"", "response": "converts a P value to an annotation string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pypy_json_encode(value, pretty=False):\n    global _dealing_with_problem\n    if pretty:\n        return pretty_json(value)\n\n    try:\n        _buffer = UnicodeBuilder(2048)\n        _value2json(value, _buffer)\n        output = _buffer.build()\n        return output\n    except Exception as e:\n        # THE PRETTY JSON WILL PROVIDE MORE DETAIL ABOUT THE SERIALIZATION CONCERNS\n        from mo_logs import Log\n\n        if _dealing_with_problem:\n            Log.error(\"Serialization of JSON problems\", e)\n        else:\n            Log.warning(\"Serialization of JSON problems\", e)\n        _dealing_with_problem = True\n        try:\n            return pretty_json(value)\n        except Exception as f:\n            Log.error(\"problem serializing object\", f)\n        finally:\n            _dealing_with_problem = False", "response": "JSON encode a value into a pypy object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nthrowing ERROR ABOUT SERIALIZING", "response": "def problem_serializing(value, e=None):\n    \"\"\"\n    THROW ERROR ABOUT SERIALIZING\n    \"\"\"\n    from mo_logs import Log\n\n    try:\n        typename = type(value).__name__\n    except Exception:\n        typename = \"<error getting name>\"\n\n    try:\n        rep = text_type(repr(value))\n    except Exception as _:\n        rep = None\n\n    if rep == None:\n        Log.error(\n            \"Problem turning value of type {{type}} to json\",\n            type=typename,\n            cause=e\n        )\n    else:\n        Log.error(\n            \"Problem turning value ({{value}}) of type {{type}} to json\",\n            value=rep,\n            type=typename,\n            cause=e\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unicode_key(key):\n    if not isinstance(key, (text_type, binary_type)):\n        from mo_logs import Log\n        Log.error(\"{{key|quote}} is not a valid key\", key=key)\n    return quote(text_type(key))", "response": "CONVERT PROPERTY VALUE TO QUOTED NAME OF SAME\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd(send, _, args):\n    curr = datetime.now()\n    uptime = args['handler'].uptime\n    load_avg = ', '.join([str(x) for x in os.getloadavg()])\n    starttime = curr - uptime['start']\n    reloaded = curr - uptime['reloaded']\n    send(\"Time since start: %s, load average: %s\" % (starttime, load_avg))\n    send(\"Time since reload: %s\" % reloaded)", "response": "Shows the bot s uptime.\n    Syntax : { command }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pcwd(func):\n    \n    @wraps(func)\n    def inner(*args, **kw):\n        with PreserveWorkingDirectory():\n            return func(*args, **kw)\n    \n    return inner", "response": "A decorator to provide the functionality of the\n    PreserveWorkingDirectory context manager for functions and methods."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recv(self, message, ref, pos):\n\n        # Get action\n        action = message.get('action', None)\n\n        # Show the message we got\n        if action != 'pingdog':\n            self.debug(\"{} - Receive: {} (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), message, ref, pos.uuid), color=\"cyan\")\n\n        # Check the action that it is requesting\n        if action == 'get_config':\n            # Get all the hardware connected to this POS\n            answer = {}\n            answer['action'] = 'config'\n            answer['commit'] = pos.commit\n            answer['hardware'] = []\n            for hw in pos.hardwares.filter(enable=True):\n                # Prepare to send back the config\n                answer['hardware'].append({'kind': hw.kind, 'config': hw.get_config(), 'uuid': hw.uuid.hex})\n            self.debug(u\"{} - Send: {} - {}\".format(pos.name.encode('ascii', 'ignore'), answer, pos.uuid), color='green')\n            self.send(answer, ref, pos)\n        elif action == 'subscribe':\n            # Get UUID\n            uid = message.get('uuid', None)\n            # Check if we got a valid UUID\n            if uid:\n                uid = uuid.UUID(uid)\n                poshw = POSHardware.objects.filter(uuid=uid).first()\n                if poshw:\n                    if poshw.enable:\n                        # Suscribe this websocket to group\n                        self.debug(\"{} - Subscribed to '{}' - {}\".format(pos.name.encode('ascii', 'ignore'), uid.hex, pos.uuid), color=\"purple\")\n                        Group(uid.hex).add(self.message.reply_channel)\n                        self.send({'action': 'subscribed', 'uuid': uid.hex, 'key': poshw.key}, ref, pos)\n                    else:\n                        self.send_error(\"You cannot subscribe to a disabled Hardware!\", ref, pos)\n                else:\n                    self.send_error(\"You cannot subscribe to a Hardware that is not available, UUID not found!\", ref, pos)\n            else:\n                self.send_error(\"You have tried to subscribe to a UUID but didn't specify any or is invalid\", ref, pos)\n        elif action == 'msg':\n            uid = message.get('uuid', None)\n            msg = message.get('msg', None)\n            if uid:\n                origin = POSHardware.objects.filter(uuid=uuid.UUID(uid)).first()\n                if origin:\n                    self.debug(\"{} - Got a message from {}: {} (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), origin.uuid, msg, ref, pos.uuid), color='purple')\n                    origin.recv(msg)\n                else:\n                    self.debug(\"{} - Got a message from UNKNOWN {}: {} (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), uid, msg, ref, pos.uuid), color='purple')\n            else:\n                self.debug(\"{} - Got a message from NO-UUID: {} (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), msg, ref, pos.uuid), color='purple')\n        elif action == 'ping':\n            super(POSConsumer, self).send({'message': json.dumps({'action': 'pong', 'ref': ref})})\n        elif action == 'pong':\n            self.debug(\"{} - Got PONG {} (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), message.get('ref', '-'), ref, pos.uuid), color='white')\n        elif action == 'pingdog':\n            super(POSConsumer, self).send({'message': json.dumps({'action': 'pongdog', 'ref': ref})})\n        elif action == 'error':\n            uid = message.get('uuid', None)\n            msg = message.get('error', 'No error')\n            if uid:\n                self.error(\"{} - Got an error from {}: {} (UUID:{}) (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), pos.uuid, msg, uid, ref, pos.uuid))\n            else:\n                self.error(\"{} - Got an error from {}: {}) (ref:{}) - {}\".format(pos.name.encode('ascii', 'ignore'), pos.uuid, msg, ref, pos.uuid))\n            log = POSLog()\n            log.pos = pos\n            if uid:\n                poshw = POSHardware.objects.filter(uuid=uid).first()\n                if poshw:\n                    log.poshw = poshw\n                    log.uuid = poshw.uuid\n            else:\n                log.uuid = pos.uuid\n            log.log = message.get('error', None)\n            log.save()\n        else:\n            # Unknown action\n            self.send_error(\"Unknown action '{}'\".format(action), ref, pos)", "response": "Called when a message is received with decoded JSON content."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_queryset(self):\n        try:\n            date = ElectionDay.objects.get(date=self.kwargs['date'])\n        except Exception:\n            raise APIException(\n                'No elections on {}.'.format(self.kwargs['date'])\n            )\n        office_ids = []\n        for election in date.elections.all():\n            office = election.race.office\n            if not office.body:\n                office_ids.append(office.uid)\n        return Office.objects.filter(uid__in=office_ids)", "response": "Returns a queryset of all executive offices holding an election on a date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd election_day to serializer context.", "response": "def get_serializer_context(self):\n        \"\"\"Adds ``election_day`` to serializer context.\"\"\"\n        context = super(OfficeMixin, self).get_serializer_context()\n        context['election_date'] = self.kwargs['date']\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nslap somebody. Syntax: {command} <nick> [for <reason>]", "response": "def cmd(send, msg, args):\n    \"\"\"Slap somebody.\n\n    Syntax: {command} <nick> [for <reason>]\n\n    \"\"\"\n    implements = ['the golden gate bridge', 'a large trout', 'a clue-by-four', 'a fresh haddock', 'moon', 'an Itanium', 'fwilson', 'a wombat']\n    methods = ['around a bit', 'upside the head']\n    if not msg:\n        channel = args['target'] if args['target'] != 'private' else args['config']['core']['channel']\n        with args['handler'].data_lock:\n            users = list(args['handler'].channels[channel].users())\n        slap = 'slaps %s %s with %s'\n        send(slap % (choice(users), choice(methods), choice(implements)), 'action')\n    else:\n        reason = ''\n        method = choice(methods)\n        implement = ''\n        msg = msg.split()\n        slapee = msg[0]\n        # Basic and stupid NLP!\n        i = 1\n        args = False\n        while i < len(msg):\n            if msg[i] == 'for':\n                args = True\n                if reason:\n                    send(\"Invalid Syntax: You can only have one for clause!\")\n                    return\n                i += 1\n                while i < len(msg):\n                    if msg[i] == 'with':\n                        break\n                    reason += \" \"\n                    reason += msg[i]\n                    i += 1\n                reason = reason.strip()\n            elif msg[i] == 'with':\n                args = True\n                if implement:\n                    send(\"Invalid Synatx: You can only have one with clause!\")\n                    return\n                i += 1\n                while i < len(msg):\n                    if msg[i] == 'for':\n                        break\n                    implement += msg[i]\n                    implement += ' '\n                    i += 1\n                implement = implement.strip()\n            elif not args:\n                slapee += ' ' + msg[i]\n            i += 1\n\n        if not implement:\n            implement = choice(implements)\n        if reason:\n            slap = 'slaps %s %s with %s for %s' % (slapee, method, implement, reason)\n        else:\n            slap = 'slaps %s %s with %s' % (slapee, method, implement)\n        send(slap, 'action')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd(send, msg, args):\n    if not msg:\n        with args['handler'].data_lock:\n            users = list(args['handler'].channels[args['target']].users()) if args['target'] != 'private' else [args['nick']]\n        msg = choice(users)\n    chain = get_chain(args['db'], msg)\n    if chain:\n        send(\" -> \".join(chain))\n    else:\n        send(\"%s has never changed their nick.\" % msg)", "response": "Gets previous nicks.\n\n    Syntax: {command} <nick>"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_database(engine: Connectable, schemas: Iterable[str] = ()) -> None:\n    assert check_argument_types()\n    metadatas = []\n    all_schemas = (None,)  # type: Tuple[Optional[str], ...]\n    all_schemas += tuple(schemas)\n    for schema in all_schemas:\n        # Reflect the schema to get the list of the tables, views and constraints\n        metadata = MetaData()\n        metadata.reflect(engine, schema=schema, views=True)\n        metadatas.append(metadata)\n\n    for metadata in metadatas:\n        metadata.drop_all(engine, checkfirst=False)", "response": "Clear any tables from an existing database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, msg, args):\n    if not hasattr(args['handler'], msg):\n        send(\"That attribute was not found in the handler.\")\n        return\n    send(str(getattr(args['handler'], msg)))", "response": "Inspects a bot attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('blogname', action=arguments.TumblrParser)\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--submit', nargs='*')\n    group.add_argument('--random', action='store_true')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    if cmdargs.random:\n        apikey = args['config']['api']['tumblrconsumerkey']\n        # First, get the number of posts\n        response = get('https://api.tumblr.com/v2/blog/%s/posts' % cmdargs.blogname, params={'api_key': apikey, 'type': 'text'}).json()\n        postcount = response['response']['total_posts']\n        if postcount <= 1:\n            send(\"No text posts found.\")\n            return\n        # No random post functionality and we can only get 20 posts per API call, so pick a random offset to get the random post\n        offset = randint(0, postcount - 1)\n        response = get('https://api.tumblr.com/v2/blog/%s/posts' % cmdargs.blogname,\n                       params={\n                           'api_key': apikey,\n                           'offset': offset,\n                           'limit': 1,\n                           'type': 'text',\n                           'filter': 'text'\n                       }).json()\n        entry = response['response']['posts'][0]['body']\n        # Account for possibility of multiple lines\n        lines = entry.splitlines()\n        for line in lines:\n            send(line)\n\n    elif cmdargs.submit:\n        if not cmdargs.submit:\n            send('Post what?')\n            return\n        if isinstance(cmdargs.submit, list):\n            cmdargs.submit = ' '.join(cmdargs.submit)\n        if args['is_admin']:\n            send(post_tumblr(args['config'], cmdargs.blogname, cmdargs.submit)[0])\n        else:\n            row = Tumblrs(post=cmdargs.submit, submitter=args['nick'], nick=args['nick'], blogname=cmdargs.blogname)\n            args['db'].add(row)\n            args['db'].flush()\n            send(\"New Tumblr Post: %s -- %s, Submitted by %s\" % (cmdargs.submit, cmdargs.blogname, args['nick']),\n                 target=args['config']['core']['ctrlchan'])\n            send(\"Issue submitted for approval.\", target=args['nick'])\n    else:\n        send(\"Did not get an argument (choices are --random, --submit)\")", "response": "Searches tumblr for a single entry in a tumblr blog."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncorrects a previous message.", "response": "def cmd(send, msg, args):\n    \"\"\"Corrects a previous message.\n\n    Syntax: {command}/<msg>/<replacement>/<ig|nick>\n\n    \"\"\"\n    if not msg:\n        send(\"Invalid Syntax.\")\n        return\n    char = msg[0]\n    msg = [x.replace(r'\\/', '/') for x in re.split(r'(?<!\\\\)\\%s' % char, msg[1:], maxsplit=2)]\n    # fix for people who forget a trailing slash\n    if len(msg) == 2 and args['config']['feature'].getboolean('lazyregex'):\n        msg.append('')\n    # not a valid sed statement.\n    if not msg or len(msg) < 3:\n        send(\"Invalid Syntax.\")\n        return\n    if args['type'] == 'privmsg':\n        send(\"Don't worry, %s is not a grammar Nazi.\" % args['botnick'])\n        return\n    string = msg[0]\n    replacement = msg[1]\n    modifiers = get_modifiers(msg[2], args['nick'], args['config']['core']['nickregex'])\n    if modifiers is None:\n        send(\"Invalid modifiers.\")\n        return\n\n    try:\n        regex = re.compile(string, re.IGNORECASE) if modifiers['ignorecase'] else re.compile(string)\n        log = get_log(args['db'], args['target'], modifiers['nick'])\n        workers = args['handler'].workers\n        result = workers.run_pool(do_replace, [log, args['config']['core'], char, regex, replacement])\n        try:\n            msg = result.get(5)\n        except multiprocessing.TimeoutError:\n            workers.restart_pool()\n            send(\"Sed regex timed out.\")\n            return\n        if msg:\n            send(msg)\n        else:\n            send(\"No match found.\")\n    except sre_constants.error as ex:\n        raise CommandFailedException(ex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the selected field attributes for each object in the Container as a JSON formatted string.", "response": "def to_json(self, *attributes, **options):\n        \"\"\" Returns the selected field *attributes* for each :class:`Field` *nested*\n        in the `Container` as a JSON formatted string.\n\n        The *attributes* of each :class:`Field` for containers *nested* in the\n        `Container` are viewed as well (chained method call).\n\n        :param str attributes: selected :class:`Field` attributes.\n            Fallback is the field :attr:`~Field.value`.\n        :keyword tuple fieldnames: sequence of dictionary keys for the selected\n            field *attributes*.\n            Defaults to ``(*attributes)``.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            `Container` views their referenced :attr:`~Pointer.data` object\n            field attributes as well (chained method call).\n        \"\"\"\n        nested = options.pop('nested', False)\n        fieldnames = options.pop('fieldnames', attributes)\n        if 'cls' in options.keys():\n            return json.dumps(self.view_fields(*attributes,\n                                               nested=nested,\n                                               fieldnames=fieldnames),\n                              **options)\n        else:\n            return json.dumps(self.view_fields(*attributes,\n                                               nested=nested,\n                                               fieldnames=fieldnames),\n                              cls=_CategoryJSONEncoder,\n                              **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of tuples for each object in the Container.", "response": "def to_list(self, *attributes, **options):\n        \"\"\" Returns a **flatten** list of ``('field path', attribute)`` or\n        ``('field path', tuple(attributes))`` tuples for each :class:`Field`\n        *nested* in the `Container`.\n\n        :param str attributes: selected :class:`Field` attributes.\n            Fallback is the field :attr:`~Field.value`.\n        :keyword str name: name of the `Container`.\n            Default is the class name of the instance.\n        :keyword bool chain: if ``True`` the field *attributes* are chained to its\n            field path. Defaults to ``False``.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            `Container` lists their referenced :attr:`~Pointer.data` object\n            field attributes as well (chained method call).\n        \"\"\"\n\n        # Name of the Container\n        name = options.pop('name', self.__class__.__name__)\n\n        fields = list()\n        if attributes:\n            field_getter = attrgetter(*attributes)\n        else:\n            field_getter = attrgetter('value')\n        for item in self.field_items(**options):\n            field_path, field = item\n            if field_path.startswith('['):\n                # Sequence\n                field_path = '{0}{1}'.format(name, field_path)\n            else:\n                field_path = '{0}.{1}'.format(name, field_path)\n            if options.get('chain', False) and len(attributes) > 1:\n                fields.append((field_path, *field_getter(field)))\n            else:\n                fields.append((field_path, field_getter(field)))\n        return fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a flattened dictionary of the object s fields.", "response": "def to_dict(self, *attributes, **options):\n        \"\"\" Returns a **flatten** :class:`ordered dictionary <collections.OrderedDict>`\n        of ``{'field path': attribute}`` or ``{'field path': tuple(attributes)}``\n        pairs for each :class:`Field` *nested* in the `Container`.\n\n        :param str attributes: selected :class:`Field` attributes.\n            Fallback is the field :attr:`~Field.value`.\n        :keyword str name: name of the `Container`.\n            Default is the class name of the instance.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            `Container` lists their referenced :attr:`~Pointer.data` object\n            field attributes as well (chained method call).\n        \"\"\"\n        # Name of the Container\n        name = options.pop('name', self.__class__.__name__)\n        # Save to file\n        save = options.pop('save', False)\n\n        fields = OrderedDict()\n        fields[name] = OrderedDict()\n        if attributes:\n            field_getter = attrgetter(*attributes)\n        else:\n            field_getter = attrgetter('value')\n        for item in self.field_items(**options):\n            field_path, field = item\n            if save and field_path.startswith('['):\n                # Sequence element\n                field_path = '_' + field_path\n            fields[name][field_path] = field_getter(field)\n        return fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_csv(self, *attributes, **options):\n        keys = self._get_fieldnames(*attributes, **options)\n        options['chain'] = True\n        return [dict(zip(keys, field)) for field in\n                self.to_list(*attributes, **options)]", "response": "Returns a list of dictionaries containing the field path*\n            and the selected field attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the values of the selected fields for each object in the object to a. csv file.", "response": "def write_csv(self, file, *attributes, **options):\n        \"\"\" Writes the field *path* and the selected field *attributes* for each\n        :class:`Field` *nested* in the `Container` to  a ``.csv`` *file*.\n\n        :param str file: name and location of the ``.csv`` *file*.\n        :param str attributes: selected :class:`Field` attributes.\n            Fallback is the field :attr:`~Field.value`.\n        :keyword str name: name of the `Container`.\n            Default is the class name of the instance.\n        :keyword tuple fieldnames: sequence of dictionary keys for the field *path*\n            and the selected field *attributes*.\n            Defaults to ``('id', *attributes)``.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            `Container` lists their referenced :attr:`~Pointer.data` object\n            field attributes as well (chained method call).\n        \"\"\"\n        with open(file, 'w', newline='') as file_handle:\n            fieldnames = self._get_fieldnames(*attributes, **options)\n            writer = csv.DictWriter(file_handle, fieldnames)\n            writer.writeheader()\n            for row in self.to_csv(*attributes, **options):\n                writer.writerow(row)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, file, *attributes, **options):\n        options['save'] = True\n        parser = ConfigParser()\n        parser.read_dict(self.to_dict(*attributes, **options))\n        with open(file, 'w') as file_handle:\n            parser.write(file_handle)\n        file_handle.close()", "response": "Save the selected fields in the current object to an. ini file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, file, **options):\n        section = options.pop('section', self.__class__.__name__)\n\n        parser = ConfigParser()\n        parser.read(file)\n\n        if parser.has_section(section):\n            verbose(options, \"[{0}]\".format(section))\n\n            for field_path, field in self.field_items(**options):\n                if field_path.startswith('['):\n                    # Sequence element\n                    option = '_' + field_path\n                else:\n                    option = field_path\n                if parser.has_option(section, option):\n                    # Bool fields\n                    if field.is_bool():\n                        field.value = parser.getboolean(section, option)\n                    # Float fields\n                    elif field.is_float():\n                        field.value = parser.getfloat(section, option)\n                    # String fields\n                    elif field.is_string():\n                        field.value = parser.get(section, option)\n                    # Stream fields\n                    elif field.is_stream():\n                        value = parser.get(section, option)\n                        stream = bytes.fromhex(value.replace(\"'\", \"\"))\n                        # Auto size a zero sized stream field to the current length\n                        if not field:\n                            field.resize(len(stream))\n                        field.value = stream\n                    # Decimal fields\n                    else:\n                        field.value = parser.get(section, option)\n                    if field_path.startswith('['):\n                        verbose(options,\n                                \"{0}{1} = {2}\".format(section,\n                                                      field_path,\n                                                      field.value))\n                    else:\n                        verbose(options,\n                                \"{0}.{1} = {2}\".format(section,\n                                                       field_path,\n                                                       field.value))\n        else:\n            verbose(options, \"No section [{0}] found.\".format(section))", "response": "Loads the object containing the key value for each field in the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_from(self, provider, **options):\n        for item in self.values():\n            # Container or Pointer\n            if is_mixin(item):\n                item.read_from(provider, **options)", "response": "Reads the necessary number of bytes from the data provider for the items in the structure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(self, buffer=bytearray(), index=Index(), **options):\n        for item in self.values():\n            index = item.serialize(buffer, index, **options)\n        return index", "response": "Serializes the structure to a byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nindex all fields in the given index and returns the last index after the first field in the Structure.", "response": "def index_fields(self, index=Index(), **options):\n        \"\"\" Indexes all fields in the `Structure` starting with the given\n        *index* and returns the :class:`Index` after the last :class:`Field`\n        in the `Structure`.\n\n        :param Index index: start :class:`Index` for the first :class:`Field`\n            in the `Structure`.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields of the\n            `Structure` indexes their referenced :attr:`~Pointer.data` object\n            fields as well (chained method call).\n        \"\"\"\n        for name, item in self.items():\n            # Container\n            if is_container(item):\n                index = item.index_fields(index, **options)\n            # Pointer\n            elif is_pointer(item) and get_nested(options):\n                index = item.index_field(index)\n                item.index_data()\n            # Field\n            elif is_field(item):\n                index = item.index_field(index)\n            else:\n                raise MemberTypeError(self, item, name, index)\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initialize_fields(self, content):\n        for name, value in content.items():\n            item = self[name]\n            # Container or Pointer\n            if is_mixin(item):\n                item.initialize_fields(value)\n            # Fields\n            elif is_field(item):\n                item.value = value\n            else:\n                raise MemberTypeError(self, item, name)", "response": "Initializes the fields in the structure with the values in the content dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef view_fields(self, *attributes, **options):\n        members = OrderedDict()\n        for name, item in self.items():\n            # Container\n            if is_container(item):\n                members[name] = item.view_fields(*attributes, **options)\n            # Pointer\n            elif is_pointer(item) and get_nested(options):\n                members[name] = item.view_fields(*attributes, **options)\n            # Field\n            elif is_field(item):\n                if attributes:\n                    field_getter = attrgetter(*attributes)\n                else:\n                    field_getter = attrgetter('value')\n                if len(attributes) > 1:\n                    fieldnames = options.get('fieldnames', attributes)\n                    members[name] = dict(zip(fieldnames, field_getter(item)))\n                else:\n                    members[name] = field_getter(item)\n\n        return members", "response": "Returns an ordered dictionary of the fields of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef field_items(self, path=str(), **options):\n        parent = path if path else str()\n\n        items = list()\n        for name, item in self.items():\n            item_path = '{0}.{1}'.format(parent, name) if parent else name\n            # Container\n            if is_container(item):\n                for field in item.field_items(item_path, **options):\n                    items.append(field)\n            # Pointer\n            elif is_pointer(item) and get_nested(options):\n                for field in item.field_items(item_path, **options):\n                    items.append(field)\n            # Field\n            elif is_field(item):\n                items.append((item_path, item))\n            else:\n                raise MemberTypeError(self, item, item_path)\n        return items", "response": "Returns a list of tuples containing the field path and field item for each nested field in the structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the metadata of the structure as an ordered dictionary.", "response": "def describe(self, name=str(), **options):\n        \"\"\" Returns the **metadata** of the `Structure` as an\n        :class:`ordered dictionary <collections.OrderedDict>`.\n\n        .. code-block:: python\n\n            metadata = {\n                'class': self.__class__.__name__,\n                'name': name if name else self.__class__.__name__,\n                'size': len(self),\n                'type': Structure.item_type.name\n                'member': [\n                    item.describe(member) for member, item in self.items()\n                ]\n            }\n\n        :param str name: optional name for the `Structure`.\n            Fallback is the class name.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields of the\n            `Structure` lists their referenced :attr:`~Pointer.data` object fields\n            as well (chained method call). Default is ``True``.\n        \"\"\"\n        members = list()\n        metadata = OrderedDict()\n        metadata['class'] = self.__class__.__name__\n        metadata['name'] = name if name else self.__class__.__name__\n        metadata['size'] = len(self)\n        metadata['type'] = self.item_type.name\n        metadata['member'] = members\n\n        for member_name, item in self.items():\n            # Container\n            if is_container(item):\n                members.append(item.describe(member_name, **options))\n            # Pointer\n            elif is_pointer(item) and get_nested(options):\n                members.append(item.describe(member_name, **options))\n            # Field\n            elif is_field(item):\n                members.append(item.describe(member_name, nested=False))\n            else:\n                raise MemberTypeError(self, item, member_name)\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, item):\n        if not is_any(item):\n            raise MemberTypeError(self, item, member=len(self))\n        self._data.append(item)", "response": "Appends the item to the end of the Sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts the item before the index in the Sequence.", "response": "def insert(self, index, item):\n        \"\"\" Inserts the *item* before the *index* into the `Sequence`.\n\n        :param int index: `Sequence` index.\n        :param item: any :class:`Structure`, :class:`Sequence`, :class:`Array`\n            or :class:`Field` instance.\n        \"\"\"\n        if not is_any(item):\n            raise MemberTypeError(self, item, member=len(self))\n        self._data.insert(index, item)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending the Sequence by appending items from the iterable.", "response": "def extend(self, iterable):\n        \"\"\" Extends the `Sequence` by appending items from the *iterable*.\n\n        :param iterable: any *iterable* that contains items of :class:`Structure`,\n            :class:`Sequence`, :class:`Array` or :class:`Field` instances. If the\n            *iterable* is one of these instances itself then the *iterable* itself\n            is appended to the `Sequence`.\n        \"\"\"\n        # Sequence\n        if is_sequence(iterable):\n            self._data.extend(iterable)\n        # Structure\n        elif is_structure(iterable):\n            members = [item for item in iterable.values()]\n            self._data.extend(members)\n        # Field\n        elif is_field(iterable):\n            self._data.extend([iterable])\n        # Iterable\n        elif isinstance(iterable, (set, tuple, list)):\n            self._data.extend(Sequence(iterable))\n        else:\n            raise MemberTypeError(self, iterable, member=len(self))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the necessary number of bytes from the data provider.", "response": "def read_from(self, provider, **options):\n        \"\"\" All :class:`Pointer` fields in the `Sequence` read the necessary\n        number of bytes from the data :class:`Provider` for their referenced\n        :attr:`~Pointer.data` object. Null pointer are ignored.\n\n        :param Provider provider: data :class:`Provider`.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            :attr:`~Pointer.data` objects of all :class:`Pointer` fields in the\n            `Sequence` reads their referenced :attr:`~Pointer.data` object as\n            well (chained method call).\n            Each :class:`Pointer` field stores the bytes for its referenced\n            :attr:`~Pointer.data` object in its :attr:`~Pointer.bytestream`.\n        \"\"\"\n        for item in iter(self):\n            # Container or Pointer\n            if is_mixin(item):\n                item.read_from(provider, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef container_size(self):\n        length = 0\n        for name, item in enumerate(self):\n            # Container\n            if is_container(item):\n                byte_length, bit_length = item.container_size()\n                length += bit_length + byte_length * 8\n            # Field\n            elif is_field(item):\n                length += item.bit_size\n            else:\n                raise MemberTypeError(self, item, name)\n        return divmod(length, 8)", "response": "Returns the accumulated bit size of all containers and fields in the Sequence as\n            a tuple of number of bytes remaining number of bits."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first Field in the Sequence or None if an empty Sequence.", "response": "def first_field(self):\n        \"\"\" Returns the first :class:`Field` in the `Sequence` or ``None``\n        for an empty `Sequence`.\n        \"\"\"\n        for name, item in enumerate(self):\n            # Container\n            if is_container(item):\n                field = item.first_field()\n                # Container is not empty\n                if field is not None:\n                    return field\n            # Field\n            elif is_field(item):\n                return item\n            else:\n                raise MemberTypeError(self, item, name)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_fields(self, content):\n        for name, pair in enumerate(zip(self, content)):\n            item, value = pair\n            # Container or Pointer\n            if is_mixin(item):\n                item.initialize_fields(value)\n            # Fields\n            elif is_field(item):\n                item.value = value\n            else:\n                raise MemberTypeError(self, item, name)", "response": "Initializes the fields of the items in the Sequence with the values in the content list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef view_fields(self, *attributes, **options):\n        items = list()\n\n        for index, item in enumerate(self):\n            if is_container(item):\n                # Container\n                items.append(item.view_fields(*attributes, **options))\n            elif is_pointer(item) and get_nested(options):\n                # Pointer\n                items.append(item.view_fields(*attributes, **options))\n            elif is_field(item):\n                # Field\n                if attributes:\n                    field_getter = attrgetter(*attributes)\n                else:\n                    field_getter = attrgetter('value')\n\n                if len(attributes) > 1:\n                    fieldnames = options.get('fieldnames', attributes)\n                    items.append(dict(zip(fieldnames, field_getter(item))))\n                else:\n                    items.append(field_getter(item))\n            else:\n                raise MemberTypeError(self, item, index)\n        return items", "response": "Returns a list with the selected field attributes or a list with the selected field attributes for each container and nested in the Sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of tuples containing the field items for each field in the sequence.", "response": "def field_items(self, path=str(), **options):\n        \"\"\" Returns a **flatten** list of ``('field path', field item)`` tuples\n        for each :class:`Field` *nested* in the `Sequence`.\n\n        :param str path: field path of the `Sequence`.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            :attr:`~Pointer.data` objects of all :class:`Pointer` fields in\n            the `Sequence` list their referenced :attr:`~Pointer.data` object\n            field items as well (chained method call).\n        \"\"\"\n        items = list()\n        for index, item in enumerate(self):\n            if path:\n                item_path = \"{0}[{1}]\".format(path, str(index))\n            else:\n                item_path = \"[{0}]\".format(str(index))\n            # Container\n            if is_container(item):\n                for field_item in item.field_items(item_path, **options):\n                    items.append(field_item)\n            # Pointer\n            elif is_pointer(item) and get_nested(options):\n                for field_item in item.field_items(item_path, **options):\n                    items.append(field_item)\n            # Field\n            elif is_field(item):\n                items.append((item_path, item))\n            else:\n                raise MemberTypeError(self, item, item_path)\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resize(self, capacity):\n        count = max(int(capacity), 0) - len(self)\n\n        if count == 0:\n            pass\n        elif -count == len(self):\n            self.clear()\n        elif count > 0:\n            for i in range(count):\n                self.append()\n        else:\n            for i in range(abs(count)):\n                self.pop()", "response": "Re - sizes the array by appending new array elements to the end."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_fields(self, content):\n\n        if isinstance(content, (list, tuple)):\n            capacity = len(content)\n            for i in range(0, len(self), capacity):\n                for name, pair in enumerate(zip(self[i:i + capacity],\n                                                content),\n                                            start=i):\n                    item, value = pair\n                    if is_mixin(item):\n                        # Container or Pointer\n                        item.initialize_fields(value)\n                    elif is_field(item):\n                        # Fields\n                        item.value = value\n                    else:\n                        raise MemberTypeError(self, item, name)\n        else:\n            for name, item in enumerate(self):\n                if is_mixin(item):\n                    # Container or Pointer\n                    item.initialize_fields(content)\n                elif is_field(item):\n                    # Fields\n                    item.value = content\n                else:\n                    raise MemberTypeError(self, item, name)", "response": "Initializes the fields of the Entry objects in the array with the values in the content list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deserialize(self, buffer=bytes(), index=Index(), **options):\n        self.index = index\n        self._value = self.unpack(buffer, index, **options)\n        return self.index_field(index)", "response": "Deserializes the object from the given byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing the object into a byte stream.", "response": "def serialize(self, buffer=bytearray(), index=Index(), **options):\n        \"\"\" Serializes the `Field` to the byte *buffer* starting at the begin\n        of the *buffer* or with the given *index* by packing the :attr:`value`\n        of the `Field` to the byte *buffer* in accordance with the encoding\n        *byte order* for the serialization and the encoding :attr:`byte_order`\n        of the `Field`.\n\n        The specific encoding :attr:`byte_order` of the `Field` overrules the\n        encoding *byte order* for the serialization.\n\n        Returns the :class:`Index` of the *buffer* after the `Field`.\n\n        Optional the serialization of the referenced :attr:`~Pointer.data` object\n        of a :class:`Pointer` field can be enabled.\n\n        :param bytearray buffer: byte stream.\n        :param Index index: current write :class:`Index` of the *buffer*.\n        :keyword byte_order: encoding byte order for the serialization.\n        :type byte_order: :class:`Byteorder`, :class:`str`\n        :keyword bool nested: if ``True`` a :class:`Pointer` field serializes\n            its referenced :attr:`~Pointer.data` object as well\n            (chained method call).\n            Each :class:`Pointer` field uses for the encoding of its referenced\n            :attr:`~Pointer.data` object its own :attr:`~Pointer.bytestream`.\n        \"\"\"\n        self.index = index\n        buffer += self.pack(buffer, **options)\n        return self.index_field(index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the index after the Field with the given index.", "response": "def index_field(self, index=Index()):\n        \"\"\" Indexes the `Field` with the given *index* und returns the\n        :class:`Index` after the `Field`.\n\n        :param Index index: start :class:`Index` for the `Field`.\n        \"\"\"\n        # Set field index\n        # Note: Updates the field alignment offset as well\n        self.index = index\n\n        # Bit offset for the next field\n        byte, bit, address, base, update = index\n        bit += self.bit_size\n\n        # Field group size\n        group_size, offset = divmod(bit, 8)\n\n        # End of field group?\n        if self.alignment.byte_size == group_size:\n            # Bad aligned field group?\n            if offset is not 0:\n                raise FieldGroupSizeError(self, index,\n                                          Alignment(group_size + 1,\n                                                    self.alignment.bit_offset))\n            else:\n                # Move byte index for the next field group\n                byte += self.alignment.byte_size\n                # Reset bit offset for the next field group\n                bit = 0\n                # Move address for the next field group\n                address += self.alignment.byte_size\n        # Index for the next field\n        return Index(byte, bit, address, base, update)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef describe(self, name=str(), **options):\n        metadata = {\n            'address': self.index.address,\n            'alignment': list(self.alignment),\n            'class': self.name,\n            'order': self.byte_order.value,\n            'index': [self.index.byte, self.index.bit],\n            'name': name if name else self.name,\n            'size': self.bit_size,\n            'type': Field.item_type.name,\n            'value': self.value\n        }\n        return OrderedDict(sorted(metadata.items()))", "response": "Returns the metadata of a field as an OrderedDict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef name(self):\n        size = len(self)\n        if size > 0:\n            return self.item_type.name.capitalize() + str(size)\n        else:\n            return self.item_type.name.capitalize()", "response": "Returns the type name of the Stream field ( read - only."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resize(self, size):\n        count = max(int(size), 0) - len(self)\n\n        if count == 0:\n            pass\n        elif -count == len(self):\n            self._value = bytes()\n        elif count > 0:\n            self._value += b'\\x00' * count\n        else:\n            self._value = self._value[:count]\n        size = len(self)\n        self._bit_size = size * 8\n        self._align_to_byte_size = size", "response": "Re - sizes the stream field by appending zero bytes or removing bytes from the end."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self):\n        length = self._value.find(b'\\x00')\n        if length >= 0:\n            return self._value[:length].decode('ascii')\n        else:\n            return self._value.decode('ascii')", "response": "Field value as an ascii encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the alignment of the log entry.", "response": "def _set_alignment(self, group_size, bit_offset=0, auto_align=False):\n        \"\"\" Sets the alignment of the ``Decimal`` field.\n\n        :param int group_size: size of the aligned `Field` group in bytes,\n            can be between ``1`` and ``8``.\n        :param int bit_offset: bit offset of the `Decimal` field within the\n            aligned `Field` group, can be between ``0`` and ``63``.\n        :param bool auto_align: if ``True`` the `Decimal` field aligns itself\n            to the next matching byte size according to the *size* of the\n            `Decimal` field.\n        \"\"\"\n        # Field alignment offset\n        field_offset = int(bit_offset)\n\n        # Auto alignment\n        if auto_align:\n            # Field alignment size\n            field_size, bit_offset = divmod(field_offset, 8)\n            if bit_offset is not 0:\n                field_size += 1\n            field_size = max(field_size, 1)\n        # No auto alignment\n        else:\n            # Field alignment size\n            field_size = int(group_size)\n\n        # Field alignment\n        alignment = Alignment(field_size, field_offset)\n\n        # Invalid field alignment size\n        if field_size not in range(1, 8):\n            raise FieldAlignmentError(self, self.index, alignment)\n\n        # Invalid field alignment offset\n        if not (0 <= field_offset <= 63):\n            raise FieldAlignmentError(self, self.index, alignment)\n\n        # Invalid field alignment\n        if field_offset >= field_size * 8:\n            raise FieldAlignmentError(self, self.index, alignment)\n\n        # Set field alignment\n        self._align_to_byte_size = alignment.byte_size\n        self._align_to_bit_offset = alignment.bit_offset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the bit size of the record.", "response": "def _set_bit_size(self, size, step=1, auto_align=False):\n        \"\"\" Sets the *size* of the `Decimal` field.\n\n        :param int size: is the *size* of the `Decimal` field in bits,\n            can be between ``1`` and ``64``.\n        :param int step: is the minimal required step *size* for the `Decimal`\n            field in bits.\n        :param bool auto_align: if ``True`` the `Decimal` field aligns itself\n            to the next matching byte size according to the *size* of the\n            `Decimal` field.\n        \"\"\"\n        # Field size\n        bit_size = int(size)\n\n        # Invalid field size\n        if bit_size % step != 0 or not (1 <= bit_size <= 64):\n            raise FieldSizeError(self, self.index, bit_size)\n\n        # Field group size\n        group_size, offset = divmod(bit_size, 8)\n        # Auto alignment\n        if auto_align:\n            if offset is not 0:\n                self._align_to_byte_size = group_size + 1\n            else:\n                self._align_to_byte_size = group_size\n        # Invalid field alignment\n        elif group_size > self.alignment.byte_size:\n            raise FieldAlignmentError(self, self.index,\n                                      Alignment(group_size,\n                                                self.alignment.bit_offset))\n        # Set field size\n        self._bit_size = bit_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_unsigned(self):\n        return self._cast(self._value, self._min(False), self._max(False), False)", "response": "Returns the field value of the Decimal field as an unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the field value of the Decimal field as a signed integer.", "response": "def as_signed(self):\n        \"\"\" Returns the field *value* of the `Decimal` field as a signed integer.\"\"\"\n        return self._cast(self._value, self._min(True), self._max(True), True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfields value as an enum name string. Fall back is an unsigned integer number. Fall back is an unsigned integer number. Fall back is an unsigned integer number. Fall back is an unsigned integer number.", "response": "def value(self):\n        \"\"\" Field value as an enum name string. Fall back is an unsigned integer number.\"\"\"\n        if self._enum and issubclass(self._enum, Enumeration):\n            name = self._enum.get_name(self._value)\n            if name:\n                return name\n        return self._value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the name of the Fraction field ( read - only.", "response": "def name(self):\n        \"\"\" Returns the type name of the `Fraction` field (read-only).\"\"\"\n        return \"{0}{1}.{2}\".format(self.item_type.name.capitalize(),\n                                   self._bits_integer,\n                                   self.bit_size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the size of the data object in bytes.", "response": "def data_size(self):\n        \"\"\" Returns the size of the :attr:`data` object in bytes (read-only).\"\"\"\n        # Container\n        if is_container(self._data):\n            byte_length, bit_length = self._data.container_size()\n            return byte_length + math.ceil(bit_length / 8)\n        # Field\n        elif is_field(self._data):\n            return math.ceil(self._data.bit_size / 8)\n        else:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_data(self, byte_order=None):\n        if self._data is None:\n            return bytes()\n        if byte_order not in ('little', 'big', Byteorder.little, Byteorder.big):\n            byte_order = self.data_byte_order\n        buffer = bytearray()\n        self._data.serialize(buffer,\n                             Index(0, 0,\n                                   self.address, self.base_address,\n                                   False),\n                             byte_order=byte_order)\n        return bytes(buffer)", "response": "Serializes the data of the object to bytes by mapping the value of each field to the number of bytes required by the serialization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nindexing each Field in the data object referenced by the Pointer field.", "response": "def index_data(self):\n        \"\"\" Indexes each :class:`Field` in the :attr:`data` object referenced\n        by the `Pointer` field.\n        \"\"\"\n        # Start index for the Data Object\n        index = Index(0, 0, self.address, self.base_address, False)\n        # Container\n        if is_container(self._data):\n            self._data.index_fields(index, nested=True)\n        # Pointer\n        elif is_pointer(self._data):\n            self._data.index_field(index)\n            self._data.index_data()\n        # Field\n        elif is_field(self._data):\n            self._data.index_field(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads from the data provider and populates the internal state of the object.", "response": "def read_from(self, provider, null_allowed=False, **options):\n        \"\"\" Reads from the data :class:`Provider` the necessary number of bytes\n        for the :attr:`data` object referenced by the `Pointer` field.\n\n        A `Pointer` field stores the binary data read from the data\n        :class:`Provider` in its :attr:`bytestream`.\n\n        :param Provider provider: data :class:`Provider`.\n        :param bool null_allowed: if ``True`` read access of address zero (Null)\n            is allowed.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            :attr:`data` object of the `Pointer` field reads their referenced\n            :attr:`~Pointer.data` object fields as well (chained method call).\n            Each `Pointer` field stores the bytes for its referenced\n            :attr:`data` object in its :attr:`bytestream`.\n        \"\"\"\n        if self._data is None:\n            pass\n        elif is_provider(provider):\n            if self._value < 0:\n                pass\n            elif null_allowed or self._value > 0:\n                while True:\n                    self.bytestream = provider.read(self.address, self.data_size)\n                    index = self.deserialize_data()\n                    # Incomplete data object\n                    if index.bit != 0:\n                        length = index.byte, index.bit\n                        raise ContainerLengthError(self, length)\n                    if not index.update:\n                        break\n                if is_mixin(self._data) and get_nested(options):\n                    self._data.read_from(provider, **options)\n            else:\n                self.bytestream = bytes()\n                self.deserialize_data()\n        else:\n            raise ProviderTypeError(self, provider)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patch(self, item, byte_order=BYTEORDER):\n        # Re-index the data object\n        self.index_data()\n\n        if is_container(item):\n            length = item.container_size()\n            if length[1] is not 0:\n                # Incomplete container\n                raise ContainerLengthError(item, length)\n\n            field = item.first_field()\n            if field is None:\n                # Empty container?\n                return None\n\n            index = field.index\n            if index.bit is not 0:\n                # Bad placed container\n                raise FieldIndexError(field, index)\n\n            # Create a dummy byte array filled with zero bytes.\n            # The dummy byte array is necessary because the length of\n            # the buffer must correlate to the field indexes of the\n            # appending fields.\n            buffer = bytearray(b'\\x00' * index.byte)\n\n            # Append to the buffer the content mapped by the container fields\n            item.serialize(buffer, index, byte_order=byte_order)\n\n            # Content of the buffer mapped by the container fields\n            content = buffer[index.byte:]\n\n            if len(content) != length[0]:\n                # Not correct filled buffer!\n                raise BufferError(len(content), length[0])\n\n            return Patch(content,\n                         index.address,\n                         byte_order,\n                         length[0] * 8,\n                         0,\n                         False)\n        elif is_field(item):\n            # Field index\n            index = item.index\n            # Field alignment\n            alignment = item.alignment\n\n            if index.bit != alignment.bit_offset:\n                # Bad aligned field?\n                raise FieldGroupOffsetError(\n                    item, index, Alignment(alignment.byte_size, index.bit))\n\n            # Create a dummy byte array filled with zero bytes.\n            # The dummy byte array is necessary because the length of\n            # the buffer must correlate to the field index of the\n            # appending field group.\n            buffer = bytearray(b'\\x00' * index.byte)\n\n            # Append to the buffer the content mapped by the field\n            item.serialize(buffer, index, byte_order=byte_order)\n\n            # Content of the buffer mapped by the field group\n            content = buffer[index.byte:]\n\n            if len(content) != alignment.byte_size:\n                # Not correct filled buffer!\n                raise BufferError(len(content), alignment.byte_size)\n\n            # Patch size in bytes for the field in the content buffer\n            patch_size, bit_offset = divmod(item.bit_size, 8)\n            if bit_offset is not 0:\n                inject = True\n                patch_size += 1\n            else:\n                inject = False\n\n            # Patch offset in bytes for the field in the content buffer\n            patch_offset, bit_offset = divmod(alignment.bit_offset, 8)\n            if bit_offset is not 0:\n                inject = True\n\n            if byte_order is Byteorder.big:\n                start = alignment.byte_size - (patch_offset + patch_size)\n                stop = alignment.byte_size - patch_offset\n            else:\n                start = patch_offset\n                stop = patch_offset + patch_size\n\n            return Patch(content[start:stop],\n                         index.address + start,\n                         byte_order,\n                         item.bit_size,\n                         bit_offset,\n                         inject)\n        else:\n            raise MemberTypeError(self, item)", "response": "Returns a memory object that shall be patched in the data source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the contents of the given item to the given data source.", "response": "def write_to(self, provider, item, byte_order=BYTEORDER):\n        \"\"\" Writes via a data :class:`Provider` the :class:`Field` values of\n        the given *item* to the `data source`.\n\n        :param Provider provider: data :class:`Provider`.\n        :param item: item to write.\n        :param byte_order: encoding :class:`Byteorder`.\n        :type byte_order: :class:`Byteorder`, :class:`str`\n        \"\"\"\n        # Create memory patch for the item to write\n        patch = self.patch(item, byte_order)\n\n        if patch is None:\n            pass\n        elif is_provider(provider):\n            if patch.inject:\n                # Unpatched content of the memory area in the data source to modify\n                content = provider.read(patch.address, len(patch.buffer))\n\n                # Decimal value of the memory area to patch\n                value = int.from_bytes(content, byte_order.value)\n\n                # Inject memory patch content\n                bit_mask = ~((2 ** patch.bit_size - 1) << patch.bit_offset)\n                bit_mask &= (2 ** (len(patch.buffer) * 8) - 1)\n                value &= bit_mask\n                value |= int.from_bytes(patch.buffer, byte_order.value)\n\n                # Patched content for the memory area in the data source\n                buffer = value.to_bytes(len(patch.buffer), byte_order.value)\n\n                provider.write(buffer, patch.address, len(buffer))\n            else:\n                provider.write(patch.buffer, patch.address, len(patch.buffer))\n        else:\n            raise ProviderTypeError(self, provider)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialize(self, buffer=bytes(), index=Index(), **options):\n        # Field\n        index = super().deserialize(buffer, index, **options)\n        # Data Object\n        if self._data and get_nested(options):\n            options[Option.byte_order.value] = self.data_byte_order\n            self._data.deserialize(self._data_stream,\n                                   Index(0, 0,\n                                         self.address, self.base_address,\n                                         False),\n                                   **options)\n        return index", "response": "Deserializes the current record into a new index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_fields(self, content):\n        for name, value in content.items():\n            if name is 'value':\n                self.value = value\n            elif name is 'data':\n                # Container or Pointer\n                if is_mixin(self._data):\n                    self._data.initialize_fields(value)\n                # Field\n                elif is_field(self._data):\n                    self._data.value = value", "response": "Initializes the fields of the items of the object with the values in the content dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindex the fields of the Nested Nested", "response": "def index_fields(self, index=Index(), **options):\n        \"\"\" Indexes the `Pointer` field and the :attr:`data` object referenced\n        by the `Pointer` field starting with the given *index* and returns the\n        :class:`Index` after the `Pointer` field.\n\n        :param Index index: :class:`Index` for the `Pointer` field.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            :attr:`data` object referenced by the `Pointer` field indexes their\n            referenced :attr:`~Pointer.data` object fields as well\n            (chained method call).\n        \"\"\"\n        index = self.index_field(index)\n\n        # Container\n        if is_container(self._data):\n            self._data.index_fields(Index(0, 0,\n                                          self.address, self.base_address,\n                                          False),\n                                    **options)\n        # Pointer\n        elif is_pointer(self._data) and get_nested(options):\n            self._data.index_fields(Index(0, 0,\n                                          self.address, self.base_address,\n                                          False),\n                                    **options)\n        # Field\n        elif is_field(self._data):\n            self._data.index_field(Index(0, 0,\n                                         self.address, self.base_address,\n                                         False))\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an ordered dictionary of the selected fields of the current object.", "response": "def view_fields(self, *attributes, **options):\n        \"\"\" Returns an :class:`ordered dictionary <collections.OrderedDict>` which\n        contains the selected field *attributes* of the `Pointer` field itself\n        extended with a ``['data']`` key which contains the selected field *attribute*\n        or the dictionaries of the selected field *attributes* for each :class:`Field`\n        *nested* in the :attr:`data` object referenced by the `Pointer` field.\n\n        The *attributes* of each :class:`Field` for containers *nested* in the\n        :attr:`data` object referenced by the `Pointer` field are viewed as well\n        (chained method call).\n\n        :param str attributes: selected :class:`Field` attributes.\n            Fallback is the field :attr:`~Field.value`.\n        :keyword tuple fieldnames: sequence of dictionary keys for the selected\n            field *attributes*. Defaults to ``(*attributes)``.\n        :keyword bool nested: if ``True`` all :class:`Pointer` fields in the\n            :attr:`data` object referenced by the `Pointer` field views their\n            referenced :attr:`~Pointer.data` object field attributes as well\n            (chained method call).\n        \"\"\"\n        items = OrderedDict()\n\n        # Pointer field\n        if attributes:\n            field_getter = attrgetter(*attributes)\n        else:\n            field_getter = attrgetter('value')\n\n        if len(attributes) > 1:\n            for key, value in zip(attributes, field_getter(self)):\n                items[key] = value\n        else:\n            items['value'] = field_getter(self)\n\n        # Data object\n        if is_container(self._data):\n            # Container\n            items['data'] = self._data.view_fields(*attributes, **options)\n        elif is_pointer(self._data) and get_nested(options):\n            # Pointer\n            items['data'] = self._data.view_fields(*attributes, **options)\n        elif is_field(self._data):\n            # Field\n            if attributes:\n                field_getter = attrgetter(*attributes)\n            else:\n                field_getter = attrgetter('value')\n            if len(attributes) > 1:\n                fieldnames = options.get('fieldnames', attributes)\n                items['data'] = dict(zip(fieldnames, field_getter(self._data)))\n            else:\n                items['data'] = field_getter(self._data)\n        else:\n            # None\n            items['data'] = self._data\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef field_items(self, path=str(), **options):\n        items = list()\n        # Field\n        items.append((path if path else 'field', self))\n        # Data Object\n        data_path = '{0}.{1}'.format(path, 'data') if path else 'data'\n        # Container\n        if is_container(self._data):\n            for field_item in self._data.field_items(data_path, **options):\n                items.append(field_item)\n        # Pointer\n        elif is_pointer(self._data) and get_nested(options):\n            for field_item in self._data.field_items(data_path, **options):\n                items.append(field_item)\n        # Field\n        elif is_field(self._data):\n            items.append((data_path, self._data))\n        return items", "response": "Returns a list of tuples containing the field path and field item for each field in the object referenced by the Pointer field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the description of a Pointer field.", "response": "def describe(self, name=str(), **options):\n        \"\"\" Returns the **metadata** of a `Pointer` as an\n        :class:`ordered dictionary <collections.OrderedDict>`.\n\n        .. code-block:: python\n\n            metadata = {\n                'address': self.index.address,\n                'alignment': [self.alignment.byte_size, self.alignment.bit_offset],\n                'class': self.__class__.__name__,\n                'index': [self.index.byte, self.index.bit],\n                'max': self.max(),\n                'min': self.min(),\n                'name': name if name else self.__class__.__name__,\n                'order': self.byte_order.value,\n                'size': self.bit_size,\n                'type': Pointer.item_type.name,\n                'value': self.value,\n                'member': [self.data.describe()]\n            }\n\n        :param str name: optional name for the `Pointer` field.\n            Fallback is the class name.\n        :keyword bool nested: if ``True`` a :class:`Pointer` field lists its\n            referenced :attr:`data` object fields as well (chained method call).\n            Default is ``True``.\n        \"\"\"\n        metadata = super().describe(name, **options)\n        metadata['class'] = self.__class__.__name__\n        metadata['name'] = name if name else self.__class__.__name__\n        metadata['type'] = Pointer.item_type.name\n        if is_any(self._data) and get_nested(options):\n            metadata['member'] = list()\n            metadata['member'].append(self._data.describe('data', **options))\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resize(self, size):\n        if isinstance(self._data, Stream):\n            self._data.resize(size)", "response": "Re - sizes the internal stream field by appending zero bytes or removing bytes from the end."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dataset representation in BMDS. d file.", "response": "def as_dfile(self):\n        \"\"\"\n        Return the dataset representation in BMDS .(d) file.\n\n        Example\n        -------\n        >>> print(dataset.as_dfile())\n        Dose Incidence NEGATIVE_RESPONSE\n        0.000000 5 70\n        1.960000 1 48\n        5.690000 3 47\n        29.750000 14 35\n        \"\"\"\n        rows = [\"Dose Incidence NEGATIVE_RESPONSE\"]\n        for i, v in enumerate(self.doses):\n            if i >= self.num_dose_groups:\n                continue\n            rows.append(\"%f %d %d\" % (self.doses[i], self.incidences[i], self.remainings[i]))\n        return \"\\n\".join(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_dict(self):\n        d = dict(doses=self.doses, ns=self.ns, incidences=self.incidences)\n        d.update(self.kwargs)\n        return d", "response": "Returns a dictionary representation of the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calculate_plotting(n, incidence):\n        p = incidence / float(n)\n        z = stats.norm.ppf(0.975)\n        q = 1. - p\n        ll = (\n            (2 * n * p + 2 * z - 1) - z * np.sqrt(2 * z - (2 + 1 / n) + 4 * p * (n * q + 1))\n        ) / (2 * (n + 2 * z))\n        ul = (\n            (2 * n * p + 2 * z + 1) + z * np.sqrt(2 * z + (2 + 1 / n) + 4 * p * (n * q - 1))\n        ) / (2 * (n + 2 * z))\n        return p, ll, ul", "response": "Calculate the error bars and confidence intervals for a specific set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef drop_dose(self):\n        for fld in (\"doses\", \"ns\", \"means\", \"stdevs\"):\n            arr = getattr(self, fld)[:-1]\n            setattr(self, fld, arr)\n        self._validate()", "response": "Drop the maximum dose and related response values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_dfile(self):\n        rows = [\"Dose NumAnimals Response Stdev\"]\n        for i, v in enumerate(self.doses):\n            if i >= self.num_dose_groups:\n                continue\n            rows.append(\n                \"%f %d %f %f\" % (self.doses[i], self.ns[i], self.means[i], self.stdevs[i])\n            )\n        return \"\\n\".join(rows)", "response": "Return the dataset representation in BMDS. d file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(self):\n        d = dict(doses=self.doses, ns=self.ns, means=self.means, stdevs=self.stdevs)\n        d.update(self.kwargs)\n        return d", "response": "Returns a dictionary representation of the dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a matplotlib figure of the dose - response dataset.", "response": "def plot(self):\n        \"\"\"\n        Return a matplotlib figure of the dose-response dataset.\n\n        Examples\n        --------\n        >>> fig = dataset.plot()\n        >>> fig.show()\n\n        .. image:: ../tests/resources/test_cdataset_plot.png\n           :align: center\n           :alt: Example generated BMD plot\n\n        Returns\n        -------\n        out : matplotlib.figure.Figure\n            A matplotlib figure representation of the dataset.\n        \"\"\"\n        fig = plotting.create_empty_figure()\n        ax = fig.gca()\n        xlabel = self.kwargs.get(\"xlabel\", \"Dose\")\n        ylabel = self.kwargs.get(\"ylabel\", \"Response\")\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.errorbar(\n            self.doses,\n            self.means,\n            yerr=self.errorbars,\n            label=\"Mean \u00b1 95% CI\",\n            **plotting.DATASET_POINT_FORMAT,\n        )\n        ax.margins(plotting.PLOT_MARGINS)\n        ax.set_title(self._get_dataset_name())\n        ax.legend(**settings.LEGEND_OPTS)\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndrop the maximum dose and related response values.", "response": "def drop_dose(self):\n        \"\"\"\n        Drop the maximum dose and related response values.\n        \"\"\"\n        doses = np.array(self.individual_doses)\n        responses = np.array(self.responses)\n        mask = doses != doses.max()\n        self.individual_doses = doses[mask].tolist()\n        self.responses = responses[mask].tolist()\n        self.set_summary_data()\n        self._validate()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the dataset representation in BMDS. d file.", "response": "def as_dfile(self):\n        \"\"\"\n        Return the dataset representation in BMDS .(d) file.\n        \"\"\"\n        rows = [\"Dose Response\"]\n        for dose, response in zip(self.individual_doses, self.responses):\n            dose_idx = self.doses.index(dose)\n            if dose_idx >= self.num_dose_groups:\n                continue\n            rows.append(\"%f %f\" % (dose, response))\n        return \"\\n\".join(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary representation of the dataset.", "response": "def to_dict(self):\n        \"\"\"\n        Return a dictionary representation of the dataset.\n        \"\"\"\n        d = dict(individual_doses=self.individual_doses, responses=self.responses)\n        d.update(self.kwargs)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a matplotlib figure of the dose - response dataset.", "response": "def plot(self):\n        \"\"\"\n        Return a matplotlib figure of the dose-response dataset.\n\n        Examples\n        --------\n        >>> fig = dataset.plot()\n        >>> fig.show()\n        >>> fig.clear()\n\n        .. image:: ../tests/resources/test_cidataset_plot.png\n           :align: center\n           :alt: Example generated BMD plot\n\n        Returns\n        -------\n        out : matplotlib.figure.Figure\n            A matplotlib figure representation of the dataset.\n        \"\"\"\n        fig = plotting.create_empty_figure()\n        ax = fig.gca()\n        xlabel = self.kwargs.get(\"xlabel\", \"Dose\")\n        ylabel = self.kwargs.get(\"ylabel\", \"Response\")\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.scatter(\n            self.individual_doses,\n            self.responses,\n            label=\"Data\",\n            **plotting.DATASET_INDIVIDUAL_FORMAT,\n        )\n        ax.margins(plotting.PLOT_MARGINS)\n        ax.set_title(self._get_dataset_name())\n        ax.legend(**settings.LEGEND_OPTS)\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cd(path, on=os):\n    \n    original = on.getcwd()\n    on.chdir(path)\n    \n    yield\n    \n    on.chdir(original)", "response": "Change the current working directory within this context."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the PATH environment variable.", "response": "def path(append=None, prepend=None, replace=None, on=os):\n    \"\"\"Update the PATH environment variable.\n    \n    Can append, prepend, or replace the path.  Each of these expects a string\n    or a list of strings (for multiple path elements) and can operate on remote\n    connections that offer an @environ@ attribute using the @on@ argument.\n    \"\"\"\n    \n    original = on.environ['PATH']\n    \n    if replace and (append or prepend):\n        raise ValueError(\"You can not combine append or prepend with replace.\")\n    \n    if replace:\n        if not isinstance(replace, list):\n            replace = list(replace)\n        \n        on.environ['PATH'] = ':'.join(replace)\n    \n    else:\n        if append:\n            if not isinstance(append, list):\n                append = list(append)\n            \n            append.insert(0, on.environ['PATH'])\n            on.environ['PATH'] = ':'.join(append)\n        \n        if prepend:\n            if not isinstance(prepend, list):\n                prepend = list(prepend)\n            \n            prepend.append(on.environ['PATH'])\n            on.environ['PATH'] = ':'.join(prepend)\n    \n    yield\n    \n    on.environ['PATH'] = original"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating one or more environment variables.", "response": "def environ(on=os, **kw):\n    \"\"\"Update one or more environment variables.\n    \n    Preserves the previous environment variable (if available) and can be\n    applied to remote connections that offer an @environ@ attribute using the\n    @on@ argument.\n    \"\"\"\n    \n    originals = list()\n    \n    for key in kw:\n        originals.append((key, on.environ.get(key, None)))\n        on.environ[key] = kw[key]\n    \n    yield\n    \n    for key, value in originals:\n        if not value:\n            del on.environ[key]\n            continue\n        \n        on.environ[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a URL for the specified endpoint.", "response": "def url_builder(self, endpoint, *, root=None, params=None, url_params=None):\n        \"\"\"Create a URL for the specified endpoint.\n\n        Arguments:\n          endpoint (:py:class:`str`): The API endpoint to access.\n          root: (:py:class:`str`, optional): The root URL for the\n            service API.\n          params: (:py:class:`dict`, optional): The values for format\n            into the created URL (defaults to ``None``).\n          url_params: (:py:class:`dict`, optional): Parameters to add\n            to the end of the URL (defaults to ``None``).\n\n        Returns:\n          :py:class:`str`: The resulting URL.\n\n        \"\"\"\n        if root is None:\n            root = self.ROOT\n        return ''.join([\n            root,\n            endpoint,\n            '?' + urlencode(url_params) if url_params else '',\n        ]).format(**params or {})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting request timeout from e. g. Retry - After header.", "response": "def calculate_timeout(http_date):\n        \"\"\"Extract request timeout from e.g. ``Retry-After`` header.\n\n        Notes:\n          Per :rfc:`2616#section-14.37`, the ``Retry-After`` header can\n          be either an integer number of seconds or an HTTP date. This\n          function can handle either.\n\n        Arguments:\n          http_date (:py:class:`str`): The date to parse.\n\n        Returns:\n          :py:class:`int`: The timeout, in seconds.\n\n        \"\"\"\n        try:\n            return int(http_date)\n        except ValueError:\n            date_after = parse(http_date)\n        utc_now = datetime.now(tz=timezone.utc)\n        return int((date_after - utc_now).total_seconds())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a service instance from an environment variable.", "response": "def from_env(cls):\n        \"\"\"Create a service instance from an environment variable.\"\"\"\n        token = getenv(cls.TOKEN_ENV_VAR)\n        if token is None:\n            msg = 'missing environment variable: {!r}'.format(cls.TOKEN_ENV_VAR)\n            raise ValueError(msg)\n        return cls(api_token=token)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url_builder(self, endpoint, params=None, url_params=None):\n        if url_params is None:\n            url_params = OrderedDict()\n        url_params[self.AUTH_PARAM] = self.api_token\n        return super().url_builder(\n            endpoint,\n            params=params,\n            url_params=url_params,\n        )", "response": "Add authentication URL parameter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_found_locations():\n    #random.seed(1704)\n    #garbage = ''.join([chr(random.randint(32,122)) for x in range(100000)])\n    #wrd_location = garbage.find('MATHS')\n    #print(wrd_location) # 73834\n    #print(garbage[wrd_location:wrd_location+5])  # HELP\n    \n    random.seed(1704)\n    print(''.join([chr(random.randint(32,122)) for x in range(100000)])[59741:59746])\n    random.seed(1572)\n    print(''.join([chr(random.randint(32,122)) for x in range(100000)])[73834:73838])\n    \n    random.seed(561240)\n    print(''.join([chr(random.randint(32,122)) for x in range(3)]))  # WTF\n    \n    random.seed(706075)\n    print(''.join([chr(random.randint(32,122)) for x in range(3)]))", "response": "Get a list of locations of the found files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decorator(decor):\n    ensure_callable(decor)\n    return _wrap_decorator(decor, \"functions or classes\",\n                           or_(inspect.isfunction, inspect.isclass))", "response": "Decorator for functions and classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap given decorator in order to provide additional functionality of the functions.", "response": "def _wrap_decorator(decorator, targets, is_valid_target):\n    \"\"\"Wraps given decorator in order to provide additional functionality:\n    optional arguments and verification of decorator's target type.\n\n    :param decorator: Decorator callable\n    :param targets: Name of the decorator targets, as plural\n                    (used in error messages)\n    :param is_valid_target: Callable for checking\n                            whether decorator's target is valid\n\n    :return: Wrapped ``decorator``\n    \"\"\"\n    @functools.wraps(decorator)\n    def wrapper(*args, **kwargs):\n        # handle the case when decorator is applied as ``@decorator``\n        # (without any parameters and parentheses)\n        one_arg = len(args) == 1 and not kwargs\n        if one_arg and is_valid_target(args[0]):\n            actual_decorator = decorator()\n            return actual_decorator(args[0])\n\n        # pass the parameters to decorator callable\n        # to get the actual decorator that can be applied to targets\n        actual_decorator = decorator(*args, **kwargs)\n        # TODO(xion): The above raises TypeError with confusing message\n        # (\"<class>.__new__() takes no parameters\") when function decorator\n        # is applied to a class. See if we can detect that and do better.\n\n        # wrap it inside a function that verifies\n        # whether a target that user has given is valid for this decorator\n        def decorator_wrapper(target):\n            if not is_valid_target(target):\n                raise TypeError(\n                    \"@%s can only be applied to %s: got %r instead\" % (\n                        decorator.__name__, targets, type(target)))\n            return actual_decorator(target)\n\n        return decorator_wrapper\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, args):\n    if msg and not check_exists(msg):\n        send(\"Non-existant subreddit.\")\n        return\n    subreddit = msg if msg else None\n    send(random_post(subreddit, args['config']['api']['bitlykey']))", "response": "Gets a random Reddit post."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd(send, msg, args):\n    if not msg:\n        send(\"Choose what?\")\n        return\n    choices = msg.split(' or ')\n    action = [\n        'draws a slip of paper from a hat and gets...', 'says eenie, menie, miney, moe and chooses...', 'picks a random number and gets...',\n        'rolls dice and gets...', 'asks a random person and gets...', 'plays rock, paper, scissors, lizard, spock and gets...'\n    ]\n    send(\"%s %s\" % (choice(action), choice(choices)), 'action')", "response": "Selects between multiple choices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npester somebody. Syntax: {command} <nick> <message>", "response": "def cmd(send, msg, args):\n    \"\"\"Pesters somebody.\n\n    Syntax: {command} <nick> <message>\n\n    \"\"\"\n    if not msg or len(msg.split()) < 2:\n        send(\"Pester needs at least two arguments.\")\n        return\n    match = re.match('(%s+) (.*)' % args['config']['core']['nickregex'], msg)\n    if match:\n        message = match.group(2) + \" \"\n        send('%s: %s' % (match.group(1), message * 3))\n    else:\n        send(\"Invalid Syntax.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_all_descendants(self):\n        descendants = set()\n        descendants = descendants.union(self.child_nodes)\n        for child in self.child_nodes:\n            descendants = descendants.union(child._get_all_descendants())\n\n        if self in descendants:\n            log.error('circular dependancy found in %s. Descendants: %s ', self, descendants)\n            raise CircularDependency('Node %s contains itself in it\\'s list of dependencies.' % (self.job.name,))\n        return descendants", "response": "Returns a set containing all descendant nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_model(cls, version, model_name):\n        models = cls.versions[version].model_options\n        for keystore in models.values():\n            if model_name in keystore:\n                return keystore[model_name]\n        raise ValueError(\"Unknown model name\")", "response": "Return the model class given the BMDS version and model - name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_and_recommend(self, drop_doses=False):\n        self.execute()\n        self.recommend()\n\n        if not drop_doses:\n            return\n\n        while self.recommended_model is None and self.dataset.num_dose_groups > 3:\n            self.doses_dropped_sessions[self.doses_dropped] = self.clone()\n            self.dataset.drop_dose()\n            self.execute()\n            self.recommend()\n            self.doses_dropped += 1", "response": "Execute and recommend a best - fitting model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a single session to an ordered dictionary.", "response": "def _add_to_to_ordered_dict(self, d, dataset_index, recommended_only=False):\n        \"\"\"\n        Save a session to an ordered dictionary. In some cases, a single session may include\n        a final session, as well as other BMDS executions where doses were dropped. This\n        will include all sessions.\n        \"\"\"\n        if self.doses_dropped_sessions:\n            for key in sorted(list(self.doses_dropped_sessions.keys())):\n                session = self.doses_dropped_sessions[key]\n                session._add_single_session_to_to_ordered_dict(d, dataset_index, recommended_only)\n        self._add_single_session_to_to_ordered_dict(d, dataset_index, recommended_only)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_single_session_to_to_ordered_dict(self, d, dataset_index, recommended_only):\n        for model_index, model in enumerate(self.models):\n            # determine if model should be presented, or if a null-model should\n            # be presented (if no model is recommended.)\n            show_null = False\n            if recommended_only:\n                if self.recommendation_enabled:\n                    if self.recommended_model is None:\n                        if model_index == 0:\n                            show_null = True\n                        else:\n                            continue\n                    elif self.recommended_model == model:\n                        pass\n                    else:\n                        continue\n                else:\n                    if model_index == 0:\n                        show_null = True\n                    else:\n                        continue\n\n            d[\"dataset_index\"].append(dataset_index)\n            d[\"doses_dropped\"].append(self.doses_dropped)\n            model._to_df(d, model_index, show_null)", "response": "Save a single session to an ordered dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _group_models(self):\n        od = OrderedDict()\n\n        # Add models to appropriate list. We only aggregate models which\n        # completed successfully and have a valid AIC and BMD.\n        for i, model in enumerate(self.models):\n            output = getattr(model, \"output\", {})\n            if output.get(\"AIC\") and output.get(\"BMD\") and output[\"BMD\"] > 0:\n                key = \"{}-{}\".format(output[\"AIC\"], output[\"BMD\"])\n                if key in od:\n                    od[key].append(model)\n                else:\n                    od[key] = [model]\n            else:\n                od[i] = [model]\n\n        # Sort each list by the number of parameters\n        def _get_num_params(model):\n            return (\n                len(model.output[\"parameters\"])\n                if hasattr(model, \"output\") and \"parameters\" in model.output\n                else 0\n            )\n\n        for key, _models in od.items():\n            _models.sort(key=_get_num_params)\n\n        return list(od.values())", "response": "Groups the models in the related cache entries into a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_numeric(obj):\n    try:\n        obj+obj, obj-obj, obj*obj, obj**obj, obj/obj\n    except ZeroDivisionError:\n        return True\n    except Exception:\n        return False\n    else:\n        return True", "response": "This function detects whether an input object is numeric or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngeneralising logarithm of a number", "response": "def glog(x,l = 2):\n    \"\"\"\n    Generalised logarithm\n\n    :param x: number\n    :param p: number added befor logarithm \n\n    \"\"\"\n    return np.log((x+np.sqrt(x**2+l**2))/2)/np.log(l)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts floats to int when only float is not enough.", "response": "def float2int(x):\n    \"\"\"\n    converts floats to int when only float() is not enough.\n\n    :param x: float\n    \"\"\"\n    if not pd.isnull(x):\n        if is_numeric(x):\n            x=int(x)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating mathmatical expressions. Syntax: {command} <expression>", "response": "def cmd(send, msg, args):\n    \"\"\"Evaluates mathmatical expressions.\n\n    Syntax: {command} <expression>\n\n    \"\"\"\n    if not msg:\n        send(\"Calculate what?\")\n        return\n\n    if \"!\" in msg:\n        args['do_kick'](args['target'], args['nick'], \"hacking\")\n        return\n\n    msg += '\\n'\n    proc = subprocess.Popen(['dc'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n    try:\n        output = proc.communicate(msg, timeout=5)[0].splitlines()\n    except subprocess.TimeoutExpired:\n        proc.terminate()\n        send(\"Execution took too long, you might have better luck with WolframAlpha.\")\n        return\n    if not output:\n        send(\"No output found, did you forget to specify 'p'?\")\n    elif len(output) > 3:\n        send(\"Your output is too long, have you tried mental math?\")\n    else:\n        for line in output:\n            send(line)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling scores. If it's a ++ add one point unless the user is trying to promote themselves. Otherwise substract one point.", "response": "def handle(send, msg, args):\n    \"\"\"Handles scores.\n\n    If it's a ++ add one point unless the user is trying to promote\n    themselves. Otherwise substract one point.\n\n    \"\"\"\n    session = args['db']\n    matches = re.findall(r\"\\b(?<!-)(%s{2,16})(\\+\\+|--)\" % args['config']['core']['nickregex'], msg)\n    if not matches:\n        return\n    if args['type'] == 'privmsg':\n        send('Hey, no points in private messages!')\n        return\n    for match in matches:\n        # limit to 5 score changes per minute\n        if args['abuse'](args['nick'], 5, 'scores'):\n            return\n        name, direction = match[0].lower(), match[1]\n        if direction == \"++\":\n            score = 1\n            if name == args['nick'].lower():\n                send(\"%s: No self promotion! You lose 10 points.\" % args['nick'])\n                score = -10\n        else:\n            score = -1\n        row = session.query(Scores).filter(Scores.nick == name).first()\n        if row is None:\n            session.add(Scores(score=score, nick=name))\n            session.commit()\n        else:\n            row.score += score\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing several XKCD comics.", "response": "def handle(send, msg, args):\n    \"\"\"Implements several XKCD comics.\"\"\"\n    output = textutils.gen_xkcd_sub(msg, True)\n    if output is None:\n        return\n    if args['type'] == 'action':\n        send(\"correction: * %s %s\" % (args['nick'], output))\n    else:\n        send(\"%s actually meant: %s\" % (args['nick'], output))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the mean samples per class in the cluster.", "response": "def calculate_mean_vectors(X, y):\n    \"\"\"Calculates the mean samples per class\n    \n    Parameters:\n    -----------\n    X : array-like, shape (m, n) - the samples\n    y : array-like, shape (m, ) - the class labels\n    \n    Returns:\n    --------\n    mean_vectors : array-like, shape (k, )\n    Those are the mean samples from each k classes.\n    \n    \"\"\"\n\n    return [np.mean(X[y == cl, :], axis=0) for cl in np.unique(y)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_within_class_scatter_matrix(X, y):\n\n    mean_vectors = calculate_mean_vectors(X, y)\n    n_features = X.shape[1]\n    Sw = np.zeros((n_features, n_features))\n\n    for cl, m in zip(np.unique(y), mean_vectors):\n        Si = np.zeros((n_features, n_features))\n        m = m.reshape(n_features, 1)\n\n        for x in X[y == cl, :]:\n            v = x.reshape(n_features, 1) - m\n            Si += v @ v.T\n        Sw += Si\n\n    return Sw", "response": "Calculates the Within - Class Scatter matrix within the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the Between - Class Scatter matrix.", "response": "def calculate_between_class_scatter_matrix(X, y):\n    \"\"\"Calculates the Between-Class Scatter matrix\n    \n    Parameters:\n    -----------\n    X : array-like, shape (m, n) - the samples\n    y : array-like, shape (m, ) - the class labels\n\n    Returns:\n    --------\n    between_class_scatter_matrix : array-like, shape (n, n)\n    \n    \"\"\"\n\n    mean_vectors = calculate_mean_vectors(X, y)\n    n_features = X.shape[1]\n    Sb = np.zeros((n_features, n_features))\n    m = np.mean(X, axis=0).reshape(n_features, 1)\n\n    for cl, m_i in zip(np.unique(y), mean_vectors):\n        v = m_i.reshape(n_features, 1) - m\n        Sb += X[y == cl, :].shape[0] * v @ v.T\n\n    return Sb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the variance - covariance matrix for the current node.", "response": "def calculate_covariance_matrix(X):\n    \"\"\"Calculates the Variance-Covariance matrix\n    \n    Parameters:\n    -----------\n    X : array-like, shape (m, n) - the data\n    \n    Returns:\n    --------\n    variance_covariance_matrix : array-like, shape(n, n)\n    \n    \"\"\"\n\n    n_features = X.shape[1]    \n    S = np.zeros((n_features, n_features))\n    m = np.mean(X, axis=0).reshape(n_features, 1)\n\n    for x in X:\n        v = x.reshape(n_features, 1) - m\n        S += v @ v.T\n\n    return 1/(X.shape[0]-1) * S"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrim a string from the alphabetical order of the words in a node.", "response": "def trim(s, prefix=None, suffix=None, strict=False):\n    \"\"\"Trim a string, removing given prefix or suffix.\n\n    :param s: String to trim\n    :param prefix: Prefix to remove from ``s``\n    :param suffix: Suffix to remove from ``s``\n    :param strict: Whether the prefix or suffix must be present in ``s``.\n                   By default, if the infix is not found, function will simply\n                   return the string passed.\n\n    Either ``prefix`` or ``suffix`` must be provided, but not both\n    (which would be ambiguous as to what to remove first).\n\n    :raise ValueError: If ``strict`` is True and required prefix or suffix\n                       was not found\n\n    Examples::\n\n        trim('foobar', prefix='foo')  # 'bar'\n        trim('foobar', suffix='bar')  # 'foo'\n        trim('foobar', prefix='baz', strict=True)  # exception\n\n    .. versionadded:: 0.0.4\n    \"\"\"\n    ensure_string(s)\n\n    has_prefix = prefix is not None\n    has_suffix = suffix is not None\n    if has_prefix == has_suffix:\n        raise ValueError(\n            \"exactly one of either prefix or suffix must be provided\")\n\n    if has_prefix:\n        ensure_string(prefix)\n        if s.startswith(prefix):\n            return s[len(prefix):]\n        elif strict:\n            raise ValueError(\n                \"string %r does not start with expected prefix %r\" % (\n                    s, prefix))\n\n    if has_suffix:\n        ensure_string(suffix)\n        if s.endswith(suffix):\n            return s[:-len(suffix)] if suffix else s\n        elif strict:\n            raise ValueError(\n                \"string %r does not end with expected suffix %r\" % (\n                    s, suffix))\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit a string into a list of words.", "response": "def split(s, by=None, maxsplit=None):\n    \"\"\"Split a string based on given delimiter(s).\n    Delimiters can be either strings or compiled regular expression objects.\n\n    :param s: String to split\n    :param by: A delimiter, or iterable thereof.\n    :param maxsplit: Maximum number of splits to perform.\n                     ``None`` means no limit,\n                     while 0 does not perform a split at all.\n\n    :return: List of words in the string ``s``\n             that were separated by delimiter(s)\n\n    :raise ValueError: If the separator is an empty string or regex\n    \"\"\"\n    ensure_string(s)\n\n    # TODO(xion): Consider introducing a case for ``split('')``\n    # to make it return ``['']`` rather than default ``[]`` thru ``str.split``.\n    # It's the so-called \"whitespace split\" that normally eliminates\n    # empty strings from result. However, ``split(s)`` for any other ``s``\n    # always returns ``[s]`` so these two approaches are at odds here.\n    # (Possibly refer to split functions in other languages for comparison).\n\n    # string delimiter are handled by appropriate standard function\n    if by is None or is_string(by):\n        return s.split(by) if maxsplit is None else s.split(by, maxsplit)\n\n    # regex delimiters have certain special cases handled explicitly below,\n    # so that we do the same things that ``str.split`` does\n    if is_regex(by):\n        if not by.pattern:\n            return s.split('')  # will fail with proper exception & message\n        if maxsplit == 0:\n            return [s]\n        return by.split(s, maxsplit=maxsplit or 0)\n\n    # multiple delimiters are handled by regex that matches them all\n    if is_iterable(by):\n        if not by:\n            raise ValueError(\"empty separator list\")\n        by = list(imap(ensure_string, by))\n        if not s:\n            return ['']  # quickly eliminate trivial case\n        or_ = s.__class__('|')\n        regex = join(or_, imap(re.escape, by))\n        return split(s, by=re.compile(regex), maxsplit=maxsplit)\n\n    raise TypeError(\"invalid separator\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join(delimiter, iterable, **kwargs):\n    ensure_string(delimiter)\n    ensure_iterable(iterable)\n\n    ensure_keyword_args(kwargs, optional=('errors', 'with_'))\n    errors = kwargs.get('errors', True)\n\n    if errors in ('raise', True):\n        iterable = imap(ensure_string, iterable)\n    elif errors in ('ignore', None):\n        iterable = ifilter(is_string, iterable)\n    elif errors in ('cast', False):\n        iterable = imap(delimiter.__class__, iterable)\n    elif errors == 'replace':\n        if 'with_' not in kwargs:\n            raise ValueError(\"'replace' error policy requires specifying \"\n                             \"replacement through with_=\")\n\n        with_ = kwargs['with_']\n        if is_string(with_):\n            replacement = lambda x: with_\n        elif callable(with_):\n            replacement = with_\n        else:\n            raise TypeError(\"error replacement must be a string or function, \"\n                            \"got %s\" % type(with_).__name__)\n\n        iterable = (x if is_string(x) else ensure_string(replacement(x))\n                    for x in iterable)\n    else:\n        raise TypeError(\n            \"%r is not a valid error handling policy for join()\" % (errors,))\n\n    return delimiter.join(iterable)", "response": "Returns a string which is a concatenation of strings in iterable separated by given delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting given text with whitespaces between words into equivalent camel - cased one.", "response": "def camel_case(arg, capitalize=None):\n    \"\"\"Converts given text with whitespaces between words\n    into equivalent camel-cased one.\n\n    :param capitalize: Whether result will have first letter upper case (True),\n                       lower case (False), or left as is (None, default).\n\n    :return: String turned into camel-case \"equivalent\"\n    \"\"\"\n    ensure_string(arg)\n    if not arg:\n        return arg\n\n    words = split(arg)\n    first_word = words[0] if len(words) > 0 else None\n\n    words = [word.capitalize() for word in words]\n    if first_word is not None:\n        if capitalize is True:\n            first_word = first_word.capitalize()\n        elif capitalize is False:\n            first_word = first_word[0].lower() + first_word[1:]\n        words[0] = first_word\n\n    return join(arg.__class__(), words)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace(needle, with_=None, in_=None):\n    if needle is None:\n        raise TypeError(\"replacement needle cannot be None\")\n    if not needle:\n        raise ValueError(\"replacement needle cannot be empty\")\n\n    if is_string(needle):\n        replacer = Replacer((needle,))\n    else:\n        ensure_iterable(needle)\n        if not is_mapping(needle):\n            if all(imap(is_pair, needle)):\n                needle = dict(needle)\n            elif not all(imap(is_string, needle)):\n                raise TypeError(\"invalid replacement needle\")\n        replacer = Replacer(needle)\n\n    if with_ is not None:\n        ensure_string(with_)\n        replacer = replacer.with_(with_)\n\n    if in_ is not None:\n        ensure_string(in_)\n        return replacer.in_(in_)\n\n    return replacer", "response": "Replaces occurrences of string with other string in a base string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random(length, chars=None):\n    if chars is None:\n        chars = string.ascii_letters + string.digits\n    else:\n        ensure_string(chars)\n        if not chars:\n            raise ValueError(\"character set must not be empty\")\n\n    if is_pair(length):\n        length = randint(*length)\n    elif isinstance(length, Integral):\n        if not length > 0:\n            raise ValueError(\n                \"random string length must be positive (got %r)\" % (length,))\n    else:\n        raise TypeError(\"random string length must be an integer; \"\n                        \"got '%s'\" % type(length).__name__)\n\n    return join(chars.__class__(), (choice(chars) for _ in xrange(length)))", "response": "Generates a random string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef with_(self, replacement):\n        ensure_string(replacement)\n        if is_mapping(self._replacements):\n            raise ReplacementError(\"string replacements already provided\")\n\n        self._replacements = dict.fromkeys(self._replacements, replacement)\n        return self", "response": "Provide replacement for string needles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform replacement in given string.", "response": "def in_(self, haystack):\n        \"\"\"Perform replacement in given string.\n\n        :param haystack: String to perform replacements in\n\n        :return: ``haystack`` after the replacements\n\n        :raise TypeError: If ``haystack`` if not a string\n        :raise ReplacementError: If no replacement(s) have been provided yet\n        \"\"\"\n        from taipan.collections import dicts\n\n        ensure_string(haystack)\n        if not is_mapping(self._replacements):\n            raise ReplacementError(\"string replacements not provided\")\n\n        # handle special cases\n        if not self._replacements:\n            return haystack\n        if len(self._replacements) == 1:\n            return haystack.replace(*dicts.peekitem(self._replacements))\n\n        # construct a regex matching any of the needles in the order\n        # of descending length (to prevent issues if they contain each other)\n        or_ = haystack.__class__('|')\n        regex = join(or_, imap(\n            re.escape, sorted(self._replacements, key=len, reverse=True)))\n\n        # do the substituion, looking up the replacement for every match\n        do_replace = lambda match: self._replacements[match.group()]\n        return re.sub(regex, do_replace, haystack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure_exists(p, assume_dirs=False):\n    if path(p).ext and not assume_dirs:\n        path(p).dirname().makedirs_p()\n    else:\n        path(p).makedirs_p()\n    return p", "response": "Ensures a given path p * exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap_list(item):\n    if item is None:\n        return []\n    elif isinstance(item, list):\n        return item\n    elif isinstance(item, (tuple, set)):\n        return list(item)\n    else:\n        return [item]", "response": "Returns an object as a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef diff_dir(dir_cmp, left_path=True):\n    for name in dir_cmp.diff_files:\n        if left_path:\n            path_root = dir_cmp.left\n        else:\n            path_root = dir_cmp.right\n        yield path.joinpath(path_root, name)\n    for sub in dir_cmp.subdirs.values():\n        # Need to iterate over the recursive call to make sure the individual values are yielded up the stack\n        for the_dir in diff_dir(sub, left_path):\n            yield the_dir", "response": "A generator that yields the paths to all files that are different from the dir_cmp object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the specified parameters for the current preprocessor.", "response": "def get_params(self, *keys):\n        \"\"\"Returns the specified parameters for the current preprocessor.\n\n        Parameters:\n        -----------\n        keys : variable sized list, containing the names of the requested parameters\n\n        Returns:\n        --------\n        values : list or dictionary, if any `keys` are specified\n        those named parameters' values are returned, otherwise\n        all parameters are returned as a dictionary\n        \n        \"\"\"\n\n        if len(keys) == 0:\n            return vars(self)\n        else:\n            return [vars(self)[k] for k in keys]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset new values to the specified parameters.", "response": "def set_params(self, **params):\n        \"\"\"Sets new values to the specified parameters.\n        \n        Parameters:\n        -----------\n        params : variable sized dictionary, n key-word arguments\n        Example:\n        ```\n        scaler.set_params(std=0.30)\n        ```\n        \n        Returns:\n        --------\n        void : void, returns nothing\n        \n        \"\"\"\n\n        for k, v in params.items():\n            vars(self)[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlook for simple one - line regex searches common across dataset types.", "response": "def _import_single_searches(self):\n        \"\"\"\n        Look for simple one-line regex searches common across dataset types.\n\n        If failed, then return -999.\n\n        AIC is only handled in this method for dichotomous continuous and\n        exponential and handled via separate methods.\n        \"\"\"\n        searches = {\n            # (?<!Setting ) is a special case for preventing\n            # \"Setting BMD = 100*(maximum dose)\" matches\n            \"BMD\": r\"(?<!Setting )BMD = +(%s)\" % self.re_num,\n            \"BMDL\": r\"BMDL = +(%s)\" % self.re_num,\n            \"BMDU\": r\"BMDU = +(%s)\" % self.re_num,\n            \"CSF\": r\"Cancer Slope Factor = +(%s)\" % self.re_num,\n            \"AIC\": r\"AIC: +(%s)\" % (self.re_num),\n            \"model_version\": r\"Version: ([\\d\\.]+);\",\n            \"model_date\": r\"Date: ([\\d/]+)\",\n        }\n        for search in searches:\n            m = re.search(searches[search], self.output_text)\n            if m:\n                try:\n                    self.output[search] = float(m.group(1))\n                except:\n                    self.output[search] = m.group(1)\n            else:\n                self.output[search] = -999"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _import_warnings(self):\n        warnings = (\n            r\"Warning: BMDL computation is at best imprecise for these data\",\n            r\"THE MODEL HAS PROBABLY NOT CONVERGED!!!\",\n            \"THIS USUALLY MEANS THE MODEL HAS NOT CONVERGED!\",\n            r\"BMR value is not in the range of the mean function\",\n            r\"BMD = 100\\*\\(maximum dose\\)\",\n            r\"BMDL computation failed\\.\",\n            \"Warning:  optimum may not have been found.  Bad completion code in Optimization routine.\",  # noqa\n            \"Warning: Likelihood for fitted model larger than the Likelihood for model A3.\",  # noqa\n        )\n        self.output[\"warnings\"] = []\n        for warning in warnings:\n            m = re.search(warning, self.output_text)\n            if m:\n                self.output[\"warnings\"].append(m.group())", "response": "Imports custom warnings from the output text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _import_dich_vals(self):\n        m = re.search(\n            r\"Chi\\^2 = ({0}|\\w+) +d.f. = +({0}|\\w+) +P-value = +({0}|\\w+)\".format(\n                self.re_num\n            ),  # noqa\n            self.output_text,\n        )\n        cw = {1: \"Chi2\", 2: \"df\", 3: \"p_value4\"}\n        for val in cw:\n            try:\n                self.output[cw[val]] = float(m.group(val))\n            except:\n                self.output[cw[val]] = -999", "response": "Import simple dichotomous values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning decorator to turn another function into a transformation.", "response": "def transformation(func):\n    \"\"\"Function decorator to turn another function into a transformation.\"\"\"\n    @wraps(func)\n    def func_as_transformation(*args, **kwargs):\n        \n        # When using transforms that return new ndarrays we lose the\n        # jicimagelib.image.Image type and the history of the image.\n        # One therefore needs to:\n        #  - Extract the history from the input jicimagelib.image.Image.\n        #  - Apply the transformation, which may return a numpy ndarray.\n        #  - Force the image to the jicimagelib.image.Image type.\n        #  - Re-attach the extracted history\n        if hasattr(args[0], 'history'):\n            # Working on jicimagelib.Image.\n            history = args[0].history\n        else:\n            # Working on something without a history, e.g. a ndarray stack.\n            history = []\n        image = func(*args, **kwargs)\n        image = Image.from_array(image, log_in_history=False)\n        image.history = history\n\n        image.history.append('Applied {} transform'.format(func.__name__))\n        if AutoWrite.on:\n            fpath = AutoName.name(func)\n            try:\n                if AutoWrite.auto_safe_dtype:\n                    safe_range_im = 255 * normalise(image)\n                    pil_im = PIL.Image.fromarray(safe_range_im.astype(np.uint8))\n                else:\n                    pil_im = PIL.Image.fromarray(image)\n            except TypeError:\n                # Give a more meaningful error message.\n                raise(TypeError(\n                    \"Cannot handle this data type: {}\".format(image.dtype)))\n            pil_im.save(fpath)\n        return image\n    return func_as_transformation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef smooth_gaussian(image, sigma=1):\n    return scipy.ndimage.filters.gaussian_filter(image, sigma=sigma, mode=\"nearest\")", "response": "Returns Gaussian smoothed image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef equalize_adaptive_clahe(image, ntiles=8, clip_limit=0.01):\n    # Convert input for skimage.\n    skimage_float_im = normalise(image)\n    \n    if np.all(skimage_float_im):\n        raise(RuntimeError(\"Cannot equalise when there is no variation.\"))\n    \n    normalised = skimage.exposure.equalize_adapthist(skimage_float_im,\n        ntiles_x=ntiles, ntiles_y=ntiles, clip_limit=clip_limit)\n\n    assert np.max(normalised) == 1.0\n    assert np.min(normalised) == 0.0\n\n    return normalised", "response": "Return contrast limited adaptive histogram equalized image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning image thresholded using Otsu s method.", "response": "def threshold_otsu(image, multiplier=1.0):\n    \"\"\"Return image thresholded using Otsu's method.\n    \"\"\"\n    otsu_value = skimage.filters.threshold_otsu(image)\n    return image > otsu_value * multiplier"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('action', choices=['check', 'master', 'commit'], nargs='?')\n\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    api_output = get('https://api.github.com/repos/%s/branches/master' % args['config']['api']['githubrepo']).json()\n    commit, version = misc.get_version(args['handler'].confdir)\n    if not cmdargs.action:\n        send(version)\n        return\n    if cmdargs.action == 'master':\n        send(api_output['commit']['sha'])\n    elif cmdargs.action == 'check':\n        if commit is None:\n            send(\"Not running from git, version %s\" % version)\n        else:\n            check = 'Same' if api_output['commit']['sha'] == commit else 'Different'\n            send(check)\n    elif cmdargs.action == 'commit':\n        if commit is None:\n            send(\"Not running from git, version %s\" % version)\n        else:\n            send(commit)", "response": "Check the git revison."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, _, args):\n    send(\"%s! %s\" % (args['name'].upper(), random.choice(squirrels)))", "response": "Ships a product.\n\n    Syntax: {command}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the KML file representation of the raster in the specified table.", "response": "def getAsKmlGrid(self, tableName, rasterId=1, rasterIdFieldName='id', rasterFieldName='raster', documentName='default', alpha=1.0, noDataValue=0, discreet=False):\n        \"\"\"\n        Creates a KML file with each cell in the raster represented by a polygon. The result is a vector grid representation of the raster.\n        Note that pixels with values between -1 and 0 are omitted as no data values. Also note that this method only works on the first band.\n        Returns the kml document as a string.\n        \"\"\"\n        # Validate alpha\n        if not (alpha >= 0 and alpha <= 1.0):\n            raise ValueError(\"RASTER CONVERSION ERROR: alpha must be between 0.0 and 1.0.\")\n\n        # Get the color ramp and parameters\n        minValue, maxValue = self.getMinMaxOfRasters(session=self._session,\n                                                     table=tableName,\n                                                     rasterIds=(str(rasterId), ),\n                                                     rasterIdField=rasterIdFieldName,\n                                                     rasterField=rasterFieldName,\n                                                     noDataValue=noDataValue)\n\n        mappedColorRamp = ColorRampGenerator.mapColorRampToValues(colorRamp=self._colorRamp,\n                                                                  minValue=minValue,\n                                                                  maxValue=maxValue,\n                                                                  alpha=alpha)\n\n        # Get polygons for each cell in kml format\n        statement = '''\n                    SELECT x, y, val, ST_AsKML(geom) AS polygon\n                    FROM (\n                    SELECT (ST_PixelAsPolygons(%s)).*\n                    FROM %s WHERE %s=%s\n                    ) AS foo\n                    ORDER BY val;\n                    ''' % (rasterFieldName, tableName, rasterIdFieldName, rasterId)\n\n        result = self._session.execute(statement)\n\n        # Initialize KML Document\n        kml = ET.Element('kml', xmlns='http://www.opengis.net/kml/2.2')\n        document = ET.SubElement(kml, 'Document')\n        docName = ET.SubElement(document, 'name')\n        docName.text = documentName\n\n        groupValue = -9999999.0\n        uniqueValues = []\n\n        # Add polygons to the kml file with styling\n        for row in result:\n            # Value will be None if it is a no data value\n            if row.val:\n                value = float(row.val)\n            else:\n                value = None\n\n            polygonString = row.polygon\n            i = int(row.x)\n            j = int(row.y)\n\n            # Only create placemarks for values that are no data values\n            if value:\n                # Collect unique values\n                if value not in uniqueValues:\n                    uniqueValues.append(value)\n\n                # Create a new placemark for each group of values\n                if value != groupValue:\n                    placemark = ET.SubElement(document, 'Placemark')\n                    placemarkName = ET.SubElement(placemark, 'name')\n                    placemarkName.text = str(value)\n\n                    # Create style tag and setup styles\n                    style = ET.SubElement(placemark, 'Style')\n\n                    # Set polygon line style\n                    lineStyle = ET.SubElement(style, 'LineStyle')\n\n                    # Set polygon line color and width\n                    lineColor = ET.SubElement(lineStyle, 'color')\n                    lineColor.text = self.LINE_COLOR\n                    lineWidth = ET.SubElement(lineStyle, 'width')\n                    lineWidth.text = str(self.LINE_WIDTH)\n\n                    # Set polygon fill color\n                    polyStyle = ET.SubElement(style, 'PolyStyle')\n                    polyColor = ET.SubElement(polyStyle, 'color')\n\n                    # Convert alpha from 0.0-1.0 decimal to 00-FF string\n                    integerAlpha = mappedColorRamp.getAlphaAsInteger()\n\n                    # Get RGB color from color ramp and convert to KML hex ABGR string with alpha\n                    integerRGB = mappedColorRamp.getColorForValue(value)\n                    hexABGR = '%02X%02X%02X%02X' % (integerAlpha,\n                                                    integerRGB[mappedColorRamp.B],\n                                                    integerRGB[mappedColorRamp.G],\n                                                    integerRGB[mappedColorRamp.R])\n\n                    # Set the polygon fill alpha and color\n                    polyColor.text = hexABGR\n\n                    # Create multigeometry tag\n                    multigeometry = ET.SubElement(placemark, 'MultiGeometry')\n\n                    # Create the data tag\n                    extendedData = ET.SubElement(placemark, 'ExtendedData')\n\n                    # Add value to data\n                    valueData = ET.SubElement(extendedData, 'Data', name='value')\n                    valueValue = ET.SubElement(valueData, 'value')\n                    valueValue.text = str(value)\n\n                    iData = ET.SubElement(extendedData, 'Data', name='i')\n                    valueI = ET.SubElement(iData, 'value')\n                    valueI.text = str(i)\n\n                    jData = ET.SubElement(extendedData, 'Data', name='j')\n                    valueJ = ET.SubElement(jData, 'value')\n                    valueJ.text = str(j)\n\n                    groupValue = value\n\n                # Get polygon object from kml string and append to the current multigeometry group\n                polygon = ET.fromstring(polygonString)\n                multigeometry.append(polygon)\n\n        if not discreet:\n            # Embed the color ramp in SLD format\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsContinuousSLD()))\n        else:\n            # Sort the unique values\n            uniqueValues.sort()\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsDiscreetSLD(uniqueValues)))\n\n        return ET.tostring(kml)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a KML wrapper and PNG representation of the raster.", "response": "def getAsKmlPng(self, tableName, rasterId=1, rasterIdFieldName='id', rasterFieldName='raster', documentName='default',\n                    alpha=1.0,  drawOrder=0, noDataValue=0, cellSize=None, resampleMethod='NearestNeighbour', discreet=False):\n        \"\"\"\n        Creates a KML wrapper and PNG represent of the raster. Returns a string of the kml file contents and\n        a binary string of the PNG contents. The color ramp used to generate the PNG is embedded in the ExtendedData\n        tag of the GroundOverlay.\n        IMPORTANT: The PNG image is referenced in the kml as 'raster.png', thus it must be written to file with that\n        name for the kml to recognize it.\n        \"\"\"\n\n        # Get the color ramp and parameters\n        minValue, maxValue = self.getMinMaxOfRasters(session=self._session,\n                                                     table=tableName,\n                                                     rasterIds=(str(rasterId), ),\n                                                     rasterIdField=rasterIdFieldName,\n                                                     rasterField=rasterFieldName,\n                                                     noDataValue=noDataValue)\n\n        mappedColorRamp = ColorRampGenerator.mapColorRampToValues(colorRamp=self._colorRamp,\n                                                                  minValue=minValue,\n                                                                  maxValue=maxValue,\n                                                                  alpha=alpha)\n\n        # Join strings in list to create ramp\n        rampString = mappedColorRamp.getPostGisColorRampString()\n\n        # Get a PNG representation of the raster\n        result = self.getRastersAsPngs(session=self._session,\n                                       tableName=tableName,\n                                       rasterIds=(str(rasterId),),\n                                       postGisRampString=rampString,\n                                       rasterField=rasterFieldName,\n                                       rasterIdField=rasterIdFieldName,\n                                       cellSize=cellSize,\n                                       resampleMethod=resampleMethod)\n\n        for row in result:\n            binaryPNG = row.png\n\n        # Determine extents for the KML wrapper file via query\n        statement = '''\n                    SELECT (foo.metadata).*\n                    FROM (\n                    SELECT ST_MetaData(ST_Transform({0}, 4326, 'Bilinear')) as metadata\n                    FROM {1}\n                    WHERE {2}={3}\n                    ) As foo;\n                    '''.format(rasterFieldName, tableName, rasterIdFieldName, rasterId)\n\n        result = self._session.execute(statement)\n\n        for row in result:\n            upperLeftY = row.upperlefty\n            scaleY = row.scaley\n            height = row.height\n\n            upperLeftX = row.upperleftx\n            scaleX = row.scalex\n            width = row.width\n\n        north = upperLeftY\n        south = upperLeftY + (scaleY * height)\n        east = upperLeftX + (scaleX * width)\n        west = upperLeftX\n\n        # Initialize KML Document\n        kml = ET.Element('kml', xmlns='http://www.opengis.net/kml/2.2')\n        document = ET.SubElement(kml, 'Document')\n        docName = ET.SubElement(document, 'name')\n        docName.text = documentName\n\n\n        # GroundOverlay\n        groundOverlay = ET.SubElement(document, 'GroundOverlay')\n        overlayName = ET.SubElement(groundOverlay, 'name')\n        overlayName.text = 'Overlay'\n\n        # DrawOrder\n        drawOrderElement = ET.SubElement(groundOverlay, 'drawOrder')\n        drawOrderElement.text = str(drawOrder)\n\n        # Define Region\n        regionElement = ET.SubElement(groundOverlay, 'Region')\n        latLonBox = ET.SubElement(regionElement, 'LatLonBox')\n\n        northElement = ET.SubElement(latLonBox, 'north')\n        northElement.text = str(north)\n\n        southElement = ET.SubElement(latLonBox, 'south')\n        southElement.text = str(south)\n\n        eastElement = ET.SubElement(latLonBox, 'east')\n        eastElement.text = str(east)\n\n        westElement = ET.SubElement(latLonBox, 'west')\n        westElement.text = str(west)\n\n\n        # Href to PNG\n        iconElement = ET.SubElement(groundOverlay, 'Icon')\n        hrefElement = ET.SubElement(iconElement, 'href')\n        hrefElement.text = 'raster.png'\n\n        # LatLonBox\n        latLonBox = ET.SubElement(groundOverlay, 'LatLonBox')\n\n        northElement = ET.SubElement(latLonBox, 'north')\n        northElement.text = str(north)\n\n        southElement = ET.SubElement(latLonBox, 'south')\n        southElement.text = str(south)\n\n        eastElement = ET.SubElement(latLonBox, 'east')\n        eastElement.text = str(east)\n\n        westElement = ET.SubElement(latLonBox, 'west')\n        westElement.text = str(west)\n\n        if not discreet:\n            # Embed the color ramp in SLD format\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsContinuousSLD()))\n        else:\n            # Determine values for discreet color ramp\n            statement = '''\n                        SELECT (pvc).*\n                        FROM (\n                              SELECT ST_ValueCount({0}) as pvc\n                              FROM {1}\n                              WHERE {2}={3}\n                             ) As foo\n                        ORDER BY (pvc).value;\n                        '''.format(rasterFieldName, tableName, rasterIdFieldName, rasterId)\n\n            result = self._session.execute(statement)\n\n            values = []\n            for row in result:\n                values.append(row.value)\n\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsDiscreetSLD(values)))\n\n        return ET.tostring(kml), binaryPNG"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sequence of rasters with timestamps as a kml grid animation.", "response": "def getAsKmlGridAnimation(self, tableName, timeStampedRasters=[], rasterIdFieldName='id', rasterFieldName='raster',\n                              documentName='default', alpha=1.0,  noDataValue=0, discreet=False):\n        \"\"\"\n        Return a sequence of rasters with timestamps as a kml with time markers for animation.\n\n        :param tableName: Name of the table to extract rasters from\n        :param timeStampedRasters: List of dictionaries with keys: rasterId, dateTime\n               rasterId = a unique integer identifier used to locate the raster (usually value of primary key column)\n               dateTime = a datetime object representing the time the raster occurs\n\n               e.g:\n               timeStampedRasters = [{ 'rasterId': 1, 'dateTime': datetime(1970, 1, 1)},\n                                     { 'rasterId': 2, 'dateTime': datetime(1970, 1, 2)},\n                                     { 'rasterId': 3, 'dateTime': datetime(1970, 1, 3)}]\n\n        :param rasterIdFieldName: Name of the id field for rasters (usually the primary key field)\n        :param rasterFieldName: Name of the field where rasters are stored (of type raster)\n        :param documentName: The name to give to the KML document (will be listed in legend under this name)\n        :param alpha: The transparency to apply to each raster cell\n        :param noDataValue: The value to be used as the no data value (default is 0)\n\n        :rtype : string\n        \"\"\"\n\n        # Validate alpha\n        if not (alpha >= 0 and alpha <= 1.0):\n            raise ValueError(\"RASTER CONVERSION ERROR: alpha must be between 0.0 and 1.0.\")\n\n        rasterIds = []\n\n        for timeStampedRaster in timeStampedRasters:\n            # Validate dictionary\n            if 'rasterId' not in timeStampedRaster:\n                raise ValueError('RASTER CONVERSION ERROR: rasterId must be provided for each raster.')\n            elif 'dateTime' not in timeStampedRaster:\n                raise ValueError('RASTER CONVERSION ERROR: dateTime must be provided for each raster.')\n\n            rasterIds.append(str(timeStampedRaster['rasterId']))\n\n        # One color ramp to rule them all\n        # Get a single color ramp that is based on the range of values in all the rasters\n        minValue, maxValue = self.getMinMaxOfRasters(session=self._session,\n                                                     table=tableName,\n                                                     rasterIds=rasterIds,\n                                                     rasterIdField=rasterIdFieldName,\n                                                     rasterField=rasterFieldName,\n                                                     noDataValue=noDataValue)\n\n        mappedColorRamp = ColorRampGenerator.mapColorRampToValues(colorRamp=self._colorRamp,\n                                                                  minValue=minValue,\n                                                                  maxValue=maxValue,\n                                                                  alpha=alpha)\n\n\n\n        # Default to time delta to None\n        deltaTime = None\n\n        # Calculate delta time between images if more than one\n        time1 = timeStampedRasters[0]['dateTime']\n\n        if len(timeStampedRasters) >= 2:\n            time2 = timeStampedRasters[1]['dateTime']\n            deltaTime = time2 - time1\n\n        # Initialize KML Document\n        kml = ET.Element('kml', xmlns='http://www.opengis.net/kml/2.2')\n        document = ET.SubElement(kml, 'Document')\n        docName = ET.SubElement(document, 'name')\n        docName.text = documentName\n\n        if not discreet:\n            # Embed the color ramp in SLD format\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsContinuousSLD()))\n        else:\n            values = []\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsDiscreetSLD(values)))\n\n        # Apply special style to hide legend items\n        style = ET.SubElement(document, 'Style', id='check-hide-children')\n        listStyle = ET.SubElement(style, 'ListStyle')\n        listItemType = ET.SubElement(listStyle, 'listItemType')\n        listItemType.text = 'checkHideChildren'\n        styleUrl = ET.SubElement(document, 'styleUrl')\n        styleUrl.text = '#check-hide-children'\n\n        # Collect unique values\n        uniqueValues = []\n\n        # Retrieve the rasters and styles\n        for timeStampedRaster in timeStampedRasters:\n            # Extract variables\n            rasterId = timeStampedRaster['rasterId']\n\n            if deltaTime:\n                dateTime = timeStampedRaster['dateTime']\n                prevDateTime = dateTime - deltaTime\n\n            # Get polygons for each cell in kml format\n            statement = '''\n                        SELECT x, y, val, ST_AsKML(geom) AS polygon\n                        FROM (\n                        SELECT (ST_PixelAsPolygons({0})).*\n                        FROM {1} WHERE {2}={3}\n                        ) AS foo\n                        ORDER BY val;\n                        '''.format(rasterFieldName, tableName, rasterIdFieldName, rasterId)\n\n            result = self._session.execute(statement)\n\n            # Set initial group value\n            groupValue = -9999999.0\n\n            # Add polygons to the kml file with styling\n            for row in result:\n                # Value will be None if it is a no data value\n                if row.val:\n                    value = float(row.val)\n                else:\n                    value = None\n\n                polygonString = row.polygon\n                i = int(row.x)\n                j = int(row.y)\n\n                # Only create placemarks for values that are not no data values\n                if value:\n                    if value not in uniqueValues:\n                        uniqueValues.append(value)\n\n                    # Create a new placemark for each group of values\n                    if value != groupValue:\n                        placemark = ET.SubElement(document, 'Placemark')\n                        placemarkName = ET.SubElement(placemark, 'name')\n                        placemarkName.text = str(value)\n\n                        # Create style tag and setup styles\n                        style = ET.SubElement(placemark, 'Style')\n\n                        # Set polygon line style\n                        lineStyle = ET.SubElement(style, 'LineStyle')\n\n                        # Set polygon line color and width\n                        lineColor = ET.SubElement(lineStyle, 'color')\n                        lineColor.text = self.LINE_COLOR\n                        lineWidth = ET.SubElement(lineStyle, 'width')\n                        lineWidth.text = str(self.LINE_WIDTH)\n\n                        # Set polygon fill color\n                        polyStyle = ET.SubElement(style, 'PolyStyle')\n                        polyColor = ET.SubElement(polyStyle, 'color')\n\n                        # Convert alpha from 0.0-1.0 decimal to 00-FF string\n                        integerAlpha = mappedColorRamp.getAlphaAsInteger()\n\n                        # Get RGB color from color ramp and convert to KML hex ABGR string with alpha\n                        integerRGB = mappedColorRamp.getColorForValue(value)\n                        hexABGR = '%02X%02X%02X%02X' % (integerAlpha,\n                                                        integerRGB[mappedColorRamp.B],\n                                                        integerRGB[mappedColorRamp.G],\n                                                        integerRGB[mappedColorRamp.R])\n\n                        # Set the polygon fill alpha and color\n                        polyColor.text = hexABGR\n\n                        if deltaTime:\n                            # Create TimeSpan tag\n                            timeSpan = ET.SubElement(placemark, 'TimeSpan')\n\n                            # Create begin and end tags\n                            begin = ET.SubElement(timeSpan, 'begin')\n                            begin.text = prevDateTime.strftime('%Y-%m-%dT%H:%M:%S')\n                            end = ET.SubElement(timeSpan, 'end')\n                            end.text = dateTime.strftime('%Y-%m-%dT%H:%M:%S')\n\n                        # Create multigeometry tag\n                        multigeometry = ET.SubElement(placemark, 'MultiGeometry')\n\n                        # Create the data tag\n                        extendedData = ET.SubElement(placemark, 'ExtendedData')\n\n                        # Add value to data\n                        valueData = ET.SubElement(extendedData, 'Data', name='value')\n                        valueValue = ET.SubElement(valueData, 'value')\n                        valueValue.text = str(value)\n\n                        iData = ET.SubElement(extendedData, 'Data', name='i')\n                        valueI = ET.SubElement(iData, 'value')\n                        valueI.text = str(i)\n\n                        jData = ET.SubElement(extendedData, 'Data', name='j')\n                        valueJ = ET.SubElement(jData, 'value')\n                        valueJ.text = str(j)\n\n                        if deltaTime:\n                            tData = ET.SubElement(extendedData, 'Data', name='t')\n                            valueT = ET.SubElement(tData, 'value')\n                            valueT.text = dateTime.strftime('%Y-%m-%dT%H:%M:%S')\n\n                        groupValue = value\n\n                    # Get polygon object from kml string and append to the current multigeometry group\n                    polygon = ET.fromstring(polygonString)\n                    multigeometry.append(polygon)\n\n        if not discreet:\n            # Embed the color ramp in SLD format\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsContinuousSLD()))\n        else:\n            # Sort the unique values\n            uniqueValues.sort()\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsDiscreetSLD(uniqueValues)))\n\n        return ET.tostring(kml)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAsKmlPngAnimation(self, tableName, timeStampedRasters=[], rasterIdFieldName='id', rasterFieldName='raster',\n                             documentName='default', noDataValue=0, alpha=1.0, drawOrder=0, cellSize=None,\n                             resampleMethod='NearestNeighbour', discreet=False):\n        \"\"\"\n        Return a sequence of rasters with timestamps as a kml with time markers for animation.\n\n        :param tableName: Name of the table to extract rasters from\n        :param timeStampedRasters: List of dictionaries with keys: rasterId, dateTime\n               rasterId = a unique integer identifier used to locate the raster (usually value of primary key column)\n               dateTime = a datetime object representing the time the raster occurs\n\n               e.g:\n               timeStampedRasters = [{ 'rasterId': 1, 'dateTime': datetime(1970, 1, 1)},\n                                     { 'rasterId': 2, 'dateTime': datetime(1970, 1, 2)},\n                                     { 'rasterId': 3, 'dateTime': datetime(1970, 1, 3)}]\n\n        :param rasterIdFieldName: Name of the id field for rasters (usually the primary key field)\n        :param rasterFieldName: Name of the field where rasters are stored (of type raster)\n        :param documentName: The name to give to the KML document (will be listed in legend under this name)\n        :param noDataValue: The value to be used as the no data value (default is 0)\n        :param alpha: The transparency to apply to each raster cell\n        :param drawOrder: The draw order determines the order images are stacked if multiple are showing.\n        :param cellSize: Specify this parameter to resample the rasters to a different size the cells (e.g.: 30 to\n                         resample to cells with dimensions 30 x 30 in units of the raster spatial reference system).\n                         NOTE: the processing time increases exponentially with shrinking cellSize values.\n\n        :rtype : (string, list)\n\n        \"\"\"\n\n\n        if not self.isNumber(noDataValue):\n            raise ValueError('RASTER CONVERSION ERROR: noDataValue must be a number.')\n\n        if not self.isNumber(drawOrder):\n            raise ValueError('RASTER CONVERSION ERROR: drawOrder must be a number.')\n\n        if not (alpha >= 0 and alpha <= 1.0):\n            raise ValueError(\"RASTER CONVERSION ERROR: alpha must be between 0.0 and 1.0.\")\n\n\n        # Extract raster Ids and validate\n        rasterIds = []\n\n        for timeStampedRaster in timeStampedRasters:\n            # Validate dictionary\n            if 'rasterId' not in timeStampedRaster:\n                raise ValueError('RASTER CONVERSION ERROR: rasterId must be provided for each raster.')\n            elif 'dateTime' not in timeStampedRaster:\n                raise ValueError('RASTER CONVERSION ERROR: dateTime must be provided for each raster.')\n\n            rasterIds.append(str(timeStampedRaster['rasterId']))\n\n        # Get the color ramp and parameters\n        minValue, maxValue = self.getMinMaxOfRasters(session=self._session,\n                                                     table=tableName,\n                                                     rasterIds=rasterIds,\n                                                     rasterIdField=rasterIdFieldName,\n                                                     rasterField=rasterFieldName,\n                                                     noDataValue=noDataValue)\n\n        mappedColorRamp = ColorRampGenerator.mapColorRampToValues(colorRamp=self._colorRamp,\n                                                                  minValue=minValue,\n                                                                  maxValue=maxValue,\n                                                                  alpha=alpha)\n\n        # Join strings in list to create ramp\n        rampString = mappedColorRamp.getPostGisColorRampString()\n\n\n        # Get a PNG representation of each raster\n        result = self.getRastersAsPngs(session=self._session,\n                                       tableName=tableName,\n                                       rasterIds=rasterIds,\n                                       postGisRampString=rampString,\n                                       rasterField=rasterFieldName,\n                                       rasterIdField=rasterIdFieldName,\n                                       cellSize=cellSize,\n                                       resampleMethod=resampleMethod)\n\n        binaryPNGs = []\n\n        for row in result:\n            binaryPNGs.append(row.png)\n\n        # Determine extents for the KML wrapper file via query\n        statement = '''\n                    SELECT (foo.metadata).*\n                    FROM (\n                    SELECT ST_MetaData(ST_Transform({0}, 4326, 'Bilinear')) as metadata\n                    FROM {1}\n                    WHERE {2}={3}\n                    ) As foo;\n                    '''.format(rasterFieldName, tableName, rasterIdFieldName, rasterIds[0])\n\n        result = self._session.execute(statement)\n\n        for row in result:\n            upperLeftY = row.upperlefty\n            scaleY = row.scaley\n            height = row.height\n\n            upperLeftX = row.upperleftx\n            scaleX = row.scalex\n            width = row.width\n\n        north = upperLeftY\n        south = upperLeftY + (scaleY * height)\n        east = upperLeftX + (scaleX * width)\n        west = upperLeftX\n\n        # Default to time delta to None\n        deltaTime = None\n\n        # Calculate delta time between images if more than one\n        time1 = timeStampedRasters[0]['dateTime']\n\n        if len(timeStampedRasters) >= 2:\n            time2 = timeStampedRasters[1]['dateTime']\n            deltaTime = time2 - time1\n\n        # Initialize KML Document\n        kml = ET.Element('kml', xmlns='http://www.opengis.net/kml/2.2')\n        document = ET.SubElement(kml, 'Document')\n        docName = ET.SubElement(document, 'name')\n        docName.text = documentName\n\n        if not discreet:\n            # Embed the color ramp in SLD format\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsContinuousSLD()))\n        else:\n            values = []\n            document.append(ET.fromstring(mappedColorRamp.getColorMapAsDiscreetSLD(values)))\n\n        # Apply special style to hide legend items\n        style = ET.SubElement(document, 'Style', id='check-hide-children')\n        listStyle = ET.SubElement(style, 'ListStyle')\n        listItemType = ET.SubElement(listStyle, 'listItemType')\n        listItemType.text = 'checkHideChildren'\n        styleUrl = ET.SubElement(document, 'styleUrl')\n        styleUrl.text = '#check-hide-children'\n\n        for index, timeStampedRaster in enumerate(timeStampedRasters):\n            # Extract variable\n            if deltaTime:\n                dateTime = timeStampedRaster['dateTime']\n                prevDateTime = dateTime - deltaTime\n\n\n            # GroundOverlay\n            groundOverlay = ET.SubElement(document, 'GroundOverlay')\n            overlayName = ET.SubElement(groundOverlay, 'name')\n            overlayName.text = 'Overlay'\n\n            if deltaTime:\n                # Create TimeSpan tag\n                timeSpan = ET.SubElement(groundOverlay, 'TimeSpan')\n\n                # Create begin tag\n                begin = ET.SubElement(timeSpan, 'begin')\n                begin.text = prevDateTime.strftime('%Y-%m-%dT%H:%M:%S')\n                end = ET.SubElement(timeSpan, 'end')\n                end.text = dateTime.strftime('%Y-%m-%dT%H:%M:%S')\n\n            # DrawOrder\n            drawOrderElement = ET.SubElement(groundOverlay, 'drawOrder')\n            drawOrderElement.text = str(drawOrder)\n\n            # Define Region\n            regionElement = ET.SubElement(groundOverlay, 'Region')\n            latLonBox = ET.SubElement(regionElement, 'LatLonBox')\n\n            northElement = ET.SubElement(latLonBox, 'north')\n            northElement.text = str(north)\n\n            southElement = ET.SubElement(latLonBox, 'south')\n            southElement.text = str(south)\n\n            eastElement = ET.SubElement(latLonBox, 'east')\n            eastElement.text = str(east)\n\n            westElement = ET.SubElement(latLonBox, 'west')\n            westElement.text = str(west)\n\n            # Href to PNG\n            iconElement = ET.SubElement(groundOverlay, 'Icon')\n            hrefElement = ET.SubElement(iconElement, 'href')\n            hrefElement.text = 'raster{0}.png'.format(index)\n\n            # LatLonBox\n            latLonBox = ET.SubElement(groundOverlay, 'LatLonBox')\n\n            northElement = ET.SubElement(latLonBox, 'north')\n            northElement.text = str(north)\n\n            southElement = ET.SubElement(latLonBox, 'south')\n            southElement.text = str(south)\n\n            eastElement = ET.SubElement(latLonBox, 'east')\n            eastElement.text = str(east)\n\n            westElement = ET.SubElement(latLonBox, 'west')\n            westElement.text = str(west)\n\n        return ET.tostring(kml), binaryPNGs", "response": "Returns a sequence of rasters with timestamps as a kml with time markers for animation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAsGrassAsciiRaster(self, tableName, rasterId=1, rasterIdFieldName='id', rasterFieldName='raster', newSRID=None):\n        # Get raster in ArcInfo Grid format\n        arcInfoGrid = self.getAsGdalRaster(rasterFieldName, tableName, rasterIdFieldName, rasterId, 'AAIGrid', newSRID).splitlines()\n\n        ## Convert arcInfoGrid to GRASS ASCII format ##\n        # Get values from header which look something this:\n        # ncols        67\n        # nrows        55\n        # xllcorner    425802.32143212341\n        # yllcorner    44091450.41551345213\n        # cellsize     90.0000000\n        # ...\n        nCols = int(arcInfoGrid[0].split()[1])\n        nRows = int(arcInfoGrid[1].split()[1])\n        xLLCorner = float(arcInfoGrid[2].split()[1])\n        yLLCorner = float(arcInfoGrid[3].split()[1])\n        cellSize = float(arcInfoGrid[4].split()[1])\n\n        # Remove old headers\n        for i in range(0, 5):\n            arcInfoGrid.pop(0)\n\n        # Check for NODATA_value row and remove if it is there\n        if 'NODATA_value' in arcInfoGrid[0]:\n            arcInfoGrid.pop(0)\n\n        ## Calculate values for GRASS ASCII headers ##\n        # These should look like this:\n        # north: 4501028.972140\n        # south: 4494548.972140\n        # east: 460348.288604\n        # west: 454318.288604\n        # rows: 72\n        # cols: 67\n        # ...\n\n        # xLLCorner and yLLCorner represent the coordinates for the Lower Left corner of the raster\n        north = yLLCorner + (cellSize * nRows)\n        south = yLLCorner\n        east = xLLCorner + (cellSize * nCols)\n        west = xLLCorner\n\n        # Create header Lines (the first shall be last and the last shall be first)\n        grassHeader = ['cols: %s' % nCols,\n                       'rows: %s' % nRows,\n                       'west: %s' % west,\n                       'east: %s' % east,\n                       'south: %s' % south,\n                       'north: %s' % north]\n\n        # Insert grass headers into the grid\n        for header in grassHeader:\n            arcInfoGrid.insert(0, header)\n\n        # Create string\n        arcInfoGridString = '\\n'.join(arcInfoGrid)\n        return arcInfoGridString", "response": "Returns a string representation of the raster in GRASS ASCII raster format."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string or buffer representation of the raster in the specified format.", "response": "def getAsGdalRaster(self, rasterFieldName, tableName, rasterIdFieldName, rasterId, gdalFormat, newSRID=None, **kwargs):\n        \"\"\"\n        Returns a string/buffer representation of the raster in the specified format. Wrapper for\n        ST_AsGDALRaster function in the database.\n        \"\"\"\n\n        # Check gdalFormat\n        if not (gdalFormat in RasterConverter.supportedGdalRasterFormats(self._session)):\n            raise ValueError('FORMAT NOT SUPPORTED: {0} format is not supported '\n                             'in this PostGIS installation.'.format(gdalFormat))\n\n        # Setup srid\n        if newSRID:\n            srid = ', {0}'.format(newSRID)\n        else:\n            srid = ''\n\n        # Compile options\n        if kwargs:\n            optionsList = []\n            for key, value in kwargs.iteritems():\n                kwargString = \"'{0}={1}'\".format(key, value)\n                optionsList.append(kwargString)\n\n            optionsString = ','.join(optionsList)\n            options = ', ARRAY[{0}]'.format(optionsString)\n        else:\n            options = ''\n\n        # Create statement\n        statement = '''\n                    SELECT ST_AsGDALRaster(\"{0}\", '{1}'{5}{6})\n                    FROM \"{2}\" WHERE \"{3}\"={4};\n                    '''.format(rasterFieldName, gdalFormat, tableName, rasterIdFieldName, rasterId,  options, srid)\n\n        # Execute query\n        result = self._session.execute(statement).scalar()\n\n        return bytes(result).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef supportedGdalRasterFormats(cls, sqlAlchemyEngineOrSession):\n        if isinstance(sqlAlchemyEngineOrSession, Engine):\n            # Create sqlalchemy session\n            sessionMaker = sessionmaker(bind=sqlAlchemyEngineOrSession)\n            session = sessionMaker()\n        elif isinstance(sqlAlchemyEngineOrSession, Session):\n            session = sqlAlchemyEngineOrSession\n\n        # Execute statement\n        statement = 'SELECT * FROM st_gdaldrivers() ORDER BY short_name;'\n\n        result = session.execute(statement)\n\n        supported = dict()\n\n        for row in result:\n            supported[row[1]] = {'description': row[2], 'options': row[3]}\n\n        return supported", "response": "Return a list of the supported GDAL raster formats."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the color ramp of the raster converter instance.", "response": "def setColorRamp(self, colorRamp=None):\n        \"\"\"\n        Set the color ramp of the raster converter instance\n        \"\"\"\n        if not colorRamp:\n            self._colorRamp = RasterConverter.setDefaultColorRamp(ColorRampEnum.COLOR_RAMP_HUE)\n        else:\n            self._colorRamp = colorRamp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the default color ramp for this locale.", "response": "def setDefaultColorRamp(self, colorRampEnum=ColorRampEnum.COLOR_RAMP_HUE):\n        \"\"\"\n        Returns the color ramp as a list of RGB tuples\n        \"\"\"\n        self._colorRamp = ColorRampGenerator.generateDefaultColorRamp(colorRampEnum)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setCustomColorRamp(self, colors=[], interpolatedPoints=10):\n        self._colorRamp = ColorRampGenerator.generateCustomColorRamp(colors, interpolatedPoints)", "response": "Sets the color ramp for this locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getRastersAsPngs(self, session, tableName, rasterIds, postGisRampString, rasterField='raster', rasterIdField='id',  cellSize=None, resampleMethod='NearestNeighbour'):\n        # Validate\n        VALID_RESAMPLE_METHODS = ('NearestNeighbour', 'Bilinear', 'Cubic', 'CubicSpline', 'Lanczos')\n\n        # Validate\n        if resampleMethod not in VALID_RESAMPLE_METHODS:\n            print('RASTER CONVERSION ERROR: {0} is not a valid resampleMethod.'\n                  ' Please use either {1}'.format(resampleMethod,\n                                                  ', '.join(VALID_RESAMPLE_METHODS)))\n\n        if cellSize is not None:\n            if not self.isNumber(cellSize):\n                raise ValueError('RASTER CONVERSION ERROR: cellSize must be a number or None.')\n\n        # Convert raster ids into formatted string\n        rasterIdsString = '({0})'.format(', '.join(rasterIds))\n\n        if cellSize is not None:\n            statement = '''\n                        SELECT ST_AsPNG(ST_Transform(ST_ColorMap(ST_Rescale({0}, {5}, '{6}'), 1, '{4}'), 4326, 'Bilinear')) As png\n                        FROM {1}\n                        WHERE {2} IN {3};\n                        '''.format(rasterField, tableName, rasterIdField, rasterIdsString, postGisRampString, cellSize,\n                                   resampleMethod)\n        else:\n            statement = '''\n                        SELECT ST_AsPNG(ST_Transform(ST_ColorMap({0}, 1, '{4}'), 4326, 'Bilinear')) As png\n                        FROM {1}\n                        WHERE {2} IN {3};\n                        '''.format(rasterField, tableName, rasterIdField, rasterIdsString, postGisRampString)\n        result = session.execute(statement)\n        return result", "response": "Returns the raster in a PNG format"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates whether a value is a number or not.", "response": "def isNumber(self, value):\n        \"\"\"\n        Validate whether a value is a number or not\n        \"\"\"\n        try:\n            str(value)\n            float(value)\n            return True\n\n        except ValueError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure that a subreddit actually exists.", "response": "def check_exists(subreddit):\n    \"\"\"Make sure that a subreddit actually exists.\"\"\"\n    req = get('http://www.reddit.com/r/%s/about.json' % subreddit, headers={'User-Agent': 'CslBot/1.0'})\n    if req.json().get('kind') == 'Listing':\n        # no subreddit exists, search results page is shown\n        return False\n    return req.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a random post from a subreddit and returns a title and shortlink to it.", "response": "def random_post(subreddit, apikey):\n    \"\"\"Gets a random post from a subreddit and returns a title and shortlink to it.\"\"\"\n    subreddit = '/r/random' if subreddit is None else '/r/%s' % subreddit\n    urlstr = 'http://reddit.com%s/random?%s' % (subreddit, time.time())\n    url = get(urlstr, headers={'User-Agent': 'CslBot/1.0'}).url\n    return '** %s - %s' % (get_title(url, apikey), get_short(url, apikey))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_file(fname):\n    print(\"NO - dont use this function read_file(fname):\")\n    exit(1)\n    lst = []\n    with open(fname, 'r') as f:\n        #hdr = f.readline()\n        for line in f:\n            lst.append(line.strip('\\n'))\n    return lst", "response": "read a CSV file and return the \n    list of names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_file_1st_col_only(fname):\n    lst = []\n    with open(fname, 'r') as f:\n        _ = f.readline()   # read the header and ignore it\n        for line in f:\n            lst.append(line.split(',')[0])\n    return lst", "response": "read a CSV file and return the \n    list of names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_to_dict(self):\n        lst = []\n        with open(self.fname, 'r') as f:\n            hdr = f.readline()\n            self.hdrs = hdr.split(',')\n            #print(\"self.hdrs = \", self.hdrs)\n            for line in f:\n                cols = line.split(',')\n                if len(cols) == len(self.hdrs):\n                    #print(cols)\n                    d = {}\n                    for ndx, col_header in enumerate(self.hdrs):\n                        #d[self.hdrs[ndx].strip('\\n').strip()] = cols[ndx].strip('\\n').strip()\n                        d[col_header.strip('\\n').strip()] = cols[ndx].strip('\\n').strip()\n                        \n                    lst.append(d)\n                else:\n                    print(\"Error parsing \" + self.fname + \" line : \" + line)\n        return lst", "response": "parse raw CSV into dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random name from the class", "response": "def get_random_choice(self):    \n        \"\"\"\n        returns a random name from the class\n        \"\"\"\n        i = random.randint(0,len(self.dat)-1)\n        return self.dat[i]['name']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_random_character(self):\n        name = self.create_name()\n        ch_class = self.classes.get_random_choice()\n        race = self.races.get_random_choice()\n        stats = self.random_stats(self.stats.dat, race, ch_class)\n        skills = []\n        story = self.stories.get_random_choice()\n        inventory = [str(random.randint(21,29)) + ' gold']\n        \n        # pick random stuff here \n        for _ in range(3):\n            inventory.append(self.inventory.get_random_choice())\n        for _ in range(3):\n            skills.append(self.skills.get_random_choice())\n        return Character(name, race, ch_class, stats, skills, story, inventory)", "response": "Generate a random character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating random stats based on the characters class and race", "response": "def random_stats(self, all_stats, race, ch_class):\n        \"\"\"\n        create random stats based on the characters class and race\n        This looks up the tables from CharacterCollection to get\n        base stats and applies a close random fit\n        \"\"\"\n        \n        # create blank list of stats to be generated\n        stats = []\n        res = {}\n        for s in all_stats:\n            stats.append(s['stat'])\n            res[s['stat']] = 0\n        \n        cur_stat = 0\n        for stat in stats:\n            for ndx, i in enumerate(self.classes.dat):\n                if i['name'] == ch_class:\n                    cur_stat = int(i[stat])  # use stats for this class as baseline\n            for ndx, i in enumerate(self.races.dat):\n                if i['name'] == race:\n                    cur_stat += int(i[stat])  # use stats for this race to modify base stats\n            #print(stat, cur_stat)\n            if cur_stat < 1:\n                cur_stat = 1\n            elif cur_stat > 10:\n                if stat not in ('Health', 'max_health'): # dont trim down health\n                    cur_stat = 10\n           \n            res[stat] = cur_stat\n        \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_from_file(self, fname):\n        with open(fname, 'r') as f:\n            for line in f:\n                k,v = line.split(' = ')\n                self._parse_char_line_to_self(k,v)", "response": "Loads the current character object from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_char_line_to_self(self, k,v):\n        k = k.strip(' ').strip('\\n')\n        v = v.strip(' ').strip('\\n')\n       # print('_parse_char_line_to_self(self, k,v): ' , k, v)\n        if k == 'CHARACTER':\n            self.name = v\n        elif k == 'Race':\n            self.race = v\n        elif k == 'Class':\n            self.ch_class = v\n        elif k == 'STATS':\n            self.stats = self._extract_stats_from_line(v)\n        elif k == 'Story':\n            self.story = v.strip(' ').strip('\\n')\n        elif k == 'SKILLS':\n            self.skills = v.split(', ')\n        elif k == 'INVENTORY':\n            self.inventory = v.split(', ')", "response": "Parse a single character line into the appropriate self parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_stats_from_line(self, txt, stats_delim=' ', val_delim=':'):\n        result = {}\n        stats_txt = txt.split(stats_delim)\n        for s in stats_txt:\n            #print('s = ', s)\n            if s.strip(' ').strip('\\n') != '':\n                k,v = s.split(val_delim)\n                result[k.strip(' ')] = v.strip(' ').strip('\\n')\n        return result", "response": "Extracts the stats from a line of text to the class params\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_to_file(self, fname):\n        with open(fname, 'w') as f:\n            f.write(str(self))", "response": "Saves a character set to file fname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake an identical copy of the character", "response": "def copy(self):\n        \"\"\" \n        make an identical copy of the character\n        \"\"\"\n        return Character(self.name, self.race,self.ch_class, self.stats, self.skills, self.story, self.inventory)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef palette(fg, bg=-1):\n\n    if not hasattr(palette, \"counter\"):\n        palette.counter = 1\n\n    if not hasattr(palette, \"selections\"):\n        palette.selections = {}\n\n    selection = \"%s%s\" % (str(fg), str(bg))\n    if not selection in palette.selections:\n        palette.selections[selection] = palette.counter\n        palette.counter += 1\n\n    # Get available colours\n    colors = [c for c in dir(_curses) if c.startswith('COLOR')]\n    if isinstance(fg, str):\n        if not \"COLOR_\"+fg.upper() in colors:\n            fg = -1\n        else:\n            fg = getattr(_curses, \"COLOR_\"+fg.upper())\n    if isinstance(bg, str):\n        if not \"COLOR_\"+bg.upper() in colors:\n            bg = -1\n        else:\n            bg = getattr(_curses, \"COLOR_\"+bg.upper())\n\n    _curses.init_pair(palette.selections[selection], fg, bg)\n    return _curses.color_pair(palette.selections[selection])", "response": "Return a new colour pair that can be used to draw a new color pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n        self.window = _curses.initscr()\n        _curses.savetty()\n        _curses.start_color()\n        _curses.use_default_colors()\n        self.window.leaveok(1)\n        _curses.raw()\n        self.window.keypad(1)\n        _curses.noecho()\n        _curses.cbreak()\n        _curses.nonl()\n        _curses.curs_set(0)\n        if self.blocking:\n            self.window.nodelay(0)\n        else:\n            self.window.nodelay(1)\n        self.running = True\n        while self.running:\n            self.cycle()\n            if self.friendly and not self.blocking:\n                time.sleep(self.delay)\n        self.stop()", "response": "Start the event loop for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n        _curses.nocbreak()\n        self.window.keypad(0)\n        _curses.echo()\n        _curses.resetty()\n        _curses.endwin()\n        self.running = False", "response": "Restore the TTY to its original state."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses input from the user and display the character codes as they re received.", "response": "def process_input(self):\n        \"\"\"\n        Send input to panes marked as active after checking for\n        a request to redraw the screen (^L), a request to exit,\n        and optionally display character codes as they're received.\n        \"\"\"\n        try:\n            character = self.window.getch()\n        except Exception as e:\n            character = -1\n            if self.debug:\n                self.addstr(self.height-1, self.width - len(e.message) + 1, e.message)\n\n        # Check for any keys we've been told to exit on\n        if character in self.exit_keys:\n            self.stop()\n\n        # Force redraw the screen on ^L\n        if character == 12:\n            self.window.clear()\n            return\n\n        # Send input to active panes (hidden panes can still receive input)\n        if character != -1:\n            [pane.process_input(character) for pane in self if pane.active ]\n\n            # Print character codes to the bottom center if debugging.\n            if self.debug:\n                self.addstr(self.height-1, self.width/2, \" \"*4)\n                self.addstr(self.height-1, self.width/2 - len(str(character)) / 2, str(character))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the heights and widths of the panes in the current window and the current geometry.", "response": "def calculate_pane_heights_and_widths(self):\n        \"\"\"\n        Update pane heights and widths based on the current window and their desired geometry.\n\n        What to bear in mind:\n          Panes may have a fixed desired size.\n          Panes may be set to expand maximally on either axis.\n          Panes may be set to fit to the sum of their content buffers (accounting for alignment).\n          Panes may be set to float.\n          Two panes set to float and expand on the same axis will not overlap.\n          EXPANDing panes may be adjacent to non-floating self-coordinating panes...\n\n        Two panes wanting a height of ten each on a five line window will overflow offscreen.\n        Using FIT for an axis on an undersized Window will also overflow offscreen.\n\n        \"\"\"\n        # Do a pass for heights\n        # Every pane must be represented in order to map properly later\n        growing_panes      = []\n        claimed_columns    = 0\n        for v_index, element in enumerate(self.panes):\n            # Get maximal height from panes in sublists\n            if type(element) == list:\n                expanding_in_sublist = [] # A list we'll append to growing_panes\n                claimed_from_sublist = [] # The heights gleaned from this pass\n                for h_index, pane in enumerate(element):\n                    if pane.hidden: continue\n\n                    # Let height be max L/R distance from top if self-coordinating\n                    if pane.coords and pane.self_coordinating:\n                        pane.height = max([pane.coords[1][0][0],pane.coords[1][1][0]])\n                        claimed_from_sublist.append(pane.height)\n                        continue\n\n                    if len(pane.geometry) < 2:\n                        pane.height = 0\n                        continue\n\n                    desired_height = pane.geometry[1]\n\n                    if isinstance(desired_height, int):\n                        pane.height = desired_height\n                        claimed_from_sublist.append(pane.height)\n                        continue\n\n                    elif isinstance(desired_height, str):\n                        # Calculate the width of panes set to FIT\n                        if desired_height == FIT:\n                            buffer = \"\"\n                            for frame in pane.content:\n                                buffer += frame[0]\n                            pane.height = len(buffer.split('\\n'))\n                            claimed_from_sublist.append(pane.height)\n                            continue\n\n                        elif desired_height == EXPAND:\n                            expanding_in_sublist.append(pane)\n                            continue\n\n                    pane.height = desired_height\n\n                # Append any expanding panes to growing_panes as a list\n                if expanding_in_sublist:\n                    growing_panes.append(expanding_in_sublist)\n\n                # The total claimed columns for this sublist:\n                if claimed_from_sublist:\n                    claimed_columns += max(claimed_from_sublist)\n            else:\n                if element.hidden: continue\n\n                if element.coords and element.self_coordinating:\n                    element.height = max([element.coords[1][0][0], element.coords[1][1][0]])\n                    claimed_columns += element.height\n                    continue\n\n                if len(element.geometry) < 2:\n                    element.height = 0\n                    continue\n\n                desired_height = element.geometry[1]\n\n                if isinstance(desired_height, int):\n                    element.height = desired_height\n                    claimed_columns += element.height\n                    continue\n\n                elif isinstance(desired_height, str):\n                    # Calculate the width of panes set to FIT\n                    if desired_height == FIT:\n                        buffer = \"\"\n                        for frame in element.content:\n                            buffer += frame[0]\n                        element.height = len(buffer.split('\\n'))\n                        claimed_columns += element.height\n                        continue\n\n                    elif desired_height == EXPAND:\n                        growing_panes.append(element)\n                        continue\n\n        # Calculate how many rows are left by panes with fixed heights\n        if growing_panes:\n            g = len(growing_panes)\n            remaining_space = self.height - claimed_columns\n            typical_expanse = remaining_space / g\n            tracking = 0\n            rmg = remaining_space % g\n\n\n            # Calculate adjustments if the height isn't evenly shared\n            for i, pane in enumerate(growing_panes):\n                if isinstance(pane, list):\n                    for k,p in enumerate(pane):\n                        p.height = typical_expanse\n                        if not i:\n                            # Account for claimed space\n                            for x in range(len(growing_panes)):\n                                if rmg == x:\n                                    p.height -= len(growing_panes) - (x+1)\n\n                            # Adjust for an extra column that can't be evenly shared\n                            if self.height % 2:\n                                if not claimed_columns:\n                                    p.height += 1\n                                else:\n                                    p.height -= claimed_columns\n                            else:\n                                p.height -= claimed_columns\n                        if not k:\n                            tracking += p.height\n                else:\n                    pane.height = typical_expanse\n                    if not i:\n                        for x in range(len(growing_panes)):\n                            if rmg == x:\n                                pane.height -= len(growing_panes) - (x+1)\n                        if self.height % 2:\n                            if not claimed_columns:\n                                pane.height += 1\n                            else:\n                                pane.height -= claimed_columns\n                        else:\n                            pane.height -= claimed_columns\n\n                    tracking += pane.height\n\n        #s = \"Growing rows: %i, %s number of rows: %s, claimed: %i, remaining: %i, remaining/growing: %i,rmodg: %i\" % \\\n        #    (g, \"odd\" if self.height % 2 else \"even\", self.height, claimed_columns,remaining_space, typical_expanse, remaining_space%g)\n#        self.addstr(self.height-1, self.width-len(s),s)\n\n        # Then a pass for widths.\n        for v_index, element in enumerate(self.panes):\n            claimed_rows    = 0\n            growing_panes   = []\n            # Get panes who will be sharing the x axis\n            if type(element) == list:\n                for h_index, pane in enumerate(element):\n                    if pane.hidden: continue\n\n                    # Calculate the widest part of a self-coordinating pane\n                    if pane.coords and pane.self_coordinating:\n                        rightmost = [pane.coords[0][1][1],pane.coords[1][1][1]]\n                        pane.width = max(rightmost)\n                        continue\n\n                    if not pane.geometry:\n                        pane.width = 0\n                        continue\n\n                    desired_width = pane.geometry[0]\n\n                    if isinstance(desired_width, int):\n                        claimed_rows += desired_width\n                        pane.width = desired_width\n                        continue\n\n                    elif isinstance(desired_width, str):\n                        # Calculate the width of panes set to FIT\n                        if desired_width == FIT:\n                            buffer = \"\"\n                            for frame in pane.content:\n                                buffer += frame[0]\n                            pane.width = max(map(len, buffer.split('\\n')))\n                            claimed_rows += pane.width\n                            continue\n\n                        elif desired_width == EXPAND:\n                            growing_panes.append(pane)\n                            continue\n\n            else:\n\n                if element.hidden: continue\n\n                if not element.geometry:\n                    element.width = 0\n                    continue\n\n                desired_geometry = element.geometry[0]\n\n                if element.coords and element.self_coordinating:\n                    rightmost = [element.coords[0][1][1],element.coords[1][1][1]]\n                    element.width = max(rightmost)\n                    continue\n\n                if isinstance(desired_geometry, int):\n                    element.width = desired_geometry\n                    continue\n\n                if isinstance(desired_geometry, str):\n                    if desired_geometry == FIT:\n                        buffer = \"\"\n                        for frame in element.content:\n                            buffer += frame[0]\n                        element.width = max(map(len, buffer.split('\\n')))\n                    elif desired_geometry == EXPAND:\n                        element.width = self.width\n\n            # Calculate the space to be shared between panes set to EXPAND\n            remaining_space = self.width - claimed_rows\n            for pane in growing_panes:\n                pane.width = remaining_space / len(growing_panes)\n\n        # Grant the rightmost panes an extra row if self.width is uneven:\n        if self.width % 2:\n            for pane in self.panes:\n                if isinstance(pane, list):\n                    for i, p in enumerate(reversed(pane)):\n                        if i == 0 and not p.self_coordinating and p.geometry \\\n                                and p.geometry[0] == EXPAND and not p.hidden:\n                                p.width += 1\n                else:                        \n                    if not pane.self_coordinating and pane.geometry \\\n                        and pane.geometry[0] == EXPAND and not pane.hidden:\n                        pane.width += 1\n                        continue\n\n        if self.debug:\n            self.addstr(self.height-5, 0, \"Window height: \" + str(self.height))\n            self.addstr(self.height-4, 0, \"Window width:  \" + str(self.width))\n            self.addstr(self.height-2, 0, \"Heights: \" + str([p.height for p in self]))\n            self.addstr(self.height-1, 0, \"Widths:  \" + str([p.width for p in self]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coordinate(self, panes=[], index=0):\n        y = 0 # height\n\n        for i, element in enumerate(self.panes):\n            x = 0 # width\n            if isinstance(element, list):\n                current_height = 0\n                for j, pane in enumerate(element):\n                    if pane.hidden: continue\n                    current_width  = pane.width\n                    current_height = pane.height\n                    upper          = ((y, x), (y, x+current_width))\n                    lower          = ((y+(current_height if current_height > 1 else 0), x),\n                                      (y+(current_height if current_height > 1 else 0), x+current_width))\n                    pane.coords    = [upper, lower]\n                    x += current_width\n                y += (current_height+1 if current_height > 1 else 1)\n            else:\n                if element.hidden: continue\n                current_width  = element.width\n                current_height = element.height\n                upper          = ((y, x), (y, x+current_width))\n                lower          = ((y+(current_height if current_height > 1 else 0), x),\n                                  (y+(current_height if current_height > 1 else 0), x+current_width))\n                element.coords = [upper, lower]\n                y += (current_height+1 if current_height > 1 else 1)\n\n            if self.debug:\n                coordinates = \"Coordinates: \" + str([p.coords for p in self])\n                if len(coordinates) > self.width:\n                    coordinates  = coordinates[:self.width - 3]\n                    coordinates += '...'\n                self.addstr(self.height-3, 0, coordinates)", "response": "Update the pane coordinates based on their height and width relative to other panes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addstr(self, h, w, text, attrs=0):\n        self.update_window_size()\n        if h > self.height or w > self.width:\n            return\n        try:\n            # Python curses addstr doesn't deal with non-ascii characters\n            #self.window.addstr(h, w, text.encode(\"ascii\", \"ignore\"), attrs)\n            self.window.addstr(h, w, text, attrs)\n        except Exception as e:\n            pass", "response": "A safe addstr wrapper that handles non - ascii characters and returns the new size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the current window height and width and clear the screen if they ve changed.", "response": "def update_window_size(self):\n        \"\"\"\n        Update the current window object with its current\n        height and width and clear the screen if they've changed.\n        \"\"\"\n        height, width = self.window.getmaxyx()\n        if self.height != height or self.width != width:\n            self.height, self.width = height, width\n            self.window.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, pane):\n        if isinstance(pane, list):\n            initialised_panes = []\n            for p in pane:\n                initialised_panes.append(self.init_pane(p))\n            self.panes.append(initialised_panes)\n        else:    \n            pane = self.init_pane(pane)\n            self.panes.append(pane)", "response": "Adds new panes to the window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, name, default=None, cache=False):\n        if cache == True:\n            for pane in self.cache:\n                if pane.name == name:\n                    return pane\n            return default\n        for pane in self:\n            if pane.name == name:\n                return pane\n        return default", "response": "Get a pane by name possibly from the cache. Return None if not found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_input(self, character):\n        func = None\n        try:\n            func = getattr(self, \"handle_%s\" % chr(character), None)\n        except:\n            pass\n        if func:\n            func()", "response": "A subclassable method for dealing with input characters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, msg, args):\n    if args['type'] == 'privmsg':\n        send('GCC is a group exercise!')\n        return\n    if 'include' in msg:\n        send(\"We're not a terribly inclusive community around here.\")\n        return\n    if 'import' in msg:\n        send(\"I'll have you know that standards compliance is important.\")\n        return\n    tmpfile = tempfile.NamedTemporaryFile()\n    for line in msg.splitlines():\n        line = line + '\\n'\n        tmpfile.write(line.encode())\n    tmpfile.flush()\n    process = subprocess.run(['gcc', '-o', '/dev/null', '-xc', tmpfile.name],\n                             stdout=subprocess.PIPE,\n                             stderr=subprocess.STDOUT,\n                             timeout=5,\n                             universal_newlines=True)\n    tmpfile.close()\n    # Take the last 3 lines to prevent Excess Flood on long error messages\n    output = process.stdout.splitlines()[:3]\n    for line in output:\n        send(line, target=args['nick'])\n    if process.returncode == 0:\n        send(gen_slogan(\"gcc victory\"))\n    else:\n        send(gen_slogan(\"gcc failed\"))", "response": "Compiles stuff.\n\n    Syntax: {command} <code>"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_image_list(self, page=1, per_page=20):\n        url = self.api_url + '/api/images'\n        params = {\n            'page': page,\n            'per_page': per_page\n        }\n        response = self._request_url(\n            url, 'get', params=params, with_access_token=True)\n        headers, result = self._parse_and_check(response)\n        images = ImageList.from_list(result)\n        images.set_attributes_from_headers(headers)\n        return images", "response": "Return a list of user s saved images."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_image(self,\n                     image_file,\n                     referer_url=None,\n                     title=None,\n                     desc=None,\n                     created_at=None,\n                     collection_id=None):\n        \"\"\"Upload an image\n\n        :param image_file: File-like object of an image file\n        :param referer_url: Referer site URL\n        :param title: Site title\n        :param desc: Comment\n        :param created_at: Image's created time in unix time\n        :param collection_id: Collection ID\n        \"\"\"\n        url = self.upload_url + '/api/upload'\n        data = {}\n        if referer_url is not None:\n            data['referer_url'] = referer_url\n        if title is not None:\n            data['title'] = title\n        if desc is not None:\n            data['desc'] = desc\n        if created_at is not None:\n            data['created_at'] = str(created_at)\n        if collection_id is not None:\n            data['collection_id'] = collection_id\n        files = {\n            'imagedata': image_file\n        }\n        response = self._request_url(\n            url, 'post', data=data, files=files, with_access_token=True)\n        headers, result = self._parse_and_check(response)\n        return Image.from_dict(result)", "response": "Upload an image to the NCBI server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_image(self, image_id):\n        url = self.api_url + '/api/images/' + image_id\n        response = self._request_url(url, 'delete', with_access_token=True)\n        headers, result = self._parse_and_check(response)\n        return Image.from_dict(result)", "response": "Delete an image from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an oEmbed format json dictionary", "response": "def get_oembed(self, url):\n        \"\"\"Return an oEmbed format json dictionary\n\n        :param url: Image page URL (ex. http://gyazo.com/xxxxx)\n        \"\"\"\n        api_url = self.api_url + '/api/oembed'\n        parameters = {\n            'url': url\n        }\n        response = self._request_url(api_url, 'get', params=parameters)\n        headers, result = self._parse_and_check(response)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _request_url(self,\n                     url,\n                     method,\n                     params=None,\n                     data=None,\n                     files=None,\n                     with_client_id=False,\n                     with_access_token=False):\n        \"\"\"Send HTTP request\n\n        :param url: URL\n        :param method: HTTP method (get, post or delete)\n        :param with_client_id: send request with client_id (default: false)\n        :param with_access_token: send request with with_access_token\n                                  (default: false)\n        :raise GyazoError:\n        \"\"\"\n        headers = {}  # type: Dict[str, Any]\n        if data is None:\n            data = {}\n        if params is None:\n            params = {}\n\n        if with_client_id and self._client_id is not None:\n            params['client_id'] = self._client_id\n\n        if with_access_token and self._access_token is not None:\n            headers['Authorization'] = \"Bearer \" + self._access_token\n\n        try:\n            return requests.request(method, url,\n                                    params=params,\n                                    data=data,\n                                    files=files,\n                                    headers=headers)\n        except requests.RequestException as e:\n            raise GyazoError(str(e))", "response": "Send HTTP request to the specified URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that all rows have the same length.", "response": "def validate_rows_length(data, length, message=None, exception=MatrixError):\n    \"\"\"Validate that all rows have the same length.\"\"\"\n    if message is None:\n        message = 'All rows must have the same length (same number of columns)'\n    for row in data:\n        if len(row) != length:\n            raise exception(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the matrix has equal number of rows and columns.", "response": "def validate_square(data, message=None, exception=MatrixError):\n    \"\"\"Validate that the matrix has equal number of rows and columns.\"\"\"\n    rows, columns = len(data), len(data[0]) if data else 0\n    if message is None:\n        message = 'Number of rows: %s != number of columns: %s in matrix' % (\n            rows, columns)\n    if rows != columns:\n        raise exception(message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_categories_equal_entities(categories, entities, message=None,\n                                       exception=MatrixError):\n    \"\"\"Validate that the matrix has equal number of entities and categories.\"\"\"\n    nb_categories = len(categories)\n    nb_entities = len(entities)\n    if message is None:\n        message = 'Number of categories: %s != number of entities: %s' % (\n            nb_categories, nb_entities)\n    if categories and nb_categories != nb_entities:\n        raise exception(message)", "response": "Validate that the matrix has equal number of entities and categories."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate data (rows length, categories=entities, square).", "response": "def validate(self):\n        \"\"\"Validate data (rows length, categories=entities, square).\"\"\"\n        validate_rows_length(self.data, self.columns, exception=self.error)\n        validate_categories_equal_entities(self.categories, self.entities,\n                                           exception=self.error)\n        if self.square:\n            validate_square(self.data, exception=self.error)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbases validation + entities = rows.", "response": "def validate(self):\n        \"\"\"Base validation + entities = rows.\"\"\"\n        super().validate()\n        nb_entities = len(self.entities)\n        if nb_entities != self.rows:\n            raise self.error(\n                'Number of entities: %s != number of rows: %s' % (\n                    nb_entities, self.rows))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the transitive closure of the matrix.", "response": "def transitive_closure(self):\n        \"\"\"Compute the transitive closure of the matrix.\"\"\"\n        data = [[1 if j else 0 for j in i] for i in self.data]\n        for k in range(self.rows):\n            for i in range(self.rows):\n                for j in range(self.rows):\n                    if data[i][k] and data[k][j]:\n                        data[i][j] = 1\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbase validation + entities = rows + columns.", "response": "def validate(self):\n        \"\"\"Base validation + entities = rows + columns.\"\"\"\n        super().validate()\n        nb_entities = len(self.entities)\n        if nb_entities != self.rows + self.columns:\n            raise self.error(\n                'Number of entities: %s != number of rows + '\n                'number of columns: %s+%s=%s' % (\n                    nb_entities, self.rows, self.columns,\n                    self.rows + self.columns))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_entities(self):\n        return [str(i) for i in range(self.rows + self.columns)]", "response": "Return range from 0 to rows + columns."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self):\n        super().validate()\n        message_dsm = 'Matrix at [%s:%s] is not an instance of '\\\n                      'DesignStructureMatrix or MultipleDomainMatrix.'\n        message_ddm = 'Matrix at [%s:%s] is not an instance of '\\\n                      'DomainMappingMatrix or MultipleDomainMatrix.'\n        messages = []\n        for i, row in enumerate(self.data):\n            for j, cell in enumerate(row):\n                if i == j:\n                    if not isinstance(cell, (\n                            DesignStructureMatrix, MultipleDomainMatrix)):\n                        messages.append(message_dsm % (i, j))\n                elif not isinstance(cell, (\n                        DomainMappingMatrix, MultipleDomainMatrix)):\n                    messages.append(message_ddm % (i, j))\n        if messages:\n            raise self.error('\\n'.join(messages))", "response": "Base validation + each cell is instance of DSM or MDM."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the distortion value of the current clusters", "response": "def _calc_distortion(self):\n        \"\"\"Calculates the distortion value of the current clusters\n        \"\"\"\n        m = self._X.shape[0]\n        self.distortion = 1/m * sum(\n            linalg.norm(self._X[i, :] - self.centroids[self.clusters[i]])**2 for i in range(m)\n        )\n        return self.distortion"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the centroids as k random samples of X", "response": "def _init_random_centroids(self):\n        \"\"\"Initialize the centroids as k random samples of X (k = n_clusters)\n        \"\"\"\n        self.centroids = self._X[np.random.choice(list(range(self._X.shape[0])), size=self.n_clusters), :]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves the centroids of the samples in each cluster to the mean of the samples in each cluster.", "response": "def _move_centroids(self):\n        \"\"\"Calculate new centroids as the means of the samples in each cluster\n        \"\"\"\n        for k in range(self.n_clusters):\n            if k in self.clusters:\n                centroid = np.mean(self._X[self.clusters == k, :], axis=0)\n                self.centroids[k] = centroid\n\n            else:\n                self.n_clusters-=1\n                self.centroids = self.centroids[:self.n_clusters]\n                self.clusters-=1\n                k-=1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _closest_centroid(self, x):\n        closest_centroid = 0\n        distance = 10^9\n\n        for i in range(self.n_clusters):\n            current_distance = linalg.norm(x - self.centroids[i])\n            if current_distance < distance:\n                closest_centroid = i\n                distance = current_distance\n\n        return closest_centroid", "response": "Returns the index of the closest centroid to the sample\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns the samples to the closest centroids to create clusters", "response": "def _assign_clusters(self):\n        \"\"\"Assign the samples to the closest centroids to create clusters\n        \"\"\"\n        self.clusters = np.array([self._closest_centroid(x) for x in self._X])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncause the bot to generate some jargon. Syntax: {command}", "response": "def cmd(send, *_):\n    \"\"\"Causes the bot to generate some jargon.\n\n    Syntax: {command}\n\n    \"\"\"\n    words = [[verb, noun, abbrev, noun, adj, abbrev, noun], [verb, adj, abbrev, noun], [verb, abbrev, noun, verb, adj, noun],\n             [verb, noun, ingverb, adj, abbrev, noun], [adj, abbrev, noun, verb, adj, noun], [abbrev, noun, verb, adj, noun, verb, abbrev, noun],\n             [ingverb, noun, verb, adj, abbrev, noun], [verb, adj, abbrev, noun, verb, abbrev, noun]]\n    msgtype = [\n        \"If we %s the %s, we can get to the %s %s through the %s %s %s!\" % tuple(map(choice, words[0])),\n        \"We need to %s the %s %s %s!\" % tuple(map(choice, words[1])),\n        \"Try to %s the %s %s, maybe it will %s the %s %s!\" % tuple(map(choice, words[2])),\n        \"You can't %s the %s without %s the %s %s %s!\" % tuple(map(choice, words[3])),\n        \"Use the %s %s %s, then you can %s the %s %s!\" % tuple(map(choice, words[4])),\n        \"The %s %s is down, %s the %s %s so we can %s the %s %s!\" % tuple(map(choice, words[5])),\n        \"%s the %s won't do anything, we need to %s the %s %s %s!\" % tuple(map(choice, words[6])),\n        \"I'll %s the %s %s %s, that should %s the %s %s!\" % tuple(map(choice, words[7]))\n    ]\n\n    send(choice(msgtype))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the F***ING weather!", "response": "def cmd(send, msg, _):\n    \"\"\"Gets the F***ING weather!\n    Syntax: {command} <location>\n    \"\"\"\n    try:\n        req = get('http://thefuckingweather.com/April/%s' % msg, timeout=5)\n        doc = fromstring(req.text)\n        elem = doc.find('.//h1')\n    except ReadTimeout:\n        elem = None\n    if elem is None:\n        send('NO FSCKING RESULTS.')\n    else:\n        send(elem.text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the needed text to automatically document a module in RSF.", "response": "def GetModuleText(heading, name, showprivate=False):\n        \"\"\"Returns the needed text to automatically document a module in RSF/sphinx\"\"\"\n        und = '='*len(heading)\n        if showprivate:\n            opts = ':private-members:'\n        else:\n            opts = ''\n        return r'''\n\n%s\n%s\n\n.. automodule:: %s\n    %s\n\n''' % (heading, und, name, opts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetClassText(heading, name, showprivate=False, showinh=False):\n        und = '-'*len(heading)\n        avail = [':private-members:', ':inherited-members:']\n        opts = []\n        if showprivate:\n            opts.append(avail[0])\n        if showinh:\n            opts.append(avail[1])\n        opts = '\\n'.join(opts)\n        return r'''\n\n%s\n%s\n\n.. autoclass:: %s\n    :show-inheritance:\n    :members:\n    :undoc-members:\n    %s\n\n''' % (heading, und, name, opts)", "response": "Returns the needed text to automatically document a class in RSF."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFunctionText(heading, name):\n        und = '-'*len(heading)\n        return r'''\n\n%s\n%s\n\n.. autofunction:: %s\n\n''' % (heading, und, name)", "response": "Returns the needed text to automatically document a function in RSF."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GenerateStaticsTable(self, title='Current Statistics'):\n        if len(self.__categories.keys()) < 1:\n            return ''\n        d = self.__categories\n        keys = sorted(d.keys())\n        cats = ', '.join(['\"%s\"' % k for k in keys])\n        vals = ', '.join(['%d' % d[k] for k in keys])\n\n        return r'''\n\n%s\n%s\n\n.. csv-table::\n   :header: %s\n\n   %s\n\n''' % (title, '-'*len(title), cats, vals)", "response": "Generates a statics table based on set categories"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ProduceContent(self, mods, showprivate=False, showinh=False):\n        result = ''\n        nestedresult = ''\n\n        # For each module\n        for mod in mods:\n            # Test to see if module to document has an __all__ variable\n            try:\n                all = mod[1].__all__\n            except AttributeError:\n                raise RuntimeError('Module (%s) MUST have `__all__` defined.' % mod[1].__name__)\n            if not showprivate and mod[0][0:1] == '_':\n                continue\n            if mod[0][0:2] == '__': #and not showprivate\n                continue\n            result += self._ProduceSingleContent(mod, showprivate, showinh)\n        return result", "response": "Internal helper to create pages for several modules that do not contain nested modules. This will automatically generate the needed RSF to document each module and save the module to its own page appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _DocPackageFromTop(self, packages, showprivate=False, showinh=False):\n        appIndex = ''\n        if not isinstance(packages, list):\n            packages = [packages]\n\n        if os.path.exists('content'):\n            shutil.rmtree('content')\n        os.makedirs('content')\n\n        appIndex += r'''\n\n.. toctree::\n   :maxdepth: 5\n   :hidden:\n   :caption: %s:\n\n''' % ('API Index')\n\n        # Iterate over each package and generate appropriate pages\n        for i in range(len(packages)):\n            # The package to document and its path\n            package = packages[i]\n            try:\n                name = package.__displayname__\n            except AttributeError:\n                name = package.__name__\n            # Make sure paths are ready\n            path = 'content/%s' % package.__name__\n            if os.path.exists(path):\n                shutil.rmtree(path)\n            os.makedirs(path)\n\n            # Check if there is top level documentation\n            # if package.__doc__:\n            # Get metadata\n            meta = 'About %s\\n%s\\n' % (name, '='*len('About ' + name))\n            author = getattr(package, \"__author__\", None)\n            license = getattr(package, \"__license__\", None)\n            copyright = getattr(package, \"__copyright__\", None)\n            version = getattr(package, \"__version__\", None)\n            if author: meta += '\\n* Author: %s' % author\n            if license: meta += '\\n* License: %s' % license\n            if copyright: meta += '\\n* Copyright: %s' % copyright\n            if version: meta += '\\n* Version: %s' % version\n            about = '%s/%s' % (path, 'index.rst')\n\n            this_toc = r'''\n\n.. toctree::\n   :maxdepth: 5\n   :caption: %s:\n''' % (name)\n\n            this_toc += self._MakePackagePages(package, showprivate=showprivate, showinh=showinh)\n            this_toc = this_toc.replace('%s/' % path, '')\n\n            with open(about, 'w') as f:\n                f.write('%s\\n\\n' % meta)\n                if package.__doc__:\n                    f.write(package.__doc__)\n                f.write(this_toc)\n\n            appIndex += '\\n   %s' % about\n\n        # Return the new content to append\n        return appIndex", "response": "Generates all of the documentation for given packages and appends new tocrees to the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserves a WSGI app to browse objects based on a root object or ZODB URI.", "response": "def eye(root=None, zodb_uri=None, port=8080):\n    \"\"\"Serves a WSGI app to browse objects based on a root object or ZODB URI.\n    \"\"\"\n    if root is not None:\n        root_factory = lambda request: Node(root)\n    elif zodb_uri is not None:\n        if '://' not in zodb_uri:\n            # treat it as a file://\n            zodb_uri = 'file://' + os.path.abspath(zodb_uri)        \n    \n        from repoze.zodbconn.finder import PersistentApplicationFinder\n        finder = PersistentApplicationFinder(zodb_uri, appmaker=lambda root: Node(root))\n        root_factory = lambda request: finder(request.environ)\n    else:\n        raise RuntimeError(\"Must specify root object or ZODB URI.\")\n    \n    app = Eye(root_factory)\n    \n    if 'DEBUG' in os.environ:\n        from repoze.debug.pdbpm import PostMortemDebug\n        app = PostMortemDebug(app)\n    \n    serve(app, host='127.0.0.1', port=port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, _, args):\n    if args['target'] == 'private':\n        send(\"You're all alone!\")\n        return\n    with args['handler'].data_lock:\n        channel = args['handler'].channels[args['target']]\n        voiced = len([x for x in args['handler'].voiced[args['target']].values() if x])\n        total = len(channel.users())\n    send(\"%d active users, %d total users, %g%% active\" % (voiced, total, voiced / total * 100))", "response": "Returns stats on the active users."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the end point of the resource.", "response": "def determine_end_point(http_request, url):\n    \"\"\"\n    returns detail, list or aggregates\n    \"\"\"\n    if url.endswith('aggregates') or url.endswith('aggregates/'):\n        return 'aggregates'\n    else:\n        return 'detail' if is_detail_url(http_request, url) else 'list'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_simulation(self):\n        for _ in range(self.num_fights):\n            # restore health between each fight\n            self.c1.stats['Health'] = self.c1.stats['max_health']\n            self.c2.stats['Health'] = self.c2.stats['max_health']\n            \n            # run the Battles\n            b = Battle(self.c1, self.c2, self.traits, self.rules, print_console='No')\n            #print(b)\n            if b.status == self.c1.name:\n                self.num_c1 += 1\n            else:\n                self.num_c2 += 1\n                \n        # tag winner        \n        if self.num_c1 > self.num_c2:\n            self.winner = self.c1.name\n        else:\n            self.winner = self.c2.name", "response": "runs the simulation for the base class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fight(self, moves, print_console):\n        for _ in range(1, moves):\n            #if i == 1 and random.randint(1,100) > 50:   # randomly choose who moves first\n            # player 1\n            result, dmg = self.calc_move(self.c1)\n            self.show_message(self.c1, self.c2, result, dmg, print_console)\n            self.take_damage(self.c2, dmg)\n            if self.is_character_dead(self.c2):\n                #print(self.c2.name + ' has died')\n                return self.c1.name\n                \n            # player 2\n            result, dmg = self.calc_move(self.c2)\n            self.show_message(self.c2, self.c1, result, dmg, print_console)\n            self.take_damage(self.c1, dmg)\n            if self.is_character_dead(self.c1):\n                #print(self.c1.name + ' has died')\n                return self.c2.name", "response": "runs a series of fights"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap to apply damage taken to a character", "response": "def take_damage(self, c, dmg):\n        \"\"\"\n        wrapper to apply damage taken to a character\n        \"\"\"\n        if c.name == self.c1.name:\n            self.c1.stats['Health'] = self.c1.stats['Health'] - dmg\n        else:\n            self.c2.stats['Health'] = self.c2.stats['Health'] - dmg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to wrap the display of the battle messages", "response": "def show_message(self, c_attack, c_defend, result, dmg, print_console='Yes'):\n        \"\"\"\n        function to wrap the display of the battle messages\n        \"\"\"\n        perc_health_att = '[' + str(round((c_attack.stats['Health']*100) / c_attack.stats['max_health'] )) + '%]'\n        perc_health_def = '[' + str(round((c_defend.stats['Health']*100) / c_defend.stats['max_health'] )) + '%]'\n        if result == 'Miss':\n            txt = c_attack.name + ' ' + perc_health_att.rjust(6) + ' miss ' + c_defend.name + ' ' + perc_health_def.rjust(6)\n        elif result == 'Crit':\n            txt = c_attack.name + ' ' + perc_health_att.rjust(6) + ' CRIT ' + c_defend.name + ' ' + perc_health_def.rjust(6)\n            txt +=  ' for ' + str(dmg)   \n        else:\n            txt = c_attack.name + ' ' + perc_health_att.rjust(6) + ' hits ' + c_defend.name + ' ' + perc_health_def.rjust(6) \n            txt +=  ' for ' + str(dmg)   \n        \n        if print_console == 'Yes':\n            print(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the amount of damage down using the battle. rules file", "response": "def calc_move(self, c):\n        \"\"\"\n        calculate the amount of damage down using the battle.rules file\n        WARNING - shitty eval functions - careful with user input.\n        TODO = max_hit = parser.parse(self.rules['hit_max']).to_pyfunc()\n        \"\"\"\n        \n        # first get local variables the same as battle.rules file so parser can interpret.\n        AGI = c.stats['AGI']\n        INT = c.stats['INT']\n        STR = c.stats['STR']\n        #STA = c.stats['STA']\n        #print('calc move : self.rules.all_rules[hit_min] = ', self.rules.all_rules['hit_min'])\n        #print('calc move : self.rules.all_rules[hit_max] = ', self.rules.all_rules['hit_max'])\n        #print('calc move :  = self.rules.all_rules[hit_limit]', self.rules.all_rules['hit_limit'])\n        hit_min   = float(self.rules.all_rules['hit_min'])\n        \n        hit_AGI_mult   = float(self.rules.all_rules['hit_AGI_mult'])\n        hit_INT_mult   = float(self.rules.all_rules['hit_INT_mult'])\n        hit_AGI_add   = float(self.rules.all_rules['hit_AGI_add'])\n        hit_INT_add   = float(self.rules.all_rules['hit_INT_add'])\n        hit_overall_add   = float(self.rules.all_rules['hit_overall_add'])\n        \n        #  hit_max = round(INT/2) + round(AGI/2) + 1\n        hit_max = round(INT*(hit_INT_mult + hit_INT_add)) + round(AGI*(hit_AGI_mult + hit_AGI_add)) + hit_overall_add\n        \n        hit_limit = float(self.rules.all_rules['hit_limit']) \n        if hit_max > hit_limit:\n            hit_max = hit_limit\n        chance_hit = random.randint(hit_min,hit_max)\n        \n        dmg_min   = float(self.rules.all_rules['dmg_min'])\n        #dmg_max   = eval(self.rules.all_rules['dmg_max'])\n        calc_agi = round((AGI + float(self.rules.all_rules['dmg_AGI_add'])) * float(self.rules.all_rules['dmg_AGI_mult']))\n        calc_int = round((INT + float(self.rules.all_rules['dmg_INT_add'])) * float(self.rules.all_rules['dmg_INT_mult']))\n        calc_str = round((STR + float(self.rules.all_rules['dmg_STR_add'])) * float(self.rules.all_rules['dmg_STR_mult'])) \n        #print('TESTING CALC_MOVE : calc_agi', calc_agi, 'calc_int',calc_int ,'calc_str',calc_str )\n        dmg_max = round((calc_agi + calc_int + calc_str) * float(self.rules.all_rules['dmg_overall_mult']) + float(self.rules.all_rules['dmg_overall_add']))\n\n        #print('hit_min  =',hit_min  , 'hit_max = ',hit_max  )\n        #print('dmg_min  =',dmg_min  , 'dmg_max = ',dmg_max  )\n        amount_dmg = random.randint(dmg_min, dmg_max)\n        \n        if chance_hit > float(self.rules.all_rules['shot_crit_greater_than']):\n            return 'Crit', amount_dmg * float(self.rules.all_rules['dmg_mult_crit'])\n        elif chance_hit < float(self.rules.all_rules['shot_hit_greater_than']):\n            return 'Miss', amount_dmg * float(self.rules.all_rules['dmg_mult_miss'])\n        else:\n            return 'Hit', amount_dmg * float(self.rules.all_rules['dmg_mult_hit'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterqueue(queue, expected):\n    while expected > 0:\n        for item in iter(queue.get, EXIT):\n            yield item\n        expected -= 1", "response": "Iterate all items from the queue until the expected number of EXIT elements is received"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the queue in input and the number of parallel tasks that send inputs", "response": "def set_in(self, que_in, num_senders):\n        \"\"\"Set the queue in input and the number of parallel tasks that send inputs\"\"\"\n        self._que_in = que_in\n        self._num_senders = num_senders"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_out(self, que_out, num_followers):\n        self._que_out = que_out\n        self._num_followers = num_followers", "response": "Set the queue in output and the number of parallel tasks that follow"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the task on all the input and send the needed number of EXIT at the end", "response": "def run(self):\n        \"\"\"Execute the task on all the input and send the needed number of EXIT at the end\"\"\"\n        input = self._consume()\n        put_item = self._que_out.put\n        \n        try:\n            if input is None: # producer\n                res = self._callable(*self._args, **self._kwargs)\n            else:\n                res = self._callable(input, *self._args, **self._kwargs)\n            if res != None:\n                for item in res:\n                    put_item(item)\n\n        except Exception as e:\n            # we catch an error, we send on the error que, we consume the input and we exit\n            # consuming the input queue avoid to keep running processes before exiting with\n            # errors\n            self._que_err.put((self.name, e))\n            if input is not None:\n                for i in input:\n                    pass\n            raise\n\n        finally:\n            for i in range(self._num_followers):\n                put_item(EXIT)\n            self._que_err.put(EXIT)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(self, workers=1, qsize=0):\n        if workers <= 0:\n            raise ValueError(\"workers have to be greater then zero\")\n        if qsize < 0:\n            raise ValueError(\"qsize have to be greater or equal zero\")\n        self.qsize = qsize # output que size\n        self.workers = workers\n        return self", "response": "Setup the pool parameters like number of workers and output queue size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitialising and return the list of processes associated with this pool", "response": "def processes(self):\n        \"\"\"Initialise and return the list of processes associated with this pool\"\"\"\n        if self._processes is None:\n            self._processes = []\n            for p in range(self.workers):\n                t = Task(self._target, self._args, self._kwargs)\n                t.name = \"%s-%d\" % (self.target_name, p)\n                self._processes.append(t)\n\n        return self._processes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_in(self, que_in, num_senders):\n        for p in self.processes:\n            p.set_in(que_in, num_senders)", "response": "Set the queue in input and the number of parallel tasks that send inputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_out(self, que_out, num_followers):\n        for p in self.processes:\n            p.set_out(que_out, num_followers)", "response": "Set the queue in output and the number of parallel tasks that follow"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts all the tasks and return data on an iterator", "response": "def results(self):\n        \"\"\"Start all the tasks and return data on an iterator\"\"\"\n        tt = None\n        for i, tf in enumerate(self[:-1]):\n            tt = self[i+1]\n            q = Queue(tf.qsize)\n            tf.set_out(q, tt.workers)\n            tt.set_in(q, tf.workers)\n\n        if tt is None: # we have only one pool\n            tt = self[0]\n        q = Queue(tt.qsize)\n        err_q = Queue()\n        tt.set_out(q, 1)\n\n        for t in self:\n            t.set_err(err_q)\n            t._start()\n\n        for item in iterqueue(q, tt.workers):\n            yield item\n\n        errors = list(iterqueue(err_q, sum(t.workers for t in self)))\n\n        for t in self:\n            t._join()\n\n        if len(errors) > 0:\n            task_name, ex = errors[0]\n            if len(errors) == 1:\n                msg = 'The task \"%s\" raised %s' % (task_name, repr(ex),)\n            else:\n                msg = '%d tasks raised an exeption. First error reported on task \"%s\": %s' % (len(errors), task_name, repr(ex))\n\n            raise TaskException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns serialized content for an office page.", "response": "def office_content(self, election_day, office):\n        \"\"\"\n        Return serialized content for an office page.\n        \"\"\"\n        from electionnight.models import PageType\n\n        office_type = ContentType.objects.get_for_model(office)\n        page_type = PageType.objects.get(\n            model_type=office_type,\n            election_day=election_day,\n            division_level=office.division.level,\n        )\n\n        page_content = self.get(\n            content_type__pk=office_type.pk,\n            object_id=office.pk,\n            election_day=election_day,\n        )\n        page_type_content = self.get(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election_day,\n        )\n        return {\n            \"site\": self.site_content(election_day)[\"site\"],\n            \"page_type\": self.serialize_content_blocks(page_type_content),\n            \"page\": self.serialize_content_blocks(page_content),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef body_content(self, election_day, body, division=None):\n        from electionnight.models import PageType\n\n        body_type = ContentType.objects.get_for_model(body)\n        page_type = PageType.objects.get(\n            model_type=body_type,\n            election_day=election_day,\n            body=body,\n            jurisdiction=body.jurisdiction,\n            division_level=body.jurisdiction.division.level,\n        )\n        page_type_content = self.get(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election_day,\n        )\n\n        kwargs = {\n            \"content_type__pk\": body_type.pk,\n            \"object_id\": body.pk,\n            \"election_day\": election_day,\n        }\n\n        if division:\n            kwargs[\"division\"] = division\n\n        content = self.get(**kwargs)\n        return {\n            \"site\": self.site_content(election_day)[\"site\"],\n            \"page_type\": self.serialize_content_blocks(page_type_content),\n            \"page\": self.serialize_content_blocks(content),\n            \"featured\": [\n                e.meta.ap_election_id for e in content.featured.all()\n            ],\n        }", "response": "Return serialized content for a body page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef division_content(self, election_day, division, special=False):\n        from electionnight.models import PageType\n\n        division_type = ContentType.objects.get_for_model(division)\n        page_type = PageType.objects.get(\n            model_type=division_type,\n            election_day=election_day,\n            division_level=division.level,\n        )\n        page_content = self.get(\n            content_type__pk=division_type.pk,\n            object_id=division.pk,\n            election_day=election_day,\n            special_election=special,\n        )\n        page_type_content = self.get(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election_day,\n        )\n        return {\n            \"site\": self.site_content(election_day)[\"site\"],\n            \"page_type\": self.serialize_content_blocks(page_type_content),\n            \"page\": self.serialize_content_blocks(page_content),\n        }", "response": "Return serialized content for a division page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef site_content(self, election_day):\n        from electionnight.models import PageType\n\n        page_type = PageType.objects.get(\n            model_type=ContentType.objects.get(\n                app_label=\"election\", model=\"electionday\"\n            ),\n            election_day=election_day,\n        )\n        site_content = self.get(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election_day,\n        )\n        return {\"site\": self.serialize_content_blocks(site_content)}", "response": "Return a dictionary of site content for the entire site on an election day."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Capitalize environment name", "response": "def get_env():\n    \"\"\"\n    Return the Capitalize environment name\n    It can be used to retrieve class base config\n    Default: Development\n    :returns: str\n    \"\"\"\n    env = \"Development\"\n    if _env_key in os.environ:\n        env = os.environ[_env_key].lower().capitalize()\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_app(kls):\n    if not hasattr(kls, \"__call__\"):\n        raise TypeError(\"init_app: '%s' is not callable\" % kls)\n    View._init_apps.add(kls)\n    return kls", "response": "Add a function to the list of middlewares that need the app object to be used for the view"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a package with the jinja2 library.", "response": "def register_package(pkg):\n    \"\"\"\n    Allow to register packages by loading and exposing: templates, static,\n    and exceptions for abort()\n\n    Structure of package\n        root\n            | $package_name\n                | __init__.py\n                |\n                | exceptions.py\n                |\n                | /templates\n                    |\n                    |\n                |\n                | /static\n                    |\n                    | assets.yml\n\n    :param pkg: str - __package__\n                    or __name__\n                    or The root dir\n                    or the dotted resource package (package.path.path,\n                    usually __name__ of templates and static\n    \"\"\"\n\n    root_pkg_dir = pkg\n    if not os.path.isdir(pkg) and \".\" in pkg:\n        root_pkg_dir = utils.get_pkg_resources_filename(pkg)\n\n    template_path = os.path.join(root_pkg_dir, \"templates\")\n    static_path = os.path.join(root_pkg_dir, \"static\")\n\n    logging.info(\"Registering Package: \" + pkg)\n    if os.path.isdir(template_path):\n        template_path = jinja2.FileSystemLoader(template_path)\n        View._template_paths.add(template_path)\n\n    if os.path.isdir(static_path):\n        View._static_paths.add(static_path)\n        View._add_asset_bundle(static_path)\n\n    if os.path.isfile(os.path.join(root_pkg_dir, \"exceptions.py\")):\n        exceptions = utils.import_string(pkg + \".exceptions\")\n        init_app(lambda x: abort.map_from_module(exceptions))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_interesting_members(base_class, cls):\n\n    base_members = dir(base_class)\n    predicate = inspect.ismethod if _py2 else inspect.isfunction\n    all_members = inspect.getmembers(cls, predicate=predicate)\n    return [member for member in all_members\n            if not member[0] in base_members\n            and ((hasattr(member[1], \"__self__\") and not member[1].__self__ in inspect.getmro(cls)) if _py2 else True)\n            and not member[0].startswith(\"_\")\n            and not member[0].startswith(\"before_\")\n            and not member[0].startswith(\"after_\")]", "response": "Returns a list of methods that can be routed to cls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_from_module(self, module):\n        maps = {}\n        for name in dir(module):\n            obj = getattr(module, name)\n            try:\n                if issubclass(obj, exceptions.HTTPException):\n                    maps[name] = obj\n            except TypeError as ter:\n                pass\n        self.mapping.update(maps)", "response": "Maps all classes in the given module with subclasses of exceptions. HTTPException\n to be called as error in with abort"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(cls, app, base_route=None, subdomain=None, route_prefix=None,\n                 trailing_slash=None):\n        \"\"\"Registers a FlaskView class for use with a specific instance of a\n        Flask app. Any methods not prefixes with an underscore are candidates\n        to be routed and will have routes registered when this method is\n        called.\n\n        :param app: an instance of a Flask application\n\n        :param base_route: The base path to use for all routes registered for\n                           this class. Overrides the base_route attribute if\n                           it has been set.\n\n        :param subdomain:  A subdomain that this registration should use when\n                           configuring routes.\n\n        :param route_prefix: A prefix to be applied to all routes registered\n                             for this class. Precedes base_route. Overrides\n                             the class' route_prefix if it has been set.\n        \"\"\"\n\n        if cls is FlaskView:\n            raise TypeError(\"cls must be a subclass of FlaskView, not FlaskView itself\")\n\n        if base_route:\n            cls.orig_base_route = cls.base_route\n            cls.base_route = base_route\n\n        if route_prefix:\n            cls.orig_route_prefix = cls.route_prefix\n            cls.route_prefix = route_prefix\n\n        if not subdomain:\n            if hasattr(app, \"subdomain\") and app.subdomain is not None:\n                subdomain = app.subdomain\n            elif hasattr(cls, \"subdomain\"):\n                subdomain = cls.subdomain\n\n        if trailing_slash is not None:\n            cls.orig_trailing_slash = cls.trailing_slash\n            cls.trailing_slash = trailing_slash\n\n        members = get_interesting_members(FlaskView, cls)\n        special_methods = [\"get\", \"put\", \"patch\", \"post\", \"delete\", \"index\"]\n\n        for name, value in members:\n            proxy = cls.make_proxy_method(name)\n            route_name = cls.build_route_name(name)\n            try:\n                if hasattr(value, \"_rule_cache\") and name in value._rule_cache:\n                    for idx, cached_rule in enumerate(value._rule_cache[name]):\n                        rule, options = cached_rule\n                        rule = cls.build_rule(rule)\n                        sub, ep, options = cls.parse_options(options)\n\n                        if not subdomain and sub:\n                            subdomain = sub\n\n                        if ep:\n                            endpoint = ep\n                        elif len(value._rule_cache[name]) == 1:\n                            endpoint = route_name\n                        else:\n                            endpoint = \"%s_%d\" % (route_name, idx,)\n\n                        app.add_url_rule(rule, endpoint, proxy,\n                                         subdomain=subdomain,\n                                         **options)\n                elif name in special_methods:\n                    if name in [\"get\", \"index\"]:\n                        methods = [\"GET\"]\n                        if name == \"index\":\n                            if hasattr(value, \"_methods_cache\"):\n                                methods = value._methods_cache\n                    else:\n                        methods = [name.upper()]\n\n                    rule = cls.build_rule(\"/\", value)\n                    if not cls.trailing_slash:\n                        rule = rule.rstrip(\"/\")\n                    app.add_url_rule(rule, route_name, proxy,\n                                     methods=methods,\n                                     subdomain=subdomain)\n\n                else:\n                    methods = value._methods_cache \\\n                        if hasattr(value, \"_methods_cache\") \\\n                        else [\"GET\"]\n\n                    name = utils.dasherize(name)\n                    route_str = '/%s/' % name\n                    if not cls.trailing_slash:\n                        route_str = route_str.rstrip('/')\n                    rule = cls.build_rule(route_str, value)\n                    app.add_url_rule(rule, route_name, proxy,\n                                     subdomain=subdomain,\n                                     methods=methods)\n            except DecoratorCompatibilityError:\n                raise DecoratorCompatibilityError(\"Incompatible decorator detected on %s in class %s\" % (name, cls.__name__))\n\n        if hasattr(cls, \"orig_base_route\"):\n            cls.base_route = cls.orig_base_route\n            del cls.orig_base_route\n\n        if hasattr(cls, \"orig_route_prefix\"):\n            cls.route_prefix = cls.orig_route_prefix\n            del cls.orig_route_prefix\n\n        if hasattr(cls, \"orig_trailing_slash\"):\n            cls.trailing_slash = cls.orig_trailing_slash\n            del cls.orig_trailing_slash", "response": "Registers a FlaskView class for use with a specific instance of a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the template file of the action view", "response": "def render_(cls, data={}, template_=None, layout_=None, **kwargs):\n        \"\"\"\n        To render data to the associate template file of the action view\n        :param data: The context data to pass to the template\n        :param template_: The file template to use. By default it will map the classname/action.html\n        :param layout_: The body layout, must contain {% include __template__ %}\n        \"\"\"\n        if not template_:\n            stack = inspect.stack()[1]\n            module = inspect.getmodule(cls).__name__\n            module_name = module.split(\".\")[-1]\n            action_name = stack[3]      # The method being called in the class\n            view_name = cls.__name__    # The name of the class without View\n\n            if view_name.endswith(\"View\"):\n                view_name = view_name[:-4]\n            template_ = \"%s/%s.html\" % (view_name, action_name)\n\n        data = data or dict()\n        if kwargs:\n            data.update(kwargs)\n        data[\"__\"] = cls._global\n        data[\"__template__\"] = template_\n\n        return render_template(layout_ or cls.base_layout, **data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef meta_tags(cls, **kwargs):\n        page_meta = cls._global.get(\"__META__\", {})\n        page_meta.update(**kwargs)\n        cls.g(__META__=page_meta)", "response": "Meta allows you to add meta data to site s meta tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize(self, value=()):\n        if value == ():\n            try:\n                return self.default()\n            except TypeError:\n                return self.default\n        else:\n            return self.clean(value)", "response": "\\ initialize returns a cleaned value or the default value raising ValueErrors\n        as necessary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclean a value converting and performing bounds checking", "response": "def clean(self, value):\n        \"\"\"clean a value, converting and performing bounds checking\"\"\"\n        if not isinstance(value, self.t):\n            value = self.t(value)\n\n        if not self.allow_negative and value < 0:\n            raise ValueError('value was negative')\n\n        if not self.allow_positive and value > 0:\n            raise ValueError('values was positive')\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef r12_serial_port(port):\n    ''' Create a serial connect to the arm. '''\n    return serial.Serial(port, baudrate=BAUD_RATE, parity=PARITY,\n                         stopbits=STOP_BITS, bytesize=BYTE_SIZE)", "response": "Create a serial connection to the arm."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for a USB port in the system.", "response": "def search_for_port(port_glob, req, expected_res):\n    ''' Find the serial port the arm is connected to. '''\n\n    # Check that the USB port actually exists, based on the known vendor and\n    # product ID.\n    if usb.core.find(idVendor=0x0403, idProduct=0x6001) is None:\n        return None\n\n    # Find ports matching the supplied glob.\n    ports = glob.glob(port_glob)\n    if len(ports) == 0:\n        return None\n\n    for port in ports:\n        with r12_serial_port(port) as ser:\n            if not ser.isOpen():\n                ser.open()\n\n            # Write a request out.\n            if sys.version_info[0] == 2:\n                ser.write(str(req).encode('utf-8'))\n            else:\n                ser.write(bytes(req, 'utf-8'))\n\n            # Wait a short period to allow the connection to generate output.\n            time.sleep(0.1)\n\n            # Read output from the serial connection check if it's what we want.\n            res = ser.read(ser.in_waiting).decode(OUTPUT_ENCODING)\n            if expected_res in res:\n                return port\n\n    raise ArmException('ST Robotics connection found, but is not responsive.'\n                       + ' Is the arm powered on?')\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self, port=None):\n        ''' Open a serial connection to the arm. '''\n        if port is None:\n            self.port = search_for_port('/dev/ttyUSB*', 'ROBOFORTH\\r\\n',\n                                        'ROBOFORTH')\n        else:\n            self.port = port\n\n        if self.port is None:\n            raise ArmException('ST Robotics connection not found.')\n\n        self.ser = r12_serial_port(port)\n\n        if not self.ser.isOpen():\n            self.ser.open()\n\n        if not self.ser.isOpen():\n            raise ArmException('Failed to open serial port. Exiting.')\n\n        return self.port", "response": "Open a serial connection to the arm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, text):\n        ''' Write text out to the arm. '''\n        # Output is converted to bytes with Windows-style line endings.\n        if sys.version_info[0] == 2:\n            text_bytes = str(text.upper() + '\\r\\n').encode('utf-8')\n        else:\n            text_bytes = bytes(text.upper() + '\\r\\n', 'utf-8')\n        self.ser.write(text_bytes)", "response": "Write text out to the arm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, timeout=READ_TIMEOUT, raw=False):\n        ''' Read data from the arm. Data is returned as a latin_1 encoded\n            string, or raw bytes if 'raw' is True. '''\n        time.sleep(READ_SLEEP_TIME)\n        raw_out = self.ser.read(self.ser.in_waiting)\n        out = raw_out.decode(OUTPUT_ENCODING)\n\n        time_waiting = 0\n        while len(out) == 0 or ending_in(out.strip(OUTPUT_STRIP_CHARS), RESPONSE_END_WORDS) is None:\n            time.sleep(READ_SLEEP_TIME)\n            time_waiting += READ_SLEEP_TIME\n\n            raw_out += self.ser.read(self.ser.in_waiting)\n            out = raw_out.decode(OUTPUT_ENCODING)\n\n            # TODO how to handle timeouts, if they're now unexpected?\n            if time_waiting >= timeout:\n                break\n\n        if raw:\n            return raw_out\n        return out", "response": "Read data from the arm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump all output currently in the arm s output queue.", "response": "def dump(self, raw=False):\n        ''' Dump all output currently in the arm's output queue. '''\n        raw_out = self.ser.read(self.ser.in_waiting)\n        if raw:\n            return raw_out\n        return raw_out.decode(OUTPUT_ENCODING)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn status of the robot arm.", "response": "def get_info(self):\n        ''' Returns status of the robot arm. '''\n        return {\n            'Connected': self.is_connected(),\n            'Port': self.port,\n            'Bytes Waiting': self.ser.in_waiting if self.ser else 0\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets details of OpenSenseMap station.", "response": "async def get_data(self):\n        \"\"\"Get details of OpenSenseMap station.\"\"\"\n        try:\n            async with async_timeout.timeout(5, loop=self._loop):\n                response = await self._session.get(self.base_url)\n\n            _LOGGER.info(\n                \"Response from OpenSenseMap API: %s\", response.status)\n            self.data = await response.json()\n            _LOGGER.debug(self.data)\n\n        except (asyncio.TimeoutError, aiohttp.ClientError, socket.gaierror):\n            _LOGGER.error(\"Can not load data from openSenseMap API\")\n            raise exceptions.OpenSenseMapConnectionError"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_value(self, key):\n        for title in _TITLES.get(key, ()) + (key,):\n            try:\n                value = [entry['lastMeasurement']['value'] for entry in\n                         self.data['sensors'] if entry['title'] == title][0]\n                return value\n            except IndexError:\n                pass\n        return None", "response": "Extract a value for a given key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd(send, msg, args):\n    if not args['config']['feature'].getboolean('hooks'):\n        send(\"Hooks are disabled, and this command depends on hooks. Please contact the bot admin(s).\")\n        return\n    if args['type'] == 'privmsg':\n        send(\"Note-passing should be done in public.\")\n        return\n    try:\n        nick, note = msg.split(maxsplit=1)\n        nicks = set(x for x in nick.split(',') if x)\n    except ValueError:\n        send(\"Not enough arguments.\")\n        return\n    nickregex = args['config']['core']['nickregex'] + '+$'\n    successful_nicks = []\n    failed_nicks = []\n    for nick in nicks:\n        if re.match(nickregex, nick):\n            row = Notes(note=note, submitter=args['nick'], nick=nick, time=datetime.now())\n            args['db'].add(row)\n            successful_nicks.append(nick)\n        else:\n            failed_nicks.append(nick)\n    if successful_nicks:\n        send(\"Note left for %s.\" % \", \".join(successful_nicks))\n    if failed_nicks:\n        send(\"Invalid nick(s): %s.\" % \", \".join(failed_nicks))", "response": "Leaves a note for a user or users."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_frame(klass, frame, connection):\n        event = frame.headers['new']\n        data = json.loads(frame.body)\n        info = data['info']\n        build = Build.fromDict(info)\n        build.connection = connection\n        return klass(build, event)", "response": "Create a new BuildStateChange event from a Stompest Frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_frame(klass, frame, connection):\n        event = frame.headers['new']\n        data = json.loads(frame.body)\n        info = data['info']\n        task = Task.fromDict(info)\n        task.connection = connection\n        return klass(task, event)", "response": "Create a new TaskStateChange event from a Stompest Frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tag(self):\n        name_or_id = self.task.tag\n        if name_or_id is None:\n            return defer.succeed(None)\n        if isinstance(name_or_id, StringType):\n            return defer.succeed(name_or_id)\n        if isinstance(name_or_id, int):\n            return self.task.connection.cache.tag_name(name_or_id)\n        return defer.fail()", "response": "Return a deferred that will be fulfilled when the Koji tag is changed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a deferred user name for this change.", "response": "def user(self):\n        \"\"\" Return a (deferred) cached Koji user name for this change. \"\"\"\n        # Note, do any tasks really have an \"owner_id\", or are they all\n        # \"owner\"?\n        owner_id = getattr(self.task, 'owner_id', self.task.owner)\n        return self.task.connection.cache.user_name(owner_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_raw(self, raw):\n        if type(raw) == list:\n            self._q += raw\n        if type(raw) == dict:\n            self._q.append(raw)\n        return self", "response": "Adds row aggregation state at the query\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef project(self, id=None, *args, **kwargs):\n        projection = {}\n\n        if id is not None:\n            projection['_id'] = id\n\n        for arg in args:\n            projection[arg] = 1\n\n        for kwarg in kwargs:\n            projection[kwarg] = kwargs[kwarg]\n\n        self._q.append({\n            '$project': projection\n        })\n\n        return self", "response": "Adds a projection stage at the query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a match stage at the query", "response": "def match(self, query_dict=None, **query):\n        \"\"\"\n        Adds a match stage at the query\n        :param query_dict: The params as dict\n        :param query: The parameters of the query\n        :return: The current object\n        \"\"\"\n        if query_dict:\n            self._q.append({'$match': query_dict})\n        else:\n            self._q.append({'$match': query})\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a group stage at aggregation", "response": "def group(self, id=None, **kwargs):\n        \"\"\"\n        Adds a group stage at aggregation query\n        :param id: The group id. Default value is None and group merge all documents\n        :param kwargs: The parameters-methods of group stage\n        :return: The current object\n        \"\"\"\n        if type(id) == str:\n            if not id.startswith('$'):\n                id = '$' + id\n        query = {\n            '_id': id\n        }\n        for key in kwargs:\n            query[key] = kwargs[key]\n        self._q.append({\n            '$group': query\n        })\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unwind(self, path, include_array_index=None, preserve_null_and_empty_arrays=False):\n        unwind_query = {}\n        unwind_query['$unwind'] = path if path[0] == '$' else '$' + path\n\n        if include_array_index:\n            unwind_query['includeArrayIndex'] = include_array_index\n        if preserve_null_and_empty_arrays:\n            unwind_query['preserveNullAndEmptyArrays'] = True\n        self._q.append(unwind_query)\n        return self", "response": "Adds an unwind stage to deconstruct an array of class entry entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort(self, **kwargs):\n        query = {}\n        for field in kwargs:\n            query[field] = kwargs[field]\n        self._q.append({'$sort': query})\n        return self", "response": "Adds a sort stage to aggregation query\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef look_up(self, _from, _localField, _foreignField, _as):\n        query = {\n            'from': _from,\n            'localField': _localField,\n            'foreignField': _foreignField,\n            'as': _as\n        }\n        self._q.append({'$lookup': query})\n        return self", "response": "Adds a look up stage at query to add the new array field to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a graph lookup operation on a collection.", "response": "def graph_look_up(self, _from, _startWith, _connectFromField, _connectToField,\n                      _as, _maxDepth=None, _depthField=None, _restrictSearchWithMatch=None):\n        \"\"\"\n        Performs a recursive search on a collection, with options for restricting the search by recursion depth and query filter.\n        :param _from: Target collection for the $graphLookup operation to search, recursively matching the connectFromField to the connectToField.\n        :param _startWith: Expression that specifies the value of the connectFromField with which to start the recursive search.\n        :param _connectFromField: Field name whose value $graphLookup uses to recursively match against the connectToField of other documents in the collection.\n        :param _connectToField: Field name in other documents against which to match the value of the field specified by the connectFromField parameter.\n        :param _as: Name of the array field added to each output document.\n        :param _maxDepth: Non-negative integral number specifying the maximum recursion depth.\n        :param _depthField: Name of the field to add to each traversed document in the search path.\n        :param _restrictSearchWithMatch: A document specifying additional conditions for the recursive search.\n        :return: The current object\n        \"\"\"\n        query = {\n            'from': _from,\n            'startWith': _startWith,\n            'connectFromField': _connectFromField,\n            'connectToField': _connectToField,\n            'as': _as\n        }\n        if _maxDepth:\n            query['maxDepth'] = _maxDepth\n        if _depthField:\n            query['depthField'] = _depthField\n        if _restrictSearchWithMatch:\n            query['restrictSearchWithMatch'] = _restrictSearchWithMatch\n        self._q.append({'$graphLookup': query})\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a stage to aggregation query which adds new fields to documents.", "response": "def add_fields(self, **fields):\n        \"\"\"\n        Adds a stage to aggregation query which adds new fields to documents.\n        :param fields: The fields that will be created\n        :return: The current object\n        \"\"\"\n        query = {}\n        for field in fields:\n            query[field] = fields[field]\n        self._q.append({'$addFields': query})\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self):\n        if self.query_set_obj is None:\n            return []\n\n        if self.is_mongoengine:\n            result = self.query_set_obj.aggregate(*self.get_query())\n        else:\n            result = self.query_set_obj.aggregate(self.get_query())\n\n        if IS_PYMONGO_3:\n            result = list(result)\n        else:\n            result = result.get('result')\n        if result:\n            return result\n        return []", "response": "Executes the query and returns the result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, args):\n    if not msg:\n        send(\"Ping what?\")\n        return\n    channel = args['target'] if args['target'] != 'private' else args['nick']\n    # CTCP PING\n    if \".\" not in msg and \":\" not in msg:\n        targets = set(msg.split())\n        if len(targets) > 3:\n            send(\"Please specify three or fewer people to ping.\")\n            return\n        for target in targets:\n            if not re.match(args['config']['core']['nickregex'], target):\n                send(\"Invalid nick %s\" % target)\n            else:\n                args['handler'].ping_map[target] = channel\n                args['handler'].connection.ctcp(\"PING\", target, \" \".join(str(time()).split('.')))\n        return\n    try:\n        answer = subprocess.check_output([args['name'], '-W', '1', '-c', '1', msg], stderr=subprocess.STDOUT)\n        answer = answer.decode().splitlines()\n        send(answer[0])\n        send(answer[1])\n    except subprocess.CalledProcessError as e:\n        if e.returncode == 2:\n            send(\"ping: unknown host \" + msg)\n        elif e.returncode == 1:\n            send(e.output.decode().splitlines()[-2])", "response": "Ping something.\n\n    Syntax: {command} <target>"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def execute_job(self):\n        self.execution_start = datetime.now()\n\n        # exit early if execution is not possible\n        if not self.can_be_executed:\n            return self._set_job_outputs(RunStatus.DID_NOT_RUN)\n\n        exe = self.get_exe_path()\n        dfile = self.write_dfile()\n        outfile = self.get_outfile(dfile)\n        o2 = outfile.replace(\".out\", \".002\")\n\n        proc = await asyncio.create_subprocess_exec(\n            exe, dfile, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n        )\n\n        try:\n            stdout, stderr = await asyncio.wait_for(\n                proc.communicate(), timeout=settings.BMDS_MODEL_TIMEOUT_SECONDS\n            )\n\n            output = None\n            if os.path.exists(outfile):\n                with open(outfile, \"r\") as f:\n                    output = f.read()\n\n            self._set_job_outputs(\n                RunStatus.SUCCESS,\n                stdout=stdout.decode().strip(),\n                stderr=stderr.decode().strip(),\n                output=output,\n            )\n\n        except asyncio.TimeoutError:\n            proc.kill()\n            stdout, stderr = await proc.communicate()\n            self._set_job_outputs(RunStatus.FAILURE)\n\n        finally:\n            if os.path.exists(outfile):\n                self.tempfiles.append(outfile)\n            else:\n                with open(dfile, \"r\") as f:\n                    txt = f.read()\n                logger.info(\"Output file not created: \\n{}\\n\\n\".format(txt))\n\n            if os.path.exists(o2):\n                self.tempfiles.append(o2)\n\n            self.tempfiles.cleanup()", "response": "Execute the BMDS model and parse outputs if successful."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning total execution time in seconds.", "response": "def execution_duration(self):\n        \"\"\"\n        Returns total BMDS execution time, in seconds.\n        \"\"\"\n        duration = None\n        if self.execution_start and self.execution_end:\n            delta = self.execution_end - self.execution_start\n            duration = delta.total_seconds()\n        return duration"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_exe_path(cls):\n        return os.path.abspath(os.path.join(ROOT, cls.bmds_version_dir, cls.exe + \".exe\"))", "response": "Returns the full path to the executable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(self):\n        fig = self.dataset.plot()\n        ax = fig.gca()\n        ax.set_title(\n            \"{}\\n{}, {}\".format(self.dataset._get_dataset_name(), self.name, self.get_bmr_text())\n        )\n        if self.has_successfully_executed:\n            self._set_x_range(ax)\n            ax.plot(self._xs, self.get_ys(self._xs), label=self.name, **plotting.LINE_FORMAT)\n            self._add_bmr_lines(ax)\n        else:\n            self._add_plot_failure(ax)\n\n        ax.legend(**settings.LEGEND_OPTS)\n\n        return fig", "response": "Plot the dataset curve - fit BMD and BMDL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_dfile(self):\n        f_in = self.tempfiles.get_tempfile(prefix=\"bmds-\", suffix=\".(d)\")\n        with open(f_in, \"w\") as f:\n            f.write(self.as_dfile())\n        return f_in", "response": "Write the generated d_file to a temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets option value or use default value.", "response": "def _get_option_value(self, key):\n        \"\"\"\n        Get option value(s), or use default value if no override value.\n\n        Two output values for 'p' type values (parameters), else one.\n        Returns a single value or tuple of two values\n        \"\"\"\n        fn_name = \"set_{}_value\".format(key)\n        if key in self.overrides:\n            val = self.overrides[key]\n        elif hasattr(self, fn_name):\n            val = getattr(self, fn_name)()\n        else:\n            val = self.defaults[key][\"d\"]\n\n        if self.defaults[key][\"t\"] == constants.FT_PARAM:\n            return val.split(\"|\")\n        else:\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self, model_index):\n        return dict(\n            name=self.name,\n            model_index=model_index,\n            model_name=self.model_name,\n            model_version=self.version,\n            has_output=self.output_created,\n            dfile=self.as_dfile(),\n            execution_halted=self.execution_halted,\n            stdout=self.stdout,\n            stderr=self.stderr,\n            outfile=getattr(self, \"outfile\", None),\n            output=getattr(self, \"output\", None),\n            logic_bin=getattr(self, \"logic_bin\", None),\n            logic_notes=getattr(self, \"logic_notes\", None),\n            recommended=getattr(self, \"recommended\", None),\n            recommended_variable=getattr(self, \"recommended_variable\", None),\n        )", "response": "Returns a dictionary representation of the current state of the current model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_config(d1, d2):\n    '''Merges to config dicts. Key values are case insensitive for merging,\n    but the value of d1 is remembered.\n    '''\n    result = deepcopy(d1)\n    elements = deque()\n    elements.append((result, d2))\n\n    while elements:\n        old, new = elements.popleft()\n\n        new = OrderedDict([(k.lower(), (k, v)) for k, v in new.items()])\n        visited_keys = []\n\n        for k, old_value in old.items():\n            klow = k.lower()\n            if klow in new:\n                new_key, new_value = new[klow]\n                visited_keys.append(new_key)\n                if all(isinstance(e, MutableMapping) for e in (old_value, new_value)):\n                    elements.append((old_value, new_value))\n                else:\n                    old[k] = deepcopy(new_value)\n\n        for k, v in new.values():\n            if k not in visited_keys:\n                old[k] = deepcopy(v)\n\n    return result", "response": "Merges two config dicts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_if_none(user_config, config, key, value):\n    '''\n    If the value of the key in is None, and doesn't exist on the user config,\n    set it to a different value\n    '''\n\n    keys = key.split('.')\n    for k in keys[:-1]:\n        try:\n            user_config = user_config[k]\n        except KeyError:\n            user_config = {}\n\n        config = config[k]\n\n    key = keys[-1]\n\n    if key not in user_config and not config[key]:\n        config[key] = value", "response": "Set the value of the key in config to value if the value of the key in is None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the line number of the first version - like header in the changelog file.", "response": "def get_header(changelog):\n    \"\"\"Return line number of the first version-like header.  We check for\n    patterns like '2.10 (unreleased)', so with either 'unreleased' or a date\n    between parenthesis as that's the format we're using.  As an alternative,\n    we support an alternative format used by some zope/plone paster templates:\n    '2.10 - unreleased' or '2.10 ~ unreleased' Note that new headers are in our\n    preferred form (so 'version (date)').\n    \"\"\"\n    pattern = re.compile(r\"\"\"\n    (?P<version>.+)  # Version string\n    \\(               # Opening (\n    (?P<date>.+)     # Date\n    \\)               # Closing )\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    alt_pattern = re.compile(r\"\"\"\n    ^                # Start of line\n    (?P<version>.+)  # Version string\n    \\ [-~]\\          # space dash/twiggle space\n    (?P<date>.+)     # Date\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    with changelog.open('rt') as f:\n        for line_number, line in enumerate(f):\n            match = pattern.search(line)\n            alt_match = alt_pattern.search(line)\n            if match or alt_match:\n                return line_number"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_admin(msg, handler):\n    if handler.config['feature']['servicestype'] == \"ircservices\":\n        match = re.match(\"STATUS (.*) ([0-3])\", msg)\n    elif handler.config['feature']['servicestype'] == \"atheme\":\n        match = re.match(\"(.*) ACC ([0-3])\", msg)\n    if match:\n        status = int(match.group(2))\n        nick = match.group(1)\n        if status != 3:\n            return\n        with handler.db.session_scope() as session:\n            admin = session.query(Permissions).filter(Permissions.nick == nick).first()\n            if admin is None:\n                session.add(Permissions(nick=nick, role='admin', registered=True, time=datetime.now()))\n            else:\n                admin.registered = True\n                admin.time = datetime.now()", "response": "Handle admin verification responses from NickServ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_tuple(obj, len_=None):\n    if not isinstance(obj, tuple):\n        return False\n\n    if len_ is None:\n        return True\n    if not isinstance(len_, Integral):\n        raise TypeError(\n            \"length must be a number (got %s instead)\" % type(len_).__name__)\n    if len_ < 0:\n        raise ValueError(\"length must be positive (got %s instead)\" % len_)\n\n    return len(obj) == len_", "response": "Checks whether given object is a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether argument is a tuple.", "response": "def ensure_tuple(arg, len_=None):\n    \"\"\"Checks whether argument is a tuple.\n    :param len_: Optional expected length of the tuple\n    :return: Argument, if it's a tuple (of given length, if any)\n    :raise TypeError: When argument is not a tuple (of given length, if any)\n    \"\"\"\n    if not is_tuple(arg, len_=len_):\n        len_part = \"\" if len_ is None else \" of length %s\" % len_\n        raise TypeError(\n            \"expected tuple%s, got %s\" % (len_part, _describe_type(arg)))\n    return arg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects a subsequence of given tuple including only specified indices.", "response": "def select(indices, from_, strict=False):\n    \"\"\"Selects a subsequence of given tuple, including only specified indices.\n\n    :param indices: Iterable of indices to include\n    :param strict: Whether ``indices`` are required to exist in the tuple.\n\n    :return: Tuple with selected elements, in the order corresponding\n             to the order of ``indices``.\n\n    :raise IndexError: If ``strict`` is True and one of ``indices``\n                       is out of range.\n    \"\"\"\n    ensure_iterable(indices)\n    ensure_sequence(from_)\n\n    if strict:\n        return from_.__class__(from_[index] for index in indices)\n    else:\n        len_ = len(from_)\n        return from_.__class__(from_[index] for index in indices\n                               if 0 <= index < len_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a subsequence from given tuple omitting specified indices.", "response": "def omit(indices, from_, strict=False):\n    \"\"\"Returns a subsequence from given tuple, omitting specified indices.\n\n    :param indices: Iterable of indices to exclude\n    :param strict: Whether ``indices`` are required to exist in the tuple\n\n    :return: Tuple without elements of specified indices\n\n    :raise IndexError: If ``strict`` is True and one of ``indices``\n                       is out of range.\n\n    .. versionadded:: 0.0.3\n    \"\"\"\n    from taipan.collections.sets import remove_subset\n\n    ensure_iterable(indices)\n    ensure_sequence(from_)\n\n    if strict:\n        remaining_indices = set(xrange(len(from_)))\n        try:\n            remove_subset(remaining_indices, indices)\n        except KeyError as e:\n            raise IndexError(int(str(e)))\n    else:\n        remaining_indices = set(xrange(len(from_))) - set(indices)\n\n    return from_.__class__(from_[index] for index in remaining_indices)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _describe_type(arg):\n    if isinstance(arg, tuple):\n        return \"tuple of length %s\" % len(arg)\n    else:\n        return type(arg).__name__", "response": "Describe given argument including length if it s a tuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a URL to the image file for the specified type and size.", "response": "def _create_image_url(self, file_path, type_, target_size):\n        \"\"\"The the closest available size for specified image type.\n\n        Arguments:\n          file_path (:py:class:`str`): The image file path.\n          type_ (:py:class:`str`): The type of image to create a URL\n            for, (``'poster'`` or ``'profile'``).\n          target_size (:py:class:`int`): The size of image to aim for (used\n            as either width or height).\n\n        \"\"\"\n        if self.image_config is None:\n            logger.warning('no image configuration available')\n            return\n        return ''.join([\n            self.image_config['secure_base_url'],\n            self._image_size(self.image_config, type_, target_size),\n            file_path,\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new instance of the class from a JSON dict.", "response": "def from_json(cls, json, image_config=None):\n        \"\"\"Create a model instance\n\n        Arguments:\n          json (:py:class:`dict`): The parsed JSON data.\n          image_config (:py:class:`dict`): The API image configuration\n            data.\n\n        Returns:\n          :py:class:`BaseModel`: The model instance.\n\n        \"\"\"\n        cls.image_config = image_config\n        return cls(**{\n            attr: json.get(attr if key is None else key)\n            for attr, key in cls.JSON_MAPPING.items()\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the closest available size for the specified image type.", "response": "def _image_size(image_config, type_, target_size):\n        \"\"\"Find the closest available size for specified image type.\n\n        Arguments:\n          image_config (:py:class:`dict`): The image config data.\n          type_ (:py:class:`str`): The type of image to create a URL\n            for, (``'poster'`` or ``'profile'``).\n          target_size (:py:class:`int`): The size of image to aim for (used\n            as either width or height).\n\n        \"\"\"\n        return min(\n            image_config['{}_sizes'.format(type_)],\n            key=lambda size: (abs(target_size - int(size[1:]))\n                              if size.startswith('w') or size.startswith('h')\n                              else 999),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_n_random_num(n, MAX_NUM=MAX_INT, unique=True):\n    fmt = \"<%dI\" % n\n    t = struct.calcsize(fmt)\n    D = [d % MAX_NUM for d in struct.unpack(fmt, os.urandom(t))]\n    if unique:\n        D = set(D)\n        assert MAX_NUM > n, \\\n            \"Cannot have {0} unique integers less than {1}\".format(n, MAX_NUM)\n        while len(D) < n:\n            print(\"Number of collision: {}. Regenerating!\".format(n - len(D)))\n            fmt = \"<%dI\" % (n - len(D))\n            t = struct.calcsize(fmt)\n            extra = struct.unpack(fmt, os.urandom(t))\n            D |= set(d % MAX_NUM for d in extra)\n        D = list(D)\n    return D", "response": "Generate a random number of n unsigned integers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample_following_dist(handle_iter, n, totalf):\n    multiplier = 1.0\n    if totalf == 1.0:\n        multiplier = 1e8\n        # print \"WARNING!! I don't except probabilities\"\n\n    totalf = totalf * multiplier\n    # print(\"# Population Size\", totalf)\n    A = gen_n_random_num(n, totalf, unique=False)\n    A.sort(reverse=True)\n    # Uniqueness check, non necessarily required, but not very\n    # computationally intensive\n    assert len(A) == n, \"Not enough randomnumbers generated\" \\\n                        \"Requried {}, generated only {}\".format(n, len(A))\n    # if not all(A[i] != A[i-1] for i in range(1,n,1)):\n    #     for i in range(1,n,1):\n    #         if A[i] == A[i-1]:\n    #             print i, A[i], A[i-1]\n    j, sampled = 0, 0\n    val = A.pop()\n    # print(handle_iter)\n    for w, f in handle_iter:\n        j += f * multiplier\n        while val < j:\n            sampled += 1\n            if sampled % 5000 == 0:\n                print(\"Sampled:\", sampled)\n            yield (val, w)\n            if A:\n                val = A.pop()\n            else:\n                val = -1\n                break\n        if not A and val == -1:\n            break\n\n    # print(\"# Stopped at:\", w, f, j, '\\n', file=sys.stderr)\n    while A and val < j:\n        yield (val, w)\n        if A:\n            i, val = A.pop()\n        else:\n            break", "response": "Generates n random passwords following the distribution from the handle_iter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the type of file e. g. gz bz2 normal", "response": "def file_type(filename, param='rb'):\n    \"\"\"returns the type of file, e.g., gz, bz2, normal\"\"\"\n    magic_dict = {\n        b\"\\x1f\\x8b\\x08\": \"gz\",\n        b\"\\x42\\x5a\\x68\": \"bz2\",\n        b\"\\x50\\x4b\\x03\\x04\": \"zip\"\n    }\n    if param.startswith('w'):\n        return filename.split('.')[-1]\n    max_len = max(len(x) for x in magic_dict)\n    with open(filename, 'rb') as f:\n        file_start = f.read(max_len)\n    for magic, filetype in list(magic_dict.items()):\n        if file_start.startswith(magic):\n            return filetype\n    return \"no match\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the groups of the given array.", "response": "def getallgroups(arr, k=-1):\n    \"\"\"\n    returns all the subset of @arr of size less than equalto @k\n    the return array will be of size \\sum_{i=1}^k nCi, n = len(arr)\n    \"\"\"\n    if k < 0:\n        k = len(arr)\n    return itertools.chain.from_iterable(itertools.combinations(set(arr), j)\n                                         for j in range(1, k + 1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open_get_line(filename, limit=-1, **kwargs):\n    allowed_keys_for_get_line = {'sep', 'pw_filter', 'errors'}\n    for k in list(kwargs.keys()):\n        if k not in allowed_keys_for_get_line:\n            del kwargs[k]\n    print(\"After filtering: {}\".format(kwargs))\n    with open_(filename, 'rt') as f:\n        for w, c in get_line(f, limit, **kwargs):\n            yield w, c", "response": "Opens the password file named filename and reads first limit passwords."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randints(s, e, n=1):\n        assert e >= s, \"Wrong range: [{}, {})\".format(s, e)\n        n = max(1, n)\n        arr = [s + a % (e - s) for a in struct.unpack('<%dL' % n, os.urandom(4 * n))]\n        return arr", "response": "returns n uniform random numbers from [ s e )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops workers and deferred events.", "response": "def stop_workers(self, clean):\n        \"\"\"Stop workers and deferred events.\"\"\"\n        with executor_lock:\n            self.executor.shutdown(clean)\n            del self.executor\n        with self.worker_lock:\n            if clean:\n                self.pool.close()\n            else:\n                self.pool.terminate()\n            self.pool.join()\n            del self.pool\n            for x in self.events.values():\n                x.event.cancel()\n            self.events.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract messages from Python string.", "response": "def extract_translations(self, string):\n        \"\"\"Extract messages from Python string.\"\"\"\n\n        tree = ast.parse(string)\n        # ast_visit(tree)\n        visitor = TransVisitor(\n            self.tranz_functions,\n            self.tranzchoice_functions)\n        visitor.visit(tree)\n\n        return visitor.translations"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a website is up.", "response": "def cmd(send, msg, args):\n    \"\"\"Checks if a website is up.\n\n    Syntax: {command} <website>\n\n    \"\"\"\n    if not msg:\n        send(\"What are you trying to get to?\")\n        return\n    nick = args['nick']\n    isup = get(\"http://isup.me/%s\" % msg).text\n    if \"looks down from here\" in isup:\n        send(\"%s: %s is down\" % (nick, msg))\n    elif \"like a site on the interwho\" in isup:\n        send(\"%s: %s is not a valid url\" % (nick, msg))\n    else:\n        send(\"%s: %s is up\" % (nick, msg))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd(send, msg, args):\n    uid = args['config']['api']['stands4uid']\n    token = args['config']['api']['stands4token']\n    parser = arguments.ArgParser(args['config'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--author', action='store_true')\n    group.add_argument('--search', action='store_true')\n    parser.add_argument('query', nargs='*')\n\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    if cmdargs.author:\n        if not cmdargs.query:\n            send(\"No author specified\")\n            return\n        searchtype = 'author'\n    elif cmdargs.search:\n        if not cmdargs.query:\n            send(\"No search terms specified\")\n            return\n        searchtype = 'search'\n    else:\n        searchtype = 'random'\n\n    if cmdargs.query:\n        cmdargs.query = ' '.join(cmdargs.query)\n    req = get(\"http://www.stands4.com/services/v2/quotes.php\",\n              params={\n                  'uid': uid,\n                  'tokenid': token,\n                  'query': cmdargs.query,\n                  'searchtype': searchtype\n              })\n    xml = etree.fromstring(req.content, parser=etree.XMLParser(recover=True))\n    if len(xml) == 0:\n        send(\"No words of wisdom found\")\n        return\n    entry = choice(xml)\n    quote = entry.find('quote').text\n    author = entry.find('author').text\n    send(\"%s -- %s\" % (quote, author))", "response": "Gets words of wisdom"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_required_directories(self):\n        required = (self.CACHE_DIR,\n                    self.LOG_DIR,\n                    self.OUTPUT_DIR,\n                    self.ENGINEER.JINJA_CACHE_DIR,)\n\n        for folder in required:\n            ensure_exists(folder, assume_dirs=True)", "response": "Creates any directories required for Engineer to function if they don t already exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the first wikipedia result for the argument.", "response": "def cmd(send, msg, args):\n    \"\"\"Returns the first wikipedia result for the argument.\n\n    Syntax: {command} [term]\n\n    \"\"\"\n    if 'livedoc' in args['name']:\n        url = 'http://livedoc.tjhsst.edu/w'\n        name = 'livedoc'\n    else:\n        url = 'http://en.wikipedia.org/w'\n        name = 'wikipedia'\n    if not msg:\n        msg = get_rand(url)\n    params = {'format': 'json', 'action': 'query', 'list': 'search', 'srlimit': '1', 'srsearch': msg}\n    data = get('%s/api.php' % url, params=params).json()\n    try:\n        article = data['query']['search'][0]['title']\n    except IndexError:\n        send(\"%s isn't important enough to have a %s article.\" % (msg, name))\n        return\n    article = article.replace(' ', '_')\n    # wikipedia uses /w for api and /wiki for articles\n    url += 'iki'\n    send('%s/%s' % (url, article))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an array of Device objects from the channel", "response": "def parse_devices(self):\n        \"\"\"Creates an array of Device objects from the channel\"\"\"\n        devices = []\n        for device in self._channel_dict[\"devices\"]:\n            devices.append(Device(device, self._is_sixteen_bit, self._ignore_list))\n        return devices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the dictionary of the channel", "response": "def update(self):\n        \"\"\"Updates the dictionary of the channel\"\"\"\n        for device in self.devices:\n            device.update()\n        for i in range(len(self._channel_dict[\"devices\"])):\n            device_dict = self._channel_dict[\"devices\"][i]\n            for device in self._devices:\n                if device.name == device_dict[\"common.ALLTYPES_NAME\"]:\n                    self._channel_dict[\"devices\"][i] = device.as_dict()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open_config(self,type=\"shared\"):\n        try:\n            #attempt to open a configuration\n            output = self.dev.rpc(\"<open-configuration><{0}/></open-configuration>\".format(type))\n        except Exception as err:\n            #output an error if the configuration is not availble\n            print err", "response": "Opens the configuration of the currently connected device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_config(self):\n        try:\n            self.dev.rpc.close_configuration()\n        except Exception as err:\n            print err", "response": "Closes the exiting opened configuration and closes the exiting opened configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a Junos config block from a template string.", "response": "def load_config_template(self,template,template_vars,type=\"text\"):\n        \"\"\"\n        :template: A templated string using Jinja2 templates\n        :template_vars: A dict containing the vars used in the :template: string\n        :type: The type of configuration to load. The default is \"text\" or a standard Junos config block. Other options are: \"set\" for set style commands, \"xml\" for xml configs\n\n        Uses standard `Jinja2`_ Templating.\n\n        .. _`Jinja2`: http://jinja.pocoo.org/\n\n        Example:\n\n        .. code-block:: python\n\n            from pyJunosManager import JunosDevice\n\n            config_template = \"system { host-name {{ hostname }}; }\"\n\n            dev = JunosDevice(host=\"1.2.3.4\",username=\"root\",password=\"Juniper\")\n            dev.open()\n            dev.open_config()\n            dev.load_config_template(config_template,hostname=\"foo\")\n            dev commit_and_quit()\n            dev.close()\n\n        \"\"\"\n        new_template = Template(template)\n        final_template = new_template.render(template_vars)\n\n        try:\n            output = self.dev.cu.load(final_template,format=type,merge=True)\n        except Exception as err:\n            print err"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncommit exiting configuration Example: .. code-block:: python from pyJunosManager import JunosDevice dev = JunosDevice(host=\"1.2.3.4\",username=\"root\",password=\"Juniper\") dev.open() dev.open_config() dev.commit_config() dev.close_config() dev.close()", "response": "def commit_config(self):\n        \"\"\"\n        Commits exiting configuration\n\n        Example:\n\n        .. code-block:: python\n\n            from pyJunosManager import JunosDevice\n\n            dev = JunosDevice(host=\"1.2.3.4\",username=\"root\",password=\"Juniper\")\n            dev.open()\n            dev.open_config()\n            dev.commit_config()\n            dev.close_config()\n            dev.close()\n        \"\"\"\n        try:\n            self.dev.rpc.commit_configuration()\n        except Exception as err:\n            print err"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commit_and_quit(self):\n        try:\n            self.dev.rpc.commit_configuration()\n            self.close_config()\n        except Exception as err:\n            print err", "response": "Commits and closes the currently open configration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport a local plugin accessible through Python path.", "response": "def load_local_plugin(name):\n        \"\"\"Import a local plugin accessible through Python path.\"\"\"\n        try:\n            module_name = '.'.join(name.split('.')[:-1])\n            module_obj = importlib.import_module(name=module_name)\n            obj = getattr(module_obj, name.split('.')[-1])\n            return obj\n        except (ImportError, AttributeError, ValueError) as e:\n            raise PluginNotFoundError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching and load every installed plugin through entry points.", "response": "def load_installed_plugins():\n        \"\"\"Search and load every installed plugin through entry points.\"\"\"\n        providers = {}\n        checkers = {}\n        for entry_point in pkg_resources.iter_entry_points(group='archan'):\n            obj = entry_point.load()\n            if issubclass(obj, Provider):\n                providers[entry_point.name] = obj\n            elif issubclass(obj, Checker):\n                checkers[entry_point.name] = obj\n        return collections.namedtuple(\n            'Plugins', 'providers checkers')(\n                providers=providers,\n                checkers=checkers)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a Config instance by reading a configuration file.", "response": "def from_file(path):\n        \"\"\"Return a ``Config`` instance by reading a configuration file.\"\"\"\n        with open(path) as stream:\n            obj = yaml.safe_load(stream)\n        Config.lint(obj)\n        return Config(config_dict=obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the configuration file if any.", "response": "def find():\n        \"\"\"Find the configuration file if any.\"\"\"\n        names = ('archan.yml', 'archan.yaml', '.archan.yml', '.archan.yaml')\n        current_dir = os.getcwd()\n        configconfig_file = os.path.join(current_dir, '.configconfig')\n        default_config_dir = os.path.join(current_dir, 'config')\n        if os.path.isfile(configconfig_file):\n            logger.debug('Reading %s to get config folder path',\n                         configconfig_file)\n            with open(configconfig_file) as stream:\n                config_dir = os.path.join(current_dir, stream.read()).strip()\n        elif os.path.isdir(default_config_dir):\n            config_dir = default_config_dir\n        else:\n            config_dir = current_dir\n        logger.debug('Config folder = %s', config_dir)\n        for name in names:\n            config_file = os.path.join(config_dir, name)\n            logger.debug('Searching for config file at %s', config_file)\n            if os.path.isfile(config_file):\n                logger.debug('Found %s', config_file)\n                return config_file\n        logger.debug('No config file found')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninflate a list of strings or dictionaries to a list of plugin instances.", "response": "def inflate_plugin_list(plugin_list, inflate_plugin):\n        \"\"\"\n        Inflate a list of strings/dictionaries to a list of plugin instances.\n\n        Args:\n            plugin_list (list): a list of str/dict.\n            inflate_plugin (method): the method to inflate the plugin.\n\n        Returns:\n            list: a plugin instances list.\n\n        Raises:\n            ValueError: when a dictionary item contains more than one key.\n        \"\"\"\n        plugins = []\n        for plugin_def in plugin_list:\n            if isinstance(plugin_def, str):\n                try:\n                    plugins.append(inflate_plugin(plugin_def))\n                except PluginNotFoundError as e:\n                    logger.error('Could not import plugin identified by %s. '\n                                 'Exception: %s.', plugin_def, e)\n            elif isinstance(plugin_def, dict):\n                if len(plugin_def) > 1:\n                    raise ValueError(\n                        'When using a plugin list, each dictionary item '\n                        'must contain only one key.')\n                identifier = list(plugin_def.keys())[0]\n                definition = plugin_def[identifier]\n                try:\n                    plugins.append(inflate_plugin(identifier, definition))\n                except PluginNotFoundError as e:\n                    logger.error('Could not import plugin identified by %s. '\n                                 'Inflate method: %s. Exception: %s.',\n                                 identifier, inflate_plugin, e)\n        return plugins"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inflate_plugin_dict(plugin_dict, inflate_plugin):\n        plugins = []\n        for identifier, definition in plugin_dict.items():\n            try:\n                plugins.append(inflate_plugin(identifier, definition))\n            except PluginNotFoundError as e:\n                logger.error('Could not import plugin identified by %s. '\n                             'Exception: %s.', identifier, e)\n        return plugins", "response": "Inflate a list of strings / dictionaries to a list of plugin instances."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inflate_nd_checker(identifier, definition):\n        if isinstance(definition, bool):\n            return Checker(name=identifier, passes=definition)\n        elif isinstance(definition, dict):\n            return Checker(definition.pop('name', identifier), **definition)\n        else:\n            raise ValueError('%s type is not supported for no-data checkers, '\n                             'use bool or dict' % type(definition))", "response": "Inflate a no - data checker from a basic definition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the plugin corresponding to the given identifier and type.", "response": "def get_plugin(self, identifier, cls=None):\n        \"\"\"\n        Return the plugin corresponding to the given identifier and type.\n\n        Args:\n            identifier (str): identifier of the plugin.\n            cls (str): one of checker / provider.\n\n        Returns:\n            Checker/Provider: plugin class.\n        \"\"\"\n        if ((cls is None or cls == 'provider')\n                and identifier in self.available_providers):\n            return self.available_providers[identifier]\n        elif ((cls is None or cls == 'checker')\n                and identifier in self.available_checkers):\n            return self.available_checkers[identifier]\n        return Config.load_local_plugin(identifier)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef provider_from_dict(self, dct):\n        provider_identifier = list(dct.keys())[0]\n        provider_class = self.get_provider(provider_identifier)\n        if provider_class:\n            return provider_class(**dct[provider_identifier])\n        return None", "response": "Return a provider instance from a dict object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checker_from_dict(self, dct):\n        checker_identifier = list(dct.keys())[0]\n        checker_class = self.get_checker(checker_identifier)\n        if checker_class:\n            return checker_class(**dct[checker_identifier])\n        return None", "response": "Return a checker instance from a dict object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninflate a plugin thanks to it s identifier definition and class.", "response": "def inflate_plugin(self, identifier, definition=None, cls=None):\n        \"\"\"\n        Inflate a plugin thanks to it's identifier, definition and class.\n\n        Args:\n            identifier (str): the plugin identifier.\n            definition (dict): the kwargs to instantiate the plugin with.\n            cls (str): \"provider\", \"checker\", or None.\n\n        Returns:\n            Provider/Checker: instance of plugin.\n        \"\"\"\n        cls = self.get_plugin(identifier, cls)\n        # TODO: implement re-usability of plugins?\n        # same instances shared across analyses (to avoid re-computing stuff)\n        return cls(**definition or {})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninflates multiple plugins based on a list or dict definition.", "response": "def inflate_plugins(self, plugins_definition, inflate_method):\n        \"\"\"\n        Inflate multiple plugins based on a list/dict definition.\n\n        Args:\n            plugins_definition (list/dict): the plugins definitions.\n            inflate_method (method): the method to indlate each plugin.\n\n        Returns:\n            list: a list of plugin instances.\n\n        Raises:\n            ValueError: when the definition type is not list or dict.\n        \"\"\"\n        if isinstance(plugins_definition, list):\n            return self.inflate_plugin_list(plugins_definition, inflate_method)\n        elif isinstance(plugins_definition, dict):\n            return self.inflate_plugin_dict(plugins_definition, inflate_method)\n        else:\n            raise ValueError('%s type is not supported for a plugin list, '\n                             'use list or dict' % type(plugins_definition))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inflate_analysis_group(self, identifier, definition):\n        providers_definition = definition.pop('providers', None)\n        checkers_definition = definition.pop('checkers', None)\n\n        analysis_group = AnalysisGroup()\n\n        try:\n\n            first_plugin = self.inflate_plugin(identifier, definition)\n\n            if isinstance(first_plugin, Checker):\n                analysis_group.checkers.append(first_plugin)\n\n                if providers_definition is None:\n                    raise ValueError(\n                        'when declaring an analysis group with a checker '\n                        'identifier, you must also declare providers with '\n                        'the \"providers\" key.')\n\n                analysis_group.providers.extend(\n                    self.inflate_providers(providers_definition))\n\n            elif isinstance(first_plugin, Provider):\n                analysis_group.providers.append(first_plugin)\n\n                if checkers_definition is None:\n                    raise ValueError(\n                        'when declaring an analysis group with a provider '\n                        'identifier, you must also declare checkers with '\n                        'the \"checkers\" key.')\n\n                analysis_group.checkers.extend(\n                    self.inflate_checkers(checkers_definition))\n\n        except PluginNotFoundError as e:\n\n            logger.warning(\n                'Could not find any plugin identified by %s, '\n                'considering entry as group name. Exception: %s.',\n                identifier, e)\n\n            analysis_group.name = definition.pop('name', identifier)\n            analysis_group.description = definition.pop('description', None)\n\n            if bool(providers_definition) != bool(checkers_definition):\n                raise ValueError(\n                    'when declaring an analysis group with a name, you must '\n                    'either declare both \"providers\" and \"checkers\" or none.')\n\n            if providers_definition and checkers_definition:\n                analysis_group.providers.extend(\n                    self.inflate_providers(providers_definition))\n                analysis_group.checkers.extend(\n                    self.inflate_checkers(checkers_definition))\n\n        self.cleanup_definition(definition)\n\n        for nd_identifier, nd_definition in definition.items():\n            analysis_group.checkers.append(\n                self.inflate_nd_checker(nd_identifier, nd_definition))\n\n        return analysis_group", "response": "Inflate an analysis group from a given definition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_plugins(self):\n        width = console_width()\n        line = Style.BRIGHT + '=' * width + '\\n'\n        middle = int(width / 2)\n        if self.available_providers:\n            print(line + ' ' * middle + 'PROVIDERS')\n            for provider in sorted(self.available_providers.values(),\n                                   key=lambda x: x.identifier):\n                provider().print()\n                print()\n        if self.available_checkers:\n            print(line + ' ' * middle + 'CHECKERS')\n            for checker in sorted(self.available_checkers.values(),\n                                  key=lambda x: x.identifier):\n                checker().print()\n                print()", "response": "Print the available plugins."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_markdown(post):\n        from engineer.conf import settings\n\n        # A hack to guarantee the YAML output is in a sensible order.\n        # The order, assuming all metadata should be written, should be:\n        # title\n        # status\n        # timestamp\n        # link\n        # via\n        # via-link\n        # slug\n        # tags\n        # updated\n        # template\n        # content-template\n        # url\n        d = [\n            ('status', post.status.name),\n            ('link', post.link),\n            ('via', post.via),\n            ('via-link', post.via_link),\n            ('tags', post.tags),\n            ('updated', post.updated_local.strftime(settings.TIME_FORMAT) if post.updated is not None else None),\n            ('template', post.template if post.template != 'theme/post_detail.html' else None),\n            ('content-template',\n             post.content_template if post.content_template != 'theme/_content_default.html' else None),\n        ]\n\n        # The complete set of metadata that should be written is the union of the FINALIZE_METADATA.config setting and\n        # the set of metadata that was in the file originally.\n        finalization_config = FinalizationPlugin.get_settings()['config']\n        metadata_to_finalize = set([m for m, s in finalization_config.iteritems() if post.status in s])\n        metadata_to_finalize.update(post.metadata_original)\n\n        if 'title' in metadata_to_finalize:\n            # insert at the top of the list\n            d.insert(0, ('title', post.title))\n        if 'slug' in metadata_to_finalize:\n            # insert right before tags\n            d.insert(d.index(('tags', post.tags)), ('slug', post.slug))\n        if 'timestamp' in metadata_to_finalize:\n            # insert right after status\n            d.insert(d.index(('status', post.status.name)), ('timestamp',\n                                                             post.timestamp_local.strftime(settings.TIME_FORMAT)))\n        if 'url' in metadata_to_finalize:\n            # insert at end of list\n            d.append(('url', post.url))\n\n        metadata = ''\n        for k, v in d:\n            if v is not None and len(v) > 0:\n                metadata += yaml.safe_dump(dict([(k, v)]), default_flow_style=False)\n\n        # handle custom metadata\n        if len(post.custom_properties):\n            metadata += '\\n'\n            metadata += yaml.safe_dump(dict(post.custom_properties), default_flow_style=False)\n        return settings.JINJA_ENV.get_template(post.markdown_template_path).render(metadata=metadata,\n                                                                                   content=post.content_finalized,\n                                                                                   post=post)", "response": "Renders the post as Markdown using the template specified in markdown_template_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, msg, args):\n    match = re.match(r'--(.+?)\\b', msg)\n    randtype = 'hex'\n    if match:\n        if match.group(1) == 'int':\n            randtype = 'int'\n        else:\n            send(\"Invalid Flag.\")\n            return\n    if randtype == 'hex':\n        send(hex(getrandbits(50)))\n    else:\n        maxlen = 1000000000\n        msg = msg.split()\n        if len(msg) == 2:\n            if msg[1].isdigit():\n                maxlen = int(msg[1])\n            else:\n                send(\"Invalid Length\")\n                return\n        send(str(randrange(maxlen)))", "response": "For when you don t have enough randomness in your life."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split(X, Y, question):\n\n    true_X, false_X = [], []\n    true_Y, false_Y = [], []\n\n    for x, y in zip(X, Y):\n        if question.match(x):\n            true_X.append(x)\n            true_Y.append(y)\n\n        else:\n            false_X.append(x)\n            false_Y.append(y)\n\n    return (np.array(true_X), np.array(false_X),\n            np.array(true_Y), np.array(false_Y))", "response": "Partitions a dataset into two lists of true and false rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the best question to ask by iterating over every feature and value and calculating the information gain.", "response": "def find_best_question(X, y, criterion):\n    \"\"\"Find the best question to ask by iterating over every feature / value\n    and calculating the information gain.\n    \"\"\"\n    \n    measure_impurity = gini_impurity if criterion == \"gini\" else entropy\n\n    current_impurity = measure_impurity(y)\n    best_info_gain = 0\n    best_question = None\n\n    for feature_n in range(X.shape[1]):\n        for value in set(X[:, feature_n]):\n            q = Question(feature_n, value)\n            _, _, true_y, false_y = split(X, y, q)\n\n            current_info_gain = info_gain(current_impurity, true_y, false_y, criterion)\n            if current_info_gain >= best_info_gain:\n                best_info_gain = current_info_gain\n                best_question = q\n\n    return best_info_gain, best_question"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_tree(X, y, criterion, max_depth, current_depth=1):\n\n    # check for max_depth accomplished\n    if max_depth >= 0 and current_depth >= max_depth:\n        return Leaf(y)\n\n    # check for 0 gain\n    gain, question = find_best_question(X, y, criterion)\n    if gain == 0:\n        return Leaf(y)\n\n    # split\n    true_X, false_X, true_y, false_y = split(X, y, question)\n\n    # Build the `true` branch of the tree recursively\n    true_branch = build_tree(\n        true_X, true_y,\n        criterion,\n        max_depth,\n        current_depth=current_depth+1\n    )\n    \n    # Build the `false` branch of the tree recursively\n    false_branch = build_tree(\n        false_X, false_y,\n        criterion,\n        max_depth,\n        current_depth=current_depth+1\n    )\n\n    # returning the root of the tree/subtree\n    return Node(\n        question=question,\n        true_branch=true_branch,\n        false_branch=false_branch\n    )", "response": "Builds the decision tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npredicts a probabilities value or label for the sample x.", "response": "def tree_predict(x, root, proba=False, regression=False):\n    \"\"\"Predicts a probabilities/value/label for the sample x.\n    \"\"\"\n\n    if isinstance(root, Leaf):\n        if proba:\n            return root.probabilities\n        elif regression:\n            return root.mean\n        else:\n            return root.most_frequent\n\n    if root.question.match(x):\n        return tree_predict(x, root.true_branch, proba=proba, regression=regression)\n    else:\n        return tree_predict(x, root.false_branch, proba=proba, regression=regression)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_tree(root, space=' '):\n\n    if isinstance(root, Leaf):\n        print(space + \"Prediction: \" + str(root.most_frequent))\n        return\n\n    print(space + str(root.question))\n\n    print(space + \"--> True:\")\n    print_tree(root.true_branch, space+'  ')\n\n    print(space + \"--> False:\")\n    print_tree(root.false_branch, space+'  ')", "response": "Prints the Decision Tree in a pretty way."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_element(driver, elem_path, by=CSS, timeout=TIMEOUT, poll_frequency=0.5):\n    wait = WebDriverWait(driver, timeout, poll_frequency)\n    return wait.until(EC.presence_of_element_located((by, elem_path)))", "response": "Find an element on the page and return it once located."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_elements(driver, elem_path, by=CSS, timeout=TIMEOUT, poll_frequency=0.5):\n    wait = WebDriverWait(driver, timeout, poll_frequency)\n    return wait.until(EC.presence_of_all_elements_located((by, elem_path)))", "response": "Find and return all elements located on the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_one(driver, locator_list, elem_type=CSS, timeout=TIMEOUT):\n    def _find_one(driver):\n        \"\"\" Expected Condition to find and return first located element \"\"\"\n        finders = {\n            CLASS_NAME: driver.find_elements_by_class_name,\n            CSS: driver.find_elements_by_css_selector,\n            ID: driver.find_elements_by_id,\n            LINK: driver.find_elements_by_link_text,\n            NAME: driver.find_elements_by_name,\n            PARTIAL_LINK: driver.find_elements_by_partial_link_text,\n            TAG: driver.find_elements_by_tag_name,\n            XPATH: driver.find_elements_by_xpath\n        }\n\n        elems = [finders[elem_type](loc) for loc in locator_list]\n\n        if any([len(elem_list) > 0 for elem_list in elems]):\n            return elems\n        else:\n            return False\n\n    raw_results = WebDriverWait(driver, timeout).until(_find_one)\n\n    # Pull out any found elements from lists\n    results = [elem for elem_list in raw_results for elem in elem_list]\n\n    return results.pop() if len(results) == 1 else results", "response": "Find one element in the list of CSS selectors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a writable element and write to it", "response": "def find_write(driver, elem_path, write_str, clear_first=True, send_enter=False,\n               by=CSS, timeout=TIMEOUT, poll_frequency=0.5):\n    \"\"\" Find a writable element and write to it\n\n    find_write locates a writable element on the page, waiting\n    for up to timeout seconds. Once found, it writes the string\n    to it.\n\n    Args:\n        driver (selenium webdriver or element): A driver or element\n        elem_path (str): String used to located the element\n        write_str (str): String to write\n        clear_first (bool): Clear the contents before writing (default True)\n        send_enter (bool): Send a keyboard ENTER after writing string\n        by (selenium By): Selenium By reference\n        timeout (int): Selenium Wait timeout, in seconds\n        poll_frequency (float): Selenium Wait polling frequency, in seconds\n\n    Returns:\n        element: Selenium element\n\n    Raises:\n        TimeoutException: Raised when target element isn't located\n    \"\"\"\n    elem = find_element(driver, elem_path=elem_path, by=by, timeout=timeout,\n                        poll_frequency=poll_frequency)\n\n    if clear_first:\n        elem.clear()\n\n    elem.send_keys(write_str)\n\n    if send_enter:\n        elem.send_keys(Keys.ENTER)\n\n    return elem"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nintensifies text. Syntax: {command} [text]", "response": "def cmd(send, msg, args):\n    \"\"\"Intensifies text.\n\n    Syntax: {command} [text]\n\n    \"\"\"\n    if not msg:\n        msg = gen_word()\n    send(gen_intensify(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading LIBSVM - format data from data_file_name and returns labels y and x.", "response": "def svm_read_problem(data_file_name, return_scipy=False):\n\t\"\"\"\n\tsvm_read_problem(data_file_name, return_scipy=False) -> [y, x], y: list, x: list of dictionary\n\tsvm_read_problem(data_file_name, return_scipy=True)  -> [y, x], y: ndarray, x: csr_matrix\n\n\tRead LIBSVM-format data from data_file_name and return labels y\n\tand data instances x.\n\t\"\"\"\n\tprob_y = []\n\tprob_x = []\n\trow_ptr = [0]\n\tcol_idx = []\n\tfor i, line in enumerate(open(data_file_name)):\n\t\tline = line.split(None, 1)\n\t\t# In case an instance with all zero features\n\t\tif len(line) == 1: line += ['']\n\t\tlabel, features = line\n\t\tprob_y += [float(label)]\n\t\tif scipy != None and return_scipy:\n\t\t\tnz = 0\n\t\t\tfor e in features.split():\n\t\t\t\tind, val = e.split(\":\")\n\t\t\t\tval = float(val)\n\t\t\t\tif val != 0:\n\t\t\t\t\tcol_idx += [int(ind)-1]\n\t\t\t\t\tprob_x += [val]\n\t\t\t\t\tnz += 1\n\t\t\trow_ptr += [row_ptr[-1]+nz]\n\t\telse:\n\t\t\txi = {}\n\t\t\tfor e in features.split():\n\t\t\t\tind, val = e.split(\":\")\n\t\t\t\txi[int(ind)] = float(val)\n\t\t\tprob_x += [xi]\n\tif scipy != None and return_scipy:\n\t\tprob_y = scipy.array(prob_y)\n\t\tprob_x = scipy.array(prob_x)\n\t\tcol_idx = scipy.array(col_idx)\n\t\trow_ptr = scipy.array(row_ptr)\n\t\tprob_x = sparse.csr_matrix((prob_x, col_idx, row_ptr))\n\treturn (prob_y, prob_x)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluations_scipy(ty, pv):\n\tif not (scipy != None and isinstance(ty, scipy.ndarray) and isinstance(pv, scipy.ndarray)):\n\t\traise TypeError(\"type of ty and pv must be ndarray\")\n\tif len(ty) != len(pv):\n\t\traise ValueError(\"len(ty) must be equal to len(pv)\")\n\tACC = 100.0*(ty == pv).mean()\n\tMSE = ((ty - pv)**2).mean()\n\tl = len(ty)\n\tsumv = pv.sum()\n\tsumy = ty.sum()\n\tsumvy = (pv*ty).sum()\n\tsumvv = (pv*pv).sum()\n\tsumyy = (ty*ty).sum()\n\twith scipy.errstate(all = 'raise'):\n\t\ttry:\n\t\t\tSCC = ((l*sumvy-sumv*sumy)*(l*sumvy-sumv*sumy))/((l*sumvv-sumv*sumv)*(l*sumyy-sumy*sumy))\n\t\texcept:\n\t\t\tSCC = float('nan')\n\treturn (float(ACC), float(MSE), float(SCC))", "response": "Compute the evaluation of two arrays of values using scipy."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the evaluations of the predicted values of the given type and pv", "response": "def evaluations(ty, pv, useScipy = True):\n\t\"\"\"\n\tevaluations(ty, pv, useScipy) -> (ACC, MSE, SCC)\n\tty, pv: list, tuple or ndarray\n\tuseScipy: convert ty, pv to ndarray, and use scipy functions for the evaluation\n\n\tCalculate accuracy, mean squared error and squared correlation coefficient\n\tusing the true values (ty) and predicted values (pv).\n\t\"\"\"\n\tif scipy != None and useScipy:\n\t\treturn evaluations_scipy(scipy.asarray(ty), scipy.asarray(pv))\n\tif len(ty) != len(pv):\n\t\traise ValueError(\"len(ty) must be equal to len(pv)\")\n\ttotal_correct = total_error = 0\n\tsumv = sumy = sumvv = sumyy = sumvy = 0\n\tfor v, y in zip(pv, ty):\n\t\tif y == v:\n\t\t\ttotal_correct += 1\n\t\ttotal_error += (v-y)*(v-y)\n\t\tsumv += v\n\t\tsumy += y\n\t\tsumvv += v*v\n\t\tsumyy += y*y\n\t\tsumvy += v*y\n\tl = len(ty)\n\tACC = 100.0*total_correct/l\n\tMSE = total_error/l\n\ttry:\n\t\tSCC = ((l*sumvy-sumv*sumy)*(l*sumvy-sumv*sumy))/((l*sumvv-sumv*sumv)*(l*sumyy-sumy*sumy))\n\texcept:\n\t\tSCC = float('nan')\n\treturn (float(ACC), float(MSE), float(SCC))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether given object is an ordered mapping.", "response": "def is_ordered_mapping(obj):\n    \"\"\"Checks whether given object is an ordered mapping,\n    e.g. a :class:`OrderedDict`.\n    :return: ``True`` if argument is an ordered mapping, ``False`` otherwise\n    \"\"\"\n    if not (is_mapping(obj) and hasattr(obj, '__reversed__')):\n        return False\n\n    # PyPy has a bug where the standard :class:`dict` has the ``__reversed__``\n    # method but it's unusable and throws an exception when called\n    try:\n        obj.__reversed__()\n    except TypeError:\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the unique divisions for all elections on an election day.", "response": "def fetch_states(self, elections):\n        \"\"\"\n        Returns the unique divisions for all elections on an election day.\n        \"\"\"\n        states = []\n\n        for election in elections:\n            if election.division.level.name == DivisionLevel.DISTRICT:\n                division = election.division.parent\n            else:\n                division = election.division\n\n            states.append(division)\n\n        return sorted(list(set(states)), key=lambda s: s.label)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a cached name if available.", "response": "def get_name(self, type_, id_):\n        \"\"\"\n        Read a cached name if available.\n\n        :param type_: str, \"owner\" or \"tag\"\n        :param id_: int, eg. 123456\n        :returns: str, or None\n        \"\"\"\n        cachefile = self.filename(type_, id_)\n        try:\n            with open(cachefile, 'r') as f:\n                return f.read()\n        except (OSError, IOError) as e:\n            if e.errno != errno.ENOENT:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_name(self, type_, id_, name):\n        cachefile = self.filename(type_, id_)\n        dirname = os.path.dirname(cachefile)\n        try:\n            os.makedirs(dirname)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        with open(cachefile, 'w') as f:\n            f.write(name)", "response": "Write a name to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filename(self, type_, id_):\n        profile = self.connection.profile\n        return os.path.join(self.directory, profile, type_, str(id_))", "response": "Returns the cache filename to read for this type and id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_or_load_name(self, type_, id_, method):\n        name = self.get_name(type_, id_)\n        if name is not None:\n            defer.returnValue(name)\n        instance = yield method(id_)\n        if instance is None:\n            defer.returnValue(None)\n        self.put_name(type_, id_, instance.name)\n        defer.returnValue(instance.name)", "response": "Reads the cache for a type of object s name. If the cache is not available then we will load the name from the server and store it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, name, *args, **kwargs):\n        # Like txkoji.Connection, we always want the full request for tasks:\n        if name in ('getTaskInfo', 'getTaskDescendants'):\n            kwargs['request'] = True\n        if kwargs:\n            kwargs['__starstar'] = True\n            args = args + (kwargs,)\n        payload = {'methodName': name, 'params': args}\n        self.calls.append(payload)", "response": "Add a new call to the list of calls that we will send to the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfire when we get information back from the XML-RPC server. This is processes the raw results of system.multicall into a usable iterator of values (and/or Faults). :param values: list of data txkoji.Connection.call() :param calls: list of calls we sent in this multicall RPC :returns: KojiMultiCallIterator with the resulting values from all our calls.", "response": "def _multicall_callback(self, values, calls):\n        \"\"\"\n        Fires when we get information back from the XML-RPC server.\n\n        This is processes the raw results of system.multicall into a usable\n        iterator of values (and/or Faults).\n\n        :param values: list of data txkoji.Connection.call()\n        :param calls: list of calls we sent in this multicall RPC\n        :returns: KojiMultiCallIterator with the resulting values from all our\n                  calls.\n        \"\"\"\n        result = KojiMultiCallIterator(values)\n        result.connection = self.connection\n        result.calls = calls\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rich_item(self, method_name, value):\n        if value is None:\n            return None\n        if method_name == 'getAverageBuildDuration':\n            return timedelta(seconds=value)\n        types = (Build, Channel, Package, Task)\n        if isinstance(value, Munch):\n            for type_ in types:\n                if type_.__name__ in method_name:\n                    item = type_(value)\n                    item.connection = self.connection\n                    return item\n        if isinstance(value, list):\n            # Do this same rich item conversion for list of Munch objects\n            items_list = [self.rich_item(method_name, val) for val in value]\n            return items_list\n        return value", "response": "Convert this value into the rich txkoji objects"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a handler to the event list.", "response": "def add_handler(self, handler):\r\n        \"\"\"Adds a handler. Also checks if it is callable.\r\n        To bypass checks, use Event.append() instead.\"\"\"\r\n        if not callable(handler):\r\n            raise TypeError(\"'%s' is not callable.\" % handler)\r\n\r\n        self.append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fire(self, *args, **kwargs):\r\n        if self.eventmanager:\r\n            # Fire global event. Assuming we have an eventmanager.\r\n            self.eventmanager.got_event(self.name, *args, **kwargs)\r\n\r\n        for handler in self:  # Iterate over handlers\r\n            try:\r\n                handler(*args, **kwargs)  # Execute handler with given args.\r\n            except StopIteration:  # Stop iterating if handler raised StopIter\r\n                break", "response": "Fires an event executing all the handlers with given args and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, events):\r\n        for method in dir(events):\r\n            # Skip attributes\r\n            if not callable(getattr(events, method)):\r\n                continue\r\n            # Skip \"trash\" functions\r\n            if method.startswith(\"_\"):\r\n                continue\r\n\r\n            if not hasattr(self, method):  # Didn't have such an event already\r\n                self[method] = Event()  # So we create it\r\n\r\n            self[method].add_handler(getattr(events, method))", "response": "Applies methods to events and creates Event objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_valid_email(email):\n    pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+[.]\\w+')\n    return bool(pattern.match(email))", "response": "Check if email is valid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a password is valid", "response": "def is_valid_password(password):\n    \"\"\"\n    Check if a password is valid\n    \"\"\"\n    pattern = re.compile(r\"^.{4,75}$\")\n    return bool(pattern.match(password))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the domain name of the url", "response": "def get_domain_name(url):\n    \"\"\"\n    Get the domain name\n    :param url:\n    :return:\n    \"\"\"\n    if not url.startswith(\"http\"):\n        url = \"http://\" + url\n    if not is_valid_url(url):\n        raise ValueError(\"Invalid URL '%s'\" % url)\n    parse = urlparse(url)\n    return parse.netloc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef time_ago(dt):\n    now = datetime.datetime.now()\n    return humanize.naturaltime(now - dt)", "response": "Return the current time ago"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a value by dot notation notaion string", "response": "def get(self, keys, default=None):\n        \"\"\"\n        To get a value by dot notation\n        :param keys: dot notaion string\n        :param default:\n        :return:\n        \"\"\"\n        try:\n            d = self\n            for k in keys.split(\".\"):\n                if not k in d:\n                    d[k] = {}\n                d = d[k]\n            if isinstance(d, bool):\n                return d\n            return d or default\n        except (TypeError, KeyError) as e:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets sequence from UniProt.", "response": "def get_sequence(queries,fap=None,fmt='fasta',\n            organism_taxid=9606,\n                 test=False):\n    \"\"\"\n    http://www.ebi.ac.uk/Tools/dbfetch/dbfetch?db=uniprotkb&id=P14060+P26439&format=fasta&style=raw&Retrieve=Retrieve\n    https://www.uniprot.org/uniprot/?format=fasta&organism=9606&query=O75116+O75116+P35548+O14944+O14944\n    \"\"\"\n    url = 'http://www.ebi.ac.uk/Tools/dbfetch/dbfetch'\n    params = {\n    'id':' '.join(queries),\n    'db':'uniprotkb',\n    'organism':organism_taxid,    \n    'format':fmt,\n    'style':'raw',\n    'Retrieve':'Retrieve',\n    }\n    response = requests.get(url, params=params)\n    if test:\n        print(response.url)\n    if response.ok:\n        if not fap is None:\n            with open(fap,'w') as f:\n                f.write(response.text)\n            return fap\n        else:\n            return response.text            \n    else:\n        print('Something went wrong ', response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_ids(queries,frm='ACC',to='ENSEMBL_PRO_ID',\n            organism_taxid=9606,test=False):\n    \"\"\"\n    https://www.uniprot.org/help/api_idmapping\n    \"\"\"\n    url = 'https://www.uniprot.org/uploadlists/'\n    params = {\n    'from':frm,\n    'to':to,\n    'format':'tab',\n    'organism':organism_taxid,    \n    'query':' '.join(queries),\n    }\n    response = requests.get(url, params=params)\n    if test:\n        print(response.url)\n    if response.ok:\n        df=pd.read_table(response.url)\n        df.columns=[frm,to]\n        return df\n    else:\n        print('Something went wrong ', response.status_code)", "response": "Map IDs to UniProt IDs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd(send, msg, args):\n\n    if not msg:\n        user = choice(get_users(args))\n    else:\n        user = msg\n    send(gen_insult(user))", "response": "Insults a user.\n\n    Syntax: {command} [nick]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a JSON string into a list of objects.", "response": "def parse(json, query_path, expected_vars=NO_VARS):\n    \"\"\"\n    INTENDED TO TREAT JSON AS A STREAM; USING MINIMAL MEMORY WHILE IT ITERATES\n    THROUGH THE STRUCTURE.  ASSUMING THE JSON IS LARGE, AND HAS A HIGH LEVEL\n    ARRAY STRUCTURE, IT WILL yield EACH OBJECT IN THAT ARRAY.  NESTED ARRAYS\n    ARE HANDLED BY REPEATING THE PARENT PROPERTIES FOR EACH MEMBER OF THE\n    NESTED ARRAY. DEEPER NESTED PROPERTIES ARE TREATED AS PRIMITIVE VALUES;\n    THE STANDARD JSON DECODER IS USED.\n\n    LARGE MANY-PROPERTY OBJECTS CAN BE HANDLED BY `items()`\n\n    :param json:       SOME STRING-LIKE STRUCTURE THAT CAN ASSUME WE LOOK AT\n                       ONE CHARACTER AT A TIME, IN ORDER\n    :param query_path: A DOT-SEPARATED STRING INDICATING THE PATH TO THE\n                       NESTED ARRAY OPTIONALLY, {\"items\":query_path} TO\n                       FURTHER ITERATE OVER PROPERTIES OF OBJECTS FOUND AT\n                       query_path\n    :param expected_vars: REQUIRED PROPERTY NAMES, USED TO DETERMINE IF\n                          MORE-THAN-ONE PASS IS REQUIRED\n    :return: RETURNS AN ITERATOR OVER ALL OBJECTS FROM ARRAY LOCATED AT query_path\n    \"\"\"\n    if hasattr(json, \"read\"):\n        # ASSUME IT IS A STREAM\n        temp = json\n        def get_more():\n            return temp.read(MIN_READ_SIZE)\n        json = List_usingStream(get_more)\n    elif hasattr(json, \"__call__\"):\n        json = List_usingStream(json)\n    elif isinstance(json, GeneratorType):\n        json = List_usingStream(json.next)\n    else:\n        Log.error(\"Expecting json to be a stream, or a function that will return more bytes\")\n\n\n    def _iterate_list(index, c, parent_path, path, expected_vars):\n        c, index = skip_whitespace(index)\n        if c == b']':\n            yield index\n            return\n\n        while True:\n            if not path:\n                index = _assign_token(index, c, expected_vars)\n                c, index = skip_whitespace(index)\n                if c == b']':\n                    yield index\n                    _done(parent_path)\n                    return\n                elif c == b',':\n                    yield index\n                    c, index = skip_whitespace(index)\n            else:\n                for index in _decode_token(index, c, parent_path, path, expected_vars):\n                    c, index = skip_whitespace(index)\n                    if c == b']':\n                        yield index\n                        _done(parent_path)\n                        return\n                    elif c == b',':\n                        yield index\n                        c, index = skip_whitespace(index)\n\n    def _done(parent_path):\n        if len(parent_path) < len(done[0]):\n            done[0] = parent_path\n\n    def _decode_object(index, c, parent_path, query_path, expected_vars):\n        if \".\" in expected_vars:\n            if len(done[0]) <= len(parent_path) and all(d == p for d, p in zip(done[0], parent_path)):\n                Log.error(\"Can not pick up more variables, iterator is done\")\n\n            if query_path:\n                Log.error(\"Can not extract objects that contain the iteration\", var=join_field(query_path))\n\n            index = _assign_token(index, c, expected_vars)\n            # c, index = skip_whitespace(index)\n            yield index\n            return\n\n        did_yield = False\n        while True:\n            c, index = skip_whitespace(index)\n            if c == b',':\n                continue\n            elif c == b'\"':\n                name, index = simple_token(index, c)\n\n                c, index = skip_whitespace(index)\n                if c != b':':\n                    Log.error(\"Expecting colon\")\n                c, index = skip_whitespace(index)\n\n                child_expected = needed(name, expected_vars)\n                child_path = parent_path + [name]\n                if any(child_expected):\n                    if not query_path:\n                        index = _assign_token(index, c, child_expected)\n                    elif query_path[0] == name:\n                        for index in _decode_token(index, c, child_path, query_path[1:], child_expected):\n                            did_yield = True\n                            yield index\n                    else:\n                        if len(done[0]) <= len(child_path):\n                            Log.error(\"Can not pick up more variables, iterator over {{path}} is done\", path=join_field(done[0]))\n                        index = _assign_token(index, c, child_expected)\n                elif query_path and query_path[0] == name:\n                    for index in _decode_token(index, c, child_path, query_path[1:], child_expected):\n                        yield index\n                else:\n                    index = jump_to_end(index, c)\n            elif c == b\"}\":\n                if not did_yield:\n                    yield index\n                break\n\n    def set_destination(expected_vars, value):\n        for i, e in enumerate(expected_vars):\n            if e is None:\n                pass\n            elif e == \".\":\n                destination[i] = value\n            elif is_data(value):\n                destination[i] = value[e]\n            else:\n                destination[i] = Null\n\n    def _decode_object_items(index, c, parent_path, query_path, expected_vars):\n        \"\"\"\n        ITERATE THROUGH THE PROPERTIES OF AN OBJECT\n        \"\"\"\n        c, index = skip_whitespace(index)\n        num_items = 0\n        while True:\n            if c == b',':\n                c, index = skip_whitespace(index)\n            elif c == b'\"':\n                name, index = simple_token(index, c)\n                if \"name\" in expected_vars:\n                    for i, e in enumerate(expected_vars):\n                        if e == \"name\":\n                            destination[i] = name\n\n                c, index = skip_whitespace(index)\n                if c != b':':\n                    Log.error(\"Expecting colon\")\n                c, index = skip_whitespace(index)\n\n                child_expected = needed(\"value\", expected_vars)\n                index = _assign_token(index, c, child_expected)\n                c, index = skip_whitespace(index)\n                DEBUG and not num_items % 1000 and Log.note(\"{{num}} items iterated\", num=num_items)\n                yield index\n                num_items += 1\n            elif c == b\"}\":\n                break\n\n    def _decode_token(index, c, parent_path, query_path, expected_vars):\n        if c == b'{':\n            if query_path and query_path[0] == \"$items\":\n                if any(expected_vars):\n                    for index in _decode_object_items(index, c, parent_path, query_path[1:], expected_vars):\n                        yield index\n                else:\n                    index = jump_to_end(index, c)\n                    yield index\n            elif not any(expected_vars):\n                index = jump_to_end(index, c)\n                yield index\n            else:\n                for index in _decode_object(index, c, parent_path, query_path, expected_vars):\n                    yield index\n        elif c == b'[':\n            for index in _iterate_list(index, c, parent_path, query_path, expected_vars):\n                yield index\n        else:\n            index = _assign_token(index, c, expected_vars)\n            yield index\n\n    def _assign_token(index, c, expected_vars):\n        if not any(expected_vars):\n            return jump_to_end(index, c)\n\n        value, index = simple_token(index, c)\n        set_destination(expected_vars, value)\n\n        return index\n\n    def jump_to_end(index, c):\n        \"\"\"\n        DO NOT PROCESS THIS JSON OBJECT, JUST RETURN WHERE IT ENDS\n        \"\"\"\n        if c == b'\"':\n            while True:\n                c = json[index]\n                index += 1\n                if c == b'\\\\':\n                    index += 1\n                elif c == b'\"':\n                    break\n            return index\n        elif c not in b\"[{\":\n            while True:\n                c = json[index]\n                index += 1\n                if c in b',]}':\n                    break\n            return index - 1\n\n        # OBJECTS AND ARRAYS ARE MORE INVOLVED\n        stack = [None] * 1024\n        stack[0] = CLOSE[c]\n        i = 0  # FOR INDEXING THE STACK\n        while True:\n            c = json[index]\n            index += 1\n\n            if c == b'\"':\n                while True:\n                    c = json[index]\n                    index += 1\n                    if c == b'\\\\':\n                        index += 1\n                    elif c == b'\"':\n                        break\n            elif c in b'[{':\n                i += 1\n                stack[i] = CLOSE[c]\n            elif c == stack[i]:\n                i -= 1\n                if i == -1:\n                    return index  # FOUND THE MATCH!  RETURN\n            elif c in b']}':\n                Log.error(\"expecting {{symbol}}\", symbol=stack[i])\n\n    def simple_token(index, c):\n        if c == b'\"':\n            json.mark(index - 1)\n            while True:\n                c = json[index]\n                index += 1\n                if c == b\"\\\\\":\n                    index += 1\n                elif c == b'\"':\n                    break\n            return json_decoder(json.release(index).decode(\"utf8\")), index\n        elif c in b\"{[\":\n            json.mark(index-1)\n            index = jump_to_end(index, c)\n            value = wrap(json_decoder(json.release(index).decode(\"utf8\")))\n            return value, index\n        elif c == b\"t\" and json.slice(index, index + 3) == b\"rue\":\n            return True, index + 3\n        elif c == b\"n\" and json.slice(index, index + 3) == b\"ull\":\n            return None, index + 3\n        elif c == b\"f\" and json.slice(index, index + 4) == b\"alse\":\n            return False, index + 4\n        else:\n            json.mark(index-1)\n            while True:\n                c = json[index]\n                if c in b',]}':\n                    break\n                index += 1\n            text = json.release(index)\n            try:\n                return float(text), index\n            except Exception:\n                Log.error(\"Not a known JSON primitive: {{text|quote}}\", text=text)\n\n    def skip_whitespace(index):\n        \"\"\"\n        RETURN NEXT NON-WHITESPACE CHAR, AND ITS INDEX\n        \"\"\"\n        c = json[index]\n        while c in WHITESPACE:\n            index += 1\n            c = json[index]\n        return c, index + 1\n\n    if is_data(query_path) and query_path.get(\"items\"):\n        path_list = split_field(query_path.get(\"items\")) + [\"$items\"]  # INSERT A MARKER SO THAT OBJECT IS STREAM DECODED\n    else:\n        path_list = split_field(query_path)\n\n    destination = [None] * len(expected_vars)\n    c, index = skip_whitespace(0)\n    done = [path_list + [None]]\n    for _ in _decode_token(index, c, [], path_list, expected_vars):\n        output = Data()\n        for i, e in enumerate(expected_vars):\n            output[e] = destination[i]\n        yield output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of the names of the required ones.", "response": "def needed(name, required):\n    \"\"\"\n    RETURN SUBSET IF name IN REQUIRED\n    \"\"\"\n    return [\n        relative_field(r, name) if r and startswith_field(r, name) else None\n        for r in required\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmarking the current entry in the memory.", "response": "def mark(self, index):\n        \"\"\"\n        KEEP THIS index IN MEMORY UNTIL release()\n        \"\"\"\n        if index < self.start:\n            Log.error(\"Can not go in reverse on stream\")\n        if self._mark != -1:\n            Log.error(\"Not expected\")\n        self._mark = index"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the appropriate parameter for a given data field", "response": "def _match_data_to_parameter(cls, data):\n    \"\"\" find the appropriate parameter for a parameter field \"\"\"\n    in_value = data[\"in\"]\n    for cls in [QueryParameter, HeaderParameter, FormDataParameter,\n                PathParameter, BodyParameter]:\n        if in_value == cls.IN:\n            return cls\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a message to a channel", "response": "def cmd(send, msg, args):\n    \"\"\"Sends a message to a channel\n    Syntax: {command} <channel> <message>\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('channel', action=arguments.ChanParser)\n    parser.add_argument('message', nargs='+')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    cmdargs.message = ' '.join(cmdargs.message)\n    send(cmdargs.message, target=cmdargs.channels[0])\n    send(\"%s sent message %s to %s\" % (args['nick'], cmdargs.message, cmdargs.channels[0]), target=args['config']['core']['ctrlchan'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmd(send, msg, args):\n    if not msg:\n        result = subprocess.run(['eix', '-c'], env={'EIX_LIMIT': '0', 'HOME': os.environ['HOME']}, stdout=subprocess.PIPE, universal_newlines=True)\n        if result.returncode:\n            send(\"eix what?\")\n            return\n        send(choice(result.stdout.splitlines()))\n        return\n    args = ['eix', '-c'] + msg.split()\n    result = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n    if result.returncode:\n        send(\"%s isn't important enough for Gentoo.\" % msg)\n    else:\n        send(result.stdout.splitlines()[0].strip())", "response": "Runs eix with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_str(number):\n    states = globals()\n    for name, value in states.items():\n        if number == value and name.isalpha() and name.isupper():\n            return name\n    return '(unknown state %d)' % number", "response": "Convert a task state ID number to a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_json(self, filename, indent=2):\n        d = self.to_dicts()\n        if hasattr(filename, \"write\"):\n            json.dump(d, filename, indent=indent)\n        elif isinstance(filename, string_types):\n            with open(os.path.expanduser(filename), \"w\") as f:\n                json.dump(d, f, indent=indent)\n        else:\n            raise ValueError(\"Unknown filename or file-object\")", "response": "Returns a JSON string of all model inputs and outputs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_df(self, recommended_only=False, include_io=True):\n        od = BMDS._df_ordered_dict(include_io)\n        [\n            session._add_to_to_ordered_dict(od, i, recommended_only)\n            for i, session in enumerate(self)\n        ]\n        return pd.DataFrame(od)", "response": "Returns a pandas DataFrame containing the models and outputs for each session."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a CSV file for each model and dataset.", "response": "def to_csv(self, filename, delimiter=\",\", recommended_only=False, include_io=True):\n        \"\"\"\n        Return a CSV for each model and dataset.\n\n        Parameters\n        ----------\n        filename : str or file\n            Either the file name (string) or an open file (file-like object)\n            where the data will be saved.\n        delimiter : str, optional\n            Delimiter used in CSV file between fields.\n        recommended_only : bool, optional\n            If True, only recommended models for each session are included. If\n            no model is recommended, then a row with it's ID will be included,\n            but all fields will be null.\n        include_io :  bool, optional\n            If True, then the input/output files from BMDS will also be\n            included, specifically the (d) input file and the out file.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        df = self.to_df(recommended_only, include_io)\n        df.to_csv(filename, index=False, sep=delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an Excel file for each model and dataset.", "response": "def to_excel(self, filename, recommended_only=False, include_io=True):\n        \"\"\"\n        Return an Excel file for each model and dataset.\n\n        Parameters\n        ----------\n        filename : str or ExcelWriter object\n            Either the file name (string) or an ExcelWriter object.\n        recommended_only : bool, optional\n            If True, only recommended models for each session are included. If\n            no model is recommended, then a row with it's ID will be included,\n            but all fields will be null.\n        include_io :  bool, optional\n            If True, then the input/output files from BMDS will also be\n            included, specifically the (d) input file and the out file.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        df = self.to_df(recommended_only, include_io)\n        if isinstance(filename, string_types):\n            filename = os.path.expanduser(filename)\n        df.to_excel(filename, index=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite batch sessions to a Word file.", "response": "def to_docx(\n        self,\n        filename=None,\n        input_dataset=True,\n        summary_table=True,\n        recommendation_details=True,\n        recommended_model=True,\n        all_models=False,\n    ):\n        \"\"\"\n        Write batch sessions to a Word file.\n\n        Parameters\n        ----------\n        filename : str or None\n            If provided, the file is saved to this location, otherwise this\n            method returns a docx.Document\n        input_dataset : bool\n            Include input dataset data table\n        summary_table : bool\n            Include model summary table\n        recommendation_details : bool\n            Include model recommendation details table\n        recommended_model : bool\n            Include the recommended model output and dose-response plot, if\n            one exists\n        all_models : bool\n            Include all models output and dose-response plots\n\n        Returns\n        -------\n        bmds.Reporter\n            The bmds.Reporter object.\n\n        \"\"\"\n        rep = Reporter()\n        for model in self:\n            rep.add_session(\n                model,\n                input_dataset,\n                summary_table,\n                recommendation_details,\n                recommended_model,\n                all_models,\n            )\n\n        if filename:\n            rep.save(filename)\n\n        return rep"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving images of dose - response curve - fits for each session.", "response": "def save_plots(self, directory, format=\"png\", recommended_only=False):\n        \"\"\"\n        Save images of dose-response curve-fits for each model.\n\n        Parameters\n        ----------\n        directory : str\n            Directory where the PNG files will be saved.\n        format : str, optional\n            Image output format. Valid options include: png, pdf, svg, ps, eps\n        recommended_only : bool, optional\n            If True, only recommended models for each session are included. If\n            no model is recommended, then a row with it's ID will be included,\n            but all fields will be null.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        for i, session in enumerate(self):\n            session.save_plots(\n                directory, prefix=str(i), format=format, recommended_only=recommended_only\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the location of a ZIP code", "response": "def cmd(send, msg, args):\n    \"\"\"Gets the location of a ZIP code\n    Syntax: {command} (zipcode)\n    Powered by STANDS4, www.stands4.com\n    \"\"\"\n    uid = args['config']['api']['stands4uid']\n    token = args['config']['api']['stands4token']\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('zipcode', action=arguments.ZipParser)\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    req = get(\"http://www.stands4.com/services/v2/zip.php\", params={'uid': uid, 'tokenid': token, 'zip': cmdargs.zipcode})\n\n    xml = etree.fromstring(req.content, parser=etree.XMLParser(recover=True))\n    location = xml.find('location').text\n    send(\"%s: %s\" % (cmdargs.zipcode, location))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads all the messages in a directory.", "response": "def load_messages(self, directory, catalogue):\n        \"\"\"\n        Loads translation found in a directory.\n\n        @type directory: string\n        @param directory: The directory to search\n\n        @type catalogue: MessageCatalogue\n        @param catalogue: The message catalogue to dump\n\n        @raises: ValueError\n        \"\"\"\n        if not os.path.isdir(directory):\n            raise ValueError(\"{0} is not a directory\".format(directory))\n\n        for format, loader in list(self.loaders.items()):\n            extension = \"{0}.{1}\".format(catalogue.locale, format)\n            files = find_files(directory, \"*.{0}\".format(extension))\n            for file in files:\n                domain = file.split(\"/\")[-1][:-1 * len(extension) - 1]\n                catalogue.add_catalogue(\n                    loader.load(\n                        file,\n                        catalogue.locale,\n                        domain))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_translations(self, catalogue, format, options={}):\n        if format not in self.dumpers:\n            raise ValueError(\n                'There is no dumper associated with format \"{0}\"'.format(format))\n\n        dumper = self.dumpers[format]\n        if \"path\" in options and not os.path.isdir(options['path']):\n            os.mkdir(options['path'])\n\n        dumper.dump(catalogue, options)", "response": "Writes the translations from the given message catalogue according to the given format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscript to find a list of recipes for a group of people with specific likes and dislikes. Output of script best ingred = ['Tea', 'Tofu', 'Cheese', 'Cucumber', 'Salad', 'Chocolate'] worst ingred = ['Fish', 'Lamb', 'Pie', 'Asparagus', 'Chicken', 'Turnips'] Use this = Tofu Use this = Cheese", "response": "def main():\n    \"\"\"\n    script to find a list of recipes for a group of people \n    with specific likes and dislikes.\n    \n    Output of script\n\n        best ingred  =  ['Tea', 'Tofu', 'Cheese', 'Cucumber', 'Salad', 'Chocolate']\n        worst ingred =  ['Fish', 'Lamb', 'Pie', 'Asparagus', 'Chicken', 'Turnips']\n        Use this =  Tofu\n        Use this =  Cheese    \n     \n    \"\"\"\n    s = rawdata.content.DataFiles()\n    all_ingredients = list(s.get_collist_by_name(data_files[1]['file'], data_files[1]['col'])[0])\n    #find_best_ingredients(ingredients_on_hand, dinner_guests)\n    best_ingred, worst_ingred = find_best_ingredients(all_ingredients, dinner_guests)\n\n    print('best ingred  = ', best_ingred)\n    print('worst ingred = ', worst_ingred)\n    \n    for have in ingredients_on_hand:\n        if have in best_ingred:\n            print('Use this = ', have)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, msg, args):\n    uid = args['config']['api']['stands4uid']\n    token = args['config']['api']['stands4token']\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--entry', type=int, default=0, nargs='?')\n    parser.add_argument('word', nargs='+')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    cmdargs.word = ' '.join(cmdargs.word)\n\n    req = get(\"http://www.stands4.com/services/v2/defs.php\", params={'uid': uid, 'tokenid': token, 'word': cmdargs.word})\n    xml = etree.fromstring(req.content, parser=etree.XMLParser(recover=True))\n    if len(xml) == 0:\n        send(\"No results found for %s\" % cmdargs.word)\n        return\n    if cmdargs.entry >= len(xml):\n        send(\"Invalid index %d for term %s\" % (cmdargs.entry, cmdargs.word))\n        return\n    term = xml[cmdargs.entry].find('term').text\n    definition = xml[cmdargs.entry].find('definition').text\n    definition = ' '.join(definition.splitlines()).strip()\n    send(\"%s: %s\" % (term, definition))", "response": "Gets the definition of a word"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nimplements the Read Detail ( read an object", "response": "def read_detail(self, request):\n        \"\"\"\n        Implements the Read Detail (read an object)\n\n        maps to GET /api/objects/:id/ in rest semantics\n        :param request: rip.Request\n        :return: rip.Response\n        \"\"\"\n        pipeline = crud_pipeline_factory.read_detail_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing the Update Detail API.", "response": "def update_detail(self, request):\n        \"\"\"\n        Implements the Update Detail (partially update an object)\n\n        maps to PATCH /api/object/:id/ in rest semantics\n        :param request: rip.Request\n        :return: rip.Response\n        \"\"\"\n        pipeline = crud_pipeline_factory.update_detail_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_list(self, request):\n        pipeline = crud_pipeline_factory.read_list_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)", "response": "Implements the List read"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing the Create Detail API.", "response": "def create_detail(self, request):\n        \"\"\"\n        Implements the Create Detail (create an object)\n\n        maps to POST /api/objects/ in rest semantics\n        :param request: rip.Request\n        :return: rip.Response\n        \"\"\"\n        pipeline = crud_pipeline_factory.create_detail_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_detail(self, request):\n        pipeline = crud_pipeline_factory.delete_detail_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)", "response": "This method is used to delete an object from the resource store. It is used to delete an object from the resource store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_aggregates(self, request):\n        pipeline = crud_pipeline_factory.get_aggregates_pipeline(\n            configuration=self.configuration)\n\n        return pipeline(request=request)", "response": "Implements the Get aggregates endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_or_update_detail(self, request):\n\n        pipeline = crud_pipeline_factory.create_or_update_detail_pipeline(\n            configuration=self.configuration)\n\n        return pipeline(request=request)", "response": "Implements Create or Update an object completely given an id\n            maps to PUT / api / object/:id in rest semantics\nMF does not implement Create or Update"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterable of n batches of the given iterable.", "response": "def batch(iterable, n, fillvalue=None):\n    \"\"\"Batches the elements of given iterable.\n\n    Resulting iterable will yield tuples containing at most ``n`` elements\n    (might be less if ``fillvalue`` isn't specified).\n\n    :param n: Number of items in every batch\n    :param fillvalue: Value to fill the last batch with. If None, last batch\n                      might be shorter than ``n`` elements\n\n    :return: Iterable of batches\n\n    .. note::\n\n        This is an extended version of grouper() recipe\n        from the :module:`itertools` module documentation.\n    \"\"\"\n    ensure_iterable(iterable)\n    if not isinstance(n, Integral):\n        raise TypeError(\"invalid number of elements in a batch\")\n    if not (n > 0):\n        raise ValueError(\"number of elements in a batch must be positive\")\n\n    # since we must use ``izip_longest``\n    # (``izip`` fails if ``n`` is greater than length of ``iterable``),\n    # we will apply some 'trimming' to resulting tuples if necessary\n    if fillvalue is None:\n        fillvalue = object()\n        trimmer = lambda item: tuple(x for x in item if x is not fillvalue)\n    else:\n        trimmer = identity()\n\n    args = [iter(iterable)] * n\n    zipped = izip_longest(*args, fillvalue=fillvalue)\n    return imap(trimmer, zipped)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncycling through given iterable n times.", "response": "def cycle(iterable, n=None):\n    \"\"\"Cycle through given iterable specific (or infinite) number of times.\n\n    :param n: Number of cycles.\n              If None, result cycles through ``iterable`` indefinitely.\n\n    :return: Iterable that cycles through given one\n\n    .. note::\n\n        This is an extended version of ncycles() recipe\n        from the :module:`itertools` module documentation\n        that also has the functionality of standard :func:`itertools.cycle`.\n    \"\"\"\n    ensure_iterable(iterable)\n\n    if n is None:\n        return cycle_(iterable)\n    else:\n        if not isinstance(n, Integral):\n            raise TypeError(\"invalid number of cycles\")\n        if n < 0:\n            raise ValueError(\"number of cycles cannot be negative\")\n\n        return chain.from_iterable(repeat(tuple(iterable), n))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct an iterable which intertwines given iterables.", "response": "def intertwine(*iterables):\n    \"\"\"Constructs an iterable which intertwines given iterables.\n\n    The resulting iterable will return an item from first sequence,\n    then from second, etc. until the last one - and then another item from\n    first, then from second, etc. - up until all iterables are exhausted.\n    \"\"\"\n    iterables = tuple(imap(ensure_iterable, iterables))\n\n    empty = object()\n    return (item\n            for iterable in izip_longest(*iterables, fillvalue=empty)\n            for item in iterable if item is not empty)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iterate(iterator, n=None):\n    ensure_iterable(iterator)\n    if n is None:\n        deque(iterator, maxlen=0)\n    else:\n        next(islice(iterator, n, n), None)", "response": "Efficiently advances the iterator N times ; by default goes to its end."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove duplicates from given iterable using given key as criterion.", "response": "def unique(iterable, key=None):\n    \"\"\"Removes duplicates from given iterable, using given key as criterion.\n\n    :param key: Key function which returns a hashable,\n                uniquely identifying an object.\n\n    :return: Iterable with duplicates removed\n    \"\"\"\n    ensure_iterable(iterable)\n    key = hash if key is None else ensure_callable(key)\n\n    def generator():\n        seen = set()\n        for elem in iterable:\n            k = key(elem)\n            if k not in seen:\n                seen.add(k)\n                yield elem\n\n    return generator()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a breadth - first search of a graph - like structure.", "response": "def breadth_first(start, expand):\n    \"\"\"Performs a breadth-first search of a graph-like structure.\n\n    :param start: Node to start the search from\n    :param expand: Function taking a node as an argument and returning iterable\n                   of its child nodes\n\n    :return: Iterable of nodes in the BFS order\n\n    Example::\n\n        tree = json.loads(some_data)\n        for item in breadth_first(tree, key_func('children', default=())):\n            do_something_with(item)\n    \"\"\"\n    ensure_callable(expand)\n\n    def generator():\n        queue = deque([start])\n        while queue:\n            node = queue.popleft()\n            yield node\n            queue.extend(expand(node))\n\n    return generator()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef depth_first(start, descend):\n    ensure_callable(descend)\n\n    def generator():\n        stack = [start]\n        while stack:\n            node = stack.pop()\n            yield node\n            stack.extend(descend(node))\n\n    return generator()", "response": "Performs a depth - first search of a graph - like structure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef topological_order(nodes, incoming):\n    ensure_iterable(nodes) ; ensure_countable(nodes)\n    ensure_callable(incoming)\n\n    # data structure for tracking node's visit state\n    NOT_VISITED, VISITING, VISITED = range(3)\n    visit_states = {}\n    visit_state = lambda node: visit_states.get(id(node), NOT_VISITED)\n\n    def visit(node):\n        \"\"\"Topological sort visitor function.\"\"\"\n        if visit_state(node) == VISITING:\n            raise ValueError(\"cycle found on node %r\" % (node,))\n        if visit_state(node) == NOT_VISITED:\n            visit_states[id(node)] = VISITING\n            for neighbor in incoming(node):\n                for n in visit(neighbor):\n                    yield n\n            visit_states[id(node)] = VISITED\n            yield node\n\n    def generator():\n        \"\"\"Main generator function that loops through the nodes\n        until we've visited them all.\n        \"\"\"\n        visited_count = 0\n        while visited_count < len(nodes):\n            visited_count = 0\n            for node in nodes:\n                if visit_state(node) == VISITED:\n                    visited_count += 1\n                else:\n                    for n in visit(node):\n                        yield n\n\n    return generator()", "response": "Returns an iterable of nodes in the topological order of a DAG - like structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef regex(regex):\n    if not hasattr(regex, 'pattern'):\n        regex = re.compile(regex)\n\n    pattern = regex.pattern\n    flags = regex.flags\n\n    codes = sre.parse(pattern)\n\n    return _strategy(codes, Context(flags=flags)).filter(regex.match)", "response": "Return strategy that generates strings that match given regex."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _strategy(codes, context):\n    if not isinstance(codes, tuple):\n        # List of codes\n        strategies = []\n\n        i = 0\n        while i < len(codes):\n            if codes[i][0] == sre.LITERAL and not (context.flags & re.IGNORECASE):\n                # Merge subsequent \"literals\" into one `just()` strategy\n                # that generates corresponding text if no IGNORECASE\n                j = i + 1\n                while j < len(codes) and codes[j][0] == sre.LITERAL:\n                    j += 1\n\n                strategies.append(hs.just(\n                    u''.join([six.unichr(charcode) for (_, charcode) in codes[i:j]])\n                ))\n\n                i = j\n            else:\n                strategies.append(_strategy(codes[i], context))\n                i += 1\n\n        return hs.tuples(*strategies).map(u''.join)\n    else:\n        # Single code\n        code, value = codes\n        if code == sre.LITERAL:\n            # Regex 'a' (single char)\n            c = six.unichr(value)\n            if context.flags & re.IGNORECASE:\n                return hs.sampled_from([c.lower(), c.upper()])\n            else:\n                return hs.just(c)\n\n        elif code == sre.NOT_LITERAL:\n            # Regex '[^a]' (negation of a single char)\n            c = six.unichr(value)\n            blacklist = set([c.lower(), c.upper()]) \\\n                if context.flags & re.IGNORECASE else [c]\n            return hs.characters(blacklist_characters=blacklist)\n\n        elif code == sre.IN:\n            # Regex '[abc0-9]' (set of characters)\n            charsets = value\n\n            builder = CharactersBuilder(negate=charsets[0][0] == sre.NEGATE,\n                                        flags=context.flags)\n\n            for charset_code, charset_value in charsets:\n                if charset_code == sre.NEGATE:\n                    # Regex '[^...]' (negation)\n                    pass\n                elif charset_code == sre.LITERAL:\n                    # Regex '[a]' (single char)\n                    builder.add_chars(six.unichr(charset_value))\n                elif charset_code == sre.RANGE:\n                    # Regex '[a-z]' (char range)\n                    low, high = charset_value\n                    for x in six.moves.range(low, high+1):\n                        builder.add_chars(six.unichr(x))\n                elif charset_code == sre.CATEGORY:\n                    # Regex '[\\w]' (char category)\n                    builder.add_category(charset_value)\n                else:\n                    raise he.InvalidArgument(\n                        'Unknown charset code: %s' % charset_code\n                    )\n\n            return builder.strategy\n\n        elif code == sre.ANY:\n            # Regex '.' (any char)\n            if context.flags & re.DOTALL:\n                return hs.characters()\n            else:\n                return hs.characters(blacklist_characters=\"\\n\")\n\n        elif code == sre.AT:\n            # Regexes like '^...', '...$', '\\bfoo', '\\Bfoo'\n            if value == sre.AT_END:\n                return hs.one_of(hs.just(u''), hs.just(u'\\n'))\n            return hs.just('')\n\n        elif code == sre.SUBPATTERN:\n            # Various groups: '(...)', '(:...)' or '(?P<name>...)'\n            old_flags = context.flags\n            if HAS_SUBPATTERN_FLAGS:\n                context.flags = (context.flags | value[1]) & ~value[2]\n\n            strat = _strategy(value[-1], context)\n\n            context.flags = old_flags\n\n            if value[0]:\n                context.groups[value[0]] = strat\n                strat = hs.shared(strat, key=value[0])\n\n            return strat\n\n        elif code == sre.GROUPREF:\n            # Regex '\\\\1' or '(?P=name)' (group reference)\n            return hs.shared(context.groups[value], key=value)\n\n        elif code == sre.ASSERT:\n            # Regex '(?=...)' or '(?<=...)' (positive lookahead/lookbehind)\n            return _strategy(value[1], context)\n\n        elif code == sre.ASSERT_NOT:\n            # Regex '(?!...)' or '(?<!...)' (negative lookahead/lookbehind)\n            return hs.just('')\n\n        elif code == sre.BRANCH:\n            # Regex 'a|b|c' (branch)\n            return hs.one_of([_strategy(branch, context) for branch in value[1]])\n\n        elif code in [sre.MIN_REPEAT, sre.MAX_REPEAT]:\n            # Regexes 'a?', 'a*', 'a+' and their non-greedy variants (repeaters)\n            at_least, at_most, regex = value\n            if at_most == 4294967295:\n                at_most = None\n            return hs.lists(_strategy(regex, context),\n                            min_size=at_least,\n                            max_size=at_most).map(''.join)\n\n        elif code == sre.GROUPREF_EXISTS:\n            # Regex '(?(id/name)yes-pattern|no-pattern)' (if group exists selection)\n            return hs.one_of(\n                _strategy(value[1], context),\n                _strategy(value[2], context) if value[2] else hs.just(u''),\n            )\n\n        else:\n            raise he.InvalidArgument('Unknown code point: %s' % repr(code))", "response": "Convert SRE regex parse tree to strategy that generates strings matching that regex represented by that parse tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns resulting strategy that generates configured char set", "response": "def strategy(self):\n        'Returns resulting strategy that generates configured char set'\n        max_codepoint = None if self._unicode else 127\n\n        strategies = []\n        if self._negate:\n            if self._categories or self._whitelist_chars:\n                strategies.append(\n                    hs.characters(\n                        blacklist_categories=self._categories | set(['Cc', 'Cs']),\n                        blacklist_characters=self._whitelist_chars,\n                        max_codepoint=max_codepoint,\n                    )\n                )\n            if self._blacklist_chars:\n                strategies.append(\n                    hs.sampled_from(\n                        list(self._blacklist_chars - self._whitelist_chars)\n                    )\n                )\n        else:\n            if self._categories or self._blacklist_chars:\n                strategies.append(\n                    hs.characters(\n                        whitelist_categories=self._categories,\n                        blacklist_characters=self._blacklist_chars,\n                        max_codepoint=max_codepoint,\n                    )\n                )\n            if self._whitelist_chars:\n                strategies.append(\n                    hs.sampled_from(\n                        list(self._whitelist_chars - self._blacklist_chars)\n                    )\n                )\n\n        return hs.one_of(*strategies) if strategies else hs.just(u'')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd unicode category to set of unicode categories.", "response": "def add_category(self, category):\n        '''\n        Add unicode category to set\n\n        Unicode categories are strings like 'Ll', 'Lu', 'Nd', etc.\n        See `unicodedata.category()`\n        '''\n        if category == sre.CATEGORY_DIGIT:\n            self._categories |= UNICODE_DIGIT_CATEGORIES\n        elif category == sre.CATEGORY_NOT_DIGIT:\n            self._categories |= UNICODE_CATEGORIES - UNICODE_DIGIT_CATEGORIES\n        elif category == sre.CATEGORY_SPACE:\n            self._categories |= UNICODE_SPACE_CATEGORIES\n            for c in (UNICODE_SPACE_CHARS if self._unicode else SPACE_CHARS):\n                self._whitelist_chars.add(c)\n        elif category == sre.CATEGORY_NOT_SPACE:\n            self._categories |= UNICODE_CATEGORIES - UNICODE_SPACE_CATEGORIES\n            for c in (UNICODE_SPACE_CHARS if self._unicode else SPACE_CHARS):\n                self._blacklist_chars.add(c)\n        elif category == sre.CATEGORY_WORD:\n            self._categories |= UNICODE_WORD_CATEGORIES\n            self._whitelist_chars.add(u'_')\n            if HAS_WEIRD_WORD_CHARS and self._unicode:\n                for c in UNICODE_WEIRD_NONWORD_CHARS:\n                    self._blacklist_chars.add(c)\n        elif category == sre.CATEGORY_NOT_WORD:\n            self._categories |= UNICODE_CATEGORIES - UNICODE_WORD_CATEGORIES\n            self._blacklist_chars.add(u'_')\n            if HAS_WEIRD_WORD_CHARS and self._unicode:\n                for c in UNICODE_WEIRD_NONWORD_CHARS:\n                    self._whitelist_chars.add(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_chars(self, chars):\n        'Add given chars to char set'\n        for c in chars:\n            if self._ignorecase:\n                self._whitelist_chars.add(c.lower())\n                self._whitelist_chars.add(c.upper())\n            else:\n                self._whitelist_chars.add(c)", "response": "Add given chars to char set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npushing android notification through www.pushbullet.com", "response": "def push_to_android(api_key, device_id, payload, push_type):\n    ''' Push android notification through www.pushbullet.com '''\n    payload['type'] = push_type\n    payload['device_id'] = device_id\n    return requests.post('https://api.pushbullet.com/api/pushes',\n                         data=payload,\n                         auth=(api_key, ''))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _device_lookup(self, device_name):\n        ''' Request informations about <name> device '''\n        device_found = {}\n        response = requests.get(self._api_url + 'devices',\n                                auth=(self._api_key, ''))\n        if response.ok:\n            for device in response.json()['devices']:\n                if device_name == device['extras']['model']:\n                    #TODO Check device['extras']['nickname'] as well\n                    device_found = device\n        return device_found", "response": "Request informations about a device"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if we should stop the timer and return a boolean indicating if we should stop the timer.", "response": "def _watchdog(self):\n        ''' Notifications are stopped if\n          * The last one was too close\n          * We reach a rated limit '''\n        too_early = (time.time() - self._last_time < self._min_interval)\n        too_much = (self._count >= self._rate_limit)\n        return (False if (too_early or too_much) else True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef str_traceback(error, tb):\n    if not isinstance(tb, types.TracebackType):\n        return tb\n\n    return ''.join(traceback.format_exception(error.__class__, error, tb))", "response": "Returns a string representation of the traceback."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_traceback(error, tb, ignore_pkg=CURRENT_PACKAGE):\n    if not isinstance(tb, types.TracebackType):\n        return tb\n\n    def in_namespace(n):\n        return n and (n.startswith(ignore_pkg + '.') or n == ignore_pkg)\n    # Skip test runner traceback levels\n    while tb and in_namespace(tb.tb_frame.f_globals['__package__']):\n        tb = tb.tb_next\n    starting_tb = tb\n    limit = 0\n    while tb and not in_namespace(tb.tb_frame.f_globals['__package__']):\n        tb = tb.tb_next\n        limit += 1\n\n    return ''.join(traceback.format_exception(error.__class__, error, starting_tb, limit))", "response": "Filter out all parent stacktraces starting with the given stacktrace that has\n    a given variable name in its globals."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_true_function(obj):\n    \"Returns the actual function and a boolean indicated if this is a method or not.\"\n    if not callable(obj):\n        raise TypeError(\"%r is not callable.\" % (obj,))\n    ismethod = inspect.ismethod(obj)\n    if inspect.isfunction(obj) or ismethod:\n        return obj, ismethod\n    if hasattr(obj, 'im_func'):\n        return obj.im_func, True\n    if inspect.isclass(obj):\n        return getattr(obj, '__init__', None), True\n    if isinstance(obj, object):\n        if hasattr(obj, 'func'):\n            return get_true_function(obj.func)\n        return obj.__call__, True\n    raise TypeError(\"Unknown type of object: %r\" % obj)", "response": "Returns the actual function and a boolean indicated if this is a method or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that the path represents an existing file and that the file exists.", "response": "def assert_valid_path(self, path):\n        \"\"\"\n        Ensures that the path represents an existing file\n\n        @type path: str\n        @param path: path to check\n\n        \"\"\"\n        if not isinstance(path, str):\n            raise NotFoundResourceException(\n                \"Resource passed to load() method must be a file path\")\n\n        if not os.path.isfile(path):\n            raise NotFoundResourceException(\n                'File \"{0}\" does not exist'.format(path))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_file(self, path):\n\n        self.assert_valid_path(path)\n\n        with open(path, 'rb') as file:\n            contents = file.read().decode('UTF-8')\n\n        return contents", "response": "Reads a file into memory and returns it s contents"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising an exception with custom type and modified error message.", "response": "def rethrow(self, msg, _type=InvalidResourceException):\n        \"\"\"\n        Raises an exception with custom type and modified error message.\n        Raised exception is based on current exc_info() and carries it's traceback\n\n        @type msg: str\n        @param msg: New error message\n\n        @type _type: type\n        @param _type: Reraised exception type\n\n        @raises: Exception\n        \"\"\"\n        exc_type, exc_value, exc_traceback = sys.exc_info()\n        msg = msg + \\\n            \"\\nOriginal message: {0} {1}\".format(exc_type.__name__, exc_value)\n        raise _type(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflattens an nested array of translations.", "response": "def flatten(self, messages, parent_key=''):\n        \"\"\"\n        Flattens an nested array of translations.\n\n        The scheme used is:\n          'key' => array('key2' => array('key3' => 'value'))\n        Becomes:\n          'key.key2.key3' => 'value'\n\n        This function takes an array by reference and will modify it\n\n        @type messages: dict\n        @param messages: The dict that will be flattened\n\n        @type parent_key: str\n        @param parent_key: Current path being parsed, used internally for recursive calls\n        \"\"\"\n        items = []\n        sep = '.'\n        for k, v in list(messages.items()):\n            new_key = \"{0}{1}{2}\".format(parent_key, sep, k) if parent_key else k\n            if isinstance(v, collections.MutableMapping):\n                items.extend(list(self.flatten(v, new_key).items()))\n            else:\n                items.append((new_key, v))\n        return dict(items)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, resource):\n        try:\n            import polib\n        except ImportError as e:\n            self.rethrow(\n                \"You need to install polib to use PoFileLoader or MoFileLoader\",\n                ImportError)\n\n        self.assert_valid_path(resource)\n\n        messages = {}\n        parsed = self._load_contents(polib, resource)\n\n        for item in parsed:\n            if item.msgid_plural:\n                plurals = sorted(item.msgstr_plural.items())\n                if item.msgid and len(plurals) > 1:\n                    messages[item.msgid] = plurals[0][1]\n                plurals = [msgstr for idx, msgstr in plurals]\n                messages[item.msgid_plural] = \"|\".join(plurals)\n            elif item.msgid:\n                messages[item.msgid] = item.msgstr\n\n        return messages", "response": "Parses given resource into a dict using polib"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_contents(self, polib, resource):\n        try:\n            return polib.pofile(resource)\n        except (ValueError, AttributeError) as e:\n            self.rethrow(\n                \"Invalid resource {0}\".format(resource),\n                InvalidResourceException)", "response": "Parses portable object using polib. pofile and returns list of tuples"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_contents(self, polib, resource):\n        import struct\n        try:\n            return polib.mofile(resource)\n        except (ValueError, AttributeError, struct.error) as e:\n            self.rethrow(\n                \"Invalid resource {0}\".format(resource),\n                InvalidResourceException)", "response": "Load the contents of a resource from the given polib file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arch(self):\n        if self.method in ('buildArch', 'createdistrepo', 'livecd'):\n            return self.params[2]\n        if self.method in ('createrepo', 'runroot'):\n            return self.params[1]\n        if self.method == 'createImage':\n            return self.params[3]\n        if self.method == 'indirectionimage':\n            return self.params[0]['arch']", "response": "Returns an architecture string for this task."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of architectures for this task.", "response": "def arches(self):\n        \"\"\"\n        Return a list of architectures for this task.\n\n        :returns: a list of arch strings (eg [\"ppc64le\", \"x86_64\"]). The list\n                  is empty if this task has no arches associated with it.\n        \"\"\"\n        if self.method == 'image':\n            return self.params[2]\n        if self.arch:\n            return [self.arch]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a timedelta object for this task.", "response": "def duration(self):\n        \"\"\"\n        Return a timedelta for this task.\n\n        Measure the time between this task's start and end time, or \"now\"\n        if the task has not yet finished.\n\n        :returns: timedelta object, or None if the task has not even started.\n        \"\"\"\n        if not self.started:\n            return None\n        start = self.started\n        end = self.completed\n        if not end:\n            end = datetime.utcnow()\n        return end - start"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef estimate_completion(self):\n        if self.completion_ts:\n            # Task is already complete. Return the exact completion time:\n            defer.returnValue(self.completed)\n        # Get the timestamps from the descendent task that's doing the work:\n        if self.method == 'build' or self.method == 'image':\n            subtask_completion = yield self.estimate_descendents()\n            defer.returnValue(subtask_completion)\n        if self.state == task_states.FREE:\n            est_completion = yield self._estimate_free()\n            defer.returnValue(est_completion)\n        avg_delta = yield self.estimate_duration()\n        if avg_delta is None:\n            defer.returnValue(None)\n        est_completion = self.started + avg_delta\n        defer.returnValue(est_completion)", "response": "Estimate completion time for a task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nestimating the duration of this task.", "response": "def estimate_duration(self):\n        \"\"\"\n        Estimate duration (timedelta) for this task.\n\n        Estimate the average length of time we expect between this task's\n        start and end times.\n\n        :returns: deferred that when fired returns a timedelta object for the\n                  estimated timedelta, or the actual timedelta, or None if we\n                  could not estimate a time for this task method.\n        \"\"\"\n        if self.completion_ts:\n            # Task is already complete. Return the exact duration timedelta.\n            return defer.succeed(self.duration)\n        if not self.package:\n            # TODO: estimate duration some other way besides\n            # getAverageBuildDuration. For example, we could estimate\n            # completion time for newRepo/createrepo tasks by looking back at\n            # the the past couple of tasks for this tag.\n            return defer.succeed(None)\n        if self.method == 'tagBuild':\n            # These are pretty short. Haphazardly guess the max SLEEPTIME plus\n            # a few seconds.\n            tag_build_time = SLEEPTIME + timedelta(seconds=15)\n            return defer.succeed(tag_build_time)\n        return average_build_duration(self.connection, self.package)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nestimate completion time for a free task.", "response": "def _estimate_free(self):\n        \"\"\"\n        Estimate completion time for a free task.\n\n        :returns: deferred that when fired returns a datetime object for the\n                  estimated, or the actual datetime, or None if we could not\n                  estimate a time for this task method.\n        \"\"\"\n        # Query the information we need for this task's channel and package.\n        capacity_deferred = self.channel.total_capacity()\n        open_tasks_deferred = self.channel.tasks(state=[task_states.OPEN])\n        avg_delta_deferred = self.estimate_duration()\n        deferreds = [capacity_deferred,\n                     open_tasks_deferred,\n                     avg_delta_deferred]\n        results = yield defer.gatherResults(deferreds, consumeErrors=True)\n        capacity, open_tasks, avg_delta = results\n        # Ensure this task's channel has spare capacity for this task.\n        open_weight = sum([task.weight for task in open_tasks])\n        if open_weight >= capacity:\n            # TODO: Evaluate all tasks in the channel and\n            # determine when enough OPEN tasks will complete so that we can\n            # get to OPEN.\n            raise NotImplementedError('channel %d is at capacity' %\n                                      self.channel_id)\n        # A builder will pick up this task and start it within SLEEPTIME.\n        # start_time is the maximum amount of time we expect to wait here.\n        start_time = self.created + SLEEPTIME\n        if avg_delta is None:\n            defer.returnValue(None)\n        est_completion = start_time + avg_delta\n        defer.returnValue(est_completion)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef estimate_descendents(self):\n        child_method = None\n        if self.method == 'build':\n            child_method = 'buildArch'\n        if self.method == 'image':\n            child_method = 'createImage'\n        if child_method is None:\n            defer.returnValue(None)\n        # Find the open child task and estimate that.\n        subtasks = yield self.descendents(method=child_method,\n                                          state=task_states.OPEN)\n        if not subtasks:\n            raise NoDescendentsError('no running %s for task %d' %\n                                     (child_method, self.id))\n        # Find subtask with the most recent start time:\n        build_task = subtasks[0]\n        for subtask in subtasks:\n            if subtask.start_ts > build_task.start_ts:\n                build_task = subtask\n        subtask_completion = yield build_task.estimate_completion()\n        defer.returnValue(subtask_completion)", "response": "Estimate the completion time for the child tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds descendant tasks optionally filtered by method and state.", "response": "def descendents(self, method=None, state=None):\n        \"\"\"\n        Find descendant tasks, optionally filtered by method and/or state.\n\n        :param method: (optional) filter for tasks, eg. \"buildArch\".\n        :param state: (optional) filter for tasks, eg. task_states.OPEN.\n        :returns: deferred that when fired returns a list of Tasks.\n        \"\"\"\n        subtasks = yield self.connection.getTaskDescendents(self.id)\n        if method:\n            subtasks = [t for t in subtasks if t.method == method]\n        if state:\n            subtasks = [t for t in subtasks if t.state == state]\n        defer.returnValue(subtasks)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a package name from a build task s parameters.", "response": "def package(self):\n        \"\"\"\n        Find a package name from a build task's parameters.\n\n        :returns: name of the package this build task is building.\n        :raises: ValueError if we could not parse this tasks's request params.\n        \"\"\"\n        if self.method == 'buildNotification':\n            return self.params[1]['name']\n        if self.method in ('createImage', 'image', 'livecd'):\n            return self.params[0]\n        if self.method == 'indirectionimage':\n            return self.params[0]['name']\n        # params[0] is the source URL for these tasks:\n        if self.method not in ('build', 'buildArch', 'buildContainer',\n                               'buildMaven', 'buildSRPMFromSCM', 'maven'):\n            return None\n        # (I wish there was a better way to do this.)\n        source = self.params[0]\n        o = urlparse(source)\n        # build tasks can load an SRPM from a \"cli-build\" tmpdir:\n        if source.endswith('.src.rpm'):\n            srpm = os.path.basename(source)\n            (name, version, release) = srpm.rsplit('-', 2)\n            # Note we're throwing away version and release here. They could be\n            # useful eventually, maybe in a \"Package\" class.\n            return name\n        # or an allowed SCM:\n        elif o.scheme:\n            package = os.path.basename(o.path)\n            if package.endswith('.git'):\n                package = package[:-4]\n            if self.method == 'buildContainer':\n                package += '-container'\n            return package\n        raise ValueError('could not parse source \"%s\"' % source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef params(self):\n        if isinstance(self.request, list):\n            return unmunchify(self.request)\n        (params, _) = xmlrpc.loads(self.request)\n        return params", "response": "Return a list of parameters in this task s request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tag(self):\n        if self.method == 'buildArch':\n            # Note: buildArch tag will be an int here.\n            return self.params[1]\n        if self.method in ('createdistrepo', 'distRepo', 'newRepo', 'runroot',\n                           'tagBuild', 'waitrepo'):\n            return self.params[0]\n        if self.method == 'tagNotification':\n            return self.params[2]\n        if self.method == 'buildMaven':\n            return self.params[1]['name']", "response": "Returns the tag name or id number for this task."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url(self):\n        endpoint = 'taskinfo?taskID=%d' % self.id\n        return posixpath.join(self.connection.weburl, endpoint)", "response": "Return a kojiweb URL for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npulls changes. Syntax: command", "response": "def cmd(send, _, args):\n    \"\"\"Pull changes.\n\n    Syntax: {command} <branch>\n\n    \"\"\"\n    try:\n        if exists(join(args['handler'].confdir, '.git')):\n            send(do_pull(srcdir=args['handler'].confdir))\n        else:\n            send(do_pull(repo=args['config']['api']['githubrepo']))\n    except subprocess.CalledProcessError as ex:\n        for line in ex.output.strip().splitlines():\n            logging.error(line)\n        raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_markov(cursor, cmdchar, ctrlchan, speaker=None, initial_run=False, debug=False):\n    if initial_run:\n        cursor.query(Babble_last).delete()\n    lastrow = cursor.query(Babble_last).first()\n    if not lastrow:\n        lastrow = Babble_last(last=0)\n        cursor.add(lastrow)\n    t = time.time()  # for debug\n    messages = get_messages(cursor, cmdchar, ctrlchan, speaker, lastrow.last)\n    # FIXME: count can be too low if speaker is not None\n    curr = messages[-1].id if messages else None\n    markov = generate_markov(cursor, 1, messages, initial_run)\n    markov2 = generate_markov(cursor, 2, messages, initial_run)\n    if debug:\n        print('Generated markov in %f' % (time.time() - t))\n        t = time.time()\n    data, count_data = build_rows(cursor, 1, markov, initial_run)\n    data2, count_data2 = build_rows(cursor, 2, markov2, initial_run)\n    if debug:\n        print('Rows built in %f' % (time.time() - t))\n    if initial_run:\n        t = time.time()  # for debug\n        delete_tables(cursor)\n        if debug:\n            print('Tables deleted in %f' % (time.time() - t))\n    t = time.time()  # for debug\n    if initial_run and cursor.bind.dialect.name == 'postgresql':\n        postgres_hack(cursor, 1, data)\n        postgres_hack(cursor, 2, data2)\n    else:\n        data = [{'source': x[0], 'target': x[1], 'key': x[2], 'word': x[3], 'freq': x[4]} for x in data]\n        cursor.bulk_insert_mappings(Babble, data)\n        data2 = [{'source': x[0], 'target': x[1], 'key': x[2], 'word': x[3], 'freq': x[4]} for x in data2]\n        cursor.bulk_insert_mappings(Babble2, data2)\n    cursor.bulk_insert_mappings(Babble_count, count_data)\n    cursor.bulk_insert_mappings(Babble_count, count_data2)\n    if debug:\n        print('Inserted rows in %f' % (time.time() - t))\n    if curr is not None:\n        lastrow.last = curr\n    if initial_run:\n        if debug:\n            t = time.time()\n        key_index = Index('ix_babble_key', Babble.key)\n        key_index2 = Index('ix_babble2_key', Babble2.key)\n        key_index.create(cursor.connection())\n        key_index2.create(cursor.connection())\n        if debug:\n            print('Created index in %f' % (time.time() - t))\n    t = time.time()  # for debug\n    cursor.commit()\n    if debug:\n        print('Commited in %f' % (time.time() - t))", "response": "Builds a markov dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start_date_of_year(year: int) -> datetime.date:\n\n    jan_one = datetime.date(year, 1, 1)\n    diff = 7 * (jan_one.isoweekday() > 3) - jan_one.isoweekday()\n\n    return jan_one + datetime.timedelta(days=diff)", "response": "Return start date of the year using MMWR week rules\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn date from epiweek", "response": "def epiweek_to_date(ew: Epiweek) -> datetime.date:\n    \"\"\"\n    Return date from epiweek (starts at Sunday)\n    \"\"\"\n\n    day_one = _start_date_of_year(ew.year)\n    diff = 7 * (ew.week - 1) + (ew.day - 1)\n\n    return day_one + datetime.timedelta(days=diff)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_to_epiweek(date=datetime.date.today()) -> Epiweek:\n\n    year = date.year\n    start_dates = list(map(_start_date_of_year, [year - 1, year, year + 1]))\n\n    start_date = start_dates[1]\n    if start_dates[1] > date:\n        start_date = start_dates[0]\n    elif date >= start_dates[2]:\n        start_date = start_dates[2]\n\n    return Epiweek(\n        year=(start_date + datetime.timedelta(days=7)).year,\n        week=((date - start_date).days // 7) + 1,\n        day=(date.isoweekday() % 7) + 1\n    )", "response": "Convert python date to Epiweek"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn number of epiweeks in a year", "response": "def epiweeks_in_year(year: int) -> int:\n    \"\"\"\n    Return number of epiweeks in a year\n    \"\"\"\n\n    if date_to_epiweek(epiweek_to_date(Epiweek(year, 53))).year == year:\n        return 53\n    else:\n        return 52"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parser(self):\n        if self._command_parser is None:\n            parents = []\n            if self.need_verbose:\n                parents.append(_verbose_parser)\n            if self.need_settings:\n                parents.append(_settings_parser)\n\n            self._command_parser = self._main_parser.add_parser(self.name,\n                                                                help=self.help,\n                                                                parents=parents,\n                                                                formatter_class=argparse.RawDescriptionHelpFormatter)\n        return self._command_parser", "response": "Returns the appropriate parser to use for adding arguments to your command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the name of the category member with the matching value.", "response": "def get_name(cls, value):\n        \"\"\" Returns the `name` of the `Category` member with the matching *value*\n        or a empty string if no member match.\n\n        Example:\n\n        >>> class Format(Category):\n        ...     hour = 'hh'\n        ...     minute = 'mm'\n        ...     second = 'ss'\n        >>> Format.get_name('hh')\n        'hour'\n        >>> Format.get_name('dd')\n        ''\n        \"\"\"\n        for member in cls:\n            if member.value == value:\n                return member.name\n        return str()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value(cls, name):\n        for member in cls:\n            if member.name == name:\n                return member.value\n        return None", "response": "Returns the value of the category member with the matching name or None if no match."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_member(cls, value, default=None):\n        for member in cls:\n            if member.value == value:\n                return member\n        return default", "response": "Returns the first Category member with the matching value or the specified default value if no match is found."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd(send, _, args):\n    adminlist = []\n    for admin in args['db'].query(Permissions).order_by(Permissions.nick).all():\n        if admin.registered:\n            adminlist.append(\"%s (V)\" % admin.nick)\n        else:\n            adminlist.append(\"%s (U)\" % admin.nick)\n    send(\", \".join(adminlist), target=args['nick'])", "response": "Returns a list of admins."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        x, y = 1,0  # set the direction\n        num_steps = 0\n        while self.s.get_state() != 'Halted':\n            self.s.command({'name':'walk', 'type':'move', 'direction':[x, y]}, self.a1)\n            self.s.command({'name':'walk', 'type':'run', 'direction':[x, y+1]}, self.a2)\n            num_steps += 1\n            if num_steps >= 3:\n                break\n        for a in self.s.agents:\n            print(a.name, 'finished at position ', a.coords['x'], a.coords['y'])", "response": "This AI simple moves the characters towards the opposite\n            edges of the simulation for 3 steps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate a configuration file against a confirm schema.", "response": "def validate(schema_file, config_file, deprecation):\n    '''Validate a configuration file against a confirm schema.'''\n\n    result = validator_from_config_file(config_file, schema_file)\n    result.validate(error_on_deprecated=deprecation)\n\n    for error in result.errors():\n        click.secho('Error   : %s' % error, err=True, fg='red')\n\n    for warning in result.warnings():\n        click.secho('Warning : %s' % warning, err=True, fg='yellow')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmigrating a configuration file using a confirm schema.", "response": "def migrate(schema_file, config_file):\n    '''Migrates a configuration file using a confirm schema.'''\n\n    schema = load_schema_file(open(schema_file, 'r'))\n    config = load_config_file(config_file, open(config_file, 'r').read())\n\n    config = append_existing_values(schema, config)\n\n    migrated_config = generate_config_parser(config)\n    migrated_config.write(sys.stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating reStructuredText documentation from a confirm schema.", "response": "def document(schema_file):\n    '''Generate reStructuredText documentation from a confirm schema.'''\n    schema = load_schema_file(open(schema_file, 'r'))\n    documentation = generate_documentation(schema)\n    sys.stdout.write(documentation)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate(schema_file, all_options):\n    '''Generates a template configuration file from a confirm schema.'''\n    schema = load_schema_file(open(schema_file, 'r'))\n    config_parser = generate_config_parser(schema, include_all=all_options)\n    config_parser.write(sys.stdout)", "response": "Generates a template configuration file from a confirm schema."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(config_file):\n    '''Initialize a confirm schema from an existing configuration file.'''\n    schema = generate_schema_file(open(config_file, 'r').read())\n    sys.stdout.write(schema)", "response": "Initialize a confirm schema from an existing configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_likelihoods(self, X):\n\n        n_samples = np.shape(X)[0]\n        likelihoods = np.zeros((n_samples, self.k))\n        for i in range(self.k):\n            likelihoods[:, i] = self.multivariate_gaussian(X, self.parameters[i])\n\n        return likelihoods", "response": "Calculate the likelihood over all samples"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _maximization(self, X):\n\n        # Iterate through clusters and recalculate mean and covariance\n        for i in range(self.k):\n            resp = np.expand_dims(self.responsibility[:, i], axis=1)\n            mean = (resp * X).sum(axis=0) / resp.sum()\n            covariance = (X - mean).T.dot((X - mean) * resp) / resp.sum()\n            self.parameters[i][\"mean\"], self.parameters[i][\"cov\"] = mean, covariance\n\n        # Update weights\n        n_samples = np.shape(X)[0]\n        self.priors = self.responsibility.sum(axis=0) / n_samples", "response": "Update the parameters and priors based on the cluster weights and the residual."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _converged(self, X):\n\n        if len(self.responsibilities) < 2:\n            return False\n\n        diff = np.linalg.norm(self.responsibilities[-1] - self.responsibilities[-2])\n        return diff <= self.tolerance", "response": "Covergence check for the current class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns GMM and return the cluster indices", "response": "def cluster(self, X):\n        \"\"\"Run GMM and return the cluster indices\"\"\"\n\n        # Initialize the gaussians randomly\n        self._init_random_gaussians(X)\n\n        # Run EM until convergence or for max iterations\n        for _ in range(self.max_iterations):\n            self._expectation(X)    # E-step\n            self._maximization(X)   # M-step\n\n            # Check convergence\n            if self._converged(X):\n                break\n\n        # Make new assignments and return them\n        self._expectation(X)\n        return self.sample_assignments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate something. Syntax: {command} [--from <language code>] [--to <language code>] <text> See https://cloud.google.com/translate/v2/translate-reference#supported_languages for a list of valid language codes", "response": "def cmd(send, msg, args):\n    \"\"\"Translate something.\n\n    Syntax: {command} [--from <language code>] [--to <language code>] <text>\n    See https://cloud.google.com/translate/v2/translate-reference#supported_languages for a list of valid language codes\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--lang', '--from', default=None)\n    parser.add_argument('--to', default='en')\n    parser.add_argument('msg', nargs='+')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    send(gen_translate(' '.join(cmdargs.msg), cmdargs.lang, cmdargs.to))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflipping a coin a number of times.", "response": "def cmd(send, msg, _):\n    \"\"\"Flips a coin a number of times.\n\n    Syntax: {command} [number]\n\n    \"\"\"\n    coin = ['heads', 'tails']\n    if not msg:\n        send('The coin lands on... %s' % choice(coin))\n    elif not msg.lstrip('-').isdigit():\n        send(\"Not A Valid Positive Integer.\")\n    else:\n        msg = int(msg)\n        if msg < 0:\n            send(\"Negative Flipping requires the (optional) quantum coprocessor.\")\n            return\n        headflips = randint(0, msg)\n        tailflips = msg - headflips\n        send('The coins land on heads %g times and on tails %g times.' % (headflips, tailflips))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_data(self):\n        data = {}\n        data['guarded'] = self.guarded[:]\n        data['voiced'] = copy.deepcopy(self.voiced)\n        data['opers'] = copy.deepcopy(self.opers)\n        data['features'] = self.features.copy()\n        data['uptime'] = self.uptime.copy()\n        data['abuselist'] = self.abuselist.copy()\n        data['who_map'] = self.who_map.copy()\n        return data", "response": "Saves the handler s data for the reload method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_data(self, data):\n        for key, val in data.items():\n            setattr(self, key, val)\n        self.uptime['reloaded'] = datetime.now()", "response": "Called from. reloader. do_reload to restore the handler s data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a nick is an admin.", "response": "def is_admin(self, send, nick, required_role='admin'):\n        \"\"\"Checks if a nick is a admin.\n\n        If NickServ hasn't responded yet, then the admin is unverified,\n        so assume they aren't a admin.\n\n        \"\"\"\n        # If the required role is None, bypass checks.\n        if not required_role:\n            return True\n        # Current roles are admin and owner, which is a superset of admin.\n        with self.db.session_scope() as session:\n            admin = session.query(orm.Permissions).filter(orm.Permissions.nick == nick).first()\n            if admin is None:\n                return False\n            # owner implies admin, but not the other way around.\n            if required_role == \"owner\" and admin.role != \"owner\":\n                return False\n            # no nickserv support, assume people are who they say they are.\n            if not self.config['feature'].getboolean('nickserv'):\n                return True\n            if not admin.registered:\n                self.update_authstatus(nick)\n                # We don't necessarily want to complain in all cases.\n                if send is not None:\n                    send(\"Unverified admin: %s\" % nick, target=self.config['core']['channel'])\n                return False\n            else:\n                if not self.features['account-notify']:\n                    # reverify every 5min if we don't have the notification feature.\n                    if datetime.now() - admin.time > timedelta(minutes=5):\n                        self.update_authstatus(nick)\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck verification for all admins.", "response": "def get_admins(self):\n        \"\"\"Check verification for all admins.\"\"\"\n        # no nickserv support, assume people are who they say they are.\n        if not self.config['feature'].getboolean('nickserv'):\n            return\n        with self.db.session_scope() as session:\n            for a in session.query(orm.Permissions).all():\n                if not a.registered:\n                    self.update_authstatus(a.nick)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abusecheck(self, send, nick, target, limit, cmd):\n        if nick not in self.abuselist:\n            self.abuselist[nick] = {}\n        if cmd not in self.abuselist[nick]:\n            self.abuselist[nick][cmd] = [datetime.now()]\n        else:\n            self.abuselist[nick][cmd].append(datetime.now())\n        count = 0\n        for x in self.abuselist[nick][cmd]:\n            # 60 seconds - arbitrary cuttoff\n            if datetime.now() - x < timedelta(seconds=60):\n                count = count + 1\n        if count > limit:\n            msg = \"%s: don't abuse scores!\" if cmd == 'scores' else \"%s: stop abusing the bot!\"\n            send(msg % nick, target=target)\n            with self.db.session_scope() as session:\n                send(misc.ignore(session, nick))\n            return True", "response": "Check if a user abuses the bot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self, target, nick, msg, msgtype, ignore_length=False, filters=None):\n        if not isinstance(msg, str):\n            raise Exception(\"Trying to send a %s to irc, only strings allowed.\" % type(msg).__name__)\n        if filters is None:\n            filters = self.outputfilter[target]\n        for i in filters:\n            if target != self.config['core']['ctrlchan']:\n                msg = i(msg)\n        # Avoid spam from commands that produce excessive output.\n        if not ignore_length:\n            # Ignore everything after the first 800 chars.\n            msg = misc.truncate_msg(msg, 800)\n\n        # We can't send messages > 512 bytes to irc.\n        max_len = misc.get_max_length(target, msgtype)\n        msgs = self.build_split_msg(msg, max_len)\n\n        for i in msgs:\n            self.do_log(target, nick, i, msgtype)\n            if msgtype == 'action':\n                self.rate_limited_send('action', target, i)\n            else:\n                self.rate_limited_send('privmsg', target, i)", "response": "Send a message to the irc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_log(self, target, nick, msg, msgtype):\n        if not isinstance(msg, str):\n            raise Exception(\"IRC doesn't like it when you send it a %s\" % type(msg).__name__)\n        target = target.lower()\n        flags = 0\n        # Properly handle /msg +#channel\n        if target.startswith(('+', '@')):\n            target = target[1:]\n        with self.data_lock:\n            if target in self.channels:\n                if self.opers[target].get(nick, False):\n                    flags |= 1\n                if self.voiced[target].get(nick, False):\n                    flags |= 2\n            else:\n                target = 'private'\n        # FIXME: should we special-case this?\n        # strip ctrl chars from !creffett\n        msg = msg.replace('\\x02\\x038,4', '<rage>')\n        self.db.log(nick, target, flags, msg, msgtype)\n\n        if self.log_to_ctrlchan:\n            ctrlchan = self.config['core']['ctrlchan']\n            if target != ctrlchan:\n                ctrlmsg = \"%s:%s:%s:%s\" % (target, msgtype, nick, msg)\n                # If we call self.send, we'll get a infinite loop.\n                self.connection.privmsg(ctrlchan, ctrlmsg.strip())", "response": "Handles logging.\n\n        | Logs to a sql db."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nleave a channel. Prevent user from leaving the primary channel.", "response": "def do_part(self, cmdargs, nick, target, msgtype, send, c):\n        \"\"\"Leaves a channel.\n\n        Prevent user from leaving the primary channel.\n\n        \"\"\"\n        channel = self.config['core']['channel']\n        botnick = self.config['core']['nick']\n        if not cmdargs:\n            # don't leave the primary channel\n            if target == channel:\n                send(\"%s must have a home.\" % botnick)\n                return\n            else:\n                cmdargs = target\n        if not cmdargs.startswith(('#', '+', '@')):\n            cmdargs = '#' + cmdargs\n        # don't leave the primary channel\n        if cmdargs == channel:\n            send(\"%s must have a home.\" % botnick)\n            return\n        # don't leave the control channel\n        if cmdargs == self.config['core']['ctrlchan']:\n            send(\"%s must remain under control, or bad things will happen.\" % botnick)\n            return\n        self.send(cmdargs, nick, \"Leaving at the request of %s\" % nick, msgtype)\n        c.part(cmdargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\njoin a channel. | Checks if bot is already joined to channel.", "response": "def do_join(self, cmdargs, nick, msgtype, send, c):\n        \"\"\"Join a channel.\n\n        | Checks if bot is already joined to channel.\n\n        \"\"\"\n        if not cmdargs:\n            send(\"Join what?\")\n            return\n        if cmdargs == '0':\n            send(\"I'm sorry, Dave. I'm afraid I can't do that.\")\n            return\n        if not cmdargs.startswith(('#', '+', '@')):\n            cmdargs = '#' + cmdargs\n        cmd = cmdargs.split()\n        # FIXME: use argparse\n        if cmd[0] in self.channels and not (len(cmd) > 1 and cmd[1] == \"force\"):\n            send(\"%s is already a member of %s\" % (self.config['core']['nick'], cmd[0]))\n            return\n        c.join(cmd[0])\n        self.send(cmd[0], nick, \"Joined at the request of \" + nick, msgtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nkicks users. - If kick is disabled, don't do anything. - If the bot is not a op, rage at a op. - Kick the user.", "response": "def do_kick(self, send, target, nick, msg, slogan=True):\n        \"\"\"Kick users.\n\n        - If kick is disabled, don't do anything.\n        - If the bot is not a op, rage at a op.\n        - Kick the user.\n\n        \"\"\"\n        if not self.kick_enabled:\n            return\n        if target not in self.channels:\n            send(\"%s: you're lucky, private message kicking hasn't been implemented yet.\" % nick)\n            return\n        with self.data_lock:\n            ops = [k for k, v in self.opers[target].items() if v]\n        botnick = self.config['core']['nick']\n        if botnick not in ops:\n            ops = ['someone'] if not ops else ops\n            send(textutils.gen_creffett(\"%s: /op the bot\" % random.choice(ops)), target=target)\n        elif random.random() < 0.01 and msg == \"shutting caps lock off\":\n            if nick in ops:\n                send(\"%s: HUEHUEHUE GIBE CAPSLOCK PLS I REPORT U\" % nick, target=target)\n            else:\n                self.connection.kick(target, nick, \"HUEHUEHUE GIBE CAPSLOCK PLS I REPORT U\")\n        else:\n            msg = textutils.gen_slogan(msg).upper() if slogan else msg\n            if nick in ops:\n                send(\"%s: %s\" % (nick, msg), target=target)\n            else:\n                self.connection.kick(target, nick, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_args(self, modargs, send, nick, target, source, name, msgtype):\n        realargs = {}\n        args = {\n            'nick': nick,\n            'handler': self,\n            'db': None,\n            'config': self.config,\n            'source': source,\n            'name': name,\n            'type': msgtype,\n            'botnick': self.connection.real_nickname,\n            'target': target if target[0] == \"#\" else \"private\",\n            'do_kick': lambda target, nick, msg: self.do_kick(send, target, nick, msg),\n            'is_admin': lambda nick: self.is_admin(send, nick),\n            'abuse': lambda nick, limit, cmd: self.abusecheck(send, nick, target, limit, cmd)\n        }\n        for arg in modargs:\n            if arg in args:\n                realargs[arg] = args[arg]\n            else:\n                raise Exception(\"Invalid Argument: %s\" % arg)\n        return realargs", "response": "Handle the various args that modules need."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo setup when connected to server.", "response": "def do_welcome(self):\n        \"\"\"Do setup when connected to server.\n\n        - Join the primary channel.\n        - Join the control channel.\n\n        \"\"\"\n        self.rate_limited_send('join', self.config['core']['channel'])\n        self.rate_limited_send('join', self.config['core']['ctrlchan'], self.config['auth']['ctrlkey'])\n        # We use this to pick up info on admins who aren't currently in a channel.\n        self.workers.defer(5, False, self.get_admins)\n        extrachans = self.config['core']['extrachans']\n        if extrachans:\n            for chan in [x.strip() for x in extrachans.split(',')]:\n                self.rate_limited_send('join', chan)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse out any filters and send them to target.", "response": "def get_filtered_send(self, cmdargs, send, target):\n        \"\"\"Parse out any filters.\"\"\"\n        parser = arguments.ArgParser(self.config)\n        parser.add_argument('--filter')\n        try:\n            filterargs, remainder = parser.parse_known_args(cmdargs)\n        except arguments.ArgumentException as ex:\n            return str(ex), None\n        cmdargs = ' '.join(remainder)\n        if filterargs.filter is None:\n            return cmdargs, send\n        filter_list, output = textutils.append_filters(filterargs.filter)\n        if filter_list is None:\n            return output, None\n\n        # define a new send to handle filter chaining\n        def filtersend(msg, mtype='privmsg', target=target, ignore_length=False):\n            self.send(target, self.connection.real_nickname, msg, mtype, ignore_length, filters=filter_list)\n\n        return cmdargs, filtersend"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd(send, _, args):\n    apikey = args['config']['api']['ebayapikey']\n    categories = get_categories(apikey)\n    item = None\n    while not item:\n        item = get_item(choice(categories), apikey)\n    send(item)", "response": "Implements xkcd 576.\n    Syntax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a tag and detects which function to use", "response": "def process_tag(self, tag):\n        \"\"\"Processes tag and detects which function to use\"\"\"\n        try:\n            if not self._is_function(tag):\n                self._tag_type_processor[tag.data_type](tag)\n        except KeyError as ex:\n            raise Exception('Tag type {0} not recognized for tag {1}'\n                            .format(\n                                tag.data_type,\n                                tag.name),\n                            ex)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing Boolean type tags", "response": "def process_boolean(self, tag):\n        \"\"\"Process Boolean type tags\"\"\"\n        tag.set_address(self.normal_register.current_bit_address)\n        self.normal_register.move_to_next_bit_address()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_boolean_array(self, tag):\n        array_size = tag.get_array_size()\n        tag.set_address(self.normal_register.get_array(array_size))\n        if self.is_sixteen_bit:\n            # each boolean address needs 1/16 byte\n            self.normal_register.move_to_next_address((array_size / 16) + 1)\n            return\n        # each boolean address needs 1/8 byte\n        self.normal_register.move_to_next_address((array_size / 8) + 1)", "response": "Process Boolean array type tags"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_byte(self, tag):\n        tag.set_address(self.normal_register.current_address)\n        # each address needs 1 byte\n        self.normal_register.move_to_next_address(1)", "response": "Process a byte type tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_string(self, tag):\n        tag.set_address(self.string_register.current_address)\n        if self.is_sixteen_bit:\n            # each string address needs 1 byte = 1/2 an address\n            self.string_register.move_to_next_address(1)\n            return\n        # each string address needs 1 byte = 1 address\n        self.string_register.move_to_next_address(1)", "response": "Process string type tags"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, msg, args):\n    nick = args['nick']\n    channel = args['target'] if args['target'] != 'private' else args['config']['core']['channel']\n    levels = {\n        1: 'Whirr...',\n        2: 'Vrrm...',\n        3: 'Zzzzhhhh...',\n        4: 'SHFRRRRM...',\n        5: 'GEEEEZZSH...',\n        6: 'PLAAAAIIID...',\n        7: 'KKKRRRAAKKKAAKRAKKGGARGHGIZZZZ...',\n        8: 'Nuke',\n        9: 'nneeeaaaooowwwwww..... BOOOOOSH BLAM KABOOM',\n        10: 'ssh root@remote.tjhsst.edu rm -rf ~%s'\n    }\n    if not msg:\n        send('What to microwave?')\n        return\n    match = re.match('(-?[0-9]*) (.*)', msg)\n    if not match:\n        send('Power level?')\n    else:\n        level = int(match.group(1))\n        target = match.group(2)\n        if level > 10:\n            send('Aborting to prevent extinction of human race.')\n            return\n        if level < 1:\n            send('Anti-matter not yet implemented.')\n            return\n        if level > 7:\n            if not args['is_admin'](nick):\n                send(\"I'm sorry. Nukes are a admin-only feature\")\n                return\n            elif msg == args['botnick']:\n                send(\"Sorry, Self-Nuking is disabled pending aquisition of a Lead-Lined Fridge.\")\n            else:\n                with args['handler'].data_lock:\n                    if target not in args['handler'].channels[channel].users():\n                        send(\"I'm sorry. Anonymous Nuking is not allowed\")\n                        return\n\n        msg = levels[1]\n        for i in range(2, level + 1):\n            if i < 8:\n                msg += ' ' + levels[i]\n        send(msg)\n        if level >= 8:\n            do_nuke(args['handler'].connection, nick, target, channel)\n        if level >= 9:\n            send(levels[9])\n        if level == 10:\n            send(levels[10] % target)\n        send('Ding, your %s is ready.' % target)", "response": "Microwaves something.\n\n    Syntax: {command} <level> <target>"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsampling code to retrieve the data from an OpenSenseMap station.", "response": "async def main():\n    \"\"\"Sample code to retrieve the data from an OpenSenseMap station.\"\"\"\n    async with aiohttp.ClientSession() as session:\n        station = OpenSenseMap(SENSOR_ID, loop, session)\n\n        # Print details about the given station\n        await station.get_data()\n\n        print(\"Name:\", station.name)\n        print(\"Description:\", station.description)\n        print(\"Coordinates:\", station.coordinates)\n\n        print(\"PM 2.5:\", station.pm2_5)\n        print(\"PM 10:\", station.pm10)\n\n        print(\"Temperature:\", station.temperature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef error(self, cmd, desc=''):\n        ''' Style for an error message. '''\n        return self._label_desc(cmd, desc, self.error_color)", "response": "Style for an error message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstyling for warning message.", "response": "def warn(self, cmd, desc=''):\n        ''' Style for warning message. '''\n        return self._label_desc(cmd, desc, self.warn_color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstyles for a success message.", "response": "def success(self, cmd, desc=''):\n        ''' Style for a success message. '''\n        return self._label_desc(cmd, desc, self.success_color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding the command loop to handle Ctrl - C.", "response": "def cmdloop(self, intro=None):\n        ''' Override the command loop to handle Ctrl-C. '''\n        self.preloop()\n\n        # Set up completion with readline.\n        if self.use_rawinput and self.completekey:\n            try:\n                import readline\n                self.old_completer = readline.get_completer()\n                readline.set_completer(self.complete)\n                readline.parse_and_bind(self.completekey + ': complete')\n            except ImportError:\n                pass\n\n        try:\n            if intro is not None:\n                self.intro = intro\n            if self.intro:\n                self.stdout.write(str(self.intro)+\"\\n\")\n            stop = None\n            while not stop:\n                if self.cmdqueue:\n                    line = self.cmdqueue.pop(0)\n                else:\n                    if self.use_rawinput:\n                        try:\n                            if sys.version_info[0] == 2:\n                                line = raw_input(self.prompt)\n                            else:\n                                line = input(self.prompt)\n                        except EOFError:\n                            line = 'EOF'\n                        except KeyboardInterrupt:\n                            line = 'ctrlc'\n                    else:\n                        self.stdout.write(self.prompt)\n                        self.stdout.flush()\n                        line = self.stdin.readline()\n                        if not len(line):\n                            line = 'EOF'\n                        else:\n                            line = line.rstrip('\\r\\n')\n                line = self.precmd(line)\n                stop = self.onecmd(line)\n                stop = self.postcmd(stop, line)\n            self.postloop()\n        finally:\n            if self.use_rawinput and self.completekey:\n                try:\n                    import readline\n                    readline.set_completer(self.old_completer)\n                except ImportError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_ctrlc(self, arg):\n        ''' Ctrl-C sends a STOP command to the arm. '''\n        print('STOP')\n        if self.arm.is_connected():\n            self.arm.write('STOP')", "response": "Ctrl - C sends a STOP command to the arm."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint information about the arm.", "response": "def do_status(self, arg):\n        ''' Print information about the arm. '''\n        info = self.arm.get_info()\n        max_len = len(max(info.keys(), key=len))\n\n        print(self.style.theme('\\nArm Status'))\n        for key, value in info.items():\n            print(self.style.help(key.ljust(max_len + 2), str(value)))\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_connect(self, arg):\n        ''' Connect to the arm. '''\n        if self.arm.is_connected():\n            print(self.style.error('Error: ', 'Arm is already connected.'))\n        else:\n            try:\n                port = self.arm.connect()\n                print(self.style.success('Success: ',\n                                         'Connected to \\'{}\\'.'.format(port)))\n            except r12.ArmException as e:\n                print(self.style.error('Error: ', str(e)))", "response": "Connect to the arm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisconnecting from the arm.", "response": "def do_disconnect(self, arg):\n        ''' Disconnect from the arm. '''\n        if not self.arm.is_connected():\n            print(self.style.error('Error: ', 'Arm is already disconnected.'))\n        else:\n            self.arm.disconnect()\n            print(self.style.success('Success: ', 'Disconnected.'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload and run an external FORTH script.", "response": "def do_run(self, arg):\n        ''' Load and run an external FORTH script. '''\n        if not self.arm.is_connected():\n            print(self.style.error('Error: ', 'Arm is not connected.'))\n            return\n\n        # Load the script.\n        try:\n            with open(arg) as f:\n                lines = [line.strip() for line in f.readlines()]\n        except IOError:\n            print(self.style.error('Error: ',\n                                   'Could not load file \\'{}\\'.'.format(arg)))\n            return\n\n        for line in lines:\n            if self.wrapper:\n                line = self.wrapper.wrap_input(line)\n            self.arm.write(line)\n            res = self.arm.read()\n            if self.wrapper:\n                res = self.wrapper.wrap_output(res)\n            print(res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping all bytes waiting in output queue.", "response": "def do_dump(self, arg):\n        ''' Output all bytes waiting in output queue. '''\n        if not self.arm.is_connected():\n            print(self.style.error('Error: ', 'Arm is not connected.'))\n            return\n        print(self.arm.dump())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef complete_run(self, text, line, b, e):\n        ''' Autocomplete file names with .forth ending. '''\n        # Don't break on path separators.\n        text = line.split()[-1]\n\n        # Try to find files with a forth file ending, .fs.\n        forth_files = glob.glob(text + '*.fs')\n\n        # Failing that, just try and complete something.\n        if len(forth_files) == 0:\n            return [f.split(os.path.sep)[-1] for f in glob.glob(text + '*')]\n\n        forth_files = [f.split(os.path.sep)[-1] for f in forth_files]\n        return forth_files", "response": "Autocomplete file names with. forth ending."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default(self, line):\n        ''' Commands with no do_* method fall to here. '''\n        # Commands that fall through to this method are interpreted as FORTH,\n        # and must be in upper case.\n        if not line.isupper():\n            print(self.style.error('Error: ', 'Unrecognized command.'))\n            return\n\n        if self.arm.is_connected():\n            if self.wrapper:\n                line = self.wrapper.wrap_input(line)\n            self.arm.write(line)\n            try:\n                res = self.arm.read()\n            except KeyboardInterrupt:\n                # NOTE interrupts aren't recursively handled.\n                self.arm.write('STOP')\n                res = self.arm.read()\n            if self.wrapper:\n                res = self.wrapper.wrap_output(res)\n            print(res)\n        else:\n            print(self.style.error('Error: ', 'Arm is not connected.'))", "response": "This method is used to set the default command for a specific class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_names(self):\n        ''' Get names for autocompletion. '''\n        # Overridden to support autocompletion for the ROBOFORTH commands.\n        return (['do_' + x for x in self.commands['shell']]\n              + ['do_' + x for x in self.commands['forth']])", "response": "Get names for autocompletion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the list of commands and descriptions from a file.", "response": "def parse_help_text(self, file_path):\n        ''' Load of list of commands and descriptions from a file. '''\n        with open(file_path) as f:\n            lines = f.readlines()\n\n        # Parse commands and descriptions, which are separated by a multi-space\n        # (any sequence of two or more space characters in a row.\n        cmds = []\n        descs = []\n        for line in lines:\n            line = line.strip()\n            if len(line) == 0:\n                cmds.append('')\n                descs.append('')\n            else:\n                tokens = line.split('  ')\n                cmds.append(tokens[0])\n                descs.append(''.join(tokens[1:]).strip())\n\n        max_len = len(max(cmds, key=len))\n\n        # Convert commands and descriptions into help text.\n        text = ''\n        for cmd, desc in zip(cmds, descs):\n            if len(cmd) == 0:\n                text += '\\n'\n            else:\n                text += self.style.help(cmd.ljust(max_len + 2), desc + '\\n')\n\n        return cmds, text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads completion list for ROBOFORTH commands.", "response": "def load_forth_commands(self, help_dir):\n        ''' Load completion list for ROBOFORTH commands. '''\n        try:\n            help_file_path = os.path.join(help_dir, 'roboforth.txt')\n            commands, help_text = self.parse_help_text(help_file_path)\n        except IOError:\n            print(self.style.warn('Warning: ',\n                                  'Failed to load ROBOFORTH help.'))\n            return\n        self.commands['forth'] = commands\n        self.help['forth'] = '\\n'.join([self.style.theme('Forth Commands'),\n                                        help_text])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting before the command loop starts.", "response": "def preloop(self):\n        ''' Executed before the command loop starts. '''\n        script_dir = os.path.dirname(os.path.realpath(__file__))\n        help_dir = os.path.join(script_dir, HELP_DIR_NAME)\n        self.load_forth_commands(help_dir)\n        self.load_shell_commands(help_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate mathmatical expressions. Syntax: {command} <expression>", "response": "def cmd(send, msg, args):\n    \"\"\"Evaluates mathmatical expressions.\n\n    Syntax: {command} <expression>\n\n    \"\"\"\n    if not msg:\n        send(\"Calculate what?\")\n        return\n    cursor = args['db']\n    scores = get_scores(cursor)\n    for word in msg.split():\n        if word in scores:\n            msg = msg.replace(word, str(scores[word]))\n    msg += '\\n'\n    proc = subprocess.Popen(['bc', '-l'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    try:\n        output = proc.communicate(msg.encode(), timeout=5)[0].decode().splitlines()\n    except subprocess.TimeoutExpired:\n        proc.terminate()\n        send(\"Execution took too long, you might have better luck with WolframAlpha.\")\n        return\n    if len(output) > 3:\n        send(\"Your output is too long, have you tried mental math?\")\n    else:\n        for line in output:\n            send(line)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate page content for the legislative office.", "response": "def bootstrap_legislative_office(self, election):\n        \"\"\"\n        For legislative offices, create page content for the legislative\n        Body the Office belongs to AND the state-level Division.\n\n        E.g., for a Texas U.S. Senate seat, create page content for:\n            - U.S. Senate page\n            - Texas state page\n        \"\"\"\n        body = election.race.office.body\n        body_division = election.race.office.body.jurisdiction.division\n        office_division = election.race.office.division\n\n        self.bootstrap_federal_body_type_page(election)\n        self.bootstrap_state_body_type_page(election)\n\n        PageContent.objects.get_or_create(\n            content_type=ContentType.objects.get_for_model(body),\n            object_id=body.pk,\n            election_day=election.election_day,\n            division=body_division,\n        )\n        # Senate seats\n        if office_division.level.name == DivisionLevel.STATE:\n            PageContent.objects.get_or_create(\n                content_type=ContentType.objects.get_for_model(\n                    office_division\n                ),\n                object_id=office_division.pk,\n                election_day=election.election_day,\n                special_election=False,\n            )\n        # House seats\n        elif office_division.level.name == DivisionLevel.DISTRICT:\n            PageContent.objects.get_or_create(\n                content_type=ContentType.objects.get_for_model(\n                    office_division.parent\n                ),\n                object_id=office_division.parent.pk,\n                election_day=election.election_day,\n                special_election=False,\n            )\n        # Generic state pages, type and content\n        page_type, created = PageType.objects.get_or_create(\n            model_type=ContentType.objects.get(\n                app_label=\"geography\", model=\"division\"\n            ),\n            election_day=election.election_day,\n            division_level=DivisionLevel.objects.get(name=DivisionLevel.STATE),\n        )\n        PageContent.objects.get_or_create(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election.election_day,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, to, subject=None, body=None, reply_to=None, template=None, **kwargs):\n        sender = self.config.get(\"MAIL_SENDER\")\n        recipients = [to] if not isinstance(to, list) else to\n        kwargs.update({\n            \"subject\": subject,\n            \"body\": body,\n            \"reply_to\": reply_to\n        })\n\n        if not self.validated:\n            abort(\"MailmanConfigurationError\")\n\n        if self.provider == \"SES\":\n            kwargs[\"to\"] = recipients\n            if template:\n                self.mail.send_template(template=template, **kwargs)\n            else:\n               self.mail.send(**kwargs)\n\n        elif self.provider == \"SMTP\":\n            if template:\n                data = self._template(template=template, **kwargs)\n                kwargs[\"subject\"] = data[\"subject\"]\n                kwargs[\"body\"] = data[\"body\"]\n            kwargs[\"recipients\"] = recipients\n            kwargs[\"sender\"] = sender\n\n            # Remove invalid Messages keys\n            _safe_keys = [\"recipients\", \"subject\", \"body\", \"html\", \"alts\",\n                          \"cc\", \"bcc\", \"attachments\", \"reply_to\", \"sender\",\n                           \"date\", \"charset\", \"extra_headers\", \"mail_options\",\n                           \"rcpt_options\"]\n            for k in kwargs.copy():\n                if k not in _safe_keys:\n                    del kwargs[k]\n\n            message = flask_mail.Message(**kwargs)\n            self.mail.send(message)\n\n        else:\n            abort(\"MailmanUnknownProviderError\")", "response": "Send an email to the specified recipients list or string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a random world sets terrain and runs agents in it", "response": "def main():\n    \"\"\"\n    generates a random world, sets terrain and runs agents in it\n     TODO - need to change pieces in multiple places (see worlds.py, cls_grid, world_generator)\n     (takes about 5 minutes to make 500x400 grid with 8% blockages)\n    \"\"\"\n    width       =  20   # grid width \n    height      =  10   # grid height\n    iterations  =  20   # how many simulations to run\n    num_agents  =   6   # number of agents to enter the world\n    \n    w = build_world(height, width)\n    print(w)\n    a = create_random_agents(w, num_agents)\n    sim = my_world.WorldSimulation(w, a, 1)\n    sim.run(iterations, 'Y', log_folder + os.sep + 'agt_run')\n    sim.world.grd.save('test_world_traversed.txt')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd(send, msg, args):\n    latest = get_latest()\n    if not msg:\n        msg = randrange(1, latest)\n    elif msg == 'latest':\n        msg = latest\n    elif msg.isdigit():\n        msg = int(msg)\n        if msg > latest or msg < 1:\n            send(\"Number out of range\")\n            return\n    else:\n        send(do_search(msg, args['config']['api']['googleapikey'], args['config']['api']['xkcdsearchid']))\n        return\n    url = 'http://xkcd.com/%d/info.0.json' % msg if msg != 'latest' else 'http://xkcd.com/info.0.json'\n    data = get(url).json()\n    output = \"%s -- http://xkcd.com/%d\" % (data['safe_title'], data['num'])\n    send(output)", "response": "Gets a xkcd comic.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_config_parser(config, include_all=False):\n\n    # The allow_no_value allows us to output commented lines.\n    config_parser = SafeConfigParser(allow_no_value=True)\n    for section_name, option_name in _get_included_schema_sections_options(config, include_all):\n\n        if not config_parser.has_section(section_name):\n            config_parser.add_section(section_name)\n\n        option = config[section_name][option_name]\n\n        if option.get('required'):\n            config_parser.set(section_name, '# REQUIRED')\n\n        config_parser.set(section_name, '# ' + option.get('description', 'No description provided.'))\n\n        if option.get('deprecated'):\n            config_parser.set(section_name, '# DEPRECATED')\n\n        option_value = _get_value(option)\n        config_parser.set(section_name, option_name, option_value)\n\n        config_parser.set(section_name, '')\n\n    return config_parser", "response": "Generates a config parser from a configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_documentation(schema):\n\n    documentation_title = \"Configuration documentation\"\n    documentation = documentation_title + \"\\n\"\n    documentation += \"=\" * len(documentation_title) + '\\n'\n\n    for section_name in schema:\n        section_created = False\n\n        for option_name in schema[section_name]:\n\n            option = schema[section_name][option_name]\n\n            if not section_created:\n                documentation += '\\n'\n                documentation += section_name + '\\n'\n                documentation += '-' * len(section_name) + '\\n'\n                section_created = True\n\n            documentation += '\\n'\n            documentation += option_name + '\\n'\n            documentation += '~' * len(option_name) + '\\n'\n\n            if option.get('required'):\n\n                documentation += \"** This option is required! **\\n\"\n\n            if option.get('type'):\n\n                documentation += '*Type : %s.*\\n' % option.get('type')\n\n            if option.get('description'):\n\n                documentation += option.get('description') + '\\n'\n\n            if option.get('default'):\n\n                documentation += 'The default value is %s.\\n' % option.get('default')\n\n            if option.get('deprecated'):\n\n                documentation += \"** This option is deprecated! **\\n\"\n\n    return documentation", "response": "Generates the reStructuredText documentation from a Confirm file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the values of the existing config to the schema.", "response": "def append_existing_values(schema, config):\n    \"\"\"\n    Adds the values of the existing config to the config dictionary.\n    \"\"\"\n\n    for section_name in config:\n        for option_name in config[section_name]:\n            option_value = config[section_name][option_name]\n\n            # Note that we must preserve existing values, wether or not they\n            # exist in the schema file!\n            schema.setdefault(section_name, {}).setdefault(option_name, {})['value'] = option_value\n\n    return schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a basic confirm schema file from a configuration file.", "response": "def generate_schema_file(config_file):\n    \"\"\"\n    Generates a basic confirm schema file from a configuration file.\n    \"\"\"\n\n    config = utils.load_config_from_ini_file(config_file)\n    schema = {}\n\n    for section_name in config:\n        for option_name in config[section_name]:\n            schema.setdefault(section_name, {}).setdefault(option_name, {})\n            schema[section_name][option_name]['description'] = 'No description provided.'\n\n    return utils.dump_schema_file(schema)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rankwithlist(l,lwith,test=False):\n    if not (isinstance(l,list) and isinstance(lwith,list)):\n        l,lwith=list(l),list(lwith)\n    from scipy.stats import rankdata\n    if test:\n        print(l,lwith)\n        print(rankdata(l),rankdata(lwith))\n        print(rankdata(l+lwith))\n    return rankdata(l+lwith)[:len(l)]", "response": "rank l wrt lwith"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_admin_user_publisher():\n\n    # ==== Setup User Admin === #\n\n    admin_email = conf.APPLICATION_ADMIN_EMAIL\n    if not admin_email:\n        print(\"ERROR: APPLICATION_ADMIN_EMAIL is empty\")\n        exit()\n\n    password = utils.generate_random_string()\n    if user.setup(model.User,\n                  admin_email=admin_email,\n                  password=password):\n\n        if mail.validated:\n            body = \"Admin Password: %s\" % password\n            mail.send(to=admin_email, subject=\"Admin Password\", body=body)\n\n        print(\"---- Setup SUPER ADMIN User ----\")\n        print(\"- Admin Email: %s\" % admin_email)\n        print(\"- Admin Password: %s\" % password)\n        print(\"-\" * 40)\n        print(\"\")\n\n    # ==== Setup Publisher === #\n\n    # admin user\n    admin_user = model.User.User.get_by_email(admin_email)\n\n    # Set default categories and post types\n    post_categories = [\"Uncategorized\"]\n    post_types = [\"Page\", \"Blog\", \"Document\", \"Other\"]\n\n    if admin_user and admin_user.role.name.lower() == \"superadmin\":\n        print(\"---- Setup PUBLISHER ----\")\n        if publisher.setup(model.Publisher,\n                           admin_user_id=admin_user.id,\n                           post_types=post_types,\n                           post_categories=post_categories):\n            print(\"Completed\")\n        print(\"-\" * 40)\n        print(\"\")", "response": "Setup Juice User and Publisher Admin\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_kind(self, kindlike):\n        if kindlike is None:\n            return (object,)\n        elif isinstance(kindlike, type):\n            return (kindlike,)\n        else:\n            return tuple(kindlike)", "response": "Make a kind out of a possible shorthand."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a string describing a kind.", "response": "def str_kind(self, kind):\n        \"\"\"Get a string describing a kind.\"\"\"\n        if len(kind) == 0:\n            return 'Nothing'\n        elif len(kind) == 1:\n            return kind[0].__name__\n        elif len(kind) == 2:\n            return kind[0].__name__ + ' or ' + kind[1].__name__\n        else:\n            return 'one of {' + ', '.join(t.__name__ for t in kind) + '}'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises TypeError if val does not satisfy kind.", "response": "def checktype(self, val, kind, **kargs):\n        \"\"\"Raise TypeError if val does not satisfy kind.\"\"\"\n        if not isinstance(val, kind):\n            raise TypeError('Expected {}; got {}'.format(\n                            self.str_kind(kind), self.str_valtype(val)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checktype_seq(self, seq, kind, *, unique=False, **kargs):\n        exp = self.str_kind(kind)\n        \n        # Make sure we have a sequence.\n        try:\n            iterator = iter(seq)\n            # Generators aren't sequences. This avoids a confusing bug\n            # where we consume a generator by type-checking it, and leave\n            # only an exhausted iterator for the user code.\n            len(seq)\n        except TypeError:\n            got = self.str_valtype(seq)\n            raise TypeError('Expected sequence of {}; '\n                            'got {} instead of sequence'.format(exp, got))\n        \n        if isinstance(seq, str):\n            raise TypeError('Expected sequence of {}; got single str '\n                            '(strings do not count as character '\n                            'sequences)'.format(exp))\n        \n        for i, item in enumerate(iterator):\n            # Depend on checktype() to check individual elements,\n            # but generate an error message that includes the position\n            # of the failure.\n            try:\n                self.checktype(item, kind, **kargs)\n            except TypeError:\n                got = self.str_valtype(item)\n                raise TypeError('Expected sequence of {}; '\n                                'got sequence with {} at position {}'.format(\n                                exp, got, i)) from None\n        \n        if unique:\n            seen = []\n            for i, item in enumerate(seq):\n                if item in seen:\n                    raise TypeError('Duplicate element {} at '\n                                    'position {}'.format(repr(item), i))\n                seen.append(item)", "response": "Raise TypeError if seq is not a sequence of elements satisfying the given kind."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raises(cls, sender, attrname, error, args=ANYTHING, kwargs=ANYTHING):\n        \"An alternative constructor which raises the given error\"\n        def raise_error():\n            raise error\n        return cls(sender, attrname, returns=Invoke(raise_error), args=ANYTHING, kwargs=ANYTHING)", "response": "An alternative constructor which raises the given error"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexpect an error or more to be raised from the given expectation.", "response": "def and_raises(self, *errors):\n        \"Expects an error or more to be raised from the given expectation.\"\n        for error in errors:\n            self.__expect(Expectation.raises, error)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef and_calls(self, *funcs):\n        for fn in funcs:\n            self.__expect(Expectation, Invoke(fn))", "response": "Expects the return value from one or more functions to be raised\n            from the given expectation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpects the return value of the expectation to be a generator of the given values", "response": "def and_yields(self, *values):\n        \"\"\"Expects the return value of the expectation to be a generator of the\n        given values\n        \"\"\"\n        def generator():\n            for value in values:\n                yield value\n        self.__expect(Expectation, Invoke(generator))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the creation of ExpectationBuilder when an attribute is invoked.", "response": "def attribute_invoked(self, sender, name, args, kwargs):\n        \"Handles the creation of ExpectationBuilder when an attribute is invoked.\"\n        return ExpectationBuilder(self.sender, self.delegate, self.add_invocation, self.add_expectations, '__call__')(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the creation of ExpectationBuilder when an attribute is read.", "response": "def attribute_read(self, sender, name):\n        \"Handles the creation of ExpectationBuilder when an attribute is read.\"\n        return ExpectationBuilder(self.sender, self.delegate, self.add_invocation, self.add_expectations, name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the creation of ExpectationBuilder when a dictionary item access.", "response": "def key_read(self, sender, name):\n        \"Handles the creation of ExpectationBuilder when a dictionary item access.\"\n        return ExpectationBuilder(self.sender, self.delegate, self.add_invocation, self.add_expectations, '__getitem__')(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef friendly_load(parser, token):\n    bits = token.contents.split()\n    if len(bits) >= 4 and bits[-2] == \"from\":\n        # from syntax is used; load individual tags from the library\n        name = bits[-1]\n        try:\n            lib = find_library(parser, name)\n            subset = load_from_library(lib, name, bits[1:-2])\n            parser.add_library(subset)\n        except TemplateSyntaxError:\n            pass\n    else:\n        # one or more libraries are specified; load and add them to the parser\n        for name in bits[1:]:\n            try:\n                lib = find_library(parser, name)\n                parser.add_library(lib)\n            except TemplateSyntaxError:\n                pass\n    return LoadNode()", "response": "A friendly load of a custom template tag set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_if_has_tag(parser, token, negate=False):\n    bits = list(token.split_contents())\n    if len(bits) < 2:\n        raise TemplateSyntaxError(\"%r takes at least one arguments\" % bits[0])\n    end_tag = 'end%s' % bits[0]\n    has_tag = all([tag in parser.tags for tag in bits[1:]])\n    has_tag = (not negate and has_tag) or (negate and not has_tag)\n    nodelist_true = nodelist_false = CommentNode()\n    if has_tag:\n        nodelist_true = parser.parse(('else', end_tag))\n        token = parser.next_token()\n        if token.contents == 'else':\n            parser.skip_past(end_tag)\n    else:\n        while parser.tokens:\n            token = parser.next_token()\n            if token.token_type == TOKEN_BLOCK and token.contents == end_tag:\n                return IfNode([\n                    (Literal(has_tag), nodelist_true),\n                    (None, nodelist_false)\n                ])\n            elif token.token_type == TOKEN_BLOCK and token.contents == 'else':\n                break\n        nodelist_false = parser.parse((end_tag,))\n        parser.next_token()\n    return IfNode([(Literal(has_tag), nodelist_true),\n                   (None, nodelist_false)])", "response": "Checks if all the given tags exist and if not exists returns a new branch that is not error due to existing tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify that the list of agents passed to the simulator are unique", "response": "def _verify_agents(self):\n        \"\"\"\n        verify agents passed to simulator by:\n        1. checking for unique names\n        2. TODO - other checks if needed\n        \"\"\"\n        #print('verifying...')\n        nmes = []\n        for agt_num, a in enumerate(self.agents):\n            #print('agent#', agt_num, 'is type', type(a))\n            nmes.append(a.name)\n        if len(nmes) == len(set(nmes)):\n            return True\n        print('Error - you need to pass unique list of agent names to simulator')\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command(self, cmd, agent, src='admin', password=''):\n        print(src, 'says ' + cmd['type']  + ' agent', agent.name, '', cmd['direction'],' password=', password)\n        if cmd['type'] == 'move':\n            self._move_agent(agent, cmd['direction'], False)\n        elif cmd['type'] == 'run':\n            print(agent.name, 'runs in direction', cmd['direction'])\n        elif cmd['type'] == 'fight':\n            print(agent.name, 'fights')", "response": "Execute a command on an agent"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _move_agent(self, agent, direction, wrap_allowed=True):\n        x,y = agent.coords['x'], agent.coords['y']\n        print('moving agent ', agent.name, 'to x,y=', direction, 'wrap_allowed = ', wrap_allowed)\n        agent.coords['x'] = x + direction[0]\n        agent.coords['y'] = y + direction[1]", "response": "move agent in direction"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('stations', nargs='*')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if not cmdargs.stations:\n        send(\"What station?\")\n        return\n    if isinstance(cmdargs.stations, list):\n        cmdargs.stations = ','.join(cmdargs.stations)\n    req = get('http://aviationweather.gov/adds/dataserver_current/httpparam',\n              params={\n                  'datasource': 'metars',\n                  'requestType': 'retrieve',\n                  'format': 'xml',\n                  'mostRecentForEachStation': 'constraint',\n                  'hoursBeforeNow': '1.25',\n                  'stationString': cmdargs.stations\n              })\n    xml = ElementTree.fromstring(req.text)\n    errors = xml.find('./errors')\n    if len(errors):\n        errstring = ','.join([error.text for error in errors])\n        send('Error: %s' % errstring)\n        return\n    data = xml.find('./data')\n    if data is None or data.attrib['num_results'] == '0':\n        send('No results found.')\n    else:\n        for station in data:\n            send(station.find('raw_text').text)", "response": "Gets the weather.\n\n    Syntax: {command} <station> [station2...]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an attribute function that returns the value of the attribute with given names in order and the object that has been passed to it.", "response": "def attr_func(*attrs, **kwargs):\n    \"\"\"Creates an \"attribute function\" for given attribute name(s).\n\n    Resulting function will retrieve attributes with given names, in order,\n    from the object that has been passed to it.\n    For example, ``attr_func('a', 'b')(foo)`` yields the same as ``foo.a.b``\n\n    :param attrs: Attribute names\n    :param default: Optional keyword argument specifying default value\n                    that will be returned when some attribute is not present\n\n    :return: Unary attribute function\n    \"\"\"\n    ensure_argcount(attrs, min_=1)\n    ensure_keyword_args(kwargs, optional=('default',))\n\n    # preprocess argument list:\n    # * allow dots in arguments, interpreting them as multiple attributes,\n    #   e.g. ``attr_func('a.b')`` as ``attr_func('a', 'b')``\n    # * make sure the attribute names are valid Python identifiers\n    attrs = map(ensure_string, attrs)\n    attrs = flatten(attr.split('.') if '.' in attr else [attr]\n                    for attr in attrs)\n    for attr in attrs:\n        if not is_identifier(attr):\n            raise ValueError(\"'%s' is not a valid attribute name\", attr)\n\n    if 'default' in kwargs:\n        default = kwargs['default']\n        if len(attrs) == 1:\n            getattrs = lambda obj: getattr(obj, attrs[0], default)\n        else:\n            def getattrs(obj):\n                for attr in attrs:\n                    try:\n                        obj = getattr(obj, attr)\n                    except AttributeError:\n                        return default\n                return obj\n    else:\n        if len(attrs) == 1:\n            getattrs = operator.attrgetter(attrs[0])\n        else:\n            def getattrs(obj):\n                for attr in attrs:\n                    obj = getattr(obj, attr)\n                return obj\n\n    return getattrs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a key function based on given keys.", "response": "def key_func(*keys, **kwargs):\n    \"\"\"Creates a \"key function\" based on given keys.\n\n    Resulting function will perform lookup using specified keys, in order,\n    on the object passed to it as an argument.\n    For example, ``key_func('a', 'b')(foo)`` is equivalent to ``foo['a']['b']``.\n\n    :param keys: Lookup keys\n    :param default: Optional keyword argument specifying default value\n                    that will be returned when some lookup key is not present\n\n    :return: Unary key function\n    \"\"\"\n    ensure_argcount(keys, min_=1)\n    ensure_keyword_args(kwargs, optional=('default',))\n\n    keys = list(map(ensure_string, keys))\n\n    if 'default' in kwargs:\n        default = kwargs['default']\n        def getitems(obj):\n            for key in keys:\n                try:\n                    obj = obj[key]\n                except KeyError:\n                    return default\n            return obj\n    else:\n        if len(keys) == 1:\n            getitems = operator.itemgetter(keys[0])\n        else:\n            def getitems(obj):\n                for key in keys:\n                    obj = obj[key]\n                return obj\n\n    return getitems"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dotcall(name, *args, **kwargs):\n    ensure_string(name)\n\n    get_member_func = attr_func(name)\n\n    def call(obj):\n        member_func = ensure_callable(get_member_func(obj))\n        return member_func(*args, **kwargs)\n\n    # through :func:`attr_func`, we may support ``name`` containing dots,\n    # but we need to turn it into valid Python identifier for function's name\n    call.__name__ = name.replace('.', '__')\n\n    return call", "response": "Creates a function that accepts an object and invokes a member functionon it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_files(path, patterns):\n    if not isinstance(patterns, (list, tuple)):\n        patterns = [patterns]\n\n    matches = []\n    for root, dirnames, filenames in os.walk(path):\n        for pattern in patterns:\n            for filename in fnmatch.filter(filenames, pattern):\n                matches.append(os.path.join(root, filename))\n    return matches", "response": "Returns all files from a given path that matches the pattern or list\n    of patterns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recursive_update(_dict, _update):\n    for k, v in _update.items():\n        if isinstance(v, collections.Mapping):\n            r = recursive_update(_dict.get(k, {}), v)\n            _dict[k] = r\n        else:\n            _dict[k] = _update[k]\n    return _dict", "response": "Same as dict. update but updates also nested dicts instead of\n    overriding then\n\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lower_items(self):\n        return (\n            (lowerkey, keyval[1])\n            for (lowerkey, keyval)\n            in list(self._store.items())\n        )", "response": "Like iteritems but with all lowercase keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattempting a forward lookup via the socket library and if it fails it will try to do a reverse lookup via the socket library and if it fails it will return False otherwise it will return True", "response": "def validate(self, value):\n        \"\"\"Attempts a forward lookup via the socket library and if\n           successful will try to do a reverse lookup to verify DNS\n           is returning both lookups.\n           \"\"\"\n        if '.' not in value:\n            self.error_message = '%s is not a fully qualified domain name.' % \\\n                                 value\n            return False\n        try:\n            ipaddress = socket.gethostbyname(value)\n        except socket.gaierror:\n            self.error_message = '%s does not resolve.' % value\n            return False\n        try:\n            socket.gethostbyaddr(ipaddress)\n        except socket.herror:\n            self.error_message = \\\n                '%s reverse address (%s) does not resolve.' % \\\n                (value, ipaddress)\n            return False\n        self._choice = value\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self, value):\n        try:\n            self._choice = IPAddress(value)\n            return True\n        except (ValueError, AddrFormatError):\n            self.error_message = '%s is not a valid IP address.' % value\n            return False", "response": "Return a boolean indicating if the value is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, value):\n        try:\n            self._choice = IPAddress(value)\n        except (ValueError, AddrFormatError):\n            self.error_message = '%s is not a valid IP address.' % value\n            return False\n        if self._choice.is_netmask():\n            return True\n        else:\n            self.error_message = '%s is not a valid IP netmask.' % value\n            return False", "response": "Return a boolean if the value is a valid netmask."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self, value):\n        '''Return a boolean indicating if the value is a valid URI'''\n        if self.blank and value == '':\n            return True\n        if URIValidator.uri_regex.match(value):\n            self._choice = value\n            return True\n        else:\n            self.error_message = '%s is not a valid URI' % value\n            return False", "response": "Return a boolean indicating if the value is a valid URI"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a boolean if the choice is a number in the enumeration", "response": "def validate(self, value):\n        \"\"\"Return a boolean if the choice is a number in the enumeration\"\"\"\n        if value in list(self.choices.keys()):\n            self._choice = value\n            return True\n        try:\n            self._choice = list(self.choices.keys())[int(value)]\n            return True\n        except (ValueError, IndexError):\n            self.error_message = '%s is not a valid choice.' % value\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the choice of the cateate entry.", "response": "def validate(self, value):\n        \"\"\"\n        Return True if the choice is an integer; False otherwise.\n\n        If the value was cast successfully to an int, set the choice that will\n        make its way into the answers dict to the cast int value, not the\n        string representation.\n        \"\"\"\n        try:\n            int_value = int(value)\n            self._choice = int_value\n            return True\n        except ValueError:\n            self.error_message = '%s is not a valid integer.' % value\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a virtual internet sets pages runs web_users on it", "response": "def main():\n    \"\"\"\n    generates a virtual internet, sets pages and runs web_users on it\n    \"\"\"\n    e = mod_env.Internet('VAIS - Load testing',  'Simulation of several websites')\n    e.create(800)\n    print(e)\n    \n    #Create some users to browse the web and load test website\n    print(npc.web_users.params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_project(project_name, skel=\"basic\"):\n    project_dir = get_project_dir_path(project_name)\n    app_tpl = pkg_resources.resource_string(__name__, '%s/app.py' % (SKELETON_DIR))\n    propel_tpl = pkg_resources.resource_string(__name__, '%s/propel.yml' % (SKELETON_DIR))\n    config_tpl = pkg_resources.resource_string(__name__, '%s/config.py' % (SKELETON_DIR))\n    model_tpl = pkg_resources.resource_string(__name__, '%s/model.py' % (SKELETON_DIR))\n    manage_tpl = pkg_resources.resource_string(__name__, '%s/juicy.py' % (SKELETON_DIR))\n\n    app_file = \"%s/app_%s.py\" % (CWD, project_name)\n    requirements_txt = \"%s/requirements.txt\" % CWD\n    propel_yml = \"%s/propel.yml\" % CWD\n    config_py = \"%s/config.py\" % APPLICATION_DIR\n    model_py = \"%s/model.py\" % APPLICATION_DIR\n    manage_py = \"%s/juicy.py\" % CWD\n\n    dirs = [\n        APPLICATION_DIR,\n        APPLICATION_DATA_DIR,\n        project_dir\n    ]\n    for d in dirs:\n        if not os.path.isdir(d):\n            os.makedirs(d)\n\n    files = [\n        (\"%s/__init__.py\" % APPLICATION_DIR, \"# Juice\"),\n        (config_py, config_tpl),\n        (model_py, model_tpl),\n        (app_file, app_tpl.format(project_name=project_name)),\n        (requirements_txt, \"%s==%s\" % (__title__, __version__)),\n        (propel_yml, propel_tpl.format(project_name=project_name)),\n        (manage_py, manage_tpl)\n    ]\n    for f in files:\n        if not os.path.isfile(f[0]):\n            with open(f[0], \"wb\") as f0:\n                f0.write(f[1])\n\n    copy_resource(\"%s/skel/%s/\" % (SKELETON_DIR, skel), project_dir)\n    copy_resource(\"%s/%s/\" % (SKELETON_DIR, \"_data\"), APPLICATION_DATA_DIR)", "response": "Create a new project"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the remote hosts in a non - remote container", "response": "def get_deploy_hosts_list(cwd, key=None, file=\"propel.yml\"):\n    \"\"\"\n    Returns the remote hosts in propel\n    :param cwd:\n    :param key:\n    :param file:\n    :return: list\n    \"\"\"\n    config = propel_deploy_config(cwd=cwd, file=file)[\"hosts\"]\n    return config[key] if key else [v for k, l in config.items() for v in l]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_deploy_assets2s3_list(cwd, file=\"propel.yml\"):\n    conf = propel_deploy_config(cwd=cwd, file=file)\n    return conf[\"assets2s3\"] if \"assets2s3\" in conf else []", "response": "Get the list of all the assets2s3 repo to publish when deploying\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef git_push_to_master(cwd, hosts, name=\"all\"):\n    with sh.pushd(cwd):\n        name = \"juicy_deploy_%s\" % name\n\n        if sh.git(\"status\", \"--porcelain\").strip():\n            raise Exception(\"Repository is UNCLEAN. Commit your changes\")\n\n        remote_list = sh.git(\"remote\").strip().split()\n        if name in remote_list:\n            sh.git(\"remote\", \"remove\", name)\n        sh.git(\"remote\", \"add\", name, hosts[0])\n        if len(hosts) > 1:\n            for h in hosts:\n                sh.git(\"remote\", \"set-url\", name, \"--push\", \"--add\", h)\n            sh.git(\"push\", name, \"master\")\n            sh.git(\"remote\", \"remove\", name)", "response": "Pushes the current node to master"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new project in the current directory", "response": "def create(project, skel):\n    \"\"\"  Create a new Project in the current directory \"\"\"\n\n    app = project_name(project)\n\n    header(\"Create New Project ...\")\n    print(\"- Project: %s \" % app)\n\n    create_project(app, skel)\n    print(\"\")\n    print(\"----- That's Juicy! ----\")\n    print(\"\")\n    print(\"- Your new project [ %s ] has been created\" % app)\n    print(\"- Location: [ application/%s ]\" % app)\n    print(\"\")\n    print(\"> What's next?\")\n    print(\"- Edit the config [ application/config.py ] \")\n    print(\"- If necessary edit and run the command [ juicy setup ]\")\n    print(\"- Launch app on devlopment mode, run [ juicy serve %s ]\" % app)\n    print(\"\")\n    print(\"*\" * 80)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserves application in development mode", "response": "def serve(project, port, no_watch):\n    \"\"\" Serve application in development mode \"\"\"\n\n    header(\"Serving application in development mode ... \")\n    print(\"- Project: %s \" % project)\n    print(\"\")\n    print(\"- Port: %s\" % port)\n    print(\"\")\n\n    module = import_module(project, True)\n\n    extra_files = []\n    if not no_watch:\n        extra_dirs = [CWD,]\n        extra_files = extra_dirs[:]\n        for extra_dir in extra_dirs:\n            for dirname, dirs, files in os.walk(extra_dir):\n                for filename in files:\n                    filename = os.path.join(dirname, filename)\n                    if os.path.isfile(filename):\n                        extra_files.append(filename)\n\n    module.app.run(debug=True,\n                   host='0.0.0.0',\n                   port=port,\n                   extra_files=extra_files)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy(remote, assets_to_s3):\n\n    header(\"Deploying...\")\n\n    if assets_to_s3:\n        for mod in get_deploy_assets2s3_list(CWD):\n            _assets2s3(mod)\n\n    remote_name = remote or \"ALL\"\n    print(\"Pushing application's content to remote: %s \" % remote_name)\n    hosts = get_deploy_hosts_list(CWD, remote or None)\n    git_push_to_master(cwd=CWD, hosts=hosts, name=remote_name)\n    print(\"Done!\")", "response": "Deploy the application to the remote"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd():\n    if os.path.isfile(os.path.join(os.path.join(CWD, \"juicy.py\"))):\n        import_module(\"juicy\")\n    else:\n        print(\"ERROR: Missing <<'juicy.py'>> @ %s\" % CWD)\n\n    cli()", "response": "Help to run the command line\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquieting a user then unquiets them after the specified period of time.", "response": "def cmd(send, msg, args):\n    \"\"\"Quiets a user, then unquiets them after the specified period of time.\n\n    Syntax: {command} <timespec> <nickname>\n    timespec is in the format: <number><unit>, where unit is s, m, h, or d.\n\n    \"\"\"\n    nickregex = args['config']['core']['nickregex']\n    setmode = args['handler'].connection.mode\n    channel = args['target']\n    with args['handler'].data_lock:\n        ops = args['handler'].opers[channel].copy()\n    if args['botnick'] not in ops:\n        send(\"Bot must be an op.\")\n        return\n    time, user = msg.split(maxsplit=1)\n    if user == args['botnick']:\n        send(\"I won't put myself in timeout!\")\n        return\n    if not re.match(nickregex, user):\n        send(\"%s is an invalid nick.\" % user)\n        return\n\n    time = parse_time(time)\n    if time is None:\n        send(\"Invalid unit.\")\n    else:\n        if args['config']['feature']['networktype'] == 'unrealircd':\n            setmode(channel, \" +b ~q:%s!*@*\" % user)\n            defer_args = [channel, \" -b ~q:%s!*@*\" % user]\n        elif args['config']['feature']['networktype'] == 'atheme':\n            setmode(channel, \" +q-v %s!*@* %s\" % (user, user))\n            defer_args = [channel, \" -q %s!*@*\" % user]\n        else:\n            raise Exception(\"networktype undefined or unknown in config.cfg\")\n        ident = args['handler'].workers.defer(time, True, setmode, *defer_args)\n        send(\"%s has been put in timeout, ident: %d\" % (user, ident))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the configuration data if required.", "response": "async def _update_config(self):\n        \"\"\"Update configuration data if required.\n\n        Notes:\n          Per `the documentation`_, this updates the API configuration\n          data *\"every few days\"*.\n\n        .. _the documentation:\n          http://docs.themoviedb.apiary.io/#reference/configuration\n\n        \"\"\"\n        if self.config['data'] is None or self.config_expired:\n            data = await self.get_data(self.url_builder('configuration'))\n            self.config = dict(data=data, last_update=datetime.now())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_data(self, url):\n        logger.debug('making request to %r', url)\n        with aiohttp.ClientSession() as session:\n            async with session.get(url, headers=self.headers) as response:\n                body = json.loads((await response.read()).decode('utf-8'))\n                if response.status == HTTPStatus.OK:\n                    if url != self.url_builder('configuration'):\n                        await self._update_config()\n                    return body\n                elif response.status == HTTPStatus.TOO_MANY_REQUESTS:\n                    timeout = self.calculate_timeout(\n                        response.headers['Retry-After'],\n                    )\n                    logger.warning(\n                        'Request limit exceeded, waiting %s seconds',\n                        timeout,\n                    )\n                    await asyncio.sleep(timeout)\n                    return await self.get_data(url)\n                logger.warning(\n                    'request failed %s: %r',\n                    response.status,\n                    body.get('status_message', '<no message>')\n                )", "response": "Get data from the TMDb API via aiohttp. get."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves movie data by search query.", "response": "async def find_movie(self, query):\n        \"\"\"Retrieve movie data by search query.\n\n        Arguments:\n          query (:py:class:`str`): Query to search for.\n\n        Returns:\n          :py:class:`list`: Possible matches.\n\n        \"\"\"\n        params = OrderedDict([\n            ('query', query), ('include_adult', False),\n        ])\n        url = self.url_builder('search/movie', {}, params)\n        data = await self.get_data(url)\n        if data is None:\n            return\n        return [\n            Movie.from_json(item, self.config['data'].get('images'))\n            for item in data.get('results', [])\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def find_person(self, query):\n        url = self.url_builder(\n            'search/person',\n            dict(),\n            url_params=OrderedDict([\n                ('query', query), ('include_adult', False)\n            ]),\n        )\n        data = await self.get_data(url)\n        if data is None:\n            return\n        return [\n            Person.from_json(item, self.config['data'].get('images'))\n            for item in data.get('results', [])\n        ]", "response": "Retrieve person data by search query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve movie by ID.", "response": "async def get_movie(self, id_):\n        \"\"\"Retrieve movie data by ID.\n\n        Arguments:\n          id_ (:py:class:`int`): The movie's TMDb ID.\n\n        Returns:\n          :py:class:`~.Movie`: The requested movie.\n\n        \"\"\"\n        url = self.url_builder(\n            'movie/{movie_id}',\n            dict(movie_id=id_),\n            url_params=OrderedDict(append_to_response='credits'),\n        )\n        data = await self.get_data(url)\n        if data is None:\n            return\n        return Movie.from_json(data, self.config['data'].get('images'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_person(self, id_):\n        data = await self._get_person_json(\n            id_,\n            OrderedDict(append_to_response='movie_credits')\n        )\n        return Person.from_json(data, self.config['data'].get('images'))", "response": "Retrieve a person by ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _get_person_json(self, id_, url_params=None):\n        url = self.url_builder(\n            'person/{person_id}',\n            dict(person_id=id_),\n            url_params=url_params or OrderedDict(),\n        )\n        data = await self.get_data(url)\n        return data", "response": "Retrieve raw person JSON by ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_random_popular_person(self, limit=500):\n        index = random.randrange(limit)\n        data = await self._get_popular_people_page()\n        if data is None:\n            return\n        if index >= len(data['results']):\n            # result is not on first page\n            page, index = self._calculate_page_index(index, data)\n            data = await self._get_popular_people_page(page)\n        if data is None:\n            return\n        json_data = data['results'][index]\n        details = await self._get_person_json(json_data['id'])\n        details.update(**json_data)\n        return Person.from_json(details, self.config['data'].get('images'))", "response": "Randomly select a popular person."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a specific page of popular person data.", "response": "async def _get_popular_people_page(self, page=1):\n        \"\"\"Get a specific page of popular person data.\n\n        Arguments:\n          page (:py:class:`int`, optional): The page to get.\n\n        Returns:\n          :py:class:`dict`: The page data.\n\n        \"\"\"\n        return await self.get_data(self.url_builder(\n            'person/popular',\n            url_params=OrderedDict(page=page),\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the location of a given index in paged data.", "response": "def _calculate_page_index(index, data):\n        \"\"\"Determine the location of a given index in paged data.\n\n        Arguments:\n          index (:py:class:`int`): The overall index.\n          data: (:py:class:`dict`) The first page of data.\n\n        Returns:\n          :py:class:`tuple`: The location of that index, in the format\n            ``(page, index_in_page)``.\n\n        \"\"\"\n        if index > data['total_results']:\n            raise ValueError('index not in paged data')\n        page_length = len(data['results'])\n        return (index // page_length) + 1, (index % page_length) - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts text into NATO form.", "response": "def cmd(send, msg, args):\n    \"\"\"Converts text into NATO form.\n\n    Syntax: {command} <text>\n\n    \"\"\"\n    if not msg:\n        send(\"NATO what?\")\n        return\n    nato = gen_nato(msg)\n    if len(nato) > 100:\n        send(\"Your NATO is too long. Have you considered letters?\")\n    else:\n        send(nato)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntelling the time. Syntax: {command}", "response": "def cmd(send, msg, _):\n    \"\"\"Tells the time.\n\n    Syntax: {command}\n\n    \"\"\"\n    bold = '\\x02'\n    if not msg:\n        msg = bold + \"Date: \" + bold + \"%A, %m/%d/%Y\" + bold + \"   Time: \" + bold + \"%H:%M:%S\"\n    send(time.strftime(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setup_configuration(self):\n        self.configuration = dict(\n            schema_cls=self.schema_cls,\n            allowed_actions=self.allowed_actions,\n            filter_by_fields=self.filter_by_fields)\n\n        authentication = self.authentication_cls(schema_cls=self.schema_cls)\n        authorization = self.authorization_cls()\n        schema_validation = self.schema_validation_cls(\n            schema_cls=self.schema_cls)\n        view_actions = self.view_actions_cls()\n        post_action_hooks = self.post_action_hooks_cls(\n            schema_cls=self.schema_cls)\n        response_converter = self.response_converter_cls(\n            schema_cls=self.schema_cls)\n        serializer = self.serializer_cls(schema_cls=self.schema_cls)\n        data_cleaner = self.data_cleaner_cls(schema_cls=self.schema_cls)\n\n        self.configuration.update(dict(\n            authentication=authentication,\n            authorization=authorization,\n            schema_validation=schema_validation,\n            view_actions=view_actions,\n            post_action_hooks=post_action_hooks,\n            response_converter=response_converter,\n            data_cleaner=data_cleaner,\n            serializer=serializer))", "response": "Setup the configuration for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, request):\n        pipeline = view_pipeline_factory.read_pipeline(\n            configuration=self.configuration)\n        return pipeline(request=request)", "response": "Implements HTTP GET\n        :param request: rip.Request\n        :return: rip.Response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a tuple of a prettyprinted error message and string representation of the error.", "response": "def output_traceback(ex):\n    \"\"\"Returns a tuple of a prettyprinted error message and string representation of the error.\"\"\"\n    # Dump full traceback to console.\n    output = \"\".join(traceback.format_exc()).strip()\n    for line in output.split('\\n'):\n        logging.error(line)\n    trace_obj = traceback.extract_tb(ex.__traceback__)[-1]\n    trace = [basename(trace_obj[0]), trace_obj[1]]\n    name = type(ex).__name__\n    output = str(ex).replace('\\n', ' ')\n    msg = \"%s in %s on line %s: %s\" % (name, trace[0], trace[1], output)\n    return (msg, output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new project", "response": "def new(project_name):\n    \"\"\"Creates a new project\"\"\"\n\n    try:\n        locale.setlocale(locale.LC_ALL, '')\n    except:\n        print(\"Warning: Unable to set locale.  Expect encoding problems.\")\n\n    config = utils.get_config()\n    config['new_project']['project_name'] = project_name\n\n    values = new_project_ui(config)\n    if type(values) is not str:\n        print('New project options:')\n        pprint.pprint(values)\n        project_dir = render.render_project(**values)\n        git.init_repo(project_dir, **values)\n    else:\n        print(values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrelease a new version of the current project.", "response": "def release(no_master, release_type):\n    '''Releases a new version'''\n\n    try:\n        locale.setlocale(locale.LC_ALL, '')\n    except:\n        print(\"Warning: Unable to set locale.  Expect encoding problems.\")\n\n    git.is_repo_clean(master=(not no_master))\n\n    config = utils.get_config()\n    config.update(utils.get_dist_metadata())\n    config['project_dir'] = Path(os.getcwd())\n    config['release_type'] = release_type\n\n    with tempfile.TemporaryDirectory(prefix='ap_tmp') as tmp_dir:\n        config['tmp_dir'] = tmp_dir\n        values = release_ui(config)\n\n        if type(values) is not str:\n            utils.release(project_name=config['project_name'], tmp_dir=tmp_dir,\n                          project_dir=config['project_dir'],\n                          pypi_servers=config['pypi_servers'], **values)\n\n            print('New release options:')\n            pprint.pprint(values)\n        else:\n            print(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure that x y have consistent types and set dtype.", "response": "def _set_types(self):\n        \"\"\"Make sure that x, y have consistent types and set dtype.\"\"\"\n        # If we given something that is not an int or a float we raise\n        # a RuntimeError as we do not want to have to guess if the given\n        # input should be interpreted as an int or a float, for example the\n        # interpretation of the string \"1\" vs the interpretation of the string\n        # \"1.0\".\n        for c in (self.x, self.y):\n            if not ( isinstance(c, int) or isinstance(c, float) ):\n                raise(RuntimeError('x, y coords should be int or float'))\n\n        if isinstance(self.x, int) and isinstance(self.y, int):\n            self._dtype = \"int\"\n        else:\n            # At least one value is a float so promote both to float.\n            self.x = float(self.x)\n            self.y = float(self.y)\n            self._dtype = \"float\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef magnitude(self):\n        return math.sqrt( self.x * self.x + self.y * self.y )", "response": "Return the magnitude when treating the point as a vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the unit vector.", "response": "def unit_vector(self):\n        \"\"\"Return the unit vector.\"\"\"\n        return Point2D( self.x / self.magnitude, self.y / self.magnitude )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a point of the specified dtype.", "response": "def astype(self, dtype):\n        \"\"\"Return a point of the specified dtype.\"\"\"\n        if dtype == \"int\":\n            return Point2D( int( round(self.x, 0) ), int( round(self.y, 0) ) )\n        elif dtype == \"float\":\n            return Point2D( float(self.x), float(self.y))\n        else:\n            raise(RuntimeError(\"Invalid dtype: {}\".format(dtype)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef free(self, local_path):\n    '''\n      Stop synchronization of local_path\n    '''\n        \n    # Process local ~~~\n\n    # 1. Syncthing config\n    config = self.get_config()\n\n    # Check whether folders are still connected to this device \n    folder = st_util.find_folder_with_path(local_path, config)\n    self.delete_folder(local_path, config)\n    pruned = st_util.prune_devices(folder, config)\n        \n    # Done processing st config, commit :)\n    self.set_config(config)\n    \n    if pruned:\n      self.restart()\n\n    # 2. App config\n    dir_config = self.adapter.get_dir_config(local_path)\n\n    if not dir_config:\n      raise custom_errors.FileNotInConfig(local_path)\n\n    kodrive_config = self.adapter.get_config()\n\n    for key in kodrive_config['directories']: \n      d = kodrive_config['directories'][key]\n      if d['local_path'].rstrip('/') == local_path.rstrip('/'):\n        del kodrive_config['directories'][key]\n        break\n    \n    # Done process app config, commit :)\n    self.adapter.set_config(kodrive_config)\n\n    # If the folder was shared, try remove data from remote \n    if dir_config['is_shared'] and dir_config['server']:\n      \n      # Process remote ~~~\n      r_api_key = dir_config['api_key']\n      r_device_id = dir_config['device_id']\n\n      if dir_config['host']:\n        host = dir_config['host']\n      else:\n        host = self.devid_to_ip(r_device_id, False)\n      \n      try:\n        # Create remote proxy to interact with remote\n        remote = SyncthingProxy(\n          r_device_id, host, r_api_key,\n          port=dir_config['port'] if 'port' in dir_config else None\n        )\n      except Exception as e:\n        return True\n\n      r_config = remote.get_config()\n      r_folder = st_util.find_folder_with_path(\n        dir_config['remote_path'], r_config\n      )\n      \n      # Delete device id from folder\n      r_config = remote.get_config()\n      self_devid = self.get_device_id()\n      del_device = remote.delete_device_from_folder(\n        dir_config['remote_path'], self_devid, r_config\n      )\n\n      # Check to see if no other folder depends has this device\n      pruned = st_util.prune_devices(r_folder, r_config)\n            \n      remote.set_config(r_config)\n\n      if pruned:\n        remote.restart()\n\n    return True", "response": "Free the local path and all of its contents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntagging a file with the given name", "response": "def tag(self, path, name):\n    '''\n      Change name associated with path\n    '''\n\n    if not path[len(path) - 1] == '/':\n      path += '/'\n\n    config = self.get_config()\n    folder = self.find_folder({\n      'path' : path\n    }, config)\n\n    if not folder:\n      raise custom_errors.FileNotInConfig(path)\n\n    old_name = folder['label']\n    folder['label'] = name\n    \n    dir_config = self.adapter.get_dir_config(path)\n    dir_config['label'] = name\n    self.adapter.set_dir_config(dir_config)\n\n    self.set_config(config)\n    # self.restart\n\n    return old_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a listing of the current channels.", "response": "def cmd(send, _, args):\n    \"\"\"Returns a listing of the current channels.\n\n    Syntax: {command}\n\n    \"\"\"\n    with args['handler'].data_lock:\n        channels = \", \".join(sorted(args['handler'].channels))\n    send(channels)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('stock', nargs='?', default=random_stock())\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    send(gen_stock(cmdargs.stock))", "response": "Gets a stock quote."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_division(self, obj):\n        if obj.level.name == DivisionLevel.DISTRICT:\n            return DivisionSerializer(obj.parent).data\n\n        return DivisionSerializer(obj).data", "response": "Returns the data for a Division."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate page content for executive offices.", "response": "def bootstrap_executive_office(self, election):\n        \"\"\"\n        For executive offices, create page content for the office.\n\n        For the president, create pages for each state result.\n        \"\"\"\n        division = election.race.office.jurisdiction.division\n        content_type = ContentType.objects.get_for_model(election.race.office)\n        PageContent.objects.get_or_create(\n            content_type=content_type,\n            object_id=election.race.office.pk,\n            election_day=election.election_day,\n            division=division,\n        )\n        if division.level == self.NATIONAL_LEVEL:\n            self.bootstrap_executive_office_states(election)\n        else:\n            # Create state governor page type\n            page_type, created = PageType.objects.get_or_create(\n                model_type=ContentType.objects.get(\n                    app_label=\"government\", model=\"office\"\n                ),\n                election_day=election.election_day,\n                division_level=self.STATE_LEVEL,\n            )\n            PageContent.objects.get_or_create(\n                content_type=ContentType.objects.get_for_model(page_type),\n                object_id=page_type.pk,\n                election_day=election.election_day,\n            )\n\n            generic_state_page_type, created = PageType.objects.get_or_create(\n                model_type=ContentType.objects.get(\n                    app_label=\"geography\", model=\"division\"\n                ),\n                election_day=election.election_day,\n                division_level=DivisionLevel.objects.get(\n                    name=DivisionLevel.STATE\n                ),\n            )\n            PageContent.objects.get_or_create(\n                content_type=ContentType.objects.get_for_model(\n                    generic_state_page_type\n                ),\n                object_id=generic_state_page_type.pk,\n                election_day=election.election_day,\n            )\n\n            PageContent.objects.get_or_create(\n                content_type=ContentType.objects.get_for_model(division),\n                object_id=division.pk,\n                election_day=election.election_day,\n                special_election=False,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a random movie.", "response": "def cmd(send, msg, args):\n    \"\"\"Gets a random movie.\n\n    Syntax: {command}\n\n    \"\"\"\n\n    req = get('http://www.imdb.com/random/title')\n    html = fromstring(req.text)\n    name = html.find('head/title').text.split('-')[0].strip()\n    key = args['config']['api']['bitlykey']\n    send(\"%s -- %s\" % (name, get_short(req.url, key)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select_message(message, number, locale):\n    parts = message.split(\"|\")\n    explicit_rules = OrderedDict()\n    standard_rules = []\n    for part in parts:\n        part = part.strip()\n\n        match_interval = INTERVAL_MESSAGE_REGEX.match(part)\n        match_standard = STANDARD_RULES_REGEX.match(part)\n        if match_interval:\n            explicit_rules[match_interval.group('interval')] = match_interval.group('message')\n        elif match_standard:\n            standard_rules.append(match_standard.groups()[0])\n        else:\n            standard_rules.append(part)\n\n    # try to match an explicit rule, then to the standard ones\n    for interval, m in list(explicit_rules.items()):\n        if test_interval(number, interval):\n            return m\n\n    position = PluralizationRules.get(number, locale)\n    if len(standard_rules) <= position:\n        # when there's exactly one rule given, and that rule is a standard\n        # rule, use this rule\n        if len(parts) == 1 and len(standard_rules) > 0:\n            return standard_rules[0]\n        raise ValueError('Unable to choose a translation for \"%s\" with locale \"%s\" for value \"%s\". '\n                         'Double check that this translation has the correct plural options (e.g. '\n                         '\"There is one apple|There are {{count}} apples\").' % (message, locale, number))\n\n    return standard_rules[position]", "response": "This method returns the correct portion of the message based on the given number and locale."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(number, locale):\n        if locale == 'pt_BR':\n            # temporary set a locale for brazilian\n            locale = 'xbr'\n\n        if len(locale) > 3:\n            locale = locale.split(\"_\")[0]\n\n        rule = PluralizationRules._rules.get(locale, lambda _: 0)\n        _return = rule(number)\n        if not isinstance(_return, int) or _return < 0:\n            return 0\n        return _return", "response": "Returns the plural position to use for the given locale and number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the given plural rule for a given locale.", "response": "def set(rule, locale):\n        \"\"\"\n        Overrides the default plural rule for a given locale.\n\n        @type rule: str\n        @param rule: Callable\n\n        @type locale: str\n        @param locale: The locale\n\n        @raises: ValueError\n        \"\"\"\n\n        if locale == 'pt_BR':\n            # temporary set a locale for brazilian\n            locale = 'xbr'\n\n        if len(locale) > 3:\n            locale = locale.split(\"_\")[0]\n\n        if not hasattr(rule, '__call__'):\n            raise ValueError('The given rule can not be called')\n\n        PluralizationRules._rules[locale] = rule"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, _):\n    if not msg:\n        send(\"What acronym?\")\n        return\n    words = get_list()\n    letters = [c for c in msg.lower() if c in string.ascii_lowercase]\n    output = \" \".join([choice(words[c]) for c in letters])\n    if output:\n        send('%s: %s' % (msg, output.title()))\n    else:\n        send(\"No acronym found for %s\" % msg)", "response": "Generates a meaning for the specified acronym."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an inspect. BoundArguments object for the application of this Struct s signature to its arguments.", "response": "def get_boundargs(cls, *args, **kargs):\n        \"\"\"Return an inspect.BoundArguments object for the application\n        of this Struct's signature to its arguments. Add missing values\n        for default fields as keyword arguments.\n        \"\"\"\n        boundargs = cls._signature.bind(*args, **kargs)\n        # Include default arguments.\n        for param in cls._signature.parameters.values():\n            if (param.name not in boundargs.arguments and\n                param.default is not param.empty):\n                boundargs.arguments[param.name] = param.default\n        return boundargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _asdict(self):\n        return OrderedDict((f.name, getattr(self, f.name))\n                           for f in self._struct)", "response": "Return an OrderedDict of the fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a copy of this Struct with the same fields except with the changes specified by kargs.", "response": "def _replace(self, **kargs):\n        \"\"\"Return a copy of this Struct with the same fields except\n        with the changes specified by kargs.\n        \"\"\"\n        fields = {f.name: getattr(self, f.name)\n                  for f in self._struct}\n        fields.update(kargs)\n        return type(self)(**fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_one(self, qry, tpl):\n        ''' get a single from from a query\n        limit 1 is automatically added '''\n        self.cur.execute(qry + ' LIMIT 1', tpl)\n        result = self.cur.fetchone()\n        # unpack tuple if it has only\n        # one element\n        # TODO unpack results\n        if type(result) is tuple and len(result) == 1:\n            result = result[0]\n        return result", "response": "get a single from a query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all rows for a query", "response": "def get_all(self, qry, tpl):\n        ''' get all rows for a query '''\n        self.cur.execute(qry, tpl)\n        result = self.cur.fetchall()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the level of logging for all loggers.", "response": "def set_level(level):\n        \"\"\"\n        Set level of logging for all loggers.\n\n        Args:\n            level (int): level of logging.\n        \"\"\"\n        Logger.level = level\n        for logger in Logger.loggers.values():\n            logger.setLevel(level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a logger object.", "response": "def get_logger(name, level=None, fmt=':%(lineno)d: %(message)s'):\n        \"\"\"\n        Return a logger.\n\n        Args:\n            name (str): name to pass to the logging module.\n            level (int): level of logging.\n            fmt (str): format string.\n\n        Returns:\n            logging.Logger: logger from ``logging.getLogger``.\n        \"\"\"\n        if name not in Logger.loggers:\n            if Logger.level is None and level is None:\n                Logger.level = level = logging.ERROR\n            elif Logger.level is None:\n                Logger.level = level\n            elif level is None:\n                level = Logger.level\n            logger = logging.getLogger(name)\n            logger_handler = logging.StreamHandler()\n            logger_handler.setFormatter(LoggingFormatter(fmt=name + fmt))\n            logger.addHandler(logger_handler)\n            logger.setLevel(level)\n            Logger.loggers[name] = logger\n        return Logger.loggers[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format(self, record):\n        if record.levelno == logging.DEBUG:\n            string = Back.WHITE + Fore.BLACK + ' debug '\n        elif record.levelno == logging.INFO:\n            string = Back.BLUE + Fore.WHITE + ' info '\n        elif record.levelno == logging.WARNING:\n            string = Back.YELLOW + Fore.BLACK + ' warning '\n        elif record.levelno == logging.ERROR:\n            string = Back.RED + Fore.WHITE + ' error '\n        elif record.levelno == logging.CRITICAL:\n            string = Back.BLACK + Fore.WHITE + ' critical '\n        else:\n            string = ''\n        return '{none}{string}{none} {super}'.format(\n            none=Style.RESET_ALL, string=string, super=super().format(record))", "response": "Override default format method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprovides a transactional scope around a series of operations.", "response": "def session_scope(self):\n        \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n        session = self.session()\n        try:\n            yield session\n            session.commit()\n        except Exception as e:\n            session.rollback()\n            raise e\n        finally:\n            session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log(self, source: str, target: str, flags: int, msg: str, mtype: str) -> None:\n        entry = Log(source=str(source), target=target, flags=flags, msg=msg, type=mtype, time=datetime.now())\n        with self.session_scope() as session:\n            session.add(entry)\n            session.flush()", "response": "Logs a message to the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a point in KML format with center at the coordinates of the point and radius as specified.", "response": "def getPointAsKmlCircle(self, tableName, radius, slices=25, extrude=0, zScaleFactor=1.0, geometryId=1,\n                            geometryIdFieldName='id', geometryFieldName='geometry'):\n        \"\"\"\n        Return a string representing a circular polygon in KML format with center at the coordinates of the point\n        and radius as specified.\n        \"\"\"\n        # Validate\n\n        # Circle Params\n        PI2 = 2 * math.pi\n\n        # Get coordinates\n        statement = '''\n                    SELECT ST_X(ST_Transform({0}, 4326)) as x, ST_Y(ST_Transform({0}, 4326)) as y, ST_Z(ST_Transform({0}, 4326)) as z\n                    FROM {1}\n                    WHERE {2}={3};\n                    '''.format(geometryFieldName, tableName, geometryIdFieldName, geometryId)\n\n        result = self._session.execute(statement)\n\n        centerLatitude= 0.0\n        centerLongitude = 0.0\n\n        for row in result:\n            centerLatitude = row.x\n            centerLongitude = row.y\n\n        # Create circle coordinates\n        coordinatesString = ''\n\n        for i in range(slices):\n            latitude = centerLatitude + (radius * math.cos(float(i) / float(slices) * PI2))\n            longitude = centerLongitude + (radius * math.sin(float(i) / float(slices) * PI2))\n            elevation = 0.0\n\n            if extrude and zScaleFactor:\n                elevation = extrude * zScaleFactor\n\n            coordinatesString += '{0},{1},{2} '.format(latitude, longitude, elevation)\n\n        # Create polygon element\n        polygon = ET.Element('Polygon')\n\n        # Create options elements\n        tesselate = ET.SubElement(polygon, 'tesselate')\n        tesselate.text = '1'\n\n        extrudeElement = ET.SubElement(polygon, 'extrude')\n\n        if extrude > 0:\n            extrudeElement.text = '1'\n        else:\n            extrudeElement.text = '0'\n\n        altitudeMode = ET.SubElement(polygon, 'altitudeMode')\n\n        if extrude > 0:\n            altitudeMode.text = 'relativeToGround'\n        else:\n            altitudeMode.text = 'clampToGround'\n\n        # Geometry\n        outerBoundaryIs = ET.SubElement(polygon, 'outerBoundaryIs')\n        lindarRing = ET.SubElement(outerBoundaryIs, 'LinearRing')\n        coordinates = ET.SubElement(lindarRing, 'coordinates')\n        coordinates.text = coordinatesString.strip()\n\n        return ET.tostring(polygon)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_domains(self):\n        if self.domains is None:\n            self.domains = list(\n                set(self.source.get_domains() + self.target.get_domains()))\n        return self.domains", "response": "Returns a list of all domains affected by operation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_messages(self, domain):\n        if domain not in self.domains:\n            raise ValueError('Invalid domain: {0}'.format(domain))\n\n        if domain not in self.messages or 'all' not in self.messages[domain]:\n            self._process_domain(domain)\n\n        return self.messages[domain]['all']", "response": "Returns all valid messages after operation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn new valid messages after operation.", "response": "def get_new_messages(self, domain):\n        \"\"\"\n        Returns new valid messages after operation.\n        @type domain: str\n        @rtype: dict\n        \"\"\"\n        if domain not in self.domains:\n            raise ValueError('Invalid domain: {0}'.format(domain))\n\n        if domain not in self.messages or 'new' not in self.messages[domain]:\n            self._process_domain(domain)\n\n        return self.messages[domain]['new']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns obsolete valid messages after operation.", "response": "def get_obsolete_messages(self, domain):\n        \"\"\"\n        Returns obsolete valid messages after operation.\n        @type domain: str\n        @rtype: dict\n        \"\"\"\n        if domain not in self.domains:\n            raise ValueError('Invalid domain: {0}'.format(domain))\n\n        if domain not in self.messages or \\\n            'obsolete' not in self.messages[domain]:\n            self._process_domain(domain)\n\n        return self.messages[domain]['obsolete']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_result(self):\n        for domain in self.domains:\n            if domain not in self.messages:\n                self._process_domain(domain)\n\n        return self.result", "response": "Returns resulting catalogue\n        @rtype: MessageCatalogue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_db(session, botconfig, confdir):\n    Base.metadata.create_all(session.connection())\n    # If we're creating a fresh db, we don't need to worry about migrations.\n    if not session.get_bind().has_table('alembic_version'):\n        conf_obj = config.Config()\n        conf_obj.set_main_option('bot_config_path', confdir)\n        with resources.path('cslbot', botconfig['alembic']['script_location']) as script_location:\n            conf_obj.set_main_option('script_location', str(script_location))\n            command.stamp(conf_obj, 'head')\n\n    # Populate permissions table with owner.\n    owner_nick = botconfig['auth']['owner']\n    if not session.query(Permissions).filter(Permissions.nick == owner_nick).count():\n        session.add(Permissions(nick=owner_nick, role='owner'))", "response": "Sets up the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample_following_dist(handle_iter, n, totalf):\n    multiplier = 1.0\n    if totalf == 1.0:\n        multiplier = 1e8\n        # print \"WARNING!! I don't except probabilities\"\n\n    totalf = totalf * multiplier\n    print(\"# Population Size\", totalf)\n    A = np.sort(np.unique(np.random.randint(0, totalf, size=n*2))[:n])\n    A = A[::-1]\n    # Uniqueness check, non necessarily required, but not very\n    # computationally intensive\n    assert len(A) == n, \"Not enough randomnumbers generated\"\\\n        \"Requried {}, generated only {}\".format(n, len(A))\n    j = 0\n    sampled = 0\n    val = A.pop()\n    # print handle_iter\n    for _,w,f in handle_iter:\n        j += f*multiplier\n        if not A: break\n        while val<j:\n            sampled += 1\n            if sampled %5000 == 0:\n                print (\"Sampled:\",sampled)\n            yield (val, w)\n            if A:\n                val = A.pop()\n            else:\n                break\n\n    print (\"# Stopped at:\", w, f, j, '\\n')\n    while A and val<j:\n        yield (val, w)\n        if A:\n            i, val = A.pop()\n        else:\n            break", "response": "Generates n passwords following the distribution from the handle_iter and yields n random numbers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning n passwords sampled from this password dataset.", "response": "def sample_pws(self, n, asperdist=True):\n        \"\"\"Returns n passwords sampled from this password dataset.  if\n        asperdist is True, then returns the password sampled according\n        the password histogram distribution (with\n        replacement). Passwords are always sampled with replacement.\n\n        TODO: The sample users, instead of passwords perse.\n        \"\"\"\n        if asperdist:\n            sample = np.random.choice(\n                self._freq_list.shape[0], size=n, p=self._freq_list/self._totalf\n            )\n        else:\n            sample = np.random.choice(len(self._T), size=n)\n        return (self._T.restore_key(i) for i in sample)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sumvalues(self, q=0):\n        if q == 0:\n            return self._totalf\n        else:\n            return -np.partition(-self._freq_list, q)[:q].sum()", "response": "Sum of top q passowrd frequencies\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iterpws(self, n):\n        for _id in np.argsort(self._freq_list)[::-1][:n]:\n            pw = self._T.restore_key(_id)\n            if self._min_pass_len <= len(pw) <= self._max_pass_len:\n                yield _id, pw, self._freq_list[_id]", "response": "Iterate over the passwords in order of their frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cross_validate(model, X, y, k_folds=5, metric=\"auto\", shuffle=True):\n\n    train_scores = []\n    test_scores = []\n    folds = KFolds(X, y, k=k_folds, shuffle=shuffle)\n\n    for X_train, X_test, y_train, y_test in folds:\n        model.fit(X_train, y_train)\n\n        if metric is None or metric == \"auto\":\n            train_scores.append(model.evaluate(X_train, y_train))\n            test_scores.append(model.evaluate(X_test, y_test))\n        else:\n            train_scores.append(\n                metric(y_train, model.predict(X_train))\n            )\n            test_scores.append(\n                metric(y_test, model.predict(X_test))\n            )\n\n    return {\n        \"train_scores\": np.array(train_scores),\n        \"test_scores\": np.array(test_scores),\n    }", "response": "Evaluates the given model on the given data and returns a dictionary with train scores and test scores."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a CIDR range.", "response": "def cmd(send, msg, args):\n    \"\"\"Gets a CIDR range.\n\n    Syntax: {command} <range>\n\n    \"\"\"\n    if not msg:\n        send(\"Need a CIDR range.\")\n        return\n    try:\n        ipn = ip_network(msg)\n    except ValueError:\n        send(\"Not a valid CIDR range.\")\n        return\n    send(\"%s - %s\" % (ipn[0], ipn[-1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes the requirements list from the current running environment", "response": "def get_environment_requirements_list():\n    \"\"\"\n    Take the requirements list from the current running environment\n\n    :return: string\n    \"\"\"\n    requirement_list = []\n    requirements = check_output([sys.executable, '-m', 'pip', 'freeze'])\n\n    for requirement in requirements.split():\n        requirement_list.append(requirement.decode(\"utf-8\"))\n\n    return requirement_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a list and returns a list of dicts with package versions", "response": "def parse_requirements_list(requirements_list):\n    \"\"\"\n    Take a list and return a list of dicts with {package, versions) based on the requirements specs\n\n    :param requirements_list: string\n    :return: string\n    \"\"\"\n    req_list = []\n\n    for requirement in requirements_list:\n        requirement_no_comments = requirement.split('#')[0].strip()\n\n        # if matching requirement line (Thing==1.2.3), update dict, continue\n        req_match = re.match(\n            r'\\s*(?P<package>[^\\s\\[\\]]+)(?P<extras>\\[\\S+\\])?==(?P<version>\\S+)',\n            requirement_no_comments\n        )\n        if req_match:\n            req_list.append({\n                'package': req_match.group('package'),\n                'version': req_match.group('version'),\n            })\n\n    return req_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pypi_package_data(package_name, version=None):\n    pypi_url = 'https://pypi.org/pypi'\n\n    if version:\n        package_url = '%s/%s/%s/json' % (pypi_url, package_name, version, )\n    else:\n        package_url = '%s/%s/json' % (pypi_url, package_name, )\n\n    try:\n        response = requests.get(package_url)\n    except requests.ConnectionError:\n        raise RuntimeError('Connection error!')\n\n    # Package not available on pypi\n    if not response.ok:\n        return None\n\n    return response.json()", "response": "Get package data from pypi by the package name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package_update_list(package_name, version):\n    package_version = semantic_version.Version.coerce(version)\n\n    # Get package and version data from pypi\n    package_data = get_pypi_package_data(package_name)\n    version_data = get_pypi_package_data(package_name, version)\n\n    # Current release specific information\n    current_release = ''\n    current_release_license = ''\n\n    # Latest release specific information\n    latest_release = ''\n    latest_release_license = ''\n\n    # Information about packages\n    major_updates = []\n    minor_updates = []\n    patch_updates = []\n    pre_releases = []\n    non_semantic_versions = []\n\n    if package_data:\n        latest_release = package_data['info']['version']\n        latest_release_license = package_data['info']['license'] if package_data['info']['license'] else ''\n\n        for release, info in package_data['releases'].items():\n            parsed_release = parse(release)\n\n            upload_time = None\n            if info:\n                upload_time = datetime.strptime(info[0]['upload_time'], \"%Y-%m-%dT%H:%M:%S\")\n\n            try:\n                # Get semantic version of package\n                release_version = semantic_version.Version.coerce(release)\n\n                if not parsed_release.is_prerelease:\n                    # Place package in the appropriate semantic visioning list\n                    if release_version in semantic_version.Spec(\">=%s\" % package_version.next_major()):\n                        major_updates.append({\n                            'version': release,\n                            'upload_time': upload_time,\n                        })\n                    elif release_version in semantic_version.Spec(\">=%s,<%s\" % (package_version.next_minor(), package_version.next_major())):\n                        minor_updates.append({\n                            'version': release,\n                            'upload_time': upload_time,\n                        })\n                    elif release_version in semantic_version.Spec(\">=%s,<%s\" % (package_version.next_patch(), package_version.next_minor())):\n                        patch_updates.append({\n                            'version': release,\n                            'upload_time': upload_time,\n                        })\n                else:\n                    pre_releases.append({\n                        'version': release,\n                        'upload_time': upload_time\n                    })\n            except ValueError:\n                # Keep track of versions that could not be recognized as semantic\n                non_semantic_versions.append({'version': release, 'upload_time': upload_time})\n\n    if version_data:\n        current_release = version_data['info']['version']\n        current_release_license = version_data['info']['license'] if version_data['info']['license'] else ''\n\n    # Get number of newer releases available for the given package\n    newer_releases = len(major_updates + minor_updates + patch_updates)\n\n    return {\n        'current_release': current_release,\n        'current_release_license': current_release_license,\n        'latest_release': latest_release,\n        'latest_release_license': latest_release_license,\n        'newer_releases': newer_releases,\n        'pre_releases': len(pre_releases),\n        'major_updates': sorted(major_updates, key=lambda x: semantic_version.Version.coerce(x['version']), reverse=True),\n        'minor_updates': sorted(minor_updates, key=lambda x: semantic_version.Version.coerce(x['version']), reverse=True),\n        'patch_updates': sorted(patch_updates, key=lambda x: semantic_version.Version.coerce(x['version']), reverse=True),\n        'pre_release_updates': sorted(pre_releases, key=lambda x: semantic_version.Version.coerce(x['version']), reverse=True),\n        'non_semantic_versions': non_semantic_versions,\n    }", "response": "Get update information of a package from a given version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __list_package_updates(package_name, version):\n\n    updates = get_package_update_list(package_name, version)\n\n    if updates['newer_releases'] or updates['pre_releases']:\n        print('%s (%s)' % (package_name, version))\n        __list_updates('Major releases', updates['major_updates'])\n        __list_updates('Minor releases', updates['minor_updates'])\n        __list_updates('Patch releases', updates['patch_updates'])\n        __list_updates('Pre releases', updates['pre_release_updates'])\n        __list_updates('Unknown releases', updates['non_semantic_versions'])\n        print(\"___\")", "response": "Function used to list all package updates in console"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __list_updates(update_type, update_list):\n    if len(update_list):\n        print(\"  %s:\" % update_type)\n        for update_item in update_list:\n            print(\"  -- %(version)s on %(upload_time)s\" % update_item)", "response": "Function used to list package updates by update type in console"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction used to output packages update information in the console", "response": "def __updatable():\n    \"\"\"\n    Function used to output packages update information in the console\n    \"\"\"\n    # Add argument for console\n    parser = argparse.ArgumentParser()\n    parser.add_argument('file', nargs='?', type=argparse.FileType(), default=None, help='Requirements file')\n    args = parser.parse_args()\n\n    # Get list of packages\n    if args.file:\n        packages = parse_requirements_list(args.file)\n    else:\n        packages = get_parsed_environment_package_list()\n\n    # Output updates\n    for package in packages:\n        __list_package_updates(package['package'], package['version'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(send, msg, args):\n    worker = args[\"handler\"].workers\n    result = worker.run_pool(get_urls, [msg])\n    try:\n        urls = result.get(5)\n    except multiprocessing.TimeoutError:\n        worker.restart_pool()\n        send(\"Url regex timed out.\", target=args[\"config\"][\"core\"][\"ctrlchan\"])\n        return\n    for url in urls:\n        # Prevent botloops\n        if (args[\"db\"].query(Urls).filter(Urls.url == url, Urls.time > datetime.now() - timedelta(seconds=10)).count() > 1):\n            return\n\n        if url.startswith(\"https://twitter.com\"):\n            tid = url.split(\"/\")[-1]\n            twitter_api = get_api(args[\"config\"])\n            status = twitter_api.GetStatus(tid)\n            text = status.text.replace(\"\\n\", \" / \")\n            send(\"** {} (@{}) on Twitter: {}\".format(status.user.name, status.user.screen_name, text))\n            return\n\n        imgkey = args[\"config\"][\"api\"][\"googleapikey\"]\n        title = urlutils.get_title(url, imgkey)\n\n        shortkey = args[\"config\"][\"api\"][\"bitlykey\"]\n        short = urlutils.get_short(url, shortkey)\n\n        last = args[\"db\"].query(Urls).filter(Urls.url == url).order_by(Urls.time.desc()).first()\n        if args[\"config\"][\"feature\"].getboolean(\"linkread\"):\n            if last is not None:\n                lasttime = last.time.strftime(\"%H:%M:%S on %Y-%m-%d\")\n                send(\"Url %s previously posted at %s by %s -- %s\" % (short, lasttime, last.nick, title))\n            else:\n                send(\"** %s - %s\" % (title, short))\n        args[\"db\"].add(Urls(url=url, title=title, nick=args[\"nick\"], time=datetime.now()))", "response": "Generate a short url."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef page_location_template(self):\n        cycle = self.election_day.cycle.name\n        model_class = self.model_type.model_class()\n        if model_class == ElectionDay:\n            return \"/{}/\".format(cycle)\n        if model_class == Office:\n            # President\n            if self.jurisdiction:\n                if self.division_level.name == DivisionLevel.STATE:\n                    return \"/{}/president/{{state}}\".format(cycle)\n                else:\n                    return \"/{}/president/\".format(cycle)\n            # Governor\n            else:\n                return \"/{}/{{state}}/governor/\".format(cycle)\n        elif model_class == Body:\n            # Senate\n            if self.body.slug == \"senate\":\n                if self.jurisdiction:\n                    if self.division_level.name == DivisionLevel.STATE:\n                        return \"/{}/senate/{{state}}/\".format(cycle)\n                    else:\n                        return \"/{}/senate/\".format(cycle)\n                else:\n                    return \"/{}/{{state}}/senate/\".format(cycle)\n            # House\n            else:\n                if self.jurisdiction:\n                    if self.division_level.name == DivisionLevel.STATE:\n                        return \"/{}/house/{{state}}/\".format(cycle)\n                    else:\n                        return \"/{}/house/\".format(cycle)\n                else:\n                    return \"/{}/{{state}}/house/\".format(cycle)\n        elif model_class == Division:\n            return \"/{}/{{state}}/\".format(cycle)\n        else:\n            return \"ORPHAN TYPE\"", "response": "Returns the published URL template for a page type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning migrations in offline mode.", "response": "def run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    botconfig = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())\n    config_path = config.get_main_option('bot_config_path', join(dirname(__file__), '../..'))\n    with open(join(config_path, 'config.cfg')) as f:\n        botconfig.read_file(f)\n    url = botconfig['db']['engine']\n\n    context.configure(url=url, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns migrations in online mode.", "response": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine and associate a\n    connection with the context.\n\n    \"\"\"\n    botconfig = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())\n    config_path = config.get_main_option('bot_config_path', join(dirname(__file__), '../..'))\n    with open(join(config_path, 'config.cfg')) as f:\n        botconfig.read_file(f)\n    url = botconfig['db']['engine']\n\n    connectable = create_engine(url)\n    with connectable.connect() as connection:\n        context.configure(connection=connection, target_metadata=target_metadata, render_as_batch=True)\n\n        with context.begin_transaction():\n            context.run_migrations()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a random quote from tjbash. org given search criteria.", "response": "def cmd(send, msg, _):\n    \"\"\"Finds a random quote from tjbash.org given search criteria.\n\n    Syntax: {command} [searchstring]\n\n    \"\"\"\n    if not msg:\n        url = 'http://tjbash.org/random1.html'\n        params = {}\n    else:\n        targs = msg.split()\n        if len(targs) == 1 and targs[0].isnumeric():\n            url = 'http://tjbash.org/%s' % targs[0]\n            params = {}\n        else:\n            url = 'http://tjbash.org/search.html'\n            params = {'query': 'tag:%s' % '+'.join(targs)}\n    req = get(url, params=params)\n    doc = fromstring(req.text)\n    quotes = doc.find_class('quote-body')\n    if not quotes:\n        send(\"There were no results.\")\n        return\n    quote = choice(quotes)\n    lines = [x.strip() for x in map(operator.methodcaller('strip'), quote.itertext())]\n    # Only send up to three lines.\n    for line in lines[:4]:\n        send(line)\n    tags = quote.getparent().find_class('quote-tags')\n    postid = quote.getparent().getparent().get('id').replace('quote-', '')\n    if tags:\n        tags = [x.text for x in tags[0].findall('.//a')]\n        send(\" -- {} -- {}http://tjbash.org/{}\".format(', '.join(tags), \"continued: \" if (len(lines) > 3) else \"\", postid))\n    else:\n        send(\" -- http://tjbash.org/{}\".format(postid))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef typed_encode(value, sub_schema, path, net_new_properties, buffer):\n    try:\n        # from jx_base import Column\n        if sub_schema.__class__.__name__=='Column':\n            value_json_type = python_type_to_json_type[value.__class__]\n            column_json_type = es_type_to_json_type[sub_schema.es_type]\n\n            if value_json_type == column_json_type:\n                pass  # ok\n            elif value_json_type == NESTED and all(python_type_to_json_type[v.__class__] == column_json_type for v in value if v != None):\n                pass  # empty arrays can be anything\n            else:\n                from mo_logs import Log\n\n                Log.error(\"Can not store {{value}} in {{column|quote}}\", value=value, column=sub_schema.name)\n\n            sub_schema = {json_type_to_inserter_type[value_json_type]: sub_schema}\n\n        if value == None:\n            from mo_logs import Log\n            Log.error(\"can not encode null (missing) values\")\n        elif value is True:\n            if BOOLEAN_TYPE not in sub_schema:\n                sub_schema[BOOLEAN_TYPE] = {}\n                net_new_properties.append(path + [BOOLEAN_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_BOOLEAN_TYPE)\n            append(buffer, 'true}')\n            return\n        elif value is False:\n            if BOOLEAN_TYPE not in sub_schema:\n                sub_schema[BOOLEAN_TYPE] = {}\n                net_new_properties.append(path + [BOOLEAN_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_BOOLEAN_TYPE)\n            append(buffer, 'false}')\n            return\n\n        _type = value.__class__\n        if _type in (dict, Data):\n            if sub_schema.__class__.__name__ == 'Column':\n                from mo_logs import Log\n                Log.error(\"Can not handle {{column|json}}\", column=sub_schema)\n\n            if NESTED_TYPE in sub_schema:\n                # PREFER NESTED, WHEN SEEN BEFORE\n                if value:\n                    append(buffer, '{')\n                    append(buffer, QUOTED_NESTED_TYPE)\n                    append(buffer, '[')\n                    _dict2json(value, sub_schema[NESTED_TYPE], path + [NESTED_TYPE], net_new_properties, buffer)\n                    append(buffer, ']' + COMMA)\n                    append(buffer, QUOTED_EXISTS_TYPE)\n                    append(buffer, text_type(len(value)))\n                    append(buffer, '}')\n                else:\n                    # SINGLETON LIST\n                    append(buffer, '{')\n                    append(buffer, QUOTED_NESTED_TYPE)\n                    append(buffer, '[{')\n                    append(buffer, QUOTED_EXISTS_TYPE)\n                    append(buffer, '1}]')\n                    append(buffer, COMMA)\n                    append(buffer, QUOTED_EXISTS_TYPE)\n                    append(buffer, '1}')\n            else:\n                if EXISTS_TYPE not in sub_schema:\n                    sub_schema[EXISTS_TYPE] = {}\n                    net_new_properties.append(path + [EXISTS_TYPE])\n\n                if value:\n                    _dict2json(value, sub_schema, path, net_new_properties, buffer)\n                else:\n                    append(buffer, '{')\n                    append(buffer, QUOTED_EXISTS_TYPE)\n                    append(buffer, '1}')\n        elif _type is binary_type:\n            if STRING_TYPE not in sub_schema:\n                sub_schema[STRING_TYPE] = True\n                net_new_properties.append(path + [STRING_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_STRING_TYPE)\n            append(buffer, '\"')\n            try:\n                v = utf82unicode(value)\n            except Exception as e:\n                raise problem_serializing(value, e)\n\n            for c in v:\n                append(buffer, ESCAPE_DCT.get(c, c))\n            append(buffer, '\"}')\n        elif _type is text_type:\n            if STRING_TYPE not in sub_schema:\n                sub_schema[STRING_TYPE] = True\n                net_new_properties.append(path + [STRING_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_STRING_TYPE)\n            append(buffer, '\"')\n            for c in value:\n                append(buffer, ESCAPE_DCT.get(c, c))\n            append(buffer, '\"}')\n        elif _type in integer_types:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, text_type(value))\n            append(buffer, '}')\n        elif _type in (float, Decimal):\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(value))\n            append(buffer, '}')\n        elif _type in (set, list, tuple, FlatList):\n            if len(value) == 0:\n                append(buffer, '{')\n                append(buffer, QUOTED_EXISTS_TYPE)\n                append(buffer, '0}')\n            elif any(v.__class__ in (Data, dict, set, list, tuple, FlatList) for v in value):\n                # THIS IS NOT DONE BECAUSE\n                if len(value) == 1:\n                    if NESTED_TYPE in sub_schema:\n                        append(buffer, '{')\n                        append(buffer, QUOTED_NESTED_TYPE)\n                        _list2json(value, sub_schema[NESTED_TYPE], path + [NESTED_TYPE], net_new_properties, buffer)\n                        append(buffer, '}')\n                    else:\n                        # NO NEED TO NEST, SO DO NOT DO IT\n                        typed_encode(value[0], sub_schema, path, net_new_properties, buffer)\n                else:\n                    if NESTED_TYPE not in sub_schema:\n                        sub_schema[NESTED_TYPE] = {}\n                        net_new_properties.append(path + [NESTED_TYPE])\n                    append(buffer, '{')\n                    append(buffer, QUOTED_NESTED_TYPE)\n                    _list2json(value, sub_schema[NESTED_TYPE], path + [NESTED_TYPE], net_new_properties, buffer)\n                    append(buffer, '}')\n            else:\n                # ALLOW PRIMITIVE MULTIVALUES\n                value = [v for v in value if v != None]\n                types = list(set(json_type_to_inserter_type[python_type_to_json_type[v.__class__]] for v in value))\n                if len(types) == 0:  # HANDLE LISTS WITH Nones IN THEM\n                    append(buffer, '{')\n                    append(buffer, QUOTED_NESTED_TYPE)\n                    append(buffer, '[]}')\n                elif len(types) > 1:\n                    _list2json(value, sub_schema, path + [NESTED_TYPE], net_new_properties, buffer)\n                else:\n                    element_type = types[0]\n                    if element_type not in sub_schema:\n                        sub_schema[element_type] = True\n                        net_new_properties.append(path + [element_type])\n                    append(buffer, '{')\n                    append(buffer, quote(element_type))\n                    append(buffer, COLON)\n                    _multivalue2json(value, sub_schema[element_type], path + [element_type], net_new_properties, buffer)\n                    append(buffer, '}')\n        elif _type is date:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(time.mktime(value.timetuple())))\n            append(buffer, '}')\n        elif _type is datetime:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(time.mktime(value.timetuple())))\n            append(buffer, '}')\n        elif _type is Date:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(value.unix))\n            append(buffer, '}')\n        elif _type is timedelta:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(value.total_seconds()))\n            append(buffer, '}')\n        elif _type is Duration:\n            if NUMBER_TYPE not in sub_schema:\n                sub_schema[NUMBER_TYPE] = True\n                net_new_properties.append(path + [NUMBER_TYPE])\n            append(buffer, '{')\n            append(buffer, QUOTED_NUMBER_TYPE)\n            append(buffer, float2json(value.seconds))\n            append(buffer, '}')\n        elif _type is NullType:\n            append(buffer, 'null')\n        elif hasattr(value, '__data__'):\n            typed_encode(value.__data__(), sub_schema, path, net_new_properties, buffer)\n        elif hasattr(value, '__iter__'):\n            if NESTED_TYPE not in sub_schema:\n                sub_schema[NESTED_TYPE] = {}\n                net_new_properties.append(path + [NESTED_TYPE])\n\n            append(buffer, '{')\n            append(buffer, QUOTED_NESTED_TYPE)\n            _iter2json(value, sub_schema[NESTED_TYPE], path + [NESTED_TYPE], net_new_properties, buffer)\n            append(buffer, '}')\n        else:\n            from mo_logs import Log\n\n            Log.error(text_type(repr(value)) + \" is not JSON serializable\")\n    except Exception as e:\n        from mo_logs import Log\n\n        Log.error(text_type(repr(value)) + \" is not JSON serializable\", cause=e)", "response": "Encodes the value in the given sub_schema to the given buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a queryset of all bodies holding an election on a date.", "response": "def get_queryset(self):\n        \"\"\"\n        Returns a queryset of all bodies holding an election on a date.\n        \"\"\"\n        try:\n            date = ElectionDay.objects.get(date=self.kwargs['date'])\n        except Exception:\n            raise APIException(\n                'No elections on {}.'.format(self.kwargs['date'])\n            )\n        body_ids = []\n        for election in date.elections.all():\n            body = election.race.office.body\n            if body:\n                body_ids.append(body.uid)\n        return Body.objects.filter(uid__in=body_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd election_day to serializer context.", "response": "def get_serializer_context(self):\n        \"\"\"Adds ``election_day`` to serializer context.\"\"\"\n        context = super(BodyMixin, self).get_serializer_context()\n        context['election_date'] = self.kwargs['date']\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an engine and selectively apply certain hacks to make it Asphalt friendly.", "response": "def configure_engine(cls, url: Union[str, URL, Dict[str, Any]] = None,\n                         bind: Union[Connection, Engine] = None, session: Dict[str, Any] = None,\n                         ready_callback: Union[Callable[[Engine, sessionmaker], Any], str] = None,\n                         poolclass: Union[str, Pool] = None, **engine_args):\n        \"\"\"\n        Create an engine and selectively apply certain hacks to make it Asphalt friendly.\n\n        :param url: the connection url passed to :func:`~sqlalchemy.create_engine`\n            (can also be a dictionary of :class:`~sqlalchemy.engine.url.URL` keyword arguments)\n        :param bind: a connection or engine to use instead of creating a new engine\n        :param session: keyword arguments to :class:`~sqlalchemy.orm.session.sessionmaker`\n        :param ready_callback: callable (or a ``module:varname`` reference to one) called with two\n            arguments: the Engine and the sessionmaker when the component is started but before the\n            resources are added to the context\n        :param poolclass: the SQLAlchemy Pool class to use; passed to\n            :func:`~sqlalchemy.create_engine`\n        :param engine_args: keyword arguments passed to :func:`~sqlalchemy.create_engine`\n\n        \"\"\"\n        assert check_argument_types()\n        if bind is None:\n            if isinstance(url, dict):\n                url = URL(**url)\n            elif isinstance(url, str):\n                url = make_url(url)\n            elif url is None:\n                raise TypeError('both \"url\" and \"bind\" cannot be None')\n\n            if isinstance(poolclass, str):\n                poolclass = resolve_reference(poolclass)\n\n            # This is a hack to get SQLite to play nice with asphalt-sqlalchemy's juggling of\n            # connections between multiple threads. The same connection should, however, never be\n            # used in multiple threads at once.\n            if url.get_dialect().name == 'sqlite':\n                connect_args = engine_args.setdefault('connect_args', {})\n                connect_args.setdefault('check_same_thread', False)\n\n            bind = create_engine(url, poolclass=poolclass, **engine_args)\n\n        session = session or {}\n        session.setdefault('expire_on_commit', False)\n        ready_callback = resolve_reference(ready_callback)\n        return bind, sessionmaker(bind, **session), ready_callback"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_portfolio(self, datetime, portfolio):\n        '''\n        Store in Rethinkdb a zipline.Portfolio object\n        '''\n        log.debug('Saving portfolio in database')\n        pf = dbutils.portfolio_to_dict(portfolio)\n        pf.pop('positions')\n        data = [{\n            \"name\": self.name,\n            \"time\": datetime.strftime(\"%Y-%m-%d %H:%M\"),\n            \"columns\": pf.keys(),\n            \"points\": [pf.values()]}]\n        # Timestamp type is not json serializable\n        data[0]['points'][0][-1] = pf['start_date'].__str__()\n\n        self.session.write_points(data)", "response": "Save a portfolio in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if given file exists and is a regular file.", "response": "def valid_file(value):\n    \"\"\"\n    Check if given file exists and is a regular file.\n\n    Args:\n        value (str): path to the file.\n\n    Raises:\n        argparse.ArgumentTypeError: if not valid.\n\n    Returns:\n        str: original value argument.\n    \"\"\"\n    if not value:\n        raise argparse.ArgumentTypeError(\"'' is not a valid file path\")\n    elif not os.path.exists(value):\n        raise argparse.ArgumentTypeError(\n            \"%s is not a valid file path\" % value)\n    elif os.path.isdir(value):\n        raise argparse.ArgumentTypeError(\n            \"%s is a directory, not a regular file\" % value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_parser():\n    parser = argparse.ArgumentParser(\n        add_help=False,\n        description='Analysis of your architecture strength based on DSM data')\n    parser.add_argument(\n        '-c', '--config', action='store', type=valid_file, dest='config_file',\n        metavar='FILE', help='Configuration file to use.')\n    parser.add_argument(\n        '-h', '--help', action='help', default=argparse.SUPPRESS,\n        help='Show this help message and exit.')\n    parser.add_argument(\n        '-i', '--input', action='store', type=valid_file, dest='input_file',\n        metavar='FILE', help='Input file containing CSV data.')\n    parser.add_argument(\n        '-l', '--list-plugins', action='store_true', dest='list_plugins',\n        default=False, help='Show the available plugins. Default: false.')\n    parser.add_argument(\n        '--no-color', action='store_true', dest='no_color', default=False,\n        help='Do not use colors. Default: false.')\n    parser.add_argument(\n        '--no-config', action='store_true', dest='no_config', default=False,\n        help='Do not load configuration from file. Default: false.')\n    parser.add_argument(\n        '-v', '--verbose-level', action='store', dest='level',\n        type=valid_level, default='ERROR', help='Level of verbosity.')\n    parser.add_argument(\n        '-V', '--version', action='version', version='archan %s' % __version__,\n        help='Show the current version of the program and exit.')\n    return parser", "response": "Return a parser for the command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a sequence that is aggregated by the specified start and end point.", "response": "def RANGE(start, end, step=None):\n    \"\"\"\n    Generates the sequence from the specified starting number by successively\n    incrementing the starting number by the specified step value up to but not including the end point.\n    See https://docs.mongodb.com/manual/reference/operator/aggregation/range/\n    for more details\n    :param start: An integer (or valid expression) that specifies the start of the sequence.\n    :param end: An integer (or valid expression) that specifies the exclusive upper limit of the sequence.\n    :param step: An integer (or valid expression) that specifies the increment value.\n    :return: Aggregation operator\n    \"\"\"\n    return {'$range': [start, end, step]} if step is not None else {'$range': [start, end]}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a subset of an array.", "response": "def SLICE(array, n, position=None):\n    \"\"\"\n    Returns a subset of an array.\n    See https://docs.mongodb.com/manual/reference/operator/aggregation/slice/\n    for more details\n    :param array: Any valid expression as long as it resolves to an array.\n    :param n: Any valid expression as long as it resolves to an integer.\n    :param position: Optional. Any valid expression as long as it resolves to an integer.\n    :return: Aggregation operator\n    \"\"\"\n    return {'$slice': [array, position, n]} if position is not None else {'$slice': [array, n]}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransposing an array of input arrays so that the first element of the output array would be an array containing, the first element of the first input array, the first element of the second input array, etc. See https://docs.mongodb.com/manual/reference/operator/aggregation/zip/ for more details :param inputs: An array of expressions that resolve to arrays. :param use_longest_length: A boolean which specifies whether the length of the longest array determines the number of arrays in the output array. :param defaults: An array of default element values to use if the input arrays have different lengths. :return: Aggregation operator", "response": "def ZIP(inputs, use_longest_length=None, defaults=None):\n    \"\"\"\n    Transposes an array of input arrays so that the first element of the output array would be an array containing,\n    the first element of the first input array,\n    the first element of the second input array, etc.\n    See https://docs.mongodb.com/manual/reference/operator/aggregation/zip/\n    for more details\n    :param inputs: An array of expressions that resolve to arrays.\n    :param use_longest_length: A boolean which specifies whether the length of the longest array determines the number of arrays in the output array.\n    :param defaults: An array of default element values to use if the input arrays have different lengths.\n    :return: Aggregation operator\n    \"\"\"\n    res = {'inputs': inputs}\n    if use_longest_length in [True, False]:\n        res['useLongestLength'] = use_longest_length\n    if defaults is not None:\n        res['defaults'] = defaults\n    return {'$zip': res}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef INDEX_OF_ARRAY(string_expression, substring_expression, start=None, end=None):\n    res = [string_expression, substring_expression]\n    if start is not None:\n        res.append(start)\n    if end is not None:\n        res.append(end)\n    return {'$indexOfArray': res}", "response": "Searches an array for an occurence of a specified value and returns the index of the first occurence."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a logger for the plugin.", "response": "def get_logger(cls, custom_name=None):\n        \"\"\"Returns a logger for the plugin.\"\"\"\n        name = custom_name or cls.get_name()\n        return logging.getLogger(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the messages within a given domain.", "response": "def all(self, domain=None):\n        \"\"\"\n        Gets the messages within a given domain.\n\n        If domain is None, it returns all messages.\n\n        @type id: The\n        @param id: message id\n\n        @rtype: dict\n        @return: A dict of messages\n        \"\"\"\n        if domain is None:\n            return {k: dict(v) for k, v in list(self.messages.items())}\n\n        return dict(self.messages.get(domain, {}))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a message translation.", "response": "def set(self, id, translation, domain='messages'):\n        \"\"\"\n        Sets a message translation.\n        \"\"\"\n        assert isinstance(id, (str, unicode))\n        assert isinstance(translation, (str, unicode))\n        assert isinstance(domain, (str, unicode))\n\n        self.add({id: translation}, domain)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has(self, id, domain):\n        assert isinstance(id, (str, unicode))\n        assert isinstance(domain, (str, unicode))\n\n        if self.defines(id, domain):\n            return True\n\n        if self.fallback_catalogue is not None:\n            return self.fallback_catalogue.has(id, domain)\n\n        return False", "response": "Checks if a message has a translation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef defines(self, id, domain='messages'):\n        assert isinstance(id, (str, unicode))\n        assert isinstance(domain, (str, unicode))\n\n        return id in self.messages.get(domain, {})", "response": "Checks if a message has a translation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a message translation.", "response": "def get(self, id, domain='messages'):\n        \"\"\"\n        Gets a message translation.\n\n        @rtype: str\n        @return: The message translation\n        \"\"\"\n        assert isinstance(id, (str, unicode))\n        assert isinstance(domain, (str, unicode))\n\n        if self.defines(id, domain):\n            return self.messages[domain][id]\n\n        if self.fallback_catalogue is not None:\n            return self.fallback_catalogue.get(id, domain)\n\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace(self, messages, domain='messages'):\n        assert isinstance(messages, (dict, CaseInsensitiveDict))\n        assert isinstance(domain, (str, unicode))\n\n        self.messages[domain] = CaseInsensitiveDict({})\n        self.add(messages, domain)", "response": "Sets translations for a given domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_catalogue(self, catalogue):\n        assert isinstance(catalogue, MessageCatalogue)\n\n        if catalogue.locale != self.locale:\n            raise ValueError(\n                'Cannot add a catalogue for locale \"%s\" as the '\n                'current locale for this catalogue is \"%s\"' %\n                (catalogue.locale, self.locale))\n\n        for domain, messages in list(catalogue.all().items()):\n            self.add(messages, domain)\n\n        for resource in catalogue.resources:\n            self.add_resource(resource)", "response": "Adds a new MessageCatalogue into the current MessageCatalogue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the given one to the current one only when the translation does not exist.", "response": "def add_fallback_catalogue(self, catalogue):\n        \"\"\"\n        Merges translations from the given Catalogue into the current one\n        only when the translation does not exist.\n\n        This is used to provide default translations when they do not exist\n        for the current locale.\n\n        @type id: The\n        @param id: message id\n\n        \"\"\"\n        assert isinstance(catalogue, MessageCatalogue)\n\n        # detect circular references\n        c = self\n        while True:\n            if c.locale == catalogue.locale:\n                raise ValueError(\n                    'Circular reference detected when adding a '\n                    'fallback catalogue for locale \"%s\".' %\n                    catalogue.locale)\n            c = c.parent\n            if c is None:\n                break\n\n        catalogue.parent = self\n        self.fallback_catalogue = catalogue\n\n        for resource in catalogue.resources:\n            self.add_resource(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trans(self, id, parameters=None, domain=None, locale=None):\n        if parameters is None:\n            parameters = {}\n        assert isinstance(parameters, dict)\n\n        if locale is None:\n            locale = self.locale\n        else:\n            self._assert_valid_locale(locale)\n\n        if domain is None:\n            domain = 'messages'\n\n        msg = self.get_catalogue(locale).get(id, domain)\n        return self.format(msg, parameters)", "response": "Returns the translated message with the given id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the fallback locales.", "response": "def set_fallback_locales(self, locales):\n        \"\"\"\n        Sets the fallback locales.\n\n        @type locales: list[str]\n        @param locales: The falback locales\n\n        @raises: ValueError: If a locale contains invalid characters\n        \"\"\"\n        # needed as the fallback locales are linked to the already loaded\n        # catalogues\n        self.catalogues = {}\n\n        for locale in locales:\n            self._assert_valid_locale(locale)\n\n        self.fallback_locales = locales"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_resource(self, format, resource, locale, domain=None):\n        if domain is None:\n            domain = 'messages'\n\n        self._assert_valid_locale(locale)\n        self.resources[locale].append([format, resource, domain])\n        if locale in self.fallback_locales:\n            self.catalogues = {}\n        else:\n            self.catalogues.pop(locale, None)", "response": "Adds a resource to the set of available resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all messages for the given locale.", "response": "def get_messages(self, locale=None):\n        \"\"\"\n        Collects all messages for the given locale.\n\n        @type locale:  str|one\n        @param locale: Locale of translations, by default is current locale\n\n        @rtype: dict:\n        @return: dict indexed by catalog name\n        \"\"\"\n        if locale is None:\n            locale = self.locale\n\n        if locale not in self.catalogues:\n            self._load_catalogue(locale)\n\n        catalogues = [self.catalogues[locale]]\n        catalogue = catalogues[0]\n        while True:\n            catalogue = catalogue.fallback_catalogue\n            if catalogue is None:\n                break\n            catalogues.append(catalogue)\n\n        messages = {}\n        for catalogue in catalogues[::-1]:\n            recursive_update(messages, catalogue.all())\n\n        return messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trans(self, id, parameters=None, domain=None, locale=None):\n        if parameters is None:\n            parameters = {}\n\n        if locale is None:\n            locale = self.locale\n        else:\n            self._assert_valid_locale(locale)\n\n        if domain is None:\n            domain = 'messages'\n\n        catalogue = self.get_catalogue(locale)\n        if not catalogue.has(id, domain):\n            raise RuntimeError(\n                \"There is no translation for {0} in domain {1}\".format(\n                    id,\n                    domain\n                )\n            )\n\n        msg = self.get_catalogue(locale).get(id, domain)\n        return self.format(msg, parameters)", "response": "Returns a string representation of the message with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string that can be used to transchoice a message in a specific locale.", "response": "def transchoice(self, id, number, parameters=None, domain=None, locale=None):\n        \"\"\"\n        Raises a RuntimeError whenever a message is missing\n        @raises: RuntimeError\n        \"\"\"\n        if parameters is None:\n            parameters = {}\n\n        if locale is None:\n            locale = self.locale\n        else:\n            self._assert_valid_locale(locale)\n\n        if domain is None:\n            domain = 'messages'\n\n        catalogue = self.get_catalogue(locale)\n        while not catalogue.defines(id, domain):\n            cat = catalogue.fallback_catalogue\n            if cat:\n                catalogue = cat\n                locale = catalogue.locale\n            else:\n                break\n\n        if not catalogue.has(id, domain):\n            raise RuntimeError(\n                \"There is no translation for {0} in domain {1}\".format(\n                    id,\n                    domain\n                )\n            )\n\n        parameters['count'] = number\n        msg = selector.select_message(\n            catalogue.get(\n                id,\n                domain\n            ),\n            number,\n            locale\n        )\n        return self.format(msg, parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the message catalogue for the given locale.", "response": "def get_catalogue(self, locale):\n        \"\"\"\n        Reloads messages catalogue if requested after more than one second\n        since last reload\n        \"\"\"\n        if locale is None:\n            locale = self.locale\n\n        if locale not in self.catalogues or datetime.now() - self.last_reload > timedelta(seconds=1):\n            self._load_catalogue(locale)\n            self.last_reload = datetime.now()\n\n        return self.catalogues[locale]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget info about a particular GO term.", "response": "def get_go_info(goterm,result='name'):\n    \"\"\"\n    quickgo\n    result: 'name','definition','synonyms'\n    \n    {'numberOfHits': 1,\n 'results': [{'id': 'GO:0000006',\n   'isObsolete': False,\n   'name': 'high-affinity zinc transmembrane transporter activity',\n   'definition': {'text': 'Enables the transfer of zinc ions (Zn2+) from one side of a membrane to the other, probably powered by proton motive force. In high-affinity transport the transporter is able to bind the solute even if it is only present at very low concentrations.',\n    'xrefs': [{'dbCode': 'TC', 'dbId': '2.A.5.1.1'}]},\n   'synonyms': [{'name': 'high-affinity zinc uptake transmembrane transporter activity',\n     'type': 'related'},\n    {'name': 'high affinity zinc uptake transmembrane transporter activity',\n     'type': 'exact'}],\n   'aspect': 'molecular_function',\n   'usage': 'Unrestricted'}],\n 'pageInfo': None}\n    \"\"\"\n    response=requests.get(f'https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/{goterm}')\n    try:       \n        return response.json()['results'][0][result]\n    except:\n        print(response.json())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds election_day to serializer context.", "response": "def get_serializer_context(self):\n        \"\"\"Adds ``election_day`` to serializer context.\"\"\"\n        context = super(SpecialMixin, self).get_serializer_context()\n        context['election_date'] = self.kwargs['date']\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether given object is a method.", "response": "def is_method(arg):\n    \"\"\"Checks whether given object is a method.\"\"\"\n    if inspect.ismethod(arg):\n        return True\n    if isinstance(arg, NonInstanceMethod):\n        return True\n\n    # Unfortunately, there is no disctinction between instance methods\n    # that are yet to become part of a class, and regular functions.\n    # We attempt to evade this little gray zone by relying on extremely strong\n    # convention (which is nevertheless _not_ enforced by the intepreter)\n    # that first argument of an instance method must be always named ``self``.\n    if inspect.isfunction(arg):\n        return _get_first_arg_name(arg) == 'self'\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ask(self, answers=None):\n        if answers is None:\n            answers = {}\n        _answers = {}\n        if self.multiple:\n            print((bold('Multiple answers are supported for this question.  ' +\n                        'Please enter a \".\"  character to finish.')))\n            _answers[self.value] = []\n            answer = self._ask(answers)\n            while answer is not None:\n                _answers[self.value].append(answer)\n                answer = self._ask(answers)\n        else:\n            _answers[self.value] = self._ask(answers)\n        if isinstance(self.validator, list):\n            for v in self.validator:\n                _answers = dict(_answers, **v.hints())\n        else:\n            _answers = dict(_answers, **self.validator.hints())\n        for q in self._questions:\n            answers = dict(answers, **_answers)\n            _answers = dict(_answers, **q.ask(answers))\n        return _answers", "response": "Ask the question then ask any sub - questions. This returns a dict with the value and answer pairs for the current\n            question plus all descendant questions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, answer):\n        if answer is None:\n            return False\n        else:\n            if isinstance(self.validator, list):\n                for v in self.validator:\n                    if not v.validate(answer):\n                        return False\n                return True\n            else:\n                return self.validator.validate(answer)", "response": "Validate the answer with our Validator class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef answer(self):\n        if isinstance(self.validator, list):\n            return self.validator[0].choice()\n        return self.validator.choice()", "response": "Return the answer for the question from the validator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting the choices for this question.", "response": "def choices(self):\n        \"\"\" Print the choices for this question.\n\n            This may be a empty string and in the case of a list of validators\n            we will only show the first validator's choices.\n        \"\"\"\n        if isinstance(self.validator, list):\n            return self.validator[0].print_choices()\n        return self.validator.print_choices()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qj(x='',  # pylint: disable=invalid-name\n       s='',\n       l=None,\n       d=False,\n       p=False,\n       t=False,\n       n=False,\n       r=_QJ_R_MAGIC,\n       z=False,\n       b=True,\n       pad=False,\n       tfc=False,\n       tic=False,\n       toc=False,\n       time=False,\n       catch=False,\n       log_all_calls=False,\n       _depth=1):\n  \"\"\"A combined logging and debugging function.\n\n  Arguments:\n    x: The thing to log. x is also the return value. Defaults to '', although\n       it's somewhat odd to call this function without passing x.\n    s: Optional string to prefix the log message with. Defaults to '', which\n       results in the function prefixing the log with the source code at the\n       call site, or the type of x if it can't extract the source code.\n    l: Optional lambda to be run after logging x. Allows useful things like\n       inspecting other variables in the current context when x gets logged. Its\n       return value is logged immediately after x is logged. Defaults to None.\n    d: Optional bool to drop into the debugger if x is logged. Defaults to\n       False.\n    p: Optional bool to log the public properties of x, including basic call\n       signatures of functions, if x is logged.\n    t: Optional bool to wrap x in a tensorflow.Print call. If x is a Tensor,\n       its value will be printed at graph execution time. The tensorflow.Print\n       calls will be prefixed with the value in s, or qj's default logging\n       prefix, just like any other qj log message. It also sets the\n       tensorflow.Print call to only print qj.MAX_FRAME_LOGS times, so that\n       it isn't too spammy when running the graph. The call attempts to validate\n       that tensorflow is available and that x can be passed to tensorflow.Print\n       before calling tensorflow.Print.\n    n: Optional bool to log the shape, min, mean, and max values of x if numpy\n       is available.\n    r: Optional alternate return value to use instead of x if x is logged. Any\n       value passed to r will be returned (even None). Only the private value\n       _QJ_R_MAGIC is ignored.\n    z: Optional bool to zero out the frame count in the current frame, so that\n       logging continues. Most useful when using qj in colabs at the top\n       (module) level, since that stack frame effectively lives forever.\n       Defaults to False.\n    b: Optional bool to enable or disable the logging of x. Defaults to True (so\n       that x is logged, assuming other conditions don't prevent logging).\n    pad: Optional bool to add padding blank lines before and after the logs.\n       Useful for visually extracting particular logs.\n    tfc: Optional bool to wrap x in a tensorflow.check_numerics call if x is a\n       Tensor.\n    tic: Optional bool to begin recording a duration.\n    toc: Optional bool to end recording a duration started with a previous\n       `tic`. Logs the corresponding duration if there was a previous `tic`.\n       `tic` and `toc` can be set in the same call -- `toc` is handled first,\n       which allows you to measure the body of a loop or comprehension with a\n       single call to `qj(tic=1, toc=1)`.\n    time: Optional bool to turn on timing of a function call. Can be used as a\n       decorator.  E.g., `@qj(time=100) def foo()...` will print timing stats\n       every 100 calls to foo.\n    catch: Optional bool to decorate a function with exception catching that\n       drops into the debugger.\n    log_all_calls: Optional bool to wrap x in a new object that logs every call\n       to x.  Experimental.\n    _depth: Private parameter used to specify which stack frame should be used\n            for both logging and debugging operations. If you're not wrapping\n            qj or adding features to qj, you should leave this at it's default.\n\n  Returns:\n    x, which allows you to insert a call to qj just about anywhere.\n  \"\"\"\n  if qj.LOG and b:\n    try:\n      # Compute and collect values needed for logging.\n      # We need the caller's stack frame both for logging the function name and\n      # line number qj was called from, and to store some state that makes the\n      # more magical features work.\n      f = inspect.currentframe()\n      for _ in range(_depth):\n        f = f.f_back\n\n      # This is the magic dictionary where we write state that gives log output\n      # that can represent the underlying function's code structure, as well as\n      # tracking how many times we logged from the stack frame, which allows us\n      # to minimize log spam from logs in loops and comprehensions.\n      qj_dict = f.f_locals.get('__qj_magic_wocha_doin__', {})\n      qj_dict = {} if z else qj_dict\n      log_count_key = 'frame_log_count_%d' % f.f_lasti\n      qj_dict[log_count_key] = qj_dict.get(log_count_key, 0) + 1\n\n      if qj_dict[log_count_key] > qj.MAX_FRAME_LOGS:\n        return x\n\n      # We're going to log things, so go ahead and collect information about the\n      # caller's stack frame.\n      func_name = qj_dict.get('func_name')\n      if func_name is None:\n        func_name = inspect.getframeinfo(f).function\n        if func_name == '<dictcomp>':\n          func_name = inspect.getframeinfo(f.f_back).function\n        if func_name == '<genexpr>':\n          func_name = inspect.getframeinfo(f.f_back).function\n        if func_name == '<listcomp>':\n          func_name = inspect.getframeinfo(f.f_back).function\n        elif func_name == '<setcomp>':\n          func_name = inspect.getframeinfo(f.f_back).function\n        elif func_name == '<lambda>':\n          func_name = inspect.getframeinfo(f.f_back).function + '.lambda'\n        if func_name.startswith('<module>'):\n          func_name = func_name.replace('<module>', 'module_level_code')\n\n        filename = os.path.basename(f.f_code.co_filename)\n        # Don't include the filename when logging in ipython contexts.\n        if filename[0] != '<':\n          filename = filename.replace('.py', '')\n          func_name = '<{}> {}'.format(filename, func_name)\n        qj_dict['func_name'] = func_name\n\n      # If we are dealing with module-level code, don't limit logging, since\n      # large amounts of module-level logs generally means we're running in a\n      # colab, and it's annoying to have your logs suddenly stop after k runs.\n      if 'module_level_code' in func_name:\n        qj_dict[log_count_key] = 1\n\n      # This is the magic that allows us to indent the logs in a sensible\n      # manner. f_lasti is the last instruction index executed in the frame\n      # (i.e., the instruction that executed the call to qj). We add each\n      # instruction index into the dictionary, setting the value to the length\n      # of the dictionary after that addition, so the first instruction we see\n      # gets a value of 1, the second a value of 2, etc.\n      qj_instructions_dict = qj_dict.get('instructions', {})\n      qj_dict['instructions'] = qj_instructions_dict\n      qj_instructions_dict[f.f_lasti] = qj_instructions_dict.get(\n          f.f_lasti, len(qj_instructions_dict) + 1)\n      # Here, we use that value to determine how many spaces we need after the\n      # log prefix.\n      spaces = ' ' * qj_instructions_dict[f.f_lasti]\n      # And we store the dictionary back in the caller's frame.\n      f.f_locals['__qj_magic_wocha_doin__'] = qj_dict\n\n      # Try to extract the source code of this call if a string wasn't specified.\n      if not s:\n        try:\n          code_key = '%s:%r:%s' % (f.f_code.co_filename, f.f_code.co_firstlineno, f.f_code.co_code)\n          fn_calls = qj._FN_MAPS.get(code_key, {})\n          if f.f_lasti not in fn_calls:\n            qj._DEBUG_QJ and qj._DISASSEMBLE_FN(f.f_code, f.f_lasti)\n            fn_calls[f.f_lasti] = _find_current_fn_call(f.f_code, f.f_lasti)\n            qj._FN_MAPS[f.f_code.co_code] = fn_calls\n          s = fn_calls.setdefault(f.f_lasti, '').strip()\n        except IOError:\n          # Couldn't get the source code, fall back to showing the type.\n          s = ''\n\n      # Now that we've computed the call count and the indentation, we can log.\n      prefix = '%s:%s%s <%d>:' % (func_name, spaces, s or type(x), f.f_lineno)\n      log = ''\n\n      # First handle parameters that might change how x is logged.\n      if n and 'numpy' in sys.modules:\n        try:\n          np = sys.modules['numpy']\n          np_x = np.array(x)\n          log = str((np_x.shape, (np.min(np_x),\n                                  (np.mean(np_x), np.std(np_x)),\n                                  np.max(np_x)),\n                     np.histogram(np_x,\n                                  bins=max(int(n),\n                                           min(np.prod(np_x.shape), 5)))[0]\n                    ))\n          s = s or str(type(x))\n          s += ' (shape (min (mean std) max) hist)'\n          prefix = '%s:%s%s <%d>:' % (func_name, spaces, s, f.f_lineno)\n        except:  # pylint: disable=bare-except\n          pass\n\n      if tic and x is '':\n        log = 'Adding tic.'\n\n      # toc needs to be processed after tic here so that the log messages make sense\n      # when using tic/toc in a single call in a loop.\n      if toc and x is '':\n        if len(qj._tics):  # pylint: disable=g-explicit-length-test\n          log = 'Computing toc.'\n        else:\n          log = 'Unable to compute toc -- no unmatched tic.'\n          toc = False\n\n      if time and x is '':\n        log = 'Preparing decorator to measure timing...' + ('\\n%s' % log if log else '')\n\n      if catch and x is '':\n        log = 'Preparing decorator to catch exceptions...' + ('\\n%s' % log if log else '')\n\n      # Now, either we have set the log message, or we are ready to build it directly from x.\n      if not log:\n        log = qj.STR_FN(x)\n      log = '(multiline log follows)\\n%s' % log if '\\n' in log else log\n\n      padding_string = ''\n      if pad:\n        if isinstance(pad, str):\n          # Turn pad into a character string with no newlines as long as the\n          # log string.\n          log_len = (len(qj.PREFIX) + len(prefix.split('\\n')[-1]) +\n                     len(log.split('\\n')[0]) + 1)\n          padding_string = (pad.replace('\\n', ' ') * log_len)[:log_len]\n        else:\n          try:\n            padding_string = '\\n' * (int(pad) - 1) + ' '\n          except ValueError:\n            padding_string = '\\n'\n\n      if padding_string:\n        qj.LOG_FN(padding_string)\n\n      # Log the primary log message.\n      qj.LOG_FN('%s%s %s%s' % (qj.PREFIX, prefix, qj._COLOR_LOG(), log))\n\n      # If there's a lambda, run it and log it.\n      if l:\n        log = qj.STR_FN(l(x))\n        log = '(multiline log follows)\\n%s' % log if '\\n' in log else log\n        qj.LOG_FN('%s%s %s%s' % (qj.PREFIX, ' ' * len(prefix), qj._COLOR_LOG(),\n                                 log))\n\n      # If we requested x's properties, compute them and log them.\n      if p:\n        try:\n          if hasattr(inspect, 'signature'):\n            argspec_func = lambda f: str(inspect.signature(f))\n          else:\n            argspec_func = lambda f: inspect.formatargspec(*inspect.getargspec(f))\n          docs = [\n              '%s%s' % (n,\n                        argspec_func(v)\n                        if inspect.isroutine(v) and not inspect.isbuiltin(v)\n                        else '')\n              for n, v in inspect.getmembers(x)\n              if n == '__init__' or not n.startswith('_')\n          ]\n        except:  # pylint: disable=bare-except\n          docs = [n for n in dir(x) if not n.startswith('_')]\n        prefix_spaces = ' ' * len(prefix)\n        qj.LOG_FN('%s%s %sPublic properties:\\n    %s' %\n                  (qj.PREFIX, prefix_spaces, qj._COLOR_LOG(), '\\n    '.join(docs)))\n\n      # If we requested tensorflow printing, wrap x in a tf.Print.\n      if t:\n        if (hasattr(x, '__module__') and\n            'tensorflow' in x.__module__ and\n            'tensorflow' in sys.modules):\n          tf = sys.modules['tensorflow']\n          prefix_spaces = ' ' * len(prefix)\n          if 'session' in x.__module__:\n            try:\n              # pylint: disable=g-import-not-at-top\n              try:\n                from tensorflow.python import debug as tf_debug\n              except ImportError:\n                from google3.third_party.tensorflow.python import debug as tf_debug\n              # pylint: enable=g-import-not-at-top\n              x = tf_debug.LocalCLIDebugWrapperSession(x)\n              x.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n\n              qj.LOG_FN('%s%s %sWrapping tf session in tfdbg session.' %\n                        (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n            except:  # pylint: disable=bare-except\n              qj.LOG_FN('%s%s %sUnable to wrap tf session in tfdbg session. '\n                        'Make sure your BUILD rule depends on '\n                        '//tensorflow/python/debug:debug_py.' %\n                        (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n          else:\n            qj.LOG_FN('%s%s %sWrapping return value in tf.Print operation.' %\n                      (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n            x = tf.Print(\n                x, [tf.shape(x), x],\n                message='%s%s%s%s' % (qj._COLOR_PREFIX(), qj.PREFIX, prefix[:-1],\n                                      qj._COLOR_END()),\n                first_n=qj.MAX_FRAME_LOGS if t is True else int(t),\n                summarize=qj.MAX_FRAME_LOGS,\n                name='qj_print_%s_%d_%s' % (\n                    func_name.split(' ')[-1], f.f_lineno,\n                    x.name.replace('/', '_').replace(':', '_') if hasattr(x, 'name') else ''))\n\n      if tfc:\n        if (hasattr(x, '__module__') and\n            'tensorflow' in x.__module__ and\n            'tensorflow' in sys.modules):\n          tf = sys.modules['tensorflow']\n          prefix_spaces = ' ' * len(prefix)\n          qj.LOG_FN('%s%s %sWrapping return value in tf.check_numerics.' %\n                    (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n          x = tf.check_numerics(\n              x,\n              message='%s%s%s%s' % (\n                  qj._COLOR_PREFIX(), qj.PREFIX, prefix[:-1], qj._COLOR_END()),\n              name='qj_check_numerics_%s_%d_%s' % (\n                  func_name.split(' ')[-1], f.f_lineno,\n                  x.name.replace('/', '_').replace(':', '_') if hasattr(x, 'name') else ''))\n\n      # toc needs to be processed before tic, so that single call tic/toc works in loops.\n      if toc:\n        if len(qj._tics):  # pylint: disable=g-explicit-length-test\n          prefix_spaces = ' ' * len(prefix)\n          toc = int(toc)\n          if toc < 0:\n            toc = len(qj._tics)\n          toc = min(toc, len(qj._tics))\n          toc_time = _time.time()\n          for _ in range(toc):\n            tic_ = qj._tics.pop()\n            qj.LOG_FN('%s%s %s%.4f seconds since %s.' %\n                      (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces, toc_time - tic_[1], tic_[0]))\n\n      if tic:\n        tic_ = (s, _time.time())\n        qj._tics.append(tic_)\n        if x is not '':\n          prefix_spaces = ' ' * len(prefix)\n          qj.LOG_FN('%s%s %sAdded tic.' %\n                    (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n\n      if time:\n        prefix_spaces = ' ' * len(prefix)\n        if isinstance(x, types.FunctionType):\n          qj.LOG_FN('%s%s %sWrapping return value in timing function.' %\n                    (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n          # pylint: disable=no-value-for-parameter\n          x = _timing(logs_every=int(time))(x)\n          # pylint: enable=no-value-for-parameter\n        elif x is '':\n          # x is '', so we'll assume it's the default value and we're decorating\n          # a function\n          x = lambda f: (\n              (qj.LOG_FN('%s%s %sDecorating %s with timing function.' %\n                         (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces, str(f)))\n               and False)\n              # pylint: disable=no-value-for-parameter\n              or _timing(logs_every=int(time))(f))\n          # pylint: enable=no-value-for-parameter\n\n      if catch:\n        prefix_spaces = ' ' * len(prefix)\n        if isinstance(x, types.FunctionType):\n          qj.LOG_FN('%s%s %sWrapping return value in exception function.' %\n                    (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n          # pylint: disable=no-value-for-parameter\n          x = _catch(exception_type=catch)(x)\n          # pylint: enable=no-value-for-parameter\n        elif x is '':\n          # x is '', so we'll assume it's the default value and we're decorating\n          # a function\n          x = lambda f: (\n              (qj.LOG_FN('%s%s %sDecorating %s with exception function.' %\n                         (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces, str(f)))\n               and False)\n              # pylint: disable=no-value-for-parameter\n              or _catch(exception_type=catch)(f))\n          # pylint: enable=no-value-for-parameter\n\n      if log_all_calls:\n        prefix_spaces = ' ' * len(prefix)\n        qj.LOG_FN('%s%s %sWrapping all public method calls for object.' %\n                  (qj.PREFIX, qj._COLOR_LOG(), prefix_spaces))\n\n        def wrap(member_name, member_fn):\n          \"\"\"Wrap member_fn in a lambda that logs.\"\"\"\n          wrapped = (lambda *a, **kw:\n                     qj('%s(%s)' % (member_name,\n                                    ', '.join(['%r' % a_ for a_ in a]\n                                              + ['%s=%r' % (k, v) for k, v in kw.items()])),\n                        'calling %s' % member_name, _depth=2)\n                     and qj(member_fn(*a, **kw),\n                            'returning from %s' % member_name, _depth=2))\n          if hasattr(member_fn, '__doc__'):\n            wrapped.__doc__ = member_fn.__doc__\n          return wrapped\n\n        class Wrapper(type(x)):\n\n          def __init__(self, x):\n            method_types = (\n                types.BuiltinFunctionType, types.BuiltinMethodType,\n                types.FunctionType, types.LambdaType, types.MethodType\n            )\n            for m in inspect.getmembers(x):\n              name = m[0]\n              if not name.startswith('_'):\n                member = m[1]\n                if isinstance(member, method_types):\n                  wrapped_fn = wrap(name, member)\n                  setattr(self, name, wrapped_fn)\n                else:\n                  # pylint: disable=line-too-long\n                  # TODO(iansf): This may be wrong. See\n                  #              https://stackoverflow.com/questions/1325673/how-to-add-property-to-a-class-dynamically\n                  # pylint: enable=line-too-long\n                  setattr(self.__class__, name, member)\n\n        x = Wrapper(x)\n\n      # If we requested an alternative return value, log it.\n      if r != _QJ_R_MAGIC:\n        prefix = '%s:%s%s <%d>:' % (func_name, spaces, s or type(r), f.f_lineno)\n        prefix_spaces = ' ' * len(prefix)\n        log = qj.STR_FN(r)\n        log = '(multiline log follows)\\n%s' % log if '\\n' in log else log\n        qj.LOG_FN('%s%s %sOverridden return value: %s' % (qj.PREFIX, prefix_spaces,\n                                                          qj._COLOR_LOG(), log))\n\n      if padding_string:\n        qj.LOG_FN(padding_string)\n\n      # vvvvvvvv NO LOGS PERMITTED AFTER THIS BLOCK vvvvvvvv\n      if qj_dict[log_count_key] == qj.MAX_FRAME_LOGS:\n        qj.LOG_FN('%s%s:%s%sMaximum per-frame logging hit (%d). '\n                  'No more logs will print at this call within this stack frame. '\n                  'Set qj.MAX_FRAME_LOGS to change the limit or pass z=1 to this qj call '\n                  'to zero out the frame log count.' %\n                  (qj.PREFIX, func_name, spaces, qj._COLOR_LOG(),\n                   qj.MAX_FRAME_LOGS))\n      # ^^^^^^^^ NO LOGS PERMITTED AFTER THIS BLOCK ^^^^^^^^\n\n      # If we requested debugging, drop into the debugger.\n      if d:\n        if not qj.DEBUG_FN:\n          try:\n            from colabtools import _debugger  # pylint: disable=g-import-not-at-top\n            qj.DEBUG_FN = lambda frame: _debugger.ColabPdb().set_trace(frame=frame)\n          except ImportError:\n            try:\n              # Import ipdb here because importing it at the top slows down execution.\n              import ipdb  # pylint: disable=g-import-not-at-top\n              qj.DEBUG_FN = ipdb.set_trace\n            except ImportError:\n              import pdb  # pylint: disable=g-import-not-at-top\n              qj.DEBUG_FN = lambda frame: pdb.Pdb().set_trace(frame=frame)\n        qj.DEBUG_FN(frame=f)\n\n      # If we requested an alternative return value, return it now that\n      # everything else is done.\n      if r != _QJ_R_MAGIC:\n        return r\n\n    finally:\n      # Delete the stack frame to ensure there are no memory leaks, as suggested\n      # by https://docs.python.org/2/library/inspect.html#the-interpreter-stack\n      del f\n\n  # After everything else is done, return x.\n  return x", "response": "A combined logging and debugging function for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _catch(f, exception_type):\n  if not (inspect.isclass(exception_type)\n          and issubclass(exception_type, Exception)):\n    exception_type = Exception\n\n  @functools.wraps(f)\n  def wrap(*args, **kw):\n    try:\n      return f(*args, **kw)\n    except exception_type as e:  # pylint: disable=broad-except\n      qj(e, 'Caught an exception in %s' % f, d=1, _depth=2)\n  return wrap", "response": "Decorator to drop into the debugger if a function throws an exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisassemble a code object.", "response": "def _disassemble3(co, lasti):\n    \"\"\"Disassemble a code object.\"\"\"\n    cell_names = co.co_cellvars + co.co_freevars\n    linestarts = dict(dis.findlinestarts(co))\n    _disassemble_bytes(co.co_code, lasti, co.co_varnames, co.co_names,\n                       co.co_consts, cell_names, linestarts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stack_effect3(op_code, oparg):\n  if op_code == 'UNPACK_SEQUENCE':\n    return oparg - 1\n  if op_code == 'UNPACK_EX':\n    return (oparg & 0xFF) + (oparg >> 8)\n  if op_code == 'BUILD_TUPLE':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_LIST':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_SET':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_STRING':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_LIST_UNPACK':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_TUPLE_UNPACK':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_TUPLE_UNPACK_WITH_CALL':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_SET_UNPACK':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_MAP_UNPACK':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_MAP_UNPACK_WITH_CALL':\n    return -oparg  # Was 1 - oparg\n  if op_code == 'BUILD_MAP':\n    return -2 * oparg  # Was 1 - 2 * oparg\n  if op_code == 'BUILD_CONST_KEY_MAP':\n    return -oparg\n  if op_code == 'RAISE_VARARGS':\n    return -oparg\n  if op_code == 'CALL_FUNCTION':\n    return -oparg\n  if op_code == 'CALL_FUNCTION_KW':\n    return -oparg - 1\n  if op_code == 'CALL_FUNCTION_EX':\n    return -((oparg & 0x01) != 0) - ((oparg & 0x02) != 0)\n  if op_code == 'MAKE_FUNCTION':\n    return -1 - ((oparg & 0x01) != 0) - ((oparg & 0x02) != 0) - ((oparg & 0x04) != 0) - ((oparg & 0x08) != 0)\n  if op_code == 'BUILD_SLICE':\n    return -2 if (oparg == 3) else -1\n  if op_code == 'FORMAT_VALUE':\n    # If there's a fmt_spec on the stack we go from 2->1 else 1->1.\n    return -1 if (oparg & FVS_MASK) == FVS_HAVE_SPEC else 0\n  if op_code == 'EXTENDED_ARG':\n    return 0  # EXTENDED_ARG just builds up a longer argument value for the next instruction (there may be multiple in a row?)\n\n  return _STACK_EFFECTS3[op_code]", "response": "Compute the effect an op_code and oparg have on the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _findlinestarts(code):\n  byte_increments = [ord(c) for c in code.co_lnotab[0::2]]\n  line_increments = [ord(c) for c in code.co_lnotab[1::2]]\n\n  lastlineno = None\n  lineno = code.co_firstlineno\n  addr = 0\n  for byte_incr, line_incr in zip(byte_increments, line_increments):\n    if byte_incr:\n      if lineno != lastlineno:\n        yield (addr, lineno)\n        lastlineno = lineno\n      addr += byte_incr\n    lineno += line_incr\n  if lineno != lastlineno:\n    yield (addr, lineno)", "response": "Find the offsets in a byte code which are start of lines in the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stack_effect(op_code, oparg):\n  n_args = lambda o: (o % 256) + 2 * (o // 256)\n\n  if op_code == 'DUP_TOPX':\n    return oparg\n  elif op_code == 'UNPACK_SEQUENCE':\n    return oparg - 1\n  elif op_code == 'BUILD_TUPLE':\n    return -oparg  # Was 1 - oparg\n  elif op_code == 'BUILD_LIST':\n    return -oparg  # Was 1 - oparg\n  elif op_code == 'BUILD_SET':\n    return -oparg  # Was 1 - oparg\n  elif op_code == 'RAISE_VARARGS':\n    return -oparg\n  elif op_code == 'CALL_FUNCTION':\n    return -n_args(oparg)  # args + (#kwargs << 8)\n  elif op_code == 'CALL_FUNCTION_VAR':\n    return -n_args(oparg) - 1  # args + (#kwargs << 8)\n  elif op_code == 'CALL_FUNCTION_KW':\n    return -n_args(oparg) - 1  # args + (#kwargs << 8)\n  elif op_code == 'CALL_FUNCTION_VAR_KW':\n    return -n_args(oparg) - 2  # args + (#kwargs << 8)\n  elif op_code == 'MAKE_FUNCTION':\n    return -oparg\n  elif op_code == 'BUILD_SLICE':\n    if oparg == 3:\n      return -2\n    else:\n      return -1\n  elif op_code == 'MAKE_CLOSURE':\n    return -oparg - 1\n\n  return _STACK_EFFECTS[op_code]", "response": "Compute the effect an op_code and oparg have on the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds commas and equals as appropriate to function argument lists in the stack.", "response": "def _annotate_fn_args(stack, fn_opname, nargs, nkw=-1, consume_fn_name=True):\n  \"\"\"Add commas and equals as appropriate to function argument lists in the stack.\"\"\"\n  kwarg_names = []\n  if nkw == -1:\n    if sys.version_info[0] < 3:\n      # Compute nkw and nargs from nargs for python 2.7\n      nargs, nkw = (nargs % 256, 2 * nargs // 256)\n    else:\n      if fn_opname == 'CALL_FUNCTION_KW':\n        if qj._DEBUG_QJ:\n          assert len(stack) and stack[-1].opname == 'LOAD_CONST'\n        if not len(stack) or stack[-1].opname != 'LOAD_CONST':\n          return\n        se = stack.pop()\n        kwarg_names = se.oparg_repr[::-1]\n        se.oparg_repr = ['']\n        nkw = len(kwarg_names)\n        nargs -= nkw\n        if qj._DEBUG_QJ:\n          assert nargs >= 0 and nkw > 0\n      else:\n        nkw = 0\n\n  for i in range(nkw):\n    se = stack.pop()\n    if se.stack_depth == 0 and (len(se.oparg_repr) == 0 or se.oparg_repr[0] == ''):\n      # Skip stack entries that don't have any effect on the stack\n      continue\n    if i % 2 == 1 and sys.version_info[0] < 3:\n      if qj._DEBUG_QJ:\n        assert se.opname == 'LOAD_CONST'\n      if se.opname == 'LOAD_CONST':\n        # kwargs are pairs of key=value in code\n        se.oparg_repr += ['=']\n    else:\n      pops = []\n      if se.opname.startswith('CALL_FUNCTION'):\n        _annotate_fn_args(stack[:], se.opname, se.oparg, -1, True)\n      pops = _collect_pops(stack, se.stack_depth - 1 if se.opname.startswith('CALL_FUNCTION') else 0, [], False)\n      if i > 1 and len(pops):\n        pops[-1].oparg_repr += [',']\n      if sys.version_info[0] >= 3:\n        target_se = pops[-1] if len(pops) else se\n        target_se.oparg_repr = [kwarg_names[i], '='] + target_se.oparg_repr\n\n  for i in range(nargs):\n    se = stack.pop()\n    if se.opname.startswith('CALL_FUNCTION'):\n      _annotate_fn_args(stack, se.opname, se.oparg, -1, True)\n    elif len(se.oparg_repr) and se.oparg_repr[0] in {']', '}', ')'}:\n      if (i > 0 or nkw > 0):\n        se.oparg_repr += [',']\n    else:\n      pops = _collect_pops(stack, se.stack_depth, [], False)\n      if (i > 0 or nkw > 0) and len(pops):\n        pops[-1].oparg_repr += [',']\n\n  if consume_fn_name:\n    _collect_pops(stack, -1, [], False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_current_fn_call(co, lasti):\n  qj._DEBUG_QJ and qj.LOG_FN('co = {}'.format(co))\n\n  if sys.version_info[0] < 3:\n    stack = _build_instruction_stack(co, lasti)\n  else:\n    stack = _build_instruction_stack3(co, lasti)\n\n  source_lines, source_offset = inspect.getsourcelines(co)\n  source_lines = [l.strip() for l in source_lines]\n\n  # Apply stack effects backwards until we arrive at the stack entries for a complete function call\n  fn_stack = _collect_pops(stack[:-1], stack[-1].stack_depth, [], 0)\n\n  if not fn_stack and stack[-1].stack_depth == 0:\n    # The function call took 0 arguments, so return early with a special string.\n    return '<empty log>'\n\n  qj._DEBUG_QJ and qj.LOG_FN('collected fn_stack:\\n%s\\n\\n' % '\\n'.join(str(se) for se in fn_stack))\n\n  # Prepare to annotate the stack with extra symbols, and filter out MAKE_FUNCTION and MAKE_CLOSURE calls, which are no longer needed.\n  annotate_stack = [se for se in fn_stack if not se.opname.startswith('MAKE_')]\n  annotate_stack.reverse()\n  _annotate_fn_args(annotate_stack, stack[-1].opname, stack[-1].oparg, -1, False)\n\n  qj._DEBUG_QJ and qj.LOG_FN('annotated fn_stack:\\n%s\\n\\n' % '\\n'.join(str(se) for se in fn_stack))\n\n  # Find the range of lines to search over.\n  min_l = stack[-1].curr_l\n  max_l = stack[0].curr_l\n  for se in fn_stack:\n    min_l = min(min_l, se.curr_l)\n    max_l = max(max_l, se.curr_l)\n\n  qj._DEBUG_QJ and qj.LOG_FN('source lines range: %d -> %d (indices: %d, %d)' % (min_l, max_l, min_l - source_offset, max_l - source_offset + 1))\n  source_chunk = ' '.join(\n      [l for l in source_lines[min_l - source_offset:max_l - source_offset + 1] if l and not l.startswith('#')])\n\n  qj._DEBUG_QJ and qj.LOG_FN('source_chunk: %r' % source_chunk)\n\n  # Build up all of the tokens for the function call.\n  tokens = []\n  for se in fn_stack:\n    opname = se.opname\n    for oparg_repr in se.oparg_repr[::-1]:\n      # Clean up the tokens\n      if not oparg_repr:\n        continue\n      oparg_repr = re.escape(oparg_repr.replace('\\n', '\\\\n'))\n      tokens.append(oparg_repr)\n\n  tokens.reverse()\n  qj._DEBUG_QJ and qj.LOG_FN('extracted tokens: {}'.format(tokens))\n  if qj._DEBUG_QJ:\n    assert tokens\n\n  # Add tokens for the function call we're extracting.\n  tokens = ['\\\\('] + tokens + ['\\\\)']\n\n  reg = '\\b*?.*?\\b*?'.join(tokens)\n  qj._DEBUG_QJ and qj.LOG_FN(reg)\n\n  # Search for the function call using the full set of tokens.\n  # Expand the search with source lines after the current set if we don't find a match.\n  shortest_match = None\n  match_attempts = 0\n  max_match_attempts = 10\n  while not shortest_match and match_attempts < max_match_attempts:\n    (shortest_match, _, _) = (\n        _find_earliest_shortest_match(source_chunk, reg, 0, len(source_chunk), num_attempts=10))\n    if not shortest_match:\n      match_attempts += 1\n\n      min_l -= 1\n      prev_line = ''\n      while not prev_line and min_l - source_offset >= 0 and min_l - source_offset < len(source_lines):\n        prev_line = source_lines[min_l - source_offset]\n        if prev_line.startswith('#'):\n          prev_line = ''\n        if not prev_line:\n          min_l -= 1\n      prev_line += ' ' if prev_line else ''\n      source_chunk = prev_line + source_chunk\n\n      max_l += 1\n      next_line = ''\n      while not next_line and max_l - source_offset >= 0 and max_l - source_offset < len(source_lines):\n        next_line = source_lines[max_l - source_offset]\n        if next_line.startswith('#'):\n          next_line = ''\n        if not next_line:\n          max_l += 1\n      next_line = (' ' if next_line else '') + next_line\n      source_chunk += next_line\n\n  # Return the string for the function call\n  if qj._DEBUG_QJ:\n    assert shortest_match\n  if shortest_match is not None:\n    match = shortest_match.group(0)\n    if qj._DEBUG_QJ:\n      assert match.startswith('(') and match.endswith(')')\n    # Do some parentheses cleanup.\n    if match.startswith('('):\n      match = match[1:]\n    lparens = match.count('(')\n    rparens = match.count(')')\n    if lparens > rparens:\n      match += ')' * (lparens - rparens)\n    elif lparens < rparens:\n      rparens_to_remove = rparens - lparens\n      while len(match) and match[-1] == ')' and rparens_to_remove > 0:\n        match = match[:-1]\n        rparens_to_remove -= 1\n    match = match.strip()\n    return match\n  else:\n    return ''", "response": "Find the current function call in the byte code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, msg, args):\n    elements = msg.split('-')\n    if len(elements) > 3 or len(elements) < 2:\n        send(\"Invalid CVE format\")\n        return\n    # If there are three fields, ignore the first (we don't actually need to send CVE-\n    if len(elements) == 3:\n        if elements[0].upper() != 'CVE':\n            send(\"Invalid CVE format\")\n            return\n        elements.pop(0)\n    # The first digit field should be exactly four digits long, the second is 4+\n    if not re.search(r\"^[\\d]{4}$\", elements[0]) or not re.search(r\"^[\\d]{4,}$\", elements[1]):\n        send(\"Invalid CVE format\")\n        return\n    search = \"%s-%s\" % (elements[0], elements[1])\n    url = 'http://cve.mitre.org/cgi-bin/cvename.cgi?name=%s' % search\n    html = fromstring(get(url).text)\n    title = html.find(\".//title\").text.splitlines()[2]\n    if title.startswith('ERROR'):\n        output = 'Invalid CVE Number'\n    else:\n        key = args['config']['api']['bitlykey']\n        output = \"%s -- %s\" % (title, get_short(url, key))\n    send(output)", "response": "Gets info on a CVE id from MITRE s CVE database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_file_data(self, path):\n        _, ext = os.path.splitext(path)\n        # YAML files\n        if ext in ('.yml', '.yaml'):\n            try:\n                with open(path) as f:\n                    return yaml.safe_load(f)\n            except YAMLError as e:\n                raise ConfigParseError(path, e)\n        # JSON files\n        elif ext == '.json':\n            try:\n                return json.loads(open(path).read())\n            except ValueError as e:\n                raise ConfigParseError(path, e)\n        else:\n            raise ConfigParseError(path, TypeError(\"Unsupported file type {}\".format(ext)))", "response": "Reads the contents of the given configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to fetch a variable from the config and expects it to be strictly an int", "response": "def get_int(self, key, optional=False):\n        \"\"\"\n        Tries to fetch a variable from the config and expects it to be strictly an int\n        :param key: Variable to look for\n        :param optional: Whether to raise ConfigKeyNotFoundError if key was not found.\n        :return: int\n        \"\"\"\n        return self._get_typed_value(key, int, lambda x: int(x), optional)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_float(self, key, optional=False):\n        return self._get_typed_value(key, float, lambda x: float(x), optional)", "response": "Tries to fetch a variable from the config and expects it to be strictly a float"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to fetch a variable from the config and expects it to be a truthy value.", "response": "def get_boolean(self, key, optional=False):\n        \"\"\"\n        Tries to fetch a variable from the config and expects it to be a truthy value. This could be a string (\"1\", \"Y\")\n        or an actual boolean. This is because we use the strtobool function in the case we find a string. The function\n        strtobool expects values of the form (\"1\", \"Y\", \"YES\", \"true\", \"True\", \"t\") and so forth for truthy values. The\n        variables populated from os env will always be strings, but we should make sure that we set expected boolean\n        variables to either truthy/falsy strings conforming to the pattern above or actual boolean values.\n        :param key: Variable to look for\n        :param optional: Whether to raise ConfigKeyNotFoundError if key was not found.\n        :return: bool\n        \"\"\"\n        return self._get_typed_value(key, bool, lambda x: bool(util.strtobool(x)), optional)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to fetch a string from the config and expects it to be a string.", "response": "def get_string(self, key, optional=False):\n        \"\"\"\n        Tries to fetch a variable from the config and expects it to be a string\n        :param key: The variable to search for in a possible list of configs\n        :param optional: Whether to raise ConfigKeyNotFoundError if key was not found.\n        :return: str string\n        \"\"\"\n        return self._get_typed_value(key, str, lambda x: str(x), optional)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_string_list(self, key, optional=False):\n        try:\n            return self._get_typed_value(key, list, lambda x: x.splitlines(), optional)\n        except ConfigTypeError:\n            s = self.get_string(key, optional)\n            return s.splitlines() if s else []", "response": "Tries to fetch a string which could be composed of multiple lines with each line having some sort of\n        separator. If the string could not be fetched it will return None. If the string could not be fetched it will return an empty list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get(self, key):\n        for conf in self.configs:\n            if key in conf:\n                return conf[key]\n\n        raise ConfigKeyNotFoundError(key)", "response": "Internal method to retrieve a value from the list of config dictionaries that have been loaded into the list of configs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of a particular type from a particular key in the current configuration.", "response": "def _get_typed_value(self, key, target_type, type_convert, optional=False):\n        \"\"\"\n        Returns value converted to a particular target_type and raises a ConfigTypeError if we can't cast the value to\n        the expected type. Also propagates the error to the caller function 'get_<type>'. If optional was set, just\n        returns None if the variable is not found.\n        :param key: The variable to search for in the possible list of configs\n        :param target_type: The type we expect the variable or key to be in.\n        :param type_convert: A lambda expression that converts the key to the desired type.\n        :param optional: If we should raise a ConfigKeyNotFoundError when the key is not found at all.\n        :return: type_convert(value)\n        \"\"\"\n        try:\n            value = self._get(key)\n        except ConfigKeyNotFoundError:\n            if not optional:\n                # Propagate the ConfigKeyNotFoundError which was caught\n                raise\n            return None\n\n        if isinstance(value, basestring):\n            try:\n                return type_convert(value)\n            except ValueError:\n                raise ConfigTypeCastError(key, value, target_type)\n\n        if isinstance(value, target_type):\n            return value\n        raise ConfigTypeError(key, value, target_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_mediation_matrix(dsm):\n        cat = dsm.categories\n        ent = dsm.entities\n        size = dsm.size[0]\n\n        if not cat:\n            cat = ['appmodule'] * size\n\n        packages = [e.split('.')[0] for e in ent]\n\n        # define and initialize the mediation matrix\n        mediation_matrix = [[0 for _ in range(size)]\n                            for _ in range(size)]\n\n        for i in range(0, size):\n            for j in range(0, size):\n                if cat[i] == 'framework':\n                    if cat[j] == 'framework':\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                elif cat[i] == 'corelib':\n                    if (cat[j] in ('framework', 'corelib') or\n                            ent[i].startswith(packages[j] + '.') or\n                            i == j):\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                elif cat[i] == 'applib':\n                    if (cat[j] in ('framework', 'corelib', 'applib') or\n                            ent[i].startswith(packages[j] + '.') or\n                            i == j):\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                elif cat[i] == 'appmodule':\n                    # we cannot force an app module to import things from\n                    # the broker if the broker itself did not import anything\n                    if (cat[j] in ('framework', 'corelib',\n                                   'applib', 'broker', 'data') or\n                            ent[i].startswith(packages[j] + '.') or\n                            i == j):\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                elif cat[i] == 'broker':\n                    # we cannot force the broker to import things from\n                    # app modules if there is nothing to be imported.\n                    # also broker should be authorized to use third apps\n                    if (cat[j] in (\n                            'appmodule', 'corelib', 'framework') or\n                            ent[i].startswith(packages[j] + '.') or\n                            i == j):\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                elif cat[i] == 'data':\n                    if (cat[j] == 'framework' or\n                            i == j):\n                        mediation_matrix[i][j] = -1\n                    else:\n                        mediation_matrix[i][j] = 0\n                else:\n                    # mediation_matrix[i][j] = -2  # errors in the generation\n                    raise DesignStructureMatrixError(\n                        'Mediation matrix value NOT generated for %s:%s' % (\n                            i, j))\n\n        return mediation_matrix", "response": "Generates the mediation matrix for the given DSM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the matrix and its mediation matrix are compliant.", "response": "def matrices_compliance(dsm, complete_mediation_matrix):\n        \"\"\"\n        Check if matrix and its mediation matrix are compliant.\n\n        Args:\n            dsm (:class:`DesignStructureMatrix`): the DSM to check.\n            complete_mediation_matrix (list of list of int): 2-dim array\n\n        Returns:\n            bool: True if compliant, else False\n        \"\"\"\n        matrix = dsm.data\n        rows_dep_matrix = len(matrix)\n        cols_dep_matrix = len(matrix[0])\n        rows_med_matrix = len(complete_mediation_matrix)\n        cols_med_matrix = len(complete_mediation_matrix[0])\n\n        if (rows_dep_matrix != rows_med_matrix or\n                cols_dep_matrix != cols_med_matrix):\n            raise DesignStructureMatrixError(\n                'Matrices are NOT compliant '\n                '(number of rows/columns not equal)')\n\n        discrepancy_found = False\n        message = []\n        for i in range(0, rows_dep_matrix):\n            for j in range(0, cols_dep_matrix):\n                if ((complete_mediation_matrix[i][j] == 0 and\n                        matrix[i][j] > 0) or\n                        (complete_mediation_matrix[i][j] == 1 and\n                         matrix[i][j] < 1)):\n                    discrepancy_found = True\n                    message.append(\n                        'Untolerated dependency at %s:%s (%s:%s): '\n                        '%s instead of %s' % (\n                            i, j, dsm.entities[i], dsm.entities[j],\n                            matrix[i][j], complete_mediation_matrix[i][j]))\n\n        message = '\\n'.join(message)\n\n        return not discrepancy_found, message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the matrix and its mediation matrix are compliant.", "response": "def check(self, dsm, **kwargs):\n        \"\"\"\n        Check if matrix and its mediation matrix are compliant.\n\n        It means that number of dependencies for each (line, column) is either\n        0 if the mediation matrix (line, column) is 0, or >0 if the mediation\n        matrix (line, column) is 1.\n\n        Args:\n            dsm (:class:`DesignStructureMatrix`): the DSM to check.\n\n        Returns:\n            bool: True if compliant, else False\n        \"\"\"\n        # generate complete_mediation_matrix according to each category\n        med_matrix = CompleteMediation.generate_mediation_matrix(dsm)\n        return CompleteMediation.matrices_compliance(dsm, med_matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck economy of mechanism.", "response": "def check(self, dsm, simplicity_factor=2, **kwargs):\n        \"\"\"\n        Check economy of mechanism.\n\n        As first abstraction, number of dependencies between two modules\n        < 2 * the number of modules\n        (dependencies to the framework are NOT considered).\n\n        Args:\n            dsm (:class:`DesignStructureMatrix`): the DSM to check.\n            simplicity_factor (int): simplicity factor.\n\n        Returns:\n            bool: True if economic, else False\n        \"\"\"\n        # economy_of_mechanism\n        economy_of_mechanism = False\n        message = ''\n        data = dsm.data\n        categories = dsm.categories\n        dsm_size = dsm.size[0]\n\n        if not categories:\n            categories = ['appmodule'] * dsm_size\n\n        dependency_number = 0\n        # evaluate Matrix(data)\n        for i in range(0, dsm_size):\n            for j in range(0, dsm_size):\n                if (categories[i] not in ('framework', 'corelib') and\n                        categories[j] not in ('framework', 'corelib') and\n                        data[i][j] > 0):\n                    dependency_number += 1\n                    # check comparison result\n        if dependency_number < dsm_size * simplicity_factor:\n            economy_of_mechanism = True\n        else:\n            message = ' '.join([\n                'Number of dependencies (%s)' % dependency_number,\n                '> number of rows (%s)' % dsm_size,\n                '* simplicity factor (%s) = %s' % (\n                    simplicity_factor, dsm_size * simplicity_factor)])\n        return economy_of_mechanism, message"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the DSM is least common.", "response": "def check(self, dsm, independence_factor=5, **kwargs):\n        \"\"\"\n        Check least common mechanism.\n\n        Args:\n            dsm (:class:`DesignStructureMatrix`): the DSM to check.\n            independence_factor (int): if the maximum dependencies for one\n                module is inferior or equal to the DSM size divided by the\n                independence factor, then this criterion is verified.\n\n        Returns:\n            bool: True if least common mechanism, else False\n        \"\"\"\n        # leastCommonMechanismMatrix\n        least_common_mechanism = False\n        message = ''\n        # get the list of dependent modules for each module\n        data = dsm.data\n        categories = dsm.categories\n        dsm_size = dsm.size[0]\n\n        if not categories:\n            categories = ['appmodule'] * dsm_size\n\n        dependent_module_number = []\n        # evaluate Matrix(data)\n        for j in range(0, dsm_size):\n            dependent_module_number.append(0)\n            for i in range(0, dsm_size):\n                if (categories[i] != 'framework' and\n                        categories[j] != 'framework' and\n                        data[i][j] > 0):\n                    dependent_module_number[j] += 1\n        # except for the broker if any  and libs, check that threshold is not\n        # overlapped\n        #  index of brokers\n        #  and app_libs are set to 0\n        for index, item in enumerate(dsm.categories):\n            if item == 'broker' or item == 'applib':\n                dependent_module_number[index] = 0\n        if max(dependent_module_number) <= dsm_size / independence_factor:\n            least_common_mechanism = True\n        else:\n            maximum = max(dependent_module_number)\n            message = (\n                'Dependencies to %s (%s) > matrix size (%s) / '\n                'independence factor (%s) = %s' % (\n                    dsm.entities[dependent_module_number.index(maximum)],\n                    maximum, dsm_size, independence_factor,\n                    dsm_size / independence_factor))\n\n        return least_common_mechanism, message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self, dsm, **kwargs):\n        layered_architecture = True\n        messages = []\n        categories = dsm.categories\n        dsm_size = dsm.size[0]\n\n        if not categories:\n            categories = ['appmodule'] * dsm_size\n\n        for i in range(0, dsm_size - 1):\n            for j in range(i + 1, dsm_size):\n                if (categories[i] != 'broker' and\n                        categories[j] != 'broker' and\n                        dsm.entities[i].split('.')[0] != dsm.entities[j].split('.')[0]):  # noqa\n                    if dsm.data[i][j] > 0:\n                        layered_architecture = False\n                        messages.append(\n                            'Dependency from %s to %s breaks the '\n                            'layered architecture.' % (\n                                dsm.entities[i], dsm.entities[j]))\n\n        return layered_architecture, '\\n'.join(messages)", "response": "Check if the DSM is layered and return a string of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking code clean. Args: dsm (:class:`DesignStructureMatrix`): the DSM to check. Returns: bool, str: True if code clean else False, messages", "response": "def check(self, dsm, **kwargs):\n        \"\"\"\n        Check code clean.\n\n        Args:\n            dsm (:class:`DesignStructureMatrix`): the DSM to check.\n\n        Returns:\n            bool, str: True if code clean else False, messages\n        \"\"\"\n        logger.debug('Entities = %s' % dsm.entities)\n        messages = []\n        code_clean = True\n        threshold = kwargs.pop('threshold', 1)\n        rows, _ = dsm.size\n        for i in range(0, rows):\n            if dsm.data[i][0] > threshold:\n                messages.append(\n                    'Number of issues (%d) in module %s '\n                    '> threshold (%d)' % (\n                        dsm.data[i][0], dsm.entities[i], threshold))\n                code_clean = False\n\n        return code_clean, '\\n'.join(messages)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_job(self, obj):\n\n        # get executable path\n        exe = session.BMDS.get_model(obj[\"bmds_version\"], obj[\"model_name\"]).get_exe_path()\n\n        # write dfile\n        dfile = self.tempfiles.get_tempfile(prefix=\"bmds-dfile-\", suffix=\".(d)\")\n        with open(dfile, \"w\") as f:\n            f.write(obj[\"dfile\"])\n\n        outfile = self.get_outfile(dfile, obj[\"model_name\"])\n        oo2 = outfile.replace(\".out\", \".002\")\n\n        proc = subprocess.Popen([exe, dfile], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        output = None\n        stdout = \"\"\n        stderr = \"\"\n\n        try:\n            stdout, stderr = proc.communicate(timeout=settings.BMDS_MODEL_TIMEOUT_SECONDS)\n\n            if os.path.exists(outfile):\n                with open(outfile, \"r\") as f:\n                    output = f.read()\n\n            status = RunStatus.SUCCESS.value\n            stdout = stdout.decode().strip()\n            stderr = stderr.decode().strip()\n\n        except subprocess.TimeoutExpired:\n            proc.kill()\n            status = RunStatus.FAILURE.value\n            stdout, stderr = proc.communicate()\n\n        finally:\n            if os.path.exists(outfile):\n                self.tempfiles.append(outfile)\n            if os.path.exists(oo2):\n                self.tempfiles.append(oo2)\n\n        self.tempfiles.cleanup()\n\n        return dict(status=status, output=output, stdout=stdout, stderr=stderr)", "response": "Execute the BMDS model and parse outputs if successful."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreport the difference between now and some specified time.", "response": "def cmd(send, msg, args):\n    \"\"\"Reports the difference between now and some specified time.\n\n    Syntax: {command} <time>\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('date', nargs='*', action=arguments.DateParser)\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if not cmdargs.date:\n        send(\"Time until when?\")\n        return\n    delta = dateutil.relativedelta.relativedelta(cmdargs.date, datetime.datetime.now())\n    diff = \"%s is \" % cmdargs.date.strftime(\"%x\")\n    if delta.years:\n        diff += \"%d years \" % (delta.years)\n    if delta.months:\n        diff += \"%d months \" % (delta.months)\n    if delta.days:\n        diff += \"%d days \" % (delta.days)\n    if delta.hours:\n        diff += \"%d hours \" % (delta.hours)\n    if delta.minutes:\n        diff += \"%d minutes \" % (delta.minutes)\n    if delta.seconds:\n        diff += \"%d seconds \" % (delta.seconds)\n    diff += \"away\"\n    send(diff)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef abstract(class_):\n    if not inspect.isclass(class_):\n        raise TypeError(\"@abstract can only be applied to classes\")\n\n    abc_meta = None\n\n    # if the class is not already using a metaclass specific to ABC,\n    # we need to change that\n    class_meta = type(class_)\n    if class_meta not in (_ABCMetaclass, _ABCObjectMetaclass):\n        # decide what metaclass to use, depending on whether it's a subclass\n        # of our universal :class:`Object` or not\n        if class_meta is type:\n            abc_meta = _ABCMetaclass  # like ABCMeta, but can never instantiate\n        elif class_meta is ObjectMetaclass:\n            abc_meta = _ABCObjectMetaclass  # ABCMeta mixed with ObjectMetaclass\n        else:\n            raise ValueError(\n                \"@abstract cannot be applied to classes with custom metaclass\")\n\n    class_.__abstract__ = True\n    return metaclass(abc_meta)(class_) if abc_meta else class_", "response": "Mark the class as _abstract_ base class forbidding its instantiation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef final(arg):\n    if inspect.isclass(arg):\n        if not isinstance(arg, ObjectMetaclass):\n            raise ValueError(\"@final can only be applied to a class \"\n                             \"that is a subclass of Object\")\n    elif not is_method(arg):\n        raise TypeError(\"@final can only be applied to classes or methods\")\n\n    method = arg.method if isinstance(arg, _WrappedMethod) else arg\n    method.__final__ = True\n\n    return arg", "response": "Mark a class or method as final."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef override(base=ABSENT):\n    arg = base  # ``base`` is just for clean, user-facing argument name\n\n    # direct application of the modifier through ``@override``\n    if inspect.isfunction(arg) or isinstance(arg, NonInstanceMethod):\n        _OverrideDecorator.maybe_signal_classmethod(arg)\n        decorator = _OverrideDecorator(None)\n        return decorator(arg)\n\n    # indirect (but simple) application of the modifier through ``@override()``\n    if arg is ABSENT:\n        return _OverrideDecorator(None)\n\n    # full-blown application, with base class specified\n    if is_class(arg) or is_string(arg):\n        return _OverrideDecorator(arg)\n\n    raise TypeError(\"explicit base class for @override \"\n                    \"must be either a string or a class object\")", "response": "Mark a method as overriding a corresponding method from superclass."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching the Twitter API.", "response": "def cmd(send, msg, args):\n    \"\"\"\n    Search the Twitter API.\n    Syntax: {command} <query> <--user username> <--count 1>\n    \"\"\"\n    if not msg:\n        send('What do you think I am, a bird?')\n        return\n\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('query', nargs='*')\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--user', dest='user', default=None)\n    group.add_argument('--count', dest='count', type=int, default=1)\n    group.add_argument('--random', action='store_true', default=False)\n\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    api = get_search_api(args['config'])\n\n    query = TwitterSearchOrder()\n    keywords = [' '.join(cmdargs.query)]\n    if cmdargs.user:\n        keywords += ['from:{}'.format(cmdargs.user)]\n    query.set_keywords(keywords)\n    query.set_language('en')\n    query.set_result_type('recent')\n    query.set_include_entities(False)\n    query.set_count(cmdargs.count)\n\n    results = list(api.search_tweets_iterable(query))\n    if not results:\n        send('No tweets here!')\n        return\n\n    if cmdargs.random:\n        shuffle(results)\n\n    max_chan_tweets = 5\n    max_pm_tweets = 25\n    if cmdargs.count > max_pm_tweets:\n        send(\"That's too many tweets! The maximum allowed through PM is {}\".format(max_pm_tweets))\n        return\n\n    if cmdargs.count > max_chan_tweets:\n        send(\"That's a lot of tweets! The maximum allowed in a channel is {}\".format(max_chan_tweets))\n\n    for i in range(0, min(cmdargs.count, max_pm_tweets)):\n        if cmdargs.count <= max_chan_tweets:\n            send(tweet_text(results[i]))\n        else:\n            send(tweet_text(results[i]), target=args['nick'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(*args, **kwargs):\n    list_, idx = _index(*args, start=0, step=1, **kwargs)\n    if idx < 0:\n        raise IndexError(\"element not found\")\n    return list_[idx]", "response": "Find the first matching element in a list and return it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the last matching element in a list and return it.", "response": "def findlast(*args, **kwargs):\n    \"\"\"Find the last matching element in a list and return it.\n\n    Usage::\n\n        findlast(element, list_)\n        findlast(of=element, in_=list_)\n        findlast(where=predicate, in_=list_)\n\n    :param element, of: Element to search for (by equality comparison)\n    :param where: Predicate defining an element to search for.\n                  This should be a callable taking a single argument\n                  and returning a boolean result.\n    :param list_, in_: List to search in\n\n    :return: Last matching element\n    :raise IndexError: If no matching elements were found\n\n    .. versionadded:: 0.0.4\n    \"\"\"\n    list_, idx = _index(*args, start=sys.maxsize, step=-1, **kwargs)\n    if idx < 0:\n        raise IndexError(\"element not found\")\n    return list_[idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches a list for an exact element or element satisfying a predicate.", "response": "def index(*args, **kwargs):\n    \"\"\"Search a list for an exact element, or element satisfying a predicate.\n\n    Usage::\n\n        index(element, list_)\n        index(of=element, in_=list_)\n        index(where=predicate, in_=list_)\n\n    :param element, of: Element to search for (by equality comparison)\n    :param where: Predicate defining an element to search for.\n                  This should be a callable taking a single argument\n                  and returning a boolean result.\n    :param list_, in_: List to search in\n\n    :return: Index of first matching element, or -1 if none was found\n\n    .. versionadded:: 0.0.3\n    \"\"\"\n    _, idx = _index(*args, start=0, step=1, **kwargs)\n    return idx"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lastindex(*args, **kwargs):\n    _, idx = _index(*args, start=sys.maxsize, step=-1, **kwargs)\n    return idx", "response": "Search a list backwards for an exact element\n    or element satisfying a predicate. Returns - 1 if no matching element was found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _index(*args, **kwargs):\n    start = kwargs.pop('start', 0)\n    step = kwargs.pop('step', 1)\n\n    if len(args) == 2:\n        elem, list_ = args\n        ensure_sequence(list_)\n        predicate = lambda item: item == elem\n    else:\n        ensure_keyword_args(kwargs,\n                            mandatory=('in_',), optional=('of', 'where'))\n        if 'of' in kwargs and 'where' in kwargs:\n            raise TypeError(\n                \"either an item or predicate must be supplied, not both\")\n        if not ('of' in kwargs or 'where' in kwargs):\n            raise TypeError(\"an item or predicate must be supplied\")\n\n        list_ = ensure_sequence(kwargs['in_'])\n        if 'where' in kwargs:\n            predicate = ensure_callable(kwargs['where'])\n        else:\n            elem = kwargs['of']\n            predicate = lambda item: item == elem\n\n    len_ = len(list_)\n    start = max(0, min(len_ - 1, start))\n\n    i = start\n    while 0 <= i < len_:\n        if predicate(list_[i]):\n            return list_, i\n        i += step\n    else:\n        return list_, -1", "response": "Implementation of list searching."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts given elements between existing elements of a list.", "response": "def intercalate(elems, list_):\n    \"\"\"Insert given elements between existing elements of a list.\n\n    :param elems: List of elements to insert between elements of ``list_`\n    :param list_: List to insert the elements to\n\n    :return: A new list where items from ``elems`` are inserted\n             between every two elements of ``list_``\n    \"\"\"\n    ensure_sequence(elems)\n    ensure_sequence(list_)\n\n    if len(list_) <= 1:\n        return list_\n\n    return sum(\n        (elems + list_[i:i+1] for i in xrange(1, len(list_))),\n        list_[:1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(_, msg, args):\n    # SHUT CAPS LOCK OFF, MORON\n\n    if args['config']['feature'].getboolean('capskick'):\n        nick = args['nick']\n        threshold = 0.65\n        text = \"shutting caps lock off\"\n        upper = [i for i in msg if i in string.ascii_uppercase]\n        if len(msg) == 0:\n            return\n        upper_ratio = len(upper) / len(msg.replace(' ', ''))\n        if args['target'] != 'private':\n            with _caps_lock:\n                if upper_ratio > threshold and len(msg) > 10:\n                    if nick in _caps:\n                        args['do_kick'](args['target'], nick, text)\n                        _caps.remove(nick)\n                    else:\n                        _caps.append(nick)\n                elif nick in _caps:\n                    _caps.remove(nick)", "response": "Check if a line is more than THRESHOLD percent uppercase."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking figs from a dictionary", "response": "def make_figs(dcfg,dp='figs',force=False):\n    \"\"\"\n    'figi','plotp'\n    \"\"\"\n    doutp=abspath(dp)\n    if isinstance(dcfg,str):\n        dcfg=pd.read_table(dcfg,\n                           error_bad_lines=False,\n                          comment='#',)        \n#     .dropna(subset=['figi','fign','plotn','plotp'])\n    dcfg=configure(dcfg,doutp,force=force)\n    templatep=f\"{doutp}/masonry/index.html\"\n    if not exists(dirname(templatep)):\n        runbashcmd(f\"cd {doutp};git clone https://github.com/rraadd88/masonry.git\")\n    else:\n        try:\n            runbashcmd(f\"cd {dirname(templatep)};git pull\")    \n        except:\n            logging.error('can not pull in masonry.git')\n    from rohan.dandage.io_files import fill_form   \n    for figi in dcfg['figi'].unique():\n#         if len(dcfg.loc[(dcfg['ploti']==figi),:])>0:\n        htmlp=dcfg.loc[(dcfg['figi']==figi),'fightmlp'].unique()[0]\n        print(basename(htmlp))\n        if not exists(htmlp) or force:\n            fill_form(dcfg.loc[(dcfg['figi']==figi),:],\n               templatep=templatep,\n               template_insert_line='<div class=\"grid__item grid__item--width{plot width scale} grid__item--height{plot height scale}\">\\n  <fig class=\"plot\"><img src=\"{plotsvgp}\"/><ploti>{ploti}</ploti></fig></div>',\n               outp=htmlp,\n               splitini='<div class=\"grid__gutter-sizer\"></div>',\n               splitend='</div><!-- class=\"grid are-images-unloaded\" -->',\n               field2replace={'<link rel=\"stylesheet\" href=\"css/style.css\">':'<link rel=\"stylesheet\" href=\"masonry/css/style.css\">',\n                             '<script  src=\"js/index.js\"></script>':'<script  src=\"masonry/js/index.js\"></script>',\n                             f'{doutp}/':''})\n            # make pdf\n            runbashcmd(f'google-chrome --headless --disable-gpu --virtual-time-budget=10000 --print-to-pdf={htmlp}.pdf {htmlp}')\n            print(htmlp)\n            \n    from rohan.dandage.figs.convert import vectors2rasters\n    vectors2rasters(doutp,ext='pdf')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd(send, msg, args):\n    if not msg:\n        msg = gen_word()\n    send(gen_fullwidth(msg.upper()))", "response": "Converts text to fullwidth characters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef task_estimates(channel, states):\n    for state in states:\n        if state != task_states.OPEN:\n            raise NotImplementedError('only estimate OPEN tasks')\n    tasks = yield channel.tasks(state=states)\n    # Estimate all the unique packages.\n    packages = set([task.package for task in tasks])\n    print('checking avg build duration for %i packages:' % len(packages))\n    packages = list(packages)\n    durations = yield average_build_durations(channel.connection, packages)\n    avg_package_durations = dict(zip(packages, durations))\n    # pprint(avg_package_durations)\n    # Determine estimates for all our tasks.\n    results = []\n    utcnow = datetime.utcnow()\n    for task in tasks:\n        avg_duration = avg_package_durations[task.package]\n        est_complete = task.started + avg_duration\n        est_remaining = est_complete - utcnow\n        result = (task, est_remaining)\n        results.append(result)\n    defer.returnValue(results)", "response": "Estimate remaining time for all tasks in this channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndescribe this timedelta in human - readable terms.", "response": "def describe_delta(delta):\n    \"\"\"\n    Describe this timedelta in human-readable terms.\n\n    :param delta: datetime.timedelta object\n    :returns: str, describing this delta\n    \"\"\"\n    s = delta.total_seconds()\n    s = abs(s)\n    hours, remainder = divmod(s, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    if hours:\n        return '%d hr %d min' % (hours, minutes)\n    if minutes:\n        return '%d min %d secs' % (minutes, seconds)\n    return '%d secs' % seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs the relative time remaining for this est_complete datetime object.", "response": "def log_est_complete(est_complete):\n    \"\"\"\n    Log the relative time remaining for this est_complete datetime object.\n    \"\"\"\n    if not est_complete:\n        print('could not determine an estimated completion time')\n        return\n    remaining = est_complete - datetime.utcnow()\n    message = 'this task should be complete in %s'\n    if remaining.total_seconds() < 0:\n        message = 'this task exceeds estimate by %s'\n    log_delta(message, remaining)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize declaration arguments to be expanded.", "response": "def patched_normalizeargs(sequence, output = None):\n    \"\"\"Normalize declaration arguments\n\n    Normalization arguments might contain Declarions, tuples, or single\n    interfaces.\n\n    Anything but individial interfaces or implements specs will be expanded.\n    \"\"\"\n    if output is None:\n        output = []\n\n    if Broken in getattr(sequence, '__bases__', ()):\n        return [sequence]\n\n    cls = sequence.__class__\n    if InterfaceClass in cls.__mro__ or zope.interface.declarations.Implements in cls.__mro__:\n        output.append(sequence)\n    else:\n        for v in sequence:\n            patched_normalizeargs(v, output)\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef profiles():\n    paths = []\n    for pattern in PROFILES:\n        pattern = os.path.expanduser(pattern)\n        paths += glob(pattern)\n    return paths", "response": "Returns a list of all the connection profile files ordered by preference."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lookup(self, profile, setting):\n        for path in profiles():\n            cfg = SafeConfigParser()\n            cfg.read(path)\n            if profile not in cfg.sections():\n                continue\n            if not cfg.has_option(profile, setting):\n                continue\n            return cfg.get(profile, setting)", "response": "Lookup a koji. conf. d file for this profile s setting."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect_from_web(klass, url):\n        # Treat any input with whitespace as invalid:\n        if re.search(r'\\s', url):\n            return\n        url = url.split(' ', 1)[0]\n        for path in profiles():\n            cfg = SafeConfigParser()\n            cfg.read(path)\n            for profile in cfg.sections():\n                if not cfg.has_option(profile, 'weburl'):\n                    continue\n                weburl = cfg.get(profile, 'weburl')\n                if url.startswith(weburl):\n                    return klass(profile)", "response": "Find a connection that matches the given URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_web(self, url):\n        # Treat any input with whitespace as invalid:\n        if re.search(r'\\s', url):\n            return defer.succeed(None)\n        o = urlparse(url)\n        endpoint = os.path.basename(o.path)\n        if o.query:\n            query = parse_qs(o.query)\n        # Known Kojiweb endpoints:\n        endpoints = {\n            'buildinfo': ('buildID', self.getBuild),\n            'channelinfo': ('channelID', self.getChannel),\n            'hostinfo': ('hostID', self.getHost),\n            'packageinfo': ('packageID', self.getPackage),\n            'taskinfo': ('taskID', self.getTaskInfo),\n            'taginfo': ('tagID', self.getTag),\n            'targetinfo': ('targetID', self.getTarget),\n            'userinfo': ('userID', self.getUser),\n        }\n        try:\n            (param, method) = endpoints[endpoint]\n        except KeyError:\n            return defer.succeed(None)\n        try:\n            id_str = query[param][0]\n            id_ = int(id_str)\n        except (KeyError, ValueError):\n            return defer.succeed(None)\n        return method(id_)", "response": "Reverse - engineer a kojiweb URL into an equivalent API response."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes an XML - RPC call to the server.", "response": "def call(self, method, *args, **kwargs):\n        \"\"\"\n        Make an XML-RPC call to the server.\n\n        If this client is logged in (with login()), this call will be\n        authenticated.\n\n        Koji has its own custom implementation of XML-RPC that supports named\n        args (kwargs). For example, to use the \"queryOpts\" kwarg:\n\n          d = client.call('listBuilds', package_id,\n                          queryOpts={'order': 'creation_ts'})\n\n        In this example, the server will order the list of builds according to\n        the \"creation_ts\" database column. Many of Koji's XML-RPC methods have\n        optional kwargs that you can set as needed.\n\n        :returns: deferred that when fired returns a dict with data from this\n                  XML-RPC call.\n        \"\"\"\n        if kwargs:\n            kwargs['__starstar'] = True\n            args = args + (kwargs,)\n        if self.session_id:\n            self.proxy.path = self._authenticated_path()\n        d = self.proxy.callRemote(method, *args)\n        d.addCallback(self._munchify_callback)\n        d.addErrback(self._parse_errback)\n        if self.callnum is not None:\n            self.callnum += 1\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the path to the authenticated request.", "response": "def _authenticated_path(self):\n        \"\"\"\n        Get the path of our XML-RPC endpoint with session auth params added.\n\n        For example:\n          /kojihub?session-id=123456&session-key=1234-asdf&callnum=0\n\n        If we're making an authenticated request, we must add these session\n        parameters to the hub's XML-RPC endpoint.\n\n        :return: a path suitable for twisted.web.xmlrpc.Proxy\n        \"\"\"\n        basepath = self.proxy.path.decode().split('?')[0]\n        params = urlencode({'session-id': self.session_id,\n                            'session-key': self.session_key,\n                            'callnum': self.callnum})\n        result = '%s?%s' % (basepath, params)\n        return result.encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAverageBuildDuration(self, package, **kwargs):\n        seconds = yield self.call('getAverageBuildDuration', package, **kwargs)\n        if seconds is None:\n            defer.returnValue(None)\n        defer.returnValue(timedelta(seconds=seconds))", "response": "Returns a deferred that when fired returns a datetime object for the average build duration for this package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all information about a build and return a custom Build class.", "response": "def getBuild(self, build_id, **kwargs):\n        \"\"\"\n        Load all information about a build and return a custom Build class.\n\n        Calls \"getBuild\" XML-RPC.\n\n        :param build_id: ``int``, for example 12345\n        :returns: deferred that when fired returns a Build (Munch, dict-like)\n                  object representing this Koji build, or None if no build was\n                  found.\n        \"\"\"\n        buildinfo = yield self.call('getBuild', build_id, **kwargs)\n        build = Build.fromDict(buildinfo)\n        if build:\n            build.connection = self\n        defer.returnValue(build)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading all information about a channel and return a custom Channel class.", "response": "def getChannel(self, channel_id, **kwargs):\n        \"\"\"\n        Load all information about a channel and return a custom Channel class.\n\n        Calls \"getChannel\" XML-RPC.\n\n        :param channel_id: ``int``, for example 12345, or ``str`` for name.\n        :returns: deferred that when fired returns a Channel (Munch, dict-like)\n                  object representing this Koji channel, or None if no channel\n                  was found.\n        \"\"\"\n        channelinfo = yield self.call('getChannel', channel_id, **kwargs)\n        channel = Channel.fromDict(channelinfo)\n        if channel:\n            channel.connection = self\n        defer.returnValue(channel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading information about a package and return a custom Package class.", "response": "def getPackage(self, name, **kwargs):\n        \"\"\"\n        Load information about a package and return a custom Package class.\n\n        Calls \"getPackage\" XML-RPC.\n\n        :param package_id: ``int``, for example 12345\n        :returns: deferred that when fired returns a Package (Munch, dict-like)\n                  object representing this Koji package, or None if no build\n                  was found.\n        \"\"\"\n        packageinfo = yield self.call('getPackage', name, **kwargs)\n        package = Package.fromDict(packageinfo)\n        if package:\n            package.connection = self\n        defer.returnValue(package)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all information about a task s descendents into Task classes.", "response": "def getTaskDescendents(self, task_id, **kwargs):\n        \"\"\"\n        Load all information about a task's descendents into Task classes.\n\n        Calls \"getTaskDescendents\" XML-RPC (with request=True to get the full\n        information.)\n\n        :param task_id: ``int``, for example 12345, parent task ID\n        :returns: deferred that when fired returns a list of Task (Munch,\n                  dict-like) objects representing Koji tasks.\n        \"\"\"\n        kwargs['request'] = True\n        data = yield self.call('getTaskDescendents', task_id, **kwargs)\n        tasks = []\n        for tdata in data[str(task_id)]:\n            task = Task.fromDict(tdata)\n            task.connection = self\n            tasks.append(task)\n        defer.returnValue(tasks)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTaskInfo(self, task_id, **kwargs):\n        kwargs['request'] = True\n        taskinfo = yield self.call('getTaskInfo', task_id, **kwargs)\n        task = Task.fromDict(taskinfo)\n        if task:\n            task.connection = self\n        defer.returnValue(task)", "response": "Load all information about a task and return a custom Task class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef listBuilds(self, package, **kwargs):\n        if isinstance(package, int):\n            package_id = package\n        else:\n            package_data = yield self.getPackage(package)\n            if package_data is None:\n                defer.returnValue([])\n            package_id = package_data.id\n        data = yield self.call('listBuilds', package_id, **kwargs)\n        builds = []\n        for bdata in data:\n            build = Build.fromDict(bdata)\n            build.connection = self\n            builds.append(build)\n        defer.returnValue(builds)", "response": "List all builds of a package."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling listTagged XML - RPC.", "response": "def listTagged(self, *args, **kwargs):\n        \"\"\"\n        List builds tagged with a tag.\n\n        Calls \"listTagged\" XML-RPC.\n\n        :returns: deferred that when fired returns a list of Build objects.\n        \"\"\"\n        data = yield self.call('listTagged', *args, **kwargs)\n        builds = []\n        for bdata in data:\n            build = Build.fromDict(bdata)\n            build.connection = self\n            builds.append(build)\n        defer.returnValue(builds)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listTasks(self, opts={}, queryOpts={}):\n        opts['decode'] = True  # decode xmlrpc data in \"request\"\n        data = yield self.call('listTasks', opts, queryOpts)\n        tasks = []\n        for tdata in data:\n            task = Task.fromDict(tdata)\n            task.connection = self\n            tasks.append(task)\n        defer.returnValue(tasks)", "response": "Get information about all Koji tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all Koji channels.", "response": "def listChannels(self, **kwargs):\n        \"\"\"\n        Get information about all Koji channels.\n\n        :param **kwargs: keyword args to pass through to listChannels RPC.\n        :returns: deferred that when fired returns a list of Channel objects.\n        \"\"\"\n        data = yield self.call('listChannels', **kwargs)\n        channels = []\n        for cdata in data:\n            channel = Channel.fromDict(cdata)\n            channel.connection = self\n            channels.append(channel)\n        defer.returnValue(channels)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs into this Koji hub.", "response": "def login(self):\n        \"\"\"\n        Return True if we successfully logged into this Koji hub.\n\n        We support GSSAPI and SSL Client authentication (not the old-style\n        krb-over-xmlrpc krbLogin method).\n\n        :returns: deferred that when fired returns True\n        \"\"\"\n        authtype = self.lookup(self.profile, 'authtype')\n        if authtype is None:\n            cert = self.lookup(self.profile, 'cert')\n            if cert and os.path.isfile(os.path.expanduser(cert)):\n                authtype = 'ssl'\n            # Note: official koji cli is a little more lax here. If authtype is\n            # None and we have a valid kerberos ccache, we still try kerberos\n            # auth.\n        if authtype == 'kerberos':\n            # Note: we don't try the old-style kerberos login here.\n            result = yield self._gssapi_login()\n        elif authtype == 'ssl':\n            result = yield self._ssl_login()\n        else:\n            raise NotImplementedError('unsupported auth: %s' % authtype)\n        self.session_id = result['session-id']\n        self.session_key = result['session-key']\n        self.callnum = 0  # increment this on every call for this session.\n        defer.returnValue(True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nauthenticates to the GSSAPI endpoint with GSSAPI authentication.", "response": "def _gssapi_login(self):\n        \"\"\"\n        Authenticate to the /ssllogin endpoint with GSSAPI authentication.\n\n        :returns: deferred that when fired returns a dict from sslLogin\n        \"\"\"\n        method = treq_kerberos.post\n        auth = treq_kerberos.TreqKerberosAuth(force_preemptive=True)\n        return self._request_login(method, auth=auth)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ssl_agent(self):\n        # Load \"cert\" into a PrivateCertificate.\n        certfile = self.lookup(self.profile, 'cert')\n        certfile = os.path.expanduser(certfile)\n        with open(certfile) as certfp:\n            pemdata = certfp.read()\n            client_cert = PrivateCertificate.loadPEM(pemdata)\n\n        trustRoot = None  # Use Twisted's platformTrust().\n        # Optionally load \"serverca\" into a Certificate.\n        servercafile = self.lookup(self.profile, 'serverca')\n        if servercafile:\n            servercafile = os.path.expanduser(servercafile)\n            trustRoot = RootCATrustRoot(servercafile)\n\n        policy = ClientCertPolicy(trustRoot=trustRoot, client_cert=client_cert)\n        return Agent(reactor, policy)", "response": "Get a Twisted Agent that performs Client SSL authentication for Koji."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nauthenticate to the sslLogin endpoint with Client SSL authentication.", "response": "def _ssl_login(self):\n        \"\"\"\n        Authenticate to the /ssllogin endpoint with Client SSL authentication.\n\n        :returns: deferred that when fired returns a dict from sslLogin\n        \"\"\"\n        method = treq.post\n        agent = self._ssl_agent()\n        return self._request_login(method, agent=agent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _request_login(self, method, **kwargs):\n        url = self.url + '/ssllogin'\n        # Build the XML-RPC HTTP request body by hand and send it with\n        # treq.\n        factory = KojiQueryFactory(path=None, host=None, method='sslLogin')\n        payload = factory.payload\n        try:\n            response = yield method(url, data=payload, **kwargs)\n        except ResponseFailed as e:\n            failure = e.reasons[0]\n            failure.raiseException()\n        if response.code > 200:\n            raise KojiLoginException('HTTP %d error' % response.code)\n        # Process the XML-RPC response content from treq.\n        content = yield response.content()\n        if hasattr(xmlrpc, 'loads'):  # Python 2:\n            result = xmlrpc.loads(content)[0][0]\n        else:\n            result = xmlrpc.client.loads(content)[0][0]\n        defer.returnValue(result)", "response": "Send a treq HTTP POST request to the Koji server and return a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_errback(self, error):\n        if isinstance(error.value, IOError):\n            raise error.value\n        if hasattr(xmlrpc, 'Fault'):  # Python 2:\n            fault = xmlrpc.Fault\n        else:\n            fault = xmlrpc.client.Fault\n        if isinstance(error.value, fault):\n            # TODO: specific errors here, see koji/__init__.py\n            if error.value.faultCode >= 1000 and error.value.faultCode <= 1022:\n                raise KojiException(error.value.faultString)\n            raise KojiException(error.value)\n        # We don't know what this is, so just raise it.\n        raise error", "response": "Parse an error from an XML - RPC call and raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_bmdl_ratio(self, models):\n        bmdls = [model.output[\"BMDL\"] for model in models if model.output[\"BMDL\"] > 0]\n\n        return max(bmdls) / min(bmdls) if len(bmdls) > 0 else 0", "response": "Return BMDL ratio in list of models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_recommended_models(models, fld_name):\n        target_value = min([model.output[fld_name] for model in models])\n        return [model for model in models if model.output[fld_name] == target_value]", "response": "Returns a list of models which have the minimum target field value\n        for a given field name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the most parsimonious model of all available models.", "response": "def _get_parsimonious_model(models):\n        \"\"\"\n        Return the most parsimonious model of all available models. The most\n        parsimonious model is defined as the model with the fewest number of\n        parameters.\n        \"\"\"\n        params = [len(model.output[\"parameters\"]) for model in models]\n        idx = params.index(min(params))\n        return models[idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if input string conforms to input regex form.", "response": "def isstrallowed(s,form):\n    \"\"\"\n    Checks is input string conforms to input regex (`form`).\n\n    :param s: input string.\n    :param form: eg. for hdf5: `\"^[a-zA-Z_][a-zA-Z0-9_]*$\"`\n    \"\"\"\n    import re\n    match = re.match(form,s)\n    return match is not None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convertstr2format(col,form):\n    if not isstrallowed(col,form):\n        col=col.replace(\" \",\"_\") \n        if not isstrallowed(col,form):\n            chars_disallowed=[char for char in col if not isstrallowed(char,form)]\n            for char in chars_disallowed:\n                col=col.replace(char,\"_\")\n    return col", "response": "Convert input string to input regex."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_pathable_string(s,replacewith='_'):\n    import re\n    return re.sub(r'[^\\w+/.]',replacewith, s.lower())", "response": "Removes symbols from a string to be compatible with directory structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses for adding labels in plots. :param l: list of strings :param break_pt: number, insert new line after this many letters", "response": "def linebreaker(l,break_pt=16):\n    \"\"\"\n    used for adding labels in plots.\n\n    :param l: list of strings\n    :param break_pt: number, insert new line after this many letters \n    \"\"\"\n\n    l_out=[]\n    for i in l:\n        if len(i)>break_pt:\n            i_words=i.split(' ')\n            i_out=''\n            line_len=0\n            for w in i_words:\n                line_len+=len(w)+1\n                if i_words.index(w)==0:\n                    i_out=w\n                elif line_len>break_pt:\n                    line_len=0\n                    i_out=\"%s\\n%s\" % (i_out,w)\n                else:\n                    i_out=\"%s %s\" % (i_out,w)\n            l_out.append(i_out)    \n#             l_out.append(\"%s\\n%s\" % (i[:break_pt],i[break_pt:]))\n        else:\n            l_out.append(i)\n    return l_out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef splitlabel(label,splitby=' ',ctrl='__'):\n    splits=label.split(splitby)\n    if len(splits)==2:\n        return splits\n    elif len(splits)==1:\n\n        return splits+[ctrl]", "response": "split a label into two or more words"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets current time in a form of a formated string. Used in logger function.", "response": "def get_time():\n    \"\"\"\n    Gets current time in a form of a formated string. Used in logger function.\n\n    \"\"\"\n    import datetime\n    time=make_pathable_string('%s' % datetime.datetime.now())\n    return time.replace('-','_').replace(':','_').replace('.','_')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a general election page type", "response": "def bootstrap_general_election(self, election):\n        \"\"\"\n        Create a general election page type\n        \"\"\"\n        election_day = election.election_day\n        page_type, created = PageType.objects.get_or_create(\n            model_type=ContentType.objects.get(\n                app_label=\"election\", model=\"electionday\"\n            ),\n            election_day=election_day,\n        )\n        PageContent.objects.get_or_create(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election_day,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asserts(self, *args, **kwargs):\r\n        result = self.match(*args, **kwargs)\r\n        self.expect(result)\r\n        return result", "response": "Wraps match method and places under an assertion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntelling you what acronyms mean.", "response": "def cmd(send, msg, _):\n    \"\"\"Tells you what acronyms mean.\n\n    Syntax: {command} <term>\n\n    \"\"\"\n    try:\n        answer = subprocess.check_output(['wtf', msg], stderr=subprocess.STDOUT)\n        send(answer.decode().strip().replace('\\n', ' or ').replace('fuck', 'fsck'))\n    except subprocess.CalledProcessError as ex:\n        send(ex.output.decode().rstrip().splitlines()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ls():\n  ''' List all synchronized directories. '''\n\n  heading, body = cli_syncthing_adapter.ls()\n\n  if heading:\n    click.echo(heading)\n\n  if body:\n    click.echo(body.strip())", "response": "List all synchronized directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(**kwargs):\n  ''' Force synchronization of directory. '''\n\n  output, err = cli_syncthing_adapter.refresh(**kwargs)\n\n  if output:\n    click.echo(\"%s\" % output, err=err)\n\n  if kwargs['verbose'] and not err:\n    with click.progressbar(\n      iterable=None,\n      length=100,\n      label='Synchronizing') as bar:\n\n      device_num = 0\n      max_devices = 1\n      prev_percent = 0\n\n      while True:\n        kwargs['progress'] = True\n        kwargs['device_num'] = device_num\n        data, err = cli_syncthing_adapter.refresh(**kwargs)\n\n        device_num = data['device_num']\n        max_devices = data['max_devices']\n\n        cur_percent = math.floor(data['percent']) - prev_percent\n        if cur_percent > 0:\n          bar.update(cur_percent)\n          prev_percent = math.floor(data['percent'])\n\n        if device_num < max_devices:\n          time.sleep(0.5)\n        else:\n          break", "response": "Force synchronization of directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging tag associated with directory.", "response": "def tag(path, name):\n  ''' Change tag associated with directory. '''\n\n  output, err = cli_syncthing_adapter.tag(path, name)\n  click.echo(\"%s\" % output, err=err)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef free(**kwargs):\n  ''' Stop synchronization of directory. '''\n\n  output, err = cli_syncthing_adapter.free(kwargs['path'])\n  click.echo(\"%s\" % output, err=err)", "response": "Stop synchronization of directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a directory shareable.", "response": "def add(**kwargs):\n  ''' Make a directory shareable. '''\n\n  output, err = cli_syncthing_adapter.add(**kwargs)\n  click.echo(\"%s\" % output, err=err)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef d3flare_json(metadata, file=None, **options):\n\n    def convert(root):\n        dct = OrderedDict()\n        item_type = root.get('type')\n        dct['class'] = root.get('class')\n        dct['name'] = root.get('name')\n\n        if item_type is ItemClass.Field.name:\n            dct['size'] = root.get('size')\n            dct['value'] = root.get('value')\n\n        children = root.get('member')\n        if children:\n            # Any containable class with children\n            dct['children'] = list()\n            if item_type is ItemClass.Pointer.name:\n                # Create pointer address field as child\n                field = OrderedDict()\n                field['class'] = dct['class']\n                field['name'] = '*' + dct['name']\n                field['size'] = root.get('size')\n                field['value'] = root.get('value')\n                dct['children'].append(field)\n            for child in map(convert, children):\n                # Recursive function call map(fnc, args).\n                dct['children'].append(child)\n        elif item_type is ItemClass.Pointer.name:\n            # Null pointer (None pointer)\n            dct['size'] = root.get('size')\n            dct['value'] = root.get('value')\n        return dct\n\n    options['indent'] = options.get('indent', 2)\n\n    if file:\n        return json.dump(convert(metadata), file, **options)\n    else:\n        return json.dumps(convert(metadata), **options)", "response": "Convert the dictionary metadata into a flat json file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _view_area(stream=bytes(), index=0, count=0):\n        # Byte stream size\n        size = len(stream)\n\n        # Start index of the viewing area\n        start = max(min(index, size), -size)\n        if start < 0:\n            start += size\n\n        # Stop index of the viewing area\n        if not count:\n            count = size\n        if count > 0:\n            stop = min(start + count, size)\n        else:\n            stop = size\n\n        return start, stop", "response": "Returns the start and stop indices for the viewing area of the entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_dump(self, source, index=0, count=0, output=str()):\n        stream = open(source, 'rb').read()\n        self.dump(stream, index, count, output)", "response": "Dumps the content of the source file to the console or to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self, stream, index=0, count=0, output=str()):\n\n        def numerate(pattern, _count):\n            return ''.join(pattern.format(x) for x in range(_count))\n\n        def write_to(file_handle, content):\n            if file_handle:\n                file_handle.write(content + \"\\n\")\n            else:\n                print(content)\n\n        dst = None\n        if output:\n            dst = open(output, 'w')\n\n        start, stop = self._view_area(stream, index, count)\n        digits = max(len(hex(start + stop)) - 2, 8)\n\n        # Write header\n        write_to(dst,\n                 \" \" * digits +\n                 \" |\" +\n                 numerate(\" {0:02d}\", self.columns) +\n                 \" |\")\n        write_to(dst,\n                 \"-\" * digits +\n                 \"-+\" +\n                 \"-\" * (self.columns * 3) +\n                 \"-+-\" +\n                 \"-\" * self.columns)\n\n        # Set start row and column\n        row = int(start / self.columns)\n        column = int(start % self.columns)\n\n        # Initialize output for start index row\n        output_line = \"{0:0{1:d}X} |\".format(row * self.columns,\n                                             digits)\n        output_line += \" ..\" * column\n        output_ascii = \".\" * column\n\n        # Iterate over viewing area\n        for value in stream[start:stop]:\n            column += 1\n            output_line += \" {0:02X}\".format(int(value))\n            if value in range(32, 126):\n                output_ascii += \"{0:c}\".format(value)\n            else:\n                output_ascii += \".\"\n            column %= self.columns\n            if not column:\n                # Write output line\n                output_line += ' | ' + output_ascii\n                write_to(dst, output_line)\n                # Next row\n                row += 1\n                output_line = \"{0:0{1:d}X} |\".format(row * self.columns,\n                                                     digits)\n                output_ascii = \"\"\n\n        # Write output of stop index row\n        if column:\n            # Fill missing columns with white spaces\n            output_line += \" \" * (self.columns - column) * 3\n            output_line += \" | \" + output_ascii\n            write_to(dst, output_line)", "response": "Dumps the content of the current entry in the given byte stream to the console or to the output file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reopen(args):\n    if not args.isadmin:\n        return \"Nope, not gonna do it.\"\n    msg = args.msg.split()\n    if not msg:\n        return \"Syntax: !poll reopen <pollnum>\"\n    if not msg[0].isdigit():\n        return \"Not a valid positve integer.\"\n    pid = int(msg[0])\n    poll = get_open_poll(args.session, pid)\n    if poll is None:\n        return \"That poll doesn't exist or has been deleted!\"\n    poll.active = 1\n    return \"Poll %d reopened!\" % pid", "response": "reopens a closed poll."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow the results of a poll.", "response": "def tally_poll(args):\n    \"\"\"Shows the results of poll.\"\"\"\n    if not args.msg:\n        return \"Syntax: !vote tally <pollnum>\"\n    if not args.msg.isdigit():\n        return \"Not A Valid Positive Integer.\"\n    pid = int(args.msg)\n    poll = get_open_poll(args.session, pid)\n    if poll is None:\n        return \"That poll doesn't exist or was deleted. Use !poll list to see valid polls\"\n    state = \"Active\" if poll.active == 1 else \"Closed\"\n    votes = args.session.query(Poll_responses).filter(Poll_responses.pid == pid).all()\n    args.send(\"%s poll: %s, %d total votes\" % (state, poll.question, len(votes)))\n    votemap = collections.defaultdict(list)\n    for v in votes:\n        votemap[v.response].append(v.voter)\n    for x in sorted(votemap.keys()):\n        args.send(\"%s: %d -- %s\" % (x, len(votemap[x]), \", \".join(votemap[x])), target=args.nick)\n    if not votemap:\n        return \"\"\n    ranking = collections.defaultdict(list)\n    for x in votemap.keys():\n        num = len(votemap[x])\n        ranking[num].append(x)\n    high = max(ranking)\n    winners = (ranking[high], high)\n    if len(winners[0]) == 1:\n        winners = (winners[0][0], high)\n        return \"The winner is %s with %d votes.\" % winners\n    else:\n        winners = (\", \".join(winners[0]), high)\n        return \"Tie between %s with %d votes.\" % winners"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vote(session, nick, pid, response):\n    if not response:\n        return \"You have to vote something!\"\n    if response == \"n\" or response == \"nay\":\n        response = \"no\"\n    elif response == \"y\" or response == \"aye\":\n        response = \"yes\"\n    poll = get_open_poll(session, pid)\n    if poll is None:\n        return \"That poll doesn't exist or isn't active. Use !poll list to see valid polls\"\n    old_vote = get_response(session, pid, nick)\n    if old_vote is None:\n        session.add(Poll_responses(pid=pid, response=response, voter=nick))\n        return \"%s voted %s.\" % (nick, response)\n    else:\n        if response == old_vote.response:\n            return \"You've already voted %s.\" % response\n        else:\n            msg = \"%s changed their vote from %s to %s.\" % (nick, old_vote.response, response)\n            old_vote.response = response\n            return msg", "response": "Votes on a poll."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a vote for a poll.", "response": "def retract(args):\n    \"\"\"Deletes a vote for a poll.\"\"\"\n    if not args.msg:\n        return \"Syntax: !vote retract <pollnum>\"\n    if not args.msg.isdigit():\n        return \"Not A Valid Positive Integer.\"\n    response = get_response(args.session, args.msg, args.nick)\n    if response is None:\n        return \"You haven't voted on that poll yet!\"\n    args.session.delete(response)\n    return \"Vote retracted\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling voting. Syntax: {command} <start|end|list|tally|edit|delete|retract|reopen|(num) vote>", "response": "def cmd(send, msg, args):\n    \"\"\"Handles voting.\n\n    Syntax: {command} <start|end|list|tally|edit|delete|retract|reopen|(num) vote>\n\n    \"\"\"\n    command = msg.split()\n    msg = \" \".join(command[1:])\n    if not command:\n        send(\"Which poll?\")\n        return\n    else:\n        command = command[0]\n    # FIXME: integrate this with ArgParser\n    if command.isdigit():\n        if args['type'] == 'privmsg':\n            send(\"We don't have secret ballots in this benevolent dictatorship!\")\n        else:\n            send(vote(args['db'], args['nick'], int(command), msg))\n        return\n    isadmin = args['is_admin'](args['nick'])\n    parser = arguments.ArgParser(args['config'])\n    parser.set_defaults(session=args['db'], msg=msg, nick=args['nick'])\n    subparser = parser.add_subparsers()\n    start_parser = subparser.add_parser('start', config=args['config'], aliases=['open', 'add', 'create'])\n    start_parser.set_defaults(func=start_poll, send=send, isadmin=isadmin, type=args['type'])\n    tally_parser = subparser.add_parser('tally')\n    tally_parser.set_defaults(func=tally_poll, send=send)\n    list_parser = subparser.add_parser('list', config=args['config'])\n    list_parser.set_defaults(func=list_polls)\n    retract_parser = subparser.add_parser('retract')\n    retract_parser.set_defaults(func=retract)\n    end_parser = subparser.add_parser('end', aliases=['close'])\n    end_parser.set_defaults(func=end_poll, isadmin=isadmin)\n    delete_parser = subparser.add_parser('delete')\n    delete_parser.set_defaults(func=delete_poll, isadmin=isadmin)\n    edit_parser = subparser.add_parser('edit')\n    edit_parser.set_defaults(func=edit_poll, isadmin=isadmin)\n    reopen_parser = subparser.add_parser('reopen')\n    reopen_parser.set_defaults(func=reopen, isadmin=isadmin)\n    try:\n        cmdargs = parser.parse_args(command)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    send(cmdargs.func(cmdargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets stats. Syntax: {command} <--high|--low|--userhigh|--nick <nick>|command>", "response": "def cmd(send, msg, args):\n    \"\"\"Gets stats.\n\n    Syntax: {command} <--high|--low|--userhigh|--nick <nick>|command>\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--high', action='store_true')\n    group.add_argument('--low', action='store_true')\n    group.add_argument('--userhigh', action='store_true')\n    group.add_argument('--nick', action=arguments.NickParser)\n    group.add_argument('command', nargs='?')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    session = args['db']\n    totals = get_command_totals(session)\n    sortedtotals = sorted(totals, key=totals.get)\n    if command_registry.is_registered(cmdargs.command):\n        send(get_command(session, cmdargs.command, totals))\n    elif cmdargs.command and not command_registry.is_registered(cmdargs.command):\n        send(\"Command %s not found.\" % cmdargs.command)\n    elif cmdargs.high:\n        send('Most Used Commands:')\n        high = list(reversed(sortedtotals))\n        for x in range(3):\n            if x < len(high):\n                send(\"%s: %s\" % (high[x], totals[high[x]]))\n    elif cmdargs.low:\n        send('Least Used Commands:')\n        low = sortedtotals\n        for x in range(3):\n            if x < len(low):\n                send(\"%s: %s\" % (low[x], totals[low[x]]))\n    elif cmdargs.userhigh:\n        totals = get_nick_totals(session)\n        sortedtotals = sorted(totals, key=totals.get)\n        high = list(reversed(sortedtotals))\n        send('Most active bot users:')\n        for x in range(3):\n            if x < len(high):\n                send(\"%s: %s\" % (high[x], totals[high[x]]))\n    elif cmdargs.nick:\n        send(get_nick(session, cmdargs.nick))\n    else:\n        command = choice(list(totals.keys()))\n        send(\"%s has been used %s times.\" % (command, totals[command]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a single page or title.", "response": "def _create_page(cls, page, lang, auto_title, cms_app=None, parent=None, namespace=None,\n                     site=None, set_home=False):\n        \"\"\"\n        Create a single page or titles\n\n        :param page: Page instance\n        :param lang: language code\n        :param auto_title: title text for the newly created title\n        :param cms_app: Apphook Class to be attached to the page\n        :param parent: parent page (None when creating the home page)\n        :param namespace: application instance name (as provided to the ApphookConfig)\n        :param set_home: mark as home page (on django CMS 3.5 only)\n\n        :return: draft copy of the created page\n        \"\"\"\n        from cms.api import create_page, create_title\n        from cms.utils.conf import get_templates\n\n        default_template = get_templates()[0][0]\n        if page is None:\n            page = create_page(\n                auto_title, language=lang, parent=parent, site=site,\n                template=default_template, in_navigation=True, published=True\n            )\n            page.application_urls = cms_app\n            page.application_namespace = namespace\n            page.save()\n            page.publish(lang)\n        elif lang not in page.get_languages():\n            create_title(\n                language=lang, title=auto_title, page=page\n            )\n            page.publish(lang)\n        if set_home:\n            page.set_as_homepage()\n        return page.get_draft_object()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_config(cls):\n        return cls.app_config.objects.create(\n            namespace=cls.auto_setup['namespace'], **cls.auto_setup['config_fields']\n        )", "response": "Creates an ApphookConfig instance based on the auto_setup dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a translation for the given ApphookConfig instance and language code.", "response": "def _create_config_translation(cls, config, lang):\n        \"\"\"\n        Creates a translation for the given ApphookConfig\n\n        Only django-parler kind of models are currently supported.\n\n        ``AutoCMSAppMixin.auto_setup['config_translated_fields']`` is used to fill in the data\n        of the instance for all the languages.\n\n        :param config: ApphookConfig instance\n        :param lang: language code for the language to create\n        \"\"\"\n        config.set_current_language(lang, initialize=True)\n        for field, data in cls.auto_setup['config_translated_fields'].items():\n            setattr(config, field, data)\n        config.save_translations()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup_pages(cls, config):\n        from cms.exceptions import NoHomeFound\n        from cms.models import Page\n        from cms.utils import get_language_list\n        from django.conf import settings\n        from django.utils.translation import override\n\n        app_page = None\n        get_url = False\n        if getattr(settings, 'ALDRYN_SEARCH_CMS_PAGE', False):\n            from aldryn_search.search_indexes import TitleIndex\n\n            def fake_url(self, obj):\n                return ''\n\n            get_url = TitleIndex.get_url\n            TitleIndex.get_url = fake_url\n        site = Site.objects.get_current()\n        auto_sites = cls.auto_setup.get('sites', True)\n        if auto_sites is True or site.pk in auto_sites:\n            if getattr(cls, 'app_config', False):\n                configs = cls.app_config.objects.all()\n                if not configs.exists():\n                    config = cls._create_config()\n                else:\n                    config = configs.first()\n\n            langs = get_language_list(site.pk)\n            if not Page.objects.on_site(site.pk).filter(application_urls=cls.__name__).exists():\n                for lang in langs:\n                    with override(lang):\n                        if config:\n                            if cls.auto_setup['config_translated_fields']:\n                                cls._create_config_translation(config, lang)\n                            namespace = config.namespace\n                        elif cls.app_name:\n                            namespace = cls.app_name\n                        else:\n                            namespace = None\n                        try:\n                            home = Page.objects.get_home(site.pk).get_draft_object()\n                        except NoHomeFound:\n                            home = None\n                        set_home = hasattr(Page, 'set_as_homepage')\n                        home = cls._create_page(\n                            home, lang, cls.auto_setup['home title'], site=site, set_home=set_home\n                        )\n                        app_page = cls._create_page(\n                            app_page, lang, cls.auto_setup['page title'], cls.__name__, home,\n                            namespace, site=site\n                        )\n                if get_url:\n                    TitleIndex.get_url = get_url", "response": "Create the page structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the analysis. Generate data from each provider, then check these data with every checker, and store the analysis results. Args: verbose (bool): whether to immediately print the results or not.", "response": "def run(self, verbose=True):\n        \"\"\"\n        Run the analysis.\n\n        Generate data from each provider, then check these data with every\n        checker, and store the analysis results.\n\n        Args:\n            verbose (bool): whether to immediately print the results or not.\n        \"\"\"\n        self.results.clear()\n\n        for analysis_group in self.config.analysis_groups:\n            if analysis_group.providers:\n                for provider in analysis_group.providers:\n                    logger.info('Run provider %s', provider.identifier)\n                    provider.run()\n                    for checker in analysis_group.checkers:\n                        result = self._get_checker_result(\n                            analysis_group, checker, provider)\n                        self.results.append(result)\n                        analysis_group.results.append(result)\n                        if verbose:\n                            result.print()\n            else:\n                for checker in analysis_group.checkers:\n                    result = self._get_checker_result(\n                        analysis_group, checker, nd='no-data-')\n                    self.results.append(result)\n                    analysis_group.results.append(result)\n                    if verbose:\n                        result.print()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noutput analysis results in TAP format.", "response": "def output_tap(self):\n        \"\"\"Output analysis results in TAP format.\"\"\"\n        tracker = Tracker(streaming=True, stream=sys.stdout)\n        for group in self.config.analysis_groups:\n            n_providers = len(group.providers)\n            n_checkers = len(group.checkers)\n            if not group.providers and group.checkers:\n                test_suite = group.name\n                description_lambda = lambda r: r.checker.name\n            elif not group.checkers:\n                logger.warning(\n                    'Invalid analysis group (no checkers), skipping')\n                continue\n            elif n_providers > n_checkers:\n                test_suite = group.checkers[0].name\n                description_lambda = lambda r: r.provider.name\n            else:\n                test_suite = group.providers[0].name\n                description_lambda = lambda r: r.checker.name\n\n            for result in group.results:\n                description = description_lambda(result)\n                if result.code == ResultCode.PASSED:\n                    tracker.add_ok(test_suite, description)\n                elif result.code == ResultCode.IGNORED:\n                    tracker.add_ok(\n                        test_suite, description + ' (ALLOWED FAILURE)')\n                elif result.code == ResultCode.NOT_IMPLEMENTED:\n                    tracker.add_not_ok(\n                        test_suite, description, 'TODO implement the test')\n                elif result.code == ResultCode.FAILED:\n                    tracker.add_not_ok(\n                        test_suite, description,\n                        diagnostics='  ---\\n  message: %s\\n  hint: %s\\n  ...' % (\n                            '\\n  message: '.join(result.messages.split('\\n')),\n                            result.checker.hint))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef successful(self):\n        for result in self.results:\n            if result.code == ResultCode.FAILED:\n                return False\n        return True", "response": "Property to tell if the run was successful."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scale_lim(lim,factor=1.05):\n  r'''\nScale limits to be 5% wider, to have a nice plot.\n\n:arguments:\n\n  **lim** (``<list>`` | ``<str>``)\n    The limits. May be a string \"[...,...]\", which is converted to a list.\n\n:options:\n\n  **factor** ([``1.05``] | ``<float>``)\n    Scale factor.\n  '''\n\n  # convert string \"[...,...]\"\n  if type(lim) == str: lim = eval(lim)\n\n  # scale limits\n  D       = lim[1] - lim[0]\n  lim[0] -= (factor-1.)/2. * D\n  lim[1] += (factor-1.)/2. * D\n\n  return lim", "response": "r Scale limits to be 5% wider."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef annotate_powerlaw(text, exp, startx, starty, width=None, rx=0.5, ry=0.5, **kwargs):\n  r'''\nAdded a label to the middle of a power-law annotation (see ``goosempl.plot_powerlaw``).\n\n:arguments:\n\n  **exp** (``float``)\n    The power-law exponent.\n\n  **startx, starty** (``float``)\n    Start coordinates.\n\n:options:\n\n  **width, height, endx, endy** (``float``)\n    Definition of the end coordinate (only on of these options is needed).\n\n  **rx, ry** (``float``)\n    Shift in x- and y-direction w.r.t. the default coordinates.\n\n  **units** ([``'relative'``] | ``'absolute'``)\n    The type of units in which the coordinates are specified. Relative coordinates correspond to a\n    fraction of the relevant axis. If you use relative coordinates, be sure to set the limits and\n    scale before calling this function!\n\n  **axis** ([``plt.gca()``] | ...)\n    Specify the axis to which to apply the limits.\n\n  ...\n    Any ``plt.text(...)`` option.\n\n:returns:\n\n  The handle of the ``plt.text(...)`` command.\n  '''\n\n  # get options/defaults\n  endx   = kwargs.pop('endx'  , None      )\n  endy   = kwargs.pop('endy'  , None      )\n  height = kwargs.pop('height', None      )\n  units  = kwargs.pop('units' , 'relative')\n  axis   = kwargs.pop('axis'  , plt.gca() )\n\n  # check\n  if axis.get_xscale() != 'log' or axis.get_yscale() != 'log':\n    raise IOError('This function only works on a log-log scale, where the power-law is a straight line')\n\n  # apply width/height\n  if width is not None:\n\n    endx = startx + width\n    endy = None\n\n  elif height is not None:\n\n    if   exp >  0: endy = starty + height\n    elif exp == 0: endy = starty\n    else         : endy = starty - height\n\n    endx = None\n\n  # transform\n  if units.lower() == 'relative':\n    [startx, endx] = rel2abs_x([startx, endx], axis)\n    [starty, endy] = rel2abs_y([starty, endy], axis)\n\n  # determine multiplication constant\n  const = starty / ( startx**exp )\n\n  # get end x/y-coordinate\n  if endx is not None: endy = const * endx**exp\n  else               : endx = ( endy / const )**( 1/exp )\n\n  # middle\n  x = 10. ** ( np.log10(startx) + rx * ( np.log10(endx) - np.log10(startx) ) )\n  y = 10. ** ( np.log10(starty) + ry * ( np.log10(endy) - np.log10(starty) ) )\n\n  # plot\n  return axis.text(x, y, text, **kwargs)", "response": "r Analog to matplotlib s plot_powerlaw function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_powerlaw(exp, startx, starty, width=None, **kwargs):\n  r'''\nPlot a power-law.\n\n:arguments:\n\n  **exp** (``float``)\n    The power-law exponent.\n\n  **startx, starty** (``float``)\n    Start coordinates.\n\n:options:\n\n  **width, height, endx, endy** (``float``)\n    Definition of the end coordinate (only on of these options is needed).\n\n  **units** ([``'relative'``] | ``'absolute'``)\n    The type of units in which the coordinates are specified. Relative coordinates correspond to a\n    fraction of the relevant axis. If you use relative coordinates, be sure to set the limits and\n    scale before calling this function!\n\n  **axis** ([``plt.gca()``] | ...)\n    Specify the axis to which to apply the limits.\n\n  ...\n    Any ``plt.plot(...)`` option.\n\n:returns:\n\n  The handle of the ``plt.plot(...)`` command.\n  '''\n\n  # get options/defaults\n  endx   = kwargs.pop('endx'  , None      )\n  endy   = kwargs.pop('endy'  , None      )\n  height = kwargs.pop('height', None      )\n  units  = kwargs.pop('units' , 'relative')\n  axis   = kwargs.pop('axis'  , plt.gca() )\n\n  # check\n  if axis.get_xscale() != 'log' or axis.get_yscale() != 'log':\n    raise IOError('This function only works on a log-log scale, where the power-law is a straight line')\n\n  # apply width/height\n  if width is not None:\n\n    endx = startx + width\n    endy = None\n\n  elif height is not None:\n\n    if   exp >  0: endy = starty + height\n    elif exp == 0: endy = starty\n    else         : endy = starty - height\n\n    endx = None\n\n  # transform\n  if units.lower() == 'relative':\n    [startx, endx] = rel2abs_x([startx, endx], axis)\n    [starty, endy] = rel2abs_y([starty, endy], axis)\n\n  # determine multiplication constant\n  const = starty / ( startx**exp )\n\n  # get end x/y-coordinate\n  if endx is not None: endy = const * endx**exp\n  else               : endx = ( endy / const )**( 1/exp )\n\n  # plot\n  return axis.plot([startx, endx], [starty, endy], **kwargs)", "response": "r Plot a power - law."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grid_powerlaw(exp, insert=0, skip=0, end=-1, step=0, axis=None, **kwargs):\n  r'''\nDraw a power-law grid: a grid that respects a certain power-law exponent. The grid-lines start from\nthe positions of the ticks.\n\n:arguments:\n\n  **exp** (``float``)\n    The power-law exponent.\n\n:options:\n\n  **insert** (``<int>``)\n    Insert extra lines in between the default lines set by the tick positions.\n\n  **skip, end, step** (``<int>``)\n    Select from the lines based on ``coor = coor[skip:end:step]``.\n\n  **axis** ([``plt.gca()``] | ...)\n    Specify the axis to which to apply the limits.\n\n  ...\n    Any ``plt.plot(...)`` option.\n\n:returns:\n\n  The handle of the ``plt.plot(...)`` command.\n  '''\n\n  # default axis\n  if axis is None: axis = plt.gca()\n\n  # default plot settings\n  kwargs.setdefault('color'    , 'k' )\n  kwargs.setdefault('linestyle', '--')\n  kwargs.setdefault('linewidth',  1  )\n\n  # check\n  if axis.get_xscale() != 'log' or axis.get_yscale() != 'log':\n    raise IOError('This function only works on a log-log scale, where the power-law is a straight line')\n\n  # zero-exponent: draw horizontal lines\n  if exp == 0:\n\n    # y-coordinate of the start positions\n    starty = abs2rel_y(axis.get_yticks(), axis=axis)\n\n    # insert extra coordinates\n    if insert > 0:\n\n      n  = len(starty)\n      x  = np.linspace(0,1,n+(n-1)*int(insert))\n      xp = np.linspace(0,1,n)\n\n      starty = np.interp(x, xp, starty)\n\n    # skip coordinates\n    starty = starty[int(skip):int(end):int(1+step)]\n\n    # set remaining coordinates\n    endy   = starty\n    startx = np.zeros((len(starty)))\n    endx   = np.ones ((len(starty)))\n\n  # all other exponents\n  else:\n\n    # get the axis' size in real coordinates\n    # - get the limits\n    xmin, xmax = axis.get_xlim()\n    ymin, ymax = axis.get_ylim()\n    # - compute the size in both directions\n    deltax = np.log10(xmax) - np.log10(xmin)\n    deltay = np.log10(ymax) - np.log10(ymin)\n\n    # convert the exponent in real coordinates to an exponent in relative coordinates\n    b = np.abs(exp) * deltax / deltay\n\n    # x-coordinate of the start positions\n    startx = abs2rel_x(axis.get_xticks(), axis=axis)\n\n    # compute how many labels need to be prepended\n    Dx   = startx[1] - startx[0]\n    nneg = int(np.floor(1./(b*Dx))) - 1\n\n    # add extra to be sure\n    if insert > 0:\n      nneg += 1\n\n    # prepend\n    if nneg > 0:\n      startx = np.hstack(( startx[0]+np.cumsum(-Dx * np.ones((nneg)))[::-1], startx ))\n\n    # insert extra coordinates\n    if insert > 0:\n\n      n  = len(startx)\n      x  = np.linspace(0,1,n+(n-1)*int(insert))\n      xp = np.linspace(0,1,n)\n\n      startx = np.interp(x, xp, startx)\n\n    # skip coordinates\n    if step > 0:\n\n      startx = startx[int(skip)::int(1+step)]\n\n    # x-coordinate of the end of the lines\n    endx = startx + 1/b\n\n    # y-coordinate of the start and the end of the lines\n    if exp > 0:\n      starty = np.zeros((len(startx)))\n      endy   = np.ones ((len(startx)))\n    else:\n      starty = np.ones ((len(startx)))\n      endy   = np.zeros((len(startx)))\n\n  # convert to real coordinates\n  startx = rel2abs_x(startx, axis)\n  endx   = rel2abs_x(endx  , axis)\n  starty = rel2abs_y(starty, axis)\n  endy   = rel2abs_y(endy  , axis)\n\n  # plot\n  lines = axis.plot(np.vstack(( startx, endx )), np.vstack(( starty, endy )), **kwargs)\n\n  # remove access in labels\n  plt.setp(lines[1:], label=\"_\")\n\n  # return handles\n  return lines", "response": "r Draws a power - law grid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef histogram_bin_edges_mincount(data, min_count, bins):\n  r'''\nMerge bins with right-neighbour until each bin has a minimum number of data-points.\n\n:arguments:\n\n  **data** (``<array_like>``)\n    Input data. The histogram is computed over the flattened array.\n\n  **bins** (``<array_like>`` | ``<int>``)\n    The bin-edges (or the number of bins, automatically converted to equal-sized bins).\n\n  **min_count** (``<int>``)\n    The minimum number of data-points per bin.\n  '''\n\n  # escape\n  if min_count is None : return bins\n  if min_count is False: return bins\n\n  # check\n  if type(min_count) != int: raise IOError('\"min_count\" must be an integer number')\n\n  # keep removing where needed\n  while True:\n\n    P, _ = np.histogram(data, bins=bins, density=False)\n\n    idx = np.where(P < min_count)[0]\n\n    if len(idx) == 0: return bins\n\n    idx = idx[0]\n\n    if idx+1 == len(P): bins = np.hstack(( bins[:(idx)  ], bins[-1]       ))\n    else              : bins = np.hstack(( bins[:(idx+1)], bins[(idx+2):] ))", "response": "r Computes the histogram of data over the bin - edges of the given minimum number of data - points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef histogram_bin_edges(data, bins=10, mode='equal', min_count=None, integer=False, remove_empty_edges=True, min_width=None):\n  r'''\nDetermine bin-edges.\n\n:arguments:\n\n  **data** (``<array_like>``)\n    Input data. The histogram is computed over the flattened array.\n\n:options:\n\n  **bins** ([``10``] | ``<int>``)\n    The number of bins.\n\n  **mode** ([``'equal'`` | ``<str>``)\n    Mode with which to compute the bin-edges:\n    * ``'equal'``: each bin has equal width.\n    * ``'log'``: logarithmic spacing.\n    * ``'uniform'``: uniform number of data-points per bin.\n\n  **min_count** (``<int>``)\n    The minimum number of data-points per bin.\n\n  **min_width** (``<float>``)\n    The minimum width of each bin.\n\n  **integer** ([``False``] | [``True``])\n    If ``True``, bins not encompassing an integer are removed\n    (e.g. a bin with edges ``[1.1, 1.9]`` is removed, but ``[0.9, 1.1]`` is not removed).\n\n  **remove_empty_edges** ([``True``] | [``False``])\n    Remove empty bins at the beginning or the end.\n\n:returns:\n\n  **bin_edges** (``<array of dtype float>``)\n    The edges to pass into histogram.\n  '''\n\n  # determine the bin-edges\n\n  if mode == 'equal':\n\n    bin_edges = np.linspace(np.min(data),np.max(data),bins+1)\n\n  elif mode == 'log':\n\n    bin_edges = np.logspace(np.log10(np.min(data)),np.log10(np.max(data)),bins+1)\n\n  elif mode == 'uniform':\n\n    # - check\n    if hasattr(bins, \"__len__\"):\n      raise IOError('Only the number of bins can be specified')\n\n    # - use the minimum count to estimate the number of bins\n    if min_count is not None and min_count is not False:\n      if type(min_count) != int: raise IOError('\"min_count\" must be an integer number')\n      bins = int(np.floor(float(len(data))/float(min_count)))\n\n    # - number of data-points in each bin (equal for each)\n    count = int(np.floor(float(len(data))/float(bins))) * np.ones(bins, dtype='int')\n\n    # - increase the number of data-points by one is an many bins as needed,\n    #   such that the total fits the total number of data-points\n    count[np.linspace(0, bins-1, len(data)-np.sum(count)).astype(np.int)] += 1\n\n    # - split the data\n    idx     = np.empty((bins+1), dtype='int')\n    idx[0 ] = 0\n    idx[1:] = np.cumsum(count)\n    idx[-1] = len(data) - 1\n\n    # - determine the bin-edges\n    bin_edges = np.unique(np.sort(data)[idx])\n\n  else:\n\n    raise IOError('Unknown option')\n\n  # remove empty starting and ending bin (related to an unfortunate choice of bin-edges)\n\n  if remove_empty_edges:\n\n    N, _ = np.histogram(data, bins=bin_edges, density=False)\n\n    idx = np.min(np.where(N>0)[0])\n    jdx = np.max(np.where(N>0)[0])\n\n    bin_edges = bin_edges[(idx):(jdx+2)]\n\n  # merge bins with too few data-points (if needed)\n\n  bin_edges = histogram_bin_edges_mincount(data, min_count=min_count, bins=bin_edges)\n\n  # merge bins that have too small of a width\n\n  bin_edges = histogram_bin_edges_minwidth(min_width=min_width, bins=bin_edges)\n\n  # select only bins that encompass an integer (and retain the original bounds)\n\n  if integer:\n\n    idx = np.where(np.diff(np.floor(bin_edges))>=1)[0]\n    idx = np.unique(np.hstack((0, idx, len(bin_edges)-1)))\n\n    bin_edges = bin_edges[idx]\n\n  # return\n\n  return bin_edges", "response": "r Computes the bin - edges of the data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cdf(data,mode='continuous',**kwargs):\n  '''\nReturn cumulative density.\n\n:arguments:\n\n  **data** (``<numpy.ndarray>``)\n    Input data, to plot the distribution for.\n\n:returns:\n\n  **P** (``<numpy.ndarray>``)\n    Cumulative probability.\n\n  **x** (``<numpy.ndarray>``)\n    Data points.\n  '''\n\n  return ( np.linspace(0.0,1.0,len(data)), np.sort(data) )", "response": "Return cumulative density.\n\n:arguments:\n\n  **data** (``<numpy.ndarray>``)\n    Input data, to plot the distribution for.\n\n:returns:\n\n  **P** (``<numpy.ndarray>``)\n    Cumulative probability.\n\n  **x** (``<numpy.ndarray>``)\n    Data points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch(*args,**kwargs):\n  '''\nAdd patches to plot. The color of the patches is indexed according to a specified color-index.\n\n:example:\n\n  Plot a finite element mesh: the outline of the undeformed configuration, and the deformed\n  configuration for which the elements get a color e.g. based on stress::\n\n    import matplotlib.pyplot as plt\n    import goosempl          as gplt\n\n    fig,ax = plt.subplots()\n\n    p = gplt.patch(coor=coor+disp,conn=conn,axis=ax,cindex=stress,cmap='YlOrRd',edgecolor=None)\n    _ = gplt.patch(coor=coor     ,conn=conn,axis=ax)\n\n    cbar = fig.colorbar(p,axis=ax,aspect=10)\n\n    plt.show()\n\n:arguments - option 1/2:\n\n  **patches** (``<list>``)\n    List with patch objects. Can be replaced by specifying ``coor`` and ``conn``.\n\n:arguments - option 2/2:\n\n  **coor** (``<numpy.ndarray>`` | ``<list>`` (nested))\n    Matrix with on each row the coordinates (positions) of each node.\n\n  **conn** (``<numpy.ndarray>`` | ``<list>`` (nested))\n    Matrix with on each row the number numbers (rows in ``coor``) which form an element (patch).\n\n:options:\n\n  **cindex** (``<numpy.ndarray>``)\n    Array with, for each patch, the value that should be indexed to a color.\n\n  **axis** (``<matplotlib>``)\n    Specify an axis to include to plot in. By default the current axis is used.\n\n  **autoscale** ([``True``] | ``False``)\n    Automatically update the limits of the plot (currently automatic limits of Collections are not\n    supported by matplotlib).\n\n:recommended options:\n\n  **cmap** (``<str>`` | ...)\n    Specify a colormap.\n\n  **linewidth** (``<float>``)\n    Width of the edges.\n\n  **edgecolor** (``<str>`` | ...)\n    Color of the edges.\n\n  **clim** (``(<float>,<float>)``)\n    Lower and upper limit of the color-axis.\n\n:returns:\n\n  **handle** (``<matplotlib>``)\n    Handle of the patch objects.\n\n.. seealso::\n\n  * `matplotlib example\n    <http://matplotlib.org/examples/api/patch_collection.html>`_.\n  '''\n\n  from matplotlib.collections import PatchCollection\n  from matplotlib.patches     import Polygon\n\n  # check dependent options\n  if ( 'coor' not in kwargs or 'conn' not in kwargs ):\n    raise IOError('Specify both \"coor\" and \"conn\"')\n\n  # extract local options\n  axis      = kwargs.pop( 'axis'      , plt.gca() )\n  cindex    = kwargs.pop( 'cindex'    , None      )\n  coor      = kwargs.pop( 'coor'      , None      )\n  conn      = kwargs.pop( 'conn'      , None      )\n  autoscale = kwargs.pop( 'autoscale' , True      )\n\n  # set defaults\n  kwargs.setdefault('edgecolor','k')\n\n  # no color-index -> set transparent\n  if cindex is None:\n    kwargs.setdefault('facecolor',(0.,0.,0.,0.))\n\n  # convert mesh -> list of Polygons\n  if coor is not None and conn is not None:\n    poly = []\n    for iconn in conn:\n      poly.append(Polygon(coor[iconn,:]))\n    args = tuple(poly, *args)\n\n  # convert patches -> matplotlib-objects\n  p = PatchCollection(args,**kwargs)\n  # add colors to patches\n  if cindex is not None:\n    p.set_array(cindex)\n  # add patches to axis\n  axis.add_collection(p)\n\n  # rescale the axes manually\n  if autoscale:\n    # - get limits\n    xlim = [ np.min(coor[:,0]) , np.max(coor[:,0]) ]\n    ylim = [ np.min(coor[:,1]) , np.max(coor[:,1]) ]\n    # - set limits +/- 10% extra margin\n    axis.set_xlim([xlim[0]-.1*(xlim[1]-xlim[0]),xlim[1]+.1*(xlim[1]-xlim[0])])\n    axis.set_ylim([ylim[0]-.1*(ylim[1]-ylim[0]),ylim[1]+.1*(ylim[1]-ylim[0])])\n\n  return p", "response": "Plot the color of the undeformed configuration and deformed configuration for each element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the squared error between two target values and predicted values.", "response": "def squared_error(y, y_pred):\n    \"\"\"Calculates the sum of the squared\n    differences between target and prediction.\n    \n    Parameters:\n    -----------\n    y : vector, shape (n_samples,)\n    The target values.\n\n    y_pred : vector, shape (n_samples,)\n    The predicted values.\n    \n    Returns:\n    --------\n    error : float number, the sum of the squared\n    differences between target and prediction\n    \n    \"\"\"\n\n    y, y_pred = convert_assert(y, y_pred)\n    return np.sum((y - y_pred) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef absolute_error(y, y_pred):\n\n    y, y_pred = convert_assert(y, y_pred)\n    return np.sum(y - y_pred)", "response": "Calculates the sum of the differences between target and predicted values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the output filter.", "response": "def cmd(send, msg, args):\n    \"\"\"Changes the output filter.\n\n    Syntax: {command} [--channel channel] <filter|--show|--list|--reset|--chain filter,[filter2,...]>\n\n    \"\"\"\n    if args['type'] == 'privmsg':\n        send('Filters must be set in channels, not via private message.')\n        return\n    isadmin = args['is_admin'](args['nick'])\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--channel', nargs='?', default=args['target'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('filter', nargs='?')\n    group.add_argument('--show', action='store_true')\n    group.add_argument('--list', action='store_true')\n    group.add_argument('--reset', '--clear', action='store_true')\n    group.add_argument('--chain')\n    if not msg:\n        send(get_filters(args['handler'], args['target']))\n        return\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.list:\n        send(\"Available filters are %s\" % \", \".join(textutils.output_filters.keys()))\n    elif cmdargs.reset and isadmin:\n        args['handler'].outputfilter[cmdargs.channel].clear()\n        send(\"Okay!\")\n    elif cmdargs.chain and isadmin:\n        if not args['handler'].outputfilter[cmdargs.channel]:\n            send(\"Must have a filter set in order to chain.\")\n            return\n        filter_list, output = textutils.append_filters(cmdargs.chain)\n        if filter_list is not None:\n            args['handler'].outputfilter[cmdargs.channel].extend(filter_list)\n        send(output)\n    elif cmdargs.show:\n        send(get_filters(args['handler'], cmdargs.channel))\n    elif isadmin:\n        # If we're just adding a filter without chain, blow away any existing filters.\n        filter_list, output = textutils.append_filters(cmdargs.filter)\n        if filter_list is not None:\n            args['handler'].outputfilter[cmdargs.channel].clear()\n            args['handler'].outputfilter[cmdargs.channel].extend(filter_list)\n        send(output)\n    else:\n        send('This command requires admin privileges.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new array containing the region with the given identifier", "response": "def select_from_array(cls, array, identifier):\n        \"\"\"Return a region from a numpy array.\n        \n        :param array: :class:`numpy.ndarray`\n        :param identifier: value representing the region to select in the array\n        :returns: :class:`jicimagelib.region.Region`\n        \"\"\"\n\n        base_array = np.zeros(array.shape)\n        array_coords = np.where(array == identifier)\n        base_array[array_coords] = 1\n\n        return cls(base_array)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a region formed by taking non - border elements.", "response": "def inner(self):\n        \"\"\"Region formed by taking non-border elements.\n\n        :returns: :class:`jicimagelib.region.Region`\n        \"\"\"\n\n        inner_array = nd.morphology.binary_erosion(self.bitmap)\n        return Region(inner_array)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef border(self):\n\n        border_array = self.bitmap - self.inner.bitmap\n        return Region(border_array)", "response": "Returns a Region formed by taking border elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convex_hull(self):\n        hull_array = skimage.morphology.convex_hull_image(self.bitmap)\n        return Region(hull_array)", "response": "Returns the convex hull of the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dilate(self, iterations=1):\n        dilated_array = nd.morphology.binary_dilation(self.bitmap, \n                                                      iterations=iterations)\n        return Region(dilated_array)", "response": "Return a dilated region."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a message to dvorak.", "response": "def cmd(send, msg, args):\n    \"\"\"Converts a message to/from dvorak.\n\n    Syntax: {command} <--nick <nick>|msg>\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--nick', action=arguments.NickParser)\n    parser.add_argument('msg', nargs='*')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.msg:\n        if cmdargs.nick:\n            send('--nick cannot be combined with a message')\n        else:\n            send(translate(\" \".join(cmdargs.msg), False).strip())\n    else:\n        log = get_log(args['db'], cmdargs.nick, args['target'])\n        if not log:\n            send(\"Couldn't find a message from %s :(\" % cmdargs.nick)\n        else:\n            send(translate(log))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd(send, msg, args):\n    session = args['db']\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--approve', action='store_true')\n    parser.add_argument('--nick', nargs='?')\n    parser.add_argument('--offset', nargs='?', type=int, default=0)\n    parser.add_argument('quote', nargs='*')\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--list', action='store_true')\n    group.add_argument('--add', action='store_true')\n    group.add_argument('--delete', '--remove', type=int)\n    group.add_argument('--edit', type=int)\n    group.add_argument('--search', nargs='*')\n\n    if not msg:\n        send(do_get_quote(session))\n        return\n\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    if cmdargs.add:\n        if args['type'] == 'privmsg':\n            send(\"You want everybody to know about your witty sayings, right?\")\n        else:\n            if cmdargs.nick is None:\n                send('You must specify a nick.')\n            elif not cmdargs.quote:\n                send('You must specify a quote.')\n            else:\n                isadmin = args['is_admin'](args['nick']) or not args['config']['feature']['quoteapprove']\n                approved = cmdargs.approve or not args['config']['feature']['quoteapprove']\n                do_add_quote(cmdargs.nick, \" \".join(cmdargs.quote), session, isadmin, approved, send, args)\n    elif cmdargs.list:\n        send(do_list_quotes(session, args['config']['core']['url']))\n    elif cmdargs.delete:\n        send(do_delete_quote(args, session, cmdargs.delete))\n    elif cmdargs.edit:\n        if args['is_admin'](args['nick']):\n            send(do_update_quote(session, cmdargs.edit, cmdargs.nick, cmdargs.quote))\n        else:\n            send(\"You aren't allowed to edit quotes. Please ask a bot admin to do it\")\n    elif cmdargs.search:\n        if cmdargs.approve or cmdargs.nick:\n            send(\"Invalid option for --search\")\n        else:\n            send(search_quote(session, cmdargs.offset, cmdargs.search))\n    else:\n        if msg.isdigit():\n            send(do_get_quote(session, int(msg)))\n        else:\n            if not re.match(args['config']['core']['nickregex'], msg):\n                send('Invalid nick %s.' % msg)\n            else:\n                send(get_quotes_nick(session, msg))", "response": "Handles quotes.\n    Syntax: {command} <number|nick>, !quote --add <quote> --nick <nick> (--approve), !quote --list, !quote --delete <number>, !quote --edit <number> <quote> --nick <nick>\n    !quote --search (--offset <num>) <number>"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd(send, _, args):\n    guarded = args['handler'].guarded\n    if not guarded:\n        send(\"Nobody is guarded.\")\n    else:\n        send(\", \".join(guarded))", "response": "Shows the currently guarded nicks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a color tuple give a value within the range of mapped values", "response": "def getColorForValue(self, value):\n        \"\"\"\n        Return a color tuple give a value within the range of mapped values\n        :param value: Lookup value\n        :rtype: tuple of RGB integer values\n        \"\"\"\n        rampIndex = 0\n\n        if value >= self.min and value <= self.max:\n            rampIndex = self.getIndexForValue(value)\n\n        elif value > self.max:\n            rampIndex = -1\n\n        elif value < self.min:\n            rampIndex = 0\n\n        return self.getColorForIndex(rampIndex)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getIndexForValue(self, value):\n        return math.trunc(self.slope * float(value) + self.intercept)", "response": "Returns the ramp index for the given value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the mapped color ramp as aContinuousSLD element.", "response": "def getColorMapAsContinuousSLD(self, nodata=-9999):\n        \"\"\"\n        Return the mapped color ramp as a\n        :rtype: str\n        \"\"\"\n        colorMap = ET.Element('ColorMap', type='interval')\n\n        # Add a line for the no-data values (nv)\n        ET.SubElement(colorMap, 'ColorMapEntry', color='#000000', quantity=str(nodata), label='NoData', opacity='0.0')\n\n        def get_label_formatter(value):\n            label_tag=\"{label:.0f}\"\n            if abs(value) < 0.01 and value != 0:\n                label_tag = \"{label:.2E}\"\n            elif abs(value) < 10:\n                label_tag=\"{label:.2f}\"\n            elif abs(value) < 99:\n                label_tag=\"{label:.1f}\"\n            return label_tag\n\n        if self.min != self.max and self.slope > 0:\n            for rampIndex in range(len(self.colorRamp)):\n                valueForIndex = (rampIndex - self.intercept) / self.slope\n                red, green, blue = self.colorRamp[rampIndex]\n                hexRGB = '#%02X%02X%02X' % (red,\n                                            green,\n                                            blue)\n\n                label_tag = get_label_formatter(valueForIndex)\n                ET.SubElement(colorMap, 'ColorMapEntry', color=hexRGB,\n                              quantity=str(valueForIndex),\n                              label=label_tag.format(label=valueForIndex),\n                              opacity=str(self.alpha))\n        else:\n            valueForIndex = self.max\n            red, green, blue = self.colorRamp[0]\n            hexRGB = '#%02X%02X%02X' % (red,\n                                        green,\n                                        blue)\n            label_tag = get_label_formatter(valueForIndex)\n            ET.SubElement(colorMap, 'ColorMapEntry', color=hexRGB,\n                          quantity=str(valueForIndex),\n                          label=label_tag.format(label=valueForIndex),\n                          opacity=str(self.alpha))\n\n\n        return ET.tostring(colorMap)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getColorMapAsDiscreetSLD(self, uniqueValues, nodata=-9999):\n        colorMap = ET.Element('ColorMap', type='values')\n        # Add a line for the no-data values (nv)\n        ET.SubElement(colorMap, 'ColorMapEntry', color='#000000', quantity=str(nodata), label='NoData', opacity='0.0')\n\n        for value in uniqueValues:\n            red, green, blue = self.getColorForValue(value)\n            hexRGB = '#%02X%02X%02X' % (red,\n                                        green,\n                                        blue)\n\n            ET.SubElement(colorMap, 'ColorMapEntry', color=hexRGB, quantity=str(value), label=str(value), opacity=str(self.alpha))\n\n        return ET.tostring(colorMap)", "response": "Create the color map SLD format from a list of unique values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generateDefaultColorRamp(cls, colorRampEnum):\n        hue = [(255, 0, 255), (231, 0, 255), (208, 0, 255), (185, 0, 255), (162, 0, 255), (139, 0, 255), (115, 0, 255), (92, 0, 255), (69, 0, 255), (46, 0, 255), (23, 0, 255),        # magenta to blue\n                   (0, 0, 255), (0, 23, 255), (0, 46, 255), (0, 69, 255), (0, 92, 255), (0, 115, 255), (0, 139, 255), (0, 162, 255), (0, 185, 255), (0, 208, 255), (0, 231, 255),          # blue to cyan\n                   (0, 255, 255), (0, 255, 231), (0, 255, 208), (0, 255, 185), (0, 255, 162), (0, 255, 139), (0, 255, 115), (0, 255, 92), (0, 255, 69), (0, 255, 46), (0, 255, 23),        # cyan to green\n                   (0, 255, 0), (23, 255, 0), (46, 255, 0), (69, 255, 0), (92, 255, 0), (115, 255, 0), (139, 255, 0), (162, 255, 0), (185, 255, 0), (208, 255, 0), (231, 255, 0),          # green to yellow\n                   (255, 255, 0), (255, 243, 0), (255, 231, 0), (255, 220, 0), (255, 208, 0), (255, 197, 0), (255, 185, 0), (255, 174, 0), (255, 162, 0), (255, 151, 0), (255, 139, 0),    # yellow to orange\n                   (255, 128, 0), (255, 116, 0), (255, 104, 0), (255, 93, 0), (255, 81, 0), (255, 69, 0), (255, 58, 0), (255, 46, 0), (255, 34, 0), (255, 23, 0), (255, 11, 0),            # orange to red\n                   (255, 0, 0)]                                                                                                                                                            # red\n\n        terrain = [(0, 100, 0), (19, 107, 0), (38, 114, 0), (57, 121, 0), (76, 129, 0), (95, 136, 0), (114, 143, 0), (133, 150, 0), (152, 158, 0), (171, 165, 0), (190, 172, 0),                   # dark green to golden rod yellow\n                   (210, 180, 0), (210, 167, 5), (210, 155, 10), (210, 142, 15), (210, 130, 20), (210, 117, 25),                                                                                   # golden rod yellow to orange brown\n                   (210, 105, 30), (188, 94, 25), (166, 83, 21), (145, 72, 17), (123, 61, 13), (101, 50, 9),                                                                                       # orange brown to dark brown\n                   (80, 40, 5), (95, 59, 27), (111, 79, 50), (127, 98, 73), (143, 118, 95), (159, 137, 118),(175, 157, 141), (191, 176, 164), (207, 196, 186), (223, 215, 209), (239, 235, 232),   # dark brown to white\n                   (255, 255, 255)]                                                                                                                                                                # white\n\n        aqua = [(150, 255, 255), (136, 240, 250), (122, 226, 245), (109, 212, 240), (95, 198, 235), (81, 184, 230), (68, 170, 225), (54, 156, 220), (40, 142, 215), (27, 128, 210), (13, 114, 205), # aqua to blue\n                (0, 100, 200), (0, 94, 195), (0, 89, 191), (0, 83, 187), (0, 78, 182), (0, 72, 178), (0, 67, 174), (0, 61, 170), (0, 56, 165), (0, 50, 161), (0, 45, 157), (0, 40, 153),            # blue to navy blue\n                (0, 36, 143), (0, 32, 134), (0, 29, 125), (0, 25, 115), (0, 21, 106), (0, 18, 97), (0, 14, 88), (0, 10, 78), (0, 7, 69), (0, 3, 60), (0, 0, 51)]                                    # navy blue to dark navy blue\n\n\n        if (colorRampEnum == ColorRampEnum.COLOR_RAMP_HUE):\n            return hue\n\n        elif (colorRampEnum == ColorRampEnum.COLOR_RAMP_TERRAIN):\n            return terrain\n\n        elif (colorRampEnum == ColorRampEnum.COLOR_RAMP_AQUA):\n            return aqua", "response": "Generate the default color ramp for the given color ramp enum"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generateCustomColorRamp(cls, colors=[], interpolatedPoints=10):\n        if not (isinstance(colors, list)):\n            print('COLOR RAMP GENERATOR WARNING: colors must be passed in as a list of RGB tuples.')\n            raise\n\n        numColors = len(colors)\n\n        colorRamp = []\n\n        # Iterate over colors\n        for index in range (0, numColors - 1):\n            bottomColor = colors[index]\n            topColor = colors[index + 1]\n\n            colorRamp.append(bottomColor)\n\n            # Calculate slopes\n            rSlope = (topColor[0] - bottomColor[0]) / float(interpolatedPoints)\n            gSlope = (topColor[1] - bottomColor[1]) / float(interpolatedPoints)\n            bSlope = (topColor[2] - bottomColor[2]) / float(interpolatedPoints)\n\n            # Interpolate colors\n            for point in range(1, interpolatedPoints):\n                red = int(rSlope * point + bottomColor[0])\n                green = int(gSlope * point + bottomColor[1])\n                blue = int(bSlope * point + bottomColor[2])\n                color = (red, green, blue)\n\n                # Make sure the color ramp contains unique colors\n                if not (color in colorRamp):\n                    colorRamp.append(color)\n\n        # Append the last color\n        colorRamp.append(colors[-1])\n\n        return colorRamp", "response": "Generates a custom color ramp for the given class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a color ramp based on min and max values of all the rasters.", "response": "def mapColorRampToValues(cls, colorRamp, minValue, maxValue, alpha=1.0):\n        \"\"\"\n        Creates color ramp based on min and max values of all the raster pixels from all rasters. If pixel value is one\n        of the no data values it will be excluded in the color ramp interpolation. Returns colorRamp, slope, intercept\n\n        :param colorRamp: A list of RGB tuples representing a color ramp (e.g.: results of either generate color ramp method)\n        :param minValue: Minimum value of range of values to map to color ramp\n        :param maxValue: Maximum value of range of values to map to color ramp\n        :param alpha: Decimal representing transparency (e.g.: 0.8)\n\n        :rtype : MappedColorRamp\n        \"\"\"\n        minRampIndex = 0  # Always zero\n        maxRampIndex = float(len(colorRamp) - 1)  # Map color ramp indices to values using equation of a line\n\n        # Resulting equation will be:\n        # rampIndex = slope * value + intercept\n        if minValue != maxValue:\n            slope = (maxRampIndex - minRampIndex) / (maxValue - minValue)\n            intercept = maxRampIndex - (slope * maxValue)\n        else:\n            slope = 0\n            intercept = minRampIndex\n\n        # Return color ramp, slope, and intercept to interpolate by value\n        mappedColorRamp = MappedColorRamp(colorRamp=colorRamp,\n                                          slope=slope,\n                                          intercept=intercept,\n                                          min=minValue,\n                                          max=maxValue,\n                                          alpha=alpha)\n\n        return mappedColorRamp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nblames a random user for something.", "response": "def cmd(send, msg, args):\n    \"\"\"Blames a random user for something.\n\n    Syntax: {command} [reason]\n\n    \"\"\"\n    user = choice(get_users(args))\n    if msg:\n        msg = \" for \" + msg\n    msg = \"blames \" + user + msg\n    send(msg, 'action')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting nick s default location to location.", "response": "def set_default(nick, location, session, send, apikey):\n    \"\"\"Sets nick's default location to location.\"\"\"\n    if valid_location(location, apikey):\n        send(\"Setting default location\")\n        default = session.query(Weather_prefs).filter(Weather_prefs.nick == nick).first()\n        if default is None:\n            default = Weather_prefs(nick=nick, location=location)\n            session.add(default)\n        else:\n            default.location = location\n    else:\n        send(\"Invalid or Ambiguous Location\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd(send, msg, args):\n    apikey = args['config']['api']['weatherapikey']\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--date', action=arguments.DateParser)\n    parser.add_argument('--hour', type=int)\n    parser.add_argument('--set', action='store_true')\n    parser.add_argument('string', nargs='*')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if isinstance(cmdargs.string, list):\n        cmdargs.string = \" \".join(cmdargs.string)\n    if cmdargs.set:\n        set_default(args['nick'], cmdargs.string, args['db'], send, apikey)\n        return\n    if cmdargs.hour is not None and cmdargs.hour > 23:\n        send(\"Invalid Hour\")\n        cmdargs.hour = None\n    nick = args['nick'] if args['name'] == 'weather' else '`bjones'\n    if not cmdargs.string:\n        cmdargs.string = get_default(nick, args['db'], send, args['config'], args['source'])\n    if cmdargs.hour is not None:\n        get_hourly(cmdargs, send, apikey)\n    elif cmdargs.date:\n        get_forecast(cmdargs, send, apikey)\n    else:\n        get_weather(cmdargs, send, apikey)", "response": "Gets the weather.\n\n    Syntax: {command} <[--date (date)] [--hour (hour)] (location)|--set (default)>\n    Powered by Weather Underground, www.wunderground.com"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a slogan. Syntax", "response": "def cmd(send, msg, _):\n    \"\"\"Gets a slogan.\n\n    Syntax: {command} [text]\n\n    \"\"\"\n    if not msg:\n        msg = textutils.gen_word()\n    send(textutils.gen_slogan(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evolve(self, years):\n        world_file = fldr + os.sep + self.name + '.txt'\n        self.build_base()\n        self.world.add_mountains()\n        self.add_life()\n        self.world.grd.save(world_file)\n        \n        print('TODO - run ' + str(years) + ' years')", "response": "run the evolution of the planet to see how it looks \n        after years"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a base random land structure using the AIKIF world model", "response": "def build_base(self):\n        \"\"\"\n        create a base random land structure using the AIKIF world model\n        \"\"\"\n        #print('Planet ' + self.name + ' has formed!')\n        self.world = my_world.World( self.grid_height, self.grid_width, [' ','x','#']) \n        \n        perc_land = (self.lava + (self.wind/10) + (self.rain/20) + (self.sun/10))*100\n        perc_sea = (100 - perc_land)\n        perc_blocked = (self.lava/10)*100\n        \n        #print('Calculating world : sea=', perc_sea, ' land=', perc_land, ' mountain=', perc_blocked,  )\n        self.world.build_random( self.num_seeds, perc_land, perc_sea, perc_blocked)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears the verified admins list", "response": "def cmd(send, msg, args):\n    \"\"\"Clears the verified admin list\n    Syntax: {command}\n    \"\"\"\n    args['db'].query(Permissions).update({\"registered\": False})\n    args['handler'].get_admins()\n    send(\"Verified admins reset.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url(self):\n        url = u'{home_url}{permalink}'.format(home_url=settings.HOME_URL,\n                                              permalink=self._permalink)\n        url = re.sub(r'/{2,}', r'/', url)\n        return url", "response": "The site - relative URL to the post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_published(self):\n        return self.status == Status.published and self.timestamp <= arrow.now()", "response": "Returns True if the post is published False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_pending(self):\n        return self.status == Status.published and self.timestamp >= arrow.now()", "response": "True if the post is marked as published but has a timestamp set in the future."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_item(self, all_posts):\n        index = all_posts.index(self)\n        if index > 0:  # has newer posts\n            newer_post = all_posts[index - 1]\n        else:\n            newer_post = None\n\n        if index < len(all_posts) - 1:  # has older posts\n            older_post = all_posts[index + 1]\n        else:\n            older_post = None\n        return settings.JINJA_ENV.get_template(self.template).render(\n            post=self,\n            newer_post=newer_post,\n            older_post=older_post,\n            all_posts=all_posts,\n            nav_context='post'\n        )", "response": "Renders the Post as HTML using the template specified in the html_template_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new PostCollection containing the subset of posts whose status is review.", "response": "def review(self):\n        \"\"\"Returns a new PostCollection containing the subset of posts whose status is :attr:`~Status.review`.\"\"\"\n        return PostCollection([p for p in self if p.status == Status.review])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_tags(self):\n        tags = set()\n        for post in self:\n            tags.update(post.tags)\n        return list(tags)", "response": "Returns a list of all the unique tags as strings that posts in the collection have."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tagged(self, tag):\n        return PostCollection([p for p in self if unicode(tag) in p.tags])", "response": "Returns a new PostCollection containing the subset of posts that are tagged with tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, w):\n        if w not in self.f2i:\n            raise ValueError(\"'{}' does not exist.\".format(w))\n\n        if w in self.reserved:\n            raise ValueError(\"'{}' is one of the reserved words, and thus\"\n                             \"cannot be removed.\".format(w))\n\n        index = self.f2i[w]\n        del self.f2i[w]\n        del self.i2f[index]\n\n        self.words.remove(w)", "response": "Removes a word from the vocabulary. The indices are unchanged."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconstruct_indices(self):\n        del self.i2f, self.f2i\n        self.f2i, self.i2f = {}, {}\n\n        for i, w in enumerate(self.words):\n            self.f2i[w] = i\n            self.i2f[i] = w", "response": "Reconstructs the word indices in case of word removals."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the contents of buffer to the beginning of the cache at the start address.", "response": "def write(self, buffer=bytes(), address=0, count=0):\n        \"\"\" Writes the content of the *buffer* to the :attr:`cache` beginning\n        at the start *address*.\n\n        :param bytes buffer: content to write.\n        :param int address: start address.\n        :param int count: number of bytes to write to the cache.\n        \"\"\"\n        view = memoryview(self._cache)\n        view[address:address + count] = buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflushes the updated file content to the given file.", "response": "def flush(self, file=str()):\n        \"\"\" Flushes the updated file content to the given *file*.\n\n        .. note::  Overwrites an existing file.\n\n        :param str file: name and location of the file.\n            Default is the original file.\n        \"\"\"\n        if file:\n            Path(file).write_bytes(self._cache)\n        else:\n            self.path.write_bytes(self._cache)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_map(fname):\n    print(\"viewing \", fname)\n    \n    app = view_tk(None)\n    app.show_grid_from_file(fname)\n    app.title('Map View')\n    #app.after(2000,vais_main_loop(app))\n    \n        # bind mouse and keyboard for interactivity\n  #  frame = Frame(app, width=100, height=100)\n   # frame.bind(\"<Button-1>\", callback)\n    app.canvas.bind(\"<Button-1>\", callback)\n    app.bind(\"<Key>\", key)\n\n    \n    app.mainloop()", "response": "display a map in high resolution"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the check method and formats the result for analysis.", "response": "def run(self, data):\n        \"\"\"\n        Run the check method and format the result for analysis.\n\n        Args:\n            data (DSM/DMM/MDM): DSM/DMM/MDM instance to check.\n\n        Returns:\n            tuple (int, str): status constant from Checker class and messages.\n        \"\"\"\n        result_type = namedtuple('Result', 'code messages')\n\n        if self.passes is True:\n            result = result_type(Checker.Code.PASSED, '')\n        elif self.passes is False:\n            if self.allow_failure:\n                result = result_type(Checker.Code.IGNORED, '')\n            else:\n                result = result_type(Checker.Code.FAILED, '')\n        else:\n            try:\n                result = self.check(data, **self.arguments)\n                messages = ''\n                if isinstance(result, tuple):\n                    result, messages = result\n\n                if result not in Checker.Code:\n                    result = Checker.Code.PASSED if bool(result) else Checker.Code.FAILED\n\n                if result == Checker.Code.FAILED and self.allow_failure:\n                    result = Checker.Code.IGNORED\n\n                result = result_type(result, messages)\n            except NotImplementedError:\n                result = result_type(Checker.Code.NOT_IMPLEMENTED, '')\n        self.result = result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_numeric(value):\n        return type(value) in [\n            int,\n            float,\n            \n            np.int8,\n            np.int16,\n            np.int32,\n            np.int64,\n\n            np.float16,\n            np.float32,\n            np.float64,\n            np.float128\n        ]", "response": "Test if a value is numeric."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a fortune. nget", "response": "def cmd(send, msg, args):\n    \"\"\"Returns a fortune.\n\n    Syntax: {command} <list|[-a|-o] [module]>\n\n    \"\"\"\n    if msg == 'list':\n        fortunes = list_fortunes() + list_fortunes(True)\n        send(\" \".join(fortunes), ignore_length=True)\n    else:\n        output = get_fortune(msg, args['name'])\n        for line in output.splitlines():\n            send(line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all available Engineer themes.", "response": "def list_theme():\n    \"\"\"List all available Engineer themes.\"\"\"\n    from engineer.themes import ThemeManager\n\n    themes = ThemeManager.themes()\n    col1, col2 = map(max, zip(*[(len(t.id) + 2, len(t.root_path) + 2) for t in themes.itervalues()]))\n\n    themes = ThemeManager.themes_by_finder()\n    for finder in sorted(themes.iterkeys()):\n        if len(themes[finder]) > 0:\n            puts(\"%s: \" % finder)\n            for theme in sorted(themes[finder], key=lambda _: _.id):\n                with indent(4):\n                    puts(\n                        columns(\n                            [colored.cyan(\"%s:\" % theme.id), col1],\n                            [colored.white(theme.root_path, bold=True), col2]\n                        )\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the Maintenance view", "response": "def view(template=None):\n    \"\"\"\n    Create the Maintenance view\n    Must be instantiated\n\n    import maintenance_view\n    MaintenanceView = maintenance_view()\n\n    :param template_: The directory containing the view pages\n    :return:\n    \"\"\"\n    if not template:\n        template = \"Juice/Plugin/MaintenancePage/index.html\"\n\n    class Maintenance(View):\n\n        @classmethod\n        def register(cls, app, **kwargs):\n            super(cls, cls).register(app, **kwargs)\n\n            if cls.get_config(\"APPLICATION_MAINTENANCE_ON\"):\n                app.logger.info(\"APPLICATION MAINTENANCE PAGE IS ON\")\n\n                @app.before_request\n                def on_maintenance():\n                    return cls.render_(layout_=template), 503\n\n    return Maintenance"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes the columns of X to each have the same distribution.", "response": "def quantile_norm(X):\n    \"\"\"Normalize the columns of X to each have the same distribution.\n\n    Given an expression matrix (microarray data, read counts, etc) of M genes\n    by N samples, quantile normalization ensures all samples have the same\n    spread of data (by construction).\n\n    The data across each row are averaged to obtain an average column. Each\n    column quantile is replaced with the corresponding quantile of the average\n    column.\n\n    Parameters\n    ----------\n    X : 2D array of float, shape (M, N)\n        The input data, with M rows (genes/features) and N columns (samples).\n\n    Returns\n    -------\n    Xn : 2D array of float, shape (M, N)\n        The normalized data.\n    \"\"\"\n    # compute the quantiles\n    quantiles = np.mean(np.sort(X, axis=0), axis=1)\n\n    # compute the column-wise ranks. Each observation is replaced with its\n    # rank in that column: the smallest observation is replaced by 1, the\n    # second-smallest by 2, ..., and the largest by M, the number of rows.\n    ranks = np.apply_along_axis(stats.rankdata, 0, X)\n\n    # convert ranks to integer indices from 0 to M-1\n    rank_indices = ranks.astype(int) - 1\n\n    # index the quantiles for each rank with the ranks matrix\n    Xn = quantiles[rank_indices]\n\n    return(Xn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes correlation matrix for two tables.", "response": "def corrdfs(df1,df2,method):\n    \"\"\"\n    df1 in columns\n    df2 in rows    \n    \"\"\"\n    dcorr=pd.DataFrame(columns=df1.columns,index=df2.columns)\n    dpval=pd.DataFrame(columns=df1.columns,index=df2.columns)\n    for c1 in df1:\n        for c2 in df2:\n            if method=='spearman':\n                dcorr.loc[c2,c1],dpval.loc[c2,c1]=spearmanr(df1[c1],df2[c2],\n                                                        nan_policy='omit'\n                                                       )\n            elif method=='pearson':\n                dcorr.loc[c2,c1],dpval.loc[c2,c1]=pearsonr(df1[c1],df2[c2],\n#                                                         nan_policy='omit'\n                                                       )\n                \n    if not df1.columns.name is None:\n        dcorr.columns.name=df1.columns.name\n        dpval.columns.name=df1.columns.name\n    if not df2.columns.name is None:\n        dcorr.index.name=df2.columns.name\n        dpval.index.name=df2.columns.name\n    return dcorr,dpval"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pretty_description(description, wrap_at=None, indent=0):\n    if wrap_at is None or wrap_at < 0:\n        width = console_width(default=79)\n        if wrap_at is None:\n            wrap_at = width\n        else:\n            wrap_at += width\n\n    indent = ' ' * indent\n    text_wrapper = textwrap.TextWrapper(\n        width=wrap_at, replace_whitespace=False,\n        initial_indent=indent, subsequent_indent=indent)\n    new_desc = []\n    for line in description.split('\\n'):\n        new_desc.append(line.replace('\\n', '').strip())\n    while not new_desc[0]:\n        del new_desc[0]\n    while not new_desc[-1]:\n        del new_desc[-1]\n    separators = [i for i, l in enumerate(new_desc) if not l]\n    paragraphs = []\n    if separators:\n        start, end = 0, separators[0]\n        paragraphs.append(new_desc[start:end])\n        for i in range(len(separators) - 1):\n            start = end + 1\n            end = separators[i + 1]\n            paragraphs.append(new_desc[start:end])\n        paragraphs.append(new_desc[end + 1:])\n        return '\\n\\n'.join(text_wrapper.fill(' '.join(p)) for p in paragraphs)\n    return text_wrapper.fill(' '.join(new_desc))", "response": "Return a pretty formatted string given some text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_name(self, indent=0, end='\\n'):\n        print(Style.BRIGHT + ' ' * indent + self.name, end=end)", "response": "Print the name of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print(self, indent=0):\n        text = (\n            '{indent}{magenta}{name}{none} ({dim}{cls}{none}, '\n            'default {dim}{default}{none})'\n        ).format(\n            indent=' ' * indent,\n            dim=Style.DIM,\n            magenta=Fore.MAGENTA,\n            none=Style.RESET_ALL,\n            name=self.name,\n            cls=self.cls,\n            default=self.default\n        )\n\n        if self.description:\n            text += ':\\n' + pretty_description(self.description,\n                                               indent=indent + 2)\n\n        print(text)", "response": "Print self with optional indent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint self with optional indent.", "response": "def print(self, indent=2):\n        \"\"\"Print self with optional indent.\"\"\"\n        status = {\n            ResultCode.NOT_IMPLEMENTED: '{}not implemented{}'.format(\n                Fore.YELLOW, Style.RESET_ALL),\n            ResultCode.IGNORED: '{}failed (ignored){}'.format(\n                Fore.YELLOW, Style.RESET_ALL),\n            ResultCode.FAILED: '{}failed{}'.format(\n                Fore.RED, Style.RESET_ALL),\n            ResultCode.PASSED: '{}passed{}'.format(\n                Fore.GREEN, Style.RESET_ALL),\n        }.get(self.code)\n        print('{bold}{group}{provider}{checker}: {none}{status}{none}'.format(\n            bold=Style.BRIGHT,\n            group=(self.group.name + ' \u2013 ') if self.group.name else '',\n            provider=(self.provider.name + ' \u2013 ') if self.provider else '',\n            checker=self.checker.name,\n            none=Style.RESET_ALL,\n            status=status))\n        if self.messages:\n            for message in self.messages.split('\\n'):\n                print(pretty_description(message, indent=indent))\n            if self.checker.hint:\n                print(pretty_description(\n                    'Hint: ' + self.checker.hint, indent=indent))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the value should be pruned ; False otherwise.", "response": "def filter(self, value, table=None):\n        '''\n        Return True if the value should be pruned; False otherwise.\n\n        If a `table` argument was provided, pass it to filterable_func.\n        '''\n        if table is not None:\n            filterable = self.filterable_func(value, table)\n        else:\n            filterable = self.filterable_func(value)\n        return filterable"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_data(self,\n                 file_path=sys.stdin,\n                 delimiter=',',\n                 categories_delimiter=None):\n        \"\"\"\n        Implement get_dsm method from Provider class.\n\n        Parse CSV to return an instance of DSM.\n\n        Args:\n            file_path (str/fd): path or file descriptor.\n            delimiter (str): character(s) used as delimiter for columns.\n            categories_delimiter (str):\n                character(s) used as delimiter for categories and keys\n                (first column).\n\n        Returns:\n            DSM: instance of DSM.\n        \"\"\"\n        if file_path == sys.stdin:\n            logger.info('Read data from standard input')\n            lines = [line.replace('\\n', '') for line in file_path]\n        else:\n            logger.info('Read data from file ' + file_path)\n            with open(file_path) as file:\n                lines = list(file)\n        columns = lines[0].rstrip('\\n').split(delimiter)[1:]\n        categories = None\n        if categories_delimiter:\n            columns, categories = zip(*[c.split(categories_delimiter, 1)\n                                        for c in columns])\n        size = len(columns)\n        data = [list(map(int, l.split(delimiter)[1:]))\n                for l in lines[1:size + 1]]\n        return DesignStructureMatrix(data, columns, categories)", "response": "Implement get_dsm method from Provider class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse tags in tag group", "response": "def parse_tags(self):\n        \"\"\"Parses tags in tag group\"\"\"\n        tags = []\n        try:\n            for tag in self._tag_group_dict[\"tags\"]:\n                tags.append(Tag(tag))\n        except:\n            return tags\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        if self._is_ignored or \"tags\" not in self._tag_group_dict:\n            return\n        for i in range(len(self._tag_group_dict[\"tags\"])):\n            tag_dict = self._tag_group_dict[\"tags\"][i]\n            for tag in self._tags:\n                if tag.name == tag_dict[\"common.ALLTYPES_NAME\"]:\n                    self._tag_group_dict[\"tags\"][i] = tag.as_dict()\n                    break\n\n        for i in range(len(self._sub_groups)):\n            sub_group = self._sub_groups[i]\n            sub_group.update()\n            self._tag_group_dict[\"tag_groups\"][i] = sub_group.as_dict()", "response": "Updates the dictionary of the tag group"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef model(UserModel):\n\n    db = UserModel.db\n\n    class SlugNameMixin(object):\n        name = db.Column(db.String(255), index=True)\n        slug = db.Column(db.String(255), index=True, unique=True)\n        description = db.Column(db.String(255))\n        image_url = db.Column(db.Text)\n\n        @classmethod\n        def get_by_slug(cls, slug=None, name=None):\n            \"\"\"\n            Return a post by slug\n            \"\"\"\n            if name and not slug:\n                slug = utils.slugify(name)\n            return cls.all().filter(cls.slug == slug).first()\n\n        @classmethod\n        def new(cls, name, slug=None):\n            slug = utils.slugify(name if not slug else slug)\n            return cls.create(name=name, slug=slug)\n\n        def rename(self, name, slug=None):\n            slug = utils.slugify(name if not slug else slug)\n            return self.update(name=name, slug=slug)\n\n    class PublisherType(SlugNameMixin, db.Model):\n        \"\"\"\n        Types\n        \"\"\"\n        @property\n        def total_posts(self):\n            return PublisherPost.all().filter(PublisherPost.type_id == self.id).count()\n\n    class PublisherCategory(SlugNameMixin, db.Model):\n        \"\"\"\n        Category\n        \"\"\"\n        @property\n        def total_posts(self):\n            return PublisherCategoryMap.all()\\\n                .filter(PublisherCategoryMap.category_id == self.id)\\\n                .count()\n\n    class PublisherTag(SlugNameMixin, db.Model):\n        \"\"\"\n        Tag\n        \"\"\"\n        @property\n        def total_posts(self):\n            return PublisherTagMap.all()\\\n                .filter(PublisherTagMap.tag_id == self.id)\\\n                .count()\n\n    class PublisherTagMap(db.Model):\n        \"\"\"\n        PostPostTag\n        \"\"\"\n        post_id = db.Column(db.Integer, db.ForeignKey(\"publisher_post.id\", ondelete='CASCADE'))\n        tag_id = db.Column(db.Integer, db.ForeignKey(PublisherTag.id, ondelete='CASCADE'))\n\n        @classmethod\n        def add(cls, post_id, tag_id):\n            c = cls.all().filter(cls.post_id == post_id)\\\n                .filter(cls.tag_id == tag_id)\\\n                .first()\n            if not c:\n                cls.create(post_id=post_id, tag_id=tag_id)\n\n        @classmethod\n        def remove(cls, post_id, tag_id):\n            c = cls.all().filter(cls.post_id == post_id)\\\n                .filter(cls.tag_id == tag_id)\\\n                .first()\n            if c:\n                c.delete(hard_delete=True)\n\n    class PublisherCategoryMap(db.Model):\n        post_id = db.Column(db.Integer, db.ForeignKey(\"publisher_post.id\", ondelete='CASCADE'))\n        category_id = db.Column(db.Integer, db.ForeignKey(PublisherCategory.id, ondelete='CASCADE'))\n\n        @classmethod\n        def add(cls, post_id, category_id):\n            c = cls.all().filter(cls.post_id == post_id)\\\n                .filter(cls.category_id == category_id)\\\n                .first()\n            if not c:\n                cls.create(post_id=post_id, category_id=category_id)\n\n        @classmethod\n        def remove(cls, post_id, category_id):\n            c = cls.all().filter(cls.post_id == post_id)\\\n                .filter(cls.category_id == category_id)\\\n                .first()\n            if c:\n                c.delete(hard_delete=True)\n\n    class PublisherPost(db.Model):\n\n        user_id = db.Column(db.Integer, db.ForeignKey(UserModel.id))\n        type_id = db.Column(db.Integer, db.ForeignKey(PublisherType.id))\n\n        title = db.Column(db.String(255))\n        slug = db.Column(db.String(255), index=True)\n        content = db.Column(db.Text)\n        description = db.Column(db.Text)\n        featured_image = db.Column(db.Text)\n        featured_embed = db.Column(db.Text)\n        featured_media_top = db.Column(db.String(10))\n        language = db.Column(db.String(255))\n        parent_id = db.Column(db.Integer)  # If the post is derived from another post\n        is_child = db.Column(db.Boolean, index=True, default=False)  #\n        is_list = db.Column(db.Boolean, index=True, default=False)  # A list is a type of post having sub post\n        is_featured = db.Column(db.Boolean, index=True, default=False)  # Feature post are limited\n        featured_at = db.Column(db.DateTime)\n        is_sticky = db.Column(db.Boolean, index=True, default=False)  # A sticky post usually stay on top, no matter the count\n        sticky_at = db.Column(db.DateTime)\n        is_published = db.Column(db.Boolean, index=True, default=True)\n        published_at = db.Column(db.DateTime)\n        published_by = db.Column(db.Integer)\n        is_revision = db.Column(db.Boolean, default=False)\n        revision_id = db.Column(db.Integer)  # When updating the post, will auto-save\n\n        is_public = db.Column(db.Boolean, index=True, default=False)\n        is_draft = db.Column(db.Boolean, index=True, default=False)\n        options_data = db.Column(db.Text, default=\"{}\")\n        menu_order = db.Column(db.Integer, default=0, index=True)\n\n        author = db.relationship(UserModel, backref=\"posts\")\n        type = db.relationship(PublisherType, backref=\"posts\")\n        categories = db.relationship(PublisherCategory,\n                                     secondary=PublisherCategoryMap.__table__.name)\n        tags = db.relationship(PublisherTag,\n                                     secondary=PublisherTagMap.__table__.name)\n\n        @classmethod\n        def new(cls, title, **kwargs):\n            \"\"\"\n            Insert a new post\n            \"\"\"\n            published_date = None\n            is_revision = False\n            is_published = False\n            is_draft = False\n            is_public = kwargs.get(\"is_public\", True)\n            parent_id = kwargs.get(\"parent_id\", None)\n\n            if kwargs.get(\"is_revision\"):\n                if not parent_id:\n                    raise ModelError(\"'parent_id' is missing for revision\")\n                is_revision = True\n                is_public = False\n            elif kwargs.get(\"is_draft\"):\n                is_draft = True\n                is_public = False\n            elif kwargs.get(\"is_published\"):\n                is_published = True\n                published_date = datetime.datetime.now()\n\n            slug = None\n            if is_published or is_draft:\n                slug = cls.create_slug(kwargs.get(\"slug\", title))\n\n            type_id = kwargs.get(\"type_id\")\n            if not type_id and kwargs.get(\"type_slug\"):\n                type_slug = kwargs.get(\"type_slug\")\n                _type = PublisherType.get_by_slug(slug=type_slug)\n                if _type:\n                    type_id = _type.id\n\n            data = {\n                \"user_id\": kwargs.get(\"user_id\", 0),\n                \"title\": title,\n                \"slug\": slug,\n                \"content\": kwargs.get(\"content\"),\n                \"description\": kwargs.get(\"description\"),\n                \"is_published\": is_published,\n                \"published_at\": published_date,\n                \"is_draft\": is_draft,\n                \"is_revision\": is_revision,\n                \"is_public\": is_public,\n                \"parent_id\": parent_id,\n                \"type_id\": type_id\n            }\n            return cls.create(**data)\n\n        @classmethod\n        def get_published(cls, id=None, slug=None, types=[], categories=[], tags=[]):\n            \"\"\"\n            Return published posts.\n            If $id or $slug it will return a single post, else all\n\n            :param id: int - the id of a post\n            :param slug: string - the slug of a post\n            :param types: list - list of types slugs\n            :param categories: list - list of categories slug\n            :param tags: list - list of tags slugs\n            :return:\n            \"\"\"\n            q = cls.all().filter(cls.is_published == True)\n\n            # Query only a single post\n            if id or slug:\n                if id:\n                    q = q.filter(cls.id == id)\n                elif slug:\n                    q = q.filter(cls.slug == slug)\n                return q.first()\n\n            # Query lists\n            else:\n                if types:\n                    q = q.join(PublisherType)\\\n                        .filter(PublisherType.slug.in_(types))\n                if categories:\n                    q = q.join(PublisherCategoryMap)\\\n                        .join(PublisherCategory)\\\n                        .filter(PublisherCategory.slug.in_(categories))\n                if tags:\n                    q = q.join(PublisherTag)\\\n                        .filter(PublisherTag.slug.in_(tags))\n                return q\n\n        @classmethod\n        def create_slug(cls, title):\n            slug = None\n            slug_counter = 0\n            _slug = utils.slugify(title).lower()\n            while True:\n                slug = _slug\n                if slug_counter > 0:\n                    slug += str(slug_counter)\n                slug_counter += 1\n                if not cls.get_by_slug(slug):\n                    break\n            return slug\n\n        @classmethod\n        def get_by_slug(cls, slug):\n            \"\"\"\n            Return a post by slug\n            \"\"\"\n            return cls.all().filter(cls.slug == slug).first()\n\n        def publish(self, published_date=None, published_by_id=None):\n            if self.is_draft:\n                data = {\n                    \"is_draft\": False,\n                    \"is_published\": True,\n                    \"published_at\": published_date or datetime.datetime.now()\n                }\n                if published_by_id:\n                    data.update({\n                        \"published_by\": published_by_id\n                    })\n\n                self.update(**data)\n\n        def set_slug(self, title):\n            slug = utils.slugify(title)\n            if title and slug != self.slug:\n                slug = self.create_slug(slug)\n                self.update(slug=slug)\n\n        def update_categories(self, categories_list):\n            \"\"\"\n            Update categories by replacing existing list with new list\n            :param categories_list: list. The new list of category\n            \"\"\"\n            cats = PublisherCategoryMap.all()\\\n                    .filter(PublisherCategoryMap.post_id == self.id)\n            cats_list = [c.category_id for c in cats]\n\n            del_cats = list(set(cats_list) - set(categories_list))\n            new_cats = list(set(categories_list) - set(cats_list))\n\n            for dc in del_cats:\n                PublisherCategoryMap.remove(post_id=self.id, category_id=dc)\n\n            for nc in new_cats:\n                PublisherCategoryMap.add(post_id=self.id, category_id=nc)\n\n        def update_tags(self, tags_list):\n            \"\"\"\n            Update tags by replacing existing list with new list\n            :param tags_list: list. The new list of tags\n            \"\"\"\n            tags = PublisherTagMap.all()\\\n                    .filter(PublisherTagMap.post_id == self.id)\n            tags_list_ = [c.tag_id for c in tags]\n\n            del_tags = list(set(tags_list_) - set(tags_list))\n            new_tags = list(set(tags_list) - set(tags_list_))\n\n            for dc in del_tags:\n                PublisherTagMap.remove(post_id=self.id, tag_id=dc)\n\n            for nc in new_tags:\n                PublisherTagMap.add(post_id=self.id, tag_id=nc)\n\n        def get_list(self):\n            if not self.is_list:\n                return None\n\n            return PublisherPost.all()\\\n                .filter(PublisherPost.is_published == True)\\\n                .filter(PublisherPost.is_child == True)\\\n                .filter(PublisherPost.parent_id == self.id)\n\n        def delete_revisions(self):\n            \"\"\"\n            Delete all revisions\n            \"\"\"\n            try:\n                PublisherPost.all()\\\n                    .filter(PublisherPost.post_id == self.id)\\\n                    .filter(PublisherPost.is_revision == True)\\\n                    .delete()\n                PublisherPost.db.commit()\n            except Exception as ex:\n                PublisherPost.db.rollback()\n\n        def set_options(self, key, values):\n            options = self.options\n            options.update({key: values})\n            self.update(options_data=json.dumps(options))\n\n        @property\n        def options(self):\n            return json.loads(self.options_data) if self.options_data else {}\n\n        @property\n        def excerpt(self):\n            \"\"\"\n            Return description as excerpt, if empty,\n            it will return the first paragraph\n            :return: str\n            \"\"\"\n            if self.description:\n                return self.description\n            else:\n                return \"\"\n\n        @property\n        def top_image(self):\n            \"\"\"\n            Return the top image\n            Return the image url if exists, or it will get the first image\n            Will get the first image from the markdown\n            \"\"\"\n            if self.featured_image:\n                return self.featured_image\n            elif self.content:\n                md_images = markdown_ext.extract_images(self.content)\n                return md_images[0] if md_images else None\n\n        @property\n        def status(self):\n            if self.is_published:\n                return \"Published\"\n            elif self.is_draft:\n                return \"Draft\"\n            elif self.is_revision:\n                return \"Revision\"\n            else:\n                return \"\"\n\n        @property\n        def total_revisions(self):\n            return PublisherPost.all()\\\n                .filter(PublisherPost.post_id == self.id)\\\n                .filter(PublisherPost.is_revision == True)\\\n                .count()\n\n    class PublisherUploadObject(db.Model):\n        parent_id = db.Column(db.Integer, index=True)\n        user_id = db.Column(db.Integer, index=True)\n        provider = db.Column(db.String(255))\n        container = db.Column(db.String(255))\n        local_path = db.Column(db.Text)\n        name = db.Column(db.Text)\n        description = db.Column(db.String(255))\n        size = db.Column(db.Integer)\n        extension = db.Column(db.String(10), index=True)\n        type = db.Column(db.String(25), index=True)\n        object_path = db.Column(db.Text)\n        object_url = db.Column(db.Text)\n        is_private = db.Column(db.Boolean, index=True, default=False)\n\n    return utils.to_struct(Post=PublisherPost,\n                           Category=PublisherCategory,\n                           Type=PublisherType,\n                           CategoryMap=PublisherCategoryMap,\n                           Tag=PublisherTag,\n                           TagMap=PublisherTagMap,\n                           UploadObject=PublisherUploadObject)", "response": "Returns a new model that represents the user s terms."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef page(view, **kwargs):\n\n    # Totally required\n    PublisherModel = kwargs.get(\"model\")\n    Post = PublisherModel.Post\n\n    view_name = view.__name__\n    templates_dir = kwargs.get(\"template_dir\", \"Juice/Plugin/Publisher/Page\")\n    template_page = templates_dir + \"/%s.html\"\n    slug = kwargs.get(\"slug\", \"slug\")\n    endpoint = kwargs.get(\"endpoint\", \"pages\")\n    endpoint_path = \"/%s/\" % endpoint\n    endpoint_namespace = view_name + \":\" + endpoint + \":\" + \"%s\"\n    title = kwargs.get(\"title\", \"\")\n    description = kwargs.get(\"description\", \"\")\n\n    query = kwargs.get(\"query\", {})\n    query.setdefault(\"types\", [])\n    query.setdefault(\"categories\", [])\n    query.setdefault(\"tags\", [])\n    query.setdefault(\"order_by\", \"published_at desc\")\n    query.setdefault(\"per_page\", 20)\n\n    _menu = kwargs.get(\"menu\", {})\n    _menu.setdefault(\"name\", \"Pages\")\n    _menu.setdefault(\"order\", 100)\n    _menu.setdefault(\"visible\", True)\n    _menu.setdefault(\"extends\", view)\n    _menu.pop(\"endpoint\", None)\n\n    #  Options for page_single to customize the slug format\n    # It will be used to access the proper endpoint and format the\n    slug_format = {\n        \"id\": {\n            \"url\": \"{id}\",\n            \"accept\": [\"id\"],\n            \"route\": \"%s/<int:id>\" % endpoint_path,\n            \"endpoint\": \"%s:%s\" % (view_name, \"id\")\n        },\n        \"slug\": {\n            \"url\": \"{slug}\",\n            \"accept\": [\"slug\"],\n            \"route\": \"%s/<slug>\" % endpoint_path,\n            \"endpoint\": \"%s:%s\" % (view_name, \"slug\")\n        },\n        \"id-slug\": {\n            \"url\": \"{id}/{slug}\",\n            \"accept\": [\"id\", \"slug\"],\n            \"route\": \"%s/<int:id>/<slug>\" % endpoint_path,\n            \"endpoint\": \"%s:%s\" % (view_name, \"id-slug\")\n        },\n        \"month-slug\": {\n            \"url\": \"{month}/{slug}\",\n            \"accept\": [\"month\", \"slug\"],\n            \"route\": '%s/<regex(\"[0-9]{4}/[0-9]{2}\"):month>/<slug>' % endpoint_path,\n            \"endpoint\": \"%s:%s\" % (view_name, \"month-slug\")\n        },\n        \"date-slug\": {\n            \"url\": \"{date}/{slug}\",\n            \"accept\": [\"date\", \"slug\"],\n            \"route\": '%s/<regex(\"[0-9]{4}/[0-9]{2}/[0-9]{2}\"):date>/<slug>' % endpoint_path,\n            \"endpoint\": \"%s:%s\" % (view_name, \"id\")\n        }\n    }\n\n    class Page(object):\n\n        @classmethod\n        def prepare_post(cls, post):\n            \"\"\"\n            Prepare the post data,\n            \"\"\"\n            url_kwargs = {\n                \"id\": post.id,\n                \"slug\": post.slug,\n                \"date\": post.published_at.strftime(\"%Y/%m/%d\"),\n                \"month\": post.published_at.strftime(\"%Y/%m\")\n            }\n            # Filter items not in the 'accept'\n            url_kwargs = {_: None if _ not in slug_format.get(slug)[\"accept\"]\n                                  else __\n                                  for _, __ in url_kwargs.items()}\n\n            url = url_for(slug_format.get(slug)[\"endpoint\"],\n                          _external=True,\n                          **url_kwargs)\n            post.url = url\n            return post\n\n        @classmethod\n        def prepare_author(cls, author):\n            \"\"\"\n            Prepare the author data\n            \"\"\"\n            name = utils.slugify(author.name or \"no-name\")\n            #url = url_for(\"%s:post_author\" % view_name, id=author.id, name=name, _external=True)\n            #author.url = url\n            return author\n\n        @classmethod\n        def get_prev_next_post(cls, post, position):\n            \"\"\"\n            Return previous or next post based on the current post\n            :params post: post object\n            :params position:\n            \"\"\"\n            position = position.lower()\n            if position not in [\"prev\", \"next\"]:\n                 raise ValueError(\"Invalid position key. Must be 'prev' or 'next'\")\n\n            posts = Post.get_published(types=post_types)\n\n            if position == \"prev\":\n                posts = posts.filter(Post.id < post.id)\n            elif position == \"next\":\n                posts = posts.filter(Post.id > post.id)\n            post = posts.first()\n            return cls.prepare_post(post) if post else None\n\n        @menu(endpoint=endpoint_namespace % \"page_index\", **_menu)\n        @template(template_page % \"page_index\")\n        @route(endpoint_path, endpoint=endpoint_namespace % \"page_index\")\n        def page_index(self, endpoint=None):\n\n            page = request.args.get(\"page\", 1)\n            app_per_page = self.get_config(\"APPLICATION_PAGINATION_PER_PAGE\", 10)\n            per_page = query.get(\"limit\", app_per_page)\n\n            self.meta_tags(title=title, description=description)\n\n            _query = {\"types\": query.get(\"types\"),\n                      \"categories\": query.get(\"categories\"),\n                      \"tags\": query.get(\"tags\")}\n\n            posts = Post\\\n                .get_published(**_query)\\\n                .order_by(query.get(\"order_by\"))\n\n            posts = posts.paginate(page=page,\n                                   per_page=per_page,\n                                   callback=self.prepare_post)\n            _kwargs = {\n                \"\"\"\n                \"post_header\": opt_endpoints.get(\"index.post_header\", None),\n                \"post_subheader\": opt_endpoints.get(\"index.post_subheader\", None),\n                \"post_show_byline\": opt_endpoints.get(\"index.post_show_byline\", True)\n                visible_with_\n                \"\"\"\n            }\n            _kwargs = dict()\n            return dict(posts=posts, **_kwargs)\n\n        @menu(\"%s Page\" % _menu[\"name\"],\n              visible=False,\n              endpoint=slug_format.get(slug).get(\"endpoint\"),\n              extends=view)  # No need to show the read in the menu\n        @template(template_page % \"page_single\")\n        @route(slug_format.get(slug).get(\"route\"),\n               endpoint=slug_format.get(slug).get(\"endpoint\"))\n        def page_single(self, id=None, slug=None, month=None, date=None):\n            \"\"\"\n            Endpoints options\n                single\n                    - post_show_byline\n            \"\"\"\n            post = None\n            _q = {}\n            if id:\n                _q = {\"id\": id}\n            elif slug:\n                _q = {\"slug\": slug}\n\n            post = Post.get_published(types=query.get(\"types\"), **_q)\n            if not post:\n                abort(\"PublisherPageNotFound\")\n\n            self.meta_tags(title=post.title,\n                           image=post.top_image,\n                           description=post.excerpt)\n\n            _kwargs = {\n                #\"post_show_byline\": opt_endpoints.get(\"single.post_show_byline\", True)\n            }\n            _kwargs = dict()\n            return dict(post=self.prepare_post(post), **_kwargs)\n\n        @menu(\"%s Archive\" % _menu[\"name\"],\n              visible=False,\n              endpoint=endpoint_namespace % \"page_archive\",\n              extends=view)\n        @template(template_page % \"page_archive\")\n        @route(endpoint_path + \"archive/\",\n               endpoint=endpoint_namespace % \"page_archive\")\n        def page_archive(self):\n\n            self.meta_tags(title=\"Archive\")\n\n            _query = {\"types\": query.get(\"types\"),\n                      \"categories\": query.get(\"categories\"),\n                      \"tags\": query.get(\"tags\")}\n\n            posts = Post.get_published(**_query)\\\n                .order_by(Post.published_at.desc())\\\n                .group_by(Post.db.func.year(Post.published_at),\n                          Post.db.func.month(Post.published_at))\n\n            return dict(posts=posts)\n\n        '''\n        @menu(opt_endpoints.get(\"authors.menu\", \"Authors\"),\n              visible=opt_endpoints.get(\"authors.show_menu\", False),\n              #order=opt_endpoints.get(\"authors.menu_order\", 91),\n              endpoint=endpoint_namespace % \"post_authors\",\n              extends=view)\n        @template(template_page % \"post_authors\")\n        @route(opt_endpoints.get(\"authors.endpoint\", \"authors\"),\n               endpoint=endpoint_namespace % \"post_authors\")\n        def post_authors(self):\n            \"\"\"\n            Endpoints options\n                - authors\n                    menu\n                    show_menu\n                    menu_order\n                    endpoint\n                    title\n            \"\"\"\n\n            self.meta_tags(title=opt_endpoints.get(\"authors.title\", \"Authors\"))\n\n            authors = []\n            return dict(authors=authors)\n\n        @menu(opt_endpoints.get(\"author.menu\", \"Author\"),\n              visible=False,\n              endpoint=endpoint_namespace % \"post_author\",\n              extends=view)\n        @template(template_page % \"post_author\")\n        @route(\"%s/<id>/<name>\" % opt_endpoints.get(\"author.endpoint\", \"author\"),\n               endpoint=endpoint_namespace % \"post_author\")\n        def post_author(self, id, name=None):\n            \"\"\"\n            Endpoints options\n                - author\n                    endpoint\n            \"\"\"\n\n            self.meta_tags(title=opt_endpoints.get(\"author.title\", \"Author\"))\n\n            author = []\n            return dict(author=author)\n        '''\n\n    \"\"\"\n    method_name = namespace.lower()\n    maps = {\n        \"page_index\": \"index\"\n    }\n    new_class_page = type(\"Page\" + namespace.capitalize(), (Page,), {})\n    new_class_page.slug_format = slug_format\n    new_class_page.slug = slug\n\n\n    for k, v in maps.items():\n        m = copy.deepcopy(getattr(new_class_page, k))\n        key = method_name + \"_\" + v\n        setattr(new_class_page, key, m)\n        nm = getattr(new_class_page, k)\n        #print(inspect.getargspec(nm))\n        if v == \"index\":\n            menu(options.get(\"menu\"),\n                  visible=True if options.get(\"menu\") else False,\n                  endpoint=\"Index:pages_index\",\n                  extends=view)(nm)\n        template(template_page % \"page_\" + v)(nm)\n        #route(endpoint_path, endpoint=endpoint_namespace % v)(nm)\n    return new_class_page\n    \"\"\"\n\n\n\n    return Page", "response": "This function creates a plugin that can read list content from the CMS and attach the publisher front - end to the views"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a float to a JSON string.", "response": "def float2json(value):\n    \"\"\"\n    CONVERT NUMBER TO JSON STRING, WITH BETTER CONTROL OVER ACCURACY\n    :param value: float, int, long, Decimal\n    :return: unicode\n    \"\"\"\n    if value == 0:\n        return u'0'\n    try:\n        sign = \"-\" if value < 0 else \"\"\n        value = abs(value)\n        sci = value.__format__(\".15e\")\n        mantissa, str_exp = sci.split(\"e\")\n        digits, more_digits = _snap_to_base_10(mantissa)\n        int_exp = int(str_exp) + more_digits\n        if int_exp > 15:\n            return sign + digits[0] + '.' + (digits[1:].rstrip('0') or '0') + u\"e\" + text_type(int_exp)\n        elif int_exp >= 0:\n            return sign + (digits[:1 + int_exp] + '.' + digits[1 + int_exp:].rstrip('0')).rstrip('.')\n        elif -4 < int_exp:\n            digits = (\"0\" * (-int_exp)) + digits\n            return sign + (digits[:1] + '.' + digits[1:].rstrip('0')).rstrip('.')\n        else:\n            return sign + digits[0] + '.' + (digits[1:].rstrip('0') or '0') + u\"e\" + text_type(int_exp)\n    except Exception as e:\n        from mo_logs import Log\n        Log.error(\"not expected\", e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scrub(value, scrub_text=_keep_whitespace, scrub_number=_scrub_number):\n    return _scrub(value, set(), [], scrub_text=scrub_text, scrub_number=scrub_number)", "response": "Scrubs a value into a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value2json(obj, pretty=False, sort_keys=False, keep_whitespace=True):\n    if FIND_LOOPS:\n        obj = scrub(obj, scrub_text=_keep_whitespace if keep_whitespace else _trim_whitespace())\n    try:\n        json = json_encoder(obj, pretty=pretty)\n        if json == None:\n            Log.note(str(type(obj)) + \" is not valid{{type}}JSON\", type=\" (pretty) \" if pretty else \" \")\n            Log.error(\"Not valid JSON: \" + str(obj) + \" of type \" + str(type(obj)))\n        return json\n    except Exception as e:\n        e = Except.wrap(e)\n        try:\n            json = pypy_json_encode(obj)\n            return json\n        except Exception:\n            pass\n        Log.error(\"Can not encode into JSON: {{value}}\", value=text_type(repr(obj)), cause=e)", "response": "Converts a value into a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a JSON string to a Python value.", "response": "def json2value(json_string, params=Null, flexible=False, leaves=False):\n    \"\"\"\n    :param json_string: THE JSON\n    :param params: STANDARD JSON PARAMS\n    :param flexible: REMOVE COMMENTS\n    :param leaves: ASSUME JSON KEYS ARE DOT-DELIMITED\n    :return: Python value\n    \"\"\"\n    if not is_text(json_string):\n        Log.error(\"only unicode json accepted\")\n\n    try:\n        if flexible:\n            # REMOVE \"\"\"COMMENTS\"\"\", # COMMENTS, //COMMENTS, AND \\n \\r\n            # DERIVED FROM https://github.com/jeads/datasource/blob/master/datasource/bases/BaseHub.py# L58\n            json_string = re.sub(r\"\\\"\\\"\\\".*?\\\"\\\"\\\"\", r\"\\n\", json_string, flags=re.MULTILINE)\n            json_string = \"\\n\".join(remove_line_comment(l) for l in json_string.split(\"\\n\"))\n            # ALLOW DICTIONARY'S NAME:VALUE LIST TO END WITH COMMA\n            json_string = re.sub(r\",\\s*\\}\", r\"}\", json_string)\n            # ALLOW LISTS TO END WITH COMMA\n            json_string = re.sub(r\",\\s*\\]\", r\"]\", json_string)\n\n        if params:\n            # LOOKUP REFERENCES\n            json_string = expand_template(json_string, params)\n\n        try:\n            value = wrap(json_decoder(text_type(json_string)))\n        except Exception as e:\n            Log.error(\"can not decode\\n{{content}}\", content=json_string, cause=e)\n\n        if leaves:\n            value = wrap_leaves(value)\n\n        return value\n\n    except Exception as e:\n        e = Except.wrap(e)\n\n        if not json_string.strip():\n            Log.error(\"JSON string is only whitespace\")\n\n        c = e\n        while \"Expecting '\" in c.cause and \"' delimiter: line\" in c.cause:\n            c = c.cause\n\n        if \"Expecting '\" in c and \"' delimiter: line\" in c:\n            line_index = int(strings.between(c.message, \" line \", \" column \")) - 1\n            column = int(strings.between(c.message, \" column \", \" \")) - 1\n            line = json_string.split(\"\\n\")[line_index].replace(\"\\t\", \" \")\n            if column > 20:\n                sample = \"...\" + line[column - 20:]\n                pointer = \"   \" + (\" \" * 20) + \"^\"\n            else:\n                sample = line\n                pointer = (\" \" * column) + \"^\"\n\n            if len(sample) > 43:\n                sample = sample[:43] + \"...\"\n\n            Log.error(CAN_NOT_DECODE_JSON + \" at:\\n\\t{{sample}}\\n\\t{{pointer}}\\n\", sample=sample, pointer=pointer)\n\n        base_str = strings.limit(json_string, 1000).encode('utf8')\n        hexx_str = bytes2hex(base_str, \" \")\n        try:\n            char_str = \" \" + \"  \".join((c.decode(\"latin1\") if ord(c) >= 32 else \".\") for c in base_str)\n        except Exception:\n            char_str = \" \"\n        Log.error(CAN_NOT_DECODE_JSON + \":\\n{{char_str}}\\n{{hexx_str}}\\n\", char_str=char_str, hexx_str=hexx_str, cause=e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries WolframAlpha. Syntax: {command} <expression>", "response": "def cmd(send, msg, args):\n    \"\"\"Queries WolframAlpha.\n\n    Syntax: {command} <expression>\n\n    \"\"\"\n    if not msg:\n        send(\"Evaluate what?\")\n        return\n    params = {'format': 'plaintext', 'reinterpret': 'true', 'input': msg, 'appid': args['config']['api']['wolframapikey']}\n    req = get('http://api.wolframalpha.com/v2/query', params=params)\n    if req.status_code == 403:\n        send(\"WolframAlpha is having issues.\")\n        return\n    if not req.content:\n        send(\"WolframAlpha returned an empty response.\")\n        return\n    xml = fromstring(req.content)\n    output = xml.findall('./pod')\n    key = args['config']['api']['bitlykey']\n    url = get_short(\"http://www.wolframalpha.com/input/?i=%s\" % quote(msg), key)\n    text = \"No output found.\"\n    for x in output:\n        if 'primary' in x.keys():\n            text = x.find('./subpod/plaintext').text\n    if text is None:\n        send(\"No Output parsable\")\n    else:\n        # Only send the first three lines of output\n        for t in text.splitlines()[:3]:\n            send(t)\n    send(\"See %s for more info\" % url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning BeautifulSoup object for given page", "response": "def _get_soup(page):\n\t\"\"\"Return BeautifulSoup object for given page\"\"\"\n\trequest = requests.get(page)\n\tdata = request.text\n\treturn bs4.BeautifulSoup(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning most recently added torrents. Can be sorted and categorized and contain multiple pages.", "response": "def recent(category=None, pages=1, sort=None, order=None):\n\t\"\"\"Return most recently added torrents. Can be sorted and categorized\n\t\tand contain multiple pages.\"\"\"\n\ts = Search()\n\ts.recent(category, pages, sort, order)\n\treturn s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, term=None, category=None, pages=1, url=search_url,\n\t\t\t\tsort=None, order=None):\n\t\t\"\"\"Search a given URL for torrent results.\"\"\"\n\n\t\tif not self.current_url:\n\t\t\tself.current_url = url\n\n\t\tif self.current_url == Search.base_url:\n\t\t\t# Searching home page so no formatting\n\t\t\tresults = self._get_results(self.current_url)\n\t\t\tself._add_results(results)\n\t\telse:\n\n\t\t\tsearch = self._format_search(term, category)\n\t\t\tsorting = self._format_sort(sort, order)\n\n\t\t\t# Now get the results.\n\t\t\tfor i in range(pages):\n\t\t\t\tresults = self._get_results(search + \"/\" + str(self._current_page) +\n\t\t\t\t\t\t\t\t\t\t\t\"/\" + sorting)\n\t\t\t\tself._add_results(results)\n\t\t\t\tself._current_page += 1\n\t\t\tself._current_page -= 1", "response": "Search a given URL for torrent results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _categorize(self, category):\n\t\tself.torrents = [result for result in self.torrents\n\t\t\t\t\t\t if result.category == category]", "response": "Remove torrents with unwanted category from self. torrents"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets page i of search results", "response": "def page(self, i):\n\t\t\"\"\"Get page i of search results\"\"\"\n\t\t# Need to clear previous results.\n\t\tself.torrents = list()\n\t\tself._current_page = i\n\t\tself.search(term=self.term, category=self.category,\n\t\t\t\t\tsort=self.sort, order=self.order)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind every div tag containing torrent details on given page and parse the results into a list of Torrents and return them", "response": "def _get_results(self, page):\n\t\t\"\"\"Find every div tag containing torrent details on given page,\n\t\t\tthen parse the results into a list of Torrents and return them\"\"\"\n\n\t\tsoup = _get_soup(page)\n\t\tdetails = soup.find_all(\"tr\", class_=\"odd\")\n\t\teven = soup.find_all(\"tr\", class_=\"even\")\n\t\t# Join the results\n\t\tfor i in range(len(even)):\n\t\t\tdetails.insert((i * 2)+1, even[i])\n\n\t\treturn self._parse_details(details)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_details(self, tag_list):\n\n\t\tresult = list()\n\t\tfor i, item in enumerate(tag_list):\n\t\t\ttitle = item.find(\"a\", class_=\"cellMainLink\")\n\t\t\ttitle_text = title.text\n\t\t\tlink = title.get(\"href\")\n\t\t\ttds = item.find_all(\"td\", class_=\"center\") # Better name here.\n\t\t\tsize = tds[0].text\n\t\t\tfiles = tds[1].text\n\t\t\tage = tds[2].text\n\t\t\tseed = tds[3].text\n\t\t\tleech = tds[4].text\n\t\t\tmagnet = item.find(\"a\", class_=\"imagnet icon16\")\n\t\t\tdownload = item.find(\"a\", class_=\"idownload icon16\")\n\t\t\tisVerified = item.find(\"a\", class_=\"iverify icon16\") != None\n\n\t\t\t# Home page doesn't have magnet or download links\n\t\t\tif magnet:\n\t\t\t\tmagnet = magnet.get(\"href\")\n\t\t\tif download:\n\t\t\t\tdownload = download.get(\"href\")\n\n\t\t\t# Get category changes depending on if we're parsing\n\t\t\t# the home page or a search page.\n\t\t\tif self.current_url == self.base_url:\n\t\t\t\tcategory = self._get_torrent_category(item, result=i)\n\t\t\telse:\n\t\t\t\tcategory = self._get_torrent_category(item)\n\n\t\t\tresult.append(Torrent(title_text, category, link, size, seed,\n\t\t\t\t\t\t\t\tleech, magnet, download,files, age, isVerified))\n\n\t\treturn result", "response": "Given a list of tags from either a search page or a KAT home page parse the details and return a list of Torrents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_torrent_category(self, tag, result=None):\n\n\t\threfs = [\"/movies/\", \"/tv/\", \"/music/\", \"/games/\", \"/applications/\", \"/anime/\",\n\t\t\t\t \"/books/\", \"/xxx/\"]\n\t\tcategory = None\n\t\tif not result is None: # if result: 0 returns false.\n\t\t\t# Searching home page, get category from result number\n\t\t\tcategory = hrefs[result / 10].strip(\"/\")\n\t\t\treturn category\n\n\t\tfor item in hrefs:\n\t\t\tif tag.select(\"a[href=\" + item + \"]\"):\n\t\t\t\tcategory = item.strip(\"/\")\n\t\t\t\treturn category", "response": "Given a tag containing torrent details try to find the category of torrent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating state page content exclusively for the U. S. president.", "response": "def bootstrap_executive_office_states(self, election):\n        \"\"\"\n        Create state page content exclusively for the U.S. president.\n        \"\"\"\n        content_type = ContentType.objects.get_for_model(election.race.office)\n        for division in Division.objects.filter(level=self.STATE_LEVEL):\n            PageContent.objects.get_or_create(\n                content_type=content_type,\n                object_id=election.race.office.pk,\n                election_day=election.election_day,\n                division=division\n            )\n        # Create national presidential page type\n        page_type, created = PageType.objects.get_or_create(\n            model_type=ContentType.objects.get(\n                app_label='government',\n                model='office'\n            ),\n            election_day=election.election_day,\n            division_level=self.NATIONAL_LEVEL,\n            jurisdiction=self.FEDERAL_JURISDICTION,\n            office=election.race.office,\n        )\n        PageContent.objects.get_or_create(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election.election_day,\n        )\n        # Create state results for president page type\n        page_type, created = PageType.objects.get_or_create(\n            model_type=ContentType.objects.get(\n                app_label='government',\n                model='office'\n            ),\n            election_day=election.election_day,\n            division_level=self.STATE_LEVEL,\n            jurisdiction=self.FEDERAL_JURISDICTION,\n            office=election.race.office,\n        )\n        PageContent.objects.get_or_create(\n            content_type=ContentType.objects.get_for_model(page_type),\n            object_id=page_type.pk,\n            election_day=election.election_day,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef average_build_duration(connection, package):\n    if isinstance(package, str) and package.endswith('-container'):\n        return average_last_builds(connection, package)\n    return connection.getAverageBuildDuration(package)", "response": "Returns the average build duration for a package or container."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef average_build_durations(connection, packages):\n    containers = [name for name in packages if name.endswith('-container')]\n    if len(containers) == len(packages):\n        containers = True\n    elif len(containers) == 0:\n        containers = False\n    else:\n        # This is going to be too complicated to do with multicalls.\n        raise NotImplementedError('cannot mix containers and non-containers')\n\n    if not containers:\n        multicall = connection.MultiCall()\n        for name in packages:\n            multicall.getAverageBuildDuration(name)\n        result = yield multicall()\n        defer.returnValue(result)\n\n    # Map all container names to packages (IDs).\n    multicall = connection.MultiCall()\n    names = set(packages)\n    for name in names:\n        multicall.getPackage(name)\n    results = yield multicall()\n    package_map = dict(zip(names, results))\n\n    # List the previous builds for each container.\n    state = build_states.COMPLETE\n    opts = {'limit': 5, 'order': '-completion_time'}\n    multicall = connection.MultiCall()\n    built_packages = []\n    for name in names:\n        package = package_map[name]\n        if package:\n            built_packages.append(name)\n            multicall.listBuilds(package.id, state=state, queryOpts=opts)\n    results = yield multicall()\n    builds_map = dict(zip(built_packages, results))\n\n    package_durations = []\n    for name in packages:\n        builds = builds_map.get(name)\n        average = None\n        if builds:\n            durations = [build.duration for build in builds]\n            average = sum(durations, timedelta()) / len(durations)\n        package_durations.append(average)\n    defer.returnValue(package_durations)", "response": "Return the average build duration for a list of packages or containers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef average_last_builds(connection, package, limit=5):\n    # TODO: take branches (targets, or tags, etc) into account when estimating\n    # a package's build time.\n    state = build_states.COMPLETE\n    opts = {'limit': limit, 'order': '-completion_time'}\n    builds = yield connection.listBuilds(package, state=state, queryOpts=opts)\n    if not builds:\n        defer.returnValue(None)\n    durations = [build.duration for build in builds]\n    average = sum(durations, timedelta()) / len(durations)\n    # print('average duration for %s is %s' % (package, average))\n    defer.returnValue(average)", "response": "Find the average duration time for the last couple of builds for a given package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling permissions Syntax: {command} (--add|--remove) --nick (nick) --role (admin)", "response": "def cmd(send, msg, args):\n    \"\"\"Handles permissions\n    Syntax: {command} (--add|--remove) --nick (nick) --role (admin)\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--nick', action=arguments.NickParser, required=True)\n    parser.add_argument('--role', choices=['admin'], required=True)\n    group = parser.add_mutually_exclusive_group(required=True)\n    group.add_argument('--add', action='store_true')\n    group.add_argument('--remove', action='store_true')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    session = args['db']\n    admin = session.query(Permissions).filter(Permissions.nick == cmdargs.nick).first()\n    if cmdargs.add:\n        if admin is None:\n            session.add(Permissions(nick=cmdargs.nick, role=cmdargs.role))\n            send(\"%s is now an %s.\" % (cmdargs.nick, cmdargs.role))\n        else:\n            send(\"%s is already an %s.\" % (admin.nick, admin.role))\n    else:\n        if admin is None:\n            send(\"%s was not an %s.\" % (cmdargs.nick, cmdargs.role))\n        else:\n            session.delete(admin)\n            send(\"%s is no longer an %s.\" % (admin.nick, admin.role))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all supported resources.", "response": "def model_resources(self):\n        \"\"\" Listing of all supported resources. \"\"\"\n\n        response = jsonify({\n            'apiVersion': '0.1',\n            'swaggerVersion': '1.1',\n            'basePath': '%s%s' % (self.base_uri(), self.api.url_prefix),\n            'apis': self.get_model_resources()\n        })\n\n        response.headers.add('Cache-Control', 'max-age=0')\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef model_resource(self, resource_name):\n\n        resource = first(\n            [resource for resource in self.api._registry.values()\n             if resource.get_api_name() == resource_name])\n\n        data = {\n            'apiVersion': '0.1',\n            'swaggerVersion': '1.1',\n            'basePath': '%s%s' % (self.base_uri(), self.api.url_prefix),\n            'resourcePath': '/meta/%s' % resource.get_api_name(),\n            'apis': self.get_model_apis(resource),\n            'models': self.get_model(resource)\n        }\n        response = jsonify(data)\n        response.headers.add('Cache-Control', 'max-age=0')\n        return response", "response": "Return a JSON response of a specific model resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_create_api(self, resource):\n\n        create_api = {\n            'path': '/%s/' % resource.get_api_name(),\n            'description': 'Operations on %s' % resource.model.__name__,\n            'operations': [\n                {\n                    'httpMethod': 'POST',\n                    'nickname': 'create%ss' % resource.model\n                    .__name__,\n                    'summary': 'Create %ss' % resource.model.__name__,\n                    'parameters': [{\n                        'description': '%s object' % (resource.model.__name__),\n                        'paramType': 'body',\n                        'required': True,\n                        'allowMultiple': False,\n                        'dataType': resource.model.__name__\n                    }]\n                }\n            ]\n        }\n\n        return create_api", "response": "Generates the meta descriptor for the resource listing api."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_update_api(self, resource):\n\n        update_api = {\n            'path': '/%s/{id}/' % resource.get_api_name(),\n            'description': 'Operations on %s' % resource.model.__name__,\n            'operations': [\n                {\n                    'httpMethod': 'PUT',\n                    'nickname': 'update%ss' % resource.model\n                    .__name__,\n                    'summary': 'Update %ss' % resource.model.__name__,\n                    'parameters': [\n                        {\n                            'paramType': 'path', \n                            'name': 'id',\n                            'description': '%s id' % (resource.model.__name__),\n                            'dataType': 'int',\n                            'required': True,\n                            'allowMultiple': False,\n                        },\n                        {\n                            'description': '%s object' % (resource.model.__name__),\n                            'paramType': 'body',\n                            'required': True,\n                            'allowMultiple': False,\n                            'dataType': resource.model.__name__\n                        }\n                    ]\n                }\n            ]\n        }\n\n        return update_api", "response": "Generates the meta descriptor for the resource listing api."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_listing_api(self, resource):\n\n        get_all_params = self.get_listing_parameters(resource)\n\n        get_all_api = {\n            'path': '/%s/' % resource.get_api_name(),\n            'description': 'Operations on %s' % resource.model.__name__,\n            'operations': [\n                {\n                    'httpMethod': 'GET',\n                    'nickname': 'list%ss' % resource.model\n                    .__name__,\n                    'summary': 'Find %ss' % resource.model.__name__,\n                    'parameters': get_all_params,\n                }\n            ]\n        }\n\n        return get_all_api", "response": "Generates the meta descriptor for the resource listing api."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item_api(self, resource):\n\n        parameters = self.get_item_parameters(resource)\n\n        get_item_api = {\n            'path': '/%s/{id}' % resource.get_api_name(),\n            'description': 'Operations on %s' % resource.model.__name__,\n            'operations': [\n                {\n                    'httpMethod': 'GET',\n                    'nickname': 'get%s' % resource.model.__name__,\n                    'summary': 'Get %s by its unique ID' %\n                               resource.model.__name__,\n                    'parameters': parameters,\n                }\n            ]\n        }\n\n        return get_item_api", "response": "Generates the meta descriptor for the resource item api."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the meta descriptor for the delete item api.", "response": "def get_delete_api(self, resource):\n        \"\"\" Generates the meta descriptor for the resource item api. \"\"\"\n\n        parameters = self.delete_item_parameters(resource)\n\n        get_item_api = {\n            'path': '/%s/{id}/' % resource.get_api_name(),\n            'description': 'Operations on %s' % resource.model.__name__,\n            \"responseClass\": \"void\",\n            'operations': [\n                {\n                    'httpMethod': 'DELETE',\n                    'nickname': 'delete%s' % resource.model.__name__,\n                    'summary': 'Delete %s by its unique ID' %\n                               resource.model.__name__,\n                    'parameters': parameters,\n                }\n            ]\n        }\n\n        return get_item_api"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _compute_std_dev(self, X):\n\n        self._sigma = []\n        if X.shape[0] <= 1:\n            self._sigma = [0.0]\n        else:\n            for x_mean in range(X.shape[0]):\n                std_dev = np.sqrt(sum([np.linalg.norm(x - x_mean) ** 2 for x in X]) / float(X.shape[0]-1))\n                self._sigma.append(std_dev)\n\n        return self._sigma", "response": "Computes the standard deviation of a Gaussian Distribution with mean vector X [ i ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _high_dim_sim(self, v, w, normalize=False, X=None, idx=0):\n\n        sim = np.exp((-np.linalg.norm(v - w) ** 2) / (2*self._sigma[idx] ** 2))\n\n        if normalize:\n            return sim / sum(map(lambda x: x[1], self._knn(idx, X, high_dim=True)))\n        else:\n            return sim", "response": "Similarity measurement based on Gaussian Distribution"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _low_dim_sim(self, v, w, normalize=False, Y=None, idx=0):\n\n        sim = (1 + np.linalg.norm(v - w) ** 2) ** -1\n\n        if normalize:\n            return sim / sum(map(lambda x: x[1], self._knn(idx, Y, high_dim=False)))\n        else:\n            return sim", "response": "Similarity measurement based on Student t - Distribution"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _knn(self, i, X, high_dim=True):\n\n        knns = []\n        for j in range(X.shape[0]):\n            if j != i:\n                if high_dim:\n                    distance = self._high_dim_sim(X[i], X[j], idx=i)\n                else:\n                    distance = self._low_dim_sim(X[i], X[j])\n                knns.append([j, distance])\n\n        return sorted(knns, key=lambda x: x[1])[:self.perplexity]", "response": "Performs KNN search based on high - dimensional similarity and distance measurement"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef auth(view, **kwargs):\n\n    endpoint_namespace = view.__name__ + \":%s\"\n    view_name = view.__name__\n    UserModel = kwargs.pop(\"model\")\n    User = UserModel.User\n\n    login_view = endpoint_namespace % \"login\"\n    on_signin_view = kwargs.get(\"signin_view\", \"Index:index\")\n    on_signout_view = kwargs.get(\"signout_view\", \"Index:index\")\n    template_dir = kwargs.get(\"template_dir\", \"Juice/Plugin/User/Account\")\n    template_page = template_dir + \"/%s.html\"\n\n    login_manager = LoginManager()\n    login_manager.login_view = login_view\n    login_manager.login_message_category = \"error\"\n    init_app(login_manager.init_app)\n\n    menu_context = view\n    _menu = kwargs.get(\"menu\", {})\n    if _menu:\n        @menu(**_menu)\n        class UserAccountMenu(object): pass\n        menu_context = UserAccountMenu\n\n    @login_manager.user_loader\n    def load_user(userid):\n        return User.get(userid)\n\n    View.g(__USER_AUTH_ENABLED__=True)\n\n    class Auth(object):\n        decorators = view.decorators + [login_required]\n\n        SESSION_KEY_SET_EMAIL_DATA = \"set_email_tmp_data\"\n        TEMP_DATA_KEY = \"login_tmp_data\"\n\n        @property\n        def tmp_data(self):\n            return session[self.TEMP_DATA_KEY]\n\n        @tmp_data.setter\n        def tmp_data(self, data):\n            session[self.TEMP_DATA_KEY] = data\n\n        def _login_enabled(self):\n            if self.get_config(\"USER_AUTH_ALLOW_LOGIN\") is not True:\n                abort(\"UserLoginDisabledError\")\n\n        def _signup_enabled(self):\n            if self.get_config(\"USER_AUTH_ALLOW_SIGNUP\") is not True:\n                abort(\"UserSignupDisabledError\")\n\n        def _oauth_enabled(self):\n            if self.get_config(\"USER_AUTH_ALLOW_OAUTH\") is not True:\n                abort(\"UserOAuthDisabledError\")\n\n        def _send_reset_password(self, user):\n            delivery = self.get_config(\"USER_AUTH_PASSWORD_RESET_METHOD\")\n            token_reset_ttl = self.get_config(\"USER_AUTH_TOKEN_RESET_TTL\", 60)\n            new_password = None\n            if delivery.upper() == \"TOKEN\":\n                token = user.set_temp_login(token_reset_ttl)\n                url = url_for(endpoint_namespace % \"reset_password\",\n                              token=token,\n                              _external=True)\n            else:\n                new_password = user.set_password(password=None, random=True)\n                url = url_for(endpoint_namespace % \"login\", _external=True)\n\n            mail.send(template=\"reset-password.txt\",\n                         method_=delivery,\n                         to=user.email,\n                         name=user.email,\n                         url=url,\n                         new_password=new_password)\n\n\n        @classmethod\n        def login_user(cls, user):\n            login_user(user)\n            now = datetime.datetime.now()\n            user.update(last_login=now, last_visited=now)\n\n        @menu(\"Login\",\n              endpoint=endpoint_namespace % \"login\",\n              visible_with_auth_user=False,\n              extends=menu_context)\n        @template(template_page % \"login\",\n                  endpoint_namespace=endpoint_namespace)\n        @route(\"login/\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"login\")\n        @no_login_required\n        def login(self):\n            \"\"\" Login page \"\"\"\n\n            self._login_enabled()\n            logout_user()\n            self.tmp_data = None\n            self.meta_tags(title=\"Login\")\n\n            if request.method == \"POST\":\n                email = request.form.get(\"email\").strip()\n                password = request.form.get(\"password\").strip()\n\n                if not email or not password:\n                    flash(\"Email or Password is empty\", \"error\")\n                    return redirect(url_for(login_view, next=request.form.get(\"next\")))\n\n                user = User.get_by_email(email)\n                if user and user.password_hash and user.password_matched(password):\n                    self.login_user(user)\n                    return redirect(request.form.get(\"next\") or url_for(on_signin_view))\n                else:\n                    flash(\"Email or Password is invalid\", \"error\")\n                    return redirect(url_for(login_view, next=request.form.get(\"next\")))\n\n            return dict(login_url_next=request.args.get(\"next\", \"\"),\n                        login_url_default=url_for(on_signin_view),\n                        signup_enabled=self.get_config(\"USER_AUTH_ALLOW_SIGNUP\"),\n                        oauth_enabled=self.get_config(\"USER_AUTH_ALLOW_LOGIN\"))\n\n        @menu(\"Logout\",\n              endpoint=endpoint_namespace % \"logout\",\n              visible_with_auth_user=True,\n              order=100,\n              extends=menu_context)\n        @route(\"logout/\",\n               endpoint=endpoint_namespace % \"logout\")\n        @no_login_required\n        def logout(self):\n            logout_user()\n            return redirect(url_for(on_signout_view or login_view))\n\n        @menu(\"Signup\",\n              endpoint=endpoint_namespace % \"signup\",\n              visible_with_auth_user=False,\n              extends=menu_context)\n        @template(template_page % \"signup\",\n                  endpoint_namespace=endpoint_namespace)\n        @route(\"signup/\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"signup\")\n        @no_login_required\n        def signup(self):\n            \"\"\"\n            For Email Signup\n            :return:\n            \"\"\"\n            self._login_enabled()\n            self._signup_enabled()\n            self.meta_tags(title=\"Signup\")\n\n            if request.method == \"POST\":\n                # reCaptcha\n                if not recaptcha.verify():\n                    flash(\"Invalid Security code\", \"error\")\n                    return redirect(url_for(endpoint_namespace % \"signup\",\n                                            next=request.form.get(\"next\")))\n                try:\n                    name = request.form.get(\"name\")\n                    email = request.form.get(\"email\")\n                    password = request.form.get(\"password\")\n                    password2 = request.form.get(\"password2\")\n                    profile_image_url = request.form.get(\"profile_image_url\", None)\n\n                    if not name:\n                        raise UserError(\"Name is required\")\n                    elif not utils.is_valid_email(email):\n                        raise UserError(\"Invalid email address '%s'\" % email)\n                    elif not password.strip() or password.strip() != password2.strip():\n                        raise UserError(\"Passwords don't match\")\n                    elif not utils.is_valid_password(password):\n                        raise UserError(\"Invalid password\")\n                    else:\n                        new_account = User.new(email=email,\n                                        password=password.strip(),\n                                        first_name=name,\n                                        profile_image_url=profile_image_url,\n                                        signup_method=\"email\")\n\n                        self.login_user(new_account)\n                        return redirect(request.form.get(\"next\") or url_for(on_signin_view))\n                except ApplicationError as ex:\n                    flash(ex.message, \"error\")\n                return redirect(url_for(endpoint_namespace % \"signup\",\n                                        next=request.form.get(\"next\")))\n\n            logout_user()\n            return dict(login_url_next=request.args.get(\"next\", \"\"))\n\n        @route(\"lost-password/\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"lost_password\")\n        @template(template_page % \"lost_password\",\n                  endpoint_namespace=endpoint_namespace)\n        @no_login_required\n        def lost_password(self):\n            self._login_enabled()\n            logout_user()\n\n            self.meta_tags(title=\"Lost Password\")\n\n            if request.method == \"POST\":\n                email = request.form.get(\"email\")\n                user = User.get_by_email(email)\n                if user:\n                    self._send_reset_password(user)\n                    flash(\"A new password has been sent to '%s'\" % email, \"success\")\n                else:\n                    flash(\"Invalid email address\", \"error\")\n                return redirect(url_for(login_view))\n            else:\n                return {}\n\n\n        @menu(\"Account Settings\",\n              endpoint=endpoint_namespace % \"account_settings\",\n              order=99,\n              visible_with_auth_user=True,\n              extends=menu_context)\n        @template(template_page % \"account_settings\",\n                  endpoint_namespace=endpoint_namespace)\n        @route(\"account-settings\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"account_settings\")\n        @fresh_login_required\n        def account_settings(self):\n            self.meta_tags(title=\"Account Settings\")\n\n            if request.method == \"POST\":\n                action = request.form.get(\"action\")\n                try:\n                    action = action.lower()\n                    #\n                    if action == \"info\":\n                        first_name = request.form.get(\"first_name\").strip()\n                        last_name = request.form.get(\"last_name\", \"\").strip()\n\n                        data = {\n                            \"first_name\": first_name,\n                            \"last_name\": last_name\n                        }\n                        current_user.update(**data)\n                        flash(\"Account info updated successfully!\", \"success\")\n                    #\n                    elif action == \"login\":\n                        confirm_password = request.form.get(\"confirm-password\").strip()\n                        if current_user.password_matched(confirm_password):\n                            self.change_login_handler()\n                            flash(\"Login Info updated successfully!\", \"success\")\n                        else:\n                            flash(\"Invalid password\", \"error\")\n                    #\n                    elif action == \"password\":\n                        confirm_password = request.form.get(\"confirm-password\").strip()\n                        if current_user.password_matched(confirm_password):\n                            self.change_password_handler()\n                            flash(\"Password updated successfully!\", \"success\")\n                        else:\n                            flash(\"Invalid password\", \"error\")\n\n                    elif action == \"profile-photo\":\n                        file = request.files.get(\"file\")\n                        if file:\n                            prefix = \"profile-photos/%s/\" % current_user.id\n                            extensions = [\"jpg\", \"jpeg\", \"png\", \"gif\"]\n                            my_photo = storage.upload(file,\n                                                      prefix=prefix,\n                                                      allowed_extensions=extensions)\n                            if my_photo:\n                                url = my_photo.url\n                                current_user.update(profile_image_url=url)\n                                flash(\"Profile Image updated successfully!\", \"success\")\n                    else:\n                        raise UserError(\"Invalid action\")\n\n                except Exception as e:\n                    flash(e.message, \"error\")\n\n                return redirect(url_for(endpoint_namespace % \"account_settings\"))\n\n            return {}\n\n        @classmethod\n        def change_login_handler(cls, user_context=None, email=None):\n            if not user_context:\n                user_context = current_user\n            if not email:\n                email = request.form.get(\"email\").strip()\n\n            if not utils.is_valid_email(email):\n                raise UserWarning(\"Invalid email address '%s'\" % email)\n            else:\n                if email != user_context.email and User.get_by_email(email):\n                    raise UserWarning(\"Email exists already '%s'\" % email)\n                elif email != user_context.email:\n                    user_context.update(email=email)\n                    return True\n            return False\n\n        @classmethod\n        def change_password_handler(cls, user_context=None, password=None,\n                                    password2=None):\n            if not user_context:\n                user_context = current_user\n            if not password:\n                password = request.form.get(\"password\").strip()\n            if not password2:\n                password2 = request.form.get(\"password2\").strip()\n\n            if password:\n                if password != password2:\n                    raise UserWarning(\"Password don't match\")\n                elif not utils.is_valid_password(password):\n                    raise UserWarning(\"Invalid password\")\n                else:\n                    user_context.set_password(password)\n                    return True\n            else:\n                raise UserWarning(\"Password is empty\")\n\n\n        # OAUTH Login\n        @route(\"oauth-login/<provider>\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"oauth_login\")\n        @template(template_page % \"oauth_login\",\n                  endpoint_namespace=endpoint_namespace)\n        @no_login_required\n        def oauth_login(self, provider):\n            \"\"\" Login via oauth providers \"\"\"\n\n            self._login_enabled()\n            self._oauth_enabled()\n\n            provider = provider.lower()\n            result = oauth.login(provider)\n            response = oauth.response\n            popup_js_custom = {\n                \"action\": \"\",\n                \"url\": \"\"\n            }\n\n            if result:\n                if result.error:\n                    pass\n\n                elif result.user:\n                    result.user.update()\n\n                    oauth_user = result.user\n                    user = User.get_by_oauth(provider=provider,\n                                             provider_user_id=oauth_user.id)\n                    if not user:\n                        if oauth_user.email and User.get_by_email(oauth_user.email):\n                            flash(\"Account already exists with this email '%s'. \"\n                                        \"Try to login or retrieve your password \" % oauth_user.email, \"error\")\n\n                            popup_js_custom.update({\n                                \"action\": \"redirect\",\n                                \"url\": url_for(login_view, next=request.form.get(\"next\"))\n                            })\n\n                        else:\n                            tmp_data = {\n                                \"is_oauth\": True,\n                                \"provider\": provider,\n                                \"id\": oauth_user.id,\n                                \"name\": oauth_user.name,\n                                \"picture\": oauth_user.picture,\n                                \"first_name\": oauth_user.first_name,\n                                \"last_name\": oauth_user.last_name,\n                                \"email\": oauth_user.email,\n                                \"link\": oauth_user.link\n                            }\n                            if not oauth_user.email:\n                                self.tmp_data = tmp_data\n\n                                popup_js_custom.update({\n                                    \"action\": \"redirect\",\n                                    \"url\": url_for(endpoint_namespace % \"setup_login\")\n                                })\n\n                            else:\n                                try:\n                                    picture = oauth_user.picture\n                                    user = User.new(email=oauth_user.email,\n                                                    name=oauth_user.name,\n                                                    signup_method=provider,\n                                                    profile_image_url=picture\n                                                    )\n                                    user.add_oauth(provider,\n                                                   oauth_user.provider_id,\n                                                   name=oauth_user.name,\n                                                   email=oauth_user.email,\n                                                   profile_image_url=oauth_user.picture,\n                                                   link=oauth_user.link)\n                                except ModelError as e:\n                                    flash(e.message, \"error\")\n                                    popup_js_custom.update({\n                                        \"action\": \"redirect\",\n                                        \"url\": url_for(endpoint_namespace % \"login\")\n                                    })\n                    if user:\n                        self.login_user(user)\n\n                    return dict(popup_js=result.popup_js(custom=popup_js_custom),\n                                template_=template_page % \"oauth_login\")\n            return response\n\n        @template(template_page % \"setup_login\",\n                  endpoint_namespace=endpoint_namespace)\n        @route(\"setup-login/\", methods=[\"GET\", \"POST\"], \n               endpoint=endpoint_namespace % \"setup_login\")\n        def setup_login(self):\n            \"\"\"\n            Allows to setup a email password if it's not provided specially\n            coming from oauth-login\n            :return:\n            \"\"\"\n            self._login_enabled()\n            self.meta_tags(title=\"Setup  Login\")\n\n            # Only user without email can set email\n            if current_user.is_authenticated() and current_user.email:\n                return redirect(url_for(endpoint_namespace % \"account_settings\"))\n\n            if self.tmp_data:\n                if request.method == \"POST\":\n                    if not self.tmp_data[\"is_oauth\"]:\n                        return redirect(endpoint_namespace % \"login\")\n\n                    try:\n                        email = request.form.get(\"email\")\n                        password = request.form.get(\"password\")\n                        password2 = request.form.get(\"password2\")\n\n                        if not utils.is_valid_email(email):\n                            raise UserError(\"Invalid email address '%s'\" % email)\n                        elif User.get_by_email(email):\n                            raise UserError(\"An account exists already with this email address '%s' \" % email)\n                        elif not password.strip() or password.strip() != password2.strip():\n                            raise UserError(\"Passwords don't match\")\n                        elif not utils.is_valid_password(password):\n                            raise UserError(\"Invalid password\")\n                        else:\n                            user = User.new(email=email,\n                                            password=password.strip(),\n                                            name=self.tmp_data[\"name\"],\n                                            profile_image_url=self.tmp_data[\"picture\"],\n                                            signup_method=self.tmp_data[\"provider\"])\n\n                            user.add_oauth(self.tmp_data[\"provider\"],\n                                           self.tmp_data[\"id\"],\n                                           name=self.tmp_data[\"name\"],\n                                           email=email,\n                                           profile_image_url=self.tmp_data[\"picture\"],\n                                           link=self.tmp_data[\"link\"])\n\n                            self.login_user(user)\n                            self.tmp_data = None\n\n                        return redirect(request.form.get(\"next\") or url_for(on_signin_view))\n                    except ApplicationError as ex:\n                        flash(ex.message, \"error\")\n                        return redirect(url_for(endpoint_namespace % \"login\"))\n\n                return dict(provider=self.tmp_data)\n\n            else:\n                return redirect(url_for(endpoint_namespace % \"login\"))\n\n        @route(\"reset-password/<token>\",\n               methods=[\"GET\", \"POST\"],\n               endpoint=endpoint_namespace % \"reset_password\")\n        @template(template_page % \"reset_password\",\n                  endpoint_namespace=endpoint_namespace)\n        @no_login_required\n        def reset_password(self, token):\n            self._login_enabled()\n            logout_user()\n\n            self.meta_tags(title=\"Reset Password\")\n            user = User.get_by_temp_login(token)\n            if user:\n                if not user.has_temp_login:\n                    return redirect(url_for(on_signin_view))\n                if request.method == \"POST\":\n                    try:\n                        self.change_password_handler(user_context=user)\n                        user.clear_temp_login()\n                        flash(\"Password updated successfully!\", \"success\")\n                        return redirect(url_for(on_signin_view))\n                    except Exception as ex:\n                        flash(\"Error: %s\" % ex.message, \"error\")\n                        return redirect(url_for(endpoint_namespace % \"reset_password\",\n                                                token=token))\n                else:\n                    return dict(token=token)\n            else:\n                abort(404, \"Invalid token\")\n\n        @route(\"oauth-connect\", methods=[\"POST\"], \n               endpoint=\"%s:oauth_connect\" % endpoint_namespace)\n        def oauth_connect(self):\n            \"\"\" To login via social \"\"\"\n            email = request.form.get(\"email\").strip()\n            name = request.form.get(\"name\").strip()\n            provider = request.form.get(\"provider\").strip()\n            provider_user_id = request.form.get(\"provider_user_id\").strip()\n            image_url = request.form.get(\"image_url\").strip()\n            next = request.form.get(\"next\", \"\")\n            try:\n                current_user.oauth_connect(provider=provider,\n                                         provider_user_id=provider_user_id,\n                                         email=email,\n                                         name=name,\n                                         image_url=image_url)\n            except Exception as ex:\n                flash(\"Unable to link your account\", \"error\")\n\n            return redirect(url_for(endpoint_namespace % \"account_settings\"))\n\n    return Auth", "response": "This plugin allows user to login to application"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(confdir=\"/etc/cslbot\"):\n    multiprocessing.set_start_method('spawn')\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-d', '--debug', help='Enable debug logging.', action='store_true')\n    parser.add_argument('--validate', help='Initialize the db and perform other sanity checks.', action='store_true')\n    args = parser.parse_args()\n    loglevel = logging.DEBUG if args.debug else logging.INFO\n    logging.basicConfig(level=loglevel, format=\"%(asctime)s %(levelname)s:%(module)s:%(message)s\")\n    # We don't need a bunch of output from the requests module.\n    logging.getLogger(\"requests\").setLevel(logging.WARNING)\n\n    cslbot = IrcBot(confdir)\n\n    if args.validate:\n        cslbot.shutdown_mp()\n        print(\"Everything is ready to go!\")\n        return\n\n    try:\n        cslbot.start()\n    except KeyboardInterrupt:\n        # KeyboardInterrupt means someone tried to ^C, so shut down the bot\n        cslbot.disconnect('Bot received a Ctrl-C')\n        cslbot.shutdown_mp()\n        sys.exit(0)\n    except Exception as ex:\n        cslbot.shutdown_mp(False)\n        logging.error(\"The bot died! %s\", ex)\n        output = \"\".join(traceback.format_exc()).strip()\n        for line in output.split('\\n'):\n            logging.error(line)\n        sys.exit(1)", "response": "Initialize the bot and start processing messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshuts down all the multiprocessing.", "response": "def shutdown_mp(self, clean=True):\n        \"\"\"Shutdown all the multiprocessing.\n\n        :param bool clean: Whether to shutdown things cleanly, or force a quick and dirty shutdown.\n\n        \"\"\"\n        # The server runs on a worker thread, so we need to shut it down first.\n        if hasattr(self, 'server'):\n            # Shutdown the server quickly.\n            try:\n                # For some strange reason, this throws an OSError on windows.\n                self.server.socket.shutdown(socket.SHUT_RDWR)\n            except OSError:\n                pass\n            self.server.socket.close()\n            self.server.shutdown()\n        if hasattr(self, 'handler'):\n            self.handler.workers.stop_workers(clean)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle all messages. - If a exception is thrown, catch it and display a nice traceback instead of crashing. - Do the appropriate processing for each event type.", "response": "def handle_msg(self, c, e):\n        \"\"\"Handles all messages.\n\n        - If a exception is thrown, catch it and display a nice traceback instead of crashing.\n        - Do the appropriate processing for each event type.\n\n        \"\"\"\n        try:\n            self.handler.handle_msg(c, e)\n        except Exception as ex:\n            backtrace.handle_traceback(ex, c, self.get_target(e), self.config)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a dictionary to print.", "response": "def _options_to_dict(df):\n    \"\"\"Make a dictionary to print.\"\"\"\n    kolums = [\"k1\", \"k2\", \"value\"]\n    d = df[kolums].values.tolist()\n    dc = {}\n    for x in d:\n        dc.setdefault(x[0], {})\n        dc[x[0]][x[1]] = x[2]\n    return dc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_repo():\n    command = ['git', 'rev-parse', '--show-toplevel']\n    if six.PY2:\n        try:\n            return check_output(command).decode('utf-8').strip()    # nosec\n        except CalledProcessError:\n            return ''\n    else:\n        return (run(command, stdout=PIPE, stderr=PIPE)\n                .stdout.decode('utf-8').strip())", "response": "Identify the path to the repository origin."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates key - subkey existence.", "response": "def _entry_must_exist(df, k1, k2):\n    \"\"\"Evaluate key-subkey existence.\n\n    Checks that the key-subkey combo exists in the\n    configuration options.\n    \"\"\"\n    count = df[(df['k1'] == k1) &\n               (df['k2'] == k2)].shape[0]\n    if count == 0:\n        raise NotRegisteredError(\n            \"Option {0}.{1} not registered\".format(k1, k2))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate key - subKey non - existence.", "response": "def _entry_must_not_exist(df, k1, k2):\n    \"\"\"Evaluate key-subkey non-existence.\n\n    Checks that the key-subkey combo does not exists in the\n    configuration options.\n    \"\"\"\n    count = df[(df['k1'] == k1) &\n               (df['k2'] == k2)].shape[0]\n    if count > 0:\n        raise AlreadyRegisteredError(\n            \"Option {0}.{1} already registered\".format(k1, k2))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new option.", "response": "def register_option(self, key, subkey, default, _type, definition,\n                        values=None, locked=False):\n        \"\"\"Create a new option.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n        :param default: Default value of the option. Type varies and it is\n            described by ``_type``.\n        :param str _type: Type of the value of the option. Available\n            options are: [``int``, ``float``, ``bool``, ``text``,\n            ``string``, ``path_in``, ``path_out``].\n        :param str definition: Brief explanation of the option.\n        :type definition: :class:`str`\n        :param values: Available values for the option.\n        :type values: :func:`list` of accepted ``_type``\n        :param bool locked: If True, option cannot be altered.\n\n        :raise:\n            :AlreadyRegisteredError: If ``key`` or ``subkey`` already\n                define an option.\n\n        \"\"\"\n        if not self.open:\n            return\n\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_not_exist(self.gc, key, subkey)\n\n        ev.value_eval(default, _type)\n        values = None if values is False else values\n        new_opt = pd.Series([key, subkey, default, _type, default,\n                             locked, definition, values], index=self.clmn)\n\n        self.gc = self.gc.append(new_opt, ignore_index=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an option from the manager.", "response": "def unregister_option(self, key, subkey):\n        \"\"\"Removes an option from the manager.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n\n        raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define\n                any option.\n        \"\"\"\n        if not self.open:\n            return\n\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        self.gc = self.gc[~((self.gc['k1'] == key) &\n                            (self.gc['k2'] == subkey))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current value of the option.", "response": "def get_option(self, key, subkey, in_path_none=False):\n        \"\"\"Get the current value of the option.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n        :param bool in_path_none: Allows for ``in_path`` values of\n            :data:`None` to be retrieved.\n\n        :return: Current value of the option (type varies).\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define\n                any option.\n            :ValueError: If a ``in_path`` type with :data:`None` value is\n                requested.\n        \"\"\"\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        df = self.gc[(self.gc[\"k1\"] == key) & (self.gc[\"k2\"] == subkey)]\n        if df[\"type\"].values[0] == \"bool\":\n            return bool(df[\"value\"].values[0])\n        elif df[\"type\"].values[0] == \"int\":\n            return int(df[\"value\"].values[0])\n        elif df[\"type\"].values[0] == \"path_in\":\n            if df[\"value\"].values[0] is None and not in_path_none:\n                raise ValueError('Unspecified path for {0}.{1}'.format(key,\n                                                                       subkey))\n            return df[\"value\"].values[0]\n        else:\n            return df[\"value\"].values[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_option_default(self, key, subkey):\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        df = self.gc[(self.gc[\"k1\"] == key) & (self.gc[\"k2\"] == subkey)]\n        if df[\"type\"].values[0] == \"bool\":\n            return bool(df[\"default\"].values[0])\n        elif df[\"type\"].values[0] == \"int\":\n            return int(df[\"default\"].values[0])\n        else:\n            return df[\"default\"].values[0]", "response": "Get the default value of the option."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the string describing a particular option.", "response": "def get_option_description(self, key, subkey):\n        \"\"\"Get the string describing a particular option.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n\n        :return: :class:`str` - description of the option.\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define any\n                option.\n        \"\"\"\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        return self.gc[(self.gc[\"k1\"] == key) &\n                       (self.gc[\"k2\"] == subkey)][\"description\"].values[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_option_type(self, key, subkey):\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        return self.gc[(self.gc[\"k1\"] == key) &\n                       (self.gc[\"k2\"] == subkey)][\"type\"].values[0]", "response": "Get the type of a particular option."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the list of available values for an option.", "response": "def get_option_alternatives(self, key, subkey):\n        \"\"\"Get list of available values for an option.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n\n        :return: Union[:func:`list`, :data:`None`] - alternative values\n            for the option, if any specified (otherwise, is open).\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define any\n                option.\n        \"\"\"\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        return self.gc[(self.gc[\"k1\"] == key) &\n                       (self.gc[\"k2\"] == subkey)][\"values\"].values[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of an option.", "response": "def set_option(self, key, subkey, value):\n        \"\"\"Sets the value of an option.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n        :param value: New value for the option (type varies).\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define any\n                option.\n            :ValueError: If the targeted obtion is locked.\n            :ValueError: If the provided value is not the expected\n                type for the option.\n            :ValueError: If the provided value is not in the expected\n                available values for the option.\n        \"\"\"\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        df = self.gc[(self.gc[\"k1\"] == key) & (self.gc[\"k2\"] == subkey)]\n        if df[\"locked\"].values[0]:\n            raise ValueError(\"{0}.{1} option is locked\".format(key, subkey))\n        ev.value_eval(value, df[\"type\"].values[0])\n        if not self.check_option(key, subkey, value):\n            info = \"{0}.{1} accepted options are: \".format(key, subkey)\n            info += \"[{}]\".format(\", \".join(df[\"values\"].values[0]))\n            raise ValueError(info)\n        self.gc.loc[\n            (self.gc[\"k1\"] == key) &\n            (self.gc[\"k2\"] == subkey), \"value\"] = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate if a given value fits the option.", "response": "def check_option(self, key, subkey, value):\n        \"\"\"Evaluate if a given value fits the option.\n\n        If an option has a limited set of available values, check if the\n        provided value is amongst them.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n        :param value: Value to test (type varies).\n\n        :return: :class:`bool` - does ``value`` belong to the options?\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define any\n                option.\n            :ValueError: If the provided value is not the expected\n                type for the option.\n        \"\"\"\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        df = self.gc[(self.gc[\"k1\"] == key) & (self.gc[\"k2\"] == subkey)]\n        ev.value_eval(value, df[\"type\"].values[0])\n        if df[\"values\"].values[0] is not None:\n            return value in df[\"values\"].values[0]\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting a single option to the default values.", "response": "def reset_option(self, key, subkey):\n        \"\"\"Resets a single option to the default values.\n\n        :param str key: First identifier of the option.\n        :param str subkey: Second identifier of the option.\n\n        :raise:\n            :NotRegisteredError: If ``key`` or ``subkey`` do not define any\n                option.\n            :ValueError: If the targeted obtion is locked.\n        \"\"\"\n        if not self.open:\n            return\n\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        df = self.gc[(self.gc[\"k1\"] == key) & (self.gc[\"k2\"] == subkey)]\n        if df[\"locked\"].values[0]:\n            raise ValueError(\"{0}.{1} option is locked\".format(key, subkey))\n        val = df[\"default\"].values[0]\n        self.gc.loc[\n            (self.gc[\"k1\"] == key) &\n            (self.gc[\"k2\"] == subkey), \"value\"] = val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lock_option(self, key, subkey):\n        key, subkey = _lower_keys(key, subkey)\n        _entry_must_exist(self.gc, key, subkey)\n\n        self.gc.loc[\n            (self.gc[\"k1\"] == key) &\n            (self.gc[\"k2\"] == subkey), \"locked\"] = True", "response": "Make an option unmutable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the options.", "response": "def show_options(self, key=\"\"):\n        \"\"\"Returns a copy the options :class:`~pandas.DataFrame`.\n\n        Called on jupyter notebook, it will print them in pretty\n        :class:`~pandas.DataFrame` format.\n\n        :param str key: First identifier of the option. If not provided,\n            all options are returned.\n\n        :return: :class:`~pandas.DataFrame`\n        \"\"\"\n        key, _ = _lower_keys(key, '')\n\n        if key == \"\":\n            return self.gc.copy()\n        return self.gc[(self.gc[\"k1\"] == key)].copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_options(self, empty=True):\n        if empty:\n            self.gc = pd.DataFrame(columns=self.clmn)\n        else:\n            self.gc[\"value\"] = self.gc[\"default\"]", "response": "Reset all options to their original value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_options_from_YAML(self, filename):\n        if not os.path.isfile(filename):\n            raise IOError(\"File {0} not found\".format(filename))\n        stream = open(filename)\n        data_dict = yaml.safe_load(stream)\n        self.set_options_from_dict(data_dict, filename)", "response": "Load options from a YAML - formated file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_options_from_JSON(self, filename):\n        if not os.path.isfile(filename):\n            raise IOError(\"File {0} not found\".format(filename))\n        data_str = \"\".join([x.strip() for x in open(filename).readlines()])\n        data_dict = json.loads(data_str)\n        self.set_options_from_dict(data_dict, filename)", "response": "Load options from a YAML - formated file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_options_from_file(self, filename, file_format='yaml'):\n        if file_format.lower() == 'yaml':\n            return self.set_options_from_YAML(filename)\n        elif file_format.lower() == 'json':\n            return self.set_options_from_JSON(filename)\n        else:\n            raise ValueError('Unknown format {}'.format(file_format))", "response": "Load options from file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload options from a dictionary.", "response": "def set_options_from_dict(self, data_dict, filename=None):\n        \"\"\"Load options from a dictionary.\n\n        :param dict data_dict: Dictionary with the options to load.\n        :param str filename: If provided, assume that non-absolute\n            paths provided are in reference to the file.\n        \"\"\"\n        if filename is not None:\n            filename = os.path.dirname(filename)\n        for k in data_dict:\n            if not isinstance(data_dict[k], dict):\n                raise ValueError(\"The input data has to be a dict of dict\")\n            for sk in data_dict[k]:\n                if self.gc[(self.gc[\"k1\"] == k) &\n                           (self.gc[\"k2\"] == sk)].shape[0] == 0:\n                    continue\n                if isinstance(data_dict[k][sk], six.string_types):\n                    data_dict[k][sk] = str(data_dict[k][sk])\n                _type = self.gc[(self.gc[\"k1\"] == k) &\n                                (self.gc[\"k2\"] == sk)][[\"type\"]].values[0]\n                data_dict[k][sk] = ev.cast(data_dict[k][sk], _type)\n                if self.get_option(k, sk, True) != data_dict[k][sk]:\n                    try:\n                        self.set_option(k, sk, data_dict[k][sk])\n                    # Provided paths do not work: try add them relative\n                    # to the config file\n                    except IOError:\n                        if filename is None:\n                            raise IOError('Error path: {0}.{1}'.format(k, sk))\n                        npat = os.path.join(filename, data_dict[k][sk])\n                        self.set_option(k, sk, os.path.normpath(npat))\n                    except ValueError:\n                        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting options to file.", "response": "def write_options_to_file(self, filename, file_format='yaml'):\n        \"\"\"Write options to file.\n\n        This is a wrapper over :func:`.write_options_to_JSON` and\n        :func:`.write_options_to_YAML`.\n\n        :param str filename: Target file to write the options.\n        :param str file_format: File format (``yaml`` or ``json``).\n\n        :raises:\n            :ValueError: If an unknown ``format`` is requested.\n        \"\"\"\n        if file_format.lower() == 'yaml':\n            self.write_options_to_YAML(filename)\n        elif file_format.lower() == 'json':\n            self.write_options_to_JSON(filename)\n        else:\n            raise ValueError('Unknown format {}'.format(file_format))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the options in YAML format to a file.", "response": "def write_options_to_YAML(self, filename):\n        \"\"\"Writes the options in YAML format to a file.\n\n        :param str filename: Target file to write the options.\n        \"\"\"\n        fd = open(filename, \"w\")\n        yaml.dump(_options_to_dict(self.gc), fd, default_flow_style=False)\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_options_to_JSON(self, filename):\n        fd = open(filename, \"w\")\n        fd.write(json.dumps(_options_to_dict(self.gc), indent=2,\n                            separators=(',', ': ')))\n        fd.close()", "response": "Writes the options in JSON format to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a docstring table to add to the library documentation.", "response": "def document_options(self):\n        \"\"\"Generates a docstring table to add to the library documentation.\n\n        :return: :class:`str`\n        \"\"\"\n        k1 = max([len(_) for _ in self.gc['k1']]) + 4\n        k1 = max([k1, len('Option Class')])\n        k2 = max([len(_) for _ in self.gc['k2']]) + 4\n        k2 = max([k2, len('Option ID')])\n\n        separators = \"  \".join([\"\".join([\"=\", ] * k1),\n                                \"\".join([\"=\", ] * k2),\n                                \"\".join([\"=\", ] * 11)])\n        line = (\"{0:>\"+str(k1)+\"}  {1:>\"+str(k2)+\"}  {2}\")\n\n        data = []\n        data.append(separators)\n        data.append(line.format('Option Class', 'Option ID', 'Description'))\n        data.append(separators)\n        for _, row in self.gc.iterrows():\n            data.append(line.format(\"**\" + row['k1'] + \"**\",\n                                    \"**\" + row['k2'] + \"**\",\n                                    row['description']))\n        data.append(separators)\n        return \"\\n\".join(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind local configuration file.", "response": "def get_local_config_file(cls, filename):\n        \"\"\"Find local file to setup default values.\n\n        There is a pre-fixed logic on how the search of the configuration\n        file is performed. If the highes priority configuration file is found,\n        there is no need to search for the next. From highest to lowest\n        priority:\n\n        1. **Local:** Configuration file found in the current working\n           directory.\n        2. **Project:** Configuration file found in the root of the current\n           working ``git`` repository.\n        3. **User:** Configuration file found in the user's ``$HOME``.\n\n        :param str filename: Raw name of the configuration file.\n\n        :return: Union[:class:`.str`, :data:`None`] - Configuration file with\n            the highest priority, :data:`None` if no config file is found.\n        \"\"\"\n        if os.path.isfile(filename):\n            # Local has priority\n            return filename\n        else:\n            try:\n                # Project. If not in a git repo, this will not exist.\n                config_repo = _get_repo()\n                if len(config_repo) == 0:\n                    raise Exception()\n                config_repo = os.path.join(config_repo, filename)\n                if os.path.isfile(config_repo):\n                    return config_repo\n                else:\n                    raise Exception()\n            except Exception:\n                home = os.getenv(\"HOME\", os.path.expanduser(\"~\"))\n                config_home = os.path.join(home, filename)\n                if os.path.isfile(config_home):\n                    return config_home\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a man page.", "response": "def cmd(send, msg, args):\n    \"\"\"Gets a man page.\n\n    Syntax: {command} [section] <command>\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('section', nargs='?')\n    parser.add_argument('command')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.section:\n        html = get('http://linux.die.net/man/%s/%s' % (cmdargs.section, cmdargs.command))\n        short = fromstring(html.text).find('.//meta[@name=\"description\"]')\n        if short is not None:\n            short = short.get('content')\n            send(\"%s -- http://linux.die.net/man/%s/%s\" % (short, cmdargs.section, cmdargs.command))\n        else:\n            send(\"No manual entry for %s in section %s\" % (cmdargs.command, cmdargs.section))\n    else:\n        for section in range(0, 8):\n            html = get('http://linux.die.net/man/%d/%s' % (section, cmdargs.command))\n            if html.status_code == 200:\n                short = fromstring(html.text).find('.//meta[@name=\"description\"]')\n                if short is not None:\n                    short = short.get('content')\n                    send(\"%s -- http://linux.die.net/man/%d/%s\" % (short, section, cmdargs.command))\n                    return\n        send(\"No manual entry for %s\" % cmdargs.command)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, msg, args):\n    key = args['config']['api']['bitlykey']\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--blacklist')\n    parser.add_argument('--unblacklist')\n\n    try:\n        cmdargs, msg = parser.parse_known_args(msg)\n        msg = ' '.join(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.blacklist:\n        if args['is_admin'](args['nick']):\n            send(blacklist_word(args['db'], cmdargs.blacklist))\n        else:\n            send(\"Blacklisting is admin-only\")\n    elif cmdargs.unblacklist:\n        if args['is_admin'](args['nick']):\n            send(unblacklist_word(args['db'], cmdargs.unblacklist))\n        else:\n            send(\"Unblacklisting is admin-only\")\n    else:\n        defn, url = get_urban(msg, args['db'], key)\n        send(defn)\n        if url:\n            send(\"See full definition at %s\" % url)", "response": "Gets a definition from urban dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef people(self):\n        '''Generates a list of all People.'''\n        people_response = self.get_request('people/')\n        return [Person(self, pjson['user']) for pjson in people_response]", "response": "Generates a list of all People."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a list of all Tasks.", "response": "def tasks(self):\n        '''Generates a list of all Tasks.'''\n        tasks_response = self.get_request('tasks/')\n        return [Task(self, tjson['task']) for tjson in tasks_response]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a list of all Clients.", "response": "def clients(self):\n        '''Generates a list of all Clients.'''\n        clients_response = self.get_request('clients/')\n        return [Client(self, cjson['client']) for cjson in clients_response]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_client(self, client_id):\n        '''Gets a single client by id.'''\n        client_response = self.get_request('clients/%s' % client_id)\n        return Client(self, client_response['client'])", "response": "Gets a single client by id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a single project by id.", "response": "def get_project(self, project_id):\n        '''Gets a single project by id.'''\n        project_response = self.get_request('projects/%s' % project_id)\n        return Project(self, project_response['project'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_person(self, first_name, last_name, email, department = None,\n    \tdefault_rate = None, admin = False, contractor = False):\n        '''Creates a Person with the given information.'''\n        person = {'user':{\n            'first_name': first_name,\n            'last_name': last_name,\n            'email': email,\n            'department': department,\n            'default_hourly_rate': default_rate,\n            'is_admin': admin,\n            'is_contractor': contractor,\n        }}\n        response = self.post_request('people/', person, follow = True)\n        if response:\n            return Person(self, response['user'])", "response": "Creates a Person with the given information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_project(self, name, client_id, budget = None, budget_by =\n    \t'none', notes = None, billable = True):\n        '''Creates a Project with the given information.'''\n        project = {'project':{\n            'name': name,\n            'client_id': client_id,\n            'budget_by': budget_by,\n            'budget': budget,\n            'notes': notes,\n            'billable': billable,\n        }}\n        response = self.post_request('projects/', project, follow = True)\n        if response:\n            return Project(self, response['project'])", "response": "Creates a Project with the given information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_client(self, name):\n        '''Creates a Client with the given information.'''\n        client = {'client':{\n            'name': name,\n        }}\n        response = self.post_request('clients/', client, follow = True)\n        if response:\n            return Client(self, response['client'])", "response": "Creates a Client with the given information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self):\n        '''Deletes the person immediately.'''\n        response = self.hv.delete_request('people/' + str(self.id))\n        return response", "response": "Deletes the person immediately."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef entries(self, start = datetime.datetime.today(), end =\n    \tdatetime.datetime.today()):\n        '''Retrieves entries from all projects/tasks logged by this person.\n\n        Can be filtered based on time by specifying start/end datetimes.'''\n        fr = start.strftime('%Y%m%d')\n        to = end.strftime('%Y%m%d')\n        url = str.format(\n            'people/{}/entries?from={}&to={}',\n            str(self.id),\n            fr,\n            to,\n        )\n        response = self.hv.get_request(url)\n        return [Entry(self.hv, ej['day_entry']) for ej in response]", "response": "Retrieves entries from all projects or tasks logged by this person. Can be filtered by specifying start and end datetimes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve entries from all people / tasks logged to this project. Can be filtered by specifying start and end datetimes.", "response": "def entries(self, start = None, end = None):\n        '''Retrieves entries from all people/tasks logged to this project.\n\n        Can be filtered based on time by specifying start/end datetimes.'''\n        if not start:\n            start = self.earliest_record\n        if not end:\n            end = self.latest_record\n        fr = start.strftime('%Y%m%d')\n        to = end.strftime('%Y%m%d')\n        url = str.format(\n            'projects/{}/entries?from={}&to={}',\n            self.id,\n            fr,\n            to,\n        )\n        response = self.hv.get_request(url)\n        return [Entry(self.hv, ej['day_entry']) for ej in response]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving all tasks currently assigned to this project.", "response": "def task_assignments(self):\n        '''Retrieves all tasks currently assigned to this project.'''\n        url = str.format(\n            'projects/{}/task_assignments',\n            self.id\n        )\n        response = self.hv.get_request(url)\n        return [TaskAssignment(self.hv, tj['task_assignment']) for tj in response]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partial(cls, prefix, source):\n        match = prefix + \".\"\n        \n        matches = cls([(key[len(match):], source[key]) for key in source if key.startswith(match)])\n        \n        if not matches:\n            raise ValueError()\n        \n        return matches", "response": "Strip a prefix from the keys of another dictionary returning a Bunch containing only valid key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('--channel', action=arguments.ChanParser)\n    parser.add_argument('nick', nargs='*')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    quote = args['db'].query(Log.msg, Log.source)\n    nick = ' '.join(cmdargs.nick) if cmdargs.nick else \"\"\n    if nick:\n        quote = quote.filter(Log.source == nick)\n    else:\n        quote = quote.filter(Log.source != args['botnick'])\n    target = cmdargs.channels[0] if hasattr(cmdargs, 'channels') else args['config']['core']['channel']\n    quote = quote.filter(or_(Log.type == 'pubmsg', Log.type == 'privmsg', Log.type == 'action'), Log.target == target,\n                         func.length(Log.msg) > 5).order_by(func.random()).first()\n    if quote:\n        send(\"%s -- %s\" % quote)\n    elif nick:\n        send(\"%s isn't very quotable.\" % nick)\n    else:\n        send(\"Nobody is very quotable :(\")", "response": "Returns a random line from the nick."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of files from the given resource", "response": "def extract_files(self, resource):\n        \"\"\"\n            :param resource str|iterable  files, a file or a directory\n            @return: iterable\n        \"\"\"\n        if hasattr(resource, \"__iter__\"):\n            files = [file for file in resource if self.can_be_extracted(file)]\n        elif os.path.isfile(resource):\n            files = [resource] if self.can_be_extracted(resource) else []\n        else:\n            files = self._extract_from_directory(resource)\n\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pick_action_todo():\n    for ndx, todo in enumerate(things_to_do):\n        #print('todo = ', todo)\n        if roll_dice(todo[\"chance\"]):\n            cur_act = actions[get_action_by_name(todo[\"name\"])]\n            if todo[\"WHERE_COL\"] == \"energy\" and my_char[\"energy\"] > todo[\"WHERE_VAL\"]:\n                return cur_act\n            if todo[\"WHERE_COL\"] == \"gold\" and my_char[\"gold\"] > todo[\"WHERE_VAL\"]:\n                return cur_act\n\n\n    return actions[3]", "response": "picks an action from the list of actions that are not in the list of actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_action(character, action):\n    stats = \"Energy=\" + str(round(character[\"energy\"], 0)) + \", \"\n    stats += \"Gold=\" + str(round(character[\"gold\"], 0)) + \", \"\n\n    ndx_action_skill = get_skill_by_name(action[\"name\"], character)\n    stats += \"Skill=\" + str(round(character[\"skills\"][ndx_action_skill][\"level\"], 1))\n\n    my_char[\"energy\"] -= action[\"cost_energy\"]\n    my_char[\"skills\"][ndx_action_skill][\"level\"] += action[\"exp_gain\"]\n\n    # NOT NEEDED act = get_action_by_name(character[\"skills\"][ndx_action_skill][\"name\"])\n    reward_item = action[\"reward_item\"]\n    #print('reward_item = ', reward_item)\n    #print('action = ', action)\n\n    inv = get_inventory_by_name(reward_item, my_char)\n    #print('inv=', inv)\n\n    if roll_dice(action[\"reward_chance\"]) :\n        my_char[\"inventory\"][inv][\"val\"] += 1\n        #my_char[\"inventory\"][inv] += 1\n        #my_char[\"inventory\"][inv][reward_item] += 1\n        print(character[\"name\"] + \" is \" + action[\"name\"] + \". \" + stats + ' FOUND ' + reward_item)\n\n    else:\n        print(character[\"name\"] + \" is \" + action[\"name\"] + \". \" + stats)", "response": "This function is called by main game loop to run an action on a character."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_inventory_by_name(nme, character):\n\n    for ndx, sk in enumerate(character[\"inventory\"]):\n        #print(\"sk = \", sk, \" , nme = \", nme)\n        if sk[\"name\"] == nme:\n            return ndx\n    return 0", "response": "returns the index of the inventory element by name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the skill by name in a character", "response": "def get_skill_by_name(nme, character):\n    \"\"\"\n    returns the skill by name in a character\n    \"\"\"\n\n    for ndx, sk in enumerate(character[\"skills\"]):\n        if sk[\"name\"] == nme:\n            return ndx\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a function that returns True for elements that match the given operator attribute and optional value.", "response": "def attribute_checker(operator, attribute, value=''):\n    \"\"\"\n    Takes an operator, attribute and optional value; returns a function that\n    will return True for elements that match that combination.\n    \"\"\"\n    return {\n        '=': lambda el: el.get(attribute) == value,\n        # attribute includes value as one of a set of space separated tokens\n        '~': lambda el: value in el.get(attribute, '').split(),\n        # attribute starts with value\n        '^': lambda el: el.get(attribute, '').startswith(value),\n        # attribute ends with value\n        '$': lambda el: el.get(attribute, '').endswith(value),\n        # attribute contains value\n        '*': lambda el: value in el.get(attribute, ''),\n        # attribute is either exactly value or starts with value-\n        '|': lambda el: el.get(attribute, '') == value \\\n            or el.get(attribute, '').startswith('%s-' % value),\n    }.get(operator, lambda el: el.has_key(attribute))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting elements from a given selector.", "response": "def select(soup, selector):\n    \"\"\"\n    soup should be a BeautifulSoup instance; selector is a CSS selector \n    specifying the elements you want to retrieve.\n    \"\"\"\n    tokens = selector.split()\n    current_context = [soup]\n    for token in tokens:\n        m = attribselect_re.match(token)\n        if m:\n            # Attribute selector\n            tag, attribute, operator, value = m.groups()\n            if not tag:\n                tag = True\n            checker = attribute_checker(operator, attribute, value)\n            found = []\n            for context in current_context:\n                found.extend([el for el in context.findAll(tag) if checker(el)])\n            current_context = found\n            continue\n        if '#' in token:\n            # ID selector\n            tag, id = token.split('#', 1)\n            if not tag:\n                tag = True\n            el = current_context[0].find(tag, {'id': id})\n            if not el:\n                return [] # No match\n            current_context = [el]\n            continue\n        if '.' in token:\n            # Class selector\n            tag, klass = token.split('.', 1)\n            if not tag:\n                tag = True\n            found = []\n            for context in current_context:\n                found.extend(\n                    context.findAll(tag,\n                        {'class': lambda attr: attr and klass in attr.split()}\n                    )\n                )\n            current_context = found\n            continue\n        if token == '*':\n            # Star selector\n            found = []\n            for context in current_context:\n                found.extend(context.findAll(True))\n            current_context = found\n            continue\n        # Here we should just have a regular tag\n        if not tag_re.match(token):\n            return []\n        found = []\n        for context in current_context:\n            found.extend(context.findAll(token))\n        current_context = found\n    return current_context"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the gradient of KL divergence with respect to the i'th example of Y", "response": "def gradient(self, P, Q, Y, i):\n        \"\"\"Computes the gradient of KL divergence with respect to the i'th example of Y\"\"\"\n\n        return 4 * sum([\n            (P[i, j] - Q[i, j]) * (Y[i] - Y[j]) * (1 + np.linalg.norm(Y[i] - Y[j]) ** 2) ** -1 \\\n            for j in range(Y.shape[0])\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raise_(exception=ABSENT, *args, **kwargs):\n    if exception is ABSENT:\n        raise\n    else:\n        if inspect.isclass(exception):\n            raise exception(*args, **kwargs)\n        else:\n            if args or kwargs:\n                raise TypeError(\"can't pass arguments along with \"\n                                \"exception object to raise_()\")\n            raise exception", "response": "Raise (or re-raises) an exception.\n\n    :param exception: Exception object to raise, or an exception class.\n                      In the latter case, remaining arguments are passed\n                      to the exception's constructor.\n                      If omitted, the currently handled exception is re-raised."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nemulates a try statement.", "response": "def try_(block, except_=None, else_=None, finally_=None):\n    \"\"\"Emulate a ``try`` block.\n\n    :param block: Function to be executed within the ``try`` statement\n    :param except_: Function to execute when an :class:`Exception` occurs.\n                    It receives a single argument: the exception object.\n                    Alternatively, a list of key-value pairs can be passed,\n                    mapping exception types to their handler functions.\n    :param else_: Function to execute when ``block`` completes successfully.\n                  Note that it requires ``except_`` to be provided as well\n    :param finally_: Function to execute at the end,\n                     regardless of whether an exception occurred or not\n\n    :return:  If no exception was raised while executing ``block``,\n              the result of ``else_`` (if provided) or ``block`` is returned.\n              Otherwise, the result of ``except_`` is returned.\n\n    Note that :func:`try_` can _still_ raise an exception if it occurs\n    while evaluating ``except_``, ``else_`` or ``finally_`` functions.\n    \"\"\"\n    ensure_callable(block)\n    if not (except_ or else_ or finally_):\n        raise TypeError(\"at least one of `except_`, `else_` or `finally_` \"\n                        \"functions must be provided\")\n    if else_ and not except_:\n        raise TypeError(\"`else_` can only be provided along with `except_`\")\n\n    if except_:\n        if callable(except_):\n            except_ = [(Exception, except_)]\n        else:\n            ensure_iterable(except_)\n            if is_mapping(except_):\n                ensure_ordered_mapping(except_)\n                except_ = except_.items()\n\n        def handle_exception():\n            \"\"\"Dispatch current exception to proper handler in ``except_``.\"\"\"\n            exc_type, exc_object = sys.exc_info()[:2]\n            for t, handler in except_:\n                if issubclass(exc_type, t):\n                    return handler(exc_object)\n            raise\n\n        if else_:\n            ensure_callable(else_)\n            if finally_:\n                ensure_callable(finally_)\n                try:\n                    block()\n                except:\n                    return handle_exception()\n                else:\n                    return else_()\n                finally:\n                    finally_()\n            else:\n                try:\n                    block()\n                except:\n                    return handle_exception()\n                else:\n                    return else_()\n        else:\n            if finally_:\n                ensure_callable(finally_)\n                try:\n                    return block()\n                except:\n                    return handle_exception()\n                finally:\n                    finally_()\n            else:\n                try:\n                    return block()\n                except:\n                    return handle_exception()\n    elif finally_:\n        ensure_callable(finally_)\n        try:\n            return block()\n        finally:\n            finally_()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef with_(contextmanager, do):\n    ensure_contextmanager(contextmanager)\n    ensure_callable(do)\n\n    with contextmanager as value:\n        return do(value)", "response": "Emulate a with statement performing an operation within a context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _cast_repr(self, caster, *args, **kwargs):\n        if self.__repr_content is None:\n            self.__repr_content = hash_and_truncate(self)\n            assert self.__uses_default_repr  # Sanity check: we are indeed using the default repr here.  If this has ever changed, something went wrong.\n\n        return caster(self.__repr_content, *args, **kwargs)", "response": "Casts the name of this instance to the provided caster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(send, *_):\n    thread_names = []\n    for x in sorted(threading.enumerate(), key=lambda k: k.name):\n        res = re.match(r'Thread-(\\d+$)', x.name)\n        if res:\n            tid = int(res.group(1))\n            # Handle the main server thread (permanently listed as _worker)\n            if x._target.__name__ == '_worker':\n                thread_names.append((tid, \"%s running server thread\" % x.name))\n            # Handle the multiprocessing pool worker threads (they don't have names beyond Thread-x)\n            elif x._target.__module__ == 'multiprocessing.pool':\n                thread_names.append((tid, \"%s running multiprocessing pool worker thread\" % x.name))\n        # Handle everything else including MainThread and deferred threads\n        else:\n            res = re.match(r'Thread-(\\d+)', x.name)\n            tid = 0\n            if res:\n                tid = int(res.group(1))\n            thread_names.append((tid, x.name))\n    for x in sorted(thread_names, key=lambda k: k[0]):\n        send(x[1])", "response": "Enumerate threads.\n            Syntax: {command}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts stop resume delete get list", "response": "def cmd(send, msg, args):\n    \"\"\"Start/stops/resume/get stopwatch\n    Syntax: {command} <start|stop|resume|delete|get|list>\n    \"\"\"\n\n    parser = arguments.ArgParser(args['config'])\n    parser.set_defaults(session=args['db'])\n    subparser = parser.add_subparsers()\n    start_parser = subparser.add_parser('start')\n    start_parser.set_defaults(func=create_stopwatch)\n    stop_parser = subparser.add_parser('stop')\n    stop_parser.add_argument('id', type=int)\n    stop_parser.set_defaults(func=stop_stopwatch)\n    resume_parser = subparser.add_parser('resume')\n    resume_parser.add_argument('id', type=int)\n    resume_parser.set_defaults(func=resume_stopwatch)\n    delete_parser = subparser.add_parser('delete')\n    delete_parser.add_argument('id', type=int)\n    delete_parser.set_defaults(func=delete_stopwatch, isadmin=args['is_admin'](args['nick']))\n    get_parser = subparser.add_parser('get')\n    get_parser.add_argument('id', type=int)\n    get_parser.set_defaults(func=get_stopwatch)\n    list_parser = subparser.add_parser('list')\n    list_parser.set_defaults(func=list_stopwatch, nick=args['nick'], send=send)\n\n    if not msg:\n        send(\"Please specify a command.\")\n        return\n\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n\n    send(cmdargs.func(cmdargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the optimum pipe implementation for the capabilities of the active system.", "response": "def pipe():\n    \"\"\"Return the optimum pipe implementation for the capabilities of the active system.\"\"\"\n    \n    try:\n        from os import pipe\n        return pipe()\n    \n    except:\n        pipe = Pipe()\n        return pipe.reader_fd, pipe.writer_fd"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self):\n        try:\n            return self.reader.recv(1)\n        except socket.error:\n            ex = exception().exception\n            if ex.args[0] == errno.EWOULDBLOCK:\n                raise IOError\n            raise", "response": "Emulate a file descriptors read method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_all(text, dic):\n\n    for i, j in dic.iteritems():\n        text = text.replace(i, j)\n    return text", "response": "Takes a string and dictionary. replaces all occurrences of i with j"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_u_start_month(month):\n    month = month.lstrip('-')\n    if month == 'uu' or month == '0u':\n        return '01'\n    if month == 'u0':\n        return '10'\n    return month.replace('u', '0')", "response": "Find the earliest legitimate month."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the latest legitimate month.", "response": "def replace_u_end_month(month):\n    \"\"\"Find the latest legitimate month.\"\"\"\n    month = month.lstrip('-')\n    if month == 'uu' or month == '1u':\n        return '12'\n    if month == 'u0':\n        return '10'\n    if month == '0u':\n        return '09'\n    if month[1] in ['1', '2']:\n        # 'u1' or 'u2'\n        return month.replace('u', '1')\n    # Otherwise it should match r'u[3-9]'.\n    return month.replace('u', '0')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_u_start_day(day):\n    day = day.lstrip('-')\n    if day == 'uu' or day == '0u':\n        return '01'\n    if day == 'u0':\n        return '10'\n    return day.replace('u', '0')", "response": "Find the earliest legitimate day."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_u_end_day(day, year, month):\n    day = day.lstrip('-')\n    year = int(year)\n    month = int(month.lstrip('-'))\n    if day == 'uu' or day == '3u':\n        # Use the last day of the month for a given year/month.\n        return str(calendar.monthrange(year, month)[1])\n    if day == '0u' or day == '1u':\n        return day.replace('u', '9')\n    if day == '2u' or day == 'u9':\n        if month != '02' or calendar.isleap(year):\n            return '29'\n        elif day == '2u':\n            # It is Feburary and not a leap year.\n            return '28'\n        else:\n            # It is February, not a leap year, day ends in 9.\n            return '19'\n    # 'u2' 'u3' 'u4' 'u5' 'u6' 'u7' 'u8'\n    if 1 < int(day[1]) < 9:\n        return day.replace('u', '2')\n    # 'u0' 'u1'\n    if day == 'u1':\n        if calendar.monthrange(year, month)[1] == 31:\n            # See if the month has a 31st.\n            return '31'\n        else:\n            return '21'\n    if day == 'u0':\n        if calendar.monthrange(year, month)[1] >= 30:\n            return '30'\n    else:\n        return '20'", "response": "Find the latest legitimate day."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_u(matchobj):\n    pieces = list(matchobj.groups(''))\n    # Replace \"u\"s in start and end years.\n    if 'u' in pieces[1]:\n        pieces[1] = pieces[1].replace('u', '0')\n    if 'u' in pieces[5]:\n        pieces[5] = pieces[5].replace('u', '9')\n    # Replace \"u\"s in start month.\n    if 'u' in pieces[2]:\n        pieces[2] = '-' + replace_u_start_month(pieces[2])\n    # Replace \"u\"s in end month.\n    if 'u' in pieces[6]:\n        pieces[6] = '-' + replace_u_end_month(pieces[6])\n    # Replace \"u\"s in start day.\n    if 'u' in pieces[3]:\n        pieces[3] = '-' + replace_u_start_day(pieces[3])\n    # Replace \"u\"s in end day.\n    if 'u' in pieces[7]:\n        pieces[7] = '-' + replace_u_end_day(pieces[7], year=pieces[5],\n                                            month=pieces[6])\n    return ''.join((''.join(pieces[:4]), '/', ''.join(pieces[4:])))", "response": "Replace u in the current ISO - 8601 date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zero_year_special_case(from_date, to_date, start, end):\n\n    if start == 'pos' and end == 'pos':\n        # always interval from earlier to later\n        if from_date.startswith('0000') and not to_date.startswith('0000'):\n            return True\n        # always interval from later to earlier\n        if not from_date.startswith('0000') and to_date.startswith('0000'):\n            return False\n        # an interval from 0000-MM-DD/0000-MM-DD ??? PARSE !!!\n        if from_date.startswith('0000') and to_date.startswith('0000'):\n            # fill from date assuming first subsequent date object if missing\n            # missing m+d, assume jan 1\n            if len(from_date) == 4:\n                fm, fd = 1, 1\n            # missing d, assume the 1st\n            elif len(from_date) == 7:\n                fm, fd = int(from_date[5:7]), 1\n            # not missing any date objects\n            elif len(from_date) == 10:\n                fm, fd = int(from_date[5:7]), int(from_date[8:10])\n            # fill to date assuming first subsequent date object if missing\n            # missing m+d, assume jan 1\n            if len(to_date) == 4:\n                tm, td = 1, 1\n            # missing d, assume the 1st\n            elif len(to_date) == 7:\n                tm, td = int(to_date[5:7]), 1\n            # not missing any date objects\n            elif len(to_date) == 10:\n                tm, td = int(to_date[5:7]), int(to_date[8:10])\n            # equality check\n            if from_date == to_date:\n                return True\n            # compare the dates\n            if fm <= tm:\n                if fd <= td:\n                    return True\n                else:\n                    return False\n            else:\n                return False\n    # these cases are always one way or the other\n    # \"-0000\" is an invalid edtf\n    elif start == 'neg' and end == 'neg':\n        return False\n    # False unless start is not \"0000\"\n    elif start == 'neg' and end == 'pos':\n        if from_date.startswith(\"0000\"):\n            return False\n        else:\n            return True", "response": "This function handles the special case of zero year special cases."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_interval(edtf_candidate):\n\n    # resolve interval into from / to datetime objects\n    from_date = None\n    to_date = None\n    # initialize interval flags for special cases, assume positive\n    end, start = 'pos', 'pos'\n    if edtf_candidate.count('/') == 1:\n        # replace all 'problem' cases (unspecified, 0000 date, ?~, -, y)\n        # break the interval into two date strings\n        edtf_candidate = replace_all(edtf_candidate, interval_replacements)\n        edtf_candidate = re.sub(U_PATTERN, replace_u, edtf_candidate)\n        parts = edtf_candidate.split('/')\n        # set flag for negative start date\n        if parts[0].startswith(\"-\"):\n            start = 'neg'\n            parts[0] = parts[0][1:]\n        # set flag for negative end date\n        if parts[1].startswith(\"-\"):\n            end = 'neg'\n            parts[1] = parts[1][1:]\n        # if starts positive and ends negative, that's always False\n        if start == 'pos' and end == 'neg':\n            return False\n        # handle special case of 0000 year\n        if parts[0].startswith(\"0000\") or parts[1].startswith(\"0000\"):\n            return zero_year_special_case(parts[0], parts[1], start, end)\n        # 2 '-' characters means we are matching year-month-day\n        if parts[0].count(\"-\") == 2:\n            from_date = datetime.datetime.strptime(parts[0], \"%Y-%m-%d\")\n        if parts[1].count(\"-\") == 2:\n            to_date = datetime.datetime.strptime(parts[1], \"%Y-%m-%d\")\n        # 1 '-' character means we are match year-month\n        if parts[0].count(\"-\") == 1:\n            from_date = datetime.datetime.strptime(parts[0], \"%Y-%m\")\n        if parts[1].count(\"-\") == 1:\n            to_date = datetime.datetime.strptime(parts[1], \"%Y-%m\")\n        # zero '-' characters means we are matching a year\n        if parts[0].count(\"-\") == 0:\n            # if from_date is unknown, we can assume the lowest possible date\n            if parts[0] == 'unknown':\n                from_date = datetime.datetime.strptime(\"0001\", \"%Y\")\n            else:\n                from_date = datetime.datetime.strptime(parts[0], \"%Y\")\n        if parts[1].count(\"-\") == 0:\n            # when the to_date is open and the from_date is valid, it's valid\n            if parts[1] == 'open' or parts[1] == 'unknown':\n                to_date = 'open'\n            else:\n                to_date = datetime.datetime.strptime(parts[1], \"%Y\")\n        # if it starts negative and ends positive, that's always True\n        if start == 'neg' and end == 'pos':\n            return True\n        # if start and end are negative, the from_date must be >= to_date\n        elif start == 'neg' and end == 'neg':\n            if from_date >= to_date and from_date and to_date:\n                return True\n        # if the to_date is unknown or open, it could be any date, therefore\n        elif (\n            parts[1] == 'unknown' or\n            parts[1] == 'open' or\n            parts[0] == 'unknown'\n        ):\n            return True\n        # if start and end are positive, the from_date must be <= to_date\n        elif start == 'pos' and end == 'pos':\n            if from_date <= to_date and from_date and to_date:\n                return True\n        else:\n            return False\n    else:\n        return False", "response": "Test to see if the edtf candidate is a valid interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isLevel2(edtf_candidate):\n\n    if \"[\" in edtf_candidate or \"{\" in edtf_candidate:\n        result = edtf_candidate == level2Expression\n    elif \" \" in edtf_candidate:\n        result = False\n    else:\n        result = edtf_candidate == level2Expression\n    return result", "response": "Checks to see if the date is level 2 valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_valid(edtf_candidate):\n\n    if (\n        isLevel0(edtf_candidate) or\n        isLevel1(edtf_candidate) or\n        isLevel2(edtf_candidate)\n    ):\n        if '/' in edtf_candidate:\n            return is_valid_interval(edtf_candidate)\n        else:\n            return True\n    else:\n        return False", "response": "isValid takes a candidate date and returns if it is valid or not"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_direct_subclass(class_, of):\n    ensure_class(class_)\n    ensure_class(of)  # TODO(xion): support predicates in addition to classes\n\n    return of in class_.__bases__", "response": "Checks whether given class is a direct subclass of the other."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether given class is a direct subclass of another.", "response": "def ensure_direct_subclass(class_, of):\n    \"\"\"Check whether given class is a direct subclass of another.\n\n    :param class_: Class to check\n    :param of: Superclass to check against\n\n    :return: ``class_``, if the check succeeds\n    :raise TypeError: When the check fails\n\n    .. versionadded:: 0.0.4\n    \"\"\"\n    if not is_direct_subclass(class_, of):\n        raise TypeError(\"expected a direct subclass of %r, got %s instead\" % (\n            of, class_.__name__))\n    return class_"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_indirect_subclass(class_, of):\n    ensure_class(class_)\n    ensure_class(of)  # TODO(xion): support predicates in addition to classes\n\n    return issubclass(class_, of) and not is_direct_subclass(class_, of)", "response": "Checks whether given is an indirect subclass of another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether given is an indirect subclass of another.", "response": "def ensure_indirect_subclass(class_, of):\n    \"\"\"Check whether given is an indirect subclass of another,\n    i.e. there exists at least intermediate base between ``of`` and ``class_``.\n\n    :param class_: Class to check\n    :param of: Superclass to check against\n\n    :return: ``class_``, if the check succeeds\n    :raise TypeError: When the check fails\n\n    .. versionadded:: 0.0.4\n    \"\"\"\n    if not is_indirect_subclass(class_, of):\n        raise TypeError(\n            \"expected an indirect subclass of %r, got %s instead\" % (\n                of, class_.__name__))\n    return class_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_subclasses(class_):\n    ensure_class(class_)\n\n    classes = set()\n\n    def descend(class_):\n        subclasses = set(class_.__subclasses__()) - classes\n        classes.update(subclasses)\n        return subclasses\n\n    result = breadth_first(class_, descend)\n    next(result)  # omit ``class_`` itself\n    return result", "response": "Iterate over all the subclasses of class_ and subclasses thereof etc. of class_."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_superclasses(class_):\n    ensure_class(class_)\n\n    classes = set()\n\n    def ascend(class_):\n        superclasses = set(class_.__bases__) - classes\n        classes.update(superclasses)\n        return superclasses\n\n    result = breadth_first(class_, ascend)\n    next(result)  # omit ``class_`` itself\n    return result", "response": "Iterate over all the superclasses of given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests program for VAIS. Generates several planets and populates with animals and plants. Then places objects and tests the sequences.", "response": "def main():\n    \"\"\"\n    test program for VAIS.\n    Generates several planets and populates with animals and plants.\n    Then places objects and tests the sequences.\n    \"\"\"\n    print(\"|---------------------------------------------------\")\n    print(\"|          Virtual AI Simulator\")\n    print(\"|---------------------------------------------------\")\n    print(\"| \")\n    print(\"| r = rebuild planets        c = create character\")\n    print(\"| s = simulation             o = create opponent\")\n    print(\"| q = quit                   b = battle characters\")\n    print(\"| \")\n    \n    planets = load_planet_list()\n    show_planet_shortlist(planets)\n    print(\"|---------------------------------------------------\")\n    cmd = input('| Enter choice ?' )\n    if cmd == 'r':\n        rebuild_planet_samples()\n    elif cmd == 'q':\n        exit(0)\n    elif cmd < str(len(planets)+1) and cmd > '0':\n        fname = planets[int(cmd) - 1]['name'] + '.txt'\n        print('viewing planet ' + fname)\n        view_world.display_map(fldr + os.sep + fname)\n    elif cmd == 'c':\n        c1 = create_character()\n    elif cmd == 'o':\n        c2 = create_character()\n    elif cmd == 'b':\n        run_simulation(c1, c2)\n    elif cmd == 's':\n        print('not implemented')\n    else:\n        print('invalid command ' + cmd)\n    main()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_planet_list():\n    planet_list = []\n    with open(fldr + os.sep + 'planet_samples.csv') as f:\n        hdr = f.readline()\n        for line in f:\n            #print(\"Building \", line)\n            name, num_seeds, width, height, wind, rain, sun, lava = parse_planet_row(line)\n            planet_list.append({'name':name, 'num_seeds':num_seeds, 'width':width, 'height':height, 'wind':wind, 'rain':rain, 'sun':sun, 'lava':lava})\n    return planet_list", "response": "load the list of prebuilt planets\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a random character", "response": "def create_character():\n    \"\"\"\n    create a random character\n    \"\"\"\n    traits = character.CharacterCollection(character.fldr)\n    c = traits.generate_random_character()\n    print(c)\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_simulation(c1, c2):\n    print('running simulation...')\n    traits = character.CharacterCollection(character.fldr)\n    c1 = traits.generate_random_character()\n    c2 = traits.generate_random_character()\n    print(c1)\n    print(c2)\n    rules = battle.BattleRules(battle.rules_file)\n    b = battle.Battle(c1, c2, traits, rules, print_console='Yes')\n    print(b.status)", "response": "Runs simulation of the Battle algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef name_replace(self, to_replace, replacement):\n        self.name = self.name.replace(to_replace, replacement)", "response": "Replaces part of tag name with new value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nattempt to parse array size out of the address", "response": "def get_array_size(self):\n        \"\"\"Attempts to parse array size out of the address\"\"\"\n        match = re.search(r\"(?<=\\[)\\d+(?=\\])\", self.get_address())\n        return int(match.group(0))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to parse array size out of the address", "response": "def get_string_length(self):\n        \"\"\"Attempts to parse array size out of the address\"\"\"\n        try:\n            return self.get_array_size()\n        except:\n            match = re.search(r\"(?<=\\.)\\d+\", self.get_address())\n            try:\n                return int(match.group(0))\n            except Exception as ex:\n                raise Exception('Could not get string size of {0} address {1}'\n                                .format(\n                                    self.name,\n                                    self.get_address()),\n                                ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts text to morse code.", "response": "def cmd(send, msg, args):\n    \"\"\"Converts text to morse code.\n\n    Syntax: {command} [text]\n\n    \"\"\"\n    if not msg:\n        msg = gen_word()\n    morse = gen_morse(msg)\n    if len(morse) > 100:\n        send(\"Your morse is too long. Have you considered Western Union?\")\n    else:\n        send(morse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef INDEX_OF_BYTES(string_expression, substring_expression, start=None, end=None):\n    res = [string_expression, substring_expression]\n    if start is not None:\n        res.append(start)\n    if end is not None:\n        res.append(end)\n    return {'$indexOfBytes': res}", "response": "Searches a string for an occurence of a substring and returns the index of the first occurence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef INDEX_OF_CP(string_expression, substring_expression, start=None, end=None):\n    res = [string_expression, substring_expression]\n    if start is not None:\n        res.append(start)\n    if end is not None:\n        res.append(end)\n    return {'$indexOfCP': res}", "response": "Searches a string for an occurence of a substring and returns the index of the first occurence."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npresent a block of text of given length.", "response": "def ellipsis(text, length, symbol=\"...\"):\n    \"\"\"Present a block of text of given length.\n    \n    If the length of available text exceeds the requested length, truncate and\n    intelligently append an ellipsis.\n    \"\"\"\n    if len(text) > length:\n        pos = text.rfind(\" \", 0, length)\n        if pos < 0:\n            return text[:length].rstrip(\".\") + symbol\n        else:\n            return text[:pos].rstrip(\".\") + symbol\n    \n    else:\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_elections(self, obj):\n        election_day = ElectionDay.objects.get(\n            date=self.context['election_date'])\n        elections = Election.objects.filter(\n            race__office=obj,\n            election_day=election_day\n        )\n        return ElectionSerializer(elections, many=True).data", "response": "All elections on an election day."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_content(self, obj):\n        election_day = ElectionDay.objects.get(\n            date=self.context['election_date'])\n        return PageContent.objects.office_content(election_day, obj)", "response": "All content for an office s page on an election day."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncancels a deferred action with the given id.", "response": "def cmd(send, msg, args):\n    \"\"\"Cancels a deferred action with the given id.\n\n    Syntax: {command} <id>\n\n    \"\"\"\n    try:\n        args['handler'].workers.cancel(int(msg))\n    except ValueError:\n        send(\"Index must be a digit.\")\n        return\n    except KeyError:\n        send(\"No such event.\")\n        return\n    send(\"Event canceled.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a number to the roman numeral equivalent.", "response": "def cmd(send, msg, _):\n    \"\"\"Convert a number to the roman numeral equivalent.\n\n    Syntax: {command} [number]\n\n    \"\"\"\n    if not msg:\n        msg = randrange(5000)\n    elif not msg.isdigit():\n        send(\"Invalid Number.\")\n        return\n    send(gen_roman(int(msg)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, args):\n    if not msg:\n        send(\"kill who?\")\n        return\n    if msg.lower() == args['botnick'].lower():\n        send('%s is not feeling suicidal right now.' % msg)\n    else:\n        send('Die, %s!' % msg)", "response": "Kills somebody.\n\n    Syntax: {command} <victim>"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef svm_load_model(model_file_name):\n\tmodel = libsvm.svm_load_model(model_file_name.encode())\n\tif not model:\n\t\tprint(\"can't open model file %s\" % model_file_name)\n\t\treturn None\n\tmodel = toPyModel(model)\n\treturn model", "response": "Load a LIBSVM model from model_file_name and return."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to predict the SVM model.", "response": "def svm_predict(y, x, m, options=\"\"):\n\t\"\"\"\n\tsvm_predict(y, x, m [, options]) -> (p_labels, p_acc, p_vals)\n\n\ty: a list/tuple/ndarray of l true labels (type must be int/double).\n\t   It is used for calculating the accuracy. Use [] if true labels are\n\t   unavailable.\n\n\tx: 1. a list/tuple of l training instances. Feature vector of\n\t      each training instance is a list/tuple or dictionary.\n\n\t   2. an l * n numpy ndarray or scipy spmatrix (n: number of features).\n\n\tPredict data (y, x) with the SVM model m.\n\toptions:\n\t    -b probability_estimates: whether to predict probability estimates,\n\t        0 or 1 (default 0); for one-class SVM only 0 is supported.\n\t    -q : quiet mode (no outputs).\n\n\tThe return tuple contains\n\tp_labels: a list of predicted labels\n\tp_acc: a tuple including  accuracy (for classification), mean-squared\n\t       error, and squared correlation coefficient (for regression).\n\tp_vals: a list of decision values or probability estimates (if '-b 1'\n\t        is specified). If k is the number of classes, for decision values,\n\t        each element includes results of predicting k(k-1)/2 binary-class\n\t        SVMs. For probabilities, each element contains k values indicating\n\t        the probability that the testing instance is in each class.\n\t        Note that the order of classes here is the same as 'model.label'\n\t        field in the model structure.\n\t\"\"\"\n\n\tdef info(s):\n\t\tprint(s)\n\n\tif scipy and isinstance(x, scipy.ndarray):\n\t\tx = scipy.ascontiguousarray(x) # enforce row-major\n\telif sparse and isinstance(x, sparse.spmatrix):\n\t\tx = x.tocsr()\n\telif not isinstance(x, (list, tuple)):\n\t\traise TypeError(\"type of x: {0} is not supported!\".format(type(x)))\n\n\tif (not isinstance(y, (list, tuple))) and (not (scipy and isinstance(y, scipy.ndarray))):\n\t\traise TypeError(\"type of y: {0} is not supported!\".format(type(y)))\n\n\tpredict_probability = 0\n\targv = options.split()\n\ti = 0\n\twhile i < len(argv):\n\t\tif argv[i] == '-b':\n\t\t\ti += 1\n\t\t\tpredict_probability = int(argv[i])\n\t\telif argv[i] == '-q':\n\t\t\tinfo = print_null\n\t\telse:\n\t\t\traise ValueError(\"Wrong options\")\n\t\ti+=1\n\n\tsvm_type = m.get_svm_type()\n\tis_prob_model = m.is_probability_model()\n\tnr_class = m.get_nr_class()\n\tpred_labels = []\n\tpred_values = []\n\n\tif scipy and isinstance(x, sparse.spmatrix):\n\t\tnr_instance = x.shape[0]\n\telse:\n\t\tnr_instance = len(x)\n\n\tif predict_probability:\n\t\tif not is_prob_model:\n\t\t\traise ValueError(\"Model does not support probabiliy estimates\")\n\n\t\tif svm_type in [NU_SVR, EPSILON_SVR]:\n\t\t\tinfo(\"Prob. model for test data: target value = predicted value + z,\\n\"\n\t\t\t\"z: Laplace distribution e^(-|z|/sigma)/(2sigma),sigma=%g\" % m.get_svr_probability());\n\t\t\tnr_class = 0\n\n\t\tprob_estimates = (c_double * nr_class)()\n\t\tfor i in range(nr_instance):\n\t\t\tif scipy and isinstance(x, sparse.spmatrix):\n\t\t\t\tindslice = slice(x.indptr[i], x.indptr[i+1])\n\t\t\t\txi, idx = gen_svm_nodearray((x.indices[indslice], x.data[indslice]), isKernel=(m.param.kernel_type == PRECOMPUTED))\n\t\t\telse:\n\t\t\t\txi, idx = gen_svm_nodearray(x[i], isKernel=(m.param.kernel_type == PRECOMPUTED))\n\t\t\tlabel = libsvm.svm_predict_probability(m, xi, prob_estimates)\n\t\t\tvalues = prob_estimates[:nr_class]\n\t\t\tpred_labels += [label]\n\t\t\tpred_values += [values]\n\telse:\n\t\tif is_prob_model:\n\t\t\tinfo(\"Model supports probability estimates, but disabled in predicton.\")\n\t\tif svm_type in (ONE_CLASS, EPSILON_SVR, NU_SVC):\n\t\t\tnr_classifier = 1\n\t\telse:\n\t\t\tnr_classifier = nr_class*(nr_class-1)//2\n\t\tdec_values = (c_double * nr_classifier)()\n\t\tfor i in range(nr_instance):\n\t\t\tif scipy and isinstance(x, sparse.spmatrix):\n\t\t\t\tindslice = slice(x.indptr[i], x.indptr[i+1])\n\t\t\t\txi, idx = gen_svm_nodearray((x.indices[indslice], x.data[indslice]), isKernel=(m.param.kernel_type == PRECOMPUTED))\n\t\t\telse:\n\t\t\t\txi, idx = gen_svm_nodearray(x[i], isKernel=(m.param.kernel_type == PRECOMPUTED))\n\t\t\tlabel = libsvm.svm_predict_values(m, xi, dec_values)\n\t\t\tif(nr_class == 1):\n\t\t\t\tvalues = [1]\n\t\t\telse:\n\t\t\t\tvalues = dec_values[:nr_classifier]\n\t\t\tpred_labels += [label]\n\t\t\tpred_values += [values]\n\n\tif len(y) == 0:\n\t\ty = [0] * nr_instance\n\tACC, MSE, SCC = evaluations(y, pred_labels)\n\n\tif svm_type in [EPSILON_SVR, NU_SVR]:\n\t\tinfo(\"Mean squared error = %g (regression)\" % MSE)\n\t\tinfo(\"Squared correlation coefficient = %g (regression)\" % SCC)\n\telse:\n\t\tinfo(\"Accuracy = %g%% (%d/%d) (classification)\" % (ACC, int(round(nr_instance*ACC/100)), nr_instance))\n\n\treturn pred_labels, (ACC, MSE, SCC), pred_values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving help. Syntax: {command} [command]", "response": "def cmd(send, msg, args):\n    \"\"\"Gives help.\n\n    Syntax: {command} [command]\n\n    \"\"\"\n    cmdchar = args['config']['core']['cmdchar']\n    if msg:\n        if msg.startswith(cmdchar):\n            msg = msg[len(cmdchar):]\n        if len(msg.split()) > 1:\n            send(\"One argument only\")\n        elif not command_registry.is_registered(msg):\n            send(\"Not a module.\")\n        else:\n            doc = command_registry.get_command(msg).get_doc()\n            if doc is None:\n                send(\"No documentation found.\")\n            else:\n                for line in doc.splitlines():\n                    send(line.format(command=cmdchar + msg), target=args['nick'])\n    else:\n        modules = sorted(command_registry.get_enabled_commands())\n        cmdlist = (' %s' % cmdchar).join(modules)\n        send('Commands: %s%s' % (cmdchar, cmdlist), target=args['nick'], ignore_length=True)\n        send('%shelp <command> for more info on a command.' % cmdchar, target=args['nick'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef route(rule=None, **kwargs):\n\n    _restricted_keys = [\"extends\", \"route\", \"decorators\"]\n    def decorator(f):\n        if inspect.isclass(f):\n            extends = kwargs.pop(\"extends\", None)\n            if extends and hasattr(extends, self.view_key):\n                for k, v in getattr(extends, self.view_key).items():\n                    kwargs.setdefault(k, v)\n\n            kwargs.setdefault(\"route\", rule)\n            kwargs[\"decorators\"] = kwargs.get(\"decorators\", []) + f.decorators\n            setattr(f, \"_route_extends__\", kwargs)\n            setattr(f, \"base_route\", kwargs.get(\"route\"))\n            setattr(f, \"decorators\", kwargs.get(\"decorators\", []))\n        else:\n            if not rule:\n                raise ValueError(\"'rule' is missing in @route \")\n\n            for k in _restricted_keys:\n                if k in kwargs:\n                    del kwargs[k]\n\n            # Put the rule cache on the method itself instead of globally\n            if not hasattr(f, '_rule_cache') or f._rule_cache is None:\n                f._rule_cache = {f.__name__: [(rule, kwargs)]}\n            elif not f.__name__ in f._rule_cache:\n                f._rule_cache[f.__name__] = [(rule, kwargs)]\n            else:\n                f._rule_cache[f.__name__].append((rule, kwargs))\n        return f\n\n    return decorator", "response": "A decorator that can be used to add custom route to both class and methods in the view."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef methods(*meth):\n    def decorator(f):\n        if not hasattr(f, '_methods_cache'):\n            f._methods_cache = [m.upper() for m in meth]\n        return f\n    return decorator", "response": "Decorator to set the methods to use without using the route\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_as_json(func):\n    if inspect.isclass(func):\n        setattr(func, \"_renderer\", json_renderer)\n        return func\n    else:\n        @functools.wraps(func)\n        def decorated_view(*args, **kwargs):\n            data = func(*args, **kwargs)\n            return _build_response(data, jsonify)\n        return decorated_view", "response": "Decorator to render as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef require_user_roles(*roles):\n    def wrapper(f):\n        @functools.wraps(f)\n        def wrapped(*args, **kwargs):\n            if ext.user_authenticated():\n                if not ext.flask_login.current_user.has_any_roles(*roles):\n                    return abort(403)\n            else:\n                return abort(401)\n            return f(*args, **kwargs)\n        return wrapped\n    return wrapper", "response": "A decorator to check if user has any of the roles specified"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new entry to the list of entries in the hierarchy.", "response": "def add(self, name, extends, **kwargs):\n        \"\"\"\n        To manually add a extends. Usually, menu by hand which\n        may not be attached to any functions\n        :param name:\n        :param cls:\n        :param method_:\n        :param is_class_:\n        :param kwargs:\n        :return:\n        \"\"\"\n        f = extends\n        self._push(name=name,\n                   module_=f.__module__,\n                   class_=f.__name__,\n                   method_=f.__name__,\n                   is_class_=False,\n                   **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening a single - element list into a single - element list.", "response": "def flatten(x):\n    \"\"\"flatten(sequence) -> list\n\n    Returns a single, flat list which contains all elements retrieved\n    from the sequence and all recursively contained sub-sequences\n    (iterables).\n\n    Examples:\n    >>> [1, 2, [3,4], (5,6)]\n    [1, 2, [3, 4], (5, 6)]\n    >>> flatten([[[1,2,3], (42,None)], [4,5], [6], 7, MyVector(8,9,10)])\n    [1, 2, 3, 42, None, 4, 5, 6, 7, 8, 9, 10]\n    \"\"\"\n\n    for el in x:\n        if hasattr(el, \"__iter__\") and not isinstance(el, (binary, unicode)):\n            for els in flatten(el):\n                yield els\n        else:\n            yield el"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge(s, t):\n\n    for k, v in t.items():\n        if isinstance(v, dict):\n            if k not in s:\n                s[k] = v\n                continue\n\n            s[k] = merge(s[k], v)\n            continue\n\n        s[k] = v\n\n    return s", "response": "Merge dictionary t into s."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_object(target, namespace=None):\n    if namespace and ':' not in target:\n        allowable = dict((i.name,  i) for i in pkg_resources.iter_entry_points(namespace))\n        if target not in allowable:\n            raise ValueError('Unknown plugin \"' + target + '\"; found: ' + ', '.join(allowable))\n        return allowable[target].load()\n\n    parts, target = target.split(':') if ':' in target else (target, None)\n    module = __import__(parts)\n\n    for part in parts.split('.')[1:] + ([target] if target else []):\n        module = getattr(module, part)\n\n    return module", "response": "This helper function loads an object identified by a dotted - notation string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getargspec(obj):\n\n    argnames, varargs, varkw, _defaults = None, None, None, None\n\n    if inspect.isfunction(obj) or inspect.ismethod(obj):\n        argnames, varargs, varkw, _defaults = inspect.getargspec(obj)\n\n    elif inspect.isclass(obj):\n        if inspect.ismethoddescriptor(obj.__init__):\n            argnames, varargs, varkw, _defaults = [], False, False, None\n\n        else:\n            argnames, varargs, varkw, _defaults = inspect.getargspec(obj.__init__)\n\n    elif hasattr(obj, '__call__'):\n        argnames, varargs, varkw, _defaults = inspect.getargspec(obj.__call__)\n\n    else:\n        raise TypeError(\"Object not callable?\")\n\n    # Need test case to prove this is even possible.\n    # if (argnames, varargs, varkw, defaults) is (None, None, None, None):\n    #     raise InspectionFailed()\n\n    if argnames and argnames[0] == 'self':\n        del argnames[0]\n\n    if _defaults is None:\n        _defaults = []\n        defaults = dict()\n\n    else:\n        # Create a mapping dictionary of defaults; this is slightly more useful.\n        defaults = dict()\n        _defaults = list(_defaults)\n        _defaults.reverse()\n        argnames.reverse()\n        for i, default in enumerate(_defaults):\n            defaults[argnames[i]] = default\n\n        argnames.reverse()\n        # del argnames[-len(_defaults):]\n\n    return argnames, defaults, True if varargs else False, True if varkw else False", "response": "An improved inspect. getargspec."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a queryset of all states holding a special election on a date.", "response": "def get_queryset(self):\n        \"\"\"\n        Returns a queryset of all states holding a non-special election on\n        a date.\n        \"\"\"\n        try:\n            date = ElectionDay.objects.get(date=self.kwargs[\"date\"])\n        except Exception:\n            raise APIException(\n                \"No elections on {}.\".format(self.kwargs[\"date\"])\n            )\n        division_ids = []\n\n        normal_elections = date.elections.filter()\n\n        if len(normal_elections) > 0:\n            for election in date.elections.all():\n                if election.division.level.name == DivisionLevel.STATE:\n                    division_ids.append(election.division.uid)\n                elif election.division.level.name == DivisionLevel.DISTRICT:\n                    division_ids.append(election.division.parent.uid)\n\n        return Division.objects.filter(uid__in=division_ids)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds election_day to serializer context.", "response": "def get_serializer_context(self):\n        \"\"\"Adds ``election_day`` to serializer context.\"\"\"\n        context = super(StateMixin, self).get_serializer_context()\n        context[\"election_date\"] = self.kwargs[\"date\"]\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_relative_path(self, domain, locale):\n        return self.relative_path_template.format(\n            domain=domain,\n            locale=locale,\n            extension=self.get_extension()\n        )", "response": "Gets the relative file path using the template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying the fuzzy matches of w within edit distance ed.", "response": "def query(self, w, ed=1):  # Can only handle ed=1\n        \"\"\"\n        Finds the fuzzy matches (within edit distance 1) of w from words \n        \"\"\"\n        assert ed <= self._ed\n        if ed == 0:\n            return [w] if w in self._L else ['']\n        w = str(w)\n        n = len(w)\n        prefix, suffix = w[:n // 2], w[n // 2:][::-1]\n        options_w_prefix = self._L.keys(prefix)\n        options_w_suffix = [x[::-1] for x in self._R.iterkeys(suffix)]\n        return [\n            _w\n            for _w in set(itertools.chain(options_w_prefix, options_w_suffix))\n            if abs(len(_w) - len(w)) <= 1 and lvdistance(str(_w), str(w), 1) <= 1\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _find_overlap(queries, client, find_method, get_method,\n                        overlap_function):\n    \"\"\"Generic find and overlap implementation.\n\n    Arguments\n      names (:py:class:`collections.abc.Sequence`): The queries of the\n        people to find overlaps for.\n      client (:py:class:`~.TMDbClient`): The TMDb client.\n      find_method (:py:class:`str`): The name of the client method to\n        use for finding candidates.\n      get_method (:py:class:`str`): The name of the client method to\n        use for getting detailed information on a candidate.\n      overlap_function (:py:class:`collections.abc.Callable`): The\n        function to call for the resulting overlap.\n\n    \"\"\"\n    results = []\n    for query in queries:\n        candidates = await getattr(client, find_method)(query)\n        if not candidates:\n            raise ValueError('no result found for {!r}'.format(query))\n        result = await getattr(client, get_method)(id_=candidates[0].id_)\n        results.append(result)\n    return await overlap_function(results, client)", "response": "Generic find and overlap implementation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--clear', action='store_true')\n    group.add_argument('--show', action='store_true')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.clear:\n        args['handler'].abuselist.clear()\n        send(\"Abuse list cleared.\")\n    elif cmdargs.show:\n        abusers = []\n        for x in args['handler'].abuselist.keys():\n            if args['db'].query(Ignore).filter(Ignore.nick == x).count():\n                abusers.append(x)\n        if abusers:\n            send(\", \".join(abusers))\n        else:\n            send(\"No abusers.\")\n    else:\n        send(\"Please specify an option.\")", "response": "Shows or clears the abuse list\n    Syntax : { command } <-- clear|-- show >\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef urlize_twitter(text):\n    html = TwitterText(text).autolink.auto_link()\n    return mark_safe(html.replace(\n        'twitter.com/search?q=', 'twitter.com/search/realtime/'))", "response": "URLize a tweet with Twitter s auto - link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _combined_properties(self):\n        result = dict(self._properties)\n        par = self._parent\n        while par:\n            result.update(par._properties)\n            par = par._parent\n        return result", "response": "Returns a dictionary with this object s properties merged with all its parent s\n        properties."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary with this object s properties merged with all its parent s properties.", "response": "def _combined_items(self):\n        \"\"\"Returns a dictionary with this object's properties merged with all its parent's\n        properties.\n\n        The returned dictionary is all the available properties for this object (and their\n        associated values).\n        \"\"\"\n        result = dict(self._items)\n        par = self._parent\n        while par:\n            result.update(par._items)\n            par = par._parent\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef before(self, context):\n        \"Invokes all before functions with context passed to them.\"\n        run.before_each.execute(context)\n        self._invoke(self._before, context)", "response": "Invokes all before functions with context passed to them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke all after functions with context passed to them.", "response": "def after(self, context):\n        \"Invokes all after functions with context passed to them.\"\n        self._invoke(self._after, context)\n        run.after_each.execute(context)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(send, msg, args):\n    parser = arguments.ArgParser(args['config'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--clear', action='store_true')\n    group.add_argument('--show', '--list', action='store_true')\n    group.add_argument('--delete', '--remove', action='store_true')\n    parser.add_argument('nick', nargs='?')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    session = args['db']\n    if cmdargs.clear:\n        session.query(Ignore).delete()\n        send(\"Ignore list cleared.\")\n    elif cmdargs.show:\n        ignored = session.query(Ignore).all()\n        if ignored:\n            send(\", \".join([x.nick for x in ignored]))\n        else:\n            send(\"Nobody is ignored.\")\n    elif cmdargs.delete:\n        if not cmdargs.nick:\n            send(\"Unignore who?\")\n        else:\n            row = session.query(Ignore).filter(Ignore.nick == cmdargs.nick).first()\n            if row is None:\n                send(\"%s is not ignored.\" % cmdargs.nick)\n            else:\n                session.delete(row)\n                send(\"%s is no longer ignored.\" % cmdargs.nick)\n    elif cmdargs.nick:\n        send(\"%s ignored %s\" % (args['nick'], cmdargs.nick), target=args['config']['core']['ctrlchan'])\n        send(misc.ignore(session, cmdargs.nick))\n    else:\n        send(\"Ignore who?\")", "response": "Handles ignoring and unignoring people\n    Syntax"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntans Trigonometric arc tan function.", "response": "def atan(x):\n    \"\"\" tan(x)\n    Trigonometric arc tan function.\n    \"\"\"\n    _math = infer_math(x)\n    if _math is math:\n        return _math.atan(x)\n    else:\n        return _math.arctan(x)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines two uncertainties according to an operator.", "response": "def combine_uncertainties(op, unc1, unc2, nom1=None, nom2=None, rho=0.):\n    \"\"\"\n    Combines two uncertainties *unc1* and *unc2* according to an operator *op* which must be either\n    ``\"+\"``, ``\"-\"``, ``\"*\"``, ``\"/\"``, or ``\"**\"``. The three latter operators require that you\n    also pass the nominal values *nom1* and *nom2*, respectively. The correlation can be configured\n    via *rho*.\n    \"\"\"\n    # operator valid?\n    if op in _op_map:\n        f = _op_map[op]\n    elif op in _op_map_reverse:\n        f = op\n        op = _op_map_reverse[op]\n    else:\n        raise ValueError(\"unknown operator: {}\".format(op))\n\n    # prepare values for combination, depends on operator\n    if op in (\"*\", \"/\", \"**\"):\n        if nom1 is None or nom2 is None:\n            raise ValueError(\"operator '{}' requires nominal values\".format(op))\n        # numpy-safe conversion to float\n        nom1 *= 1.\n        nom2 *= 1.\n        # convert uncertainties to relative values\n        unc1 /= nom1\n        unc2 /= nom2\n        # determine\n        nom = abs(f(nom1, nom2))\n    else:\n        nom = 1.\n\n    # combined formula\n    if op == \"**\":\n        return nom * abs(nom2) * (unc1**2. + (math.log(nom1) * unc2)**2. + 2 * rho *\n            math.log(nom1) * unc1 * unc2)**0.5\n    else:\n        # flip rho for sub and div\n        if op in (\"-\", \"/\"):\n            rho = -rho\n        return nom * (unc1**2. + unc2**2. + 2. * rho * unc1 * unc2)**0.5"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensure_number(num, *args, **kwargs):\n    return num if isinstance(num, Number) else Number(num, *args, **kwargs)", "response": "Ensures that num is an instance of Number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_list(obj, cast=True):\n    if isinstance(obj, list):\n        return list(obj)\n    if isinstance(obj, types.GeneratorType):\n        return list(obj)\n    if isinstance(obj, (tuple, set)) and cast:\n        return list(obj)\n    else:\n        return [obj]", "response": "Converts an object to a list and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_value(val):\n    val = ensure_nominal(val)\n\n    if not is_numpy(val):\n        # handle 0 separately\n        if val == 0:\n            return (0., 0)\n\n        mag = int(math.floor(math.log10(abs(val))))\n        sig = float(val) / (10.**mag)\n\n    else:\n        log = np.zeros(val.shape)\n        np.log10(np.abs(val), out=log, where=(val != 0))\n        mag = np.floor(log).astype(np.int)\n        sig = val.astype(np.float) / (10.**mag)\n\n    return (sig, mag)", "response": "Splits a value into its significand and decimal exponent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string version of a value val matching the significant digits as given in ref.", "response": "def match_precision(val, ref, *args, **kwargs):\n    \"\"\"\n    Returns a string version of a value *val* matching the significant digits as given in *ref*.\n    *val* might also be a numpy array. All remaining *args* and *kwargs* are forwarded to\n    ``Decimal.quantize``. Example:\n\n    .. code-block:: python\n\n        match_precision(1.234, \".1\") # -> \"1.2\"\n        match_precision(1.234, \"1.\") # -> \"1\"\n        match_precision(1.234, \".1\", decimal.ROUND_UP) # -> \"1.3\"\n\n        a = np.array([1.234, 5.678, -9.101])\n        match_precision(a, \".1\") # -> [\"1.2\", \"5.7\", \"-9.1\"]\n    \"\"\"\n    val = ensure_nominal(val)\n\n    if not is_numpy(val):\n        ret = _match_precision(val, ref, *args, **kwargs)\n\n    else:\n        # strategy: map into a flat list, create chararray with max itemsize, reshape\n        strings = [_match_precision(v, r, *args, **kwargs) for v, r in np.nditer([val, ref])]\n        ret = np.chararray(len(strings), itemsize=max(len(s) for s in strings))\n        ret[:] = strings\n        ret = ret.reshape(val.shape)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef round_uncertainty(unc, method=\"publication\"):\n    # validate the method\n    meth = method.lower()\n    if meth not in (\"pub\", \"publication\", \"pdg\", \"one\", \"onedigit\"):\n        raise ValueError(\"unknown rounding method: {}\".format(method))\n\n    # split the uncertainty\n    sig, mag = split_value(unc)\n\n    # infer the precision based on the method and get updated significand and magnitude\n    if not is_numpy(unc):\n        prec, sig, mag = _infer_precision(unc, sig, mag, meth)\n        replace_args = (\".\", \"\")\n    else:\n        prec = np.ones(unc.shape).astype(np.int)\n        for p, u, s, m in np.nditer([prec, unc, sig, mag], op_flags=[\"readwrite\"]):\n            p[...], s[...], m[...] = _infer_precision(u, s, m, meth)\n        replace_args = (b\".\", b\"\")\n\n    # determine the significant digits and the decimal magnitude that would reconstruct the value\n    digits = match_precision(sig, 10.**(1 - prec)).replace(*replace_args)\n    mag -= prec - 1\n\n    return (digits, mag)", "response": "Rounds an uncertainty following a specific method and returns a 2 - tuple containing the number of significant digits as a string and the decimal magnitude that is required to recover the uncertainty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nround a number val to a single symmetric uncertainty or asymmetric uncertainties and returns a 3 - tuple containing the central value and the decimal magnitude of the uncertainties.", "response": "def round_value(val, unc=None, unc_down=None, method=\"publication\"):\n    \"\"\"\n    Rounds a number *val* with a single symmetric uncertainty *unc* or asymmetric uncertainties\n    *unc* (interpreted as *up*) and *unc_down*, and calculates the orders of their magnitudes. They\n    both can be a float or a list of floats for simultaneous evaluation. When *val* is a\n    :py:class:`Number` instance, its combined uncertainty is used instead. Returns a 3-tuple\n    containing:\n\n    - The string representation of the central value.\n    - The string representations of the uncertainties in a list. For the symmetric case, this list\n      contains only one element.\n    - The decimal magnitude.\n\n    Examples:\n\n    .. code-block:: python\n\n        round_value(1.23, 0.456)        # -> (\"123\", [\"46\"], -2)\n        round_value(1.23, 0.456, 0.987) # -> (\"123\", [\"46\", \"99\"], -2)\n\n        round_value(1.23, [0.456, 0.312]) # -> (\"123\", [[\"456\", \"312\"]], -3)\n\n        vals = np.array([1.23, 4.56])\n        uncs = np.array([0.45678, 0.078])\n        round_value(vals, uncs) # -> ([\"1230\", \"4560\"], [[\"457\", \"78\"]], -3)\n    \"\"\"\n    if isinstance(val, Number):\n        unc, unc_down = val.get_uncertainty()\n        val = val.nominal\n    elif unc is None:\n        raise ValueError(\"unc must be set when val is not a Number instance\")\n\n    # prepare unc values\n    asym = unc_down is not None\n    unc_up = unc\n    if not asym:\n        unc_down = unc_up\n\n    if not is_numpy(val):\n        # treat as lists for simultaneous rounding when not numpy arrays\n        passed_list = isinstance(unc_up, (list, tuple)) or isinstance(unc_down, (list, tuple))\n        unc_up = make_list(unc_up)\n        unc_down = make_list(unc_down)\n\n        # sanity checks\n        if len(unc_up) != len(unc_down):\n            raise ValueError(\"uncertainties should have same length when passed as lists\")\n        elif any(unc < 0 for unc in unc_up):\n            raise ValueError(\"up uncertainties must be positive: {}\".format(unc_up))\n        elif any(unc < 0 for unc in unc_down):\n            raise ValueError(\"down uncertainties must be positive: {}\".format(unc_down))\n\n        # to determine the precision, use the uncertainty with the smallest magnitude\n        ref_mag = min(round_uncertainty(u, method=method)[1] for u in unc_up + unc_down)\n\n        # convert the uncertainty and central value to match the reference magnitude\n        scale = 1. / 10.**ref_mag\n        val_str = match_precision(scale * val, \"1\")\n        up_strs = [match_precision(scale * u, \"1\") for u in unc_up]\n        down_strs = [match_precision(scale * u, \"1\") for u in unc_down]\n\n        if passed_list:\n            return (val_str, [up_strs, down_strs] if asym else [up_strs], ref_mag)\n        else:\n            return (val_str, [up_strs[0], down_strs[0]] if asym else [up_strs[0]], ref_mag)\n\n    else:\n        # sanity checks\n        if (unc_up < 0).any():\n            raise ValueError(\"up uncertainties must be positive: {}\".format(unc_up))\n        elif (unc_down < 0).any():\n            raise ValueError(\"down uncertainties must be positive: {}\".format(unc_down))\n\n        # to determine the precision, use the uncertainty with the smallest magnitude\n        ref_mag_up = round_uncertainty(unc_up, method=method)[1]\n        ref_mag_down = round_uncertainty(unc_down, method=method)[1]\n        ref_mag = min(ref_mag_up.min(), ref_mag_down.min())\n\n        scale = 1. / 10.**ref_mag\n        val_str = match_precision(scale * val, \"1\")\n        up_str = match_precision(scale * unc_up, \"1\")\n        down_str = match_precision(scale * unc_down, \"1\")\n\n        return (val_str, [up_str, down_str] if asym else [up_str], ref_mag)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninferring the SI prefix of a value f and returns the string label and decimal magnitude in a 2 - tuple.", "response": "def infer_si_prefix(f):\n    \"\"\"\n    Infers the SI prefix of a value *f* and returns the string label and decimal magnitude in a\n    2-tuple. Example:\n\n    .. code-block:: python\n\n        infer_si_prefix(1)     # -> (\"\", 0)\n        infer_si_prefix(25)    # -> (\"\", 0)\n        infer_si_prefix(4320)  # -> (\"k\", 3)\n    \"\"\"\n    if f == 0:\n        return \"\", 0\n    else:\n        mag = 3 * int(math.log10(abs(float(f))) // 3)\n        return si_refixes[mag], mag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild and returns the property s fdel method for the member defined by name.", "response": "def _fset(self, name):\n        \"\"\"\n        Build and returns the property's *fdel* method for the member defined by *name*.\n        \"\"\"\n        def fset(inst, value):\n            # the setter uses the wrapped function as well\n            # to allow for value checks\n            value = self.fparse(inst, value)\n            setattr(inst, name, value)\n        return fset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the absolute up and down variaton for an uncertainty name.", "response": "def get_uncertainty(self, name=DEFAULT, direction=None, **kwargs):\n        \"\"\" get_uncertainty(name=DEFAULT, direction=None, default=None)\n        Returns the *absolute* up and down variaton in a 2-tuple for an uncertainty *name*. When\n        *direction* is set, the particular value is returned instead of a 2-tuple. In case no\n        uncertainty was found and *default* is given, that value is returned.\n        \"\"\"\n        if direction not in (None, self.UP, self.DOWN):\n            raise ValueError(\"unknown direction: {}\".format(direction))\n\n        unc = self.uncertainties.get(name, *kwargs.values())\n\n        if direction is None:\n            return unc\n        else:\n            return unc[0 if direction == self.UP else 1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the uncertainty value for an uncertainty name.", "response": "def set_uncertainty(self, name, value):\n        \"\"\"\n        Sets the uncertainty *value* for an uncertainty *name*. *value* should have one of the\n        formats as described in :py:meth:`uncertainties`.\n        \"\"\"\n        uncertainties = self.__class__.uncertainties.fparse(self, {name: value})\n        self._uncertainties.update(uncertainties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef str(self, format=None, unit=None, scientific=False, si=False, labels=True, style=\"plain\",\n            styles=None, force_asymmetric=False, **kwargs):\n        r\"\"\"\n        Returns a readable string representiation of the number. *format* is used to format\n        non-NumPy nominal and uncertainty values. It can be a string such as ``\"%d\"``, a function\n        that is called with the value to format, or a rounding method as accepted by\n        :py:meth:`round_value`. When *None* (the default), :py:attr:`default_format` is used. All\n        keyword arguments except wildcard *kwargs* are only used to format non-NumPy values. In case\n        of NumPy objects, *kwargs* are passed to `numpy.array2string\n        <https://docs.scipy.org/doc/numpy/reference/generated/numpy.array2string.html>`_.\n\n        When *unit* is set, it is appended to the end of the string. When *scientific* is *True*,\n        all values are represented by their scientific notation. When *scientific* is *False* and\n        *si* is *True*, the appropriate SI prefix is used. *labels* controls whether uncertainty\n        labels are shown in the string. When *True*, uncertainty names are used, but it can also\n        be a list of labels whose order should match the uncertainty dict traversal order. *style*\n        can be ``\"plain\"``, ``\"latex\"``, or ``\"root\"``. *styles* can be a dict with fields\n        ``\"space\"``, ``\"label\"``, ``\"unit\"``, ``\"sym\"``, ``\"asym\"``, ``\"sci\"`` to customize every\n        aspect of the format style on top of :py:attr:`style_dict`. Unless *force_asymmetric* is\n        *True*, an uncertainty is quoted symmetric if it yields identical values in both directions.\n\n        Examples:\n\n        .. code-block:: python\n\n            n = Number(17.321, {\"a\": 1.158, \"b\": 0.453})\n            n.str()               # -> '17.321 +- 1.158 (a) +- 0.453 (b)'\n            n.str(\"%.1f\")         # -> '17.3 +- 1.2 (a) +- 0.5 (b)'\n            n.str(\"publication\")  # -> '17.32 +- 1.16 (a) +- 0.45 (b)'\n            n.str(\"pdg\")          # -> '17.3 +- 1.2 (a) +- 0.5 (b)'\n\n            n = Number(8848, 10)\n            n.str(unit=\"m\")                           # -> \"8848.0 +- 10.0 m\"\n            n.str(unit=\"m\", force_asymmetric=True)    # -> \"8848.0 +10.0-10.0 m\"\n            n.str(unit=\"m\", scientific=True)          # -> \"8.848 +- 0.01 x 1E3 m\"\n            n.str(\"%.2f\", unit=\"m\", scientific=True)  # -> \"8.85 +- 0.01 x 1E3 m\"\n            n.str(unit=\"m\", si=True)                  # -> \"8.848 +- 0.01 km\"\n            n.str(\"%.2f\", unit=\"m\", si=True)          # -> \"8.85 +- 0.01 km\"\n            n.str(unit=\"m\", style=\"latex\")            # -> \"8848.0 \\pm 10.0\\,m\"\n            n.str(unit=\"m\", style=\"latex\", si=True)   # -> \"8.848 \\pm 0.01\\,km\"\n            n.str(unit=\"m\", style=\"root\")             # -> \"8848.0 #pm 10.0 m\"\n            n.str(unit=\"m\", style=\"root\", si=True)    # -> \"8.848 #pm 0.01 km\"\n        \"\"\"\n        if format is None:\n            format = self.default_format or self.__class__.default_format\n\n        if not self.is_numpy:\n            # check style\n            style = style.lower()\n            if style not in style_dict.keys():\n                raise ValueError(\"unknown style '{}'\".format(style))\n            d = style_dict[style]\n\n            # extend by custom styles\n            if styles:\n                d.update(styles)\n\n            # scientific or SI notation?\n            prefix = \"\"\n            transform = lambda x: x\n            if scientific or si:\n                if scientific:\n                    mag = 0 if self.nominal == 0 else int(math.floor(math.log10(abs(self.nominal))))\n                else:\n                    prefix, mag = infer_si_prefix(self.nominal)\n                transform = lambda x: x * 10.**(-mag)\n\n            # gather and transform values\n            nominal = transform(self.nominal)\n            names, ups, downs = [], [], []\n            for name, (up, down) in self.uncertainties.items():\n                names.append(name)\n                ups.append(transform(up))\n                downs.append(transform(down))\n\n            # special formats implemented by round_value\n            if format in (\"pub\", \"publication\", \"pdg\", \"one\", \"onedigit\"):\n                nominal, (ups, downs), _mag = round_value(self.nominal, ups, downs, method=format)\n                fmt = lambda x: match_precision(float(x) * 10.**_mag, 10.**_mag)\n\n            # string formatting\n            elif not callable(format):\n                fmt = lambda x: format % x\n\n            # helper to build the ending consisting of scientific notation or SI prefix, and unit\n            def ending():\n                e = \"\"\n                if scientific and mag:\n                    e += d[\"space\"] + d[\"sci\"].format(mag=mag)\n                _unit = (prefix or \"\") + (unit or \"\")\n                if _unit:\n                    e += d[\"unit\"].format(unit=_unit)\n                return e\n\n            # start building the text\n            text = fmt(nominal, **kwargs)\n\n            # no uncertainties\n            if len(names) == 0:\n                text += ending()\n                if style == \"plain\" and labels:\n                    text += d[\"space\"] + d[\"label\"].format(label=\"no uncertainties\")\n\n            # one ore more uncertainties\n            else:\n                # special case: only the default uncertainty\n                if len(names) == 1 and names[0] == self.DEFAULT:\n                    labels = False\n\n                for i, (name, up, down) in enumerate(zip(names, ups, downs)):\n                    up = str(fmt(up))\n                    down = str(fmt(down))\n\n                    if up == down and not force_asymmetric:\n                        text += d[\"space\"] + d[\"sym\"].format(unc=up)\n                    else:\n                        text += d[\"space\"] + d[\"asym\"].format(up=up, down=down)\n\n                    if labels:\n                        label = labels[i] if isinstance(labels, (list, tuple)) else name\n                        text += d[\"space\"] + d[\"label\"].format(label=label)\n\n                text += ending()\n\n            return text\n\n        else:\n            # we are dealing with a numpy array here\n            # start with nominal text\n            text = np.array2string(self.nominal, **kwargs)\n\n            # uncertainty text\n            uncs = self.uncertainties\n            if len(uncs) == 0:\n                text += \" (no uncertainties)\"\n            elif len(uncs) == 1 and list(uncs.keys())[0] == self.DEFAULT:\n                up, down = self.get_uncertainty()\n                text += \"\\n+ {}\".format(np.array2string(up, **kwargs))\n                text += \"\\n- {}\".format(np.array2string(down, **kwargs))\n            else:\n                for name, (up, down) in uncs.items():\n                    text += \"\\n+ {} {}\".format(name, np.array2string(up, **kwargs))\n                    text += \"\\n- {} {}\".format(name, np.array2string(down, **kwargs))\n\n            return text", "response": "r Returns a readable string representation of the number."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the string representation of the object.", "response": "def repr(self, *args, **kwargs):\n        \"\"\"\n        Returns the unique string representation of the number.\n        \"\"\"\n        if not self.is_numpy:\n            text = \"'\" + self.str(*args, **kwargs) + \"'\"\n        else:\n            text = \"{} numpy array, {} uncertainties\".format(self.shape, len(self.uncertainties))\n\n        return \"<{} at {}, {}>\".format(self.__class__.__name__, hex(id(self)), text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a deep copy of the number instance.", "response": "def copy(self, nominal=None, uncertainties=None):\n        \"\"\"\n        Returns a deep copy of the number instance. When *nominal* or *uncertainties* are set, they\n        overwrite the fields of the copied instance.\n        \"\"\"\n        if nominal is None:\n            nominal = self.nominal\n        if uncertainties is None:\n            uncertainties = self.uncertainties\n        return self.__class__(nominal, uncertainties=uncertainties)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, direction=NOMINAL, names=ALL, diff=False, factor=False):\n        if direction == self.NOMINAL:\n            value = self.nominal\n\n        elif direction in (self.UP, self.DOWN):\n            # find uncertainties to take into account\n            if names == self.ALL:\n                names = self.uncertainties.keys()\n            else:\n                names = make_list(names)\n                if any(name not in self.uncertainties for name in names):\n                    unknown = list(set(names) - set(self.uncertainties.keys()))\n                    raise ValueError(\"unknown uncertainty name(s): {}\".format(unknown))\n\n            # calculate the combined uncertainty without correlation\n            idx = int(direction == self.DOWN)\n            uncs = [self.uncertainties[name][idx] for name in names]\n            unc = sum(u**2. for u in uncs)**0.5\n\n            # determine the output value\n            if diff:\n                value = unc\n            elif direction == self.UP:\n                value = self.nominal + unc\n            else:\n                value = self.nominal - unc\n\n        else:\n            raise ValueError(\"unknown direction: {}\".format(direction))\n\n        return value if not factor else value / self.nominal", "response": "get returns the nominal value of the contained uncertainties in the specified direction"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, *args, **kwargs):\n        return self._apply(operator.add, *args, **kwargs)", "response": "Adds an instance of another number instance to the current number set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sub(self, *args, **kwargs):\n        return self._apply(operator.sub, *args, **kwargs)", "response": "Subtracts an instance from the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmultiplying by other number instance.", "response": "def mul(self, *args, **kwargs):\n        \"\"\" mul(other, rho=0, inplace=True)\n        Multiplies by an *other* number instance. The correlation coefficient *rho* can be\n        configured per uncertainty when passed as a dict. When *inplace* is *False*, a new instance\n        is returned.\n        \"\"\"\n        return self._apply(operator.mul, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef div(self, *args, **kwargs):\n        return self._apply(operator.truediv, *args, **kwargs)", "response": "Divides by other number instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pow(self, *args, **kwargs):\n        return self._apply(operator.pow, *args, **kwargs)", "response": "Returns a new instance of\n        with the power of the other number instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a new math function with name and returns an Operation instance.", "response": "def register(cls, function=None, name=None):\n        \"\"\"\n        Registers a new math function *function* with *name* and returns an :py:class:`Operation`\n        instance. A math function expects a :py:class:`Number` as its first argument, followed by\n        optional (keyword) arguments. When *name* is *None*, the name of the *function* is used. The\n        returned object can be used to set the derivative (similar to *property*). Example:\n\n        .. code-block:: python\n\n            @ops.register\n            def my_op(x):\n                return x * 2 + 1\n\n            @my_op.derive\n            def my_op(x):\n                return 2\n\n            num = Number(5, 2)\n            print(num) # -> 5.00 (+2.00, -2.00)\n\n            num = ops.my_op(num)\n            print(num) # -> 11.00 (+4.00, -4.00)\n\n        Please note that there is no need to register *simple* functions as in the particular\n        example above as most of them are just composite operations whose derivatives are already\n        known.\n        \"\"\"\n        def register(function):\n            op = Operation(function, name=name)\n\n            @functools.wraps(function)\n            def wrapper(num, *args, **kwargs):\n                if op.derivative is None:\n                    raise Exception(\"cannot run operation '{}', no derivative registered\".format(\n                        op.name))\n\n                # ensure we deal with a number instance\n                num = ensure_number(num)\n\n                # apply to the nominal value\n                nominal = op.function(num.nominal, *args, **kwargs)\n\n                # apply to all uncertainties via\n                # unc_f = derivative_f(x) * unc_x\n                x = abs(op.derivative(num.nominal, *args, **kwargs))\n                uncertainties = {}\n                for name in num.uncertainties.keys():\n                    up, down = num.get_uncertainty(name)\n                    uncertainties[name] = (x * up, x * down)\n\n                # create and return the new number\n                return num.__class__(nominal, uncertainties)\n\n            # actual registration\n            cls._instances[op.name] = op\n            setattr(cls, op.name, staticmethod(wrapper))\n\n            return op\n\n        if function is None:\n            return register\n        else:\n            return register(function)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef byte_order_option(default=BYTEORDER):\n\n    def decorator(method):\n        @wraps(method)\n        def wrapper(*args, **kwargs):\n            option = Option.byte_order.value\n            kwargs[option] = kwargs.get(option, default)\n            return method(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Decorator to specify a byte_order option."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattaches the option ``nested`` with its *default* value to the keyword arguments when the option does not exist. All positional arguments and keyword arguments are forwarded unchanged.", "response": "def nested_option(default=False):\n    \"\"\" Attaches the option ``nested`` with its *default* value to the\n    keyword arguments when the option does not exist. All positional\n    arguments and keyword arguments are forwarded unchanged.\n    \"\"\"\n\n    def decorator(method):\n        @wraps(method)\n        def wrapper(*args, **kwargs):\n            option = Option.nested.value\n            kwargs[option] = kwargs.get(option, bool(default))\n            return method(*args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verbose_option(default=False):\n\n    def decorator(method):\n        @wraps(method)\n        def wrapper(*args, **kwargs):\n            option = Option.verbose.value\n            kwargs[option] = kwargs.get(option, bool(default))\n            return method(*args, **kwargs)\n\n        return wrapper\n\n    return decorator", "response": "Decorator to specify a verbose option."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef boolean(input):\n    \n    try:\n        input = input.strip().lower()\n    except AttributeError:\n        return bool(input)\n    \n    if input in ('yes', 'y', 'on', 'true', 't', '1'):\n        return True\n    \n    if input in ('no', 'n', 'off', 'false', 'f', '0'):\n        return False\n    \n    raise ValueError(\"Unable to convert {0!r} to a boolean value.\".format(input))", "response": "Convert the given input to a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array(input, separator=',', strip=True, empty=False):\n    \n    if input is None:\n        return []\n    \n    if isinstance(input, list):\n        if not empty:\n            return [i for i in input if i]\n        \n        return input\n    \n    if not isinstance(input, (binary, unicode)):\n        if not empty:\n            return [i for i in list(input) if i]\n        \n        return list(input)\n    \n    if not strip:\n        if not empty:\n            return [i for i in input.split(separator) if i]\n        \n        return input.split(separator)\n    \n    if not empty:\n        return [i for i in [i.strip() for i in input.split(separator)] if i]\n    \n    return [i.strip() for i in input.split(separator)]", "response": "Convert the given input to a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef number(input):\n    \n    try:\n        return int(input)\n    except (TypeError, ValueError):\n        pass\n    \n    try:\n        return float(input)\n    except (TypeError, ValueError):\n        raise ValueError(\"Unable to convert {0!r} to a number.\".format(input))", "response": "Convert the given input to a number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting states holding a non - special election on election day.", "response": "def get_states(self, obj):\n        \"\"\"States holding a non-special election on election day.\"\"\"\n        return reverse(\n            'electionnight_api_state-election-list',\n            request=self.context['request'],\n            kwargs={'date': obj.date}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bodies(self, obj):\n        return reverse(\n            'electionnight_api_body-election-list',\n            request=self.context['request'],\n            kwargs={'date': obj.date}\n        )", "response": "Bodies with offices up for election on election day."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_executive_offices(self, obj):\n        return reverse(\n            'electionnight_api_office-election-list',\n            request=self.context['request'],\n            kwargs={'date': obj.date}\n        )", "response": "Returns the executive offices up for election on election day."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_special_elections(self, obj):\n        return reverse(\n            'electionnight_api_special-election-list',\n            request=self.context['request'],\n            kwargs={'date': obj.date}\n        )", "response": "States holding a special election on election day."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(arg=None):\n    res = ''\n\n    t_arg = type(arg)\n    if t_arg in (list, tuple):\n        for i in arg:\n            res += normalize(i)\n    elif t_arg is dict:\n        keys = arg.keys()\n        keys.sort()\n        for key in keys:\n            res += '%s%s' % (normalize(key), normalize(arg[key]))\n    elif t_arg is unicode:\n        res = arg.encode('utf8')\n    elif t_arg is bool:\n        res = 'true' if arg else 'false'\n    elif arg != None:\n        res = str(arg)\n\n    return res", "response": "Normalizes an argument for signing purpose."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsign a message using a shared secret.", "response": "def sign(shared_secret, msg):\n    \"\"\"Signs a message using a shared secret.\n\n    :param shared_secret: The shared secret used to sign the message\n    :param msg: The message to sign\n\n    :return: The signature as a string\n\n    .. doctest::\n\n     >>> from cloud.rpc import sign\n     >>> sign('sEcReT_KeY', 'hello world')\n     '5f048ebaf6f06576b60716dc8f815d85'\n    \"\"\"\n    if isinstance(msg, unicode):\n        msg = msg.encode('utf8')\n    return hashlib.md5(msg + shared_secret).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_parser_to_dict(config_parser):\n    response = {}\n\n    for section in config_parser.sections():\n        for option in config_parser.options(section):\n            response.setdefault(section, {})[option] = config_parser.get(section, option)\n\n    return response", "response": "Convert a ConfigParser to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a config file.", "response": "def load_config_file(config_file_path, config_file):\n    \"\"\"\n    Loads a config file, whether it is a yaml file or a .INI file.\n\n    :param config_file_path: Path of the configuration file, used to infer the file format.\n    :returns: Dictionary representation of the configuration file.\n    \"\"\"\n\n    if config_file_path.lower().endswith(\".yaml\"):\n        return yaml.load(config_file)\n\n    if any(config_file_path.lower().endswith(extension) for extension in INI_FILE_EXTENSIONS):\n        return load_config_from_ini_file(config_file)\n\n    # At this point we have to guess the format of the configuration file.\n    try:\n        return yaml.load(config_file)\n    except yaml.YAMLError:\n        pass\n\n    try:\n        return load_config_from_ini_file(config_file)\n    except:\n        pass\n\n    raise Exception(\"Could not load configuration file!\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(dict_, keys=(), default=None):\n    ensure_mapping(dict_)\n    ensure_iterable(keys)\n\n    for key in keys:\n        try:\n            return dict_[key]\n        except KeyError:\n            pass\n\n    return default", "response": "Returns the first value in dict_ or default if no key is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select(keys, from_, strict=False):\n    ensure_iterable(keys)\n    ensure_mapping(from_)\n\n    if strict:\n        return from_.__class__((k, from_[k]) for k in keys)\n    else:\n        existing_keys = set(keys) & set(iterkeys(from_))\n        return from_.__class__((k, from_[k]) for k in existing_keys)", "response": "Selects a subset of given dictionary including only the specified keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef omit(keys, from_, strict=False):\n    ensure_iterable(keys)\n    ensure_mapping(from_)\n\n    if strict:\n        remaining_keys = set(iterkeys(from_))\n        remove_subset(remaining_keys, keys)  # raises KeyError if necessary\n    else:\n        remaining_keys = set(iterkeys(from_)) - set(keys)\n\n    return from_.__class__((k, from_[k]) for k in remaining_keys)", "response": "Returns a subset of given dictionary by omitting specified keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new dictionary comprising of items for which predicate returns True.", "response": "def filteritems(predicate, dict_):\n    \"\"\"Return a new dictionary comprising of items\n    for which ``predicate`` returns True.\n\n    :param predicate: Predicate taking a key-value pair, or None\n\n    .. versionchanged: 0.0.2\n       ``predicate`` is now taking a key-value pair as a single argument.\n    \"\"\"\n    predicate = all if predicate is None else ensure_callable(predicate)\n    ensure_mapping(dict_)\n    return dict_.__class__(ifilter(predicate, iteritems(dict_)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef starfilteritems(predicate, dict_):\n    ensure_mapping(dict_)\n\n    if predicate is None:\n        predicate = lambda k, v: all((k, v))\n    else:\n        ensure_callable(predicate)\n\n    return dict_.__class__((k, v) for k, v in iteritems(dict_)\n                           if predicate(k, v))", "response": "Return a new dictionary comprising of keys and values for which predicate returns True."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new dictionary comprising of keys for which predicate returns True and their corresponding values.", "response": "def filterkeys(predicate, dict_):\n    \"\"\"Return a new dictionary comprising of keys\n    for which ``predicate`` returns True, and their corresponding values.\n\n    :param predicate: Predicate taking a dictionary key, or None\n    \"\"\"\n    predicate = bool if predicate is None else ensure_callable(predicate)\n    ensure_mapping(dict_)\n    return dict_.__class__((k, v) for k, v in iteritems(dict_) if predicate(k))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new dictionary where the keys and values come from applying function to key - value pairs from given dictionary.", "response": "def mapitems(function, dict_):\n    \"\"\"Return a new dictionary where the keys and values come from applying\n    ``function`` to key-value pairs from given dictionary.\n\n    .. warning::\n\n        If ``function`` returns a key-value pair with the same key\n        more than once, it is undefined which value will be chosen\n        for that key in the resulting dictionary.\n\n    :param function: Function taking a key-value pair as a single argument,\n                     and returning a new key-value pair; or None\n                     (corresponding to identity function)\n\n    .. versionadded:: 0.0.2\n    \"\"\"\n    ensure_mapping(dict_)\n    function = identity() if function is None else ensure_callable(function)\n    return dict_.__class__(imap(function, iteritems(dict_)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new dictionary where the keys and values come from applying function to the keys and values of given dictionary.", "response": "def starmapitems(function, dict_):\n    \"\"\"Return a new dictionary where the keys and values come from applying\n    ``function`` to the keys and values of given dictionary.\n\n    .. warning::\n\n        If ``function`` returns a key-value pair with the same key\n        more than once, it is undefined which value will be chosen\n        for that key in the resulting dictionary.\n\n    :param function: Function taking key and value as two arguments\n                     and returning a new key-value pair, or None\n                     (corresponding to identity function)\n\n    .. versionadded:: 0.0.2\n    \"\"\"\n    ensure_mapping(dict_)\n\n    if function is None:\n        function = lambda k, v: (k, v)\n    else:\n        ensure_callable(function)\n\n    return dict_.__class__(starmap(function, iteritems(dict_)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new dictionary where the keys come from applying function to the keys of given dictionary.", "response": "def mapkeys(function, dict_):\n    \"\"\"Return a new dictionary where the keys come from applying ``function``\n    to the keys of given dictionary.\n\n    .. warning::\n\n        If ``function`` returns the same value for more than one key,\n        it is undefined which key will be chosen for the resulting dictionary.\n\n    :param function: Function taking a dictionary key,\n                     or None (corresponding to identity function)\n\n    .. versionadded:: 0.0.2\n    \"\"\"\n    ensure_mapping(dict_)\n    function = identity() if function is None else ensure_callable(function)\n    return dict_.__class__((function(k), v) for k, v in iteritems(dict_))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(*dicts, **kwargs):\n    ensure_argcount(dicts, min_=1)\n    dicts = list(imap(ensure_mapping, dicts))\n\n    ensure_keyword_args(kwargs, optional=('deep', 'overwrite'))\n\n    return _nary_dict_update(dicts, copy=True,\n                             deep=kwargs.get('deep', False),\n                             overwrite=kwargs.get('overwrite', True))", "response": "Merges two or more dictionaries into a single dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextend a dictionary with keys and values from other dictionaries.", "response": "def extend(dict_, *dicts, **kwargs):\n    \"\"\"Extend a dictionary with keys and values from other dictionaries.\n\n    :param dict_: Dictionary to extend\n\n    Optional keyword arguments allow to control the exact way\n    in which ``dict_`` will be extended.\n\n    :param overwrite:\n\n        Whether repeated keys should have their values overwritten,\n        retaining the last value, as per given order of dictionaries.\n        This is the default behavior (equivalent to ``overwrite=True``).\n        If ``overwrite=False``, repeated keys are simply ignored.\n\n        Example::\n\n            >> foo = {'a': 1}\n            >> extend(foo, {'a': 10, 'b': 2}, overwrite=True)\n            {'a': 10, 'b': 2}\n            >> foo = {'a': 1}\n            >> extend(foo, {'a': 10, 'b': 2}, overwrite=False)\n            {'a': 1, 'b': 2}\n\n    :param deep:\n\n        Whether extending should proceed recursively, and cause\n        corresponding subdictionaries to be merged into each other.\n        By default, this does not happen (equivalent to ``deep=False``).\n\n        Example::\n\n            >> foo = {'a': {'b': 1}}\n            >> extend(foo, {'a': {'c': 2}}, deep=False)\n            {'a': {'c': 2}}\n            >> foo = {'a': {'b': 1}}\n            >> extend(foo, {'a': {'c': 2}}, deep=True)\n            {'a': {'b': 1, 'c': 2}}\n\n    :return: Extended ``dict_``\n\n    .. versionadded:: 0.0.2\n    \"\"\"\n    ensure_mapping(dict_)\n    dicts = list(imap(ensure_mapping, dicts))\n\n    ensure_keyword_args(kwargs, optional=('deep', 'overwrite'))\n\n    return _nary_dict_update([dict_] + dicts, copy=False,\n                             deep=kwargs.get('deep', False),\n                             overwrite=kwargs.get('overwrite', True))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _recursive_dict_update(dict_, other, **kwargs):\n    overwrite = kwargs['overwrite']\n\n    for key, other_value in iteritems(other):\n        if key in dict_:\n            value = dict_[key]\n            if is_mapping(value) and is_mapping(other_value):\n                _recursive_dict_update(value, other_value, overwrite=overwrite)\n                continue\n        if overwrite:\n            dict_[key] = other_value\n        else:\n            dict_.setdefault(key, other_value)", "response": "Deep version of dict. update."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invert(dict_):\n    ensure_mapping(dict_)\n    return dict_.__class__(izip(itervalues(dict_), iterkeys(dict_)))", "response": "Return an inverted dictionary where former values are keys\n    and former keys are values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a path between two wikipedia articles.", "response": "def cmd(send, msg, args):\n    \"\"\"Find a path between two wikipedia articles.\n\n    Syntax: {command} [article] [article]\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('first', nargs='?')\n    parser.add_argument('second', nargs='?')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if not cmdargs.first:\n        cmdargs.first = get_article()\n    else:\n        if not check_article(cmdargs.first):\n            send(\"%s isn't a valid wikipedia article, fetching a random one...\" % cmdargs.first)\n            cmdargs.first = get_article()\n    if not cmdargs.second:\n        cmdargs.second = get_article()\n    else:\n        if not check_article(cmdargs.second):\n            send(\"%s isn't a valid wikipedia article, fetching a random one...\" % cmdargs.second)\n            cmdargs.second = get_article()\n\n    path = gen_path(cmdargs)\n    if path:\n        send(path.replace('_', ' '))\n    else:\n        send(\"No path found between %s and %s. Do you need to add more links?\" % (cmdargs.first.replace('_', ' '), cmdargs.second.replace('_', ' ')))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a subset from given set.", "response": "def remove_subset(set_, subset):\n    \"\"\"Remove a subset from given set.\n\n    This is essentially an extension of :func:`set.remove`\n    to work with more than one set element.\n\n    :raise KeyError: If some element from ``subset`` is not present in ``set_``\n\n    .. versionadded:: 0.0.2\n    \"\"\"\n    ensure_set(set_)\n    ensure_iterable(subset)\n\n    for elem in subset:\n        set_.remove(elem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all k - subsets of given set.", "response": "def k_subsets(set_, k):\n    \"\"\"Return subsets of given set with given cardinality.\n    :param k: Cardinality of subsets to return\n    :return: Iterable containing all ``k``-subsets of given set\n    \"\"\"\n    ensure_countable(set_)\n\n    if not isinstance(k, Integral):\n        raise TypeError(\"subset cardinality must be a number\")\n    if not (k >= 0):\n        raise ValueError(\"subset cardinality must be positive\")\n    if not (k <= len(set_)):\n        raise ValueError(\"subset cardinality must not exceed set cardinality\")\n\n    result = combinations(set_, k)\n    return _harmonize_subset_types(set_, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all subsets of given set i. e. iterable containing all its subsets and sorted by ascending cardinality.", "response": "def power(set_):\n    \"\"\"Returns all subsets of given set.\n\n    :return: Powerset of given set, i.e. iterable containing all its subsets,\n             sorted by ascending cardinality.\n    \"\"\"\n    ensure_countable(set_)\n\n    result = chain.from_iterable(combinations(set_, r)\n                                 for r in xrange(len(set_) + 1))\n    return _harmonize_subset_types(set_, result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a parition of given set into 1 - element subsets.", "response": "def trivial_partition(set_):\n    \"\"\"Returns a parition of given set into 1-element subsets.\n\n    :return: Trivial partition of given set, i.e. iterable containing disjoint\n             1-element sets, each consisting of a single element\n             from given set\n    \"\"\"\n    ensure_countable(set_)\n\n    result = ((x,) for x in set_)\n    return _harmonize_subset_types(set_, result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert morse to ascii.", "response": "def cmd(send, msg, _):\n    \"\"\"Converts morse to ascii.\n\n    Syntax: {command} <text>\n\n    \"\"\"\n    demorse_codes = {\n        '.----': '1',\n        '-.--': 'y',\n        '..-': 'u',\n        '...': 's',\n        '-.-.': 'c',\n        '.-.-.': '+',\n        '--..--': ',',\n        '-.-': 'k',\n        '.--.': 'p',\n        '----.': '9',\n        '-----': '0',\n        '  ': ' ',\n        '...--': '3',\n        '-....-': '-',\n        '...-..-': '$',\n        '..---': '2',\n        '.--.-.': '@',\n        '-...-': '=',\n        '-....': '6',\n        '...-': 'v',\n        '.----.': \"'\",\n        '....': 'h',\n        '.....': '5',\n        '....-': '4',\n        '.': 'e',\n        '.-.-.-': '.',\n        '-': 't',\n        '.-..': 'l',\n        '..': 'i',\n        '.-': 'a',\n        '-..-': 'x',\n        '-...': 'b',\n        '-.': 'n',\n        '.-..-.': '\"',\n        '.--': 'w',\n        '-.--.-': ')',\n        '--...': '7',\n        '.-.': 'r',\n        '.---': 'j',\n        '---..': '8',\n        '--': 'm',\n        '-.-.-.': ';',\n        '-.-.--': '!',\n        '-..': 'd',\n        '-.--.': '(',\n        '..-.': 'f',\n        '---...': ':',\n        '-..-.': '/',\n        '..--.-': '_',\n        '.-...': '&',\n        '..--..': '?',\n        '--.': 'g',\n        '--..': 'z',\n        '--.-': 'q',\n        '---': 'o'\n    }\n    demorse = \"\"\n    if not msg:\n        send(\"demorse what?\")\n        return\n    for word in msg.lower().split(\"   \"):\n        for c in word.split():\n            if c in demorse_codes:\n                demorse += demorse_codes[c]\n            else:\n                demorse += \"?\"\n        demorse += \" \"\n    send(demorse)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a reason for something.", "response": "def cmd(send, *_):\n    \"\"\"Gives a reason for something.\n\n    Syntax: {command}\n\n    \"\"\"\n    a = [\"primary\", \"secondary\", \"tertiary\", \"hydraulic\", \"compressed\", \"required\", \"pseudo\", \"intangible\", \"flux\"]\n    b = [\n        \"compressor\", \"engine\", \"lift\", \"elevator\", \"irc bot\", \"stabilizer\", \"computer\", \"fwilson\", \"csl\", \"4506\", \"router\", \"switch\", \"thingy\",\n        \"capacitor\"\n    ]\n    c = [\n        \"broke\", \"exploded\", \"corrupted\", \"melted\", \"froze\", \"died\", \"reset\", \"was seen by the godofskies\", \"burned\", \"corroded\", \"reversed polarity\",\n        \"was accidentallied\", \"nuked\"\n    ]\n    send(\"because %s %s %s\" % ((choice(a), choice(b), choice(c))))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cast(type_, value, default=ABSENT):\n    # ``type_`` not being a type would theoretically be grounds for TypeError,\n    # but since that kind of exception is a valid and expected outcome here\n    # in some cases, we use the closest Python has to compilation error instead\n    assert isinstance(type_, type)\n\n    # conunterintuitively, invalid conversions to numeric types\n    # would raise ValueError rather than the more appropriate TypeError,\n    # so we correct this inconsistency\n    to_number = issubclass(type_, Number)\n    exception = ValueError if to_number else TypeError\n\n    try:\n        return type_(value)\n    except exception as e:\n        if default is ABSENT:\n            if to_number:\n                # since Python 3 chains exceptions, we can supply slightly\n                # more relevant error message while still retaining\n                # the original information of ValueError as the cause\n                msg = (\"cannot convert %r to %r\" % (value, type_) if IS_PY3\n                       else str(e))\n                raise TypeError(msg)\n            else:\n                raise\n        return type_(default)", "response": "Cast a value into a given type optionally returning a default if provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensure_boolean(arg):\n    if not isinstance(arg, bool):\n        raise TypeError(\"expected a boolean, got %s\" % type(arg).__name__)\n    return arg", "response": "Checks whether given argument is a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_identifier(s):\n    ensure_string(s)\n\n    if not IDENTIFIER_FORM_RE.match(s):\n        return False\n    if is_keyword(s):\n        return False\n\n    # ``None`` is not part of ``keyword.kwlist`` in Python 2.x,\n    # so we need to check for it explicitly\n    if s == 'None' and not IS_PY3:\n        return False\n\n    return True", "response": "Checks whether given string is a valid Python identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether given string is a __magic__ Python identifier.", "response": "def is_magic(s):\n    \"\"\"Check whether given string is a __magic__ Python identifier.\n    :return: Whether ``s`` is a __magic__ Python identifier\n    \"\"\"\n    if not is_identifier(s):\n        return False\n    return len(s) > 4 and s.startswith('__') and s.endswith('__')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_model(modelfunc, fname='', listw=[], outfname='',\n                 limit=int(3e6), min_pwlen=6, topk=10000, sep=r'\\s+'):\n    \"\"\":modelfunc: is a function that takes a word and returns its\n    splits.  for ngram model this function returns all the ngrams of a\n    word, for PCFG it will return splits of the password.\n    @modelfunc: func: string -> [list of strings]\n    @fname: name of the file to read from\n    @listw: list of passwords. Used passwords from both the files and\n            listw if provided.\n    @outfname: the file to write down the model.\n    \"\"\"\n\n    def length_filter(pw):\n        pw = ''.join(c for c in pw if c in VALID_CHARS)\n        return len(pw) >= min_pwlen\n\n    pws = []\n    if fname:\n        pws = helper.open_get_line(fname, limit=limit, pw_filter=length_filter, sep=sep)\n\n    big_dict = defaultdict(int)\n    total_f, total_e = 0, 0\n    # Add topk passwords from the input dataset to the list\n    topk_pws = []\n    for pw, c in itertools.chain(pws, listw):\n        for ng in modelfunc(pw):\n            big_dict[ng] += c\n        total_f += c\n        total_e += 1\n        if len(big_dict) % 100000 == 0:\n            print((\"Dictionary size: {} (Total_freq: {}; Total_pws: {}\"\\\n                   .format(len(big_dict), total_f, total_e)))\n        if len(topk_pws) >= topk:\n            heapq.heappushpop(topk_pws, (c, pw))\n        else:\n            heapq.heappush(topk_pws, (c, pw))\n    # Adding topk password to deal with probability reduction of popular\n    # passwords. Mostly effective for n-gram models\n    print(\"topk={}\".format(topk))\n    if topk > 0:\n        for c, pw in topk_pws:\n            tpw = helper.START + pw + helper.END\n            big_dict[tpw] += c\n            total_f += c\n            total_e += 1\n\n    big_dict[NPWS_W] = total_e\n    big_dict[TOTALF_W] = total_f\n\n    nDawg = dawg.IntCompletionDAWG(big_dict)\n    if not outfname:\n        outfname = 'tmpmodel.dawg.gz'\n    elif not outfname.endswith('.gz'):\n        outfname += '.gz'\n    pathlib.Path(outfname).parent.mkdir(parents=True, exist_ok=True)\n    helper.save_dawg(nDawg, outfname)\n    return nDawg", "response": "creates a model from a list of words."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlowering case and change the symbols to closest characters", "response": "def normalize(pw):\n    \"\"\" Lower case, and change the symbols to closest characters\"\"\"\n    pw_lower = pw.lower()\n    return ''.join(helper.L33T.get(c, c) for c in pw_lower)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the qth most probable element in the dawg.", "response": "def qth_pw(self, q):\n        \"\"\"\n        returns the qth most probable element in the dawg.\n        \"\"\"\n        return heapq.nlargest(q + 2, self._T.iteritems(),\n                              key=operator.itemgetter(1))[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the probability of a token and a non - token.", "response": "def tokprob(self, tok, nonT):\n        \"\"\"\n        return P[nonT -> tok], \n        e.g., P[ W3 -> 'abc']\n        \"\"\"\n\n        p = self._T.get(tok, 0) / float(self._T.get(nonT, 1))\n        if not p:\n            p = MIN_PROB\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the probability of pw under the Weir PCFG model.", "response": "def prob(self, pw):\n        \"\"\"\n        Return the probability of pw under the Weir PCFG model.\n        P[{S -> L2D1Y3, L2 -> 'ab', D1 -> '1', Y3 -> '!@#'}]\n        \"\"\"\n\n        tokens = self.pcfgtokensofw(pw)\n        S, tokens = tokens[0], tokens[1:]\n        l = len(tokens)\n        assert l % 2 == 0, \"Expecting even number of tokens!. got {}\".format(tokens)\n\n        p = float(self._T.get(S, 0.0)) / sum(v for k, v in self._T.items('__S__'))\n        for i, t in enumerate(tokens):\n            f = self._T.get(t, 0.0)\n            if f == 0:\n                return 0.0\n            if i < l / 2:\n                p /= f\n            else:\n                p *= f\n                # print pw, p, t, self._T.get(t)\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cprob(self, c, history):\n        if not history:\n            return 1\n        hist = history[:]\n        if len(history) >= self._n:\n            history = history[-(self._n-1):]\n        if not isinstance(history, str):\n            history = str(history)\n        d, n = 0.0, 0.0\n        while (d == 0.0) and len(history) >= 1:\n            try:\n                d = self.get_freq(history)\n                n = self.get_freq(history + c)\n            except UnicodeDecodeError as e:\n                print((\"ERROR:\", repr(history), e))\n                raise e\n            history = history[1:]\n\n        assert d != 0, \"ERROR: Denominator zero!\\n\" \\\n                       \"d={} n={} history={!r} c={!r} ({})\" \\\n            .format(d, n, hist, c, self._n)\n\n        return (n + 1) / (d + N_VALID_CHARS-1)", "response": "Return probability of a character in a history."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the next set of characters and their probabilities", "response": "def _get_next(self, history):\n        \"\"\"Get the next set of characters and their probabilities\"\"\"\n        orig_history = history\n        if not history:\n            return helper.START\n        history = history[-(self._n-1):]\n        while history and not self._T.get(history):\n            history = history[1:]\n        kv = [(k, v) for k, v in self._T.items(history)\n              if not (k in reserved_words or k == history)]\n        total = sum(v for k, v in kv)\n        while total == 0 and len(history) > 0:\n            history = history[1:]\n            kv = [(k, v) for k, v in self._T.items(history)\n                  if not (k in reserved_words or k == history)]\n            total = sum(v for k, v in kv)\n        assert total > 0, \"Sorry there is no n-gram with {!r}\".format(orig_history)\n        d = defaultdict(float)\n        total = self._T.get(history)\n        for k, v in kv:\n            k = k[len(history):]\n            d[k] += (v+1)/(total + N_VALID_CHARS-1)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates next character from the distribution of characters next.", "response": "def _gen_next(self, history):\n        \"\"\"Generate next character sampled from the distribution of characters next.\n        \"\"\"\n        orig_history = history\n        if not history:\n            return helper.START\n        history = history[-(self._n-1):]\n        kv = [(k, v) for k, v in self._T.items(history)\n              if k not in reserved_words]\n        total = sum(v for k, v in kv)\n        while total == 0 and len(history) > 0:\n            history = history[1:]\n            kv = [(k, v) for k, v in self._T.items(history) \n                  if k not in reserved_words]\n            total = sum(v for k, v in kv)\n        assert total > 0, \"Sorry there is no n-gram with {!r}\".format(orig_history)\n        _, sampled_k = list(helper.sample_following_dist(kv, 1, total))[0]\n        # print(\">>>\", repr(sampled_k), len(history))\n        return sampled_k[len(history)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a set of passwords in order between upto N_max.", "response": "def generate_pws_in_order(self, n, filter_func=None, N_max=1e6):\n        \"\"\"\n        Generates passwords in order between upto N_max\n        @N_max is the maximum size of the priority queue will be tolerated,\n        so if the size of the queue is bigger than 1.5 * N_max, it will shrink\n        the size to 0.75 * N_max\n        @n is the number of password to generate.\n        **This function is expensive, and shuold be called only if necessary.\n        Cache its call as much as possible**\n        # TODO: Need to recheck how to make sure this is working.\n        \"\"\"\n        # assert alpha < beta, 'alpha={} must be less than beta={}'.format(alpha, beta)\n        states = [(-1.0, helper.START)]\n        # get the topk first\n        p_min = 1e-9 / (n**2)   # max 1 million entries in the heap \n        ret = []\n        done = set()\n        already_added_in_heap = set()\n        while len(ret) < n and len(states) > 0:\n        # while n > 0 and len(states) > 0:\n            p, s = heapq.heappop(states)\n            if p < 0:\n                p = -p\n            if s in done: continue\n            assert s[0] == helper.START, \"Broken s: {!r}\".format(s)\n            if s[-1] == helper.END:\n                done.add(s)\n                clean_s = s[1:-1]\n                if filter_func is None or filter_func(clean_s):\n                    ret.append((clean_s, p))\n                    # n -= 1\n                    # yield (clean_s, p)\n            else:\n                for c, f in self._get_next(s).items():\n                    if (f*p < p_min or (s+c) in done or\n                        (s+c) in already_added_in_heap):\n                        continue\n                    already_added_in_heap.add(s+c)\n                    heapq.heappush(states, (-f*p, s+c))\n            if len(states) > N_max * 3 / 2:\n                print(\"Heap size: {}. ret={}. (expected: {}) s={!r}\"\n                      .format(len(states), len(ret), n, s))\n                print(\"The size of states={}.  Still need={} pws. Truncating\"\n                      .format(len(states), n - len(ret)))\n                states = heapq.nsmallest(int(N_max * 3/4), states)\n                print(\"Done\")\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the probability of pw in the model", "response": "def prob(self, pw):\n        \"\"\"\n        returns the probabiltiy of pw in the model.\n        P[pw] = n(pw)/n(__total__)\n        \"\"\"\n        return float(self._T.get(pw, 0)) / self._T[TOTALF_W]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncorrect the probability error due to truncating the distribution.", "response": "def prob_correction(self, f=1):\n        \"\"\"\n        Corrects the probability error due to truncating the distribution.\n        \"\"\"\n        total = {'rockyou': 32602160}\n        return f * self._T[TOTALF_W] / total.get(self._leak, self._T[TOTALF_W])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine what can be serialised and what shouldn t be serialised", "response": "def serialisable(cls, key, obj):\n        '''Determines what can be serialised and what shouldn't\n        '''\n        # ignore class method names\n        if key.startswith('_Serialisable'.format(cls.__name__)):\n            return False\n        if key in obj.__whitelist:\n            return True\n        # class variables will be prefixed with '_<cls.__name__>__variable'\n        # so let's remove these too\n        #if key.startswith('__'):\n        if '__' in key:\n            return False\n        # ignore our own class variables\n        #if key in ['_Serialisable__whitelist', '_Serialisable__blacklist']:\n        #    return False\n        if key in obj.__blacklist:\n            return False\n        if callable(getattr(obj, key)):\n            return False\n        # check for properties\n        if hasattr(obj.__class__, key):\n            if isinstance(getattr(obj.__class__, key), property):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserialises the object by default serialises anything that isn t in the blacklist and isn t callable.", "response": "def to_dict(cls, obj):\n        '''Serialises the object, by default serialises anything\n        that isn't prefixed with __, isn't in the blacklist, and isn't\n        callable.\n        '''\n        return {\n            k: getattr(obj, k)\n            for k in dir(obj)\n            if cls.serialisable(k, obj)\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning array normalised such that all values are between 0 and 1.", "response": "def normalise(array):\n    \"\"\"Return array normalised such that all values are between 0 and 1.\n\n    If all the values in the array are the same the function will return:\n    - np.zeros(array.shape, dtype=np.float) if the value is 0 or less\n    - np.ones(array.shape, dtype=np.float) if the value is greater than 0\n\n    :param array: numpy.array\n    :returns: numpy.array.astype(numpy.float)\n    \"\"\"\n    min_val = array.min()\n    max_val = array.max()\n    array_range = max_val - min_val\n\n    if array_range == 0:\n        # min_val == max_val\n        if min_val > 0:\n            return np.ones(array.shape, dtype=np.float)\n        return np.zeros(array.shape, dtype=np.float)\n\n    return (array.astype(np.float) - min_val) / array_range"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn 2D array projection of the input 3D array.", "response": "def reduce_stack(array3D, z_function):\n    \"\"\"Return 2D array projection of the input 3D array.\n\n    The input function is applied to each line of an input x, y value.\n\n    :param array3D: 3D numpy.array\n    :param z_function: function to use for the projection (e.g. :func:`max`)\n    \"\"\"\n    xmax, ymax, _ = array3D.shape\n    projection = np.zeros((xmax, ymax), dtype=array3D.dtype)\n    for x in range(xmax):\n        for y in range(ymax):\n            projection[x, y] = z_function(array3D[x, y, :])\n    return projection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_stack(array3D, z_function):\n    _, _, zdim = array3D.shape\n    return np.dstack([z_function(array3D[:,:,z]) for z in range(zdim)])", "response": "Return 3D array where each z - slice has had the function applied to it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_dtype(array, allowed):\n    if not hasattr(allowed, \"__iter__\"):\n        allowed = [allowed,]\n    if array.dtype not in allowed:\n        raise(TypeError(\n            \"Invalid dtype {}. Allowed dtype(s): {}\".format(array.dtype, allowed)))", "response": "Raises TypeError if the array is not of an allowed dtype."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction decorator for specifying input and output array dtypes.", "response": "def dtype_contract(input_dtype=None, output_dtype=None):\n    \"\"\"Function decorator for specifying input and/or output array dtypes.\"\"\"\n    def wrap(function):\n        @wraps(function)\n        def wrapped_function(*args, **kwargs):\n            if input_dtype is not None:\n                check_dtype(args[0], input_dtype)\n            array = function(*args, **kwargs)\n            if output_dtype is not None:\n                check_dtype(array, output_dtype)\n            return array\n        return wrapped_function\n    return wrap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the control channel.", "response": "def handle_ctrlchan(handler, msg, nick, send):\n    \"\"\"Handle the control channel.\"\"\"\n    with handler.db.session_scope() as db:\n        parser = init_parser(send, handler, nick, db)\n        try:\n            cmdargs = parser.parse_args(msg)\n        except arguments.ArgumentException as e:\n            # FIXME: figure out a better way to allow non-commands without spamming the channel.\n            err_str = r\"invalid choice: .* \\(choose from 'quote', 'help', 'chanserv', 'cs', 'disable', 'enable', 'guard', 'unguard', 'show', 'accept', 'reject'\\)\"\n            if not re.match(err_str, str(e)):\n                send(str(e))\n            return\n        cmdargs.func(cmdargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd(send, msg, args):\n    incidents = get_incidents(args['config']['api']['wmatakey'])\n    if not incidents:\n        send(\"No incidents found. Sure you picked the right metro system?\")\n        return\n    for t, i in incidents.items():\n        send(\"%s:\" % get_type(t))\n        for desc in i:\n            send(desc)", "response": "Provides Metro Info.\n    Syntax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef page_location(self):\n        cycle = self.election_day.cycle.name\n        if self.content_type.model_class() == PageType:\n            print(self.content_object)\n            return self.content_object.page_location_template()\n        elif self.content_type.model_class() == Division:\n            if self.content_object.level.name == DivisionLevel.STATE:\n                if self.special_election:\n                    # /{state}/special-election/{month-day}/\n                    path = os.path.join(\n                        self.content_object.slug,\n                        \"special-election\",\n                        self.election_day.special_election_datestring(),\n                    )\n                else:\n                    # /{state}/\n                    path = self.content_object.slug\n            else:\n                # /  National\n                path = \"\"\n        # Offices and Bodies\n        else:\n            if self.division.level.name == DivisionLevel.STATE:\n                if not self.content_object.body:\n                    path = os.path.join(self.division.slug, \"governor\")\n                else:\n                    path = os.path.join(\n                        self.division.slug, self.content_object.slug\n                    )\n            else:\n                path = self.content_object.slug\n        return (\n            os.sep + os.path.normpath(os.path.join(cycle, path)) + os.sep\n        )", "response": "Returns the published URL for the page."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets object by its name. Return None if object not found.", "response": "def _get_object(self, name):\n        \"\"\"Get object by its name. Return None if object not found\"\"\"\n        clean_name = self._clean_name(name)\n        try:\n            return self.driver.get_object(self.bucket, clean_name)\n        except ObjectDoesNotExistError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, name):\n        obj = self._get_object(name)\n        if obj:\n            return self.driver.delete_object(obj)", "response": "Delete object on remote"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting the contents of the specified path returning a 2 - tuple of lists ; the first item being directories the second item being files.", "response": "def listdir(self, path='/'):\n        \"\"\"Lists the contents of the specified path,\n        returning a 2-tuple of lists; the first item being\n        directories, the second item being files.\n        \"\"\"\n        container = self._get_bucket()\n        objects = self.driver.list_container_objects(container)\n        path = self._clean_name(path)\n        if not path.endswith('/'):\n            path = \"%s/\" % path\n        files = []\n        dirs = []\n        # TOFIX: better algorithm to filter correctly\n        # (and not depend on google-storage empty folder naming)\n        for o in objects:\n            if path == '/':\n                if o.name.count('/') == 0:\n                    files.append(o.name)\n                elif o.name.count('/') == 1:\n                    dir_name = o.name[:o.name.index('/')]\n                    if dir_name not in dirs:\n                        dirs.append(dir_name)\n            elif o.name.startswith(path):\n                if o.name.count('/') <= path.count('/'):\n                    # TOFIX : special case for google storage with empty dir\n                    if o.name.endswith('_$folder$'):\n                        name = o.name[:-9]\n                        name = name[len(path):]\n                        dirs.append(name)\n                    else:\n                        name = o.name[len(path):]\n                        files.append(name)\n        return (dirs, files)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns auto generated file name.", "response": "def name(cls, func):\n        \"\"\"Return auto generated file name.\"\"\" \n        cls.count = cls.count + 1\n        fpath = '{}_{}{}'.format(cls.count, func.__name__, cls.suffix)\n        if cls.directory:\n            fpath = os.path.join(cls.directory, fpath)\n        return fpath"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npattern used to split the input file.", "response": "def split_pattern(self):\n        \"\"\"Pattern used to split the input file.\"\"\"\n        patterns = []\n        for p in self.split_order:\n            patterns.append('_{}%{}'.format(p.capitalize(), p))\n        return ''.join(patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list sorted nicely by name.", "response": "def _sorted_nicely(self, l):\n        \"\"\"Return list sorted in the way that humans expect.\n        \n        :param l: iterable to be sorted\n        :returns: sorted list\n        \"\"\"\n        convert = lambda text: int(text) if text.isdigit() else text\n        alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n        return sorted(l, key = alphanum_key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn manifest as a list.", "response": "def manifest(self, entry):\n        \"\"\"Returns manifest as a list.\n        \n        :param entry: :class:`jicimagelib.image.FileBackend.Entry`\n        :returns: list\n        \"\"\"\n        entries = []\n        for fname in self._sorted_nicely(os.listdir(entry.directory)):\n            if fname == 'manifest.json':\n                continue\n            fpath = os.path.abspath(os.path.join(entry.directory, fname))\n            metadata = self.metadata_from_fname(fname)\n            entries.append({\"filename\": fpath,\n                            \"series\": metadata.s,\n                            \"channel\": metadata.c,\n                            \"zslice\": metadata.z,\n                            \"timepoint\": metadata.t})\n        return entries"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command(self, input_file, output_dir=None):\n        base_name = os.path.basename(input_file)\n        name, suffix = base_name.split('.', 1)\n        output_file = '{}{}.tif'.format(name, self.split_pattern)\n        if output_dir:\n            output_file = os.path.join(output_dir, output_file)\n        return ['bfconvert', input_file, output_file]", "response": "Return the command for running bfconvert as a list.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning meta data extracted from file name.", "response": "def metadata_from_fname(self, fname):\n        \"\"\"Return meta data extracted from file name.\n        \n        :param fname: metadata file name\n        :returns: dynamically created :class:`collections.namedtuple`\n        \"\"\"\n        MetaData = namedtuple('MetaData', self.split_order)\n        base_name = os.path.basename(fname)              # e.g. 'test_S1_C2_Z3_T4.tif'\n        name, suffix = base_name.split('.')              # e.g. 'test_S1_C2_Z3_T4', 'tif'\n        data = name.split('_')[-len(self.split_order):]  # e.g. ['S1', 'C2', 'Z3', 'T4']\n        args = [ int(x[1:]) for x in data ]               # e.g. [1, 2, 3, 4]\n        return MetaData(*args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef already_converted(self, fpath):\n        manifest_fpath = os.path.join(self.backend.directory,\n                                      os.path.basename(fpath),\n                                      'manifest.json')\n        return os.path.isfile(manifest_fpath)", "response": "Return true if the file already has a manifest file in the backend.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh_stats(self):\n        self.tot_pix = 0\n        self.tot_sea = 0\n        self.tot_land = 0\n        self.tot_blocked = 0\n        for row in range(self.grd.grid_height):\n            for col in range(self.grd.grid_width):\n                self.tot_pix += 1\n                val = self.grd.get_tile(row, col)\n                if val == TERRAIN_SEA: \n                    self.tot_sea += 1\n                elif val == TERRAIN_LAND: \n                    self.tot_land += 1\n                else:\n                    self.tot_blocked += 1", "response": "This function is used to update the statistics of the terrain tables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_random(self, num_seeds=4, perc_land=40, perc_sea=30, perc_blocked=30):\n        rnge = math.floor(num_seeds/2)\n        # self.show_grid_stats()\n        seeds = [[randint(0,self.grd.grid_height-1), randint(0,self.grd.grid_width-1)] for _ in range(rnge) for _ in range(rnge)]\n        for seed in seeds:\n            self.expand_seed(seed, (self.grd.grid_height * self.grd.grid_width)/(perc_sea),  TERRAIN_LAND)\n        \n        self.refresh_stats()\n        #   print(self.show_grid_stats())\n        expand = 1\n        old_land = self.tot_land\n        while (100*self.tot_land)/self.tot_pix < perc_land - 1:\n            expand +=1\n            \n            self.denoise_grid(TERRAIN_LAND, expand)\n            self.refresh_stats()\n            #  print(expand, self.show_grid_stats())\n            if old_land == self.tot_land:   # no extra expansion, so add another seed\n                self.expand_seed(self.add_new_seed(), 50, TERRAIN_LAND)\n            else:\n                old_land = self.tot_land\n        self.add_blocks(perc_blocked)\n        self.refresh_stats()", "response": "Builds a random set of random elements for a set of seas and a set of narrow block points."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pick_random_target(self):\n        start_x = math.floor(self.grd.grid_height/2)\n        start_y = math.floor(self.grd.grid_width /2)\n        min_dist_from_x = 3\n        min_dist_from_y = 5\n        move_random_x = randint(1, math.floor(self.grd.grid_height/2))\n        move_random_y = randint(1, math.floor(self.grd.grid_width/2))\n        x = start_x + move_random_x - min_dist_from_x\n        y = start_y + move_random_y - min_dist_from_y\n        return [x,y]", "response": "returns coords of a randomly generated starting position"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpanding a random seed in the grid", "response": "def expand_seed(self, start_seed, num_iterations, val):\n        \"\"\"\n        takes a seed start point and grows out in random\n        directions setting cell points to val\n        \"\"\"\n        self.grd.set_tile(start_seed[0], start_seed[1], val)\n        cur_pos = [start_seed[0], start_seed[1]]\n        while num_iterations > 0:   # don't use loop as it will hit boundaries often\n            num_iterations -= 1\n            for y in range(cur_pos[0]-randint(0,2), cur_pos[0] + randint(0,2)):\n                for x in range(cur_pos[1]-randint(0,2), cur_pos[1] + randint(0,2)):\n                    if x < self.grd.grid_width and x >= 0 and y >= 0 and y < self.grd.grid_height:\n                        #print(x,y,val)\n                        if self.grd.get_tile(y,x) != val:\n                            self.grd.set_tile(y, x, TERRAIN_LAND)\n                            num_iterations -= 1\n            new_x = cur_pos[0] + randint(0,3)-2\n            new_y = cur_pos[1] + randint(0,3)-2\n            if new_x > self.grd.grid_width - 1:\n                new_x = 0\n            if new_y > self.grd.grid_height - 1:\n                new_y = 0\n            if new_x < 0:\n                new_x = self.grd.grid_width - 1\n            if new_y < 0:\n                new_y = self.grd.grid_height - 1\n            cur_pos = [new_y, new_x]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef denoise_grid(self, val, expand=1):\n        \n        updated_grid = [[self.grd.get_tile(y,x) \\\n                        for x in range(self.grd.grid_width)] \\\n                        for y in range(self.grd.grid_height)]\n        for row in range(self.grd.get_grid_height() - expand):\n            for col in range(self.grd.get_grid_width() - expand):\n                updated_grid[row][col] = self.grd.get_tile(row,col)  # set original point\n                if self.grd.get_tile(row,col) == val:\n                    for y in range(-expand, expand):\n                        for x in range(-expand, expand):\n                            new_x = col+x\n                            new_y = row+y\n                            if new_x < 0: new_x = 0\n                            if new_y < 0: new_y = 0\n                            if new_x > self.grd.get_grid_width() - 1: new_x = self.grd.get_grid_width() - 1\n                            if new_y > self.grd.get_grid_height() - 1: new_y = self.grd.get_grid_height() - 1\n                            # randomly NOT denoise to make interesting edges\n                            if expand > 0: \n                                if randint(1,expand * 2) > (expand+1):\n                                    updated_grid[new_y][new_x] = val\n                            else:\n                                updated_grid[new_y][new_x] = val\n                        \n        \n        self.grd.replace_grid(updated_grid)", "response": "denoise the grid of the given value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a series of blocks to the set of sea and land features.", "response": "def add_blocks(self, perc_blocked=30):\n        \"\"\"  \n        adds a series of blocks - normally more straight than\n        random sea/land features - blocks are default 5x2\n        \"\"\"\n        self.refresh_stats()\n        #print(self.show_grid_stats())\n        while (100*(self.tot_blocked-10))/self.tot_pix < perc_blocked - 1:\n            self.add_block()\n            self.refresh_stats()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_mountains(self):\n        from noise import pnoise2\n        import random\n        random.seed()\n        octaves = (random.random() * 0.5) + 0.5\n        freq = 17.0 * octaves  # \n        for y in range(self.grd.grid_height - 1):\n            for x in range(self.grd.grid_width - 1):\n                pixel = self.grd.get_tile(y,x)\n                if pixel == 'X':     # denoise blocks of mountains\n                    n = int(pnoise2(x/freq, y / freq, 1)*11+5)\n                    if n < 1:\n                        self.grd.set_tile(y, x, '#')", "response": "This function creates more natural looking blocking areas of agents and mounts them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_block(self):\n        row_max = self.grd.get_grid_height() - 15\n        if row_max < 2:\n            row_max = 2\n        row = randint(0, row_max)\n        \n        col_max = self.grd.get_grid_width() - 10\n        if col_max < 2:\n            col_max = 2\n        col = randint(0, col_max)\n        \n        direction = randint(1,19)-10\n        if direction > 0:\n            y_len = 10 * (math.floor(self.grd.get_grid_height() / 120) + 1)\n            x_len = 1 * (math.floor(self.grd.get_grid_width() / 200) + 1)\n        else:\n            y_len = 1 * (math.floor(self.grd.get_grid_height() / 200) + 1)\n            x_len = 10 * (math.floor(self.grd.get_grid_width() / 120) + 1)\n        \n        print(\"Adding block to \", row, col, direction)\n        for r in range(row, row + y_len):\n            for c in range(col, col + x_len):\n                self.grd.set_tile(r,c,TERRAIN_BLOCKED)", "response": "add a random size block to the map"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun each agent in the world for num_runs iterations Save the grid results to file if base name is passed to method.", "response": "def run(self, num_runs, show_trails, log_file_base):\n        \"\"\"\n        Run each agent in the world for 'num_runs' iterations\n        Optionally saves grid results to file if base name is\n        passed to method.\n        \"\"\"\n        print(\"--------------------------------------------------\")\n        print(\"Starting Simulation - target = \", self.agent_list[0].target_y, self.agent_list[0].target_x)\n        self.world.grd.set_tile(self.agent_list[0].target_y , self.agent_list[0].target_x , 'T')\n        self.highlight_cell_surroundings(self.agent_list[0].target_y, self.agent_list[0].target_x)\n        self.start_all_agents()\n        # save the agents results here\n        try:\n            with open (log_file_base + '__agents.txt', \"w\") as f:\n                f.write(\"Starting World = \\n\")\n                f.write(str(self.world.grd))\n        except Exception:\n            print('Cant save log results to ' + log_file_base)\n            \n        for cur_run in range(0,num_runs):\n            print(\"WorldSimulation:run#\", cur_run)\n            for num, agt in enumerate(self.agent_list):\n                if show_trails == 'Y':\n                    if len(self.agent_list) == 1 or len(self.agent_list) > 9:\n                        self.world.grd.set_tile(agt.current_y, agt.current_x, 'o')\n                    else:\n                        self.world.grd.set_tile(agt.current_y, agt.current_x, str(num))\n                agt.do_your_job()\n                self.world.grd.set_tile(agt.current_y, agt.current_x, 'A')    # update the main world grid with agents changes\n            \n            # save grid after each run if required\n            if log_file_base != 'N':\n                self.world.grd.save(log_file_base + '_' + str(cur_run) + '.log')\n    \n        # save the agents results here\n        with open (log_file_base + '__agents.txt', \"a\") as f:\n            f.write(\"\\nWorld tgt= [\" + str(self.agent_list[0].target_y) + \",\" + str(self.agent_list[0].target_x) + \"]\\n\")\n            f.write(str(self.world.grd))\n            f.write('\\n\\nAgent Name , starting, num Steps , num Climbs\\n')\n            for num, agt in enumerate(self.agent_list):\n                res = agt.name + ' , [' + str(agt.start_y) + ', ' + str(agt.start_x) + '], '\n                res += str(agt.num_steps)  + ' , ' + str(agt.num_climbs) + ' , '\n                res += ''.join([a for a in agt.results])\n                f.write(res + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhighlighting the cells around a target to make it simpler", "response": "def highlight_cell_surroundings(self, target_y, target_x):\n        \"\"\"\n        highlights the cells around a target to make it simpler\n        to see on a grid. Currently assumes the target is within\n        the boundary by 1 on all sides\n        \"\"\"\n        #print('SELF_WORLD', self.world)\n        #print('target_y, target_x, self.world.grd.grid_height, self.world.grd.grid_width ', target_y, target_x, self.#world.grd.grid_height, self.world.grd.grid_width )\n        #exit(0)\n        \n        if target_y < 1:\n            print(\"target too close to top\")\n        if target_y > self.world.grd.grid_height - 1:  \n            print(\"target too close to bottom\")\n        if target_x < 1:\n            print(\"target too close to left\")\n        if target_x < self.world.grd.grid_width:  \n            print(\"target too close to right\")\n        #valid_cells = ['\\\\', '-', '|', '/']    \n        self.world.grd.set_tile(target_y - 1, target_x - 1, '\\\\')\n        self.world.grd.set_tile(target_y - 0, target_x - 1, '-')\n        self.world.grd.set_tile(target_y + 1, target_x - 1, '/')\n\n        self.world.grd.set_tile(target_y - 1, target_x - 0, '|')\n        self.world.grd.set_tile(target_y + 1, target_x - 0, '|')\n        \n        self.world.grd.set_tile(target_y - 1, target_x + 1, '/')\n        self.world.grd.set_tile(target_y - 0, target_x + 1, '-')\n        self.world.grd.set_tile(target_y + 1, target_x + 1, '\\\\')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nabuse the bot. Syntax", "response": "def cmd(send, _, args):\n    \"\"\"Abuses the bot.\n\n    Syntax: {command}\n\n    \"\"\"\n\n    def lenny_send(msg):\n        send(gen_lenny(msg))\n\n    key = args['config']['api']['bitlykey']\n    cmds = [lambda: gen_fortune(lenny_send), lambda: gen_urban(lenny_send, args['db'], key)]\n    choice(cmds)()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gffatributes2ids(s):\n    Name,gene_id,transcript_id,protein_id,exon_id=np.nan,np.nan,np.nan,np.nan,np.nan\n    if '=' in s:\n        d=dict([i.split('=') for i in s.split(';')])\n        if 'Parent' in d:\n            d[d['Parent'].split(':')[0]+'_id']=d['Parent'].split(':')[1]\n        Name,gene_id,transcript_id,protein_id,exon_id=np.nan,np.nan,np.nan,np.nan,np.nan\n        if 'Name' in d:    \n            Name=d['Name']\n        if 'gene_id' in d:    \n            gene_id=d['gene_id']\n        if 'transcript_id' in d:    \n            transcript_id=d['transcript_id']\n        if 'protein_id' in d:    \n            protein_id=d['protein_id']\n        if 'exon_id' in d:    \n            exon_id=d['exon_id']\n    return Name,gene_id,transcript_id,protein_id,exon_id", "response": "Convert GFF3 attributes to seprate ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hamming_distance(s1, s2):\n#     print(s1,s2)\n    if len(s1) != len(s2):\n        raise ValueError(\"Undefined for sequences of unequal length\")\n    return sum(el1 != el2 for el1, el2 in zip(s1.upper(), s2.upper()))", "response": "Return the Hamming distance between two equal - length sequences"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef align(s1,s2,test=False,seqfmt='dna',\n         psm=None,pmm=None,pgo=None,pge=None,\n         matrix=None,\n         outscore=False):\n    \"\"\"\n    Creates pairwise local alignment between seqeunces.\n    Get the visualization and alignment scores.\n    :param s1: seqeunce 1\n    :param s2: seqeunce 2    \n    \n    REF: http://biopython.org/DIST/docs/api/Bio.pairwise2-module.html\n    The match parameters are:\n\n    CODE  DESCRIPTION\n    x     No parameters. Identical characters have score of 1, otherwise 0.\n    m     A match score is the score of identical chars, otherwise mismatch\n          score.\n    d     A dictionary returns the score of any pair of characters.\n    c     A callback function returns scores.\n    The gap penalty parameters are:\n\n    CODE  DESCRIPTION\n    x     No gap penalties.\n    s     Same open and extend gap penalties for both sequences.\n    d     The sequences have different open and extend gap penalties.\n    c     A callback function returns the gap penalties.  \n    --\n    DNA: \n    localms: psm=2,pmm=0.5,pgo=-3,pge=-1):\n    Protein:\n    http://resources.qiagenbioinformatics.com/manuals/clcgenomicsworkbench/650/Use_scoring_matrices.html\n    \"\"\"\n    import operator\n    from Bio import pairwise2\n    if seqfmt=='dna':\n        if any([p is None for p in [psm,pmm,pgo,pge]]):\n            alignments = pairwise2.align.localxx(s1.upper(),s2.upper())\n        else:\n            alignments = pairwise2.align.localms(s1.upper(),s2.upper(),psm,pmm,pgo,pge)\n    elif seqfmt=='protein':\n        from Bio.pairwise2 import format_alignment\n        from Bio.SubsMat import MatrixInfo\n        if matrix is None:\n            matrix = MatrixInfo.blosum62\n        alignments =pairwise2.align.globaldx(s1, s2, matrix)\n#         print(format_alignment(*a))        \n    if test:\n        print(alignments)\n    alignsymb=np.nan\n    score=np.nan\n    sorted_alignments = sorted(alignments, key=operator.itemgetter(2))\n    for a in alignments:\n        alignstr=pairwise2.format_alignment(*a)\n        alignsymb=alignstr.split('\\n')[1]\n        score=a[2]\n        if test:\n            print(alignstr)\n        break\n    if not outscore:\n        return alignsymb.replace(' ','-'),score\n    else:\n        return score", "response": "Create a pairwise local alignment between two sequences."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate a DNA sequence into a human - readable sequence.", "response": "def translate(dnaseq,host='human',fmtout=str,tax_id=None):\n    \"\"\"\n    Translates a DNA seqeunce\n    :param dnaseq: DNA sequence\n    :param host: host organism\n    :param fmtout: format of output sequence\n    \"\"\"\n    if isinstance(dnaseq,str): \n        dnaseq=Seq.Seq(dnaseq,Alphabet.generic_dna)\n    if tax_id is None:\n        tax_id=1 # stanndard codon table. ref http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc25\n    prtseq=dnaseq.translate(table=tax_id)\n    if fmtout is str:\n        return str(prtseq)\n    else:\n        return prtseq"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave a portfolio in the database", "response": "def save_portfolio(self, datetime, portfolio, perf_tracker, recorded_vars):\n        '''\n        Store in Rethinkdb a zipline.Portfolio object\n        '''\n        if perf_tracker.progress != 0.0 and self.table:\n\n            metrics = perf_tracker.to_dict()\n            metrics.update({\n                'date': datetime,\n                'recorded': recorded_vars,\n                'portfolio': dbutils.portfolio_to_dict(portfolio)\n            })\n\n            log.debug('Saving metrics in database')\n            log.debug(\n                rdb.table(self.table)\n                   .insert(metrics)\n                   .run(self.session)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a github issue or gets a open one.", "response": "def cmd(send, msg, args):\n    \"\"\"Files a github issue or gets a open one.\n\n    Syntax: {command} <title [--desc description]|--get <number>>\n\n    \"\"\"\n    repo = args['config']['api']['githubrepo']\n    apikey = args['config']['api']['githubapikey']\n    if not repo:\n        send(\"GitHub repository undefined in config.cfg!\")\n        return\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('title', nargs='*', default='')\n    parser.add_argument('--get', '--show', action='store_true')\n    parser.add_argument('--description', nargs='+', default=\"No description given.\")\n    cmdargs, remainder = parser.parse_known_args(msg)\n    if isinstance(cmdargs.title, list):\n        cmdargs.title = ' '.join(cmdargs.title)\n    if isinstance(cmdargs.description, list):\n        cmdargs.description = ' '.join(cmdargs.description)\n    if remainder:\n        cmdargs.title = \"%s %s\" % (cmdargs.title, ' '.join(remainder))\n    if args['type'] == 'privmsg':\n        send('You want to let everybody know about your problems, right?')\n    elif cmdargs.get or cmdargs.title.isdigit():\n        issue = get('https://api.github.com/repos/%s/issues/%d' % (repo, int(cmdargs.title))).json()\n        if 'message' in issue:\n            send(\"Invalid Issue Number\")\n        else:\n            send(\"%s (%s) -- %s\" % (issue['title'], issue['state'], issue['html_url']))\n    elif not cmdargs.title:\n        issues = []\n        n = 1\n        while True:\n            headers = {'Authorization': 'token %s' % apikey}\n            page = get('https://api.github.com/repos/%s/issues' % repo, params={'per_page': '100', 'page': n}, headers=headers).json()\n            n += 1\n            if page:\n                issues += page\n            else:\n                break\n        if len(issues) == 0:\n            send(\"No open issues to choose from!\")\n        else:\n            issue = choice(issues)\n            num_issues = len([x for x in issues if 'pull_request' not in x])\n            send(\"There are %d open issues, here's one.\" % num_issues)\n            send(\"#%d -- %s -- %s\" % (issue['number'], issue['title'], issue['html_url']))\n    elif cmdargs.title and args['is_admin'](args['nick']):\n        url, success = create_issue(cmdargs.title, cmdargs.description, args['source'], repo, apikey)\n        if success:\n            send(\"Issue created -- %s -- %s -- %s\" % (url, cmdargs.title, cmdargs.description))\n        else:\n            send(\"Error creating issue: %s\" % url)\n    elif cmdargs.title:\n        row = Issues(title=cmdargs.title, description=cmdargs.description, source=str(args['source']))  # str needed to make mysqlconnector happy\n        args['db'].add(row)\n        args['db'].flush()\n        send(\"New Issue: #%d -- %s -- %s, Submitted by %s\" % (row.id, cmdargs.title, cmdargs.description, args['nick']),\n             target=args['config']['core']['ctrlchan'])\n        send(\"Issue submitted for approval.\", target=args['nick'])\n    else:\n        send(\"Invalid arguments.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist loaded hooks Syntax", "response": "def cmd(send, *_):\n    \"\"\"Lists loaded hooks\n    Syntax: {command}\n    \"\"\"\n    hooklist = ', '.join([str(x) for x in hook_registry.get_known_hooks()])\n    send('Loaded hooks: %s' % (hooklist))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a ctypes pointer to a Python svm_model", "response": "def toPyModel(model_ptr):\n\t\"\"\"\n\ttoPyModel(model_ptr) -> svm_model\n\n\tConvert a ctypes POINTER(svm_model) to a Python svm_model\n\t\"\"\"\n\tif bool(model_ptr) == False:\n\t\traise ValueError(\"Null pointer\")\n\tm = model_ptr.contents\n\tm.__createfrom__ = 'C'\n\treturn m"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmd(send, msg, args):\n    if not msg:\n        send(\"Explain What?\")\n        return\n    msg = msg.replace(' ', '+')\n    msg = 'http://lmgtfy.com/?q=%s' % msg\n    key = args['config']['api']['bitlykey']\n    send(get_short(msg, key))", "response": "Explain things.\n\n    Syntax: {command} <text>"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit as close to the end as possible.", "response": "def split_msg(msgs: List[bytes], max_len: int) -> Tuple[str, List[bytes]]:\n    \"\"\"Splits as close to the end as possible.\"\"\"\n    msg = \"\"\n    while len(msg.encode()) < max_len:\n        if len(msg.encode()) + len(msgs[0]) > max_len:\n            return msg, msgs\n        char = msgs.pop(0).decode()\n        # If we have a space within 15 chars of the length limit, split there to avoid words being broken up.\n        if char == \" \" and len(msg.encode()) > max_len - 15:\n            return msg, msgs\n        msg += char\n    return msg, msgs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(self, order, sids):\n        ''' Check if a message is available '''\n        payload = \"{}\"\n        #TODO store hashes {'intuition': {'id1': value, 'id2': value}}\n        # Block self.timeout seconds on self.channel for a message\n        raw_msg = self.client.blpop(self.channel, timeout=self.timeout)\n        if raw_msg:\n            _, payload = raw_msg\n\n            msg = json.loads(payload.replace(\"'\", '\"'), encoding='utf-8')\n            for sid in msg.keys():\n                #TODO Harmonize lower() and upper() symbols\n                if sid.lower() in map(str.lower, sids):\n                    print('ordering {} of {}'.format(msg[sid], sid))\n                    #order(sid.upper(), msg[sid])\n                    order(sid, msg[sid])\n                else:\n                    print('skipping unknown symbol {}'.format(sid))", "response": "Check if a message is available on the channel and order the sids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncausing the bot to snack on something.", "response": "def cmd(send, msg, args):\n    \"\"\"Causes the bot to snack on something.\n\n    Syntax: {command} [object]\n\n    \"\"\"\n    if not msg:\n        send(\"This tastes yummy!\")\n    elif msg == args['botnick']:\n        send(\"wyang says Cannibalism is generally frowned upon.\")\n    else:\n        send(\"%s tastes yummy!\" % msg.capitalize())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the next item from the cache.", "response": "def next(self):\n        \"\"\"\n        Provide iteration capabilities\n\n        Use a small object cache for performance\n        \"\"\"\n        if not self._cache:\n            self._cache = self._get_results()\n            self._retrieved += len(self._cache)\n\n        # If we don't have any other data to return, we just\n        # stop the iteration.\n        if not self._cache:\n            raise StopIteration()\n\n        # Consuming the cache and updating the \"cursor\"\n        return self._cache.pop(0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nthrow something. Syntax: {command} <object> [at <target>]", "response": "def cmd(send, msg, args):\n    \"\"\"Throw something.\n\n    Syntax: {command} <object> [at <target>]\n\n    \"\"\"\n    users = get_users(args)\n    if \" into \" in msg and msg != \"into\":\n        match = re.match('(.*) into (.*)', msg)\n        if match:\n            msg = 'throws %s into %s' % (match.group(1), match.group(2))\n            send(msg, 'action')\n        else:\n            return\n    elif \" at \" in msg and msg != \"at\":\n        match = re.match('(.*) at (.*)', msg)\n        if match:\n            msg = 'throws %s at %s' % (match.group(1), match.group(2))\n            send(msg, 'action')\n        else:\n            return\n    elif msg:\n        msg = 'throws %s at %s' % (msg, choice(users))\n        send(msg, 'action')\n    else:\n        send(\"Throw what?\")\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a function so that all unspecified arguments will be injected if possible.", "response": "def wrap(self, function):\n        \"\"\"\n        Wraps a function so that all unspecified arguments will be injected if\n        possible. Specified arguments always have precedence.\n        \"\"\"\n        func = inspect.getfullargspec(function)\n        needed_arguments = func.args + func.kwonlyargs\n\n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            arguments = kwargs.copy()\n            missing_arguments = needed_arguments - arguments.keys()\n            for arg in missing_arguments:\n                try:\n                    arguments[arg] = self._get_argument(arg)\n                except KeyError:\n                    pass\n            return function(*args, **arguments)\n\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall a specified function using the provided arguments and injectable arguments.", "response": "def call(self, func, *args, **kwargs):\n        \"\"\"\n        Calls a specified function using the provided arguments and injectable\n        arguments.\n\n        If the function must be called multiple times, it may be best to use\n        wrap().\n        \"\"\"\n        wrapped = self.wrap(func)\n        return wrapped(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        if self.___closed:\n            return\n\n        for ref in self.___subs:\n            sub = ref()\n            if sub is not None:\n                sub.close()\n\n        # Destroy in reverse order as first elements created have more components depending on them\n        for call in self.___close_list[::-1]:\n            if inspect.iscoroutinefunction(call):\n                self.loop.run_until_complete(call())\n            else:\n                call()\n\n        self.___closed = True", "response": "Closes the injector and all sub - injectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_array(cls, array, name=None, log_in_history=True):\n        image = array.view(cls)\n        event = 'Created image from array'\n        if name:\n            event = '{} as {}'.format(event, name)\n        if log_in_history:\n            image.history.append(event)\n        return image", "response": "Return an image instance from an array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_file(cls, fpath, name=None, log_in_history=True):\n        use_plugin('freeimage')\n        ar = imread(fpath)\n\n        # Create a :class:`jicimagelib.image.Image` instance.\n        image = Image.from_array(ar, name)\n\n        # Reset history, as image is created from file not array.\n        image.history = []\n        event = 'Created image from {}'.format(fpath)\n        if name:\n            event = '{} as {}'.format(event, name)\n        if log_in_history:\n            image.history.append(event)\n\n        return image", "response": "Create an image from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef png(self):\n        use_plugin('freeimage')\n        with TemporaryFilePath(suffix='.png') as tmp:\n            safe_range_im = 255 * normalise(self)\n            imsave(tmp.fpath, safe_range_im.astype(np.uint8))\n            with open(tmp.fpath, 'rb') as fh:\n                return fh.read()", "response": "Return png string of image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if arguments match my meta data.", "response": "def is_me(self, s, c, z, t):\n        \"\"\"Return True if arguments match my meta data.\n\n        :param s: series\n        :param c: channel\n        :param z: zslice\n        :param t: timepoint\n        :returns: :class:`bool`\n        \"\"\"\n        if (self.series == s\n            and self.channel == c\n            and self.zslice == z\n            and self.timepoint == t):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef in_zstack(self, s, c, t):\n        if (self.series == s\n            and self.channel == c\n            and self.timepoint == t):\n            return True\n        return False", "response": "Return True if I am in the zstack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_manifest(self, fpath):\n        with open(fpath, 'r') as fh:\n            for entry in json.load(fh):\n\n                # Every entry of a manifest file needs to have a \"filename\"\n                # attribute. It is the only requirement so we check for it in a\n                # strict fashion.\n                if \"filename\" not in entry:\n                    raise(RuntimeError(\n                        'Entries in {} need to have \"filename\"'.format(fpath)))\n\n                filename = entry.pop(\"filename\")\n\n                proxy_image = None\n                if isinstance(self, MicroscopyCollection):\n                    proxy_image = MicroscopyImage(filename, entry)\n                else:\n                    proxy_image = ProxyImage(filename, entry)\n                self.append(proxy_image)", "response": "Parse the manifest file to build up the collection of images."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a : class : jcimagelib. image. MicroscopyImage instance.", "response": "def proxy_image(self, s=0, c=0, z=0, t=0):\n        \"\"\"Return a :class:`jicimagelib.image.MicroscopyImage` instance.\n        \n        :param s: series\n        :param c: channel\n        :param z: zslice\n        :param t: timepoint\n        :returns: :class:`jicimagelib.image.MicroscopyImage`\n        \"\"\"\n        for proxy_image in self:\n            if proxy_image.is_me(s=s, c=c, z=z, t=t):\n                return proxy_image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zstack_proxy_iterator(self, s=0, c=0, t=0):\n        for proxy_image in self:\n            if proxy_image.in_zstack(s=s, c=c, t=t):\n                yield proxy_image", "response": "Return iterator of proxy images in the zstack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zstack_array(self, s=0, c=0, t=0):\n        return np.dstack([x.image for x in self.zstack_proxy_iterator(s=s, c=c, t=t)])", "response": "Return zstack as a numpy. ndarray."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image(self, s=0, c=0, z=0, t=0):\n        return self.proxy_image(s=s, c=c, z=z, t=t).image", "response": "Return image as a : class : jcimagelib. image. Image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a microscopy file into the internal list.", "response": "def load(self, fpath):\n        \"\"\"Load a microscopy file.\n        \n        :param fpath: path to microscopy file\n        \"\"\"\n        def is_microscopy_item(fpath):\n            \"\"\"Return True if the fpath is likely to be microscopy data.\n\n            :param fpath: file path to image\n            :returns: :class:`bool`\n            \"\"\"\n            l = fpath.split('.')\n            ext = l[-1]\n            pre_ext = l[-2]\n            if ( (ext == 'tif' or ext == 'tiff')\n                and pre_ext != 'ome' ):\n                return False\n            return True\n\n        if not self.convert.already_converted(fpath):\n            path_to_manifest = self.convert(fpath)\n        else:\n            path_to_manifest = os.path.join(self.backend.directory,\n                                            os.path.basename(fpath),\n                                            'manifest.json')\n\n        \n        collection = None\n        if is_microscopy_item(fpath):\n            collection = MicroscopyCollection()\n        else:\n            collection = ImageCollection()\n        collection.parse_manifest(path_to_manifest)\n        self.append(collection)\n\n        return collection"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind all specs in a given directory. Returns a list of Example and ExampleGroup instances.", "response": "def find_specs(self, directory):\n        \"\"\"Finds all specs in a given directory. Returns a list of\n        Example and ExampleGroup instances.\n        \"\"\"\n        specs = []\n        spec_files = self.file_finder.find(directory)\n        for spec_file in spec_files:\n            specs.extend(self.spec_finder.find(spec_file.module))\n        return specs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute(self, example_groups):\n        total_successes, total_errors, total_skipped = 0, 0, 0\n        for group in example_groups:\n            runner = ExampleRunner(group, self.formatter)\n            successes, errors, skips = runner.run()\n            total_successes += successes\n            total_errors += errors\n            total_skipped += skips\n        return total_successes, total_errors, total_skipped", "response": "Runs the specs. Returns a tuple indicating the number of successes failures and skipped."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding and runs the specs. Returns a tuple indicating the number of successes failures skipped.", "response": "def run(self, directories=None):\n        \"\"\"Finds and runs the specs. Returns a tuple indicating the\n        number of (succeses, failures, skipped)>\n        \"\"\"\n        if directories is None:\n            directories = [os.getcwd()]\n\n        total_successes, total_errors, total_skipped = 0, 0, 0\n        for directory in directories:\n            successes, errors, skips = self.execute(self.find_specs(directory))\n            total_successes += successes\n            total_errors += errors\n            total_skipped += skips\n\n\n        self.formatter.finalize()\n        return total_successes, total_errors, total_skipped"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uncurry(f):\n    ensure_callable(f)\n\n    result = lambda args=(), kwargs=None: f(*args, **(kwargs or {}))\n    functools.update_wrapper(result, f, ('__name__', '__module__'))\n    return result", "response": "Convert a curried function into a function on tuples\n    and dictionaries\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flip(f):\n    ensure_callable(f)\n\n    result = lambda *args, **kwargs: f(*reversed(args), **kwargs)\n    functools.update_wrapper(result, f, ('__name__', '__module__'))\n    return result", "response": "Flip the order of positonal arguments of given function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function that returns a result of the functions passed in.", "response": "def compose(*fs):\n    \"\"\"Creates composition of the functions passed in.\n\n    :param fs: One-argument functions, with the possible exception of last one\n               that can accept arbitrary arguments\n\n    :return: Function returning a result of functions from ``fs``\n             applied consecutively to the argument(s), in reverse order\n    \"\"\"\n    ensure_argcount(fs, min_=1)\n    fs = list(imap(ensure_callable, fs))\n\n    if len(fs) == 1:\n        return fs[0]\n    if len(fs) == 2:\n        f1, f2 = fs\n        return lambda *args, **kwargs: f1(f2(*args, **kwargs))\n    if len(fs) == 3:\n        f1, f2, f3 = fs\n        return lambda *args, **kwargs: f1(f2(f3(*args, **kwargs)))\n\n    fs.reverse()\n\n    def g(*args, **kwargs):\n        x = fs[0](*args, **kwargs)\n        for f in fs[1:]:\n            x = f(x)\n        return x\n\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge(arg, *rest, **kwargs):\n    ensure_keyword_args(kwargs, optional=('default',))\n\n    has_default = 'default' in kwargs\n    if has_default:\n        default = ensure_callable(kwargs['default'])\n\n    # if more than one argument was given, they must all be functions;\n    # result will be a function that takes multiple arguments (rather than\n    # a single collection) and returns a tuple\n    unary_result = True\n    if rest:\n        fs = (ensure_callable(arg),) + tuple(imap(ensure_callable, rest))\n        unary_result = False\n    else:\n        fs = arg\n\n    if is_mapping(fs):\n        if has_default:\n            return lambda arg_: fs.__class__((k, fs.get(k, default)(arg_[k]))\n                                             for k in arg_)\n        else:\n            return lambda arg_: fs.__class__((k, fs[k](arg_[k]))\n                                             for k in arg_)\n    else:\n        ensure_sequence(fs)\n        if has_default:\n            # we cannot use ``izip_longest(fs, arg_, fillvalue=default)``,\n            # because we want to terminate the generator\n            # only when ``arg_`` is exhausted (not when just ``fs`` is)\n            func = lambda arg_: fs.__class__(\n                (fs[i] if i < len(fs) else default)(x)\n                for i, x in enumerate(arg_))\n        else:\n            # we cannot use ``izip(fs, arg_)`` because it would short-circuit\n            # if ``arg_`` is longer than ``fs``, rather than raising\n            # the required ``IndexError``\n            func = lambda arg_: fs.__class__(fs[i](x)\n                                             for i, x in enumerate(arg_))\n        return func if unary_result else lambda *args: func(args)", "response": "Merge a collection with functions as items into a single function\n    that takes a collection and maps its items through corresponding functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a function that returns true for given arguments iff every given function evaluates to true for those arguments.", "response": "def and_(*fs):\n    \"\"\"Creates a function that returns true for given arguments\n    iff every given function evalutes to true for those arguments.\n\n    :param fs: Functions to combine\n\n    :return: Short-circuiting function performing logical conjunction\n             on results of ``fs`` applied to its arguments\n    \"\"\"\n    ensure_argcount(fs, min_=1)\n    fs = list(imap(ensure_callable, fs))\n\n    if len(fs) == 1:\n        return fs[0]\n    if len(fs) == 2:\n        f1, f2 = fs\n        return lambda *args, **kwargs: (\n            f1(*args, **kwargs) and f2(*args, **kwargs))\n    if len(fs) == 3:\n        f1, f2, f3 = fs\n        return lambda *args, **kwargs: (\n            f1(*args, **kwargs) and f2(*args, **kwargs) and f3(*args, **kwargs))\n\n    def g(*args, **kwargs):\n        for f in fs:\n            if not f(*args, **kwargs):\n                return False\n        return True\n\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving a model in the registry", "response": "def save_model(self, name, datapackage_url, datapackage,\n                   model, dataset_name, author, status, loaded):\n        \"\"\"\n        Save a model in the registry\n        :param name: name for the model\n        :param datapackage_url: origin URL for the datapackage which is the\n            source for this model\n        :param datapackage: datapackage object from which this model was\n            derived\n        :param dataset_name: Title of the dataset\n        :param author: Author of the dataset\n        :param model: model to save\n        :param status: What's the status for loading\n        :param loaded: Was the package loaded successfully\n        \"\"\"\n        document = {\n            # Fields used by babbage API\n            'id': name,\n            'model': model,\n            'package': datapackage,\n            'origin_url': datapackage_url,\n\n            # Extra fields available in search\n            'dataset': dataset_name,\n            'author': author,\n            'loading_status': status,\n            'loaded': loaded,\n            'last_update': time.time()\n        }\n        self.es.index(index=self.index_name, doc_type=self.DOC_TYPE,\n                      body=document, id=name)\n        # Make sure that the data is saved\n        self.es.indices.flush(self.index_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the model in the registry", "response": "def update_model(self, name, **kw):\n        \"\"\"\n        Update a model in the registry (create if needed)\n        :param name: name for the model\n        :param datapackage_url: origin URL for the datapackage which is the\n            source for this model\n        :param datapackage: datapackage object from which this model was\n            derived\n        :param dataset_name: Title of the dataset\n        :param author: Author of the dataset\n        :param model: model to save\n        :param status: What's the status for loading\n        :param loaded: Was the package loaded successfully\n        \"\"\"\n\n        # If `model` or `datapackage` in kw args, completely remove respective\n        # field from the ES item, so it can be replaced below (rather than\n        # merged).\n        if 'model' in kw:\n            body_remove_model = \\\n                '{\"script\" : \"ctx._source.remove(\\u0027model\\u0027)\"}'\n            self.es.update(index=self.index_name, doc_type=self.DOC_TYPE,\n                           body=body_remove_model, id=name)\n\n        if 'datapackage' in kw:\n            body_remove_datapackage = \\\n                '{\"script\" : \"ctx._source.remove(\\u0027package\\u0027)\"}'\n            self.es.update(index=self.index_name, doc_type=self.DOC_TYPE,\n                           body=body_remove_datapackage, id=name)\n\n        document = {\n            'id': name,\n            'last_update': time.time()\n        }\n        for key, param in [\n                ('model', 'model'),\n                ('package', 'datapackage'),\n                ('origin_url', 'datapackage_url'),\n                ('dataset', 'dataset_name'),\n                ('author', 'author'),\n                ('loading_status', 'status'),\n                ('loaded', 'loaded')]:\n            if param in kw:\n                document[key] = kw[param]\n\n        body = dict(\n            doc=document,\n            doc_as_upsert=True\n        )\n        self.es.update(index=self.index_name, doc_type=self.DOC_TYPE,\n                       body=body, id=name)\n        # Make sure that the data is saved\n        self.es.indices.flush(self.index_name)\n        # Clear the api cache (if api_cache isn't None)\n        try:\n            api_cache.clear(name)\n        except AttributeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a model from the registry", "response": "def delete_model(self, name):\n        \"\"\"\n        Delete a model from the registry\n        :param name: name for the model\n        \"\"\"\n        try:\n            ret = self.es.delete(index=self.index_name,\n                                 doc_type=self.DOC_TYPE, id=name)\n        except NotFoundError:\n            return False\n        # Make sure that the data is saved\n        self.es.indices.flush(self.index_name)\n        return ret['found']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_raw(self, name):\n        try:\n            ret = self.es.get(index=self.index_name, doc_type=self.DOC_TYPE,\n                              id=name, _source=self.PACKAGE_FIELDS)\n            if ret['found']:\n                source = ret['_source']\n                return (name,\n                        source.get('origin_url'),\n                        source.get('package'),\n                        source.get('model'),\n                        source.get('dataset'),\n                        source.get('author'),\n                        source.get('loading_status'),\n                        source.get('loaded', True))\n            raise KeyError(name)\n        except NotFoundError:\n            raise KeyError(name)", "response": "Get all data for a specific model in the registry"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_models(self):\n        try:\n            count = self.es.count(index=self.index_name,\n                                  doc_type=self.DOC_TYPE, q='*')['count']\n            from_ = 0\n            while from_ < count:\n                ret = self.es.search(index=self.index_name,\n                                     doc_type=self.DOC_TYPE, q='*',\n                                     size=self.BATCH_SIZE, from_=from_,\n                                     _source=self.PACKAGE_FIELDS)\n                for hit in ret.get('hits', {}).get('hits', []):\n                    yield hit['_source']['id']\n                from_ += self.BATCH_SIZE\n        except NotFoundError:\n            return", "response": "List all available models in the DB."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_stats(self):\n        try:\n            query = {\n                # We only care about the aggregations, so don't return the hits\n                'size': 0,\n                'aggs': {\n                    'num_packages': {\n                        'value_count': {\n                            'field': 'id',\n                        },\n                    },\n                    'num_records': {\n                        'sum': {\n                            'field': 'package.count_of_rows',\n                        },\n                    },\n                    'num_countries': {\n                        'cardinality': {\n                            'field': 'package.countryCode.keyword',\n                        },\n                    },\n                },\n            }\n            aggregations = self.es.search(index=self.index_name,\n                                          body=query)['aggregations']\n\n            return {\n                key: int(value['value'])\n                for key, value in aggregations.items()\n            }\n        except NotFoundError:\n            return {}", "response": "Get some stats on the packages in the registry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_model(self, name):\n        return self.es.exists(index=self.index_name,\n                              doc_type=self.DOC_TYPE, id=name)", "response": "Check if a model exists in the registry"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the model associated with a specific name. Raises KeyError if the model doesn t exist.", "response": "def get_model(self, name):\n        \"\"\"\n        Return the model associated with a specific name.\n        Raises KeyError in case the model doesn't exist.\n        :param name: model name to fetch\n        :return: Python object representing the model\n        \"\"\"\n        try:\n            ret = self.es.get(index=self.index_name, doc_type=self.DOC_TYPE,\n                              id=name, _source=self.PACKAGE_FIELDS)\n            if ret['found']:\n                return ret['_source']['model']\n            raise KeyError(name)\n        except NotFoundError:\n            raise KeyError(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a random FML post.", "response": "def cmd(send, msg, args):\n    \"\"\"Gets a random FML post.\n\n    Syntax: {command}\n\n    \"\"\"\n    req = get(\"http://api.fmylife.com/view/random\", params={'language': 'en', 'key': args['config']['api']['fmlkey']})\n    doc = fromstring(req.content)\n    send(doc.xpath('//text')[0].text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\norder the bot to leave a channel", "response": "def cmd(send, msg, args):\n    \"\"\"Orders the bot to leave a channel\n    Syntax: {command} <channel>\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('channel', nargs='+', action=arguments.ChanParser)\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    for chan in cmdargs.channels:\n        args['handler'].do_part(chan, args['nick'], args['target'], args['type'], send, args['handler'].connection)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting scores. Syntax: {command} <--high|--low|nick>", "response": "def cmd(send, msg, args):\n    \"\"\"Gets scores.\n\n    Syntax: {command} <--high|--low|nick>\n\n    \"\"\"\n    if not args['config']['feature'].getboolean('hooks'):\n        send(\"Hooks are disabled, and this command depends on hooks. Please contact the bot admin(s).\")\n        return\n    session = args['db']\n    parser = arguments.ArgParser(args['config'])\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--high', action='store_true')\n    group.add_argument('--low', action='store_true')\n    group.add_argument('nick', nargs='?', action=arguments.NickParser)\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if cmdargs.high:\n        data = session.query(Scores).order_by(Scores.score.desc()).limit(3).all()\n        send('High Scores:')\n        for x in data:\n            send(\"%s: %s\" % (x.nick, x.score))\n    elif cmdargs.low:\n        data = session.query(Scores).order_by(Scores.score).limit(3).all()\n        send('Low Scores:')\n        for x in data:\n            send(\"%s: %s\" % (x.nick, x.score))\n    elif cmdargs.nick:\n        name = cmdargs.nick.lower()\n        if name == 'c':\n            send(\"We all know you love C better than anything else, so why rub it in?\")\n            return\n        score = session.query(Scores).filter(Scores.nick == name).scalar()\n        if score is not None:\n            plural = '' if abs(score.score) == 1 else 's'\n            if name == args['botnick'].lower():\n                emote = ':)' if score.score > 0 else ':(' if score.score < 0 else ':|'\n                output = 'has %s point%s! %s' % (score.score, plural, emote)\n                send(output, 'action')\n            else:\n                send(\"%s has %i point%s!\" % (name, score.score, plural))\n        else:\n            send(\"Nobody cares about %s\" % name)\n    else:\n        if session.query(Scores).count() == 0:\n            send(\"Nobody cares about anything =(\")\n        else:\n            query = session.query(Scores).order_by(func.random()).first()\n            plural = '' if abs(query.score) == 1 else 's'\n            send(\"%s has %i point%s!\" % (query.nick, query.score, plural))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding how param src affects param dest", "response": "def add_affect(self, name, src, dest, val, condition = None ):\n        \"\"\"\n        adds how param 'src' affects param 'dest' to the list\n        \"\"\"\n        self.affects.append(ParamAffects(name, src, dest, val, condition))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_by_name(self, nme):\n        for p in self.params:\n            if p.name == nme:\n                return p\n        return None", "response": "returns the first parameter that matches the name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_affects_for_param(self, nme):\n        res = []\n        for a in self.affects:\n            if a.name == nme:\n                res.append(a)\n        return res", "response": "Searches all affects and returns a list of all affects that affect the param named nme"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the EzDnaApi64. dll file and returns a new DNA object.", "response": "def LoadDll(location):\r\n    \"\"\"\r\n    If the EzDnaApi64.dll file is not in the default location\r\n    (C:\\Program Files (x86)\\eDNA\\EzDnaApi64.dll) then the user must specify\r\n    the correct location of the file, before this module can be used.\r\n\r\n    :param location: the full location of EzDnaApi64.dll, including filename\r\n    \"\"\"\r\n    if os.path.isfile(location):\r\n        global dna_dll\r\n        dna_dll = cdll.LoadLibrary(location)\r\n    else:\r\n        raise Exception(\"ERROR- file does not exist at \" + location)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DoesIDExist(tag_name):\r\n    # the eDNA API requires that the tag_name be specified in a binary format,\r\n    # and the ctypes library must be used to create a C++ variable type.\r\n    szPoint = c_char_p(tag_name.encode('utf-8'))\r\n    result = bool(dna_dll.DoesIdExist(szPoint))\r\n    return result", "response": "Returns true if a fully - qualified site. service. tag eDNA tag exists in any of the connected services."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves data from eDNA history for a given tag.", "response": "def GetHistAvg(tag_name, start_time, end_time, period,\r\n               desc_as_label=False, label=None):\r\n    \"\"\"\r\n    Retrieves data from eDNA history for a given tag. The data will be\r\n    averaged over the specified \"period\".\r\n\r\n    :param tag_name: fully-qualified (site.service.tag) eDNA tag\r\n    :param start_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param end_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param period: in units of seconds (e.g. 10)\r\n    :param desc_as_label: use the tag description as the column name instead\r\n        of the full tag\r\n    :param label: supply a custom label to use as the DataFrame column name\r\n    :return: a pandas DataFrame with timestamp, value, and status\r\n    \"\"\"\r\n    return GetHist(tag_name, start_time, end_time, mode=\"avg\", period=period,\r\n                   desc_as_label=desc_as_label, label=label)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a pandas DataFrame with timestamp value and status for a given tag.", "response": "def GetHistRaw(tag_name, start_time, end_time, high_speed=False,\r\n               desc_as_label=False, label=None):\r\n    \"\"\"\r\n    Retrieves raw data from eDNA history for a given tag.\r\n\r\n    :param tag_name: fully-qualified (site.service.tag) eDNA tag\r\n    :param start_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param end_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param high_speed: true = pull milliseconds\r\n    :param desc_as_label: use the tag description as the column name instead\r\n        of the full tag\r\n    :param label: supply a custom label to use as the DataFrame column name\r\n    :return: a pandas DataFrame with timestamp, value, and status\r\n    \"\"\"\r\n    return GetHist(tag_name, start_time, end_time, mode=\"raw\",\r\n                   desc_as_label=desc_as_label, label=label)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves data from eDNA history for a given tag.", "response": "def GetHist(tag_name, start_time, end_time, period=5, mode=\"raw\",\r\n            desc_as_label=False, label=None, high_speed=False, utc=False):\r\n    \"\"\"\r\n    Retrieves data from eDNA history for a given tag.\r\n\r\n    :param tag_name: fully-qualified (site.service.tag) eDNA tag\r\n    :param start_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param end_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param period: specify the number of seconds for the pull interval\r\n    :param mode: \"raw\", \"snap\", \"avg\", \"interp\", \"max\", \"min\"\r\n        See eDNA documentation for more information.\r\n    :param desc_as_label: use the tag description as the column name instead\r\n        of the full tag\r\n    :param label: supply a custom label to use as the DataFrame column name\r\n    :param high_speed: if True, pull millisecond data\r\n    :param utc: if True, use the integer time format instead of DateTime\r\n    :return: a pandas DataFrame with timestamp, value, and status\r\n    \"\"\"\r\n    # Check if the point even exists\r\n    if not DoesIDExist(tag_name):\r\n        warnings.warn(\"WARNING- \" + tag_name + \" does not exist or \" +\r\n            \"connection was dropped. Try again if tag does exist.\")\r\n        return pd.DataFrame()\r\n\r\n    # Define all required variables in the correct ctypes format\r\n    szPoint = c_char_p(tag_name.encode('utf-8'))\r\n    tStart = c_long(StringToUTCTime(start_time))\r\n    tEnd = c_long(StringToUTCTime(end_time))\r\n    tPeriod = c_long(period)\r\n    pulKey = c_ulong(0)\r\n\r\n    # Initialize the data pull using the specified pulKey, which is an\r\n    # identifier that tells eDNA which data pull is occurring\r\n    mode = mode.lower().strip()\r\n    if not high_speed:\r\n        if mode == \"avg\":\r\n            nRet = dna_dll.DnaGetHistAvgUTC(szPoint, tStart, tEnd, tPeriod, byref(pulKey))\r\n        if mode == \"interp\":\r\n            nRet = dna_dll.DnaGetHistInterpUTC(szPoint, tStart, tEnd, tPeriod, byref(pulKey))\r\n        if mode == \"min\":\r\n            nRet = dna_dll.DnaGetHistMinUTC(szPoint, tStart, tEnd, tPeriod, byref(pulKey))\r\n        if mode == \"max\":\r\n            nRet = dna_dll.DnaGetHistMaxUTC(szPoint, tStart, tEnd, tPeriod, byref(pulKey))\r\n        if mode == \"snap\":\r\n            nRet = dna_dll.DnaGetHistSnapUTC(szPoint, tStart, tEnd, tPeriod, byref(pulKey))\r\n        else:\r\n            nRet = dna_dll.DnaGetHistRawUTC(szPoint, tStart, tEnd, byref(pulKey))\r\n        time_, val, stat = _GetNextHistSmallUTC(pulKey, nRet)\r\n    else:\r\n        nStartMillis = c_ushort(0)\r\n        nEndMillis = c_ushort(0)\r\n        nRet = dna_dll.DnaGetHSHistRawUTC(szPoint, tStart, nStartMillis,\r\n            tEnd, nEndMillis, byref(pulKey))\r\n        time_, val, stat = _GetNextHSHistUTC(pulKey, nRet)\r\n\r\n    # The history request must be cancelled to free up network resources\r\n    dna_dll.DnaCancelHistRequest(pulKey)\r\n\r\n    # To construct the pandas DataFrame, the tag name will be used as the\r\n    # column name, and the index (which is in the strange eDNA format) must be\r\n    # converted to an actual DateTime\r\n    d = {tag_name + ' Status': stat, tag_name: val}\r\n    df = pd.DataFrame(data=d, index=time_)\r\n    if not utc:\r\n        if not high_speed:\r\n            df.index = pd.to_datetime(df.index, unit=\"s\")\r\n        else:\r\n            df.index = pd.to_datetime(df.index, unit=\"ms\")\r\n    if df.empty:\r\n        warnings.warn('WARNING- No data retrieved for ' + tag_name + '. ' +\r\n                      'Check eDNA connection, ensure that the start time is ' +\r\n                      'not later than the end time, verify that the ' +\r\n                      'DateTime formatting matches eDNA requirements, and ' +\r\n                      'check that data exists in the query time period.')\r\n\r\n    # Check if the user would rather use the description as the column name\r\n    if desc_as_label or label:\r\n        if label:\r\n            new_label = label\r\n        else:\r\n            new_label = _GetLabel(tag_name)\r\n        df.rename(inplace=True, columns={tag_name: new_label,\r\n                  tag_name + \" Status\": new_label + \" Status\"})\r\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetMultipleTags(tag_list, start_time, end_time, sampling_rate=None,\r\n                    fill_limit=99999, verify_time=False, desc_as_label=False,\r\n                    utc=False):\r\n    \"\"\"\r\n    Retrieves raw data from eDNA history for multiple tags, merging them into\r\n    a single DataFrame, and resampling the data according to the specified\r\n    sampling_rate.\r\n\r\n    :param tag_list: a list of fully-qualified (site.service.tag) eDNA tags\r\n    :param start_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param end_time: must be in format mm/dd/yy hh:mm:ss\r\n    :param sampling_rate: in units of seconds\r\n    :param fill_limit: in units of data points\r\n    :param verify_time: verify that the time is not before or after the query\r\n    :param desc_as_label: use the tag description as the column name instead\r\n        of the full tag\r\n    :param utc: if True, use the integer time format instead of DateTime\r\n    :return: a pandas DataFrame with timestamp and values\r\n    \"\"\"\r\n    # Since we are pulling data from multiple tags, let's iterate over each\r\n    # one. For this case, we only want to pull data using the \"raw\" method,\r\n    # which will obtain all data as it is actually stored in the historian.\r\n    dfs = []\r\n    columns_names = []\r\n    for tag in tag_list:\r\n        df = GetHist(tag, start_time, end_time, utc=utc)\r\n        if not df.empty:\r\n            # Sometimes a duplicate index/value pair is retrieved from\r\n            # eDNA, which will cause the concat to fail if not removed\r\n            # df.drop_duplicates(inplace=True)\r\n            df = df[~df.index.duplicated(keep='first')]\r\n            # If the user wants to use descriptions as labels, we need to\r\n            # ensure that only unique labels are used\r\n            label = tag\r\n            if desc_as_label:\r\n                orig_label = _GetLabel(tag)\r\n                label = orig_label\r\n                rename_number = 2\r\n                while label in columns_names:\r\n                    label = orig_label + str(rename_number)\r\n                    rename_number += 1\r\n                columns_names.append(label)\r\n                df.rename(columns={tag: label}, inplace=True)\r\n            # Add the DataFrame to the list, to be concatenated later\r\n            dfs.append(pd.DataFrame(df[label]))\r\n\r\n    # Next, we concatenate all the DataFrames using an outer join (default).\r\n    # Verify integrity is slow, but it ensures that the concatenation\r\n    # worked correctly.\r\n    if dfs:\r\n        merged_df = pd.concat(dfs, axis=1, verify_integrity=True)\r\n        merged_df = merged_df.fillna(method=\"ffill\", limit=fill_limit)\r\n    else:\r\n        warnings.warn('WARNING- No data retrieved for any tags. ' +\r\n                      'Check eDNA connection, ensure that the start time is ' +\r\n                      'not later than the end time, verify that the ' +\r\n                      'DateTime formatting matches eDNA requirements, and ' +\r\n                      'check that data exists in the query time period.')\r\n        return pd.DataFrame()\r\n\r\n    # eDNA sometimes pulls data too early or too far- let's filter out all\r\n    # the data that is not within our original criteria.\r\n    if verify_time:\r\n        start_np = pd.to_datetime(start_time)\r\n        end_np = pd.to_datetime(end_time)\r\n        mask = (merged_df.index > start_np) & (merged_df.index <= end_np)\r\n        merged_df = merged_df.loc[mask]\r\n\r\n    # Finally, we resample the data at the rate requested by the user.\r\n    if sampling_rate:\r\n        sampling_string = str(sampling_rate) + \"S\"\r\n        merged_df = merged_df.resample(sampling_string).fillna(\r\n            method=\"ffill\", limit=fill_limit)\r\n    return merged_df", "response": "Retrieves raw data from eDNA history for multiple tags."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetPoints(edna_service):\r\n    # Define all required variables in the correct ctypes format\r\n    szServiceName = c_char_p(edna_service.encode('utf-8'))\r\n    nStarting, pulKey, pdValue = c_ushort(0), c_ulong(0), c_double(-9999)\r\n    szPoint, szTime = create_string_buffer(30), create_string_buffer(30)\r\n    szStatus, szDesc = create_string_buffer(20), create_string_buffer(90)\r\n    szUnits = create_string_buffer(20)\r\n    szPoint2, szTime2 = create_string_buffer(30), create_string_buffer(30)\r\n    szStatus2, szDesc2 = create_string_buffer(20), create_string_buffer(90)\r\n    szUnits2, pdValue2 = create_string_buffer(20), c_double(-9999)\r\n    nPoint, nTime, nStatus = c_ushort(30), c_ushort(30), c_ushort(20)\r\n    nDesc, nUnits = c_ushort(90), c_ushort(20)\r\n\r\n    # Call the eDNA function. nRet is zero if the function is successful.\r\n    points = []\r\n    nRet = dna_dll.DnaGetPointEntry(szServiceName, nStarting, byref(pulKey),\r\n        byref(szPoint), nPoint, byref(pdValue), byref(szTime), nTime,\r\n        byref(szStatus), nStatus, byref(szDesc), nDesc, byref(szUnits), nUnits)\r\n    tag = _FormatPoints(szPoint, pdValue, szTime, szStatus, szDesc, szUnits)\r\n    if tag:\r\n        points.append(tag)\r\n\r\n    # Iterate across all the returned services\r\n    while nRet == 0:\r\n        nRet = dna_dll.DnaGetNextPointEntry(pulKey, byref(szPoint2), nPoint,\r\n            byref(pdValue2), byref(szTime2), nTime, byref(szStatus2), nStatus,\r\n            byref(szDesc2), nDesc, byref(szUnits2), nUnits)\r\n        # We want to ensure only UTF-8 characters are returned. Ignoring\r\n        # characters is slightly unsafe, but they should only occur in the\r\n        # units or description, so it's not a huge issue.\r\n        tag = _FormatPoints(szPoint2, pdValue2, szTime2, szStatus2, szDesc2,\r\n                            szUnits2)\r\n        if tag:\r\n            points.append(tag)\r\n\r\n    # If no results were returned, raise a warning\r\n    df = pd.DataFrame()\r\n    if points:\r\n        df = pd.DataFrame(points, columns=[\"Tag\", \"Value\", \"Time\", \"Status\",\r\n                                           \"Description\", \"Units\"])\r\n    else:\r\n        warnings.warn(\"WARNING- No points were returned. Check that the \" +\r\n                      \"service exists and contains points.\")\r\n    return df", "response": "Gets all the points in the given eDNA service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the current information about a real - time interval.", "response": "def GetRTFull(tag_name):\r\n    \"\"\"\r\n    Gets current information about a point configured in a real-time\r\n    eDNA service, including current value, time, status, description,\r\n    and units.\r\n\r\n    :param tag_name: fully-qualified (site.service.tag) eDNA tag\r\n    :return: tuple of: alue, time, status, statusint, description, units\r\n    \"\"\"\r\n    # Check if the point even exists\r\n    if not DoesIDExist(tag_name):\r\n        warnings.warn(\"WARNING- \" + tag_name + \" does not exist or \" +\r\n                      \"connection was dropped. Try again if tag does exist.\")\r\n        return None\r\n\r\n    # Define all required variables in the correct ctypes format\r\n    szPoint = c_char_p(tag_name.encode('utf-8'))\r\n    pdValue, ptTime = c_double(-9999), c_long(-9999)\r\n    szValue, szTime = create_string_buffer(20), create_string_buffer(20)\r\n    szStatus, szDesc = create_string_buffer(20), create_string_buffer(20)\r\n    szUnits = create_string_buffer(20)\r\n    nValue, nTime, nStatus = c_ushort(20), c_ushort(20), c_ushort(20)\r\n    pusStatus, nDesc, nUnits = c_ushort(0), c_ushort(0), c_ushort(0)\r\n\r\n    # Call the eDNA function. nRet is zero if the function is successful\r\n    nRet = dna_dll.DNAGetRTFull(szPoint, byref(pdValue), byref(szValue),\r\n        nValue, byref(ptTime), byref(szTime), nTime, byref(pusStatus),\r\n        byref(szStatus), nStatus, byref(szDesc), nDesc, byref(szUnits), nUnits)\r\n\r\n    # Check to make sure the function returned correctly. If not, return None\r\n    if nRet == 0:\r\n        return ([pdValue.value, szTime.value.decode('utf-8'),\r\n                szStatus.value.decode('utf-8'), pusStatus.value,\r\n                szDesc.value.decode('utf-8'), szUnits.value.decode('utf-8')])\r\n    else:\r\n        warnings.warn(\"WARNING- eDNA API failed with code \" + str(nRet))\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetServices():\r\n    # Define all required variables in the correct ctypes format\r\n    pulKey = c_ulong(0)\r\n    szType = c_char_p(\"\".encode('utf-8'))\r\n    szStartSvcName = c_char_p(\"\".encode('utf-8'))\r\n    szSvcName, szSvcDesc = create_string_buffer(30), create_string_buffer(90)\r\n    szSvcType, szSvcStat = create_string_buffer(30), create_string_buffer(30)\r\n    szSvcName2, szSvcDesc2 = create_string_buffer(30), create_string_buffer(90)\r\n    szSvcType2, szSvcStat2 = create_string_buffer(30), create_string_buffer(30)\r\n    nSvcName, nSvcDesc = c_ushort(30), c_ushort(90)\r\n    nSvcType, nSvcStat = c_ushort(30), c_ushort(30)\r\n\r\n    # Call the eDNA function. nRet is zero if the function is successful.\r\n    services = []\r\n    nRet = dna_dll.DnaGetServiceEntry(szType, szStartSvcName, byref(pulKey),\r\n        byref(szSvcName), nSvcName, byref(szSvcDesc), nSvcDesc,\r\n        byref(szSvcType), nSvcType, byref(szSvcStat), nSvcStat)\r\n    serv = _FormatServices(szSvcName, szSvcDesc, szSvcType, szSvcStat)\r\n    if serv:\r\n        services.append(serv)\r\n\r\n    # Iterate across all the returned services\r\n    while nRet == 0:\r\n        nRet = dna_dll.DnaGetNextServiceEntry(pulKey,\r\n            byref(szSvcName2), nSvcName, byref(szSvcDesc2), nSvcDesc,\r\n            byref(szSvcType2), nSvcType, byref(szSvcStat2), nSvcStat)\r\n        # We want to ensure only UTF-8 characters are returned. Ignoring\r\n        # characters is slightly unsafe, but they should only occur in the\r\n        # units or description, so it's not a huge issue.\r\n        serv = _FormatServices(szSvcName2, szSvcDesc2, szSvcType2, szSvcStat2)\r\n        if serv:\r\n            services.append(serv)\r\n\r\n    # If no results were returned, raise a warning\r\n    df = pd.DataFrame()\r\n    if services:\r\n        df = pd.DataFrame(services, columns=[\"Name\", \"Description\", \"Type\",\r\n                                             \"Status\"])\r\n    else:\r\n        warnings.warn(\"WARNING- No connected eDNA services detected. Check \" +\r\n                      \"your DNASys.ini file and your network connection.\")\r\n    return df", "response": "Returns all the connected eDNA services in the form of a list of pandas DataFrames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the current description of a point configured in a real - time eDNA service.", "response": "def GetTagDescription(tag_name):\r\n    \"\"\"\r\n    Gets the current description of a point configured in a real-time eDNA\r\n    service.\r\n\r\n    :param tag_name: fully-qualified (site.service.tag) eDNA tag\r\n    :return: tag description\r\n    \"\"\"\r\n    # Check if the point even exists\r\n    if not DoesIDExist(tag_name):\r\n        warnings.warn(\"WARNING- \" + tag_name + \" does not exist or \" +\r\n                      \"connection was dropped. Try again if tag does exist.\")\r\n        return None\r\n\r\n    # To get the point information for the service, we need the Site.Service\r\n    split_tag = tag_name.split(\".\")\r\n    # If the full Site.Service.Tag was not supplied, return the tag_name\r\n    if len(split_tag) < 3:\r\n        warnings.warn(\"WARNING- Please supply the full Site.Service.Tag.\")\r\n        return tag_name\r\n    # The Site.Service will be the first two split strings\r\n    site_service = split_tag[0] + \".\" + split_tag[1]\r\n\r\n    # GetPoints will return a DataFrame with point information\r\n    points = GetPoints(site_service)\r\n    if tag_name in points.Tag.values:\r\n        description = points[points.Tag == tag_name].Description.values[0]\r\n        if description:\r\n            return description\r\n        else:\r\n            return tag_name\r\n    else:\r\n        warnings.warn(\"WARNING- \" + tag_name + \" not found in service.\")\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef HistAppendValues(site_service, tag_name, times, values, statuses):\r\n    # Define all required variables in the correct ctypes format\r\n    szService = c_char_p(site_service.encode('utf-8'))\r\n    szPoint = c_char_p(tag_name.encode('utf-8'))\r\n    nCount = c_ushort(1)\r\n\r\n    # Iterate over each user-supplied data point\r\n    for dttime, value, status in zip(times, values, statuses):\r\n        # Define all required variables in the correct ctypes format\r\n        PtTimeList = c_long(dttime)\r\n        PusStatusList = c_ushort(status)\r\n        PszValueList = c_char_p(str(value).encode('utf-8'))\r\n        szError = create_string_buffer(20)\r\n        nError = c_ushort(20)\r\n        # Call the history append file\r\n        nRet = dna_dll.DnaHistAppendValues(szService, szPoint,\r\n                    nCount, byref(PtTimeList), byref(PusStatusList),\r\n                    byref(PszValueList), byref(szError), nError)", "response": "Append a value to a eDNA history service."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen an eDNA point picker where the user can select a single tag.", "response": "def SelectPoint():\r\n    \"\"\"\r\n    Opens an eDNA point picker, where the user can select a single tag.\r\n\r\n    :return: selected tag name\r\n    \"\"\"\r\n    # Define all required variables in the correct ctypes format\r\n    pszPoint = create_string_buffer(20)\r\n    nPoint = c_ushort(20)\r\n    # Opens the point picker\r\n    dna_dll.DnaSelectPoint(byref(pszPoint), nPoint)\r\n    tag_result = pszPoint.value.decode('utf-8')\r\n    return tag_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef StringToUTCTime(time_string):\r\n    szTime = c_char_p(time_string.encode('utf-8'))\r\n    res = dna_dll.StringToUTCTime(szTime)\r\n    return res", "response": "Converts a DateTime string into a UTC time."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls genomes Installs genomes Installs genomes", "response": "def get_genomes(cfg):\n    \"\"\"\n    Installs genomes\n    \n    :param cfg: configuration dict\n    \"\"\"\n    if cfg['host']=='homo_sapiens':\n        contigs=['1',\n                 '2',\n                 '3',\n                 '4',\n                 '5',\n                 '6',\n                 '7',\n                 '8',\n                 '9',\n                 '10',\n                 '11',\n                 '12',\n                 '13',\n                 '14',\n                 '15',\n                 '16',\n                 '17',\n                 '18',\n                 '19',\n                 '20',\n                 '21',\n                 '22',\n                 'X','Y']\n    else:\n        runbashcmd(f\"pyensembl install --reference-name {cfg['genomeassembly']} --release {cfg['genomerelease']} --species {cfg['host']}\")\n\n        import pyensembl\n        ensembl = pyensembl.EnsemblRelease(species=pyensembl.species.Species.register(\n                                            latin_name=cfg['host'],\n                                            synonyms=[cfg['host']],\n                                            reference_assemblies={\n                                                cfg['genomeassembly']: (cfg['genomerelease'], cfg['genomerelease']),\n                                            }),release=cfg['genomerelease'])\n        contig_mito=['MTDNA','MITO','MT']\n        contigs=[c for c in ensembl.contigs() if ((not '.' in c) and (len(c)<5) and (c not in contig_mito))]    \n    if len(contigs)==0:\n        contigs=[c for c in ensembl.contigs()]\n        # logging.error([c for c in ensembl.contigs()])\n        # logging.error('no contigs identified by pyensembl; aborting')\n        # sys.exit(0)\n    logging.info(f\"{len(contigs)} contigs/chromosomes in the genome\")\n    logging.info(contigs)\n    # raw genome next\n    if 'human' in cfg['host'].lower():\n        cfg['host']='homo_sapiens'\n    if 'yeast' in cfg['host'].lower():\n        cfg['host']='saccharomyces_cerevisiae'\n    host_=\"_\".join(s for s in cfg['host'].split('_')).capitalize()\n    if 'GRCh37' in cfg['genomeassembly']:    \n        ensembl_fastad=f\"pub/grch37/update/fasta/{cfg['host']}/dna/\"\n    else:\n        ensembl_fastad=f\"pub/release-{cfg['genomerelease']}/fasta/{cfg['host']}/dna/\"        \n    genome_fastad=f\"{cfg['genomed']}/{ensembl_fastad}\"\n    cfg['genomep']=f'{genome_fastad}/genome.fa'.format()\n    if not exists(cfg['genomep']):\n        logging.error(f\"not found: {cfg['genomep']}\")\n        ifdlref = input(f\"Genome file are not there at {genome_fastad}.\\n Download?[Y/n]: \")\n        if ifdlref=='Y':\n        # #FIXME download contigs and cat and get index, sizes\n            for contig in contigs:\n                fn=f\"{cfg['host'].capitalize()}.{cfg['genomeassembly']}.dna_sm.chromosome.{contig}.fa.gz\"\n                fp=f'{ensembl_fastad}/{fn}'\n                if not exists(f\"{cfg['genomed']}{fp.replace('.gz','')}\"):\n                    if not exists(f\"{cfg['genomed']}{fp}\"):\n                        logging.info(f'downloading {fp}')\n                        cmd=f\"wget -q -x -nH ftp://ftp.ensembl.org/{fp} -P {cfg['genomed']}\"\n                        try:\n                            runbashcmd(cmd,test=cfg['test'])\n                        except:\n                            fn=f\"{cfg['host'].capitalize()}.{cfg['genomeassembly']}.dna_sm.toplevel.fa.gz\"\n                            fp='{}/{}'.format(ensembl_fastad,fn)                        \n                            if not exists(fp):\n                                cmd=f\"wget -q -x -nH ftp://ftp.ensembl.org/{fp} -P {cfg['genomed']}\"\n                                # print(cmd)\n                                runbashcmd(cmd,test=cfg['test'])\n                                break\n                #                 break\n            # make the fa ready\n            if not exists(cfg['genomep']):\n                cmd=f\"gunzip {genome_fastad}*.fa.gz;cat {genome_fastad}/*.fa > {genome_fastad}/genome.fa;\"\n                runbashcmd(cmd,test=cfg['test'])\n        else:\n            logging.error('abort')\n            sys.exit(1)\n    if not exists(cfg['genomep']+'.bwt'):\n        cmd=f\"{cfg['bwa']} index {cfg['genomep']}\"\n        runbashcmd(cmd,test=cfg['test'])\n    else:        \n        logging.info('bwa index is present')\n    if not exists(cfg['genomep']+'.fai'):\n        cmd=f\"{cfg['samtools']} faidx {cfg['genomep']}\"\n        runbashcmd(cmd,test=cfg['test'])\n    else:\n        logging.info('samtools index is present')\n    if not exists(cfg['genomep']+'.sizes'):\n        cmd=f\"cut -f1,2 {cfg['genomep']}.fai > {cfg['genomep']}.sizes\"            \n        runbashcmd(cmd,test=cfg['test'])\n    else:\n        logging.info('sizes of contigs are present')\n\n    if 'GRCh37' in cfg['genomeassembly']:    \n#     ftp://ftp.ensembl.org/pub/grch37/update/gff3/homo_sapiens/Homo_sapiens.GRCh37.87.gff3.gz\n        ensembl_gff3d=f\"pub/grch37/update/gff3/{cfg['host']}/\"    \n    else:\n        ensembl_gff3d=f\"pub/release-{cfg['genomerelease']}/gff3/{cfg['host']}/\"    \n    \n    genome_gff3d=f\"{cfg['genomed']}/{ensembl_gff3d}\"\n    cfg['genomegffp']=f'{genome_gff3d}/genome.gff3'\n    if not exists(cfg['genomegffp']):\n        logging.error('not found: {}'.format(cfg['genomegffp']))\n        ifdlref = input(\"Download genome annotations at {}?[Y/n]: \".format(genome_gff3d))\n        if ifdlref=='Y':\n        # #FIXME download contigs and cat and get index, sizes\n            fn=f\"{cfg['host'].capitalize()}.{cfg['genomeassembly']}.{cfg['genomerelease']}.gff3.gz\"\n            fp=f\"{ensembl_gff3d}/{fn}\"\n            if not exists(fp):\n                cmd=f\"wget -x -nH ftp://ftp.ensembl.org/{fp} -P {cfg['genomed']}\"\n                runbashcmd(cmd,test=cfg['test'])\n            # move to genome.gff3\n                cmd=f\"cp {genome_gff3d}/{fn} {cfg['genomegffp']}\"\n                runbashcmd(cmd,test=cfg['test'])\n\n        else:\n            logging.error('abort')\n            sys.exit(1)\n    logging.info('genomes are installed!')\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting a date from a given string.", "response": "def extractDate(text):\n    \"\"\" Tries to extract a date from a given :obj:`str`.\n\n        :param str text: Input date. A :obj:`datetime.date` object is passed\n             thought without modification.\n        :rtype: :obj:`datetime.date`\"\"\"\n    if type(text) is datetime.date:\n        return text\n    match = date_format.search(text.lower())\n    if not match:\n        raise ValueError('unsupported date format: {0}'.format(text.lower()))\n    # convert DD.MM.YYYY into YYYY-MM-DD\n    if match.group('month'):\n        if not match.group('month') in month_names:\n            raise ValueError('unknown month names: \"{0}\"'\n                             .format(match.group('month')))\n        year = int(match.group('year'))\n        return datetime.date(\n            year if year > 2000 else 2000 + year,\n            int(month_names[match.group('month')]),\n            int(match.group('day')))\n    else:\n        parts = list(map(lambda v: int(v), '-'.join(reversed(\n            match.group('datestr').split('.'))).split('-')))\n        if parts[0] < 2000:\n            parts[0] += 2000\n        return datetime.date(*parts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convertPrice(variant, regex=None, short_regex=None, none_regex=none_price_regex):\n    ''' Helper function to convert the given input price into integers (cents\n        count). :obj:`int`, :obj:`float` and :obj:`str` are supported\n\n        :param variant: Price\n        :param re.compile regex: Regex to convert str into price. The re should\n             contain two named groups `euro` and `cent`\n        :param re.compile short_regex: Short regex version (no cent part)\n             group `euro` should contain a valid integer.\n        :param re.compile none_regex: Regex to detect that no value is provided\n             if the input data is str, the normal regex do not match and this\n             regex matches `None` is returned.\n        :rtype: int/None'''\n    if isinstance(variant, int) and not isinstance(variant, bool):\n        return variant\n    elif isinstance(variant, float):\n        return round(variant * 100)\n    elif isinstance(variant, str):\n        match = (regex or default_price_regex).search(variant) \\\n            or (short_regex or short_price_regex).match(variant)\n        if not match:\n            if none_regex and none_regex.match(variant):\n                return None\n            raise ValueError('Could not extract price: {0}'.format(variant))\n        return int(match.group('euro')) * 100 + \\\n            int(match.groupdict().get('cent', '').ljust(2, '0'))\n    else:\n        raise TypeError('Unknown price type: {0!r}'.format(variant))", "response": "Helper function to convert the given price into integers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buildPrices(data, roles=None, regex=default_price_regex,\n                default=None, additional={}):\n    ''' Create a dictionary with price information. Multiple ways are\n        supported.\n\n        :rtype: :obj:`dict`: keys are role as str, values are the prices as\n             cent count'''\n    if isinstance(data, dict):\n        data = [(item[0], convertPrice(item[1])) for item in data.items()]\n        return dict([v for v in data if v[1] is not None])\n    elif isinstance(data, (str, float, int)) and not isinstance(data, bool):\n        if default is None:\n            raise ValueError('You have to call setAdditionalCharges '\n                             'before it is possible to pass a string as price')\n        basePrice = convertPrice(data)\n        if basePrice is None:\n            return {}\n        prices = {default: basePrice}\n        for role in additional:\n            extraCharge = convertPrice(additional[role])\n            if extraCharge is None:\n                continue\n            prices[role] = basePrice + extraCharge\n        return prices\n    elif roles:\n        prices = {}\n        priceRoles = iter(roles)\n        for priceData in data:\n            price = convertPrice(priceData)\n            if price is None:\n                continue\n            prices[next(priceRoles)] = price\n        return prices\n    else:\n        raise TypeError('This type is for prices not supported!')", "response": "Create a dictionary with price information. Multiple ways are\n        supported."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef buildLegend(legend=None, text=None, regex=None, key=lambda v: v):\n    ''' Helper method to build or extend a legend from a text. The given regex\n        will be used to find legend inside the text.\n\n        :param dict legend: Initial legend data\n        :param str text: Text from which should legend information extracted.\n            None means do no extraction.\n        :param str regex: Regex to find legend part inside the given text. The\n            regex should have a named group `name` (key) and a named group\n            `value` (value).\n        :param callable key: function to map the key to a legend key\n        :rtype: dict'''\n    if legend is None:\n        legend = {}\n    if text is not None:\n        for match in re.finditer(regex or default_legend_regex,\n                                 text, re.UNICODE):\n            legend[key(match.group('name'))] = match.group('value').strip()\n    return legend", "response": "Helper method to build or extend a legend from a text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extractNotes(name, notes, legend=None, regex=None, key=lambda v: v):\n    ''' This functions uses legend data to extract e.g. (1) references in a\n        meal name and add these in full text to the notes.\n\n        :param str name: The meal name\n        :param list notes: The initial list of notes for this meal\n        :param dict legend: The legend data. Use `None` to skip extraction. The\n            key is searched inside the meal name (with the given regex) and if\n            found the value is added to the notes list.\n        :param re.compile regex: The regex to find legend references in the\n            meal name. The regex must have exactly one group which identifies\n            the key in the legend data. If you pass None the\n            :py:data:`default_extra_regex` is used. Only compiled regex are\n            supported.\n        :param callable key: function to map the key to a legend key\n        :rtype: tuple with name and notes'''\n    if legend is None:\n        return name, notes\n    if regex is None:\n        regex = default_extra_regex\n    # extract note\n    for note in list(','.join(regex.findall(name)).split(',')):\n        if not note:\n            continue\n        note = key(note)\n        if note in legend:\n            if legend[note] not in notes:\n                notes.append(legend[note])\n        else:\n            print('could not find extra note \"{0}\"'.format(note))\n    # from notes from name\n    name = regex.sub('', name).replace('\\xa0', ' ').replace('  ', ' ').strip()\n    return name, notes", "response": "This function extracts the notes from the given meal name and adds them to the list of notes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving all stored information about this date.", "response": "def clearDay(self, date):\n        \"\"\" Remove all stored information about this date (meals or closed\n            information).\n\n            :param date: Date of the day\n            :type date: datetime.date\"\"\"\n        date = self._handleDate(date)\n        if date in self._days:\n            del self._days[date]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether the day has meals for the given date.", "response": "def hasMealsFor(self, date):\n        \"\"\" Checks whether for this day are information stored.\n\n            :param date: Date of the day\n            :type date: datetime.date\n            :rtype: bool\"\"\"\n        date = self._handleDate(date)\n        if date not in self._days or self._days[date] is False:\n            return False\n        return len(self._days[date]) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toXMLFeed(self):\n        feed = self.toXML()\n\n        xml_header = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n        return xml_header + feed.toprettyxml(indent='  ')", "response": "Convert this cateen information into string\n            which is a valid OpenMensa v2 xml feed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toTag(self, output):\n        ''' This methods adds all data of this canteen as canteen xml tag\n        to the given xml Document.\n\n        :meth:`toXMLFeed` uses this method to create the XML Feed. So there is\n        normally no need to call it directly.\n\n        :param output: XML Document to which the data should be added\n        :type output: xml.dom.DOMImplementation.createDocument\n        '''\n        # create canteen tag, which represents our data\n        canteen = output.createElement('canteen')\n        if self._name is not None:\n            canteen.appendChild(self._buildStringTag('name', self._name, output))\n        if self._address is not None:\n            canteen.appendChild(self._buildStringTag('address', self._address, output))\n        if self._city is not None:\n            canteen.appendChild(self._buildStringTag('city', self._city, output))\n        if self._phone is not None:\n            canteen.appendChild(self._buildStringTag('phone', self._phone, output))\n        if self._email is not None:\n            canteen.appendChild(self._buildStringTag('email', self._email, output))\n        if self._location is not None:\n            canteen.appendChild(self._buildLocationTag(self._location, output))\n        if self._availability is not None:\n            canteen.appendChild(self._buildStringTag('availability', self._availability, output))\n        # iterate above all feeds:\n        for feed in sorted(self.feeds, key=lambda v: v.priority):\n            canteen.appendChild(feed.toTag(output))\n        # iterate above all days (sorted):\n        for date in sorted(self._days.keys()):\n            day = output.createElement('day')\n            day.setAttribute('date', str(date))\n            if self._days[date] is False:  # canteen closed\n                closed = output.createElement('closed')\n                day.appendChild(closed)\n                canteen.appendChild(day)\n                continue\n            # canteen is open\n            for categoryname in self._days[date]:\n                day.appendChild(self._buildCategoryTag(\n                    categoryname, self._days[date][categoryname], output))\n            canteen.appendChild(day)\n        return canteen", "response": "This method adds all data of this canteen object as canteen xml tag which represents our data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addMeal(self, date, category, name, notes=None, prices=None,\n                roles=None):\n        \"\"\" Same as :py:meth:`.BaseBuilder.addMeal` but uses\n            helper functions to convert input parameters into needed types.\n            Meals names are auto-shortend to the allowed 250 characters.\n            The following paramer is new:\n\n            :param roles:  Is passed as role parameter to :func:`buildPrices`\n            \"\"\"\n        if self.legendData:  # do legend extraction\n            name, notes = extractNotes(name, notes or [],\n                                       legend=self.legendData,\n                                       key=self.legendKeyFunc,\n                                       regex=self.extra_regex)\n        prices = buildPrices(prices or {}, roles,\n                             default=self.additionalCharges[0],\n                             additional=self.additionalCharges[1])\n        if len(name) > 250:\n            name = name[:247] + '...'\n        super(LazyBuilder, self).addMeal(extractDate(date), category, name,\n                                         notes or [], prices)", "response": "Add a new Meal to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, X, y):\n\n        X = np.array(X, dtype=np.float32)\n        y = np.array(y, dtype=np.float32)\n        assert X.shape[0] == y.shape[0]\n\n        return X, y", "response": "Fits the given model to the data and labels provided."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an existing session to a Word report.", "response": "def add_session(\n        self,\n        session,\n        input_dataset=True,\n        summary_table=True,\n        recommendation_details=True,\n        recommended_model=True,\n        all_models=False,\n    ):\n        \"\"\"\n        Add an existing session to a Word report.\n\n        Parameters\n        ----------\n        session : bmds.Session\n            BMDS session to be included in reporting\n        input_dataset : bool\n            Include input dataset data table\n        summary_table : bool\n            Include model summary table\n        recommendation_details : bool\n            Include model recommendation details table\n        recommended_model : bool\n            Include the recommended model output and dose-response plot, if\n            one exists\n        all_models : bool\n            Include all models output and dose-response plots\n\n        Returns\n        -------\n        None.\n        \"\"\"\n\n        self.doc.add_paragraph(session.dataset._get_dataset_name(), self.styles.header_1)\n        self.doc.add_paragraph(\"BMDS version: {}\".format(session.version_pretty))\n\n        if input_dataset:\n            self._add_dataset(session)\n            self.doc.add_paragraph()\n\n        if summary_table:\n            self._add_session_summary_table(session)\n            self.doc.add_paragraph()\n\n        if recommendation_details:\n            self._add_recommendation_details_table(session)\n            self.doc.add_paragraph()\n\n        if recommended_model and all_models:\n            self._add_recommended_model(session)\n            self._add_all_models(session, except_recommended=True)\n            self.doc.add_paragraph()\n        elif recommended_model:\n            self._add_recommended_model(session)\n            self.doc.add_paragraph()\n        elif all_models:\n            self._add_all_models(session, except_recommended=False)\n            self.doc.add_paragraph()\n\n        self.doc.add_page_break()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename):\n        self.doc.save(os.path.expanduser(filename))", "response": "Save the document to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the most recent modeling session for a given table.", "response": "def _get_session_for_table(self, base_session):\n        \"\"\"\n        Only present session for modeling when doses were dropped if it's succesful;\n        otherwise show the original modeling session.\n        \"\"\"\n        if base_session.recommended_model is None and base_session.doses_dropped > 0:\n            return base_session.doses_dropped_sessions[0]\n        return base_session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_driver_simulated(self):\n        self._device_dict[\"servermain.MULTIPLE_TYPES_DEVICE_DRIVER\"] = \"Simulator\"\n        if self._is_sixteen_bit:\n            self._device_dict[\"servermain.DEVICE_MODEL\"] = 0\n        else:\n            self._device_dict[\"servermain.DEVICE_MODEL\"] = 1\n        self._device_dict[\"servermain.DEVICE_ID_OCTAL\"] = 1", "response": "Sets the device driver type to simulated"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an array of TagGroup objects in the Kepware device", "response": "def parse_tag_groups(self):\n        \"\"\"Gets an array of TagGroup objects in the Kepware device\"\"\"\n        tag_groups = []\n        if 'tag_groups' not in self._device_dict:\n            return tag_groups\n        to_remove = []\n        for tag_group in self._device_dict['tag_groups']:\n            if tag_group['common.ALLTYPES_NAME'] in self._ignore_list:\n                to_remove.append(tag_group)\n                continue\n            tag_groups.append(TagGroup(tag_group))\n        for removable in to_remove:\n            self._device_dict['tag_groups'].remove(removable)\n\n        return tag_groups"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the dictionary of the device", "response": "def update(self):\n        \"\"\"Updates the dictionary of the device\"\"\"\n        if \"tag_groups\" not in self._device_dict:\n            return\n        for group in self.tag_groups:\n            group.update()\n        for i in range(len(self._device_dict[\"tag_groups\"])):\n            tag_group_dict = self._device_dict[\"tag_groups\"][i]\n            for group in self.tag_groups:\n                if group.name == tag_group_dict[\"common.ALLTYPES_NAME\"]:\n                    self._device_dict[\"tag_groups\"][i] = group.as_dict()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddAnalogShortIdRecordNoStatus(site_service, tag, time_value, value):\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szPointId = c_char_p(tag.encode('utf-8'))\n    tTime = c_long(int(time_value))\n    dValue = c_double(value)\n\n    # Try to push the data. Function will return 0 if successful.\n    nRet = dnaserv_dll.DnaAddAnalogShortIdRecordNoStatus(szService, szPointId,\n                                                         tTime, dValue)\n    return nRet", "response": "This function will add an analog value to the specified eDNA service and tag without an associated point status."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddDigitalShortIdRecord(site_service, tag, time_value, value,\n    status_string=\"OK              \", warn=False, chattering=False,\n    unreliable=False, manual=False):\n    \"\"\"\n    This function will add a digital value to the specified eDNA service and\n    tag, including all default point status definitions.\n\n    :param site_service: The site.service where data will be pushed\n    :param tag: The eDNA tag to push data. Tag only (e.g. ADE1CA01)\n    :param time_value: The time of the point, which MUST be in UTC Epoch\n                format. For example, \"1483926416\" not \"2016/01/01 01:01:01\".\n    :param value: should be either TRUE or FALSE\n    :param status_string: a string that must be EXACTLY 16 characters\n    :param warn: TRUE if the point is in a warning state\n    :param chattering: TRUE if the point is in a chattering state\n    :param unreliable: TRUE if the point is in an unreliable state\n    :param manual: TRUE if the point was manually set\n    :return: 0, if the data push is successful\n    \"\"\"\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szPointId = c_char_p(tag.encode('utf-8'))\n    tTime = c_long(int(time_value))\n    # TODO- check if the string is exactly 16 characters and convert\n    szStatus = create_string_buffer(status_string.encode('utf-8'))\n    bSet = c_int(int(value))\n    bDigitalWarning = c_int(int(warn))\n    bDigitalChattering = c_int(int(chattering))\n    bUnreliable = c_int(int(unreliable))\n    bManual = c_int(int(manual))\n\n    # Try to push the data. Function will return 0 if successful.\n    nRet = dnaserv_dll.DnaAddDigitalShortIdRecord(szService, szPointId,\n                tTime, bSet, szStatus, bDigitalWarning, bDigitalChattering,\n                bUnreliable, bManual)\n    return nRet", "response": "This function will add a digital value to the specified eDNA service and tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddAnalogShortIdMsecRecord(site_service, tag, time_value, msec, value,\n    low_warn=False, high_warn=False, low_alarm=False, high_alarm=False,\n    oor_low=False, oor_high=False, unreliable=False, manual=False):\n    \"\"\"\n    This function will add an analog value to the specified eDNA service and\n    tag, with many optional status definitions.\n\n    :param site_service: The site.service where data will be pushed\n    :param tag: The eDNA tag to push data. Tag only (e.g. ADE1CA01)\n    :param time_value: The time of the point, which MUST be in UTC Epoch\n                format. For example, \"1483926416\" not \"2016/01/01 01:01:01\".\n    :param msec: The additional milliseconds for the time_value\n    :param value: The value associated with the above time.\n    :param low_warn: TRUE if the point is in a low warning state\n    :param high_warn: TRUE if the point is in a high warning state\n    :param low_alarm: TRUE if the point is in a low alarm state\n    :param high_alarm: TRUE if the point is in a high alarm state\n    :param oor_low: TRUE if the point is out-of-range low\n    :param oor_high: TRUE if the point is out-of-range high\n    :param unreliable: TRUE if the point is unreliable\n    :param manual: TRUE if the point is manually set\n    :return: 0, if the data push is successful\n    \"\"\"\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szPointId = c_char_p(tag.encode('utf-8'))\n    tTime = c_long(int(time_value))\n    dValue = c_double(value)\n    bLowWarning = c_int(int(low_warn))\n    bHighWarning = c_int(int(high_warn))\n    bLowAlarm = c_int(int(low_alarm))\n    bHighAlarm = c_int(int(high_alarm))\n    bOutOfRangeLow = c_int(int(oor_low))\n    bOutOfRangeHigh = c_int(int(oor_high))\n    bUnReliable = c_int(int(unreliable))\n    bManual = c_int(int(manual))\n    usMsec = c_ushort(msec)\n\n    # Try to push the data. Function will return 0 if successful.\n    nRet = dnaserv_dll.DnaAddAnalogShortIdMsecRecord(szService, szPointId,\n                tTime, dValue, bLowWarning, bHighWarning, bLowAlarm,\n                bHighAlarm, bOutOfRangeLow, bOutOfRangeHigh, bUnReliable,\n                bManual, usMsec)\n    return nRet", "response": "This function will add an analog value to the specified eDNA service and tag."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AddAnalogShortIdMsecRecordNoStatus(site_service, tag, time_value, msec,\n                                       value):\n    \"\"\"\n    This function will add an analog value to the specified eDNA service and\n    tag, without an associated point status.\n\n    :param site_service: The site.service where data will be pushed\n    :param tag: The eDNA tag to push data. Tag only (e.g. ADE1CA01)\n    :param time_value: The time of the point, which MUST be in UTC Epoch\n                format. For example, \"1483926416\" not \"2016/01/01 01:01:01\".\n    :param msec: The additional milliseconds for the time_value\n    :param value: The value associated with the above time.\n    :return: 0, if the data push is successful\n    \"\"\"\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szPointId = c_char_p(tag.encode('utf-8'))\n    tTime = c_long(int(time_value))\n    dValue = c_double(value)\n    usMsec = c_ushort(msec)\n\n    # Try to push the data. Function will return 0 if successful.\n    nRet = dnaserv_dll.DnaAddAnalogShortIdMsecRecordNoStatus(szService,\n                szPointId, tTime, dValue, usMsec)\n    return nRet", "response": "This function will add an analog value to the specified eDNA service and tag without an associated point status."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddDigitalShortIdMsecRecord(site_service, tag, time_value, msec,\n    value, status_string=\"OK              \", warn=False, chattering=False,\n    unreliable=False, manual=False):\n    \"\"\"\n    This function will add a digital value to the specified eDNA service and\n    tag, including all default point status definitions.\n\n    :param site_service: The site.service where data will be pushed\n    :param tag: The eDNA tag to push data. Tag only (e.g. ADE1CA01)\n    :param time_value: The time of the point, which MUST be in UTC Epoch\n                format. For example, \"1483926416\" not \"2016/01/01 01:01:01\".\n    :param msec: The additional milliseconds for the time_value\n    :param value: should be either TRUE or FALSE\n    :param status_string: a string that must be EXACTLY 16 characters\n    :param warn: TRUE if the point is in a warning state\n    :param chattering: TRUE if the point is in a chattering state\n    :param unreliable: TRUE if the point is in an unreliable state\n    :param manual: TRUE if the point was manually set\n    :return: 0, if the data push is successful\n    \"\"\"\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szPointId = c_char_p(tag.encode('utf-8'))\n    tTime = c_long(int(time_value))\n    szStatus = create_string_buffer(status_string.encode('utf-8'))\n    bSet = c_int(int(value))\n    bDigitalWarning = c_int(int(warn))\n    bDigitalChattering = c_int(int(chattering))\n    bUnreliable = c_int(int(unreliable))\n    bManual = c_int(int(manual))\n    usMsec = c_ushort(msec)\n\n    # Try to push the data. Function will return 0 if successful.\n    nRet = dnaserv_dll.DnaAddDigitalShortIdMsecRecord(szService, szPointId,\n                tTime, bSet, szStatus, bDigitalWarning, bDigitalChattering,\n                bUnreliable, bManual, usMsec)\n    return nRet", "response": "This function will add a digital value to the specified eDNA service and tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflushing all the queued records.", "response": "def FlushShortIdRecords(site_service):\n    \"\"\"\n    Flush all the queued records.\n\n    :param site_service: The site.service where data was pushed\n    :return: message whether function was successful\n    \"\"\"\n    # Define all required variables in the correct ctypes format\n    szService = c_char_p(site_service.encode('utf-8'))\n    szMessage = create_string_buffer(b\"                    \")\n    nMessage = c_ushort(20)\n\n    # Try to flush the data. Function will return message regarding success.\n    nRet = dnaserv_dll.DnaFlushShortIdRecords(szService, byref(szMessage),\n                                              nMessage)\n    return str(nRet) + szMessage.value.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndefines the remote scheduler which will connect to the remote scheduler.", "response": "def set_scheduler(self, host, username='root', password=None, private_key=None, private_key_pass=None):\n        \"\"\"\n        Defines the remote scheduler\n\n        Args:\n            host (str): the hostname or ip address of the remote scheduler\n            username (str, optional): the username used to connect to the remote scheduler. Default is 'root'\n            password (str, optional): the password for username on the remote scheduler. Either the password or the private_key must be defined. Default is None.\n            private_key (str, optional): the path to the private ssh key used to connect to the remote scheduler. Either the password or the private_key must be defined. Default is None.\n            private_key_pass (str, optional): the passphrase for the private_key. Default is None.\n\n        Returns:\n            An RemoteClient representing the remote scheduler.\n        \"\"\"\n        self._remote = RemoteClient(host, username, password, private_key, private_key_pass)\n        self._remote_id = uuid.uuid4().hex"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_cwd(fn):\n        def wrapped(self, *args, **kwargs):\n            log.info('Calling function: %s with args=%s', fn, args if args else [])\n            cwd = os.getcwd()\n            log.info('Saved cwd: %s', cwd)\n            os.chdir(self._cwd)\n            log.info('Changing working directory to: %s', self._cwd)\n            try:\n                return fn(self, *args, **kwargs)\n            finally:\n                os.chdir(cwd)\n                log.info('Restored working directory to: %s', cwd)\n\n        return wrapped", "response": "Decorator to set the specified working directory to execute the function and then restore the previous cwd."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a job from the job queue or from being executed.", "response": "def remove(self, options=[], sub_job_num=None):\n        \"\"\"Removes a job from the job queue, or from being executed.\n\n        Args:\n            options (list of str, optional): A list of command line options for the condor_rm command. For\n                details on valid options see: http://research.cs.wisc.edu/htcondor/manual/current/condor_rm.html.\n                Defaults to an empty list.\n            job_num (int, optional): The number of sub_job to remove rather than the whole cluster. Defaults to None.\n\n        \"\"\"\n        args = ['condor_rm']\n        args.extend(options)\n        job_id = '%s.%s' % (self.cluster_id, sub_job_num) if sub_job_num else str(self.cluster_id)\n        args.append(job_id)\n        out, err = self._execute(args)\n        return out,err"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans up and closes connection to remote server if defined.", "response": "def close_remote(self):\n        \"\"\"Cleans up and closes connection to remote server if defined.\n\n        \"\"\"\n        if self._remote:\n            try:\n                # first see if remote dir is still there\n                self._remote.execute('ls %s' % (self._remote_id,))\n                if self.status != 'Completed':\n                    self.remove()\n                self._remote.execute('rm -rf %s' % (self._remote_id,))\n            except RuntimeError:\n                pass\n            self._remote.close()\n            del self._remote"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gini_impurity(s):\n    return 1 - sum(prop(s[i], s)**2 for i in range(len(s)))", "response": "Calculate the Gini Impurity for a list of samples."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the Entropy Impurity for a list of samples.", "response": "def entropy(s):\n    \"\"\"Calculate the Entropy Impurity for a list of samples.\n    \"\"\"\n    return -sum(\n        p*np.log(p) for i in range(len(s)) for p in [prop(s[i], s)]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_status(self, sub_job_num=None):\n        job_id = '%s.%s' % (self.cluster_id, sub_job_num) if sub_job_num else str(self.cluster_id)\n        format = ['-format', '\"%d\"', 'JobStatus']\n        cmd = 'condor_q {0} {1} && condor_history {0} {1}'.format(job_id, ' '.join(format))\n        args = [cmd]\n        out, err = self._execute(args, shell=True, run_in_job_dir=False)\n        if err:\n            log.error('Error while updating status for job %s: %s', job_id, err)\n            raise HTCondorError(err)\n        if not out:\n            log.error('Error while updating status for job %s: Job not found.', job_id)\n            raise HTCondorError('Job not found.')\n\n        out = out.replace('\\\"', '').split('\\n')\n\n\n        status_code = 0\n        for status_code_str in out:\n            try:\n                status_code = int(status_code_str.strip())\n            except:\n                pass\n\n        log.info('Job %s status: %d', job_id, status_code)\n\n        key = CONDOR_JOB_STATUSES[status_code]\n\n        return key", "response": "Gets the workflow status."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_statuses(self, sub_job_num=None):\n        # initialize status dictionary\n        status_dict = dict()\n\n        for val in CONDOR_JOB_STATUSES.values():\n            status_dict[val] = 0\n\n        for node in self.node_set:\n            job = node.job\n            try:\n                job_status = job.status\n                status_dict[job_status] += 1\n            except (KeyError, HTCondorError):\n                status_dict['Unexpanded'] += 1\n\n        return status_dict", "response": "Update statuses of jobs in workflow."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_node_ids(self, sub_job_num=None):\n        # Build condor_q and condor_history commands\n        dag_id = '%s.%s' % (self.cluster_id, sub_job_num) if sub_job_num else str(self.cluster_id)\n        job_delimiter = '+++'\n        attr_delimiter = ';;;'\n\n        format = [\n            '-format', '\"%d' + attr_delimiter + '\"', 'ClusterId',\n            '-format', '\"%v' + attr_delimiter + '\"', 'Cmd',\n            '-format', '\"%v' + attr_delimiter + '\"', 'Args',     # Old way\n            '-format', '\"%v' + job_delimiter + '\"', 'Arguments'  # New way\n        ]\n        # Get ID, Executable, and Arguments for each job that is either started to be processed or finished in the workflow\n        cmd = 'condor_q -constraint DAGManJobID=={0} {1} && condor_history -constraint DAGManJobID=={0} {1}'.format(dag_id, ' '.join(format))\n\n        # 'condor_q -constraint DAGManJobID==1018 -format \"%d\\n\" ClusterId -format \"%s\\n\" CMD -format \"%s\\n\" ARGS && condor_history -constraint DAGManJobID==1018 -format \"%d\\n\" ClusterId -format \"%s\\n\" CMD -format \"%s\\n\" ARGS'\n        _args = [cmd]\n        out, err = self._execute(_args, shell=True, run_in_job_dir=False)\n\n        if err:\n            log.error('Error while associating ids for jobs dag %s: %s', dag_id, err)\n            raise HTCondorError(err)\n        if not out:\n            log.warning('Error while associating ids for jobs in dag %s: No jobs found for dag.', dag_id)\n\n        try:\n            # Split into one line per job\n            jobs_out = out.split(job_delimiter)\n\n            # Match node to cluster id using combination of cmd and arguments\n            for node in self._node_set:\n                job = node.job\n\n                # Skip jobs that already have cluster id defined\n                if job.cluster_id != job.NULL_CLUSTER_ID:\n                    continue\n\n                for job_out in jobs_out:\n                    if not job_out or attr_delimiter not in job_out:\n                        continue\n\n                    # Split line by attributes\n                    cluster_id, cmd, _args, _arguments = job_out.split(attr_delimiter)\n\n                    # If new form of arguments is used, _args will be 'undefined' and _arguments will not\n                    if _args == 'undefined' and _arguments != 'undefined':\n                        args = _arguments.strip()\n\n                    # If both are undefined, then there are no arguments\n                    elif _args == 'undefined' and _arguments == 'undefined':\n                        args = None\n\n                    # Otherwise, using old form and _arguments will be 'undefined' and _args will not.\n                    else:\n                        args = _args.strip()\n\n                    job_cmd = job.executable\n                    job_args = job.arguments.strip() if job.arguments else None\n\n                    if job_cmd in cmd and job_args == args:\n                        log.info('Linking cluster_id %s to job with command and arguments: %s %s', cluster_id,\n                                  job_cmd, job_args)\n                        job._cluster_id = int(cluster_id)\n                        break\n\n        except ValueError as e:\n            log.warning(str(e))", "response": "Associate Jobs with respective cluster ids."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit(self, options=[]):\n        self.complete_node_set()\n        self._write_job_file()\n\n        args = ['condor_submit_dag']\n        args.extend(options)\n        args.append(self.dag_file)\n\n        log.info('Submitting workflow %s with options: %s', self.name, args)\n        return super(Workflow, self).submit(args)", "response": "Submit the workflow to the workflow."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncatch and log any errors that arise from reimporting a module but do not die.", "response": "def safe_reload(modname: types.ModuleType) -> Union[None, str]:\n    \"\"\"Catch and log any errors that arise from reimporting a module, but do not die.\n\n    :return: None when import was successful. String is the first line of the error message\n\n    \"\"\"\n    try:\n        importlib.reload(modname)\n        return None\n    except Exception as e:\n        logging.error(\"Failed to reimport module: %s\", modname)\n        msg, _ = backtrace.output_traceback(e)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_load(modname: str) -> Union[None, str]:\n    try:\n        importlib.import_module(modname)\n        return None\n    except Exception as ex:\n        logging.error(\"Failed to import module: %s\", modname)\n        msg, _ = backtrace.output_traceback(ex)\n        return msg", "response": "Load a module and return the first line of the error message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan_and_reimport(mod_type: str) -> List[Tuple[str, str]]:\n    mod_enabled, mod_disabled = get_modules(mod_type)\n    errors = []\n    for mod in mod_enabled + mod_disabled:\n        if mod in sys.modules:\n            msg = safe_reload(sys.modules[mod])\n        else:\n            msg = safe_load(mod)\n        if msg is not None:\n            errors.append((mod, msg))\n    return errors", "response": "Scans folder for modules and reimports them if they are not already imported."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of lists of values to designate the buckets", "response": "def _ranging(self):\n        \"\"\"\n        Should be a list of values to designate the buckets\n        \"\"\"\n        agg_ranges = []\n        for i, val in enumerate(self.range_list):\n            if i == 0:\n                agg_ranges.append({\"to\": val})\n            else:\n                previous = self.range_list[i - 1]\n                agg_ranges.append({\"from\": previous, \"to\": val})\n\n            if i + 1 == len(self.range_list):\n                agg_ranges.append({\"from\": val})\n        return agg_ranges"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_random_surah(self, lang='id'):\n        # Ensure the language supported.\n        if lang not in self.SUPPORTED_LANGUAGES:\n            message = 'Currently your selected language not yet supported.'\n            raise ODOAException(message)\n        # Get random surah and construct the url.\n        rand_surah = random.randint(1, self.TOTAL_SURAH)\n        surah_url = '{base}/surah/surah_{pages}.json'.format(base=self.BASE_API,\n                                                             pages=rand_surah)\n        try:\n            response = urlopen(surah_url)                        # Fetch data from given url.\n            data = json.loads(response.read().decode('utf-8'))   # Get response and convert to dict.\n        except IOError:\n            traceback.print_exc(file=sys.stdout)\n            raise ODOAException\n        else:\n            # Get random ayat.\n            random_ayah = random.randint(1, int(data.get('count')))\n            ayah_key = 'verse_{index}'.format(index=random_ayah)\n            ayah = data['verse'][ayah_key].encode('utf-8')\n            surah_index = data.get('index')\n            surah_name = data.get('name')\n            # Get translation and sound url.\n            translation = self.__get_translation(surah=surah_index,\n                                                 ayah=ayah_key,\n                                                 lang=lang)\n            sound = self.__get_sound(surah=surah_index, ayah=random_ayah)\n            desc = '{name}:{ayah}'.format(name=surah_name, ayah=random_ayah)\n            meta = Metadata(ayah, desc, translation, sound)\n            return meta", "response": "Perform http request to get random surah.\n\n        Parameter:\n            :lang       --  String contains language code.\n\n        Return:\n            :dict       --  Paired ayat, sound, description and the translation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming http request to get translation from given surah ayah and language code.", "response": "def __get_translation(self, surah, ayah, lang):\n        \"\"\"\n        Perform http request to get translation from given surah, ayah and\n        language.\n\n        Parameter:\n            :surah      --  Surah index from API pages.\n            :ayat       --  Ayat key.\n            :lang       --  Language code.\n\n        Return:\n            :string     --  Translation from given surah and ayat.\n        \"\"\"\n        # Construct url to fetch translation data.\n        url = '{base}/translations/{lang}/{lang}_translation_{surah}.json'.format(\n            base=self.BASE_API, lang=lang, surah=int(surah)\n        )\n        try:\n            response = urlopen(url)                             # Fetch data from give url.\n            data = json.loads(response.read().decode('utf-8'))  # Get response and convert to dict.\n            translation = data['verse'][ayah]\n        except ODOAException:\n            return None\n        else:\n            return translation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the mp3 sound URL for the given surah and ayah.", "response": "def __get_sound(self, surah, ayah):\n        \"\"\"\n        Perform http request to get sound from given surah and ayah.\n\n        Parameter:\n            :surah      --  Surah index from API pages.\n            :ayat       --  Ayat key.\n\n        Return:\n            :string     --  URL for mp3 sound.\n        \"\"\"\n        # Formatting ayah with 0 leading.\n        # http://stackoverflow.com/questions/17118071/python-add-leading-zeroes-using-str-format\n        format_ayah = '{0:0>3}'.format(ayah)\n        sound_url = '{base}/sounds/{surah}/{ayah}.mp3'.format(\n            base=self.BASE_API, surah=surah, ayah=format_ayah\n        )\n        return sound_url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn county FIPS code if the object is in county mode else None.", "response": "def get_fipscode(self, obj):\n        \"\"\"County FIPS code\"\"\"\n        if obj.division.level.name == DivisionLevel.COUNTY:\n            return obj.division.code\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_statepostal(self, obj):\n        if obj.division.level.name == DivisionLevel.STATE:\n            return us.states.lookup(obj.division.code).abbr\n        elif obj.division.level.name == DivisionLevel.COUNTY:\n            return us.states.lookup(obj.division.parent.code).abbr\n        return None", "response": "Returns the state postal abbreviation if county or state else None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_polid(self, obj):\n        ap_id = obj.candidate_election.candidate.ap_candidate_id\n        if 'polid-' in ap_id:\n            return ap_id.replace('polid-', '')\n        return None", "response": "Return the polid of the AP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_polnum(self, obj):\n        ap_id = obj.candidate_election.candidate.ap_candidate_id\n        if 'polnum-' in ap_id:\n            return ap_id.replace('polnum-', '')\n        return None", "response": "Return the polnum of the APC or APC if polnum is not None."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_precinctsreporting(self, obj):\n        if obj.division.level == \\\n                obj.candidate_election.election.division.level:\n            return obj.candidate_election.election.meta.precincts_reporting\n        return None", "response": "Returns the precincts reporting if vote is top level result else None."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_precinctsreportingpct(self, obj):\n        if obj.division.level == \\\n                obj.candidate_election.election.division.level:\n            return obj.candidate_election.election.meta.precincts_reporting_pct\n        return None", "response": "Returns the Precincts reporting percent of the vote."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the precincts total if vote is top level result else None.", "response": "def get_precinctstotal(self, obj):\n        \"\"\"Precincts total if vote is top level result else ``None``.\"\"\"\n        if obj.division.level == \\\n                obj.candidate_election.election.division.level:\n            return obj.candidate_election.election.meta.precincts_total\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, tableName='rasters', rasters=[]):\n        '''\n        Accepts a list of paths to raster files to load into the database.\n        Returns the ids of the rasters loaded successfully in the same order\n        as the list passed in.\n        '''\n        # Create table if necessary\n        Base.metadata.create_all(self._engine)\n\n        # Create a session\n        Session = sessionmaker(bind=self._engine)\n        session = Session()\n\n        for raster in rasters:\n            # Must read in using the raster2pgsql commandline tool.\n            rasterPath = raster['path']\n\n            if 'srid' in raster:\n                srid = str(raster['srid'])\n            else:\n                srid = '4326'\n\n            if 'no-data' in raster:\n                noData = str(raster['no-data'])\n            else:\n                noData = '-1'\n\n            wellKnownBinary = RasterLoader.rasterToWKB(rasterPath, srid, noData, self._raster2pgsql)\n\n            rasterBinary = wellKnownBinary\n\n            # Get the filename\n            filename = os.path.split(rasterPath)[1]\n\n            # Populate raster record\n            mapKitRaster = MapKitRaster()\n            mapKitRaster.filename = filename\n            mapKitRaster.raster = rasterBinary\n\n            if 'timestamp' in raster:\n                mapKitRaster.timestamp = raster['timestamp']\n\n            # Add to session\n            session.add(mapKitRaster)\n\n        session.commit()", "response": "Load rasters into the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rasterToWKB(cls, rasterPath, srid, noData, raster2pgsql):\n        raster2pgsqlProcess = subprocess.Popen([raster2pgsql,\n                                                '-s', srid,\n                                                '-N', noData,\n                                                rasterPath,\n                                                'n_a'],stdout=subprocess.PIPE)\n\n        # This commandline tool generates the SQL to load the raster into the database\n        # However, we want to use SQLAlchemy to load the values into the database.\n        # We do this by extracting the value from the sql that is generated.\n        sql, error = raster2pgsqlProcess.communicate()\n        if sql:\n            # This esoteric line is used to extract only the value of the raster (which is stored as a Well Know Binary string)\n            # Example of Output:\n            # BEGIN;\n            # INSERT INTO \"idx_index_maps\" (\"rast\") VALUES ('0100...56C096CE87'::raster);\n            # END;\n            # The WKB is wrapped in single quotes. Splitting on single quotes isolates it as the\n            # second item in the resulting list.\n            wellKnownBinary = sql.split(\"'\")[1]\n        else:\n            print(error)\n            raise\n        return wellKnownBinary", "response": "Takes a raster file and converts it to Well Known Binary text using raster2pgsql."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a WKB file from a GRASS ASCII raster.", "response": "def grassAsciiRasterToWKB(cls, session, grassRasterPath, srid, noData=0):\n        \"\"\"\n        Load GRASS ASCII rasters directly using the makeSingleBandWKBRaster method. Do this to eliminate the raster2pgsql\n        dependency.\n        \"\"\"\n        # Constants\n        NUM_HEADER_LINES = 6\n\n        # Defaults\n        north = 0.0\n        east = 0.0\n        west = 0.0\n        rows = 0\n        columns = 0\n\n        if grassRasterPath is not None:\n            # If the path to the file is given, open the file and extract contents.\n            with open(grassRasterPath, 'r') as f:\n                rasterLines = f.readlines()\n        else:\n            print(\"RASTER LOAD ERROR: Must provide the path the raster.\")\n            raise\n\n        # Extract the headers from the file and derive metadata\n        for line in rasterLines[0:NUM_HEADER_LINES]:\n            spline = line.split()\n\n            if 'north' in spline[0].lower():\n                north = float(spline[1])\n            elif 'east' in spline[0].lower():\n                east = float(spline[1])\n            elif 'west' in spline[0].lower():\n                west = float(spline[1])\n            elif 'rows' in spline[0].lower():\n                rows = int(spline[1])\n            elif 'cols' in spline[0].lower():\n                columns = int(spline[1])\n\n        # Define raster metadata from headers\n        width = columns\n        height = rows\n        upperLeftX = west\n        upperLeftY = north\n        cellSizeX = int(abs(west - east) / columns)\n        cellSizeY = -1 * cellSizeX\n\n        # Assemble the data array string\n        dataArrayList = []\n\n        for line in rasterLines[NUM_HEADER_LINES:len(rasterLines)]:\n            dataArrayList.append('[{0}]'.format(', '.join(line.split())))\n\n        dataArrayString = '[{0}]'.format(', '.join(dataArrayList))\n\n        # Create well known binary raster\n        wellKnownBinary = cls.makeSingleBandWKBRaster(session=session,\n                                                      width=width, height=height,\n                                                      upperLeftX=upperLeftX, upperLeftY=upperLeftY,\n                                                      cellSizeX=cellSizeX, cellSizeY=cellSizeY,\n                                                      skewX=0, skewY=0,\n                                                      srid=srid,\n                                                      dataArray=dataArrayString,\n                                                      noDataValue=noData)\n\n        return wellKnownBinary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating Well Known Binary via SQL. Must be used on a PostGIS database as it relies on several PostGIS database functions. :param session: SQLAlchemy session object bound to a PostGIS enabled database :param height: Height of the raster (or number of rows) :param width: Width of the raster (or number of columns) :param upperLeftX: Raster upper left corner X coordinate :param upperLeftY: Raster upper left corner Y coordinate :param cellSizeX: Raster cell size in X direction :param cellSizeY: Raster cell size in Y direction :param skewX: Skew in X direction :param skewY: Skew in Y direction :param srid: SRID of the raster :param initialValue: Initial / default value of the raster cells :param noDataValue: Value of cells to be considered as cells containing no cells :param dataArray: 2-dimensional list of values or a string representation of a 2-dimensional list that will be used to populate the raster values", "response": "def makeSingleBandWKBRaster(cls, session, width, height, upperLeftX, upperLeftY, cellSizeX, cellSizeY, skewX, skewY, srid, dataArray, initialValue=None, noDataValue=None):\n        \"\"\"\n        Generate Well Known Binary via SQL. Must be used on a PostGIS database as it relies on several PostGIS\n        database functions.\n        :param session: SQLAlchemy session object bound to a PostGIS enabled database\n        :param height: Height of the raster (or number of rows)\n        :param width: Width of the raster (or number of columns)\n        :param upperLeftX: Raster upper left corner X coordinate\n        :param upperLeftY: Raster upper left corner Y coordinate\n        :param cellSizeX: Raster cell size in X direction\n        :param cellSizeY: Raster cell size in Y direction\n        :param skewX: Skew in X direction\n        :param skewY: Skew in Y direction\n        :param srid: SRID of the raster\n        :param initialValue: Initial / default value of the raster cells\n        :param noDataValue: Value of cells to be considered as cells containing no cells\n        :param dataArray: 2-dimensional list of values or a string representation of a 2-dimensional list that will be used to populate the raster values\n        \"\"\"\n        # Stringify the data array\n        if isinstance(dataArray, str):\n            dataArrayString = dataArray\n        else:\n            dataArrayString = json.dumps(dataArray)\n\n        # Validate\n        if initialValue is None:\n            initialValue = 'NULL'\n\n        if noDataValue is None:\n            noDataValue = 'NULL'\n\n        # Cell size in the Y direction must be negative\n        if cellSizeY > 0:\n            print('RASTER LOADER WARNING: cellSizeY should be defined as negative.')\n            cellSizeY = -1 * cellSizeY\n\n        # Create the SQL statement\n        statement = '''\n                    SELECT ST_SetValues(\n                        ST_AddBand(\n                            ST_MakeEmptyRaster({0}::integer, {1}::integer, {2}, {3}, {4}, {5}, {6}, {7}, {8}::integer),\n                            1::integer, '32BF'::text, {9}::double precision, {10}::double precision\n                        ),\n                        1, 1, 1, ARRAY{11}::double precision[][]\n                    );\n                    '''.format(width,\n                               height,\n                               upperLeftX,\n                               upperLeftY,\n                               cellSizeX,\n                               cellSizeY,\n                               skewX,\n                               skewY,\n                               srid,\n                               initialValue,\n                               noDataValue,\n                               dataArrayString)\n\n        result = session.execute(statement)\n\n        # Extract result\n        wellKnownBinary = ''\n\n        for row in result:\n            wellKnownBinary = row[0]\n\n        return wellKnownBinary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaying something at a later time.", "response": "def cmd(send, msg, args):\n    \"\"\"Says something at a later time.\n\n    Syntax: {command} <delay> <msg>\n\n    \"\"\"\n    parser = arguments.ArgParser(args['config'])\n    parser.add_argument('delay')\n    parser.add_argument('msg', nargs='+')\n    try:\n        cmdargs = parser.parse_args(msg)\n    except arguments.ArgumentException as e:\n        send(str(e))\n        return\n    if isinstance(cmdargs.msg, list):\n        cmdargs.msg = ' '.join(cmdargs.msg)\n    cmdargs.delay = parse_time(cmdargs.delay)\n    if cmdargs.delay is None:\n        send(\"Invalid unit.\")\n    elif cmdargs.delay < 0:\n        send(\"Time travel not yet implemented, sorry.\")\n    else:\n        ident = args['handler'].workers.defer(cmdargs.delay, False, send, cmdargs.msg)\n        send(\"Message deferred, ident: %s\" % ident)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimize(self, to_buy, to_sell):\n        '''\n        Buy sid * parameters['buy_amount'] * parameters['scale'][sid]\n        Sell sid * parameters['sell_amount'] * parameters['scale'][sid]\n        '''\n        allocations = {}\n\n        # Process every stock the same way\n        for s in to_buy:\n            quantity = self.properties.get('buy_amount', 100)\n            if s in self.properties.get('scale', {}):\n                quantity *= self.properties['scale'][s]\n            # Allocate defined amount to buy\n            allocations[s] = int(quantity)\n\n        # NOTE You must provide sell_amount if you want to short\n        for s in to_sell:\n            quantity = self.properties.get(\n                'sell_amount', self.portfolio.positions[s].amount)\n            if s in self.properties.get('scale', {}):\n                quantity *= self.properties['scale'][s]\n            # Allocate defined amount to buy\n            allocations[s] = -int(quantity)\n\n        # Defaults values\n        e_ret = 0\n        e_risk = 1\n        return allocations, e_ret, e_risk", "response": "Optimize the amount of the items in to_buy and to_sell to_buy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _replace(self, **kwds):\n        'Return a new NamedTuple object replacing specified fields with new values'\n        result = self._make(map(kwds.pop, self._fields, self))\n        \n        if kwds:\n            raise ValueError('Got unexpected field names: %r' % kwds.keys())\n        \n        return result", "response": "Return a new NamedTuple object replacing specified fields with new values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delunnamedcol(df):\n    cols_del=[c for c in df.columns if 'Unnamed' in c]\n    return df.drop(cols_del,axis=1)", "response": "Deletes all the unnamed columns from a DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concat_cols(df1,df2,idx_col,df1_cols,df2_cols,\n                df1_suffix,df2_suffix,wc_cols=[],suffix_all=False):\n    \"\"\"\n    Concatenates two pandas tables \n\n    :param df1: dataframe 1\n    :param df2: dataframe 2\n    :param idx_col: column name which will be used as a common index \n    \"\"\"\n\n    df1=df1.set_index(idx_col)\n    df2=df2.set_index(idx_col)    \n    if not len(wc_cols)==0:\n        for wc in wc_cols:\n            df1_cols=df1_cols+[c for c in df1.columns if wc in c]\n            df2_cols=df2_cols+[c for c in df2.columns if wc in c]\n    combo=pd.concat([df1.loc[:,df1_cols],df2.loc[:,df2_cols]],axis=1)\n    # find common columns and rename them\n    # print df1_cols\n    # print df2_cols    \n    if suffix_all:\n        df1_cols=[\"%s%s\" % (c,df1_suffix) for c in df1_cols]\n        df2_cols=[\"%s%s\" % (c,df2_suffix) for c in df2_cols]\n        # df1_cols[df1_cols.index(col)]=\"%s%s\" % (col,df1_suffix)\n        # df2_cols[df2_cols.index(col)]=\"%s%s\" % (col,df2_suffix)\n    else:\n        common_cols=[col for col in df1_cols if col in df2_cols]\n        for col in common_cols:\n            df1_cols[df1_cols.index(col)]=\"%s%s\" % (col,df1_suffix)\n            df2_cols[df2_cols.index(col)]=\"%s%s\" % (col,df2_suffix)\n    combo.columns=df1_cols+df2_cols\n    combo.index.name=idx_col\n    return combo", "response": "Concatenates two pandas tables \n df1 and df2 with the same columns."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_colmin(data):\n    data=data.T\n    colmins=[]\n    for col in data:\n        colmins.append(data[col].idxmin())\n    return colmins", "response": "Get rowwise column names with minimum values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rename_cols(df,names,renames=None,prefix=None,suffix=None):\n    if not prefix is None:\n        renames=[ \"%s%s\" % (prefix,s) for s in names]\n    if not suffix is None:    \n        renames=[ \"%s%s\" % (s,suffix) for s in names]\n    if not renames is None:\n        for i,name in enumerate(names):\n#             names=[renames[i] if s==names[i] else s for s in names]    \n            rename=renames[i]    \n            df.loc[:,rename]=df.loc[:,name]\n        df=df.drop(names,axis=1)\n        return df", "response": "rename columns of a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreordering rows of a dataframe by another dataframe", "response": "def reorderbydf(df2,df1):\n    \"\"\"\n    Reorder rows of a dataframe by other dataframe\n\n    :param df2: input dataframe\n    :param df1: template dataframe \n    \"\"\"\n    df3=pd.DataFrame()\n    for idx,row in df1.iterrows():\n        df3=df3.append(df2.loc[idx,:])\n    return df3"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a dmap into a liner.", "response": "def dmap2lin(df,idxn='index',coln='column',colvalue_name='value'):\n    \"\"\"\n    dmap: ids in index and columns \n    idxn,coln of dmap -> 1st and 2nd col\n    \"\"\"\n#     df.columns.name=coln\n    df.index.name=idxn\n    return df.reset_index().melt(id_vars=[df.index.name],\n                             var_name=coln,value_name=colvalue_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a DataFrame to a sequence of unstacked lines.", "response": "def df2unstack(df,coln='columns',idxn='index',col='value'):\n    \"\"\"\n    will be deprecated\n    \"\"\"\n    return dmap2lin(df,idxn=idxn,coln=coln,colvalue_name=col)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef df2chucks(din,chunksize,outd,fn,return_fmt='\\t',force=False):\n    from os.path import exists#,splitext,dirname,splitext,basename,realpath\n    from os import makedirs\n    din.index=range(0,len(din),1)\n\n    chunkrange=list(np.arange(0,len(din),chunksize))\n    chunkrange=list(zip([c+1 if ci!=0 else 0 for ci,c in enumerate(chunkrange)],chunkrange[1:]+[len(din)-1]))\n\n    chunk2range={}\n    for ri,r in enumerate(chunkrange):    \n        chunk2range[ri+1]=r\n\n    if not exists(outd):\n        makedirs(outd)\n    chunks=[]\n    chunkps=[]\n    for chunk in chunk2range:\n        chunkp='{}/{}_chunk{:08d}.tsv'.format(outd,fn,chunk)\n        rnge=chunk2range[chunk]\n        din_=din.loc[rnge[0]:rnge[1],:]\n        if not exists(chunkp) or force:\n            if return_fmt=='list':\n                chunks.append(din_)\n            else:\n                din_.to_csv(chunkp,sep=return_fmt)\n            del din_\n        chunkps.append(chunkp)\n    if return_fmt=='list':\n        return chunks\n    else:\n        return chunkps", "response": "Convert a dataframe into a list of chucks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dflin2dfbinarymap(dflin,col1,col2,params_df2submap={'aggfunc':'sum','binary':True,'binaryby':'nan'},test=False):\n    # get the submap ready\n    df_map=df2submap(df=dflin,\n              col=col1,idx=col2,**params_df2submap)\n    if test:           \n        logging.debug(df_map.unstack().unique())\n    # make columns and index symmetric\n    df_map_symm=dfmap2symmcolidx(df_map)\n    df_map_symm=df_map_symm.fillna(False)\n    if test:           \n        logging.debug(df_map_symm.unstack().unique())\n    df_map_symm=(df_map_symm+df_map_symm.T)/2\n    if test:           \n        logging.debug(df_map_symm.unstack().unique())\n    df_map_symm=df_map_symm!=0\n    if test:           \n        logging.debug(df_map_symm.unstack().unique())\n    return df_map_symm", "response": "converts a df in binary form to a df in a binary form"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_offdiag_vals(dcorr):\n    del_indexes=[]\n    for spc1 in np.unique(dcorr.index.get_level_values(0)):\n        for spc2 in np.unique(dcorr.index.get_level_values(0)):\n            if (not (spc1,spc2) in del_indexes) and (not (spc2,spc1) in del_indexes):\n                del_indexes.append((spc1,spc2))\n    #         break\n    for spc1 in np.unique(dcorr.index.get_level_values(0)):\n        for spc2 in np.unique(dcorr.index.get_level_values(0)):\n            if spc1==spc2:\n                del_indexes.append((spc1,spc2))\n    \n    return dcorr.drop(del_indexes)", "response": "get offdiag values from the given correlation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a dataframe with a list of columns with a single column as a list of tuples of synonymns", "response": "def dfsyn2appended(df,colsyn,colsynfmt=None,colsynstrsep=';'):\n    \"\"\"\n    for merging dfs with names with df with synonymns\n    param colsyn: col containing tuples of synonymns \n    \"\"\"\n    colsynappended=colsyn+' appended'\n    df.index=range(len(df))\n    if colsynfmt=='str':\n        df.loc[:,colsyn]=df.loc[:,colsyn].apply(lambda x : x.split(colsynstrsep))\n    #make duplicated row for each synonymn\n    dfsynappended=df[colsyn].apply(pd.Series).unstack().reset_index().drop('level_0',axis=1).set_index('level_1')\n    dfsynappended.columns=[colsynappended]\n    dfsynappended=dfsynappended.dropna()\n    return dfsynappended.join(df,how='left')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop duplicates from a dataframe", "response": "def drop_duplicates_agg(df,colsgroupby,cols2aggf,test=False):\n    \"\"\"\n    colsgroupby: unique names ~index\n    cols2aggf: rest of the cols `unique_dropna_str` for categories\n    \"\"\"\n    if test:\n        print(df.shape)\n        print(df.drop_duplicates(subset=colsgroupby).shape)\n    #ddup aggregated\n    dfdupagg=df.loc[(df.duplicated(subset=colsgroupby,keep=False)),:].groupby(colsgroupby).agg(cols2aggf)\n    #drop duplicates all\n    df_=df.drop_duplicates(subset=colsgroupby,keep=False)\n    if test:\n        print(df_.shape)\n    #append ddup aggregated\n    dfout=df_.append(dfdupagg,sort=True)\n    if test:\n        print(dfout.shape)\n    return dfout"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the intersection of the given set of tables.", "response": "def get_intersectionsbysubsets(df,cols_fracby2vals,cols_subset,col_ids):\n    \"\"\"\n    cols_fracby:\n    cols_subset:\n    \"\"\"\n    for col_fracby in cols_fracby2vals:\n        val=cols_fracby2vals[col_fracby]\n        ids=df.loc[(df[col_fracby]==val),col_ids].dropna().unique()\n        for col_subset in cols_subset:\n            for subset in dropna(df[col_subset].unique()):\n                ids_subset=df.loc[(df[col_subset]==subset),col_ids].dropna().unique()\n                df.loc[(df[col_subset]==subset),f'P {col_fracby} {col_subset}']=len(set(ids_subset).intersection(ids))/len(ids_subset)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_dict(data):\n        data = deepcopy(data)\n\n        created_at = data.get('created_at', None)\n        if created_at is not None:\n            data['created_at'] = dateutil.parser.parse(created_at)\n\n        return Image(**data)", "response": "Create a new Image instance from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a JSON string representation of this instance", "response": "def to_json(self, indent=None, sort_keys=True):\n        \"\"\"Return a JSON string representation of this instance\n\n        :param indent: specify an indent level or a string used to indent each\n                       level\n        :param sort_keys: the output is sorted by key\n        \"\"\"\n        return json.dumps(self.to_dict(), indent=indent, sort_keys=sort_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self):\n        data = {}\n\n        if self.created_at:\n            data['created_at'] = self.created_at.strftime(\n                '%Y-%m-%dT%H:%M:%S%z')\n        if self.image_id:\n            data['image_id'] = self.image_id\n        if self.permalink_url:\n            data['permalink_url'] = self.permalink_url\n        if self.thumb_url:\n            data['thumb_url'] = self.thumb_url\n        if self.type:\n            data['type'] = self.type\n        if self.url:\n            data['url'] = self.url\n\n        return data", "response": "Return a dict representation of this instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads an image file from the server.", "response": "def download(self):\n        \"\"\"Download an image file if it exists\n\n        :raise GyazoError:\n        \"\"\"\n        if self.url:\n            try:\n                return requests.get(self.url).content\n            except requests.RequestException as e:\n                raise GyazoError(str(e))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a thumbnail image file", "response": "def download_thumb(self):\n        \"\"\"Download a thumbnail image file\n\n        :raise GyazoError:\n        \"\"\"\n        try:\n            return requests.get(self.thumb_url).content\n        except requests.RequestException as e:\n            raise GyazoError(str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if there is a next page or False otherwise.", "response": "def has_next_page(self):\n        \"\"\"Whether there is a next page or not\n\n        :getter: Return true if there is a next page\n        \"\"\"\n        return self.current_page < math.ceil(self.total_count / self.per_page)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset instance attributes from HTTP headers.", "response": "def set_attributes_from_headers(self, headers):\n        \"\"\"Set instance attributes with HTTP header\n\n        :param headers: HTTP header\n        \"\"\"\n        self.total_count = headers.get('x-total-count', None)\n        self.current_page = headers.get('x-current-page', None)\n        self.per_page = headers.get('x-per-page', None)\n        self.user_type = headers.get('x-user-type', None)\n\n        if self.total_count:\n            self.total_count = int(self.total_count)\n        if self.current_page:\n            self.current_page = int(self.current_page)\n        if self.per_page:\n            self.per_page = int(self.per_page)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasks Magic 8 - Ball a question.", "response": "def cmd(send, msg, args):\n    \"\"\"Asks the Magic 8-Ball a question.\n    Syntax: {command} <question>\n    \"\"\"\n    if not msg:\n        send(\"What is your question?\")\n        # let people !8ball again if they screw up and forget the part where you ask a question.\n        args['handler'].abuselist[args['nick']]['8ball'].pop()\n        return\n    answers = {\n        \"It is certain\": \"yes\",\n        \"It is decidedly so\": \"yes\",\n        \"Without a doubt\": \"yes\",\n        \"Yes, definitely\": \"yes\",\n        \"You may rely on it\": \"yes\",\n        \"As I see it, yes\": \"yes\",\n        \"Most likely\": \"yes\",\n        \"Outlook good\": \"yes\",\n        \"Yes\": \"yes\",\n        \"Signs point to yes\": \"yes\",\n        \"Reply hazy, try again\": \"maybe\",\n        \"Ask again later\": \"maybe\",\n        \"Better not tell you now\": \"maybe\",\n        \"Cannot predict now\": \"maybe\",\n        \"Concentrate and ask again\": \"maybe\",\n        \"Don't count on it\": \"no\",\n        \"My reply is no\": \"no\",\n        \"My sources say no\": \"no\",\n        \"Outlook not so good\": \"no\",\n        \"Very doubtful\": \"no\"\n    }\n    answer = choice(list(answers.keys()))\n    send('says... %s' % answer, 'action')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the base classes of the new class to be created.", "response": "def _validate_base_classes(meta, bases):\n        \"\"\"Validate the base classes of the new class to be created,\n        making sure none of them are ``@final``.\n        \"\"\"\n        for base in bases:\n            if meta._is_final(base):\n                raise ClassError(\n                    \"cannot inherit from @final class %s\" % (base.__name__,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates usage of @override and @final modifiers on methods of the given class.", "response": "def _validate_method_decoration(meta, class_):\n        \"\"\"Validate the usage of ``@override`` and ``@final`` modifiers\n        on methods of the given ``class_``.\n        \"\"\"\n        # TODO(xion): employ some code inspection tricks to serve ClassErrors\n        # as if they were thrown at the offending class's/method's definition\n\n        super_mro = class_.__mro__[1:]\n        own_methods = ((name, member)\n                       for name, member in class_.__dict__.items()\n                       if is_method(member))\n\n        # check that ``@override`` modifier is present where it should be\n        # and absent where it shouldn't (e.g. ``@final`` methods)\n        for name, method in own_methods:\n            shadowed_method, base_class = next(\n                ((getattr(base, name), base)\n                 for base in super_mro if hasattr(base, name)),\n                (None, None)\n            )\n            if meta._is_override(method):\n                # ``@override`` is legal only when the method actually shadows\n                # a method from a superclass, and that metod is not ``@final``\n                if not shadowed_method:\n                    raise ClassError(\"unnecessary @override on %s.%s\" % (\n                        class_.__name__, name), class_=class_)\n                if meta._is_final(shadowed_method):\n                    raise ClassError(\n                        \"illegal @override on a @final method %s.%s\" % (\n                            base_class.__name__, name), class_=class_)\n\n                # if @override had parameter supplied, verify if it was\n                # the same class as the base of shadowed method\n                override_base = meta._get_override_base(method)\n                if override_base and base_class is not override_base:\n                    if is_class(override_base):\n                        raise ClassError(\n                            \"incorrect override base: expected %s, got %s\" % (\n                                base_class.__name__, override_base.__name__))\n                    else:\n                        raise ClassError(\n                            \"invalid override base specified: %s\" % (\n                                override_base,))\n\n                setattr(class_, name, method.method)\n            else:\n                if shadowed_method and name not in meta.OVERRIDE_EXEMPTIONS:\n                    if meta._is_final(shadowed_method):\n                        msg = \"%s.%s is hiding a @final method %s.%s\" % (\n                            class_.__name__, name, base_class.__name__, name)\n                    else:\n                        msg = (\"overridden method %s.%s \"\n                               \"must be marked with @override\" % (\n                                class_.__name__, name))\n                    raise ClassError(msg, class_=class_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether given object or method is marked as final.", "response": "def _is_final(meta, arg):\n        \"\"\"Checks whether given class or method has been marked\n        with the ``@final`` decorator.\n        \"\"\"\n        if inspect.isclass(arg) and not isinstance(arg, ObjectMetaclass):\n            return False  # of classes, only subclasses of Object can be final\n\n        # account for method wrappers, such as the one introduced by @override\n        from taipan.objective.modifiers import _WrappedMethod\n        if isinstance(arg, _WrappedMethod):\n            arg = arg.method\n\n        return getattr(arg, '__final__', False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_override(meta, method):\n        from taipan.objective.modifiers import _OverriddenMethod\n        return isinstance(method, _OverriddenMethod)", "response": "Checks whether given class or instance method has been marked\n        with the override decorator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the override base class from the override_wrapper.", "response": "def _get_override_base(self, override_wrapper):\n        \"\"\"Retrieve the override base class from the\n        :class:`_OverriddenMethod` wrapper.\n        \"\"\"\n        base = override_wrapper.modifier.base\n        if not base:\n            return None\n        if is_class(base):\n            return base\n\n        # resolve the (possibly qualified) class name\n        if '.' in base:\n            # repeatedly try to import the first N-1, N-2, etc. dot-separated\n            # parts of the qualified name; this way we can handle all names\n            # including `package.module.Class.InnerClass`\n            dot_parts = base.split('.')\n            for i in xrange(len(dot_parts) - 1, 1, -1):  # n-1 -> 1\n                module_name = '.'.join(dot_parts[:i])\n                class_name = '.'.join(dot_parts[i:])\n                try:\n                    module = __import__(module_name, fromlist=[dot_parts[i]])\n                    break\n                except ImportError:\n                    pass\n            else:\n                # couldn't resolve class name, return it verbatim\n                return base\n        else:\n            class_name = base\n            module_name = override_wrapper.method.__module__\n            module = sys.modules[module_name]\n\n        return getattr(module, class_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trace_dependencies(req, requirement_set, dependencies, _visited=None):\r\n    _visited = _visited or set()\r\n    if req in _visited:\r\n        return\r\n    _visited.add(req)\r\n    for reqName in req.requirements():\r\n        try:\r\n            name = pkg_resources.Requirement.parse(reqName).project_name\r\n        except ValueError, e:\r\n            logger.error('Invalid requirement: %r (%s) in requirement %s' % (\r\n                reqName, e, req))\r\n            continue\r\n        subreq = requirement_set.get_requirement(name)\r\n        dependencies.append((req, subreq))\r\n        trace_dependencies(subreq, requirement_set, dependencies, _visited)", "response": "Trace all dependency relationships\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pad_zeroes(addr, n_zeroes):\n    if len(addr) < n_zeroes:\n        return pad_zeroes(\"0\" + addr, n_zeroes)\n    return addr", "response": "Padds the address with zeroes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the next address after the current + i", "response": "def next_addr(addr, i):\n    \"\"\"Gets address after the current + i\"\"\"\n    str_addr = pad_zeroes(str(int_addr(addr) + i), len(addr[1:]))\n    return addr[0] + str_addr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmarking an address as being used in simulator", "response": "def mark_address(self, addr, size):\n        \"\"\"Marks address as being used in simulator\"\"\"\n        i = 0\n        while i < size:\n            self._register_map[addr] = True\n            i += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_address_avoid_collision(self, start_addr):\n        i = 1\n        while self.is_address_in_use(next_addr(start_addr, i)):\n            i += 1\n        return next_addr(start_addr, i)", "response": "Finds the next address which does not collide with any other address"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_to_next_address(self, size_of_current):\n        self._size_of_current_register_address = size_of_current\n        self._current_address = self.next_address()\n        self.mark_address(self._current_address, size_of_current)", "response": "Moves the register s current address to the next available byte."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_to_next_bit_address(self):\n        self._current_bit_address = self.next_bit_address()\n        self.mark_address(self._current_bit_address.split('.')[0], self._size_of_current_register_address)", "response": "Moves to next available bit address position"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the next boolean address", "response": "def next_bit_address(self):\n        \"\"\"Gets the next boolean address\"\"\"\n        if self._current_bit_address == \"\":\n            if self._is_16bit:\n                return \"{0}.{1}\".format(\n                    self.next_address(),\n                    \"00\")\n            return \"{0}.{1}\".format(\n                self.next_address(),\n                \"0\")\n        if self._is_16bit:\n            bool_half = int(self._current_bit_address.split(\".\")[1])\n            if bool_half < 4:\n                register_half = self._current_bit_address.split(\".\")[0]\n                return \"{0}.{1}\".format(\n                    register_half,\n                    pad_zeroes(str(bool_half + 1), 2))\n            self.move_to_next_address(self._size_of_current_register_address)\n            return \"{0}.{1}\".format(\n                self.next_address(),\n                \"00\")\n        bool_half = int(self._current_bit_address.split(\".\")[1])\n        if bool_half < 3:\n            register_half = self._current_bit_address.split(\".\")[0]\n            return \"{0}.{1}\".format(\n                register_half,\n                bool_half + 1)\n        self.move_to_next_address(self._size_of_current_register_address)\n        return \"{0}.{1}\".format(\n            self.next_address(),\n            \"0\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nroute an election to its appropriate bootstrap method.", "response": "def route_election(self, election):\n        \"\"\"\n        Legislative or executive office?\n        \"\"\"\n        if (\n            election.election_type.slug == ElectionType.GENERAL\n            or ElectionType.GENERAL_RUNOFF\n        ):\n            self.bootstrap_general_election(election)\n        elif election.race.special:\n            self.bootstrap_special_election(election)\n\n        if election.race.office.is_executive:\n            self.bootstrap_executive_office(election)\n        else:\n            self.bootstrap_legislative_office(election)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the DBIogrid intmap file.", "response": "def get_dbiogrid_intmap(taxid,dbiogridp,dbiogrid_intmap_symmp,dbiogrid_intlinp,dbiogrid_intmapp,\n                        logf=None,\n                        experimental_system_type='physical',\n                        genefmt='name',\n                        force=False,test=False,\n                        keep_exp_syss=[],del_exp_syss=[],\n                        filldiagonal_withna=False):\n    \"\"\"\n    taxid=559292\n    del_exp_syss=[\"Co-purification\", \"Co-fractionation\", \"Proximity Label-MS\", \n                                  \"Affinity Capture-RNA\", \"Protein-peptide\"]\n    \"\"\"    \n    gene_fmt2colns={'biogrid':{'id':'Systematic Name',\n                 'name':'Official Symbol'},}\n    if (not exists(dbiogrid_intmap_symmp)) or force:\n        if not exists(dbiogrid_intmapp) or force:\n            if not exists(dbiogrid_intlinp) or force:\n                if dbiogridp.endswith('tab2.txt'):\n                    print(f\"converting to parquet\")\n                    dbiogrid=pd.read_csv(dbiogridp,\n                       sep='\\t',low_memory=False)\n                    dbiogridp=dbiogridp+\".pqt\"\n                    to_table_pqt(dbiogrid,dbiogridp)\n                    print(f\"use {dbiogridp}\")\n                elif dbiogridp.endswith('tab2.txt.pqt'):\n                    dbiogrid=read_table_pqt(dbiogridp)\n                # filter biogrid\n                # taxonomic id of Scer\n                dbiogrid=dbiogrid.loc[((dbiogrid['Experimental System Type']==experimental_system_type) \\\n                           & (dbiogrid['Organism Interactor A']==taxid) \\\n                           & (dbiogrid['Organism Interactor B']==taxid)),:]\n\n                print('All physical Experimental Systems.')\n                if test:\n                    dlog=pd.DataFrame(dbiogrid['Experimental System'].value_counts())\n                    print(dlog)\n                    if not logf is None:\n                        to_table(dlog,f'{logf}.all_int.tsv')                    \n                if len(keep_exp_syss)!=0:\n                    dbiogrid=dbiogrid.loc[((dbiogrid['Experimental System'].isin(keep_exp_syss))),:]\n                elif len(del_exp_syss)!=0:\n                    dbiogrid=dbiogrid.loc[((~dbiogrid['Experimental System'].isin(del_exp_syss))),:]\n                elif len(del_exp_syss)!=0 and len(keep_exp_syss)!=0:\n                    print('Error: either specify keep_exp_syss or del_exp_syss')\n                    return False\n                if test:\n                    print('Experimental Systems used.')\n                    dlog=pd.DataFrame(dbiogrid['Experimental System'].value_counts())\n                    if not logf is None:\n                        to_table(dlog,f'{logf}.kept_int.tsv')\n                    print(dlog)\n                to_table_pqt(dbiogrid,dbiogrid_intlinp)\n            else:\n                dbiogrid=read_table_pqt(dbiogrid_intlinp)\n            # this cell makes a symmetric interaction map\n            dbiogrid['count']=1\n            if test:\n                print(dbiogrid['count'].sum())\n            # mean of counts of intearations\n            ## higher is more confident interaction captured in multiple assays\n            dbiogrid_grid=dbiogrid.pivot_table(values='count',\n                                             index=f\"{gene_fmt2colns['biogrid'][genefmt]} Interactor A\",\n                                            columns=f\"{gene_fmt2colns['biogrid'][genefmt]} Interactor B\",\n                                            aggfunc='sum',)\n\n            # make it symmetric\n            if test:\n                print('shape of non-symm intmap: ',dbiogrid_grid.shape)\n            to_table_pqt(dbiogrid_grid,dbiogrid_intmapp)\n        else:         \n#             dbiogrid_grid=pd.read_table(dbiogrid_intmapp)\n            dbiogrid_grid=read_table_pqt(dbiogrid_intmapp+'.pqt')\n        dbiogrid_grid=set_index(dbiogrid_grid,f\"{gene_fmt2colns['biogrid'][genefmt]} Interactor A\")\n        geneids=set(dbiogrid_grid.index).union(set(dbiogrid_grid.columns))\n        if test:\n            print('total number of genes',len(geneids))\n        # missing rows to nan\n        dbiogrid_intmap_symm=pd.DataFrame(columns=geneids,index=geneids)\n\n        dbiogrid_intmap_symm.loc[dbiogrid_grid.index,:]=dbiogrid_grid.loc[dbiogrid_grid.index,:]\n        dbiogrid_intmap_symm.loc[:,dbiogrid_grid.columns]=dbiogrid_grid.loc[:,dbiogrid_grid.columns]\n        if test:\n            print(dbiogrid_intmap_symm.shape)\n        dbiogrid_intmap_symm=dbiogrid_intmap_symm.fillna(0)\n        dbiogrid_intmap_symm=(dbiogrid_intmap_symm+dbiogrid_intmap_symm.T)/2\n        dbiogrid_intmap_symm.index.name='Interactor A'\n        dbiogrid_intmap_symm.columns.name='Interactor B'\n#         if test:\n#             dbiogrid_intmap_symm=dbiogrid_intmap_symm.iloc[:5,:5]\n        if filldiagonal_withna:\n            dbiogrid_intmap_symm=filldiagonal(dbiogrid_intmap_symm)\n        to_table_pqt(dbiogrid_intmap_symm,dbiogrid_intmap_symmp)\n        print('file saved at: ',dbiogrid_intmap_symmp)\n        dbiogrid_intmap_symm_lin=get_degrees(dbiogrid_intmap_symm)\n        dbiogrid_intmap_symm_lin.index.name=f'gene {genefmt}'\n        to_table(dbiogrid_intmap_symm_lin,f'{dbiogrid_intmap_symmp}.degrees.tsv')\n    else:\n        dbiogrid_intmap_symm=read_table_pqt(dbiogrid_intmap_symmp)\n    return dbiogrid_intmap_symm"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the remote endpoint", "response": "def send(self, msg=None, ref=None):\n        '''\n        Example of msg for each POSHARDWARE:\n            TICKET: {'data': 'print this text, process thid dictionary or take my money'}\n            CASH:   {'data': '...ANYTHING except None to open the Cash Drawer...' }\n            DNIE:   {'data': '...ANYTHING except None to get again data from DNIe if connected...' }\n            WEIGHT: {'data': '...ANYTHING except None to get the value of the last wegith' }\n            OTHERS: {'data': '...ANYTHING you need to communicate to the device'}\n        '''\n        if self.kind in ['CASH', 'DNIE', 'WEIGHT']:\n            data = 'DOIT'\n        else:\n            if msg is not None:\n                data = msg\n            else:\n                raise IOError(\"Nothing to say to the remote endpoint???\")\n\n        # Say it to send this message\n        self.pos.send(data, ref, self.uuid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of Bugreport objects. Given a list of bugnumbers this method returns a list of Bugreport objects.", "response": "def get_status(*nrs):\n    \"\"\"Returns a list of Bugreport objects.\n\n    Given a list of bugnumbers this method returns a list of Bugreport\n    objects.\n\n    Parameters\n    ----------\n    nrs : int or list of ints\n        the bugnumbers\n\n    Returns\n    -------\n    bugs : list of Bugreport objects\n\n    \"\"\"\n    # If we called get_status with one single bug, we get a single bug,\n    # if we called it with a list of bugs, we get a list,\n    # No available bugreports returns an empty list\n    bugs = []\n    list_ = []\n    for nr in nrs:\n        if isinstance(nr, list):\n            list_.extend(nr)\n        else:\n            list_.append(nr)\n    # Process the input in batches to avoid hitting resource limits on the BTS\n    soap_client = _build_soap_client()\n    for i in range(0, len(list_), BATCH_SIZE):\n        slice_ = list_[i:i + BATCH_SIZE]\n        # I build body by hand, pysimplesoap doesn't generate soap Arrays\n        # without using wsdl\n        method_el = SimpleXMLElement('<get_status></get_status>')\n        _build_int_array_el('arg0', method_el, slice_)\n        reply = soap_client.call('get_status', method_el)\n        for bug_item_el in reply('s-gensym3').children() or []:\n            bug_el = bug_item_el.children()[1]\n            bugs.append(_parse_status(bug_el))\n    return bugs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget buglists by usertags.", "response": "def get_usertag(email, *tags):\n    \"\"\"Get buglists by usertags.\n\n    Parameters\n    ----------\n    email : str\n    tags : tuple of strings\n        If tags are given the dictionary is limited to the matching\n        tags, if no tags are given all available tags are returned.\n\n    Returns\n    -------\n    mapping : dict\n        a mapping of usertag -> buglist\n\n    \"\"\"\n    reply = _soap_client_call('get_usertag', email, *tags)\n    map_el = reply('s-gensym3')\n    mapping = {}\n    # element <s-gensys3> in response can have standard type\n    # xsi:type=apachens:Map (example, for email debian-python@lists.debian.org)\n    # OR no type, in this case keys are the names of child elements and\n    # the array is contained in the child elements\n    type_attr = map_el.attributes().get('xsi:type')\n    if type_attr and type_attr.value == 'apachens:Map':\n        for usertag_el in map_el.children() or []:\n            tag = _uc(str(usertag_el('key')))\n            buglist_el = usertag_el('value')\n            mapping[tag] = [int(bug) for bug in buglist_el.children() or []]\n    else:\n        for usertag_el in map_el.children() or []:\n            tag = _uc(usertag_el.get_name())\n            mapping[tag] = [int(bug) for bug in usertag_el.children() or []]\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets Buglogs. A buglog is a dictionary with the following mappings: * \"header\" => string * \"body\" => string * \"attachments\" => list * \"msg_num\" => int * \"message\" => email.message.Message Parameters ---------- nr : int the bugnumber Returns ------- buglogs : list of dicts", "response": "def get_bug_log(nr):\n    \"\"\"Get Buglogs.\n\n    A buglog is a dictionary with the following mappings:\n        * \"header\" => string\n        * \"body\" => string\n        * \"attachments\" => list\n        * \"msg_num\" => int\n        * \"message\" => email.message.Message\n\n    Parameters\n    ----------\n    nr : int\n        the bugnumber\n\n    Returns\n    -------\n    buglogs : list of dicts\n\n    \"\"\"\n    reply = _soap_client_call('get_bug_log', nr)\n    items_el = reply('soapenc:Array')\n    buglogs = []\n    for buglog_el in items_el.children():\n        buglog = {}\n        buglog[\"header\"] = _parse_string_el(buglog_el(\"header\"))\n        buglog[\"body\"] = _parse_string_el(buglog_el(\"body\"))\n        buglog[\"msg_num\"] = int(buglog_el(\"msg_num\"))\n        # server always returns an empty attachments array ?\n        buglog[\"attachments\"] = []\n\n        mail_parser = email.feedparser.FeedParser()\n        mail_parser.feed(buglog[\"header\"])\n        mail_parser.feed(\"\\n\\n\")\n        mail_parser.feed(buglog[\"body\"])\n        buglog[\"message\"] = mail_parser.close()\n\n        buglogs.append(buglog)\n    return buglogs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef newest_bugs(amount):\n    reply = _soap_client_call('newest_bugs', amount)\n    items_el = reply('soapenc:Array')\n    return [int(item_el) for item_el in items_el.children() or []]", "response": "Returns the newest bugs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget list of bugs matching certain criteria.", "response": "def get_bugs(*key_value):\n    \"\"\"Get list of bugs matching certain criteria.\n\n    The conditions are defined by key value pairs.\n\n    Possible keys are:\n        * \"package\": bugs for the given package\n        * \"submitter\": bugs from the submitter\n        * \"maint\": bugs belonging to a maintainer\n        * \"src\": bugs belonging to a source package\n        * \"severity\": bugs with a certain severity\n        * \"status\": can be either \"done\", \"forwarded\", or \"open\"\n        * \"tag\": see http://www.debian.org/Bugs/Developer#tags for\n           available tags\n        * \"owner\": bugs which are assigned to `owner`\n        * \"bugs\": takes single int or list of bugnumbers, filters the list\n           according to given criteria\n        * \"correspondent\": bugs where `correspondent` has sent a mail to\n\n    Arguments\n    ---------\n    key_value : str\n\n    Returns\n    -------\n    bugs : list of ints\n        the bugnumbers\n\n    Examples\n    --------\n    >>> get_bugs('package', 'gtk-qt-engine', 'severity', 'normal')\n    [12345, 23456]\n\n    \"\"\"\n    # previous versions also accepted\n    # get_bugs(['package', 'gtk-qt-engine', 'severity', 'normal'])\n    # if key_value is a list in a one elemented tuple, remove the\n    # wrapping list\n    if len(key_value) == 1 and isinstance(key_value[0], list):\n        key_value = tuple(key_value[0])\n\n    # pysimplesoap doesn't generate soap Arrays without using wsdl\n    # I build body by hand, converting list to array and using standard\n    # pysimplesoap marshalling for other types\n    method_el = SimpleXMLElement('<get_bugs></get_bugs>')\n    for arg_n, kv in enumerate(key_value):\n        arg_name = 'arg' + str(arg_n)\n        if isinstance(kv, (list, tuple)):\n            _build_int_array_el(arg_name, method_el, kv)\n        else:\n            method_el.marshall(arg_name, kv)\n\n    soap_client = _build_soap_client()\n    reply = soap_client.call('get_bugs', method_el)\n    items_el = reply('soapenc:Array')\n    return [int(item_el) for item_el in items_el.children() or []]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a status xml element into a Bugreport object", "response": "def _parse_status(bug_el):\n    \"\"\"Return a bugreport object from a given status xml element\"\"\"\n    bug = Bugreport()\n\n    # plain fields\n    for field in ('originator', 'subject', 'msgid', 'package', 'severity',\n                  'owner', 'summary', 'location', 'source', 'pending',\n                  'forwarded'):\n        setattr(bug, field, _parse_string_el(bug_el(field)))\n\n    bug.date = datetime.utcfromtimestamp(float(bug_el('date')))\n    bug.log_modified = datetime.utcfromtimestamp(float(bug_el('log_modified')))\n    bug.tags = [_uc(tag) for tag in str(bug_el('tags')).split()]\n    bug.done = _parse_bool(bug_el('done'))\n    bug.archived = _parse_bool(bug_el('archived'))\n    bug.unarchived = _parse_bool(bug_el('unarchived'))\n    bug.bug_num = int(bug_el('bug_num'))\n    bug.mergedwith = [int(i) for i in str(bug_el('mergedwith')).split()]\n    bug.blockedby = [int(i) for i in str(bug_el('blockedby')).split()]\n    bug.blocks = [int(i) for i in str(bug_el('blocks')).split()]\n\n    bug.found_versions = [_uc(str(el)) for el in\n                          bug_el('found_versions').children() or []]\n    bug.fixed_versions = [_uc(str(el)) for el in\n                          bug_el('fixed_versions').children() or []]\n    affects = [_f for _f in str(bug_el('affects')).split(',') if _f]\n    bug.affects = [_uc(a).strip() for a in affects]\n    # Also available, but unused or broken\n    # bug.keywords = [_uc(keyword) for keyword in\n    #                 str(bug_el('keywords')).split()]\n    # bug.fixed = _parse_crappy_soap(tmp, \"fixed\")\n    # bug.found = _parse_crappy_soap(tmp, \"found\")\n    # bug.found_date = \\\n    #     [datetime.utcfromtimestamp(i) for i in tmp[\"found_date\"]]\n    # bug.fixed_date = \\\n    #     [datetime.utcfromtimestamp(i) for i in tmp[\"fixed_date\"]]\n    return bug"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_soap_method_args(*args):\n    soap_args = []\n    for arg_n, arg in enumerate(args):\n        soap_args.append(('arg' + str(arg_n), arg))\n    return soap_args", "response": "Convert arguments to be consumed by a SoapClient method\n    Soap client required a list of named arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps to call SoapClient method", "response": "def _soap_client_call(method_name, *args):\n    \"\"\"Wrapper to call SoapClient method\"\"\"\n    # a new client instance is built for threading issues\n    soap_client = _build_soap_client()\n    soap_args = _convert_soap_method_args(*args)\n    # if pysimplesoap version requires it, apply a workaround for\n    # https://github.com/pysimplesoap/pysimplesoap/issues/31\n    if PYSIMPLESOAP_1_16_2:\n        return getattr(soap_client, method_name)(*soap_args)\n    else:\n        return getattr(soap_client, method_name)(soap_client, *soap_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a soapenc : Array made of ints called el_name as a child of parent", "response": "def _build_int_array_el(el_name, parent, list_):\n    \"\"\"build a soapenc:Array made of ints called `el_name` as a child\n    of `parent`\"\"\"\n    el = parent.add_child(el_name)\n    el.add_attribute('xmlns:soapenc',\n                     'http://schemas.xmlsoap.org/soap/encoding/')\n    el.add_attribute('xsi:type', 'soapenc:Array')\n    el.add_attribute('soapenc:arrayType', 'xsd:int[{:d}]'.format(len(list_)))\n    for item in list_:\n        item_el = el.add_child('item', str(item))\n        item_el.add_attribute('xsi:type', 'xsd:int')\n    return el"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_string_el(el):\n    value = str(el)\n    el_type = el.attributes().get('xsi:type')\n    if el_type and el_type.value == 'xsd:base64Binary':\n        value = base64.b64decode(value)\n        if not PY2:\n            value = value.decode('utf-8', errors='replace')\n    value = _uc(value)\n    return value", "response": "read a string element maybe encoded in base64"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwalk the contract directory and returns a Solidity input JSON object as a dict", "response": "def get_solc_input(self):\n        \"\"\"Walks the contract directory and returns a Solidity input dict\n\n        Learn more about Solidity input JSON here: https://goo.gl/7zKBvj\n\n        Returns:\n            dict: A Solidity input JSON object as a dict\n        \"\"\"\n\n        def legal(r, file_name):\n            hidden = file_name[0] == '.'\n            dotsol = len(file_name) > 3 and file_name[-4:] == '.sol'\n            path = os.path.normpath(os.path.join(r, file_name))\n            notfile = not os.path.isfile(path)\n            symlink = Path(path).is_symlink()\n            return dotsol and (not (symlink or hidden or notfile))\n\n        solc_input = {\n            'language': 'Solidity',\n            'sources': {\n                file_name: {\n                    'urls': [os.path.realpath(os.path.join(r, file_name))]\n                } for r, d, f in os.walk(self.contracts_dir) for file_name in f if legal(r, file_name)\n            },\n            'settings': {\n                'optimizer': {\n                    'enabled': 1,\n                    'runs': 10000\n                },\n                'outputSelection': {\n                    \"*\": {\n                        \"\": [\n                            \"legacyAST\",\n                            \"ast\"\n                        ],\n                        \"*\": [\n                            \"abi\",\n                            \"evm.bytecode.object\",\n                            \"evm.bytecode.sourceMap\",\n                            \"evm.deployedBytecode.object\",\n                            \"evm.deployedBytecode.sourceMap\"\n                        ]\n                    }\n                }\n            }\n        }\n\n        return solc_input"}
